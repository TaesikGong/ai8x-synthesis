2024-02-26 16:30:18,830 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.02.26-163018/2024.02.26-163018.log
2024-02-26 16:30:22,008 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-02-26 16:30:22,008 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-02-26 16:33:48,744 - Dataset sizes:
	training=4428
	validation=1392
	test=1392
2024-02-26 16:33:48,746 - Reading compression schedule from: policies/schedule-camvid.yaml
2024-02-26 16:33:48,754 - 

2024-02-26 16:33:48,755 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:33:51,473 - Epoch: [0][   10/  139]    Overall Loss 1.331506    Objective Loss 1.331506                                        LR 0.001000    Time 0.271757    
2024-02-26 16:33:52,525 - Epoch: [0][   20/  139]    Overall Loss 1.270706    Objective Loss 1.270706                                        LR 0.001000    Time 0.188409    
2024-02-26 16:33:53,581 - Epoch: [0][   30/  139]    Overall Loss 1.234963    Objective Loss 1.234963                                        LR 0.001000    Time 0.160771    
2024-02-26 16:33:54,602 - Epoch: [0][   40/  139]    Overall Loss 1.213301    Objective Loss 1.213301                                        LR 0.001000    Time 0.146082    
2024-02-26 16:33:55,607 - Epoch: [0][   50/  139]    Overall Loss 1.199299    Objective Loss 1.199299                                        LR 0.001000    Time 0.136960    
2024-02-26 16:33:56,667 - Epoch: [0][   60/  139]    Overall Loss 1.187169    Objective Loss 1.187169                                        LR 0.001000    Time 0.131778    
2024-02-26 16:33:57,718 - Epoch: [0][   70/  139]    Overall Loss 1.178699    Objective Loss 1.178699                                        LR 0.001000    Time 0.127961    
2024-02-26 16:33:58,749 - Epoch: [0][   80/  139]    Overall Loss 1.170420    Objective Loss 1.170420                                        LR 0.001000    Time 0.124843    
2024-02-26 16:33:59,779 - Epoch: [0][   90/  139]    Overall Loss 1.164492    Objective Loss 1.164492                                        LR 0.001000    Time 0.122413    
2024-02-26 16:34:00,792 - Epoch: [0][  100/  139]    Overall Loss 1.159336    Objective Loss 1.159336                                        LR 0.001000    Time 0.120290    
2024-02-26 16:34:01,844 - Epoch: [0][  110/  139]    Overall Loss 1.154975    Objective Loss 1.154975                                        LR 0.001000    Time 0.118914    
2024-02-26 16:34:02,881 - Epoch: [0][  120/  139]    Overall Loss 1.151140    Objective Loss 1.151140                                        LR 0.001000    Time 0.117638    
2024-02-26 16:34:03,925 - Epoch: [0][  130/  139]    Overall Loss 1.148304    Objective Loss 1.148304                                        LR 0.001000    Time 0.116609    
2024-02-26 16:34:09,133 - Epoch: [0][  139/  139]    Overall Loss 1.145486    Objective Loss 1.145486    Top1 84.829659    LR 0.001000    Time 0.146522    
2024-02-26 16:34:09,324 - --- validate (epoch=0)-----------
2024-02-26 16:34:09,324 - 1392 samples (32 per mini-batch)
2024-02-26 16:34:43,064 - Epoch: [0][   10/   44]    Loss 1.145314    Top1 75.447077    
2024-02-26 16:35:15,985 - Epoch: [0][   20/   44]    Loss 1.147479    Top1 75.735235    
2024-02-26 16:35:48,143 - Epoch: [0][   30/   44]    Loss 1.152468    Top1 75.471193    
2024-02-26 16:36:20,381 - Epoch: [0][   40/   44]    Loss 1.153754    Top1 75.317851    
2024-02-26 16:36:31,647 - Epoch: [0][   44/   44]    Loss 1.155917    Top1 75.103819    
2024-02-26 16:36:31,834 - ==> Top1: 75.104    Loss: 1.156

2024-02-26 16:36:31,841 - ==> Best [Top1: 75.104   Sparsity:0.00   Params: 278176 on epoch: 0]
2024-02-26 16:36:31,842 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 16:36:31,874 - 

2024-02-26 16:36:31,875 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:36:33,805 - Epoch: [1][   10/  139]    Overall Loss 1.096225    Objective Loss 1.096225                                        LR 0.001000    Time 0.192840    
2024-02-26 16:36:34,827 - Epoch: [1][   20/  139]    Overall Loss 1.101397    Objective Loss 1.101397                                        LR 0.001000    Time 0.147471    
2024-02-26 16:36:35,851 - Epoch: [1][   30/  139]    Overall Loss 1.104438    Objective Loss 1.104438                                        LR 0.001000    Time 0.132419    
2024-02-26 16:36:36,895 - Epoch: [1][   40/  139]    Overall Loss 1.103383    Objective Loss 1.103383                                        LR 0.001000    Time 0.125404    
2024-02-26 16:36:37,919 - Epoch: [1][   50/  139]    Overall Loss 1.102963    Objective Loss 1.102963                                        LR 0.001000    Time 0.120765    
2024-02-26 16:36:38,946 - Epoch: [1][   60/  139]    Overall Loss 1.101966    Objective Loss 1.101966                                        LR 0.001000    Time 0.117746    
2024-02-26 16:36:40,017 - Epoch: [1][   70/  139]    Overall Loss 1.101133    Objective Loss 1.101133                                        LR 0.001000    Time 0.116216    
2024-02-26 16:36:41,056 - Epoch: [1][   80/  139]    Overall Loss 1.100093    Objective Loss 1.100093                                        LR 0.001000    Time 0.114659    
2024-02-26 16:36:42,094 - Epoch: [1][   90/  139]    Overall Loss 1.099754    Objective Loss 1.099754                                        LR 0.001000    Time 0.113439    
2024-02-26 16:36:43,145 - Epoch: [1][  100/  139]    Overall Loss 1.098072    Objective Loss 1.098072                                        LR 0.001000    Time 0.112589    
2024-02-26 16:36:44,201 - Epoch: [1][  110/  139]    Overall Loss 1.097474    Objective Loss 1.097474                                        LR 0.001000    Time 0.111947    
2024-02-26 16:36:45,238 - Epoch: [1][  120/  139]    Overall Loss 1.096876    Objective Loss 1.096876                                        LR 0.001000    Time 0.111248    
2024-02-26 16:36:46,307 - Epoch: [1][  130/  139]    Overall Loss 1.096796    Objective Loss 1.096796                                        LR 0.001000    Time 0.110907    
2024-02-26 16:36:51,872 - Epoch: [1][  139/  139]    Overall Loss 1.096606    Objective Loss 1.096606    Top1 85.584166    LR 0.001000    Time 0.143764    
2024-02-26 16:36:52,141 - --- validate (epoch=1)-----------
2024-02-26 16:36:52,142 - 1392 samples (32 per mini-batch)
2024-02-26 16:37:26,725 - Epoch: [1][   10/   44]    Loss 1.130436    Top1 82.876436    
2024-02-26 16:37:57,979 - Epoch: [1][   20/   44]    Loss 1.126744    Top1 83.484602    
2024-02-26 16:38:31,516 - Epoch: [1][   30/   44]    Loss 1.127925    Top1 82.972674    
2024-02-26 16:39:02,162 - Epoch: [1][   40/   44]    Loss 1.126234    Top1 82.975219    
2024-02-26 16:39:12,192 - Epoch: [1][   44/   44]    Loss 1.127870    Top1 82.841221    
2024-02-26 16:39:12,488 - ==> Top1: 82.841    Loss: 1.128

2024-02-26 16:39:12,497 - ==> Best [Top1: 82.841   Sparsity:0.00   Params: 278176 on epoch: 1]
2024-02-26 16:39:12,497 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 16:39:12,538 - 

2024-02-26 16:39:12,538 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:39:14,332 - Epoch: [2][   10/  139]    Overall Loss 1.092159    Objective Loss 1.092159                                        LR 0.001000    Time 0.179221    
2024-02-26 16:39:15,343 - Epoch: [2][   20/  139]    Overall Loss 1.091883    Objective Loss 1.091883                                        LR 0.001000    Time 0.140132    
2024-02-26 16:39:16,404 - Epoch: [2][   30/  139]    Overall Loss 1.091552    Objective Loss 1.091552                                        LR 0.001000    Time 0.128755    
2024-02-26 16:39:17,409 - Epoch: [2][   40/  139]    Overall Loss 1.091354    Objective Loss 1.091354                                        LR 0.001000    Time 0.121694    
2024-02-26 16:39:18,421 - Epoch: [2][   50/  139]    Overall Loss 1.091028    Objective Loss 1.091028                                        LR 0.001000    Time 0.117571    
2024-02-26 16:39:19,464 - Epoch: [2][   60/  139]    Overall Loss 1.089673    Objective Loss 1.089673                                        LR 0.001000    Time 0.115352    
2024-02-26 16:39:20,442 - Epoch: [2][   70/  139]    Overall Loss 1.088817    Objective Loss 1.088817                                        LR 0.001000    Time 0.112840    
2024-02-26 16:39:21,441 - Epoch: [2][   80/  139]    Overall Loss 1.088904    Objective Loss 1.088904                                        LR 0.001000    Time 0.111214    
2024-02-26 16:39:22,449 - Epoch: [2][   90/  139]    Overall Loss 1.088054    Objective Loss 1.088054                                        LR 0.001000    Time 0.110040    
2024-02-26 16:39:23,449 - Epoch: [2][  100/  139]    Overall Loss 1.087528    Objective Loss 1.087528                                        LR 0.001000    Time 0.109030    
2024-02-26 16:39:24,467 - Epoch: [2][  110/  139]    Overall Loss 1.087382    Objective Loss 1.087382                                        LR 0.001000    Time 0.108368    
2024-02-26 16:39:25,535 - Epoch: [2][  120/  139]    Overall Loss 1.087455    Objective Loss 1.087455                                        LR 0.001000    Time 0.108230    
2024-02-26 16:39:26,582 - Epoch: [2][  130/  139]    Overall Loss 1.087492    Objective Loss 1.087492                                        LR 0.001000    Time 0.107954    
2024-02-26 16:39:32,021 - Epoch: [2][  139/  139]    Overall Loss 1.087272    Objective Loss 1.087272    Top1 89.905124    LR 0.001000    Time 0.140096    
2024-02-26 16:39:32,271 - --- validate (epoch=2)-----------
2024-02-26 16:39:32,273 - 1392 samples (32 per mini-batch)
2024-02-26 16:40:05,452 - Epoch: [2][   10/   44]    Loss 1.129992    Top1 78.270362    
2024-02-26 16:40:36,808 - Epoch: [2][   20/   44]    Loss 1.117874    Top1 79.967281    
2024-02-26 16:41:09,311 - Epoch: [2][   30/   44]    Loss 1.117683    Top1 79.668560    
2024-02-26 16:41:41,064 - Epoch: [2][   40/   44]    Loss 1.113598    Top1 80.121362    
2024-02-26 16:41:51,887 - Epoch: [2][   44/   44]    Loss 1.114562    Top1 79.952142    
2024-02-26 16:41:52,190 - ==> Top1: 79.952    Loss: 1.115

2024-02-26 16:41:52,196 - ==> Best [Top1: 82.841   Sparsity:0.00   Params: 278176 on epoch: 1]
2024-02-26 16:41:52,197 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 16:41:52,228 - 

2024-02-26 16:41:52,229 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:41:54,003 - Epoch: [3][   10/  139]    Overall Loss 1.081040    Objective Loss 1.081040                                        LR 0.001000    Time 0.177276    
2024-02-26 16:41:55,012 - Epoch: [3][   20/  139]    Overall Loss 1.084477    Objective Loss 1.084477                                        LR 0.001000    Time 0.139000    
2024-02-26 16:41:55,996 - Epoch: [3][   30/  139]    Overall Loss 1.084284    Objective Loss 1.084284                                        LR 0.001000    Time 0.125469    
2024-02-26 16:41:56,995 - Epoch: [3][   40/  139]    Overall Loss 1.084534    Objective Loss 1.084534                                        LR 0.001000    Time 0.119042    
2024-02-26 16:41:57,999 - Epoch: [3][   50/  139]    Overall Loss 1.084203    Objective Loss 1.084203                                        LR 0.001000    Time 0.115040    
2024-02-26 16:41:59,031 - Epoch: [3][   60/  139]    Overall Loss 1.085081    Objective Loss 1.085081                                        LR 0.001000    Time 0.113045    
2024-02-26 16:42:00,057 - Epoch: [3][   70/  139]    Overall Loss 1.084173    Objective Loss 1.084173                                        LR 0.001000    Time 0.111550    
2024-02-26 16:42:01,184 - Epoch: [3][   80/  139]    Overall Loss 1.082883    Objective Loss 1.082883                                        LR 0.001000    Time 0.111685    
2024-02-26 16:42:02,185 - Epoch: [3][   90/  139]    Overall Loss 1.082469    Objective Loss 1.082469                                        LR 0.001000    Time 0.110381    
2024-02-26 16:42:03,235 - Epoch: [3][  100/  139]    Overall Loss 1.081971    Objective Loss 1.081971                                        LR 0.001000    Time 0.109836    
2024-02-26 16:42:04,279 - Epoch: [3][  110/  139]    Overall Loss 1.082625    Objective Loss 1.082625                                        LR 0.001000    Time 0.109333    
2024-02-26 16:42:05,366 - Epoch: [3][  120/  139]    Overall Loss 1.083070    Objective Loss 1.083070                                        LR 0.001000    Time 0.109271    
2024-02-26 16:42:06,499 - Epoch: [3][  130/  139]    Overall Loss 1.082800    Objective Loss 1.082800                                        LR 0.001000    Time 0.109580    
2024-02-26 16:42:11,735 - Epoch: [3][  139/  139]    Overall Loss 1.082985    Objective Loss 1.082985    Top1 89.095517    LR 0.001000    Time 0.140147    
2024-02-26 16:42:11,969 - --- validate (epoch=3)-----------
2024-02-26 16:42:11,970 - 1392 samples (32 per mini-batch)
2024-02-26 16:42:42,182 - Epoch: [3][   10/   44]    Loss 1.091877    Top1 87.037396    
2024-02-26 16:43:11,424 - Epoch: [3][   20/   44]    Loss 1.087387    Top1 86.979056    
2024-02-26 16:43:40,257 - Epoch: [3][   30/   44]    Loss 1.088655    Top1 86.873342    
2024-02-26 16:44:10,407 - Epoch: [3][   40/   44]    Loss 1.089524    Top1 86.569529    
2024-02-26 16:44:20,858 - Epoch: [3][   44/   44]    Loss 1.088610    Top1 86.731819    
2024-02-26 16:44:21,071 - ==> Top1: 86.732    Loss: 1.089

2024-02-26 16:44:21,081 - ==> Best [Top1: 86.732   Sparsity:0.00   Params: 278176 on epoch: 3]
2024-02-26 16:44:21,081 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 16:44:21,118 - 

2024-02-26 16:44:21,118 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:44:23,015 - Epoch: [4][   10/  139]    Overall Loss 1.094236    Objective Loss 1.094236                                        LR 0.001000    Time 0.189622    
2024-02-26 16:44:23,978 - Epoch: [4][   20/  139]    Overall Loss 1.089271    Objective Loss 1.089271                                        LR 0.001000    Time 0.142900    
2024-02-26 16:44:25,038 - Epoch: [4][   30/  139]    Overall Loss 1.087294    Objective Loss 1.087294                                        LR 0.001000    Time 0.130554    
2024-02-26 16:44:26,032 - Epoch: [4][   40/  139]    Overall Loss 1.083246    Objective Loss 1.083246                                        LR 0.001000    Time 0.122755    
2024-02-26 16:44:27,141 - Epoch: [4][   50/  139]    Overall Loss 1.081790    Objective Loss 1.081790                                        LR 0.001000    Time 0.120349    
2024-02-26 16:44:28,289 - Epoch: [4][   60/  139]    Overall Loss 1.080294    Objective Loss 1.080294                                        LR 0.001000    Time 0.119407    
2024-02-26 16:44:29,323 - Epoch: [4][   70/  139]    Overall Loss 1.080010    Objective Loss 1.080010                                        LR 0.001000    Time 0.117103    
2024-02-26 16:44:30,324 - Epoch: [4][   80/  139]    Overall Loss 1.079935    Objective Loss 1.079935                                        LR 0.001000    Time 0.114972    
2024-02-26 16:44:31,341 - Epoch: [4][   90/  139]    Overall Loss 1.080588    Objective Loss 1.080588                                        LR 0.001000    Time 0.113481    
2024-02-26 16:44:32,343 - Epoch: [4][  100/  139]    Overall Loss 1.080721    Objective Loss 1.080721                                        LR 0.001000    Time 0.112148    
2024-02-26 16:44:33,367 - Epoch: [4][  110/  139]    Overall Loss 1.080394    Objective Loss 1.080394                                        LR 0.001000    Time 0.111258    
2024-02-26 16:44:34,378 - Epoch: [4][  120/  139]    Overall Loss 1.080079    Objective Loss 1.080079                                        LR 0.001000    Time 0.110406    
2024-02-26 16:44:35,387 - Epoch: [4][  130/  139]    Overall Loss 1.079995    Objective Loss 1.079995                                        LR 0.001000    Time 0.109665    
2024-02-26 16:44:40,286 - Epoch: [4][  139/  139]    Overall Loss 1.079974    Objective Loss 1.079974    Top1 87.909555    LR 0.001000    Time 0.137807    
2024-02-26 16:44:40,578 - --- validate (epoch=4)-----------
2024-02-26 16:44:40,579 - 1392 samples (32 per mini-batch)
2024-02-26 16:45:14,259 - Epoch: [4][   10/   44]    Loss 1.090859    Top1 85.004681    
2024-02-26 16:45:45,375 - Epoch: [4][   20/   44]    Loss 1.089840    Top1 85.262276    
2024-02-26 16:46:17,292 - Epoch: [4][   30/   44]    Loss 1.089414    Top1 85.061307    
2024-02-26 16:46:48,297 - Epoch: [4][   40/   44]    Loss 1.085878    Top1 85.422390    
2024-02-26 16:46:58,560 - Epoch: [4][   44/   44]    Loss 1.085797    Top1 85.417284    
2024-02-26 16:46:58,843 - ==> Top1: 85.417    Loss: 1.086

2024-02-26 16:46:58,850 - ==> Best [Top1: 86.732   Sparsity:0.00   Params: 278176 on epoch: 3]
2024-02-26 16:46:58,850 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 16:46:58,890 - 

2024-02-26 16:46:58,890 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:47:00,696 - Epoch: [5][   10/  139]    Overall Loss 1.074541    Objective Loss 1.074541                                        LR 0.001000    Time 0.180482    
2024-02-26 16:47:01,686 - Epoch: [5][   20/  139]    Overall Loss 1.078427    Objective Loss 1.078427                                        LR 0.001000    Time 0.139671    
2024-02-26 16:47:02,689 - Epoch: [5][   30/  139]    Overall Loss 1.080061    Objective Loss 1.080061                                        LR 0.001000    Time 0.126537    
2024-02-26 16:47:03,714 - Epoch: [5][   40/  139]    Overall Loss 1.079868    Objective Loss 1.079868                                        LR 0.001000    Time 0.120507    
2024-02-26 16:47:04,704 - Epoch: [5][   50/  139]    Overall Loss 1.077688    Objective Loss 1.077688                                        LR 0.001000    Time 0.116185    
2024-02-26 16:47:05,703 - Epoch: [5][   60/  139]    Overall Loss 1.077815    Objective Loss 1.077815                                        LR 0.001000    Time 0.113456    
2024-02-26 16:47:06,735 - Epoch: [5][   70/  139]    Overall Loss 1.077512    Objective Loss 1.077512                                        LR 0.001000    Time 0.111983    
2024-02-26 16:47:07,725 - Epoch: [5][   80/  139]    Overall Loss 1.076993    Objective Loss 1.076993                                        LR 0.001000    Time 0.110360    
2024-02-26 16:47:08,721 - Epoch: [5][   90/  139]    Overall Loss 1.076587    Objective Loss 1.076587                                        LR 0.001000    Time 0.109148    
2024-02-26 16:47:09,730 - Epoch: [5][  100/  139]    Overall Loss 1.077265    Objective Loss 1.077265                                        LR 0.001000    Time 0.108321    
2024-02-26 16:47:10,809 - Epoch: [5][  110/  139]    Overall Loss 1.077434    Objective Loss 1.077434                                        LR 0.001000    Time 0.108273    
2024-02-26 16:47:11,916 - Epoch: [5][  120/  139]    Overall Loss 1.077354    Objective Loss 1.077354                                        LR 0.001000    Time 0.108475    
2024-02-26 16:47:12,926 - Epoch: [5][  130/  139]    Overall Loss 1.077221    Objective Loss 1.077221                                        LR 0.001000    Time 0.107891    
2024-02-26 16:47:18,175 - Epoch: [5][  139/  139]    Overall Loss 1.078245    Objective Loss 1.078245    Top1 86.759489    LR 0.001000    Time 0.138667    
2024-02-26 16:47:18,458 - --- validate (epoch=5)-----------
2024-02-26 16:47:18,460 - 1392 samples (32 per mini-batch)
2024-02-26 16:47:50,694 - Epoch: [5][   10/   44]    Loss 1.086249    Top1 85.033685    
2024-02-26 16:48:18,619 - Epoch: [5][   20/   44]    Loss 1.082877    Top1 85.281889    
2024-02-26 16:48:46,676 - Epoch: [5][   30/   44]    Loss 1.087177    Top1 85.014731    
2024-02-26 16:49:15,176 - Epoch: [5][   40/   44]    Loss 1.082758    Top1 85.617576    
2024-02-26 16:49:26,395 - Epoch: [5][   44/   44]    Loss 1.081003    Top1 85.587956    
2024-02-26 16:49:26,688 - ==> Top1: 85.588    Loss: 1.081

2024-02-26 16:49:26,695 - ==> Best [Top1: 86.732   Sparsity:0.00   Params: 278176 on epoch: 3]
2024-02-26 16:49:26,695 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 16:49:26,727 - 

2024-02-26 16:49:26,727 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:49:28,745 - Epoch: [6][   10/  139]    Overall Loss 1.076967    Objective Loss 1.076967                                        LR 0.001000    Time 0.201594    
2024-02-26 16:49:29,758 - Epoch: [6][   20/  139]    Overall Loss 1.079324    Objective Loss 1.079324                                        LR 0.001000    Time 0.151388    
2024-02-26 16:49:30,778 - Epoch: [6][   30/  139]    Overall Loss 1.078194    Objective Loss 1.078194                                        LR 0.001000    Time 0.134889    
2024-02-26 16:49:31,803 - Epoch: [6][   40/  139]    Overall Loss 1.077270    Objective Loss 1.077270                                        LR 0.001000    Time 0.126761    
2024-02-26 16:49:32,824 - Epoch: [6][   50/  139]    Overall Loss 1.076329    Objective Loss 1.076329                                        LR 0.001000    Time 0.121581    
2024-02-26 16:49:33,826 - Epoch: [6][   60/  139]    Overall Loss 1.074568    Objective Loss 1.074568                                        LR 0.001000    Time 0.118004    
2024-02-26 16:49:34,840 - Epoch: [6][   70/  139]    Overall Loss 1.074712    Objective Loss 1.074712                                        LR 0.001000    Time 0.115611    
2024-02-26 16:49:35,868 - Epoch: [6][   80/  139]    Overall Loss 1.074633    Objective Loss 1.074633                                        LR 0.001000    Time 0.113998    
2024-02-26 16:49:36,896 - Epoch: [6][   90/  139]    Overall Loss 1.074215    Objective Loss 1.074215                                        LR 0.001000    Time 0.112740    
2024-02-26 16:49:37,926 - Epoch: [6][  100/  139]    Overall Loss 1.074182    Objective Loss 1.074182                                        LR 0.001000    Time 0.111751    
2024-02-26 16:49:38,949 - Epoch: [6][  110/  139]    Overall Loss 1.073818    Objective Loss 1.073818                                        LR 0.001000    Time 0.110886    
2024-02-26 16:49:39,958 - Epoch: [6][  120/  139]    Overall Loss 1.073835    Objective Loss 1.073835                                        LR 0.001000    Time 0.110044    
2024-02-26 16:49:40,980 - Epoch: [6][  130/  139]    Overall Loss 1.074446    Objective Loss 1.074446                                        LR 0.001000    Time 0.109431    
2024-02-26 16:49:46,226 - Epoch: [6][  139/  139]    Overall Loss 1.074829    Objective Loss 1.074829    Top1 87.172419    LR 0.001000    Time 0.140083    
2024-02-26 16:49:46,606 - --- validate (epoch=6)-----------
2024-02-26 16:49:46,607 - 1392 samples (32 per mini-batch)
2024-02-26 16:50:20,756 - Epoch: [6][   10/   44]    Loss 1.117473    Top1 82.176665    
2024-02-26 16:50:53,536 - Epoch: [6][   20/   44]    Loss 1.118151    Top1 81.473051    
2024-02-26 16:51:26,150 - Epoch: [6][   30/   44]    Loss 1.116420    Top1 81.517368    
2024-02-26 16:51:53,700 - Epoch: [6][   40/   44]    Loss 1.115029    Top1 81.431628    
2024-02-26 16:52:02,832 - Epoch: [6][   44/   44]    Loss 1.114418    Top1 81.531866    
2024-02-26 16:52:03,056 - ==> Top1: 81.532    Loss: 1.114

2024-02-26 16:52:03,063 - ==> Best [Top1: 86.732   Sparsity:0.00   Params: 278176 on epoch: 3]
2024-02-26 16:52:03,063 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 16:52:03,096 - 

2024-02-26 16:52:03,096 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:52:05,135 - Epoch: [7][   10/  139]    Overall Loss 1.069193    Objective Loss 1.069193                                        LR 0.001000    Time 0.203721    
2024-02-26 16:52:06,126 - Epoch: [7][   20/  139]    Overall Loss 1.071346    Objective Loss 1.071346                                        LR 0.001000    Time 0.151344    
2024-02-26 16:52:07,130 - Epoch: [7][   30/  139]    Overall Loss 1.071107    Objective Loss 1.071107                                        LR 0.001000    Time 0.134347    
2024-02-26 16:52:08,149 - Epoch: [7][   40/  139]    Overall Loss 1.073474    Objective Loss 1.073474                                        LR 0.001000    Time 0.126225    
2024-02-26 16:52:09,118 - Epoch: [7][   50/  139]    Overall Loss 1.073668    Objective Loss 1.073668                                        LR 0.001000    Time 0.120341    
2024-02-26 16:52:10,105 - Epoch: [7][   60/  139]    Overall Loss 1.073161    Objective Loss 1.073161                                        LR 0.001000    Time 0.116724    
2024-02-26 16:52:11,182 - Epoch: [7][   70/  139]    Overall Loss 1.073968    Objective Loss 1.073968                                        LR 0.001000    Time 0.115417    
2024-02-26 16:52:12,193 - Epoch: [7][   80/  139]    Overall Loss 1.074039    Objective Loss 1.074039                                        LR 0.001000    Time 0.113615    
2024-02-26 16:52:13,176 - Epoch: [7][   90/  139]    Overall Loss 1.075437    Objective Loss 1.075437                                        LR 0.001000    Time 0.111905    
2024-02-26 16:52:14,207 - Epoch: [7][  100/  139]    Overall Loss 1.074645    Objective Loss 1.074645                                        LR 0.001000    Time 0.111019    
2024-02-26 16:52:15,197 - Epoch: [7][  110/  139]    Overall Loss 1.075437    Objective Loss 1.075437                                        LR 0.001000    Time 0.109919    
2024-02-26 16:52:16,229 - Epoch: [7][  120/  139]    Overall Loss 1.075800    Objective Loss 1.075800                                        LR 0.001000    Time 0.109354    
2024-02-26 16:52:17,260 - Epoch: [7][  130/  139]    Overall Loss 1.075608    Objective Loss 1.075608                                        LR 0.001000    Time 0.108871    
2024-02-26 16:52:22,610 - Epoch: [7][  139/  139]    Overall Loss 1.075681    Objective Loss 1.075681    Top1 88.718851    LR 0.001000    Time 0.140309    
2024-02-26 16:52:22,846 - --- validate (epoch=7)-----------
2024-02-26 16:52:22,846 - 1392 samples (32 per mini-batch)
2024-02-26 16:52:52,364 - Epoch: [7][   10/   44]    Loss 1.082924    Top1 87.609202    
2024-02-26 16:53:19,323 - Epoch: [7][   20/   44]    Loss 1.082005    Top1 88.061909    
2024-02-26 16:53:48,122 - Epoch: [7][   30/   44]    Loss 1.079790    Top1 88.186154    
2024-02-26 16:54:18,970 - Epoch: [7][   40/   44]    Loss 1.078949    Top1 88.287465    
2024-02-26 16:54:29,579 - Epoch: [7][   44/   44]    Loss 1.078944    Top1 88.426490    
2024-02-26 16:54:29,845 - ==> Top1: 88.426    Loss: 1.079

2024-02-26 16:54:29,854 - ==> Best [Top1: 88.426   Sparsity:0.00   Params: 278176 on epoch: 7]
2024-02-26 16:54:29,854 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 16:54:29,888 - 

2024-02-26 16:54:29,888 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:54:31,841 - Epoch: [8][   10/  139]    Overall Loss 1.074888    Objective Loss 1.074888                                        LR 0.001000    Time 0.195125    
2024-02-26 16:54:32,873 - Epoch: [8][   20/  139]    Overall Loss 1.074068    Objective Loss 1.074068                                        LR 0.001000    Time 0.149093    
2024-02-26 16:54:33,904 - Epoch: [8][   30/  139]    Overall Loss 1.076207    Objective Loss 1.076207                                        LR 0.001000    Time 0.133751    
2024-02-26 16:54:34,969 - Epoch: [8][   40/  139]    Overall Loss 1.076023    Objective Loss 1.076023                                        LR 0.001000    Time 0.126916    
2024-02-26 16:54:35,974 - Epoch: [8][   50/  139]    Overall Loss 1.074082    Objective Loss 1.074082                                        LR 0.001000    Time 0.121619    
2024-02-26 16:54:36,986 - Epoch: [8][   60/  139]    Overall Loss 1.074135    Objective Loss 1.074135                                        LR 0.001000    Time 0.118208    
2024-02-26 16:54:38,001 - Epoch: [8][   70/  139]    Overall Loss 1.073463    Objective Loss 1.073463                                        LR 0.001000    Time 0.115799    
2024-02-26 16:54:39,019 - Epoch: [8][   80/  139]    Overall Loss 1.072527    Objective Loss 1.072527                                        LR 0.001000    Time 0.114040    
2024-02-26 16:54:40,032 - Epoch: [8][   90/  139]    Overall Loss 1.071523    Objective Loss 1.071523                                        LR 0.001000    Time 0.112621    
2024-02-26 16:54:41,046 - Epoch: [8][  100/  139]    Overall Loss 1.071178    Objective Loss 1.071178                                        LR 0.001000    Time 0.111491    
2024-02-26 16:54:42,087 - Epoch: [8][  110/  139]    Overall Loss 1.070944    Objective Loss 1.070944                                        LR 0.001000    Time 0.110808    
2024-02-26 16:54:43,114 - Epoch: [8][  120/  139]    Overall Loss 1.071991    Objective Loss 1.071991                                        LR 0.001000    Time 0.110124    
2024-02-26 16:54:44,128 - Epoch: [8][  130/  139]    Overall Loss 1.071997    Objective Loss 1.071997                                        LR 0.001000    Time 0.109448    
2024-02-26 16:54:49,721 - Epoch: [8][  139/  139]    Overall Loss 1.072174    Objective Loss 1.072174    Top1 90.645397    LR 0.001000    Time 0.142590    
2024-02-26 16:54:50,031 - --- validate (epoch=8)-----------
2024-02-26 16:54:50,032 - 1392 samples (32 per mini-batch)
2024-02-26 16:55:22,736 - Epoch: [8][   10/   44]    Loss 1.076495    Top1 89.319289    
2024-02-26 16:55:54,138 - Epoch: [8][   20/   44]    Loss 1.072319    Top1 89.432112    
2024-02-26 16:56:22,414 - Epoch: [8][   30/   44]    Loss 1.073128    Top1 89.068651    
2024-02-26 16:56:51,506 - Epoch: [8][   40/   44]    Loss 1.074014    Top1 88.648178    
2024-02-26 16:57:01,583 - Epoch: [8][   44/   44]    Loss 1.073312    Top1 88.731119    
2024-02-26 16:57:01,892 - ==> Top1: 88.731    Loss: 1.073

2024-02-26 16:57:01,899 - ==> Best [Top1: 88.731   Sparsity:0.00   Params: 278176 on epoch: 8]
2024-02-26 16:57:01,900 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 16:57:01,947 - 

2024-02-26 16:57:01,948 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:57:03,784 - Epoch: [9][   10/  139]    Overall Loss 1.073578    Objective Loss 1.073578                                        LR 0.001000    Time 0.183324    
2024-02-26 16:57:04,817 - Epoch: [9][   20/  139]    Overall Loss 1.068297    Objective Loss 1.068297                                        LR 0.001000    Time 0.143237    
2024-02-26 16:57:05,821 - Epoch: [9][   30/  139]    Overall Loss 1.073528    Objective Loss 1.073528                                        LR 0.001000    Time 0.128929    
2024-02-26 16:57:06,870 - Epoch: [9][   40/  139]    Overall Loss 1.073584    Objective Loss 1.073584                                        LR 0.001000    Time 0.122918    
2024-02-26 16:57:07,901 - Epoch: [9][   50/  139]    Overall Loss 1.073739    Objective Loss 1.073739                                        LR 0.001000    Time 0.118925    
2024-02-26 16:57:08,931 - Epoch: [9][   60/  139]    Overall Loss 1.072620    Objective Loss 1.072620                                        LR 0.001000    Time 0.116270    
2024-02-26 16:57:09,989 - Epoch: [9][   70/  139]    Overall Loss 1.073593    Objective Loss 1.073593                                        LR 0.001000    Time 0.114757    
2024-02-26 16:57:11,049 - Epoch: [9][   80/  139]    Overall Loss 1.074299    Objective Loss 1.074299                                        LR 0.001000    Time 0.113651    
2024-02-26 16:57:12,095 - Epoch: [9][   90/  139]    Overall Loss 1.074123    Objective Loss 1.074123                                        LR 0.001000    Time 0.112641    
2024-02-26 16:57:13,103 - Epoch: [9][  100/  139]    Overall Loss 1.073538    Objective Loss 1.073538                                        LR 0.001000    Time 0.111447    
2024-02-26 16:57:14,138 - Epoch: [9][  110/  139]    Overall Loss 1.072933    Objective Loss 1.072933                                        LR 0.001000    Time 0.110721    
2024-02-26 16:57:15,246 - Epoch: [9][  120/  139]    Overall Loss 1.072787    Objective Loss 1.072787                                        LR 0.001000    Time 0.110720    
2024-02-26 16:57:16,300 - Epoch: [9][  130/  139]    Overall Loss 1.072893    Objective Loss 1.072893                                        LR 0.001000    Time 0.110305    
2024-02-26 16:57:21,013 - Epoch: [9][  139/  139]    Overall Loss 1.072830    Objective Loss 1.072830    Top1 91.160844    LR 0.001000    Time 0.137064    
2024-02-26 16:57:21,349 - --- validate (epoch=9)-----------
2024-02-26 16:57:21,350 - 1392 samples (32 per mini-batch)
2024-02-26 16:57:51,154 - Epoch: [9][   10/   44]    Loss 1.064025    Top1 90.354687    
2024-02-26 16:58:19,613 - Epoch: [9][   20/   44]    Loss 1.071071    Top1 90.073974    
2024-02-26 16:58:51,780 - Epoch: [9][   30/   44]    Loss 1.075946    Top1 89.612484    
2024-02-26 16:59:22,890 - Epoch: [9][   40/   44]    Loss 1.074767    Top1 89.425809    
2024-02-26 16:59:33,571 - Epoch: [9][   44/   44]    Loss 1.073889    Top1 89.347425    
2024-02-26 16:59:33,793 - ==> Top1: 89.347    Loss: 1.074

2024-02-26 16:59:33,800 - ==> Best [Top1: 89.347   Sparsity:0.00   Params: 278176 on epoch: 9]
2024-02-26 16:59:33,800 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 16:59:33,840 - 

2024-02-26 16:59:33,840 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:59:35,788 - Epoch: [10][   10/  139]    Overall Loss 1.067934    Objective Loss 1.067934                                        LR 0.001000    Time 0.194649    
2024-02-26 16:59:36,824 - Epoch: [10][   20/  139]    Overall Loss 1.070219    Objective Loss 1.070219                                        LR 0.001000    Time 0.149053    
2024-02-26 16:59:37,866 - Epoch: [10][   30/  139]    Overall Loss 1.067298    Objective Loss 1.067298                                        LR 0.001000    Time 0.134088    
2024-02-26 16:59:38,899 - Epoch: [10][   40/  139]    Overall Loss 1.066388    Objective Loss 1.066388                                        LR 0.001000    Time 0.126353    
2024-02-26 16:59:39,947 - Epoch: [10][   50/  139]    Overall Loss 1.066565    Objective Loss 1.066565                                        LR 0.001000    Time 0.121772    
2024-02-26 16:59:40,959 - Epoch: [10][   60/  139]    Overall Loss 1.068368    Objective Loss 1.068368                                        LR 0.001000    Time 0.118324    
2024-02-26 16:59:41,983 - Epoch: [10][   70/  139]    Overall Loss 1.068610    Objective Loss 1.068610                                        LR 0.001000    Time 0.116046    
2024-02-26 16:59:42,994 - Epoch: [10][   80/  139]    Overall Loss 1.067685    Objective Loss 1.067685                                        LR 0.001000    Time 0.114166    
2024-02-26 16:59:44,015 - Epoch: [10][   90/  139]    Overall Loss 1.067650    Objective Loss 1.067650                                        LR 0.001000    Time 0.112813    
2024-02-26 16:59:45,023 - Epoch: [10][  100/  139]    Overall Loss 1.067588    Objective Loss 1.067588                                        LR 0.001000    Time 0.111603    
2024-02-26 16:59:46,038 - Epoch: [10][  110/  139]    Overall Loss 1.068328    Objective Loss 1.068328                                        LR 0.001000    Time 0.110680    
2024-02-26 16:59:47,069 - Epoch: [10][  120/  139]    Overall Loss 1.069068    Objective Loss 1.069068                                        LR 0.001000    Time 0.110039    
2024-02-26 16:59:48,072 - Epoch: [10][  130/  139]    Overall Loss 1.069143    Objective Loss 1.069143                                        LR 0.001000    Time 0.109283    
2024-02-26 16:59:53,265 - Epoch: [10][  139/  139]    Overall Loss 1.069227    Objective Loss 1.069227    Top1 92.865554    LR 0.001000    Time 0.139564    
2024-02-26 16:59:53,447 - --- validate (epoch=10)-----------
2024-02-26 16:59:53,448 - 1392 samples (32 per mini-batch)
2024-02-26 17:00:27,346 - Epoch: [10][   10/   44]    Loss 1.070112    Top1 88.963956    
2024-02-26 17:00:57,700 - Epoch: [10][   20/   44]    Loss 1.074336    Top1 88.652873    
2024-02-26 17:01:27,085 - Epoch: [10][   30/   44]    Loss 1.073806    Top1 88.761499    
2024-02-26 17:01:57,380 - Epoch: [10][   40/   44]    Loss 1.073642    Top1 88.677656    
2024-02-26 17:02:07,561 - Epoch: [10][   44/   44]    Loss 1.073326    Top1 88.694256    
2024-02-26 17:02:08,003 - ==> Top1: 88.694    Loss: 1.073

2024-02-26 17:02:08,010 - ==> Best [Top1: 89.347   Sparsity:0.00   Params: 278176 on epoch: 9]
2024-02-26 17:02:08,010 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:02:08,043 - 

2024-02-26 17:02:08,043 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:02:09,987 - Epoch: [11][   10/  139]    Overall Loss 1.055721    Objective Loss 1.055721                                        LR 0.001000    Time 0.194229    
2024-02-26 17:02:11,046 - Epoch: [11][   20/  139]    Overall Loss 1.063017    Objective Loss 1.063017                                        LR 0.001000    Time 0.150029    
2024-02-26 17:02:12,072 - Epoch: [11][   30/  139]    Overall Loss 1.062360    Objective Loss 1.062360                                        LR 0.001000    Time 0.134175    
2024-02-26 17:02:13,153 - Epoch: [11][   40/  139]    Overall Loss 1.064076    Objective Loss 1.064076                                        LR 0.001000    Time 0.127636    
2024-02-26 17:02:14,198 - Epoch: [11][   50/  139]    Overall Loss 1.065056    Objective Loss 1.065056                                        LR 0.001000    Time 0.123000    
2024-02-26 17:02:15,197 - Epoch: [11][   60/  139]    Overall Loss 1.064427    Objective Loss 1.064427                                        LR 0.001000    Time 0.119137    
2024-02-26 17:02:16,251 - Epoch: [11][   70/  139]    Overall Loss 1.064979    Objective Loss 1.064979                                        LR 0.001000    Time 0.117160    
2024-02-26 17:02:17,308 - Epoch: [11][   80/  139]    Overall Loss 1.066204    Objective Loss 1.066204                                        LR 0.001000    Time 0.115721    
2024-02-26 17:02:18,360 - Epoch: [11][   90/  139]    Overall Loss 1.066430    Objective Loss 1.066430                                        LR 0.001000    Time 0.114545    
2024-02-26 17:02:19,432 - Epoch: [11][  100/  139]    Overall Loss 1.066986    Objective Loss 1.066986                                        LR 0.001000    Time 0.113802    
2024-02-26 17:02:20,502 - Epoch: [11][  110/  139]    Overall Loss 1.067221    Objective Loss 1.067221                                        LR 0.001000    Time 0.113173    
2024-02-26 17:02:21,537 - Epoch: [11][  120/  139]    Overall Loss 1.067578    Objective Loss 1.067578                                        LR 0.001000    Time 0.112365    
2024-02-26 17:02:22,587 - Epoch: [11][  130/  139]    Overall Loss 1.067816    Objective Loss 1.067816                                        LR 0.001000    Time 0.111788    
2024-02-26 17:02:27,774 - Epoch: [11][  139/  139]    Overall Loss 1.068074    Objective Loss 1.068074    Top1 88.375495    LR 0.001000    Time 0.141865    
2024-02-26 17:02:28,037 - --- validate (epoch=11)-----------
2024-02-26 17:02:28,038 - 1392 samples (32 per mini-batch)
2024-02-26 17:02:58,618 - Epoch: [11][   10/   44]    Loss 1.083946    Top1 87.418309    
2024-02-26 17:03:29,846 - Epoch: [11][   20/   44]    Loss 1.081828    Top1 87.167952    
2024-02-26 17:04:02,112 - Epoch: [11][   30/   44]    Loss 1.085792    Top1 86.887775    
2024-02-26 17:04:33,944 - Epoch: [11][   40/   44]    Loss 1.082568    Top1 86.829901    
2024-02-26 17:04:45,504 - Epoch: [11][   44/   44]    Loss 1.085030    Top1 86.726212    
2024-02-26 17:04:45,788 - ==> Top1: 86.726    Loss: 1.085

2024-02-26 17:04:45,796 - ==> Best [Top1: 89.347   Sparsity:0.00   Params: 278176 on epoch: 9]
2024-02-26 17:04:45,796 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:04:45,829 - 

2024-02-26 17:04:45,829 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:04:47,701 - Epoch: [12][   10/  139]    Overall Loss 1.078124    Objective Loss 1.078124                                        LR 0.001000    Time 0.187062    
2024-02-26 17:04:48,712 - Epoch: [12][   20/  139]    Overall Loss 1.073151    Objective Loss 1.073151                                        LR 0.001000    Time 0.144043    
2024-02-26 17:04:49,715 - Epoch: [12][   30/  139]    Overall Loss 1.073109    Objective Loss 1.073109                                        LR 0.001000    Time 0.129443    
2024-02-26 17:04:50,745 - Epoch: [12][   40/  139]    Overall Loss 1.075365    Objective Loss 1.075365                                        LR 0.001000    Time 0.122785    
2024-02-26 17:04:51,764 - Epoch: [12][   50/  139]    Overall Loss 1.073667    Objective Loss 1.073667                                        LR 0.001000    Time 0.118599    
2024-02-26 17:04:52,762 - Epoch: [12][   60/  139]    Overall Loss 1.073150    Objective Loss 1.073150                                        LR 0.001000    Time 0.115464    
2024-02-26 17:04:53,764 - Epoch: [12][   70/  139]    Overall Loss 1.073080    Objective Loss 1.073080                                        LR 0.001000    Time 0.113274    
2024-02-26 17:04:54,754 - Epoch: [12][   80/  139]    Overall Loss 1.071934    Objective Loss 1.071934                                        LR 0.001000    Time 0.111483    
2024-02-26 17:04:55,782 - Epoch: [12][   90/  139]    Overall Loss 1.071777    Objective Loss 1.071777                                        LR 0.001000    Time 0.110364    
2024-02-26 17:04:56,765 - Epoch: [12][  100/  139]    Overall Loss 1.071286    Objective Loss 1.071286                                        LR 0.001000    Time 0.109148    
2024-02-26 17:04:57,773 - Epoch: [12][  110/  139]    Overall Loss 1.070990    Objective Loss 1.070990                                        LR 0.001000    Time 0.108384    
2024-02-26 17:04:58,766 - Epoch: [12][  120/  139]    Overall Loss 1.070167    Objective Loss 1.070167                                        LR 0.001000    Time 0.107629    
2024-02-26 17:04:59,768 - Epoch: [12][  130/  139]    Overall Loss 1.069963    Objective Loss 1.069963                                        LR 0.001000    Time 0.107050    
2024-02-26 17:05:05,193 - Epoch: [12][  139/  139]    Overall Loss 1.069346    Objective Loss 1.069346    Top1 89.274578    LR 0.001000    Time 0.139141    
2024-02-26 17:05:05,444 - --- validate (epoch=12)-----------
2024-02-26 17:05:05,445 - 1392 samples (32 per mini-batch)
2024-02-26 17:05:36,513 - Epoch: [12][   10/   44]    Loss 1.068122    Top1 89.128342    
2024-02-26 17:06:04,215 - Epoch: [12][   20/   44]    Loss 1.065375    Top1 89.526232    
2024-02-26 17:06:29,322 - Epoch: [12][   30/   44]    Loss 1.065236    Top1 89.334129    
2024-02-26 17:06:53,238 - Epoch: [12][   40/   44]    Loss 1.068196    Top1 89.326200    
2024-02-26 17:07:01,644 - Epoch: [12][   44/   44]    Loss 1.069078    Top1 89.402582    
2024-02-26 17:07:01,851 - ==> Top1: 89.403    Loss: 1.069

2024-02-26 17:07:01,858 - ==> Best [Top1: 89.403   Sparsity:0.00   Params: 278176 on epoch: 12]
2024-02-26 17:07:01,858 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:07:01,895 - 

2024-02-26 17:07:01,895 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:07:03,751 - Epoch: [13][   10/  139]    Overall Loss 1.065514    Objective Loss 1.065514                                        LR 0.001000    Time 0.185475    
2024-02-26 17:07:04,774 - Epoch: [13][   20/  139]    Overall Loss 1.064072    Objective Loss 1.064072                                        LR 0.001000    Time 0.143852    
2024-02-26 17:07:05,784 - Epoch: [13][   30/  139]    Overall Loss 1.061047    Objective Loss 1.061047                                        LR 0.001000    Time 0.129517    
2024-02-26 17:07:06,797 - Epoch: [13][   40/  139]    Overall Loss 1.062656    Objective Loss 1.062656                                        LR 0.001000    Time 0.122448    
2024-02-26 17:07:07,800 - Epoch: [13][   50/  139]    Overall Loss 1.064119    Objective Loss 1.064119                                        LR 0.001000    Time 0.117996    
2024-02-26 17:07:08,809 - Epoch: [13][   60/  139]    Overall Loss 1.065473    Objective Loss 1.065473                                        LR 0.001000    Time 0.115142    
2024-02-26 17:07:09,796 - Epoch: [13][   70/  139]    Overall Loss 1.064891    Objective Loss 1.064891                                        LR 0.001000    Time 0.112777    
2024-02-26 17:07:10,793 - Epoch: [13][   80/  139]    Overall Loss 1.066164    Objective Loss 1.066164                                        LR 0.001000    Time 0.111135    
2024-02-26 17:07:11,796 - Epoch: [13][   90/  139]    Overall Loss 1.066436    Objective Loss 1.066436                                        LR 0.001000    Time 0.109924    
2024-02-26 17:07:12,779 - Epoch: [13][  100/  139]    Overall Loss 1.066013    Objective Loss 1.066013                                        LR 0.001000    Time 0.108755    
2024-02-26 17:07:13,770 - Epoch: [13][  110/  139]    Overall Loss 1.065938    Objective Loss 1.065938                                        LR 0.001000    Time 0.107869    
2024-02-26 17:07:14,767 - Epoch: [13][  120/  139]    Overall Loss 1.066065    Objective Loss 1.066065                                        LR 0.001000    Time 0.107179    
2024-02-26 17:07:15,773 - Epoch: [13][  130/  139]    Overall Loss 1.066606    Objective Loss 1.066606                                        LR 0.001000    Time 0.106665    
2024-02-26 17:07:20,651 - Epoch: [13][  139/  139]    Overall Loss 1.066290    Objective Loss 1.066290    Top1 91.074101    LR 0.001000    Time 0.134849    
2024-02-26 17:07:20,850 - --- validate (epoch=13)-----------
2024-02-26 17:07:20,851 - 1392 samples (32 per mini-batch)
2024-02-26 17:07:54,076 - Epoch: [13][   10/   44]    Loss 1.070020    Top1 87.560475    
2024-02-26 17:08:25,083 - Epoch: [13][   20/   44]    Loss 1.077850    Top1 87.293430    
2024-02-26 17:08:57,066 - Epoch: [13][   30/   44]    Loss 1.076479    Top1 87.741264    
2024-02-26 17:09:29,978 - Epoch: [13][   40/   44]    Loss 1.078961    Top1 87.913854    
2024-02-26 17:09:40,697 - Epoch: [13][   44/   44]    Loss 1.077742    Top1 88.106219    
2024-02-26 17:09:40,928 - ==> Top1: 88.106    Loss: 1.078

2024-02-26 17:09:40,935 - ==> Best [Top1: 89.403   Sparsity:0.00   Params: 278176 on epoch: 12]
2024-02-26 17:09:40,935 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:09:40,975 - 

2024-02-26 17:09:40,975 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:09:42,762 - Epoch: [14][   10/  139]    Overall Loss 1.065338    Objective Loss 1.065338                                        LR 0.001000    Time 0.178543    
2024-02-26 17:09:43,771 - Epoch: [14][   20/  139]    Overall Loss 1.063134    Objective Loss 1.063134                                        LR 0.001000    Time 0.139657    
2024-02-26 17:09:44,762 - Epoch: [14][   30/  139]    Overall Loss 1.062969    Objective Loss 1.062969                                        LR 0.001000    Time 0.126094    
2024-02-26 17:09:45,767 - Epoch: [14][   40/  139]    Overall Loss 1.063991    Objective Loss 1.063991                                        LR 0.001000    Time 0.119697    
2024-02-26 17:09:46,795 - Epoch: [14][   50/  139]    Overall Loss 1.064977    Objective Loss 1.064977                                        LR 0.001000    Time 0.115933    
2024-02-26 17:09:47,800 - Epoch: [14][   60/  139]    Overall Loss 1.064394    Objective Loss 1.064394                                        LR 0.001000    Time 0.113345    
2024-02-26 17:09:48,847 - Epoch: [14][   70/  139]    Overall Loss 1.064004    Objective Loss 1.064004                                        LR 0.001000    Time 0.112105    
2024-02-26 17:09:49,970 - Epoch: [14][   80/  139]    Overall Loss 1.064155    Objective Loss 1.064155                                        LR 0.001000    Time 0.112116    
2024-02-26 17:09:51,007 - Epoch: [14][   90/  139]    Overall Loss 1.064078    Objective Loss 1.064078                                        LR 0.001000    Time 0.111178    
2024-02-26 17:09:52,057 - Epoch: [14][  100/  139]    Overall Loss 1.065088    Objective Loss 1.065088                                        LR 0.001000    Time 0.110546    
2024-02-26 17:09:53,078 - Epoch: [14][  110/  139]    Overall Loss 1.065962    Objective Loss 1.065962                                        LR 0.001000    Time 0.109775    
2024-02-26 17:09:54,063 - Epoch: [14][  120/  139]    Overall Loss 1.066126    Objective Loss 1.066126                                        LR 0.001000    Time 0.108825    
2024-02-26 17:09:55,085 - Epoch: [14][  130/  139]    Overall Loss 1.066032    Objective Loss 1.066032                                        LR 0.001000    Time 0.108312    
2024-02-26 17:09:59,580 - Epoch: [14][  139/  139]    Overall Loss 1.065898    Objective Loss 1.065898    Top1 91.756558    LR 0.001000    Time 0.133637    
2024-02-26 17:09:59,986 - --- validate (epoch=14)-----------
2024-02-26 17:09:59,986 - 1392 samples (32 per mini-batch)
2024-02-26 17:10:28,610 - Epoch: [14][   10/   44]    Loss 1.071152    Top1 88.390200    
2024-02-26 17:10:55,766 - Epoch: [14][   20/   44]    Loss 1.069345    Top1 89.097454    
2024-02-26 17:11:22,752 - Epoch: [14][   30/   44]    Loss 1.065926    Top1 89.647970    
2024-02-26 17:11:49,150 - Epoch: [14][   40/   44]    Loss 1.067947    Top1 89.604366    
2024-02-26 17:11:58,828 - Epoch: [14][   44/   44]    Loss 1.067810    Top1 89.530412    
2024-02-26 17:11:59,044 - ==> Top1: 89.530    Loss: 1.068

2024-02-26 17:11:59,051 - ==> Best [Top1: 89.530   Sparsity:0.00   Params: 278176 on epoch: 14]
2024-02-26 17:11:59,051 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:11:59,086 - 

2024-02-26 17:11:59,087 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:12:00,892 - Epoch: [15][   10/  139]    Overall Loss 1.067900    Objective Loss 1.067900                                        LR 0.001000    Time 0.180320    
2024-02-26 17:12:01,906 - Epoch: [15][   20/  139]    Overall Loss 1.062661    Objective Loss 1.062661                                        LR 0.001000    Time 0.140807    
2024-02-26 17:12:02,959 - Epoch: [15][   30/  139]    Overall Loss 1.064194    Objective Loss 1.064194                                        LR 0.001000    Time 0.128962    
2024-02-26 17:12:03,956 - Epoch: [15][   40/  139]    Overall Loss 1.064728    Objective Loss 1.064728                                        LR 0.001000    Time 0.121626    
2024-02-26 17:12:04,976 - Epoch: [15][   50/  139]    Overall Loss 1.066021    Objective Loss 1.066021                                        LR 0.001000    Time 0.117671    
2024-02-26 17:12:05,976 - Epoch: [15][   60/  139]    Overall Loss 1.064652    Objective Loss 1.064652                                        LR 0.001000    Time 0.114723    
2024-02-26 17:12:06,991 - Epoch: [15][   70/  139]    Overall Loss 1.064898    Objective Loss 1.064898                                        LR 0.001000    Time 0.112814    
2024-02-26 17:12:08,011 - Epoch: [15][   80/  139]    Overall Loss 1.064997    Objective Loss 1.064997                                        LR 0.001000    Time 0.111444    
2024-02-26 17:12:09,033 - Epoch: [15][   90/  139]    Overall Loss 1.064405    Objective Loss 1.064405                                        LR 0.001000    Time 0.110408    
2024-02-26 17:12:10,036 - Epoch: [15][  100/  139]    Overall Loss 1.064790    Objective Loss 1.064790                                        LR 0.001000    Time 0.109392    
2024-02-26 17:12:11,045 - Epoch: [15][  110/  139]    Overall Loss 1.064982    Objective Loss 1.064982                                        LR 0.001000    Time 0.108613    
2024-02-26 17:12:12,069 - Epoch: [15][  120/  139]    Overall Loss 1.065379    Objective Loss 1.065379                                        LR 0.001000    Time 0.108089    
2024-02-26 17:12:13,083 - Epoch: [15][  130/  139]    Overall Loss 1.065128    Objective Loss 1.065128                                        LR 0.001000    Time 0.107570    
2024-02-26 17:12:18,679 - Epoch: [15][  139/  139]    Overall Loss 1.065113    Objective Loss 1.065113    Top1 93.404204    LR 0.001000    Time 0.140854    
2024-02-26 17:12:18,961 - --- validate (epoch=15)-----------
2024-02-26 17:12:18,962 - 1392 samples (32 per mini-batch)
2024-02-26 17:12:51,172 - Epoch: [15][   10/   44]    Loss 1.101863    Top1 85.371686    
2024-02-26 17:13:22,930 - Epoch: [15][   20/   44]    Loss 1.106935    Top1 84.500430    
2024-02-26 17:13:54,419 - Epoch: [15][   30/   44]    Loss 1.107194    Top1 84.555572    
2024-02-26 17:14:23,872 - Epoch: [15][   40/   44]    Loss 1.105945    Top1 84.283020    
2024-02-26 17:14:33,473 - Epoch: [15][   44/   44]    Loss 1.105646    Top1 84.409690    
2024-02-26 17:14:33,711 - ==> Top1: 84.410    Loss: 1.106

2024-02-26 17:14:33,717 - ==> Best [Top1: 89.530   Sparsity:0.00   Params: 278176 on epoch: 14]
2024-02-26 17:14:33,718 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:14:33,749 - 

2024-02-26 17:14:33,749 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:14:35,523 - Epoch: [16][   10/  139]    Overall Loss 1.062106    Objective Loss 1.062106                                        LR 0.001000    Time 0.177186    
2024-02-26 17:14:36,551 - Epoch: [16][   20/  139]    Overall Loss 1.062380    Objective Loss 1.062380                                        LR 0.001000    Time 0.139967    
2024-02-26 17:14:37,607 - Epoch: [16][   30/  139]    Overall Loss 1.061034    Objective Loss 1.061034                                        LR 0.001000    Time 0.128489    
2024-02-26 17:14:38,609 - Epoch: [16][   40/  139]    Overall Loss 1.061489    Objective Loss 1.061489                                        LR 0.001000    Time 0.121392    
2024-02-26 17:14:39,625 - Epoch: [16][   50/  139]    Overall Loss 1.063399    Objective Loss 1.063399                                        LR 0.001000    Time 0.117423    
2024-02-26 17:14:40,611 - Epoch: [16][   60/  139]    Overall Loss 1.062293    Objective Loss 1.062293                                        LR 0.001000    Time 0.114259    
2024-02-26 17:14:41,606 - Epoch: [16][   70/  139]    Overall Loss 1.062955    Objective Loss 1.062955                                        LR 0.001000    Time 0.112140    
2024-02-26 17:14:42,611 - Epoch: [16][   80/  139]    Overall Loss 1.063313    Objective Loss 1.063313                                        LR 0.001000    Time 0.110675    
2024-02-26 17:14:43,639 - Epoch: [16][   90/  139]    Overall Loss 1.062851    Objective Loss 1.062851                                        LR 0.001000    Time 0.109788    
2024-02-26 17:14:44,675 - Epoch: [16][  100/  139]    Overall Loss 1.063630    Objective Loss 1.063630                                        LR 0.001000    Time 0.109152    
2024-02-26 17:14:45,781 - Epoch: [16][  110/  139]    Overall Loss 1.063227    Objective Loss 1.063227                                        LR 0.001000    Time 0.109278    
2024-02-26 17:14:46,882 - Epoch: [16][  120/  139]    Overall Loss 1.062719    Objective Loss 1.062719                                        LR 0.001000    Time 0.109336    
2024-02-26 17:14:47,966 - Epoch: [16][  130/  139]    Overall Loss 1.063198    Objective Loss 1.063198                                        LR 0.001000    Time 0.109259    
2024-02-26 17:14:53,378 - Epoch: [16][  139/  139]    Overall Loss 1.063927    Objective Loss 1.063927    Top1 90.709780    LR 0.001000    Time 0.141005    
2024-02-26 17:14:53,655 - --- validate (epoch=16)-----------
2024-02-26 17:14:53,656 - 1392 samples (32 per mini-batch)
2024-02-26 17:15:22,633 - Epoch: [16][   10/   44]    Loss 1.090248    Top1 88.204328    
2024-02-26 17:15:51,076 - Epoch: [16][   20/   44]    Loss 1.083607    Top1 88.818247    
2024-02-26 17:16:17,275 - Epoch: [16][   30/   44]    Loss 1.083060    Top1 88.759061    
2024-02-26 17:16:44,631 - Epoch: [16][   40/   44]    Loss 1.082666    Top1 88.779424    
2024-02-26 17:16:56,357 - Epoch: [16][   44/   44]    Loss 1.081391    Top1 88.905191    
2024-02-26 17:16:56,596 - ==> Top1: 88.905    Loss: 1.081

2024-02-26 17:16:56,603 - ==> Best [Top1: 89.530   Sparsity:0.00   Params: 278176 on epoch: 14]
2024-02-26 17:16:56,604 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:16:56,635 - 

2024-02-26 17:16:56,635 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:16:58,580 - Epoch: [17][   10/  139]    Overall Loss 1.060398    Objective Loss 1.060398                                        LR 0.001000    Time 0.194300    
2024-02-26 17:16:59,568 - Epoch: [17][   20/  139]    Overall Loss 1.061976    Objective Loss 1.061976                                        LR 0.001000    Time 0.146480    
2024-02-26 17:17:00,572 - Epoch: [17][   30/  139]    Overall Loss 1.062961    Objective Loss 1.062961                                        LR 0.001000    Time 0.131086    
2024-02-26 17:17:01,587 - Epoch: [17][   40/  139]    Overall Loss 1.064810    Objective Loss 1.064810                                        LR 0.001000    Time 0.123343    
2024-02-26 17:17:02,592 - Epoch: [17][   50/  139]    Overall Loss 1.064806    Objective Loss 1.064806                                        LR 0.001000    Time 0.118766    
2024-02-26 17:17:03,598 - Epoch: [17][   60/  139]    Overall Loss 1.063136    Objective Loss 1.063136                                        LR 0.001000    Time 0.115718    
2024-02-26 17:17:04,614 - Epoch: [17][   70/  139]    Overall Loss 1.062958    Objective Loss 1.062958                                        LR 0.001000    Time 0.113698    
2024-02-26 17:17:05,623 - Epoch: [17][   80/  139]    Overall Loss 1.061968    Objective Loss 1.061968                                        LR 0.001000    Time 0.112084    
2024-02-26 17:17:06,626 - Epoch: [17][   90/  139]    Overall Loss 1.063289    Objective Loss 1.063289                                        LR 0.001000    Time 0.110760    
2024-02-26 17:17:07,640 - Epoch: [17][  100/  139]    Overall Loss 1.064063    Objective Loss 1.064063                                        LR 0.001000    Time 0.109815    
2024-02-26 17:17:08,688 - Epoch: [17][  110/  139]    Overall Loss 1.063500    Objective Loss 1.063500                                        LR 0.001000    Time 0.109358    
2024-02-26 17:17:09,675 - Epoch: [17][  120/  139]    Overall Loss 1.063702    Objective Loss 1.063702                                        LR 0.001000    Time 0.108460    
2024-02-26 17:17:10,697 - Epoch: [17][  130/  139]    Overall Loss 1.063485    Objective Loss 1.063485                                        LR 0.001000    Time 0.107977    
2024-02-26 17:17:16,040 - Epoch: [17][  139/  139]    Overall Loss 1.064003    Objective Loss 1.064003    Top1 94.891279    LR 0.001000    Time 0.139419    
2024-02-26 17:17:16,235 - --- validate (epoch=17)-----------
2024-02-26 17:17:16,236 - 1392 samples (32 per mini-batch)
2024-02-26 17:17:48,580 - Epoch: [17][   10/   44]    Loss 1.097147    Top1 85.384224    
2024-02-26 17:18:19,519 - Epoch: [17][   20/   44]    Loss 1.090316    Top1 84.871009    
2024-02-26 17:18:50,095 - Epoch: [17][   30/   44]    Loss 1.090535    Top1 84.562740    
2024-02-26 17:19:20,081 - Epoch: [17][   40/   44]    Loss 1.091805    Top1 84.410131    
2024-02-26 17:19:30,626 - Epoch: [17][   44/   44]    Loss 1.090031    Top1 84.576990    
2024-02-26 17:19:30,937 - ==> Top1: 84.577    Loss: 1.090

2024-02-26 17:19:30,942 - ==> Best [Top1: 89.530   Sparsity:0.00   Params: 278176 on epoch: 14]
2024-02-26 17:19:30,942 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:19:30,974 - 

2024-02-26 17:19:30,975 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:19:32,852 - Epoch: [18][   10/  139]    Overall Loss 1.071715    Objective Loss 1.071715                                        LR 0.001000    Time 0.187475    
2024-02-26 17:19:33,867 - Epoch: [18][   20/  139]    Overall Loss 1.063110    Objective Loss 1.063110                                        LR 0.001000    Time 0.144436    
2024-02-26 17:19:34,896 - Epoch: [18][   30/  139]    Overall Loss 1.062832    Objective Loss 1.062832                                        LR 0.001000    Time 0.130564    
2024-02-26 17:19:35,936 - Epoch: [18][   40/  139]    Overall Loss 1.063512    Objective Loss 1.063512                                        LR 0.001000    Time 0.123368    
2024-02-26 17:19:36,948 - Epoch: [18][   50/  139]    Overall Loss 1.063310    Objective Loss 1.063310                                        LR 0.001000    Time 0.118937    
2024-02-26 17:19:38,001 - Epoch: [18][   60/  139]    Overall Loss 1.063193    Objective Loss 1.063193                                        LR 0.001000    Time 0.116646    
2024-02-26 17:19:39,035 - Epoch: [18][   70/  139]    Overall Loss 1.062478    Objective Loss 1.062478                                        LR 0.001000    Time 0.114756    
2024-02-26 17:19:40,082 - Epoch: [18][   80/  139]    Overall Loss 1.064126    Objective Loss 1.064126                                        LR 0.001000    Time 0.113490    
2024-02-26 17:19:41,112 - Epoch: [18][   90/  139]    Overall Loss 1.063309    Objective Loss 1.063309                                        LR 0.001000    Time 0.112307    
2024-02-26 17:19:42,202 - Epoch: [18][  100/  139]    Overall Loss 1.063216    Objective Loss 1.063216                                        LR 0.001000    Time 0.111970    
2024-02-26 17:19:43,291 - Epoch: [18][  110/  139]    Overall Loss 1.063218    Objective Loss 1.063218                                        LR 0.001000    Time 0.111692    
2024-02-26 17:19:44,402 - Epoch: [18][  120/  139]    Overall Loss 1.062664    Objective Loss 1.062664                                        LR 0.001000    Time 0.111637    
2024-02-26 17:19:45,477 - Epoch: [18][  130/  139]    Overall Loss 1.062507    Objective Loss 1.062507                                        LR 0.001000    Time 0.111304    
2024-02-26 17:19:50,834 - Epoch: [18][  139/  139]    Overall Loss 1.062228    Objective Loss 1.062228    Top1 91.398381    LR 0.001000    Time 0.142636    
2024-02-26 17:19:51,155 - --- validate (epoch=18)-----------
2024-02-26 17:19:51,156 - 1392 samples (32 per mini-batch)
2024-02-26 17:20:23,021 - Epoch: [18][   10/   44]    Loss 1.072050    Top1 89.126756    
2024-02-26 17:20:52,652 - Epoch: [18][   20/   44]    Loss 1.068614    Top1 89.764556    
2024-02-26 17:21:23,792 - Epoch: [18][   30/   44]    Loss 1.070073    Top1 89.831845    
2024-02-26 17:21:55,239 - Epoch: [18][   40/   44]    Loss 1.071430    Top1 89.849197    
2024-02-26 17:22:06,581 - Epoch: [18][   44/   44]    Loss 1.071415    Top1 89.785198    
2024-02-26 17:22:06,882 - ==> Top1: 89.785    Loss: 1.071

2024-02-26 17:22:06,888 - ==> Best [Top1: 89.785   Sparsity:0.00   Params: 278176 on epoch: 18]
2024-02-26 17:22:06,889 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:22:06,930 - 

2024-02-26 17:22:06,930 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:22:08,787 - Epoch: [19][   10/  139]    Overall Loss 1.056433    Objective Loss 1.056433                                        LR 0.001000    Time 0.185553    
2024-02-26 17:22:09,807 - Epoch: [19][   20/  139]    Overall Loss 1.063274    Objective Loss 1.063274                                        LR 0.001000    Time 0.143716    
2024-02-26 17:22:10,793 - Epoch: [19][   30/  139]    Overall Loss 1.063359    Objective Loss 1.063359                                        LR 0.001000    Time 0.128673    
2024-02-26 17:22:11,812 - Epoch: [19][   40/  139]    Overall Loss 1.063771    Objective Loss 1.063771                                        LR 0.001000    Time 0.121949    
2024-02-26 17:22:12,811 - Epoch: [19][   50/  139]    Overall Loss 1.064174    Objective Loss 1.064174                                        LR 0.001000    Time 0.117533    
2024-02-26 17:22:13,870 - Epoch: [19][   60/  139]    Overall Loss 1.062997    Objective Loss 1.062997                                        LR 0.001000    Time 0.115574    
2024-02-26 17:22:14,886 - Epoch: [19][   70/  139]    Overall Loss 1.063150    Objective Loss 1.063150                                        LR 0.001000    Time 0.113577    
2024-02-26 17:22:15,920 - Epoch: [19][   80/  139]    Overall Loss 1.063018    Objective Loss 1.063018                                        LR 0.001000    Time 0.112291    
2024-02-26 17:22:16,928 - Epoch: [19][   90/  139]    Overall Loss 1.063011    Objective Loss 1.063011                                        LR 0.001000    Time 0.111013    
2024-02-26 17:22:17,959 - Epoch: [19][  100/  139]    Overall Loss 1.062565    Objective Loss 1.062565                                        LR 0.001000    Time 0.110209    
2024-02-26 17:22:18,961 - Epoch: [19][  110/  139]    Overall Loss 1.062427    Objective Loss 1.062427                                        LR 0.001000    Time 0.109300    
2024-02-26 17:22:20,002 - Epoch: [19][  120/  139]    Overall Loss 1.061547    Objective Loss 1.061547                                        LR 0.001000    Time 0.108859    
2024-02-26 17:22:21,041 - Epoch: [19][  130/  139]    Overall Loss 1.061607    Objective Loss 1.061607                                        LR 0.001000    Time 0.108469    
2024-02-26 17:22:26,385 - Epoch: [19][  139/  139]    Overall Loss 1.061879    Objective Loss 1.061879    Top1 91.443247    LR 0.001000    Time 0.139887    
2024-02-26 17:22:26,635 - --- validate (epoch=19)-----------
2024-02-26 17:22:26,635 - 1392 samples (32 per mini-batch)
2024-02-26 17:22:59,602 - Epoch: [19][   10/   44]    Loss 1.060598    Top1 91.116557    
2024-02-26 17:23:31,934 - Epoch: [19][   20/   44]    Loss 1.059981    Top1 90.659395    
2024-02-26 17:24:04,519 - Epoch: [19][   30/   44]    Loss 1.061942    Top1 90.666781    
2024-02-26 17:24:36,525 - Epoch: [19][   40/   44]    Loss 1.060059    Top1 90.652296    
2024-02-26 17:24:47,640 - Epoch: [19][   44/   44]    Loss 1.059301    Top1 90.642612    
2024-02-26 17:24:47,936 - ==> Top1: 90.643    Loss: 1.059

2024-02-26 17:24:47,943 - ==> Best [Top1: 90.643   Sparsity:0.00   Params: 278176 on epoch: 19]
2024-02-26 17:24:47,943 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:24:47,979 - 

2024-02-26 17:24:47,979 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:24:49,850 - Epoch: [20][   10/  139]    Overall Loss 1.056278    Objective Loss 1.056278                                        LR 0.000500    Time 0.186980    
2024-02-26 17:24:50,885 - Epoch: [20][   20/  139]    Overall Loss 1.054402    Objective Loss 1.054402                                        LR 0.000500    Time 0.145211    
2024-02-26 17:24:51,889 - Epoch: [20][   30/  139]    Overall Loss 1.058734    Objective Loss 1.058734                                        LR 0.000500    Time 0.130239    
2024-02-26 17:24:52,955 - Epoch: [20][   40/  139]    Overall Loss 1.059417    Objective Loss 1.059417                                        LR 0.000500    Time 0.123918    
2024-02-26 17:24:54,000 - Epoch: [20][   50/  139]    Overall Loss 1.058579    Objective Loss 1.058579                                        LR 0.000500    Time 0.120022    
2024-02-26 17:24:55,034 - Epoch: [20][   60/  139]    Overall Loss 1.059530    Objective Loss 1.059530                                        LR 0.000500    Time 0.117236    
2024-02-26 17:24:56,035 - Epoch: [20][   70/  139]    Overall Loss 1.059440    Objective Loss 1.059440                                        LR 0.000500    Time 0.114776    
2024-02-26 17:24:57,081 - Epoch: [20][   80/  139]    Overall Loss 1.058690    Objective Loss 1.058690                                        LR 0.000500    Time 0.113505    
2024-02-26 17:24:58,138 - Epoch: [20][   90/  139]    Overall Loss 1.058778    Objective Loss 1.058778                                        LR 0.000500    Time 0.112620    
2024-02-26 17:24:59,195 - Epoch: [20][  100/  139]    Overall Loss 1.059415    Objective Loss 1.059415                                        LR 0.000500    Time 0.111924    
2024-02-26 17:25:00,209 - Epoch: [20][  110/  139]    Overall Loss 1.059212    Objective Loss 1.059212                                        LR 0.000500    Time 0.110963    
2024-02-26 17:25:01,243 - Epoch: [20][  120/  139]    Overall Loss 1.059373    Objective Loss 1.059373                                        LR 0.000500    Time 0.110328    
2024-02-26 17:25:02,278 - Epoch: [20][  130/  139]    Overall Loss 1.059965    Objective Loss 1.059965                                        LR 0.000500    Time 0.109798    
2024-02-26 17:25:07,663 - Epoch: [20][  139/  139]    Overall Loss 1.059993    Objective Loss 1.059993    Top1 93.451473    LR 0.000500    Time 0.141430    
2024-02-26 17:25:07,906 - --- validate (epoch=20)-----------
2024-02-26 17:25:07,907 - 1392 samples (32 per mini-batch)
2024-02-26 17:25:41,065 - Epoch: [20][   10/   44]    Loss 1.076878    Top1 89.061665    
2024-02-26 17:26:11,425 - Epoch: [20][   20/   44]    Loss 1.083420    Top1 88.279848    
2024-02-26 17:26:42,140 - Epoch: [20][   30/   44]    Loss 1.077871    Top1 88.504324    
2024-02-26 17:27:13,959 - Epoch: [20][   40/   44]    Loss 1.074610    Top1 88.612576    
2024-02-26 17:27:24,716 - Epoch: [20][   44/   44]    Loss 1.073709    Top1 88.678321    
2024-02-26 17:27:25,004 - ==> Top1: 88.678    Loss: 1.074

2024-02-26 17:27:25,012 - ==> Best [Top1: 90.643   Sparsity:0.00   Params: 278176 on epoch: 19]
2024-02-26 17:27:25,012 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:27:25,051 - 

2024-02-26 17:27:25,051 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:27:26,883 - Epoch: [21][   10/  139]    Overall Loss 1.057913    Objective Loss 1.057913                                        LR 0.000500    Time 0.183084    
2024-02-26 17:27:27,879 - Epoch: [21][   20/  139]    Overall Loss 1.057849    Objective Loss 1.057849                                        LR 0.000500    Time 0.141289    
2024-02-26 17:27:28,875 - Epoch: [21][   30/  139]    Overall Loss 1.058908    Objective Loss 1.058908                                        LR 0.000500    Time 0.127391    
2024-02-26 17:27:29,868 - Epoch: [21][   40/  139]    Overall Loss 1.059465    Objective Loss 1.059465                                        LR 0.000500    Time 0.120337    
2024-02-26 17:27:30,865 - Epoch: [21][   50/  139]    Overall Loss 1.057794    Objective Loss 1.057794                                        LR 0.000500    Time 0.116214    
2024-02-26 17:27:31,879 - Epoch: [21][   60/  139]    Overall Loss 1.057070    Objective Loss 1.057070                                        LR 0.000500    Time 0.113725    
2024-02-26 17:27:32,884 - Epoch: [21][   70/  139]    Overall Loss 1.057755    Objective Loss 1.057755                                        LR 0.000500    Time 0.111825    
2024-02-26 17:27:33,920 - Epoch: [21][   80/  139]    Overall Loss 1.057415    Objective Loss 1.057415                                        LR 0.000500    Time 0.110791    
2024-02-26 17:27:34,934 - Epoch: [21][   90/  139]    Overall Loss 1.057400    Objective Loss 1.057400                                        LR 0.000500    Time 0.109747    
2024-02-26 17:27:35,927 - Epoch: [21][  100/  139]    Overall Loss 1.058198    Objective Loss 1.058198                                        LR 0.000500    Time 0.108697    
2024-02-26 17:27:36,965 - Epoch: [21][  110/  139]    Overall Loss 1.058082    Objective Loss 1.058082                                        LR 0.000500    Time 0.108247    
2024-02-26 17:27:38,006 - Epoch: [21][  120/  139]    Overall Loss 1.058014    Objective Loss 1.058014                                        LR 0.000500    Time 0.107890    
2024-02-26 17:27:39,043 - Epoch: [21][  130/  139]    Overall Loss 1.057767    Objective Loss 1.057767                                        LR 0.000500    Time 0.107563    
2024-02-26 17:27:44,365 - Epoch: [21][  139/  139]    Overall Loss 1.057810    Objective Loss 1.057810    Top1 94.401788    LR 0.000500    Time 0.138877    
2024-02-26 17:27:44,716 - --- validate (epoch=21)-----------
2024-02-26 17:27:44,716 - 1392 samples (32 per mini-batch)
2024-02-26 17:28:17,273 - Epoch: [21][   10/   44]    Loss 1.064053    Top1 90.396262    
2024-02-26 17:28:47,524 - Epoch: [21][   20/   44]    Loss 1.070613    Top1 90.043826    
2024-02-26 17:29:17,093 - Epoch: [21][   30/   44]    Loss 1.068830    Top1 89.878796    
2024-02-26 17:29:46,628 - Epoch: [21][   40/   44]    Loss 1.065256    Top1 90.101841    
2024-02-26 17:29:56,662 - Epoch: [21][   44/   44]    Loss 1.066443    Top1 89.900066    
2024-02-26 17:29:56,965 - ==> Top1: 89.900    Loss: 1.066

2024-02-26 17:29:56,973 - ==> Best [Top1: 90.643   Sparsity:0.00   Params: 278176 on epoch: 19]
2024-02-26 17:29:56,973 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:29:57,008 - 

2024-02-26 17:29:57,009 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:29:58,955 - Epoch: [22][   10/  139]    Overall Loss 1.053010    Objective Loss 1.053010                                        LR 0.000500    Time 0.194471    
2024-02-26 17:29:59,994 - Epoch: [22][   20/  139]    Overall Loss 1.054724    Objective Loss 1.054724                                        LR 0.000500    Time 0.149151    
2024-02-26 17:30:00,973 - Epoch: [22][   30/  139]    Overall Loss 1.057215    Objective Loss 1.057215                                        LR 0.000500    Time 0.132050    
2024-02-26 17:30:02,009 - Epoch: [22][   40/  139]    Overall Loss 1.059666    Objective Loss 1.059666                                        LR 0.000500    Time 0.124948    
2024-02-26 17:30:03,009 - Epoch: [22][   50/  139]    Overall Loss 1.058743    Objective Loss 1.058743                                        LR 0.000500    Time 0.119933    
2024-02-26 17:30:04,050 - Epoch: [22][   60/  139]    Overall Loss 1.057840    Objective Loss 1.057840                                        LR 0.000500    Time 0.117292    
2024-02-26 17:30:05,050 - Epoch: [22][   70/  139]    Overall Loss 1.057628    Objective Loss 1.057628                                        LR 0.000500    Time 0.114801    
2024-02-26 17:30:06,069 - Epoch: [22][   80/  139]    Overall Loss 1.057136    Objective Loss 1.057136                                        LR 0.000500    Time 0.113185    
2024-02-26 17:30:07,055 - Epoch: [22][   90/  139]    Overall Loss 1.057257    Objective Loss 1.057257                                        LR 0.000500    Time 0.111556    
2024-02-26 17:30:08,074 - Epoch: [22][  100/  139]    Overall Loss 1.056925    Objective Loss 1.056925                                        LR 0.000500    Time 0.110588    
2024-02-26 17:30:09,096 - Epoch: [22][  110/  139]    Overall Loss 1.056321    Objective Loss 1.056321                                        LR 0.000500    Time 0.109821    
2024-02-26 17:30:10,131 - Epoch: [22][  120/  139]    Overall Loss 1.056597    Objective Loss 1.056597                                        LR 0.000500    Time 0.109291    
2024-02-26 17:30:11,218 - Epoch: [22][  130/  139]    Overall Loss 1.056694    Objective Loss 1.056694                                        LR 0.000500    Time 0.109242    
2024-02-26 17:30:16,449 - Epoch: [22][  139/  139]    Overall Loss 1.057611    Objective Loss 1.057611    Top1 94.405438    LR 0.000500    Time 0.139798    
2024-02-26 17:30:16,703 - --- validate (epoch=22)-----------
2024-02-26 17:30:16,704 - 1392 samples (32 per mini-batch)
2024-02-26 17:30:47,904 - Epoch: [22][   10/   44]    Loss 1.062738    Top1 88.807817    
2024-02-26 17:31:19,672 - Epoch: [22][   20/   44]    Loss 1.063608    Top1 89.620286    
2024-02-26 17:31:52,157 - Epoch: [22][   30/   44]    Loss 1.066988    Top1 89.945454    
2024-02-26 17:32:23,906 - Epoch: [22][   40/   44]    Loss 1.066206    Top1 90.080557    
2024-02-26 17:32:34,720 - Epoch: [22][   44/   44]    Loss 1.065551    Top1 90.052549    
2024-02-26 17:32:34,961 - ==> Top1: 90.053    Loss: 1.066

2024-02-26 17:32:34,968 - ==> Best [Top1: 90.643   Sparsity:0.00   Params: 278176 on epoch: 19]
2024-02-26 17:32:34,969 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:32:35,003 - 

2024-02-26 17:32:35,003 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:32:36,875 - Epoch: [23][   10/  139]    Overall Loss 1.061145    Objective Loss 1.061145                                        LR 0.000500    Time 0.186986    
2024-02-26 17:32:37,865 - Epoch: [23][   20/  139]    Overall Loss 1.058913    Objective Loss 1.058913                                        LR 0.000500    Time 0.142957    
2024-02-26 17:32:38,853 - Epoch: [23][   30/  139]    Overall Loss 1.058057    Objective Loss 1.058057                                        LR 0.000500    Time 0.128213    
2024-02-26 17:32:39,860 - Epoch: [23][   40/  139]    Overall Loss 1.056631    Objective Loss 1.056631                                        LR 0.000500    Time 0.121316    
2024-02-26 17:32:40,838 - Epoch: [23][   50/  139]    Overall Loss 1.058090    Objective Loss 1.058090                                        LR 0.000500    Time 0.116602    
2024-02-26 17:32:41,825 - Epoch: [23][   60/  139]    Overall Loss 1.057727    Objective Loss 1.057727                                        LR 0.000500    Time 0.113616    
2024-02-26 17:32:42,838 - Epoch: [23][   70/  139]    Overall Loss 1.059224    Objective Loss 1.059224                                        LR 0.000500    Time 0.111842    
2024-02-26 17:32:43,887 - Epoch: [23][   80/  139]    Overall Loss 1.060083    Objective Loss 1.060083                                        LR 0.000500    Time 0.110976    
2024-02-26 17:32:44,917 - Epoch: [23][   90/  139]    Overall Loss 1.058976    Objective Loss 1.058976                                        LR 0.000500    Time 0.110081    
2024-02-26 17:32:45,938 - Epoch: [23][  100/  139]    Overall Loss 1.058149    Objective Loss 1.058149                                        LR 0.000500    Time 0.109282    
2024-02-26 17:32:46,991 - Epoch: [23][  110/  139]    Overall Loss 1.058319    Objective Loss 1.058319                                        LR 0.000500    Time 0.108913    
2024-02-26 17:32:48,078 - Epoch: [23][  120/  139]    Overall Loss 1.058386    Objective Loss 1.058386                                        LR 0.000500    Time 0.108891    
2024-02-26 17:32:49,173 - Epoch: [23][  130/  139]    Overall Loss 1.057985    Objective Loss 1.057985                                        LR 0.000500    Time 0.108925    
2024-02-26 17:32:54,561 - Epoch: [23][  139/  139]    Overall Loss 1.057665    Objective Loss 1.057665    Top1 94.462502    LR 0.000500    Time 0.140633    
2024-02-26 17:32:54,882 - --- validate (epoch=23)-----------
2024-02-26 17:32:54,883 - 1392 samples (32 per mini-batch)
2024-02-26 17:33:27,668 - Epoch: [23][   10/   44]    Loss 1.064364    Top1 90.655021    
2024-02-26 17:33:58,881 - Epoch: [23][   20/   44]    Loss 1.065824    Top1 90.778490    
2024-02-26 17:34:27,817 - Epoch: [23][   30/   44]    Loss 1.067751    Top1 90.957031    
2024-02-26 17:34:56,517 - Epoch: [23][   40/   44]    Loss 1.067725    Top1 90.772735    
2024-02-26 17:35:06,869 - Epoch: [23][   44/   44]    Loss 1.068503    Top1 90.763777    
2024-02-26 17:35:07,203 - ==> Top1: 90.764    Loss: 1.069

2024-02-26 17:35:07,210 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 17:35:07,211 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:35:07,247 - 

2024-02-26 17:35:07,247 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:35:09,151 - Epoch: [24][   10/  139]    Overall Loss 1.051311    Objective Loss 1.051311                                        LR 0.000500    Time 0.190219    
2024-02-26 17:35:10,162 - Epoch: [24][   20/  139]    Overall Loss 1.055262    Objective Loss 1.055262                                        LR 0.000500    Time 0.145616    
2024-02-26 17:35:11,145 - Epoch: [24][   30/  139]    Overall Loss 1.057782    Objective Loss 1.057782                                        LR 0.000500    Time 0.129797    
2024-02-26 17:35:12,169 - Epoch: [24][   40/  139]    Overall Loss 1.056338    Objective Loss 1.056338                                        LR 0.000500    Time 0.122931    
2024-02-26 17:35:13,142 - Epoch: [24][   50/  139]    Overall Loss 1.057111    Objective Loss 1.057111                                        LR 0.000500    Time 0.117786    
2024-02-26 17:35:14,132 - Epoch: [24][   60/  139]    Overall Loss 1.056467    Objective Loss 1.056467                                        LR 0.000500    Time 0.114646    
2024-02-26 17:35:15,151 - Epoch: [24][   70/  139]    Overall Loss 1.057202    Objective Loss 1.057202                                        LR 0.000500    Time 0.112808    
2024-02-26 17:35:16,219 - Epoch: [24][   80/  139]    Overall Loss 1.057135    Objective Loss 1.057135                                        LR 0.000500    Time 0.112030    
2024-02-26 17:35:17,214 - Epoch: [24][   90/  139]    Overall Loss 1.057174    Objective Loss 1.057174                                        LR 0.000500    Time 0.110635    
2024-02-26 17:35:18,244 - Epoch: [24][  100/  139]    Overall Loss 1.057092    Objective Loss 1.057092                                        LR 0.000500    Time 0.109868    
2024-02-26 17:35:19,230 - Epoch: [24][  110/  139]    Overall Loss 1.057693    Objective Loss 1.057693                                        LR 0.000500    Time 0.108829    
2024-02-26 17:35:20,241 - Epoch: [24][  120/  139]    Overall Loss 1.057527    Objective Loss 1.057527                                        LR 0.000500    Time 0.108186    
2024-02-26 17:35:21,255 - Epoch: [24][  130/  139]    Overall Loss 1.057461    Objective Loss 1.057461                                        LR 0.000500    Time 0.107654    
2024-02-26 17:35:26,418 - Epoch: [24][  139/  139]    Overall Loss 1.057778    Objective Loss 1.057778    Top1 93.220283    LR 0.000500    Time 0.137828    
2024-02-26 17:35:26,705 - --- validate (epoch=24)-----------
2024-02-26 17:35:26,706 - 1392 samples (32 per mini-batch)
2024-02-26 17:35:58,769 - Epoch: [24][   10/   44]    Loss 1.064633    Top1 91.265264    
2024-02-26 17:36:29,958 - Epoch: [24][   20/   44]    Loss 1.059581    Top1 91.028775    
2024-02-26 17:37:01,001 - Epoch: [24][   30/   44]    Loss 1.063717    Top1 90.815262    
2024-02-26 17:37:32,641 - Epoch: [24][   40/   44]    Loss 1.065504    Top1 90.472101    
2024-02-26 17:37:44,122 - Epoch: [24][   44/   44]    Loss 1.063975    Top1 90.500335    
2024-02-26 17:37:44,371 - ==> Top1: 90.500    Loss: 1.064

2024-02-26 17:37:44,379 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 17:37:44,379 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:37:44,411 - 

2024-02-26 17:37:44,412 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:37:46,534 - Epoch: [25][   10/  139]    Overall Loss 1.065895    Objective Loss 1.065895                                        LR 0.000500    Time 0.212047    
2024-02-26 17:37:47,621 - Epoch: [25][   20/  139]    Overall Loss 1.058898    Objective Loss 1.058898                                        LR 0.000500    Time 0.160316    
2024-02-26 17:37:48,648 - Epoch: [25][   30/  139]    Overall Loss 1.058826    Objective Loss 1.058826                                        LR 0.000500    Time 0.141070    
2024-02-26 17:37:49,683 - Epoch: [25][   40/  139]    Overall Loss 1.056779    Objective Loss 1.056779                                        LR 0.000500    Time 0.131665    
2024-02-26 17:37:50,702 - Epoch: [25][   50/  139]    Overall Loss 1.056656    Objective Loss 1.056656                                        LR 0.000500    Time 0.125704    
2024-02-26 17:37:51,745 - Epoch: [25][   60/  139]    Overall Loss 1.057410    Objective Loss 1.057410                                        LR 0.000500    Time 0.122113    
2024-02-26 17:37:52,798 - Epoch: [25][   70/  139]    Overall Loss 1.056674    Objective Loss 1.056674                                        LR 0.000500    Time 0.119701    
2024-02-26 17:37:53,887 - Epoch: [25][   80/  139]    Overall Loss 1.056667    Objective Loss 1.056667                                        LR 0.000500    Time 0.118351    
2024-02-26 17:37:54,966 - Epoch: [25][   90/  139]    Overall Loss 1.056307    Objective Loss 1.056307                                        LR 0.000500    Time 0.117175    
2024-02-26 17:37:56,011 - Epoch: [25][  100/  139]    Overall Loss 1.056740    Objective Loss 1.056740                                        LR 0.000500    Time 0.115901    
2024-02-26 17:37:57,041 - Epoch: [25][  110/  139]    Overall Loss 1.057340    Objective Loss 1.057340                                        LR 0.000500    Time 0.114733    
2024-02-26 17:37:58,096 - Epoch: [25][  120/  139]    Overall Loss 1.057524    Objective Loss 1.057524                                        LR 0.000500    Time 0.113958    
2024-02-26 17:37:59,143 - Epoch: [25][  130/  139]    Overall Loss 1.057215    Objective Loss 1.057215                                        LR 0.000500    Time 0.113236    
2024-02-26 17:38:04,604 - Epoch: [25][  139/  139]    Overall Loss 1.058102    Objective Loss 1.058102    Top1 93.198106    LR 0.000500    Time 0.145189    
2024-02-26 17:38:04,882 - --- validate (epoch=25)-----------
2024-02-26 17:38:04,883 - 1392 samples (32 per mini-batch)
2024-02-26 17:38:40,830 - Epoch: [25][   10/   44]    Loss 1.067571    Top1 89.735773    
2024-02-26 17:39:10,184 - Epoch: [25][   20/   44]    Loss 1.068427    Top1 90.077098    
2024-02-26 17:39:39,766 - Epoch: [25][   30/   44]    Loss 1.060714    Top1 90.099093    
2024-02-26 17:40:08,164 - Epoch: [25][   40/   44]    Loss 1.056579    Top1 89.936925    
2024-02-26 17:40:19,126 - Epoch: [25][   44/   44]    Loss 1.057244    Top1 89.996375    
2024-02-26 17:40:19,347 - ==> Top1: 89.996    Loss: 1.057

2024-02-26 17:40:19,354 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 17:40:19,355 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:40:19,395 - 

2024-02-26 17:40:19,395 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:40:21,305 - Epoch: [26][   10/  139]    Overall Loss 1.059411    Objective Loss 1.059411                                        LR 0.000500    Time 0.190801    
2024-02-26 17:40:22,319 - Epoch: [26][   20/  139]    Overall Loss 1.059203    Objective Loss 1.059203                                        LR 0.000500    Time 0.146037    
2024-02-26 17:40:23,338 - Epoch: [26][   30/  139]    Overall Loss 1.059732    Objective Loss 1.059732                                        LR 0.000500    Time 0.131294    
2024-02-26 17:40:24,347 - Epoch: [26][   40/  139]    Overall Loss 1.057794    Objective Loss 1.057794                                        LR 0.000500    Time 0.123673    
2024-02-26 17:40:25,395 - Epoch: [26][   50/  139]    Overall Loss 1.056050    Objective Loss 1.056050                                        LR 0.000500    Time 0.119887    
2024-02-26 17:40:26,425 - Epoch: [26][   60/  139]    Overall Loss 1.056564    Objective Loss 1.056564                                        LR 0.000500    Time 0.117060    
2024-02-26 17:40:27,462 - Epoch: [26][   70/  139]    Overall Loss 1.055811    Objective Loss 1.055811                                        LR 0.000500    Time 0.115140    
2024-02-26 17:40:28,473 - Epoch: [26][   80/  139]    Overall Loss 1.056462    Objective Loss 1.056462                                        LR 0.000500    Time 0.113383    
2024-02-26 17:40:29,509 - Epoch: [26][   90/  139]    Overall Loss 1.057648    Objective Loss 1.057648                                        LR 0.000500    Time 0.112280    
2024-02-26 17:40:30,548 - Epoch: [26][  100/  139]    Overall Loss 1.056942    Objective Loss 1.056942                                        LR 0.000500    Time 0.111441    
2024-02-26 17:40:31,559 - Epoch: [26][  110/  139]    Overall Loss 1.057470    Objective Loss 1.057470                                        LR 0.000500    Time 0.110492    
2024-02-26 17:40:32,586 - Epoch: [26][  120/  139]    Overall Loss 1.058091    Objective Loss 1.058091                                        LR 0.000500    Time 0.109836    
2024-02-26 17:40:33,618 - Epoch: [26][  130/  139]    Overall Loss 1.057780    Objective Loss 1.057780                                        LR 0.000500    Time 0.109321    
2024-02-26 17:40:38,864 - Epoch: [26][  139/  139]    Overall Loss 1.057781    Objective Loss 1.057781    Top1 93.254510    LR 0.000500    Time 0.139979    
2024-02-26 17:40:39,154 - --- validate (epoch=26)-----------
2024-02-26 17:40:39,156 - 1392 samples (32 per mini-batch)
2024-02-26 17:41:11,442 - Epoch: [26][   10/   44]    Loss 1.058167    Top1 89.756021    
2024-02-26 17:41:42,844 - Epoch: [26][   20/   44]    Loss 1.060285    Top1 90.499897    
2024-02-26 17:42:13,669 - Epoch: [26][   30/   44]    Loss 1.062916    Top1 90.351335    
2024-02-26 17:42:43,197 - Epoch: [26][   40/   44]    Loss 1.061383    Top1 90.239454    
2024-02-26 17:42:52,409 - Epoch: [26][   44/   44]    Loss 1.061464    Top1 90.276008    
2024-02-26 17:42:52,683 - ==> Top1: 90.276    Loss: 1.061

2024-02-26 17:42:52,691 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 17:42:52,691 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:42:52,723 - 

2024-02-26 17:42:52,724 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:42:54,573 - Epoch: [27][   10/  139]    Overall Loss 1.060391    Objective Loss 1.060391                                        LR 0.000500    Time 0.184372    
2024-02-26 17:42:55,576 - Epoch: [27][   20/  139]    Overall Loss 1.056072    Objective Loss 1.056072                                        LR 0.000500    Time 0.142261    
2024-02-26 17:42:56,605 - Epoch: [27][   30/  139]    Overall Loss 1.056403    Objective Loss 1.056403                                        LR 0.000500    Time 0.129139    
2024-02-26 17:42:57,637 - Epoch: [27][   40/  139]    Overall Loss 1.058943    Objective Loss 1.058943                                        LR 0.000500    Time 0.122624    
2024-02-26 17:42:58,698 - Epoch: [27][   50/  139]    Overall Loss 1.059303    Objective Loss 1.059303                                        LR 0.000500    Time 0.119304    
2024-02-26 17:42:59,714 - Epoch: [27][   60/  139]    Overall Loss 1.058960    Objective Loss 1.058960                                        LR 0.000500    Time 0.116357    
2024-02-26 17:43:00,740 - Epoch: [27][   70/  139]    Overall Loss 1.057998    Objective Loss 1.057998                                        LR 0.000500    Time 0.114374    
2024-02-26 17:43:01,793 - Epoch: [27][   80/  139]    Overall Loss 1.056832    Objective Loss 1.056832                                        LR 0.000500    Time 0.113238    
2024-02-26 17:43:02,871 - Epoch: [27][   90/  139]    Overall Loss 1.056107    Objective Loss 1.056107                                        LR 0.000500    Time 0.112625    
2024-02-26 17:43:03,931 - Epoch: [27][  100/  139]    Overall Loss 1.056136    Objective Loss 1.056136                                        LR 0.000500    Time 0.111947    
2024-02-26 17:43:05,023 - Epoch: [27][  110/  139]    Overall Loss 1.055737    Objective Loss 1.055737                                        LR 0.000500    Time 0.111692    
2024-02-26 17:43:06,093 - Epoch: [27][  120/  139]    Overall Loss 1.056113    Objective Loss 1.056113                                        LR 0.000500    Time 0.111218    
2024-02-26 17:43:07,194 - Epoch: [27][  130/  139]    Overall Loss 1.056297    Objective Loss 1.056297                                        LR 0.000500    Time 0.111125    
2024-02-26 17:43:12,448 - Epoch: [27][  139/  139]    Overall Loss 1.056446    Objective Loss 1.056446    Top1 93.790812    LR 0.000500    Time 0.141724    
2024-02-26 17:43:12,881 - --- validate (epoch=27)-----------
2024-02-26 17:43:12,884 - 1392 samples (32 per mini-batch)
2024-02-26 17:43:43,844 - Epoch: [27][   10/   44]    Loss 1.053144    Top1 90.405168    
2024-02-26 17:44:13,772 - Epoch: [27][   20/   44]    Loss 1.061181    Top1 90.078254    
2024-02-26 17:44:38,148 - Epoch: [27][   30/   44]    Loss 1.064332    Top1 90.033963    
2024-02-26 17:45:09,068 - Epoch: [27][   40/   44]    Loss 1.066674    Top1 89.909376    
2024-02-26 17:45:20,413 - Epoch: [27][   44/   44]    Loss 1.067221    Top1 89.851177    
2024-02-26 17:45:20,637 - ==> Top1: 89.851    Loss: 1.067

2024-02-26 17:45:20,644 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 17:45:20,644 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:45:20,676 - 

2024-02-26 17:45:20,677 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:45:22,606 - Epoch: [28][   10/  139]    Overall Loss 1.057684    Objective Loss 1.057684                                        LR 0.000500    Time 0.192742    
2024-02-26 17:45:23,615 - Epoch: [28][   20/  139]    Overall Loss 1.060544    Objective Loss 1.060544                                        LR 0.000500    Time 0.146779    
2024-02-26 17:45:24,622 - Epoch: [28][   30/  139]    Overall Loss 1.059627    Objective Loss 1.059627                                        LR 0.000500    Time 0.131417    
2024-02-26 17:45:25,652 - Epoch: [28][   40/  139]    Overall Loss 1.057941    Objective Loss 1.057941                                        LR 0.000500    Time 0.124278    
2024-02-26 17:45:26,647 - Epoch: [28][   50/  139]    Overall Loss 1.056554    Objective Loss 1.056554                                        LR 0.000500    Time 0.119313    
2024-02-26 17:45:27,666 - Epoch: [28][   60/  139]    Overall Loss 1.055503    Objective Loss 1.055503                                        LR 0.000500    Time 0.116396    
2024-02-26 17:45:28,669 - Epoch: [28][   70/  139]    Overall Loss 1.055584    Objective Loss 1.055584                                        LR 0.000500    Time 0.114092    
2024-02-26 17:45:29,712 - Epoch: [28][   80/  139]    Overall Loss 1.055131    Objective Loss 1.055131                                        LR 0.000500    Time 0.112855    
2024-02-26 17:45:30,736 - Epoch: [28][   90/  139]    Overall Loss 1.055874    Objective Loss 1.055874                                        LR 0.000500    Time 0.111688    
2024-02-26 17:45:31,759 - Epoch: [28][  100/  139]    Overall Loss 1.055862    Objective Loss 1.055862                                        LR 0.000500    Time 0.110739    
2024-02-26 17:45:32,768 - Epoch: [28][  110/  139]    Overall Loss 1.055989    Objective Loss 1.055989                                        LR 0.000500    Time 0.109843    
2024-02-26 17:45:33,779 - Epoch: [28][  120/  139]    Overall Loss 1.055480    Objective Loss 1.055480                                        LR 0.000500    Time 0.109103    
2024-02-26 17:45:34,806 - Epoch: [28][  130/  139]    Overall Loss 1.055465    Objective Loss 1.055465                                        LR 0.000500    Time 0.108606    
2024-02-26 17:45:40,005 - Epoch: [28][  139/  139]    Overall Loss 1.055845    Objective Loss 1.055845    Top1 95.128468    LR 0.000500    Time 0.138975    
2024-02-26 17:45:40,348 - --- validate (epoch=28)-----------
2024-02-26 17:45:40,349 - 1392 samples (32 per mini-batch)
2024-02-26 17:46:12,565 - Epoch: [28][   10/   44]    Loss 1.069522    Top1 89.750288    
2024-02-26 17:46:43,435 - Epoch: [28][   20/   44]    Loss 1.063213    Top1 90.098620    
2024-02-26 17:47:12,091 - Epoch: [28][   30/   44]    Loss 1.061148    Top1 90.119328    
2024-02-26 17:47:37,388 - Epoch: [28][   40/   44]    Loss 1.060489    Top1 90.137080    
2024-02-26 17:47:45,954 - Epoch: [28][   44/   44]    Loss 1.061034    Top1 90.192915    
2024-02-26 17:47:46,179 - ==> Top1: 90.193    Loss: 1.061

2024-02-26 17:47:46,188 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 17:47:46,188 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:47:46,218 - 

2024-02-26 17:47:46,219 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:47:48,136 - Epoch: [29][   10/  139]    Overall Loss 1.050264    Objective Loss 1.050264                                        LR 0.000500    Time 0.191576    
2024-02-26 17:47:49,139 - Epoch: [29][   20/  139]    Overall Loss 1.051471    Objective Loss 1.051471                                        LR 0.000500    Time 0.145373    
2024-02-26 17:47:50,210 - Epoch: [29][   30/  139]    Overall Loss 1.052923    Objective Loss 1.052923                                        LR 0.000500    Time 0.132600    
2024-02-26 17:47:51,233 - Epoch: [29][   40/  139]    Overall Loss 1.055658    Objective Loss 1.055658                                        LR 0.000500    Time 0.125007    
2024-02-26 17:47:52,290 - Epoch: [29][   50/  139]    Overall Loss 1.055077    Objective Loss 1.055077                                        LR 0.000500    Time 0.121120    
2024-02-26 17:47:53,353 - Epoch: [29][   60/  139]    Overall Loss 1.054632    Objective Loss 1.054632                                        LR 0.000500    Time 0.118654    
2024-02-26 17:47:54,406 - Epoch: [29][   70/  139]    Overall Loss 1.055205    Objective Loss 1.055205                                        LR 0.000500    Time 0.116732    
2024-02-26 17:47:55,456 - Epoch: [29][   80/  139]    Overall Loss 1.055675    Objective Loss 1.055675                                        LR 0.000500    Time 0.115251    
2024-02-26 17:47:56,493 - Epoch: [29][   90/  139]    Overall Loss 1.055427    Objective Loss 1.055427                                        LR 0.000500    Time 0.113971    
2024-02-26 17:47:57,555 - Epoch: [29][  100/  139]    Overall Loss 1.055890    Objective Loss 1.055890                                        LR 0.000500    Time 0.112987    
2024-02-26 17:47:58,674 - Epoch: [29][  110/  139]    Overall Loss 1.055533    Objective Loss 1.055533                                        LR 0.000500    Time 0.112884    
2024-02-26 17:47:59,806 - Epoch: [29][  120/  139]    Overall Loss 1.056256    Objective Loss 1.056256                                        LR 0.000500    Time 0.112900    
2024-02-26 17:48:00,914 - Epoch: [29][  130/  139]    Overall Loss 1.056062    Objective Loss 1.056062                                        LR 0.000500    Time 0.112734    
2024-02-26 17:48:05,820 - Epoch: [29][  139/  139]    Overall Loss 1.056250    Objective Loss 1.056250    Top1 94.151521    LR 0.000500    Time 0.140723    
2024-02-26 17:48:06,137 - --- validate (epoch=29)-----------
2024-02-26 17:48:06,139 - 1392 samples (32 per mini-batch)
2024-02-26 17:48:36,466 - Epoch: [29][   10/   44]    Loss 1.074717    Top1 91.019786    
2024-02-26 17:49:05,516 - Epoch: [29][   20/   44]    Loss 1.070492    Top1 90.342434    
2024-02-26 17:49:34,541 - Epoch: [29][   30/   44]    Loss 1.071218    Top1 90.417439    
2024-02-26 17:50:05,380 - Epoch: [29][   40/   44]    Loss 1.071022    Top1 90.378502    
2024-02-26 17:50:15,989 - Epoch: [29][   44/   44]    Loss 1.069783    Top1 90.402930    
2024-02-26 17:50:16,229 - ==> Top1: 90.403    Loss: 1.070

2024-02-26 17:50:16,236 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 17:50:16,237 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:50:16,276 - 

2024-02-26 17:50:16,276 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:50:18,168 - Epoch: [30][   10/  139]    Overall Loss 1.050643    Objective Loss 1.050643                                        LR 0.000500    Time 0.189065    
2024-02-26 17:50:19,165 - Epoch: [30][   20/  139]    Overall Loss 1.051494    Objective Loss 1.051494                                        LR 0.000500    Time 0.144325    
2024-02-26 17:50:20,181 - Epoch: [30][   30/  139]    Overall Loss 1.052784    Objective Loss 1.052784                                        LR 0.000500    Time 0.130078    
2024-02-26 17:50:21,194 - Epoch: [30][   40/  139]    Overall Loss 1.054159    Objective Loss 1.054159                                        LR 0.000500    Time 0.122851    
2024-02-26 17:50:22,211 - Epoch: [30][   50/  139]    Overall Loss 1.056222    Objective Loss 1.056222                                        LR 0.000500    Time 0.118615    
2024-02-26 17:50:23,244 - Epoch: [30][   60/  139]    Overall Loss 1.056853    Objective Loss 1.056853                                        LR 0.000500    Time 0.116056    
2024-02-26 17:50:24,287 - Epoch: [30][   70/  139]    Overall Loss 1.057454    Objective Loss 1.057454                                        LR 0.000500    Time 0.114366    
2024-02-26 17:50:25,323 - Epoch: [30][   80/  139]    Overall Loss 1.055616    Objective Loss 1.055616                                        LR 0.000500    Time 0.112808    
2024-02-26 17:50:26,351 - Epoch: [30][   90/  139]    Overall Loss 1.056024    Objective Loss 1.056024                                        LR 0.000500    Time 0.111692    
2024-02-26 17:50:27,386 - Epoch: [30][  100/  139]    Overall Loss 1.055426    Objective Loss 1.055426                                        LR 0.000500    Time 0.110865    
2024-02-26 17:50:28,425 - Epoch: [30][  110/  139]    Overall Loss 1.055850    Objective Loss 1.055850                                        LR 0.000500    Time 0.110228    
2024-02-26 17:50:29,474 - Epoch: [30][  120/  139]    Overall Loss 1.055763    Objective Loss 1.055763                                        LR 0.000500    Time 0.109782    
2024-02-26 17:50:30,522 - Epoch: [30][  130/  139]    Overall Loss 1.056196    Objective Loss 1.056196                                        LR 0.000500    Time 0.109393    
2024-02-26 17:50:35,909 - Epoch: [30][  139/  139]    Overall Loss 1.056576    Objective Loss 1.056576    Top1 93.711517    LR 0.000500    Time 0.141059    
2024-02-26 17:50:36,214 - --- validate (epoch=30)-----------
2024-02-26 17:50:36,214 - 1392 samples (32 per mini-batch)
2024-02-26 17:51:09,297 - Epoch: [30][   10/   44]    Loss 1.062837    Top1 90.514304    
2024-02-26 17:51:39,650 - Epoch: [30][   20/   44]    Loss 1.063119    Top1 90.941534    
2024-02-26 17:52:04,481 - Epoch: [30][   30/   44]    Loss 1.065178    Top1 90.626463    
2024-02-26 17:52:27,411 - Epoch: [30][   40/   44]    Loss 1.065729    Top1 90.397689    
2024-02-26 17:52:36,172 - Epoch: [30][   44/   44]    Loss 1.064896    Top1 90.467709    
2024-02-26 17:52:36,534 - ==> Top1: 90.468    Loss: 1.065

2024-02-26 17:52:36,541 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 17:52:36,541 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:52:36,574 - 

2024-02-26 17:52:36,574 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:52:38,664 - Epoch: [31][   10/  139]    Overall Loss 1.059008    Objective Loss 1.059008                                        LR 0.000500    Time 0.208826    
2024-02-26 17:52:39,669 - Epoch: [31][   20/  139]    Overall Loss 1.055942    Objective Loss 1.055942                                        LR 0.000500    Time 0.154608    
2024-02-26 17:52:40,712 - Epoch: [31][   30/  139]    Overall Loss 1.055633    Objective Loss 1.055633                                        LR 0.000500    Time 0.137813    
2024-02-26 17:52:41,765 - Epoch: [31][   40/  139]    Overall Loss 1.056413    Objective Loss 1.056413                                        LR 0.000500    Time 0.129682    
2024-02-26 17:52:42,781 - Epoch: [31][   50/  139]    Overall Loss 1.056607    Objective Loss 1.056607                                        LR 0.000500    Time 0.124046    
2024-02-26 17:52:43,857 - Epoch: [31][   60/  139]    Overall Loss 1.056098    Objective Loss 1.056098                                        LR 0.000500    Time 0.121289    
2024-02-26 17:52:44,948 - Epoch: [31][   70/  139]    Overall Loss 1.055742    Objective Loss 1.055742                                        LR 0.000500    Time 0.119545    
2024-02-26 17:52:45,956 - Epoch: [31][   80/  139]    Overall Loss 1.056782    Objective Loss 1.056782                                        LR 0.000500    Time 0.117198    
2024-02-26 17:52:47,017 - Epoch: [31][   90/  139]    Overall Loss 1.056637    Objective Loss 1.056637                                        LR 0.000500    Time 0.115951    
2024-02-26 17:52:48,048 - Epoch: [31][  100/  139]    Overall Loss 1.056937    Objective Loss 1.056937                                        LR 0.000500    Time 0.114663    
2024-02-26 17:52:49,108 - Epoch: [31][  110/  139]    Overall Loss 1.057336    Objective Loss 1.057336                                        LR 0.000500    Time 0.113871    
2024-02-26 17:52:50,145 - Epoch: [31][  120/  139]    Overall Loss 1.056536    Objective Loss 1.056536                                        LR 0.000500    Time 0.113022    
2024-02-26 17:52:51,297 - Epoch: [31][  130/  139]    Overall Loss 1.056464    Objective Loss 1.056464                                        LR 0.000500    Time 0.113179    
2024-02-26 17:52:56,757 - Epoch: [31][  139/  139]    Overall Loss 1.056069    Objective Loss 1.056069    Top1 94.873726    LR 0.000500    Time 0.145121    
2024-02-26 17:52:57,097 - --- validate (epoch=31)-----------
2024-02-26 17:52:57,098 - 1392 samples (32 per mini-batch)
2024-02-26 17:53:26,884 - Epoch: [31][   10/   44]    Loss 1.066324    Top1 89.739239    
2024-02-26 17:53:57,473 - Epoch: [31][   20/   44]    Loss 1.068382    Top1 90.184812    
2024-02-26 17:54:28,698 - Epoch: [31][   30/   44]    Loss 1.070557    Top1 90.308600    
2024-02-26 17:55:00,087 - Epoch: [31][   40/   44]    Loss 1.070672    Top1 90.176440    
2024-02-26 17:55:10,897 - Epoch: [31][   44/   44]    Loss 1.069670    Top1 90.212221    
2024-02-26 17:55:11,106 - ==> Top1: 90.212    Loss: 1.070

2024-02-26 17:55:11,116 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 17:55:11,116 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:55:11,147 - 

2024-02-26 17:55:11,147 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:55:12,997 - Epoch: [32][   10/  139]    Overall Loss 1.050451    Objective Loss 1.050451                                        LR 0.000500    Time 0.184878    
2024-02-26 17:55:14,012 - Epoch: [32][   20/  139]    Overall Loss 1.051043    Objective Loss 1.051043                                        LR 0.000500    Time 0.143105    
2024-02-26 17:55:15,058 - Epoch: [32][   30/  139]    Overall Loss 1.053093    Objective Loss 1.053093                                        LR 0.000500    Time 0.130252    
2024-02-26 17:55:16,086 - Epoch: [32][   40/  139]    Overall Loss 1.051314    Objective Loss 1.051314                                        LR 0.000500    Time 0.123386    
2024-02-26 17:55:17,117 - Epoch: [32][   50/  139]    Overall Loss 1.054325    Objective Loss 1.054325                                        LR 0.000500    Time 0.119315    
2024-02-26 17:55:18,150 - Epoch: [32][   60/  139]    Overall Loss 1.054910    Objective Loss 1.054910                                        LR 0.000500    Time 0.116634    
2024-02-26 17:55:19,165 - Epoch: [32][   70/  139]    Overall Loss 1.055689    Objective Loss 1.055689                                        LR 0.000500    Time 0.114453    
2024-02-26 17:55:20,201 - Epoch: [32][   80/  139]    Overall Loss 1.055529    Objective Loss 1.055529                                        LR 0.000500    Time 0.113096    
2024-02-26 17:55:21,222 - Epoch: [32][   90/  139]    Overall Loss 1.054670    Objective Loss 1.054670                                        LR 0.000500    Time 0.111858    
2024-02-26 17:55:22,293 - Epoch: [32][  100/  139]    Overall Loss 1.055030    Objective Loss 1.055030                                        LR 0.000500    Time 0.111378    
2024-02-26 17:55:23,334 - Epoch: [32][  110/  139]    Overall Loss 1.055283    Objective Loss 1.055283                                        LR 0.000500    Time 0.110717    
2024-02-26 17:55:24,366 - Epoch: [32][  120/  139]    Overall Loss 1.054989    Objective Loss 1.054989                                        LR 0.000500    Time 0.110082    
2024-02-26 17:55:25,388 - Epoch: [32][  130/  139]    Overall Loss 1.055549    Objective Loss 1.055549                                        LR 0.000500    Time 0.109466    
2024-02-26 17:55:30,554 - Epoch: [32][  139/  139]    Overall Loss 1.055319    Objective Loss 1.055319    Top1 93.683783    LR 0.000500    Time 0.139544    
2024-02-26 17:55:30,841 - --- validate (epoch=32)-----------
2024-02-26 17:55:30,841 - 1392 samples (32 per mini-batch)
2024-02-26 17:56:03,495 - Epoch: [32][   10/   44]    Loss 1.079813    Top1 89.723367    
2024-02-26 17:56:31,316 - Epoch: [32][   20/   44]    Loss 1.078949    Top1 89.939312    
2024-02-26 17:56:57,246 - Epoch: [32][   30/   44]    Loss 1.075163    Top1 89.804219    
2024-02-26 17:57:23,361 - Epoch: [32][   40/   44]    Loss 1.074742    Top1 89.924963    
2024-02-26 17:57:32,390 - Epoch: [32][   44/   44]    Loss 1.074080    Top1 89.895076    
2024-02-26 17:57:32,807 - ==> Top1: 89.895    Loss: 1.074

2024-02-26 17:57:32,814 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 17:57:32,815 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 17:57:32,846 - 

2024-02-26 17:57:32,846 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:57:34,834 - Epoch: [33][   10/  139]    Overall Loss 1.061457    Objective Loss 1.061457                                        LR 0.000500    Time 0.198653    
2024-02-26 17:57:35,835 - Epoch: [33][   20/  139]    Overall Loss 1.063261    Objective Loss 1.063261                                        LR 0.000500    Time 0.149296    
2024-02-26 17:57:36,822 - Epoch: [33][   30/  139]    Overall Loss 1.058007    Objective Loss 1.058007                                        LR 0.000500    Time 0.132424    
2024-02-26 17:57:37,806 - Epoch: [33][   40/  139]    Overall Loss 1.055713    Objective Loss 1.055713                                        LR 0.000500    Time 0.123880    
2024-02-26 17:57:38,794 - Epoch: [33][   50/  139]    Overall Loss 1.054335    Objective Loss 1.054335                                        LR 0.000500    Time 0.118853    
2024-02-26 17:57:39,821 - Epoch: [33][   60/  139]    Overall Loss 1.054241    Objective Loss 1.054241                                        LR 0.000500    Time 0.116144    
2024-02-26 17:57:40,833 - Epoch: [33][   70/  139]    Overall Loss 1.054680    Objective Loss 1.054680                                        LR 0.000500    Time 0.113996    
2024-02-26 17:57:41,863 - Epoch: [33][   80/  139]    Overall Loss 1.054735    Objective Loss 1.054735                                        LR 0.000500    Time 0.112610    
2024-02-26 17:57:42,908 - Epoch: [33][   90/  139]    Overall Loss 1.054083    Objective Loss 1.054083                                        LR 0.000500    Time 0.111436    
2024-02-26 17:57:43,924 - Epoch: [33][  100/  139]    Overall Loss 1.054596    Objective Loss 1.054596                                        LR 0.000500    Time 0.110444    
2024-02-26 17:57:44,981 - Epoch: [33][  110/  139]    Overall Loss 1.054328    Objective Loss 1.054328                                        LR 0.000500    Time 0.110002    
2024-02-26 17:57:45,994 - Epoch: [33][  120/  139]    Overall Loss 1.053958    Objective Loss 1.053958                                        LR 0.000500    Time 0.109273    
2024-02-26 17:57:47,029 - Epoch: [33][  130/  139]    Overall Loss 1.054450    Objective Loss 1.054450                                        LR 0.000500    Time 0.108822    
2024-02-26 17:57:52,232 - Epoch: [33][  139/  139]    Overall Loss 1.054432    Objective Loss 1.054432    Top1 94.573622    LR 0.000500    Time 0.139210    
2024-02-26 17:57:52,589 - --- validate (epoch=33)-----------
2024-02-26 17:57:52,590 - 1392 samples (32 per mini-batch)
2024-02-26 17:58:24,951 - Epoch: [33][   10/   44]    Loss 1.071966    Top1 90.237636    
2024-02-26 17:58:57,205 - Epoch: [33][   20/   44]    Loss 1.074034    Top1 90.013129    
2024-02-26 17:59:29,429 - Epoch: [33][   30/   44]    Loss 1.072535    Top1 90.245032    
2024-02-26 18:00:01,620 - Epoch: [33][   40/   44]    Loss 1.071061    Top1 90.404908    
2024-02-26 18:00:12,666 - Epoch: [33][   44/   44]    Loss 1.069589    Top1 90.342520    
2024-02-26 18:00:12,878 - ==> Top1: 90.343    Loss: 1.070

2024-02-26 18:00:12,886 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 18:00:12,886 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 18:00:12,917 - 

2024-02-26 18:00:12,917 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:00:14,887 - Epoch: [34][   10/  139]    Overall Loss 1.051748    Objective Loss 1.051748                                        LR 0.000500    Time 0.196788    
2024-02-26 18:00:15,882 - Epoch: [34][   20/  139]    Overall Loss 1.057455    Objective Loss 1.057455                                        LR 0.000500    Time 0.148077    
2024-02-26 18:00:16,877 - Epoch: [34][   30/  139]    Overall Loss 1.058661    Objective Loss 1.058661                                        LR 0.000500    Time 0.131854    
2024-02-26 18:00:17,951 - Epoch: [34][   40/  139]    Overall Loss 1.058303    Objective Loss 1.058303                                        LR 0.000500    Time 0.125731    
2024-02-26 18:00:18,960 - Epoch: [34][   50/  139]    Overall Loss 1.057471    Objective Loss 1.057471                                        LR 0.000500    Time 0.120756    
2024-02-26 18:00:19,994 - Epoch: [34][   60/  139]    Overall Loss 1.057329    Objective Loss 1.057329                                        LR 0.000500    Time 0.117853    
2024-02-26 18:00:21,000 - Epoch: [34][   70/  139]    Overall Loss 1.056338    Objective Loss 1.056338                                        LR 0.000500    Time 0.115366    
2024-02-26 18:00:22,021 - Epoch: [34][   80/  139]    Overall Loss 1.054261    Objective Loss 1.054261                                        LR 0.000500    Time 0.113702    
2024-02-26 18:00:23,065 - Epoch: [34][   90/  139]    Overall Loss 1.055717    Objective Loss 1.055717                                        LR 0.000500    Time 0.112526    
2024-02-26 18:00:24,121 - Epoch: [34][  100/  139]    Overall Loss 1.055696    Objective Loss 1.055696                                        LR 0.000500    Time 0.111827    
2024-02-26 18:00:25,142 - Epoch: [34][  110/  139]    Overall Loss 1.055319    Objective Loss 1.055319                                        LR 0.000500    Time 0.110929    
2024-02-26 18:00:26,167 - Epoch: [34][  120/  139]    Overall Loss 1.055962    Objective Loss 1.055962                                        LR 0.000500    Time 0.110226    
2024-02-26 18:00:27,198 - Epoch: [34][  130/  139]    Overall Loss 1.055327    Objective Loss 1.055327                                        LR 0.000500    Time 0.109673    
2024-02-26 18:00:32,691 - Epoch: [34][  139/  139]    Overall Loss 1.055807    Objective Loss 1.055807    Top1 95.662679    LR 0.000500    Time 0.142086    
2024-02-26 18:00:32,998 - --- validate (epoch=34)-----------
2024-02-26 18:00:32,998 - 1392 samples (32 per mini-batch)
2024-02-26 18:01:05,407 - Epoch: [34][   10/   44]    Loss 1.067459    Top1 90.305489    
2024-02-26 18:01:34,710 - Epoch: [34][   20/   44]    Loss 1.068199    Top1 90.529258    
2024-02-26 18:02:03,727 - Epoch: [34][   30/   44]    Loss 1.066765    Top1 90.341158    
2024-02-26 18:02:33,422 - Epoch: [34][   40/   44]    Loss 1.064447    Top1 90.362962    
2024-02-26 18:02:43,487 - Epoch: [34][   44/   44]    Loss 1.064329    Top1 90.362010    
2024-02-26 18:02:43,737 - ==> Top1: 90.362    Loss: 1.064

2024-02-26 18:02:43,744 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 18:02:43,744 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 18:02:43,783 - 

2024-02-26 18:02:43,783 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:02:45,611 - Epoch: [35][   10/  139]    Overall Loss 1.055468    Objective Loss 1.055468                                        LR 0.000500    Time 0.182646    
2024-02-26 18:02:46,583 - Epoch: [35][   20/  139]    Overall Loss 1.053773    Objective Loss 1.053773                                        LR 0.000500    Time 0.139870    
2024-02-26 18:02:47,601 - Epoch: [35][   30/  139]    Overall Loss 1.054975    Objective Loss 1.054975                                        LR 0.000500    Time 0.127135    
2024-02-26 18:02:48,592 - Epoch: [35][   40/  139]    Overall Loss 1.055109    Objective Loss 1.055109                                        LR 0.000500    Time 0.120108    
2024-02-26 18:02:49,665 - Epoch: [35][   50/  139]    Overall Loss 1.054666    Objective Loss 1.054666                                        LR 0.000500    Time 0.117524    
2024-02-26 18:02:50,686 - Epoch: [35][   60/  139]    Overall Loss 1.053764    Objective Loss 1.053764                                        LR 0.000500    Time 0.114947    
2024-02-26 18:02:51,680 - Epoch: [35][   70/  139]    Overall Loss 1.053802    Objective Loss 1.053802                                        LR 0.000500    Time 0.112712    
2024-02-26 18:02:52,702 - Epoch: [35][   80/  139]    Overall Loss 1.053379    Objective Loss 1.053379                                        LR 0.000500    Time 0.111390    
2024-02-26 18:02:53,712 - Epoch: [35][   90/  139]    Overall Loss 1.053932    Objective Loss 1.053932                                        LR 0.000500    Time 0.110236    
2024-02-26 18:02:54,720 - Epoch: [35][  100/  139]    Overall Loss 1.054053    Objective Loss 1.054053                                        LR 0.000500    Time 0.109279    
2024-02-26 18:02:55,709 - Epoch: [35][  110/  139]    Overall Loss 1.054314    Objective Loss 1.054314                                        LR 0.000500    Time 0.108335    
2024-02-26 18:02:56,736 - Epoch: [35][  120/  139]    Overall Loss 1.054580    Objective Loss 1.054580                                        LR 0.000500    Time 0.107858    
2024-02-26 18:02:57,736 - Epoch: [35][  130/  139]    Overall Loss 1.054817    Objective Loss 1.054817                                        LR 0.000500    Time 0.107250    
2024-02-26 18:03:02,682 - Epoch: [35][  139/  139]    Overall Loss 1.054959    Objective Loss 1.054959    Top1 94.128115    LR 0.000500    Time 0.135883    
2024-02-26 18:03:03,041 - --- validate (epoch=35)-----------
2024-02-26 18:03:03,043 - 1392 samples (32 per mini-batch)
2024-02-26 18:03:35,302 - Epoch: [35][   10/   44]    Loss 1.068566    Top1 90.299395    
2024-02-26 18:04:06,873 - Epoch: [35][   20/   44]    Loss 1.068054    Top1 89.414779    
2024-02-26 18:04:38,836 - Epoch: [35][   30/   44]    Loss 1.068693    Top1 89.080606    
2024-02-26 18:05:11,464 - Epoch: [35][   40/   44]    Loss 1.070217    Top1 89.274145    
2024-02-26 18:05:22,486 - Epoch: [35][   44/   44]    Loss 1.069464    Top1 89.181526    
2024-02-26 18:05:22,735 - ==> Top1: 89.182    Loss: 1.069

2024-02-26 18:05:22,742 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 18:05:22,743 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 18:05:22,776 - 

2024-02-26 18:05:22,776 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:05:24,724 - Epoch: [36][   10/  139]    Overall Loss 1.054402    Objective Loss 1.054402                                        LR 0.000500    Time 0.194632    
2024-02-26 18:05:25,730 - Epoch: [36][   20/  139]    Overall Loss 1.055269    Objective Loss 1.055269                                        LR 0.000500    Time 0.147616    
2024-02-26 18:05:26,718 - Epoch: [36][   30/  139]    Overall Loss 1.054003    Objective Loss 1.054003                                        LR 0.000500    Time 0.131311    
2024-02-26 18:05:27,704 - Epoch: [36][   40/  139]    Overall Loss 1.053908    Objective Loss 1.053908                                        LR 0.000500    Time 0.123119    
2024-02-26 18:05:28,721 - Epoch: [36][   50/  139]    Overall Loss 1.053383    Objective Loss 1.053383                                        LR 0.000500    Time 0.118828    
2024-02-26 18:05:29,754 - Epoch: [36][   60/  139]    Overall Loss 1.053425    Objective Loss 1.053425                                        LR 0.000500    Time 0.116241    
2024-02-26 18:05:30,733 - Epoch: [36][   70/  139]    Overall Loss 1.053183    Objective Loss 1.053183                                        LR 0.000500    Time 0.113611    
2024-02-26 18:05:31,747 - Epoch: [36][   80/  139]    Overall Loss 1.053278    Objective Loss 1.053278                                        LR 0.000500    Time 0.112079    
2024-02-26 18:05:32,774 - Epoch: [36][   90/  139]    Overall Loss 1.052239    Objective Loss 1.052239                                        LR 0.000500    Time 0.111029    
2024-02-26 18:05:33,837 - Epoch: [36][  100/  139]    Overall Loss 1.053629    Objective Loss 1.053629                                        LR 0.000500    Time 0.110554    
2024-02-26 18:05:34,914 - Epoch: [36][  110/  139]    Overall Loss 1.053351    Objective Loss 1.053351                                        LR 0.000500    Time 0.110291    
2024-02-26 18:05:35,933 - Epoch: [36][  120/  139]    Overall Loss 1.053476    Objective Loss 1.053476                                        LR 0.000500    Time 0.109585    
2024-02-26 18:05:36,963 - Epoch: [36][  130/  139]    Overall Loss 1.053985    Objective Loss 1.053985                                        LR 0.000500    Time 0.109076    
2024-02-26 18:05:42,178 - Epoch: [36][  139/  139]    Overall Loss 1.054429    Objective Loss 1.054429    Top1 94.107205    LR 0.000500    Time 0.139524    
2024-02-26 18:05:42,468 - --- validate (epoch=36)-----------
2024-02-26 18:05:42,469 - 1392 samples (32 per mini-batch)
2024-02-26 18:06:14,167 - Epoch: [36][   10/   44]    Loss 1.078660    Top1 89.585344    
2024-02-26 18:06:43,122 - Epoch: [36][   20/   44]    Loss 1.074096    Top1 89.669121    
2024-02-26 18:07:10,454 - Epoch: [36][   30/   44]    Loss 1.070714    Top1 89.594845    
2024-02-26 18:07:39,364 - Epoch: [36][   40/   44]    Loss 1.068825    Top1 89.366211    
2024-02-26 18:07:50,504 - Epoch: [36][   44/   44]    Loss 1.068865    Top1 89.362197    
2024-02-26 18:07:50,707 - ==> Top1: 89.362    Loss: 1.069

2024-02-26 18:07:50,715 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 18:07:50,715 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 18:07:50,747 - 

2024-02-26 18:07:50,747 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:07:52,586 - Epoch: [37][   10/  139]    Overall Loss 1.052682    Objective Loss 1.052682                                        LR 0.000500    Time 0.183777    
2024-02-26 18:07:53,579 - Epoch: [37][   20/  139]    Overall Loss 1.052987    Objective Loss 1.052987                                        LR 0.000500    Time 0.141483    
2024-02-26 18:07:54,576 - Epoch: [37][   30/  139]    Overall Loss 1.053514    Objective Loss 1.053514                                        LR 0.000500    Time 0.127539    
2024-02-26 18:07:55,586 - Epoch: [37][   40/  139]    Overall Loss 1.051276    Objective Loss 1.051276                                        LR 0.000500    Time 0.120880    
2024-02-26 18:07:56,568 - Epoch: [37][   50/  139]    Overall Loss 1.051314    Objective Loss 1.051314                                        LR 0.000500    Time 0.116320    
2024-02-26 18:07:57,569 - Epoch: [37][   60/  139]    Overall Loss 1.051824    Objective Loss 1.051824                                        LR 0.000500    Time 0.113615    
2024-02-26 18:07:58,597 - Epoch: [37][   70/  139]    Overall Loss 1.052058    Objective Loss 1.052058                                        LR 0.000500    Time 0.112056    
2024-02-26 18:07:59,622 - Epoch: [37][   80/  139]    Overall Loss 1.052121    Objective Loss 1.052121                                        LR 0.000500    Time 0.110852    
2024-02-26 18:08:00,609 - Epoch: [37][   90/  139]    Overall Loss 1.053254    Objective Loss 1.053254                                        LR 0.000500    Time 0.109500    
2024-02-26 18:08:01,622 - Epoch: [37][  100/  139]    Overall Loss 1.053864    Objective Loss 1.053864                                        LR 0.000500    Time 0.108676    
2024-02-26 18:08:02,626 - Epoch: [37][  110/  139]    Overall Loss 1.053187    Objective Loss 1.053187                                        LR 0.000500    Time 0.107916    
2024-02-26 18:08:03,653 - Epoch: [37][  120/  139]    Overall Loss 1.052664    Objective Loss 1.052664                                        LR 0.000500    Time 0.107480    
2024-02-26 18:08:04,649 - Epoch: [37][  130/  139]    Overall Loss 1.053002    Objective Loss 1.053002                                        LR 0.000500    Time 0.106869    
2024-02-26 18:08:09,911 - Epoch: [37][  139/  139]    Overall Loss 1.053652    Objective Loss 1.053652    Top1 94.373943    LR 0.000500    Time 0.137799    
2024-02-26 18:08:10,172 - --- validate (epoch=37)-----------
2024-02-26 18:08:10,173 - 1392 samples (32 per mini-batch)
2024-02-26 18:08:42,475 - Epoch: [37][   10/   44]    Loss 1.071431    Top1 89.843326    
2024-02-26 18:09:14,006 - Epoch: [37][   20/   44]    Loss 1.072701    Top1 89.939116    
2024-02-26 18:09:46,049 - Epoch: [37][   30/   44]    Loss 1.068918    Top1 90.034043    
2024-02-26 18:10:17,083 - Epoch: [37][   40/   44]    Loss 1.068107    Top1 89.947007    
2024-02-26 18:10:27,218 - Epoch: [37][   44/   44]    Loss 1.066166    Top1 90.042809    
2024-02-26 18:10:27,514 - ==> Top1: 90.043    Loss: 1.066

2024-02-26 18:10:27,521 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 18:10:27,521 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 18:10:27,554 - 

2024-02-26 18:10:27,554 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:10:29,444 - Epoch: [38][   10/  139]    Overall Loss 1.048751    Objective Loss 1.048751                                        LR 0.000500    Time 0.188892    
2024-02-26 18:10:30,457 - Epoch: [38][   20/  139]    Overall Loss 1.049261    Objective Loss 1.049261                                        LR 0.000500    Time 0.145011    
2024-02-26 18:10:31,484 - Epoch: [38][   30/  139]    Overall Loss 1.051783    Objective Loss 1.051783                                        LR 0.000500    Time 0.130897    
2024-02-26 18:10:32,500 - Epoch: [38][   40/  139]    Overall Loss 1.050684    Objective Loss 1.050684                                        LR 0.000500    Time 0.123560    
2024-02-26 18:10:33,545 - Epoch: [38][   50/  139]    Overall Loss 1.052706    Objective Loss 1.052706                                        LR 0.000500    Time 0.119735    
2024-02-26 18:10:34,585 - Epoch: [38][   60/  139]    Overall Loss 1.053138    Objective Loss 1.053138                                        LR 0.000500    Time 0.117100    
2024-02-26 18:10:35,642 - Epoch: [38][   70/  139]    Overall Loss 1.053269    Objective Loss 1.053269                                        LR 0.000500    Time 0.115454    
2024-02-26 18:10:36,727 - Epoch: [38][   80/  139]    Overall Loss 1.053372    Objective Loss 1.053372                                        LR 0.000500    Time 0.114581    
2024-02-26 18:10:37,778 - Epoch: [38][   90/  139]    Overall Loss 1.052911    Objective Loss 1.052911                                        LR 0.000500    Time 0.113517    
2024-02-26 18:10:38,839 - Epoch: [38][  100/  139]    Overall Loss 1.053563    Objective Loss 1.053563                                        LR 0.000500    Time 0.112770    
2024-02-26 18:10:39,897 - Epoch: [38][  110/  139]    Overall Loss 1.053323    Objective Loss 1.053323                                        LR 0.000500    Time 0.112134    
2024-02-26 18:10:40,930 - Epoch: [38][  120/  139]    Overall Loss 1.053918    Objective Loss 1.053918                                        LR 0.000500    Time 0.111385    
2024-02-26 18:10:42,004 - Epoch: [38][  130/  139]    Overall Loss 1.053404    Objective Loss 1.053404                                        LR 0.000500    Time 0.111079    
2024-02-26 18:10:47,333 - Epoch: [38][  139/  139]    Overall Loss 1.053877    Objective Loss 1.053877    Top1 93.952833    LR 0.000500    Time 0.142219    
2024-02-26 18:10:47,633 - --- validate (epoch=38)-----------
2024-02-26 18:10:47,634 - 1392 samples (32 per mini-batch)
2024-02-26 18:11:18,983 - Epoch: [38][   10/   44]    Loss 1.063833    Top1 90.438517    
2024-02-26 18:11:49,205 - Epoch: [38][   20/   44]    Loss 1.066625    Top1 90.460904    
2024-02-26 18:12:19,305 - Epoch: [38][   30/   44]    Loss 1.067429    Top1 90.376441    
2024-02-26 18:12:51,758 - Epoch: [38][   40/   44]    Loss 1.067296    Top1 90.316107    
2024-02-26 18:13:03,207 - Epoch: [38][   44/   44]    Loss 1.067673    Top1 90.243758    
2024-02-26 18:13:03,427 - ==> Top1: 90.244    Loss: 1.068

2024-02-26 18:13:03,434 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 18:13:03,434 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 18:13:03,466 - 

2024-02-26 18:13:03,466 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:13:05,336 - Epoch: [39][   10/  139]    Overall Loss 1.055568    Objective Loss 1.055568                                        LR 0.000500    Time 0.186822    
2024-02-26 18:13:06,360 - Epoch: [39][   20/  139]    Overall Loss 1.056095    Objective Loss 1.056095                                        LR 0.000500    Time 0.144599    
2024-02-26 18:13:07,399 - Epoch: [39][   30/  139]    Overall Loss 1.054770    Objective Loss 1.054770                                        LR 0.000500    Time 0.130990    
2024-02-26 18:13:08,397 - Epoch: [39][   40/  139]    Overall Loss 1.054147    Objective Loss 1.054147                                        LR 0.000500    Time 0.123186    
2024-02-26 18:13:09,403 - Epoch: [39][   50/  139]    Overall Loss 1.055084    Objective Loss 1.055084                                        LR 0.000500    Time 0.118662    
2024-02-26 18:13:10,391 - Epoch: [39][   60/  139]    Overall Loss 1.054156    Objective Loss 1.054156                                        LR 0.000500    Time 0.115329    
2024-02-26 18:13:11,425 - Epoch: [39][   70/  139]    Overall Loss 1.054231    Objective Loss 1.054231                                        LR 0.000500    Time 0.113627    
2024-02-26 18:13:12,453 - Epoch: [39][   80/  139]    Overall Loss 1.054545    Objective Loss 1.054545                                        LR 0.000500    Time 0.112266    
2024-02-26 18:13:13,466 - Epoch: [39][   90/  139]    Overall Loss 1.054524    Objective Loss 1.054524                                        LR 0.000500    Time 0.111034    
2024-02-26 18:13:14,465 - Epoch: [39][  100/  139]    Overall Loss 1.054483    Objective Loss 1.054483                                        LR 0.000500    Time 0.109917    
2024-02-26 18:13:15,468 - Epoch: [39][  110/  139]    Overall Loss 1.054489    Objective Loss 1.054489                                        LR 0.000500    Time 0.109039    
2024-02-26 18:13:16,493 - Epoch: [39][  120/  139]    Overall Loss 1.053953    Objective Loss 1.053953                                        LR 0.000500    Time 0.108488    
2024-02-26 18:13:17,505 - Epoch: [39][  130/  139]    Overall Loss 1.054644    Objective Loss 1.054644                                        LR 0.000500    Time 0.107920    
2024-02-26 18:13:22,648 - Epoch: [39][  139/  139]    Overall Loss 1.054994    Objective Loss 1.054994    Top1 94.862977    LR 0.000500    Time 0.137929    
2024-02-26 18:13:22,849 - --- validate (epoch=39)-----------
2024-02-26 18:13:22,849 - 1392 samples (32 per mini-batch)
2024-02-26 18:13:55,159 - Epoch: [39][   10/   44]    Loss 1.062976    Top1 90.364556    
2024-02-26 18:14:26,321 - Epoch: [39][   20/   44]    Loss 1.066351    Top1 90.382296    
2024-02-26 18:14:56,092 - Epoch: [39][   30/   44]    Loss 1.067659    Top1 90.255268    
2024-02-26 18:15:25,038 - Epoch: [39][   40/   44]    Loss 1.068805    Top1 90.269811    
2024-02-26 18:15:35,238 - Epoch: [39][   44/   44]    Loss 1.068045    Top1 90.253924    
2024-02-26 18:15:35,586 - ==> Top1: 90.254    Loss: 1.068

2024-02-26 18:15:35,593 - ==> Best [Top1: 90.764   Sparsity:0.00   Params: 278176 on epoch: 23]
2024-02-26 18:15:35,595 - Saving checkpoint to: logs/2024.02.26-163018/checkpoint.pth.tar
2024-02-26 18:15:35,636 - 

2024-02-26 18:15:35,636 - Initiating quantization aware training (QAT)...
2024-02-26 18:15:35,698 - 

2024-02-26 18:15:35,698 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:15:37,790 - Epoch: [40][   10/  139]    Overall Loss 1.043341    Objective Loss 1.043341                                        LR 0.000500    Time 0.208982    
2024-02-26 18:15:38,894 - Epoch: [40][   20/  139]    Overall Loss 0.993739    Objective Loss 0.993739                                        LR 0.000500    Time 0.159655    
2024-02-26 18:15:40,022 - Epoch: [40][   30/  139]    Overall Loss 0.988732    Objective Loss 0.988732                                        LR 0.000500    Time 0.144002    
2024-02-26 18:15:41,130 - Epoch: [40][   40/  139]    Overall Loss 0.973892    Objective Loss 0.973892                                        LR 0.000500    Time 0.135694    
2024-02-26 18:15:42,267 - Epoch: [40][   50/  139]    Overall Loss 0.957333    Objective Loss 0.957333                                        LR 0.000500    Time 0.131282    
2024-02-26 18:15:43,564 - Epoch: [40][   60/  139]    Overall Loss 0.946215    Objective Loss 0.946215                                        LR 0.000500    Time 0.130661    
2024-02-26 18:15:44,799 - Epoch: [40][   70/  139]    Overall Loss 0.929393    Objective Loss 0.929393                                        LR 0.000500    Time 0.129637    
2024-02-26 18:15:45,952 - Epoch: [40][   80/  139]    Overall Loss 0.914140    Objective Loss 0.914140                                        LR 0.000500    Time 0.127838    
2024-02-26 18:15:47,182 - Epoch: [40][   90/  139]    Overall Loss 0.898853    Objective Loss 0.898853                                        LR 0.000500    Time 0.127289    
2024-02-26 18:15:48,375 - Epoch: [40][  100/  139]    Overall Loss 0.885301    Objective Loss 0.885301                                        LR 0.000500    Time 0.126481    
2024-02-26 18:15:49,426 - Epoch: [40][  110/  139]    Overall Loss 0.873613    Objective Loss 0.873613                                        LR 0.000500    Time 0.124536    
2024-02-26 18:15:50,568 - Epoch: [40][  120/  139]    Overall Loss 0.859285    Objective Loss 0.859285                                        LR 0.000500    Time 0.123667    
2024-02-26 18:15:51,682 - Epoch: [40][  130/  139]    Overall Loss 0.847702    Objective Loss 0.847702                                        LR 0.000500    Time 0.122717    
2024-02-26 18:15:56,815 - Epoch: [40][  139/  139]    Overall Loss 0.836691    Objective Loss 0.836691    Top1 79.791870    LR 0.000500    Time 0.151697    
2024-02-26 18:15:57,125 - --- validate (epoch=40)-----------
2024-02-26 18:15:57,126 - 1392 samples (32 per mini-batch)
2024-02-26 18:16:27,667 - Epoch: [40][   10/   44]    Loss 0.735236    Top1 71.948149    
2024-02-26 18:16:55,984 - Epoch: [40][   20/   44]    Loss 0.732912    Top1 72.436619    
2024-02-26 18:17:27,075 - Epoch: [40][   30/   44]    Loss 0.737610    Top1 72.366177    
2024-02-26 18:17:58,776 - Epoch: [40][   40/   44]    Loss 0.741323    Top1 71.818477    
2024-02-26 18:18:10,257 - Epoch: [40][   44/   44]    Loss 0.741531    Top1 71.682245    
2024-02-26 18:18:10,649 - ==> Top1: 71.682    Loss: 0.742

2024-02-26 18:18:10,656 - ==> Best [Top1: 71.682   Sparsity:0.00   Params: 278176 on epoch: 40]
2024-02-26 18:18:10,656 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:18:10,688 - 

2024-02-26 18:18:10,688 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:18:12,710 - Epoch: [41][   10/  139]    Overall Loss 0.721828    Objective Loss 0.721828                                        LR 0.000500    Time 0.202033    
2024-02-26 18:18:13,807 - Epoch: [41][   20/  139]    Overall Loss 0.711435    Objective Loss 0.711435                                        LR 0.000500    Time 0.155815    
2024-02-26 18:18:14,939 - Epoch: [41][   30/  139]    Overall Loss 0.700820    Objective Loss 0.700820                                        LR 0.000500    Time 0.141571    
2024-02-26 18:18:16,045 - Epoch: [41][   40/  139]    Overall Loss 0.688181    Objective Loss 0.688181                                        LR 0.000500    Time 0.133793    
2024-02-26 18:18:17,147 - Epoch: [41][   50/  139]    Overall Loss 0.673687    Objective Loss 0.673687                                        LR 0.000500    Time 0.129068    
2024-02-26 18:18:18,226 - Epoch: [41][   60/  139]    Overall Loss 0.666774    Objective Loss 0.666774                                        LR 0.000500    Time 0.125518    
2024-02-26 18:18:19,352 - Epoch: [41][   70/  139]    Overall Loss 0.663657    Objective Loss 0.663657                                        LR 0.000500    Time 0.123669    
2024-02-26 18:18:20,442 - Epoch: [41][   80/  139]    Overall Loss 0.658011    Objective Loss 0.658011                                        LR 0.000500    Time 0.121820    
2024-02-26 18:18:21,542 - Epoch: [41][   90/  139]    Overall Loss 0.652690    Objective Loss 0.652690                                        LR 0.000500    Time 0.120503    
2024-02-26 18:18:22,650 - Epoch: [41][  100/  139]    Overall Loss 0.648421    Objective Loss 0.648421                                        LR 0.000500    Time 0.119527    
2024-02-26 18:18:23,811 - Epoch: [41][  110/  139]    Overall Loss 0.644158    Objective Loss 0.644158                                        LR 0.000500    Time 0.119212    
2024-02-26 18:18:24,995 - Epoch: [41][  120/  139]    Overall Loss 0.641354    Objective Loss 0.641354                                        LR 0.000500    Time 0.119134    
2024-02-26 18:18:26,150 - Epoch: [41][  130/  139]    Overall Loss 0.636932    Objective Loss 0.636932                                        LR 0.000500    Time 0.118846    
2024-02-26 18:18:31,594 - Epoch: [41][  139/  139]    Overall Loss 0.631523    Objective Loss 0.631523    Top1 86.086552    LR 0.000500    Time 0.150312    
2024-02-26 18:18:31,903 - --- validate (epoch=41)-----------
2024-02-26 18:18:31,903 - 1392 samples (32 per mini-batch)
2024-02-26 18:19:04,168 - Epoch: [41][   10/   44]    Loss 0.578733    Top1 85.850913    
2024-02-26 18:19:34,380 - Epoch: [41][   20/   44]    Loss 0.579518    Top1 85.818362    
2024-02-26 18:20:03,865 - Epoch: [41][   30/   44]    Loss 0.583541    Top1 85.576878    
2024-02-26 18:20:32,134 - Epoch: [41][   40/   44]    Loss 0.585808    Top1 85.455762    
2024-02-26 18:20:42,965 - Epoch: [41][   44/   44]    Loss 0.587759    Top1 85.370371    
2024-02-26 18:20:43,275 - ==> Top1: 85.370    Loss: 0.588

2024-02-26 18:20:43,283 - ==> Best [Top1: 85.370   Sparsity:0.00   Params: 278176 on epoch: 41]
2024-02-26 18:20:43,283 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:20:43,327 - 

2024-02-26 18:20:43,327 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:20:45,482 - Epoch: [42][   10/  139]    Overall Loss 0.587514    Objective Loss 0.587514                                        LR 0.000500    Time 0.215369    
2024-02-26 18:20:46,575 - Epoch: [42][   20/  139]    Overall Loss 0.570691    Objective Loss 0.570691                                        LR 0.000500    Time 0.162294    
2024-02-26 18:20:47,688 - Epoch: [42][   30/  139]    Overall Loss 0.574531    Objective Loss 0.574531                                        LR 0.000500    Time 0.145262    
2024-02-26 18:20:48,941 - Epoch: [42][   40/  139]    Overall Loss 0.572100    Objective Loss 0.572100                                        LR 0.000500    Time 0.140240    
2024-02-26 18:20:50,587 - Epoch: [42][   50/  139]    Overall Loss 0.569879    Objective Loss 0.569879                                        LR 0.000500    Time 0.145083    
2024-02-26 18:20:51,753 - Epoch: [42][   60/  139]    Overall Loss 0.564112    Objective Loss 0.564112                                        LR 0.000500    Time 0.140333    
2024-02-26 18:20:52,833 - Epoch: [42][   70/  139]    Overall Loss 0.561525    Objective Loss 0.561525                                        LR 0.000500    Time 0.135705    
2024-02-26 18:20:53,989 - Epoch: [42][   80/  139]    Overall Loss 0.557899    Objective Loss 0.557899                                        LR 0.000500    Time 0.133176    
2024-02-26 18:20:55,077 - Epoch: [42][   90/  139]    Overall Loss 0.554628    Objective Loss 0.554628                                        LR 0.000500    Time 0.130466    
2024-02-26 18:20:56,177 - Epoch: [42][  100/  139]    Overall Loss 0.551508    Objective Loss 0.551508                                        LR 0.000500    Time 0.128415    
2024-02-26 18:20:57,306 - Epoch: [42][  110/  139]    Overall Loss 0.548295    Objective Loss 0.548295                                        LR 0.000500    Time 0.126993    
2024-02-26 18:20:58,394 - Epoch: [42][  120/  139]    Overall Loss 0.543291    Objective Loss 0.543291                                        LR 0.000500    Time 0.125472    
2024-02-26 18:20:59,504 - Epoch: [42][  130/  139]    Overall Loss 0.542150    Objective Loss 0.542150                                        LR 0.000500    Time 0.124263    
2024-02-26 18:21:05,026 - Epoch: [42][  139/  139]    Overall Loss 0.540737    Objective Loss 0.540737    Top1 89.446595    LR 0.000500    Time 0.155940    
2024-02-26 18:21:05,416 - --- validate (epoch=42)-----------
2024-02-26 18:21:05,417 - 1392 samples (32 per mini-batch)
2024-02-26 18:21:37,825 - Epoch: [42][   10/   44]    Loss 0.530216    Top1 88.817204    
2024-02-26 18:22:09,799 - Epoch: [42][   20/   44]    Loss 0.535820    Top1 88.380682    
2024-02-26 18:22:42,054 - Epoch: [42][   30/   44]    Loss 0.530570    Top1 88.731935    
2024-02-26 18:23:13,524 - Epoch: [42][   40/   44]    Loss 0.530980    Top1 88.658563    
2024-02-26 18:23:24,517 - Epoch: [42][   44/   44]    Loss 0.531303    Top1 88.626138    
2024-02-26 18:23:24,747 - ==> Top1: 88.626    Loss: 0.531

2024-02-26 18:23:24,754 - ==> Best [Top1: 88.626   Sparsity:0.00   Params: 278176 on epoch: 42]
2024-02-26 18:23:24,754 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:23:24,789 - 

2024-02-26 18:23:24,789 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:23:26,809 - Epoch: [43][   10/  139]    Overall Loss 0.506947    Objective Loss 0.506947                                        LR 0.000500    Time 0.201796    
2024-02-26 18:23:27,915 - Epoch: [43][   20/  139]    Overall Loss 0.508081    Objective Loss 0.508081                                        LR 0.000500    Time 0.156141    
2024-02-26 18:23:29,006 - Epoch: [43][   30/  139]    Overall Loss 0.505334    Objective Loss 0.505334                                        LR 0.000500    Time 0.140465    
2024-02-26 18:23:30,091 - Epoch: [43][   40/  139]    Overall Loss 0.503623    Objective Loss 0.503623                                        LR 0.000500    Time 0.132444    
2024-02-26 18:23:31,163 - Epoch: [43][   50/  139]    Overall Loss 0.504206    Objective Loss 0.504206                                        LR 0.000500    Time 0.127385    
2024-02-26 18:23:32,247 - Epoch: [43][   60/  139]    Overall Loss 0.508206    Objective Loss 0.508206                                        LR 0.000500    Time 0.124209    
2024-02-26 18:23:33,368 - Epoch: [43][   70/  139]    Overall Loss 0.508388    Objective Loss 0.508388                                        LR 0.000500    Time 0.122470    
2024-02-26 18:23:34,476 - Epoch: [43][   80/  139]    Overall Loss 0.511542    Objective Loss 0.511542                                        LR 0.000500    Time 0.120999    
2024-02-26 18:23:35,581 - Epoch: [43][   90/  139]    Overall Loss 0.510658    Objective Loss 0.510658                                        LR 0.000500    Time 0.119822    
2024-02-26 18:23:36,651 - Epoch: [43][  100/  139]    Overall Loss 0.509652    Objective Loss 0.509652                                        LR 0.000500    Time 0.118538    
2024-02-26 18:23:37,762 - Epoch: [43][  110/  139]    Overall Loss 0.508543    Objective Loss 0.508543                                        LR 0.000500    Time 0.117851    
2024-02-26 18:23:38,837 - Epoch: [43][  120/  139]    Overall Loss 0.507152    Objective Loss 0.507152                                        LR 0.000500    Time 0.116983    
2024-02-26 18:23:39,948 - Epoch: [43][  130/  139]    Overall Loss 0.507114    Objective Loss 0.507114                                        LR 0.000500    Time 0.116527    
2024-02-26 18:23:45,064 - Epoch: [43][  139/  139]    Overall Loss 0.506108    Objective Loss 0.506108    Top1 88.598486    LR 0.000500    Time 0.145777    
2024-02-26 18:23:45,316 - --- validate (epoch=43)-----------
2024-02-26 18:23:45,316 - 1392 samples (32 per mini-batch)
2024-02-26 18:24:15,717 - Epoch: [43][   10/   44]    Loss 0.536334    Top1 88.310706    
2024-02-26 18:24:41,847 - Epoch: [43][   20/   44]    Loss 0.537721    Top1 88.136043    
2024-02-26 18:25:08,678 - Epoch: [43][   30/   44]    Loss 0.542484    Top1 87.854404    
2024-02-26 18:25:33,028 - Epoch: [43][   40/   44]    Loss 0.544690    Top1 87.719082    
2024-02-26 18:25:41,309 - Epoch: [43][   44/   44]    Loss 0.543256    Top1 87.764190    
2024-02-26 18:25:41,707 - ==> Top1: 87.764    Loss: 0.543

2024-02-26 18:25:41,714 - ==> Best [Top1: 88.626   Sparsity:0.00   Params: 278176 on epoch: 42]
2024-02-26 18:25:41,714 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:25:41,745 - 

2024-02-26 18:25:41,746 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:25:43,687 - Epoch: [44][   10/  139]    Overall Loss 0.494003    Objective Loss 0.494003                                        LR 0.000500    Time 0.193808    
2024-02-26 18:25:44,800 - Epoch: [44][   20/  139]    Overall Loss 0.488925    Objective Loss 0.488925                                        LR 0.000500    Time 0.152515    
2024-02-26 18:25:46,399 - Epoch: [44][   30/  139]    Overall Loss 0.491166    Objective Loss 0.491166                                        LR 0.000500    Time 0.154978    
2024-02-26 18:25:47,583 - Epoch: [44][   40/  139]    Overall Loss 0.490489    Objective Loss 0.490489                                        LR 0.000500    Time 0.145802    
2024-02-26 18:25:48,681 - Epoch: [44][   50/  139]    Overall Loss 0.487944    Objective Loss 0.487944                                        LR 0.000500    Time 0.138595    
2024-02-26 18:25:49,874 - Epoch: [44][   60/  139]    Overall Loss 0.485977    Objective Loss 0.485977                                        LR 0.000500    Time 0.135371    
2024-02-26 18:25:51,000 - Epoch: [44][   70/  139]    Overall Loss 0.484534    Objective Loss 0.484534                                        LR 0.000500    Time 0.132103    
2024-02-26 18:25:52,170 - Epoch: [44][   80/  139]    Overall Loss 0.485465    Objective Loss 0.485465                                        LR 0.000500    Time 0.130210    
2024-02-26 18:25:53,337 - Epoch: [44][   90/  139]    Overall Loss 0.484716    Objective Loss 0.484716                                        LR 0.000500    Time 0.128703    
2024-02-26 18:25:54,432 - Epoch: [44][  100/  139]    Overall Loss 0.484594    Objective Loss 0.484594                                        LR 0.000500    Time 0.126777    
2024-02-26 18:25:55,741 - Epoch: [44][  110/  139]    Overall Loss 0.484074    Objective Loss 0.484074                                        LR 0.000500    Time 0.127144    
2024-02-26 18:25:56,919 - Epoch: [44][  120/  139]    Overall Loss 0.484612    Objective Loss 0.484612                                        LR 0.000500    Time 0.126353    
2024-02-26 18:25:58,163 - Epoch: [44][  130/  139]    Overall Loss 0.485058    Objective Loss 0.485058                                        LR 0.000500    Time 0.126202    
2024-02-26 18:26:02,943 - Epoch: [44][  139/  139]    Overall Loss 0.486682    Objective Loss 0.486682    Top1 89.151040    LR 0.000500    Time 0.152413    
2024-02-26 18:26:03,214 - --- validate (epoch=44)-----------
2024-02-26 18:26:03,215 - 1392 samples (32 per mini-batch)
2024-02-26 18:26:34,730 - Epoch: [44][   10/   44]    Loss 0.560086    Top1 87.104222    
2024-02-26 18:27:05,420 - Epoch: [44][   20/   44]    Loss 0.559649    Top1 87.074840    
2024-02-26 18:27:37,638 - Epoch: [44][   30/   44]    Loss 0.556525    Top1 87.230373    
2024-02-26 18:28:10,004 - Epoch: [44][   40/   44]    Loss 0.556418    Top1 87.237812    
2024-02-26 18:28:20,248 - Epoch: [44][   44/   44]    Loss 0.553395    Top1 87.349470    
2024-02-26 18:28:20,594 - ==> Top1: 87.349    Loss: 0.553

2024-02-26 18:28:20,601 - ==> Best [Top1: 88.626   Sparsity:0.00   Params: 278176 on epoch: 42]
2024-02-26 18:28:20,601 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:28:20,634 - 

2024-02-26 18:28:20,634 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:28:22,693 - Epoch: [45][   10/  139]    Overall Loss 0.486834    Objective Loss 0.486834                                        LR 0.000500    Time 0.205709    
2024-02-26 18:28:23,734 - Epoch: [45][   20/  139]    Overall Loss 0.487812    Objective Loss 0.487812                                        LR 0.000500    Time 0.154839    
2024-02-26 18:28:24,770 - Epoch: [45][   30/  139]    Overall Loss 0.483919    Objective Loss 0.483919                                        LR 0.000500    Time 0.137755    
2024-02-26 18:28:25,853 - Epoch: [45][   40/  139]    Overall Loss 0.484730    Objective Loss 0.484730                                        LR 0.000500    Time 0.130374    
2024-02-26 18:28:26,885 - Epoch: [45][   50/  139]    Overall Loss 0.482179    Objective Loss 0.482179                                        LR 0.000500    Time 0.124928    
2024-02-26 18:28:27,989 - Epoch: [45][   60/  139]    Overall Loss 0.481921    Objective Loss 0.481921                                        LR 0.000500    Time 0.122493    
2024-02-26 18:28:29,129 - Epoch: [45][   70/  139]    Overall Loss 0.481587    Objective Loss 0.481587                                        LR 0.000500    Time 0.121260    
2024-02-26 18:28:30,195 - Epoch: [45][   80/  139]    Overall Loss 0.480833    Objective Loss 0.480833                                        LR 0.000500    Time 0.119426    
2024-02-26 18:28:31,353 - Epoch: [45][   90/  139]    Overall Loss 0.479725    Objective Loss 0.479725                                        LR 0.000500    Time 0.119008    
2024-02-26 18:28:32,555 - Epoch: [45][  100/  139]    Overall Loss 0.478933    Objective Loss 0.478933                                        LR 0.000500    Time 0.119119    
2024-02-26 18:28:33,701 - Epoch: [45][  110/  139]    Overall Loss 0.477453    Objective Loss 0.477453                                        LR 0.000500    Time 0.118699    
2024-02-26 18:28:34,945 - Epoch: [45][  120/  139]    Overall Loss 0.476539    Objective Loss 0.476539                                        LR 0.000500    Time 0.119173    
2024-02-26 18:28:36,154 - Epoch: [45][  130/  139]    Overall Loss 0.475494    Objective Loss 0.475494                                        LR 0.000500    Time 0.119302    
2024-02-26 18:28:40,797 - Epoch: [45][  139/  139]    Overall Loss 0.475650    Objective Loss 0.475650    Top1 91.921880    LR 0.000500    Time 0.144976    
2024-02-26 18:28:41,206 - --- validate (epoch=45)-----------
2024-02-26 18:28:41,207 - 1392 samples (32 per mini-batch)
2024-02-26 18:29:08,577 - Epoch: [45][   10/   44]    Loss 0.542242    Top1 88.016713    
2024-02-26 18:29:35,529 - Epoch: [45][   20/   44]    Loss 0.534250    Top1 88.448016    
2024-02-26 18:30:01,420 - Epoch: [45][   30/   44]    Loss 0.534783    Top1 88.409188    
2024-02-26 18:30:25,857 - Epoch: [45][   40/   44]    Loss 0.530654    Top1 88.604898    
2024-02-26 18:30:35,243 - Epoch: [45][   44/   44]    Loss 0.530630    Top1 88.634388    
2024-02-26 18:30:35,556 - ==> Top1: 88.634    Loss: 0.531

2024-02-26 18:30:35,563 - ==> Best [Top1: 88.634   Sparsity:0.00   Params: 278176 on epoch: 45]
2024-02-26 18:30:35,563 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:30:35,603 - 

2024-02-26 18:30:35,603 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:30:37,632 - Epoch: [46][   10/  139]    Overall Loss 0.462452    Objective Loss 0.462452                                        LR 0.000500    Time 0.202739    
2024-02-26 18:30:38,787 - Epoch: [46][   20/  139]    Overall Loss 0.464321    Objective Loss 0.464321                                        LR 0.000500    Time 0.159090    
2024-02-26 18:30:39,908 - Epoch: [46][   30/  139]    Overall Loss 0.464526    Objective Loss 0.464526                                        LR 0.000500    Time 0.143396    
2024-02-26 18:30:41,016 - Epoch: [46][   40/  139]    Overall Loss 0.464044    Objective Loss 0.464044                                        LR 0.000500    Time 0.135223    
2024-02-26 18:30:42,175 - Epoch: [46][   50/  139]    Overall Loss 0.466411    Objective Loss 0.466411                                        LR 0.000500    Time 0.131337    
2024-02-26 18:30:43,280 - Epoch: [46][   60/  139]    Overall Loss 0.467011    Objective Loss 0.467011                                        LR 0.000500    Time 0.127851    
2024-02-26 18:30:44,442 - Epoch: [46][   70/  139]    Overall Loss 0.468364    Objective Loss 0.468364                                        LR 0.000500    Time 0.126168    
2024-02-26 18:30:45,573 - Epoch: [46][   80/  139]    Overall Loss 0.469020    Objective Loss 0.469020                                        LR 0.000500    Time 0.124530    
2024-02-26 18:30:46,750 - Epoch: [46][   90/  139]    Overall Loss 0.469827    Objective Loss 0.469827                                        LR 0.000500    Time 0.123768    
2024-02-26 18:30:47,876 - Epoch: [46][  100/  139]    Overall Loss 0.471167    Objective Loss 0.471167                                        LR 0.000500    Time 0.122647    
2024-02-26 18:30:49,047 - Epoch: [46][  110/  139]    Overall Loss 0.470030    Objective Loss 0.470030                                        LR 0.000500    Time 0.122132    
2024-02-26 18:30:50,213 - Epoch: [46][  120/  139]    Overall Loss 0.470413    Objective Loss 0.470413                                        LR 0.000500    Time 0.121664    
2024-02-26 18:30:51,418 - Epoch: [46][  130/  139]    Overall Loss 0.469242    Objective Loss 0.469242                                        LR 0.000500    Time 0.121569    
2024-02-26 18:30:56,447 - Epoch: [46][  139/  139]    Overall Loss 0.469421    Objective Loss 0.469421    Top1 93.253721    LR 0.000500    Time 0.149876    
2024-02-26 18:30:56,793 - --- validate (epoch=46)-----------
2024-02-26 18:30:56,794 - 1392 samples (32 per mini-batch)
2024-02-26 18:31:29,910 - Epoch: [46][   10/   44]    Loss 0.517815    Top1 89.466010    
2024-02-26 18:32:01,380 - Epoch: [46][   20/   44]    Loss 0.507012    Top1 90.128851    
2024-02-26 18:32:33,203 - Epoch: [46][   30/   44]    Loss 0.509667    Top1 89.993965    
2024-02-26 18:33:02,541 - Epoch: [46][   40/   44]    Loss 0.512110    Top1 89.856840    
2024-02-26 18:33:12,066 - Epoch: [46][   44/   44]    Loss 0.515051    Top1 89.723592    
2024-02-26 18:33:12,429 - ==> Top1: 89.724    Loss: 0.515

2024-02-26 18:33:12,438 - ==> Best [Top1: 89.724   Sparsity:0.00   Params: 278176 on epoch: 46]
2024-02-26 18:33:12,439 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:33:12,479 - 

2024-02-26 18:33:12,480 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:33:14,492 - Epoch: [47][   10/  139]    Overall Loss 0.458853    Objective Loss 0.458853                                        LR 0.000500    Time 0.200933    
2024-02-26 18:33:15,545 - Epoch: [47][   20/  139]    Overall Loss 0.458782    Objective Loss 0.458782                                        LR 0.000500    Time 0.153065    
2024-02-26 18:33:16,651 - Epoch: [47][   30/  139]    Overall Loss 0.456790    Objective Loss 0.456790                                        LR 0.000500    Time 0.138902    
2024-02-26 18:33:17,776 - Epoch: [47][   40/  139]    Overall Loss 0.459081    Objective Loss 0.459081                                        LR 0.000500    Time 0.132288    
2024-02-26 18:33:18,871 - Epoch: [47][   50/  139]    Overall Loss 0.457910    Objective Loss 0.457910                                        LR 0.000500    Time 0.127726    
2024-02-26 18:33:20,020 - Epoch: [47][   60/  139]    Overall Loss 0.458327    Objective Loss 0.458327                                        LR 0.000500    Time 0.125571    
2024-02-26 18:33:21,222 - Epoch: [47][   70/  139]    Overall Loss 0.457637    Objective Loss 0.457637                                        LR 0.000500    Time 0.124801    
2024-02-26 18:33:22,340 - Epoch: [47][   80/  139]    Overall Loss 0.457966    Objective Loss 0.457966                                        LR 0.000500    Time 0.123161    
2024-02-26 18:33:23,508 - Epoch: [47][   90/  139]    Overall Loss 0.459111    Objective Loss 0.459111                                        LR 0.000500    Time 0.122445    
2024-02-26 18:33:24,628 - Epoch: [47][  100/  139]    Overall Loss 0.459323    Objective Loss 0.459323                                        LR 0.000500    Time 0.121401    
2024-02-26 18:33:25,799 - Epoch: [47][  110/  139]    Overall Loss 0.460195    Objective Loss 0.460195                                        LR 0.000500    Time 0.121002    
2024-02-26 18:33:26,967 - Epoch: [47][  120/  139]    Overall Loss 0.460624    Objective Loss 0.460624                                        LR 0.000500    Time 0.120642    
2024-02-26 18:33:28,112 - Epoch: [47][  130/  139]    Overall Loss 0.460849    Objective Loss 0.460849                                        LR 0.000500    Time 0.120170    
2024-02-26 18:33:33,286 - Epoch: [47][  139/  139]    Overall Loss 0.459961    Objective Loss 0.459961    Top1 92.542907    LR 0.000500    Time 0.149606    
2024-02-26 18:33:33,572 - --- validate (epoch=47)-----------
2024-02-26 18:33:33,573 - 1392 samples (32 per mini-batch)
2024-02-26 18:34:06,975 - Epoch: [47][   10/   44]    Loss 0.528214    Top1 88.942248    
2024-02-26 18:34:35,637 - Epoch: [47][   20/   44]    Loss 0.528848    Top1 88.984065    
2024-02-26 18:35:00,658 - Epoch: [47][   30/   44]    Loss 0.522610    Top1 89.308352    
2024-02-26 18:35:31,154 - Epoch: [47][   40/   44]    Loss 0.519925    Top1 89.478376    
2024-02-26 18:35:41,972 - Epoch: [47][   44/   44]    Loss 0.518606    Top1 89.571459    
2024-02-26 18:35:42,275 - ==> Top1: 89.571    Loss: 0.519

2024-02-26 18:35:42,282 - ==> Best [Top1: 89.724   Sparsity:0.00   Params: 278176 on epoch: 46]
2024-02-26 18:35:42,282 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:35:42,312 - 

2024-02-26 18:35:42,313 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:35:44,451 - Epoch: [48][   10/  139]    Overall Loss 0.460716    Objective Loss 0.460716                                        LR 0.000500    Time 0.213676    
2024-02-26 18:35:45,518 - Epoch: [48][   20/  139]    Overall Loss 0.454911    Objective Loss 0.454911                                        LR 0.000500    Time 0.160090    
2024-02-26 18:35:46,656 - Epoch: [48][   30/  139]    Overall Loss 0.454942    Objective Loss 0.454942                                        LR 0.000500    Time 0.144631    
2024-02-26 18:35:47,744 - Epoch: [48][   40/  139]    Overall Loss 0.453949    Objective Loss 0.453949                                        LR 0.000500    Time 0.135669    
2024-02-26 18:35:48,852 - Epoch: [48][   50/  139]    Overall Loss 0.454406    Objective Loss 0.454406                                        LR 0.000500    Time 0.130663    
2024-02-26 18:35:49,965 - Epoch: [48][   60/  139]    Overall Loss 0.455348    Objective Loss 0.455348                                        LR 0.000500    Time 0.127414    
2024-02-26 18:35:51,076 - Epoch: [48][   70/  139]    Overall Loss 0.455729    Objective Loss 0.455729                                        LR 0.000500    Time 0.125073    
2024-02-26 18:35:52,209 - Epoch: [48][   80/  139]    Overall Loss 0.456484    Objective Loss 0.456484                                        LR 0.000500    Time 0.123592    
2024-02-26 18:35:53,322 - Epoch: [48][   90/  139]    Overall Loss 0.456403    Objective Loss 0.456403                                        LR 0.000500    Time 0.122217    
2024-02-26 18:35:54,451 - Epoch: [48][  100/  139]    Overall Loss 0.455485    Objective Loss 0.455485                                        LR 0.000500    Time 0.121282    
2024-02-26 18:35:55,577 - Epoch: [48][  110/  139]    Overall Loss 0.455732    Objective Loss 0.455732                                        LR 0.000500    Time 0.120484    
2024-02-26 18:35:56,657 - Epoch: [48][  120/  139]    Overall Loss 0.456100    Objective Loss 0.456100                                        LR 0.000500    Time 0.119440    
2024-02-26 18:35:57,788 - Epoch: [48][  130/  139]    Overall Loss 0.456751    Objective Loss 0.456751                                        LR 0.000500    Time 0.118944    
2024-02-26 18:36:03,092 - Epoch: [48][  139/  139]    Overall Loss 0.456378    Objective Loss 0.456378    Top1 93.573544    LR 0.000500    Time 0.149397    
2024-02-26 18:36:03,363 - --- validate (epoch=48)-----------
2024-02-26 18:36:03,364 - 1392 samples (32 per mini-batch)
2024-02-26 18:36:36,544 - Epoch: [48][   10/   44]    Loss 0.515729    Top1 89.690615    
2024-02-26 18:37:08,246 - Epoch: [48][   20/   44]    Loss 0.518303    Top1 89.548922    
2024-02-26 18:37:39,726 - Epoch: [48][   30/   44]    Loss 0.514683    Top1 89.743910    
2024-02-26 18:38:08,649 - Epoch: [48][   40/   44]    Loss 0.511696    Top1 89.919234    
2024-02-26 18:38:19,221 - Epoch: [48][   44/   44]    Loss 0.512384    Top1 89.867937    
2024-02-26 18:38:19,467 - ==> Top1: 89.868    Loss: 0.512

2024-02-26 18:38:19,474 - ==> Best [Top1: 89.868   Sparsity:0.00   Params: 278176 on epoch: 48]
2024-02-26 18:38:19,474 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:38:19,509 - 

2024-02-26 18:38:19,509 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:38:21,583 - Epoch: [49][   10/  139]    Overall Loss 0.453179    Objective Loss 0.453179                                        LR 0.000500    Time 0.207235    
2024-02-26 18:38:22,683 - Epoch: [49][   20/  139]    Overall Loss 0.452667    Objective Loss 0.452667                                        LR 0.000500    Time 0.158620    
2024-02-26 18:38:23,849 - Epoch: [49][   30/  139]    Overall Loss 0.453796    Objective Loss 0.453796                                        LR 0.000500    Time 0.144570    
2024-02-26 18:38:24,997 - Epoch: [49][   40/  139]    Overall Loss 0.451258    Objective Loss 0.451258                                        LR 0.000500    Time 0.137125    
2024-02-26 18:38:26,121 - Epoch: [49][   50/  139]    Overall Loss 0.451078    Objective Loss 0.451078                                        LR 0.000500    Time 0.132169    
2024-02-26 18:38:27,194 - Epoch: [49][   60/  139]    Overall Loss 0.450430    Objective Loss 0.450430                                        LR 0.000500    Time 0.128004    
2024-02-26 18:38:28,478 - Epoch: [49][   70/  139]    Overall Loss 0.449979    Objective Loss 0.449979                                        LR 0.000500    Time 0.128060    
2024-02-26 18:38:29,787 - Epoch: [49][   80/  139]    Overall Loss 0.449661    Objective Loss 0.449661                                        LR 0.000500    Time 0.128408    
2024-02-26 18:38:30,957 - Epoch: [49][   90/  139]    Overall Loss 0.450369    Objective Loss 0.450369                                        LR 0.000500    Time 0.127125    
2024-02-26 18:38:32,253 - Epoch: [49][  100/  139]    Overall Loss 0.449819    Objective Loss 0.449819                                        LR 0.000500    Time 0.127369    
2024-02-26 18:38:33,544 - Epoch: [49][  110/  139]    Overall Loss 0.449568    Objective Loss 0.449568                                        LR 0.000500    Time 0.127524    
2024-02-26 18:38:34,688 - Epoch: [49][  120/  139]    Overall Loss 0.450337    Objective Loss 0.450337                                        LR 0.000500    Time 0.126425    
2024-02-26 18:38:35,774 - Epoch: [49][  130/  139]    Overall Loss 0.451143    Objective Loss 0.451143                                        LR 0.000500    Time 0.125043    
2024-02-26 18:38:41,141 - Epoch: [49][  139/  139]    Overall Loss 0.451617    Objective Loss 0.451617    Top1 91.487801    LR 0.000500    Time 0.155556    
2024-02-26 18:38:41,374 - --- validate (epoch=49)-----------
2024-02-26 18:38:41,375 - 1392 samples (32 per mini-batch)
2024-02-26 18:39:13,884 - Epoch: [49][   10/   44]    Loss 0.503609    Top1 90.175027    
2024-02-26 18:39:43,953 - Epoch: [49][   20/   44]    Loss 0.513838    Top1 89.638619    
2024-02-26 18:40:16,040 - Epoch: [49][   30/   44]    Loss 0.516262    Top1 89.465683    
2024-02-26 18:40:47,346 - Epoch: [49][   40/   44]    Loss 0.519113    Top1 89.300408    
2024-02-26 18:40:57,909 - Epoch: [49][   44/   44]    Loss 0.519857    Top1 89.288394    
2024-02-26 18:40:58,198 - ==> Top1: 89.288    Loss: 0.520

2024-02-26 18:40:58,205 - ==> Best [Top1: 89.868   Sparsity:0.00   Params: 278176 on epoch: 48]
2024-02-26 18:40:58,206 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:40:58,237 - 

2024-02-26 18:40:58,237 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:41:00,247 - Epoch: [50][   10/  139]    Overall Loss 0.451000    Objective Loss 0.451000                                        LR 0.000500    Time 0.200785    
2024-02-26 18:41:01,343 - Epoch: [50][   20/  139]    Overall Loss 0.451391    Objective Loss 0.451391                                        LR 0.000500    Time 0.155190    
2024-02-26 18:41:02,450 - Epoch: [50][   30/  139]    Overall Loss 0.451350    Objective Loss 0.451350                                        LR 0.000500    Time 0.140309    
2024-02-26 18:41:03,509 - Epoch: [50][   40/  139]    Overall Loss 0.450820    Objective Loss 0.450820                                        LR 0.000500    Time 0.131702    
2024-02-26 18:41:04,607 - Epoch: [50][   50/  139]    Overall Loss 0.448559    Objective Loss 0.448559                                        LR 0.000500    Time 0.127075    
2024-02-26 18:41:05,697 - Epoch: [50][   60/  139]    Overall Loss 0.448863    Objective Loss 0.448863                                        LR 0.000500    Time 0.124039    
2024-02-26 18:41:06,774 - Epoch: [50][   70/  139]    Overall Loss 0.448599    Objective Loss 0.448599                                        LR 0.000500    Time 0.121695    
2024-02-26 18:41:07,869 - Epoch: [50][   80/  139]    Overall Loss 0.448384    Objective Loss 0.448384                                        LR 0.000500    Time 0.120158    
2024-02-26 18:41:08,934 - Epoch: [50][   90/  139]    Overall Loss 0.447967    Objective Loss 0.447967                                        LR 0.000500    Time 0.118639    
2024-02-26 18:41:10,046 - Epoch: [50][  100/  139]    Overall Loss 0.447903    Objective Loss 0.447903                                        LR 0.000500    Time 0.117891    
2024-02-26 18:41:11,162 - Epoch: [50][  110/  139]    Overall Loss 0.448374    Objective Loss 0.448374                                        LR 0.000500    Time 0.117174    
2024-02-26 18:41:12,235 - Epoch: [50][  120/  139]    Overall Loss 0.448882    Objective Loss 0.448882                                        LR 0.000500    Time 0.116348    
2024-02-26 18:41:13,335 - Epoch: [50][  130/  139]    Overall Loss 0.449585    Objective Loss 0.449585                                        LR 0.000500    Time 0.115850    
2024-02-26 18:41:18,728 - Epoch: [50][  139/  139]    Overall Loss 0.448864    Objective Loss 0.448864    Top1 94.873175    LR 0.000500    Time 0.147148    
2024-02-26 18:41:18,940 - --- validate (epoch=50)-----------
2024-02-26 18:41:18,940 - 1392 samples (32 per mini-batch)
2024-02-26 18:41:51,895 - Epoch: [50][   10/   44]    Loss 0.518412    Top1 89.600179    
2024-02-26 18:42:24,513 - Epoch: [50][   20/   44]    Loss 0.513632    Top1 89.842557    
2024-02-26 18:42:57,696 - Epoch: [50][   30/   44]    Loss 0.513199    Top1 89.857248    
2024-02-26 18:43:28,118 - Epoch: [50][   40/   44]    Loss 0.512557    Top1 89.869948    
2024-02-26 18:43:39,803 - Epoch: [50][   44/   44]    Loss 0.513650    Top1 89.838605    
2024-02-26 18:43:40,113 - ==> Top1: 89.839    Loss: 0.514

2024-02-26 18:43:40,120 - ==> Best [Top1: 89.868   Sparsity:0.00   Params: 278176 on epoch: 48]
2024-02-26 18:43:40,121 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:43:40,171 - 

2024-02-26 18:43:40,172 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:43:42,472 - Epoch: [51][   10/  139]    Overall Loss 0.447522    Objective Loss 0.447522                                        LR 0.000500    Time 0.229706    
2024-02-26 18:43:43,574 - Epoch: [51][   20/  139]    Overall Loss 0.445077    Objective Loss 0.445077                                        LR 0.000500    Time 0.169920    
2024-02-26 18:43:44,684 - Epoch: [51][   30/  139]    Overall Loss 0.444491    Objective Loss 0.444491                                        LR 0.000500    Time 0.150273    
2024-02-26 18:43:45,761 - Epoch: [51][   40/  139]    Overall Loss 0.444077    Objective Loss 0.444077                                        LR 0.000500    Time 0.139607    
2024-02-26 18:43:46,985 - Epoch: [51][   50/  139]    Overall Loss 0.444927    Objective Loss 0.444927                                        LR 0.000500    Time 0.136148    
2024-02-26 18:43:48,482 - Epoch: [51][   60/  139]    Overall Loss 0.444769    Objective Loss 0.444769                                        LR 0.000500    Time 0.138397    
2024-02-26 18:43:49,871 - Epoch: [51][   70/  139]    Overall Loss 0.445392    Objective Loss 0.445392                                        LR 0.000500    Time 0.138456    
2024-02-26 18:43:51,058 - Epoch: [51][   80/  139]    Overall Loss 0.444361    Objective Loss 0.444361                                        LR 0.000500    Time 0.135977    
2024-02-26 18:43:52,454 - Epoch: [51][   90/  139]    Overall Loss 0.443958    Objective Loss 0.443958                                        LR 0.000500    Time 0.136374    
2024-02-26 18:43:53,663 - Epoch: [51][  100/  139]    Overall Loss 0.443795    Objective Loss 0.443795                                        LR 0.000500    Time 0.134816    
2024-02-26 18:43:54,880 - Epoch: [51][  110/  139]    Overall Loss 0.445072    Objective Loss 0.445072                                        LR 0.000500    Time 0.133616    
2024-02-26 18:43:56,284 - Epoch: [51][  120/  139]    Overall Loss 0.446440    Objective Loss 0.446440                                        LR 0.000500    Time 0.134176    
2024-02-26 18:43:57,489 - Epoch: [51][  130/  139]    Overall Loss 0.447043    Objective Loss 0.447043                                        LR 0.000500    Time 0.133125    
2024-02-26 18:44:03,142 - Epoch: [51][  139/  139]    Overall Loss 0.448188    Objective Loss 0.448188    Top1 93.054557    LR 0.000500    Time 0.165167    
2024-02-26 18:44:03,513 - --- validate (epoch=51)-----------
2024-02-26 18:44:03,514 - 1392 samples (32 per mini-batch)
2024-02-26 18:44:34,366 - Epoch: [51][   10/   44]    Loss 0.507811    Top1 90.207393    
2024-02-26 18:45:05,591 - Epoch: [51][   20/   44]    Loss 0.505220    Top1 90.347156    
2024-02-26 18:45:37,325 - Epoch: [51][   30/   44]    Loss 0.509165    Top1 90.121470    
2024-02-26 18:46:09,423 - Epoch: [51][   40/   44]    Loss 0.507458    Top1 90.201227    
2024-02-26 18:46:20,259 - Epoch: [51][   44/   44]    Loss 0.510371    Top1 90.081669    
2024-02-26 18:46:20,547 - ==> Top1: 90.082    Loss: 0.510

2024-02-26 18:46:20,554 - ==> Best [Top1: 90.082   Sparsity:0.00   Params: 278176 on epoch: 51]
2024-02-26 18:46:20,554 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:46:20,587 - 

2024-02-26 18:46:20,588 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:46:22,647 - Epoch: [52][   10/  139]    Overall Loss 0.437481    Objective Loss 0.437481                                        LR 0.000500    Time 0.205818    
2024-02-26 18:46:23,727 - Epoch: [52][   20/  139]    Overall Loss 0.443286    Objective Loss 0.443286                                        LR 0.000500    Time 0.156859    
2024-02-26 18:46:24,845 - Epoch: [52][   30/  139]    Overall Loss 0.442450    Objective Loss 0.442450                                        LR 0.000500    Time 0.141816    
2024-02-26 18:46:25,982 - Epoch: [52][   40/  139]    Overall Loss 0.442700    Objective Loss 0.442700                                        LR 0.000500    Time 0.134756    
2024-02-26 18:46:27,051 - Epoch: [52][   50/  139]    Overall Loss 0.442894    Objective Loss 0.442894                                        LR 0.000500    Time 0.129175    
2024-02-26 18:46:28,165 - Epoch: [52][   60/  139]    Overall Loss 0.442725    Objective Loss 0.442725                                        LR 0.000500    Time 0.126189    
2024-02-26 18:46:29,246 - Epoch: [52][   70/  139]    Overall Loss 0.443909    Objective Loss 0.443909                                        LR 0.000500    Time 0.123600    
2024-02-26 18:46:30,381 - Epoch: [52][   80/  139]    Overall Loss 0.444240    Objective Loss 0.444240                                        LR 0.000500    Time 0.122326    
2024-02-26 18:46:31,506 - Epoch: [52][   90/  139]    Overall Loss 0.443852    Objective Loss 0.443852                                        LR 0.000500    Time 0.121230    
2024-02-26 18:46:32,593 - Epoch: [52][  100/  139]    Overall Loss 0.445218    Objective Loss 0.445218                                        LR 0.000500    Time 0.119969    
2024-02-26 18:46:33,749 - Epoch: [52][  110/  139]    Overall Loss 0.445561    Objective Loss 0.445561                                        LR 0.000500    Time 0.119445    
2024-02-26 18:46:34,873 - Epoch: [52][  120/  139]    Overall Loss 0.445229    Objective Loss 0.445229                                        LR 0.000500    Time 0.118780    
2024-02-26 18:46:35,990 - Epoch: [52][  130/  139]    Overall Loss 0.444484    Objective Loss 0.444484                                        LR 0.000500    Time 0.118225    
2024-02-26 18:46:41,461 - Epoch: [52][  139/  139]    Overall Loss 0.444661    Objective Loss 0.444661    Top1 94.153520    LR 0.000500    Time 0.149929    
2024-02-26 18:46:41,767 - --- validate (epoch=52)-----------
2024-02-26 18:46:41,767 - 1392 samples (32 per mini-batch)
2024-02-26 18:47:16,339 - Epoch: [52][   10/   44]    Loss 0.519848    Top1 89.360909    
2024-02-26 18:47:48,876 - Epoch: [52][   20/   44]    Loss 0.516313    Top1 89.696557    
2024-02-26 18:48:18,386 - Epoch: [52][   30/   44]    Loss 0.517440    Top1 89.649572    
2024-02-26 18:48:44,712 - Epoch: [52][   40/   44]    Loss 0.517774    Top1 89.630319    
2024-02-26 18:48:53,223 - Epoch: [52][   44/   44]    Loss 0.515141    Top1 89.763157    
2024-02-26 18:48:53,537 - ==> Top1: 89.763    Loss: 0.515

2024-02-26 18:48:53,543 - ==> Best [Top1: 90.082   Sparsity:0.00   Params: 278176 on epoch: 51]
2024-02-26 18:48:53,544 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:48:53,574 - 

2024-02-26 18:48:53,575 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:48:55,530 - Epoch: [53][   10/  139]    Overall Loss 0.433242    Objective Loss 0.433242                                        LR 0.000500    Time 0.195368    
2024-02-26 18:48:56,640 - Epoch: [53][   20/  139]    Overall Loss 0.441045    Objective Loss 0.441045                                        LR 0.000500    Time 0.153148    
2024-02-26 18:48:57,759 - Epoch: [53][   30/  139]    Overall Loss 0.439131    Objective Loss 0.439131                                        LR 0.000500    Time 0.139359    
2024-02-26 18:48:58,852 - Epoch: [53][   40/  139]    Overall Loss 0.439269    Objective Loss 0.439269                                        LR 0.000500    Time 0.131837    
2024-02-26 18:49:00,038 - Epoch: [53][   50/  139]    Overall Loss 0.438433    Objective Loss 0.438433                                        LR 0.000500    Time 0.129160    
2024-02-26 18:49:01,123 - Epoch: [53][   60/  139]    Overall Loss 0.439511    Objective Loss 0.439511                                        LR 0.000500    Time 0.125714    
2024-02-26 18:49:02,215 - Epoch: [53][   70/  139]    Overall Loss 0.440978    Objective Loss 0.440978                                        LR 0.000500    Time 0.123340    
2024-02-26 18:49:03,335 - Epoch: [53][   80/  139]    Overall Loss 0.440173    Objective Loss 0.440173                                        LR 0.000500    Time 0.121917    
2024-02-26 18:49:04,463 - Epoch: [53][   90/  139]    Overall Loss 0.440665    Objective Loss 0.440665                                        LR 0.000500    Time 0.120892    
2024-02-26 18:49:06,710 - Epoch: [53][  100/  139]    Overall Loss 0.440913    Objective Loss 0.440913                                        LR 0.000500    Time 0.131270    
2024-02-26 18:49:07,945 - Epoch: [53][  110/  139]    Overall Loss 0.441642    Objective Loss 0.441642                                        LR 0.000500    Time 0.130552    
2024-02-26 18:49:09,208 - Epoch: [53][  120/  139]    Overall Loss 0.441277    Objective Loss 0.441277                                        LR 0.000500    Time 0.130193    
2024-02-26 18:49:10,438 - Epoch: [53][  130/  139]    Overall Loss 0.441157    Objective Loss 0.441157                                        LR 0.000500    Time 0.129628    
2024-02-26 18:49:15,326 - Epoch: [53][  139/  139]    Overall Loss 0.441291    Objective Loss 0.441291    Top1 92.431164    LR 0.000500    Time 0.156398    
2024-02-26 18:49:15,687 - --- validate (epoch=53)-----------
2024-02-26 18:49:15,688 - 1392 samples (32 per mini-batch)
2024-02-26 18:49:47,735 - Epoch: [53][   10/   44]    Loss 0.513004    Top1 89.792945    
2024-02-26 18:50:19,789 - Epoch: [53][   20/   44]    Loss 0.519239    Top1 89.513767    
2024-02-26 18:50:51,633 - Epoch: [53][   30/   44]    Loss 0.519779    Top1 89.458101    
2024-02-26 18:51:22,670 - Epoch: [53][   40/   44]    Loss 0.515631    Top1 89.692993    
2024-02-26 18:51:32,986 - Epoch: [53][   44/   44]    Loss 0.516389    Top1 89.617221    
2024-02-26 18:51:33,385 - ==> Top1: 89.617    Loss: 0.516

2024-02-26 18:51:33,392 - ==> Best [Top1: 90.082   Sparsity:0.00   Params: 278176 on epoch: 51]
2024-02-26 18:51:33,393 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:51:33,425 - 

2024-02-26 18:51:33,426 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:51:35,552 - Epoch: [54][   10/  139]    Overall Loss 0.447668    Objective Loss 0.447668                                        LR 0.000500    Time 0.212489    
2024-02-26 18:51:36,737 - Epoch: [54][   20/  139]    Overall Loss 0.439872    Objective Loss 0.439872                                        LR 0.000500    Time 0.165431    
2024-02-26 18:51:37,989 - Epoch: [54][   30/  139]    Overall Loss 0.438442    Objective Loss 0.438442                                        LR 0.000500    Time 0.152008    
2024-02-26 18:51:39,080 - Epoch: [54][   40/  139]    Overall Loss 0.439721    Objective Loss 0.439721                                        LR 0.000500    Time 0.141277    
2024-02-26 18:51:40,141 - Epoch: [54][   50/  139]    Overall Loss 0.439533    Objective Loss 0.439533                                        LR 0.000500    Time 0.134229    
2024-02-26 18:51:41,221 - Epoch: [54][   60/  139]    Overall Loss 0.438869    Objective Loss 0.438869                                        LR 0.000500    Time 0.129847    
2024-02-26 18:51:42,390 - Epoch: [54][   70/  139]    Overall Loss 0.439036    Objective Loss 0.439036                                        LR 0.000500    Time 0.127990    
2024-02-26 18:51:43,572 - Epoch: [54][   80/  139]    Overall Loss 0.439947    Objective Loss 0.439947                                        LR 0.000500    Time 0.126752    
2024-02-26 18:51:44,691 - Epoch: [54][   90/  139]    Overall Loss 0.439997    Objective Loss 0.439997                                        LR 0.000500    Time 0.125095    
2024-02-26 18:51:45,825 - Epoch: [54][  100/  139]    Overall Loss 0.438842    Objective Loss 0.438842                                        LR 0.000500    Time 0.123916    
2024-02-26 18:51:46,915 - Epoch: [54][  110/  139]    Overall Loss 0.438722    Objective Loss 0.438722                                        LR 0.000500    Time 0.122560    
2024-02-26 18:51:47,998 - Epoch: [54][  120/  139]    Overall Loss 0.438894    Objective Loss 0.438894                                        LR 0.000500    Time 0.121361    
2024-02-26 18:51:49,140 - Epoch: [54][  130/  139]    Overall Loss 0.439600    Objective Loss 0.439600                                        LR 0.000500    Time 0.120810    
2024-02-26 18:51:54,129 - Epoch: [54][  139/  139]    Overall Loss 0.439443    Objective Loss 0.439443    Top1 93.466991    LR 0.000500    Time 0.148877    
2024-02-26 18:51:54,467 - --- validate (epoch=54)-----------
2024-02-26 18:51:54,468 - 1392 samples (32 per mini-batch)
2024-02-26 18:52:22,791 - Epoch: [54][   10/   44]    Loss 0.511351    Top1 90.027945    
2024-02-26 18:52:50,085 - Epoch: [54][   20/   44]    Loss 0.513116    Top1 89.960442    
2024-02-26 18:53:14,952 - Epoch: [54][   30/   44]    Loss 0.510993    Top1 90.076390    
2024-02-26 18:53:37,873 - Epoch: [54][   40/   44]    Loss 0.505813    Top1 90.355779    
2024-02-26 18:53:47,418 - Epoch: [54][   44/   44]    Loss 0.505823    Top1 90.363733    
2024-02-26 18:53:47,679 - ==> Top1: 90.364    Loss: 0.506

2024-02-26 18:53:47,686 - ==> Best [Top1: 90.364   Sparsity:0.00   Params: 278176 on epoch: 54]
2024-02-26 18:53:47,686 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:53:47,720 - 

2024-02-26 18:53:47,721 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:53:49,760 - Epoch: [55][   10/  139]    Overall Loss 0.433010    Objective Loss 0.433010                                        LR 0.000500    Time 0.203754    
2024-02-26 18:53:50,831 - Epoch: [55][   20/  139]    Overall Loss 0.434183    Objective Loss 0.434183                                        LR 0.000500    Time 0.155370    
2024-02-26 18:53:51,906 - Epoch: [55][   30/  139]    Overall Loss 0.436231    Objective Loss 0.436231                                        LR 0.000500    Time 0.139391    
2024-02-26 18:53:52,971 - Epoch: [55][   40/  139]    Overall Loss 0.437741    Objective Loss 0.437741                                        LR 0.000500    Time 0.131156    
2024-02-26 18:53:54,033 - Epoch: [55][   50/  139]    Overall Loss 0.439340    Objective Loss 0.439340                                        LR 0.000500    Time 0.126157    
2024-02-26 18:53:55,144 - Epoch: [55][   60/  139]    Overall Loss 0.437279    Objective Loss 0.437279                                        LR 0.000500    Time 0.123142    
2024-02-26 18:53:56,311 - Epoch: [55][   70/  139]    Overall Loss 0.436722    Objective Loss 0.436722                                        LR 0.000500    Time 0.122205    
2024-02-26 18:53:57,453 - Epoch: [55][   80/  139]    Overall Loss 0.436419    Objective Loss 0.436419                                        LR 0.000500    Time 0.121199    
2024-02-26 18:53:58,537 - Epoch: [55][   90/  139]    Overall Loss 0.436548    Objective Loss 0.436548                                        LR 0.000500    Time 0.119762    
2024-02-26 18:53:59,658 - Epoch: [55][  100/  139]    Overall Loss 0.436468    Objective Loss 0.436468                                        LR 0.000500    Time 0.118991    
2024-02-26 18:54:00,772 - Epoch: [55][  110/  139]    Overall Loss 0.436931    Objective Loss 0.436931                                        LR 0.000500    Time 0.118293    
2024-02-26 18:54:01,856 - Epoch: [55][  120/  139]    Overall Loss 0.437013    Objective Loss 0.437013                                        LR 0.000500    Time 0.117463    
2024-02-26 18:54:02,974 - Epoch: [55][  130/  139]    Overall Loss 0.437489    Objective Loss 0.437489                                        LR 0.000500    Time 0.117018    
2024-02-26 18:54:08,118 - Epoch: [55][  139/  139]    Overall Loss 0.437975    Objective Loss 0.437975    Top1 93.502814    LR 0.000500    Time 0.146444    
2024-02-26 18:54:08,495 - --- validate (epoch=55)-----------
2024-02-26 18:54:08,496 - 1392 samples (32 per mini-batch)
2024-02-26 18:54:41,634 - Epoch: [55][   10/   44]    Loss 0.507768    Top1 90.220201    
2024-02-26 18:55:14,626 - Epoch: [55][   20/   44]    Loss 0.503367    Top1 90.463862    
2024-02-26 18:55:45,997 - Epoch: [55][   30/   44]    Loss 0.503920    Top1 90.442654    
2024-02-26 18:56:17,461 - Epoch: [55][   40/   44]    Loss 0.504214    Top1 90.397746    
2024-02-26 18:56:27,075 - Epoch: [55][   44/   44]    Loss 0.505029    Top1 90.363023    
2024-02-26 18:56:27,543 - ==> Top1: 90.363    Loss: 0.505

2024-02-26 18:56:27,550 - ==> Best [Top1: 90.364   Sparsity:0.00   Params: 278176 on epoch: 54]
2024-02-26 18:56:27,550 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:56:27,581 - 

2024-02-26 18:56:27,581 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:56:29,698 - Epoch: [56][   10/  139]    Overall Loss 0.442465    Objective Loss 0.442465                                        LR 0.000500    Time 0.211513    
2024-02-26 18:56:30,803 - Epoch: [56][   20/  139]    Overall Loss 0.440655    Objective Loss 0.440655                                        LR 0.000500    Time 0.160979    
2024-02-26 18:56:31,937 - Epoch: [56][   30/  139]    Overall Loss 0.438898    Objective Loss 0.438898                                        LR 0.000500    Time 0.145092    
2024-02-26 18:56:33,002 - Epoch: [56][   40/  139]    Overall Loss 0.436337    Objective Loss 0.436337                                        LR 0.000500    Time 0.135417    
2024-02-26 18:56:34,153 - Epoch: [56][   50/  139]    Overall Loss 0.436451    Objective Loss 0.436451                                        LR 0.000500    Time 0.131339    
2024-02-26 18:56:35,238 - Epoch: [56][   60/  139]    Overall Loss 0.435686    Objective Loss 0.435686                                        LR 0.000500    Time 0.127525    
2024-02-26 18:56:36,450 - Epoch: [56][   70/  139]    Overall Loss 0.435846    Objective Loss 0.435846                                        LR 0.000500    Time 0.126609    
2024-02-26 18:56:37,638 - Epoch: [56][   80/  139]    Overall Loss 0.435475    Objective Loss 0.435475                                        LR 0.000500    Time 0.125625    
2024-02-26 18:56:38,818 - Epoch: [56][   90/  139]    Overall Loss 0.434245    Objective Loss 0.434245                                        LR 0.000500    Time 0.124760    
2024-02-26 18:56:40,058 - Epoch: [56][  100/  139]    Overall Loss 0.434413    Objective Loss 0.434413                                        LR 0.000500    Time 0.124674    
2024-02-26 18:56:41,214 - Epoch: [56][  110/  139]    Overall Loss 0.435002    Objective Loss 0.435002                                        LR 0.000500    Time 0.123847    
2024-02-26 18:56:42,536 - Epoch: [56][  120/  139]    Overall Loss 0.435000    Objective Loss 0.435000                                        LR 0.000500    Time 0.124534    
2024-02-26 18:56:43,801 - Epoch: [56][  130/  139]    Overall Loss 0.435192    Objective Loss 0.435192                                        LR 0.000500    Time 0.124679    
2024-02-26 18:56:48,732 - Epoch: [56][  139/  139]    Overall Loss 0.435465    Objective Loss 0.435465    Top1 94.994934    LR 0.000500    Time 0.152078    
2024-02-26 18:56:48,967 - --- validate (epoch=56)-----------
2024-02-26 18:56:48,967 - 1392 samples (32 per mini-batch)
2024-02-26 18:57:19,890 - Epoch: [56][   10/   44]    Loss 0.516914    Top1 89.653454    
2024-02-26 18:57:46,117 - Epoch: [56][   20/   44]    Loss 0.516972    Top1 89.566252    
2024-02-26 18:58:10,328 - Epoch: [56][   30/   44]    Loss 0.514894    Top1 89.718217    
2024-02-26 18:58:39,866 - Epoch: [56][   40/   44]    Loss 0.515268    Top1 89.715718    
2024-02-26 18:58:51,227 - Epoch: [56][   44/   44]    Loss 0.516983    Top1 89.650068    
2024-02-26 18:58:51,441 - ==> Top1: 89.650    Loss: 0.517

2024-02-26 18:58:51,449 - ==> Best [Top1: 90.364   Sparsity:0.00   Params: 278176 on epoch: 54]
2024-02-26 18:58:51,449 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 18:58:51,489 - 

2024-02-26 18:58:51,489 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:58:53,512 - Epoch: [57][   10/  139]    Overall Loss 0.438101    Objective Loss 0.438101                                        LR 0.000500    Time 0.202176    
2024-02-26 18:58:54,618 - Epoch: [57][   20/  139]    Overall Loss 0.434055    Objective Loss 0.434055                                        LR 0.000500    Time 0.156331    
2024-02-26 18:58:55,747 - Epoch: [57][   30/  139]    Overall Loss 0.435665    Objective Loss 0.435665                                        LR 0.000500    Time 0.141820    
2024-02-26 18:58:56,873 - Epoch: [57][   40/  139]    Overall Loss 0.435926    Objective Loss 0.435926                                        LR 0.000500    Time 0.134493    
2024-02-26 18:58:57,963 - Epoch: [57][   50/  139]    Overall Loss 0.434410    Objective Loss 0.434410                                        LR 0.000500    Time 0.129378    
2024-02-26 18:58:59,088 - Epoch: [57][   60/  139]    Overall Loss 0.433460    Objective Loss 0.433460                                        LR 0.000500    Time 0.126557    
2024-02-26 18:59:00,203 - Epoch: [57][   70/  139]    Overall Loss 0.433508    Objective Loss 0.433508                                        LR 0.000500    Time 0.124395    
2024-02-26 18:59:01,327 - Epoch: [57][   80/  139]    Overall Loss 0.433589    Objective Loss 0.433589                                        LR 0.000500    Time 0.122886    
2024-02-26 18:59:02,479 - Epoch: [57][   90/  139]    Overall Loss 0.434100    Objective Loss 0.434100                                        LR 0.000500    Time 0.122025    
2024-02-26 18:59:03,599 - Epoch: [57][  100/  139]    Overall Loss 0.433758    Objective Loss 0.433758                                        LR 0.000500    Time 0.121017    
2024-02-26 18:59:04,703 - Epoch: [57][  110/  139]    Overall Loss 0.433438    Objective Loss 0.433438                                        LR 0.000500    Time 0.120044    
2024-02-26 18:59:05,868 - Epoch: [57][  120/  139]    Overall Loss 0.433284    Objective Loss 0.433284                                        LR 0.000500    Time 0.119634    
2024-02-26 18:59:06,984 - Epoch: [57][  130/  139]    Overall Loss 0.432928    Objective Loss 0.432928                                        LR 0.000500    Time 0.119012    
2024-02-26 18:59:12,151 - Epoch: [57][  139/  139]    Overall Loss 0.433823    Objective Loss 0.433823    Top1 94.694169    LR 0.000500    Time 0.148476    
2024-02-26 18:59:12,429 - --- validate (epoch=57)-----------
2024-02-26 18:59:12,431 - 1392 samples (32 per mini-batch)
2024-02-26 18:59:44,514 - Epoch: [57][   10/   44]    Loss 0.512811    Top1 89.946768    
2024-02-26 19:00:16,630 - Epoch: [57][   20/   44]    Loss 0.508764    Top1 90.188790    
2024-02-26 19:00:46,366 - Epoch: [57][   30/   44]    Loss 0.515760    Top1 89.785243    
2024-02-26 19:01:13,983 - Epoch: [57][   40/   44]    Loss 0.515637    Top1 89.797272    
2024-02-26 19:01:22,679 - Epoch: [57][   44/   44]    Loss 0.512347    Top1 89.967349    
2024-02-26 19:01:23,096 - ==> Top1: 89.967    Loss: 0.512

2024-02-26 19:01:23,103 - ==> Best [Top1: 90.364   Sparsity:0.00   Params: 278176 on epoch: 54]
2024-02-26 19:01:23,104 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:01:23,138 - 

2024-02-26 19:01:23,139 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:01:25,232 - Epoch: [58][   10/  139]    Overall Loss 0.436093    Objective Loss 0.436093                                        LR 0.000500    Time 0.209143    
2024-02-26 19:01:26,378 - Epoch: [58][   20/  139]    Overall Loss 0.435136    Objective Loss 0.435136                                        LR 0.000500    Time 0.161825    
2024-02-26 19:01:27,457 - Epoch: [58][   30/  139]    Overall Loss 0.436631    Objective Loss 0.436631                                        LR 0.000500    Time 0.143827    
2024-02-26 19:01:28,565 - Epoch: [58][   40/  139]    Overall Loss 0.435911    Objective Loss 0.435911                                        LR 0.000500    Time 0.135570    
2024-02-26 19:01:29,661 - Epoch: [58][   50/  139]    Overall Loss 0.435529    Objective Loss 0.435529                                        LR 0.000500    Time 0.130360    
2024-02-26 19:01:30,851 - Epoch: [58][   60/  139]    Overall Loss 0.435301    Objective Loss 0.435301                                        LR 0.000500    Time 0.128468    
2024-02-26 19:01:32,063 - Epoch: [58][   70/  139]    Overall Loss 0.433436    Objective Loss 0.433436                                        LR 0.000500    Time 0.127418    
2024-02-26 19:01:33,196 - Epoch: [58][   80/  139]    Overall Loss 0.432495    Objective Loss 0.432495                                        LR 0.000500    Time 0.125646    
2024-02-26 19:01:34,391 - Epoch: [58][   90/  139]    Overall Loss 0.432212    Objective Loss 0.432212                                        LR 0.000500    Time 0.124952    
2024-02-26 19:01:35,714 - Epoch: [58][  100/  139]    Overall Loss 0.432072    Objective Loss 0.432072                                        LR 0.000500    Time 0.125684    
2024-02-26 19:01:36,957 - Epoch: [58][  110/  139]    Overall Loss 0.432385    Objective Loss 0.432385                                        LR 0.000500    Time 0.125549    
2024-02-26 19:01:38,147 - Epoch: [58][  120/  139]    Overall Loss 0.432921    Objective Loss 0.432921                                        LR 0.000500    Time 0.124999    
2024-02-26 19:01:39,356 - Epoch: [58][  130/  139]    Overall Loss 0.432811    Objective Loss 0.432811                                        LR 0.000500    Time 0.124674    
2024-02-26 19:01:44,249 - Epoch: [58][  139/  139]    Overall Loss 0.432484    Objective Loss 0.432484    Top1 95.082905    LR 0.000500    Time 0.151803    
2024-02-26 19:01:44,780 - --- validate (epoch=58)-----------
2024-02-26 19:01:44,780 - 1392 samples (32 per mini-batch)
2024-02-26 19:02:10,932 - Epoch: [58][   10/   44]    Loss 0.504963    Top1 90.342881    
2024-02-26 19:02:35,936 - Epoch: [58][   20/   44]    Loss 0.507006    Top1 90.228260    
2024-02-26 19:03:04,782 - Epoch: [58][   30/   44]    Loss 0.502655    Top1 90.492932    
2024-02-26 19:03:36,544 - Epoch: [58][   40/   44]    Loss 0.502524    Top1 90.501412    
2024-02-26 19:03:47,923 - Epoch: [58][   44/   44]    Loss 0.503566    Top1 90.466215    
2024-02-26 19:03:48,213 - ==> Top1: 90.466    Loss: 0.504

2024-02-26 19:03:48,221 - ==> Best [Top1: 90.466   Sparsity:0.00   Params: 278176 on epoch: 58]
2024-02-26 19:03:48,221 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:03:48,255 - 

2024-02-26 19:03:48,255 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:03:50,358 - Epoch: [59][   10/  139]    Overall Loss 0.426483    Objective Loss 0.426483                                        LR 0.000500    Time 0.210149    
2024-02-26 19:03:51,442 - Epoch: [59][   20/  139]    Overall Loss 0.429692    Objective Loss 0.429692                                        LR 0.000500    Time 0.159208    
2024-02-26 19:03:52,505 - Epoch: [59][   30/  139]    Overall Loss 0.433197    Objective Loss 0.433197                                        LR 0.000500    Time 0.141569    
2024-02-26 19:03:53,566 - Epoch: [59][   40/  139]    Overall Loss 0.431040    Objective Loss 0.431040                                        LR 0.000500    Time 0.132670    
2024-02-26 19:03:54,619 - Epoch: [59][   50/  139]    Overall Loss 0.430243    Objective Loss 0.430243                                        LR 0.000500    Time 0.127182    
2024-02-26 19:03:55,759 - Epoch: [59][   60/  139]    Overall Loss 0.431256    Objective Loss 0.431256                                        LR 0.000500    Time 0.124974    
2024-02-26 19:03:56,822 - Epoch: [59][   70/  139]    Overall Loss 0.432044    Objective Loss 0.432044                                        LR 0.000500    Time 0.122301    
2024-02-26 19:03:57,928 - Epoch: [59][   80/  139]    Overall Loss 0.432190    Objective Loss 0.432190                                        LR 0.000500    Time 0.120822    
2024-02-26 19:03:59,075 - Epoch: [59][   90/  139]    Overall Loss 0.432719    Objective Loss 0.432719                                        LR 0.000500    Time 0.120139    
2024-02-26 19:04:00,133 - Epoch: [59][  100/  139]    Overall Loss 0.433547    Objective Loss 0.433547                                        LR 0.000500    Time 0.118691    
2024-02-26 19:04:01,239 - Epoch: [59][  110/  139]    Overall Loss 0.433407    Objective Loss 0.433407                                        LR 0.000500    Time 0.117956    
2024-02-26 19:04:02,361 - Epoch: [59][  120/  139]    Overall Loss 0.433522    Objective Loss 0.433522                                        LR 0.000500    Time 0.117469    
2024-02-26 19:04:03,465 - Epoch: [59][  130/  139]    Overall Loss 0.432929    Objective Loss 0.432929                                        LR 0.000500    Time 0.116920    
2024-02-26 19:04:08,549 - Epoch: [59][  139/  139]    Overall Loss 0.432248    Objective Loss 0.432248    Top1 95.758080    LR 0.000500    Time 0.145919    
2024-02-26 19:04:08,828 - --- validate (epoch=59)-----------
2024-02-26 19:04:08,829 - 1392 samples (32 per mini-batch)
2024-02-26 19:04:42,465 - Epoch: [59][   10/   44]    Loss 0.495498    Top1 90.920266    
2024-02-26 19:05:10,294 - Epoch: [59][   20/   44]    Loss 0.500626    Top1 90.658272    
2024-02-26 19:05:34,796 - Epoch: [59][   30/   44]    Loss 0.500636    Top1 90.666233    
2024-02-26 19:05:59,627 - Epoch: [59][   40/   44]    Loss 0.502609    Top1 90.568485    
2024-02-26 19:06:08,282 - Epoch: [59][   44/   44]    Loss 0.502208    Top1 90.575264    
2024-02-26 19:06:08,696 - ==> Top1: 90.575    Loss: 0.502

2024-02-26 19:06:08,702 - ==> Best [Top1: 90.575   Sparsity:0.00   Params: 278176 on epoch: 59]
2024-02-26 19:06:08,703 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:06:08,742 - 

2024-02-26 19:06:08,742 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:06:10,821 - Epoch: [60][   10/  139]    Overall Loss 0.431510    Objective Loss 0.431510                                        LR 0.000500    Time 0.207583    
2024-02-26 19:06:12,042 - Epoch: [60][   20/  139]    Overall Loss 0.427546    Objective Loss 0.427546                                        LR 0.000500    Time 0.164786    
2024-02-26 19:06:13,142 - Epoch: [60][   30/  139]    Overall Loss 0.431694    Objective Loss 0.431694                                        LR 0.000500    Time 0.146509    
2024-02-26 19:06:14,252 - Epoch: [60][   40/  139]    Overall Loss 0.431950    Objective Loss 0.431950                                        LR 0.000500    Time 0.137619    
2024-02-26 19:06:15,375 - Epoch: [60][   50/  139]    Overall Loss 0.431859    Objective Loss 0.431859                                        LR 0.000500    Time 0.132553    
2024-02-26 19:06:16,534 - Epoch: [60][   60/  139]    Overall Loss 0.430174    Objective Loss 0.430174                                        LR 0.000500    Time 0.129759    
2024-02-26 19:06:17,645 - Epoch: [60][   70/  139]    Overall Loss 0.429045    Objective Loss 0.429045                                        LR 0.000500    Time 0.127091    
2024-02-26 19:06:18,742 - Epoch: [60][   80/  139]    Overall Loss 0.429478    Objective Loss 0.429478                                        LR 0.000500    Time 0.124909    
2024-02-26 19:06:19,816 - Epoch: [60][   90/  139]    Overall Loss 0.429629    Objective Loss 0.429629                                        LR 0.000500    Time 0.122947    
2024-02-26 19:06:21,005 - Epoch: [60][  100/  139]    Overall Loss 0.430746    Objective Loss 0.430746                                        LR 0.000500    Time 0.122538    
2024-02-26 19:06:22,211 - Epoch: [60][  110/  139]    Overall Loss 0.431434    Objective Loss 0.431434                                        LR 0.000500    Time 0.122355    
2024-02-26 19:06:23,430 - Epoch: [60][  120/  139]    Overall Loss 0.431654    Objective Loss 0.431654                                        LR 0.000500    Time 0.122316    
2024-02-26 19:06:24,759 - Epoch: [60][  130/  139]    Overall Loss 0.431110    Objective Loss 0.431110                                        LR 0.000500    Time 0.123121    
2024-02-26 19:06:29,917 - Epoch: [60][  139/  139]    Overall Loss 0.431030    Objective Loss 0.431030    Top1 93.658415    LR 0.000500    Time 0.152237    
2024-02-26 19:06:30,211 - --- validate (epoch=60)-----------
2024-02-26 19:06:30,212 - 1392 samples (32 per mini-batch)
2024-02-26 19:06:56,690 - Epoch: [60][   10/   44]    Loss 0.529719    Top1 89.158348    
2024-02-26 19:07:25,341 - Epoch: [60][   20/   44]    Loss 0.519692    Top1 89.678510    
2024-02-26 19:07:58,231 - Epoch: [60][   30/   44]    Loss 0.526338    Top1 89.353077    
2024-02-26 19:08:30,872 - Epoch: [60][   40/   44]    Loss 0.526541    Top1 89.335031    
2024-02-26 19:08:42,310 - Epoch: [60][   44/   44]    Loss 0.527276    Top1 89.363210    
2024-02-26 19:08:42,537 - ==> Top1: 89.363    Loss: 0.527

2024-02-26 19:08:42,544 - ==> Best [Top1: 90.575   Sparsity:0.00   Params: 278176 on epoch: 59]
2024-02-26 19:08:42,544 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:08:42,574 - 

2024-02-26 19:08:42,574 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:08:44,647 - Epoch: [61][   10/  139]    Overall Loss 0.438154    Objective Loss 0.438154                                        LR 0.000500    Time 0.207149    
2024-02-26 19:08:45,736 - Epoch: [61][   20/  139]    Overall Loss 0.431104    Objective Loss 0.431104                                        LR 0.000500    Time 0.157971    
2024-02-26 19:08:46,844 - Epoch: [61][   30/  139]    Overall Loss 0.430751    Objective Loss 0.430751                                        LR 0.000500    Time 0.142212    
2024-02-26 19:08:47,909 - Epoch: [61][   40/  139]    Overall Loss 0.432403    Objective Loss 0.432403                                        LR 0.000500    Time 0.133254    
2024-02-26 19:08:49,003 - Epoch: [61][   50/  139]    Overall Loss 0.431589    Objective Loss 0.431589                                        LR 0.000500    Time 0.128454    
2024-02-26 19:08:50,062 - Epoch: [61][   60/  139]    Overall Loss 0.431247    Objective Loss 0.431247                                        LR 0.000500    Time 0.124686    
2024-02-26 19:08:51,178 - Epoch: [61][   70/  139]    Overall Loss 0.429775    Objective Loss 0.429775                                        LR 0.000500    Time 0.122804    
2024-02-26 19:08:52,247 - Epoch: [61][   80/  139]    Overall Loss 0.430473    Objective Loss 0.430473                                        LR 0.000500    Time 0.120811    
2024-02-26 19:08:53,341 - Epoch: [61][   90/  139]    Overall Loss 0.430506    Objective Loss 0.430506                                        LR 0.000500    Time 0.119526    
2024-02-26 19:08:54,478 - Epoch: [61][  100/  139]    Overall Loss 0.430224    Objective Loss 0.430224                                        LR 0.000500    Time 0.118938    
2024-02-26 19:08:55,591 - Epoch: [61][  110/  139]    Overall Loss 0.429389    Objective Loss 0.429389                                        LR 0.000500    Time 0.118243    
2024-02-26 19:08:56,668 - Epoch: [61][  120/  139]    Overall Loss 0.429937    Objective Loss 0.429937                                        LR 0.000500    Time 0.117351    
2024-02-26 19:08:57,798 - Epoch: [61][  130/  139]    Overall Loss 0.429559    Objective Loss 0.429559                                        LR 0.000500    Time 0.117010    
2024-02-26 19:09:03,237 - Epoch: [61][  139/  139]    Overall Loss 0.429916    Objective Loss 0.429916    Top1 95.038021    LR 0.000500    Time 0.148564    
2024-02-26 19:09:03,473 - --- validate (epoch=61)-----------
2024-02-26 19:09:03,474 - 1392 samples (32 per mini-batch)
2024-02-26 19:09:33,794 - Epoch: [61][   10/   44]    Loss 0.526110    Top1 89.230619    
2024-02-26 19:09:58,350 - Epoch: [61][   20/   44]    Loss 0.523447    Top1 89.315387    
2024-02-26 19:10:22,669 - Epoch: [61][   30/   44]    Loss 0.525171    Top1 89.203572    
2024-02-26 19:10:46,499 - Epoch: [61][   40/   44]    Loss 0.521834    Top1 89.408342    
2024-02-26 19:10:54,257 - Epoch: [61][   44/   44]    Loss 0.521983    Top1 89.400924    
2024-02-26 19:10:54,629 - ==> Top1: 89.401    Loss: 0.522

2024-02-26 19:10:54,636 - ==> Best [Top1: 90.575   Sparsity:0.00   Params: 278176 on epoch: 59]
2024-02-26 19:10:54,636 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:10:54,667 - 

2024-02-26 19:10:54,667 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:10:56,622 - Epoch: [62][   10/  139]    Overall Loss 0.436830    Objective Loss 0.436830                                        LR 0.000500    Time 0.195355    
2024-02-26 19:10:57,707 - Epoch: [62][   20/  139]    Overall Loss 0.430212    Objective Loss 0.430212                                        LR 0.000500    Time 0.151900    
2024-02-26 19:10:58,813 - Epoch: [62][   30/  139]    Overall Loss 0.428817    Objective Loss 0.428817                                        LR 0.000500    Time 0.138139    
2024-02-26 19:10:59,908 - Epoch: [62][   40/  139]    Overall Loss 0.428252    Objective Loss 0.428252                                        LR 0.000500    Time 0.130946    
2024-02-26 19:11:01,058 - Epoch: [62][   50/  139]    Overall Loss 0.427381    Objective Loss 0.427381                                        LR 0.000500    Time 0.127757    
2024-02-26 19:11:02,163 - Epoch: [62][   60/  139]    Overall Loss 0.428605    Objective Loss 0.428605                                        LR 0.000500    Time 0.124868    
2024-02-26 19:11:03,270 - Epoch: [62][   70/  139]    Overall Loss 0.429478    Objective Loss 0.429478                                        LR 0.000500    Time 0.122830    
2024-02-26 19:11:04,371 - Epoch: [62][   80/  139]    Overall Loss 0.430319    Objective Loss 0.430319                                        LR 0.000500    Time 0.121093    
2024-02-26 19:11:05,511 - Epoch: [62][   90/  139]    Overall Loss 0.430684    Objective Loss 0.430684                                        LR 0.000500    Time 0.120291    
2024-02-26 19:11:06,690 - Epoch: [62][  100/  139]    Overall Loss 0.431061    Objective Loss 0.431061                                        LR 0.000500    Time 0.120048    
2024-02-26 19:11:07,849 - Epoch: [62][  110/  139]    Overall Loss 0.431311    Objective Loss 0.431311                                        LR 0.000500    Time 0.119531    
2024-02-26 19:11:09,031 - Epoch: [62][  120/  139]    Overall Loss 0.431139    Objective Loss 0.431139                                        LR 0.000500    Time 0.119409    
2024-02-26 19:11:10,235 - Epoch: [62][  130/  139]    Overall Loss 0.430814    Objective Loss 0.430814                                        LR 0.000500    Time 0.119482    
2024-02-26 19:11:15,420 - Epoch: [62][  139/  139]    Overall Loss 0.430802    Objective Loss 0.430802    Top1 95.720587    LR 0.000500    Time 0.149048    
2024-02-26 19:11:15,775 - --- validate (epoch=62)-----------
2024-02-26 19:11:15,776 - 1392 samples (32 per mini-batch)
2024-02-26 19:11:46,541 - Epoch: [62][   10/   44]    Loss 0.512288    Top1 90.025940    
2024-02-26 19:12:17,906 - Epoch: [62][   20/   44]    Loss 0.504384    Top1 90.455708    
2024-02-26 19:12:50,252 - Epoch: [62][   30/   44]    Loss 0.508223    Top1 90.237126    
2024-02-26 19:13:22,241 - Epoch: [62][   40/   44]    Loss 0.503121    Top1 90.529884    
2024-02-26 19:13:33,613 - Epoch: [62][   44/   44]    Loss 0.506394    Top1 90.366529    
2024-02-26 19:13:33,876 - ==> Top1: 90.367    Loss: 0.506

2024-02-26 19:13:33,883 - ==> Best [Top1: 90.575   Sparsity:0.00   Params: 278176 on epoch: 59]
2024-02-26 19:13:33,883 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:13:33,920 - 

2024-02-26 19:13:33,920 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:13:36,156 - Epoch: [63][   10/  139]    Overall Loss 0.423556    Objective Loss 0.423556                                        LR 0.000500    Time 0.223404    
2024-02-26 19:13:37,221 - Epoch: [63][   20/  139]    Overall Loss 0.425226    Objective Loss 0.425226                                        LR 0.000500    Time 0.164283    
2024-02-26 19:13:38,331 - Epoch: [63][   30/  139]    Overall Loss 0.424275    Objective Loss 0.424275                                        LR 0.000500    Time 0.146506    
2024-02-26 19:13:39,655 - Epoch: [63][   40/  139]    Overall Loss 0.425691    Objective Loss 0.425691                                        LR 0.000500    Time 0.142940    
2024-02-26 19:13:40,834 - Epoch: [63][   50/  139]    Overall Loss 0.425800    Objective Loss 0.425800                                        LR 0.000500    Time 0.137930    
2024-02-26 19:13:42,102 - Epoch: [63][   60/  139]    Overall Loss 0.425090    Objective Loss 0.425090                                        LR 0.000500    Time 0.136062    
2024-02-26 19:13:43,315 - Epoch: [63][   70/  139]    Overall Loss 0.424399    Objective Loss 0.424399                                        LR 0.000500    Time 0.133940    
2024-02-26 19:13:44,607 - Epoch: [63][   80/  139]    Overall Loss 0.425603    Objective Loss 0.425603                                        LR 0.000500    Time 0.133325    
2024-02-26 19:13:45,764 - Epoch: [63][   90/  139]    Overall Loss 0.426431    Objective Loss 0.426431                                        LR 0.000500    Time 0.131360    
2024-02-26 19:13:47,000 - Epoch: [63][  100/  139]    Overall Loss 0.426727    Objective Loss 0.426727                                        LR 0.000500    Time 0.130580    
2024-02-26 19:13:48,360 - Epoch: [63][  110/  139]    Overall Loss 0.426498    Objective Loss 0.426498                                        LR 0.000500    Time 0.131070    
2024-02-26 19:13:49,535 - Epoch: [63][  120/  139]    Overall Loss 0.427139    Objective Loss 0.427139                                        LR 0.000500    Time 0.129933    
2024-02-26 19:13:50,884 - Epoch: [63][  130/  139]    Overall Loss 0.426389    Objective Loss 0.426389                                        LR 0.000500    Time 0.130312    
2024-02-26 19:13:56,668 - Epoch: [63][  139/  139]    Overall Loss 0.426486    Objective Loss 0.426486    Top1 95.392272    LR 0.000500    Time 0.163482    
2024-02-26 19:13:56,949 - --- validate (epoch=63)-----------
2024-02-26 19:13:56,949 - 1392 samples (32 per mini-batch)
2024-02-26 19:14:30,279 - Epoch: [63][   10/   44]    Loss 0.473672    Top1 92.207470    
2024-02-26 19:15:01,813 - Epoch: [63][   20/   44]    Loss 0.497856    Top1 90.859985    
2024-02-26 19:15:32,352 - Epoch: [63][   30/   44]    Loss 0.499550    Top1 90.746046    
2024-02-26 19:16:02,040 - Epoch: [63][   40/   44]    Loss 0.500909    Top1 90.673273    
2024-02-26 19:16:11,850 - Epoch: [63][   44/   44]    Loss 0.502859    Top1 90.613623    
2024-02-26 19:16:12,091 - ==> Top1: 90.614    Loss: 0.503

2024-02-26 19:16:12,098 - ==> Best [Top1: 90.614   Sparsity:0.00   Params: 278176 on epoch: 63]
2024-02-26 19:16:12,098 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:16:12,137 - 

2024-02-26 19:16:12,137 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:16:14,091 - Epoch: [64][   10/  139]    Overall Loss 0.424871    Objective Loss 0.424871                                        LR 0.000500    Time 0.195176    
2024-02-26 19:16:15,189 - Epoch: [64][   20/  139]    Overall Loss 0.426715    Objective Loss 0.426715                                        LR 0.000500    Time 0.152402    
2024-02-26 19:16:16,281 - Epoch: [64][   30/  139]    Overall Loss 0.430854    Objective Loss 0.430854                                        LR 0.000500    Time 0.137975    
2024-02-26 19:16:17,395 - Epoch: [64][   40/  139]    Overall Loss 0.430319    Objective Loss 0.430319                                        LR 0.000500    Time 0.131315    
2024-02-26 19:16:18,502 - Epoch: [64][   50/  139]    Overall Loss 0.431600    Objective Loss 0.431600                                        LR 0.000500    Time 0.127181    
2024-02-26 19:16:19,597 - Epoch: [64][   60/  139]    Overall Loss 0.431273    Objective Loss 0.431273                                        LR 0.000500    Time 0.124214    
2024-02-26 19:16:20,729 - Epoch: [64][   70/  139]    Overall Loss 0.430298    Objective Loss 0.430298                                        LR 0.000500    Time 0.122635    
2024-02-26 19:16:21,838 - Epoch: [64][   80/  139]    Overall Loss 0.429935    Objective Loss 0.429935                                        LR 0.000500    Time 0.121152    
2024-02-26 19:16:22,940 - Epoch: [64][   90/  139]    Overall Loss 0.429449    Objective Loss 0.429449                                        LR 0.000500    Time 0.119924    
2024-02-26 19:16:24,069 - Epoch: [64][  100/  139]    Overall Loss 0.429254    Objective Loss 0.429254                                        LR 0.000500    Time 0.119215    
2024-02-26 19:16:25,148 - Epoch: [64][  110/  139]    Overall Loss 0.429264    Objective Loss 0.429264                                        LR 0.000500    Time 0.118185    
2024-02-26 19:16:26,241 - Epoch: [64][  120/  139]    Overall Loss 0.430019    Objective Loss 0.430019                                        LR 0.000500    Time 0.117437    
2024-02-26 19:16:27,313 - Epoch: [64][  130/  139]    Overall Loss 0.431680    Objective Loss 0.431680                                        LR 0.000500    Time 0.116643    
2024-02-26 19:16:32,847 - Epoch: [64][  139/  139]    Overall Loss 0.432328    Objective Loss 0.432328    Top1 93.879756    LR 0.000500    Time 0.148898    
2024-02-26 19:16:33,150 - --- validate (epoch=64)-----------
2024-02-26 19:16:33,150 - 1392 samples (32 per mini-batch)
2024-02-26 19:17:05,503 - Epoch: [64][   10/   44]    Loss 0.522750    Top1 89.105023    
2024-02-26 19:17:36,556 - Epoch: [64][   20/   44]    Loss 0.520551    Top1 89.290259    
2024-02-26 19:18:07,938 - Epoch: [64][   30/   44]    Loss 0.518710    Top1 89.415519    
2024-02-26 19:18:40,937 - Epoch: [64][   40/   44]    Loss 0.516435    Top1 89.536053    
2024-02-26 19:18:50,839 - Epoch: [64][   44/   44]    Loss 0.513545    Top1 89.636504    
2024-02-26 19:18:51,146 - ==> Top1: 89.637    Loss: 0.514

2024-02-26 19:18:51,149 - ==> Best [Top1: 90.614   Sparsity:0.00   Params: 278176 on epoch: 63]
2024-02-26 19:18:51,149 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:18:51,178 - 

2024-02-26 19:18:51,179 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:18:53,301 - Epoch: [65][   10/  139]    Overall Loss 0.439966    Objective Loss 0.439966                                        LR 0.000500    Time 0.211977    
2024-02-26 19:18:54,476 - Epoch: [65][   20/  139]    Overall Loss 0.441405    Objective Loss 0.441405                                        LR 0.000500    Time 0.164693    
2024-02-26 19:18:55,667 - Epoch: [65][   30/  139]    Overall Loss 0.440670    Objective Loss 0.440670                                        LR 0.000500    Time 0.149481    
2024-02-26 19:18:56,790 - Epoch: [65][   40/  139]    Overall Loss 0.440925    Objective Loss 0.440925                                        LR 0.000500    Time 0.140156    
2024-02-26 19:18:58,007 - Epoch: [65][   50/  139]    Overall Loss 0.441046    Objective Loss 0.441046                                        LR 0.000500    Time 0.136443    
2024-02-26 19:18:59,257 - Epoch: [65][   60/  139]    Overall Loss 0.438824    Objective Loss 0.438824                                        LR 0.000500    Time 0.134526    
2024-02-26 19:19:00,541 - Epoch: [65][   70/  139]    Overall Loss 0.438037    Objective Loss 0.438037                                        LR 0.000500    Time 0.133643    
2024-02-26 19:19:01,927 - Epoch: [65][   80/  139]    Overall Loss 0.437220    Objective Loss 0.437220                                        LR 0.000500    Time 0.134252    
2024-02-26 19:19:03,299 - Epoch: [65][   90/  139]    Overall Loss 0.436322    Objective Loss 0.436322                                        LR 0.000500    Time 0.134574    
2024-02-26 19:19:04,581 - Epoch: [65][  100/  139]    Overall Loss 0.434838    Objective Loss 0.434838                                        LR 0.000500    Time 0.133931    
2024-02-26 19:19:06,119 - Epoch: [65][  110/  139]    Overall Loss 0.433872    Objective Loss 0.433872                                        LR 0.000500    Time 0.135729    
2024-02-26 19:19:07,425 - Epoch: [65][  120/  139]    Overall Loss 0.432834    Objective Loss 0.432834                                        LR 0.000500    Time 0.135294    
2024-02-26 19:19:08,572 - Epoch: [65][  130/  139]    Overall Loss 0.432333    Objective Loss 0.432333                                        LR 0.000500    Time 0.133703    
2024-02-26 19:19:13,606 - Epoch: [65][  139/  139]    Overall Loss 0.432244    Objective Loss 0.432244    Top1 94.504268    LR 0.000500    Time 0.161137    
2024-02-26 19:19:13,963 - --- validate (epoch=65)-----------
2024-02-26 19:19:13,964 - 1392 samples (32 per mini-batch)
2024-02-26 19:19:43,042 - Epoch: [65][   10/   44]    Loss 0.496111    Top1 90.950807    
2024-02-26 19:20:13,897 - Epoch: [65][   20/   44]    Loss 0.492060    Top1 91.203987    
2024-02-26 19:20:42,280 - Epoch: [65][   30/   44]    Loss 0.494695    Top1 91.035611    
2024-02-26 19:21:11,775 - Epoch: [65][   40/   44]    Loss 0.498570    Top1 90.805054    
2024-02-26 19:21:23,192 - Epoch: [65][   44/   44]    Loss 0.498385    Top1 90.822075    
2024-02-26 19:21:23,488 - ==> Top1: 90.822    Loss: 0.498

2024-02-26 19:21:23,495 - ==> Best [Top1: 90.822   Sparsity:0.00   Params: 278176 on epoch: 65]
2024-02-26 19:21:23,495 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:21:23,536 - 

2024-02-26 19:21:23,536 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:21:25,616 - Epoch: [66][   10/  139]    Overall Loss 0.430190    Objective Loss 0.430190                                        LR 0.000500    Time 0.207829    
2024-02-26 19:21:26,715 - Epoch: [66][   20/  139]    Overall Loss 0.427592    Objective Loss 0.427592                                        LR 0.000500    Time 0.158798    
2024-02-26 19:21:27,856 - Epoch: [66][   30/  139]    Overall Loss 0.425149    Objective Loss 0.425149                                        LR 0.000500    Time 0.143863    
2024-02-26 19:21:28,992 - Epoch: [66][   40/  139]    Overall Loss 0.422816    Objective Loss 0.422816                                        LR 0.000500    Time 0.136279    
2024-02-26 19:21:30,088 - Epoch: [66][   50/  139]    Overall Loss 0.423560    Objective Loss 0.423560                                        LR 0.000500    Time 0.130914    
2024-02-26 19:21:31,183 - Epoch: [66][   60/  139]    Overall Loss 0.424393    Objective Loss 0.424393                                        LR 0.000500    Time 0.127339    
2024-02-26 19:21:32,345 - Epoch: [66][   70/  139]    Overall Loss 0.424112    Objective Loss 0.424112                                        LR 0.000500    Time 0.125733    
2024-02-26 19:21:33,476 - Epoch: [66][   80/  139]    Overall Loss 0.424532    Objective Loss 0.424532                                        LR 0.000500    Time 0.124133    
2024-02-26 19:21:34,622 - Epoch: [66][   90/  139]    Overall Loss 0.424184    Objective Loss 0.424184                                        LR 0.000500    Time 0.123060    
2024-02-26 19:21:35,777 - Epoch: [66][  100/  139]    Overall Loss 0.424154    Objective Loss 0.424154                                        LR 0.000500    Time 0.122297    
2024-02-26 19:21:36,908 - Epoch: [66][  110/  139]    Overall Loss 0.423801    Objective Loss 0.423801                                        LR 0.000500    Time 0.121454    
2024-02-26 19:21:38,026 - Epoch: [66][  120/  139]    Overall Loss 0.424403    Objective Loss 0.424403                                        LR 0.000500    Time 0.120642    
2024-02-26 19:21:39,240 - Epoch: [66][  130/  139]    Overall Loss 0.424300    Objective Loss 0.424300                                        LR 0.000500    Time 0.120684    
2024-02-26 19:21:44,560 - Epoch: [66][  139/  139]    Overall Loss 0.423738    Objective Loss 0.423738    Top1 95.749403    LR 0.000500    Time 0.151135    
2024-02-26 19:21:44,924 - --- validate (epoch=66)-----------
2024-02-26 19:21:44,924 - 1392 samples (32 per mini-batch)
2024-02-26 19:22:18,275 - Epoch: [66][   10/   44]    Loss 0.510929    Top1 90.207953    
2024-02-26 19:22:50,723 - Epoch: [66][   20/   44]    Loss 0.506821    Top1 90.414034    
2024-02-26 19:23:20,357 - Epoch: [66][   30/   44]    Loss 0.501032    Top1 90.732831    
2024-02-26 19:23:46,591 - Epoch: [66][   40/   44]    Loss 0.500186    Top1 90.784906    
2024-02-26 19:23:55,268 - Epoch: [66][   44/   44]    Loss 0.501117    Top1 90.758586    
2024-02-26 19:23:55,516 - ==> Top1: 90.759    Loss: 0.501

2024-02-26 19:23:55,523 - ==> Best [Top1: 90.822   Sparsity:0.00   Params: 278176 on epoch: 65]
2024-02-26 19:23:55,523 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:23:55,554 - 

2024-02-26 19:23:55,554 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:23:57,498 - Epoch: [67][   10/  139]    Overall Loss 0.436364    Objective Loss 0.436364                                        LR 0.000500    Time 0.194296    
2024-02-26 19:23:58,553 - Epoch: [67][   20/  139]    Overall Loss 0.428784    Objective Loss 0.428784                                        LR 0.000500    Time 0.149862    
2024-02-26 19:23:59,652 - Epoch: [67][   30/  139]    Overall Loss 0.425660    Objective Loss 0.425660                                        LR 0.000500    Time 0.136505    
2024-02-26 19:24:00,699 - Epoch: [67][   40/  139]    Overall Loss 0.425272    Objective Loss 0.425272                                        LR 0.000500    Time 0.128546    
2024-02-26 19:24:01,784 - Epoch: [67][   50/  139]    Overall Loss 0.424530    Objective Loss 0.424530                                        LR 0.000500    Time 0.124525    
2024-02-26 19:24:02,871 - Epoch: [67][   60/  139]    Overall Loss 0.423798    Objective Loss 0.423798                                        LR 0.000500    Time 0.121878    
2024-02-26 19:24:04,007 - Epoch: [67][   70/  139]    Overall Loss 0.423505    Objective Loss 0.423505                                        LR 0.000500    Time 0.120698    
2024-02-26 19:24:05,094 - Epoch: [67][   80/  139]    Overall Loss 0.423019    Objective Loss 0.423019                                        LR 0.000500    Time 0.119183    
2024-02-26 19:24:06,260 - Epoch: [67][   90/  139]    Overall Loss 0.423023    Objective Loss 0.423023                                        LR 0.000500    Time 0.118893    
2024-02-26 19:24:07,378 - Epoch: [67][  100/  139]    Overall Loss 0.423559    Objective Loss 0.423559                                        LR 0.000500    Time 0.118181    
2024-02-26 19:24:08,513 - Epoch: [67][  110/  139]    Overall Loss 0.424007    Objective Loss 0.424007                                        LR 0.000500    Time 0.117744    
2024-02-26 19:24:09,694 - Epoch: [67][  120/  139]    Overall Loss 0.423667    Objective Loss 0.423667                                        LR 0.000500    Time 0.117772    
2024-02-26 19:24:10,849 - Epoch: [67][  130/  139]    Overall Loss 0.423938    Objective Loss 0.423938                                        LR 0.000500    Time 0.117595    
2024-02-26 19:24:16,076 - Epoch: [67][  139/  139]    Overall Loss 0.424379    Objective Loss 0.424379    Top1 93.732153    LR 0.000500    Time 0.147492    
2024-02-26 19:24:16,535 - --- validate (epoch=67)-----------
2024-02-26 19:24:16,535 - 1392 samples (32 per mini-batch)
2024-02-26 19:24:49,157 - Epoch: [67][   10/   44]    Loss 0.511626    Top1 90.220801    
2024-02-26 19:25:16,972 - Epoch: [67][   20/   44]    Loss 0.498576    Top1 90.921562    
2024-02-26 19:25:46,663 - Epoch: [67][   30/   44]    Loss 0.501435    Top1 90.802624    
2024-02-26 19:26:18,473 - Epoch: [67][   40/   44]    Loss 0.504057    Top1 90.642352    
2024-02-26 19:26:29,932 - Epoch: [67][   44/   44]    Loss 0.502167    Top1 90.776300    
2024-02-26 19:26:30,171 - ==> Top1: 90.776    Loss: 0.502

2024-02-26 19:26:30,178 - ==> Best [Top1: 90.822   Sparsity:0.00   Params: 278176 on epoch: 65]
2024-02-26 19:26:30,179 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:26:30,214 - 

2024-02-26 19:26:30,214 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:26:32,202 - Epoch: [68][   10/  139]    Overall Loss 0.430170    Objective Loss 0.430170                                        LR 0.000500    Time 0.198585    
2024-02-26 19:26:33,267 - Epoch: [68][   20/  139]    Overall Loss 0.429585    Objective Loss 0.429585                                        LR 0.000500    Time 0.152530    
2024-02-26 19:26:34,344 - Epoch: [68][   30/  139]    Overall Loss 0.433481    Objective Loss 0.433481                                        LR 0.000500    Time 0.137106    
2024-02-26 19:26:35,512 - Epoch: [68][   40/  139]    Overall Loss 0.431121    Objective Loss 0.431121                                        LR 0.000500    Time 0.132006    
2024-02-26 19:26:36,620 - Epoch: [68][   50/  139]    Overall Loss 0.431272    Objective Loss 0.431272                                        LR 0.000500    Time 0.127760    
2024-02-26 19:26:37,767 - Epoch: [68][   60/  139]    Overall Loss 0.429812    Objective Loss 0.429812                                        LR 0.000500    Time 0.125574    
2024-02-26 19:26:38,858 - Epoch: [68][   70/  139]    Overall Loss 0.428358    Objective Loss 0.428358                                        LR 0.000500    Time 0.123203    
2024-02-26 19:26:39,993 - Epoch: [68][   80/  139]    Overall Loss 0.427513    Objective Loss 0.427513                                        LR 0.000500    Time 0.121972    
2024-02-26 19:26:41,161 - Epoch: [68][   90/  139]    Overall Loss 0.428035    Objective Loss 0.428035                                        LR 0.000500    Time 0.121390    
2024-02-26 19:26:42,297 - Epoch: [68][  100/  139]    Overall Loss 0.427151    Objective Loss 0.427151                                        LR 0.000500    Time 0.120608    
2024-02-26 19:26:43,419 - Epoch: [68][  110/  139]    Overall Loss 0.426811    Objective Loss 0.426811                                        LR 0.000500    Time 0.119835    
2024-02-26 19:26:44,538 - Epoch: [68][  120/  139]    Overall Loss 0.426705    Objective Loss 0.426705                                        LR 0.000500    Time 0.119168    
2024-02-26 19:26:45,703 - Epoch: [68][  130/  139]    Overall Loss 0.426418    Objective Loss 0.426418                                        LR 0.000500    Time 0.118955    
2024-02-26 19:26:50,776 - Epoch: [68][  139/  139]    Overall Loss 0.425894    Objective Loss 0.425894    Top1 95.252098    LR 0.000500    Time 0.147749    
2024-02-26 19:26:51,006 - --- validate (epoch=68)-----------
2024-02-26 19:26:51,007 - 1392 samples (32 per mini-batch)
2024-02-26 19:27:23,321 - Epoch: [68][   10/   44]    Loss 0.523136    Top1 89.579266    
2024-02-26 19:27:54,357 - Epoch: [68][   20/   44]    Loss 0.507635    Top1 90.384031    
2024-02-26 19:28:23,025 - Epoch: [68][   30/   44]    Loss 0.505154    Top1 90.530587    
2024-02-26 19:28:51,951 - Epoch: [68][   40/   44]    Loss 0.500568    Top1 90.798608    
2024-02-26 19:29:02,774 - Epoch: [68][   44/   44]    Loss 0.501366    Top1 90.748891    
2024-02-26 19:29:03,115 - ==> Top1: 90.749    Loss: 0.501

2024-02-26 19:29:03,121 - ==> Best [Top1: 90.822   Sparsity:0.00   Params: 278176 on epoch: 65]
2024-02-26 19:29:03,121 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:29:03,152 - 

2024-02-26 19:29:03,153 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:29:05,167 - Epoch: [69][   10/  139]    Overall Loss 0.419612    Objective Loss 0.419612                                        LR 0.000500    Time 0.201147    
2024-02-26 19:29:06,263 - Epoch: [69][   20/  139]    Overall Loss 0.417029    Objective Loss 0.417029                                        LR 0.000500    Time 0.155328    
2024-02-26 19:29:07,310 - Epoch: [69][   30/  139]    Overall Loss 0.414256    Objective Loss 0.414256                                        LR 0.000500    Time 0.138433    
2024-02-26 19:29:08,458 - Epoch: [69][   40/  139]    Overall Loss 0.416010    Objective Loss 0.416010                                        LR 0.000500    Time 0.132525    
2024-02-26 19:29:09,650 - Epoch: [69][   50/  139]    Overall Loss 0.417364    Objective Loss 0.417364                                        LR 0.000500    Time 0.129835    
2024-02-26 19:29:10,957 - Epoch: [69][   60/  139]    Overall Loss 0.417875    Objective Loss 0.417875                                        LR 0.000500    Time 0.129966    
2024-02-26 19:29:12,137 - Epoch: [69][   70/  139]    Overall Loss 0.419040    Objective Loss 0.419040                                        LR 0.000500    Time 0.128251    
2024-02-26 19:29:13,423 - Epoch: [69][   80/  139]    Overall Loss 0.419214    Objective Loss 0.419214                                        LR 0.000500    Time 0.128103    
2024-02-26 19:29:14,681 - Epoch: [69][   90/  139]    Overall Loss 0.419619    Objective Loss 0.419619                                        LR 0.000500    Time 0.127844    
2024-02-26 19:29:15,841 - Epoch: [69][  100/  139]    Overall Loss 0.420060    Objective Loss 0.420060                                        LR 0.000500    Time 0.126651    
2024-02-26 19:29:17,075 - Epoch: [69][  110/  139]    Overall Loss 0.419772    Objective Loss 0.419772                                        LR 0.000500    Time 0.126354    
2024-02-26 19:29:18,302 - Epoch: [69][  120/  139]    Overall Loss 0.419817    Objective Loss 0.419817                                        LR 0.000500    Time 0.126042    
2024-02-26 19:29:19,485 - Epoch: [69][  130/  139]    Overall Loss 0.419858    Objective Loss 0.419858                                        LR 0.000500    Time 0.125437    
2024-02-26 19:29:24,881 - Epoch: [69][  139/  139]    Overall Loss 0.419837    Objective Loss 0.419837    Top1 96.005430    LR 0.000500    Time 0.156135    
2024-02-26 19:29:25,177 - --- validate (epoch=69)-----------
2024-02-26 19:29:25,177 - 1392 samples (32 per mini-batch)
2024-02-26 19:29:57,597 - Epoch: [69][   10/   44]    Loss 0.510280    Top1 90.342556    
2024-02-26 19:30:29,865 - Epoch: [69][   20/   44]    Loss 0.508311    Top1 90.414919    
2024-02-26 19:31:01,977 - Epoch: [69][   30/   44]    Loss 0.510089    Top1 90.282072    
2024-02-26 19:31:33,715 - Epoch: [69][   40/   44]    Loss 0.506493    Top1 90.500051    
2024-02-26 19:31:45,133 - Epoch: [69][   44/   44]    Loss 0.506108    Top1 90.521078    
2024-02-26 19:31:45,477 - ==> Top1: 90.521    Loss: 0.506

2024-02-26 19:31:45,484 - ==> Best [Top1: 90.822   Sparsity:0.00   Params: 278176 on epoch: 65]
2024-02-26 19:31:45,485 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:31:45,513 - 

2024-02-26 19:31:45,514 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:31:47,666 - Epoch: [70][   10/  139]    Overall Loss 0.417624    Objective Loss 0.417624                                        LR 0.000500    Time 0.215031    
2024-02-26 19:31:48,791 - Epoch: [70][   20/  139]    Overall Loss 0.420126    Objective Loss 0.420126                                        LR 0.000500    Time 0.163687    
2024-02-26 19:31:49,896 - Epoch: [70][   30/  139]    Overall Loss 0.418629    Objective Loss 0.418629                                        LR 0.000500    Time 0.145954    
2024-02-26 19:31:51,028 - Epoch: [70][   40/  139]    Overall Loss 0.417807    Objective Loss 0.417807                                        LR 0.000500    Time 0.137736    
2024-02-26 19:31:52,159 - Epoch: [70][   50/  139]    Overall Loss 0.417272    Objective Loss 0.417272                                        LR 0.000500    Time 0.132798    
2024-02-26 19:31:53,273 - Epoch: [70][   60/  139]    Overall Loss 0.418049    Objective Loss 0.418049                                        LR 0.000500    Time 0.129202    
2024-02-26 19:31:54,396 - Epoch: [70][   70/  139]    Overall Loss 0.418284    Objective Loss 0.418284                                        LR 0.000500    Time 0.126774    
2024-02-26 19:31:55,559 - Epoch: [70][   80/  139]    Overall Loss 0.418106    Objective Loss 0.418106                                        LR 0.000500    Time 0.125462    
2024-02-26 19:31:56,678 - Epoch: [70][   90/  139]    Overall Loss 0.419339    Objective Loss 0.419339                                        LR 0.000500    Time 0.123939    
2024-02-26 19:31:57,807 - Epoch: [70][  100/  139]    Overall Loss 0.420131    Objective Loss 0.420131                                        LR 0.000500    Time 0.122833    
2024-02-26 19:31:58,932 - Epoch: [70][  110/  139]    Overall Loss 0.420254    Objective Loss 0.420254                                        LR 0.000500    Time 0.121878    
2024-02-26 19:32:00,084 - Epoch: [70][  120/  139]    Overall Loss 0.419903    Objective Loss 0.419903                                        LR 0.000500    Time 0.121314    
2024-02-26 19:32:01,211 - Epoch: [70][  130/  139]    Overall Loss 0.420149    Objective Loss 0.420149                                        LR 0.000500    Time 0.120648    
2024-02-26 19:32:07,086 - Epoch: [70][  139/  139]    Overall Loss 0.420732    Objective Loss 0.420732    Top1 94.843625    LR 0.000500    Time 0.155005    
2024-02-26 19:32:07,385 - --- validate (epoch=70)-----------
2024-02-26 19:32:07,386 - 1392 samples (32 per mini-batch)
2024-02-26 19:32:41,614 - Epoch: [70][   10/   44]    Loss 0.503016    Top1 90.573370    
2024-02-26 19:33:11,224 - Epoch: [70][   20/   44]    Loss 0.502135    Top1 90.631787    
2024-02-26 19:33:39,619 - Epoch: [70][   30/   44]    Loss 0.500495    Top1 90.736061    
2024-02-26 19:34:07,863 - Epoch: [70][   40/   44]    Loss 0.502512    Top1 90.632616    
2024-02-26 19:34:17,878 - Epoch: [70][   44/   44]    Loss 0.504394    Top1 90.563343    
2024-02-26 19:34:18,159 - ==> Top1: 90.563    Loss: 0.504

2024-02-26 19:34:18,165 - ==> Best [Top1: 90.822   Sparsity:0.00   Params: 278176 on epoch: 65]
2024-02-26 19:34:18,165 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:34:18,205 - 

2024-02-26 19:34:18,205 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:34:20,280 - Epoch: [71][   10/  139]    Overall Loss 0.425275    Objective Loss 0.425275                                        LR 0.000500    Time 0.207276    
2024-02-26 19:34:21,385 - Epoch: [71][   20/  139]    Overall Loss 0.422363    Objective Loss 0.422363                                        LR 0.000500    Time 0.158849    
2024-02-26 19:34:22,528 - Epoch: [71][   30/  139]    Overall Loss 0.420402    Objective Loss 0.420402                                        LR 0.000500    Time 0.143955    
2024-02-26 19:34:23,652 - Epoch: [71][   40/  139]    Overall Loss 0.421063    Objective Loss 0.421063                                        LR 0.000500    Time 0.136036    
2024-02-26 19:34:24,770 - Epoch: [71][   50/  139]    Overall Loss 0.418811    Objective Loss 0.418811                                        LR 0.000500    Time 0.131180    
2024-02-26 19:34:25,888 - Epoch: [71][   60/  139]    Overall Loss 0.417973    Objective Loss 0.417973                                        LR 0.000500    Time 0.127933    
2024-02-26 19:34:27,018 - Epoch: [71][   70/  139]    Overall Loss 0.418669    Objective Loss 0.418669                                        LR 0.000500    Time 0.125781    
2024-02-26 19:34:28,201 - Epoch: [71][   80/  139]    Overall Loss 0.419856    Objective Loss 0.419856                                        LR 0.000500    Time 0.124846    
2024-02-26 19:34:29,463 - Epoch: [71][   90/  139]    Overall Loss 0.419859    Objective Loss 0.419859                                        LR 0.000500    Time 0.124986    
2024-02-26 19:34:30,599 - Epoch: [71][  100/  139]    Overall Loss 0.419782    Objective Loss 0.419782                                        LR 0.000500    Time 0.123833    
2024-02-26 19:34:31,722 - Epoch: [71][  110/  139]    Overall Loss 0.419605    Objective Loss 0.419605                                        LR 0.000500    Time 0.122781    
2024-02-26 19:34:32,901 - Epoch: [71][  120/  139]    Overall Loss 0.419715    Objective Loss 0.419715                                        LR 0.000500    Time 0.122366    
2024-02-26 19:34:34,027 - Epoch: [71][  130/  139]    Overall Loss 0.419847    Objective Loss 0.419847                                        LR 0.000500    Time 0.121605    
2024-02-26 19:34:39,481 - Epoch: [71][  139/  139]    Overall Loss 0.420235    Objective Loss 0.420235    Top1 94.514815    LR 0.000500    Time 0.152968    
2024-02-26 19:34:39,747 - --- validate (epoch=71)-----------
2024-02-26 19:34:39,748 - 1392 samples (32 per mini-batch)
2024-02-26 19:35:12,263 - Epoch: [71][   10/   44]    Loss 0.508263    Top1 90.399407    
2024-02-26 19:35:44,466 - Epoch: [71][   20/   44]    Loss 0.503610    Top1 90.634517    
2024-02-26 19:36:15,812 - Epoch: [71][   30/   44]    Loss 0.503536    Top1 90.664283    
2024-02-26 19:36:47,859 - Epoch: [71][   40/   44]    Loss 0.502696    Top1 90.698880    
2024-02-26 19:36:59,332 - Epoch: [71][   44/   44]    Loss 0.500677    Top1 90.777444    
2024-02-26 19:36:59,722 - ==> Top1: 90.777    Loss: 0.501

2024-02-26 19:36:59,728 - ==> Best [Top1: 90.822   Sparsity:0.00   Params: 278176 on epoch: 65]
2024-02-26 19:36:59,728 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:36:59,768 - 

2024-02-26 19:36:59,768 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:37:02,042 - Epoch: [72][   10/  139]    Overall Loss 0.421411    Objective Loss 0.421411                                        LR 0.000500    Time 0.227086    
2024-02-26 19:37:03,397 - Epoch: [72][   20/  139]    Overall Loss 0.425850    Objective Loss 0.425850                                        LR 0.000500    Time 0.181244    
2024-02-26 19:37:04,750 - Epoch: [72][   30/  139]    Overall Loss 0.424031    Objective Loss 0.424031                                        LR 0.000500    Time 0.165235    
2024-02-26 19:37:05,964 - Epoch: [72][   40/  139]    Overall Loss 0.425613    Objective Loss 0.425613                                        LR 0.000500    Time 0.154249    
2024-02-26 19:37:07,220 - Epoch: [72][   50/  139]    Overall Loss 0.424821    Objective Loss 0.424821                                        LR 0.000500    Time 0.148522    
2024-02-26 19:37:08,485 - Epoch: [72][   60/  139]    Overall Loss 0.424462    Objective Loss 0.424462                                        LR 0.000500    Time 0.144846    
2024-02-26 19:37:09,706 - Epoch: [72][   70/  139]    Overall Loss 0.424000    Objective Loss 0.424000                                        LR 0.000500    Time 0.141580    
2024-02-26 19:37:11,048 - Epoch: [72][   80/  139]    Overall Loss 0.423407    Objective Loss 0.423407                                        LR 0.000500    Time 0.140646    
2024-02-26 19:37:12,337 - Epoch: [72][   90/  139]    Overall Loss 0.423527    Objective Loss 0.423527                                        LR 0.000500    Time 0.139337    
2024-02-26 19:37:13,499 - Epoch: [72][  100/  139]    Overall Loss 0.423040    Objective Loss 0.423040                                        LR 0.000500    Time 0.137012    
2024-02-26 19:37:14,686 - Epoch: [72][  110/  139]    Overall Loss 0.422554    Objective Loss 0.422554                                        LR 0.000500    Time 0.135341    
2024-02-26 19:37:15,853 - Epoch: [72][  120/  139]    Overall Loss 0.422416    Objective Loss 0.422416                                        LR 0.000500    Time 0.133786    
2024-02-26 19:37:16,993 - Epoch: [72][  130/  139]    Overall Loss 0.421936    Objective Loss 0.421936                                        LR 0.000500    Time 0.132260    
2024-02-26 19:37:22,583 - Epoch: [72][  139/  139]    Overall Loss 0.421469    Objective Loss 0.421469    Top1 95.813676    LR 0.000500    Time 0.163909    
2024-02-26 19:37:22,873 - --- validate (epoch=72)-----------
2024-02-26 19:37:22,875 - 1392 samples (32 per mini-batch)
2024-02-26 19:37:55,376 - Epoch: [72][   10/   44]    Loss 0.491927    Top1 91.257576    
2024-02-26 19:38:26,443 - Epoch: [72][   20/   44]    Loss 0.499326    Top1 90.819489    
2024-02-26 19:38:50,924 - Epoch: [72][   30/   44]    Loss 0.498845    Top1 90.837930    
2024-02-26 19:39:14,166 - Epoch: [72][   40/   44]    Loss 0.500740    Top1 90.753976    
2024-02-26 19:39:22,736 - Epoch: [72][   44/   44]    Loss 0.499334    Top1 90.818987    
2024-02-26 19:39:22,966 - ==> Top1: 90.819    Loss: 0.499

2024-02-26 19:39:22,973 - ==> Best [Top1: 90.822   Sparsity:0.00   Params: 278176 on epoch: 65]
2024-02-26 19:39:22,973 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:39:23,004 - 

2024-02-26 19:39:23,004 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:39:25,045 - Epoch: [73][   10/  139]    Overall Loss 0.416534    Objective Loss 0.416534                                        LR 0.000500    Time 0.203975    
2024-02-26 19:39:26,128 - Epoch: [73][   20/  139]    Overall Loss 0.418514    Objective Loss 0.418514                                        LR 0.000500    Time 0.156079    
2024-02-26 19:39:27,223 - Epoch: [73][   30/  139]    Overall Loss 0.418693    Objective Loss 0.418693                                        LR 0.000500    Time 0.140524    
2024-02-26 19:39:28,313 - Epoch: [73][   40/  139]    Overall Loss 0.417991    Objective Loss 0.417991                                        LR 0.000500    Time 0.132610    
2024-02-26 19:39:29,367 - Epoch: [73][   50/  139]    Overall Loss 0.418249    Objective Loss 0.418249                                        LR 0.000500    Time 0.127162    
2024-02-26 19:39:30,423 - Epoch: [73][   60/  139]    Overall Loss 0.420382    Objective Loss 0.420382                                        LR 0.000500    Time 0.123556    
2024-02-26 19:39:31,527 - Epoch: [73][   70/  139]    Overall Loss 0.419315    Objective Loss 0.419315                                        LR 0.000500    Time 0.121654    
2024-02-26 19:39:32,576 - Epoch: [73][   80/  139]    Overall Loss 0.419278    Objective Loss 0.419278                                        LR 0.000500    Time 0.119557    
2024-02-26 19:39:33,678 - Epoch: [73][   90/  139]    Overall Loss 0.418856    Objective Loss 0.418856                                        LR 0.000500    Time 0.118508    
2024-02-26 19:39:34,850 - Epoch: [73][  100/  139]    Overall Loss 0.419942    Objective Loss 0.419942                                        LR 0.000500    Time 0.118374    
2024-02-26 19:39:35,946 - Epoch: [73][  110/  139]    Overall Loss 0.419809    Objective Loss 0.419809                                        LR 0.000500    Time 0.117569    
2024-02-26 19:39:37,005 - Epoch: [73][  120/  139]    Overall Loss 0.419975    Objective Loss 0.419975                                        LR 0.000500    Time 0.116587    
2024-02-26 19:39:38,083 - Epoch: [73][  130/  139]    Overall Loss 0.419589    Objective Loss 0.419589                                        LR 0.000500    Time 0.115909    
2024-02-26 19:39:42,665 - Epoch: [73][  139/  139]    Overall Loss 0.419903    Objective Loss 0.419903    Top1 94.143358    LR 0.000500    Time 0.141363    
2024-02-26 19:39:43,032 - --- validate (epoch=73)-----------
2024-02-26 19:39:43,033 - 1392 samples (32 per mini-batch)
2024-02-26 19:40:14,281 - Epoch: [73][   10/   44]    Loss 0.506224    Top1 90.404595    
2024-02-26 19:40:45,816 - Epoch: [73][   20/   44]    Loss 0.499080    Top1 90.850063    
2024-02-26 19:41:18,026 - Epoch: [73][   30/   44]    Loss 0.501069    Top1 90.733004    
2024-02-26 19:41:44,926 - Epoch: [73][   40/   44]    Loss 0.498788    Top1 90.883014    
2024-02-26 19:41:53,001 - Epoch: [73][   44/   44]    Loss 0.499246    Top1 90.862358    
2024-02-26 19:41:53,247 - ==> Top1: 90.862    Loss: 0.499

2024-02-26 19:41:53,254 - ==> Best [Top1: 90.862   Sparsity:0.00   Params: 278176 on epoch: 73]
2024-02-26 19:41:53,255 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:41:53,294 - 

2024-02-26 19:41:53,295 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:41:55,255 - Epoch: [74][   10/  139]    Overall Loss 0.416415    Objective Loss 0.416415                                        LR 0.000500    Time 0.195904    
2024-02-26 19:41:56,371 - Epoch: [74][   20/  139]    Overall Loss 0.417874    Objective Loss 0.417874                                        LR 0.000500    Time 0.153699    
2024-02-26 19:41:57,426 - Epoch: [74][   30/  139]    Overall Loss 0.418343    Objective Loss 0.418343                                        LR 0.000500    Time 0.137642    
2024-02-26 19:41:58,640 - Epoch: [74][   40/  139]    Overall Loss 0.418397    Objective Loss 0.418397                                        LR 0.000500    Time 0.133556    
2024-02-26 19:41:59,739 - Epoch: [74][   50/  139]    Overall Loss 0.418229    Objective Loss 0.418229                                        LR 0.000500    Time 0.128811    
2024-02-26 19:42:00,937 - Epoch: [74][   60/  139]    Overall Loss 0.417720    Objective Loss 0.417720                                        LR 0.000500    Time 0.127304    
2024-02-26 19:42:02,210 - Epoch: [74][   70/  139]    Overall Loss 0.416514    Objective Loss 0.416514                                        LR 0.000500    Time 0.127290    
2024-02-26 19:42:03,375 - Epoch: [74][   80/  139]    Overall Loss 0.415810    Objective Loss 0.415810                                        LR 0.000500    Time 0.125942    
2024-02-26 19:42:04,587 - Epoch: [74][   90/  139]    Overall Loss 0.415915    Objective Loss 0.415915                                        LR 0.000500    Time 0.125409    
2024-02-26 19:42:05,792 - Epoch: [74][  100/  139]    Overall Loss 0.416179    Objective Loss 0.416179                                        LR 0.000500    Time 0.124909    
2024-02-26 19:42:06,884 - Epoch: [74][  110/  139]    Overall Loss 0.415923    Objective Loss 0.415923                                        LR 0.000500    Time 0.123478    
2024-02-26 19:42:07,979 - Epoch: [74][  120/  139]    Overall Loss 0.416315    Objective Loss 0.416315                                        LR 0.000500    Time 0.122311    
2024-02-26 19:42:09,052 - Epoch: [74][  130/  139]    Overall Loss 0.416012    Objective Loss 0.416012                                        LR 0.000500    Time 0.121152    
2024-02-26 19:42:13,163 - Epoch: [74][  139/  139]    Overall Loss 0.416044    Objective Loss 0.416044    Top1 94.889060    LR 0.000500    Time 0.142881    
2024-02-26 19:42:13,532 - --- validate (epoch=74)-----------
2024-02-26 19:42:13,532 - 1392 samples (32 per mini-batch)
2024-02-26 19:42:38,426 - Epoch: [74][   10/   44]    Loss 0.510841    Top1 90.321983    
2024-02-26 19:43:02,792 - Epoch: [74][   20/   44]    Loss 0.502513    Top1 90.790742    
2024-02-26 19:43:27,614 - Epoch: [74][   30/   44]    Loss 0.502140    Top1 90.794743    
2024-02-26 19:43:57,209 - Epoch: [74][   40/   44]    Loss 0.501415    Top1 90.824335    
2024-02-26 19:44:08,349 - Epoch: [74][   44/   44]    Loss 0.501296    Top1 90.839792    
2024-02-26 19:44:08,666 - ==> Top1: 90.840    Loss: 0.501

2024-02-26 19:44:08,672 - ==> Best [Top1: 90.862   Sparsity:0.00   Params: 278176 on epoch: 73]
2024-02-26 19:44:08,673 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:44:08,703 - 

2024-02-26 19:44:08,704 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:44:10,733 - Epoch: [75][   10/  139]    Overall Loss 0.416878    Objective Loss 0.416878                                        LR 0.000500    Time 0.202771    
2024-02-26 19:44:11,781 - Epoch: [75][   20/  139]    Overall Loss 0.416437    Objective Loss 0.416437                                        LR 0.000500    Time 0.153744    
2024-02-26 19:44:12,886 - Epoch: [75][   30/  139]    Overall Loss 0.413300    Objective Loss 0.413300                                        LR 0.000500    Time 0.139294    
2024-02-26 19:44:13,975 - Epoch: [75][   40/  139]    Overall Loss 0.415925    Objective Loss 0.415925                                        LR 0.000500    Time 0.131684    
2024-02-26 19:44:15,082 - Epoch: [75][   50/  139]    Overall Loss 0.416251    Objective Loss 0.416251                                        LR 0.000500    Time 0.127463    
2024-02-26 19:44:16,173 - Epoch: [75][   60/  139]    Overall Loss 0.416844    Objective Loss 0.416844                                        LR 0.000500    Time 0.124386    
2024-02-26 19:44:17,329 - Epoch: [75][   70/  139]    Overall Loss 0.416947    Objective Loss 0.416947                                        LR 0.000500    Time 0.123115    
2024-02-26 19:44:18,437 - Epoch: [75][   80/  139]    Overall Loss 0.416199    Objective Loss 0.416199                                        LR 0.000500    Time 0.121559    
2024-02-26 19:44:19,533 - Epoch: [75][   90/  139]    Overall Loss 0.416539    Objective Loss 0.416539                                        LR 0.000500    Time 0.120227    
2024-02-26 19:44:20,693 - Epoch: [75][  100/  139]    Overall Loss 0.416481    Objective Loss 0.416481                                        LR 0.000500    Time 0.119790    
2024-02-26 19:44:21,781 - Epoch: [75][  110/  139]    Overall Loss 0.416173    Objective Loss 0.416173                                        LR 0.000500    Time 0.118784    
2024-02-26 19:44:22,866 - Epoch: [75][  120/  139]    Overall Loss 0.416252    Objective Loss 0.416252                                        LR 0.000500    Time 0.117923    
2024-02-26 19:44:24,000 - Epoch: [75][  130/  139]    Overall Loss 0.416587    Objective Loss 0.416587                                        LR 0.000500    Time 0.117573    
2024-02-26 19:44:29,341 - Epoch: [75][  139/  139]    Overall Loss 0.416631    Objective Loss 0.416631    Top1 95.696925    LR 0.000500    Time 0.148377    
2024-02-26 19:44:29,634 - --- validate (epoch=75)-----------
2024-02-26 19:44:29,635 - 1392 samples (32 per mini-batch)
2024-02-26 19:45:02,717 - Epoch: [75][   10/   44]    Loss 0.491442    Top1 91.347096    
2024-02-26 19:45:33,712 - Epoch: [75][   20/   44]    Loss 0.498226    Top1 90.998297    
2024-02-26 19:46:00,829 - Epoch: [75][   30/   44]    Loss 0.498486    Top1 90.968049    
2024-02-26 19:46:27,982 - Epoch: [75][   40/   44]    Loss 0.498906    Top1 90.960074    
2024-02-26 19:46:37,113 - Epoch: [75][   44/   44]    Loss 0.497476    Top1 90.995994    
2024-02-26 19:46:37,549 - ==> Top1: 90.996    Loss: 0.497

2024-02-26 19:46:37,556 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 19:46:37,556 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:46:37,596 - 

2024-02-26 19:46:37,597 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:46:39,615 - Epoch: [76][   10/  139]    Overall Loss 0.414975    Objective Loss 0.414975                                        LR 0.000500    Time 0.201551    
2024-02-26 19:46:42,022 - Epoch: [76][   20/  139]    Overall Loss 0.415265    Objective Loss 0.415265                                        LR 0.000500    Time 0.221059    
2024-02-26 19:46:43,587 - Epoch: [76][   30/  139]    Overall Loss 0.413187    Objective Loss 0.413187                                        LR 0.000500    Time 0.199535    
2024-02-26 19:46:44,649 - Epoch: [76][   40/  139]    Overall Loss 0.412846    Objective Loss 0.412846                                        LR 0.000500    Time 0.176178    
2024-02-26 19:46:45,863 - Epoch: [76][   50/  139]    Overall Loss 0.415493    Objective Loss 0.415493                                        LR 0.000500    Time 0.165220    
2024-02-26 19:46:47,031 - Epoch: [76][   60/  139]    Overall Loss 0.417891    Objective Loss 0.417891                                        LR 0.000500    Time 0.157141    
2024-02-26 19:46:48,212 - Epoch: [76][   70/  139]    Overall Loss 0.418389    Objective Loss 0.418389                                        LR 0.000500    Time 0.151545    
2024-02-26 19:46:49,351 - Epoch: [76][   80/  139]    Overall Loss 0.417760    Objective Loss 0.417760                                        LR 0.000500    Time 0.146839    
2024-02-26 19:46:50,474 - Epoch: [76][   90/  139]    Overall Loss 0.417715    Objective Loss 0.417715                                        LR 0.000500    Time 0.142999    
2024-02-26 19:46:51,717 - Epoch: [76][  100/  139]    Overall Loss 0.417521    Objective Loss 0.417521                                        LR 0.000500    Time 0.141122    
2024-02-26 19:46:52,888 - Epoch: [76][  110/  139]    Overall Loss 0.417555    Objective Loss 0.417555                                        LR 0.000500    Time 0.138935    
2024-02-26 19:46:54,020 - Epoch: [76][  120/  139]    Overall Loss 0.418709    Objective Loss 0.418709                                        LR 0.000500    Time 0.136785    
2024-02-26 19:46:55,268 - Epoch: [76][  130/  139]    Overall Loss 0.418626    Objective Loss 0.418626                                        LR 0.000500    Time 0.135854    
2024-02-26 19:47:00,383 - Epoch: [76][  139/  139]    Overall Loss 0.418747    Objective Loss 0.418747    Top1 95.751733    LR 0.000500    Time 0.163855    
2024-02-26 19:47:00,633 - --- validate (epoch=76)-----------
2024-02-26 19:47:00,634 - 1392 samples (32 per mini-batch)
2024-02-26 19:47:31,478 - Epoch: [76][   10/   44]    Loss 0.506586    Top1 90.436896    
2024-02-26 19:48:00,689 - Epoch: [76][   20/   44]    Loss 0.506308    Top1 90.523119    
2024-02-26 19:48:33,118 - Epoch: [76][   30/   44]    Loss 0.507579    Top1 90.464453    
2024-02-26 19:49:04,432 - Epoch: [76][   40/   44]    Loss 0.514241    Top1 90.078320    
2024-02-26 19:49:15,793 - Epoch: [76][   44/   44]    Loss 0.513810    Top1 90.084854    
2024-02-26 19:49:16,022 - ==> Top1: 90.085    Loss: 0.514

2024-02-26 19:49:16,028 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 19:49:16,029 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:49:16,058 - 

2024-02-26 19:49:16,058 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:49:18,052 - Epoch: [77][   10/  139]    Overall Loss 0.416833    Objective Loss 0.416833                                        LR 0.000500    Time 0.199174    
2024-02-26 19:49:19,150 - Epoch: [77][   20/  139]    Overall Loss 0.416954    Objective Loss 0.416954                                        LR 0.000500    Time 0.154410    
2024-02-26 19:49:20,222 - Epoch: [77][   30/  139]    Overall Loss 0.415570    Objective Loss 0.415570                                        LR 0.000500    Time 0.138658    
2024-02-26 19:49:21,328 - Epoch: [77][   40/  139]    Overall Loss 0.416139    Objective Loss 0.416139                                        LR 0.000500    Time 0.131606    
2024-02-26 19:49:22,385 - Epoch: [77][   50/  139]    Overall Loss 0.416946    Objective Loss 0.416946                                        LR 0.000500    Time 0.126413    
2024-02-26 19:49:23,478 - Epoch: [77][   60/  139]    Overall Loss 0.416456    Objective Loss 0.416456                                        LR 0.000500    Time 0.123544    
2024-02-26 19:49:24,578 - Epoch: [77][   70/  139]    Overall Loss 0.416422    Objective Loss 0.416422                                        LR 0.000500    Time 0.121599    
2024-02-26 19:49:25,658 - Epoch: [77][   80/  139]    Overall Loss 0.415563    Objective Loss 0.415563                                        LR 0.000500    Time 0.119889    
2024-02-26 19:49:26,732 - Epoch: [77][   90/  139]    Overall Loss 0.415721    Objective Loss 0.415721                                        LR 0.000500    Time 0.118488    
2024-02-26 19:49:27,815 - Epoch: [77][  100/  139]    Overall Loss 0.415612    Objective Loss 0.415612                                        LR 0.000500    Time 0.117458    
2024-02-26 19:49:28,865 - Epoch: [77][  110/  139]    Overall Loss 0.415768    Objective Loss 0.415768                                        LR 0.000500    Time 0.116319    
2024-02-26 19:49:29,920 - Epoch: [77][  120/  139]    Overall Loss 0.415442    Objective Loss 0.415442                                        LR 0.000500    Time 0.115417    
2024-02-26 19:49:31,041 - Epoch: [77][  130/  139]    Overall Loss 0.415242    Objective Loss 0.415242                                        LR 0.000500    Time 0.115150    
2024-02-26 19:49:36,767 - Epoch: [77][  139/  139]    Overall Loss 0.415941    Objective Loss 0.415941    Top1 95.695788    LR 0.000500    Time 0.148789    
2024-02-26 19:49:37,041 - --- validate (epoch=77)-----------
2024-02-26 19:49:37,042 - 1392 samples (32 per mini-batch)
2024-02-26 19:50:07,704 - Epoch: [77][   10/   44]    Loss 0.516464    Top1 89.998189    
2024-02-26 19:50:37,576 - Epoch: [77][   20/   44]    Loss 0.512555    Top1 90.166204    
2024-02-26 19:51:07,123 - Epoch: [77][   30/   44]    Loss 0.509074    Top1 90.367269    
2024-02-26 19:51:33,064 - Epoch: [77][   40/   44]    Loss 0.509671    Top1 90.337845    
2024-02-26 19:51:42,077 - Epoch: [77][   44/   44]    Loss 0.512678    Top1 90.203173    
2024-02-26 19:51:42,639 - ==> Top1: 90.203    Loss: 0.513

2024-02-26 19:51:42,646 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 19:51:42,647 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:51:42,685 - 

2024-02-26 19:51:42,686 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:51:45,044 - Epoch: [78][   10/  139]    Overall Loss 0.413219    Objective Loss 0.413219                                        LR 0.000500    Time 0.235697    
2024-02-26 19:51:46,228 - Epoch: [78][   20/  139]    Overall Loss 0.411532    Objective Loss 0.411532                                        LR 0.000500    Time 0.177029    
2024-02-26 19:51:47,300 - Epoch: [78][   30/  139]    Overall Loss 0.410723    Objective Loss 0.410723                                        LR 0.000500    Time 0.153721    
2024-02-26 19:51:48,392 - Epoch: [78][   40/  139]    Overall Loss 0.413401    Objective Loss 0.413401                                        LR 0.000500    Time 0.142573    
2024-02-26 19:51:49,480 - Epoch: [78][   50/  139]    Overall Loss 0.413228    Objective Loss 0.413228                                        LR 0.000500    Time 0.135808    
2024-02-26 19:51:50,576 - Epoch: [78][   60/  139]    Overall Loss 0.412248    Objective Loss 0.412248                                        LR 0.000500    Time 0.131433    
2024-02-26 19:51:51,742 - Epoch: [78][   70/  139]    Overall Loss 0.413027    Objective Loss 0.413027                                        LR 0.000500    Time 0.129302    
2024-02-26 19:51:52,834 - Epoch: [78][   80/  139]    Overall Loss 0.414013    Objective Loss 0.414013                                        LR 0.000500    Time 0.126774    
2024-02-26 19:51:53,944 - Epoch: [78][   90/  139]    Overall Loss 0.414465    Objective Loss 0.414465                                        LR 0.000500    Time 0.125022    
2024-02-26 19:51:55,318 - Epoch: [78][  100/  139]    Overall Loss 0.414364    Objective Loss 0.414364                                        LR 0.000500    Time 0.126244    
2024-02-26 19:51:56,732 - Epoch: [78][  110/  139]    Overall Loss 0.414706    Objective Loss 0.414706                                        LR 0.000500    Time 0.127615    
2024-02-26 19:51:57,913 - Epoch: [78][  120/  139]    Overall Loss 0.415349    Objective Loss 0.415349                                        LR 0.000500    Time 0.126822    
2024-02-26 19:51:59,185 - Epoch: [78][  130/  139]    Overall Loss 0.415670    Objective Loss 0.415670                                        LR 0.000500    Time 0.126847    
2024-02-26 19:52:04,792 - Epoch: [78][  139/  139]    Overall Loss 0.416123    Objective Loss 0.416123    Top1 95.564913    LR 0.000500    Time 0.158961    
2024-02-26 19:52:05,147 - --- validate (epoch=78)-----------
2024-02-26 19:52:05,148 - 1392 samples (32 per mini-batch)
2024-02-26 19:52:38,140 - Epoch: [78][   10/   44]    Loss 0.529946    Top1 89.090521    
2024-02-26 19:53:09,302 - Epoch: [78][   20/   44]    Loss 0.526244    Top1 89.331572    
2024-02-26 19:53:41,643 - Epoch: [78][   30/   44]    Loss 0.524342    Top1 89.476530    
2024-02-26 19:54:12,810 - Epoch: [78][   40/   44]    Loss 0.532391    Top1 89.017734    
2024-02-26 19:54:23,262 - Epoch: [78][   44/   44]    Loss 0.533773    Top1 88.896176    
2024-02-26 19:54:23,630 - ==> Top1: 88.896    Loss: 0.534

2024-02-26 19:54:23,639 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 19:54:23,639 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:54:23,673 - 

2024-02-26 19:54:23,673 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:54:25,759 - Epoch: [79][   10/  139]    Overall Loss 0.419276    Objective Loss 0.419276                                        LR 0.000500    Time 0.208446    
2024-02-26 19:54:26,848 - Epoch: [79][   20/  139]    Overall Loss 0.418249    Objective Loss 0.418249                                        LR 0.000500    Time 0.158629    
2024-02-26 19:54:27,995 - Epoch: [79][   30/  139]    Overall Loss 0.416483    Objective Loss 0.416483                                        LR 0.000500    Time 0.143985    
2024-02-26 19:54:29,098 - Epoch: [79][   40/  139]    Overall Loss 0.415890    Objective Loss 0.415890                                        LR 0.000500    Time 0.135552    
2024-02-26 19:54:30,194 - Epoch: [79][   50/  139]    Overall Loss 0.417145    Objective Loss 0.417145                                        LR 0.000500    Time 0.130344    
2024-02-26 19:54:31,355 - Epoch: [79][   60/  139]    Overall Loss 0.418169    Objective Loss 0.418169                                        LR 0.000500    Time 0.127959    
2024-02-26 19:54:32,518 - Epoch: [79][   70/  139]    Overall Loss 0.417429    Objective Loss 0.417429                                        LR 0.000500    Time 0.126273    
2024-02-26 19:54:33,730 - Epoch: [79][   80/  139]    Overall Loss 0.417331    Objective Loss 0.417331                                        LR 0.000500    Time 0.125642    
2024-02-26 19:54:34,848 - Epoch: [79][   90/  139]    Overall Loss 0.417270    Objective Loss 0.417270                                        LR 0.000500    Time 0.124093    
2024-02-26 19:54:35,978 - Epoch: [79][  100/  139]    Overall Loss 0.416923    Objective Loss 0.416923                                        LR 0.000500    Time 0.122976    
2024-02-26 19:54:37,199 - Epoch: [79][  110/  139]    Overall Loss 0.416699    Objective Loss 0.416699                                        LR 0.000500    Time 0.122889    
2024-02-26 19:54:38,302 - Epoch: [79][  120/  139]    Overall Loss 0.416674    Objective Loss 0.416674                                        LR 0.000500    Time 0.121830    
2024-02-26 19:54:39,511 - Epoch: [79][  130/  139]    Overall Loss 0.416994    Objective Loss 0.416994                                        LR 0.000500    Time 0.121756    
2024-02-26 19:54:45,172 - Epoch: [79][  139/  139]    Overall Loss 0.416457    Objective Loss 0.416457    Top1 95.474264    LR 0.000500    Time 0.154590    
2024-02-26 19:54:45,486 - --- validate (epoch=79)-----------
2024-02-26 19:54:45,488 - 1392 samples (32 per mini-batch)
2024-02-26 19:55:17,956 - Epoch: [79][   10/   44]    Loss 0.506913    Top1 90.607048    
2024-02-26 19:55:46,835 - Epoch: [79][   20/   44]    Loss 0.508993    Top1 90.480034    
2024-02-26 19:56:15,453 - Epoch: [79][   30/   44]    Loss 0.513027    Top1 90.238012    
2024-02-26 19:56:43,279 - Epoch: [79][   40/   44]    Loss 0.506475    Top1 90.603364    
2024-02-26 19:56:54,184 - Epoch: [79][   44/   44]    Loss 0.504559    Top1 90.701073    
2024-02-26 19:56:54,424 - ==> Top1: 90.701    Loss: 0.505

2024-02-26 19:56:54,432 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 19:56:54,432 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:56:54,461 - 

2024-02-26 19:56:54,461 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:56:56,459 - Epoch: [80][   10/  139]    Overall Loss 0.412019    Objective Loss 0.412019                                        LR 0.000500    Time 0.199606    
2024-02-26 19:56:57,540 - Epoch: [80][   20/  139]    Overall Loss 0.416176    Objective Loss 0.416176                                        LR 0.000500    Time 0.153828    
2024-02-26 19:56:58,701 - Epoch: [80][   30/  139]    Overall Loss 0.415572    Objective Loss 0.415572                                        LR 0.000500    Time 0.141220    
2024-02-26 19:56:59,816 - Epoch: [80][   40/  139]    Overall Loss 0.413812    Objective Loss 0.413812                                        LR 0.000500    Time 0.133745    
2024-02-26 19:57:00,904 - Epoch: [80][   50/  139]    Overall Loss 0.411946    Objective Loss 0.411946                                        LR 0.000500    Time 0.128740    
2024-02-26 19:57:02,036 - Epoch: [80][   60/  139]    Overall Loss 0.410824    Objective Loss 0.410824                                        LR 0.000500    Time 0.126145    
2024-02-26 19:57:03,155 - Epoch: [80][   70/  139]    Overall Loss 0.410647    Objective Loss 0.410647                                        LR 0.000500    Time 0.124092    
2024-02-26 19:57:04,246 - Epoch: [80][   80/  139]    Overall Loss 0.410671    Objective Loss 0.410671                                        LR 0.000500    Time 0.122219    
2024-02-26 19:57:05,376 - Epoch: [80][   90/  139]    Overall Loss 0.411084    Objective Loss 0.411084                                        LR 0.000500    Time 0.121178    
2024-02-26 19:57:06,481 - Epoch: [80][  100/  139]    Overall Loss 0.411084    Objective Loss 0.411084                                        LR 0.000500    Time 0.120103    
2024-02-26 19:57:07,607 - Epoch: [80][  110/  139]    Overall Loss 0.412293    Objective Loss 0.412293                                        LR 0.000500    Time 0.119419    
2024-02-26 19:57:08,725 - Epoch: [80][  120/  139]    Overall Loss 0.412466    Objective Loss 0.412466                                        LR 0.000500    Time 0.118773    
2024-02-26 19:57:09,818 - Epoch: [80][  130/  139]    Overall Loss 0.412323    Objective Loss 0.412323                                        LR 0.000500    Time 0.118040    
2024-02-26 19:57:15,128 - Epoch: [80][  139/  139]    Overall Loss 0.412265    Objective Loss 0.412265    Top1 96.009209    LR 0.000500    Time 0.148592    
2024-02-26 19:57:15,472 - --- validate (epoch=80)-----------
2024-02-26 19:57:15,472 - 1392 samples (32 per mini-batch)
2024-02-26 19:57:48,919 - Epoch: [80][   10/   44]    Loss 0.518291    Top1 89.878197    
2024-02-26 19:58:20,557 - Epoch: [80][   20/   44]    Loss 0.512165    Top1 90.236723    
2024-02-26 19:58:51,539 - Epoch: [80][   30/   44]    Loss 0.515129    Top1 90.058123    
2024-02-26 19:59:20,942 - Epoch: [80][   40/   44]    Loss 0.512803    Top1 90.196861    
2024-02-26 19:59:31,146 - Epoch: [80][   44/   44]    Loss 0.512062    Top1 90.219468    
2024-02-26 19:59:31,379 - ==> Top1: 90.219    Loss: 0.512

2024-02-26 19:59:31,387 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 19:59:31,387 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 19:59:31,416 - 

2024-02-26 19:59:31,416 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:59:33,764 - Epoch: [81][   10/  139]    Overall Loss 0.404091    Objective Loss 0.404091                                        LR 0.000500    Time 0.234648    
2024-02-26 19:59:34,873 - Epoch: [81][   20/  139]    Overall Loss 0.408405    Objective Loss 0.408405                                        LR 0.000500    Time 0.171904    
2024-02-26 19:59:35,969 - Epoch: [81][   30/  139]    Overall Loss 0.409288    Objective Loss 0.409288                                        LR 0.000500    Time 0.151115    
2024-02-26 19:59:37,042 - Epoch: [81][   40/  139]    Overall Loss 0.411690    Objective Loss 0.411690                                        LR 0.000500    Time 0.140150    
2024-02-26 19:59:38,169 - Epoch: [81][   50/  139]    Overall Loss 0.412310    Objective Loss 0.412310                                        LR 0.000500    Time 0.134642    
2024-02-26 19:59:39,255 - Epoch: [81][   60/  139]    Overall Loss 0.412734    Objective Loss 0.412734                                        LR 0.000500    Time 0.130287    
2024-02-26 19:59:40,391 - Epoch: [81][   70/  139]    Overall Loss 0.412828    Objective Loss 0.412828                                        LR 0.000500    Time 0.127898    
2024-02-26 19:59:41,444 - Epoch: [81][   80/  139]    Overall Loss 0.413078    Objective Loss 0.413078                                        LR 0.000500    Time 0.125067    
2024-02-26 19:59:42,549 - Epoch: [81][   90/  139]    Overall Loss 0.413734    Objective Loss 0.413734                                        LR 0.000500    Time 0.123443    
2024-02-26 19:59:43,709 - Epoch: [81][  100/  139]    Overall Loss 0.415569    Objective Loss 0.415569                                        LR 0.000500    Time 0.122690    
2024-02-26 19:59:44,950 - Epoch: [81][  110/  139]    Overall Loss 0.418149    Objective Loss 0.418149                                        LR 0.000500    Time 0.122813    
2024-02-26 19:59:46,092 - Epoch: [81][  120/  139]    Overall Loss 0.419797    Objective Loss 0.419797                                        LR 0.000500    Time 0.121989    
2024-02-26 19:59:47,326 - Epoch: [81][  130/  139]    Overall Loss 0.420399    Objective Loss 0.420399                                        LR 0.000500    Time 0.122086    
2024-02-26 19:59:52,474 - Epoch: [81][  139/  139]    Overall Loss 0.420405    Objective Loss 0.420405    Top1 95.277997    LR 0.000500    Time 0.151212    
2024-02-26 19:59:52,769 - --- validate (epoch=81)-----------
2024-02-26 19:59:52,770 - 1392 samples (32 per mini-batch)
2024-02-26 20:00:24,235 - Epoch: [81][   10/   44]    Loss 0.512233    Top1 90.277637    
2024-02-26 20:00:53,869 - Epoch: [81][   20/   44]    Loss 0.520370    Top1 89.841383    
2024-02-26 20:01:21,741 - Epoch: [81][   30/   44]    Loss 0.519167    Top1 89.881529    
2024-02-26 20:01:52,824 - Epoch: [81][   40/   44]    Loss 0.518728    Top1 89.913213    
2024-02-26 20:02:03,782 - Epoch: [81][   44/   44]    Loss 0.518931    Top1 89.934264    
2024-02-26 20:02:04,011 - ==> Top1: 89.934    Loss: 0.519

2024-02-26 20:02:04,018 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:02:04,018 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:02:04,049 - 

2024-02-26 20:02:04,049 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:02:06,140 - Epoch: [82][   10/  139]    Overall Loss 0.417705    Objective Loss 0.417705                                        LR 0.000500    Time 0.208913    
2024-02-26 20:02:07,265 - Epoch: [82][   20/  139]    Overall Loss 0.415441    Objective Loss 0.415441                                        LR 0.000500    Time 0.160672    
2024-02-26 20:02:08,355 - Epoch: [82][   30/  139]    Overall Loss 0.413134    Objective Loss 0.413134                                        LR 0.000500    Time 0.143404    
2024-02-26 20:02:09,466 - Epoch: [82][   40/  139]    Overall Loss 0.413129    Objective Loss 0.413129                                        LR 0.000500    Time 0.135310    
2024-02-26 20:02:10,566 - Epoch: [82][   50/  139]    Overall Loss 0.413016    Objective Loss 0.413016                                        LR 0.000500    Time 0.130214    
2024-02-26 20:02:11,764 - Epoch: [82][   60/  139]    Overall Loss 0.413797    Objective Loss 0.413797                                        LR 0.000500    Time 0.128478    
2024-02-26 20:02:12,885 - Epoch: [82][   70/  139]    Overall Loss 0.413915    Objective Loss 0.413915                                        LR 0.000500    Time 0.126129    
2024-02-26 20:02:13,968 - Epoch: [82][   80/  139]    Overall Loss 0.413857    Objective Loss 0.413857                                        LR 0.000500    Time 0.123890    
2024-02-26 20:02:15,106 - Epoch: [82][   90/  139]    Overall Loss 0.413953    Objective Loss 0.413953                                        LR 0.000500    Time 0.122761    
2024-02-26 20:02:16,227 - Epoch: [82][  100/  139]    Overall Loss 0.413583    Objective Loss 0.413583                                        LR 0.000500    Time 0.121687    
2024-02-26 20:02:17,388 - Epoch: [82][  110/  139]    Overall Loss 0.414023    Objective Loss 0.414023                                        LR 0.000500    Time 0.121174    
2024-02-26 20:02:18,510 - Epoch: [82][  120/  139]    Overall Loss 0.413615    Objective Loss 0.413615                                        LR 0.000500    Time 0.120419    
2024-02-26 20:02:19,688 - Epoch: [82][  130/  139]    Overall Loss 0.414066    Objective Loss 0.414066                                        LR 0.000500    Time 0.120212    
2024-02-26 20:02:24,681 - Epoch: [82][  139/  139]    Overall Loss 0.414222    Objective Loss 0.414222    Top1 94.398431    LR 0.000500    Time 0.148342    
2024-02-26 20:02:25,145 - --- validate (epoch=82)-----------
2024-02-26 20:02:25,146 - 1392 samples (32 per mini-batch)
2024-02-26 20:02:57,825 - Epoch: [82][   10/   44]    Loss 0.531121    Top1 89.146529    
2024-02-26 20:03:27,977 - Epoch: [82][   20/   44]    Loss 0.515276    Top1 89.994058    
2024-02-26 20:03:57,230 - Epoch: [82][   30/   44]    Loss 0.507859    Top1 90.408886    
2024-02-26 20:04:21,332 - Epoch: [82][   40/   44]    Loss 0.508239    Top1 90.383862    
2024-02-26 20:04:29,779 - Epoch: [82][   44/   44]    Loss 0.507832    Top1 90.385970    
2024-02-26 20:04:30,146 - ==> Top1: 90.386    Loss: 0.508

2024-02-26 20:04:30,153 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:04:30,154 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:04:30,192 - 

2024-02-26 20:04:30,192 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:04:32,314 - Epoch: [83][   10/  139]    Overall Loss 0.427007    Objective Loss 0.427007                                        LR 0.000500    Time 0.211875    
2024-02-26 20:04:33,389 - Epoch: [83][   20/  139]    Overall Loss 0.425882    Objective Loss 0.425882                                        LR 0.000500    Time 0.159682    
2024-02-26 20:04:34,541 - Epoch: [83][   30/  139]    Overall Loss 0.423514    Objective Loss 0.423514                                        LR 0.000500    Time 0.144841    
2024-02-26 20:04:35,675 - Epoch: [83][   40/  139]    Overall Loss 0.423648    Objective Loss 0.423648                                        LR 0.000500    Time 0.136965    
2024-02-26 20:04:36,801 - Epoch: [83][   50/  139]    Overall Loss 0.423424    Objective Loss 0.423424                                        LR 0.000500    Time 0.132065    
2024-02-26 20:04:37,952 - Epoch: [83][   60/  139]    Overall Loss 0.423938    Objective Loss 0.423938                                        LR 0.000500    Time 0.129229    
2024-02-26 20:04:39,144 - Epoch: [83][   70/  139]    Overall Loss 0.422996    Objective Loss 0.422996                                        LR 0.000500    Time 0.127793    
2024-02-26 20:04:40,300 - Epoch: [83][   80/  139]    Overall Loss 0.422803    Objective Loss 0.422803                                        LR 0.000500    Time 0.126263    
2024-02-26 20:04:41,417 - Epoch: [83][   90/  139]    Overall Loss 0.421546    Objective Loss 0.421546                                        LR 0.000500    Time 0.124632    
2024-02-26 20:04:42,613 - Epoch: [83][  100/  139]    Overall Loss 0.420464    Objective Loss 0.420464                                        LR 0.000500    Time 0.124130    
2024-02-26 20:04:43,739 - Epoch: [83][  110/  139]    Overall Loss 0.420066    Objective Loss 0.420066                                        LR 0.000500    Time 0.123072    
2024-02-26 20:04:44,804 - Epoch: [83][  120/  139]    Overall Loss 0.419036    Objective Loss 0.419036                                        LR 0.000500    Time 0.121683    
2024-02-26 20:04:46,019 - Epoch: [83][  130/  139]    Overall Loss 0.418362    Objective Loss 0.418362                                        LR 0.000500    Time 0.121670    
2024-02-26 20:04:51,012 - Epoch: [83][  139/  139]    Overall Loss 0.417903    Objective Loss 0.417903    Top1 96.082634    LR 0.000500    Time 0.149709    
2024-02-26 20:04:51,356 - --- validate (epoch=83)-----------
2024-02-26 20:04:51,357 - 1392 samples (32 per mini-batch)
2024-02-26 20:05:18,946 - Epoch: [83][   10/   44]    Loss 0.517957    Top1 89.797492    
2024-02-26 20:05:48,954 - Epoch: [83][   20/   44]    Loss 0.508649    Top1 90.303713    
2024-02-26 20:06:20,467 - Epoch: [83][   30/   44]    Loss 0.506808    Top1 90.437320    
2024-02-26 20:06:52,553 - Epoch: [83][   40/   44]    Loss 0.506835    Top1 90.441628    
2024-02-26 20:07:03,598 - Epoch: [83][   44/   44]    Loss 0.506761    Top1 90.475970    
2024-02-26 20:07:03,930 - ==> Top1: 90.476    Loss: 0.507

2024-02-26 20:07:03,938 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:07:03,938 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:07:03,968 - 

2024-02-26 20:07:03,968 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:07:05,985 - Epoch: [84][   10/  139]    Overall Loss 0.406167    Objective Loss 0.406167                                        LR 0.000500    Time 0.201457    
2024-02-26 20:07:07,097 - Epoch: [84][   20/  139]    Overall Loss 0.412292    Objective Loss 0.412292                                        LR 0.000500    Time 0.156312    
2024-02-26 20:07:08,181 - Epoch: [84][   30/  139]    Overall Loss 0.411636    Objective Loss 0.411636                                        LR 0.000500    Time 0.140294    
2024-02-26 20:07:09,241 - Epoch: [84][   40/  139]    Overall Loss 0.411878    Objective Loss 0.411878                                        LR 0.000500    Time 0.131705    
2024-02-26 20:07:10,298 - Epoch: [84][   50/  139]    Overall Loss 0.412607    Objective Loss 0.412607                                        LR 0.000500    Time 0.126504    
2024-02-26 20:07:11,459 - Epoch: [84][   60/  139]    Overall Loss 0.412428    Objective Loss 0.412428                                        LR 0.000500    Time 0.124749    
2024-02-26 20:07:12,575 - Epoch: [84][   70/  139]    Overall Loss 0.412131    Objective Loss 0.412131                                        LR 0.000500    Time 0.122853    
2024-02-26 20:07:13,715 - Epoch: [84][   80/  139]    Overall Loss 0.412110    Objective Loss 0.412110                                        LR 0.000500    Time 0.121738    
2024-02-26 20:07:14,870 - Epoch: [84][   90/  139]    Overall Loss 0.411920    Objective Loss 0.411920                                        LR 0.000500    Time 0.121037    
2024-02-26 20:07:15,944 - Epoch: [84][  100/  139]    Overall Loss 0.412240    Objective Loss 0.412240                                        LR 0.000500    Time 0.119674    
2024-02-26 20:07:17,058 - Epoch: [84][  110/  139]    Overall Loss 0.412236    Objective Loss 0.412236                                        LR 0.000500    Time 0.118788    
2024-02-26 20:07:18,152 - Epoch: [84][  120/  139]    Overall Loss 0.412216    Objective Loss 0.412216                                        LR 0.000500    Time 0.118007    
2024-02-26 20:07:19,261 - Epoch: [84][  130/  139]    Overall Loss 0.412199    Objective Loss 0.412199                                        LR 0.000500    Time 0.117455    
2024-02-26 20:07:24,436 - Epoch: [84][  139/  139]    Overall Loss 0.413038    Objective Loss 0.413038    Top1 94.897864    LR 0.000500    Time 0.147074    
2024-02-26 20:07:24,727 - --- validate (epoch=84)-----------
2024-02-26 20:07:24,728 - 1392 samples (32 per mini-batch)
2024-02-26 20:07:54,928 - Epoch: [84][   10/   44]    Loss 0.521591    Top1 89.470813    
2024-02-26 20:08:22,253 - Epoch: [84][   20/   44]    Loss 0.523315    Top1 89.381104    
2024-02-26 20:08:46,590 - Epoch: [84][   30/   44]    Loss 0.519614    Top1 89.600805    
2024-02-26 20:09:09,423 - Epoch: [84][   40/   44]    Loss 0.515550    Top1 89.808830    
2024-02-26 20:09:17,140 - Epoch: [84][   44/   44]    Loss 0.513932    Top1 89.871846    
2024-02-26 20:09:17,514 - ==> Top1: 89.872    Loss: 0.514

2024-02-26 20:09:17,520 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:09:17,521 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:09:17,553 - 

2024-02-26 20:09:17,553 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:09:19,509 - Epoch: [85][   10/  139]    Overall Loss 0.412395    Objective Loss 0.412395                                        LR 0.000500    Time 0.195464    
2024-02-26 20:09:20,619 - Epoch: [85][   20/  139]    Overall Loss 0.416205    Objective Loss 0.416205                                        LR 0.000500    Time 0.153206    
2024-02-26 20:09:21,766 - Epoch: [85][   30/  139]    Overall Loss 0.413749    Objective Loss 0.413749                                        LR 0.000500    Time 0.140353    
2024-02-26 20:09:22,816 - Epoch: [85][   40/  139]    Overall Loss 0.414805    Objective Loss 0.414805                                        LR 0.000500    Time 0.131500    
2024-02-26 20:09:23,899 - Epoch: [85][   50/  139]    Overall Loss 0.415509    Objective Loss 0.415509                                        LR 0.000500    Time 0.126853    
2024-02-26 20:09:24,990 - Epoch: [85][   60/  139]    Overall Loss 0.414213    Objective Loss 0.414213                                        LR 0.000500    Time 0.123871    
2024-02-26 20:09:26,122 - Epoch: [85][   70/  139]    Overall Loss 0.414539    Objective Loss 0.414539                                        LR 0.000500    Time 0.122341    
2024-02-26 20:09:27,354 - Epoch: [85][   80/  139]    Overall Loss 0.414061    Objective Loss 0.414061                                        LR 0.000500    Time 0.122445    
2024-02-26 20:09:28,644 - Epoch: [85][   90/  139]    Overall Loss 0.413923    Objective Loss 0.413923                                        LR 0.000500    Time 0.123170    
2024-02-26 20:09:29,747 - Epoch: [85][  100/  139]    Overall Loss 0.413790    Objective Loss 0.413790                                        LR 0.000500    Time 0.121875    
2024-02-26 20:09:31,065 - Epoch: [85][  110/  139]    Overall Loss 0.414012    Objective Loss 0.414012                                        LR 0.000500    Time 0.122769    
2024-02-26 20:09:32,311 - Epoch: [85][  120/  139]    Overall Loss 0.413745    Objective Loss 0.413745                                        LR 0.000500    Time 0.122918    
2024-02-26 20:09:33,447 - Epoch: [85][  130/  139]    Overall Loss 0.413087    Objective Loss 0.413087                                        LR 0.000500    Time 0.122197    
2024-02-26 20:09:38,745 - Epoch: [85][  139/  139]    Overall Loss 0.412835    Objective Loss 0.412835    Top1 96.390626    LR 0.000500    Time 0.152399    
2024-02-26 20:09:39,157 - --- validate (epoch=85)-----------
2024-02-26 20:09:39,157 - 1392 samples (32 per mini-batch)
2024-02-26 20:10:11,260 - Epoch: [85][   10/   44]    Loss 0.499513    Top1 91.008931    
2024-02-26 20:10:42,676 - Epoch: [85][   20/   44]    Loss 0.506892    Top1 90.572666    
2024-02-26 20:11:14,851 - Epoch: [85][   30/   44]    Loss 0.503547    Top1 90.739524    
2024-02-26 20:11:45,654 - Epoch: [85][   40/   44]    Loss 0.501919    Top1 90.823189    
2024-02-26 20:11:55,738 - Epoch: [85][   44/   44]    Loss 0.501171    Top1 90.868152    
2024-02-26 20:11:55,975 - ==> Top1: 90.868    Loss: 0.501

2024-02-26 20:11:55,982 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:11:55,982 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:11:56,018 - 

2024-02-26 20:11:56,019 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:11:58,587 - Epoch: [86][   10/  139]    Overall Loss 0.406030    Objective Loss 0.406030                                        LR 0.000500    Time 0.256558    
2024-02-26 20:11:59,868 - Epoch: [86][   20/  139]    Overall Loss 0.409322    Objective Loss 0.409322                                        LR 0.000500    Time 0.192310    
2024-02-26 20:12:01,024 - Epoch: [86][   30/  139]    Overall Loss 0.409705    Objective Loss 0.409705                                        LR 0.000500    Time 0.166698    
2024-02-26 20:12:02,270 - Epoch: [86][   40/  139]    Overall Loss 0.410278    Objective Loss 0.410278                                        LR 0.000500    Time 0.156143    
2024-02-26 20:12:03,314 - Epoch: [86][   50/  139]    Overall Loss 0.411218    Objective Loss 0.411218                                        LR 0.000500    Time 0.145789    
2024-02-26 20:12:04,444 - Epoch: [86][   60/  139]    Overall Loss 0.410270    Objective Loss 0.410270                                        LR 0.000500    Time 0.140319    
2024-02-26 20:12:05,652 - Epoch: [86][   70/  139]    Overall Loss 0.409489    Objective Loss 0.409489                                        LR 0.000500    Time 0.137523    
2024-02-26 20:12:06,807 - Epoch: [86][   80/  139]    Overall Loss 0.410320    Objective Loss 0.410320                                        LR 0.000500    Time 0.134761    
2024-02-26 20:12:07,923 - Epoch: [86][   90/  139]    Overall Loss 0.410385    Objective Loss 0.410385                                        LR 0.000500    Time 0.132178    
2024-02-26 20:12:09,058 - Epoch: [86][  100/  139]    Overall Loss 0.410193    Objective Loss 0.410193                                        LR 0.000500    Time 0.130301    
2024-02-26 20:12:10,198 - Epoch: [86][  110/  139]    Overall Loss 0.410199    Objective Loss 0.410199                                        LR 0.000500    Time 0.128817    
2024-02-26 20:12:11,374 - Epoch: [86][  120/  139]    Overall Loss 0.410364    Objective Loss 0.410364                                        LR 0.000500    Time 0.127615    
2024-02-26 20:12:12,505 - Epoch: [86][  130/  139]    Overall Loss 0.410455    Objective Loss 0.410455                                        LR 0.000500    Time 0.126495    
2024-02-26 20:12:17,589 - Epoch: [86][  139/  139]    Overall Loss 0.410058    Objective Loss 0.410058    Top1 96.598760    LR 0.000500    Time 0.154876    
2024-02-26 20:12:18,012 - --- validate (epoch=86)-----------
2024-02-26 20:12:18,013 - 1392 samples (32 per mini-batch)
2024-02-26 20:12:46,867 - Epoch: [86][   10/   44]    Loss 0.504559    Top1 90.731231    
2024-02-26 20:13:11,999 - Epoch: [86][   20/   44]    Loss 0.501164    Top1 90.952700    
2024-02-26 20:13:38,461 - Epoch: [86][   30/   44]    Loss 0.501810    Top1 90.903530    
2024-02-26 20:14:03,741 - Epoch: [86][   40/   44]    Loss 0.502095    Top1 90.896888    
2024-02-26 20:14:13,324 - Epoch: [86][   44/   44]    Loss 0.503313    Top1 90.819643    
2024-02-26 20:14:13,559 - ==> Top1: 90.820    Loss: 0.503

2024-02-26 20:14:13,567 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:14:13,567 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:14:13,597 - 

2024-02-26 20:14:13,598 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:14:15,590 - Epoch: [87][   10/  139]    Overall Loss 0.409990    Objective Loss 0.409990                                        LR 0.000500    Time 0.199086    
2024-02-26 20:14:16,713 - Epoch: [87][   20/  139]    Overall Loss 0.413024    Objective Loss 0.413024                                        LR 0.000500    Time 0.155636    
2024-02-26 20:14:17,803 - Epoch: [87][   30/  139]    Overall Loss 0.410917    Objective Loss 0.410917                                        LR 0.000500    Time 0.140074    
2024-02-26 20:14:18,995 - Epoch: [87][   40/  139]    Overall Loss 0.411003    Objective Loss 0.411003                                        LR 0.000500    Time 0.134847    
2024-02-26 20:14:20,083 - Epoch: [87][   50/  139]    Overall Loss 0.410605    Objective Loss 0.410605                                        LR 0.000500    Time 0.129616    
2024-02-26 20:14:21,201 - Epoch: [87][   60/  139]    Overall Loss 0.409735    Objective Loss 0.409735                                        LR 0.000500    Time 0.126634    
2024-02-26 20:14:22,266 - Epoch: [87][   70/  139]    Overall Loss 0.410408    Objective Loss 0.410408                                        LR 0.000500    Time 0.123739    
2024-02-26 20:14:23,367 - Epoch: [87][   80/  139]    Overall Loss 0.411141    Objective Loss 0.411141                                        LR 0.000500    Time 0.122030    
2024-02-26 20:14:24,415 - Epoch: [87][   90/  139]    Overall Loss 0.410804    Objective Loss 0.410804                                        LR 0.000500    Time 0.120101    
2024-02-26 20:14:25,481 - Epoch: [87][  100/  139]    Overall Loss 0.410364    Objective Loss 0.410364                                        LR 0.000500    Time 0.118747    
2024-02-26 20:14:26,557 - Epoch: [87][  110/  139]    Overall Loss 0.410553    Objective Loss 0.410553                                        LR 0.000500    Time 0.117730    
2024-02-26 20:14:27,684 - Epoch: [87][  120/  139]    Overall Loss 0.411032    Objective Loss 0.411032                                        LR 0.000500    Time 0.117303    
2024-02-26 20:14:28,803 - Epoch: [87][  130/  139]    Overall Loss 0.411514    Objective Loss 0.411514                                        LR 0.000500    Time 0.116883    
2024-02-26 20:14:33,933 - Epoch: [87][  139/  139]    Overall Loss 0.411125    Objective Loss 0.411125    Top1 96.355610    LR 0.000500    Time 0.146214    
2024-02-26 20:14:34,184 - --- validate (epoch=87)-----------
2024-02-26 20:14:34,185 - 1392 samples (32 per mini-batch)
2024-02-26 20:15:07,145 - Epoch: [87][   10/   44]    Loss 0.503315    Top1 90.798410    
2024-02-26 20:15:39,061 - Epoch: [87][   20/   44]    Loss 0.506427    Top1 90.623760    
2024-02-26 20:16:09,933 - Epoch: [87][   30/   44]    Loss 0.506652    Top1 90.581969    
2024-02-26 20:16:36,116 - Epoch: [87][   40/   44]    Loss 0.503095    Top1 90.767022    
2024-02-26 20:16:45,174 - Epoch: [87][   44/   44]    Loss 0.501253    Top1 90.849241    
2024-02-26 20:16:45,420 - ==> Top1: 90.849    Loss: 0.501

2024-02-26 20:16:45,427 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:16:45,427 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:16:45,458 - 

2024-02-26 20:16:45,458 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:16:47,605 - Epoch: [88][   10/  139]    Overall Loss 0.405807    Objective Loss 0.405807                                        LR 0.000500    Time 0.214579    
2024-02-26 20:16:48,771 - Epoch: [88][   20/  139]    Overall Loss 0.405843    Objective Loss 0.405843                                        LR 0.000500    Time 0.165496    
2024-02-26 20:16:49,864 - Epoch: [88][   30/  139]    Overall Loss 0.405464    Objective Loss 0.405464                                        LR 0.000500    Time 0.146778    
2024-02-26 20:16:51,015 - Epoch: [88][   40/  139]    Overall Loss 0.405509    Objective Loss 0.405509                                        LR 0.000500    Time 0.138823    
2024-02-26 20:16:52,068 - Epoch: [88][   50/  139]    Overall Loss 0.406909    Objective Loss 0.406909                                        LR 0.000500    Time 0.132105    
2024-02-26 20:16:53,198 - Epoch: [88][   60/  139]    Overall Loss 0.407201    Objective Loss 0.407201                                        LR 0.000500    Time 0.128916    
2024-02-26 20:16:54,344 - Epoch: [88][   70/  139]    Overall Loss 0.407261    Objective Loss 0.407261                                        LR 0.000500    Time 0.126868    
2024-02-26 20:16:55,552 - Epoch: [88][   80/  139]    Overall Loss 0.408258    Objective Loss 0.408258                                        LR 0.000500    Time 0.126091    
2024-02-26 20:16:56,687 - Epoch: [88][   90/  139]    Overall Loss 0.409001    Objective Loss 0.409001                                        LR 0.000500    Time 0.124685    
2024-02-26 20:16:57,889 - Epoch: [88][  100/  139]    Overall Loss 0.410245    Objective Loss 0.410245                                        LR 0.000500    Time 0.124228    
2024-02-26 20:16:59,171 - Epoch: [88][  110/  139]    Overall Loss 0.410119    Objective Loss 0.410119                                        LR 0.000500    Time 0.124580    
2024-02-26 20:17:00,361 - Epoch: [88][  120/  139]    Overall Loss 0.410311    Objective Loss 0.410311                                        LR 0.000500    Time 0.124114    
2024-02-26 20:17:01,594 - Epoch: [88][  130/  139]    Overall Loss 0.410565    Objective Loss 0.410565                                        LR 0.000500    Time 0.124046    
2024-02-26 20:17:06,783 - Epoch: [88][  139/  139]    Overall Loss 0.411036    Objective Loss 0.411036    Top1 95.583806    LR 0.000500    Time 0.153342    
2024-02-26 20:17:07,110 - --- validate (epoch=88)-----------
2024-02-26 20:17:07,111 - 1392 samples (32 per mini-batch)
2024-02-26 20:17:38,093 - Epoch: [88][   10/   44]    Loss 0.509665    Top1 90.433065    
2024-02-26 20:18:06,662 - Epoch: [88][   20/   44]    Loss 0.507936    Top1 90.485005    
2024-02-26 20:18:35,159 - Epoch: [88][   30/   44]    Loss 0.510093    Top1 90.305628    
2024-02-26 20:19:06,800 - Epoch: [88][   40/   44]    Loss 0.508470    Top1 90.389372    
2024-02-26 20:19:18,350 - Epoch: [88][   44/   44]    Loss 0.507882    Top1 90.416854    
2024-02-26 20:19:18,571 - ==> Top1: 90.417    Loss: 0.508

2024-02-26 20:19:18,578 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:19:18,578 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:19:18,607 - 

2024-02-26 20:19:18,608 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:19:20,696 - Epoch: [89][   10/  139]    Overall Loss 0.413029    Objective Loss 0.413029                                        LR 0.000500    Time 0.208647    
2024-02-26 20:19:21,797 - Epoch: [89][   20/  139]    Overall Loss 0.411408    Objective Loss 0.411408                                        LR 0.000500    Time 0.159299    
2024-02-26 20:19:22,894 - Epoch: [89][   30/  139]    Overall Loss 0.412126    Objective Loss 0.412126                                        LR 0.000500    Time 0.142749    
2024-02-26 20:19:23,995 - Epoch: [89][   40/  139]    Overall Loss 0.411402    Objective Loss 0.411402                                        LR 0.000500    Time 0.134551    
2024-02-26 20:19:25,091 - Epoch: [89][   50/  139]    Overall Loss 0.412178    Objective Loss 0.412178                                        LR 0.000500    Time 0.129543    
2024-02-26 20:19:26,179 - Epoch: [89][   60/  139]    Overall Loss 0.412828    Objective Loss 0.412828                                        LR 0.000500    Time 0.126074    
2024-02-26 20:19:27,229 - Epoch: [89][   70/  139]    Overall Loss 0.413375    Objective Loss 0.413375                                        LR 0.000500    Time 0.123062    
2024-02-26 20:19:28,333 - Epoch: [89][   80/  139]    Overall Loss 0.413048    Objective Loss 0.413048                                        LR 0.000500    Time 0.121468    
2024-02-26 20:19:29,424 - Epoch: [89][   90/  139]    Overall Loss 0.412609    Objective Loss 0.412609                                        LR 0.000500    Time 0.120082    
2024-02-26 20:19:30,535 - Epoch: [89][  100/  139]    Overall Loss 0.412355    Objective Loss 0.412355                                        LR 0.000500    Time 0.119172    
2024-02-26 20:19:31,610 - Epoch: [89][  110/  139]    Overall Loss 0.411877    Objective Loss 0.411877                                        LR 0.000500    Time 0.118102    
2024-02-26 20:19:32,722 - Epoch: [89][  120/  139]    Overall Loss 0.411860    Objective Loss 0.411860                                        LR 0.000500    Time 0.117517    
2024-02-26 20:19:33,825 - Epoch: [89][  130/  139]    Overall Loss 0.411573    Objective Loss 0.411573                                        LR 0.000500    Time 0.116957    
2024-02-26 20:19:39,528 - Epoch: [89][  139/  139]    Overall Loss 0.411461    Objective Loss 0.411461    Top1 94.914575    LR 0.000500    Time 0.150409    
2024-02-26 20:19:39,802 - --- validate (epoch=89)-----------
2024-02-26 20:19:39,802 - 1392 samples (32 per mini-batch)
2024-02-26 20:20:12,078 - Epoch: [89][   10/   44]    Loss 0.498690    Top1 91.107929    
2024-02-26 20:20:42,496 - Epoch: [89][   20/   44]    Loss 0.506896    Top1 90.613592    
2024-02-26 20:21:11,173 - Epoch: [89][   30/   44]    Loss 0.507899    Top1 90.536898    
2024-02-26 20:21:37,472 - Epoch: [89][   40/   44]    Loss 0.506124    Top1 90.641030    
2024-02-26 20:21:47,345 - Epoch: [89][   44/   44]    Loss 0.507941    Top1 90.575611    
2024-02-26 20:21:47,648 - ==> Top1: 90.576    Loss: 0.508

2024-02-26 20:21:47,655 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:21:47,655 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:21:47,692 - 

2024-02-26 20:21:47,693 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:21:49,738 - Epoch: [90][   10/  139]    Overall Loss 0.425839    Objective Loss 0.425839                                        LR 0.000500    Time 0.204287    
2024-02-26 20:21:50,851 - Epoch: [90][   20/  139]    Overall Loss 0.423203    Objective Loss 0.423203                                        LR 0.000500    Time 0.157715    
2024-02-26 20:21:51,934 - Epoch: [90][   30/  139]    Overall Loss 0.420373    Objective Loss 0.420373                                        LR 0.000500    Time 0.141226    
2024-02-26 20:21:53,032 - Epoch: [90][   40/  139]    Overall Loss 0.416895    Objective Loss 0.416895                                        LR 0.000500    Time 0.133367    
2024-02-26 20:21:54,128 - Epoch: [90][   50/  139]    Overall Loss 0.416685    Objective Loss 0.416685                                        LR 0.000500    Time 0.128603    
2024-02-26 20:21:55,234 - Epoch: [90][   60/  139]    Overall Loss 0.416230    Objective Loss 0.416230                                        LR 0.000500    Time 0.125595    
2024-02-26 20:21:56,351 - Epoch: [90][   70/  139]    Overall Loss 0.416574    Objective Loss 0.416574                                        LR 0.000500    Time 0.123598    
2024-02-26 20:21:57,463 - Epoch: [90][   80/  139]    Overall Loss 0.415592    Objective Loss 0.415592                                        LR 0.000500    Time 0.122044    
2024-02-26 20:21:58,661 - Epoch: [90][   90/  139]    Overall Loss 0.415432    Objective Loss 0.415432                                        LR 0.000500    Time 0.121783    
2024-02-26 20:21:59,947 - Epoch: [90][  100/  139]    Overall Loss 0.414365    Objective Loss 0.414365                                        LR 0.000500    Time 0.122460    
2024-02-26 20:22:01,069 - Epoch: [90][  110/  139]    Overall Loss 0.413655    Objective Loss 0.413655                                        LR 0.000500    Time 0.121524    
2024-02-26 20:22:02,220 - Epoch: [90][  120/  139]    Overall Loss 0.413147    Objective Loss 0.413147                                        LR 0.000500    Time 0.120984    
2024-02-26 20:22:03,386 - Epoch: [90][  130/  139]    Overall Loss 0.412343    Objective Loss 0.412343                                        LR 0.000500    Time 0.120640    
2024-02-26 20:22:08,898 - Epoch: [90][  139/  139]    Overall Loss 0.411916    Objective Loss 0.411916    Top1 96.752728    LR 0.000500    Time 0.152481    
2024-02-26 20:22:09,315 - --- validate (epoch=90)-----------
2024-02-26 20:22:09,316 - 1392 samples (32 per mini-batch)
2024-02-26 20:22:41,041 - Epoch: [90][   10/   44]    Loss 0.505181    Top1 90.740979    
2024-02-26 20:23:08,727 - Epoch: [90][   20/   44]    Loss 0.502434    Top1 90.875258    
2024-02-26 20:23:40,716 - Epoch: [90][   30/   44]    Loss 0.501975    Top1 90.892063    
2024-02-26 20:24:13,138 - Epoch: [90][   40/   44]    Loss 0.500810    Top1 90.968332    
2024-02-26 20:24:24,422 - Epoch: [90][   44/   44]    Loss 0.502191    Top1 90.956326    
2024-02-26 20:24:24,643 - ==> Top1: 90.956    Loss: 0.502

2024-02-26 20:24:24,649 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:24:24,650 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:24:24,681 - 

2024-02-26 20:24:24,681 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:24:26,646 - Epoch: [91][   10/  139]    Overall Loss 0.405078    Objective Loss 0.405078                                        LR 0.000500    Time 0.196344    
2024-02-26 20:24:27,744 - Epoch: [91][   20/  139]    Overall Loss 0.408055    Objective Loss 0.408055                                        LR 0.000500    Time 0.153009    
2024-02-26 20:24:28,824 - Epoch: [91][   30/  139]    Overall Loss 0.408691    Objective Loss 0.408691                                        LR 0.000500    Time 0.137989    
2024-02-26 20:24:29,936 - Epoch: [91][   40/  139]    Overall Loss 0.408026    Objective Loss 0.408026                                        LR 0.000500    Time 0.131259    
2024-02-26 20:24:31,039 - Epoch: [91][   50/  139]    Overall Loss 0.408501    Objective Loss 0.408501                                        LR 0.000500    Time 0.127058    
2024-02-26 20:24:32,129 - Epoch: [91][   60/  139]    Overall Loss 0.408226    Objective Loss 0.408226                                        LR 0.000500    Time 0.124021    
2024-02-26 20:24:33,232 - Epoch: [91][   70/  139]    Overall Loss 0.407620    Objective Loss 0.407620                                        LR 0.000500    Time 0.122057    
2024-02-26 20:24:34,361 - Epoch: [91][   80/  139]    Overall Loss 0.407839    Objective Loss 0.407839                                        LR 0.000500    Time 0.120893    
2024-02-26 20:24:35,466 - Epoch: [91][   90/  139]    Overall Loss 0.407831    Objective Loss 0.407831                                        LR 0.000500    Time 0.119735    
2024-02-26 20:24:36,569 - Epoch: [91][  100/  139]    Overall Loss 0.407788    Objective Loss 0.407788                                        LR 0.000500    Time 0.118782    
2024-02-26 20:24:37,673 - Epoch: [91][  110/  139]    Overall Loss 0.407651    Objective Loss 0.407651                                        LR 0.000500    Time 0.118002    
2024-02-26 20:24:38,776 - Epoch: [91][  120/  139]    Overall Loss 0.407780    Objective Loss 0.407780                                        LR 0.000500    Time 0.117356    
2024-02-26 20:24:39,872 - Epoch: [91][  130/  139]    Overall Loss 0.408077    Objective Loss 0.408077                                        LR 0.000500    Time 0.116754    
2024-02-26 20:24:45,212 - Epoch: [91][  139/  139]    Overall Loss 0.408042    Objective Loss 0.408042    Top1 96.079626    LR 0.000500    Time 0.147603    
2024-02-26 20:24:45,473 - --- validate (epoch=91)-----------
2024-02-26 20:24:45,474 - 1392 samples (32 per mini-batch)
2024-02-26 20:25:14,350 - Epoch: [91][   10/   44]    Loss 0.506452    Top1 90.676635    
2024-02-26 20:25:39,397 - Epoch: [91][   20/   44]    Loss 0.503897    Top1 90.779234    
2024-02-26 20:26:03,832 - Epoch: [91][   30/   44]    Loss 0.502052    Top1 90.868703    
2024-02-26 20:26:28,691 - Epoch: [91][   40/   44]    Loss 0.505192    Top1 90.690132    
2024-02-26 20:26:36,996 - Epoch: [91][   44/   44]    Loss 0.505392    Top1 90.693284    
2024-02-26 20:26:37,360 - ==> Top1: 90.693    Loss: 0.505

2024-02-26 20:26:37,367 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:26:37,368 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:26:37,404 - 

2024-02-26 20:26:37,404 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:26:39,490 - Epoch: [92][   10/  139]    Overall Loss 0.410308    Objective Loss 0.410308                                        LR 0.000500    Time 0.208243    
2024-02-26 20:26:40,651 - Epoch: [92][   20/  139]    Overall Loss 0.406953    Objective Loss 0.406953                                        LR 0.000500    Time 0.162137    
2024-02-26 20:26:41,735 - Epoch: [92][   30/  139]    Overall Loss 0.407749    Objective Loss 0.407749                                        LR 0.000500    Time 0.144192    
2024-02-26 20:26:42,861 - Epoch: [92][   40/  139]    Overall Loss 0.408419    Objective Loss 0.408419                                        LR 0.000500    Time 0.136269    
2024-02-26 20:26:43,975 - Epoch: [92][   50/  139]    Overall Loss 0.406757    Objective Loss 0.406757                                        LR 0.000500    Time 0.131282    
2024-02-26 20:26:45,117 - Epoch: [92][   60/  139]    Overall Loss 0.406117    Objective Loss 0.406117                                        LR 0.000500    Time 0.128421    
2024-02-26 20:26:46,251 - Epoch: [92][   70/  139]    Overall Loss 0.406322    Objective Loss 0.406322                                        LR 0.000500    Time 0.126273    
2024-02-26 20:26:47,427 - Epoch: [92][   80/  139]    Overall Loss 0.406653    Objective Loss 0.406653                                        LR 0.000500    Time 0.125179    
2024-02-26 20:26:48,560 - Epoch: [92][   90/  139]    Overall Loss 0.406463    Objective Loss 0.406463                                        LR 0.000500    Time 0.123851    
2024-02-26 20:26:49,661 - Epoch: [92][  100/  139]    Overall Loss 0.406787    Objective Loss 0.406787                                        LR 0.000500    Time 0.122327    
2024-02-26 20:26:50,831 - Epoch: [92][  110/  139]    Overall Loss 0.407130    Objective Loss 0.407130                                        LR 0.000500    Time 0.121838    
2024-02-26 20:26:51,988 - Epoch: [92][  120/  139]    Overall Loss 0.409444    Objective Loss 0.409444                                        LR 0.000500    Time 0.121323    
2024-02-26 20:26:53,153 - Epoch: [92][  130/  139]    Overall Loss 0.410851    Objective Loss 0.410851                                        LR 0.000500    Time 0.120940    
2024-02-26 20:26:58,648 - Epoch: [92][  139/  139]    Overall Loss 0.411544    Objective Loss 0.411544    Top1 94.728709    LR 0.000500    Time 0.152642    
2024-02-26 20:26:59,068 - --- validate (epoch=92)-----------
2024-02-26 20:26:59,070 - 1392 samples (32 per mini-batch)
2024-02-26 20:27:30,808 - Epoch: [92][   10/   44]    Loss 0.530592    Top1 89.065743    
2024-02-26 20:28:02,811 - Epoch: [92][   20/   44]    Loss 0.533543    Top1 88.904375    
2024-02-26 20:28:34,900 - Epoch: [92][   30/   44]    Loss 0.530488    Top1 89.060455    
2024-02-26 20:29:06,475 - Epoch: [92][   40/   44]    Loss 0.527173    Top1 89.247995    
2024-02-26 20:29:17,729 - Epoch: [92][   44/   44]    Loss 0.528643    Top1 89.183966    
2024-02-26 20:29:18,160 - ==> Top1: 89.184    Loss: 0.529

2024-02-26 20:29:18,169 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:29:18,169 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:29:18,205 - 

2024-02-26 20:29:18,206 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:29:20,245 - Epoch: [93][   10/  139]    Overall Loss 0.420638    Objective Loss 0.420638                                        LR 0.000500    Time 0.203781    
2024-02-26 20:29:21,314 - Epoch: [93][   20/  139]    Overall Loss 0.417853    Objective Loss 0.417853                                        LR 0.000500    Time 0.155275    
2024-02-26 20:29:22,410 - Epoch: [93][   30/  139]    Overall Loss 0.415440    Objective Loss 0.415440                                        LR 0.000500    Time 0.140035    
2024-02-26 20:29:23,469 - Epoch: [93][   40/  139]    Overall Loss 0.415122    Objective Loss 0.415122                                        LR 0.000500    Time 0.131505    
2024-02-26 20:29:24,590 - Epoch: [93][   50/  139]    Overall Loss 0.413380    Objective Loss 0.413380                                        LR 0.000500    Time 0.127616    
2024-02-26 20:29:25,740 - Epoch: [93][   60/  139]    Overall Loss 0.412758    Objective Loss 0.412758                                        LR 0.000500    Time 0.125496    
2024-02-26 20:29:26,939 - Epoch: [93][   70/  139]    Overall Loss 0.411917    Objective Loss 0.411917                                        LR 0.000500    Time 0.124691    
2024-02-26 20:29:28,059 - Epoch: [93][   80/  139]    Overall Loss 0.411074    Objective Loss 0.411074                                        LR 0.000500    Time 0.123090    
2024-02-26 20:29:29,320 - Epoch: [93][   90/  139]    Overall Loss 0.410559    Objective Loss 0.410559                                        LR 0.000500    Time 0.123263    
2024-02-26 20:29:30,451 - Epoch: [93][  100/  139]    Overall Loss 0.410370    Objective Loss 0.410370                                        LR 0.000500    Time 0.122248    
2024-02-26 20:29:31,638 - Epoch: [93][  110/  139]    Overall Loss 0.410001    Objective Loss 0.410001                                        LR 0.000500    Time 0.121918    
2024-02-26 20:29:32,795 - Epoch: [93][  120/  139]    Overall Loss 0.409777    Objective Loss 0.409777                                        LR 0.000500    Time 0.121391    
2024-02-26 20:29:33,874 - Epoch: [93][  130/  139]    Overall Loss 0.409402    Objective Loss 0.409402                                        LR 0.000500    Time 0.120351    
2024-02-26 20:29:38,911 - Epoch: [93][  139/  139]    Overall Loss 0.409399    Objective Loss 0.409399    Top1 95.642227    LR 0.000500    Time 0.148792    
2024-02-26 20:29:39,370 - --- validate (epoch=93)-----------
2024-02-26 20:29:39,371 - 1392 samples (32 per mini-batch)
2024-02-26 20:30:09,340 - Epoch: [93][   10/   44]    Loss 0.496643    Top1 91.193868    
2024-02-26 20:30:36,325 - Epoch: [93][   20/   44]    Loss 0.500659    Top1 90.992050    
2024-02-26 20:31:04,588 - Epoch: [93][   30/   44]    Loss 0.502623    Top1 90.872864    
2024-02-26 20:31:34,503 - Epoch: [93][   40/   44]    Loss 0.502021    Top1 90.892922    
2024-02-26 20:31:45,454 - Epoch: [93][   44/   44]    Loss 0.503449    Top1 90.820422    
2024-02-26 20:31:45,683 - ==> Top1: 90.820    Loss: 0.503

2024-02-26 20:31:45,690 - ==> Best [Top1: 90.996   Sparsity:0.00   Params: 278176 on epoch: 75]
2024-02-26 20:31:45,690 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:31:45,719 - 

2024-02-26 20:31:45,719 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:31:47,699 - Epoch: [94][   10/  139]    Overall Loss 0.412249    Objective Loss 0.412249                                        LR 0.000500    Time 0.197845    
2024-02-26 20:31:48,798 - Epoch: [94][   20/  139]    Overall Loss 0.408188    Objective Loss 0.408188                                        LR 0.000500    Time 0.153795    
2024-02-26 20:31:49,851 - Epoch: [94][   30/  139]    Overall Loss 0.407848    Objective Loss 0.407848                                        LR 0.000500    Time 0.137596    
2024-02-26 20:31:50,938 - Epoch: [94][   40/  139]    Overall Loss 0.406651    Objective Loss 0.406651                                        LR 0.000500    Time 0.130366    
2024-02-26 20:31:52,032 - Epoch: [94][   50/  139]    Overall Loss 0.406535    Objective Loss 0.406535                                        LR 0.000500    Time 0.126161    
2024-02-26 20:31:53,136 - Epoch: [94][   60/  139]    Overall Loss 0.406344    Objective Loss 0.406344                                        LR 0.000500    Time 0.123514    
2024-02-26 20:31:54,254 - Epoch: [94][   70/  139]    Overall Loss 0.406461    Objective Loss 0.406461                                        LR 0.000500    Time 0.121826    
2024-02-26 20:31:55,348 - Epoch: [94][   80/  139]    Overall Loss 0.406497    Objective Loss 0.406497                                        LR 0.000500    Time 0.120261    
2024-02-26 20:31:56,448 - Epoch: [94][   90/  139]    Overall Loss 0.406871    Objective Loss 0.406871                                        LR 0.000500    Time 0.119106    
2024-02-26 20:31:57,545 - Epoch: [94][  100/  139]    Overall Loss 0.406579    Objective Loss 0.406579                                        LR 0.000500    Time 0.118162    
2024-02-26 20:31:58,624 - Epoch: [94][  110/  139]    Overall Loss 0.406872    Objective Loss 0.406872                                        LR 0.000500    Time 0.117215    
2024-02-26 20:31:59,762 - Epoch: [94][  120/  139]    Overall Loss 0.406637    Objective Loss 0.406637                                        LR 0.000500    Time 0.116923    
2024-02-26 20:32:00,874 - Epoch: [94][  130/  139]    Overall Loss 0.406822    Objective Loss 0.406822                                        LR 0.000500    Time 0.116479    
2024-02-26 20:32:06,302 - Epoch: [94][  139/  139]    Overall Loss 0.406234    Objective Loss 0.406234    Top1 97.038726    LR 0.000500    Time 0.147984    
2024-02-26 20:32:06,506 - --- validate (epoch=94)-----------
2024-02-26 20:32:06,507 - 1392 samples (32 per mini-batch)
2024-02-26 20:32:38,513 - Epoch: [94][   10/   44]    Loss 0.494347    Top1 91.214839    
2024-02-26 20:33:10,313 - Epoch: [94][   20/   44]    Loss 0.498331    Top1 90.971649    
2024-02-26 20:33:41,474 - Epoch: [94][   30/   44]    Loss 0.498013    Top1 91.023536    
2024-02-26 20:34:08,810 - Epoch: [94][   40/   44]    Loss 0.497671    Top1 91.058956    
2024-02-26 20:34:17,838 - Epoch: [94][   44/   44]    Loss 0.496321    Top1 91.083519    
2024-02-26 20:34:18,205 - ==> Top1: 91.084    Loss: 0.496

2024-02-26 20:34:18,212 - ==> Best [Top1: 91.084   Sparsity:0.00   Params: 278176 on epoch: 94]
2024-02-26 20:34:18,212 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:34:18,247 - 

2024-02-26 20:34:18,247 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:34:20,255 - Epoch: [95][   10/  139]    Overall Loss 0.403350    Objective Loss 0.403350                                        LR 0.000500    Time 0.200646    
2024-02-26 20:34:21,315 - Epoch: [95][   20/  139]    Overall Loss 0.403567    Objective Loss 0.403567                                        LR 0.000500    Time 0.153302    
2024-02-26 20:34:22,417 - Epoch: [95][   30/  139]    Overall Loss 0.402706    Objective Loss 0.402706                                        LR 0.000500    Time 0.138896    
2024-02-26 20:34:23,624 - Epoch: [95][   40/  139]    Overall Loss 0.403975    Objective Loss 0.403975                                        LR 0.000500    Time 0.134351    
2024-02-26 20:34:24,697 - Epoch: [95][   50/  139]    Overall Loss 0.404676    Objective Loss 0.404676                                        LR 0.000500    Time 0.128917    
2024-02-26 20:34:25,792 - Epoch: [95][   60/  139]    Overall Loss 0.406679    Objective Loss 0.406679                                        LR 0.000500    Time 0.125675    
2024-02-26 20:34:26,906 - Epoch: [95][   70/  139]    Overall Loss 0.408295    Objective Loss 0.408295                                        LR 0.000500    Time 0.123627    
2024-02-26 20:34:28,046 - Epoch: [95][   80/  139]    Overall Loss 0.411571    Objective Loss 0.411571                                        LR 0.000500    Time 0.122420    
2024-02-26 20:34:29,168 - Epoch: [95][   90/  139]    Overall Loss 0.413302    Objective Loss 0.413302                                        LR 0.000500    Time 0.121268    
2024-02-26 20:34:30,423 - Epoch: [95][  100/  139]    Overall Loss 0.414697    Objective Loss 0.414697                                        LR 0.000500    Time 0.121690    
2024-02-26 20:34:31,531 - Epoch: [95][  110/  139]    Overall Loss 0.415011    Objective Loss 0.415011                                        LR 0.000500    Time 0.120692    
2024-02-26 20:34:32,716 - Epoch: [95][  120/  139]    Overall Loss 0.416609    Objective Loss 0.416609                                        LR 0.000500    Time 0.120504    
2024-02-26 20:34:34,047 - Epoch: [95][  130/  139]    Overall Loss 0.416740    Objective Loss 0.416740                                        LR 0.000500    Time 0.121469    
2024-02-26 20:34:39,246 - Epoch: [95][  139/  139]    Overall Loss 0.416281    Objective Loss 0.416281    Top1 95.979017    LR 0.000500    Time 0.150998    
2024-02-26 20:34:39,713 - --- validate (epoch=95)-----------
2024-02-26 20:34:39,714 - 1392 samples (32 per mini-batch)
2024-02-26 20:35:10,367 - Epoch: [95][   10/   44]    Loss 0.508981    Top1 90.330869    
2024-02-26 20:35:37,133 - Epoch: [95][   20/   44]    Loss 0.509351    Top1 90.298463    
2024-02-26 20:36:04,342 - Epoch: [95][   30/   44]    Loss 0.505058    Top1 90.556692    
2024-02-26 20:36:35,581 - Epoch: [95][   40/   44]    Loss 0.507514    Top1 90.442434    
2024-02-26 20:36:46,824 - Epoch: [95][   44/   44]    Loss 0.505177    Top1 90.538226    
2024-02-26 20:36:47,129 - ==> Top1: 90.538    Loss: 0.505

2024-02-26 20:36:47,136 - ==> Best [Top1: 91.084   Sparsity:0.00   Params: 278176 on epoch: 94]
2024-02-26 20:36:47,136 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:36:47,176 - 

2024-02-26 20:36:47,176 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:36:49,207 - Epoch: [96][   10/  139]    Overall Loss 0.410759    Objective Loss 0.410759                                        LR 0.000500    Time 0.202874    
2024-02-26 20:36:50,289 - Epoch: [96][   20/  139]    Overall Loss 0.410899    Objective Loss 0.410899                                        LR 0.000500    Time 0.155462    
2024-02-26 20:36:51,375 - Epoch: [96][   30/  139]    Overall Loss 0.410147    Objective Loss 0.410147                                        LR 0.000500    Time 0.139451    
2024-02-26 20:36:52,485 - Epoch: [96][   40/  139]    Overall Loss 0.410331    Objective Loss 0.410331                                        LR 0.000500    Time 0.132330    
2024-02-26 20:36:53,597 - Epoch: [96][   50/  139]    Overall Loss 0.409815    Objective Loss 0.409815                                        LR 0.000500    Time 0.128073    
2024-02-26 20:36:54,711 - Epoch: [96][   60/  139]    Overall Loss 0.410965    Objective Loss 0.410965                                        LR 0.000500    Time 0.125107    
2024-02-26 20:36:55,846 - Epoch: [96][   70/  139]    Overall Loss 0.412979    Objective Loss 0.412979                                        LR 0.000500    Time 0.123437    
2024-02-26 20:36:56,946 - Epoch: [96][   80/  139]    Overall Loss 0.414337    Objective Loss 0.414337                                        LR 0.000500    Time 0.121749    
2024-02-26 20:36:58,062 - Epoch: [96][   90/  139]    Overall Loss 0.414414    Objective Loss 0.414414                                        LR 0.000500    Time 0.120607    
2024-02-26 20:36:59,191 - Epoch: [96][  100/  139]    Overall Loss 0.414381    Objective Loss 0.414381                                        LR 0.000500    Time 0.119832    
2024-02-26 20:37:00,285 - Epoch: [96][  110/  139]    Overall Loss 0.414164    Objective Loss 0.414164                                        LR 0.000500    Time 0.118882    
2024-02-26 20:37:01,385 - Epoch: [96][  120/  139]    Overall Loss 0.413923    Objective Loss 0.413923                                        LR 0.000500    Time 0.118137    
2024-02-26 20:37:02,509 - Epoch: [96][  130/  139]    Overall Loss 0.413607    Objective Loss 0.413607                                        LR 0.000500    Time 0.117684    
2024-02-26 20:37:08,085 - Epoch: [96][  139/  139]    Overall Loss 0.413250    Objective Loss 0.413250    Top1 96.273343    LR 0.000500    Time 0.150179    
2024-02-26 20:37:08,398 - --- validate (epoch=96)-----------
2024-02-26 20:37:08,399 - 1392 samples (32 per mini-batch)
2024-02-26 20:37:40,932 - Epoch: [96][   10/   44]    Loss 0.498451    Top1 90.935255    
2024-02-26 20:38:10,743 - Epoch: [96][   20/   44]    Loss 0.492795    Top1 91.240297    
2024-02-26 20:38:37,159 - Epoch: [96][   30/   44]    Loss 0.501907    Top1 90.766027    
2024-02-26 20:39:03,153 - Epoch: [96][   40/   44]    Loss 0.502018    Top1 90.779025    
2024-02-26 20:39:12,099 - Epoch: [96][   44/   44]    Loss 0.502057    Top1 90.750824    
2024-02-26 20:39:12,497 - ==> Top1: 90.751    Loss: 0.502

2024-02-26 20:39:12,504 - ==> Best [Top1: 91.084   Sparsity:0.00   Params: 278176 on epoch: 94]
2024-02-26 20:39:12,505 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:39:12,539 - 

2024-02-26 20:39:12,539 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:39:14,509 - Epoch: [97][   10/  139]    Overall Loss 0.403515    Objective Loss 0.403515                                        LR 0.000500    Time 0.196937    
2024-02-26 20:39:15,643 - Epoch: [97][   20/  139]    Overall Loss 0.405898    Objective Loss 0.405898                                        LR 0.000500    Time 0.155116    
2024-02-26 20:39:16,741 - Epoch: [97][   30/  139]    Overall Loss 0.407384    Objective Loss 0.407384                                        LR 0.000500    Time 0.139975    
2024-02-26 20:39:17,980 - Epoch: [97][   40/  139]    Overall Loss 0.407032    Objective Loss 0.407032                                        LR 0.000500    Time 0.135940    
2024-02-26 20:39:19,227 - Epoch: [97][   50/  139]    Overall Loss 0.405985    Objective Loss 0.405985                                        LR 0.000500    Time 0.133677    
2024-02-26 20:39:20,338 - Epoch: [97][   60/  139]    Overall Loss 0.405797    Objective Loss 0.405797                                        LR 0.000500    Time 0.129899    
2024-02-26 20:39:21,592 - Epoch: [97][   70/  139]    Overall Loss 0.405514    Objective Loss 0.405514                                        LR 0.000500    Time 0.129261    
2024-02-26 20:39:22,869 - Epoch: [97][   80/  139]    Overall Loss 0.405240    Objective Loss 0.405240                                        LR 0.000500    Time 0.129050    
2024-02-26 20:39:24,123 - Epoch: [97][   90/  139]    Overall Loss 0.405612    Objective Loss 0.405612                                        LR 0.000500    Time 0.128636    
2024-02-26 20:39:25,328 - Epoch: [97][  100/  139]    Overall Loss 0.406017    Objective Loss 0.406017                                        LR 0.000500    Time 0.127823    
2024-02-26 20:39:26,632 - Epoch: [97][  110/  139]    Overall Loss 0.406188    Objective Loss 0.406188                                        LR 0.000500    Time 0.128053    
2024-02-26 20:39:27,793 - Epoch: [97][  120/  139]    Overall Loss 0.405494    Objective Loss 0.405494                                        LR 0.000500    Time 0.127047    
2024-02-26 20:39:29,128 - Epoch: [97][  130/  139]    Overall Loss 0.405500    Objective Loss 0.405500                                        LR 0.000500    Time 0.127540    
2024-02-26 20:39:35,078 - Epoch: [97][  139/  139]    Overall Loss 0.405433    Objective Loss 0.405433    Top1 95.977054    LR 0.000500    Time 0.162080    
2024-02-26 20:39:35,316 - --- validate (epoch=97)-----------
2024-02-26 20:39:35,317 - 1392 samples (32 per mini-batch)
2024-02-26 20:40:09,072 - Epoch: [97][   10/   44]    Loss 0.498586    Top1 90.948204    
2024-02-26 20:40:41,418 - Epoch: [97][   20/   44]    Loss 0.502747    Top1 90.732431    
2024-02-26 20:41:12,990 - Epoch: [97][   30/   44]    Loss 0.503477    Top1 90.705034    
2024-02-26 20:41:45,409 - Epoch: [97][   40/   44]    Loss 0.503441    Top1 90.719245    
2024-02-26 20:41:56,263 - Epoch: [97][   44/   44]    Loss 0.503432    Top1 90.698428    
2024-02-26 20:41:56,485 - ==> Top1: 90.698    Loss: 0.503

2024-02-26 20:41:56,494 - ==> Best [Top1: 91.084   Sparsity:0.00   Params: 278176 on epoch: 94]
2024-02-26 20:41:56,494 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:41:56,524 - 

2024-02-26 20:41:56,524 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:41:58,637 - Epoch: [98][   10/  139]    Overall Loss 0.404942    Objective Loss 0.404942                                        LR 0.000500    Time 0.211113    
2024-02-26 20:41:59,744 - Epoch: [98][   20/  139]    Overall Loss 0.404963    Objective Loss 0.404963                                        LR 0.000500    Time 0.160870    
2024-02-26 20:42:00,838 - Epoch: [98][   30/  139]    Overall Loss 0.403322    Objective Loss 0.403322                                        LR 0.000500    Time 0.143688    
2024-02-26 20:42:01,947 - Epoch: [98][   40/  139]    Overall Loss 0.403506    Objective Loss 0.403506                                        LR 0.000500    Time 0.135465    
2024-02-26 20:42:03,094 - Epoch: [98][   50/  139]    Overall Loss 0.403988    Objective Loss 0.403988                                        LR 0.000500    Time 0.131296    
2024-02-26 20:42:04,232 - Epoch: [98][   60/  139]    Overall Loss 0.404003    Objective Loss 0.404003                                        LR 0.000500    Time 0.128353    
2024-02-26 20:42:05,375 - Epoch: [98][   70/  139]    Overall Loss 0.404047    Objective Loss 0.404047                                        LR 0.000500    Time 0.126331    
2024-02-26 20:42:06,455 - Epoch: [98][   80/  139]    Overall Loss 0.404688    Objective Loss 0.404688                                        LR 0.000500    Time 0.124036    
2024-02-26 20:42:07,548 - Epoch: [98][   90/  139]    Overall Loss 0.404977    Objective Loss 0.404977                                        LR 0.000500    Time 0.122379    
2024-02-26 20:42:08,714 - Epoch: [98][  100/  139]    Overall Loss 0.405445    Objective Loss 0.405445                                        LR 0.000500    Time 0.121792    
2024-02-26 20:42:09,862 - Epoch: [98][  110/  139]    Overall Loss 0.405273    Objective Loss 0.405273                                        LR 0.000500    Time 0.121154    
2024-02-26 20:42:10,987 - Epoch: [98][  120/  139]    Overall Loss 0.404733    Objective Loss 0.404733                                        LR 0.000500    Time 0.120422    
2024-02-26 20:42:12,093 - Epoch: [98][  130/  139]    Overall Loss 0.404529    Objective Loss 0.404529                                        LR 0.000500    Time 0.119656    
2024-02-26 20:42:17,858 - Epoch: [98][  139/  139]    Overall Loss 0.404737    Objective Loss 0.404737    Top1 96.050516    LR 0.000500    Time 0.153381    
2024-02-26 20:42:18,173 - --- validate (epoch=98)-----------
2024-02-26 20:42:18,175 - 1392 samples (32 per mini-batch)
2024-02-26 20:42:50,382 - Epoch: [98][   10/   44]    Loss 0.500404    Top1 90.921802    
2024-02-26 20:43:19,921 - Epoch: [98][   20/   44]    Loss 0.504606    Top1 90.715573    
2024-02-26 20:43:48,838 - Epoch: [98][   30/   44]    Loss 0.505087    Top1 90.661846    
2024-02-26 20:44:18,440 - Epoch: [98][   40/   44]    Loss 0.499143    Top1 91.000328    
2024-02-26 20:44:28,208 - Epoch: [98][   44/   44]    Loss 0.498761    Top1 91.061450    
2024-02-26 20:44:28,464 - ==> Top1: 91.061    Loss: 0.499

2024-02-26 20:44:28,471 - ==> Best [Top1: 91.084   Sparsity:0.00   Params: 278176 on epoch: 94]
2024-02-26 20:44:28,471 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:44:28,502 - 

2024-02-26 20:44:28,502 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:44:30,441 - Epoch: [99][   10/  139]    Overall Loss 0.403863    Objective Loss 0.403863                                        LR 0.000500    Time 0.193740    
2024-02-26 20:44:31,650 - Epoch: [99][   20/  139]    Overall Loss 0.402644    Objective Loss 0.402644                                        LR 0.000500    Time 0.157286    
2024-02-26 20:44:32,826 - Epoch: [99][   30/  139]    Overall Loss 0.403678    Objective Loss 0.403678                                        LR 0.000500    Time 0.144032    
2024-02-26 20:44:34,003 - Epoch: [99][   40/  139]    Overall Loss 0.403877    Objective Loss 0.403877                                        LR 0.000500    Time 0.137420    
2024-02-26 20:44:35,124 - Epoch: [99][   50/  139]    Overall Loss 0.404443    Objective Loss 0.404443                                        LR 0.000500    Time 0.132360    
2024-02-26 20:44:36,231 - Epoch: [99][   60/  139]    Overall Loss 0.404051    Objective Loss 0.404051                                        LR 0.000500    Time 0.128733    
2024-02-26 20:44:37,396 - Epoch: [99][   70/  139]    Overall Loss 0.404060    Objective Loss 0.404060                                        LR 0.000500    Time 0.126977    
2024-02-26 20:44:38,566 - Epoch: [99][   80/  139]    Overall Loss 0.404013    Objective Loss 0.404013                                        LR 0.000500    Time 0.125713    
2024-02-26 20:44:39,693 - Epoch: [99][   90/  139]    Overall Loss 0.403764    Objective Loss 0.403764                                        LR 0.000500    Time 0.124262    
2024-02-26 20:44:40,899 - Epoch: [99][  100/  139]    Overall Loss 0.403777    Objective Loss 0.403777                                        LR 0.000500    Time 0.123887    
2024-02-26 20:44:41,956 - Epoch: [99][  110/  139]    Overall Loss 0.404384    Objective Loss 0.404384                                        LR 0.000500    Time 0.122221    
2024-02-26 20:44:43,081 - Epoch: [99][  120/  139]    Overall Loss 0.404439    Objective Loss 0.404439                                        LR 0.000500    Time 0.121411    
2024-02-26 20:44:44,281 - Epoch: [99][  130/  139]    Overall Loss 0.405001    Objective Loss 0.405001                                        LR 0.000500    Time 0.121290    
2024-02-26 20:44:49,616 - Epoch: [99][  139/  139]    Overall Loss 0.404670    Objective Loss 0.404670    Top1 96.459998    LR 0.000500    Time 0.151733    
2024-02-26 20:44:49,944 - --- validate (epoch=99)-----------
2024-02-26 20:44:49,945 - 1392 samples (32 per mini-batch)
2024-02-26 20:45:23,370 - Epoch: [99][   10/   44]    Loss 0.493150    Top1 91.456846    
2024-02-26 20:45:55,260 - Epoch: [99][   20/   44]    Loss 0.502097    Top1 90.987073    
2024-02-26 20:46:27,914 - Epoch: [99][   30/   44]    Loss 0.505597    Top1 90.775390    
2024-02-26 20:47:00,092 - Epoch: [99][   40/   44]    Loss 0.503050    Top1 90.900137    
2024-02-26 20:47:11,087 - Epoch: [99][   44/   44]    Loss 0.501161    Top1 90.974024    
2024-02-26 20:47:11,693 - ==> Top1: 90.974    Loss: 0.501

2024-02-26 20:47:11,698 - ==> Best [Top1: 91.084   Sparsity:0.00   Params: 278176 on epoch: 94]
2024-02-26 20:47:11,698 - Saving checkpoint to: logs/2024.02.26-163018/qat_checkpoint.pth.tar
2024-02-26 20:47:11,765 - --- test ---------------------
2024-02-26 20:47:11,765 - 1392 samples (32 per mini-batch)
2024-02-26 20:47:43,576 - Test: [   10/   44]    Loss 0.503947    Top1 90.812554    
2024-02-26 20:48:13,777 - Test: [   20/   44]    Loss 0.500293    Top1 91.034465    
2024-02-26 20:48:42,915 - Test: [   30/   44]    Loss 0.496254    Top1 91.254625    
2024-02-26 20:49:12,209 - Test: [   40/   44]    Loss 0.499251    Top1 91.103605    
2024-02-26 20:49:22,452 - Test: [   44/   44]    Loss 0.501996    Top1 90.974024    
2024-02-26 20:49:22,679 - ==> Top1: 90.974    Loss: 0.502

2024-02-26 20:49:22,740 - 
2024-02-26 20:49:22,740 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.02.26-163018/2024.02.26-163018.log
