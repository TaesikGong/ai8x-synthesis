2024-04-23 15:49:54,283 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.23-154954/2024.04.23-154954.log
2024-04-23 15:50:00,689 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-04-23 15:50:00,690 - Optimizer Args: {'lr': 0.00032, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-04-23 15:50:00,794 - Dataset sizes:
	training=9469
	validation=3925
	test=3925
2024-04-23 15:50:00,795 - Reading compression schedule from: policies/schedule-cifar100.yaml
2024-04-23 15:50:00,803 - 

2024-04-23 15:50:00,803 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:50:21,737 - Epoch: [0][  100/  296]    Overall Loss 2.188390    Objective Loss 2.188390                                        LR 0.000320    Time 0.209128    
2024-04-23 15:50:42,762 - Epoch: [0][  200/  296]    Overall Loss 2.130049    Objective Loss 2.130049                                        LR 0.000320    Time 0.209555    
2024-04-23 15:51:01,790 - Epoch: [0][  296/  296]    Overall Loss 2.087745    Objective Loss 2.087745    Top1 36.065574    Top5 78.688525    LR 0.000320    Time 0.205803    
2024-04-23 15:51:02,067 - --- validate (epoch=0)-----------
2024-04-23 15:51:02,069 - 3925 samples (32 per mini-batch)
2024-04-23 15:51:25,359 - Epoch: [0][  100/  123]    Loss 2.096518    Top1 27.406250    Top5 72.906250    
2024-04-23 15:51:30,345 - Epoch: [0][  123/  123]    Loss 2.107048    Top1 27.133758    Top5 72.560510    
2024-04-23 15:51:30,661 - ==> Top1: 27.134    Top5: 72.561    Loss: 2.107

2024-04-23 15:51:30,672 - ==> Best [Top1: 27.134   Top5: 72.561   Sparsity:0.00   Params: 371568 on epoch: 0]
2024-04-23 15:51:30,680 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 15:51:30,802 - 

2024-04-23 15:51:30,804 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:51:50,150 - Epoch: [1][  100/  296]    Overall Loss 1.923646    Objective Loss 1.923646                                        LR 0.000320    Time 0.193202    
2024-04-23 15:52:04,365 - Epoch: [1][  200/  296]    Overall Loss 1.889632    Objective Loss 1.889632                                        LR 0.000320    Time 0.167546    
2024-04-23 15:52:19,069 - Epoch: [1][  296/  296]    Overall Loss 1.856491    Objective Loss 1.856491    Top1 50.819672    Top5 83.606557    LR 0.000320    Time 0.162811    
2024-04-23 15:52:19,323 - --- validate (epoch=1)-----------
2024-04-23 15:52:19,325 - 3925 samples (32 per mini-batch)
2024-04-23 15:52:41,500 - Epoch: [1][  100/  123]    Loss 2.067551    Top1 30.312500    Top5 72.031250    
2024-04-23 15:52:46,475 - Epoch: [1][  123/  123]    Loss 2.073628    Top1 30.267516    Top5 72.101911    
2024-04-23 15:52:46,618 - ==> Top1: 30.268    Top5: 72.102    Loss: 2.074

2024-04-23 15:52:46,624 - ==> Best [Top1: 30.268   Top5: 72.102   Sparsity:0.00   Params: 371568 on epoch: 1]
2024-04-23 15:52:46,624 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 15:52:46,675 - 

2024-04-23 15:52:46,676 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:53:06,851 - Epoch: [2][  100/  296]    Overall Loss 1.735174    Objective Loss 1.735174                                        LR 0.000320    Time 0.201558    
2024-04-23 15:53:24,647 - Epoch: [2][  200/  296]    Overall Loss 1.706976    Objective Loss 1.706976                                        LR 0.000320    Time 0.189663    
2024-04-23 15:53:41,109 - Epoch: [2][  296/  296]    Overall Loss 1.695582    Objective Loss 1.695582    Top1 40.983607    Top5 88.524590    LR 0.000320    Time 0.183706    
2024-04-23 15:53:41,370 - --- validate (epoch=2)-----------
2024-04-23 15:53:41,372 - 3925 samples (32 per mini-batch)
2024-04-23 15:54:00,382 - Epoch: [2][  100/  123]    Loss 1.655831    Top1 44.250000    Top5 86.468750    
2024-04-23 15:54:04,851 - Epoch: [2][  123/  123]    Loss 1.660514    Top1 43.847134    Top5 86.394904    
2024-04-23 15:54:05,074 - ==> Top1: 43.847    Top5: 86.395    Loss: 1.661

2024-04-23 15:54:05,081 - ==> Best [Top1: 43.847   Top5: 86.395   Sparsity:0.00   Params: 371568 on epoch: 2]
2024-04-23 15:54:05,082 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 15:54:05,141 - 

2024-04-23 15:54:05,142 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:54:21,661 - Epoch: [3][  100/  296]    Overall Loss 1.640798    Objective Loss 1.640798                                        LR 0.000320    Time 0.164981    
2024-04-23 15:54:40,931 - Epoch: [3][  200/  296]    Overall Loss 1.624975    Objective Loss 1.624975                                        LR 0.000320    Time 0.178733    
2024-04-23 15:54:58,618 - Epoch: [3][  296/  296]    Overall Loss 1.604567    Objective Loss 1.604567    Top1 45.901639    Top5 88.524590    LR 0.000320    Time 0.180445    
2024-04-23 15:54:58,876 - --- validate (epoch=3)-----------
2024-04-23 15:54:58,878 - 3925 samples (32 per mini-batch)
2024-04-23 15:55:20,729 - Epoch: [3][  100/  123]    Loss 1.468735    Top1 50.781250    Top5 90.500000    
2024-04-23 15:55:25,187 - Epoch: [3][  123/  123]    Loss 1.478237    Top1 50.624204    Top5 90.343949    
2024-04-23 15:55:25,391 - ==> Top1: 50.624    Top5: 90.344    Loss: 1.478

2024-04-23 15:55:25,400 - ==> Best [Top1: 50.624   Top5: 90.344   Sparsity:0.00   Params: 371568 on epoch: 3]
2024-04-23 15:55:25,402 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 15:55:25,464 - 

2024-04-23 15:55:25,465 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:55:42,148 - Epoch: [4][  100/  296]    Overall Loss 1.560016    Objective Loss 1.560016                                        LR 0.000320    Time 0.166623    
2024-04-23 15:55:57,806 - Epoch: [4][  200/  296]    Overall Loss 1.550207    Objective Loss 1.550207                                        LR 0.000320    Time 0.161501    
2024-04-23 15:56:12,151 - Epoch: [4][  296/  296]    Overall Loss 1.537924    Objective Loss 1.537924    Top1 57.377049    Top5 91.803279    LR 0.000320    Time 0.157522    
2024-04-23 15:56:12,278 - --- validate (epoch=4)-----------
2024-04-23 15:56:12,279 - 3925 samples (32 per mini-batch)
2024-04-23 15:56:32,300 - Epoch: [4][  100/  123]    Loss 1.588786    Top1 47.937500    Top5 85.156250    
2024-04-23 15:56:36,501 - Epoch: [4][  123/  123]    Loss 1.608047    Top1 47.184713    Top5 84.891720    
2024-04-23 15:56:36,797 - ==> Top1: 47.185    Top5: 84.892    Loss: 1.608

2024-04-23 15:56:36,807 - ==> Best [Top1: 50.624   Top5: 90.344   Sparsity:0.00   Params: 371568 on epoch: 3]
2024-04-23 15:56:36,808 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 15:56:36,859 - 

2024-04-23 15:56:36,860 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:56:56,207 - Epoch: [5][  100/  296]    Overall Loss 1.531290    Objective Loss 1.531290                                        LR 0.000320    Time 0.193267    
2024-04-23 15:57:14,491 - Epoch: [5][  200/  296]    Overall Loss 1.502102    Objective Loss 1.502102                                        LR 0.000320    Time 0.187947    
2024-04-23 15:57:32,326 - Epoch: [5][  296/  296]    Overall Loss 1.500155    Objective Loss 1.500155    Top1 54.098361    Top5 93.442623    LR 0.000320    Time 0.187187    
2024-04-23 15:57:32,780 - --- validate (epoch=5)-----------
2024-04-23 15:57:32,781 - 3925 samples (32 per mini-batch)
2024-04-23 15:57:55,121 - Epoch: [5][  100/  123]    Loss 1.414781    Top1 53.125000    Top5 90.781250    
2024-04-23 15:57:59,360 - Epoch: [5][  123/  123]    Loss 1.417698    Top1 53.044586    Top5 90.522293    
2024-04-23 15:57:59,574 - ==> Top1: 53.045    Top5: 90.522    Loss: 1.418

2024-04-23 15:57:59,583 - ==> Best [Top1: 53.045   Top5: 90.522   Sparsity:0.00   Params: 371568 on epoch: 5]
2024-04-23 15:57:59,584 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 15:57:59,670 - 

2024-04-23 15:57:59,671 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:58:21,552 - Epoch: [6][  100/  296]    Overall Loss 1.504037    Objective Loss 1.504037                                        LR 0.000320    Time 0.218582    
2024-04-23 15:58:40,809 - Epoch: [6][  200/  296]    Overall Loss 1.470867    Objective Loss 1.470867                                        LR 0.000320    Time 0.205479    
2024-04-23 15:59:00,099 - Epoch: [6][  296/  296]    Overall Loss 1.463271    Objective Loss 1.463271    Top1 50.819672    Top5 96.721311    LR 0.000320    Time 0.203938    
2024-04-23 15:59:00,411 - --- validate (epoch=6)-----------
2024-04-23 15:59:00,413 - 3925 samples (32 per mini-batch)
2024-04-23 15:59:22,515 - Epoch: [6][  100/  123]    Loss 1.429782    Top1 52.218750    Top5 90.187500    
2024-04-23 15:59:26,867 - Epoch: [6][  123/  123]    Loss 1.423767    Top1 52.840764    Top5 90.012739    
2024-04-23 15:59:27,028 - ==> Top1: 52.841    Top5: 90.013    Loss: 1.424

2024-04-23 15:59:27,038 - ==> Best [Top1: 53.045   Top5: 90.522   Sparsity:0.00   Params: 371568 on epoch: 5]
2024-04-23 15:59:27,039 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 15:59:27,095 - 

2024-04-23 15:59:27,096 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:59:45,779 - Epoch: [7][  100/  296]    Overall Loss 1.418199    Objective Loss 1.418199                                        LR 0.000320    Time 0.186625    
2024-04-23 16:00:02,915 - Epoch: [7][  200/  296]    Overall Loss 1.429441    Objective Loss 1.429441                                        LR 0.000320    Time 0.178889    
2024-04-23 16:00:18,763 - Epoch: [7][  296/  296]    Overall Loss 1.433982    Objective Loss 1.433982    Top1 50.819672    Top5 85.245902    LR 0.000320    Time 0.174348    
2024-04-23 16:00:18,966 - --- validate (epoch=7)-----------
2024-04-23 16:00:18,967 - 3925 samples (32 per mini-batch)
2024-04-23 16:00:33,523 - Epoch: [7][  100/  123]    Loss 1.308450    Top1 57.375000    Top5 92.187500    
2024-04-23 16:00:37,533 - Epoch: [7][  123/  123]    Loss 1.304187    Top1 57.452229    Top5 92.280255    
2024-04-23 16:00:37,733 - ==> Top1: 57.452    Top5: 92.280    Loss: 1.304

2024-04-23 16:00:37,742 - ==> Best [Top1: 57.452   Top5: 92.280   Sparsity:0.00   Params: 371568 on epoch: 7]
2024-04-23 16:00:37,742 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:00:37,809 - 

2024-04-23 16:00:37,810 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:00:58,558 - Epoch: [8][  100/  296]    Overall Loss 1.387553    Objective Loss 1.387553                                        LR 0.000320    Time 0.207250    
2024-04-23 16:01:14,547 - Epoch: [8][  200/  296]    Overall Loss 1.387829    Objective Loss 1.387829                                        LR 0.000320    Time 0.183462    
2024-04-23 16:01:27,790 - Epoch: [8][  296/  296]    Overall Loss 1.397140    Objective Loss 1.397140    Top1 49.180328    Top5 80.327869    LR 0.000320    Time 0.168641    
2024-04-23 16:01:27,996 - --- validate (epoch=8)-----------
2024-04-23 16:01:27,997 - 3925 samples (32 per mini-batch)
2024-04-23 16:01:46,677 - Epoch: [8][  100/  123]    Loss 1.416836    Top1 52.875000    Top5 91.156250    
2024-04-23 16:01:50,144 - Epoch: [8][  123/  123]    Loss 1.399964    Top1 53.146497    Top5 91.312102    
2024-04-23 16:01:50,282 - ==> Top1: 53.146    Top5: 91.312    Loss: 1.400

2024-04-23 16:01:50,290 - ==> Best [Top1: 57.452   Top5: 92.280   Sparsity:0.00   Params: 371568 on epoch: 7]
2024-04-23 16:01:50,291 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:01:50,337 - 

2024-04-23 16:01:50,338 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:02:05,100 - Epoch: [9][  100/  296]    Overall Loss 1.354754    Objective Loss 1.354754                                        LR 0.000320    Time 0.147431    
2024-04-23 16:02:13,526 - Epoch: [9][  200/  296]    Overall Loss 1.389671    Objective Loss 1.389671                                        LR 0.000320    Time 0.115775    
2024-04-23 16:02:24,190 - Epoch: [9][  296/  296]    Overall Loss 1.378525    Objective Loss 1.378525    Top1 54.098361    Top5 88.524590    LR 0.000320    Time 0.114198    
2024-04-23 16:02:24,349 - --- validate (epoch=9)-----------
2024-04-23 16:02:24,351 - 3925 samples (32 per mini-batch)
2024-04-23 16:02:37,277 - Epoch: [9][  100/  123]    Loss 1.219727    Top1 59.875000    Top5 92.937500    
2024-04-23 16:02:40,268 - Epoch: [9][  123/  123]    Loss 1.232828    Top1 59.261146    Top5 92.993631    
2024-04-23 16:02:40,439 - ==> Top1: 59.261    Top5: 92.994    Loss: 1.233

2024-04-23 16:02:40,446 - ==> Best [Top1: 59.261   Top5: 92.994   Sparsity:0.00   Params: 371568 on epoch: 9]
2024-04-23 16:02:40,446 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:02:40,501 - 

2024-04-23 16:02:40,502 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:03:00,193 - Epoch: [10][  100/  296]    Overall Loss 1.371245    Objective Loss 1.371245                                        LR 0.000320    Time 0.196697    
2024-04-23 16:03:12,316 - Epoch: [10][  200/  296]    Overall Loss 1.358459    Objective Loss 1.358459                                        LR 0.000320    Time 0.158878    
2024-04-23 16:03:27,672 - Epoch: [10][  296/  296]    Overall Loss 1.354909    Objective Loss 1.354909    Top1 45.901639    Top5 83.606557    LR 0.000320    Time 0.159164    
2024-04-23 16:03:27,799 - --- validate (epoch=10)-----------
2024-04-23 16:03:27,799 - 3925 samples (32 per mini-batch)
2024-04-23 16:03:40,273 - Epoch: [10][  100/  123]    Loss 1.192876    Top1 61.062500    Top5 93.406250    
2024-04-23 16:03:42,774 - Epoch: [10][  123/  123]    Loss 1.197005    Top1 60.891720    Top5 93.197452    
2024-04-23 16:03:42,906 - ==> Top1: 60.892    Top5: 93.197    Loss: 1.197

2024-04-23 16:03:42,912 - ==> Best [Top1: 60.892   Top5: 93.197   Sparsity:0.00   Params: 371568 on epoch: 10]
2024-04-23 16:03:42,912 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:03:42,957 - 

2024-04-23 16:03:42,958 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:03:56,067 - Epoch: [11][  100/  296]    Overall Loss 1.357453    Objective Loss 1.357453                                        LR 0.000320    Time 0.130910    
2024-04-23 16:04:11,044 - Epoch: [11][  200/  296]    Overall Loss 1.350930    Objective Loss 1.350930                                        LR 0.000320    Time 0.140240    
2024-04-23 16:04:24,849 - Epoch: [11][  296/  296]    Overall Loss 1.342012    Objective Loss 1.342012    Top1 63.934426    Top5 91.803279    LR 0.000320    Time 0.141333    
2024-04-23 16:04:25,021 - --- validate (epoch=11)-----------
2024-04-23 16:04:25,022 - 3925 samples (32 per mini-batch)
2024-04-23 16:04:44,242 - Epoch: [11][  100/  123]    Loss 1.236384    Top1 59.062500    Top5 92.281250    
2024-04-23 16:04:49,139 - Epoch: [11][  123/  123]    Loss 1.227175    Top1 59.490446    Top5 92.484076    
2024-04-23 16:04:49,355 - ==> Top1: 59.490    Top5: 92.484    Loss: 1.227

2024-04-23 16:04:49,367 - ==> Best [Top1: 60.892   Top5: 93.197   Sparsity:0.00   Params: 371568 on epoch: 10]
2024-04-23 16:04:49,368 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:04:49,424 - 

2024-04-23 16:04:49,424 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:05:09,563 - Epoch: [12][  100/  296]    Overall Loss 1.358886    Objective Loss 1.358886                                        LR 0.000320    Time 0.201161    
2024-04-23 16:05:28,294 - Epoch: [12][  200/  296]    Overall Loss 1.348277    Objective Loss 1.348277                                        LR 0.000320    Time 0.194128    
2024-04-23 16:05:46,132 - Epoch: [12][  296/  296]    Overall Loss 1.333657    Objective Loss 1.333657    Top1 57.377049    Top5 88.524590    LR 0.000320    Time 0.191356    
2024-04-23 16:05:46,316 - --- validate (epoch=12)-----------
2024-04-23 16:05:46,317 - 3925 samples (32 per mini-batch)
2024-04-23 16:06:06,433 - Epoch: [12][  100/  123]    Loss 1.148140    Top1 62.031250    Top5 93.781250    
2024-04-23 16:06:11,113 - Epoch: [12][  123/  123]    Loss 1.154927    Top1 61.859873    Top5 93.579618    
2024-04-23 16:06:11,342 - ==> Top1: 61.860    Top5: 93.580    Loss: 1.155

2024-04-23 16:06:11,352 - ==> Best [Top1: 61.860   Top5: 93.580   Sparsity:0.00   Params: 371568 on epoch: 12]
2024-04-23 16:06:11,353 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:06:11,438 - 

2024-04-23 16:06:11,439 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:06:31,852 - Epoch: [13][  100/  296]    Overall Loss 1.313409    Objective Loss 1.313409                                        LR 0.000320    Time 0.203894    
2024-04-23 16:06:51,109 - Epoch: [13][  200/  296]    Overall Loss 1.302838    Objective Loss 1.302838                                        LR 0.000320    Time 0.198124    
2024-04-23 16:07:09,172 - Epoch: [13][  296/  296]    Overall Loss 1.293052    Objective Loss 1.293052    Top1 59.016393    Top5 91.803279    LR 0.000320    Time 0.194829    
2024-04-23 16:07:09,301 - --- validate (epoch=13)-----------
2024-04-23 16:07:09,301 - 3925 samples (32 per mini-batch)
2024-04-23 16:07:29,356 - Epoch: [13][  100/  123]    Loss 1.271495    Top1 56.468750    Top5 92.718750    
2024-04-23 16:07:33,528 - Epoch: [13][  123/  123]    Loss 1.271982    Top1 56.611465    Top5 92.840764    
2024-04-23 16:07:33,737 - ==> Top1: 56.611    Top5: 92.841    Loss: 1.272

2024-04-23 16:07:33,745 - ==> Best [Top1: 61.860   Top5: 93.580   Sparsity:0.00   Params: 371568 on epoch: 12]
2024-04-23 16:07:33,746 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:07:33,812 - 

2024-04-23 16:07:33,812 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:07:53,453 - Epoch: [14][  100/  296]    Overall Loss 1.294322    Objective Loss 1.294322                                        LR 0.000320    Time 0.196193    
2024-04-23 16:08:12,826 - Epoch: [14][  200/  296]    Overall Loss 1.289284    Objective Loss 1.289284                                        LR 0.000320    Time 0.194850    
2024-04-23 16:08:27,644 - Epoch: [14][  296/  296]    Overall Loss 1.292359    Objective Loss 1.292359    Top1 45.901639    Top5 93.442623    LR 0.000320    Time 0.181657    
2024-04-23 16:08:27,994 - --- validate (epoch=14)-----------
2024-04-23 16:08:27,995 - 3925 samples (32 per mini-batch)
2024-04-23 16:08:49,878 - Epoch: [14][  100/  123]    Loss 1.090464    Top1 64.718750    Top5 94.906250    
2024-04-23 16:08:54,731 - Epoch: [14][  123/  123]    Loss 1.106069    Top1 64.178344    Top5 94.700637    
2024-04-23 16:08:54,973 - ==> Top1: 64.178    Top5: 94.701    Loss: 1.106

2024-04-23 16:08:54,984 - ==> Best [Top1: 64.178   Top5: 94.701   Sparsity:0.00   Params: 371568 on epoch: 14]
2024-04-23 16:08:54,985 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:08:55,054 - 

2024-04-23 16:08:55,055 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:09:15,017 - Epoch: [15][  100/  296]    Overall Loss 1.301026    Objective Loss 1.301026                                        LR 0.000320    Time 0.199400    
2024-04-23 16:09:33,427 - Epoch: [15][  200/  296]    Overall Loss 1.280195    Objective Loss 1.280195                                        LR 0.000320    Time 0.191649    
2024-04-23 16:09:49,829 - Epoch: [15][  296/  296]    Overall Loss 1.274329    Objective Loss 1.274329    Top1 62.295082    Top5 96.721311    LR 0.000320    Time 0.184838    
2024-04-23 16:09:50,047 - --- validate (epoch=15)-----------
2024-04-23 16:09:50,048 - 3925 samples (32 per mini-batch)
2024-04-23 16:10:10,056 - Epoch: [15][  100/  123]    Loss 1.071478    Top1 64.937500    Top5 94.687500    
2024-04-23 16:10:14,682 - Epoch: [15][  123/  123]    Loss 1.064411    Top1 65.197452    Top5 94.878981    
2024-04-23 16:10:14,971 - ==> Top1: 65.197    Top5: 94.879    Loss: 1.064

2024-04-23 16:10:14,982 - ==> Best [Top1: 65.197   Top5: 94.879   Sparsity:0.00   Params: 371568 on epoch: 15]
2024-04-23 16:10:14,983 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:10:15,074 - 

2024-04-23 16:10:15,075 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:10:36,165 - Epoch: [16][  100/  296]    Overall Loss 1.261747    Objective Loss 1.261747                                        LR 0.000320    Time 0.210676    
2024-04-23 16:10:54,181 - Epoch: [16][  200/  296]    Overall Loss 1.260987    Objective Loss 1.260987                                        LR 0.000320    Time 0.195320    
2024-04-23 16:11:10,789 - Epoch: [16][  296/  296]    Overall Loss 1.257260    Objective Loss 1.257260    Top1 54.098361    Top5 90.163934    LR 0.000320    Time 0.188011    
2024-04-23 16:11:10,997 - --- validate (epoch=16)-----------
2024-04-23 16:11:10,998 - 3925 samples (32 per mini-batch)
2024-04-23 16:11:32,356 - Epoch: [16][  100/  123]    Loss 1.227495    Top1 59.531250    Top5 93.125000    
2024-04-23 16:11:37,184 - Epoch: [16][  123/  123]    Loss 1.218551    Top1 59.745223    Top5 93.197452    
2024-04-23 16:11:37,379 - ==> Top1: 59.745    Top5: 93.197    Loss: 1.219

2024-04-23 16:11:37,391 - ==> Best [Top1: 65.197   Top5: 94.879   Sparsity:0.00   Params: 371568 on epoch: 15]
2024-04-23 16:11:37,392 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:11:37,441 - 

2024-04-23 16:11:37,442 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:11:55,866 - Epoch: [17][  100/  296]    Overall Loss 1.223672    Objective Loss 1.223672                                        LR 0.000320    Time 0.184000    
2024-04-23 16:12:14,125 - Epoch: [17][  200/  296]    Overall Loss 1.223797    Objective Loss 1.223797                                        LR 0.000320    Time 0.183194    
2024-04-23 16:12:30,796 - Epoch: [17][  296/  296]    Overall Loss 1.236763    Objective Loss 1.236763    Top1 62.295082    Top5 95.081967    LR 0.000320    Time 0.180041    
2024-04-23 16:12:30,993 - --- validate (epoch=17)-----------
2024-04-23 16:12:30,994 - 3925 samples (32 per mini-batch)
2024-04-23 16:12:52,222 - Epoch: [17][  100/  123]    Loss 1.082759    Top1 64.187500    Top5 94.531250    
2024-04-23 16:12:56,954 - Epoch: [17][  123/  123]    Loss 1.076884    Top1 64.458599    Top5 94.649682    
2024-04-23 16:12:57,164 - ==> Top1: 64.459    Top5: 94.650    Loss: 1.077

2024-04-23 16:12:57,175 - ==> Best [Top1: 65.197   Top5: 94.879   Sparsity:0.00   Params: 371568 on epoch: 15]
2024-04-23 16:12:57,176 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:12:57,257 - 

2024-04-23 16:12:57,258 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:13:16,788 - Epoch: [18][  100/  296]    Overall Loss 1.227822    Objective Loss 1.227822                                        LR 0.000320    Time 0.195062    
2024-04-23 16:13:33,504 - Epoch: [18][  200/  296]    Overall Loss 1.234435    Objective Loss 1.234435                                        LR 0.000320    Time 0.180984    
2024-04-23 16:13:51,010 - Epoch: [18][  296/  296]    Overall Loss 1.219655    Objective Loss 1.219655    Top1 55.737705    Top5 95.081967    LR 0.000320    Time 0.181363    
2024-04-23 16:13:51,246 - --- validate (epoch=18)-----------
2024-04-23 16:13:51,248 - 3925 samples (32 per mini-batch)
2024-04-23 16:14:13,281 - Epoch: [18][  100/  123]    Loss 1.197708    Top1 59.781250    Top5 93.031250    
2024-04-23 16:14:17,066 - Epoch: [18][  123/  123]    Loss 1.194618    Top1 59.949045    Top5 92.891720    
2024-04-23 16:14:17,302 - ==> Top1: 59.949    Top5: 92.892    Loss: 1.195

2024-04-23 16:14:17,311 - ==> Best [Top1: 65.197   Top5: 94.879   Sparsity:0.00   Params: 371568 on epoch: 15]
2024-04-23 16:14:17,312 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:14:17,402 - 

2024-04-23 16:14:17,403 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:14:36,893 - Epoch: [19][  100/  296]    Overall Loss 1.226577    Objective Loss 1.226577                                        LR 0.000320    Time 0.194660    
2024-04-23 16:14:55,300 - Epoch: [19][  200/  296]    Overall Loss 1.206702    Objective Loss 1.206702                                        LR 0.000320    Time 0.189267    
2024-04-23 16:15:12,275 - Epoch: [19][  296/  296]    Overall Loss 1.216099    Objective Loss 1.216099    Top1 55.737705    Top5 93.442623    LR 0.000320    Time 0.185166    
2024-04-23 16:15:12,473 - --- validate (epoch=19)-----------
2024-04-23 16:15:12,474 - 3925 samples (32 per mini-batch)
2024-04-23 16:15:36,666 - Epoch: [19][  100/  123]    Loss 1.278826    Top1 58.687500    Top5 92.843750    
2024-04-23 16:15:40,887 - Epoch: [19][  123/  123]    Loss 1.275266    Top1 58.675159    Top5 93.095541    
2024-04-23 16:15:41,144 - ==> Top1: 58.675    Top5: 93.096    Loss: 1.275

2024-04-23 16:15:41,154 - ==> Best [Top1: 65.197   Top5: 94.879   Sparsity:0.00   Params: 371568 on epoch: 15]
2024-04-23 16:15:41,155 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:15:41,210 - 

2024-04-23 16:15:41,211 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:15:59,200 - Epoch: [20][  100/  296]    Overall Loss 1.186888    Objective Loss 1.186888                                        LR 0.000320    Time 0.179684    
2024-04-23 16:16:19,196 - Epoch: [20][  200/  296]    Overall Loss 1.210953    Objective Loss 1.210953                                        LR 0.000320    Time 0.189704    
2024-04-23 16:16:38,377 - Epoch: [20][  296/  296]    Overall Loss 1.203943    Objective Loss 1.203943    Top1 54.098361    Top5 93.442623    LR 0.000320    Time 0.192911    
2024-04-23 16:16:38,623 - --- validate (epoch=20)-----------
2024-04-23 16:16:38,624 - 3925 samples (32 per mini-batch)
2024-04-23 16:17:00,089 - Epoch: [20][  100/  123]    Loss 1.076697    Top1 64.562500    Top5 93.718750    
2024-04-23 16:17:05,866 - Epoch: [20][  123/  123]    Loss 1.085575    Top1 63.949045    Top5 93.579618    
2024-04-23 16:17:06,083 - ==> Top1: 63.949    Top5: 93.580    Loss: 1.086

2024-04-23 16:17:06,094 - ==> Best [Top1: 65.197   Top5: 94.879   Sparsity:0.00   Params: 371568 on epoch: 15]
2024-04-23 16:17:06,095 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:17:06,156 - 

2024-04-23 16:17:06,157 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:17:28,217 - Epoch: [21][  100/  296]    Overall Loss 1.184214    Objective Loss 1.184214                                        LR 0.000320    Time 0.220379    
2024-04-23 16:17:46,424 - Epoch: [21][  200/  296]    Overall Loss 1.184768    Objective Loss 1.184768                                        LR 0.000320    Time 0.201119    
2024-04-23 16:18:04,290 - Epoch: [21][  296/  296]    Overall Loss 1.189032    Objective Loss 1.189032    Top1 55.737705    Top5 96.721311    LR 0.000320    Time 0.196182    
2024-04-23 16:18:04,539 - --- validate (epoch=21)-----------
2024-04-23 16:18:04,541 - 3925 samples (32 per mini-batch)
2024-04-23 16:18:26,015 - Epoch: [21][  100/  123]    Loss 1.039048    Top1 65.625000    Top5 94.843750    
2024-04-23 16:18:29,921 - Epoch: [21][  123/  123]    Loss 1.036520    Top1 65.961783    Top5 95.006369    
2024-04-23 16:18:30,087 - ==> Top1: 65.962    Top5: 95.006    Loss: 1.037

2024-04-23 16:18:30,096 - ==> Best [Top1: 65.962   Top5: 95.006   Sparsity:0.00   Params: 371568 on epoch: 21]
2024-04-23 16:18:30,097 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:18:30,162 - 

2024-04-23 16:18:30,163 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:18:50,313 - Epoch: [22][  100/  296]    Overall Loss 1.180407    Objective Loss 1.180407                                        LR 0.000320    Time 0.201262    
2024-04-23 16:19:12,023 - Epoch: [22][  200/  296]    Overall Loss 1.182121    Objective Loss 1.182121                                        LR 0.000320    Time 0.209063    
2024-04-23 16:19:30,645 - Epoch: [22][  296/  296]    Overall Loss 1.181003    Objective Loss 1.181003    Top1 63.934426    Top5 91.803279    LR 0.000320    Time 0.204094    
2024-04-23 16:19:30,937 - --- validate (epoch=22)-----------
2024-04-23 16:19:30,938 - 3925 samples (32 per mini-batch)
2024-04-23 16:19:55,926 - Epoch: [22][  100/  123]    Loss 1.089175    Top1 63.687500    Top5 93.781250    
2024-04-23 16:20:01,641 - Epoch: [22][  123/  123]    Loss 1.092185    Top1 63.745223    Top5 93.834395    
2024-04-23 16:20:01,845 - ==> Top1: 63.745    Top5: 93.834    Loss: 1.092

2024-04-23 16:20:01,855 - ==> Best [Top1: 65.962   Top5: 95.006   Sparsity:0.00   Params: 371568 on epoch: 21]
2024-04-23 16:20:01,856 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:20:01,923 - 

2024-04-23 16:20:01,924 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:20:23,228 - Epoch: [23][  100/  296]    Overall Loss 1.189504    Objective Loss 1.189504                                        LR 0.000320    Time 0.212800    
2024-04-23 16:20:40,544 - Epoch: [23][  200/  296]    Overall Loss 1.185413    Objective Loss 1.185413                                        LR 0.000320    Time 0.192875    
2024-04-23 16:20:56,472 - Epoch: [23][  296/  296]    Overall Loss 1.180386    Objective Loss 1.180386    Top1 54.098361    Top5 88.524590    LR 0.000320    Time 0.184063    
2024-04-23 16:20:56,711 - --- validate (epoch=23)-----------
2024-04-23 16:20:56,712 - 3925 samples (32 per mini-batch)
2024-04-23 16:21:15,217 - Epoch: [23][  100/  123]    Loss 1.106323    Top1 63.250000    Top5 94.000000    
2024-04-23 16:21:20,295 - Epoch: [23][  123/  123]    Loss 1.111991    Top1 63.337580    Top5 93.859873    
2024-04-23 16:21:20,522 - ==> Top1: 63.338    Top5: 93.860    Loss: 1.112

2024-04-23 16:21:20,530 - ==> Best [Top1: 65.962   Top5: 95.006   Sparsity:0.00   Params: 371568 on epoch: 21]
2024-04-23 16:21:20,530 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:21:20,582 - 

2024-04-23 16:21:20,583 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:21:38,089 - Epoch: [24][  100/  296]    Overall Loss 1.152750    Objective Loss 1.152750                                        LR 0.000320    Time 0.174819    
2024-04-23 16:21:56,068 - Epoch: [24][  200/  296]    Overall Loss 1.145788    Objective Loss 1.145788                                        LR 0.000320    Time 0.177183    
2024-04-23 16:22:12,278 - Epoch: [24][  296/  296]    Overall Loss 1.160827    Objective Loss 1.160827    Top1 72.131148    Top5 95.081967    LR 0.000320    Time 0.174416    
2024-04-23 16:22:12,567 - --- validate (epoch=24)-----------
2024-04-23 16:22:12,569 - 3925 samples (32 per mini-batch)
2024-04-23 16:22:33,011 - Epoch: [24][  100/  123]    Loss 1.124725    Top1 62.625000    Top5 93.906250    
2024-04-23 16:22:36,793 - Epoch: [24][  123/  123]    Loss 1.132626    Top1 62.369427    Top5 93.885350    
2024-04-23 16:22:36,977 - ==> Top1: 62.369    Top5: 93.885    Loss: 1.133

2024-04-23 16:22:36,985 - ==> Best [Top1: 65.962   Top5: 95.006   Sparsity:0.00   Params: 371568 on epoch: 21]
2024-04-23 16:22:36,986 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:22:37,028 - 

2024-04-23 16:22:37,029 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:22:55,534 - Epoch: [25][  100/  296]    Overall Loss 1.155029    Objective Loss 1.155029                                        LR 0.000320    Time 0.184818    
2024-04-23 16:23:12,931 - Epoch: [25][  200/  296]    Overall Loss 1.146396    Objective Loss 1.146396                                        LR 0.000320    Time 0.179277    
2024-04-23 16:23:28,562 - Epoch: [25][  296/  296]    Overall Loss 1.133487    Objective Loss 1.133487    Top1 55.737705    Top5 91.803279    LR 0.000320    Time 0.173872    
2024-04-23 16:23:28,871 - --- validate (epoch=25)-----------
2024-04-23 16:23:28,873 - 3925 samples (32 per mini-batch)
2024-04-23 16:23:49,161 - Epoch: [25][  100/  123]    Loss 0.964732    Top1 68.156250    Top5 95.718750    
2024-04-23 16:23:52,592 - Epoch: [25][  123/  123]    Loss 0.969809    Top1 68.203822    Top5 95.490446    
2024-04-23 16:23:52,844 - ==> Top1: 68.204    Top5: 95.490    Loss: 0.970

2024-04-23 16:23:52,856 - ==> Best [Top1: 68.204   Top5: 95.490   Sparsity:0.00   Params: 371568 on epoch: 25]
2024-04-23 16:23:52,857 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:23:52,932 - 

2024-04-23 16:23:52,933 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:24:11,701 - Epoch: [26][  100/  296]    Overall Loss 1.112011    Objective Loss 1.112011                                        LR 0.000320    Time 0.187447    
2024-04-23 16:24:24,824 - Epoch: [26][  200/  296]    Overall Loss 1.154261    Objective Loss 1.154261                                        LR 0.000320    Time 0.159227    
2024-04-23 16:24:41,834 - Epoch: [26][  296/  296]    Overall Loss 1.152246    Objective Loss 1.152246    Top1 67.213115    Top5 95.081967    LR 0.000320    Time 0.164984    
2024-04-23 16:24:42,074 - --- validate (epoch=26)-----------
2024-04-23 16:24:42,075 - 3925 samples (32 per mini-batch)
2024-04-23 16:25:00,607 - Epoch: [26][  100/  123]    Loss 1.031275    Top1 65.250000    Top5 95.218750    
2024-04-23 16:25:04,601 - Epoch: [26][  123/  123]    Loss 1.015401    Top1 65.834395    Top5 95.184713    
2024-04-23 16:25:04,801 - ==> Top1: 65.834    Top5: 95.185    Loss: 1.015

2024-04-23 16:25:04,811 - ==> Best [Top1: 68.204   Top5: 95.490   Sparsity:0.00   Params: 371568 on epoch: 25]
2024-04-23 16:25:04,812 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:25:04,856 - 

2024-04-23 16:25:04,857 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:25:22,760 - Epoch: [27][  100/  296]    Overall Loss 1.126698    Objective Loss 1.126698                                        LR 0.000320    Time 0.178801    
2024-04-23 16:25:38,656 - Epoch: [27][  200/  296]    Overall Loss 1.120239    Objective Loss 1.120239                                        LR 0.000320    Time 0.168772    
2024-04-23 16:25:55,124 - Epoch: [27][  296/  296]    Overall Loss 1.124758    Objective Loss 1.124758    Top1 67.213115    Top5 93.442623    LR 0.000320    Time 0.169607    
2024-04-23 16:25:55,364 - --- validate (epoch=27)-----------
2024-04-23 16:25:55,365 - 3925 samples (32 per mini-batch)
2024-04-23 16:26:19,466 - Epoch: [27][  100/  123]    Loss 0.948476    Top1 69.000000    Top5 95.500000    
2024-04-23 16:26:24,606 - Epoch: [27][  123/  123]    Loss 0.948907    Top1 68.942675    Top5 95.566879    
2024-04-23 16:26:24,881 - ==> Top1: 68.943    Top5: 95.567    Loss: 0.949

2024-04-23 16:26:24,895 - ==> Best [Top1: 68.943   Top5: 95.567   Sparsity:0.00   Params: 371568 on epoch: 27]
2024-04-23 16:26:24,896 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:26:24,981 - 

2024-04-23 16:26:24,982 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:26:44,806 - Epoch: [28][  100/  296]    Overall Loss 1.132449    Objective Loss 1.132449                                        LR 0.000320    Time 0.197974    
2024-04-23 16:27:00,604 - Epoch: [28][  200/  296]    Overall Loss 1.133739    Objective Loss 1.133739                                        LR 0.000320    Time 0.177861    
2024-04-23 16:27:14,721 - Epoch: [28][  296/  296]    Overall Loss 1.128672    Objective Loss 1.128672    Top1 54.098361    Top5 100.000000    LR 0.000320    Time 0.167802    
2024-04-23 16:27:14,988 - --- validate (epoch=28)-----------
2024-04-23 16:27:14,990 - 3925 samples (32 per mini-batch)
2024-04-23 16:27:33,345 - Epoch: [28][  100/  123]    Loss 0.917540    Top1 69.906250    Top5 95.906250    
2024-04-23 16:27:36,844 - Epoch: [28][  123/  123]    Loss 0.928871    Top1 69.324841    Top5 95.872611    
2024-04-23 16:27:37,016 - ==> Top1: 69.325    Top5: 95.873    Loss: 0.929

2024-04-23 16:27:37,020 - ==> Best [Top1: 69.325   Top5: 95.873   Sparsity:0.00   Params: 371568 on epoch: 28]
2024-04-23 16:27:37,020 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:27:37,054 - 

2024-04-23 16:27:37,054 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:27:55,511 - Epoch: [29][  100/  296]    Overall Loss 1.121750    Objective Loss 1.121750                                        LR 0.000320    Time 0.184349    
2024-04-23 16:28:11,748 - Epoch: [29][  200/  296]    Overall Loss 1.105104    Objective Loss 1.105104                                        LR 0.000320    Time 0.173247    
2024-04-23 16:28:28,967 - Epoch: [29][  296/  296]    Overall Loss 1.116975    Objective Loss 1.116975    Top1 63.934426    Top5 91.803279    LR 0.000320    Time 0.175161    
2024-04-23 16:28:29,209 - --- validate (epoch=29)-----------
2024-04-23 16:28:29,210 - 3925 samples (32 per mini-batch)
2024-04-23 16:28:48,789 - Epoch: [29][  100/  123]    Loss 1.027753    Top1 65.968750    Top5 95.406250    
2024-04-23 16:28:52,928 - Epoch: [29][  123/  123]    Loss 1.032697    Top1 65.656051    Top5 95.235669    
2024-04-23 16:28:53,182 - ==> Top1: 65.656    Top5: 95.236    Loss: 1.033

2024-04-23 16:28:53,191 - ==> Best [Top1: 69.325   Top5: 95.873   Sparsity:0.00   Params: 371568 on epoch: 28]
2024-04-23 16:28:53,192 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:28:53,248 - 

2024-04-23 16:28:53,249 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:29:14,788 - Epoch: [30][  100/  296]    Overall Loss 1.075360    Objective Loss 1.075360                                        LR 0.000320    Time 0.215141    
2024-04-23 16:29:31,394 - Epoch: [30][  200/  296]    Overall Loss 1.103314    Objective Loss 1.103314                                        LR 0.000320    Time 0.190485    
2024-04-23 16:29:47,683 - Epoch: [30][  296/  296]    Overall Loss 1.106017    Objective Loss 1.106017    Top1 52.459016    Top5 90.163934    LR 0.000320    Time 0.183664    
2024-04-23 16:29:47,990 - --- validate (epoch=30)-----------
2024-04-23 16:29:47,991 - 3925 samples (32 per mini-batch)
2024-04-23 16:30:07,222 - Epoch: [30][  100/  123]    Loss 1.059087    Top1 65.062500    Top5 95.750000    
2024-04-23 16:30:09,773 - Epoch: [30][  123/  123]    Loss 1.059830    Top1 65.019108    Top5 95.541401    
2024-04-23 16:30:10,064 - ==> Top1: 65.019    Top5: 95.541    Loss: 1.060

2024-04-23 16:30:10,073 - ==> Best [Top1: 69.325   Top5: 95.873   Sparsity:0.00   Params: 371568 on epoch: 28]
2024-04-23 16:30:10,074 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:30:10,135 - 

2024-04-23 16:30:10,136 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:30:27,686 - Epoch: [31][  100/  296]    Overall Loss 1.112067    Objective Loss 1.112067                                        LR 0.000320    Time 0.175259    
2024-04-23 16:30:41,243 - Epoch: [31][  200/  296]    Overall Loss 1.101288    Objective Loss 1.101288                                        LR 0.000320    Time 0.155304    
2024-04-23 16:30:54,366 - Epoch: [31][  296/  296]    Overall Loss 1.104272    Objective Loss 1.104272    Top1 65.573770    Top5 91.803279    LR 0.000320    Time 0.149203    
2024-04-23 16:30:54,593 - --- validate (epoch=31)-----------
2024-04-23 16:30:54,594 - 3925 samples (32 per mini-batch)
2024-04-23 16:31:11,116 - Epoch: [31][  100/  123]    Loss 0.936876    Top1 68.968750    Top5 95.343750    
2024-04-23 16:31:15,162 - Epoch: [31][  123/  123]    Loss 0.936882    Top1 68.866242    Top5 95.592357    
2024-04-23 16:31:15,361 - ==> Top1: 68.866    Top5: 95.592    Loss: 0.937

2024-04-23 16:31:15,367 - ==> Best [Top1: 69.325   Top5: 95.873   Sparsity:0.00   Params: 371568 on epoch: 28]
2024-04-23 16:31:15,368 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:31:15,406 - 

2024-04-23 16:31:15,407 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:31:32,153 - Epoch: [32][  100/  296]    Overall Loss 1.098162    Objective Loss 1.098162                                        LR 0.000320    Time 0.167211    
2024-04-23 16:31:43,180 - Epoch: [32][  200/  296]    Overall Loss 1.088988    Objective Loss 1.088988                                        LR 0.000320    Time 0.138644    
2024-04-23 16:31:57,980 - Epoch: [32][  296/  296]    Overall Loss 1.088324    Objective Loss 1.088324    Top1 70.491803    Top5 96.721311    LR 0.000320    Time 0.143612    
2024-04-23 16:31:58,221 - --- validate (epoch=32)-----------
2024-04-23 16:31:58,222 - 3925 samples (32 per mini-batch)
2024-04-23 16:32:14,343 - Epoch: [32][  100/  123]    Loss 0.911797    Top1 70.218750    Top5 96.062500    
2024-04-23 16:32:17,569 - Epoch: [32][  123/  123]    Loss 0.918080    Top1 70.114650    Top5 96.101911    
2024-04-23 16:32:17,777 - ==> Top1: 70.115    Top5: 96.102    Loss: 0.918

2024-04-23 16:32:17,786 - ==> Best [Top1: 70.115   Top5: 96.102   Sparsity:0.00   Params: 371568 on epoch: 32]
2024-04-23 16:32:17,786 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:32:17,850 - 

2024-04-23 16:32:17,851 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:32:35,535 - Epoch: [33][  100/  296]    Overall Loss 1.116787    Objective Loss 1.116787                                        LR 0.000320    Time 0.176618    
2024-04-23 16:32:52,149 - Epoch: [33][  200/  296]    Overall Loss 1.100550    Objective Loss 1.100550                                        LR 0.000320    Time 0.171275    
2024-04-23 16:33:06,447 - Epoch: [33][  296/  296]    Overall Loss 1.112659    Objective Loss 1.112659    Top1 52.459016    Top5 88.524590    LR 0.000320    Time 0.163961    
2024-04-23 16:33:06,704 - --- validate (epoch=33)-----------
2024-04-23 16:33:06,705 - 3925 samples (32 per mini-batch)
2024-04-23 16:33:27,437 - Epoch: [33][  100/  123]    Loss 0.978766    Top1 67.500000    Top5 95.406250    
2024-04-23 16:33:31,064 - Epoch: [33][  123/  123]    Loss 0.977772    Top1 67.439490    Top5 95.592357    
2024-04-23 16:33:31,270 - ==> Top1: 67.439    Top5: 95.592    Loss: 0.978

2024-04-23 16:33:31,279 - ==> Best [Top1: 70.115   Top5: 96.102   Sparsity:0.00   Params: 371568 on epoch: 32]
2024-04-23 16:33:31,280 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:33:31,327 - 

2024-04-23 16:33:31,328 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:33:49,413 - Epoch: [34][  100/  296]    Overall Loss 1.084642    Objective Loss 1.084642                                        LR 0.000320    Time 0.180633    
2024-04-23 16:34:09,470 - Epoch: [34][  200/  296]    Overall Loss 1.093419    Objective Loss 1.093419                                        LR 0.000320    Time 0.190473    
2024-04-23 16:34:25,737 - Epoch: [34][  296/  296]    Overall Loss 1.086060    Objective Loss 1.086060    Top1 75.409836    Top5 96.721311    LR 0.000320    Time 0.183584    
2024-04-23 16:34:26,012 - --- validate (epoch=34)-----------
2024-04-23 16:34:26,013 - 3925 samples (32 per mini-batch)
2024-04-23 16:34:44,257 - Epoch: [34][  100/  123]    Loss 0.876770    Top1 71.031250    Top5 96.125000    
2024-04-23 16:34:49,377 - Epoch: [34][  123/  123]    Loss 0.879252    Top1 71.184713    Top5 96.152866    
2024-04-23 16:34:49,604 - ==> Top1: 71.185    Top5: 96.153    Loss: 0.879

2024-04-23 16:34:49,615 - ==> Best [Top1: 71.185   Top5: 96.153   Sparsity:0.00   Params: 371568 on epoch: 34]
2024-04-23 16:34:49,616 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:34:49,691 - 

2024-04-23 16:34:49,692 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:35:06,999 - Epoch: [35][  100/  296]    Overall Loss 1.063026    Objective Loss 1.063026                                        LR 0.000320    Time 0.172849    
2024-04-23 16:35:23,558 - Epoch: [35][  200/  296]    Overall Loss 1.059263    Objective Loss 1.059263                                        LR 0.000320    Time 0.169109    
2024-04-23 16:35:38,741 - Epoch: [35][  296/  296]    Overall Loss 1.062482    Objective Loss 1.062482    Top1 65.573770    Top5 98.360656    LR 0.000320    Time 0.165488    
2024-04-23 16:35:38,998 - --- validate (epoch=35)-----------
2024-04-23 16:35:39,000 - 3925 samples (32 per mini-batch)
2024-04-23 16:35:57,917 - Epoch: [35][  100/  123]    Loss 0.930801    Top1 68.968750    Top5 96.000000    
2024-04-23 16:36:02,418 - Epoch: [35][  123/  123]    Loss 0.911854    Top1 69.554140    Top5 96.178344    
2024-04-23 16:36:02,757 - ==> Top1: 69.554    Top5: 96.178    Loss: 0.912

2024-04-23 16:36:02,767 - ==> Best [Top1: 71.185   Top5: 96.153   Sparsity:0.00   Params: 371568 on epoch: 34]
2024-04-23 16:36:02,768 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:36:02,823 - 

2024-04-23 16:36:02,824 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:36:21,819 - Epoch: [36][  100/  296]    Overall Loss 1.095063    Objective Loss 1.095063                                        LR 0.000320    Time 0.189725    
2024-04-23 16:36:38,195 - Epoch: [36][  200/  296]    Overall Loss 1.066800    Objective Loss 1.066800                                        LR 0.000320    Time 0.176629    
2024-04-23 16:36:54,433 - Epoch: [36][  296/  296]    Overall Loss 1.074140    Objective Loss 1.074140    Top1 49.180328    Top5 96.721311    LR 0.000320    Time 0.174131    
2024-04-23 16:36:54,739 - --- validate (epoch=36)-----------
2024-04-23 16:36:54,741 - 3925 samples (32 per mini-batch)
2024-04-23 16:37:15,718 - Epoch: [36][  100/  123]    Loss 0.968356    Top1 69.062500    Top5 95.937500    
2024-04-23 16:37:20,212 - Epoch: [36][  123/  123]    Loss 0.956376    Top1 69.222930    Top5 96.025478    
2024-04-23 16:37:20,447 - ==> Top1: 69.223    Top5: 96.025    Loss: 0.956

2024-04-23 16:37:20,458 - ==> Best [Top1: 71.185   Top5: 96.153   Sparsity:0.00   Params: 371568 on epoch: 34]
2024-04-23 16:37:20,459 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:37:20,533 - 

2024-04-23 16:37:20,534 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:37:37,836 - Epoch: [37][  100/  296]    Overall Loss 1.068685    Objective Loss 1.068685                                        LR 0.000320    Time 0.172790    
2024-04-23 16:37:54,407 - Epoch: [37][  200/  296]    Overall Loss 1.066663    Objective Loss 1.066663                                        LR 0.000320    Time 0.169141    
2024-04-23 16:38:10,416 - Epoch: [37][  296/  296]    Overall Loss 1.085856    Objective Loss 1.085856    Top1 63.934426    Top5 95.081967    LR 0.000320    Time 0.168297    
2024-04-23 16:38:10,705 - --- validate (epoch=37)-----------
2024-04-23 16:38:10,707 - 3925 samples (32 per mini-batch)
2024-04-23 16:38:31,702 - Epoch: [37][  100/  123]    Loss 0.873536    Top1 71.500000    Top5 96.437500    
2024-04-23 16:38:36,445 - Epoch: [37][  123/  123]    Loss 0.879786    Top1 71.363057    Top5 96.254777    
2024-04-23 16:38:36,694 - ==> Top1: 71.363    Top5: 96.255    Loss: 0.880

2024-04-23 16:38:36,704 - ==> Best [Top1: 71.363   Top5: 96.255   Sparsity:0.00   Params: 371568 on epoch: 37]
2024-04-23 16:38:36,705 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:38:36,777 - 

2024-04-23 16:38:36,778 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:38:53,977 - Epoch: [38][  100/  296]    Overall Loss 1.048523    Objective Loss 1.048523                                        LR 0.000320    Time 0.171763    
2024-04-23 16:39:08,511 - Epoch: [38][  200/  296]    Overall Loss 1.054635    Objective Loss 1.054635                                        LR 0.000320    Time 0.158442    
2024-04-23 16:39:24,794 - Epoch: [38][  296/  296]    Overall Loss 1.054747    Objective Loss 1.054747    Top1 65.573770    Top5 98.360656    LR 0.000320    Time 0.161993    
2024-04-23 16:39:25,077 - --- validate (epoch=38)-----------
2024-04-23 16:39:25,079 - 3925 samples (32 per mini-batch)
2024-04-23 16:39:45,576 - Epoch: [38][  100/  123]    Loss 0.922520    Top1 69.937500    Top5 95.625000    
2024-04-23 16:39:49,732 - Epoch: [38][  123/  123]    Loss 0.917639    Top1 70.165605    Top5 95.541401    
2024-04-23 16:39:49,963 - ==> Top1: 70.166    Top5: 95.541    Loss: 0.918

2024-04-23 16:39:49,975 - ==> Best [Top1: 71.363   Top5: 96.255   Sparsity:0.00   Params: 371568 on epoch: 37]
2024-04-23 16:39:49,976 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:39:50,037 - 

2024-04-23 16:39:50,038 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:40:08,797 - Epoch: [39][  100/  296]    Overall Loss 1.047822    Objective Loss 1.047822                                        LR 0.000320    Time 0.187363    
2024-04-23 16:40:24,013 - Epoch: [39][  200/  296]    Overall Loss 1.055983    Objective Loss 1.055983                                        LR 0.000320    Time 0.169654    
2024-04-23 16:40:41,330 - Epoch: [39][  296/  296]    Overall Loss 1.057225    Objective Loss 1.057225    Top1 70.491803    Top5 95.081967    LR 0.000320    Time 0.173062    
2024-04-23 16:40:41,606 - --- validate (epoch=39)-----------
2024-04-23 16:40:41,608 - 3925 samples (32 per mini-batch)
2024-04-23 16:41:03,318 - Epoch: [39][  100/  123]    Loss 0.894054    Top1 70.968750    Top5 96.218750    
2024-04-23 16:41:07,240 - Epoch: [39][  123/  123]    Loss 0.883352    Top1 71.031847    Top5 96.331210    
2024-04-23 16:41:07,462 - ==> Top1: 71.032    Top5: 96.331    Loss: 0.883

2024-04-23 16:41:07,476 - ==> Best [Top1: 71.363   Top5: 96.255   Sparsity:0.00   Params: 371568 on epoch: 37]
2024-04-23 16:41:07,478 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:41:07,574 - 

2024-04-23 16:41:07,575 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:41:30,393 - Epoch: [40][  100/  296]    Overall Loss 1.049838    Objective Loss 1.049838                                        LR 0.000320    Time 0.227920    
2024-04-23 16:41:50,815 - Epoch: [40][  200/  296]    Overall Loss 1.044020    Objective Loss 1.044020                                        LR 0.000320    Time 0.215938    
2024-04-23 16:42:11,352 - Epoch: [40][  296/  296]    Overall Loss 1.055013    Objective Loss 1.055013    Top1 67.213115    Top5 98.360656    LR 0.000320    Time 0.215218    
2024-04-23 16:42:11,626 - --- validate (epoch=40)-----------
2024-04-23 16:42:11,628 - 3925 samples (32 per mini-batch)
2024-04-23 16:42:34,812 - Epoch: [40][  100/  123]    Loss 0.906082    Top1 70.750000    Top5 95.968750    
2024-04-23 16:42:38,994 - Epoch: [40][  123/  123]    Loss 0.922665    Top1 70.369427    Top5 95.745223    
2024-04-23 16:42:39,345 - ==> Top1: 70.369    Top5: 95.745    Loss: 0.923

2024-04-23 16:42:39,357 - ==> Best [Top1: 71.363   Top5: 96.255   Sparsity:0.00   Params: 371568 on epoch: 37]
2024-04-23 16:42:39,358 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:42:39,414 - 

2024-04-23 16:42:39,415 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:43:04,058 - Epoch: [41][  100/  296]    Overall Loss 1.028796    Objective Loss 1.028796                                        LR 0.000320    Time 0.246180    
2024-04-23 16:43:26,015 - Epoch: [41][  200/  296]    Overall Loss 1.034427    Objective Loss 1.034427                                        LR 0.000320    Time 0.232761    
2024-04-23 16:43:46,131 - Epoch: [41][  296/  296]    Overall Loss 1.044421    Objective Loss 1.044421    Top1 60.655738    Top5 90.163934    LR 0.000320    Time 0.225166    
2024-04-23 16:43:46,495 - --- validate (epoch=41)-----------
2024-04-23 16:43:46,496 - 3925 samples (32 per mini-batch)
2024-04-23 16:44:14,261 - Epoch: [41][  100/  123]    Loss 0.900040    Top1 70.656250    Top5 96.093750    
2024-04-23 16:44:19,310 - Epoch: [41][  123/  123]    Loss 0.903871    Top1 70.369427    Top5 95.898089    
2024-04-23 16:44:19,490 - ==> Top1: 70.369    Top5: 95.898    Loss: 0.904

2024-04-23 16:44:19,500 - ==> Best [Top1: 71.363   Top5: 96.255   Sparsity:0.00   Params: 371568 on epoch: 37]
2024-04-23 16:44:19,501 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:44:19,548 - 

2024-04-23 16:44:19,549 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:44:36,520 - Epoch: [42][  100/  296]    Overall Loss 1.054670    Objective Loss 1.054670                                        LR 0.000320    Time 0.169517    
2024-04-23 16:44:55,965 - Epoch: [42][  200/  296]    Overall Loss 1.040886    Objective Loss 1.040886                                        LR 0.000320    Time 0.181872    
2024-04-23 16:45:13,768 - Epoch: [42][  296/  296]    Overall Loss 1.038533    Objective Loss 1.038533    Top1 70.491803    Top5 95.081967    LR 0.000320    Time 0.182954    
2024-04-23 16:45:14,059 - --- validate (epoch=42)-----------
2024-04-23 16:45:14,063 - 3925 samples (32 per mini-batch)
2024-04-23 16:45:35,093 - Epoch: [42][  100/  123]    Loss 1.011176    Top1 66.031250    Top5 94.906250    
2024-04-23 16:45:39,722 - Epoch: [42][  123/  123]    Loss 1.007829    Top1 66.114650    Top5 94.904459    
2024-04-23 16:45:39,979 - ==> Top1: 66.115    Top5: 94.904    Loss: 1.008

2024-04-23 16:45:39,991 - ==> Best [Top1: 71.363   Top5: 96.255   Sparsity:0.00   Params: 371568 on epoch: 37]
2024-04-23 16:45:39,993 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:45:40,084 - 

2024-04-23 16:45:40,085 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:46:01,768 - Epoch: [43][  100/  296]    Overall Loss 1.018168    Objective Loss 1.018168                                        LR 0.000320    Time 0.216578    
2024-04-23 16:46:20,370 - Epoch: [43][  200/  296]    Overall Loss 1.022992    Objective Loss 1.022992                                        LR 0.000320    Time 0.201190    
2024-04-23 16:46:37,423 - Epoch: [43][  296/  296]    Overall Loss 1.031308    Objective Loss 1.031308    Top1 62.295082    Top5 96.721311    LR 0.000320    Time 0.193481    
2024-04-23 16:46:37,745 - --- validate (epoch=43)-----------
2024-04-23 16:46:37,747 - 3925 samples (32 per mini-batch)
2024-04-23 16:46:58,778 - Epoch: [43][  100/  123]    Loss 0.891274    Top1 70.718750    Top5 95.843750    
2024-04-23 16:47:03,684 - Epoch: [43][  123/  123]    Loss 0.887048    Top1 70.929936    Top5 95.872611    
2024-04-23 16:47:03,920 - ==> Top1: 70.930    Top5: 95.873    Loss: 0.887

2024-04-23 16:47:03,932 - ==> Best [Top1: 71.363   Top5: 96.255   Sparsity:0.00   Params: 371568 on epoch: 37]
2024-04-23 16:47:03,933 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:47:03,989 - 

2024-04-23 16:47:03,990 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:47:22,963 - Epoch: [44][  100/  296]    Overall Loss 1.040499    Objective Loss 1.040499                                        LR 0.000320    Time 0.189500    
2024-04-23 16:47:42,658 - Epoch: [44][  200/  296]    Overall Loss 1.021378    Objective Loss 1.021378                                        LR 0.000320    Time 0.193112    
2024-04-23 16:47:56,973 - Epoch: [44][  296/  296]    Overall Loss 1.026612    Objective Loss 1.026612    Top1 72.131148    Top5 96.721311    LR 0.000320    Time 0.178768    
2024-04-23 16:47:57,260 - --- validate (epoch=44)-----------
2024-04-23 16:47:57,261 - 3925 samples (32 per mini-batch)
2024-04-23 16:48:18,877 - Epoch: [44][  100/  123]    Loss 0.880923    Top1 71.406250    Top5 96.406250    
2024-04-23 16:48:23,304 - Epoch: [44][  123/  123]    Loss 0.875373    Top1 71.541401    Top5 96.280255    
2024-04-23 16:48:23,558 - ==> Top1: 71.541    Top5: 96.280    Loss: 0.875

2024-04-23 16:48:23,570 - ==> Best [Top1: 71.541   Top5: 96.280   Sparsity:0.00   Params: 371568 on epoch: 44]
2024-04-23 16:48:23,572 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:48:23,680 - 

2024-04-23 16:48:23,681 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:48:43,950 - Epoch: [45][  100/  296]    Overall Loss 1.015563    Objective Loss 1.015563                                        LR 0.000320    Time 0.202449    
2024-04-23 16:49:02,078 - Epoch: [45][  200/  296]    Overall Loss 1.007354    Objective Loss 1.007354                                        LR 0.000320    Time 0.191747    
2024-04-23 16:49:13,614 - Epoch: [45][  296/  296]    Overall Loss 1.019168    Objective Loss 1.019168    Top1 65.573770    Top5 96.721311    LR 0.000320    Time 0.168462    
2024-04-23 16:49:13,836 - --- validate (epoch=45)-----------
2024-04-23 16:49:13,837 - 3925 samples (32 per mini-batch)
2024-04-23 16:49:33,071 - Epoch: [45][  100/  123]    Loss 0.895793    Top1 70.625000    Top5 95.468750    
2024-04-23 16:49:37,243 - Epoch: [45][  123/  123]    Loss 0.888823    Top1 70.394904    Top5 95.719745    
2024-04-23 16:49:37,472 - ==> Top1: 70.395    Top5: 95.720    Loss: 0.889

2024-04-23 16:49:37,483 - ==> Best [Top1: 71.541   Top5: 96.280   Sparsity:0.00   Params: 371568 on epoch: 44]
2024-04-23 16:49:37,484 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:49:37,540 - 

2024-04-23 16:49:37,541 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:49:57,543 - Epoch: [46][  100/  296]    Overall Loss 1.012220    Objective Loss 1.012220                                        LR 0.000320    Time 0.199784    
2024-04-23 16:50:15,531 - Epoch: [46][  200/  296]    Overall Loss 1.034638    Objective Loss 1.034638                                        LR 0.000320    Time 0.189719    
2024-04-23 16:50:32,314 - Epoch: [46][  296/  296]    Overall Loss 1.028463    Objective Loss 1.028463    Top1 70.491803    Top5 95.081967    LR 0.000320    Time 0.184817    
2024-04-23 16:50:32,578 - --- validate (epoch=46)-----------
2024-04-23 16:50:32,580 - 3925 samples (32 per mini-batch)
2024-04-23 16:50:54,247 - Epoch: [46][  100/  123]    Loss 0.890577    Top1 71.750000    Top5 96.062500    
2024-04-23 16:50:58,982 - Epoch: [46][  123/  123]    Loss 0.887104    Top1 71.847134    Top5 96.076433    
2024-04-23 16:50:59,248 - ==> Top1: 71.847    Top5: 96.076    Loss: 0.887

2024-04-23 16:50:59,259 - ==> Best [Top1: 71.847   Top5: 96.076   Sparsity:0.00   Params: 371568 on epoch: 46]
2024-04-23 16:50:59,259 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:50:59,334 - 

2024-04-23 16:50:59,335 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:51:19,717 - Epoch: [47][  100/  296]    Overall Loss 1.004797    Objective Loss 1.004797                                        LR 0.000320    Time 0.203574    
2024-04-23 16:51:37,811 - Epoch: [47][  200/  296]    Overall Loss 0.994769    Objective Loss 0.994769                                        LR 0.000320    Time 0.192150    
2024-04-23 16:51:58,541 - Epoch: [47][  296/  296]    Overall Loss 1.002153    Objective Loss 1.002153    Top1 70.491803    Top5 95.081967    LR 0.000320    Time 0.199797    
2024-04-23 16:51:58,847 - --- validate (epoch=47)-----------
2024-04-23 16:51:58,848 - 3925 samples (32 per mini-batch)
2024-04-23 16:52:22,223 - Epoch: [47][  100/  123]    Loss 0.919617    Top1 69.906250    Top5 95.250000    
2024-04-23 16:52:27,007 - Epoch: [47][  123/  123]    Loss 0.914687    Top1 69.630573    Top5 95.363057    
2024-04-23 16:52:27,276 - ==> Top1: 69.631    Top5: 95.363    Loss: 0.915

2024-04-23 16:52:27,286 - ==> Best [Top1: 71.847   Top5: 96.076   Sparsity:0.00   Params: 371568 on epoch: 46]
2024-04-23 16:52:27,287 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:52:27,344 - 

2024-04-23 16:52:27,345 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:52:46,998 - Epoch: [48][  100/  296]    Overall Loss 1.006747    Objective Loss 1.006747                                        LR 0.000320    Time 0.196316    
2024-04-23 16:53:04,808 - Epoch: [48][  200/  296]    Overall Loss 1.009862    Objective Loss 1.009862                                        LR 0.000320    Time 0.187099    
2024-04-23 16:53:18,364 - Epoch: [48][  296/  296]    Overall Loss 1.011563    Objective Loss 1.011563    Top1 65.573770    Top5 96.721311    LR 0.000320    Time 0.172145    
2024-04-23 16:53:18,630 - --- validate (epoch=48)-----------
2024-04-23 16:53:18,631 - 3925 samples (32 per mini-batch)
2024-04-23 16:53:36,454 - Epoch: [48][  100/  123]    Loss 0.799686    Top1 73.500000    Top5 96.750000    
2024-04-23 16:53:40,619 - Epoch: [48][  123/  123]    Loss 0.818196    Top1 73.121019    Top5 96.611465    
2024-04-23 16:53:40,838 - ==> Top1: 73.121    Top5: 96.611    Loss: 0.818

2024-04-23 16:53:40,849 - ==> Best [Top1: 73.121   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 48]
2024-04-23 16:53:40,849 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:53:40,922 - 

2024-04-23 16:53:40,923 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:54:00,424 - Epoch: [49][  100/  296]    Overall Loss 0.949630    Objective Loss 0.949630                                        LR 0.000320    Time 0.194771    
2024-04-23 16:54:15,462 - Epoch: [49][  200/  296]    Overall Loss 0.996441    Objective Loss 0.996441                                        LR 0.000320    Time 0.172467    
2024-04-23 16:54:29,501 - Epoch: [49][  296/  296]    Overall Loss 0.984937    Objective Loss 0.984937    Top1 65.573770    Top5 95.081967    LR 0.000320    Time 0.163892    
2024-04-23 16:54:29,784 - --- validate (epoch=49)-----------
2024-04-23 16:54:29,785 - 3925 samples (32 per mini-batch)
2024-04-23 16:54:46,673 - Epoch: [49][  100/  123]    Loss 0.855292    Top1 71.625000    Top5 96.312500    
2024-04-23 16:54:49,905 - Epoch: [49][  123/  123]    Loss 0.864500    Top1 71.439490    Top5 96.127389    
2024-04-23 16:54:50,141 - ==> Top1: 71.439    Top5: 96.127    Loss: 0.864

2024-04-23 16:54:50,151 - ==> Best [Top1: 73.121   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 48]
2024-04-23 16:54:50,152 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:54:50,196 - 

2024-04-23 16:54:50,197 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:55:05,442 - Epoch: [50][  100/  296]    Overall Loss 1.000212    Objective Loss 1.000212                                        LR 0.000320    Time 0.152226    
2024-04-23 16:55:19,774 - Epoch: [50][  200/  296]    Overall Loss 0.991660    Objective Loss 0.991660                                        LR 0.000320    Time 0.147667    
2024-04-23 16:55:34,168 - Epoch: [50][  296/  296]    Overall Loss 0.997967    Objective Loss 0.997967    Top1 70.491803    Top5 98.360656    LR 0.000320    Time 0.148333    
2024-04-23 16:55:34,385 - --- validate (epoch=50)-----------
2024-04-23 16:55:34,387 - 3925 samples (32 per mini-batch)
2024-04-23 16:55:50,394 - Epoch: [50][  100/  123]    Loss 0.853664    Top1 71.406250    Top5 96.156250    
2024-04-23 16:55:53,719 - Epoch: [50][  123/  123]    Loss 0.850513    Top1 71.617834    Top5 96.203822    
2024-04-23 16:55:53,926 - ==> Top1: 71.618    Top5: 96.204    Loss: 0.851

2024-04-23 16:55:53,935 - ==> Best [Top1: 73.121   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 48]
2024-04-23 16:55:53,936 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:55:53,983 - 

2024-04-23 16:55:53,984 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:56:10,415 - Epoch: [51][  100/  296]    Overall Loss 1.005283    Objective Loss 1.005283                                        LR 0.000320    Time 0.164074    
2024-04-23 16:56:25,712 - Epoch: [51][  200/  296]    Overall Loss 1.011160    Objective Loss 1.011160                                        LR 0.000320    Time 0.158409    
2024-04-23 16:56:42,387 - Epoch: [51][  296/  296]    Overall Loss 1.010149    Objective Loss 1.010149    Top1 65.573770    Top5 95.081967    LR 0.000320    Time 0.163297    
2024-04-23 16:56:42,648 - --- validate (epoch=51)-----------
2024-04-23 16:56:42,650 - 3925 samples (32 per mini-batch)
2024-04-23 16:57:02,305 - Epoch: [51][  100/  123]    Loss 0.938104    Top1 68.687500    Top5 95.218750    
2024-04-23 16:57:05,897 - Epoch: [51][  123/  123]    Loss 0.944894    Top1 68.229299    Top5 95.363057    
2024-04-23 16:57:06,127 - ==> Top1: 68.229    Top5: 95.363    Loss: 0.945

2024-04-23 16:57:06,136 - ==> Best [Top1: 73.121   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 48]
2024-04-23 16:57:06,137 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:57:06,202 - 

2024-04-23 16:57:06,203 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:57:20,688 - Epoch: [52][  100/  296]    Overall Loss 1.004639    Objective Loss 1.004639                                        LR 0.000320    Time 0.144642    
2024-04-23 16:57:35,268 - Epoch: [52][  200/  296]    Overall Loss 0.995901    Objective Loss 0.995901                                        LR 0.000320    Time 0.145108    
2024-04-23 16:57:51,079 - Epoch: [52][  296/  296]    Overall Loss 0.994067    Objective Loss 0.994067    Top1 67.213115    Top5 95.081967    LR 0.000320    Time 0.151394    
2024-04-23 16:57:51,372 - --- validate (epoch=52)-----------
2024-04-23 16:57:51,373 - 3925 samples (32 per mini-batch)
2024-04-23 16:58:13,140 - Epoch: [52][  100/  123]    Loss 0.879651    Top1 70.593750    Top5 96.156250    
2024-04-23 16:58:17,451 - Epoch: [52][  123/  123]    Loss 0.870473    Top1 71.031847    Top5 96.229299    
2024-04-23 16:58:17,691 - ==> Top1: 71.032    Top5: 96.229    Loss: 0.870

2024-04-23 16:58:17,701 - ==> Best [Top1: 73.121   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 48]
2024-04-23 16:58:17,702 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:58:17,778 - 

2024-04-23 16:58:17,779 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:58:35,205 - Epoch: [53][  100/  296]    Overall Loss 0.979762    Objective Loss 0.979762                                        LR 0.000320    Time 0.174033    
2024-04-23 16:58:48,138 - Epoch: [53][  200/  296]    Overall Loss 0.968999    Objective Loss 0.968999                                        LR 0.000320    Time 0.151574    
2024-04-23 16:59:02,970 - Epoch: [53][  296/  296]    Overall Loss 0.977535    Objective Loss 0.977535    Top1 70.491803    Top5 93.442623    LR 0.000320    Time 0.152457    
2024-04-23 16:59:03,267 - --- validate (epoch=53)-----------
2024-04-23 16:59:03,269 - 3925 samples (32 per mini-batch)
2024-04-23 16:59:19,050 - Epoch: [53][  100/  123]    Loss 0.817105    Top1 73.656250    Top5 96.343750    
2024-04-23 16:59:23,085 - Epoch: [53][  123/  123]    Loss 0.812779    Top1 73.477707    Top5 96.407643    
2024-04-23 16:59:23,266 - ==> Top1: 73.478    Top5: 96.408    Loss: 0.813

2024-04-23 16:59:23,274 - ==> Best [Top1: 73.478   Top5: 96.408   Sparsity:0.00   Params: 371568 on epoch: 53]
2024-04-23 16:59:23,275 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 16:59:23,326 - 

2024-04-23 16:59:23,327 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:59:38,537 - Epoch: [54][  100/  296]    Overall Loss 0.966566    Objective Loss 0.966566                                        LR 0.000320    Time 0.151888    
2024-04-23 16:59:53,540 - Epoch: [54][  200/  296]    Overall Loss 0.990336    Objective Loss 0.990336                                        LR 0.000320    Time 0.150850    
2024-04-23 17:00:05,862 - Epoch: [54][  296/  296]    Overall Loss 1.002116    Objective Loss 1.002116    Top1 75.409836    Top5 95.081967    LR 0.000320    Time 0.143482    
2024-04-23 17:00:06,164 - --- validate (epoch=54)-----------
2024-04-23 17:00:06,165 - 3925 samples (32 per mini-batch)
2024-04-23 17:00:22,537 - Epoch: [54][  100/  123]    Loss 0.895051    Top1 70.187500    Top5 96.281250    
2024-04-23 17:00:25,496 - Epoch: [54][  123/  123]    Loss 0.891964    Top1 70.420382    Top5 96.101911    
2024-04-23 17:00:25,684 - ==> Top1: 70.420    Top5: 96.102    Loss: 0.892

2024-04-23 17:00:25,694 - ==> Best [Top1: 73.478   Top5: 96.408   Sparsity:0.00   Params: 371568 on epoch: 53]
2024-04-23 17:00:25,695 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:00:25,736 - 

2024-04-23 17:00:25,736 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:00:42,175 - Epoch: [55][  100/  296]    Overall Loss 0.955915    Objective Loss 0.955915                                        LR 0.000320    Time 0.164172    
2024-04-23 17:00:56,412 - Epoch: [55][  200/  296]    Overall Loss 0.959670    Objective Loss 0.959670                                        LR 0.000320    Time 0.153144    
2024-04-23 17:01:08,044 - Epoch: [55][  296/  296]    Overall Loss 0.983650    Objective Loss 0.983650    Top1 67.213115    Top5 93.442623    LR 0.000320    Time 0.142713    
2024-04-23 17:01:08,265 - --- validate (epoch=55)-----------
2024-04-23 17:01:08,265 - 3925 samples (32 per mini-batch)
2024-04-23 17:01:24,361 - Epoch: [55][  100/  123]    Loss 0.817634    Top1 73.093750    Top5 96.531250    
2024-04-23 17:01:26,792 - Epoch: [55][  123/  123]    Loss 0.827916    Top1 72.687898    Top5 96.433121    
2024-04-23 17:01:27,008 - ==> Top1: 72.688    Top5: 96.433    Loss: 0.828

2024-04-23 17:01:27,016 - ==> Best [Top1: 73.478   Top5: 96.408   Sparsity:0.00   Params: 371568 on epoch: 53]
2024-04-23 17:01:27,016 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:01:27,061 - 

2024-04-23 17:01:27,062 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:01:42,061 - Epoch: [56][  100/  296]    Overall Loss 0.977232    Objective Loss 0.977232                                        LR 0.000320    Time 0.149755    
2024-04-23 17:01:55,581 - Epoch: [56][  200/  296]    Overall Loss 0.973787    Objective Loss 0.973787                                        LR 0.000320    Time 0.142374    
2024-04-23 17:02:09,712 - Epoch: [56][  296/  296]    Overall Loss 0.966730    Objective Loss 0.966730    Top1 68.852459    Top5 91.803279    LR 0.000320    Time 0.143869    
2024-04-23 17:02:09,941 - --- validate (epoch=56)-----------
2024-04-23 17:02:09,942 - 3925 samples (32 per mini-batch)
2024-04-23 17:02:24,465 - Epoch: [56][  100/  123]    Loss 0.888560    Top1 71.218750    Top5 96.062500    
2024-04-23 17:02:27,392 - Epoch: [56][  123/  123]    Loss 0.894712    Top1 70.853503    Top5 96.050955    
2024-04-23 17:02:27,619 - ==> Top1: 70.854    Top5: 96.051    Loss: 0.895

2024-04-23 17:02:27,627 - ==> Best [Top1: 73.478   Top5: 96.408   Sparsity:0.00   Params: 371568 on epoch: 53]
2024-04-23 17:02:27,628 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:02:27,674 - 

2024-04-23 17:02:27,674 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:02:41,537 - Epoch: [57][  100/  296]    Overall Loss 0.997638    Objective Loss 0.997638                                        LR 0.000320    Time 0.138416    
2024-04-23 17:02:53,681 - Epoch: [57][  200/  296]    Overall Loss 0.981996    Objective Loss 0.981996                                        LR 0.000320    Time 0.129820    
2024-04-23 17:03:05,426 - Epoch: [57][  296/  296]    Overall Loss 0.981618    Objective Loss 0.981618    Top1 63.934426    Top5 91.803279    LR 0.000320    Time 0.127329    
2024-04-23 17:03:05,654 - --- validate (epoch=57)-----------
2024-04-23 17:03:05,656 - 3925 samples (32 per mini-batch)
2024-04-23 17:03:25,364 - Epoch: [57][  100/  123]    Loss 0.912472    Top1 69.718750    Top5 96.281250    
2024-04-23 17:03:28,314 - Epoch: [57][  123/  123]    Loss 0.918633    Top1 69.452229    Top5 96.229299    
2024-04-23 17:03:28,497 - ==> Top1: 69.452    Top5: 96.229    Loss: 0.919

2024-04-23 17:03:28,507 - ==> Best [Top1: 73.478   Top5: 96.408   Sparsity:0.00   Params: 371568 on epoch: 53]
2024-04-23 17:03:28,507 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:03:28,546 - 

2024-04-23 17:03:28,547 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:03:39,435 - Epoch: [58][  100/  296]    Overall Loss 0.949686    Objective Loss 0.949686                                        LR 0.000320    Time 0.108673    
2024-04-23 17:03:53,075 - Epoch: [58][  200/  296]    Overall Loss 0.970934    Objective Loss 0.970934                                        LR 0.000320    Time 0.122429    
2024-04-23 17:04:05,809 - Epoch: [58][  296/  296]    Overall Loss 0.981365    Objective Loss 0.981365    Top1 70.491803    Top5 98.360656    LR 0.000320    Time 0.125680    
2024-04-23 17:04:06,004 - --- validate (epoch=58)-----------
2024-04-23 17:04:06,005 - 3925 samples (32 per mini-batch)
2024-04-23 17:04:25,321 - Epoch: [58][  100/  123]    Loss 0.825209    Top1 72.843750    Top5 95.937500    
2024-04-23 17:04:27,919 - Epoch: [58][  123/  123]    Loss 0.823274    Top1 72.662420    Top5 96.152866    
2024-04-23 17:04:28,231 - ==> Top1: 72.662    Top5: 96.153    Loss: 0.823

2024-04-23 17:04:28,237 - ==> Best [Top1: 73.478   Top5: 96.408   Sparsity:0.00   Params: 371568 on epoch: 53]
2024-04-23 17:04:28,237 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:04:28,280 - 

2024-04-23 17:04:28,281 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:04:38,631 - Epoch: [59][  100/  296]    Overall Loss 0.931412    Objective Loss 0.931412                                        LR 0.000320    Time 0.103291    
2024-04-23 17:04:47,211 - Epoch: [59][  200/  296]    Overall Loss 0.931674    Objective Loss 0.931674                                        LR 0.000320    Time 0.094459    
2024-04-23 17:04:56,267 - Epoch: [59][  296/  296]    Overall Loss 0.950928    Objective Loss 0.950928    Top1 73.770492    Top5 95.081967    LR 0.000320    Time 0.094358    
2024-04-23 17:04:56,448 - --- validate (epoch=59)-----------
2024-04-23 17:04:56,449 - 3925 samples (32 per mini-batch)
2024-04-23 17:05:09,866 - Epoch: [59][  100/  123]    Loss 0.898952    Top1 69.687500    Top5 95.968750    
2024-04-23 17:05:12,288 - Epoch: [59][  123/  123]    Loss 0.886331    Top1 70.369427    Top5 96.152866    
2024-04-23 17:05:12,481 - ==> Top1: 70.369    Top5: 96.153    Loss: 0.886

2024-04-23 17:05:12,487 - ==> Best [Top1: 73.478   Top5: 96.408   Sparsity:0.00   Params: 371568 on epoch: 53]
2024-04-23 17:05:12,487 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:05:12,520 - 

2024-04-23 17:05:12,522 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:05:24,154 - Epoch: [60][  100/  296]    Overall Loss 0.952211    Objective Loss 0.952211                                        LR 0.000320    Time 0.116125    
2024-04-23 17:05:32,100 - Epoch: [60][  200/  296]    Overall Loss 0.959928    Objective Loss 0.959928                                        LR 0.000320    Time 0.097700    
2024-04-23 17:05:42,405 - Epoch: [60][  296/  296]    Overall Loss 0.965652    Objective Loss 0.965652    Top1 68.852459    Top5 98.360656    LR 0.000320    Time 0.100765    
2024-04-23 17:05:42,631 - --- validate (epoch=60)-----------
2024-04-23 17:05:42,632 - 3925 samples (32 per mini-batch)
2024-04-23 17:05:53,391 - Epoch: [60][  100/  123]    Loss 0.830870    Top1 72.656250    Top5 96.250000    
2024-04-23 17:05:55,333 - Epoch: [60][  123/  123]    Loss 0.838872    Top1 72.484076    Top5 96.178344    
2024-04-23 17:05:55,617 - ==> Top1: 72.484    Top5: 96.178    Loss: 0.839

2024-04-23 17:05:55,625 - ==> Best [Top1: 73.478   Top5: 96.408   Sparsity:0.00   Params: 371568 on epoch: 53]
2024-04-23 17:05:55,625 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:05:55,664 - 

2024-04-23 17:05:55,665 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:06:04,808 - Epoch: [61][  100/  296]    Overall Loss 0.963555    Objective Loss 0.963555                                        LR 0.000320    Time 0.091264    
2024-04-23 17:06:13,561 - Epoch: [61][  200/  296]    Overall Loss 0.955212    Objective Loss 0.955212                                        LR 0.000320    Time 0.089307    
2024-04-23 17:06:22,607 - Epoch: [61][  296/  296]    Overall Loss 0.945801    Objective Loss 0.945801    Top1 73.770492    Top5 95.081967    LR 0.000320    Time 0.090842    
2024-04-23 17:06:22,853 - --- validate (epoch=61)-----------
2024-04-23 17:06:22,854 - 3925 samples (32 per mini-batch)
2024-04-23 17:06:37,098 - Epoch: [61][  100/  123]    Loss 0.811763    Top1 74.031250    Top5 96.375000    
2024-04-23 17:06:39,677 - Epoch: [61][  123/  123]    Loss 0.809774    Top1 74.140127    Top5 96.484076    
2024-04-23 17:06:40,003 - ==> Top1: 74.140    Top5: 96.484    Loss: 0.810

2024-04-23 17:06:40,010 - ==> Best [Top1: 74.140   Top5: 96.484   Sparsity:0.00   Params: 371568 on epoch: 61]
2024-04-23 17:06:40,010 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:06:40,079 - 

2024-04-23 17:06:40,080 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:06:53,515 - Epoch: [62][  100/  296]    Overall Loss 0.953718    Objective Loss 0.953718                                        LR 0.000320    Time 0.134114    
2024-04-23 17:07:03,327 - Epoch: [62][  200/  296]    Overall Loss 0.939588    Objective Loss 0.939588                                        LR 0.000320    Time 0.116018    
2024-04-23 17:07:13,464 - Epoch: [62][  296/  296]    Overall Loss 0.955011    Objective Loss 0.955011    Top1 78.688525    Top5 93.442623    LR 0.000320    Time 0.112577    
2024-04-23 17:07:13,719 - --- validate (epoch=62)-----------
2024-04-23 17:07:13,719 - 3925 samples (32 per mini-batch)
2024-04-23 17:07:31,422 - Epoch: [62][  100/  123]    Loss 0.779901    Top1 73.625000    Top5 96.656250    
2024-04-23 17:07:36,267 - Epoch: [62][  123/  123]    Loss 0.798703    Top1 73.171975    Top5 96.585987    
2024-04-23 17:07:36,554 - ==> Top1: 73.172    Top5: 96.586    Loss: 0.799

2024-04-23 17:07:36,563 - ==> Best [Top1: 74.140   Top5: 96.484   Sparsity:0.00   Params: 371568 on epoch: 61]
2024-04-23 17:07:36,564 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:07:36,610 - 

2024-04-23 17:07:36,611 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:07:55,230 - Epoch: [63][  100/  296]    Overall Loss 0.984559    Objective Loss 0.984559                                        LR 0.000320    Time 0.185966    
2024-04-23 17:08:11,991 - Epoch: [63][  200/  296]    Overall Loss 0.943250    Objective Loss 0.943250                                        LR 0.000320    Time 0.176683    
2024-04-23 17:08:23,674 - Epoch: [63][  296/  296]    Overall Loss 0.936955    Objective Loss 0.936955    Top1 72.131148    Top5 100.000000    LR 0.000320    Time 0.158786    
2024-04-23 17:08:23,944 - --- validate (epoch=63)-----------
2024-04-23 17:08:23,945 - 3925 samples (32 per mini-batch)
2024-04-23 17:08:37,553 - Epoch: [63][  100/  123]    Loss 0.825606    Top1 72.718750    Top5 96.500000    
2024-04-23 17:08:40,471 - Epoch: [63][  123/  123]    Loss 0.829261    Top1 72.815287    Top5 96.331210    
2024-04-23 17:08:40,652 - ==> Top1: 72.815    Top5: 96.331    Loss: 0.829

2024-04-23 17:08:40,661 - ==> Best [Top1: 74.140   Top5: 96.484   Sparsity:0.00   Params: 371568 on epoch: 61]
2024-04-23 17:08:40,662 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:08:40,704 - 

2024-04-23 17:08:40,705 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:08:55,879 - Epoch: [64][  100/  296]    Overall Loss 0.921862    Objective Loss 0.921862                                        LR 0.000320    Time 0.151531    
2024-04-23 17:09:11,702 - Epoch: [64][  200/  296]    Overall Loss 0.948500    Objective Loss 0.948500                                        LR 0.000320    Time 0.154765    
2024-04-23 17:09:25,184 - Epoch: [64][  296/  296]    Overall Loss 0.951658    Objective Loss 0.951658    Top1 73.770492    Top5 98.360656    LR 0.000320    Time 0.150046    
2024-04-23 17:09:25,370 - --- validate (epoch=64)-----------
2024-04-23 17:09:25,370 - 3925 samples (32 per mini-batch)
2024-04-23 17:09:42,237 - Epoch: [64][  100/  123]    Loss 0.842587    Top1 72.125000    Top5 96.312500    
2024-04-23 17:09:45,328 - Epoch: [64][  123/  123]    Loss 0.844441    Top1 71.872611    Top5 96.458599    
2024-04-23 17:09:45,509 - ==> Top1: 71.873    Top5: 96.459    Loss: 0.844

2024-04-23 17:09:45,517 - ==> Best [Top1: 74.140   Top5: 96.484   Sparsity:0.00   Params: 371568 on epoch: 61]
2024-04-23 17:09:45,517 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:09:45,559 - 

2024-04-23 17:09:45,559 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:10:00,675 - Epoch: [65][  100/  296]    Overall Loss 0.927071    Objective Loss 0.927071                                        LR 0.000320    Time 0.150940    
2024-04-23 17:10:13,955 - Epoch: [65][  200/  296]    Overall Loss 0.926383    Objective Loss 0.926383                                        LR 0.000320    Time 0.141772    
2024-04-23 17:10:26,494 - Epoch: [65][  296/  296]    Overall Loss 0.924900    Objective Loss 0.924900    Top1 72.131148    Top5 98.360656    LR 0.000320    Time 0.138094    
2024-04-23 17:10:26,715 - --- validate (epoch=65)-----------
2024-04-23 17:10:26,716 - 3925 samples (32 per mini-batch)
2024-04-23 17:10:46,191 - Epoch: [65][  100/  123]    Loss 0.815384    Top1 72.968750    Top5 96.250000    
2024-04-23 17:10:50,901 - Epoch: [65][  123/  123]    Loss 0.829168    Top1 72.509554    Top5 96.076433    
2024-04-23 17:10:51,177 - ==> Top1: 72.510    Top5: 96.076    Loss: 0.829

2024-04-23 17:10:51,195 - ==> Best [Top1: 74.140   Top5: 96.484   Sparsity:0.00   Params: 371568 on epoch: 61]
2024-04-23 17:10:51,196 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:10:51,284 - 

2024-04-23 17:10:51,286 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:11:09,376 - Epoch: [66][  100/  296]    Overall Loss 0.941129    Objective Loss 0.941129                                        LR 0.000320    Time 0.180674    
2024-04-23 17:11:29,976 - Epoch: [66][  200/  296]    Overall Loss 0.956751    Objective Loss 0.956751                                        LR 0.000320    Time 0.193224    
2024-04-23 17:11:47,796 - Epoch: [66][  296/  296]    Overall Loss 0.952750    Objective Loss 0.952750    Top1 65.573770    Top5 93.442623    LR 0.000320    Time 0.190692    
2024-04-23 17:11:48,045 - --- validate (epoch=66)-----------
2024-04-23 17:11:48,047 - 3925 samples (32 per mini-batch)
2024-04-23 17:12:07,881 - Epoch: [66][  100/  123]    Loss 0.824354    Top1 72.937500    Top5 96.562500    
2024-04-23 17:12:11,877 - Epoch: [66][  123/  123]    Loss 0.821991    Top1 72.789809    Top5 96.433121    
2024-04-23 17:12:12,122 - ==> Top1: 72.790    Top5: 96.433    Loss: 0.822

2024-04-23 17:12:12,134 - ==> Best [Top1: 74.140   Top5: 96.484   Sparsity:0.00   Params: 371568 on epoch: 61]
2024-04-23 17:12:12,134 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:12:12,191 - 

2024-04-23 17:12:12,192 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:12:29,450 - Epoch: [67][  100/  296]    Overall Loss 0.914667    Objective Loss 0.914667                                        LR 0.000320    Time 0.172345    
2024-04-23 17:12:41,011 - Epoch: [67][  200/  296]    Overall Loss 0.917209    Objective Loss 0.917209                                        LR 0.000320    Time 0.143877    
2024-04-23 17:12:54,692 - Epoch: [67][  296/  296]    Overall Loss 0.925943    Objective Loss 0.925943    Top1 72.131148    Top5 95.081967    LR 0.000320    Time 0.143363    
2024-04-23 17:12:54,968 - --- validate (epoch=67)-----------
2024-04-23 17:12:54,969 - 3925 samples (32 per mini-batch)
2024-04-23 17:13:13,913 - Epoch: [67][  100/  123]    Loss 0.816357    Top1 72.937500    Top5 96.500000    
2024-04-23 17:13:18,026 - Epoch: [67][  123/  123]    Loss 0.817063    Top1 73.248408    Top5 96.331210    
2024-04-23 17:13:18,250 - ==> Top1: 73.248    Top5: 96.331    Loss: 0.817

2024-04-23 17:13:18,257 - ==> Best [Top1: 74.140   Top5: 96.484   Sparsity:0.00   Params: 371568 on epoch: 61]
2024-04-23 17:13:18,257 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:13:18,298 - 

2024-04-23 17:13:18,299 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:13:28,248 - Epoch: [68][  100/  296]    Overall Loss 0.921274    Objective Loss 0.921274                                        LR 0.000320    Time 0.099307    
2024-04-23 17:13:40,107 - Epoch: [68][  200/  296]    Overall Loss 0.925642    Objective Loss 0.925642                                        LR 0.000320    Time 0.108852    
2024-04-23 17:13:52,517 - Epoch: [68][  296/  296]    Overall Loss 0.939330    Objective Loss 0.939330    Top1 65.573770    Top5 98.360656    LR 0.000320    Time 0.115401    
2024-04-23 17:13:52,779 - --- validate (epoch=68)-----------
2024-04-23 17:13:52,779 - 3925 samples (32 per mini-batch)
2024-04-23 17:14:07,912 - Epoch: [68][  100/  123]    Loss 0.809591    Top1 73.718750    Top5 95.937500    
2024-04-23 17:14:10,964 - Epoch: [68][  123/  123]    Loss 0.804912    Top1 73.910828    Top5 96.101911    
2024-04-23 17:14:11,158 - ==> Top1: 73.911    Top5: 96.102    Loss: 0.805

2024-04-23 17:14:11,164 - ==> Best [Top1: 74.140   Top5: 96.484   Sparsity:0.00   Params: 371568 on epoch: 61]
2024-04-23 17:14:11,165 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:14:11,204 - 

2024-04-23 17:14:11,204 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:14:25,594 - Epoch: [69][  100/  296]    Overall Loss 0.933213    Objective Loss 0.933213                                        LR 0.000320    Time 0.143680    
2024-04-23 17:14:39,281 - Epoch: [69][  200/  296]    Overall Loss 0.937843    Objective Loss 0.937843                                        LR 0.000320    Time 0.140173    
2024-04-23 17:14:51,048 - Epoch: [69][  296/  296]    Overall Loss 0.933227    Objective Loss 0.933227    Top1 68.852459    Top5 95.081967    LR 0.000320    Time 0.134399    
2024-04-23 17:14:51,321 - --- validate (epoch=69)-----------
2024-04-23 17:14:51,322 - 3925 samples (32 per mini-batch)
2024-04-23 17:15:06,558 - Epoch: [69][  100/  123]    Loss 0.812411    Top1 73.031250    Top5 96.593750    
2024-04-23 17:15:09,856 - Epoch: [69][  123/  123]    Loss 0.814796    Top1 73.070064    Top5 96.382166    
2024-04-23 17:15:10,040 - ==> Top1: 73.070    Top5: 96.382    Loss: 0.815

2024-04-23 17:15:10,048 - ==> Best [Top1: 74.140   Top5: 96.484   Sparsity:0.00   Params: 371568 on epoch: 61]
2024-04-23 17:15:10,048 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:15:10,087 - 

2024-04-23 17:15:10,088 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:15:25,765 - Epoch: [70][  100/  296]    Overall Loss 0.926345    Objective Loss 0.926345                                        LR 0.000320    Time 0.156569    
2024-04-23 17:15:42,830 - Epoch: [70][  200/  296]    Overall Loss 0.930843    Objective Loss 0.930843                                        LR 0.000320    Time 0.163504    
2024-04-23 17:15:57,136 - Epoch: [70][  296/  296]    Overall Loss 0.933345    Objective Loss 0.933345    Top1 73.770492    Top5 95.081967    LR 0.000320    Time 0.158739    
2024-04-23 17:15:57,380 - --- validate (epoch=70)-----------
2024-04-23 17:15:57,381 - 3925 samples (32 per mini-batch)
2024-04-23 17:16:13,770 - Epoch: [70][  100/  123]    Loss 0.807315    Top1 73.343750    Top5 96.656250    
2024-04-23 17:16:18,260 - Epoch: [70][  123/  123]    Loss 0.807499    Top1 73.324841    Top5 96.713376    
2024-04-23 17:16:18,518 - ==> Top1: 73.325    Top5: 96.713    Loss: 0.807

2024-04-23 17:16:18,530 - ==> Best [Top1: 74.140   Top5: 96.484   Sparsity:0.00   Params: 371568 on epoch: 61]
2024-04-23 17:16:18,531 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:16:18,603 - 

2024-04-23 17:16:18,604 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:16:37,722 - Epoch: [71][  100/  296]    Overall Loss 0.919766    Objective Loss 0.919766                                        LR 0.000320    Time 0.190962    
2024-04-23 17:16:51,585 - Epoch: [71][  200/  296]    Overall Loss 0.925863    Objective Loss 0.925863                                        LR 0.000320    Time 0.164693    
2024-04-23 17:17:09,005 - Epoch: [71][  296/  296]    Overall Loss 0.934083    Objective Loss 0.934083    Top1 70.491803    Top5 98.360656    LR 0.000320    Time 0.170061    
2024-04-23 17:17:09,245 - --- validate (epoch=71)-----------
2024-04-23 17:17:09,246 - 3925 samples (32 per mini-batch)
2024-04-23 17:17:30,992 - Epoch: [71][  100/  123]    Loss 0.828158    Top1 72.906250    Top5 96.375000    
2024-04-23 17:17:35,572 - Epoch: [71][  123/  123]    Loss 0.834349    Top1 72.789809    Top5 96.458599    
2024-04-23 17:17:35,846 - ==> Top1: 72.790    Top5: 96.459    Loss: 0.834

2024-04-23 17:17:35,854 - ==> Best [Top1: 74.140   Top5: 96.484   Sparsity:0.00   Params: 371568 on epoch: 61]
2024-04-23 17:17:35,855 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:17:35,914 - 

2024-04-23 17:17:35,915 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:17:50,490 - Epoch: [72][  100/  296]    Overall Loss 0.935204    Objective Loss 0.935204                                        LR 0.000320    Time 0.145529    
2024-04-23 17:18:06,159 - Epoch: [72][  200/  296]    Overall Loss 0.914007    Objective Loss 0.914007                                        LR 0.000320    Time 0.150996    
2024-04-23 17:18:22,754 - Epoch: [72][  296/  296]    Overall Loss 0.923929    Objective Loss 0.923929    Top1 70.491803    Top5 96.721311    LR 0.000320    Time 0.158016    
2024-04-23 17:18:22,981 - --- validate (epoch=72)-----------
2024-04-23 17:18:22,982 - 3925 samples (32 per mini-batch)
2024-04-23 17:18:37,927 - Epoch: [72][  100/  123]    Loss 0.821360    Top1 72.718750    Top5 96.718750    
2024-04-23 17:18:40,851 - Epoch: [72][  123/  123]    Loss 0.813645    Top1 72.687898    Top5 96.764331    
2024-04-23 17:18:41,054 - ==> Top1: 72.688    Top5: 96.764    Loss: 0.814

2024-04-23 17:18:41,063 - ==> Best [Top1: 74.140   Top5: 96.484   Sparsity:0.00   Params: 371568 on epoch: 61]
2024-04-23 17:18:41,064 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:18:41,109 - 

2024-04-23 17:18:41,109 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:18:58,655 - Epoch: [73][  100/  296]    Overall Loss 0.957134    Objective Loss 0.957134                                        LR 0.000320    Time 0.175236    
2024-04-23 17:19:14,571 - Epoch: [73][  200/  296]    Overall Loss 0.931162    Objective Loss 0.931162                                        LR 0.000320    Time 0.167085    
2024-04-23 17:19:27,746 - Epoch: [73][  296/  296]    Overall Loss 0.928290    Objective Loss 0.928290    Top1 77.049180    Top5 96.721311    LR 0.000320    Time 0.157320    
2024-04-23 17:19:27,958 - --- validate (epoch=73)-----------
2024-04-23 17:19:27,959 - 3925 samples (32 per mini-batch)
2024-04-23 17:19:49,149 - Epoch: [73][  100/  123]    Loss 0.771810    Top1 75.000000    Top5 96.687500    
2024-04-23 17:19:53,199 - Epoch: [73][  123/  123]    Loss 0.770728    Top1 75.184713    Top5 96.611465    
2024-04-23 17:19:53,428 - ==> Top1: 75.185    Top5: 96.611    Loss: 0.771

2024-04-23 17:19:53,440 - ==> Best [Top1: 75.185   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 73]
2024-04-23 17:19:53,441 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:19:53,519 - 

2024-04-23 17:19:53,520 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:20:11,621 - Epoch: [74][  100/  296]    Overall Loss 0.930731    Objective Loss 0.930731                                        LR 0.000320    Time 0.180796    
2024-04-23 17:20:28,666 - Epoch: [74][  200/  296]    Overall Loss 0.911454    Objective Loss 0.911454                                        LR 0.000320    Time 0.175516    
2024-04-23 17:20:46,971 - Epoch: [74][  296/  296]    Overall Loss 0.914943    Objective Loss 0.914943    Top1 75.409836    Top5 90.163934    LR 0.000320    Time 0.180365    
2024-04-23 17:20:47,230 - --- validate (epoch=74)-----------
2024-04-23 17:20:47,231 - 3925 samples (32 per mini-batch)
2024-04-23 17:21:09,387 - Epoch: [74][  100/  123]    Loss 0.789638    Top1 74.312500    Top5 96.843750    
2024-04-23 17:21:12,656 - Epoch: [74][  123/  123]    Loss 0.783989    Top1 74.114650    Top5 96.789809    
2024-04-23 17:21:12,893 - ==> Top1: 74.115    Top5: 96.790    Loss: 0.784

2024-04-23 17:21:12,904 - ==> Best [Top1: 75.185   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 73]
2024-04-23 17:21:12,905 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:21:12,990 - 

2024-04-23 17:21:12,992 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:21:31,338 - Epoch: [75][  100/  296]    Overall Loss 0.867220    Objective Loss 0.867220                                        LR 0.000320    Time 0.183211    
2024-04-23 17:21:47,518 - Epoch: [75][  200/  296]    Overall Loss 0.875663    Objective Loss 0.875663                                        LR 0.000320    Time 0.172399    
2024-04-23 17:22:01,870 - Epoch: [75][  296/  296]    Overall Loss 0.888577    Objective Loss 0.888577    Top1 67.213115    Top5 96.721311    LR 0.000320    Time 0.164892    
2024-04-23 17:22:02,174 - --- validate (epoch=75)-----------
2024-04-23 17:22:02,175 - 3925 samples (32 per mini-batch)
2024-04-23 17:22:23,590 - Epoch: [75][  100/  123]    Loss 0.782870    Top1 74.875000    Top5 96.343750    
2024-04-23 17:22:28,400 - Epoch: [75][  123/  123]    Loss 0.791171    Top1 74.522293    Top5 96.305732    
2024-04-23 17:22:28,605 - ==> Top1: 74.522    Top5: 96.306    Loss: 0.791

2024-04-23 17:22:28,615 - ==> Best [Top1: 75.185   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 73]
2024-04-23 17:22:28,616 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:22:28,683 - 

2024-04-23 17:22:28,684 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:22:46,211 - Epoch: [76][  100/  296]    Overall Loss 0.895258    Objective Loss 0.895258                                        LR 0.000320    Time 0.175046    
2024-04-23 17:22:57,418 - Epoch: [76][  200/  296]    Overall Loss 0.907441    Objective Loss 0.907441                                        LR 0.000320    Time 0.143461    
2024-04-23 17:23:12,728 - Epoch: [76][  296/  296]    Overall Loss 0.911939    Objective Loss 0.911939    Top1 73.770492    Top5 98.360656    LR 0.000320    Time 0.148589    
2024-04-23 17:23:13,005 - --- validate (epoch=76)-----------
2024-04-23 17:23:13,007 - 3925 samples (32 per mini-batch)
2024-04-23 17:23:32,685 - Epoch: [76][  100/  123]    Loss 0.833168    Top1 73.312500    Top5 96.156250    
2024-04-23 17:23:35,100 - Epoch: [76][  123/  123]    Loss 0.845621    Top1 72.738854    Top5 96.050955    
2024-04-23 17:23:35,372 - ==> Top1: 72.739    Top5: 96.051    Loss: 0.846

2024-04-23 17:23:35,381 - ==> Best [Top1: 75.185   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 73]
2024-04-23 17:23:35,381 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:23:35,425 - 

2024-04-23 17:23:35,426 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:23:55,760 - Epoch: [77][  100/  296]    Overall Loss 0.865523    Objective Loss 0.865523                                        LR 0.000320    Time 0.203091    
2024-04-23 17:24:13,264 - Epoch: [77][  200/  296]    Overall Loss 0.885300    Objective Loss 0.885300                                        LR 0.000320    Time 0.188950    
2024-04-23 17:24:30,493 - Epoch: [77][  296/  296]    Overall Loss 0.900954    Objective Loss 0.900954    Top1 62.295082    Top5 98.360656    LR 0.000320    Time 0.185811    
2024-04-23 17:24:30,799 - --- validate (epoch=77)-----------
2024-04-23 17:24:30,800 - 3925 samples (32 per mini-batch)
2024-04-23 17:24:52,855 - Epoch: [77][  100/  123]    Loss 0.795244    Top1 74.156250    Top5 96.062500    
2024-04-23 17:24:57,078 - Epoch: [77][  123/  123]    Loss 0.797127    Top1 74.267516    Top5 96.305732    
2024-04-23 17:24:57,291 - ==> Top1: 74.268    Top5: 96.306    Loss: 0.797

2024-04-23 17:24:57,301 - ==> Best [Top1: 75.185   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 73]
2024-04-23 17:24:57,301 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:24:57,348 - 

2024-04-23 17:24:57,349 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:25:10,973 - Epoch: [78][  100/  296]    Overall Loss 0.893119    Objective Loss 0.893119                                        LR 0.000320    Time 0.136029    
2024-04-23 17:25:26,921 - Epoch: [78][  200/  296]    Overall Loss 0.912411    Objective Loss 0.912411                                        LR 0.000320    Time 0.147645    
2024-04-23 17:25:45,979 - Epoch: [78][  296/  296]    Overall Loss 0.904894    Objective Loss 0.904894    Top1 65.573770    Top5 98.360656    LR 0.000320    Time 0.164077    
2024-04-23 17:25:46,231 - --- validate (epoch=78)-----------
2024-04-23 17:25:46,233 - 3925 samples (32 per mini-batch)
2024-04-23 17:26:03,911 - Epoch: [78][  100/  123]    Loss 0.792897    Top1 74.031250    Top5 96.281250    
2024-04-23 17:26:07,844 - Epoch: [78][  123/  123]    Loss 0.773032    Top1 74.828025    Top5 96.535032    
2024-04-23 17:26:08,097 - ==> Top1: 74.828    Top5: 96.535    Loss: 0.773

2024-04-23 17:26:08,111 - ==> Best [Top1: 75.185   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 73]
2024-04-23 17:26:08,112 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:26:08,213 - 

2024-04-23 17:26:08,214 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:26:27,289 - Epoch: [79][  100/  296]    Overall Loss 0.921196    Objective Loss 0.921196                                        LR 0.000320    Time 0.190494    
2024-04-23 17:26:40,726 - Epoch: [79][  200/  296]    Overall Loss 0.900464    Objective Loss 0.900464                                        LR 0.000320    Time 0.162321    
2024-04-23 17:26:56,216 - Epoch: [79][  296/  296]    Overall Loss 0.912599    Objective Loss 0.912599    Top1 78.688525    Top5 98.360656    LR 0.000320    Time 0.161935    
2024-04-23 17:26:56,471 - --- validate (epoch=79)-----------
2024-04-23 17:26:56,473 - 3925 samples (32 per mini-batch)
2024-04-23 17:27:20,613 - Epoch: [79][  100/  123]    Loss 0.799892    Top1 73.937500    Top5 96.406250    
2024-04-23 17:27:26,506 - Epoch: [79][  123/  123]    Loss 0.801479    Top1 73.859873    Top5 96.305732    
2024-04-23 17:27:26,822 - ==> Top1: 73.860    Top5: 96.306    Loss: 0.801

2024-04-23 17:27:26,830 - ==> Best [Top1: 75.185   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 73]
2024-04-23 17:27:26,830 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:27:26,878 - 

2024-04-23 17:27:26,879 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:27:46,304 - Epoch: [80][  100/  296]    Overall Loss 0.880755    Objective Loss 0.880755                                        LR 0.000320    Time 0.194039    
2024-04-23 17:28:05,788 - Epoch: [80][  200/  296]    Overall Loss 0.879605    Objective Loss 0.879605                                        LR 0.000320    Time 0.194343    
2024-04-23 17:28:25,477 - Epoch: [80][  296/  296]    Overall Loss 0.902152    Objective Loss 0.902152    Top1 54.098361    Top5 91.803279    LR 0.000320    Time 0.197769    
2024-04-23 17:28:25,749 - --- validate (epoch=80)-----------
2024-04-23 17:28:25,750 - 3925 samples (32 per mini-batch)
2024-04-23 17:28:42,912 - Epoch: [80][  100/  123]    Loss 0.814388    Top1 73.656250    Top5 96.156250    
2024-04-23 17:28:46,153 - Epoch: [80][  123/  123]    Loss 0.815598    Top1 73.095541    Top5 96.433121    
2024-04-23 17:28:46,360 - ==> Top1: 73.096    Top5: 96.433    Loss: 0.816

2024-04-23 17:28:46,371 - ==> Best [Top1: 75.185   Top5: 96.611   Sparsity:0.00   Params: 371568 on epoch: 73]
2024-04-23 17:28:46,371 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:28:46,430 - 

2024-04-23 17:28:46,431 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:29:03,433 - Epoch: [81][  100/  296]    Overall Loss 0.904936    Objective Loss 0.904936                                        LR 0.000320    Time 0.169804    
2024-04-23 17:29:19,073 - Epoch: [81][  200/  296]    Overall Loss 0.905482    Objective Loss 0.905482                                        LR 0.000320    Time 0.162976    
2024-04-23 17:29:34,160 - Epoch: [81][  296/  296]    Overall Loss 0.907081    Objective Loss 0.907081    Top1 68.852459    Top5 93.442623    LR 0.000320    Time 0.161021    
2024-04-23 17:29:34,392 - --- validate (epoch=81)-----------
2024-04-23 17:29:34,393 - 3925 samples (32 per mini-batch)
2024-04-23 17:29:52,116 - Epoch: [81][  100/  123]    Loss 0.768607    Top1 75.187500    Top5 96.750000    
2024-04-23 17:29:55,871 - Epoch: [81][  123/  123]    Loss 0.763238    Top1 75.388535    Top5 96.866242    
2024-04-23 17:29:56,087 - ==> Top1: 75.389    Top5: 96.866    Loss: 0.763

2024-04-23 17:29:56,094 - ==> Best [Top1: 75.389   Top5: 96.866   Sparsity:0.00   Params: 371568 on epoch: 81]
2024-04-23 17:29:56,095 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:29:56,157 - 

2024-04-23 17:29:56,158 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:30:14,506 - Epoch: [82][  100/  296]    Overall Loss 0.840062    Objective Loss 0.840062                                        LR 0.000320    Time 0.183264    
2024-04-23 17:30:30,842 - Epoch: [82][  200/  296]    Overall Loss 0.859884    Objective Loss 0.859884                                        LR 0.000320    Time 0.173210    
2024-04-23 17:30:44,684 - Epoch: [82][  296/  296]    Overall Loss 0.870239    Objective Loss 0.870239    Top1 78.688525    Top5 98.360656    LR 0.000320    Time 0.163733    
2024-04-23 17:30:44,894 - --- validate (epoch=82)-----------
2024-04-23 17:30:44,894 - 3925 samples (32 per mini-batch)
2024-04-23 17:31:05,018 - Epoch: [82][  100/  123]    Loss 0.784854    Top1 74.406250    Top5 96.937500    
2024-04-23 17:31:08,823 - Epoch: [82][  123/  123]    Loss 0.782822    Top1 74.624204    Top5 96.815287    
2024-04-23 17:31:09,062 - ==> Top1: 74.624    Top5: 96.815    Loss: 0.783

2024-04-23 17:31:09,075 - ==> Best [Top1: 75.389   Top5: 96.866   Sparsity:0.00   Params: 371568 on epoch: 81]
2024-04-23 17:31:09,076 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:31:09,143 - 

2024-04-23 17:31:09,144 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:31:26,744 - Epoch: [83][  100/  296]    Overall Loss 0.881372    Objective Loss 0.881372                                        LR 0.000320    Time 0.175780    
2024-04-23 17:31:44,056 - Epoch: [83][  200/  296]    Overall Loss 0.874246    Objective Loss 0.874246                                        LR 0.000320    Time 0.174338    
2024-04-23 17:32:00,084 - Epoch: [83][  296/  296]    Overall Loss 0.875820    Objective Loss 0.875820    Top1 72.131148    Top5 95.081967    LR 0.000320    Time 0.171875    
2024-04-23 17:32:00,372 - --- validate (epoch=83)-----------
2024-04-23 17:32:00,373 - 3925 samples (32 per mini-batch)
2024-04-23 17:32:19,908 - Epoch: [83][  100/  123]    Loss 0.779975    Top1 74.593750    Top5 96.500000    
2024-04-23 17:32:23,298 - Epoch: [83][  123/  123]    Loss 0.785376    Top1 74.318471    Top5 96.509554    
2024-04-23 17:32:23,484 - ==> Top1: 74.318    Top5: 96.510    Loss: 0.785

2024-04-23 17:32:23,495 - ==> Best [Top1: 75.389   Top5: 96.866   Sparsity:0.00   Params: 371568 on epoch: 81]
2024-04-23 17:32:23,495 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:32:23,535 - 

2024-04-23 17:32:23,536 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:32:41,773 - Epoch: [84][  100/  296]    Overall Loss 0.912076    Objective Loss 0.912076                                        LR 0.000320    Time 0.182152    
2024-04-23 17:32:57,108 - Epoch: [84][  200/  296]    Overall Loss 0.887137    Objective Loss 0.887137                                        LR 0.000320    Time 0.167646    
2024-04-23 17:33:09,768 - Epoch: [84][  296/  296]    Overall Loss 0.887416    Objective Loss 0.887416    Top1 72.131148    Top5 96.721311    LR 0.000320    Time 0.155982    
2024-04-23 17:33:10,017 - --- validate (epoch=84)-----------
2024-04-23 17:33:10,018 - 3925 samples (32 per mini-batch)
2024-04-23 17:33:30,964 - Epoch: [84][  100/  123]    Loss 0.766233    Top1 74.500000    Top5 96.562500    
2024-04-23 17:33:35,391 - Epoch: [84][  123/  123]    Loss 0.765325    Top1 74.649682    Top5 96.611465    
2024-04-23 17:33:35,629 - ==> Top1: 74.650    Top5: 96.611    Loss: 0.765

2024-04-23 17:33:35,640 - ==> Best [Top1: 75.389   Top5: 96.866   Sparsity:0.00   Params: 371568 on epoch: 81]
2024-04-23 17:33:35,641 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:33:35,698 - 

2024-04-23 17:33:35,699 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:33:54,745 - Epoch: [85][  100/  296]    Overall Loss 0.864266    Objective Loss 0.864266                                        LR 0.000320    Time 0.190231    
2024-04-23 17:34:13,031 - Epoch: [85][  200/  296]    Overall Loss 0.872172    Objective Loss 0.872172                                        LR 0.000320    Time 0.186438    
2024-04-23 17:34:29,636 - Epoch: [85][  296/  296]    Overall Loss 0.895626    Objective Loss 0.895626    Top1 70.491803    Top5 96.721311    LR 0.000320    Time 0.182002    
2024-04-23 17:34:29,911 - --- validate (epoch=85)-----------
2024-04-23 17:34:29,912 - 3925 samples (32 per mini-batch)
2024-04-23 17:34:51,017 - Epoch: [85][  100/  123]    Loss 0.795975    Top1 74.281250    Top5 96.531250    
2024-04-23 17:34:55,305 - Epoch: [85][  123/  123]    Loss 0.810658    Top1 73.656051    Top5 96.509554    
2024-04-23 17:34:55,528 - ==> Top1: 73.656    Top5: 96.510    Loss: 0.811

2024-04-23 17:34:55,535 - ==> Best [Top1: 75.389   Top5: 96.866   Sparsity:0.00   Params: 371568 on epoch: 81]
2024-04-23 17:34:55,535 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:34:55,568 - 

2024-04-23 17:34:55,569 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:35:18,475 - Epoch: [86][  100/  296]    Overall Loss 0.879217    Objective Loss 0.879217                                        LR 0.000320    Time 0.228844    
2024-04-23 17:35:37,537 - Epoch: [86][  200/  296]    Overall Loss 0.876766    Objective Loss 0.876766                                        LR 0.000320    Time 0.209632    
2024-04-23 17:35:56,564 - Epoch: [86][  296/  296]    Overall Loss 0.872806    Objective Loss 0.872806    Top1 70.491803    Top5 98.360656    LR 0.000320    Time 0.205853    
2024-04-23 17:35:56,829 - --- validate (epoch=86)-----------
2024-04-23 17:35:56,830 - 3925 samples (32 per mini-batch)
2024-04-23 17:36:16,747 - Epoch: [86][  100/  123]    Loss 0.753133    Top1 75.500000    Top5 96.968750    
2024-04-23 17:36:21,625 - Epoch: [86][  123/  123]    Loss 0.754867    Top1 75.668790    Top5 96.738854    
2024-04-23 17:36:21,907 - ==> Top1: 75.669    Top5: 96.739    Loss: 0.755

2024-04-23 17:36:21,917 - ==> Best [Top1: 75.669   Top5: 96.739   Sparsity:0.00   Params: 371568 on epoch: 86]
2024-04-23 17:36:21,918 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:36:21,985 - 

2024-04-23 17:36:21,986 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:36:43,489 - Epoch: [87][  100/  296]    Overall Loss 0.891634    Objective Loss 0.891634                                        LR 0.000320    Time 0.214781    
2024-04-23 17:37:03,967 - Epoch: [87][  200/  296]    Overall Loss 0.886969    Objective Loss 0.886969                                        LR 0.000320    Time 0.209670    
2024-04-23 17:37:21,297 - Epoch: [87][  296/  296]    Overall Loss 0.883556    Objective Loss 0.883556    Top1 70.491803    Top5 95.081967    LR 0.000320    Time 0.200146    
2024-04-23 17:37:21,545 - --- validate (epoch=87)-----------
2024-04-23 17:37:21,546 - 3925 samples (32 per mini-batch)
2024-04-23 17:37:43,057 - Epoch: [87][  100/  123]    Loss 0.750798    Top1 75.687500    Top5 97.031250    
2024-04-23 17:37:47,581 - Epoch: [87][  123/  123]    Loss 0.750388    Top1 75.490446    Top5 96.993631    
2024-04-23 17:37:47,822 - ==> Top1: 75.490    Top5: 96.994    Loss: 0.750

2024-04-23 17:37:47,831 - ==> Best [Top1: 75.669   Top5: 96.739   Sparsity:0.00   Params: 371568 on epoch: 86]
2024-04-23 17:37:47,831 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:37:47,893 - 

2024-04-23 17:37:47,894 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:38:09,320 - Epoch: [88][  100/  296]    Overall Loss 0.847652    Objective Loss 0.847652                                        LR 0.000320    Time 0.214030    
2024-04-23 17:38:25,526 - Epoch: [88][  200/  296]    Overall Loss 0.861369    Objective Loss 0.861369                                        LR 0.000320    Time 0.187944    
2024-04-23 17:38:41,529 - Epoch: [88][  296/  296]    Overall Loss 0.874175    Objective Loss 0.874175    Top1 60.655738    Top5 96.721311    LR 0.000320    Time 0.180987    
2024-04-23 17:38:41,801 - --- validate (epoch=88)-----------
2024-04-23 17:38:41,803 - 3925 samples (32 per mini-batch)
2024-04-23 17:39:01,400 - Epoch: [88][  100/  123]    Loss 0.757230    Top1 74.937500    Top5 97.000000    
2024-04-23 17:39:06,095 - Epoch: [88][  123/  123]    Loss 0.764373    Top1 74.649682    Top5 96.917197    
2024-04-23 17:39:06,348 - ==> Top1: 74.650    Top5: 96.917    Loss: 0.764

2024-04-23 17:39:06,359 - ==> Best [Top1: 75.669   Top5: 96.739   Sparsity:0.00   Params: 371568 on epoch: 86]
2024-04-23 17:39:06,360 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:39:06,447 - 

2024-04-23 17:39:06,448 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:39:27,875 - Epoch: [89][  100/  296]    Overall Loss 0.857776    Objective Loss 0.857776                                        LR 0.000320    Time 0.214045    
2024-04-23 17:39:46,216 - Epoch: [89][  200/  296]    Overall Loss 0.855454    Objective Loss 0.855454                                        LR 0.000320    Time 0.198632    
2024-04-23 17:40:06,874 - Epoch: [89][  296/  296]    Overall Loss 0.866198    Objective Loss 0.866198    Top1 63.934426    Top5 95.081967    LR 0.000320    Time 0.203931    
2024-04-23 17:40:07,169 - --- validate (epoch=89)-----------
2024-04-23 17:40:07,170 - 3925 samples (32 per mini-batch)
2024-04-23 17:40:26,407 - Epoch: [89][  100/  123]    Loss 0.755555    Top1 75.562500    Top5 97.031250    
2024-04-23 17:40:29,330 - Epoch: [89][  123/  123]    Loss 0.751975    Top1 75.796178    Top5 96.840764    
2024-04-23 17:40:29,533 - ==> Top1: 75.796    Top5: 96.841    Loss: 0.752

2024-04-23 17:40:29,540 - ==> Best [Top1: 75.796   Top5: 96.841   Sparsity:0.00   Params: 371568 on epoch: 89]
2024-04-23 17:40:29,540 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:40:29,590 - 

2024-04-23 17:40:29,591 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:40:46,229 - Epoch: [90][  100/  296]    Overall Loss 0.857106    Objective Loss 0.857106                                        LR 0.000320    Time 0.166172    
2024-04-23 17:41:03,473 - Epoch: [90][  200/  296]    Overall Loss 0.873365    Objective Loss 0.873365                                        LR 0.000320    Time 0.169202    
2024-04-23 17:41:17,554 - Epoch: [90][  296/  296]    Overall Loss 0.875373    Objective Loss 0.875373    Top1 60.655738    Top5 88.524590    LR 0.000320    Time 0.161831    
2024-04-23 17:41:17,793 - --- validate (epoch=90)-----------
2024-04-23 17:41:17,794 - 3925 samples (32 per mini-batch)
2024-04-23 17:41:36,767 - Epoch: [90][  100/  123]    Loss 0.749412    Top1 76.062500    Top5 97.000000    
2024-04-23 17:41:41,758 - Epoch: [90][  123/  123]    Loss 0.765666    Top1 75.414013    Top5 96.840764    
2024-04-23 17:41:42,045 - ==> Top1: 75.414    Top5: 96.841    Loss: 0.766

2024-04-23 17:41:42,057 - ==> Best [Top1: 75.796   Top5: 96.841   Sparsity:0.00   Params: 371568 on epoch: 89]
2024-04-23 17:41:42,058 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:41:42,117 - 

2024-04-23 17:41:42,118 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:42:00,452 - Epoch: [91][  100/  296]    Overall Loss 0.855717    Objective Loss 0.855717                                        LR 0.000320    Time 0.183098    
2024-04-23 17:42:17,376 - Epoch: [91][  200/  296]    Overall Loss 0.855850    Objective Loss 0.855850                                        LR 0.000320    Time 0.176061    
2024-04-23 17:42:34,098 - Epoch: [91][  296/  296]    Overall Loss 0.865142    Objective Loss 0.865142    Top1 78.688525    Top5 100.000000    LR 0.000320    Time 0.175383    
2024-04-23 17:42:34,401 - --- validate (epoch=91)-----------
2024-04-23 17:42:34,403 - 3925 samples (32 per mini-batch)
2024-04-23 17:42:54,745 - Epoch: [91][  100/  123]    Loss 0.777951    Top1 74.906250    Top5 96.406250    
2024-04-23 17:42:58,898 - Epoch: [91][  123/  123]    Loss 0.782476    Top1 74.802548    Top5 96.458599    
2024-04-23 17:42:59,139 - ==> Top1: 74.803    Top5: 96.459    Loss: 0.782

2024-04-23 17:42:59,147 - ==> Best [Top1: 75.796   Top5: 96.841   Sparsity:0.00   Params: 371568 on epoch: 89]
2024-04-23 17:42:59,148 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:42:59,189 - 

2024-04-23 17:42:59,190 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:43:15,585 - Epoch: [92][  100/  296]    Overall Loss 0.876030    Objective Loss 0.876030                                        LR 0.000320    Time 0.163741    
2024-04-23 17:43:33,179 - Epoch: [92][  200/  296]    Overall Loss 0.897544    Objective Loss 0.897544                                        LR 0.000320    Time 0.169730    
2024-04-23 17:43:48,549 - Epoch: [92][  296/  296]    Overall Loss 0.884825    Objective Loss 0.884825    Top1 63.934426    Top5 95.081967    LR 0.000320    Time 0.166537    
2024-04-23 17:43:48,759 - --- validate (epoch=92)-----------
2024-04-23 17:43:48,760 - 3925 samples (32 per mini-batch)
2024-04-23 17:44:06,837 - Epoch: [92][  100/  123]    Loss 0.772190    Top1 74.750000    Top5 96.500000    
2024-04-23 17:44:10,651 - Epoch: [92][  123/  123]    Loss 0.764245    Top1 75.184713    Top5 96.560510    
2024-04-23 17:44:10,937 - ==> Top1: 75.185    Top5: 96.561    Loss: 0.764

2024-04-23 17:44:10,945 - ==> Best [Top1: 75.796   Top5: 96.841   Sparsity:0.00   Params: 371568 on epoch: 89]
2024-04-23 17:44:10,946 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:44:11,015 - 

2024-04-23 17:44:11,017 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:44:32,525 - Epoch: [93][  100/  296]    Overall Loss 0.858412    Objective Loss 0.858412                                        LR 0.000320    Time 0.214849    
2024-04-23 17:44:47,970 - Epoch: [93][  200/  296]    Overall Loss 0.851044    Objective Loss 0.851044                                        LR 0.000320    Time 0.184542    
2024-04-23 17:45:03,219 - Epoch: [93][  296/  296]    Overall Loss 0.866252    Objective Loss 0.866252    Top1 70.491803    Top5 96.721311    LR 0.000320    Time 0.176133    
2024-04-23 17:45:03,510 - --- validate (epoch=93)-----------
2024-04-23 17:45:03,511 - 3925 samples (32 per mini-batch)
2024-04-23 17:45:24,216 - Epoch: [93][  100/  123]    Loss 0.811135    Top1 73.812500    Top5 96.593750    
2024-04-23 17:45:28,506 - Epoch: [93][  123/  123]    Loss 0.798794    Top1 74.140127    Top5 96.687898    
2024-04-23 17:45:28,707 - ==> Top1: 74.140    Top5: 96.688    Loss: 0.799

2024-04-23 17:45:28,721 - ==> Best [Top1: 75.796   Top5: 96.841   Sparsity:0.00   Params: 371568 on epoch: 89]
2024-04-23 17:45:28,722 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:45:28,804 - 

2024-04-23 17:45:28,805 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:45:49,768 - Epoch: [94][  100/  296]    Overall Loss 0.864330    Objective Loss 0.864330                                        LR 0.000320    Time 0.209399    
2024-04-23 17:46:09,544 - Epoch: [94][  200/  296]    Overall Loss 0.854845    Objective Loss 0.854845                                        LR 0.000320    Time 0.203469    
2024-04-23 17:46:26,690 - Epoch: [94][  296/  296]    Overall Loss 0.859503    Objective Loss 0.859503    Top1 73.770492    Top5 100.000000    LR 0.000320    Time 0.195335    
2024-04-23 17:46:26,992 - --- validate (epoch=94)-----------
2024-04-23 17:46:26,993 - 3925 samples (32 per mini-batch)
2024-04-23 17:46:52,725 - Epoch: [94][  100/  123]    Loss 0.769415    Top1 74.812500    Top5 96.625000    
2024-04-23 17:46:57,329 - Epoch: [94][  123/  123]    Loss 0.779034    Top1 74.522293    Top5 96.535032    
2024-04-23 17:46:57,620 - ==> Top1: 74.522    Top5: 96.535    Loss: 0.779

2024-04-23 17:46:57,627 - ==> Best [Top1: 75.796   Top5: 96.841   Sparsity:0.00   Params: 371568 on epoch: 89]
2024-04-23 17:46:57,628 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:46:57,685 - 

2024-04-23 17:46:57,687 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:47:20,398 - Epoch: [95][  100/  296]    Overall Loss 0.841111    Objective Loss 0.841111                                        LR 0.000320    Time 0.226880    
2024-04-23 17:47:40,557 - Epoch: [95][  200/  296]    Overall Loss 0.861894    Objective Loss 0.861894                                        LR 0.000320    Time 0.214122    
2024-04-23 17:48:02,193 - Epoch: [95][  296/  296]    Overall Loss 0.863509    Objective Loss 0.863509    Top1 75.409836    Top5 98.360656    LR 0.000320    Time 0.217697    
2024-04-23 17:48:02,461 - --- validate (epoch=95)-----------
2024-04-23 17:48:02,463 - 3925 samples (32 per mini-batch)
2024-04-23 17:48:24,692 - Epoch: [95][  100/  123]    Loss 0.745135    Top1 75.093750    Top5 96.937500    
2024-04-23 17:48:29,658 - Epoch: [95][  123/  123]    Loss 0.747219    Top1 75.210191    Top5 96.840764    
2024-04-23 17:48:29,884 - ==> Top1: 75.210    Top5: 96.841    Loss: 0.747

2024-04-23 17:48:29,894 - ==> Best [Top1: 75.796   Top5: 96.841   Sparsity:0.00   Params: 371568 on epoch: 89]
2024-04-23 17:48:29,894 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:48:29,966 - 

2024-04-23 17:48:29,967 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:48:49,306 - Epoch: [96][  100/  296]    Overall Loss 0.877263    Objective Loss 0.877263                                        LR 0.000320    Time 0.193166    
2024-04-23 17:49:06,132 - Epoch: [96][  200/  296]    Overall Loss 0.864584    Objective Loss 0.864584                                        LR 0.000320    Time 0.180606    
2024-04-23 17:49:23,178 - Epoch: [96][  296/  296]    Overall Loss 0.863847    Objective Loss 0.863847    Top1 60.655738    Top5 96.721311    LR 0.000320    Time 0.179542    
2024-04-23 17:49:23,399 - --- validate (epoch=96)-----------
2024-04-23 17:49:23,400 - 3925 samples (32 per mini-batch)
2024-04-23 17:49:45,264 - Epoch: [96][  100/  123]    Loss 0.741788    Top1 75.250000    Top5 97.093750    
2024-04-23 17:49:49,941 - Epoch: [96][  123/  123]    Loss 0.743308    Top1 75.261146    Top5 96.942675    
2024-04-23 17:49:50,140 - ==> Top1: 75.261    Top5: 96.943    Loss: 0.743

2024-04-23 17:49:50,149 - ==> Best [Top1: 75.796   Top5: 96.841   Sparsity:0.00   Params: 371568 on epoch: 89]
2024-04-23 17:49:50,150 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:49:50,206 - 

2024-04-23 17:49:50,207 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:50:09,325 - Epoch: [97][  100/  296]    Overall Loss 0.826992    Objective Loss 0.826992                                        LR 0.000320    Time 0.190960    
2024-04-23 17:50:30,496 - Epoch: [97][  200/  296]    Overall Loss 0.843081    Objective Loss 0.843081                                        LR 0.000320    Time 0.201232    
2024-04-23 17:50:47,543 - Epoch: [97][  296/  296]    Overall Loss 0.840849    Objective Loss 0.840849    Top1 80.327869    Top5 100.000000    LR 0.000320    Time 0.193492    
2024-04-23 17:50:47,775 - --- validate (epoch=97)-----------
2024-04-23 17:50:47,777 - 3925 samples (32 per mini-batch)
2024-04-23 17:51:10,205 - Epoch: [97][  100/  123]    Loss 0.756820    Top1 74.937500    Top5 96.625000    
2024-04-23 17:51:14,425 - Epoch: [97][  123/  123]    Loss 0.758197    Top1 75.057325    Top5 96.407643    
2024-04-23 17:51:14,627 - ==> Top1: 75.057    Top5: 96.408    Loss: 0.758

2024-04-23 17:51:14,636 - ==> Best [Top1: 75.796   Top5: 96.841   Sparsity:0.00   Params: 371568 on epoch: 89]
2024-04-23 17:51:14,637 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:51:14,682 - 

2024-04-23 17:51:14,684 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:51:32,918 - Epoch: [98][  100/  296]    Overall Loss 0.838643    Objective Loss 0.838643                                        LR 0.000320    Time 0.182124    
2024-04-23 17:51:52,003 - Epoch: [98][  200/  296]    Overall Loss 0.858617    Objective Loss 0.858617                                        LR 0.000320    Time 0.186362    
2024-04-23 17:52:11,027 - Epoch: [98][  296/  296]    Overall Loss 0.863418    Objective Loss 0.863418    Top1 65.573770    Top5 91.803279    LR 0.000320    Time 0.190111    
2024-04-23 17:52:11,292 - --- validate (epoch=98)-----------
2024-04-23 17:52:11,293 - 3925 samples (32 per mini-batch)
2024-04-23 17:52:30,610 - Epoch: [98][  100/  123]    Loss 0.802501    Top1 73.812500    Top5 96.062500    
2024-04-23 17:52:34,984 - Epoch: [98][  123/  123]    Loss 0.813440    Top1 73.859873    Top5 96.178344    
2024-04-23 17:52:35,189 - ==> Top1: 73.860    Top5: 96.178    Loss: 0.813

2024-04-23 17:52:35,199 - ==> Best [Top1: 75.796   Top5: 96.841   Sparsity:0.00   Params: 371568 on epoch: 89]
2024-04-23 17:52:35,200 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:52:35,266 - 

2024-04-23 17:52:35,267 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:52:57,192 - Epoch: [99][  100/  296]    Overall Loss 0.851218    Objective Loss 0.851218                                        LR 0.000320    Time 0.219031    
2024-04-23 17:53:11,798 - Epoch: [99][  200/  296]    Overall Loss 0.836587    Objective Loss 0.836587                                        LR 0.000320    Time 0.182450    
2024-04-23 17:53:27,012 - Epoch: [99][  296/  296]    Overall Loss 0.851364    Objective Loss 0.851364    Top1 63.934426    Top5 91.803279    LR 0.000320    Time 0.174611    
2024-04-23 17:53:27,232 - --- validate (epoch=99)-----------
2024-04-23 17:53:27,233 - 3925 samples (32 per mini-batch)
2024-04-23 17:53:47,082 - Epoch: [99][  100/  123]    Loss 0.745587    Top1 76.125000    Top5 96.812500    
2024-04-23 17:53:51,165 - Epoch: [99][  123/  123]    Loss 0.756361    Top1 75.796178    Top5 96.662420    
2024-04-23 17:53:51,365 - ==> Top1: 75.796    Top5: 96.662    Loss: 0.756

2024-04-23 17:53:51,373 - ==> Best [Top1: 75.796   Top5: 96.841   Sparsity:0.00   Params: 371568 on epoch: 89]
2024-04-23 17:53:51,374 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:53:51,422 - 

2024-04-23 17:53:51,422 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:54:09,551 - Epoch: [100][  100/  296]    Overall Loss 0.841473    Objective Loss 0.841473                                        LR 0.000080    Time 0.181068    
2024-04-23 17:54:24,945 - Epoch: [100][  200/  296]    Overall Loss 0.814168    Objective Loss 0.814168                                        LR 0.000080    Time 0.167395    
2024-04-23 17:54:41,180 - Epoch: [100][  296/  296]    Overall Loss 0.807782    Objective Loss 0.807782    Top1 77.049180    Top5 95.081967    LR 0.000080    Time 0.167886    
2024-04-23 17:54:41,443 - --- validate (epoch=100)-----------
2024-04-23 17:54:41,444 - 3925 samples (32 per mini-batch)
2024-04-23 17:55:02,289 - Epoch: [100][  100/  123]    Loss 0.685282    Top1 78.312500    Top5 96.968750    
2024-04-23 17:55:06,469 - Epoch: [100][  123/  123]    Loss 0.694166    Top1 77.936306    Top5 97.146497    
2024-04-23 17:55:06,729 - ==> Top1: 77.936    Top5: 97.146    Loss: 0.694

2024-04-23 17:55:06,739 - ==> Best [Top1: 77.936   Top5: 97.146   Sparsity:0.00   Params: 371568 on epoch: 100]
2024-04-23 17:55:06,739 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:55:06,799 - 

2024-04-23 17:55:06,800 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:55:25,859 - Epoch: [101][  100/  296]    Overall Loss 0.800727    Objective Loss 0.800727                                        LR 0.000080    Time 0.190378    
2024-04-23 17:55:40,026 - Epoch: [101][  200/  296]    Overall Loss 0.808160    Objective Loss 0.808160                                        LR 0.000080    Time 0.165931    
2024-04-23 17:55:57,344 - Epoch: [101][  296/  296]    Overall Loss 0.802098    Objective Loss 0.802098    Top1 62.295082    Top5 98.360656    LR 0.000080    Time 0.170551    
2024-04-23 17:55:57,608 - --- validate (epoch=101)-----------
2024-04-23 17:55:57,610 - 3925 samples (32 per mini-batch)
2024-04-23 17:56:20,070 - Epoch: [101][  100/  123]    Loss 0.688038    Top1 77.656250    Top5 97.312500    
2024-04-23 17:56:24,748 - Epoch: [101][  123/  123]    Loss 0.694922    Top1 77.630573    Top5 97.095541    
2024-04-23 17:56:24,960 - ==> Top1: 77.631    Top5: 97.096    Loss: 0.695

2024-04-23 17:56:24,972 - ==> Best [Top1: 77.936   Top5: 97.146   Sparsity:0.00   Params: 371568 on epoch: 100]
2024-04-23 17:56:24,973 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:56:25,032 - 

2024-04-23 17:56:25,034 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:56:45,936 - Epoch: [102][  100/  296]    Overall Loss 0.778432    Objective Loss 0.778432                                        LR 0.000080    Time 0.208791    
2024-04-23 17:57:00,064 - Epoch: [102][  200/  296]    Overall Loss 0.788509    Objective Loss 0.788509                                        LR 0.000080    Time 0.174938    
2024-04-23 17:57:13,604 - Epoch: [102][  296/  296]    Overall Loss 0.792067    Objective Loss 0.792067    Top1 83.606557    Top5 98.360656    LR 0.000080    Time 0.163880    
2024-04-23 17:57:13,810 - --- validate (epoch=102)-----------
2024-04-23 17:57:13,811 - 3925 samples (32 per mini-batch)
2024-04-23 17:57:32,876 - Epoch: [102][  100/  123]    Loss 0.685486    Top1 78.093750    Top5 97.250000    
2024-04-23 17:57:36,584 - Epoch: [102][  123/  123]    Loss 0.693035    Top1 77.936306    Top5 97.019108    
2024-04-23 17:57:36,760 - ==> Top1: 77.936    Top5: 97.019    Loss: 0.693

2024-04-23 17:57:36,768 - ==> Best [Top1: 77.936   Top5: 97.146   Sparsity:0.00   Params: 371568 on epoch: 100]
2024-04-23 17:57:36,768 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:57:36,803 - 

2024-04-23 17:57:36,804 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:57:55,813 - Epoch: [103][  100/  296]    Overall Loss 0.803485    Objective Loss 0.803485                                        LR 0.000080    Time 0.189870    
2024-04-23 17:58:12,593 - Epoch: [103][  200/  296]    Overall Loss 0.795731    Objective Loss 0.795731                                        LR 0.000080    Time 0.178730    
2024-04-23 17:58:29,585 - Epoch: [103][  296/  296]    Overall Loss 0.792902    Objective Loss 0.792902    Top1 77.049180    Top5 100.000000    LR 0.000080    Time 0.178104    
2024-04-23 17:58:29,850 - --- validate (epoch=103)-----------
2024-04-23 17:58:29,852 - 3925 samples (32 per mini-batch)
2024-04-23 17:58:51,532 - Epoch: [103][  100/  123]    Loss 0.703181    Top1 76.625000    Top5 97.062500    
2024-04-23 17:58:55,157 - Epoch: [103][  123/  123]    Loss 0.707275    Top1 76.815287    Top5 97.248408    
2024-04-23 17:58:55,392 - ==> Top1: 76.815    Top5: 97.248    Loss: 0.707

2024-04-23 17:58:55,400 - ==> Best [Top1: 77.936   Top5: 97.146   Sparsity:0.00   Params: 371568 on epoch: 100]
2024-04-23 17:58:55,401 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 17:58:55,454 - 

2024-04-23 17:58:55,456 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:59:15,813 - Epoch: [104][  100/  296]    Overall Loss 0.801466    Objective Loss 0.801466                                        LR 0.000080    Time 0.203340    
2024-04-23 17:59:33,376 - Epoch: [104][  200/  296]    Overall Loss 0.791716    Objective Loss 0.791716                                        LR 0.000080    Time 0.189383    
2024-04-23 17:59:51,495 - Epoch: [104][  296/  296]    Overall Loss 0.785837    Objective Loss 0.785837    Top1 75.409836    Top5 98.360656    LR 0.000080    Time 0.189099    
2024-04-23 17:59:51,717 - --- validate (epoch=104)-----------
2024-04-23 17:59:51,718 - 3925 samples (32 per mini-batch)
2024-04-23 18:00:12,897 - Epoch: [104][  100/  123]    Loss 0.689361    Top1 77.875000    Top5 97.312500    
2024-04-23 18:00:16,444 - Epoch: [104][  123/  123]    Loss 0.696255    Top1 77.707006    Top5 97.197452    
2024-04-23 18:00:16,656 - ==> Top1: 77.707    Top5: 97.197    Loss: 0.696

2024-04-23 18:00:16,664 - ==> Best [Top1: 77.936   Top5: 97.146   Sparsity:0.00   Params: 371568 on epoch: 100]
2024-04-23 18:00:16,665 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:00:16,729 - 

2024-04-23 18:00:16,730 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:00:37,347 - Epoch: [105][  100/  296]    Overall Loss 0.769796    Objective Loss 0.769796                                        LR 0.000080    Time 0.205934    
2024-04-23 18:00:55,624 - Epoch: [105][  200/  296]    Overall Loss 0.755818    Objective Loss 0.755818                                        LR 0.000080    Time 0.194247    
2024-04-23 18:01:12,728 - Epoch: [105][  296/  296]    Overall Loss 0.758797    Objective Loss 0.758797    Top1 70.491803    Top5 98.360656    LR 0.000080    Time 0.188962    
2024-04-23 18:01:12,980 - --- validate (epoch=105)-----------
2024-04-23 18:01:12,981 - 3925 samples (32 per mini-batch)
2024-04-23 18:01:33,546 - Epoch: [105][  100/  123]    Loss 0.697899    Top1 77.656250    Top5 97.187500    
2024-04-23 18:01:38,062 - Epoch: [105][  123/  123]    Loss 0.698676    Top1 77.579618    Top5 97.222930    
2024-04-23 18:01:38,298 - ==> Top1: 77.580    Top5: 97.223    Loss: 0.699

2024-04-23 18:01:38,310 - ==> Best [Top1: 77.936   Top5: 97.146   Sparsity:0.00   Params: 371568 on epoch: 100]
2024-04-23 18:01:38,311 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:01:38,372 - 

2024-04-23 18:01:38,373 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:01:57,554 - Epoch: [106][  100/  296]    Overall Loss 0.772292    Objective Loss 0.772292                                        LR 0.000080    Time 0.191598    
2024-04-23 18:02:15,520 - Epoch: [106][  200/  296]    Overall Loss 0.781410    Objective Loss 0.781410                                        LR 0.000080    Time 0.185524    
2024-04-23 18:02:33,693 - Epoch: [106][  296/  296]    Overall Loss 0.772532    Objective Loss 0.772532    Top1 81.967213    Top5 100.000000    LR 0.000080    Time 0.186680    
2024-04-23 18:02:33,940 - --- validate (epoch=106)-----------
2024-04-23 18:02:33,941 - 3925 samples (32 per mini-batch)
2024-04-23 18:02:55,572 - Epoch: [106][  100/  123]    Loss 0.681456    Top1 77.656250    Top5 97.468750    
2024-04-23 18:02:59,960 - Epoch: [106][  123/  123]    Loss 0.682353    Top1 77.528662    Top5 97.452229    
2024-04-23 18:03:00,130 - ==> Top1: 77.529    Top5: 97.452    Loss: 0.682

2024-04-23 18:03:00,136 - ==> Best [Top1: 77.936   Top5: 97.146   Sparsity:0.00   Params: 371568 on epoch: 100]
2024-04-23 18:03:00,137 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:03:00,178 - 

2024-04-23 18:03:00,179 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:03:21,004 - Epoch: [107][  100/  296]    Overall Loss 0.787854    Objective Loss 0.787854                                        LR 0.000080    Time 0.208022    
2024-04-23 18:03:37,504 - Epoch: [107][  200/  296]    Overall Loss 0.765018    Objective Loss 0.765018                                        LR 0.000080    Time 0.186402    
2024-04-23 18:03:56,858 - Epoch: [107][  296/  296]    Overall Loss 0.777107    Objective Loss 0.777107    Top1 81.967213    Top5 95.081967    LR 0.000080    Time 0.191261    
2024-04-23 18:03:57,116 - --- validate (epoch=107)-----------
2024-04-23 18:03:57,118 - 3925 samples (32 per mini-batch)
2024-04-23 18:04:20,924 - Epoch: [107][  100/  123]    Loss 0.693257    Top1 76.843750    Top5 97.218750    
2024-04-23 18:04:25,229 - Epoch: [107][  123/  123]    Loss 0.686379    Top1 77.121019    Top5 97.324841    
2024-04-23 18:04:25,429 - ==> Top1: 77.121    Top5: 97.325    Loss: 0.686

2024-04-23 18:04:25,436 - ==> Best [Top1: 77.936   Top5: 97.146   Sparsity:0.00   Params: 371568 on epoch: 100]
2024-04-23 18:04:25,437 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:04:25,482 - 

2024-04-23 18:04:25,483 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:04:43,066 - Epoch: [108][  100/  296]    Overall Loss 0.791635    Objective Loss 0.791635                                        LR 0.000080    Time 0.175607    
2024-04-23 18:04:59,100 - Epoch: [108][  200/  296]    Overall Loss 0.785513    Objective Loss 0.785513                                        LR 0.000080    Time 0.167868    
2024-04-23 18:05:14,937 - Epoch: [108][  296/  296]    Overall Loss 0.780482    Objective Loss 0.780482    Top1 65.573770    Top5 100.000000    LR 0.000080    Time 0.166861    
2024-04-23 18:05:15,202 - --- validate (epoch=108)-----------
2024-04-23 18:05:15,203 - 3925 samples (32 per mini-batch)
2024-04-23 18:05:35,601 - Epoch: [108][  100/  123]    Loss 0.702935    Top1 76.968750    Top5 97.250000    
2024-04-23 18:05:40,427 - Epoch: [108][  123/  123]    Loss 0.694694    Top1 77.350318    Top5 97.171975    
2024-04-23 18:05:40,664 - ==> Top1: 77.350    Top5: 97.172    Loss: 0.695

2024-04-23 18:05:40,675 - ==> Best [Top1: 77.936   Top5: 97.146   Sparsity:0.00   Params: 371568 on epoch: 100]
2024-04-23 18:05:40,676 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:05:40,730 - 

2024-04-23 18:05:40,731 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:06:02,485 - Epoch: [109][  100/  296]    Overall Loss 0.754883    Objective Loss 0.754883                                        LR 0.000080    Time 0.217312    
2024-04-23 18:06:18,337 - Epoch: [109][  200/  296]    Overall Loss 0.768213    Objective Loss 0.768213                                        LR 0.000080    Time 0.187810    
2024-04-23 18:06:29,355 - Epoch: [109][  296/  296]    Overall Loss 0.777401    Objective Loss 0.777401    Top1 75.409836    Top5 93.442623    LR 0.000080    Time 0.164068    
2024-04-23 18:06:29,456 - --- validate (epoch=109)-----------
2024-04-23 18:06:29,457 - 3925 samples (32 per mini-batch)
2024-04-23 18:06:47,460 - Epoch: [109][  100/  123]    Loss 0.680611    Top1 78.406250    Top5 97.500000    
2024-04-23 18:06:50,752 - Epoch: [109][  123/  123]    Loss 0.685083    Top1 77.936306    Top5 97.477707    
2024-04-23 18:06:50,930 - ==> Top1: 77.936    Top5: 97.478    Loss: 0.685

2024-04-23 18:06:50,937 - ==> Best [Top1: 77.936   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 109]
2024-04-23 18:06:50,938 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:06:51,004 - 

2024-04-23 18:06:51,005 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:07:05,234 - Epoch: [110][  100/  296]    Overall Loss 0.770826    Objective Loss 0.770826                                        LR 0.000080    Time 0.142100    
2024-04-23 18:07:20,290 - Epoch: [110][  200/  296]    Overall Loss 0.760713    Objective Loss 0.760713                                        LR 0.000080    Time 0.146227    
2024-04-23 18:07:40,316 - Epoch: [110][  296/  296]    Overall Loss 0.764538    Objective Loss 0.764538    Top1 78.688525    Top5 96.721311    LR 0.000080    Time 0.166374    
2024-04-23 18:07:40,602 - --- validate (epoch=110)-----------
2024-04-23 18:07:40,603 - 3925 samples (32 per mini-batch)
2024-04-23 18:08:08,251 - Epoch: [110][  100/  123]    Loss 0.692858    Top1 77.406250    Top5 97.406250    
2024-04-23 18:08:13,933 - Epoch: [110][  123/  123]    Loss 0.680222    Top1 77.732484    Top5 97.503185    
2024-04-23 18:08:14,214 - ==> Top1: 77.732    Top5: 97.503    Loss: 0.680

2024-04-23 18:08:14,230 - ==> Best [Top1: 77.936   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 109]
2024-04-23 18:08:14,231 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:08:14,327 - 

2024-04-23 18:08:14,328 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:08:35,798 - Epoch: [111][  100/  296]    Overall Loss 0.755914    Objective Loss 0.755914                                        LR 0.000080    Time 0.214465    
2024-04-23 18:08:55,888 - Epoch: [111][  200/  296]    Overall Loss 0.746538    Objective Loss 0.746538                                        LR 0.000080    Time 0.207571    
2024-04-23 18:09:13,024 - Epoch: [111][  296/  296]    Overall Loss 0.757517    Objective Loss 0.757517    Top1 65.573770    Top5 96.721311    LR 0.000080    Time 0.198074    
2024-04-23 18:09:13,219 - --- validate (epoch=111)-----------
2024-04-23 18:09:13,221 - 3925 samples (32 per mini-batch)
2024-04-23 18:09:33,217 - Epoch: [111][  100/  123]    Loss 0.657998    Top1 78.812500    Top5 97.562500    
2024-04-23 18:09:37,462 - Epoch: [111][  123/  123]    Loss 0.687883    Top1 77.936306    Top5 97.273885    
2024-04-23 18:09:37,661 - ==> Top1: 77.936    Top5: 97.274    Loss: 0.688

2024-04-23 18:09:37,675 - ==> Best [Top1: 77.936   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 109]
2024-04-23 18:09:37,676 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:09:37,727 - 

2024-04-23 18:09:37,728 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:09:57,166 - Epoch: [112][  100/  296]    Overall Loss 0.790696    Objective Loss 0.790696                                        LR 0.000080    Time 0.194146    
2024-04-23 18:10:15,132 - Epoch: [112][  200/  296]    Overall Loss 0.783990    Objective Loss 0.783990                                        LR 0.000080    Time 0.186793    
2024-04-23 18:10:31,311 - Epoch: [112][  296/  296]    Overall Loss 0.774522    Objective Loss 0.774522    Top1 80.327869    Top5 98.360656    LR 0.000080    Time 0.180800    
2024-04-23 18:10:31,572 - --- validate (epoch=112)-----------
2024-04-23 18:10:31,574 - 3925 samples (32 per mini-batch)
2024-04-23 18:10:57,729 - Epoch: [112][  100/  123]    Loss 0.675501    Top1 77.781250    Top5 97.406250    
2024-04-23 18:11:03,024 - Epoch: [112][  123/  123]    Loss 0.668777    Top1 78.191083    Top5 97.222930    
2024-04-23 18:11:03,337 - ==> Top1: 78.191    Top5: 97.223    Loss: 0.669

2024-04-23 18:11:03,349 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:11:03,350 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:11:03,424 - 

2024-04-23 18:11:03,425 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:11:25,255 - Epoch: [113][  100/  296]    Overall Loss 0.754729    Objective Loss 0.754729                                        LR 0.000080    Time 0.218085    
2024-04-23 18:11:44,571 - Epoch: [113][  200/  296]    Overall Loss 0.758074    Objective Loss 0.758074                                        LR 0.000080    Time 0.205513    
2024-04-23 18:12:01,279 - Epoch: [113][  296/  296]    Overall Loss 0.774706    Objective Loss 0.774706    Top1 72.131148    Top5 90.163934    LR 0.000080    Time 0.195237    
2024-04-23 18:12:01,576 - --- validate (epoch=113)-----------
2024-04-23 18:12:01,577 - 3925 samples (32 per mini-batch)
2024-04-23 18:12:21,616 - Epoch: [113][  100/  123]    Loss 0.684067    Top1 77.062500    Top5 97.156250    
2024-04-23 18:12:26,540 - Epoch: [113][  123/  123]    Loss 0.678658    Top1 77.503185    Top5 97.121019    
2024-04-23 18:12:26,815 - ==> Top1: 77.503    Top5: 97.121    Loss: 0.679

2024-04-23 18:12:26,824 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:12:26,825 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:12:26,911 - 

2024-04-23 18:12:26,912 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:12:48,342 - Epoch: [114][  100/  296]    Overall Loss 0.753570    Objective Loss 0.753570                                        LR 0.000080    Time 0.214056    
2024-04-23 18:13:06,083 - Epoch: [114][  200/  296]    Overall Loss 0.756852    Objective Loss 0.756852                                        LR 0.000080    Time 0.195629    
2024-04-23 18:13:23,463 - Epoch: [114][  296/  296]    Overall Loss 0.763895    Objective Loss 0.763895    Top1 68.852459    Top5 93.442623    LR 0.000080    Time 0.190827    
2024-04-23 18:13:23,758 - --- validate (epoch=114)-----------
2024-04-23 18:13:23,759 - 3925 samples (32 per mini-batch)
2024-04-23 18:13:43,833 - Epoch: [114][  100/  123]    Loss 0.683267    Top1 78.000000    Top5 97.062500    
2024-04-23 18:13:47,411 - Epoch: [114][  123/  123]    Loss 0.689914    Top1 77.426752    Top5 97.171975    
2024-04-23 18:13:47,699 - ==> Top1: 77.427    Top5: 97.172    Loss: 0.690

2024-04-23 18:13:47,708 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:13:47,708 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:13:47,753 - 

2024-04-23 18:13:47,754 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:14:05,967 - Epoch: [115][  100/  296]    Overall Loss 0.800955    Objective Loss 0.800955                                        LR 0.000080    Time 0.181900    
2024-04-23 18:14:25,378 - Epoch: [115][  200/  296]    Overall Loss 0.776931    Objective Loss 0.776931                                        LR 0.000080    Time 0.187892    
2024-04-23 18:14:41,788 - Epoch: [115][  296/  296]    Overall Loss 0.772262    Objective Loss 0.772262    Top1 77.049180    Top5 96.721311    LR 0.000080    Time 0.182327    
2024-04-23 18:14:42,046 - --- validate (epoch=115)-----------
2024-04-23 18:14:42,047 - 3925 samples (32 per mini-batch)
2024-04-23 18:15:04,278 - Epoch: [115][  100/  123]    Loss 0.688369    Top1 77.750000    Top5 97.250000    
2024-04-23 18:15:08,912 - Epoch: [115][  123/  123]    Loss 0.694872    Top1 77.554140    Top5 97.248408    
2024-04-23 18:15:09,131 - ==> Top1: 77.554    Top5: 97.248    Loss: 0.695

2024-04-23 18:15:09,141 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:15:09,142 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:15:09,193 - 

2024-04-23 18:15:09,194 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:15:28,081 - Epoch: [116][  100/  296]    Overall Loss 0.776280    Objective Loss 0.776280                                        LR 0.000080    Time 0.188639    
2024-04-23 18:15:51,435 - Epoch: [116][  200/  296]    Overall Loss 0.770080    Objective Loss 0.770080                                        LR 0.000080    Time 0.210976    
2024-04-23 18:16:09,398 - Epoch: [116][  296/  296]    Overall Loss 0.766965    Objective Loss 0.766965    Top1 75.409836    Top5 98.360656    LR 0.000080    Time 0.203164    
2024-04-23 18:16:09,674 - --- validate (epoch=116)-----------
2024-04-23 18:16:09,676 - 3925 samples (32 per mini-batch)
2024-04-23 18:16:31,629 - Epoch: [116][  100/  123]    Loss 0.700421    Top1 76.781250    Top5 97.281250    
2024-04-23 18:16:35,112 - Epoch: [116][  123/  123]    Loss 0.684867    Top1 77.324841    Top5 97.299363    
2024-04-23 18:16:35,358 - ==> Top1: 77.325    Top5: 97.299    Loss: 0.685

2024-04-23 18:16:35,369 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:16:35,370 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:16:35,424 - 

2024-04-23 18:16:35,424 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:16:52,904 - Epoch: [117][  100/  296]    Overall Loss 0.723360    Objective Loss 0.723360                                        LR 0.000080    Time 0.174571    
2024-04-23 18:17:10,151 - Epoch: [117][  200/  296]    Overall Loss 0.741073    Objective Loss 0.741073                                        LR 0.000080    Time 0.173386    
2024-04-23 18:17:26,259 - Epoch: [117][  296/  296]    Overall Loss 0.734762    Objective Loss 0.734762    Top1 72.131148    Top5 96.721311    LR 0.000080    Time 0.171507    
2024-04-23 18:17:26,536 - --- validate (epoch=117)-----------
2024-04-23 18:17:26,537 - 3925 samples (32 per mini-batch)
2024-04-23 18:17:51,731 - Epoch: [117][  100/  123]    Loss 0.684907    Top1 77.562500    Top5 97.375000    
2024-04-23 18:17:55,724 - Epoch: [117][  123/  123]    Loss 0.681708    Top1 77.910828    Top5 97.299363    
2024-04-23 18:17:56,060 - ==> Top1: 77.911    Top5: 97.299    Loss: 0.682

2024-04-23 18:17:56,075 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:17:56,077 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:17:56,158 - 

2024-04-23 18:17:56,159 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:18:16,820 - Epoch: [118][  100/  296]    Overall Loss 0.718329    Objective Loss 0.718329                                        LR 0.000080    Time 0.206379    
2024-04-23 18:18:35,396 - Epoch: [118][  200/  296]    Overall Loss 0.753527    Objective Loss 0.753527                                        LR 0.000080    Time 0.195961    
2024-04-23 18:18:54,108 - Epoch: [118][  296/  296]    Overall Loss 0.756029    Objective Loss 0.756029    Top1 81.967213    Top5 96.721311    LR 0.000080    Time 0.195553    
2024-04-23 18:18:54,398 - --- validate (epoch=118)-----------
2024-04-23 18:18:54,399 - 3925 samples (32 per mini-batch)
2024-04-23 18:19:15,385 - Epoch: [118][  100/  123]    Loss 0.677501    Top1 77.687500    Top5 97.562500    
2024-04-23 18:19:19,776 - Epoch: [118][  123/  123]    Loss 0.681989    Top1 77.783439    Top5 97.273885    
2024-04-23 18:19:20,054 - ==> Top1: 77.783    Top5: 97.274    Loss: 0.682

2024-04-23 18:19:20,066 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:19:20,067 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:19:20,124 - 

2024-04-23 18:19:20,125 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:19:38,847 - Epoch: [119][  100/  296]    Overall Loss 0.710124    Objective Loss 0.710124                                        LR 0.000080    Time 0.186966    
2024-04-23 18:19:57,846 - Epoch: [119][  200/  296]    Overall Loss 0.752073    Objective Loss 0.752073                                        LR 0.000080    Time 0.188375    
2024-04-23 18:20:15,439 - Epoch: [119][  296/  296]    Overall Loss 0.749357    Objective Loss 0.749357    Top1 81.967213    Top5 100.000000    LR 0.000080    Time 0.186648    
2024-04-23 18:20:15,690 - --- validate (epoch=119)-----------
2024-04-23 18:20:15,692 - 3925 samples (32 per mini-batch)
2024-04-23 18:20:40,518 - Epoch: [119][  100/  123]    Loss 0.684792    Top1 78.093750    Top5 97.375000    
2024-04-23 18:20:45,512 - Epoch: [119][  123/  123]    Loss 0.691496    Top1 77.579618    Top5 97.248408    
2024-04-23 18:20:45,753 - ==> Top1: 77.580    Top5: 97.248    Loss: 0.691

2024-04-23 18:20:45,766 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:20:45,767 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:20:45,835 - 

2024-04-23 18:20:45,836 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:21:05,959 - Epoch: [120][  100/  296]    Overall Loss 0.757226    Objective Loss 0.757226                                        LR 0.000080    Time 0.200994    
2024-04-23 18:21:24,647 - Epoch: [120][  200/  296]    Overall Loss 0.745763    Objective Loss 0.745763                                        LR 0.000080    Time 0.193828    
2024-04-23 18:21:40,363 - Epoch: [120][  296/  296]    Overall Loss 0.752577    Objective Loss 0.752577    Top1 77.049180    Top5 96.721311    LR 0.000080    Time 0.183990    
2024-04-23 18:21:40,645 - --- validate (epoch=120)-----------
2024-04-23 18:21:40,646 - 3925 samples (32 per mini-batch)
2024-04-23 18:22:02,291 - Epoch: [120][  100/  123]    Loss 0.682496    Top1 77.531250    Top5 97.093750    
2024-04-23 18:22:07,006 - Epoch: [120][  123/  123]    Loss 0.681497    Top1 77.477707    Top5 97.070064    
2024-04-23 18:22:07,243 - ==> Top1: 77.478    Top5: 97.070    Loss: 0.681

2024-04-23 18:22:07,252 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:22:07,253 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:22:07,300 - 

2024-04-23 18:22:07,301 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:22:27,901 - Epoch: [121][  100/  296]    Overall Loss 0.763291    Objective Loss 0.763291                                        LR 0.000080    Time 0.205759    
2024-04-23 18:22:44,927 - Epoch: [121][  200/  296]    Overall Loss 0.750933    Objective Loss 0.750933                                        LR 0.000080    Time 0.187899    
2024-04-23 18:23:02,193 - Epoch: [121][  296/  296]    Overall Loss 0.738578    Objective Loss 0.738578    Top1 75.409836    Top5 96.721311    LR 0.000080    Time 0.185218    
2024-04-23 18:23:02,404 - --- validate (epoch=121)-----------
2024-04-23 18:23:02,405 - 3925 samples (32 per mini-batch)
2024-04-23 18:23:24,110 - Epoch: [121][  100/  123]    Loss 0.687299    Top1 77.531250    Top5 97.406250    
2024-04-23 18:23:29,515 - Epoch: [121][  123/  123]    Loss 0.683401    Top1 77.987261    Top5 97.299363    
2024-04-23 18:23:29,778 - ==> Top1: 77.987    Top5: 97.299    Loss: 0.683

2024-04-23 18:23:29,789 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:23:29,791 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:23:29,867 - 

2024-04-23 18:23:29,869 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:23:50,852 - Epoch: [122][  100/  296]    Overall Loss 0.730865    Objective Loss 0.730865                                        LR 0.000080    Time 0.209570    
2024-04-23 18:24:09,375 - Epoch: [122][  200/  296]    Overall Loss 0.751925    Objective Loss 0.751925                                        LR 0.000080    Time 0.197294    
2024-04-23 18:24:27,006 - Epoch: [122][  296/  296]    Overall Loss 0.757333    Objective Loss 0.757333    Top1 75.409836    Top5 93.442623    LR 0.000080    Time 0.192804    
2024-04-23 18:24:27,291 - --- validate (epoch=122)-----------
2024-04-23 18:24:27,292 - 3925 samples (32 per mini-batch)
2024-04-23 18:24:48,729 - Epoch: [122][  100/  123]    Loss 0.698300    Top1 76.781250    Top5 97.437500    
2024-04-23 18:24:53,035 - Epoch: [122][  123/  123]    Loss 0.683041    Top1 77.401274    Top5 97.401274    
2024-04-23 18:24:53,220 - ==> Top1: 77.401    Top5: 97.401    Loss: 0.683

2024-04-23 18:24:53,227 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:24:53,228 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:24:53,272 - 

2024-04-23 18:24:53,273 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:25:12,748 - Epoch: [123][  100/  296]    Overall Loss 0.774774    Objective Loss 0.774774                                        LR 0.000080    Time 0.194527    
2024-04-23 18:25:30,968 - Epoch: [123][  200/  296]    Overall Loss 0.760229    Objective Loss 0.760229                                        LR 0.000080    Time 0.188252    
2024-04-23 18:25:48,623 - Epoch: [123][  296/  296]    Overall Loss 0.758541    Objective Loss 0.758541    Top1 75.409836    Top5 95.081967    LR 0.000080    Time 0.186761    
2024-04-23 18:25:48,839 - --- validate (epoch=123)-----------
2024-04-23 18:25:48,840 - 3925 samples (32 per mini-batch)
2024-04-23 18:26:10,932 - Epoch: [123][  100/  123]    Loss 0.672140    Top1 77.718750    Top5 97.437500    
2024-04-23 18:26:15,218 - Epoch: [123][  123/  123]    Loss 0.678333    Top1 77.732484    Top5 97.248408    
2024-04-23 18:26:15,489 - ==> Top1: 77.732    Top5: 97.248    Loss: 0.678

2024-04-23 18:26:15,501 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:26:15,502 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:26:15,560 - 

2024-04-23 18:26:15,561 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:26:33,652 - Epoch: [124][  100/  296]    Overall Loss 0.731498    Objective Loss 0.731498                                        LR 0.000080    Time 0.180687    
2024-04-23 18:26:52,697 - Epoch: [124][  200/  296]    Overall Loss 0.731433    Objective Loss 0.731433                                        LR 0.000080    Time 0.185451    
2024-04-23 18:27:11,504 - Epoch: [124][  296/  296]    Overall Loss 0.731213    Objective Loss 0.731213    Top1 72.131148    Top5 100.000000    LR 0.000080    Time 0.188778    
2024-04-23 18:27:11,729 - --- validate (epoch=124)-----------
2024-04-23 18:27:11,731 - 3925 samples (32 per mini-batch)
2024-04-23 18:27:36,054 - Epoch: [124][  100/  123]    Loss 0.684552    Top1 77.562500    Top5 97.375000    
2024-04-23 18:27:40,953 - Epoch: [124][  123/  123]    Loss 0.683849    Top1 77.681529    Top5 97.401274    
2024-04-23 18:27:41,245 - ==> Top1: 77.682    Top5: 97.401    Loss: 0.684

2024-04-23 18:27:41,256 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:27:41,256 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:27:41,309 - 

2024-04-23 18:27:41,310 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:28:00,263 - Epoch: [125][  100/  296]    Overall Loss 0.737424    Objective Loss 0.737424                                        LR 0.000080    Time 0.189306    
2024-04-23 18:28:12,815 - Epoch: [125][  200/  296]    Overall Loss 0.728851    Objective Loss 0.728851                                        LR 0.000080    Time 0.157310    
2024-04-23 18:28:24,507 - Epoch: [125][  296/  296]    Overall Loss 0.743031    Objective Loss 0.743031    Top1 81.967213    Top5 98.360656    LR 0.000080    Time 0.145729    
2024-04-23 18:28:24,790 - --- validate (epoch=125)-----------
2024-04-23 18:28:24,791 - 3925 samples (32 per mini-batch)
2024-04-23 18:28:44,226 - Epoch: [125][  100/  123]    Loss 0.677627    Top1 77.937500    Top5 97.250000    
2024-04-23 18:28:47,095 - Epoch: [125][  123/  123]    Loss 0.678980    Top1 77.732484    Top5 97.324841    
2024-04-23 18:28:47,309 - ==> Top1: 77.732    Top5: 97.325    Loss: 0.679

2024-04-23 18:28:47,318 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:28:47,319 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:28:47,370 - 

2024-04-23 18:28:47,371 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:29:06,732 - Epoch: [126][  100/  296]    Overall Loss 0.757484    Objective Loss 0.757484                                        LR 0.000080    Time 0.193384    
2024-04-23 18:29:23,601 - Epoch: [126][  200/  296]    Overall Loss 0.753539    Objective Loss 0.753539                                        LR 0.000080    Time 0.180928    
2024-04-23 18:29:43,140 - Epoch: [126][  296/  296]    Overall Loss 0.750510    Objective Loss 0.750510    Top1 78.688525    Top5 96.721311    LR 0.000080    Time 0.188178    
2024-04-23 18:29:43,464 - --- validate (epoch=126)-----------
2024-04-23 18:29:43,466 - 3925 samples (32 per mini-batch)
2024-04-23 18:30:02,529 - Epoch: [126][  100/  123]    Loss 0.690919    Top1 77.218750    Top5 97.375000    
2024-04-23 18:30:07,935 - Epoch: [126][  123/  123]    Loss 0.683728    Top1 77.859873    Top5 97.248408    
2024-04-23 18:30:08,168 - ==> Top1: 77.860    Top5: 97.248    Loss: 0.684

2024-04-23 18:30:08,180 - ==> Best [Top1: 78.191   Top5: 97.223   Sparsity:0.00   Params: 371568 on epoch: 112]
2024-04-23 18:30:08,181 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:30:08,233 - 

2024-04-23 18:30:08,234 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:30:28,365 - Epoch: [127][  100/  296]    Overall Loss 0.766891    Objective Loss 0.766891                                        LR 0.000080    Time 0.201074    
2024-04-23 18:30:46,469 - Epoch: [127][  200/  296]    Overall Loss 0.746945    Objective Loss 0.746945                                        LR 0.000080    Time 0.190936    
2024-04-23 18:31:01,743 - Epoch: [127][  296/  296]    Overall Loss 0.741205    Objective Loss 0.741205    Top1 77.049180    Top5 98.360656    LR 0.000080    Time 0.180546    
2024-04-23 18:31:01,974 - --- validate (epoch=127)-----------
2024-04-23 18:31:01,975 - 3925 samples (32 per mini-batch)
2024-04-23 18:31:19,852 - Epoch: [127][  100/  123]    Loss 0.684680    Top1 78.468750    Top5 97.093750    
2024-04-23 18:31:23,615 - Epoch: [127][  123/  123]    Loss 0.682316    Top1 78.445860    Top5 97.248408    
2024-04-23 18:31:23,825 - ==> Top1: 78.446    Top5: 97.248    Loss: 0.682

2024-04-23 18:31:23,833 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:31:23,833 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:31:23,892 - 

2024-04-23 18:31:23,893 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:31:43,269 - Epoch: [128][  100/  296]    Overall Loss 0.738714    Objective Loss 0.738714                                        LR 0.000080    Time 0.193532    
2024-04-23 18:32:01,555 - Epoch: [128][  200/  296]    Overall Loss 0.762999    Objective Loss 0.762999                                        LR 0.000080    Time 0.188085    
2024-04-23 18:32:18,531 - Epoch: [128][  296/  296]    Overall Loss 0.763516    Objective Loss 0.763516    Top1 75.409836    Top5 98.360656    LR 0.000080    Time 0.184370    
2024-04-23 18:32:18,781 - --- validate (epoch=128)-----------
2024-04-23 18:32:18,782 - 3925 samples (32 per mini-batch)
2024-04-23 18:32:38,002 - Epoch: [128][  100/  123]    Loss 0.696745    Top1 77.656250    Top5 97.125000    
2024-04-23 18:32:42,977 - Epoch: [128][  123/  123]    Loss 0.684798    Top1 78.318471    Top5 97.121019    
2024-04-23 18:32:43,176 - ==> Top1: 78.318    Top5: 97.121    Loss: 0.685

2024-04-23 18:32:43,187 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:32:43,187 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:32:43,243 - 

2024-04-23 18:32:43,244 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:33:03,334 - Epoch: [129][  100/  296]    Overall Loss 0.797352    Objective Loss 0.797352                                        LR 0.000080    Time 0.200667    
2024-04-23 18:33:22,316 - Epoch: [129][  200/  296]    Overall Loss 0.748974    Objective Loss 0.748974                                        LR 0.000080    Time 0.195135    
2024-04-23 18:33:40,918 - Epoch: [129][  296/  296]    Overall Loss 0.748119    Objective Loss 0.748119    Top1 81.967213    Top5 95.081967    LR 0.000080    Time 0.194620    
2024-04-23 18:33:41,211 - --- validate (epoch=129)-----------
2024-04-23 18:33:41,212 - 3925 samples (32 per mini-batch)
2024-04-23 18:34:01,139 - Epoch: [129][  100/  123]    Loss 0.685049    Top1 78.343750    Top5 96.781250    
2024-04-23 18:34:05,489 - Epoch: [129][  123/  123]    Loss 0.688741    Top1 78.038217    Top5 96.891720    
2024-04-23 18:34:05,726 - ==> Top1: 78.038    Top5: 96.892    Loss: 0.689

2024-04-23 18:34:05,736 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:34:05,737 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:34:05,789 - 

2024-04-23 18:34:05,790 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:34:24,157 - Epoch: [130][  100/  296]    Overall Loss 0.763124    Objective Loss 0.763124                                        LR 0.000080    Time 0.183434    
2024-04-23 18:34:41,787 - Epoch: [130][  200/  296]    Overall Loss 0.747382    Objective Loss 0.747382                                        LR 0.000080    Time 0.179752    
2024-04-23 18:35:00,185 - Epoch: [130][  296/  296]    Overall Loss 0.748090    Objective Loss 0.748090    Top1 67.213115    Top5 100.000000    LR 0.000080    Time 0.183539    
2024-04-23 18:35:00,415 - --- validate (epoch=130)-----------
2024-04-23 18:35:00,416 - 3925 samples (32 per mini-batch)
2024-04-23 18:35:17,878 - Epoch: [130][  100/  123]    Loss 0.677627    Top1 77.937500    Top5 97.187500    
2024-04-23 18:35:21,589 - Epoch: [130][  123/  123]    Loss 0.687362    Top1 77.834395    Top5 97.248408    
2024-04-23 18:35:21,802 - ==> Top1: 77.834    Top5: 97.248    Loss: 0.687

2024-04-23 18:35:21,808 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:35:21,808 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:35:21,853 - 

2024-04-23 18:35:21,854 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:35:38,881 - Epoch: [131][  100/  296]    Overall Loss 0.732157    Objective Loss 0.732157                                        LR 0.000080    Time 0.170042    
2024-04-23 18:35:57,503 - Epoch: [131][  200/  296]    Overall Loss 0.747215    Objective Loss 0.747215                                        LR 0.000080    Time 0.178019    
2024-04-23 18:36:15,422 - Epoch: [131][  296/  296]    Overall Loss 0.749604    Objective Loss 0.749604    Top1 80.327869    Top5 98.360656    LR 0.000080    Time 0.180744    
2024-04-23 18:36:15,717 - --- validate (epoch=131)-----------
2024-04-23 18:36:15,718 - 3925 samples (32 per mini-batch)
2024-04-23 18:36:35,356 - Epoch: [131][  100/  123]    Loss 0.684166    Top1 78.031250    Top5 97.250000    
2024-04-23 18:36:39,700 - Epoch: [131][  123/  123]    Loss 0.676352    Top1 77.987261    Top5 97.248408    
2024-04-23 18:36:39,981 - ==> Top1: 77.987    Top5: 97.248    Loss: 0.676

2024-04-23 18:36:39,990 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:36:39,991 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:36:40,042 - 

2024-04-23 18:36:40,044 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:36:58,220 - Epoch: [132][  100/  296]    Overall Loss 0.747501    Objective Loss 0.747501                                        LR 0.000080    Time 0.181464    
2024-04-23 18:37:14,995 - Epoch: [132][  200/  296]    Overall Loss 0.740285    Objective Loss 0.740285                                        LR 0.000080    Time 0.174501    
2024-04-23 18:37:30,212 - Epoch: [132][  296/  296]    Overall Loss 0.738427    Objective Loss 0.738427    Top1 77.049180    Top5 98.360656    LR 0.000080    Time 0.169241    
2024-04-23 18:37:30,448 - --- validate (epoch=132)-----------
2024-04-23 18:37:30,449 - 3925 samples (32 per mini-batch)
2024-04-23 18:37:49,124 - Epoch: [132][  100/  123]    Loss 0.678843    Top1 77.562500    Top5 97.406250    
2024-04-23 18:37:53,502 - Epoch: [132][  123/  123]    Loss 0.678471    Top1 77.757962    Top5 97.324841    
2024-04-23 18:37:53,741 - ==> Top1: 77.758    Top5: 97.325    Loss: 0.678

2024-04-23 18:37:53,750 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:37:53,751 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:37:53,799 - 

2024-04-23 18:37:53,800 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:38:12,356 - Epoch: [133][  100/  296]    Overall Loss 0.757265    Objective Loss 0.757265                                        LR 0.000080    Time 0.185323    
2024-04-23 18:38:29,335 - Epoch: [133][  200/  296]    Overall Loss 0.745012    Objective Loss 0.745012                                        LR 0.000080    Time 0.177450    
2024-04-23 18:38:45,008 - Epoch: [133][  296/  296]    Overall Loss 0.746529    Objective Loss 0.746529    Top1 75.409836    Top5 95.081967    LR 0.000080    Time 0.172779    
2024-04-23 18:38:45,258 - --- validate (epoch=133)-----------
2024-04-23 18:38:45,259 - 3925 samples (32 per mini-batch)
2024-04-23 18:39:07,522 - Epoch: [133][  100/  123]    Loss 0.699425    Top1 77.187500    Top5 97.093750    
2024-04-23 18:39:12,152 - Epoch: [133][  123/  123]    Loss 0.687948    Top1 77.375796    Top5 97.095541    
2024-04-23 18:39:12,386 - ==> Top1: 77.376    Top5: 97.096    Loss: 0.688

2024-04-23 18:39:12,394 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:39:12,394 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:39:12,443 - 

2024-04-23 18:39:12,444 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:39:33,098 - Epoch: [134][  100/  296]    Overall Loss 0.730702    Objective Loss 0.730702                                        LR 0.000080    Time 0.206311    
2024-04-23 18:39:51,420 - Epoch: [134][  200/  296]    Overall Loss 0.732244    Objective Loss 0.732244                                        LR 0.000080    Time 0.194642    
2024-04-23 18:40:06,796 - Epoch: [134][  296/  296]    Overall Loss 0.733319    Objective Loss 0.733319    Top1 72.131148    Top5 91.803279    LR 0.000080    Time 0.183393    
2024-04-23 18:40:07,021 - --- validate (epoch=134)-----------
2024-04-23 18:40:07,022 - 3925 samples (32 per mini-batch)
2024-04-23 18:40:23,107 - Epoch: [134][  100/  123]    Loss 0.690632    Top1 77.437500    Top5 96.906250    
2024-04-23 18:40:26,558 - Epoch: [134][  123/  123]    Loss 0.678753    Top1 77.936306    Top5 97.095541    
2024-04-23 18:40:26,798 - ==> Top1: 77.936    Top5: 97.096    Loss: 0.679

2024-04-23 18:40:26,810 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:40:26,811 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:40:26,862 - 

2024-04-23 18:40:26,863 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:40:45,295 - Epoch: [135][  100/  296]    Overall Loss 0.746379    Objective Loss 0.746379                                        LR 0.000080    Time 0.184090    
2024-04-23 18:41:00,319 - Epoch: [135][  200/  296]    Overall Loss 0.738355    Objective Loss 0.738355                                        LR 0.000080    Time 0.167056    
2024-04-23 18:41:14,792 - Epoch: [135][  296/  296]    Overall Loss 0.737579    Objective Loss 0.737579    Top1 78.688525    Top5 96.721311    LR 0.000080    Time 0.161702    
2024-04-23 18:41:14,999 - --- validate (epoch=135)-----------
2024-04-23 18:41:14,999 - 3925 samples (32 per mini-batch)
2024-04-23 18:41:35,015 - Epoch: [135][  100/  123]    Loss 0.675825    Top1 78.375000    Top5 97.343750    
2024-04-23 18:41:39,330 - Epoch: [135][  123/  123]    Loss 0.675626    Top1 77.910828    Top5 97.426752    
2024-04-23 18:41:39,554 - ==> Top1: 77.911    Top5: 97.427    Loss: 0.676

2024-04-23 18:41:39,563 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:41:39,564 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:41:39,611 - 

2024-04-23 18:41:39,612 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:41:56,599 - Epoch: [136][  100/  296]    Overall Loss 0.761538    Objective Loss 0.761538                                        LR 0.000080    Time 0.169647    
2024-04-23 18:42:13,596 - Epoch: [136][  200/  296]    Overall Loss 0.751424    Objective Loss 0.751424                                        LR 0.000080    Time 0.169697    
2024-04-23 18:42:29,312 - Epoch: [136][  296/  296]    Overall Loss 0.750963    Objective Loss 0.750963    Top1 73.770492    Top5 96.721311    LR 0.000080    Time 0.167674    
2024-04-23 18:42:29,550 - --- validate (epoch=136)-----------
2024-04-23 18:42:29,552 - 3925 samples (32 per mini-batch)
2024-04-23 18:42:47,335 - Epoch: [136][  100/  123]    Loss 0.688880    Top1 77.718750    Top5 97.187500    
2024-04-23 18:42:51,558 - Epoch: [136][  123/  123]    Loss 0.682399    Top1 77.732484    Top5 97.401274    
2024-04-23 18:42:51,821 - ==> Top1: 77.732    Top5: 97.401    Loss: 0.682

2024-04-23 18:42:51,834 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:42:51,835 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:42:51,910 - 

2024-04-23 18:42:51,911 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:43:09,759 - Epoch: [137][  100/  296]    Overall Loss 0.751827    Objective Loss 0.751827                                        LR 0.000080    Time 0.178233    
2024-04-23 18:43:24,499 - Epoch: [137][  200/  296]    Overall Loss 0.742733    Objective Loss 0.742733                                        LR 0.000080    Time 0.162712    
2024-04-23 18:43:40,063 - Epoch: [137][  296/  296]    Overall Loss 0.737670    Objective Loss 0.737670    Top1 78.688525    Top5 95.081967    LR 0.000080    Time 0.162452    
2024-04-23 18:43:40,342 - --- validate (epoch=137)-----------
2024-04-23 18:43:40,344 - 3925 samples (32 per mini-batch)
2024-04-23 18:44:00,250 - Epoch: [137][  100/  123]    Loss 0.682455    Top1 77.875000    Top5 97.250000    
2024-04-23 18:44:04,418 - Epoch: [137][  123/  123]    Loss 0.687037    Top1 77.783439    Top5 97.375796    
2024-04-23 18:44:04,653 - ==> Top1: 77.783    Top5: 97.376    Loss: 0.687

2024-04-23 18:44:04,664 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:44:04,666 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:44:04,745 - 

2024-04-23 18:44:04,747 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:44:30,981 - Epoch: [138][  100/  296]    Overall Loss 0.730257    Objective Loss 0.730257                                        LR 0.000080    Time 0.262099    
2024-04-23 18:44:53,607 - Epoch: [138][  200/  296]    Overall Loss 0.741794    Objective Loss 0.741794                                        LR 0.000080    Time 0.244063    
2024-04-23 18:45:15,581 - Epoch: [138][  296/  296]    Overall Loss 0.747620    Objective Loss 0.747620    Top1 86.885246    Top5 100.000000    LR 0.000080    Time 0.239078    
2024-04-23 18:45:15,880 - --- validate (epoch=138)-----------
2024-04-23 18:45:15,881 - 3925 samples (32 per mini-batch)
2024-04-23 18:45:35,525 - Epoch: [138][  100/  123]    Loss 0.692747    Top1 77.781250    Top5 97.531250    
2024-04-23 18:45:39,492 - Epoch: [138][  123/  123]    Loss 0.683165    Top1 78.038217    Top5 97.452229    
2024-04-23 18:45:39,749 - ==> Top1: 78.038    Top5: 97.452    Loss: 0.683

2024-04-23 18:45:39,759 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:45:39,759 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:45:39,808 - 

2024-04-23 18:45:39,809 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:45:56,414 - Epoch: [139][  100/  296]    Overall Loss 0.721446    Objective Loss 0.721446                                        LR 0.000080    Time 0.165814    
2024-04-23 18:46:13,236 - Epoch: [139][  200/  296]    Overall Loss 0.737699    Objective Loss 0.737699                                        LR 0.000080    Time 0.166908    
2024-04-23 18:46:31,721 - Epoch: [139][  296/  296]    Overall Loss 0.733906    Objective Loss 0.733906    Top1 77.049180    Top5 96.721311    LR 0.000080    Time 0.175154    
2024-04-23 18:46:32,022 - --- validate (epoch=139)-----------
2024-04-23 18:46:32,024 - 3925 samples (32 per mini-batch)
2024-04-23 18:46:53,858 - Epoch: [139][  100/  123]    Loss 0.686572    Top1 77.875000    Top5 97.281250    
2024-04-23 18:46:59,060 - Epoch: [139][  123/  123]    Loss 0.681029    Top1 78.012739    Top5 97.401274    
2024-04-23 18:46:59,292 - ==> Top1: 78.013    Top5: 97.401    Loss: 0.681

2024-04-23 18:46:59,298 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:46:59,299 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:46:59,341 - 

2024-04-23 18:46:59,343 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:47:17,325 - Epoch: [140][  100/  296]    Overall Loss 0.740371    Objective Loss 0.740371                                        LR 0.000080    Time 0.179601    
2024-04-23 18:47:36,075 - Epoch: [140][  200/  296]    Overall Loss 0.732157    Objective Loss 0.732157                                        LR 0.000080    Time 0.183443    
2024-04-23 18:47:57,666 - Epoch: [140][  296/  296]    Overall Loss 0.741389    Objective Loss 0.741389    Top1 78.688525    Top5 98.360656    LR 0.000080    Time 0.196818    
2024-04-23 18:47:57,896 - --- validate (epoch=140)-----------
2024-04-23 18:47:57,897 - 3925 samples (32 per mini-batch)
2024-04-23 18:48:22,940 - Epoch: [140][  100/  123]    Loss 0.687803    Top1 77.593750    Top5 97.531250    
2024-04-23 18:48:27,420 - Epoch: [140][  123/  123]    Loss 0.681021    Top1 77.859873    Top5 97.350318    
2024-04-23 18:48:27,652 - ==> Top1: 77.860    Top5: 97.350    Loss: 0.681

2024-04-23 18:48:27,662 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:48:27,663 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:48:27,716 - 

2024-04-23 18:48:27,717 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:48:45,364 - Epoch: [141][  100/  296]    Overall Loss 0.757434    Objective Loss 0.757434                                        LR 0.000080    Time 0.176238    
2024-04-23 18:49:00,217 - Epoch: [141][  200/  296]    Overall Loss 0.730600    Objective Loss 0.730600                                        LR 0.000080    Time 0.162285    
2024-04-23 18:49:14,574 - Epoch: [141][  296/  296]    Overall Loss 0.741958    Objective Loss 0.741958    Top1 68.852459    Top5 96.721311    LR 0.000080    Time 0.158079    
2024-04-23 18:49:14,830 - --- validate (epoch=141)-----------
2024-04-23 18:49:14,832 - 3925 samples (32 per mini-batch)
2024-04-23 18:49:33,157 - Epoch: [141][  100/  123]    Loss 0.671674    Top1 78.062500    Top5 97.593750    
2024-04-23 18:49:36,869 - Epoch: [141][  123/  123]    Loss 0.675840    Top1 77.987261    Top5 97.503185    
2024-04-23 18:49:37,063 - ==> Top1: 77.987    Top5: 97.503    Loss: 0.676

2024-04-23 18:49:37,073 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:49:37,073 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:49:37,119 - 

2024-04-23 18:49:37,120 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:49:55,212 - Epoch: [142][  100/  296]    Overall Loss 0.714596    Objective Loss 0.714596                                        LR 0.000080    Time 0.180683    
2024-04-23 18:50:09,976 - Epoch: [142][  200/  296]    Overall Loss 0.721732    Objective Loss 0.721732                                        LR 0.000080    Time 0.164051    
2024-04-23 18:50:21,290 - Epoch: [142][  296/  296]    Overall Loss 0.723948    Objective Loss 0.723948    Top1 78.688525    Top5 100.000000    LR 0.000080    Time 0.149006    
2024-04-23 18:50:21,486 - --- validate (epoch=142)-----------
2024-04-23 18:50:21,487 - 3925 samples (32 per mini-batch)
2024-04-23 18:50:39,935 - Epoch: [142][  100/  123]    Loss 0.686650    Top1 77.437500    Top5 97.312500    
2024-04-23 18:50:43,650 - Epoch: [142][  123/  123]    Loss 0.688503    Top1 77.452229    Top5 97.375796    
2024-04-23 18:50:43,856 - ==> Top1: 77.452    Top5: 97.376    Loss: 0.689

2024-04-23 18:50:43,862 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:50:43,862 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:50:43,895 - 

2024-04-23 18:50:43,896 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:50:54,828 - Epoch: [143][  100/  296]    Overall Loss 0.712536    Objective Loss 0.712536                                        LR 0.000080    Time 0.109122    
2024-04-23 18:51:05,499 - Epoch: [143][  200/  296]    Overall Loss 0.743622    Objective Loss 0.743622                                        LR 0.000080    Time 0.107814    
2024-04-23 18:51:21,292 - Epoch: [143][  296/  296]    Overall Loss 0.737935    Objective Loss 0.737935    Top1 77.049180    Top5 100.000000    LR 0.000080    Time 0.126132    
2024-04-23 18:51:21,548 - --- validate (epoch=143)-----------
2024-04-23 18:51:21,549 - 3925 samples (32 per mini-batch)
2024-04-23 18:51:41,247 - Epoch: [143][  100/  123]    Loss 0.678140    Top1 78.031250    Top5 97.312500    
2024-04-23 18:51:45,316 - Epoch: [143][  123/  123]    Loss 0.686556    Top1 77.681529    Top5 97.222930    
2024-04-23 18:51:45,566 - ==> Top1: 77.682    Top5: 97.223    Loss: 0.687

2024-04-23 18:51:45,574 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:51:45,574 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:51:45,624 - 

2024-04-23 18:51:45,625 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:52:07,236 - Epoch: [144][  100/  296]    Overall Loss 0.714591    Objective Loss 0.714591                                        LR 0.000080    Time 0.215872    
2024-04-23 18:52:24,768 - Epoch: [144][  200/  296]    Overall Loss 0.726744    Objective Loss 0.726744                                        LR 0.000080    Time 0.195474    
2024-04-23 18:52:43,862 - Epoch: [144][  296/  296]    Overall Loss 0.742180    Objective Loss 0.742180    Top1 73.770492    Top5 93.442623    LR 0.000080    Time 0.196512    
2024-04-23 18:52:44,125 - --- validate (epoch=144)-----------
2024-04-23 18:52:44,127 - 3925 samples (32 per mini-batch)
2024-04-23 18:53:04,983 - Epoch: [144][  100/  123]    Loss 0.679809    Top1 78.218750    Top5 97.468750    
2024-04-23 18:53:08,737 - Epoch: [144][  123/  123]    Loss 0.684798    Top1 78.140127    Top5 97.222930    
2024-04-23 18:53:09,010 - ==> Top1: 78.140    Top5: 97.223    Loss: 0.685

2024-04-23 18:53:09,018 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:53:09,019 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:53:09,072 - 

2024-04-23 18:53:09,073 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:53:28,068 - Epoch: [145][  100/  296]    Overall Loss 0.722451    Objective Loss 0.722451                                        LR 0.000080    Time 0.189717    
2024-04-23 18:53:44,625 - Epoch: [145][  200/  296]    Overall Loss 0.722590    Objective Loss 0.722590                                        LR 0.000080    Time 0.177531    
2024-04-23 18:54:01,087 - Epoch: [145][  296/  296]    Overall Loss 0.730965    Objective Loss 0.730965    Top1 81.967213    Top5 96.721311    LR 0.000080    Time 0.175498    
2024-04-23 18:54:01,347 - --- validate (epoch=145)-----------
2024-04-23 18:54:01,348 - 3925 samples (32 per mini-batch)
2024-04-23 18:54:17,057 - Epoch: [145][  100/  123]    Loss 0.677737    Top1 78.593750    Top5 97.312500    
2024-04-23 18:54:20,001 - Epoch: [145][  123/  123]    Loss 0.690127    Top1 78.063694    Top5 97.273885    
2024-04-23 18:54:20,205 - ==> Top1: 78.064    Top5: 97.274    Loss: 0.690

2024-04-23 18:54:20,213 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:54:20,213 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:54:20,258 - 

2024-04-23 18:54:20,259 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:54:35,363 - Epoch: [146][  100/  296]    Overall Loss 0.716481    Objective Loss 0.716481                                        LR 0.000080    Time 0.150835    
2024-04-23 18:54:49,232 - Epoch: [146][  200/  296]    Overall Loss 0.719426    Objective Loss 0.719426                                        LR 0.000080    Time 0.144662    
2024-04-23 18:55:03,829 - Epoch: [146][  296/  296]    Overall Loss 0.724845    Objective Loss 0.724845    Top1 83.606557    Top5 98.360656    LR 0.000080    Time 0.146979    
2024-04-23 18:55:04,093 - --- validate (epoch=146)-----------
2024-04-23 18:55:04,094 - 3925 samples (32 per mini-batch)
2024-04-23 18:55:21,154 - Epoch: [146][  100/  123]    Loss 0.687614    Top1 78.125000    Top5 97.281250    
2024-04-23 18:55:24,963 - Epoch: [146][  123/  123]    Loss 0.683707    Top1 78.267516    Top5 97.299363    
2024-04-23 18:55:25,190 - ==> Top1: 78.268    Top5: 97.299    Loss: 0.684

2024-04-23 18:55:25,200 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:55:25,201 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:55:25,253 - 

2024-04-23 18:55:25,253 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:55:42,227 - Epoch: [147][  100/  296]    Overall Loss 0.755232    Objective Loss 0.755232                                        LR 0.000080    Time 0.169520    
2024-04-23 18:55:54,944 - Epoch: [147][  200/  296]    Overall Loss 0.745617    Objective Loss 0.745617                                        LR 0.000080    Time 0.148242    
2024-04-23 18:56:05,203 - Epoch: [147][  296/  296]    Overall Loss 0.748561    Objective Loss 0.748561    Top1 72.131148    Top5 96.721311    LR 0.000080    Time 0.134766    
2024-04-23 18:56:05,400 - --- validate (epoch=147)-----------
2024-04-23 18:56:05,401 - 3925 samples (32 per mini-batch)
2024-04-23 18:56:20,721 - Epoch: [147][  100/  123]    Loss 0.677387    Top1 78.156250    Top5 97.250000    
2024-04-23 18:56:23,707 - Epoch: [147][  123/  123]    Loss 0.678280    Top1 78.216561    Top5 97.273885    
2024-04-23 18:56:23,928 - ==> Top1: 78.217    Top5: 97.274    Loss: 0.678

2024-04-23 18:56:23,937 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:56:23,937 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:56:23,978 - 

2024-04-23 18:56:23,979 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:56:38,884 - Epoch: [148][  100/  296]    Overall Loss 0.734147    Objective Loss 0.734147                                        LR 0.000080    Time 0.148865    
2024-04-23 18:56:54,820 - Epoch: [148][  200/  296]    Overall Loss 0.724373    Objective Loss 0.724373                                        LR 0.000080    Time 0.154010    
2024-04-23 18:57:07,105 - Epoch: [148][  296/  296]    Overall Loss 0.727554    Objective Loss 0.727554    Top1 72.131148    Top5 93.442623    LR 0.000080    Time 0.145498    
2024-04-23 18:57:07,317 - --- validate (epoch=148)-----------
2024-04-23 18:57:07,320 - 3925 samples (32 per mini-batch)
2024-04-23 18:57:22,872 - Epoch: [148][  100/  123]    Loss 0.680568    Top1 77.843750    Top5 97.687500    
2024-04-23 18:57:25,606 - Epoch: [148][  123/  123]    Loss 0.688995    Top1 77.783439    Top5 97.350318    
2024-04-23 18:57:25,805 - ==> Top1: 77.783    Top5: 97.350    Loss: 0.689

2024-04-23 18:57:25,814 - ==> Best [Top1: 78.446   Top5: 97.248   Sparsity:0.00   Params: 371568 on epoch: 127]
2024-04-23 18:57:25,814 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:57:25,854 - 

2024-04-23 18:57:25,855 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:57:40,441 - Epoch: [149][  100/  296]    Overall Loss 0.757920    Objective Loss 0.757920                                        LR 0.000080    Time 0.145647    
2024-04-23 18:57:52,724 - Epoch: [149][  200/  296]    Overall Loss 0.746378    Objective Loss 0.746378                                        LR 0.000080    Time 0.134145    
2024-04-23 18:58:05,011 - Epoch: [149][  296/  296]    Overall Loss 0.728900    Objective Loss 0.728900    Top1 81.967213    Top5 95.081967    LR 0.000080    Time 0.132089    
2024-04-23 18:58:05,254 - --- validate (epoch=149)-----------
2024-04-23 18:58:05,255 - 3925 samples (32 per mini-batch)
2024-04-23 18:58:20,240 - Epoch: [149][  100/  123]    Loss 0.687815    Top1 78.375000    Top5 97.343750    
2024-04-23 18:58:22,683 - Epoch: [149][  123/  123]    Loss 0.679580    Top1 78.624204    Top5 97.324841    
2024-04-23 18:58:22,926 - ==> Top1: 78.624    Top5: 97.325    Loss: 0.680

2024-04-23 18:58:22,937 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 18:58:22,938 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:58:22,993 - 

2024-04-23 18:58:22,994 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:58:36,942 - Epoch: [150][  100/  296]    Overall Loss 0.743470    Objective Loss 0.743470                                        LR 0.000020    Time 0.139263    
2024-04-23 18:58:48,400 - Epoch: [150][  200/  296]    Overall Loss 0.719844    Objective Loss 0.719844                                        LR 0.000020    Time 0.126825    
2024-04-23 18:58:59,056 - Epoch: [150][  296/  296]    Overall Loss 0.711327    Objective Loss 0.711327    Top1 75.409836    Top5 95.081967    LR 0.000020    Time 0.121629    
2024-04-23 18:58:59,301 - --- validate (epoch=150)-----------
2024-04-23 18:58:59,303 - 3925 samples (32 per mini-batch)
2024-04-23 18:59:18,324 - Epoch: [150][  100/  123]    Loss 0.669068    Top1 78.437500    Top5 97.468750    
2024-04-23 18:59:22,008 - Epoch: [150][  123/  123]    Loss 0.676088    Top1 78.165605    Top5 97.426752    
2024-04-23 18:59:22,220 - ==> Top1: 78.166    Top5: 97.427    Loss: 0.676

2024-04-23 18:59:22,234 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 18:59:22,235 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 18:59:22,298 - 

2024-04-23 18:59:22,299 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:59:41,504 - Epoch: [151][  100/  296]    Overall Loss 0.726985    Objective Loss 0.726985                                        LR 0.000020    Time 0.191830    
2024-04-23 18:59:59,347 - Epoch: [151][  200/  296]    Overall Loss 0.713917    Objective Loss 0.713917                                        LR 0.000020    Time 0.185015    
2024-04-23 19:00:16,888 - Epoch: [151][  296/  296]    Overall Loss 0.711123    Objective Loss 0.711123    Top1 80.327869    Top5 98.360656    LR 0.000020    Time 0.184208    
2024-04-23 19:00:17,132 - --- validate (epoch=151)-----------
2024-04-23 19:00:17,134 - 3925 samples (32 per mini-batch)
2024-04-23 19:00:37,729 - Epoch: [151][  100/  123]    Loss 0.676949    Top1 78.218750    Top5 97.312500    
2024-04-23 19:00:41,624 - Epoch: [151][  123/  123]    Loss 0.675526    Top1 78.191083    Top5 97.375796    
2024-04-23 19:00:41,872 - ==> Top1: 78.191    Top5: 97.376    Loss: 0.676

2024-04-23 19:00:41,884 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:00:41,885 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:00:41,945 - 

2024-04-23 19:00:41,946 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:01:01,118 - Epoch: [152][  100/  296]    Overall Loss 0.685734    Objective Loss 0.685734                                        LR 0.000020    Time 0.191494    
2024-04-23 19:01:15,125 - Epoch: [152][  200/  296]    Overall Loss 0.692553    Objective Loss 0.692553                                        LR 0.000020    Time 0.165683    
2024-04-23 19:01:30,793 - Epoch: [152][  296/  296]    Overall Loss 0.688635    Objective Loss 0.688635    Top1 81.967213    Top5 98.360656    LR 0.000020    Time 0.164816    
2024-04-23 19:01:31,044 - --- validate (epoch=152)-----------
2024-04-23 19:01:31,045 - 3925 samples (32 per mini-batch)
2024-04-23 19:01:52,387 - Epoch: [152][  100/  123]    Loss 0.685931    Top1 77.875000    Top5 97.281250    
2024-04-23 19:01:56,480 - Epoch: [152][  123/  123]    Loss 0.674660    Top1 77.987261    Top5 97.452229    
2024-04-23 19:01:56,686 - ==> Top1: 77.987    Top5: 97.452    Loss: 0.675

2024-04-23 19:01:56,693 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:01:56,693 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:01:56,765 - 

2024-04-23 19:01:56,766 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:02:15,942 - Epoch: [153][  100/  296]    Overall Loss 0.701896    Objective Loss 0.701896                                        LR 0.000020    Time 0.191553    
2024-04-23 19:02:33,271 - Epoch: [153][  200/  296]    Overall Loss 0.708050    Objective Loss 0.708050                                        LR 0.000020    Time 0.182324    
2024-04-23 19:02:48,305 - Epoch: [153][  296/  296]    Overall Loss 0.717368    Objective Loss 0.717368    Top1 73.770492    Top5 91.803279    LR 0.000020    Time 0.173919    
2024-04-23 19:02:48,616 - --- validate (epoch=153)-----------
2024-04-23 19:02:48,617 - 3925 samples (32 per mini-batch)
2024-04-23 19:03:09,774 - Epoch: [153][  100/  123]    Loss 0.685070    Top1 77.781250    Top5 97.375000    
2024-04-23 19:03:13,362 - Epoch: [153][  123/  123]    Loss 0.675160    Top1 78.267516    Top5 97.426752    
2024-04-23 19:03:13,853 - ==> Top1: 78.268    Top5: 97.427    Loss: 0.675

2024-04-23 19:03:13,862 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:03:13,862 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:03:13,912 - 

2024-04-23 19:03:13,913 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:03:31,995 - Epoch: [154][  100/  296]    Overall Loss 0.702795    Objective Loss 0.702795                                        LR 0.000020    Time 0.180599    
2024-04-23 19:03:45,765 - Epoch: [154][  200/  296]    Overall Loss 0.723098    Objective Loss 0.723098                                        LR 0.000020    Time 0.159057    
2024-04-23 19:04:02,616 - Epoch: [154][  296/  296]    Overall Loss 0.716851    Objective Loss 0.716851    Top1 73.770492    Top5 96.721311    LR 0.000020    Time 0.164334    
2024-04-23 19:04:02,889 - --- validate (epoch=154)-----------
2024-04-23 19:04:02,890 - 3925 samples (32 per mini-batch)
2024-04-23 19:04:19,708 - Epoch: [154][  100/  123]    Loss 0.670178    Top1 78.312500    Top5 97.343750    
2024-04-23 19:04:23,472 - Epoch: [154][  123/  123]    Loss 0.673245    Top1 78.445860    Top5 97.375796    
2024-04-23 19:04:23,691 - ==> Top1: 78.446    Top5: 97.376    Loss: 0.673

2024-04-23 19:04:23,700 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:04:23,701 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:04:23,755 - 

2024-04-23 19:04:23,756 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:04:38,572 - Epoch: [155][  100/  296]    Overall Loss 0.703751    Objective Loss 0.703751                                        LR 0.000020    Time 0.147968    
2024-04-23 19:04:54,069 - Epoch: [155][  200/  296]    Overall Loss 0.705514    Objective Loss 0.705514                                        LR 0.000020    Time 0.151373    
2024-04-23 19:05:06,814 - Epoch: [155][  296/  296]    Overall Loss 0.705046    Objective Loss 0.705046    Top1 80.327869    Top5 100.000000    LR 0.000020    Time 0.145277    
2024-04-23 19:05:07,006 - --- validate (epoch=155)-----------
2024-04-23 19:05:07,007 - 3925 samples (32 per mini-batch)
2024-04-23 19:05:26,410 - Epoch: [155][  100/  123]    Loss 0.668754    Top1 78.562500    Top5 97.343750    
2024-04-23 19:05:30,170 - Epoch: [155][  123/  123]    Loss 0.672597    Top1 78.394904    Top5 97.528662    
2024-04-23 19:05:30,377 - ==> Top1: 78.395    Top5: 97.529    Loss: 0.673

2024-04-23 19:05:30,388 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:05:30,388 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:05:30,441 - 

2024-04-23 19:05:30,442 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:05:50,722 - Epoch: [156][  100/  296]    Overall Loss 0.715743    Objective Loss 0.715743                                        LR 0.000020    Time 0.202567    
2024-04-23 19:06:09,019 - Epoch: [156][  200/  296]    Overall Loss 0.711305    Objective Loss 0.711305                                        LR 0.000020    Time 0.192658    
2024-04-23 19:06:27,398 - Epoch: [156][  296/  296]    Overall Loss 0.713630    Objective Loss 0.713630    Top1 80.327869    Top5 98.360656    LR 0.000020    Time 0.192191    
2024-04-23 19:06:27,595 - --- validate (epoch=156)-----------
2024-04-23 19:06:27,596 - 3925 samples (32 per mini-batch)
2024-04-23 19:06:46,391 - Epoch: [156][  100/  123]    Loss 0.682025    Top1 78.093750    Top5 97.343750    
2024-04-23 19:06:49,206 - Epoch: [156][  123/  123]    Loss 0.667322    Top1 78.547771    Top5 97.630573    
2024-04-23 19:06:49,340 - ==> Top1: 78.548    Top5: 97.631    Loss: 0.667

2024-04-23 19:06:49,351 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:06:49,351 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:06:49,390 - 

2024-04-23 19:06:49,391 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:07:04,948 - Epoch: [157][  100/  296]    Overall Loss 0.725331    Objective Loss 0.725331                                        LR 0.000020    Time 0.155372    
2024-04-23 19:07:20,136 - Epoch: [157][  200/  296]    Overall Loss 0.719141    Objective Loss 0.719141                                        LR 0.000020    Time 0.153523    
2024-04-23 19:07:33,994 - Epoch: [157][  296/  296]    Overall Loss 0.723974    Objective Loss 0.723974    Top1 80.327869    Top5 96.721311    LR 0.000020    Time 0.150488    
2024-04-23 19:07:34,195 - --- validate (epoch=157)-----------
2024-04-23 19:07:34,196 - 3925 samples (32 per mini-batch)
2024-04-23 19:07:54,311 - Epoch: [157][  100/  123]    Loss 0.666671    Top1 78.781250    Top5 97.312500    
2024-04-23 19:07:58,609 - Epoch: [157][  123/  123]    Loss 0.672312    Top1 78.318471    Top5 97.375796    
2024-04-23 19:07:58,851 - ==> Top1: 78.318    Top5: 97.376    Loss: 0.672

2024-04-23 19:07:58,863 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:07:58,864 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:07:58,922 - 

2024-04-23 19:07:58,923 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:08:18,604 - Epoch: [158][  100/  296]    Overall Loss 0.731648    Objective Loss 0.731648                                        LR 0.000020    Time 0.196613    
2024-04-23 19:08:36,924 - Epoch: [158][  200/  296]    Overall Loss 0.725538    Objective Loss 0.725538                                        LR 0.000020    Time 0.189818    
2024-04-23 19:08:53,630 - Epoch: [158][  296/  296]    Overall Loss 0.717220    Objective Loss 0.717220    Top1 75.409836    Top5 98.360656    LR 0.000020    Time 0.184631    
2024-04-23 19:08:53,889 - --- validate (epoch=158)-----------
2024-04-23 19:08:53,891 - 3925 samples (32 per mini-batch)
2024-04-23 19:09:16,009 - Epoch: [158][  100/  123]    Loss 0.662675    Top1 78.750000    Top5 97.468750    
2024-04-23 19:09:19,542 - Epoch: [158][  123/  123]    Loss 0.676163    Top1 78.292994    Top5 97.375796    
2024-04-23 19:09:19,918 - ==> Top1: 78.293    Top5: 97.376    Loss: 0.676

2024-04-23 19:09:19,932 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:09:19,932 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:09:20,012 - 

2024-04-23 19:09:20,013 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:09:39,568 - Epoch: [159][  100/  296]    Overall Loss 0.695550    Objective Loss 0.695550                                        LR 0.000020    Time 0.195335    
2024-04-23 19:09:56,715 - Epoch: [159][  200/  296]    Overall Loss 0.704571    Objective Loss 0.704571                                        LR 0.000020    Time 0.183314    
2024-04-23 19:10:12,241 - Epoch: [159][  296/  296]    Overall Loss 0.700793    Objective Loss 0.700793    Top1 70.491803    Top5 93.442623    LR 0.000020    Time 0.176247    
2024-04-23 19:10:12,526 - --- validate (epoch=159)-----------
2024-04-23 19:10:12,527 - 3925 samples (32 per mini-batch)
2024-04-23 19:10:32,989 - Epoch: [159][  100/  123]    Loss 0.675587    Top1 78.281250    Top5 97.500000    
2024-04-23 19:10:36,508 - Epoch: [159][  123/  123]    Loss 0.667638    Top1 78.547771    Top5 97.528662    
2024-04-23 19:10:36,703 - ==> Top1: 78.548    Top5: 97.529    Loss: 0.668

2024-04-23 19:10:36,714 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:10:36,714 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:10:36,765 - 

2024-04-23 19:10:36,766 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:10:53,519 - Epoch: [160][  100/  296]    Overall Loss 0.705949    Objective Loss 0.705949                                        LR 0.000020    Time 0.167316    
2024-04-23 19:11:08,735 - Epoch: [160][  200/  296]    Overall Loss 0.706580    Objective Loss 0.706580                                        LR 0.000020    Time 0.159637    
2024-04-23 19:11:23,345 - Epoch: [160][  296/  296]    Overall Loss 0.707165    Objective Loss 0.707165    Top1 80.327869    Top5 100.000000    LR 0.000020    Time 0.157155    
2024-04-23 19:11:23,571 - --- validate (epoch=160)-----------
2024-04-23 19:11:23,572 - 3925 samples (32 per mini-batch)
2024-04-23 19:11:41,803 - Epoch: [160][  100/  123]    Loss 0.650704    Top1 78.625000    Top5 97.625000    
2024-04-23 19:11:45,735 - Epoch: [160][  123/  123]    Loss 0.669495    Top1 78.114650    Top5 97.452229    
2024-04-23 19:11:45,938 - ==> Top1: 78.115    Top5: 97.452    Loss: 0.669

2024-04-23 19:11:45,946 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:11:45,947 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:11:45,984 - 

2024-04-23 19:11:45,984 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:12:02,077 - Epoch: [161][  100/  296]    Overall Loss 0.741445    Objective Loss 0.741445                                        LR 0.000020    Time 0.160712    
2024-04-23 19:12:18,363 - Epoch: [161][  200/  296]    Overall Loss 0.722329    Objective Loss 0.722329                                        LR 0.000020    Time 0.161684    
2024-04-23 19:12:31,488 - Epoch: [161][  296/  296]    Overall Loss 0.725998    Objective Loss 0.725998    Top1 67.213115    Top5 98.360656    LR 0.000020    Time 0.153521    
2024-04-23 19:12:31,749 - --- validate (epoch=161)-----------
2024-04-23 19:12:31,751 - 3925 samples (32 per mini-batch)
2024-04-23 19:12:53,674 - Epoch: [161][  100/  123]    Loss 0.650306    Top1 79.406250    Top5 97.593750    
2024-04-23 19:12:57,512 - Epoch: [161][  123/  123]    Loss 0.672641    Top1 78.369427    Top5 97.401274    
2024-04-23 19:12:57,770 - ==> Top1: 78.369    Top5: 97.401    Loss: 0.673

2024-04-23 19:12:57,783 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:12:57,784 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:12:57,844 - 

2024-04-23 19:12:57,845 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:13:18,397 - Epoch: [162][  100/  296]    Overall Loss 0.699250    Objective Loss 0.699250                                        LR 0.000020    Time 0.205297    
2024-04-23 19:13:36,916 - Epoch: [162][  200/  296]    Overall Loss 0.692506    Objective Loss 0.692506                                        LR 0.000020    Time 0.195139    
2024-04-23 19:13:55,470 - Epoch: [162][  296/  296]    Overall Loss 0.697818    Objective Loss 0.697818    Top1 73.770492    Top5 98.360656    LR 0.000020    Time 0.194465    
2024-04-23 19:13:55,648 - --- validate (epoch=162)-----------
2024-04-23 19:13:55,649 - 3925 samples (32 per mini-batch)
2024-04-23 19:14:12,971 - Epoch: [162][  100/  123]    Loss 0.665497    Top1 77.937500    Top5 97.531250    
2024-04-23 19:14:17,073 - Epoch: [162][  123/  123]    Loss 0.669124    Top1 77.987261    Top5 97.375796    
2024-04-23 19:14:17,274 - ==> Top1: 77.987    Top5: 97.376    Loss: 0.669

2024-04-23 19:14:17,286 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:14:17,286 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:14:17,336 - 

2024-04-23 19:14:17,337 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:14:36,509 - Epoch: [163][  100/  296]    Overall Loss 0.671997    Objective Loss 0.671997                                        LR 0.000020    Time 0.191497    
2024-04-23 19:14:52,207 - Epoch: [163][  200/  296]    Overall Loss 0.687219    Objective Loss 0.687219                                        LR 0.000020    Time 0.174136    
2024-04-23 19:15:10,028 - Epoch: [163][  296/  296]    Overall Loss 0.692649    Objective Loss 0.692649    Top1 77.049180    Top5 100.000000    LR 0.000020    Time 0.177800    
2024-04-23 19:15:10,258 - --- validate (epoch=163)-----------
2024-04-23 19:15:10,258 - 3925 samples (32 per mini-batch)
2024-04-23 19:15:30,853 - Epoch: [163][  100/  123]    Loss 0.689637    Top1 77.656250    Top5 97.281250    
2024-04-23 19:15:34,923 - Epoch: [163][  123/  123]    Loss 0.672874    Top1 78.063694    Top5 97.503185    
2024-04-23 19:15:35,156 - ==> Top1: 78.064    Top5: 97.503    Loss: 0.673

2024-04-23 19:15:35,162 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:15:35,162 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:15:35,207 - 

2024-04-23 19:15:35,208 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:15:54,469 - Epoch: [164][  100/  296]    Overall Loss 0.700657    Objective Loss 0.700657                                        LR 0.000020    Time 0.192394    
2024-04-23 19:16:11,946 - Epoch: [164][  200/  296]    Overall Loss 0.711745    Objective Loss 0.711745                                        LR 0.000020    Time 0.183477    
2024-04-23 19:16:29,209 - Epoch: [164][  296/  296]    Overall Loss 0.707768    Objective Loss 0.707768    Top1 78.688525    Top5 96.721311    LR 0.000020    Time 0.182224    
2024-04-23 19:16:29,431 - --- validate (epoch=164)-----------
2024-04-23 19:16:29,431 - 3925 samples (32 per mini-batch)
2024-04-23 19:16:49,165 - Epoch: [164][  100/  123]    Loss 0.665974    Top1 78.406250    Top5 97.468750    
2024-04-23 19:16:54,164 - Epoch: [164][  123/  123]    Loss 0.671599    Top1 78.216561    Top5 97.426752    
2024-04-23 19:16:54,469 - ==> Top1: 78.217    Top5: 97.427    Loss: 0.672

2024-04-23 19:16:54,481 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:16:54,482 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:16:54,543 - 

2024-04-23 19:16:54,544 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:17:16,860 - Epoch: [165][  100/  296]    Overall Loss 0.737592    Objective Loss 0.737592                                        LR 0.000020    Time 0.222932    
2024-04-23 19:17:33,934 - Epoch: [165][  200/  296]    Overall Loss 0.716179    Objective Loss 0.716179                                        LR 0.000020    Time 0.196737    
2024-04-23 19:17:49,855 - Epoch: [165][  296/  296]    Overall Loss 0.711478    Objective Loss 0.711478    Top1 72.131148    Top5 98.360656    LR 0.000020    Time 0.186658    
2024-04-23 19:17:50,062 - --- validate (epoch=165)-----------
2024-04-23 19:17:50,063 - 3925 samples (32 per mini-batch)
2024-04-23 19:18:07,009 - Epoch: [165][  100/  123]    Loss 0.683793    Top1 78.062500    Top5 97.406250    
2024-04-23 19:18:09,805 - Epoch: [165][  123/  123]    Loss 0.671665    Top1 78.394904    Top5 97.477707    
2024-04-23 19:18:10,068 - ==> Top1: 78.395    Top5: 97.478    Loss: 0.672

2024-04-23 19:18:10,077 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:18:10,078 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:18:10,128 - 

2024-04-23 19:18:10,129 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:18:23,933 - Epoch: [166][  100/  296]    Overall Loss 0.718049    Objective Loss 0.718049                                        LR 0.000020    Time 0.137822    
2024-04-23 19:18:37,535 - Epoch: [166][  200/  296]    Overall Loss 0.696337    Objective Loss 0.696337                                        LR 0.000020    Time 0.136828    
2024-04-23 19:18:51,535 - Epoch: [166][  296/  296]    Overall Loss 0.701714    Objective Loss 0.701714    Top1 72.131148    Top5 96.721311    LR 0.000020    Time 0.139685    
2024-04-23 19:18:51,737 - --- validate (epoch=166)-----------
2024-04-23 19:18:51,738 - 3925 samples (32 per mini-batch)
2024-04-23 19:19:10,062 - Epoch: [166][  100/  123]    Loss 0.672500    Top1 78.531250    Top5 97.437500    
2024-04-23 19:19:13,978 - Epoch: [166][  123/  123]    Loss 0.670367    Top1 78.420382    Top5 97.503185    
2024-04-23 19:19:14,169 - ==> Top1: 78.420    Top5: 97.503    Loss: 0.670

2024-04-23 19:19:14,175 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:19:14,175 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:19:14,219 - 

2024-04-23 19:19:14,220 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:19:32,396 - Epoch: [167][  100/  296]    Overall Loss 0.734298    Objective Loss 0.734298                                        LR 0.000020    Time 0.181560    
2024-04-23 19:19:48,773 - Epoch: [167][  200/  296]    Overall Loss 0.721612    Objective Loss 0.721612                                        LR 0.000020    Time 0.172555    
2024-04-23 19:20:06,804 - Epoch: [167][  296/  296]    Overall Loss 0.710557    Objective Loss 0.710557    Top1 67.213115    Top5 95.081967    LR 0.000020    Time 0.177448    
2024-04-23 19:20:07,098 - --- validate (epoch=167)-----------
2024-04-23 19:20:07,100 - 3925 samples (32 per mini-batch)
2024-04-23 19:20:24,293 - Epoch: [167][  100/  123]    Loss 0.688123    Top1 77.812500    Top5 97.343750    
2024-04-23 19:20:27,957 - Epoch: [167][  123/  123]    Loss 0.673971    Top1 77.987261    Top5 97.477707    
2024-04-23 19:20:28,233 - ==> Top1: 77.987    Top5: 97.478    Loss: 0.674

2024-04-23 19:20:28,243 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:20:28,244 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:20:28,291 - 

2024-04-23 19:20:28,292 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:20:46,819 - Epoch: [168][  100/  296]    Overall Loss 0.698743    Objective Loss 0.698743                                        LR 0.000020    Time 0.185067    
2024-04-23 19:21:05,355 - Epoch: [168][  200/  296]    Overall Loss 0.688771    Objective Loss 0.688771                                        LR 0.000020    Time 0.185124    
2024-04-23 19:21:22,080 - Epoch: [168][  296/  296]    Overall Loss 0.696386    Objective Loss 0.696386    Top1 81.967213    Top5 96.721311    LR 0.000020    Time 0.181527    
2024-04-23 19:21:22,361 - --- validate (epoch=168)-----------
2024-04-23 19:21:22,362 - 3925 samples (32 per mini-batch)
2024-04-23 19:21:36,916 - Epoch: [168][  100/  123]    Loss 0.670897    Top1 78.125000    Top5 97.531250    
2024-04-23 19:21:40,057 - Epoch: [168][  123/  123]    Loss 0.672708    Top1 78.267516    Top5 97.350318    
2024-04-23 19:21:40,267 - ==> Top1: 78.268    Top5: 97.350    Loss: 0.673

2024-04-23 19:21:40,274 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:21:40,275 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:21:40,308 - 

2024-04-23 19:21:40,309 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:21:53,645 - Epoch: [169][  100/  296]    Overall Loss 0.725558    Objective Loss 0.725558                                        LR 0.000020    Time 0.133143    
2024-04-23 19:22:08,251 - Epoch: [169][  200/  296]    Overall Loss 0.716681    Objective Loss 0.716681                                        LR 0.000020    Time 0.139505    
2024-04-23 19:22:22,346 - Epoch: [169][  296/  296]    Overall Loss 0.717245    Objective Loss 0.717245    Top1 75.409836    Top5 93.442623    LR 0.000020    Time 0.141813    
2024-04-23 19:22:22,529 - --- validate (epoch=169)-----------
2024-04-23 19:22:22,530 - 3925 samples (32 per mini-batch)
2024-04-23 19:22:40,391 - Epoch: [169][  100/  123]    Loss 0.681265    Top1 78.062500    Top5 97.500000    
2024-04-23 19:22:43,132 - Epoch: [169][  123/  123]    Loss 0.672010    Top1 78.140127    Top5 97.426752    
2024-04-23 19:22:43,333 - ==> Top1: 78.140    Top5: 97.427    Loss: 0.672

2024-04-23 19:22:43,343 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:22:43,343 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:22:43,387 - 

2024-04-23 19:22:43,388 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:23:03,451 - Epoch: [170][  100/  296]    Overall Loss 0.736106    Objective Loss 0.736106                                        LR 0.000020    Time 0.200439    
2024-04-23 19:23:15,491 - Epoch: [170][  200/  296]    Overall Loss 0.728816    Objective Loss 0.728816                                        LR 0.000020    Time 0.160326    
2024-04-23 19:23:23,483 - Epoch: [170][  296/  296]    Overall Loss 0.727009    Objective Loss 0.727009    Top1 85.245902    Top5 98.360656    LR 0.000020    Time 0.135264    
2024-04-23 19:23:23,774 - --- validate (epoch=170)-----------
2024-04-23 19:23:23,776 - 3925 samples (32 per mini-batch)
2024-04-23 19:23:41,258 - Epoch: [170][  100/  123]    Loss 0.673732    Top1 78.125000    Top5 97.625000    
2024-04-23 19:23:44,413 - Epoch: [170][  123/  123]    Loss 0.676048    Top1 78.038217    Top5 97.477707    
2024-04-23 19:23:44,630 - ==> Top1: 78.038    Top5: 97.478    Loss: 0.676

2024-04-23 19:23:44,638 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:23:44,639 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:23:44,686 - 

2024-04-23 19:23:44,686 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:24:03,282 - Epoch: [171][  100/  296]    Overall Loss 0.729771    Objective Loss 0.729771                                        LR 0.000020    Time 0.185748    
2024-04-23 19:24:21,438 - Epoch: [171][  200/  296]    Overall Loss 0.714990    Objective Loss 0.714990                                        LR 0.000020    Time 0.183562    
2024-04-23 19:24:33,756 - Epoch: [171][  296/  296]    Overall Loss 0.716090    Objective Loss 0.716090    Top1 83.606557    Top5 100.000000    LR 0.000020    Time 0.165581    
2024-04-23 19:24:33,996 - --- validate (epoch=171)-----------
2024-04-23 19:24:33,997 - 3925 samples (32 per mini-batch)
2024-04-23 19:24:48,101 - Epoch: [171][  100/  123]    Loss 0.669707    Top1 77.781250    Top5 97.437500    
2024-04-23 19:24:52,114 - Epoch: [171][  123/  123]    Loss 0.677636    Top1 77.757962    Top5 97.503185    
2024-04-23 19:24:52,343 - ==> Top1: 77.758    Top5: 97.503    Loss: 0.678

2024-04-23 19:24:52,352 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:24:52,352 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:24:52,399 - 

2024-04-23 19:24:52,400 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:25:05,030 - Epoch: [172][  100/  296]    Overall Loss 0.709998    Objective Loss 0.709998                                        LR 0.000020    Time 0.126112    
2024-04-23 19:25:19,470 - Epoch: [172][  200/  296]    Overall Loss 0.698318    Objective Loss 0.698318                                        LR 0.000020    Time 0.135154    
2024-04-23 19:25:33,215 - Epoch: [172][  296/  296]    Overall Loss 0.694604    Objective Loss 0.694604    Top1 81.967213    Top5 98.360656    LR 0.000020    Time 0.137695    
2024-04-23 19:25:33,427 - --- validate (epoch=172)-----------
2024-04-23 19:25:33,428 - 3925 samples (32 per mini-batch)
2024-04-23 19:25:51,742 - Epoch: [172][  100/  123]    Loss 0.663991    Top1 78.531250    Top5 97.531250    
2024-04-23 19:25:55,251 - Epoch: [172][  123/  123]    Loss 0.673979    Top1 78.191083    Top5 97.401274    
2024-04-23 19:25:55,471 - ==> Top1: 78.191    Top5: 97.401    Loss: 0.674

2024-04-23 19:25:55,481 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:25:55,482 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:25:55,530 - 

2024-04-23 19:25:55,531 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:26:09,339 - Epoch: [173][  100/  296]    Overall Loss 0.725595    Objective Loss 0.725595                                        LR 0.000020    Time 0.137873    
2024-04-23 19:26:19,682 - Epoch: [173][  200/  296]    Overall Loss 0.716082    Objective Loss 0.716082                                        LR 0.000020    Time 0.120555    
2024-04-23 19:26:31,054 - Epoch: [173][  296/  296]    Overall Loss 0.708022    Objective Loss 0.708022    Top1 80.327869    Top5 98.360656    LR 0.000020    Time 0.119808    
2024-04-23 19:26:31,303 - --- validate (epoch=173)-----------
2024-04-23 19:26:31,304 - 3925 samples (32 per mini-batch)
2024-04-23 19:26:48,424 - Epoch: [173][  100/  123]    Loss 0.663351    Top1 78.218750    Top5 97.500000    
2024-04-23 19:26:52,108 - Epoch: [173][  123/  123]    Loss 0.673331    Top1 77.961783    Top5 97.528662    
2024-04-23 19:26:52,366 - ==> Top1: 77.962    Top5: 97.529    Loss: 0.673

2024-04-23 19:26:52,374 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:26:52,375 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:26:52,417 - 

2024-04-23 19:26:52,418 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:27:08,506 - Epoch: [174][  100/  296]    Overall Loss 0.711976    Objective Loss 0.711976                                        LR 0.000020    Time 0.160660    
2024-04-23 19:27:25,471 - Epoch: [174][  200/  296]    Overall Loss 0.722420    Objective Loss 0.722420                                        LR 0.000020    Time 0.165052    
2024-04-23 19:27:34,022 - Epoch: [174][  296/  296]    Overall Loss 0.719458    Objective Loss 0.719458    Top1 83.606557    Top5 96.721311    LR 0.000020    Time 0.140342    
2024-04-23 19:27:34,320 - --- validate (epoch=174)-----------
2024-04-23 19:27:34,321 - 3925 samples (32 per mini-batch)
2024-04-23 19:27:50,988 - Epoch: [174][  100/  123]    Loss 0.667698    Top1 78.781250    Top5 97.500000    
2024-04-23 19:27:52,727 - Epoch: [174][  123/  123]    Loss 0.672841    Top1 78.496815    Top5 97.477707    
2024-04-23 19:27:52,942 - ==> Top1: 78.497    Top5: 97.478    Loss: 0.673

2024-04-23 19:27:52,951 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:27:52,951 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:27:52,991 - 

2024-04-23 19:27:52,992 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:28:03,060 - Epoch: [175][  100/  296]    Overall Loss 0.707613    Objective Loss 0.707613                                        LR 0.000020    Time 0.100475    
2024-04-23 19:28:16,936 - Epoch: [175][  200/  296]    Overall Loss 0.721552    Objective Loss 0.721552                                        LR 0.000020    Time 0.119514    
2024-04-23 19:28:26,949 - Epoch: [175][  296/  296]    Overall Loss 0.715363    Objective Loss 0.715363    Top1 81.967213    Top5 95.081967    LR 0.000020    Time 0.114519    
2024-04-23 19:28:27,200 - --- validate (epoch=175)-----------
2024-04-23 19:28:27,202 - 3925 samples (32 per mini-batch)
2024-04-23 19:28:37,490 - Epoch: [175][  100/  123]    Loss 0.665278    Top1 78.937500    Top5 97.468750    
2024-04-23 19:28:40,143 - Epoch: [175][  123/  123]    Loss 0.679257    Top1 78.318471    Top5 97.452229    
2024-04-23 19:28:40,325 - ==> Top1: 78.318    Top5: 97.452    Loss: 0.679

2024-04-23 19:28:40,333 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:28:40,334 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:28:40,374 - 

2024-04-23 19:28:40,375 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:28:51,107 - Epoch: [176][  100/  296]    Overall Loss 0.708797    Objective Loss 0.708797                                        LR 0.000020    Time 0.107125    
2024-04-23 19:29:00,395 - Epoch: [176][  200/  296]    Overall Loss 0.704192    Objective Loss 0.704192                                        LR 0.000020    Time 0.099920    
2024-04-23 19:29:10,163 - Epoch: [176][  296/  296]    Overall Loss 0.692106    Objective Loss 0.692106    Top1 73.770492    Top5 95.081967    LR 0.000020    Time 0.100450    
2024-04-23 19:29:10,389 - --- validate (epoch=176)-----------
2024-04-23 19:29:10,390 - 3925 samples (32 per mini-batch)
2024-04-23 19:29:26,535 - Epoch: [176][  100/  123]    Loss 0.652958    Top1 78.781250    Top5 97.625000    
2024-04-23 19:29:29,742 - Epoch: [176][  123/  123]    Loss 0.670203    Top1 78.165605    Top5 97.477707    
2024-04-23 19:29:29,955 - ==> Top1: 78.166    Top5: 97.478    Loss: 0.670

2024-04-23 19:29:29,964 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:29:29,964 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:29:30,009 - 

2024-04-23 19:29:30,010 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:29:48,069 - Epoch: [177][  100/  296]    Overall Loss 0.700272    Objective Loss 0.700272                                        LR 0.000020    Time 0.180388    
2024-04-23 19:30:05,321 - Epoch: [177][  200/  296]    Overall Loss 0.701401    Objective Loss 0.701401                                        LR 0.000020    Time 0.176357    
2024-04-23 19:30:18,944 - Epoch: [177][  296/  296]    Overall Loss 0.701602    Objective Loss 0.701602    Top1 88.524590    Top5 98.360656    LR 0.000020    Time 0.165123    
2024-04-23 19:30:19,240 - --- validate (epoch=177)-----------
2024-04-23 19:30:19,241 - 3925 samples (32 per mini-batch)
2024-04-23 19:30:35,638 - Epoch: [177][  100/  123]    Loss 0.680021    Top1 78.250000    Top5 97.187500    
2024-04-23 19:30:38,958 - Epoch: [177][  123/  123]    Loss 0.674113    Top1 78.318471    Top5 97.299363    
2024-04-23 19:30:39,170 - ==> Top1: 78.318    Top5: 97.299    Loss: 0.674

2024-04-23 19:30:39,176 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:30:39,177 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:30:39,217 - 

2024-04-23 19:30:39,218 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:30:56,135 - Epoch: [178][  100/  296]    Overall Loss 0.704677    Objective Loss 0.704677                                        LR 0.000020    Time 0.168965    
2024-04-23 19:31:10,413 - Epoch: [178][  200/  296]    Overall Loss 0.698263    Objective Loss 0.698263                                        LR 0.000020    Time 0.155776    
2024-04-23 19:31:22,961 - Epoch: [178][  296/  296]    Overall Loss 0.697577    Objective Loss 0.697577    Top1 73.770492    Top5 95.081967    LR 0.000020    Time 0.147581    
2024-04-23 19:31:23,203 - --- validate (epoch=178)-----------
2024-04-23 19:31:23,204 - 3925 samples (32 per mini-batch)
2024-04-23 19:31:41,565 - Epoch: [178][  100/  123]    Loss 0.676563    Top1 77.968750    Top5 97.531250    
2024-04-23 19:31:44,728 - Epoch: [178][  123/  123]    Loss 0.670118    Top1 78.318471    Top5 97.477707    
2024-04-23 19:31:44,957 - ==> Top1: 78.318    Top5: 97.478    Loss: 0.670

2024-04-23 19:31:44,968 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:31:44,968 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:31:45,008 - 

2024-04-23 19:31:45,008 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:31:59,254 - Epoch: [179][  100/  296]    Overall Loss 0.717123    Objective Loss 0.717123                                        LR 0.000020    Time 0.142261    
2024-04-23 19:32:15,382 - Epoch: [179][  200/  296]    Overall Loss 0.718540    Objective Loss 0.718540                                        LR 0.000020    Time 0.151670    
2024-04-23 19:32:29,508 - Epoch: [179][  296/  296]    Overall Loss 0.707929    Objective Loss 0.707929    Top1 75.409836    Top5 98.360656    LR 0.000020    Time 0.150144    
2024-04-23 19:32:29,698 - --- validate (epoch=179)-----------
2024-04-23 19:32:29,699 - 3925 samples (32 per mini-batch)
2024-04-23 19:32:46,836 - Epoch: [179][  100/  123]    Loss 0.676863    Top1 78.125000    Top5 97.375000    
2024-04-23 19:32:50,914 - Epoch: [179][  123/  123]    Loss 0.668070    Top1 78.165605    Top5 97.426752    
2024-04-23 19:32:51,188 - ==> Top1: 78.166    Top5: 97.427    Loss: 0.668

2024-04-23 19:32:51,197 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:32:51,198 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:32:51,260 - 

2024-04-23 19:32:51,260 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:33:11,519 - Epoch: [180][  100/  296]    Overall Loss 0.722821    Objective Loss 0.722821                                        LR 0.000020    Time 0.202379    
2024-04-23 19:33:27,054 - Epoch: [180][  200/  296]    Overall Loss 0.715186    Objective Loss 0.715186                                        LR 0.000020    Time 0.178767    
2024-04-23 19:33:39,020 - Epoch: [180][  296/  296]    Overall Loss 0.712147    Objective Loss 0.712147    Top1 77.049180    Top5 93.442623    LR 0.000020    Time 0.161152    
2024-04-23 19:33:39,267 - --- validate (epoch=180)-----------
2024-04-23 19:33:39,268 - 3925 samples (32 per mini-batch)
2024-04-23 19:33:57,723 - Epoch: [180][  100/  123]    Loss 0.680658    Top1 78.125000    Top5 97.375000    
2024-04-23 19:34:02,055 - Epoch: [180][  123/  123]    Loss 0.673108    Top1 78.089172    Top5 97.375796    
2024-04-23 19:34:02,272 - ==> Top1: 78.089    Top5: 97.376    Loss: 0.673

2024-04-23 19:34:02,283 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:34:02,283 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:34:02,333 - 

2024-04-23 19:34:02,334 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:34:19,926 - Epoch: [181][  100/  296]    Overall Loss 0.697166    Objective Loss 0.697166                                        LR 0.000020    Time 0.175703    
2024-04-23 19:34:30,469 - Epoch: [181][  200/  296]    Overall Loss 0.699385    Objective Loss 0.699385                                        LR 0.000020    Time 0.140474    
2024-04-23 19:34:42,872 - Epoch: [181][  296/  296]    Overall Loss 0.702293    Objective Loss 0.702293    Top1 68.852459    Top5 95.081967    LR 0.000020    Time 0.136755    
2024-04-23 19:34:43,071 - --- validate (epoch=181)-----------
2024-04-23 19:34:43,072 - 3925 samples (32 per mini-batch)
2024-04-23 19:34:58,264 - Epoch: [181][  100/  123]    Loss 0.663084    Top1 78.562500    Top5 97.531250    
2024-04-23 19:35:00,510 - Epoch: [181][  123/  123]    Loss 0.665155    Top1 78.343949    Top5 97.579618    
2024-04-23 19:35:00,681 - ==> Top1: 78.344    Top5: 97.580    Loss: 0.665

2024-04-23 19:35:00,685 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:35:00,685 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:35:00,733 - 

2024-04-23 19:35:00,734 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:35:13,807 - Epoch: [182][  100/  296]    Overall Loss 0.703011    Objective Loss 0.703011                                        LR 0.000020    Time 0.130517    
2024-04-23 19:35:24,288 - Epoch: [182][  200/  296]    Overall Loss 0.710811    Objective Loss 0.710811                                        LR 0.000020    Time 0.117578    
2024-04-23 19:35:35,054 - Epoch: [182][  296/  296]    Overall Loss 0.700917    Objective Loss 0.700917    Top1 72.131148    Top5 93.442623    LR 0.000020    Time 0.115756    
2024-04-23 19:35:35,308 - --- validate (epoch=182)-----------
2024-04-23 19:35:35,309 - 3925 samples (32 per mini-batch)
2024-04-23 19:35:52,140 - Epoch: [182][  100/  123]    Loss 0.683262    Top1 77.812500    Top5 97.281250    
2024-04-23 19:35:55,366 - Epoch: [182][  123/  123]    Loss 0.672772    Top1 78.216561    Top5 97.452229    
2024-04-23 19:35:55,593 - ==> Top1: 78.217    Top5: 97.452    Loss: 0.673

2024-04-23 19:35:55,602 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:35:55,603 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:35:55,649 - 

2024-04-23 19:35:55,650 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:36:09,242 - Epoch: [183][  100/  296]    Overall Loss 0.711380    Objective Loss 0.711380                                        LR 0.000020    Time 0.135725    
2024-04-23 19:36:21,790 - Epoch: [183][  200/  296]    Overall Loss 0.708503    Objective Loss 0.708503                                        LR 0.000020    Time 0.130504    
2024-04-23 19:36:35,141 - Epoch: [183][  296/  296]    Overall Loss 0.695684    Objective Loss 0.695684    Top1 78.688525    Top5 96.721311    LR 0.000020    Time 0.133220    
2024-04-23 19:36:35,316 - --- validate (epoch=183)-----------
2024-04-23 19:36:35,317 - 3925 samples (32 per mini-batch)
2024-04-23 19:36:50,393 - Epoch: [183][  100/  123]    Loss 0.675344    Top1 77.750000    Top5 97.218750    
2024-04-23 19:36:52,946 - Epoch: [183][  123/  123]    Loss 0.672085    Top1 77.961783    Top5 97.299363    
2024-04-23 19:36:53,171 - ==> Top1: 77.962    Top5: 97.299    Loss: 0.672

2024-04-23 19:36:53,177 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:36:53,177 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:36:53,212 - 

2024-04-23 19:36:53,213 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:37:06,804 - Epoch: [184][  100/  296]    Overall Loss 0.703471    Objective Loss 0.703471                                        LR 0.000020    Time 0.135709    
2024-04-23 19:37:22,201 - Epoch: [184][  200/  296]    Overall Loss 0.710929    Objective Loss 0.710929                                        LR 0.000020    Time 0.144740    
2024-04-23 19:37:39,081 - Epoch: [184][  296/  296]    Overall Loss 0.703744    Objective Loss 0.703744    Top1 77.049180    Top5 98.360656    LR 0.000020    Time 0.154766    
2024-04-23 19:37:39,325 - --- validate (epoch=184)-----------
2024-04-23 19:37:39,326 - 3925 samples (32 per mini-batch)
2024-04-23 19:37:59,846 - Epoch: [184][  100/  123]    Loss 0.676841    Top1 77.781250    Top5 97.500000    
2024-04-23 19:38:03,381 - Epoch: [184][  123/  123]    Loss 0.665728    Top1 77.987261    Top5 97.528662    
2024-04-23 19:38:03,595 - ==> Top1: 77.987    Top5: 97.529    Loss: 0.666

2024-04-23 19:38:03,604 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:38:03,605 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:38:03,662 - 

2024-04-23 19:38:03,663 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:38:21,243 - Epoch: [185][  100/  296]    Overall Loss 0.743365    Objective Loss 0.743365                                        LR 0.000020    Time 0.175589    
2024-04-23 19:38:37,991 - Epoch: [185][  200/  296]    Overall Loss 0.722809    Objective Loss 0.722809                                        LR 0.000020    Time 0.171429    
2024-04-23 19:38:54,380 - Epoch: [185][  296/  296]    Overall Loss 0.719357    Objective Loss 0.719357    Top1 77.049180    Top5 96.721311    LR 0.000020    Time 0.171134    
2024-04-23 19:38:54,672 - --- validate (epoch=185)-----------
2024-04-23 19:38:54,673 - 3925 samples (32 per mini-batch)
2024-04-23 19:39:09,196 - Epoch: [185][  100/  123]    Loss 0.658442    Top1 78.093750    Top5 97.562500    
2024-04-23 19:39:12,107 - Epoch: [185][  123/  123]    Loss 0.669723    Top1 77.936306    Top5 97.452229    
2024-04-23 19:39:12,305 - ==> Top1: 77.936    Top5: 97.452    Loss: 0.670

2024-04-23 19:39:12,314 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:39:12,315 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:39:12,361 - 

2024-04-23 19:39:12,361 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:39:28,895 - Epoch: [186][  100/  296]    Overall Loss 0.724946    Objective Loss 0.724946                                        LR 0.000020    Time 0.165141    
2024-04-23 19:39:44,079 - Epoch: [186][  200/  296]    Overall Loss 0.701142    Objective Loss 0.701142                                        LR 0.000020    Time 0.158391    
2024-04-23 19:39:56,043 - Epoch: [186][  296/  296]    Overall Loss 0.689074    Objective Loss 0.689074    Top1 80.327869    Top5 95.081967    LR 0.000020    Time 0.147379    
2024-04-23 19:39:56,271 - --- validate (epoch=186)-----------
2024-04-23 19:39:56,272 - 3925 samples (32 per mini-batch)
2024-04-23 19:40:10,559 - Epoch: [186][  100/  123]    Loss 0.666643    Top1 78.500000    Top5 97.218750    
2024-04-23 19:40:12,852 - Epoch: [186][  123/  123]    Loss 0.669827    Top1 78.216561    Top5 97.426752    
2024-04-23 19:40:13,016 - ==> Top1: 78.217    Top5: 97.427    Loss: 0.670

2024-04-23 19:40:13,025 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:40:13,025 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:40:13,062 - 

2024-04-23 19:40:13,063 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:40:27,046 - Epoch: [187][  100/  296]    Overall Loss 0.727034    Objective Loss 0.727034                                        LR 0.000020    Time 0.139612    
2024-04-23 19:40:39,819 - Epoch: [187][  200/  296]    Overall Loss 0.711512    Objective Loss 0.711512                                        LR 0.000020    Time 0.133570    
2024-04-23 19:40:50,184 - Epoch: [187][  296/  296]    Overall Loss 0.706400    Objective Loss 0.706400    Top1 85.245902    Top5 98.360656    LR 0.000020    Time 0.125207    
2024-04-23 19:40:50,426 - --- validate (epoch=187)-----------
2024-04-23 19:40:50,428 - 3925 samples (32 per mini-batch)
2024-04-23 19:41:06,257 - Epoch: [187][  100/  123]    Loss 0.655962    Top1 78.906250    Top5 97.718750    
2024-04-23 19:41:09,035 - Epoch: [187][  123/  123]    Loss 0.666619    Top1 78.496815    Top5 97.528662    
2024-04-23 19:41:09,270 - ==> Top1: 78.497    Top5: 97.529    Loss: 0.667

2024-04-23 19:41:09,279 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:41:09,280 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:41:09,319 - 

2024-04-23 19:41:09,319 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:41:23,271 - Epoch: [188][  100/  296]    Overall Loss 0.684096    Objective Loss 0.684096                                        LR 0.000020    Time 0.139319    
2024-04-23 19:41:40,491 - Epoch: [188][  200/  296]    Overall Loss 0.677555    Objective Loss 0.677555                                        LR 0.000020    Time 0.155656    
2024-04-23 19:41:55,518 - Epoch: [188][  296/  296]    Overall Loss 0.686742    Objective Loss 0.686742    Top1 86.885246    Top5 95.081967    LR 0.000020    Time 0.155876    
2024-04-23 19:41:55,803 - --- validate (epoch=188)-----------
2024-04-23 19:41:55,804 - 3925 samples (32 per mini-batch)
2024-04-23 19:42:12,753 - Epoch: [188][  100/  123]    Loss 0.677798    Top1 77.406250    Top5 97.218750    
2024-04-23 19:42:17,242 - Epoch: [188][  123/  123]    Loss 0.671448    Top1 77.808917    Top5 97.324841    
2024-04-23 19:42:17,529 - ==> Top1: 77.809    Top5: 97.325    Loss: 0.671

2024-04-23 19:42:17,542 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:42:17,543 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:42:17,604 - 

2024-04-23 19:42:17,605 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:42:34,805 - Epoch: [189][  100/  296]    Overall Loss 0.708192    Objective Loss 0.708192                                        LR 0.000020    Time 0.171792    
2024-04-23 19:42:51,564 - Epoch: [189][  200/  296]    Overall Loss 0.697759    Objective Loss 0.697759                                        LR 0.000020    Time 0.169590    
2024-04-23 19:43:05,842 - Epoch: [189][  296/  296]    Overall Loss 0.693895    Objective Loss 0.693895    Top1 77.049180    Top5 100.000000    LR 0.000020    Time 0.162761    
2024-04-23 19:43:06,038 - --- validate (epoch=189)-----------
2024-04-23 19:43:06,039 - 3925 samples (32 per mini-batch)
2024-04-23 19:43:18,633 - Epoch: [189][  100/  123]    Loss 0.680107    Top1 77.843750    Top5 97.343750    
2024-04-23 19:43:21,312 - Epoch: [189][  123/  123]    Loss 0.672997    Top1 78.165605    Top5 97.452229    
2024-04-23 19:43:21,520 - ==> Top1: 78.166    Top5: 97.452    Loss: 0.673

2024-04-23 19:43:21,526 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:43:21,527 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:43:21,562 - 

2024-04-23 19:43:21,563 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:43:34,764 - Epoch: [190][  100/  296]    Overall Loss 0.699912    Objective Loss 0.699912                                        LR 0.000020    Time 0.131826    
2024-04-23 19:43:50,873 - Epoch: [190][  200/  296]    Overall Loss 0.699799    Objective Loss 0.699799                                        LR 0.000020    Time 0.146361    
2024-04-23 19:44:05,535 - Epoch: [190][  296/  296]    Overall Loss 0.700142    Objective Loss 0.700142    Top1 67.213115    Top5 100.000000    LR 0.000020    Time 0.148363    
2024-04-23 19:44:05,785 - --- validate (epoch=190)-----------
2024-04-23 19:44:05,786 - 3925 samples (32 per mini-batch)
2024-04-23 19:44:25,853 - Epoch: [190][  100/  123]    Loss 0.659657    Top1 78.968750    Top5 97.531250    
2024-04-23 19:44:30,574 - Epoch: [190][  123/  123]    Loss 0.664546    Top1 78.445860    Top5 97.554140    
2024-04-23 19:44:30,832 - ==> Top1: 78.446    Top5: 97.554    Loss: 0.665

2024-04-23 19:44:30,842 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:44:30,843 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:44:30,895 - 

2024-04-23 19:44:30,896 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:44:50,555 - Epoch: [191][  100/  296]    Overall Loss 0.711446    Objective Loss 0.711446                                        LR 0.000020    Time 0.196373    
2024-04-23 19:45:07,387 - Epoch: [191][  200/  296]    Overall Loss 0.712074    Objective Loss 0.712074                                        LR 0.000020    Time 0.182248    
2024-04-23 19:45:25,849 - Epoch: [191][  296/  296]    Overall Loss 0.704942    Objective Loss 0.704942    Top1 77.049180    Top5 95.081967    LR 0.000020    Time 0.185450    
2024-04-23 19:45:26,151 - --- validate (epoch=191)-----------
2024-04-23 19:45:26,152 - 3925 samples (32 per mini-batch)
2024-04-23 19:45:44,624 - Epoch: [191][  100/  123]    Loss 0.678937    Top1 78.406250    Top5 97.125000    
2024-04-23 19:45:48,449 - Epoch: [191][  123/  123]    Loss 0.674250    Top1 78.318471    Top5 97.324841    
2024-04-23 19:45:48,644 - ==> Top1: 78.318    Top5: 97.325    Loss: 0.674

2024-04-23 19:45:48,654 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:45:48,655 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:45:48,706 - 

2024-04-23 19:45:48,707 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:46:02,877 - Epoch: [192][  100/  296]    Overall Loss 0.710033    Objective Loss 0.710033                                        LR 0.000020    Time 0.141510    
2024-04-23 19:46:15,384 - Epoch: [192][  200/  296]    Overall Loss 0.697205    Objective Loss 0.697205                                        LR 0.000020    Time 0.133197    
2024-04-23 19:46:27,625 - Epoch: [192][  296/  296]    Overall Loss 0.698715    Objective Loss 0.698715    Top1 70.491803    Top5 98.360656    LR 0.000020    Time 0.131290    
2024-04-23 19:46:27,848 - --- validate (epoch=192)-----------
2024-04-23 19:46:27,850 - 3925 samples (32 per mini-batch)
2024-04-23 19:46:44,542 - Epoch: [192][  100/  123]    Loss 0.688333    Top1 77.500000    Top5 97.218750    
2024-04-23 19:46:47,231 - Epoch: [192][  123/  123]    Loss 0.673416    Top1 78.089172    Top5 97.248408    
2024-04-23 19:46:47,412 - ==> Top1: 78.089    Top5: 97.248    Loss: 0.673

2024-04-23 19:46:47,416 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:46:47,416 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:46:47,449 - 

2024-04-23 19:46:47,450 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:47:01,779 - Epoch: [193][  100/  296]    Overall Loss 0.685607    Objective Loss 0.685607                                        LR 0.000020    Time 0.143080    
2024-04-23 19:47:13,128 - Epoch: [193][  200/  296]    Overall Loss 0.691622    Objective Loss 0.691622                                        LR 0.000020    Time 0.128189    
2024-04-23 19:47:25,140 - Epoch: [193][  296/  296]    Overall Loss 0.679825    Objective Loss 0.679825    Top1 75.409836    Top5 95.081967    LR 0.000020    Time 0.127139    
2024-04-23 19:47:25,357 - --- validate (epoch=193)-----------
2024-04-23 19:47:25,358 - 3925 samples (32 per mini-batch)
2024-04-23 19:47:38,874 - Epoch: [193][  100/  123]    Loss 0.674017    Top1 78.312500    Top5 97.437500    
2024-04-23 19:47:41,417 - Epoch: [193][  123/  123]    Loss 0.671631    Top1 78.165605    Top5 97.426752    
2024-04-23 19:47:41,597 - ==> Top1: 78.166    Top5: 97.427    Loss: 0.672

2024-04-23 19:47:41,606 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:47:41,607 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:47:41,646 - 

2024-04-23 19:47:41,647 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:47:52,955 - Epoch: [194][  100/  296]    Overall Loss 0.708412    Objective Loss 0.708412                                        LR 0.000020    Time 0.112891    
2024-04-23 19:48:03,863 - Epoch: [194][  200/  296]    Overall Loss 0.700958    Objective Loss 0.700958                                        LR 0.000020    Time 0.110893    
2024-04-23 19:48:14,381 - Epoch: [194][  296/  296]    Overall Loss 0.700494    Objective Loss 0.700494    Top1 80.327869    Top5 96.721311    LR 0.000020    Time 0.110403    
2024-04-23 19:48:14,564 - --- validate (epoch=194)-----------
2024-04-23 19:48:14,565 - 3925 samples (32 per mini-batch)
2024-04-23 19:48:29,344 - Epoch: [194][  100/  123]    Loss 0.673650    Top1 78.031250    Top5 97.312500    
2024-04-23 19:48:33,422 - Epoch: [194][  123/  123]    Loss 0.671218    Top1 78.012739    Top5 97.350318    
2024-04-23 19:48:33,655 - ==> Top1: 78.013    Top5: 97.350    Loss: 0.671

2024-04-23 19:48:33,669 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:48:33,670 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:48:33,768 - 

2024-04-23 19:48:33,769 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:48:52,150 - Epoch: [195][  100/  296]    Overall Loss 0.704622    Objective Loss 0.704622                                        LR 0.000020    Time 0.183579    
2024-04-23 19:49:07,576 - Epoch: [195][  200/  296]    Overall Loss 0.702392    Objective Loss 0.702392                                        LR 0.000020    Time 0.168822    
2024-04-23 19:49:23,066 - Epoch: [195][  296/  296]    Overall Loss 0.695095    Objective Loss 0.695095    Top1 81.967213    Top5 95.081967    LR 0.000020    Time 0.166329    
2024-04-23 19:49:23,358 - --- validate (epoch=195)-----------
2024-04-23 19:49:23,360 - 3925 samples (32 per mini-batch)
2024-04-23 19:49:38,455 - Epoch: [195][  100/  123]    Loss 0.692211    Top1 77.375000    Top5 97.375000    
2024-04-23 19:49:40,616 - Epoch: [195][  123/  123]    Loss 0.672762    Top1 77.961783    Top5 97.401274    
2024-04-23 19:49:40,806 - ==> Top1: 77.962    Top5: 97.401    Loss: 0.673

2024-04-23 19:49:40,816 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:49:40,816 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:49:40,865 - 

2024-04-23 19:49:40,866 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:49:51,023 - Epoch: [196][  100/  296]    Overall Loss 0.681837    Objective Loss 0.681837                                        LR 0.000020    Time 0.101393    
2024-04-23 19:49:59,897 - Epoch: [196][  200/  296]    Overall Loss 0.694809    Objective Loss 0.694809                                        LR 0.000020    Time 0.094981    
2024-04-23 19:50:10,288 - Epoch: [196][  296/  296]    Overall Loss 0.702134    Objective Loss 0.702134    Top1 80.327869    Top5 98.360656    LR 0.000020    Time 0.099222    
2024-04-23 19:50:10,477 - --- validate (epoch=196)-----------
2024-04-23 19:50:10,478 - 3925 samples (32 per mini-batch)
2024-04-23 19:50:22,737 - Epoch: [196][  100/  123]    Loss 0.675501    Top1 78.062500    Top5 97.437500    
2024-04-23 19:50:25,484 - Epoch: [196][  123/  123]    Loss 0.672811    Top1 78.012739    Top5 97.375796    
2024-04-23 19:50:25,640 - ==> Top1: 78.013    Top5: 97.376    Loss: 0.673

2024-04-23 19:50:25,648 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:50:25,649 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:50:25,694 - 

2024-04-23 19:50:25,695 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:50:36,933 - Epoch: [197][  100/  296]    Overall Loss 0.679386    Objective Loss 0.679386                                        LR 0.000020    Time 0.112204    
2024-04-23 19:50:47,685 - Epoch: [197][  200/  296]    Overall Loss 0.695319    Objective Loss 0.695319                                        LR 0.000020    Time 0.109767    
2024-04-23 19:51:00,370 - Epoch: [197][  296/  296]    Overall Loss 0.691526    Objective Loss 0.691526    Top1 86.885246    Top5 98.360656    LR 0.000020    Time 0.116961    
2024-04-23 19:51:00,640 - --- validate (epoch=197)-----------
2024-04-23 19:51:00,641 - 3925 samples (32 per mini-batch)
2024-04-23 19:51:15,378 - Epoch: [197][  100/  123]    Loss 0.682779    Top1 77.937500    Top5 97.281250    
2024-04-23 19:51:18,267 - Epoch: [197][  123/  123]    Loss 0.673431    Top1 78.012739    Top5 97.401274    
2024-04-23 19:51:18,454 - ==> Top1: 78.013    Top5: 97.401    Loss: 0.673

2024-04-23 19:51:18,460 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:51:18,461 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:51:18,498 - 

2024-04-23 19:51:18,499 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:51:31,283 - Epoch: [198][  100/  296]    Overall Loss 0.707816    Objective Loss 0.707816                                        LR 0.000020    Time 0.127646    
2024-04-23 19:51:43,829 - Epoch: [198][  200/  296]    Overall Loss 0.705230    Objective Loss 0.705230                                        LR 0.000020    Time 0.126457    
2024-04-23 19:51:54,717 - Epoch: [198][  296/  296]    Overall Loss 0.694877    Objective Loss 0.694877    Top1 90.163934    Top5 100.000000    LR 0.000020    Time 0.122167    
2024-04-23 19:51:54,902 - --- validate (epoch=198)-----------
2024-04-23 19:51:54,903 - 3925 samples (32 per mini-batch)
2024-04-23 19:52:17,562 - Epoch: [198][  100/  123]    Loss 0.666284    Top1 78.312500    Top5 97.531250    
2024-04-23 19:52:22,317 - Epoch: [198][  123/  123]    Loss 0.670602    Top1 78.191083    Top5 97.401274    
2024-04-23 19:52:22,572 - ==> Top1: 78.191    Top5: 97.401    Loss: 0.671

2024-04-23 19:52:22,581 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:52:22,582 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:52:22,622 - 

2024-04-23 19:52:22,622 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:52:39,833 - Epoch: [199][  100/  296]    Overall Loss 0.672661    Objective Loss 0.672661                                        LR 0.000020    Time 0.171882    
2024-04-23 19:52:56,063 - Epoch: [199][  200/  296]    Overall Loss 0.668864    Objective Loss 0.668864                                        LR 0.000020    Time 0.166995    
2024-04-23 19:53:13,816 - Epoch: [199][  296/  296]    Overall Loss 0.682856    Objective Loss 0.682856    Top1 68.852459    Top5 98.360656    LR 0.000020    Time 0.172745    
2024-04-23 19:53:14,092 - --- validate (epoch=199)-----------
2024-04-23 19:53:14,094 - 3925 samples (32 per mini-batch)
2024-04-23 19:53:35,136 - Epoch: [199][  100/  123]    Loss 0.689180    Top1 78.187500    Top5 97.500000    
2024-04-23 19:53:38,799 - Epoch: [199][  123/  123]    Loss 0.673241    Top1 78.547771    Top5 97.375796    
2024-04-23 19:53:39,003 - ==> Top1: 78.548    Top5: 97.376    Loss: 0.673

2024-04-23 19:53:39,013 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:53:39,014 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:53:39,074 - 

2024-04-23 19:53:39,075 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:53:57,683 - Epoch: [200][  100/  296]    Overall Loss 0.710877    Objective Loss 0.710877                                        LR 0.000005    Time 0.185869    
2024-04-23 19:54:14,591 - Epoch: [200][  200/  296]    Overall Loss 0.718349    Objective Loss 0.718349                                        LR 0.000005    Time 0.177382    
2024-04-23 19:54:31,713 - Epoch: [200][  296/  296]    Overall Loss 0.707501    Objective Loss 0.707501    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.177639    
2024-04-23 19:54:31,958 - --- validate (epoch=200)-----------
2024-04-23 19:54:31,959 - 3925 samples (32 per mini-batch)
2024-04-23 19:54:49,794 - Epoch: [200][  100/  123]    Loss 0.661690    Top1 78.718750    Top5 97.593750    
2024-04-23 19:54:53,688 - Epoch: [200][  123/  123]    Loss 0.670913    Top1 78.496815    Top5 97.554140    
2024-04-23 19:54:53,956 - ==> Top1: 78.497    Top5: 97.554    Loss: 0.671

2024-04-23 19:54:53,967 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:54:53,968 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:54:54,023 - 

2024-04-23 19:54:54,024 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:55:08,893 - Epoch: [201][  100/  296]    Overall Loss 0.693155    Objective Loss 0.693155                                        LR 0.000005    Time 0.148464    
2024-04-23 19:55:20,961 - Epoch: [201][  200/  296]    Overall Loss 0.688461    Objective Loss 0.688461                                        LR 0.000005    Time 0.134481    
2024-04-23 19:55:29,808 - Epoch: [201][  296/  296]    Overall Loss 0.695244    Objective Loss 0.695244    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.120697    
2024-04-23 19:55:30,024 - --- validate (epoch=201)-----------
2024-04-23 19:55:30,027 - 3925 samples (32 per mini-batch)
2024-04-23 19:55:44,166 - Epoch: [201][  100/  123]    Loss 0.676223    Top1 78.000000    Top5 97.406250    
2024-04-23 19:55:47,505 - Epoch: [201][  123/  123]    Loss 0.672052    Top1 78.292994    Top5 97.477707    
2024-04-23 19:55:47,724 - ==> Top1: 78.293    Top5: 97.478    Loss: 0.672

2024-04-23 19:55:47,733 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:55:47,734 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:55:47,770 - 

2024-04-23 19:55:47,771 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:56:06,762 - Epoch: [202][  100/  296]    Overall Loss 0.665912    Objective Loss 0.665912                                        LR 0.000005    Time 0.189694    
2024-04-23 19:56:25,170 - Epoch: [202][  200/  296]    Overall Loss 0.668433    Objective Loss 0.668433                                        LR 0.000005    Time 0.186799    
2024-04-23 19:56:43,131 - Epoch: [202][  296/  296]    Overall Loss 0.679710    Objective Loss 0.679710    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.186836    
2024-04-23 19:56:43,380 - --- validate (epoch=202)-----------
2024-04-23 19:56:43,382 - 3925 samples (32 per mini-batch)
2024-04-23 19:57:05,878 - Epoch: [202][  100/  123]    Loss 0.676162    Top1 77.906250    Top5 97.406250    
2024-04-23 19:57:10,479 - Epoch: [202][  123/  123]    Loss 0.670595    Top1 78.242038    Top5 97.528662    
2024-04-23 19:57:10,747 - ==> Top1: 78.242    Top5: 97.529    Loss: 0.671

2024-04-23 19:57:10,758 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:57:10,759 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:57:10,811 - 

2024-04-23 19:57:10,812 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:57:25,883 - Epoch: [203][  100/  296]    Overall Loss 0.676434    Objective Loss 0.676434                                        LR 0.000005    Time 0.150493    
2024-04-23 19:57:42,015 - Epoch: [203][  200/  296]    Overall Loss 0.689278    Objective Loss 0.689278                                        LR 0.000005    Time 0.155795    
2024-04-23 19:57:57,465 - Epoch: [203][  296/  296]    Overall Loss 0.679627    Objective Loss 0.679627    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.157398    
2024-04-23 19:57:57,723 - --- validate (epoch=203)-----------
2024-04-23 19:57:57,724 - 3925 samples (32 per mini-batch)
2024-04-23 19:58:16,620 - Epoch: [203][  100/  123]    Loss 0.660379    Top1 78.625000    Top5 97.437500    
2024-04-23 19:58:18,763 - Epoch: [203][  123/  123]    Loss 0.671142    Top1 78.318471    Top5 97.299363    
2024-04-23 19:58:18,955 - ==> Top1: 78.318    Top5: 97.299    Loss: 0.671

2024-04-23 19:58:18,964 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:58:18,964 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:58:19,005 - 

2024-04-23 19:58:19,005 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:58:33,806 - Epoch: [204][  100/  296]    Overall Loss 0.666970    Objective Loss 0.666970                                        LR 0.000005    Time 0.147799    
2024-04-23 19:58:48,390 - Epoch: [204][  200/  296]    Overall Loss 0.678082    Objective Loss 0.678082                                        LR 0.000005    Time 0.146724    
2024-04-23 19:59:00,043 - Epoch: [204][  296/  296]    Overall Loss 0.685731    Objective Loss 0.685731    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.138446    
2024-04-23 19:59:00,236 - --- validate (epoch=204)-----------
2024-04-23 19:59:00,236 - 3925 samples (32 per mini-batch)
2024-04-23 19:59:14,526 - Epoch: [204][  100/  123]    Loss 0.662430    Top1 78.562500    Top5 97.593750    
2024-04-23 19:59:16,581 - Epoch: [204][  123/  123]    Loss 0.670534    Top1 78.496815    Top5 97.375796    
2024-04-23 19:59:16,774 - ==> Top1: 78.497    Top5: 97.376    Loss: 0.671

2024-04-23 19:59:16,783 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 19:59:16,783 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 19:59:16,838 - 

2024-04-23 19:59:16,839 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:59:27,964 - Epoch: [205][  100/  296]    Overall Loss 0.680724    Objective Loss 0.680724                                        LR 0.000005    Time 0.111069    
2024-04-23 19:59:38,275 - Epoch: [205][  200/  296]    Overall Loss 0.692489    Objective Loss 0.692489                                        LR 0.000005    Time 0.107001    
2024-04-23 19:59:49,212 - Epoch: [205][  296/  296]    Overall Loss 0.690444    Objective Loss 0.690444    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.109198    
2024-04-23 19:59:49,409 - --- validate (epoch=205)-----------
2024-04-23 19:59:49,410 - 3925 samples (32 per mini-batch)
2024-04-23 20:00:00,900 - Epoch: [205][  100/  123]    Loss 0.661255    Top1 78.656250    Top5 97.625000    
2024-04-23 20:00:03,989 - Epoch: [205][  123/  123]    Loss 0.670118    Top1 78.471338    Top5 97.528662    
2024-04-23 20:00:04,164 - ==> Top1: 78.471    Top5: 97.529    Loss: 0.670

2024-04-23 20:00:04,173 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 20:00:04,174 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:00:04,209 - 

2024-04-23 20:00:04,210 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:00:15,645 - Epoch: [206][  100/  296]    Overall Loss 0.685476    Objective Loss 0.685476                                        LR 0.000005    Time 0.114177    
2024-04-23 20:00:25,968 - Epoch: [206][  200/  296]    Overall Loss 0.686449    Objective Loss 0.686449                                        LR 0.000005    Time 0.108618    
2024-04-23 20:00:34,592 - Epoch: [206][  296/  296]    Overall Loss 0.681092    Objective Loss 0.681092    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.102470    
2024-04-23 20:00:34,780 - --- validate (epoch=206)-----------
2024-04-23 20:00:34,781 - 3925 samples (32 per mini-batch)
2024-04-23 20:00:47,349 - Epoch: [206][  100/  123]    Loss 0.679620    Top1 78.000000    Top5 97.375000    
2024-04-23 20:00:50,088 - Epoch: [206][  123/  123]    Loss 0.671484    Top1 78.369427    Top5 97.375796    
2024-04-23 20:00:50,264 - ==> Top1: 78.369    Top5: 97.376    Loss: 0.671

2024-04-23 20:00:50,272 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 20:00:50,273 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:00:50,312 - 

2024-04-23 20:00:50,312 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:00:58,874 - Epoch: [207][  100/  296]    Overall Loss 0.695692    Objective Loss 0.695692                                        LR 0.000005    Time 0.085461    
2024-04-23 20:01:06,687 - Epoch: [207][  200/  296]    Overall Loss 0.706153    Objective Loss 0.706153                                        LR 0.000005    Time 0.081721    
2024-04-23 20:01:20,243 - Epoch: [207][  296/  296]    Overall Loss 0.687430    Objective Loss 0.687430    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.100970    
2024-04-23 20:01:20,445 - --- validate (epoch=207)-----------
2024-04-23 20:01:20,446 - 3925 samples (32 per mini-batch)
2024-04-23 20:01:34,614 - Epoch: [207][  100/  123]    Loss 0.671826    Top1 78.562500    Top5 97.562500    
2024-04-23 20:01:36,822 - Epoch: [207][  123/  123]    Loss 0.671492    Top1 78.522293    Top5 97.503185    
2024-04-23 20:01:37,013 - ==> Top1: 78.522    Top5: 97.503    Loss: 0.671

2024-04-23 20:01:37,019 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 20:01:37,019 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:01:37,061 - 

2024-04-23 20:01:37,062 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:01:48,258 - Epoch: [208][  100/  296]    Overall Loss 0.695917    Objective Loss 0.695917                                        LR 0.000005    Time 0.111782    
2024-04-23 20:01:58,074 - Epoch: [208][  200/  296]    Overall Loss 0.697589    Objective Loss 0.697589                                        LR 0.000005    Time 0.104891    
2024-04-23 20:02:07,131 - Epoch: [208][  296/  296]    Overall Loss 0.696051    Objective Loss 0.696051    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.101419    
2024-04-23 20:02:07,314 - --- validate (epoch=208)-----------
2024-04-23 20:02:07,315 - 3925 samples (32 per mini-batch)
2024-04-23 20:02:23,230 - Epoch: [208][  100/  123]    Loss 0.666640    Top1 78.593750    Top5 97.562500    
2024-04-23 20:02:26,516 - Epoch: [208][  123/  123]    Loss 0.667966    Top1 78.343949    Top5 97.503185    
2024-04-23 20:02:26,696 - ==> Top1: 78.344    Top5: 97.503    Loss: 0.668

2024-04-23 20:02:26,705 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 20:02:26,705 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:02:26,760 - 

2024-04-23 20:02:26,760 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:02:42,114 - Epoch: [209][  100/  296]    Overall Loss 0.663522    Objective Loss 0.663522                                        LR 0.000005    Time 0.153366    
2024-04-23 20:02:56,635 - Epoch: [209][  200/  296]    Overall Loss 0.673875    Objective Loss 0.673875                                        LR 0.000005    Time 0.149215    
2024-04-23 20:03:09,152 - Epoch: [209][  296/  296]    Overall Loss 0.680953    Objective Loss 0.680953    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.143054    
2024-04-23 20:03:09,390 - --- validate (epoch=209)-----------
2024-04-23 20:03:09,392 - 3925 samples (32 per mini-batch)
2024-04-23 20:03:28,840 - Epoch: [209][  100/  123]    Loss 0.670667    Top1 78.218750    Top5 97.593750    
2024-04-23 20:03:32,720 - Epoch: [209][  123/  123]    Loss 0.669199    Top1 78.445860    Top5 97.554140    
2024-04-23 20:03:32,884 - ==> Top1: 78.446    Top5: 97.554    Loss: 0.669

2024-04-23 20:03:32,890 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 20:03:32,891 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:03:32,933 - 

2024-04-23 20:03:32,934 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:03:48,503 - Epoch: [210][  100/  296]    Overall Loss 0.667733    Objective Loss 0.667733                                        LR 0.000005    Time 0.155529    
2024-04-23 20:04:01,518 - Epoch: [210][  200/  296]    Overall Loss 0.698922    Objective Loss 0.698922                                        LR 0.000005    Time 0.142767    
2024-04-23 20:04:15,148 - Epoch: [210][  296/  296]    Overall Loss 0.692923    Objective Loss 0.692923    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.142467    
2024-04-23 20:04:15,304 - --- validate (epoch=210)-----------
2024-04-23 20:04:15,305 - 3925 samples (32 per mini-batch)
2024-04-23 20:04:34,286 - Epoch: [210][  100/  123]    Loss 0.670436    Top1 78.093750    Top5 97.437500    
2024-04-23 20:04:37,441 - Epoch: [210][  123/  123]    Loss 0.671961    Top1 78.165605    Top5 97.401274    
2024-04-23 20:04:37,688 - ==> Top1: 78.166    Top5: 97.401    Loss: 0.672

2024-04-23 20:04:37,699 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 20:04:37,700 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:04:37,751 - 

2024-04-23 20:04:37,752 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:04:55,470 - Epoch: [211][  100/  296]    Overall Loss 0.697597    Objective Loss 0.697597                                        LR 0.000005    Time 0.176989    
2024-04-23 20:05:09,139 - Epoch: [211][  200/  296]    Overall Loss 0.693289    Objective Loss 0.693289                                        LR 0.000005    Time 0.156758    
2024-04-23 20:05:23,922 - Epoch: [211][  296/  296]    Overall Loss 0.691202    Objective Loss 0.691202    Top1 67.213115    Top5 96.721311    LR 0.000005    Time 0.155811    
2024-04-23 20:05:24,079 - --- validate (epoch=211)-----------
2024-04-23 20:05:24,080 - 3925 samples (32 per mini-batch)
2024-04-23 20:05:42,406 - Epoch: [211][  100/  123]    Loss 0.680684    Top1 77.968750    Top5 97.375000    
2024-04-23 20:05:45,691 - Epoch: [211][  123/  123]    Loss 0.670178    Top1 78.547771    Top5 97.528662    
2024-04-23 20:05:45,884 - ==> Top1: 78.548    Top5: 97.529    Loss: 0.670

2024-04-23 20:05:45,896 - ==> Best [Top1: 78.624   Top5: 97.325   Sparsity:0.00   Params: 371568 on epoch: 149]
2024-04-23 20:05:45,896 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:05:45,946 - 

2024-04-23 20:05:45,947 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:06:02,122 - Epoch: [212][  100/  296]    Overall Loss 0.659782    Objective Loss 0.659782                                        LR 0.000005    Time 0.161567    
2024-04-23 20:06:16,582 - Epoch: [212][  200/  296]    Overall Loss 0.674023    Objective Loss 0.674023                                        LR 0.000005    Time 0.153003    
2024-04-23 20:06:30,283 - Epoch: [212][  296/  296]    Overall Loss 0.675193    Objective Loss 0.675193    Top1 70.491803    Top5 98.360656    LR 0.000005    Time 0.149615    
2024-04-23 20:06:30,490 - --- validate (epoch=212)-----------
2024-04-23 20:06:30,491 - 3925 samples (32 per mini-batch)
2024-04-23 20:06:47,196 - Epoch: [212][  100/  123]    Loss 0.676738    Top1 78.531250    Top5 97.375000    
2024-04-23 20:06:50,129 - Epoch: [212][  123/  123]    Loss 0.669856    Top1 78.649682    Top5 97.477707    
2024-04-23 20:06:50,325 - ==> Top1: 78.650    Top5: 97.478    Loss: 0.670

2024-04-23 20:06:50,334 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:06:50,335 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:06:50,396 - 

2024-04-23 20:06:50,397 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:07:05,249 - Epoch: [213][  100/  296]    Overall Loss 0.677789    Objective Loss 0.677789                                        LR 0.000005    Time 0.148347    
2024-04-23 20:07:18,912 - Epoch: [213][  200/  296]    Overall Loss 0.678308    Objective Loss 0.678308                                        LR 0.000005    Time 0.142411    
2024-04-23 20:07:32,193 - Epoch: [213][  296/  296]    Overall Loss 0.687068    Objective Loss 0.687068    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.141038    
2024-04-23 20:07:32,425 - --- validate (epoch=213)-----------
2024-04-23 20:07:32,426 - 3925 samples (32 per mini-batch)
2024-04-23 20:07:47,201 - Epoch: [213][  100/  123]    Loss 0.685479    Top1 77.718750    Top5 97.406250    
2024-04-23 20:07:49,681 - Epoch: [213][  123/  123]    Loss 0.667401    Top1 78.369427    Top5 97.605096    
2024-04-23 20:07:49,923 - ==> Top1: 78.369    Top5: 97.605    Loss: 0.667

2024-04-23 20:07:49,932 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:07:49,933 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:07:49,977 - 

2024-04-23 20:07:49,978 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:08:01,910 - Epoch: [214][  100/  296]    Overall Loss 0.671203    Objective Loss 0.671203                                        LR 0.000005    Time 0.119150    
2024-04-23 20:08:09,058 - Epoch: [214][  200/  296]    Overall Loss 0.689244    Objective Loss 0.689244                                        LR 0.000005    Time 0.095244    
2024-04-23 20:08:15,161 - Epoch: [214][  296/  296]    Overall Loss 0.691443    Objective Loss 0.691443    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.084931    
2024-04-23 20:08:15,358 - --- validate (epoch=214)-----------
2024-04-23 20:08:15,359 - 3925 samples (32 per mini-batch)
2024-04-23 20:08:24,687 - Epoch: [214][  100/  123]    Loss 0.684151    Top1 77.968750    Top5 97.343750    
2024-04-23 20:08:26,535 - Epoch: [214][  123/  123]    Loss 0.669535    Top1 78.547771    Top5 97.452229    
2024-04-23 20:08:26,701 - ==> Top1: 78.548    Top5: 97.452    Loss: 0.670

2024-04-23 20:08:26,709 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:08:26,709 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:08:26,748 - 

2024-04-23 20:08:26,748 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:08:35,001 - Epoch: [215][  100/  296]    Overall Loss 0.705696    Objective Loss 0.705696                                        LR 0.000005    Time 0.082391    
2024-04-23 20:08:41,751 - Epoch: [215][  200/  296]    Overall Loss 0.694173    Objective Loss 0.694173                                        LR 0.000005    Time 0.074870    
2024-04-23 20:08:50,646 - Epoch: [215][  296/  296]    Overall Loss 0.687672    Objective Loss 0.687672    Top1 67.213115    Top5 100.000000    LR 0.000005    Time 0.080593    
2024-04-23 20:08:50,810 - --- validate (epoch=215)-----------
2024-04-23 20:08:50,811 - 3925 samples (32 per mini-batch)
2024-04-23 20:09:04,417 - Epoch: [215][  100/  123]    Loss 0.677230    Top1 78.437500    Top5 97.343750    
2024-04-23 20:09:07,159 - Epoch: [215][  123/  123]    Loss 0.670293    Top1 78.471338    Top5 97.426752    
2024-04-23 20:09:07,351 - ==> Top1: 78.471    Top5: 97.427    Loss: 0.670

2024-04-23 20:09:07,360 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:09:07,360 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:09:07,399 - 

2024-04-23 20:09:07,400 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:09:23,017 - Epoch: [216][  100/  296]    Overall Loss 0.692920    Objective Loss 0.692920                                        LR 0.000005    Time 0.155994    
2024-04-23 20:09:35,114 - Epoch: [216][  200/  296]    Overall Loss 0.692313    Objective Loss 0.692313                                        LR 0.000005    Time 0.138398    
2024-04-23 20:09:44,794 - Epoch: [216][  296/  296]    Overall Loss 0.682630    Objective Loss 0.682630    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.126165    
2024-04-23 20:09:45,002 - --- validate (epoch=216)-----------
2024-04-23 20:09:45,003 - 3925 samples (32 per mini-batch)
2024-04-23 20:09:57,088 - Epoch: [216][  100/  123]    Loss 0.667630    Top1 78.531250    Top5 97.437500    
2024-04-23 20:10:00,518 - Epoch: [216][  123/  123]    Loss 0.669731    Top1 78.471338    Top5 97.452229    
2024-04-23 20:10:00,706 - ==> Top1: 78.471    Top5: 97.452    Loss: 0.670

2024-04-23 20:10:00,717 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:10:00,717 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:10:00,786 - 

2024-04-23 20:10:00,786 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:10:12,968 - Epoch: [217][  100/  296]    Overall Loss 0.704365    Objective Loss 0.704365                                        LR 0.000005    Time 0.121643    
2024-04-23 20:10:23,288 - Epoch: [217][  200/  296]    Overall Loss 0.694618    Objective Loss 0.694618                                        LR 0.000005    Time 0.112337    
2024-04-23 20:10:34,191 - Epoch: [217][  296/  296]    Overall Loss 0.695032    Objective Loss 0.695032    Top1 67.213115    Top5 96.721311    LR 0.000005    Time 0.112684    
2024-04-23 20:10:34,382 - --- validate (epoch=217)-----------
2024-04-23 20:10:34,384 - 3925 samples (32 per mini-batch)
2024-04-23 20:10:46,453 - Epoch: [217][  100/  123]    Loss 0.660469    Top1 78.812500    Top5 97.406250    
2024-04-23 20:10:48,508 - Epoch: [217][  123/  123]    Loss 0.671005    Top1 78.598726    Top5 97.477707    
2024-04-23 20:10:48,711 - ==> Top1: 78.599    Top5: 97.478    Loss: 0.671

2024-04-23 20:10:48,717 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:10:48,717 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:10:48,755 - 

2024-04-23 20:10:48,755 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:11:00,795 - Epoch: [218][  100/  296]    Overall Loss 0.706188    Objective Loss 0.706188                                        LR 0.000005    Time 0.120228    
2024-04-23 20:11:11,403 - Epoch: [218][  200/  296]    Overall Loss 0.699366    Objective Loss 0.699366                                        LR 0.000005    Time 0.113071    
2024-04-23 20:11:22,445 - Epoch: [218][  296/  296]    Overall Loss 0.705056    Objective Loss 0.705056    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.113654    
2024-04-23 20:11:22,583 - --- validate (epoch=218)-----------
2024-04-23 20:11:22,584 - 3925 samples (32 per mini-batch)
2024-04-23 20:11:41,634 - Epoch: [218][  100/  123]    Loss 0.655528    Top1 78.718750    Top5 97.656250    
2024-04-23 20:11:45,902 - Epoch: [218][  123/  123]    Loss 0.669898    Top1 78.394904    Top5 97.528662    
2024-04-23 20:11:46,142 - ==> Top1: 78.395    Top5: 97.529    Loss: 0.670

2024-04-23 20:11:46,153 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:11:46,153 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:11:46,194 - 

2024-04-23 20:11:46,194 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:11:58,114 - Epoch: [219][  100/  296]    Overall Loss 0.717857    Objective Loss 0.717857                                        LR 0.000005    Time 0.119023    
2024-04-23 20:12:09,821 - Epoch: [219][  200/  296]    Overall Loss 0.697141    Objective Loss 0.697141                                        LR 0.000005    Time 0.117966    
2024-04-23 20:12:18,825 - Epoch: [219][  296/  296]    Overall Loss 0.681257    Objective Loss 0.681257    Top1 72.131148    Top5 93.442623    LR 0.000005    Time 0.110075    
2024-04-23 20:12:18,979 - --- validate (epoch=219)-----------
2024-04-23 20:12:18,980 - 3925 samples (32 per mini-batch)
2024-04-23 20:12:32,148 - Epoch: [219][  100/  123]    Loss 0.669292    Top1 78.687500    Top5 97.437500    
2024-04-23 20:12:34,872 - Epoch: [219][  123/  123]    Loss 0.671345    Top1 78.471338    Top5 97.426752    
2024-04-23 20:12:35,096 - ==> Top1: 78.471    Top5: 97.427    Loss: 0.671

2024-04-23 20:12:35,105 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:12:35,105 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:12:35,147 - 

2024-04-23 20:12:35,147 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:12:45,612 - Epoch: [220][  100/  296]    Overall Loss 0.690920    Objective Loss 0.690920                                        LR 0.000005    Time 0.104482    
2024-04-23 20:12:56,253 - Epoch: [220][  200/  296]    Overall Loss 0.699414    Objective Loss 0.699414                                        LR 0.000005    Time 0.105368    
2024-04-23 20:13:05,732 - Epoch: [220][  296/  296]    Overall Loss 0.703833    Objective Loss 0.703833    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.103166    
2024-04-23 20:13:05,917 - --- validate (epoch=220)-----------
2024-04-23 20:13:05,917 - 3925 samples (32 per mini-batch)
2024-04-23 20:13:19,431 - Epoch: [220][  100/  123]    Loss 0.666003    Top1 78.500000    Top5 97.312500    
2024-04-23 20:13:22,581 - Epoch: [220][  123/  123]    Loss 0.669375    Top1 78.522293    Top5 97.452229    
2024-04-23 20:13:22,797 - ==> Top1: 78.522    Top5: 97.452    Loss: 0.669

2024-04-23 20:13:22,807 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:13:22,807 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:13:22,847 - 

2024-04-23 20:13:22,848 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:13:34,245 - Epoch: [221][  100/  296]    Overall Loss 0.688535    Objective Loss 0.688535                                        LR 0.000005    Time 0.113794    
2024-04-23 20:13:44,402 - Epoch: [221][  200/  296]    Overall Loss 0.667414    Objective Loss 0.667414                                        LR 0.000005    Time 0.107602    
2024-04-23 20:13:55,436 - Epoch: [221][  296/  296]    Overall Loss 0.678297    Objective Loss 0.678297    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.109927    
2024-04-23 20:13:55,640 - --- validate (epoch=221)-----------
2024-04-23 20:13:55,640 - 3925 samples (32 per mini-batch)
2024-04-23 20:14:09,418 - Epoch: [221][  100/  123]    Loss 0.668534    Top1 78.875000    Top5 97.437500    
2024-04-23 20:14:11,608 - Epoch: [221][  123/  123]    Loss 0.674212    Top1 78.547771    Top5 97.375796    
2024-04-23 20:14:11,799 - ==> Top1: 78.548    Top5: 97.376    Loss: 0.674

2024-04-23 20:14:11,808 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:14:11,809 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:14:11,859 - 

2024-04-23 20:14:11,859 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:14:24,677 - Epoch: [222][  100/  296]    Overall Loss 0.669147    Objective Loss 0.669147                                        LR 0.000005    Time 0.128007    
2024-04-23 20:14:34,040 - Epoch: [222][  200/  296]    Overall Loss 0.692207    Objective Loss 0.692207                                        LR 0.000005    Time 0.110743    
2024-04-23 20:14:44,407 - Epoch: [222][  296/  296]    Overall Loss 0.704630    Objective Loss 0.704630    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.109800    
2024-04-23 20:14:44,601 - --- validate (epoch=222)-----------
2024-04-23 20:14:44,602 - 3925 samples (32 per mini-batch)
2024-04-23 20:14:57,423 - Epoch: [222][  100/  123]    Loss 0.685213    Top1 77.843750    Top5 97.343750    
2024-04-23 20:14:59,645 - Epoch: [222][  123/  123]    Loss 0.671390    Top1 78.496815    Top5 97.426752    
2024-04-23 20:14:59,832 - ==> Top1: 78.497    Top5: 97.427    Loss: 0.671

2024-04-23 20:14:59,837 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:14:59,838 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:14:59,873 - 

2024-04-23 20:14:59,873 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:15:11,941 - Epoch: [223][  100/  296]    Overall Loss 0.674665    Objective Loss 0.674665                                        LR 0.000005    Time 0.120500    
2024-04-23 20:15:23,994 - Epoch: [223][  200/  296]    Overall Loss 0.694117    Objective Loss 0.694117                                        LR 0.000005    Time 0.120433    
2024-04-23 20:15:36,223 - Epoch: [223][  296/  296]    Overall Loss 0.695668    Objective Loss 0.695668    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.122636    
2024-04-23 20:15:36,453 - --- validate (epoch=223)-----------
2024-04-23 20:15:36,454 - 3925 samples (32 per mini-batch)
2024-04-23 20:15:51,349 - Epoch: [223][  100/  123]    Loss 0.677251    Top1 78.406250    Top5 97.125000    
2024-04-23 20:15:54,052 - Epoch: [223][  123/  123]    Loss 0.671935    Top1 78.394904    Top5 97.299363    
2024-04-23 20:15:54,205 - ==> Top1: 78.395    Top5: 97.299    Loss: 0.672

2024-04-23 20:15:54,212 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:15:54,213 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:15:54,249 - 

2024-04-23 20:15:54,249 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:16:04,962 - Epoch: [224][  100/  296]    Overall Loss 0.689540    Objective Loss 0.689540                                        LR 0.000005    Time 0.106967    
2024-04-23 20:16:15,712 - Epoch: [224][  200/  296]    Overall Loss 0.668463    Objective Loss 0.668463                                        LR 0.000005    Time 0.107155    
2024-04-23 20:16:28,605 - Epoch: [224][  296/  296]    Overall Loss 0.683424    Objective Loss 0.683424    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.115912    
2024-04-23 20:16:28,796 - --- validate (epoch=224)-----------
2024-04-23 20:16:28,797 - 3925 samples (32 per mini-batch)
2024-04-23 20:16:43,106 - Epoch: [224][  100/  123]    Loss 0.658146    Top1 78.718750    Top5 97.656250    
2024-04-23 20:16:45,569 - Epoch: [224][  123/  123]    Loss 0.670084    Top1 78.445860    Top5 97.452229    
2024-04-23 20:16:45,757 - ==> Top1: 78.446    Top5: 97.452    Loss: 0.670

2024-04-23 20:16:45,767 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:16:45,768 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:16:45,807 - 

2024-04-23 20:16:45,808 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:16:56,635 - Epoch: [225][  100/  296]    Overall Loss 0.706692    Objective Loss 0.706692                                        LR 0.000005    Time 0.108108    
2024-04-23 20:17:06,084 - Epoch: [225][  200/  296]    Overall Loss 0.676809    Objective Loss 0.676809                                        LR 0.000005    Time 0.101223    
2024-04-23 20:17:14,546 - Epoch: [225][  296/  296]    Overall Loss 0.682743    Objective Loss 0.682743    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.096931    
2024-04-23 20:17:14,722 - --- validate (epoch=225)-----------
2024-04-23 20:17:14,723 - 3925 samples (32 per mini-batch)
2024-04-23 20:17:26,429 - Epoch: [225][  100/  123]    Loss 0.679348    Top1 77.937500    Top5 97.343750    
2024-04-23 20:17:29,394 - Epoch: [225][  123/  123]    Loss 0.672358    Top1 78.369427    Top5 97.299363    
2024-04-23 20:17:29,584 - ==> Top1: 78.369    Top5: 97.299    Loss: 0.672

2024-04-23 20:17:29,592 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:17:29,593 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:17:29,633 - 

2024-04-23 20:17:29,633 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:17:39,681 - Epoch: [226][  100/  296]    Overall Loss 0.696776    Objective Loss 0.696776                                        LR 0.000005    Time 0.100328    
2024-04-23 20:17:51,692 - Epoch: [226][  200/  296]    Overall Loss 0.673576    Objective Loss 0.673576                                        LR 0.000005    Time 0.110138    
2024-04-23 20:18:00,523 - Epoch: [226][  296/  296]    Overall Loss 0.679828    Objective Loss 0.679828    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.104206    
2024-04-23 20:18:00,736 - --- validate (epoch=226)-----------
2024-04-23 20:18:00,737 - 3925 samples (32 per mini-batch)
2024-04-23 20:18:15,685 - Epoch: [226][  100/  123]    Loss 0.653075    Top1 78.843750    Top5 97.625000    
2024-04-23 20:18:18,403 - Epoch: [226][  123/  123]    Loss 0.669793    Top1 78.598726    Top5 97.426752    
2024-04-23 20:18:18,566 - ==> Top1: 78.599    Top5: 97.427    Loss: 0.670

2024-04-23 20:18:18,570 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:18:18,571 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:18:18,605 - 

2024-04-23 20:18:18,606 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:18:30,857 - Epoch: [227][  100/  296]    Overall Loss 0.704836    Objective Loss 0.704836                                        LR 0.000005    Time 0.122339    
2024-04-23 20:18:45,181 - Epoch: [227][  200/  296]    Overall Loss 0.679864    Objective Loss 0.679864                                        LR 0.000005    Time 0.132720    
2024-04-23 20:18:58,423 - Epoch: [227][  296/  296]    Overall Loss 0.685740    Objective Loss 0.685740    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.134361    
2024-04-23 20:18:58,656 - --- validate (epoch=227)-----------
2024-04-23 20:18:58,656 - 3925 samples (32 per mini-batch)
2024-04-23 20:19:13,658 - Epoch: [227][  100/  123]    Loss 0.677964    Top1 78.250000    Top5 97.281250    
2024-04-23 20:19:17,038 - Epoch: [227][  123/  123]    Loss 0.670292    Top1 78.420382    Top5 97.477707    
2024-04-23 20:19:17,222 - ==> Top1: 78.420    Top5: 97.478    Loss: 0.670

2024-04-23 20:19:17,229 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:19:17,229 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:19:17,277 - 

2024-04-23 20:19:17,278 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:19:27,309 - Epoch: [228][  100/  296]    Overall Loss 0.660728    Objective Loss 0.660728                                        LR 0.000005    Time 0.100143    
2024-04-23 20:19:42,311 - Epoch: [228][  200/  296]    Overall Loss 0.686905    Objective Loss 0.686905                                        LR 0.000005    Time 0.125007    
2024-04-23 20:19:54,159 - Epoch: [228][  296/  296]    Overall Loss 0.691087    Objective Loss 0.691087    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.124440    
2024-04-23 20:19:54,324 - --- validate (epoch=228)-----------
2024-04-23 20:19:54,325 - 3925 samples (32 per mini-batch)
2024-04-23 20:20:09,543 - Epoch: [228][  100/  123]    Loss 0.687037    Top1 77.937500    Top5 97.468750    
2024-04-23 20:20:11,484 - Epoch: [228][  123/  123]    Loss 0.669096    Top1 78.598726    Top5 97.452229    
2024-04-23 20:20:11,677 - ==> Top1: 78.599    Top5: 97.452    Loss: 0.669

2024-04-23 20:20:11,682 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:20:11,682 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:20:11,715 - 

2024-04-23 20:20:11,716 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:20:21,348 - Epoch: [229][  100/  296]    Overall Loss 0.667270    Objective Loss 0.667270                                        LR 0.000005    Time 0.096149    
2024-04-23 20:20:30,843 - Epoch: [229][  200/  296]    Overall Loss 0.683536    Objective Loss 0.683536                                        LR 0.000005    Time 0.095466    
2024-04-23 20:20:40,264 - Epoch: [229][  296/  296]    Overall Loss 0.685012    Objective Loss 0.685012    Top1 68.852459    Top5 93.442623    LR 0.000005    Time 0.096279    
2024-04-23 20:20:40,414 - --- validate (epoch=229)-----------
2024-04-23 20:20:40,415 - 3925 samples (32 per mini-batch)
2024-04-23 20:20:52,944 - Epoch: [229][  100/  123]    Loss 0.661844    Top1 78.656250    Top5 97.531250    
2024-04-23 20:20:55,573 - Epoch: [229][  123/  123]    Loss 0.668630    Top1 78.573248    Top5 97.477707    
2024-04-23 20:20:55,725 - ==> Top1: 78.573    Top5: 97.478    Loss: 0.669

2024-04-23 20:20:55,732 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:20:55,732 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:20:55,765 - 

2024-04-23 20:20:55,765 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:21:09,355 - Epoch: [230][  100/  296]    Overall Loss 0.681192    Objective Loss 0.681192                                        LR 0.000005    Time 0.135726    
2024-04-23 20:21:22,378 - Epoch: [230][  200/  296]    Overall Loss 0.675407    Objective Loss 0.675407                                        LR 0.000005    Time 0.132886    
2024-04-23 20:21:35,953 - Epoch: [230][  296/  296]    Overall Loss 0.682167    Objective Loss 0.682167    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.135593    
2024-04-23 20:21:36,128 - --- validate (epoch=230)-----------
2024-04-23 20:21:36,129 - 3925 samples (32 per mini-batch)
2024-04-23 20:21:50,906 - Epoch: [230][  100/  123]    Loss 0.681322    Top1 77.875000    Top5 97.625000    
2024-04-23 20:21:53,623 - Epoch: [230][  123/  123]    Loss 0.675120    Top1 78.343949    Top5 97.426752    
2024-04-23 20:21:53,781 - ==> Top1: 78.344    Top5: 97.427    Loss: 0.675

2024-04-23 20:21:53,789 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:21:53,790 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:21:53,836 - 

2024-04-23 20:21:53,836 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:22:03,042 - Epoch: [231][  100/  296]    Overall Loss 0.663327    Objective Loss 0.663327                                        LR 0.000005    Time 0.091892    
2024-04-23 20:22:11,699 - Epoch: [231][  200/  296]    Overall Loss 0.678283    Objective Loss 0.678283                                        LR 0.000005    Time 0.089154    
2024-04-23 20:22:19,095 - Epoch: [231][  296/  296]    Overall Loss 0.677518    Objective Loss 0.677518    Top1 88.524590    Top5 98.360656    LR 0.000005    Time 0.085178    
2024-04-23 20:22:19,229 - --- validate (epoch=231)-----------
2024-04-23 20:22:19,230 - 3925 samples (32 per mini-batch)
2024-04-23 20:22:30,640 - Epoch: [231][  100/  123]    Loss 0.676225    Top1 78.500000    Top5 97.312500    
2024-04-23 20:22:32,827 - Epoch: [231][  123/  123]    Loss 0.669961    Top1 78.522293    Top5 97.401274    
2024-04-23 20:22:32,996 - ==> Top1: 78.522    Top5: 97.401    Loss: 0.670

2024-04-23 20:22:33,003 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:22:33,003 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:22:33,042 - 

2024-04-23 20:22:33,043 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:22:47,811 - Epoch: [232][  100/  296]    Overall Loss 0.689957    Objective Loss 0.689957                                        LR 0.000005    Time 0.147505    
2024-04-23 20:23:04,624 - Epoch: [232][  200/  296]    Overall Loss 0.693140    Objective Loss 0.693140                                        LR 0.000005    Time 0.157738    
2024-04-23 20:23:18,637 - Epoch: [232][  296/  296]    Overall Loss 0.687731    Objective Loss 0.687731    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.153865    
2024-04-23 20:23:18,844 - --- validate (epoch=232)-----------
2024-04-23 20:23:18,845 - 3925 samples (32 per mini-batch)
2024-04-23 20:23:35,517 - Epoch: [232][  100/  123]    Loss 0.667459    Top1 78.250000    Top5 97.625000    
2024-04-23 20:23:38,525 - Epoch: [232][  123/  123]    Loss 0.667545    Top1 78.318471    Top5 97.477707    
2024-04-23 20:23:38,718 - ==> Top1: 78.318    Top5: 97.478    Loss: 0.668

2024-04-23 20:23:38,726 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:23:38,726 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:23:38,775 - 

2024-04-23 20:23:38,775 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:23:53,224 - Epoch: [233][  100/  296]    Overall Loss 0.654206    Objective Loss 0.654206                                        LR 0.000005    Time 0.144316    
2024-04-23 20:24:04,072 - Epoch: [233][  200/  296]    Overall Loss 0.681202    Objective Loss 0.681202                                        LR 0.000005    Time 0.126303    
2024-04-23 20:24:17,400 - Epoch: [233][  296/  296]    Overall Loss 0.684310    Objective Loss 0.684310    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.130317    
2024-04-23 20:24:17,615 - --- validate (epoch=233)-----------
2024-04-23 20:24:17,616 - 3925 samples (32 per mini-batch)
2024-04-23 20:24:34,512 - Epoch: [233][  100/  123]    Loss 0.686661    Top1 78.125000    Top5 97.125000    
2024-04-23 20:24:37,896 - Epoch: [233][  123/  123]    Loss 0.670394    Top1 78.624204    Top5 97.401274    
2024-04-23 20:24:38,139 - ==> Top1: 78.624    Top5: 97.401    Loss: 0.670

2024-04-23 20:24:38,153 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:24:38,154 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:24:38,200 - 

2024-04-23 20:24:38,201 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:24:54,891 - Epoch: [234][  100/  296]    Overall Loss 0.686908    Objective Loss 0.686908                                        LR 0.000005    Time 0.166732    
2024-04-23 20:25:04,622 - Epoch: [234][  200/  296]    Overall Loss 0.689005    Objective Loss 0.689005                                        LR 0.000005    Time 0.131930    
2024-04-23 20:25:16,774 - Epoch: [234][  296/  296]    Overall Loss 0.688444    Objective Loss 0.688444    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.130148    
2024-04-23 20:25:17,071 - --- validate (epoch=234)-----------
2024-04-23 20:25:17,072 - 3925 samples (32 per mini-batch)
2024-04-23 20:25:34,773 - Epoch: [234][  100/  123]    Loss 0.675802    Top1 78.343750    Top5 97.218750    
2024-04-23 20:25:38,647 - Epoch: [234][  123/  123]    Loss 0.676610    Top1 78.216561    Top5 97.375796    
2024-04-23 20:25:38,869 - ==> Top1: 78.217    Top5: 97.376    Loss: 0.677

2024-04-23 20:25:38,879 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:25:38,879 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:25:38,928 - 

2024-04-23 20:25:38,928 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:25:54,749 - Epoch: [235][  100/  296]    Overall Loss 0.681197    Objective Loss 0.681197                                        LR 0.000005    Time 0.158032    
2024-04-23 20:26:08,106 - Epoch: [235][  200/  296]    Overall Loss 0.687782    Objective Loss 0.687782                                        LR 0.000005    Time 0.145711    
2024-04-23 20:26:20,891 - Epoch: [235][  296/  296]    Overall Loss 0.696756    Objective Loss 0.696756    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.141599    
2024-04-23 20:26:21,097 - --- validate (epoch=235)-----------
2024-04-23 20:26:21,098 - 3925 samples (32 per mini-batch)
2024-04-23 20:26:35,537 - Epoch: [235][  100/  123]    Loss 0.682565    Top1 77.906250    Top5 97.312500    
2024-04-23 20:26:37,549 - Epoch: [235][  123/  123]    Loss 0.671333    Top1 78.292994    Top5 97.401274    
2024-04-23 20:26:37,739 - ==> Top1: 78.293    Top5: 97.401    Loss: 0.671

2024-04-23 20:26:37,744 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:26:37,744 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:26:37,778 - 

2024-04-23 20:26:37,778 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:26:48,884 - Epoch: [236][  100/  296]    Overall Loss 0.690353    Objective Loss 0.690353                                        LR 0.000005    Time 0.110888    
2024-04-23 20:26:56,227 - Epoch: [236][  200/  296]    Overall Loss 0.683669    Objective Loss 0.683669                                        LR 0.000005    Time 0.092081    
2024-04-23 20:27:05,769 - Epoch: [236][  296/  296]    Overall Loss 0.678048    Objective Loss 0.678048    Top1 70.491803    Top5 98.360656    LR 0.000005    Time 0.094399    
2024-04-23 20:27:05,962 - --- validate (epoch=236)-----------
2024-04-23 20:27:05,963 - 3925 samples (32 per mini-batch)
2024-04-23 20:27:17,717 - Epoch: [236][  100/  123]    Loss 0.654870    Top1 78.906250    Top5 97.312500    
2024-04-23 20:27:20,057 - Epoch: [236][  123/  123]    Loss 0.668187    Top1 78.496815    Top5 97.477707    
2024-04-23 20:27:20,210 - ==> Top1: 78.497    Top5: 97.478    Loss: 0.668

2024-04-23 20:27:20,219 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:27:20,219 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:27:20,278 - 

2024-04-23 20:27:20,279 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:27:34,052 - Epoch: [237][  100/  296]    Overall Loss 0.661127    Objective Loss 0.661127                                        LR 0.000005    Time 0.137573    
2024-04-23 20:27:49,543 - Epoch: [237][  200/  296]    Overall Loss 0.669911    Objective Loss 0.669911                                        LR 0.000005    Time 0.146166    
2024-04-23 20:28:02,702 - Epoch: [237][  296/  296]    Overall Loss 0.680869    Objective Loss 0.680869    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.143161    
2024-04-23 20:28:02,913 - --- validate (epoch=237)-----------
2024-04-23 20:28:02,914 - 3925 samples (32 per mini-batch)
2024-04-23 20:28:16,139 - Epoch: [237][  100/  123]    Loss 0.667024    Top1 78.531250    Top5 97.500000    
2024-04-23 20:28:19,236 - Epoch: [237][  123/  123]    Loss 0.664194    Top1 78.547771    Top5 97.579618    
2024-04-23 20:28:19,470 - ==> Top1: 78.548    Top5: 97.580    Loss: 0.664

2024-04-23 20:28:19,479 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:28:19,480 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:28:19,521 - 

2024-04-23 20:28:19,521 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:28:32,556 - Epoch: [238][  100/  296]    Overall Loss 0.670049    Objective Loss 0.670049                                        LR 0.000005    Time 0.130179    
2024-04-23 20:28:45,263 - Epoch: [238][  200/  296]    Overall Loss 0.681290    Objective Loss 0.681290                                        LR 0.000005    Time 0.128535    
2024-04-23 20:28:59,478 - Epoch: [238][  296/  296]    Overall Loss 0.683719    Objective Loss 0.683719    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.134821    
2024-04-23 20:28:59,689 - --- validate (epoch=238)-----------
2024-04-23 20:28:59,690 - 3925 samples (32 per mini-batch)
2024-04-23 20:29:19,033 - Epoch: [238][  100/  123]    Loss 0.677399    Top1 78.250000    Top5 97.312500    
2024-04-23 20:29:22,502 - Epoch: [238][  123/  123]    Loss 0.671689    Top1 78.165605    Top5 97.401274    
2024-04-23 20:29:22,690 - ==> Top1: 78.166    Top5: 97.401    Loss: 0.672

2024-04-23 20:29:22,698 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:29:22,699 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:29:22,736 - 

2024-04-23 20:29:22,736 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:29:38,623 - Epoch: [239][  100/  296]    Overall Loss 0.705739    Objective Loss 0.705739                                        LR 0.000005    Time 0.158686    
2024-04-23 20:29:52,232 - Epoch: [239][  200/  296]    Overall Loss 0.683945    Objective Loss 0.683945                                        LR 0.000005    Time 0.147303    
2024-04-23 20:30:06,133 - Epoch: [239][  296/  296]    Overall Loss 0.687043    Objective Loss 0.687043    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.146444    
2024-04-23 20:30:06,360 - --- validate (epoch=239)-----------
2024-04-23 20:30:06,361 - 3925 samples (32 per mini-batch)
2024-04-23 20:30:21,707 - Epoch: [239][  100/  123]    Loss 0.687112    Top1 77.812500    Top5 97.343750    
2024-04-23 20:30:24,959 - Epoch: [239][  123/  123]    Loss 0.668598    Top1 78.496815    Top5 97.452229    
2024-04-23 20:30:25,109 - ==> Top1: 78.497    Top5: 97.452    Loss: 0.669

2024-04-23 20:30:25,114 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:30:25,114 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:30:25,148 - 

2024-04-23 20:30:25,149 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:30:35,422 - Epoch: [240][  100/  296]    Overall Loss 0.715928    Objective Loss 0.715928                                        LR 0.000005    Time 0.102562    
2024-04-23 20:30:48,001 - Epoch: [240][  200/  296]    Overall Loss 0.715573    Objective Loss 0.715573                                        LR 0.000005    Time 0.114092    
2024-04-23 20:31:00,539 - Epoch: [240][  296/  296]    Overall Loss 0.701079    Objective Loss 0.701079    Top1 86.885246    Top5 95.081967    LR 0.000005    Time 0.119395    
2024-04-23 20:31:00,706 - --- validate (epoch=240)-----------
2024-04-23 20:31:00,707 - 3925 samples (32 per mini-batch)
2024-04-23 20:31:17,481 - Epoch: [240][  100/  123]    Loss 0.671393    Top1 78.656250    Top5 97.625000    
2024-04-23 20:31:20,207 - Epoch: [240][  123/  123]    Loss 0.673626    Top1 78.522293    Top5 97.554140    
2024-04-23 20:31:20,416 - ==> Top1: 78.522    Top5: 97.554    Loss: 0.674

2024-04-23 20:31:20,426 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:31:20,426 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:31:20,470 - 

2024-04-23 20:31:20,470 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:31:32,456 - Epoch: [241][  100/  296]    Overall Loss 0.677541    Objective Loss 0.677541                                        LR 0.000005    Time 0.119685    
2024-04-23 20:31:45,502 - Epoch: [241][  200/  296]    Overall Loss 0.683481    Objective Loss 0.683481                                        LR 0.000005    Time 0.124993    
2024-04-23 20:31:55,999 - Epoch: [241][  296/  296]    Overall Loss 0.688455    Objective Loss 0.688455    Top1 70.491803    Top5 95.081967    LR 0.000005    Time 0.119866    
2024-04-23 20:31:56,164 - --- validate (epoch=241)-----------
2024-04-23 20:31:56,165 - 3925 samples (32 per mini-batch)
2024-04-23 20:32:14,140 - Epoch: [241][  100/  123]    Loss 0.665366    Top1 78.281250    Top5 97.437500    
2024-04-23 20:32:17,752 - Epoch: [241][  123/  123]    Loss 0.667529    Top1 78.242038    Top5 97.477707    
2024-04-23 20:32:18,001 - ==> Top1: 78.242    Top5: 97.478    Loss: 0.668

2024-04-23 20:32:18,011 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:32:18,012 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:32:18,066 - 

2024-04-23 20:32:18,067 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:32:34,364 - Epoch: [242][  100/  296]    Overall Loss 0.671434    Objective Loss 0.671434                                        LR 0.000005    Time 0.162778    
2024-04-23 20:32:46,853 - Epoch: [242][  200/  296]    Overall Loss 0.678104    Objective Loss 0.678104                                        LR 0.000005    Time 0.143756    
2024-04-23 20:33:01,620 - Epoch: [242][  296/  296]    Overall Loss 0.686435    Objective Loss 0.686435    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.146975    
2024-04-23 20:33:01,863 - --- validate (epoch=242)-----------
2024-04-23 20:33:01,864 - 3925 samples (32 per mini-batch)
2024-04-23 20:33:19,557 - Epoch: [242][  100/  123]    Loss 0.674594    Top1 78.281250    Top5 97.406250    
2024-04-23 20:33:23,421 - Epoch: [242][  123/  123]    Loss 0.670172    Top1 78.242038    Top5 97.477707    
2024-04-23 20:33:23,659 - ==> Top1: 78.242    Top5: 97.478    Loss: 0.670

2024-04-23 20:33:23,672 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:33:23,673 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:33:23,740 - 

2024-04-23 20:33:23,741 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:33:40,372 - Epoch: [243][  100/  296]    Overall Loss 0.681136    Objective Loss 0.681136                                        LR 0.000005    Time 0.166104    
2024-04-23 20:33:51,732 - Epoch: [243][  200/  296]    Overall Loss 0.705152    Objective Loss 0.705152                                        LR 0.000005    Time 0.139767    
2024-04-23 20:34:05,206 - Epoch: [243][  296/  296]    Overall Loss 0.694599    Objective Loss 0.694599    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.139904    
2024-04-23 20:34:05,557 - --- validate (epoch=243)-----------
2024-04-23 20:34:05,558 - 3925 samples (32 per mini-batch)
2024-04-23 20:34:24,054 - Epoch: [243][  100/  123]    Loss 0.663518    Top1 78.875000    Top5 97.343750    
2024-04-23 20:34:27,159 - Epoch: [243][  123/  123]    Loss 0.668993    Top1 78.522293    Top5 97.503185    
2024-04-23 20:34:27,331 - ==> Top1: 78.522    Top5: 97.503    Loss: 0.669

2024-04-23 20:34:27,341 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:34:27,341 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:34:27,396 - 

2024-04-23 20:34:27,396 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:34:42,674 - Epoch: [244][  100/  296]    Overall Loss 0.657027    Objective Loss 0.657027                                        LR 0.000005    Time 0.152606    
2024-04-23 20:34:58,725 - Epoch: [244][  200/  296]    Overall Loss 0.682342    Objective Loss 0.682342                                        LR 0.000005    Time 0.156484    
2024-04-23 20:35:12,307 - Epoch: [244][  296/  296]    Overall Loss 0.678931    Objective Loss 0.678931    Top1 75.409836    Top5 93.442623    LR 0.000005    Time 0.151565    
2024-04-23 20:35:12,526 - --- validate (epoch=244)-----------
2024-04-23 20:35:12,527 - 3925 samples (32 per mini-batch)
2024-04-23 20:35:29,132 - Epoch: [244][  100/  123]    Loss 0.664104    Top1 78.593750    Top5 97.312500    
2024-04-23 20:35:32,707 - Epoch: [244][  123/  123]    Loss 0.672602    Top1 78.140127    Top5 97.299363    
2024-04-23 20:35:32,914 - ==> Top1: 78.140    Top5: 97.299    Loss: 0.673

2024-04-23 20:35:32,922 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:35:32,922 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:35:32,988 - 

2024-04-23 20:35:32,989 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:35:48,638 - Epoch: [245][  100/  296]    Overall Loss 0.661148    Objective Loss 0.661148                                        LR 0.000005    Time 0.156313    
2024-04-23 20:35:59,270 - Epoch: [245][  200/  296]    Overall Loss 0.666711    Objective Loss 0.666711                                        LR 0.000005    Time 0.131232    
2024-04-23 20:36:11,742 - Epoch: [245][  296/  296]    Overall Loss 0.685871    Objective Loss 0.685871    Top1 85.245902    Top5 93.442623    LR 0.000005    Time 0.130750    
2024-04-23 20:36:11,942 - --- validate (epoch=245)-----------
2024-04-23 20:36:11,943 - 3925 samples (32 per mini-batch)
2024-04-23 20:36:27,058 - Epoch: [245][  100/  123]    Loss 0.681848    Top1 78.031250    Top5 97.187500    
2024-04-23 20:36:30,477 - Epoch: [245][  123/  123]    Loss 0.671468    Top1 78.191083    Top5 97.299363    
2024-04-23 20:36:30,643 - ==> Top1: 78.191    Top5: 97.299    Loss: 0.671

2024-04-23 20:36:30,653 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:36:30,653 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:36:30,696 - 

2024-04-23 20:36:30,697 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:36:43,720 - Epoch: [246][  100/  296]    Overall Loss 0.719558    Objective Loss 0.719558                                        LR 0.000005    Time 0.130079    
2024-04-23 20:36:57,955 - Epoch: [246][  200/  296]    Overall Loss 0.697838    Objective Loss 0.697838                                        LR 0.000005    Time 0.136131    
2024-04-23 20:37:07,724 - Epoch: [246][  296/  296]    Overall Loss 0.696270    Objective Loss 0.696270    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.124931    
2024-04-23 20:37:07,960 - --- validate (epoch=246)-----------
2024-04-23 20:37:07,961 - 3925 samples (32 per mini-batch)
2024-04-23 20:37:23,930 - Epoch: [246][  100/  123]    Loss 0.675326    Top1 78.375000    Top5 97.281250    
2024-04-23 20:37:27,583 - Epoch: [246][  123/  123]    Loss 0.672078    Top1 78.394904    Top5 97.401274    
2024-04-23 20:37:27,744 - ==> Top1: 78.395    Top5: 97.401    Loss: 0.672

2024-04-23 20:37:27,754 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:37:27,755 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:37:27,804 - 

2024-04-23 20:37:27,805 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:37:44,098 - Epoch: [247][  100/  296]    Overall Loss 0.709707    Objective Loss 0.709707                                        LR 0.000005    Time 0.162755    
2024-04-23 20:37:57,612 - Epoch: [247][  200/  296]    Overall Loss 0.678730    Objective Loss 0.678730                                        LR 0.000005    Time 0.148858    
2024-04-23 20:38:09,010 - Epoch: [247][  296/  296]    Overall Loss 0.680061    Objective Loss 0.680061    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.139037    
2024-04-23 20:38:09,229 - --- validate (epoch=247)-----------
2024-04-23 20:38:09,230 - 3925 samples (32 per mini-batch)
2024-04-23 20:38:22,225 - Epoch: [247][  100/  123]    Loss 0.673327    Top1 78.093750    Top5 97.468750    
2024-04-23 20:38:24,908 - Epoch: [247][  123/  123]    Loss 0.670572    Top1 78.089172    Top5 97.477707    
2024-04-23 20:38:25,106 - ==> Top1: 78.089    Top5: 97.478    Loss: 0.671

2024-04-23 20:38:25,111 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:38:25,112 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:38:25,145 - 

2024-04-23 20:38:25,146 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:38:37,198 - Epoch: [248][  100/  296]    Overall Loss 0.681131    Objective Loss 0.681131                                        LR 0.000005    Time 0.120362    
2024-04-23 20:38:47,624 - Epoch: [248][  200/  296]    Overall Loss 0.681899    Objective Loss 0.681899                                        LR 0.000005    Time 0.112224    
2024-04-23 20:38:57,265 - Epoch: [248][  296/  296]    Overall Loss 0.684720    Objective Loss 0.684720    Top1 65.573770    Top5 95.081967    LR 0.000005    Time 0.108347    
2024-04-23 20:38:57,488 - --- validate (epoch=248)-----------
2024-04-23 20:38:57,489 - 3925 samples (32 per mini-batch)
2024-04-23 20:39:11,398 - Epoch: [248][  100/  123]    Loss 0.672871    Top1 78.250000    Top5 97.312500    
2024-04-23 20:39:14,213 - Epoch: [248][  123/  123]    Loss 0.672663    Top1 78.318471    Top5 97.324841    
2024-04-23 20:39:14,411 - ==> Top1: 78.318    Top5: 97.325    Loss: 0.673

2024-04-23 20:39:14,419 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:39:14,420 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:39:14,461 - 

2024-04-23 20:39:14,462 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:39:25,828 - Epoch: [249][  100/  296]    Overall Loss 0.678745    Objective Loss 0.678745                                        LR 0.000005    Time 0.113516    
2024-04-23 20:39:36,664 - Epoch: [249][  200/  296]    Overall Loss 0.674678    Objective Loss 0.674678                                        LR 0.000005    Time 0.110849    
2024-04-23 20:39:45,582 - Epoch: [249][  296/  296]    Overall Loss 0.684117    Objective Loss 0.684117    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.104982    
2024-04-23 20:39:45,736 - --- validate (epoch=249)-----------
2024-04-23 20:39:45,736 - 3925 samples (32 per mini-batch)
2024-04-23 20:40:00,819 - Epoch: [249][  100/  123]    Loss 0.649925    Top1 78.937500    Top5 97.468750    
2024-04-23 20:40:03,495 - Epoch: [249][  123/  123]    Loss 0.669123    Top1 78.267516    Top5 97.426752    
2024-04-23 20:40:03,657 - ==> Top1: 78.268    Top5: 97.427    Loss: 0.669

2024-04-23 20:40:03,665 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:40:03,666 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:40:03,701 - 

2024-04-23 20:40:03,701 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:40:15,028 - Epoch: [250][  100/  296]    Overall Loss 0.703487    Objective Loss 0.703487                                        LR 0.000005    Time 0.113096    
2024-04-23 20:40:24,306 - Epoch: [250][  200/  296]    Overall Loss 0.679212    Objective Loss 0.679212                                        LR 0.000005    Time 0.102861    
2024-04-23 20:40:32,968 - Epoch: [250][  296/  296]    Overall Loss 0.676089    Objective Loss 0.676089    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.098714    
2024-04-23 20:40:33,201 - --- validate (epoch=250)-----------
2024-04-23 20:40:33,202 - 3925 samples (32 per mini-batch)
2024-04-23 20:40:49,510 - Epoch: [250][  100/  123]    Loss 0.675923    Top1 78.531250    Top5 97.437500    
2024-04-23 20:40:52,850 - Epoch: [250][  123/  123]    Loss 0.672166    Top1 78.547771    Top5 97.503185    
2024-04-23 20:40:53,038 - ==> Top1: 78.548    Top5: 97.503    Loss: 0.672

2024-04-23 20:40:53,047 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:40:53,047 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:40:53,086 - 

2024-04-23 20:40:53,086 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:41:04,380 - Epoch: [251][  100/  296]    Overall Loss 0.657844    Objective Loss 0.657844                                        LR 0.000005    Time 0.112771    
2024-04-23 20:41:12,702 - Epoch: [251][  200/  296]    Overall Loss 0.674345    Objective Loss 0.674345                                        LR 0.000005    Time 0.097914    
2024-04-23 20:41:23,444 - Epoch: [251][  296/  296]    Overall Loss 0.687550    Objective Loss 0.687550    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.102398    
2024-04-23 20:41:23,701 - --- validate (epoch=251)-----------
2024-04-23 20:41:23,702 - 3925 samples (32 per mini-batch)
2024-04-23 20:41:37,939 - Epoch: [251][  100/  123]    Loss 0.654593    Top1 78.875000    Top5 97.500000    
2024-04-23 20:41:40,677 - Epoch: [251][  123/  123]    Loss 0.670911    Top1 78.191083    Top5 97.375796    
2024-04-23 20:41:40,890 - ==> Top1: 78.191    Top5: 97.376    Loss: 0.671

2024-04-23 20:41:40,899 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:41:40,899 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:41:40,941 - 

2024-04-23 20:41:40,942 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:41:52,018 - Epoch: [252][  100/  296]    Overall Loss 0.676982    Objective Loss 0.676982                                        LR 0.000005    Time 0.110584    
2024-04-23 20:41:59,929 - Epoch: [252][  200/  296]    Overall Loss 0.680137    Objective Loss 0.680137                                        LR 0.000005    Time 0.094764    
2024-04-23 20:42:09,112 - Epoch: [252][  296/  296]    Overall Loss 0.686510    Objective Loss 0.686510    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.095007    
2024-04-23 20:42:09,287 - --- validate (epoch=252)-----------
2024-04-23 20:42:09,288 - 3925 samples (32 per mini-batch)
2024-04-23 20:42:25,001 - Epoch: [252][  100/  123]    Loss 0.662451    Top1 78.375000    Top5 97.375000    
2024-04-23 20:42:28,374 - Epoch: [252][  123/  123]    Loss 0.669471    Top1 78.063694    Top5 97.426752    
2024-04-23 20:42:28,546 - ==> Top1: 78.064    Top5: 97.427    Loss: 0.669

2024-04-23 20:42:28,555 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:42:28,556 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:42:28,596 - 

2024-04-23 20:42:28,596 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:42:43,096 - Epoch: [253][  100/  296]    Overall Loss 0.682012    Objective Loss 0.682012                                        LR 0.000005    Time 0.144830    
2024-04-23 20:42:54,540 - Epoch: [253][  200/  296]    Overall Loss 0.682808    Objective Loss 0.682808                                        LR 0.000005    Time 0.129554    
2024-04-23 20:43:04,249 - Epoch: [253][  296/  296]    Overall Loss 0.689172    Objective Loss 0.689172    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.120282    
2024-04-23 20:43:04,468 - --- validate (epoch=253)-----------
2024-04-23 20:43:04,469 - 3925 samples (32 per mini-batch)
2024-04-23 20:43:18,938 - Epoch: [253][  100/  123]    Loss 0.682417    Top1 77.687500    Top5 97.500000    
2024-04-23 20:43:21,948 - Epoch: [253][  123/  123]    Loss 0.668858    Top1 78.292994    Top5 97.503185    
2024-04-23 20:43:22,171 - ==> Top1: 78.293    Top5: 97.503    Loss: 0.669

2024-04-23 20:43:22,177 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:43:22,177 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:43:22,214 - 

2024-04-23 20:43:22,214 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:43:34,533 - Epoch: [254][  100/  296]    Overall Loss 0.651481    Objective Loss 0.651481                                        LR 0.000005    Time 0.123024    
2024-04-23 20:43:44,327 - Epoch: [254][  200/  296]    Overall Loss 0.669952    Objective Loss 0.669952                                        LR 0.000005    Time 0.110404    
2024-04-23 20:43:51,159 - Epoch: [254][  296/  296]    Overall Loss 0.670908    Objective Loss 0.670908    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.097629    
2024-04-23 20:43:51,335 - --- validate (epoch=254)-----------
2024-04-23 20:43:51,336 - 3925 samples (32 per mini-batch)
2024-04-23 20:44:01,004 - Epoch: [254][  100/  123]    Loss 0.674501    Top1 78.312500    Top5 97.218750    
2024-04-23 20:44:03,052 - Epoch: [254][  123/  123]    Loss 0.668855    Top1 78.267516    Top5 97.350318    
2024-04-23 20:44:03,233 - ==> Top1: 78.268    Top5: 97.350    Loss: 0.669

2024-04-23 20:44:03,242 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:44:03,242 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:44:03,281 - 

2024-04-23 20:44:03,281 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:44:12,041 - Epoch: [255][  100/  296]    Overall Loss 0.645492    Objective Loss 0.645492                                        LR 0.000005    Time 0.087436    
2024-04-23 20:44:19,266 - Epoch: [255][  200/  296]    Overall Loss 0.667111    Objective Loss 0.667111                                        LR 0.000005    Time 0.079764    
2024-04-23 20:44:26,735 - Epoch: [255][  296/  296]    Overall Loss 0.676473    Objective Loss 0.676473    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.079080    
2024-04-23 20:44:26,912 - --- validate (epoch=255)-----------
2024-04-23 20:44:26,913 - 3925 samples (32 per mini-batch)
2024-04-23 20:44:38,421 - Epoch: [255][  100/  123]    Loss 0.660986    Top1 79.000000    Top5 97.531250    
2024-04-23 20:44:40,444 - Epoch: [255][  123/  123]    Loss 0.672124    Top1 78.216561    Top5 97.452229    
2024-04-23 20:44:40,652 - ==> Top1: 78.217    Top5: 97.452    Loss: 0.672

2024-04-23 20:44:40,659 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:44:40,660 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:44:40,693 - 

2024-04-23 20:44:40,693 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:44:52,416 - Epoch: [256][  100/  296]    Overall Loss 0.683865    Objective Loss 0.683865                                        LR 0.000005    Time 0.117083    
2024-04-23 20:45:00,701 - Epoch: [256][  200/  296]    Overall Loss 0.669684    Objective Loss 0.669684                                        LR 0.000005    Time 0.099893    
2024-04-23 20:45:09,253 - Epoch: [256][  296/  296]    Overall Loss 0.678900    Objective Loss 0.678900    Top1 90.163934    Top5 100.000000    LR 0.000005    Time 0.096337    
2024-04-23 20:45:09,445 - --- validate (epoch=256)-----------
2024-04-23 20:45:09,446 - 3925 samples (32 per mini-batch)
2024-04-23 20:45:20,379 - Epoch: [256][  100/  123]    Loss 0.658186    Top1 78.781250    Top5 97.437500    
2024-04-23 20:45:22,588 - Epoch: [256][  123/  123]    Loss 0.668772    Top1 78.267516    Top5 97.452229    
2024-04-23 20:45:22,763 - ==> Top1: 78.268    Top5: 97.452    Loss: 0.669

2024-04-23 20:45:22,771 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:45:22,772 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:45:22,808 - 

2024-04-23 20:45:22,809 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:45:36,552 - Epoch: [257][  100/  296]    Overall Loss 0.680261    Objective Loss 0.680261                                        LR 0.000005    Time 0.137284    
2024-04-23 20:45:46,943 - Epoch: [257][  200/  296]    Overall Loss 0.688891    Objective Loss 0.688891                                        LR 0.000005    Time 0.120516    
2024-04-23 20:45:52,956 - Epoch: [257][  296/  296]    Overall Loss 0.681998    Objective Loss 0.681998    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.101700    
2024-04-23 20:45:53,166 - --- validate (epoch=257)-----------
2024-04-23 20:45:53,167 - 3925 samples (32 per mini-batch)
2024-04-23 20:46:03,404 - Epoch: [257][  100/  123]    Loss 0.653186    Top1 78.968750    Top5 97.500000    
2024-04-23 20:46:05,201 - Epoch: [257][  123/  123]    Loss 0.670961    Top1 78.420382    Top5 97.426752    
2024-04-23 20:46:05,403 - ==> Top1: 78.420    Top5: 97.427    Loss: 0.671

2024-04-23 20:46:05,414 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:46:05,415 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:46:05,454 - 

2024-04-23 20:46:05,455 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:46:17,963 - Epoch: [258][  100/  296]    Overall Loss 0.691225    Objective Loss 0.691225                                        LR 0.000005    Time 0.124902    
2024-04-23 20:46:30,396 - Epoch: [258][  200/  296]    Overall Loss 0.693841    Objective Loss 0.693841                                        LR 0.000005    Time 0.124531    
2024-04-23 20:46:43,185 - Epoch: [258][  296/  296]    Overall Loss 0.682682    Objective Loss 0.682682    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.127298    
2024-04-23 20:46:43,361 - --- validate (epoch=258)-----------
2024-04-23 20:46:43,362 - 3925 samples (32 per mini-batch)
2024-04-23 20:46:59,291 - Epoch: [258][  100/  123]    Loss 0.657400    Top1 78.593750    Top5 97.531250    
2024-04-23 20:47:02,959 - Epoch: [258][  123/  123]    Loss 0.667939    Top1 78.216561    Top5 97.605096    
2024-04-23 20:47:03,186 - ==> Top1: 78.217    Top5: 97.605    Loss: 0.668

2024-04-23 20:47:03,196 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:47:03,196 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:47:03,243 - 

2024-04-23 20:47:03,243 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:47:18,429 - Epoch: [259][  100/  296]    Overall Loss 0.675361    Objective Loss 0.675361                                        LR 0.000005    Time 0.151688    
2024-04-23 20:47:34,661 - Epoch: [259][  200/  296]    Overall Loss 0.671655    Objective Loss 0.671655                                        LR 0.000005    Time 0.156918    
2024-04-23 20:47:47,108 - Epoch: [259][  296/  296]    Overall Loss 0.680364    Objective Loss 0.680364    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.148030    
2024-04-23 20:47:47,261 - --- validate (epoch=259)-----------
2024-04-23 20:47:47,262 - 3925 samples (32 per mini-batch)
2024-04-23 20:48:03,279 - Epoch: [259][  100/  123]    Loss 0.663020    Top1 78.437500    Top5 97.656250    
2024-04-23 20:48:05,139 - Epoch: [259][  123/  123]    Loss 0.671708    Top1 78.394904    Top5 97.452229    
2024-04-23 20:48:05,305 - ==> Top1: 78.395    Top5: 97.452    Loss: 0.672

2024-04-23 20:48:05,313 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:48:05,313 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:48:05,350 - 

2024-04-23 20:48:05,351 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:48:15,533 - Epoch: [260][  100/  296]    Overall Loss 0.707660    Objective Loss 0.707660                                        LR 0.000005    Time 0.101635    
2024-04-23 20:48:28,250 - Epoch: [260][  200/  296]    Overall Loss 0.686284    Objective Loss 0.686284                                        LR 0.000005    Time 0.114313    
2024-04-23 20:48:43,298 - Epoch: [260][  296/  296]    Overall Loss 0.690282    Objective Loss 0.690282    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.128026    
2024-04-23 20:48:43,496 - --- validate (epoch=260)-----------
2024-04-23 20:48:43,497 - 3925 samples (32 per mini-batch)
2024-04-23 20:48:58,738 - Epoch: [260][  100/  123]    Loss 0.679997    Top1 77.906250    Top5 97.656250    
2024-04-23 20:49:01,521 - Epoch: [260][  123/  123]    Loss 0.671510    Top1 78.191083    Top5 97.630573    
2024-04-23 20:49:01,704 - ==> Top1: 78.191    Top5: 97.631    Loss: 0.672

2024-04-23 20:49:01,713 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:49:01,714 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:49:01,758 - 

2024-04-23 20:49:01,758 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:49:15,079 - Epoch: [261][  100/  296]    Overall Loss 0.678504    Objective Loss 0.678504                                        LR 0.000005    Time 0.133028    
2024-04-23 20:49:23,177 - Epoch: [261][  200/  296]    Overall Loss 0.697880    Objective Loss 0.697880                                        LR 0.000005    Time 0.106926    
2024-04-23 20:49:31,947 - Epoch: [261][  296/  296]    Overall Loss 0.703758    Objective Loss 0.703758    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.101819    
2024-04-23 20:49:32,180 - --- validate (epoch=261)-----------
2024-04-23 20:49:32,181 - 3925 samples (32 per mini-batch)
2024-04-23 20:49:48,381 - Epoch: [261][  100/  123]    Loss 0.664291    Top1 78.031250    Top5 97.531250    
2024-04-23 20:49:51,944 - Epoch: [261][  123/  123]    Loss 0.670918    Top1 78.216561    Top5 97.477707    
2024-04-23 20:49:52,112 - ==> Top1: 78.217    Top5: 97.478    Loss: 0.671

2024-04-23 20:49:52,116 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:49:52,117 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:49:52,150 - 

2024-04-23 20:49:52,151 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:50:04,640 - Epoch: [262][  100/  296]    Overall Loss 0.717479    Objective Loss 0.717479                                        LR 0.000005    Time 0.124711    
2024-04-23 20:50:13,264 - Epoch: [262][  200/  296]    Overall Loss 0.703225    Objective Loss 0.703225                                        LR 0.000005    Time 0.105394    
2024-04-23 20:50:20,479 - Epoch: [262][  296/  296]    Overall Loss 0.696982    Objective Loss 0.696982    Top1 85.245902    Top5 96.721311    LR 0.000005    Time 0.095535    
2024-04-23 20:50:20,627 - --- validate (epoch=262)-----------
2024-04-23 20:50:20,628 - 3925 samples (32 per mini-batch)
2024-04-23 20:50:37,462 - Epoch: [262][  100/  123]    Loss 0.671539    Top1 78.312500    Top5 97.437500    
2024-04-23 20:50:40,962 - Epoch: [262][  123/  123]    Loss 0.669252    Top1 78.394904    Top5 97.503185    
2024-04-23 20:50:41,114 - ==> Top1: 78.395    Top5: 97.503    Loss: 0.669

2024-04-23 20:50:41,123 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:50:41,124 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:50:41,171 - 

2024-04-23 20:50:41,172 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:50:56,957 - Epoch: [263][  100/  296]    Overall Loss 0.672011    Objective Loss 0.672011                                        LR 0.000005    Time 0.157680    
2024-04-23 20:51:09,924 - Epoch: [263][  200/  296]    Overall Loss 0.672417    Objective Loss 0.672417                                        LR 0.000005    Time 0.143586    
2024-04-23 20:51:21,994 - Epoch: [263][  296/  296]    Overall Loss 0.676705    Objective Loss 0.676705    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.137740    
2024-04-23 20:51:22,166 - --- validate (epoch=263)-----------
2024-04-23 20:51:22,167 - 3925 samples (32 per mini-batch)
2024-04-23 20:51:40,136 - Epoch: [263][  100/  123]    Loss 0.656209    Top1 78.781250    Top5 97.406250    
2024-04-23 20:51:43,872 - Epoch: [263][  123/  123]    Loss 0.670986    Top1 78.369427    Top5 97.401274    
2024-04-23 20:51:44,052 - ==> Top1: 78.369    Top5: 97.401    Loss: 0.671

2024-04-23 20:51:44,059 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:51:44,060 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:51:44,112 - 

2024-04-23 20:51:44,113 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:51:56,974 - Epoch: [264][  100/  296]    Overall Loss 0.699173    Objective Loss 0.699173                                        LR 0.000005    Time 0.128435    
2024-04-23 20:52:10,167 - Epoch: [264][  200/  296]    Overall Loss 0.703879    Objective Loss 0.703879                                        LR 0.000005    Time 0.130101    
2024-04-23 20:52:22,897 - Epoch: [264][  296/  296]    Overall Loss 0.701444    Objective Loss 0.701444    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.130856    
2024-04-23 20:52:23,087 - --- validate (epoch=264)-----------
2024-04-23 20:52:23,088 - 3925 samples (32 per mini-batch)
2024-04-23 20:52:39,078 - Epoch: [264][  100/  123]    Loss 0.676176    Top1 78.187500    Top5 97.562500    
2024-04-23 20:52:42,157 - Epoch: [264][  123/  123]    Loss 0.672751    Top1 78.140127    Top5 97.477707    
2024-04-23 20:52:42,339 - ==> Top1: 78.140    Top5: 97.478    Loss: 0.673

2024-04-23 20:52:42,352 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:52:42,352 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:52:42,391 - 

2024-04-23 20:52:42,391 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:52:52,486 - Epoch: [265][  100/  296]    Overall Loss 0.708623    Objective Loss 0.708623                                        LR 0.000005    Time 0.100779    
2024-04-23 20:53:02,452 - Epoch: [265][  200/  296]    Overall Loss 0.706587    Objective Loss 0.706587                                        LR 0.000005    Time 0.100143    
2024-04-23 20:53:12,273 - Epoch: [265][  296/  296]    Overall Loss 0.694991    Objective Loss 0.694991    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.100796    
2024-04-23 20:53:12,486 - --- validate (epoch=265)-----------
2024-04-23 20:53:12,487 - 3925 samples (32 per mini-batch)
2024-04-23 20:53:28,736 - Epoch: [265][  100/  123]    Loss 0.670917    Top1 78.375000    Top5 97.437500    
2024-04-23 20:53:31,321 - Epoch: [265][  123/  123]    Loss 0.670393    Top1 78.242038    Top5 97.503185    
2024-04-23 20:53:31,551 - ==> Top1: 78.242    Top5: 97.503    Loss: 0.670

2024-04-23 20:53:31,560 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:53:31,561 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:53:31,602 - 

2024-04-23 20:53:31,603 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:53:42,987 - Epoch: [266][  100/  296]    Overall Loss 0.662888    Objective Loss 0.662888                                        LR 0.000005    Time 0.113658    
2024-04-23 20:53:53,392 - Epoch: [266][  200/  296]    Overall Loss 0.670783    Objective Loss 0.670783                                        LR 0.000005    Time 0.108775    
2024-04-23 20:54:04,165 - Epoch: [266][  296/  296]    Overall Loss 0.676211    Objective Loss 0.676211    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.109842    
2024-04-23 20:54:04,351 - --- validate (epoch=266)-----------
2024-04-23 20:54:04,352 - 3925 samples (32 per mini-batch)
2024-04-23 20:54:18,263 - Epoch: [266][  100/  123]    Loss 0.669250    Top1 78.375000    Top5 97.437500    
2024-04-23 20:54:21,339 - Epoch: [266][  123/  123]    Loss 0.669836    Top1 78.420382    Top5 97.452229    
2024-04-23 20:54:21,512 - ==> Top1: 78.420    Top5: 97.452    Loss: 0.670

2024-04-23 20:54:21,519 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:54:21,520 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:54:21,559 - 

2024-04-23 20:54:21,560 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:54:35,147 - Epoch: [267][  100/  296]    Overall Loss 0.688976    Objective Loss 0.688976                                        LR 0.000005    Time 0.135704    
2024-04-23 20:54:45,988 - Epoch: [267][  200/  296]    Overall Loss 0.691164    Objective Loss 0.691164                                        LR 0.000005    Time 0.121969    
2024-04-23 20:54:57,787 - Epoch: [267][  296/  296]    Overall Loss 0.687080    Objective Loss 0.687080    Top1 85.245902    Top5 96.721311    LR 0.000005    Time 0.122219    
2024-04-23 20:54:58,032 - --- validate (epoch=267)-----------
2024-04-23 20:54:58,034 - 3925 samples (32 per mini-batch)
2024-04-23 20:55:12,042 - Epoch: [267][  100/  123]    Loss 0.680195    Top1 78.437500    Top5 97.281250    
2024-04-23 20:55:15,345 - Epoch: [267][  123/  123]    Loss 0.671836    Top1 78.445860    Top5 97.401274    
2024-04-23 20:55:15,551 - ==> Top1: 78.446    Top5: 97.401    Loss: 0.672

2024-04-23 20:55:15,558 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:55:15,558 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:55:15,603 - 

2024-04-23 20:55:15,604 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:55:28,348 - Epoch: [268][  100/  296]    Overall Loss 0.667301    Objective Loss 0.667301                                        LR 0.000005    Time 0.127287    
2024-04-23 20:55:41,576 - Epoch: [268][  200/  296]    Overall Loss 0.674486    Objective Loss 0.674486                                        LR 0.000005    Time 0.129708    
2024-04-23 20:55:56,077 - Epoch: [268][  296/  296]    Overall Loss 0.675896    Objective Loss 0.675896    Top1 86.885246    Top5 100.000000    LR 0.000005    Time 0.136585    
2024-04-23 20:55:56,281 - --- validate (epoch=268)-----------
2024-04-23 20:55:56,282 - 3925 samples (32 per mini-batch)
2024-04-23 20:56:10,930 - Epoch: [268][  100/  123]    Loss 0.682239    Top1 77.906250    Top5 97.500000    
2024-04-23 20:56:13,339 - Epoch: [268][  123/  123]    Loss 0.670235    Top1 78.318471    Top5 97.324841    
2024-04-23 20:56:13,511 - ==> Top1: 78.318    Top5: 97.325    Loss: 0.670

2024-04-23 20:56:13,515 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:56:13,516 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:56:13,547 - 

2024-04-23 20:56:13,548 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:56:23,066 - Epoch: [269][  100/  296]    Overall Loss 0.698970    Objective Loss 0.698970                                        LR 0.000005    Time 0.095036    
2024-04-23 20:56:32,378 - Epoch: [269][  200/  296]    Overall Loss 0.683705    Objective Loss 0.683705                                        LR 0.000005    Time 0.094005    
2024-04-23 20:56:42,070 - Epoch: [269][  296/  296]    Overall Loss 0.680075    Objective Loss 0.680075    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.096208    
2024-04-23 20:56:42,241 - --- validate (epoch=269)-----------
2024-04-23 20:56:42,242 - 3925 samples (32 per mini-batch)
2024-04-23 20:56:56,010 - Epoch: [269][  100/  123]    Loss 0.673313    Top1 78.375000    Top5 97.343750    
2024-04-23 20:56:58,487 - Epoch: [269][  123/  123]    Loss 0.670344    Top1 78.598726    Top5 97.375796    
2024-04-23 20:56:58,672 - ==> Top1: 78.599    Top5: 97.376    Loss: 0.670

2024-04-23 20:56:58,681 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:56:58,682 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:56:58,731 - 

2024-04-23 20:56:58,732 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:57:09,594 - Epoch: [270][  100/  296]    Overall Loss 0.686334    Objective Loss 0.686334                                        LR 0.000005    Time 0.108440    
2024-04-23 20:57:22,288 - Epoch: [270][  200/  296]    Overall Loss 0.686498    Objective Loss 0.686498                                        LR 0.000005    Time 0.117613    
2024-04-23 20:57:36,283 - Epoch: [270][  296/  296]    Overall Loss 0.684160    Objective Loss 0.684160    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.126696    
2024-04-23 20:57:36,509 - --- validate (epoch=270)-----------
2024-04-23 20:57:36,510 - 3925 samples (32 per mini-batch)
2024-04-23 20:57:50,279 - Epoch: [270][  100/  123]    Loss 0.667412    Top1 78.468750    Top5 97.375000    
2024-04-23 20:57:52,851 - Epoch: [270][  123/  123]    Loss 0.669955    Top1 78.318471    Top5 97.375796    
2024-04-23 20:57:53,026 - ==> Top1: 78.318    Top5: 97.376    Loss: 0.670

2024-04-23 20:57:53,036 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:57:53,037 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:57:53,080 - 

2024-04-23 20:57:53,081 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:58:06,049 - Epoch: [271][  100/  296]    Overall Loss 0.665091    Objective Loss 0.665091                                        LR 0.000005    Time 0.129509    
2024-04-23 20:58:18,368 - Epoch: [271][  200/  296]    Overall Loss 0.680549    Objective Loss 0.680549                                        LR 0.000005    Time 0.126273    
2024-04-23 20:58:29,283 - Epoch: [271][  296/  296]    Overall Loss 0.674605    Objective Loss 0.674605    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.122146    
2024-04-23 20:58:29,466 - --- validate (epoch=271)-----------
2024-04-23 20:58:29,467 - 3925 samples (32 per mini-batch)
2024-04-23 20:58:41,587 - Epoch: [271][  100/  123]    Loss 0.677103    Top1 78.281250    Top5 97.437500    
2024-04-23 20:58:44,130 - Epoch: [271][  123/  123]    Loss 0.672823    Top1 78.191083    Top5 97.375796    
2024-04-23 20:58:44,377 - ==> Top1: 78.191    Top5: 97.376    Loss: 0.673

2024-04-23 20:58:44,387 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:58:44,387 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:58:44,428 - 

2024-04-23 20:58:44,429 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:58:56,089 - Epoch: [272][  100/  296]    Overall Loss 0.671206    Objective Loss 0.671206                                        LR 0.000005    Time 0.116430    
2024-04-23 20:59:09,159 - Epoch: [272][  200/  296]    Overall Loss 0.690503    Objective Loss 0.690503                                        LR 0.000005    Time 0.123464    
2024-04-23 20:59:20,908 - Epoch: [272][  296/  296]    Overall Loss 0.688816    Objective Loss 0.688816    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.123061    
2024-04-23 20:59:21,110 - --- validate (epoch=272)-----------
2024-04-23 20:59:21,111 - 3925 samples (32 per mini-batch)
2024-04-23 20:59:34,170 - Epoch: [272][  100/  123]    Loss 0.670202    Top1 79.000000    Top5 97.375000    
2024-04-23 20:59:36,307 - Epoch: [272][  123/  123]    Loss 0.669027    Top1 78.522293    Top5 97.452229    
2024-04-23 20:59:36,473 - ==> Top1: 78.522    Top5: 97.452    Loss: 0.669

2024-04-23 20:59:36,483 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 20:59:36,483 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 20:59:36,520 - 

2024-04-23 20:59:36,520 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:59:50,693 - Epoch: [273][  100/  296]    Overall Loss 0.701545    Objective Loss 0.701545                                        LR 0.000005    Time 0.141546    
2024-04-23 21:00:03,287 - Epoch: [273][  200/  296]    Overall Loss 0.690896    Objective Loss 0.690896                                        LR 0.000005    Time 0.133661    
2024-04-23 21:00:12,799 - Epoch: [273][  296/  296]    Overall Loss 0.680776    Objective Loss 0.680776    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.122394    
2024-04-23 21:00:13,007 - --- validate (epoch=273)-----------
2024-04-23 21:00:13,008 - 3925 samples (32 per mini-batch)
2024-04-23 21:00:28,710 - Epoch: [273][  100/  123]    Loss 0.657734    Top1 78.875000    Top5 97.343750    
2024-04-23 21:00:31,593 - Epoch: [273][  123/  123]    Loss 0.668156    Top1 78.369427    Top5 97.401274    
2024-04-23 21:00:31,773 - ==> Top1: 78.369    Top5: 97.401    Loss: 0.668

2024-04-23 21:00:31,785 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:00:31,785 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:00:31,830 - 

2024-04-23 21:00:31,830 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:00:42,123 - Epoch: [274][  100/  296]    Overall Loss 0.674122    Objective Loss 0.674122                                        LR 0.000005    Time 0.102761    
2024-04-23 21:00:50,943 - Epoch: [274][  200/  296]    Overall Loss 0.684080    Objective Loss 0.684080                                        LR 0.000005    Time 0.095399    
2024-04-23 21:00:58,992 - Epoch: [274][  296/  296]    Overall Loss 0.689601    Objective Loss 0.689601    Top1 70.491803    Top5 98.360656    LR 0.000005    Time 0.091605    
2024-04-23 21:00:59,192 - --- validate (epoch=274)-----------
2024-04-23 21:00:59,193 - 3925 samples (32 per mini-batch)
2024-04-23 21:01:12,489 - Epoch: [274][  100/  123]    Loss 0.664339    Top1 78.375000    Top5 97.468750    
2024-04-23 21:01:15,264 - Epoch: [274][  123/  123]    Loss 0.667830    Top1 78.343949    Top5 97.426752    
2024-04-23 21:01:15,401 - ==> Top1: 78.344    Top5: 97.427    Loss: 0.668

2024-04-23 21:01:15,405 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:01:15,405 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:01:15,432 - 

2024-04-23 21:01:15,432 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:01:29,863 - Epoch: [275][  100/  296]    Overall Loss 0.693778    Objective Loss 0.693778                                        LR 0.000005    Time 0.144131    
2024-04-23 21:01:45,065 - Epoch: [275][  200/  296]    Overall Loss 0.690423    Objective Loss 0.690423                                        LR 0.000005    Time 0.147997    
2024-04-23 21:01:57,707 - Epoch: [275][  296/  296]    Overall Loss 0.687507    Objective Loss 0.687507    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.142655    
2024-04-23 21:01:57,936 - --- validate (epoch=275)-----------
2024-04-23 21:01:57,937 - 3925 samples (32 per mini-batch)
2024-04-23 21:02:14,038 - Epoch: [275][  100/  123]    Loss 0.668031    Top1 78.093750    Top5 97.593750    
2024-04-23 21:02:17,122 - Epoch: [275][  123/  123]    Loss 0.668583    Top1 78.496815    Top5 97.477707    
2024-04-23 21:02:17,350 - ==> Top1: 78.497    Top5: 97.478    Loss: 0.669

2024-04-23 21:02:17,359 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:02:17,360 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:02:17,408 - 

2024-04-23 21:02:17,408 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:02:27,081 - Epoch: [276][  100/  296]    Overall Loss 0.680219    Objective Loss 0.680219                                        LR 0.000005    Time 0.096562    
2024-04-23 21:02:35,929 - Epoch: [276][  200/  296]    Overall Loss 0.672769    Objective Loss 0.672769                                        LR 0.000005    Time 0.092444    
2024-04-23 21:02:43,199 - Epoch: [276][  296/  296]    Overall Loss 0.665929    Objective Loss 0.665929    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.086975    
2024-04-23 21:02:43,417 - --- validate (epoch=276)-----------
2024-04-23 21:02:43,417 - 3925 samples (32 per mini-batch)
2024-04-23 21:02:53,607 - Epoch: [276][  100/  123]    Loss 0.671227    Top1 78.156250    Top5 97.468750    
2024-04-23 21:02:55,668 - Epoch: [276][  123/  123]    Loss 0.667958    Top1 78.292994    Top5 97.528662    
2024-04-23 21:02:55,861 - ==> Top1: 78.293    Top5: 97.529    Loss: 0.668

2024-04-23 21:02:55,870 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:02:55,870 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:02:55,904 - 

2024-04-23 21:02:55,905 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:03:04,868 - Epoch: [277][  100/  296]    Overall Loss 0.701491    Objective Loss 0.701491                                        LR 0.000005    Time 0.089464    
2024-04-23 21:03:12,381 - Epoch: [277][  200/  296]    Overall Loss 0.676772    Objective Loss 0.676772                                        LR 0.000005    Time 0.082220    
2024-04-23 21:03:20,398 - Epoch: [277][  296/  296]    Overall Loss 0.690708    Objective Loss 0.690708    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.082588    
2024-04-23 21:03:20,600 - --- validate (epoch=277)-----------
2024-04-23 21:03:20,601 - 3925 samples (32 per mini-batch)
2024-04-23 21:03:30,555 - Epoch: [277][  100/  123]    Loss 0.669788    Top1 78.062500    Top5 97.468750    
2024-04-23 21:03:32,427 - Epoch: [277][  123/  123]    Loss 0.666152    Top1 78.242038    Top5 97.528662    
2024-04-23 21:03:32,601 - ==> Top1: 78.242    Top5: 97.529    Loss: 0.666

2024-04-23 21:03:32,610 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:03:32,611 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:03:32,648 - 

2024-04-23 21:03:32,649 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:03:40,943 - Epoch: [278][  100/  296]    Overall Loss 0.679538    Objective Loss 0.679538                                        LR 0.000005    Time 0.082795    
2024-04-23 21:03:49,254 - Epoch: [278][  200/  296]    Overall Loss 0.694916    Objective Loss 0.694916                                        LR 0.000005    Time 0.082880    
2024-04-23 21:03:57,373 - Epoch: [278][  296/  296]    Overall Loss 0.686075    Objective Loss 0.686075    Top1 85.245902    Top5 96.721311    LR 0.000005    Time 0.083384    
2024-04-23 21:03:57,576 - --- validate (epoch=278)-----------
2024-04-23 21:03:57,576 - 3925 samples (32 per mini-batch)
2024-04-23 21:04:09,933 - Epoch: [278][  100/  123]    Loss 0.676411    Top1 78.343750    Top5 97.281250    
2024-04-23 21:04:12,864 - Epoch: [278][  123/  123]    Loss 0.670139    Top1 78.496815    Top5 97.426752    
2024-04-23 21:04:13,067 - ==> Top1: 78.497    Top5: 97.427    Loss: 0.670

2024-04-23 21:04:13,077 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:04:13,077 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:04:13,117 - 

2024-04-23 21:04:13,118 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:04:26,563 - Epoch: [279][  100/  296]    Overall Loss 0.677999    Objective Loss 0.677999                                        LR 0.000005    Time 0.134283    
2024-04-23 21:04:38,141 - Epoch: [279][  200/  296]    Overall Loss 0.687003    Objective Loss 0.687003                                        LR 0.000005    Time 0.124944    
2024-04-23 21:04:49,969 - Epoch: [279][  296/  296]    Overall Loss 0.686106    Objective Loss 0.686106    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.124330    
2024-04-23 21:04:50,133 - --- validate (epoch=279)-----------
2024-04-23 21:04:50,135 - 3925 samples (32 per mini-batch)
2024-04-23 21:05:05,472 - Epoch: [279][  100/  123]    Loss 0.667477    Top1 78.312500    Top5 97.281250    
2024-04-23 21:05:09,456 - Epoch: [279][  123/  123]    Loss 0.671242    Top1 78.140127    Top5 97.299363    
2024-04-23 21:05:09,663 - ==> Top1: 78.140    Top5: 97.299    Loss: 0.671

2024-04-23 21:05:09,674 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:05:09,674 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:05:09,721 - 

2024-04-23 21:05:09,721 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:05:28,908 - Epoch: [280][  100/  296]    Overall Loss 0.690828    Objective Loss 0.690828                                        LR 0.000005    Time 0.191737    
2024-04-23 21:05:43,551 - Epoch: [280][  200/  296]    Overall Loss 0.696016    Objective Loss 0.696016                                        LR 0.000005    Time 0.169016    
2024-04-23 21:05:58,038 - Epoch: [280][  296/  296]    Overall Loss 0.694151    Objective Loss 0.694151    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.163095    
2024-04-23 21:05:58,256 - --- validate (epoch=280)-----------
2024-04-23 21:05:58,257 - 3925 samples (32 per mini-batch)
2024-04-23 21:06:17,152 - Epoch: [280][  100/  123]    Loss 0.662019    Top1 78.187500    Top5 97.406250    
2024-04-23 21:06:20,349 - Epoch: [280][  123/  123]    Loss 0.668321    Top1 78.063694    Top5 97.375796    
2024-04-23 21:06:20,587 - ==> Top1: 78.064    Top5: 97.376    Loss: 0.668

2024-04-23 21:06:20,599 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:06:20,599 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:06:20,651 - 

2024-04-23 21:06:20,652 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:06:38,358 - Epoch: [281][  100/  296]    Overall Loss 0.661139    Objective Loss 0.661139                                        LR 0.000005    Time 0.176893    
2024-04-23 21:06:51,478 - Epoch: [281][  200/  296]    Overall Loss 0.672687    Objective Loss 0.672687                                        LR 0.000005    Time 0.153967    
2024-04-23 21:07:03,061 - Epoch: [281][  296/  296]    Overall Loss 0.687939    Objective Loss 0.687939    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.143113    
2024-04-23 21:07:03,340 - --- validate (epoch=281)-----------
2024-04-23 21:07:03,341 - 3925 samples (32 per mini-batch)
2024-04-23 21:07:20,682 - Epoch: [281][  100/  123]    Loss 0.662219    Top1 78.468750    Top5 97.187500    
2024-04-23 21:07:23,822 - Epoch: [281][  123/  123]    Loss 0.672159    Top1 78.165605    Top5 97.197452    
2024-04-23 21:07:24,024 - ==> Top1: 78.166    Top5: 97.197    Loss: 0.672

2024-04-23 21:07:24,034 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:07:24,034 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:07:24,083 - 

2024-04-23 21:07:24,084 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:07:39,982 - Epoch: [282][  100/  296]    Overall Loss 0.682070    Objective Loss 0.682070                                        LR 0.000005    Time 0.158803    
2024-04-23 21:07:53,868 - Epoch: [282][  200/  296]    Overall Loss 0.680551    Objective Loss 0.680551                                        LR 0.000005    Time 0.148752    
2024-04-23 21:08:06,934 - Epoch: [282][  296/  296]    Overall Loss 0.687338    Objective Loss 0.687338    Top1 85.245902    Top5 96.721311    LR 0.000005    Time 0.144600    
2024-04-23 21:08:07,136 - --- validate (epoch=282)-----------
2024-04-23 21:08:07,137 - 3925 samples (32 per mini-batch)
2024-04-23 21:08:23,687 - Epoch: [282][  100/  123]    Loss 0.670407    Top1 78.218750    Top5 97.406250    
2024-04-23 21:08:27,145 - Epoch: [282][  123/  123]    Loss 0.668794    Top1 78.343949    Top5 97.554140    
2024-04-23 21:08:27,348 - ==> Top1: 78.344    Top5: 97.554    Loss: 0.669

2024-04-23 21:08:27,356 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:08:27,357 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:08:27,399 - 

2024-04-23 21:08:27,400 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:08:40,788 - Epoch: [283][  100/  296]    Overall Loss 0.681841    Objective Loss 0.681841                                        LR 0.000005    Time 0.133701    
2024-04-23 21:08:53,988 - Epoch: [283][  200/  296]    Overall Loss 0.675729    Objective Loss 0.675729                                        LR 0.000005    Time 0.132775    
2024-04-23 21:09:11,546 - Epoch: [283][  296/  296]    Overall Loss 0.684941    Objective Loss 0.684941    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.148980    
2024-04-23 21:09:11,808 - --- validate (epoch=283)-----------
2024-04-23 21:09:11,809 - 3925 samples (32 per mini-batch)
2024-04-23 21:09:28,309 - Epoch: [283][  100/  123]    Loss 0.659004    Top1 78.500000    Top5 97.593750    
2024-04-23 21:09:31,842 - Epoch: [283][  123/  123]    Loss 0.669492    Top1 78.369427    Top5 97.477707    
2024-04-23 21:09:32,066 - ==> Top1: 78.369    Top5: 97.478    Loss: 0.669

2024-04-23 21:09:32,075 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:09:32,075 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:09:32,122 - 

2024-04-23 21:09:32,123 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:09:47,353 - Epoch: [284][  100/  296]    Overall Loss 0.681376    Objective Loss 0.681376                                        LR 0.000005    Time 0.152114    
2024-04-23 21:09:59,774 - Epoch: [284][  200/  296]    Overall Loss 0.696173    Objective Loss 0.696173                                        LR 0.000005    Time 0.138083    
2024-04-23 21:10:10,325 - Epoch: [284][  296/  296]    Overall Loss 0.691801    Objective Loss 0.691801    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.128892    
2024-04-23 21:10:10,560 - --- validate (epoch=284)-----------
2024-04-23 21:10:10,561 - 3925 samples (32 per mini-batch)
2024-04-23 21:10:27,185 - Epoch: [284][  100/  123]    Loss 0.667554    Top1 78.843750    Top5 97.250000    
2024-04-23 21:10:30,020 - Epoch: [284][  123/  123]    Loss 0.672724    Top1 78.420382    Top5 97.324841    
2024-04-23 21:10:30,238 - ==> Top1: 78.420    Top5: 97.325    Loss: 0.673

2024-04-23 21:10:30,247 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:10:30,248 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:10:30,287 - 

2024-04-23 21:10:30,288 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:10:42,116 - Epoch: [285][  100/  296]    Overall Loss 0.681385    Objective Loss 0.681385                                        LR 0.000005    Time 0.118111    
2024-04-23 21:10:53,886 - Epoch: [285][  200/  296]    Overall Loss 0.686090    Objective Loss 0.686090                                        LR 0.000005    Time 0.117816    
2024-04-23 21:11:06,796 - Epoch: [285][  296/  296]    Overall Loss 0.694076    Objective Loss 0.694076    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.123168    
2024-04-23 21:11:06,952 - --- validate (epoch=285)-----------
2024-04-23 21:11:06,952 - 3925 samples (32 per mini-batch)
2024-04-23 21:11:23,699 - Epoch: [285][  100/  123]    Loss 0.662474    Top1 78.218750    Top5 97.468750    
2024-04-23 21:11:26,472 - Epoch: [285][  123/  123]    Loss 0.670977    Top1 78.114650    Top5 97.350318    
2024-04-23 21:11:26,657 - ==> Top1: 78.115    Top5: 97.350    Loss: 0.671

2024-04-23 21:11:26,665 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:11:26,666 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:11:26,705 - 

2024-04-23 21:11:26,706 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:11:42,760 - Epoch: [286][  100/  296]    Overall Loss 0.687187    Objective Loss 0.687187                                        LR 0.000005    Time 0.160368    
2024-04-23 21:11:55,116 - Epoch: [286][  200/  296]    Overall Loss 0.676535    Objective Loss 0.676535                                        LR 0.000005    Time 0.141888    
2024-04-23 21:12:02,945 - Epoch: [286][  296/  296]    Overall Loss 0.692774    Objective Loss 0.692774    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.122266    
2024-04-23 21:12:03,187 - --- validate (epoch=286)-----------
2024-04-23 21:12:03,188 - 3925 samples (32 per mini-batch)
2024-04-23 21:12:15,792 - Epoch: [286][  100/  123]    Loss 0.672253    Top1 78.406250    Top5 97.281250    
2024-04-23 21:12:18,056 - Epoch: [286][  123/  123]    Loss 0.669638    Top1 78.267516    Top5 97.324841    
2024-04-23 21:12:18,245 - ==> Top1: 78.268    Top5: 97.325    Loss: 0.670

2024-04-23 21:12:18,254 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:12:18,254 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:12:18,297 - 

2024-04-23 21:12:18,297 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:12:29,145 - Epoch: [287][  100/  296]    Overall Loss 0.660592    Objective Loss 0.660592                                        LR 0.000005    Time 0.108300    
2024-04-23 21:12:37,781 - Epoch: [287][  200/  296]    Overall Loss 0.669158    Objective Loss 0.669158                                        LR 0.000005    Time 0.097254    
2024-04-23 21:12:48,930 - Epoch: [287][  296/  296]    Overall Loss 0.665917    Objective Loss 0.665917    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.103326    
2024-04-23 21:12:49,130 - --- validate (epoch=287)-----------
2024-04-23 21:12:49,131 - 3925 samples (32 per mini-batch)
2024-04-23 21:13:03,117 - Epoch: [287][  100/  123]    Loss 0.670955    Top1 78.250000    Top5 97.343750    
2024-04-23 21:13:07,087 - Epoch: [287][  123/  123]    Loss 0.671542    Top1 78.292994    Top5 97.299363    
2024-04-23 21:13:07,287 - ==> Top1: 78.293    Top5: 97.299    Loss: 0.672

2024-04-23 21:13:07,298 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:13:07,298 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:13:07,344 - 

2024-04-23 21:13:07,345 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:13:22,973 - Epoch: [288][  100/  296]    Overall Loss 0.690701    Objective Loss 0.690701                                        LR 0.000005    Time 0.156093    
2024-04-23 21:13:38,648 - Epoch: [288][  200/  296]    Overall Loss 0.681697    Objective Loss 0.681697                                        LR 0.000005    Time 0.156331    
2024-04-23 21:13:53,971 - Epoch: [288][  296/  296]    Overall Loss 0.684892    Objective Loss 0.684892    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.157346    
2024-04-23 21:13:54,212 - --- validate (epoch=288)-----------
2024-04-23 21:13:54,213 - 3925 samples (32 per mini-batch)
2024-04-23 21:14:06,735 - Epoch: [288][  100/  123]    Loss 0.669791    Top1 78.375000    Top5 97.531250    
2024-04-23 21:14:09,023 - Epoch: [288][  123/  123]    Loss 0.670837    Top1 78.369427    Top5 97.452229    
2024-04-23 21:14:09,256 - ==> Top1: 78.369    Top5: 97.452    Loss: 0.671

2024-04-23 21:14:09,265 - ==> Best [Top1: 78.650   Top5: 97.478   Sparsity:0.00   Params: 371568 on epoch: 212]
2024-04-23 21:14:09,265 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:14:09,303 - 

2024-04-23 21:14:09,304 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:14:18,403 - Epoch: [289][  100/  296]    Overall Loss 0.688704    Objective Loss 0.688704                                        LR 0.000005    Time 0.090829    
2024-04-23 21:14:28,135 - Epoch: [289][  200/  296]    Overall Loss 0.691486    Objective Loss 0.691486                                        LR 0.000005    Time 0.094000    
2024-04-23 21:14:40,884 - Epoch: [289][  296/  296]    Overall Loss 0.687580    Objective Loss 0.687580    Top1 88.524590    Top5 95.081967    LR 0.000005    Time 0.106530    
2024-04-23 21:14:41,036 - --- validate (epoch=289)-----------
2024-04-23 21:14:41,036 - 3925 samples (32 per mini-batch)
2024-04-23 21:15:00,270 - Epoch: [289][  100/  123]    Loss 0.686754    Top1 78.187500    Top5 97.218750    
2024-04-23 21:15:04,744 - Epoch: [289][  123/  123]    Loss 0.668577    Top1 78.700637    Top5 97.375796    
2024-04-23 21:15:04,943 - ==> Top1: 78.701    Top5: 97.376    Loss: 0.669

2024-04-23 21:15:04,951 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:15:04,952 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:15:05,006 - 

2024-04-23 21:15:05,007 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:15:24,272 - Epoch: [290][  100/  296]    Overall Loss 0.679374    Objective Loss 0.679374                                        LR 0.000005    Time 0.192485    
2024-04-23 21:15:38,524 - Epoch: [290][  200/  296]    Overall Loss 0.681197    Objective Loss 0.681197                                        LR 0.000005    Time 0.167425    
2024-04-23 21:15:51,587 - Epoch: [290][  296/  296]    Overall Loss 0.679971    Objective Loss 0.679971    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.157204    
2024-04-23 21:15:51,787 - --- validate (epoch=290)-----------
2024-04-23 21:15:51,788 - 3925 samples (32 per mini-batch)
2024-04-23 21:16:09,820 - Epoch: [290][  100/  123]    Loss 0.678868    Top1 78.031250    Top5 97.468750    
2024-04-23 21:16:13,216 - Epoch: [290][  123/  123]    Loss 0.669417    Top1 78.369427    Top5 97.528662    
2024-04-23 21:16:13,414 - ==> Top1: 78.369    Top5: 97.529    Loss: 0.669

2024-04-23 21:16:13,420 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:16:13,420 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:16:13,457 - 

2024-04-23 21:16:13,458 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:16:27,877 - Epoch: [291][  100/  296]    Overall Loss 0.667511    Objective Loss 0.667511                                        LR 0.000005    Time 0.144009    
2024-04-23 21:16:41,660 - Epoch: [291][  200/  296]    Overall Loss 0.672832    Objective Loss 0.672832                                        LR 0.000005    Time 0.140835    
2024-04-23 21:16:54,609 - Epoch: [291][  296/  296]    Overall Loss 0.685425    Objective Loss 0.685425    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.138859    
2024-04-23 21:16:54,825 - --- validate (epoch=291)-----------
2024-04-23 21:16:54,826 - 3925 samples (32 per mini-batch)
2024-04-23 21:17:11,573 - Epoch: [291][  100/  123]    Loss 0.669473    Top1 78.343750    Top5 97.218750    
2024-04-23 21:17:15,241 - Epoch: [291][  123/  123]    Loss 0.670504    Top1 78.369427    Top5 97.299363    
2024-04-23 21:17:15,468 - ==> Top1: 78.369    Top5: 97.299    Loss: 0.671

2024-04-23 21:17:15,477 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:17:15,478 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:17:15,529 - 

2024-04-23 21:17:15,530 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:17:30,407 - Epoch: [292][  100/  296]    Overall Loss 0.716531    Objective Loss 0.716531                                        LR 0.000005    Time 0.148621    
2024-04-23 21:17:45,738 - Epoch: [292][  200/  296]    Overall Loss 0.681809    Objective Loss 0.681809                                        LR 0.000005    Time 0.150891    
2024-04-23 21:17:59,613 - Epoch: [292][  296/  296]    Overall Loss 0.682589    Objective Loss 0.682589    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.148780    
2024-04-23 21:17:59,867 - --- validate (epoch=292)-----------
2024-04-23 21:17:59,868 - 3925 samples (32 per mini-batch)
2024-04-23 21:18:17,623 - Epoch: [292][  100/  123]    Loss 0.659140    Top1 79.000000    Top5 97.406250    
2024-04-23 21:18:21,566 - Epoch: [292][  123/  123]    Loss 0.672982    Top1 78.598726    Top5 97.299363    
2024-04-23 21:18:21,742 - ==> Top1: 78.599    Top5: 97.299    Loss: 0.673

2024-04-23 21:18:21,751 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:18:21,752 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:18:21,794 - 

2024-04-23 21:18:21,795 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:18:34,182 - Epoch: [293][  100/  296]    Overall Loss 0.682408    Objective Loss 0.682408                                        LR 0.000005    Time 0.123684    
2024-04-23 21:18:47,211 - Epoch: [293][  200/  296]    Overall Loss 0.682857    Objective Loss 0.682857                                        LR 0.000005    Time 0.126911    
2024-04-23 21:18:56,323 - Epoch: [293][  296/  296]    Overall Loss 0.681880    Objective Loss 0.681880    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.116486    
2024-04-23 21:18:56,490 - --- validate (epoch=293)-----------
2024-04-23 21:18:56,491 - 3925 samples (32 per mini-batch)
2024-04-23 21:19:09,327 - Epoch: [293][  100/  123]    Loss 0.663241    Top1 78.437500    Top5 97.312500    
2024-04-23 21:19:11,380 - Epoch: [293][  123/  123]    Loss 0.667981    Top1 78.191083    Top5 97.375796    
2024-04-23 21:19:11,559 - ==> Top1: 78.191    Top5: 97.376    Loss: 0.668

2024-04-23 21:19:11,564 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:19:11,564 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:19:11,595 - 

2024-04-23 21:19:11,596 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:19:23,922 - Epoch: [294][  100/  296]    Overall Loss 0.705994    Objective Loss 0.705994                                        LR 0.000005    Time 0.123085    
2024-04-23 21:19:34,647 - Epoch: [294][  200/  296]    Overall Loss 0.688312    Objective Loss 0.688312                                        LR 0.000005    Time 0.115088    
2024-04-23 21:19:46,266 - Epoch: [294][  296/  296]    Overall Loss 0.679723    Objective Loss 0.679723    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.116964    
2024-04-23 21:19:46,474 - --- validate (epoch=294)-----------
2024-04-23 21:19:46,475 - 3925 samples (32 per mini-batch)
2024-04-23 21:20:02,023 - Epoch: [294][  100/  123]    Loss 0.677880    Top1 77.968750    Top5 97.312500    
2024-04-23 21:20:04,743 - Epoch: [294][  123/  123]    Loss 0.674448    Top1 78.165605    Top5 97.273885    
2024-04-23 21:20:04,920 - ==> Top1: 78.166    Top5: 97.274    Loss: 0.674

2024-04-23 21:20:04,927 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:20:04,928 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:20:04,978 - 

2024-04-23 21:20:04,978 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:20:15,842 - Epoch: [295][  100/  296]    Overall Loss 0.669812    Objective Loss 0.669812                                        LR 0.000005    Time 0.108467    
2024-04-23 21:20:24,121 - Epoch: [295][  200/  296]    Overall Loss 0.686291    Objective Loss 0.686291                                        LR 0.000005    Time 0.095556    
2024-04-23 21:20:33,951 - Epoch: [295][  296/  296]    Overall Loss 0.688333    Objective Loss 0.688333    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.097722    
2024-04-23 21:20:34,136 - --- validate (epoch=295)-----------
2024-04-23 21:20:34,137 - 3925 samples (32 per mini-batch)
2024-04-23 21:20:47,223 - Epoch: [295][  100/  123]    Loss 0.661742    Top1 78.000000    Top5 97.437500    
2024-04-23 21:20:49,310 - Epoch: [295][  123/  123]    Loss 0.673513    Top1 77.961783    Top5 97.426752    
2024-04-23 21:20:49,534 - ==> Top1: 77.962    Top5: 97.427    Loss: 0.674

2024-04-23 21:20:49,544 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:20:49,545 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:20:49,590 - 

2024-04-23 21:20:49,590 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:21:00,778 - Epoch: [296][  100/  296]    Overall Loss 0.723360    Objective Loss 0.723360                                        LR 0.000005    Time 0.111703    
2024-04-23 21:21:12,315 - Epoch: [296][  200/  296]    Overall Loss 0.698467    Objective Loss 0.698467                                        LR 0.000005    Time 0.113457    
2024-04-23 21:21:20,085 - Epoch: [296][  296/  296]    Overall Loss 0.699924    Objective Loss 0.699924    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.102867    
2024-04-23 21:21:20,306 - --- validate (epoch=296)-----------
2024-04-23 21:21:20,307 - 3925 samples (32 per mini-batch)
2024-04-23 21:21:34,856 - Epoch: [296][  100/  123]    Loss 0.665471    Top1 78.343750    Top5 97.531250    
2024-04-23 21:21:37,299 - Epoch: [296][  123/  123]    Loss 0.669243    Top1 78.343949    Top5 97.426752    
2024-04-23 21:21:37,466 - ==> Top1: 78.344    Top5: 97.427    Loss: 0.669

2024-04-23 21:21:37,475 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:21:37,476 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:21:37,516 - 

2024-04-23 21:21:37,517 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:21:49,947 - Epoch: [297][  100/  296]    Overall Loss 0.680859    Objective Loss 0.680859                                        LR 0.000005    Time 0.124120    
2024-04-23 21:22:01,932 - Epoch: [297][  200/  296]    Overall Loss 0.679701    Objective Loss 0.679701                                        LR 0.000005    Time 0.121901    
2024-04-23 21:22:12,202 - Epoch: [297][  296/  296]    Overall Loss 0.696411    Objective Loss 0.696411    Top1 67.213115    Top5 95.081967    LR 0.000005    Time 0.117010    
2024-04-23 21:22:12,405 - --- validate (epoch=297)-----------
2024-04-23 21:22:12,406 - 3925 samples (32 per mini-batch)
2024-04-23 21:22:26,563 - Epoch: [297][  100/  123]    Loss 0.676518    Top1 78.031250    Top5 97.468750    
2024-04-23 21:22:28,625 - Epoch: [297][  123/  123]    Loss 0.673437    Top1 78.267516    Top5 97.503185    
2024-04-23 21:22:28,786 - ==> Top1: 78.268    Top5: 97.503    Loss: 0.673

2024-04-23 21:22:28,791 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:22:28,792 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:22:28,825 - 

2024-04-23 21:22:28,825 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:22:39,041 - Epoch: [298][  100/  296]    Overall Loss 0.703556    Objective Loss 0.703556                                        LR 0.000005    Time 0.101997    
2024-04-23 21:22:51,534 - Epoch: [298][  200/  296]    Overall Loss 0.691704    Objective Loss 0.691704                                        LR 0.000005    Time 0.113388    
2024-04-23 21:23:03,839 - Epoch: [298][  296/  296]    Overall Loss 0.683724    Objective Loss 0.683724    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.118127    
2024-04-23 21:23:04,076 - --- validate (epoch=298)-----------
2024-04-23 21:23:04,077 - 3925 samples (32 per mini-batch)
2024-04-23 21:23:15,964 - Epoch: [298][  100/  123]    Loss 0.673154    Top1 78.000000    Top5 97.625000    
2024-04-23 21:23:17,748 - Epoch: [298][  123/  123]    Loss 0.669346    Top1 78.267516    Top5 97.350318    
2024-04-23 21:23:17,937 - ==> Top1: 78.268    Top5: 97.350    Loss: 0.669

2024-04-23 21:23:17,946 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:23:17,947 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:23:17,985 - 

2024-04-23 21:23:17,986 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:23:27,437 - Epoch: [299][  100/  296]    Overall Loss 0.666724    Objective Loss 0.666724                                        LR 0.000005    Time 0.094340    
2024-04-23 21:23:36,721 - Epoch: [299][  200/  296]    Overall Loss 0.667017    Objective Loss 0.667017                                        LR 0.000005    Time 0.093516    
2024-04-23 21:23:48,328 - Epoch: [299][  296/  296]    Overall Loss 0.685642    Objective Loss 0.685642    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.102346    
2024-04-23 21:23:48,546 - --- validate (epoch=299)-----------
2024-04-23 21:23:48,547 - 3925 samples (32 per mini-batch)
2024-04-23 21:24:04,152 - Epoch: [299][  100/  123]    Loss 0.671982    Top1 78.687500    Top5 97.437500    
2024-04-23 21:24:07,547 - Epoch: [299][  123/  123]    Loss 0.672991    Top1 78.420382    Top5 97.426752    
2024-04-23 21:24:07,773 - ==> Top1: 78.420    Top5: 97.427    Loss: 0.673

2024-04-23 21:24:07,782 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:24:07,782 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:24:07,822 - 

2024-04-23 21:24:07,822 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:24:19,880 - Epoch: [300][  100/  296]    Overall Loss 0.669889    Objective Loss 0.669889                                        LR 0.000005    Time 0.120425    
2024-04-23 21:24:30,145 - Epoch: [300][  200/  296]    Overall Loss 0.670048    Objective Loss 0.670048                                        LR 0.000005    Time 0.111451    
2024-04-23 21:24:37,193 - Epoch: [300][  296/  296]    Overall Loss 0.687183    Objective Loss 0.687183    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.099063    
2024-04-23 21:24:37,394 - --- validate (epoch=300)-----------
2024-04-23 21:24:37,395 - 3925 samples (32 per mini-batch)
2024-04-23 21:24:49,194 - Epoch: [300][  100/  123]    Loss 0.664950    Top1 78.125000    Top5 97.562500    
2024-04-23 21:24:51,327 - Epoch: [300][  123/  123]    Loss 0.668651    Top1 78.165605    Top5 97.477707    
2024-04-23 21:24:51,494 - ==> Top1: 78.166    Top5: 97.478    Loss: 0.669

2024-04-23 21:24:51,503 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:24:51,503 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:24:51,539 - 

2024-04-23 21:24:51,540 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:25:02,609 - Epoch: [301][  100/  296]    Overall Loss 0.698305    Objective Loss 0.698305                                        LR 0.000005    Time 0.110528    
2024-04-23 21:25:12,155 - Epoch: [301][  200/  296]    Overall Loss 0.692822    Objective Loss 0.692822                                        LR 0.000005    Time 0.102905    
2024-04-23 21:25:20,788 - Epoch: [301][  296/  296]    Overall Loss 0.691603    Objective Loss 0.691603    Top1 72.131148    Top5 100.000000    LR 0.000005    Time 0.098649    
2024-04-23 21:25:20,939 - --- validate (epoch=301)-----------
2024-04-23 21:25:20,941 - 3925 samples (32 per mini-batch)
2024-04-23 21:25:33,525 - Epoch: [301][  100/  123]    Loss 0.671701    Top1 77.968750    Top5 97.375000    
2024-04-23 21:25:35,772 - Epoch: [301][  123/  123]    Loss 0.672030    Top1 78.012739    Top5 97.452229    
2024-04-23 21:25:35,979 - ==> Top1: 78.013    Top5: 97.452    Loss: 0.672

2024-04-23 21:25:35,986 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:25:35,986 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:25:36,035 - 

2024-04-23 21:25:36,036 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:25:48,978 - Epoch: [302][  100/  296]    Overall Loss 0.691896    Objective Loss 0.691896                                        LR 0.000005    Time 0.129235    
2024-04-23 21:25:59,392 - Epoch: [302][  200/  296]    Overall Loss 0.698268    Objective Loss 0.698268                                        LR 0.000005    Time 0.116600    
2024-04-23 21:26:10,055 - Epoch: [302][  296/  296]    Overall Loss 0.697748    Objective Loss 0.697748    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.114755    
2024-04-23 21:26:10,239 - --- validate (epoch=302)-----------
2024-04-23 21:26:10,240 - 3925 samples (32 per mini-batch)
2024-04-23 21:26:21,074 - Epoch: [302][  100/  123]    Loss 0.672142    Top1 78.250000    Top5 97.375000    
2024-04-23 21:26:23,485 - Epoch: [302][  123/  123]    Loss 0.670008    Top1 78.242038    Top5 97.426752    
2024-04-23 21:26:23,679 - ==> Top1: 78.242    Top5: 97.427    Loss: 0.670

2024-04-23 21:26:23,687 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:26:23,688 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:26:23,729 - 

2024-04-23 21:26:23,729 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:26:34,419 - Epoch: [303][  100/  296]    Overall Loss 0.675336    Objective Loss 0.675336                                        LR 0.000005    Time 0.106739    
2024-04-23 21:26:42,148 - Epoch: [303][  200/  296]    Overall Loss 0.692909    Objective Loss 0.692909                                        LR 0.000005    Time 0.091936    
2024-04-23 21:26:50,415 - Epoch: [303][  296/  296]    Overall Loss 0.693870    Objective Loss 0.693870    Top1 81.967213    Top5 93.442623    LR 0.000005    Time 0.090000    
2024-04-23 21:26:50,580 - --- validate (epoch=303)-----------
2024-04-23 21:26:50,581 - 3925 samples (32 per mini-batch)
2024-04-23 21:27:02,171 - Epoch: [303][  100/  123]    Loss 0.674248    Top1 78.343750    Top5 97.281250    
2024-04-23 21:27:04,620 - Epoch: [303][  123/  123]    Loss 0.672233    Top1 78.242038    Top5 97.324841    
2024-04-23 21:27:04,787 - ==> Top1: 78.242    Top5: 97.325    Loss: 0.672

2024-04-23 21:27:04,792 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:27:04,793 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:27:04,824 - 

2024-04-23 21:27:04,824 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:27:15,815 - Epoch: [304][  100/  296]    Overall Loss 0.693352    Objective Loss 0.693352                                        LR 0.000005    Time 0.109736    
2024-04-23 21:27:29,009 - Epoch: [304][  200/  296]    Overall Loss 0.703114    Objective Loss 0.703114                                        LR 0.000005    Time 0.120744    
2024-04-23 21:27:40,864 - Epoch: [304][  296/  296]    Overall Loss 0.703108    Objective Loss 0.703108    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.121579    
2024-04-23 21:27:41,022 - --- validate (epoch=304)-----------
2024-04-23 21:27:41,023 - 3925 samples (32 per mini-batch)
2024-04-23 21:27:51,197 - Epoch: [304][  100/  123]    Loss 0.671225    Top1 78.468750    Top5 97.156250    
2024-04-23 21:27:53,330 - Epoch: [304][  123/  123]    Loss 0.675030    Top1 78.140127    Top5 97.299363    
2024-04-23 21:27:53,478 - ==> Top1: 78.140    Top5: 97.299    Loss: 0.675

2024-04-23 21:27:53,486 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:27:53,487 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:27:53,523 - 

2024-04-23 21:27:53,523 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:28:03,262 - Epoch: [305][  100/  296]    Overall Loss 0.679349    Objective Loss 0.679349                                        LR 0.000005    Time 0.097228    
2024-04-23 21:28:15,708 - Epoch: [305][  200/  296]    Overall Loss 0.684845    Objective Loss 0.684845                                        LR 0.000005    Time 0.110774    
2024-04-23 21:28:23,806 - Epoch: [305][  296/  296]    Overall Loss 0.690234    Objective Loss 0.690234    Top1 88.524590    Top5 98.360656    LR 0.000005    Time 0.102161    
2024-04-23 21:28:23,965 - --- validate (epoch=305)-----------
2024-04-23 21:28:23,966 - 3925 samples (32 per mini-batch)
2024-04-23 21:28:39,168 - Epoch: [305][  100/  123]    Loss 0.666438    Top1 78.187500    Top5 97.593750    
2024-04-23 21:28:42,240 - Epoch: [305][  123/  123]    Loss 0.672182    Top1 78.089172    Top5 97.401274    
2024-04-23 21:28:42,409 - ==> Top1: 78.089    Top5: 97.401    Loss: 0.672

2024-04-23 21:28:42,414 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:28:42,415 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:28:42,451 - 

2024-04-23 21:28:42,451 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:28:52,350 - Epoch: [306][  100/  296]    Overall Loss 0.681817    Objective Loss 0.681817                                        LR 0.000005    Time 0.098827    
2024-04-23 21:29:00,548 - Epoch: [306][  200/  296]    Overall Loss 0.691204    Objective Loss 0.691204                                        LR 0.000005    Time 0.090325    
2024-04-23 21:29:09,671 - Epoch: [306][  296/  296]    Overall Loss 0.690943    Objective Loss 0.690943    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.091804    
2024-04-23 21:29:09,824 - --- validate (epoch=306)-----------
2024-04-23 21:29:09,825 - 3925 samples (32 per mini-batch)
2024-04-23 21:29:21,377 - Epoch: [306][  100/  123]    Loss 0.675638    Top1 78.125000    Top5 97.531250    
2024-04-23 21:29:23,453 - Epoch: [306][  123/  123]    Loss 0.671293    Top1 78.191083    Top5 97.452229    
2024-04-23 21:29:23,588 - ==> Top1: 78.191    Top5: 97.452    Loss: 0.671

2024-04-23 21:29:23,596 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:29:23,597 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:29:23,634 - 

2024-04-23 21:29:23,634 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:29:35,438 - Epoch: [307][  100/  296]    Overall Loss 0.711114    Objective Loss 0.711114                                        LR 0.000005    Time 0.117863    
2024-04-23 21:29:49,872 - Epoch: [307][  200/  296]    Overall Loss 0.694934    Objective Loss 0.694934                                        LR 0.000005    Time 0.131024    
2024-04-23 21:29:59,865 - Epoch: [307][  296/  296]    Overall Loss 0.691968    Objective Loss 0.691968    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.122236    
2024-04-23 21:30:00,079 - --- validate (epoch=307)-----------
2024-04-23 21:30:00,080 - 3925 samples (32 per mini-batch)
2024-04-23 21:30:16,304 - Epoch: [307][  100/  123]    Loss 0.673652    Top1 77.968750    Top5 97.500000    
2024-04-23 21:30:19,268 - Epoch: [307][  123/  123]    Loss 0.665655    Top1 78.394904    Top5 97.554140    
2024-04-23 21:30:19,451 - ==> Top1: 78.395    Top5: 97.554    Loss: 0.666

2024-04-23 21:30:19,462 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:30:19,462 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:30:19,506 - 

2024-04-23 21:30:19,507 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:30:32,349 - Epoch: [308][  100/  296]    Overall Loss 0.673256    Objective Loss 0.673256                                        LR 0.000005    Time 0.128241    
2024-04-23 21:30:41,674 - Epoch: [308][  200/  296]    Overall Loss 0.683407    Objective Loss 0.683407                                        LR 0.000005    Time 0.110665    
2024-04-23 21:30:49,925 - Epoch: [308][  296/  296]    Overall Loss 0.687645    Objective Loss 0.687645    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.102602    
2024-04-23 21:30:50,161 - --- validate (epoch=308)-----------
2024-04-23 21:30:50,162 - 3925 samples (32 per mini-batch)
2024-04-23 21:31:03,718 - Epoch: [308][  100/  123]    Loss 0.664981    Top1 78.531250    Top5 97.500000    
2024-04-23 21:31:06,347 - Epoch: [308][  123/  123]    Loss 0.669519    Top1 78.242038    Top5 97.503185    
2024-04-23 21:31:06,476 - ==> Top1: 78.242    Top5: 97.503    Loss: 0.670

2024-04-23 21:31:06,482 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:31:06,482 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:31:06,523 - 

2024-04-23 21:31:06,524 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:31:15,602 - Epoch: [309][  100/  296]    Overall Loss 0.688299    Objective Loss 0.688299                                        LR 0.000005    Time 0.090625    
2024-04-23 21:31:25,066 - Epoch: [309][  200/  296]    Overall Loss 0.686941    Objective Loss 0.686941                                        LR 0.000005    Time 0.092557    
2024-04-23 21:31:37,665 - Epoch: [309][  296/  296]    Overall Loss 0.692363    Objective Loss 0.692363    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.105051    
2024-04-23 21:31:37,835 - --- validate (epoch=309)-----------
2024-04-23 21:31:37,836 - 3925 samples (32 per mini-batch)
2024-04-23 21:31:51,261 - Epoch: [309][  100/  123]    Loss 0.654874    Top1 78.406250    Top5 97.531250    
2024-04-23 21:31:53,264 - Epoch: [309][  123/  123]    Loss 0.671195    Top1 78.063694    Top5 97.426752    
2024-04-23 21:31:53,482 - ==> Top1: 78.064    Top5: 97.427    Loss: 0.671

2024-04-23 21:31:53,494 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:31:53,494 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:31:53,534 - 

2024-04-23 21:31:53,535 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:32:07,187 - Epoch: [310][  100/  296]    Overall Loss 0.694724    Objective Loss 0.694724                                        LR 0.000005    Time 0.136339    
2024-04-23 21:32:20,539 - Epoch: [310][  200/  296]    Overall Loss 0.679950    Objective Loss 0.679950                                        LR 0.000005    Time 0.134850    
2024-04-23 21:32:28,584 - Epoch: [310][  296/  296]    Overall Loss 0.676314    Objective Loss 0.676314    Top1 68.852459    Top5 95.081967    LR 0.000005    Time 0.118249    
2024-04-23 21:32:28,781 - --- validate (epoch=310)-----------
2024-04-23 21:32:28,782 - 3925 samples (32 per mini-batch)
2024-04-23 21:32:42,546 - Epoch: [310][  100/  123]    Loss 0.662598    Top1 78.906250    Top5 97.562500    
2024-04-23 21:32:45,769 - Epoch: [310][  123/  123]    Loss 0.671268    Top1 78.522293    Top5 97.528662    
2024-04-23 21:32:45,981 - ==> Top1: 78.522    Top5: 97.529    Loss: 0.671

2024-04-23 21:32:45,990 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:32:45,990 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:32:46,027 - 

2024-04-23 21:32:46,028 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:32:57,816 - Epoch: [311][  100/  296]    Overall Loss 0.663020    Objective Loss 0.663020                                        LR 0.000005    Time 0.117714    
2024-04-23 21:33:07,477 - Epoch: [311][  200/  296]    Overall Loss 0.656854    Objective Loss 0.656854                                        LR 0.000005    Time 0.107082    
2024-04-23 21:33:16,610 - Epoch: [311][  296/  296]    Overall Loss 0.681536    Objective Loss 0.681536    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.103156    
2024-04-23 21:33:16,779 - --- validate (epoch=311)-----------
2024-04-23 21:33:16,780 - 3925 samples (32 per mini-batch)
2024-04-23 21:33:34,165 - Epoch: [311][  100/  123]    Loss 0.669688    Top1 78.562500    Top5 97.562500    
2024-04-23 21:33:37,789 - Epoch: [311][  123/  123]    Loss 0.677202    Top1 78.242038    Top5 97.299363    
2024-04-23 21:33:38,014 - ==> Top1: 78.242    Top5: 97.299    Loss: 0.677

2024-04-23 21:33:38,023 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:33:38,023 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:33:38,063 - 

2024-04-23 21:33:38,064 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:33:47,256 - Epoch: [312][  100/  296]    Overall Loss 0.680246    Objective Loss 0.680246                                        LR 0.000005    Time 0.091762    
2024-04-23 21:33:58,312 - Epoch: [312][  200/  296]    Overall Loss 0.679206    Objective Loss 0.679206                                        LR 0.000005    Time 0.101081    
2024-04-23 21:34:09,472 - Epoch: [312][  296/  296]    Overall Loss 0.684855    Objective Loss 0.684855    Top1 72.131148    Top5 93.442623    LR 0.000005    Time 0.105954    
2024-04-23 21:34:09,652 - --- validate (epoch=312)-----------
2024-04-23 21:34:09,653 - 3925 samples (32 per mini-batch)
2024-04-23 21:34:26,158 - Epoch: [312][  100/  123]    Loss 0.657992    Top1 78.750000    Top5 97.406250    
2024-04-23 21:34:28,632 - Epoch: [312][  123/  123]    Loss 0.672531    Top1 78.318471    Top5 97.375796    
2024-04-23 21:34:28,826 - ==> Top1: 78.318    Top5: 97.376    Loss: 0.673

2024-04-23 21:34:28,835 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:34:28,836 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:34:28,874 - 

2024-04-23 21:34:28,874 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:34:41,202 - Epoch: [313][  100/  296]    Overall Loss 0.699451    Objective Loss 0.699451                                        LR 0.000005    Time 0.123090    
2024-04-23 21:34:51,238 - Epoch: [313][  200/  296]    Overall Loss 0.693782    Objective Loss 0.693782                                        LR 0.000005    Time 0.111645    
2024-04-23 21:35:03,932 - Epoch: [313][  296/  296]    Overall Loss 0.685612    Objective Loss 0.685612    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.118272    
2024-04-23 21:35:04,161 - --- validate (epoch=313)-----------
2024-04-23 21:35:04,163 - 3925 samples (32 per mini-batch)
2024-04-23 21:35:21,216 - Epoch: [313][  100/  123]    Loss 0.671934    Top1 78.000000    Top5 97.218750    
2024-04-23 21:35:23,557 - Epoch: [313][  123/  123]    Loss 0.674319    Top1 78.089172    Top5 97.299363    
2024-04-23 21:35:23,778 - ==> Top1: 78.089    Top5: 97.299    Loss: 0.674

2024-04-23 21:35:23,786 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:35:23,787 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:35:23,823 - 

2024-04-23 21:35:23,823 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:35:33,220 - Epoch: [314][  100/  296]    Overall Loss 0.699696    Objective Loss 0.699696                                        LR 0.000005    Time 0.093816    
2024-04-23 21:35:41,749 - Epoch: [314][  200/  296]    Overall Loss 0.710416    Objective Loss 0.710416                                        LR 0.000005    Time 0.089479    
2024-04-23 21:35:50,514 - Epoch: [314][  296/  296]    Overall Loss 0.694143    Objective Loss 0.694143    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.090020    
2024-04-23 21:35:50,671 - --- validate (epoch=314)-----------
2024-04-23 21:35:50,671 - 3925 samples (32 per mini-batch)
2024-04-23 21:36:03,028 - Epoch: [314][  100/  123]    Loss 0.656165    Top1 78.406250    Top5 97.750000    
2024-04-23 21:36:05,197 - Epoch: [314][  123/  123]    Loss 0.667707    Top1 78.191083    Top5 97.579618    
2024-04-23 21:36:05,347 - ==> Top1: 78.191    Top5: 97.580    Loss: 0.668

2024-04-23 21:36:05,355 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:36:05,355 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:36:05,394 - 

2024-04-23 21:36:05,394 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:36:16,615 - Epoch: [315][  100/  296]    Overall Loss 0.692224    Objective Loss 0.692224                                        LR 0.000005    Time 0.112036    
2024-04-23 21:36:25,078 - Epoch: [315][  200/  296]    Overall Loss 0.692265    Objective Loss 0.692265                                        LR 0.000005    Time 0.098260    
2024-04-23 21:36:32,928 - Epoch: [315][  296/  296]    Overall Loss 0.683311    Objective Loss 0.683311    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.092866    
2024-04-23 21:36:33,110 - --- validate (epoch=315)-----------
2024-04-23 21:36:33,111 - 3925 samples (32 per mini-batch)
2024-04-23 21:36:47,390 - Epoch: [315][  100/  123]    Loss 0.666058    Top1 78.781250    Top5 97.437500    
2024-04-23 21:36:50,544 - Epoch: [315][  123/  123]    Loss 0.672408    Top1 78.496815    Top5 97.350318    
2024-04-23 21:36:50,741 - ==> Top1: 78.497    Top5: 97.350    Loss: 0.672

2024-04-23 21:36:50,746 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:36:50,747 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:36:50,784 - 

2024-04-23 21:36:50,785 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:37:04,095 - Epoch: [316][  100/  296]    Overall Loss 0.666081    Objective Loss 0.666081                                        LR 0.000005    Time 0.132912    
2024-04-23 21:37:17,066 - Epoch: [316][  200/  296]    Overall Loss 0.681466    Objective Loss 0.681466                                        LR 0.000005    Time 0.131226    
2024-04-23 21:37:27,569 - Epoch: [316][  296/  296]    Overall Loss 0.691430    Objective Loss 0.691430    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.124096    
2024-04-23 21:37:27,724 - --- validate (epoch=316)-----------
2024-04-23 21:37:27,725 - 3925 samples (32 per mini-batch)
2024-04-23 21:37:44,442 - Epoch: [316][  100/  123]    Loss 0.662262    Top1 78.343750    Top5 97.406250    
2024-04-23 21:37:48,916 - Epoch: [316][  123/  123]    Loss 0.666900    Top1 78.471338    Top5 97.426752    
2024-04-23 21:37:49,102 - ==> Top1: 78.471    Top5: 97.427    Loss: 0.667

2024-04-23 21:37:49,110 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:37:49,110 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:37:49,158 - 

2024-04-23 21:37:49,158 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:38:03,298 - Epoch: [317][  100/  296]    Overall Loss 0.680397    Objective Loss 0.680397                                        LR 0.000005    Time 0.141241    
2024-04-23 21:38:20,707 - Epoch: [317][  200/  296]    Overall Loss 0.693449    Objective Loss 0.693449                                        LR 0.000005    Time 0.157583    
2024-04-23 21:38:37,077 - Epoch: [317][  296/  296]    Overall Loss 0.687878    Objective Loss 0.687878    Top1 90.163934    Top5 100.000000    LR 0.000005    Time 0.161728    
2024-04-23 21:38:37,440 - --- validate (epoch=317)-----------
2024-04-23 21:38:37,441 - 3925 samples (32 per mini-batch)
2024-04-23 21:38:53,268 - Epoch: [317][  100/  123]    Loss 0.672576    Top1 78.250000    Top5 97.375000    
2024-04-23 21:38:56,453 - Epoch: [317][  123/  123]    Loss 0.669764    Top1 78.318471    Top5 97.452229    
2024-04-23 21:38:56,616 - ==> Top1: 78.318    Top5: 97.452    Loss: 0.670

2024-04-23 21:38:56,627 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:38:56,628 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:38:56,674 - 

2024-04-23 21:38:56,675 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:39:12,141 - Epoch: [318][  100/  296]    Overall Loss 0.639700    Objective Loss 0.639700                                        LR 0.000005    Time 0.154480    
2024-04-23 21:39:23,637 - Epoch: [318][  200/  296]    Overall Loss 0.655649    Objective Loss 0.655649                                        LR 0.000005    Time 0.134644    
2024-04-23 21:39:38,017 - Epoch: [318][  296/  296]    Overall Loss 0.665125    Objective Loss 0.665125    Top1 72.131148    Top5 93.442623    LR 0.000005    Time 0.139505    
2024-04-23 21:39:38,194 - --- validate (epoch=318)-----------
2024-04-23 21:39:38,195 - 3925 samples (32 per mini-batch)
2024-04-23 21:39:56,249 - Epoch: [318][  100/  123]    Loss 0.667403    Top1 78.281250    Top5 97.156250    
2024-04-23 21:39:59,402 - Epoch: [318][  123/  123]    Loss 0.667759    Top1 78.242038    Top5 97.426752    
2024-04-23 21:39:59,580 - ==> Top1: 78.242    Top5: 97.427    Loss: 0.668

2024-04-23 21:39:59,592 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:39:59,592 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:39:59,642 - 

2024-04-23 21:39:59,643 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:40:16,116 - Epoch: [319][  100/  296]    Overall Loss 0.701617    Objective Loss 0.701617                                        LR 0.000005    Time 0.164555    
2024-04-23 21:40:31,407 - Epoch: [319][  200/  296]    Overall Loss 0.677913    Objective Loss 0.677913                                        LR 0.000005    Time 0.158644    
2024-04-23 21:40:43,904 - Epoch: [319][  296/  296]    Overall Loss 0.688180    Objective Loss 0.688180    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.149357    
2024-04-23 21:40:44,155 - --- validate (epoch=319)-----------
2024-04-23 21:40:44,156 - 3925 samples (32 per mini-batch)
2024-04-23 21:41:02,619 - Epoch: [319][  100/  123]    Loss 0.675219    Top1 78.281250    Top5 97.312500    
2024-04-23 21:41:06,025 - Epoch: [319][  123/  123]    Loss 0.672572    Top1 78.292994    Top5 97.375796    
2024-04-23 21:41:06,136 - ==> Top1: 78.293    Top5: 97.376    Loss: 0.673

2024-04-23 21:41:06,143 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:41:06,143 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:41:06,186 - 

2024-04-23 21:41:06,187 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:41:18,583 - Epoch: [320][  100/  296]    Overall Loss 0.676946    Objective Loss 0.676946                                        LR 0.000005    Time 0.123776    
2024-04-23 21:41:33,132 - Epoch: [320][  200/  296]    Overall Loss 0.691751    Objective Loss 0.691751                                        LR 0.000005    Time 0.134561    
2024-04-23 21:41:47,320 - Epoch: [320][  296/  296]    Overall Loss 0.695345    Objective Loss 0.695345    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.138806    
2024-04-23 21:41:47,550 - --- validate (epoch=320)-----------
2024-04-23 21:41:47,550 - 3925 samples (32 per mini-batch)
2024-04-23 21:42:00,504 - Epoch: [320][  100/  123]    Loss 0.660065    Top1 78.781250    Top5 97.531250    
2024-04-23 21:42:02,931 - Epoch: [320][  123/  123]    Loss 0.672880    Top1 78.165605    Top5 97.452229    
2024-04-23 21:42:03,106 - ==> Top1: 78.166    Top5: 97.452    Loss: 0.673

2024-04-23 21:42:03,115 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:42:03,115 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:42:03,165 - 

2024-04-23 21:42:03,165 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:42:16,640 - Epoch: [321][  100/  296]    Overall Loss 0.664935    Objective Loss 0.664935                                        LR 0.000005    Time 0.134577    
2024-04-23 21:42:32,013 - Epoch: [321][  200/  296]    Overall Loss 0.665775    Objective Loss 0.665775                                        LR 0.000005    Time 0.144063    
2024-04-23 21:42:44,505 - Epoch: [321][  296/  296]    Overall Loss 0.677799    Objective Loss 0.677799    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.139495    
2024-04-23 21:42:44,688 - --- validate (epoch=321)-----------
2024-04-23 21:42:44,689 - 3925 samples (32 per mini-batch)
2024-04-23 21:43:01,188 - Epoch: [321][  100/  123]    Loss 0.667404    Top1 78.250000    Top5 97.531250    
2024-04-23 21:43:03,942 - Epoch: [321][  123/  123]    Loss 0.671958    Top1 78.292994    Top5 97.375796    
2024-04-23 21:43:04,097 - ==> Top1: 78.293    Top5: 97.376    Loss: 0.672

2024-04-23 21:43:04,105 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:43:04,106 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:43:04,151 - 

2024-04-23 21:43:04,151 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:43:17,379 - Epoch: [322][  100/  296]    Overall Loss 0.698413    Objective Loss 0.698413                                        LR 0.000005    Time 0.132116    
2024-04-23 21:43:30,026 - Epoch: [322][  200/  296]    Overall Loss 0.678559    Objective Loss 0.678559                                        LR 0.000005    Time 0.129210    
2024-04-23 21:43:42,123 - Epoch: [322][  296/  296]    Overall Loss 0.665009    Objective Loss 0.665009    Top1 90.163934    Top5 100.000000    LR 0.000005    Time 0.128124    
2024-04-23 21:43:42,380 - --- validate (epoch=322)-----------
2024-04-23 21:43:42,381 - 3925 samples (32 per mini-batch)
2024-04-23 21:43:57,219 - Epoch: [322][  100/  123]    Loss 0.667055    Top1 78.406250    Top5 97.562500    
2024-04-23 21:44:00,156 - Epoch: [322][  123/  123]    Loss 0.666660    Top1 78.573248    Top5 97.426752    
2024-04-23 21:44:00,324 - ==> Top1: 78.573    Top5: 97.427    Loss: 0.667

2024-04-23 21:44:00,332 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:44:00,332 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:44:00,386 - 

2024-04-23 21:44:00,387 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:44:13,331 - Epoch: [323][  100/  296]    Overall Loss 0.679542    Objective Loss 0.679542                                        LR 0.000005    Time 0.129269    
2024-04-23 21:44:23,740 - Epoch: [323][  200/  296]    Overall Loss 0.687584    Objective Loss 0.687584                                        LR 0.000005    Time 0.116598    
2024-04-23 21:44:33,846 - Epoch: [323][  296/  296]    Overall Loss 0.691957    Objective Loss 0.691957    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.112877    
2024-04-23 21:44:34,036 - --- validate (epoch=323)-----------
2024-04-23 21:44:34,037 - 3925 samples (32 per mini-batch)
2024-04-23 21:44:50,087 - Epoch: [323][  100/  123]    Loss 0.662589    Top1 78.625000    Top5 97.500000    
2024-04-23 21:44:53,038 - Epoch: [323][  123/  123]    Loss 0.671732    Top1 78.471338    Top5 97.426752    
2024-04-23 21:44:53,267 - ==> Top1: 78.471    Top5: 97.427    Loss: 0.672

2024-04-23 21:44:53,277 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:44:53,277 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:44:53,345 - 

2024-04-23 21:44:53,346 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:45:09,163 - Epoch: [324][  100/  296]    Overall Loss 0.684634    Objective Loss 0.684634                                        LR 0.000005    Time 0.157965    
2024-04-23 21:45:23,392 - Epoch: [324][  200/  296]    Overall Loss 0.685671    Objective Loss 0.685671                                        LR 0.000005    Time 0.150046    
2024-04-23 21:45:37,826 - Epoch: [324][  296/  296]    Overall Loss 0.687455    Objective Loss 0.687455    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.150099    
2024-04-23 21:45:38,081 - --- validate (epoch=324)-----------
2024-04-23 21:45:38,082 - 3925 samples (32 per mini-batch)
2024-04-23 21:45:51,089 - Epoch: [324][  100/  123]    Loss 0.657589    Top1 79.062500    Top5 97.750000    
2024-04-23 21:45:53,492 - Epoch: [324][  123/  123]    Loss 0.669877    Top1 78.649682    Top5 97.426752    
2024-04-23 21:45:53,653 - ==> Top1: 78.650    Top5: 97.427    Loss: 0.670

2024-04-23 21:45:53,658 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:45:53,659 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:45:53,696 - 

2024-04-23 21:45:53,697 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:46:05,869 - Epoch: [325][  100/  296]    Overall Loss 0.690837    Objective Loss 0.690837                                        LR 0.000005    Time 0.121543    
2024-04-23 21:46:20,312 - Epoch: [325][  200/  296]    Overall Loss 0.691739    Objective Loss 0.691739                                        LR 0.000005    Time 0.132904    
2024-04-23 21:46:37,554 - Epoch: [325][  296/  296]    Overall Loss 0.678838    Objective Loss 0.678838    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.147992    
2024-04-23 21:46:37,757 - --- validate (epoch=325)-----------
2024-04-23 21:46:37,758 - 3925 samples (32 per mini-batch)
2024-04-23 21:46:55,241 - Epoch: [325][  100/  123]    Loss 0.674758    Top1 78.187500    Top5 97.687500    
2024-04-23 21:46:58,884 - Epoch: [325][  123/  123]    Loss 0.672181    Top1 78.267516    Top5 97.426752    
2024-04-23 21:46:59,064 - ==> Top1: 78.268    Top5: 97.427    Loss: 0.672

2024-04-23 21:46:59,072 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:46:59,073 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:46:59,118 - 

2024-04-23 21:46:59,119 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:47:15,111 - Epoch: [326][  100/  296]    Overall Loss 0.666841    Objective Loss 0.666841                                        LR 0.000005    Time 0.159765    
2024-04-23 21:47:28,443 - Epoch: [326][  200/  296]    Overall Loss 0.689319    Objective Loss 0.689319                                        LR 0.000005    Time 0.146464    
2024-04-23 21:47:40,373 - Epoch: [326][  296/  296]    Overall Loss 0.685801    Objective Loss 0.685801    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.139216    
2024-04-23 21:47:40,565 - --- validate (epoch=326)-----------
2024-04-23 21:47:40,566 - 3925 samples (32 per mini-batch)
2024-04-23 21:47:57,098 - Epoch: [326][  100/  123]    Loss 0.665058    Top1 78.437500    Top5 97.375000    
2024-04-23 21:48:00,506 - Epoch: [326][  123/  123]    Loss 0.670073    Top1 78.267516    Top5 97.375796    
2024-04-23 21:48:00,830 - ==> Top1: 78.268    Top5: 97.376    Loss: 0.670

2024-04-23 21:48:00,840 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:48:00,841 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:48:00,884 - 

2024-04-23 21:48:00,884 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:48:16,219 - Epoch: [327][  100/  296]    Overall Loss 0.660174    Objective Loss 0.660174                                        LR 0.000005    Time 0.153166    
2024-04-23 21:48:29,460 - Epoch: [327][  200/  296]    Overall Loss 0.669453    Objective Loss 0.669453                                        LR 0.000005    Time 0.142709    
2024-04-23 21:48:42,772 - Epoch: [327][  296/  296]    Overall Loss 0.670083    Objective Loss 0.670083    Top1 86.885246    Top5 96.721311    LR 0.000005    Time 0.141345    
2024-04-23 21:48:43,141 - --- validate (epoch=327)-----------
2024-04-23 21:48:43,142 - 3925 samples (32 per mini-batch)
2024-04-23 21:49:01,658 - Epoch: [327][  100/  123]    Loss 0.675625    Top1 78.093750    Top5 97.531250    
2024-04-23 21:49:04,851 - Epoch: [327][  123/  123]    Loss 0.670227    Top1 78.547771    Top5 97.452229    
2024-04-23 21:49:05,100 - ==> Top1: 78.548    Top5: 97.452    Loss: 0.670

2024-04-23 21:49:05,111 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:49:05,112 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:49:05,160 - 

2024-04-23 21:49:05,161 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:49:21,365 - Epoch: [328][  100/  296]    Overall Loss 0.674118    Objective Loss 0.674118                                        LR 0.000005    Time 0.161860    
2024-04-23 21:49:36,319 - Epoch: [328][  200/  296]    Overall Loss 0.664211    Objective Loss 0.664211                                        LR 0.000005    Time 0.155624    
2024-04-23 21:49:51,664 - Epoch: [328][  296/  296]    Overall Loss 0.670549    Objective Loss 0.670549    Top1 85.245902    Top5 93.442623    LR 0.000005    Time 0.156940    
2024-04-23 21:49:51,843 - --- validate (epoch=328)-----------
2024-04-23 21:49:51,844 - 3925 samples (32 per mini-batch)
2024-04-23 21:50:08,920 - Epoch: [328][  100/  123]    Loss 0.690040    Top1 77.968750    Top5 96.968750    
2024-04-23 21:50:12,278 - Epoch: [328][  123/  123]    Loss 0.672276    Top1 78.343949    Top5 97.248408    
2024-04-23 21:50:12,478 - ==> Top1: 78.344    Top5: 97.248    Loss: 0.672

2024-04-23 21:50:12,488 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:50:12,489 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:50:12,535 - 

2024-04-23 21:50:12,536 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:50:26,288 - Epoch: [329][  100/  296]    Overall Loss 0.664294    Objective Loss 0.664294                                        LR 0.000005    Time 0.137345    
2024-04-23 21:50:39,637 - Epoch: [329][  200/  296]    Overall Loss 0.671750    Objective Loss 0.671750                                        LR 0.000005    Time 0.135333    
2024-04-23 21:50:52,114 - Epoch: [329][  296/  296]    Overall Loss 0.676980    Objective Loss 0.676980    Top1 62.295082    Top5 95.081967    LR 0.000005    Time 0.133546    
2024-04-23 21:50:52,355 - --- validate (epoch=329)-----------
2024-04-23 21:50:52,356 - 3925 samples (32 per mini-batch)
2024-04-23 21:51:08,100 - Epoch: [329][  100/  123]    Loss 0.669831    Top1 78.218750    Top5 97.250000    
2024-04-23 21:51:11,905 - Epoch: [329][  123/  123]    Loss 0.669306    Top1 78.394904    Top5 97.299363    
2024-04-23 21:51:12,145 - ==> Top1: 78.395    Top5: 97.299    Loss: 0.669

2024-04-23 21:51:12,156 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:51:12,157 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:51:12,207 - 

2024-04-23 21:51:12,207 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:51:28,894 - Epoch: [330][  100/  296]    Overall Loss 0.680441    Objective Loss 0.680441                                        LR 0.000005    Time 0.166703    
2024-04-23 21:51:44,036 - Epoch: [330][  200/  296]    Overall Loss 0.669992    Objective Loss 0.669992                                        LR 0.000005    Time 0.158976    
2024-04-23 21:51:56,994 - Epoch: [330][  296/  296]    Overall Loss 0.671681    Objective Loss 0.671681    Top1 67.213115    Top5 98.360656    LR 0.000005    Time 0.151144    
2024-04-23 21:51:57,239 - --- validate (epoch=330)-----------
2024-04-23 21:51:57,240 - 3925 samples (32 per mini-batch)
2024-04-23 21:52:14,620 - Epoch: [330][  100/  123]    Loss 0.664112    Top1 78.343750    Top5 97.437500    
2024-04-23 21:52:17,929 - Epoch: [330][  123/  123]    Loss 0.668490    Top1 78.394904    Top5 97.350318    
2024-04-23 21:52:18,162 - ==> Top1: 78.395    Top5: 97.350    Loss: 0.668

2024-04-23 21:52:18,173 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:52:18,173 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:52:18,225 - 

2024-04-23 21:52:18,226 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:52:33,685 - Epoch: [331][  100/  296]    Overall Loss 0.689043    Objective Loss 0.689043                                        LR 0.000005    Time 0.154428    
2024-04-23 21:52:47,749 - Epoch: [331][  200/  296]    Overall Loss 0.686091    Objective Loss 0.686091                                        LR 0.000005    Time 0.147455    
2024-04-23 21:53:00,858 - Epoch: [331][  296/  296]    Overall Loss 0.689256    Objective Loss 0.689256    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.143862    
2024-04-23 21:53:01,087 - --- validate (epoch=331)-----------
2024-04-23 21:53:01,088 - 3925 samples (32 per mini-batch)
2024-04-23 21:53:16,807 - Epoch: [331][  100/  123]    Loss 0.669034    Top1 78.656250    Top5 97.468750    
2024-04-23 21:53:20,686 - Epoch: [331][  123/  123]    Loss 0.672008    Top1 78.242038    Top5 97.452229    
2024-04-23 21:53:20,943 - ==> Top1: 78.242    Top5: 97.452    Loss: 0.672

2024-04-23 21:53:20,952 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:53:20,952 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:53:21,012 - 

2024-04-23 21:53:21,014 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:53:35,445 - Epoch: [332][  100/  296]    Overall Loss 0.685406    Objective Loss 0.685406                                        LR 0.000005    Time 0.144129    
2024-04-23 21:53:49,737 - Epoch: [332][  200/  296]    Overall Loss 0.682140    Objective Loss 0.682140                                        LR 0.000005    Time 0.143442    
2024-04-23 21:54:02,579 - Epoch: [332][  296/  296]    Overall Loss 0.684011    Objective Loss 0.684011    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.140260    
2024-04-23 21:54:02,763 - --- validate (epoch=332)-----------
2024-04-23 21:54:02,764 - 3925 samples (32 per mini-batch)
2024-04-23 21:54:19,682 - Epoch: [332][  100/  123]    Loss 0.672571    Top1 78.218750    Top5 97.437500    
2024-04-23 21:54:22,963 - Epoch: [332][  123/  123]    Loss 0.667028    Top1 78.369427    Top5 97.452229    
2024-04-23 21:54:23,260 - ==> Top1: 78.369    Top5: 97.452    Loss: 0.667

2024-04-23 21:54:23,269 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:54:23,270 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:54:23,312 - 

2024-04-23 21:54:23,313 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:54:38,088 - Epoch: [333][  100/  296]    Overall Loss 0.649254    Objective Loss 0.649254                                        LR 0.000005    Time 0.147582    
2024-04-23 21:54:52,752 - Epoch: [333][  200/  296]    Overall Loss 0.662332    Objective Loss 0.662332                                        LR 0.000005    Time 0.147039    
2024-04-23 21:55:07,505 - Epoch: [333][  296/  296]    Overall Loss 0.673383    Objective Loss 0.673383    Top1 68.852459    Top5 100.000000    LR 0.000005    Time 0.149151    
2024-04-23 21:55:07,742 - --- validate (epoch=333)-----------
2024-04-23 21:55:07,743 - 3925 samples (32 per mini-batch)
2024-04-23 21:55:20,465 - Epoch: [333][  100/  123]    Loss 0.657721    Top1 78.468750    Top5 97.468750    
2024-04-23 21:55:23,478 - Epoch: [333][  123/  123]    Loss 0.671056    Top1 78.242038    Top5 97.426752    
2024-04-23 21:55:23,746 - ==> Top1: 78.242    Top5: 97.427    Loss: 0.671

2024-04-23 21:55:23,756 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:55:23,757 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:55:23,800 - 

2024-04-23 21:55:23,801 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:55:36,469 - Epoch: [334][  100/  296]    Overall Loss 0.662534    Objective Loss 0.662534                                        LR 0.000005    Time 0.126509    
2024-04-23 21:55:49,773 - Epoch: [334][  200/  296]    Overall Loss 0.655312    Objective Loss 0.655312                                        LR 0.000005    Time 0.129692    
2024-04-23 21:56:03,397 - Epoch: [334][  296/  296]    Overall Loss 0.671202    Objective Loss 0.671202    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.133608    
2024-04-23 21:56:03,630 - --- validate (epoch=334)-----------
2024-04-23 21:56:03,631 - 3925 samples (32 per mini-batch)
2024-04-23 21:56:21,296 - Epoch: [334][  100/  123]    Loss 0.658328    Top1 78.312500    Top5 97.750000    
2024-04-23 21:56:24,859 - Epoch: [334][  123/  123]    Loss 0.667470    Top1 78.140127    Top5 97.554140    
2024-04-23 21:56:25,047 - ==> Top1: 78.140    Top5: 97.554    Loss: 0.667

2024-04-23 21:56:25,056 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:56:25,057 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:56:25,098 - 

2024-04-23 21:56:25,098 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:56:35,991 - Epoch: [335][  100/  296]    Overall Loss 0.671376    Objective Loss 0.671376                                        LR 0.000005    Time 0.108761    
2024-04-23 21:56:47,124 - Epoch: [335][  200/  296]    Overall Loss 0.681361    Objective Loss 0.681361                                        LR 0.000005    Time 0.109967    
2024-04-23 21:57:01,147 - Epoch: [335][  296/  296]    Overall Loss 0.680829    Objective Loss 0.680829    Top1 86.885246    Top5 100.000000    LR 0.000005    Time 0.121616    
2024-04-23 21:57:01,359 - --- validate (epoch=335)-----------
2024-04-23 21:57:01,361 - 3925 samples (32 per mini-batch)
2024-04-23 21:57:16,582 - Epoch: [335][  100/  123]    Loss 0.680845    Top1 77.562500    Top5 97.093750    
2024-04-23 21:57:18,492 - Epoch: [335][  123/  123]    Loss 0.670390    Top1 78.063694    Top5 97.324841    
2024-04-23 21:57:18,681 - ==> Top1: 78.064    Top5: 97.325    Loss: 0.670

2024-04-23 21:57:18,689 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:57:18,690 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:57:18,728 - 

2024-04-23 21:57:18,729 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:57:30,658 - Epoch: [336][  100/  296]    Overall Loss 0.686288    Objective Loss 0.686288                                        LR 0.000005    Time 0.119136    
2024-04-23 21:57:46,652 - Epoch: [336][  200/  296]    Overall Loss 0.682028    Objective Loss 0.682028                                        LR 0.000005    Time 0.139459    
2024-04-23 21:58:00,301 - Epoch: [336][  296/  296]    Overall Loss 0.684256    Objective Loss 0.684256    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.140287    
2024-04-23 21:58:00,513 - --- validate (epoch=336)-----------
2024-04-23 21:58:00,515 - 3925 samples (32 per mini-batch)
2024-04-23 21:58:18,997 - Epoch: [336][  100/  123]    Loss 0.675192    Top1 78.312500    Top5 97.156250    
2024-04-23 21:58:22,908 - Epoch: [336][  123/  123]    Loss 0.672843    Top1 78.445860    Top5 97.350318    
2024-04-23 21:58:23,048 - ==> Top1: 78.446    Top5: 97.350    Loss: 0.673

2024-04-23 21:58:23,057 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:58:23,057 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:58:23,097 - 

2024-04-23 21:58:23,098 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:58:39,212 - Epoch: [337][  100/  296]    Overall Loss 0.689292    Objective Loss 0.689292                                        LR 0.000005    Time 0.160980    
2024-04-23 21:58:53,016 - Epoch: [337][  200/  296]    Overall Loss 0.683083    Objective Loss 0.683083                                        LR 0.000005    Time 0.149423    
2024-04-23 21:59:05,458 - Epoch: [337][  296/  296]    Overall Loss 0.666824    Objective Loss 0.666824    Top1 68.852459    Top5 95.081967    LR 0.000005    Time 0.142950    
2024-04-23 21:59:05,781 - --- validate (epoch=337)-----------
2024-04-23 21:59:05,782 - 3925 samples (32 per mini-batch)
2024-04-23 21:59:21,692 - Epoch: [337][  100/  123]    Loss 0.659570    Top1 78.718750    Top5 97.406250    
2024-04-23 21:59:23,823 - Epoch: [337][  123/  123]    Loss 0.669738    Top1 78.445860    Top5 97.350318    
2024-04-23 21:59:24,036 - ==> Top1: 78.446    Top5: 97.350    Loss: 0.670

2024-04-23 21:59:24,044 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 21:59:24,044 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 21:59:24,077 - 

2024-04-23 21:59:24,077 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:59:33,027 - Epoch: [338][  100/  296]    Overall Loss 0.675035    Objective Loss 0.675035                                        LR 0.000005    Time 0.089347    
2024-04-23 21:59:40,139 - Epoch: [338][  200/  296]    Overall Loss 0.687249    Objective Loss 0.687249                                        LR 0.000005    Time 0.080159    
2024-04-23 21:59:47,807 - Epoch: [338][  296/  296]    Overall Loss 0.684794    Objective Loss 0.684794    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.080022    
2024-04-23 21:59:47,979 - --- validate (epoch=338)-----------
2024-04-23 21:59:47,979 - 3925 samples (32 per mini-batch)
2024-04-23 22:00:01,923 - Epoch: [338][  100/  123]    Loss 0.671271    Top1 78.531250    Top5 96.937500    
2024-04-23 22:00:04,475 - Epoch: [338][  123/  123]    Loss 0.673531    Top1 78.343949    Top5 97.121019    
2024-04-23 22:00:04,698 - ==> Top1: 78.344    Top5: 97.121    Loss: 0.674

2024-04-23 22:00:04,704 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:00:04,705 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:00:04,737 - 

2024-04-23 22:00:04,737 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:00:15,971 - Epoch: [339][  100/  296]    Overall Loss 0.670298    Objective Loss 0.670298                                        LR 0.000005    Time 0.112176    
2024-04-23 22:00:32,567 - Epoch: [339][  200/  296]    Overall Loss 0.676723    Objective Loss 0.676723                                        LR 0.000005    Time 0.138990    
2024-04-23 22:00:47,568 - Epoch: [339][  296/  296]    Overall Loss 0.678829    Objective Loss 0.678829    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.144539    
2024-04-23 22:00:47,725 - --- validate (epoch=339)-----------
2024-04-23 22:00:47,725 - 3925 samples (32 per mini-batch)
2024-04-23 22:00:59,924 - Epoch: [339][  100/  123]    Loss 0.659771    Top1 79.281250    Top5 97.156250    
2024-04-23 22:01:01,843 - Epoch: [339][  123/  123]    Loss 0.670744    Top1 78.573248    Top5 97.350318    
2024-04-23 22:01:02,012 - ==> Top1: 78.573    Top5: 97.350    Loss: 0.671

2024-04-23 22:01:02,020 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:01:02,020 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:01:02,059 - 

2024-04-23 22:01:02,060 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:01:13,611 - Epoch: [340][  100/  296]    Overall Loss 0.696225    Objective Loss 0.696225                                        LR 0.000005    Time 0.115335    
2024-04-23 22:01:25,455 - Epoch: [340][  200/  296]    Overall Loss 0.679189    Objective Loss 0.679189                                        LR 0.000005    Time 0.116806    
2024-04-23 22:01:36,543 - Epoch: [340][  296/  296]    Overall Loss 0.685585    Objective Loss 0.685585    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.116330    
2024-04-23 22:01:36,750 - --- validate (epoch=340)-----------
2024-04-23 22:01:36,751 - 3925 samples (32 per mini-batch)
2024-04-23 22:01:51,555 - Epoch: [340][  100/  123]    Loss 0.659018    Top1 78.468750    Top5 97.468750    
2024-04-23 22:01:54,742 - Epoch: [340][  123/  123]    Loss 0.670225    Top1 78.140127    Top5 97.477707    
2024-04-23 22:01:54,940 - ==> Top1: 78.140    Top5: 97.478    Loss: 0.670

2024-04-23 22:01:54,950 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:01:54,951 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:01:54,996 - 

2024-04-23 22:01:54,997 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:02:09,788 - Epoch: [341][  100/  296]    Overall Loss 0.684460    Objective Loss 0.684460                                        LR 0.000005    Time 0.147748    
2024-04-23 22:02:24,644 - Epoch: [341][  200/  296]    Overall Loss 0.690744    Objective Loss 0.690744                                        LR 0.000005    Time 0.148068    
2024-04-23 22:02:38,609 - Epoch: [341][  296/  296]    Overall Loss 0.680763    Objective Loss 0.680763    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.147173    
2024-04-23 22:02:38,786 - --- validate (epoch=341)-----------
2024-04-23 22:02:38,787 - 3925 samples (32 per mini-batch)
2024-04-23 22:02:55,144 - Epoch: [341][  100/  123]    Loss 0.667824    Top1 78.625000    Top5 97.468750    
2024-04-23 22:02:59,188 - Epoch: [341][  123/  123]    Loss 0.671570    Top1 78.649682    Top5 97.375796    
2024-04-23 22:02:59,423 - ==> Top1: 78.650    Top5: 97.376    Loss: 0.672

2024-04-23 22:02:59,433 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:02:59,433 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:02:59,486 - 

2024-04-23 22:02:59,487 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:03:14,527 - Epoch: [342][  100/  296]    Overall Loss 0.669971    Objective Loss 0.669971                                        LR 0.000005    Time 0.150228    
2024-04-23 22:03:28,006 - Epoch: [342][  200/  296]    Overall Loss 0.669161    Objective Loss 0.669161                                        LR 0.000005    Time 0.142434    
2024-04-23 22:03:40,628 - Epoch: [342][  296/  296]    Overall Loss 0.670639    Objective Loss 0.670639    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.138837    
2024-04-23 22:03:40,850 - --- validate (epoch=342)-----------
2024-04-23 22:03:40,851 - 3925 samples (32 per mini-batch)
2024-04-23 22:03:56,307 - Epoch: [342][  100/  123]    Loss 0.660992    Top1 78.812500    Top5 97.343750    
2024-04-23 22:03:58,141 - Epoch: [342][  123/  123]    Loss 0.669781    Top1 78.369427    Top5 97.350318    
2024-04-23 22:03:58,307 - ==> Top1: 78.369    Top5: 97.350    Loss: 0.670

2024-04-23 22:03:58,316 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:03:58,316 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:03:58,357 - 

2024-04-23 22:03:58,357 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:04:13,898 - Epoch: [343][  100/  296]    Overall Loss 0.676788    Objective Loss 0.676788                                        LR 0.000005    Time 0.155230    
2024-04-23 22:04:28,257 - Epoch: [343][  200/  296]    Overall Loss 0.684210    Objective Loss 0.684210                                        LR 0.000005    Time 0.149336    
2024-04-23 22:04:40,524 - Epoch: [343][  296/  296]    Overall Loss 0.679805    Objective Loss 0.679805    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.142295    
2024-04-23 22:04:40,756 - --- validate (epoch=343)-----------
2024-04-23 22:04:40,758 - 3925 samples (32 per mini-batch)
2024-04-23 22:04:59,176 - Epoch: [343][  100/  123]    Loss 0.667663    Top1 78.406250    Top5 97.656250    
2024-04-23 22:05:02,762 - Epoch: [343][  123/  123]    Loss 0.668721    Top1 78.394904    Top5 97.375796    
2024-04-23 22:05:02,944 - ==> Top1: 78.395    Top5: 97.376    Loss: 0.669

2024-04-23 22:05:02,957 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:05:02,958 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:05:03,009 - 

2024-04-23 22:05:03,009 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:05:18,161 - Epoch: [344][  100/  296]    Overall Loss 0.669387    Objective Loss 0.669387                                        LR 0.000005    Time 0.151325    
2024-04-23 22:05:31,521 - Epoch: [344][  200/  296]    Overall Loss 0.687813    Objective Loss 0.687813                                        LR 0.000005    Time 0.142379    
2024-04-23 22:05:43,661 - Epoch: [344][  296/  296]    Overall Loss 0.690151    Objective Loss 0.690151    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.137164    
2024-04-23 22:05:43,899 - --- validate (epoch=344)-----------
2024-04-23 22:05:43,900 - 3925 samples (32 per mini-batch)
2024-04-23 22:06:01,018 - Epoch: [344][  100/  123]    Loss 0.657440    Top1 78.937500    Top5 97.625000    
2024-04-23 22:06:05,203 - Epoch: [344][  123/  123]    Loss 0.665755    Top1 78.496815    Top5 97.477707    
2024-04-23 22:06:05,383 - ==> Top1: 78.497    Top5: 97.478    Loss: 0.666

2024-04-23 22:06:05,392 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:06:05,392 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:06:05,431 - 

2024-04-23 22:06:05,431 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:06:21,724 - Epoch: [345][  100/  296]    Overall Loss 0.711495    Objective Loss 0.711495                                        LR 0.000005    Time 0.162765    
2024-04-23 22:06:35,595 - Epoch: [345][  200/  296]    Overall Loss 0.695657    Objective Loss 0.695657                                        LR 0.000005    Time 0.150656    
2024-04-23 22:06:48,139 - Epoch: [345][  296/  296]    Overall Loss 0.687687    Objective Loss 0.687687    Top1 86.885246    Top5 100.000000    LR 0.000005    Time 0.144125    
2024-04-23 22:06:48,379 - --- validate (epoch=345)-----------
2024-04-23 22:06:48,380 - 3925 samples (32 per mini-batch)
2024-04-23 22:07:04,004 - Epoch: [345][  100/  123]    Loss 0.663842    Top1 78.812500    Top5 97.531250    
2024-04-23 22:07:07,150 - Epoch: [345][  123/  123]    Loss 0.668850    Top1 78.624204    Top5 97.401274    
2024-04-23 22:07:07,351 - ==> Top1: 78.624    Top5: 97.401    Loss: 0.669

2024-04-23 22:07:07,361 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:07:07,362 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:07:07,411 - 

2024-04-23 22:07:07,412 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:07:23,248 - Epoch: [346][  100/  296]    Overall Loss 0.672729    Objective Loss 0.672729                                        LR 0.000005    Time 0.158163    
2024-04-23 22:07:30,688 - Epoch: [346][  200/  296]    Overall Loss 0.679777    Objective Loss 0.679777                                        LR 0.000005    Time 0.116203    
2024-04-23 22:07:42,866 - Epoch: [346][  296/  296]    Overall Loss 0.686884    Objective Loss 0.686884    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.119611    
2024-04-23 22:07:43,089 - --- validate (epoch=346)-----------
2024-04-23 22:07:43,089 - 3925 samples (32 per mini-batch)
2024-04-23 22:07:59,484 - Epoch: [346][  100/  123]    Loss 0.670793    Top1 78.218750    Top5 97.437500    
2024-04-23 22:08:02,685 - Epoch: [346][  123/  123]    Loss 0.670274    Top1 78.471338    Top5 97.452229    
2024-04-23 22:08:02,897 - ==> Top1: 78.471    Top5: 97.452    Loss: 0.670

2024-04-23 22:08:02,905 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:08:02,905 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:08:02,949 - 

2024-04-23 22:08:02,950 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:08:15,017 - Epoch: [347][  100/  296]    Overall Loss 0.676482    Objective Loss 0.676482                                        LR 0.000005    Time 0.120514    
2024-04-23 22:08:26,378 - Epoch: [347][  200/  296]    Overall Loss 0.669528    Objective Loss 0.669528                                        LR 0.000005    Time 0.116979    
2024-04-23 22:08:39,946 - Epoch: [347][  296/  296]    Overall Loss 0.672180    Objective Loss 0.672180    Top1 68.852459    Top5 98.360656    LR 0.000005    Time 0.124825    
2024-04-23 22:08:40,189 - --- validate (epoch=347)-----------
2024-04-23 22:08:40,190 - 3925 samples (32 per mini-batch)
2024-04-23 22:08:56,952 - Epoch: [347][  100/  123]    Loss 0.675418    Top1 78.187500    Top5 97.250000    
2024-04-23 22:08:59,914 - Epoch: [347][  123/  123]    Loss 0.673128    Top1 78.394904    Top5 97.324841    
2024-04-23 22:09:00,201 - ==> Top1: 78.395    Top5: 97.325    Loss: 0.673

2024-04-23 22:09:00,210 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:09:00,211 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:09:00,256 - 

2024-04-23 22:09:00,257 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:09:17,545 - Epoch: [348][  100/  296]    Overall Loss 0.677031    Objective Loss 0.677031                                        LR 0.000005    Time 0.172711    
2024-04-23 22:09:31,593 - Epoch: [348][  200/  296]    Overall Loss 0.684551    Objective Loss 0.684551                                        LR 0.000005    Time 0.156516    
2024-04-23 22:09:48,144 - Epoch: [348][  296/  296]    Overall Loss 0.690790    Objective Loss 0.690790    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.161624    
2024-04-23 22:09:48,439 - --- validate (epoch=348)-----------
2024-04-23 22:09:48,440 - 3925 samples (32 per mini-batch)
2024-04-23 22:10:06,195 - Epoch: [348][  100/  123]    Loss 0.676792    Top1 78.343750    Top5 97.031250    
2024-04-23 22:10:09,695 - Epoch: [348][  123/  123]    Loss 0.671485    Top1 78.471338    Top5 97.248408    
2024-04-23 22:10:09,894 - ==> Top1: 78.471    Top5: 97.248    Loss: 0.671

2024-04-23 22:10:09,901 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:10:09,902 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:10:09,943 - 

2024-04-23 22:10:09,943 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:10:22,936 - Epoch: [349][  100/  296]    Overall Loss 0.661448    Objective Loss 0.661448                                        LR 0.000005    Time 0.129769    
2024-04-23 22:10:33,115 - Epoch: [349][  200/  296]    Overall Loss 0.652700    Objective Loss 0.652700                                        LR 0.000005    Time 0.115703    
2024-04-23 22:10:41,870 - Epoch: [349][  296/  296]    Overall Loss 0.672711    Objective Loss 0.672711    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.107707    
2024-04-23 22:10:42,085 - --- validate (epoch=349)-----------
2024-04-23 22:10:42,086 - 3925 samples (32 per mini-batch)
2024-04-23 22:10:52,184 - Epoch: [349][  100/  123]    Loss 0.666705    Top1 78.593750    Top5 97.468750    
2024-04-23 22:10:54,032 - Epoch: [349][  123/  123]    Loss 0.670150    Top1 78.420382    Top5 97.375796    
2024-04-23 22:10:54,172 - ==> Top1: 78.420    Top5: 97.376    Loss: 0.670

2024-04-23 22:10:54,180 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:10:54,181 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:10:54,216 - 

2024-04-23 22:10:54,216 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:11:08,191 - Epoch: [350][  100/  296]    Overall Loss 0.670537    Objective Loss 0.670537                                        LR 0.000005    Time 0.139576    
2024-04-23 22:11:19,724 - Epoch: [350][  200/  296]    Overall Loss 0.665512    Objective Loss 0.665512                                        LR 0.000005    Time 0.127365    
2024-04-23 22:11:30,502 - Epoch: [350][  296/  296]    Overall Loss 0.678093    Objective Loss 0.678093    Top1 67.213115    Top5 98.360656    LR 0.000005    Time 0.122419    
2024-04-23 22:11:30,702 - --- validate (epoch=350)-----------
2024-04-23 22:11:30,703 - 3925 samples (32 per mini-batch)
2024-04-23 22:11:43,600 - Epoch: [350][  100/  123]    Loss 0.672143    Top1 78.281250    Top5 97.312500    
2024-04-23 22:11:48,244 - Epoch: [350][  123/  123]    Loss 0.670165    Top1 78.496815    Top5 97.452229    
2024-04-23 22:11:48,386 - ==> Top1: 78.497    Top5: 97.452    Loss: 0.670

2024-04-23 22:11:48,391 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:11:48,391 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:11:48,432 - 

2024-04-23 22:11:48,433 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:12:04,781 - Epoch: [351][  100/  296]    Overall Loss 0.708166    Objective Loss 0.708166                                        LR 0.000005    Time 0.163326    
2024-04-23 22:12:20,280 - Epoch: [351][  200/  296]    Overall Loss 0.711851    Objective Loss 0.711851                                        LR 0.000005    Time 0.159083    
2024-04-23 22:12:33,012 - Epoch: [351][  296/  296]    Overall Loss 0.699098    Objective Loss 0.699098    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.150453    
2024-04-23 22:12:33,187 - --- validate (epoch=351)-----------
2024-04-23 22:12:33,188 - 3925 samples (32 per mini-batch)
2024-04-23 22:12:50,086 - Epoch: [351][  100/  123]    Loss 0.663762    Top1 78.437500    Top5 97.468750    
2024-04-23 22:12:53,439 - Epoch: [351][  123/  123]    Loss 0.668706    Top1 78.267516    Top5 97.375796    
2024-04-23 22:12:53,594 - ==> Top1: 78.268    Top5: 97.376    Loss: 0.669

2024-04-23 22:12:53,605 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:12:53,605 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:12:53,649 - 

2024-04-23 22:12:53,650 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:13:09,534 - Epoch: [352][  100/  296]    Overall Loss 0.720697    Objective Loss 0.720697                                        LR 0.000005    Time 0.158680    
2024-04-23 22:13:22,393 - Epoch: [352][  200/  296]    Overall Loss 0.708568    Objective Loss 0.708568                                        LR 0.000005    Time 0.143553    
2024-04-23 22:13:34,418 - Epoch: [352][  296/  296]    Overall Loss 0.688984    Objective Loss 0.688984    Top1 65.573770    Top5 98.360656    LR 0.000005    Time 0.137572    
2024-04-23 22:13:34,600 - --- validate (epoch=352)-----------
2024-04-23 22:13:34,601 - 3925 samples (32 per mini-batch)
2024-04-23 22:13:46,778 - Epoch: [352][  100/  123]    Loss 0.673029    Top1 77.968750    Top5 97.500000    
2024-04-23 22:13:49,090 - Epoch: [352][  123/  123]    Loss 0.668958    Top1 78.292994    Top5 97.375796    
2024-04-23 22:13:49,314 - ==> Top1: 78.293    Top5: 97.376    Loss: 0.669

2024-04-23 22:13:49,322 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:13:49,323 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:13:49,364 - 

2024-04-23 22:13:49,365 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:14:02,913 - Epoch: [353][  100/  296]    Overall Loss 0.672532    Objective Loss 0.672532                                        LR 0.000005    Time 0.135295    
2024-04-23 22:14:16,389 - Epoch: [353][  200/  296]    Overall Loss 0.676229    Objective Loss 0.676229                                        LR 0.000005    Time 0.134938    
2024-04-23 22:14:26,851 - Epoch: [353][  296/  296]    Overall Loss 0.677483    Objective Loss 0.677483    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.126470    
2024-04-23 22:14:26,994 - --- validate (epoch=353)-----------
2024-04-23 22:14:26,995 - 3925 samples (32 per mini-batch)
2024-04-23 22:14:40,622 - Epoch: [353][  100/  123]    Loss 0.672204    Top1 78.343750    Top5 97.437500    
2024-04-23 22:14:42,794 - Epoch: [353][  123/  123]    Loss 0.667588    Top1 78.496815    Top5 97.528662    
2024-04-23 22:14:43,084 - ==> Top1: 78.497    Top5: 97.529    Loss: 0.668

2024-04-23 22:14:43,093 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:14:43,094 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:14:43,133 - 

2024-04-23 22:14:43,134 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:14:55,406 - Epoch: [354][  100/  296]    Overall Loss 0.693398    Objective Loss 0.693398                                        LR 0.000005    Time 0.122542    
2024-04-23 22:15:03,510 - Epoch: [354][  200/  296]    Overall Loss 0.686611    Objective Loss 0.686611                                        LR 0.000005    Time 0.101721    
2024-04-23 22:15:11,713 - Epoch: [354][  296/  296]    Overall Loss 0.688752    Objective Loss 0.688752    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.096389    
2024-04-23 22:15:11,918 - --- validate (epoch=354)-----------
2024-04-23 22:15:11,919 - 3925 samples (32 per mini-batch)
2024-04-23 22:15:22,998 - Epoch: [354][  100/  123]    Loss 0.672090    Top1 78.281250    Top5 97.250000    
2024-04-23 22:15:25,878 - Epoch: [354][  123/  123]    Loss 0.669492    Top1 78.292994    Top5 97.452229    
2024-04-23 22:15:26,081 - ==> Top1: 78.293    Top5: 97.452    Loss: 0.669

2024-04-23 22:15:26,091 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:15:26,092 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:15:26,128 - 

2024-04-23 22:15:26,128 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:15:42,036 - Epoch: [355][  100/  296]    Overall Loss 0.686845    Objective Loss 0.686845                                        LR 0.000005    Time 0.158909    
2024-04-23 22:15:54,961 - Epoch: [355][  200/  296]    Overall Loss 0.685714    Objective Loss 0.685714                                        LR 0.000005    Time 0.144003    
2024-04-23 22:16:07,275 - Epoch: [355][  296/  296]    Overall Loss 0.674399    Objective Loss 0.674399    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.138847    
2024-04-23 22:16:07,492 - --- validate (epoch=355)-----------
2024-04-23 22:16:07,493 - 3925 samples (32 per mini-batch)
2024-04-23 22:16:24,520 - Epoch: [355][  100/  123]    Loss 0.675964    Top1 78.156250    Top5 97.343750    
2024-04-23 22:16:27,735 - Epoch: [355][  123/  123]    Loss 0.670763    Top1 78.394904    Top5 97.248408    
2024-04-23 22:16:27,910 - ==> Top1: 78.395    Top5: 97.248    Loss: 0.671

2024-04-23 22:16:27,917 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:16:27,917 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:16:27,959 - 

2024-04-23 22:16:27,960 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:16:43,022 - Epoch: [356][  100/  296]    Overall Loss 0.683001    Objective Loss 0.683001                                        LR 0.000005    Time 0.150470    
2024-04-23 22:16:55,505 - Epoch: [356][  200/  296]    Overall Loss 0.674537    Objective Loss 0.674537                                        LR 0.000005    Time 0.137590    
2024-04-23 22:17:03,994 - Epoch: [356][  296/  296]    Overall Loss 0.682317    Objective Loss 0.682317    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.121594    
2024-04-23 22:17:04,154 - --- validate (epoch=356)-----------
2024-04-23 22:17:04,155 - 3925 samples (32 per mini-batch)
2024-04-23 22:17:21,391 - Epoch: [356][  100/  123]    Loss 0.689144    Top1 77.593750    Top5 97.062500    
2024-04-23 22:17:24,681 - Epoch: [356][  123/  123]    Loss 0.672843    Top1 78.114650    Top5 97.273885    
2024-04-23 22:17:24,881 - ==> Top1: 78.115    Top5: 97.274    Loss: 0.673

2024-04-23 22:17:24,889 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:17:24,889 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:17:24,942 - 

2024-04-23 22:17:24,943 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:17:34,874 - Epoch: [357][  100/  296]    Overall Loss 0.655405    Objective Loss 0.655405                                        LR 0.000005    Time 0.099171    
2024-04-23 22:17:48,878 - Epoch: [357][  200/  296]    Overall Loss 0.682330    Objective Loss 0.682330                                        LR 0.000005    Time 0.119532    
2024-04-23 22:17:58,854 - Epoch: [357][  296/  296]    Overall Loss 0.677327    Objective Loss 0.677327    Top1 70.491803    Top5 98.360656    LR 0.000005    Time 0.114416    
2024-04-23 22:17:58,997 - --- validate (epoch=357)-----------
2024-04-23 22:17:58,998 - 3925 samples (32 per mini-batch)
2024-04-23 22:18:11,781 - Epoch: [357][  100/  123]    Loss 0.657976    Top1 78.750000    Top5 97.625000    
2024-04-23 22:18:14,173 - Epoch: [357][  123/  123]    Loss 0.672171    Top1 78.242038    Top5 97.528662    
2024-04-23 22:18:14,309 - ==> Top1: 78.242    Top5: 97.529    Loss: 0.672

2024-04-23 22:18:14,319 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:18:14,319 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:18:14,360 - 

2024-04-23 22:18:14,360 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:18:28,078 - Epoch: [358][  100/  296]    Overall Loss 0.640423    Objective Loss 0.640423                                        LR 0.000005    Time 0.137011    
2024-04-23 22:18:41,410 - Epoch: [358][  200/  296]    Overall Loss 0.657376    Objective Loss 0.657376                                        LR 0.000005    Time 0.135080    
2024-04-23 22:18:54,096 - Epoch: [358][  296/  296]    Overall Loss 0.672172    Objective Loss 0.672172    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.134076    
2024-04-23 22:18:54,254 - --- validate (epoch=358)-----------
2024-04-23 22:18:54,255 - 3925 samples (32 per mini-batch)
2024-04-23 22:19:08,871 - Epoch: [358][  100/  123]    Loss 0.676296    Top1 78.343750    Top5 97.406250    
2024-04-23 22:19:11,753 - Epoch: [358][  123/  123]    Loss 0.670455    Top1 78.649682    Top5 97.528662    
2024-04-23 22:19:11,872 - ==> Top1: 78.650    Top5: 97.529    Loss: 0.670

2024-04-23 22:19:11,883 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:19:11,884 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:19:11,930 - 

2024-04-23 22:19:11,930 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:19:25,851 - Epoch: [359][  100/  296]    Overall Loss 0.681969    Objective Loss 0.681969                                        LR 0.000005    Time 0.139054    
2024-04-23 22:19:41,045 - Epoch: [359][  200/  296]    Overall Loss 0.689738    Objective Loss 0.689738                                        LR 0.000005    Time 0.145430    
2024-04-23 22:19:53,760 - Epoch: [359][  296/  296]    Overall Loss 0.691436    Objective Loss 0.691436    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.141166    
2024-04-23 22:19:53,956 - --- validate (epoch=359)-----------
2024-04-23 22:19:53,957 - 3925 samples (32 per mini-batch)
2024-04-23 22:20:10,056 - Epoch: [359][  100/  123]    Loss 0.659861    Top1 78.593750    Top5 97.781250    
2024-04-23 22:20:14,315 - Epoch: [359][  123/  123]    Loss 0.671238    Top1 78.394904    Top5 97.477707    
2024-04-23 22:20:14,551 - ==> Top1: 78.395    Top5: 97.478    Loss: 0.671

2024-04-23 22:20:14,562 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:20:14,563 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:20:14,612 - 

2024-04-23 22:20:14,613 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:20:29,651 - Epoch: [360][  100/  296]    Overall Loss 0.669728    Objective Loss 0.669728                                        LR 0.000005    Time 0.150220    
2024-04-23 22:20:42,718 - Epoch: [360][  200/  296]    Overall Loss 0.685482    Objective Loss 0.685482                                        LR 0.000005    Time 0.140369    
2024-04-23 22:20:55,283 - Epoch: [360][  296/  296]    Overall Loss 0.686329    Objective Loss 0.686329    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.137239    
2024-04-23 22:20:55,476 - --- validate (epoch=360)-----------
2024-04-23 22:20:55,477 - 3925 samples (32 per mini-batch)
2024-04-23 22:21:14,052 - Epoch: [360][  100/  123]    Loss 0.677064    Top1 78.375000    Top5 97.562500    
2024-04-23 22:21:17,386 - Epoch: [360][  123/  123]    Loss 0.670276    Top1 78.471338    Top5 97.477707    
2024-04-23 22:21:17,538 - ==> Top1: 78.471    Top5: 97.478    Loss: 0.670

2024-04-23 22:21:17,548 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:21:17,548 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:21:17,595 - 

2024-04-23 22:21:17,596 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:21:29,757 - Epoch: [361][  100/  296]    Overall Loss 0.666393    Objective Loss 0.666393                                        LR 0.000005    Time 0.121447    
2024-04-23 22:21:45,210 - Epoch: [361][  200/  296]    Overall Loss 0.683950    Objective Loss 0.683950                                        LR 0.000005    Time 0.137908    
2024-04-23 22:21:57,786 - Epoch: [361][  296/  296]    Overall Loss 0.690206    Objective Loss 0.690206    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.135621    
2024-04-23 22:21:57,976 - --- validate (epoch=361)-----------
2024-04-23 22:21:57,977 - 3925 samples (32 per mini-batch)
2024-04-23 22:22:14,472 - Epoch: [361][  100/  123]    Loss 0.675203    Top1 78.031250    Top5 97.156250    
2024-04-23 22:22:17,128 - Epoch: [361][  123/  123]    Loss 0.672753    Top1 78.267516    Top5 97.273885    
2024-04-23 22:22:17,339 - ==> Top1: 78.268    Top5: 97.274    Loss: 0.673

2024-04-23 22:22:17,347 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:22:17,348 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:22:17,387 - 

2024-04-23 22:22:17,387 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:22:33,869 - Epoch: [362][  100/  296]    Overall Loss 0.678054    Objective Loss 0.678054                                        LR 0.000005    Time 0.164668    
2024-04-23 22:22:49,455 - Epoch: [362][  200/  296]    Overall Loss 0.665685    Objective Loss 0.665685                                        LR 0.000005    Time 0.160193    
2024-04-23 22:23:03,208 - Epoch: [362][  296/  296]    Overall Loss 0.682118    Objective Loss 0.682118    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.154651    
2024-04-23 22:23:03,393 - --- validate (epoch=362)-----------
2024-04-23 22:23:03,394 - 3925 samples (32 per mini-batch)
2024-04-23 22:23:20,444 - Epoch: [362][  100/  123]    Loss 0.669168    Top1 78.250000    Top5 97.406250    
2024-04-23 22:23:24,242 - Epoch: [362][  123/  123]    Loss 0.672372    Top1 78.267516    Top5 97.350318    
2024-04-23 22:23:24,461 - ==> Top1: 78.268    Top5: 97.350    Loss: 0.672

2024-04-23 22:23:24,471 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:23:24,471 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:23:24,532 - 

2024-04-23 22:23:24,533 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:23:38,888 - Epoch: [363][  100/  296]    Overall Loss 0.705834    Objective Loss 0.705834                                        LR 0.000005    Time 0.143385    
2024-04-23 22:23:52,109 - Epoch: [363][  200/  296]    Overall Loss 0.693662    Objective Loss 0.693662                                        LR 0.000005    Time 0.137710    
2024-04-23 22:24:05,207 - Epoch: [363][  296/  296]    Overall Loss 0.692580    Objective Loss 0.692580    Top1 75.409836    Top5 91.803279    LR 0.000005    Time 0.137245    
2024-04-23 22:24:05,384 - --- validate (epoch=363)-----------
2024-04-23 22:24:05,384 - 3925 samples (32 per mini-batch)
2024-04-23 22:24:23,217 - Epoch: [363][  100/  123]    Loss 0.681513    Top1 77.906250    Top5 97.625000    
2024-04-23 22:24:26,954 - Epoch: [363][  123/  123]    Loss 0.669217    Top1 78.292994    Top5 97.554140    
2024-04-23 22:24:27,182 - ==> Top1: 78.293    Top5: 97.554    Loss: 0.669

2024-04-23 22:24:27,191 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:24:27,192 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:24:27,231 - 

2024-04-23 22:24:27,232 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:24:42,567 - Epoch: [364][  100/  296]    Overall Loss 0.667140    Objective Loss 0.667140                                        LR 0.000005    Time 0.153187    
2024-04-23 22:24:54,686 - Epoch: [364][  200/  296]    Overall Loss 0.667006    Objective Loss 0.667006                                        LR 0.000005    Time 0.137096    
2024-04-23 22:25:05,083 - Epoch: [364][  296/  296]    Overall Loss 0.670697    Objective Loss 0.670697    Top1 70.491803    Top5 95.081967    LR 0.000005    Time 0.127710    
2024-04-23 22:25:05,318 - --- validate (epoch=364)-----------
2024-04-23 22:25:05,319 - 3925 samples (32 per mini-batch)
2024-04-23 22:25:22,046 - Epoch: [364][  100/  123]    Loss 0.669376    Top1 77.968750    Top5 97.468750    
2024-04-23 22:25:24,563 - Epoch: [364][  123/  123]    Loss 0.671644    Top1 78.242038    Top5 97.350318    
2024-04-23 22:25:24,746 - ==> Top1: 78.242    Top5: 97.350    Loss: 0.672

2024-04-23 22:25:24,755 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:25:24,756 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:25:24,795 - 

2024-04-23 22:25:24,796 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:25:37,377 - Epoch: [365][  100/  296]    Overall Loss 0.664998    Objective Loss 0.664998                                        LR 0.000005    Time 0.125643    
2024-04-23 22:25:45,742 - Epoch: [365][  200/  296]    Overall Loss 0.682101    Objective Loss 0.682101                                        LR 0.000005    Time 0.104574    
2024-04-23 22:25:55,509 - Epoch: [365][  296/  296]    Overall Loss 0.674684    Objective Loss 0.674684    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.103607    
2024-04-23 22:25:55,675 - --- validate (epoch=365)-----------
2024-04-23 22:25:55,676 - 3925 samples (32 per mini-batch)
2024-04-23 22:26:06,360 - Epoch: [365][  100/  123]    Loss 0.659281    Top1 78.750000    Top5 97.625000    
2024-04-23 22:26:08,799 - Epoch: [365][  123/  123]    Loss 0.669895    Top1 78.343949    Top5 97.477707    
2024-04-23 22:26:09,017 - ==> Top1: 78.344    Top5: 97.478    Loss: 0.670

2024-04-23 22:26:09,025 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:26:09,026 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:26:09,086 - 

2024-04-23 22:26:09,087 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:26:18,858 - Epoch: [366][  100/  296]    Overall Loss 0.702215    Objective Loss 0.702215                                        LR 0.000005    Time 0.097541    
2024-04-23 22:26:28,009 - Epoch: [366][  200/  296]    Overall Loss 0.682982    Objective Loss 0.682982                                        LR 0.000005    Time 0.094444    
2024-04-23 22:26:35,282 - Epoch: [366][  296/  296]    Overall Loss 0.677360    Objective Loss 0.677360    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.088334    
2024-04-23 22:26:35,445 - --- validate (epoch=366)-----------
2024-04-23 22:26:35,446 - 3925 samples (32 per mini-batch)
2024-04-23 22:26:46,814 - Epoch: [366][  100/  123]    Loss 0.662237    Top1 78.281250    Top5 97.218750    
2024-04-23 22:26:49,184 - Epoch: [366][  123/  123]    Loss 0.671499    Top1 78.242038    Top5 97.324841    
2024-04-23 22:26:49,328 - ==> Top1: 78.242    Top5: 97.325    Loss: 0.671

2024-04-23 22:26:49,332 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:26:49,333 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:26:49,359 - 

2024-04-23 22:26:49,360 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:27:03,381 - Epoch: [367][  100/  296]    Overall Loss 0.706631    Objective Loss 0.706631                                        LR 0.000005    Time 0.140044    
2024-04-23 22:27:15,570 - Epoch: [367][  200/  296]    Overall Loss 0.709949    Objective Loss 0.709949                                        LR 0.000005    Time 0.130891    
2024-04-23 22:27:23,619 - Epoch: [367][  296/  296]    Overall Loss 0.696546    Objective Loss 0.696546    Top1 86.885246    Top5 96.721311    LR 0.000005    Time 0.115591    
2024-04-23 22:27:23,837 - --- validate (epoch=367)-----------
2024-04-23 22:27:23,838 - 3925 samples (32 per mini-batch)
2024-04-23 22:27:37,464 - Epoch: [367][  100/  123]    Loss 0.667564    Top1 78.250000    Top5 97.593750    
2024-04-23 22:27:40,407 - Epoch: [367][  123/  123]    Loss 0.673730    Top1 78.089172    Top5 97.605096    
2024-04-23 22:27:40,634 - ==> Top1: 78.089    Top5: 97.605    Loss: 0.674

2024-04-23 22:27:40,645 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:27:40,645 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:27:40,689 - 

2024-04-23 22:27:40,689 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:27:50,738 - Epoch: [368][  100/  296]    Overall Loss 0.665946    Objective Loss 0.665946                                        LR 0.000005    Time 0.100325    
2024-04-23 22:28:08,020 - Epoch: [368][  200/  296]    Overall Loss 0.667805    Objective Loss 0.667805                                        LR 0.000005    Time 0.136500    
2024-04-23 22:28:21,264 - Epoch: [368][  296/  296]    Overall Loss 0.668716    Objective Loss 0.668716    Top1 86.885246    Top5 96.721311    LR 0.000005    Time 0.136925    
2024-04-23 22:28:21,482 - --- validate (epoch=368)-----------
2024-04-23 22:28:21,483 - 3925 samples (32 per mini-batch)
2024-04-23 22:28:39,654 - Epoch: [368][  100/  123]    Loss 0.662825    Top1 78.843750    Top5 97.406250    
2024-04-23 22:28:42,720 - Epoch: [368][  123/  123]    Loss 0.670068    Top1 78.522293    Top5 97.324841    
2024-04-23 22:28:42,907 - ==> Top1: 78.522    Top5: 97.325    Loss: 0.670

2024-04-23 22:28:42,918 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:28:42,918 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:28:42,971 - 

2024-04-23 22:28:42,972 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:28:58,193 - Epoch: [369][  100/  296]    Overall Loss 0.708302    Objective Loss 0.708302                                        LR 0.000005    Time 0.152014    
2024-04-23 22:29:12,796 - Epoch: [369][  200/  296]    Overall Loss 0.689530    Objective Loss 0.689530                                        LR 0.000005    Time 0.148948    
2024-04-23 22:29:25,710 - Epoch: [369][  296/  296]    Overall Loss 0.680859    Objective Loss 0.680859    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.144212    
2024-04-23 22:29:25,911 - --- validate (epoch=369)-----------
2024-04-23 22:29:25,912 - 3925 samples (32 per mini-batch)
2024-04-23 22:29:42,781 - Epoch: [369][  100/  123]    Loss 0.667434    Top1 78.562500    Top5 97.312500    
2024-04-23 22:29:46,405 - Epoch: [369][  123/  123]    Loss 0.675080    Top1 78.191083    Top5 97.222930    
2024-04-23 22:29:46,571 - ==> Top1: 78.191    Top5: 97.223    Loss: 0.675

2024-04-23 22:29:46,580 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:29:46,581 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:29:46,624 - 

2024-04-23 22:29:46,625 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:30:02,400 - Epoch: [370][  100/  296]    Overall Loss 0.698108    Objective Loss 0.698108                                        LR 0.000005    Time 0.157576    
2024-04-23 22:30:16,811 - Epoch: [370][  200/  296]    Overall Loss 0.693618    Objective Loss 0.693618                                        LR 0.000005    Time 0.150749    
2024-04-23 22:30:29,716 - Epoch: [370][  296/  296]    Overall Loss 0.686061    Objective Loss 0.686061    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.145401    
2024-04-23 22:30:29,900 - --- validate (epoch=370)-----------
2024-04-23 22:30:29,901 - 3925 samples (32 per mini-batch)
2024-04-23 22:30:44,247 - Epoch: [370][  100/  123]    Loss 0.662918    Top1 78.281250    Top5 97.625000    
2024-04-23 22:30:47,894 - Epoch: [370][  123/  123]    Loss 0.667877    Top1 78.140127    Top5 97.503185    
2024-04-23 22:30:48,109 - ==> Top1: 78.140    Top5: 97.503    Loss: 0.668

2024-04-23 22:30:48,120 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:30:48,121 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:30:48,168 - 

2024-04-23 22:30:48,169 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:31:00,894 - Epoch: [371][  100/  296]    Overall Loss 0.689309    Objective Loss 0.689309                                        LR 0.000005    Time 0.127080    
2024-04-23 22:31:09,254 - Epoch: [371][  200/  296]    Overall Loss 0.684428    Objective Loss 0.684428                                        LR 0.000005    Time 0.105254    
2024-04-23 22:31:18,869 - Epoch: [371][  296/  296]    Overall Loss 0.672835    Objective Loss 0.672835    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.103546    
2024-04-23 22:31:19,061 - --- validate (epoch=371)-----------
2024-04-23 22:31:19,062 - 3925 samples (32 per mini-batch)
2024-04-23 22:31:33,684 - Epoch: [371][  100/  123]    Loss 0.675491    Top1 77.875000    Top5 97.437500    
2024-04-23 22:31:36,888 - Epoch: [371][  123/  123]    Loss 0.670702    Top1 77.987261    Top5 97.426752    
2024-04-23 22:31:37,047 - ==> Top1: 77.987    Top5: 97.427    Loss: 0.671

2024-04-23 22:31:37,054 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:31:37,054 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:31:37,090 - 

2024-04-23 22:31:37,091 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:31:51,705 - Epoch: [372][  100/  296]    Overall Loss 0.720302    Objective Loss 0.720302                                        LR 0.000005    Time 0.145967    
2024-04-23 22:32:05,934 - Epoch: [372][  200/  296]    Overall Loss 0.695705    Objective Loss 0.695705                                        LR 0.000005    Time 0.144047    
2024-04-23 22:32:20,335 - Epoch: [372][  296/  296]    Overall Loss 0.685225    Objective Loss 0.685225    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.145934    
2024-04-23 22:32:20,687 - --- validate (epoch=372)-----------
2024-04-23 22:32:20,687 - 3925 samples (32 per mini-batch)
2024-04-23 22:32:39,362 - Epoch: [372][  100/  123]    Loss 0.677581    Top1 78.062500    Top5 97.531250    
2024-04-23 22:32:44,074 - Epoch: [372][  123/  123]    Loss 0.669934    Top1 78.343949    Top5 97.528662    
2024-04-23 22:32:44,331 - ==> Top1: 78.344    Top5: 97.529    Loss: 0.670

2024-04-23 22:32:44,343 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:32:44,344 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:32:44,388 - 

2024-04-23 22:32:44,389 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:33:01,545 - Epoch: [373][  100/  296]    Overall Loss 0.663736    Objective Loss 0.663736                                        LR 0.000005    Time 0.171399    
2024-04-23 22:33:17,921 - Epoch: [373][  200/  296]    Overall Loss 0.684658    Objective Loss 0.684658                                        LR 0.000005    Time 0.167507    
2024-04-23 22:33:32,192 - Epoch: [373][  296/  296]    Overall Loss 0.677786    Objective Loss 0.677786    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.161353    
2024-04-23 22:33:32,406 - --- validate (epoch=373)-----------
2024-04-23 22:33:32,406 - 3925 samples (32 per mini-batch)
2024-04-23 22:33:47,129 - Epoch: [373][  100/  123]    Loss 0.668379    Top1 78.281250    Top5 97.312500    
2024-04-23 22:33:50,339 - Epoch: [373][  123/  123]    Loss 0.668898    Top1 78.420382    Top5 97.401274    
2024-04-23 22:33:50,583 - ==> Top1: 78.420    Top5: 97.401    Loss: 0.669

2024-04-23 22:33:50,590 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:33:50,591 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:33:50,650 - 

2024-04-23 22:33:50,651 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:34:05,406 - Epoch: [374][  100/  296]    Overall Loss 0.700003    Objective Loss 0.700003                                        LR 0.000005    Time 0.147369    
2024-04-23 22:34:20,578 - Epoch: [374][  200/  296]    Overall Loss 0.682864    Objective Loss 0.682864                                        LR 0.000005    Time 0.149472    
2024-04-23 22:34:36,804 - Epoch: [374][  296/  296]    Overall Loss 0.685881    Objective Loss 0.685881    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.155759    
2024-04-23 22:34:37,059 - --- validate (epoch=374)-----------
2024-04-23 22:34:37,061 - 3925 samples (32 per mini-batch)
2024-04-23 22:34:54,403 - Epoch: [374][  100/  123]    Loss 0.668519    Top1 78.406250    Top5 97.312500    
2024-04-23 22:34:58,919 - Epoch: [374][  123/  123]    Loss 0.670012    Top1 78.420382    Top5 97.477707    
2024-04-23 22:34:59,070 - ==> Top1: 78.420    Top5: 97.478    Loss: 0.670

2024-04-23 22:34:59,079 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:34:59,080 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:34:59,119 - 

2024-04-23 22:34:59,119 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:35:10,541 - Epoch: [375][  100/  296]    Overall Loss 0.671945    Objective Loss 0.671945                                        LR 0.000005    Time 0.114056    
2024-04-23 22:35:18,108 - Epoch: [375][  200/  296]    Overall Loss 0.675329    Objective Loss 0.675329                                        LR 0.000005    Time 0.094795    
2024-04-23 22:35:30,829 - Epoch: [375][  296/  296]    Overall Loss 0.673472    Objective Loss 0.673472    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.106971    
2024-04-23 22:35:31,059 - --- validate (epoch=375)-----------
2024-04-23 22:35:31,060 - 3925 samples (32 per mini-batch)
2024-04-23 22:35:46,934 - Epoch: [375][  100/  123]    Loss 0.663429    Top1 78.562500    Top5 97.343750    
2024-04-23 22:35:49,285 - Epoch: [375][  123/  123]    Loss 0.671541    Top1 78.292994    Top5 97.401274    
2024-04-23 22:35:49,426 - ==> Top1: 78.293    Top5: 97.401    Loss: 0.672

2024-04-23 22:35:49,436 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:35:49,436 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:35:49,474 - 

2024-04-23 22:35:49,475 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:35:57,963 - Epoch: [376][  100/  296]    Overall Loss 0.719462    Objective Loss 0.719462                                        LR 0.000005    Time 0.084761    
2024-04-23 22:36:08,587 - Epoch: [376][  200/  296]    Overall Loss 0.707578    Objective Loss 0.707578                                        LR 0.000005    Time 0.095426    
2024-04-23 22:36:18,190 - Epoch: [376][  296/  296]    Overall Loss 0.695211    Objective Loss 0.695211    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.096878    
2024-04-23 22:36:18,307 - --- validate (epoch=376)-----------
2024-04-23 22:36:18,308 - 3925 samples (32 per mini-batch)
2024-04-23 22:36:30,157 - Epoch: [376][  100/  123]    Loss 0.670422    Top1 78.250000    Top5 97.593750    
2024-04-23 22:36:32,670 - Epoch: [376][  123/  123]    Loss 0.668609    Top1 78.445860    Top5 97.426752    
2024-04-23 22:36:32,834 - ==> Top1: 78.446    Top5: 97.427    Loss: 0.669

2024-04-23 22:36:32,842 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:36:32,843 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:36:32,902 - 

2024-04-23 22:36:32,903 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:36:48,107 - Epoch: [377][  100/  296]    Overall Loss 0.687750    Objective Loss 0.687750                                        LR 0.000005    Time 0.151899    
2024-04-23 22:37:01,817 - Epoch: [377][  200/  296]    Overall Loss 0.692413    Objective Loss 0.692413                                        LR 0.000005    Time 0.144412    
2024-04-23 22:37:14,906 - Epoch: [377][  296/  296]    Overall Loss 0.684664    Objective Loss 0.684664    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.141743    
2024-04-23 22:37:15,160 - --- validate (epoch=377)-----------
2024-04-23 22:37:15,161 - 3925 samples (32 per mini-batch)
2024-04-23 22:37:31,633 - Epoch: [377][  100/  123]    Loss 0.663668    Top1 78.562500    Top5 97.375000    
2024-04-23 22:37:35,239 - Epoch: [377][  123/  123]    Loss 0.671307    Top1 78.394904    Top5 97.401274    
2024-04-23 22:37:35,469 - ==> Top1: 78.395    Top5: 97.401    Loss: 0.671

2024-04-23 22:37:35,478 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:37:35,479 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:37:35,522 - 

2024-04-23 22:37:35,523 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:37:46,895 - Epoch: [378][  100/  296]    Overall Loss 0.672646    Objective Loss 0.672646                                        LR 0.000005    Time 0.113553    
2024-04-23 22:37:56,178 - Epoch: [378][  200/  296]    Overall Loss 0.664614    Objective Loss 0.664614                                        LR 0.000005    Time 0.103112    
2024-04-23 22:38:08,942 - Epoch: [378][  296/  296]    Overall Loss 0.670602    Objective Loss 0.670602    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.112748    
2024-04-23 22:38:09,149 - --- validate (epoch=378)-----------
2024-04-23 22:38:09,150 - 3925 samples (32 per mini-batch)
2024-04-23 22:38:24,048 - Epoch: [378][  100/  123]    Loss 0.680348    Top1 77.843750    Top5 97.437500    
2024-04-23 22:38:26,230 - Epoch: [378][  123/  123]    Loss 0.673947    Top1 78.191083    Top5 97.375796    
2024-04-23 22:38:26,381 - ==> Top1: 78.191    Top5: 97.376    Loss: 0.674

2024-04-23 22:38:26,390 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:38:26,391 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:38:26,433 - 

2024-04-23 22:38:26,434 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:38:38,260 - Epoch: [379][  100/  296]    Overall Loss 0.672525    Objective Loss 0.672525                                        LR 0.000005    Time 0.118079    
2024-04-23 22:38:48,761 - Epoch: [379][  200/  296]    Overall Loss 0.677563    Objective Loss 0.677563                                        LR 0.000005    Time 0.111468    
2024-04-23 22:38:59,749 - Epoch: [379][  296/  296]    Overall Loss 0.664033    Objective Loss 0.664033    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.112390    
2024-04-23 22:38:59,917 - --- validate (epoch=379)-----------
2024-04-23 22:38:59,918 - 3925 samples (32 per mini-batch)
2024-04-23 22:39:15,096 - Epoch: [379][  100/  123]    Loss 0.680148    Top1 77.875000    Top5 97.406250    
2024-04-23 22:39:18,232 - Epoch: [379][  123/  123]    Loss 0.669105    Top1 78.394904    Top5 97.528662    
2024-04-23 22:39:18,446 - ==> Top1: 78.395    Top5: 97.529    Loss: 0.669

2024-04-23 22:39:18,458 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:39:18,459 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:39:18,525 - 

2024-04-23 22:39:18,526 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:39:35,596 - Epoch: [380][  100/  296]    Overall Loss 0.689146    Objective Loss 0.689146                                        LR 0.000005    Time 0.170504    
2024-04-23 22:39:49,718 - Epoch: [380][  200/  296]    Overall Loss 0.680142    Objective Loss 0.680142                                        LR 0.000005    Time 0.155793    
2024-04-23 22:40:04,384 - Epoch: [380][  296/  296]    Overall Loss 0.681807    Objective Loss 0.681807    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.154759    
2024-04-23 22:40:04,611 - --- validate (epoch=380)-----------
2024-04-23 22:40:04,612 - 3925 samples (32 per mini-batch)
2024-04-23 22:40:21,310 - Epoch: [380][  100/  123]    Loss 0.672958    Top1 78.062500    Top5 97.343750    
2024-04-23 22:40:25,364 - Epoch: [380][  123/  123]    Loss 0.666907    Top1 78.267516    Top5 97.452229    
2024-04-23 22:40:25,546 - ==> Top1: 78.268    Top5: 97.452    Loss: 0.667

2024-04-23 22:40:25,553 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:40:25,553 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:40:25,590 - 

2024-04-23 22:40:25,591 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:40:39,932 - Epoch: [381][  100/  296]    Overall Loss 0.678749    Objective Loss 0.678749                                        LR 0.000005    Time 0.143230    
2024-04-23 22:40:53,661 - Epoch: [381][  200/  296]    Overall Loss 0.677340    Objective Loss 0.677340                                        LR 0.000005    Time 0.140179    
2024-04-23 22:41:06,773 - Epoch: [381][  296/  296]    Overall Loss 0.680797    Objective Loss 0.680797    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.138964    
2024-04-23 22:41:06,951 - --- validate (epoch=381)-----------
2024-04-23 22:41:06,952 - 3925 samples (32 per mini-batch)
2024-04-23 22:41:26,050 - Epoch: [381][  100/  123]    Loss 0.654484    Top1 78.593750    Top5 97.625000    
2024-04-23 22:41:29,365 - Epoch: [381][  123/  123]    Loss 0.668519    Top1 78.165605    Top5 97.528662    
2024-04-23 22:41:29,566 - ==> Top1: 78.166    Top5: 97.529    Loss: 0.669

2024-04-23 22:41:29,575 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:41:29,576 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:41:29,628 - 

2024-04-23 22:41:29,628 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:41:44,371 - Epoch: [382][  100/  296]    Overall Loss 0.618155    Objective Loss 0.618155                                        LR 0.000005    Time 0.147272    
2024-04-23 22:41:59,407 - Epoch: [382][  200/  296]    Overall Loss 0.652741    Objective Loss 0.652741                                        LR 0.000005    Time 0.148738    
2024-04-23 22:42:14,137 - Epoch: [382][  296/  296]    Overall Loss 0.666166    Objective Loss 0.666166    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.150215    
2024-04-23 22:42:14,400 - --- validate (epoch=382)-----------
2024-04-23 22:42:14,402 - 3925 samples (32 per mini-batch)
2024-04-23 22:42:32,177 - Epoch: [382][  100/  123]    Loss 0.666272    Top1 78.343750    Top5 97.593750    
2024-04-23 22:42:34,571 - Epoch: [382][  123/  123]    Loss 0.666770    Top1 78.292994    Top5 97.503185    
2024-04-23 22:42:34,757 - ==> Top1: 78.293    Top5: 97.503    Loss: 0.667

2024-04-23 22:42:34,766 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:42:34,767 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:42:34,804 - 

2024-04-23 22:42:34,804 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:42:46,510 - Epoch: [383][  100/  296]    Overall Loss 0.667188    Objective Loss 0.667188                                        LR 0.000005    Time 0.116886    
2024-04-23 22:42:55,530 - Epoch: [383][  200/  296]    Overall Loss 0.673635    Objective Loss 0.673635                                        LR 0.000005    Time 0.103463    
2024-04-23 22:43:06,155 - Epoch: [383][  296/  296]    Overall Loss 0.667009    Objective Loss 0.667009    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.105751    
2024-04-23 22:43:06,362 - --- validate (epoch=383)-----------
2024-04-23 22:43:06,363 - 3925 samples (32 per mini-batch)
2024-04-23 22:43:21,057 - Epoch: [383][  100/  123]    Loss 0.666769    Top1 78.375000    Top5 97.500000    
2024-04-23 22:43:24,374 - Epoch: [383][  123/  123]    Loss 0.669993    Top1 78.292994    Top5 97.554140    
2024-04-23 22:43:24,681 - ==> Top1: 78.293    Top5: 97.554    Loss: 0.670

2024-04-23 22:43:24,687 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:43:24,687 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:43:24,726 - 

2024-04-23 22:43:24,727 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:43:39,011 - Epoch: [384][  100/  296]    Overall Loss 0.684165    Objective Loss 0.684165                                        LR 0.000005    Time 0.142662    
2024-04-23 22:43:51,172 - Epoch: [384][  200/  296]    Overall Loss 0.689339    Objective Loss 0.689339                                        LR 0.000005    Time 0.132063    
2024-04-23 22:43:58,378 - Epoch: [384][  296/  296]    Overall Loss 0.690086    Objective Loss 0.690086    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.113526    
2024-04-23 22:43:58,594 - --- validate (epoch=384)-----------
2024-04-23 22:43:58,596 - 3925 samples (32 per mini-batch)
2024-04-23 22:44:11,687 - Epoch: [384][  100/  123]    Loss 0.659158    Top1 78.593750    Top5 97.468750    
2024-04-23 22:44:13,919 - Epoch: [384][  123/  123]    Loss 0.666611    Top1 78.445860    Top5 97.528662    
2024-04-23 22:44:14,076 - ==> Top1: 78.446    Top5: 97.529    Loss: 0.667

2024-04-23 22:44:14,085 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:44:14,086 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:44:14,122 - 

2024-04-23 22:44:14,123 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:44:23,855 - Epoch: [385][  100/  296]    Overall Loss 0.669273    Objective Loss 0.669273                                        LR 0.000005    Time 0.097178    
2024-04-23 22:44:31,326 - Epoch: [385][  200/  296]    Overall Loss 0.666723    Objective Loss 0.666723                                        LR 0.000005    Time 0.085877    
2024-04-23 22:44:39,704 - Epoch: [385][  296/  296]    Overall Loss 0.671983    Objective Loss 0.671983    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.086281    
2024-04-23 22:44:39,902 - --- validate (epoch=385)-----------
2024-04-23 22:44:39,903 - 3925 samples (32 per mini-batch)
2024-04-23 22:44:51,794 - Epoch: [385][  100/  123]    Loss 0.661419    Top1 78.687500    Top5 97.406250    
2024-04-23 22:44:54,095 - Epoch: [385][  123/  123]    Loss 0.667411    Top1 78.445860    Top5 97.503185    
2024-04-23 22:44:54,247 - ==> Top1: 78.446    Top5: 97.503    Loss: 0.667

2024-04-23 22:44:54,256 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:44:54,256 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:44:54,293 - 

2024-04-23 22:44:54,294 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:45:03,502 - Epoch: [386][  100/  296]    Overall Loss 0.664701    Objective Loss 0.664701                                        LR 0.000005    Time 0.091923    
2024-04-23 22:45:11,371 - Epoch: [386][  200/  296]    Overall Loss 0.663953    Objective Loss 0.663953                                        LR 0.000005    Time 0.085235    
2024-04-23 22:45:27,602 - Epoch: [386][  296/  296]    Overall Loss 0.675421    Objective Loss 0.675421    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.112375    
2024-04-23 22:45:27,785 - --- validate (epoch=386)-----------
2024-04-23 22:45:27,787 - 3925 samples (32 per mini-batch)
2024-04-23 22:45:44,896 - Epoch: [386][  100/  123]    Loss 0.672940    Top1 78.281250    Top5 97.500000    
2024-04-23 22:45:48,071 - Epoch: [386][  123/  123]    Loss 0.669385    Top1 78.343949    Top5 97.528662    
2024-04-23 22:45:48,281 - ==> Top1: 78.344    Top5: 97.529    Loss: 0.669

2024-04-23 22:45:48,292 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:45:48,293 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:45:48,338 - 

2024-04-23 22:45:48,339 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:46:03,838 - Epoch: [387][  100/  296]    Overall Loss 0.651463    Objective Loss 0.651463                                        LR 0.000005    Time 0.154813    
2024-04-23 22:46:17,313 - Epoch: [387][  200/  296]    Overall Loss 0.668768    Objective Loss 0.668768                                        LR 0.000005    Time 0.144705    
2024-04-23 22:46:31,234 - Epoch: [387][  296/  296]    Overall Loss 0.662785    Objective Loss 0.662785    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.144757    
2024-04-23 22:46:31,408 - --- validate (epoch=387)-----------
2024-04-23 22:46:31,408 - 3925 samples (32 per mini-batch)
2024-04-23 22:46:46,017 - Epoch: [387][  100/  123]    Loss 0.645519    Top1 79.156250    Top5 97.718750    
2024-04-23 22:46:49,728 - Epoch: [387][  123/  123]    Loss 0.666346    Top1 78.420382    Top5 97.503185    
2024-04-23 22:46:49,937 - ==> Top1: 78.420    Top5: 97.503    Loss: 0.666

2024-04-23 22:46:49,947 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:46:49,948 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:46:49,990 - 

2024-04-23 22:46:49,991 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:47:04,016 - Epoch: [388][  100/  296]    Overall Loss 0.667492    Objective Loss 0.667492                                        LR 0.000005    Time 0.140089    
2024-04-23 22:47:14,700 - Epoch: [388][  200/  296]    Overall Loss 0.675026    Objective Loss 0.675026                                        LR 0.000005    Time 0.123381    
2024-04-23 22:47:25,314 - Epoch: [388][  296/  296]    Overall Loss 0.676980    Objective Loss 0.676980    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.119169    
2024-04-23 22:47:25,514 - --- validate (epoch=388)-----------
2024-04-23 22:47:25,514 - 3925 samples (32 per mini-batch)
2024-04-23 22:47:40,330 - Epoch: [388][  100/  123]    Loss 0.655176    Top1 78.750000    Top5 97.843750    
2024-04-23 22:47:41,934 - Epoch: [388][  123/  123]    Loss 0.670308    Top1 78.445860    Top5 97.605096    
2024-04-23 22:47:42,143 - ==> Top1: 78.446    Top5: 97.605    Loss: 0.670

2024-04-23 22:47:42,148 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:47:42,149 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:47:42,186 - 

2024-04-23 22:47:42,187 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:47:57,230 - Epoch: [389][  100/  296]    Overall Loss 0.678577    Objective Loss 0.678577                                        LR 0.000005    Time 0.150270    
2024-04-23 22:48:12,785 - Epoch: [389][  200/  296]    Overall Loss 0.677721    Objective Loss 0.677721                                        LR 0.000005    Time 0.152830    
2024-04-23 22:48:27,200 - Epoch: [389][  296/  296]    Overall Loss 0.683606    Objective Loss 0.683606    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.151905    
2024-04-23 22:48:27,422 - --- validate (epoch=389)-----------
2024-04-23 22:48:27,423 - 3925 samples (32 per mini-batch)
2024-04-23 22:48:45,617 - Epoch: [389][  100/  123]    Loss 0.659143    Top1 78.312500    Top5 97.531250    
2024-04-23 22:48:49,992 - Epoch: [389][  123/  123]    Loss 0.668368    Top1 78.522293    Top5 97.426752    
2024-04-23 22:48:50,279 - ==> Top1: 78.522    Top5: 97.427    Loss: 0.668

2024-04-23 22:48:50,290 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:48:50,291 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:48:50,337 - 

2024-04-23 22:48:50,338 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:49:04,884 - Epoch: [390][  100/  296]    Overall Loss 0.668513    Objective Loss 0.668513                                        LR 0.000005    Time 0.145300    
2024-04-23 22:49:19,118 - Epoch: [390][  200/  296]    Overall Loss 0.663961    Objective Loss 0.663961                                        LR 0.000005    Time 0.143756    
2024-04-23 22:49:31,828 - Epoch: [390][  296/  296]    Overall Loss 0.671696    Objective Loss 0.671696    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.140021    
2024-04-23 22:49:32,009 - --- validate (epoch=390)-----------
2024-04-23 22:49:32,010 - 3925 samples (32 per mini-batch)
2024-04-23 22:49:48,716 - Epoch: [390][  100/  123]    Loss 0.655803    Top1 78.781250    Top5 97.500000    
2024-04-23 22:49:52,023 - Epoch: [390][  123/  123]    Loss 0.669289    Top1 78.471338    Top5 97.503185    
2024-04-23 22:49:52,207 - ==> Top1: 78.471    Top5: 97.503    Loss: 0.669

2024-04-23 22:49:52,214 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:49:52,214 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:49:52,256 - 

2024-04-23 22:49:52,257 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:50:06,951 - Epoch: [391][  100/  296]    Overall Loss 0.679755    Objective Loss 0.679755                                        LR 0.000005    Time 0.146745    
2024-04-23 22:50:19,915 - Epoch: [391][  200/  296]    Overall Loss 0.683916    Objective Loss 0.683916                                        LR 0.000005    Time 0.138116    
2024-04-23 22:50:31,606 - Epoch: [391][  296/  296]    Overall Loss 0.686370    Objective Loss 0.686370    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.132775    
2024-04-23 22:50:31,826 - --- validate (epoch=391)-----------
2024-04-23 22:50:31,828 - 3925 samples (32 per mini-batch)
2024-04-23 22:50:42,649 - Epoch: [391][  100/  123]    Loss 0.674455    Top1 78.156250    Top5 97.437500    
2024-04-23 22:50:44,417 - Epoch: [391][  123/  123]    Loss 0.669355    Top1 78.216561    Top5 97.579618    
2024-04-23 22:50:44,612 - ==> Top1: 78.217    Top5: 97.580    Loss: 0.669

2024-04-23 22:50:44,621 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:50:44,622 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:50:44,661 - 

2024-04-23 22:50:44,662 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:50:54,166 - Epoch: [392][  100/  296]    Overall Loss 0.676300    Objective Loss 0.676300                                        LR 0.000005    Time 0.094883    
2024-04-23 22:51:01,772 - Epoch: [392][  200/  296]    Overall Loss 0.686826    Objective Loss 0.686826                                        LR 0.000005    Time 0.085394    
2024-04-23 22:51:10,463 - Epoch: [392][  296/  296]    Overall Loss 0.694414    Objective Loss 0.694414    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.087009    
2024-04-23 22:51:10,624 - --- validate (epoch=392)-----------
2024-04-23 22:51:10,624 - 3925 samples (32 per mini-batch)
2024-04-23 22:51:22,180 - Epoch: [392][  100/  123]    Loss 0.664685    Top1 78.718750    Top5 97.562500    
2024-04-23 22:51:24,896 - Epoch: [392][  123/  123]    Loss 0.667627    Top1 78.292994    Top5 97.554140    
2024-04-23 22:51:25,061 - ==> Top1: 78.293    Top5: 97.554    Loss: 0.668

2024-04-23 22:51:25,071 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:51:25,072 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:51:25,108 - 

2024-04-23 22:51:25,109 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:51:39,812 - Epoch: [393][  100/  296]    Overall Loss 0.665857    Objective Loss 0.665857                                        LR 0.000005    Time 0.146866    
2024-04-23 22:51:47,470 - Epoch: [393][  200/  296]    Overall Loss 0.678679    Objective Loss 0.678679                                        LR 0.000005    Time 0.111648    
2024-04-23 22:51:57,791 - Epoch: [393][  296/  296]    Overall Loss 0.673462    Objective Loss 0.673462    Top1 70.491803    Top5 100.000000    LR 0.000005    Time 0.110256    
2024-04-23 22:51:57,981 - --- validate (epoch=393)-----------
2024-04-23 22:51:57,982 - 3925 samples (32 per mini-batch)
2024-04-23 22:52:13,943 - Epoch: [393][  100/  123]    Loss 0.685101    Top1 77.968750    Top5 97.156250    
2024-04-23 22:52:17,192 - Epoch: [393][  123/  123]    Loss 0.670543    Top1 78.242038    Top5 97.324841    
2024-04-23 22:52:17,369 - ==> Top1: 78.242    Top5: 97.325    Loss: 0.671

2024-04-23 22:52:17,374 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:52:17,374 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:52:17,412 - 

2024-04-23 22:52:17,413 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:52:30,116 - Epoch: [394][  100/  296]    Overall Loss 0.692168    Objective Loss 0.692168                                        LR 0.000005    Time 0.126867    
2024-04-23 22:52:42,656 - Epoch: [394][  200/  296]    Overall Loss 0.676035    Objective Loss 0.676035                                        LR 0.000005    Time 0.126057    
2024-04-23 22:52:54,996 - Epoch: [394][  296/  296]    Overall Loss 0.678516    Objective Loss 0.678516    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.126812    
2024-04-23 22:52:55,109 - --- validate (epoch=394)-----------
2024-04-23 22:52:55,110 - 3925 samples (32 per mini-batch)
2024-04-23 22:53:08,437 - Epoch: [394][  100/  123]    Loss 0.661245    Top1 78.625000    Top5 97.281250    
2024-04-23 22:53:10,403 - Epoch: [394][  123/  123]    Loss 0.670598    Top1 78.292994    Top5 97.503185    
2024-04-23 22:53:10,655 - ==> Top1: 78.293    Top5: 97.503    Loss: 0.671

2024-04-23 22:53:10,661 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:53:10,661 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:53:10,691 - 

2024-04-23 22:53:10,691 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:53:21,527 - Epoch: [395][  100/  296]    Overall Loss 0.676049    Objective Loss 0.676049                                        LR 0.000005    Time 0.108197    
2024-04-23 22:53:31,035 - Epoch: [395][  200/  296]    Overall Loss 0.670974    Objective Loss 0.670974                                        LR 0.000005    Time 0.101561    
2024-04-23 22:53:42,792 - Epoch: [395][  296/  296]    Overall Loss 0.671124    Objective Loss 0.671124    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.108286    
2024-04-23 22:53:43,055 - --- validate (epoch=395)-----------
2024-04-23 22:53:43,056 - 3925 samples (32 per mini-batch)
2024-04-23 22:53:59,778 - Epoch: [395][  100/  123]    Loss 0.654401    Top1 78.843750    Top5 97.656250    
2024-04-23 22:54:02,781 - Epoch: [395][  123/  123]    Loss 0.670418    Top1 78.267516    Top5 97.554140    
2024-04-23 22:54:03,046 - ==> Top1: 78.268    Top5: 97.554    Loss: 0.670

2024-04-23 22:54:03,057 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:54:03,057 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:54:03,109 - 

2024-04-23 22:54:03,110 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:54:18,429 - Epoch: [396][  100/  296]    Overall Loss 0.707396    Objective Loss 0.707396                                        LR 0.000005    Time 0.153014    
2024-04-23 22:54:33,374 - Epoch: [396][  200/  296]    Overall Loss 0.683751    Objective Loss 0.683751                                        LR 0.000005    Time 0.151152    
2024-04-23 22:54:45,193 - Epoch: [396][  296/  296]    Overall Loss 0.681429    Objective Loss 0.681429    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.142008    
2024-04-23 22:54:45,424 - --- validate (epoch=396)-----------
2024-04-23 22:54:45,425 - 3925 samples (32 per mini-batch)
2024-04-23 22:55:03,060 - Epoch: [396][  100/  123]    Loss 0.668790    Top1 78.500000    Top5 97.406250    
2024-04-23 22:55:06,395 - Epoch: [396][  123/  123]    Loss 0.669015    Top1 78.420382    Top5 97.554140    
2024-04-23 22:55:06,559 - ==> Top1: 78.420    Top5: 97.554    Loss: 0.669

2024-04-23 22:55:06,568 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:55:06,569 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:55:06,613 - 

2024-04-23 22:55:06,614 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:55:22,612 - Epoch: [397][  100/  296]    Overall Loss 0.675346    Objective Loss 0.675346                                        LR 0.000005    Time 0.159805    
2024-04-23 22:55:35,828 - Epoch: [397][  200/  296]    Overall Loss 0.664352    Objective Loss 0.664352                                        LR 0.000005    Time 0.145900    
2024-04-23 22:55:49,697 - Epoch: [397][  296/  296]    Overall Loss 0.672604    Objective Loss 0.672604    Top1 72.131148    Top5 100.000000    LR 0.000005    Time 0.145393    
2024-04-23 22:55:49,897 - --- validate (epoch=397)-----------
2024-04-23 22:55:49,898 - 3925 samples (32 per mini-batch)
2024-04-23 22:56:06,078 - Epoch: [397][  100/  123]    Loss 0.664479    Top1 78.625000    Top5 97.468750    
2024-04-23 22:56:09,750 - Epoch: [397][  123/  123]    Loss 0.667009    Top1 78.343949    Top5 97.477707    
2024-04-23 22:56:09,948 - ==> Top1: 78.344    Top5: 97.478    Loss: 0.667

2024-04-23 22:56:09,959 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:56:09,959 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:56:10,003 - 

2024-04-23 22:56:10,004 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:56:27,503 - Epoch: [398][  100/  296]    Overall Loss 0.676096    Objective Loss 0.676096                                        LR 0.000005    Time 0.174826    
2024-04-23 22:56:40,313 - Epoch: [398][  200/  296]    Overall Loss 0.670083    Objective Loss 0.670083                                        LR 0.000005    Time 0.151386    
2024-04-23 22:56:53,638 - Epoch: [398][  296/  296]    Overall Loss 0.677877    Objective Loss 0.677877    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.147253    
2024-04-23 22:56:53,859 - --- validate (epoch=398)-----------
2024-04-23 22:56:53,860 - 3925 samples (32 per mini-batch)
2024-04-23 22:57:07,879 - Epoch: [398][  100/  123]    Loss 0.668662    Top1 78.062500    Top5 97.531250    
2024-04-23 22:57:11,122 - Epoch: [398][  123/  123]    Loss 0.667489    Top1 78.318471    Top5 97.605096    
2024-04-23 22:57:11,343 - ==> Top1: 78.318    Top5: 97.605    Loss: 0.667

2024-04-23 22:57:11,353 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:57:11,353 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:57:11,402 - 

2024-04-23 22:57:11,402 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:57:23,710 - Epoch: [399][  100/  296]    Overall Loss 0.692024    Objective Loss 0.692024                                        LR 0.000005    Time 0.122921    
2024-04-23 22:57:35,580 - Epoch: [399][  200/  296]    Overall Loss 0.677134    Objective Loss 0.677134                                        LR 0.000005    Time 0.120727    
2024-04-23 22:57:46,062 - Epoch: [399][  296/  296]    Overall Loss 0.691204    Objective Loss 0.691204    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.116935    
2024-04-23 22:57:46,269 - --- validate (epoch=399)-----------
2024-04-23 22:57:46,271 - 3925 samples (32 per mini-batch)
2024-04-23 22:57:59,313 - Epoch: [399][  100/  123]    Loss 0.671665    Top1 78.718750    Top5 97.562500    
2024-04-23 22:58:01,819 - Epoch: [399][  123/  123]    Loss 0.669962    Top1 78.598726    Top5 97.554140    
2024-04-23 22:58:01,973 - ==> Top1: 78.599    Top5: 97.554    Loss: 0.670

2024-04-23 22:58:01,981 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:58:01,982 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:58:02,032 - 

2024-04-23 22:58:02,033 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:58:13,344 - Epoch: [400][  100/  296]    Overall Loss 0.678425    Objective Loss 0.678425                                        LR 0.000005    Time 0.112951    
2024-04-23 22:58:28,093 - Epoch: [400][  200/  296]    Overall Loss 0.684554    Objective Loss 0.684554                                        LR 0.000005    Time 0.130141    
2024-04-23 22:58:36,831 - Epoch: [400][  296/  296]    Overall Loss 0.688713    Objective Loss 0.688713    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.117400    
2024-04-23 22:58:37,051 - --- validate (epoch=400)-----------
2024-04-23 22:58:37,053 - 3925 samples (32 per mini-batch)
2024-04-23 22:58:49,475 - Epoch: [400][  100/  123]    Loss 0.669933    Top1 78.500000    Top5 97.562500    
2024-04-23 22:58:52,499 - Epoch: [400][  123/  123]    Loss 0.675091    Top1 78.318471    Top5 97.452229    
2024-04-23 22:58:52,673 - ==> Top1: 78.318    Top5: 97.452    Loss: 0.675

2024-04-23 22:58:52,683 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:58:52,684 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:58:52,736 - 

2024-04-23 22:58:52,736 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:59:07,010 - Epoch: [401][  100/  296]    Overall Loss 0.681289    Objective Loss 0.681289                                        LR 0.000005    Time 0.142555    
2024-04-23 22:59:19,470 - Epoch: [401][  200/  296]    Overall Loss 0.676464    Objective Loss 0.676464                                        LR 0.000005    Time 0.133496    
2024-04-23 22:59:34,570 - Epoch: [401][  296/  296]    Overall Loss 0.675508    Objective Loss 0.675508    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.141162    
2024-04-23 22:59:34,800 - --- validate (epoch=401)-----------
2024-04-23 22:59:34,801 - 3925 samples (32 per mini-batch)
2024-04-23 22:59:47,141 - Epoch: [401][  100/  123]    Loss 0.670164    Top1 78.218750    Top5 97.718750    
2024-04-23 22:59:49,679 - Epoch: [401][  123/  123]    Loss 0.671181    Top1 78.292994    Top5 97.477707    
2024-04-23 22:59:49,888 - ==> Top1: 78.293    Top5: 97.478    Loss: 0.671

2024-04-23 22:59:49,899 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 22:59:49,900 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 22:59:49,951 - 

2024-04-23 22:59:49,951 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:00:02,376 - Epoch: [402][  100/  296]    Overall Loss 0.684746    Objective Loss 0.684746                                        LR 0.000005    Time 0.124074    
2024-04-23 23:00:15,838 - Epoch: [402][  200/  296]    Overall Loss 0.690150    Objective Loss 0.690150                                        LR 0.000005    Time 0.129263    
2024-04-23 23:00:27,945 - Epoch: [402][  296/  296]    Overall Loss 0.686765    Objective Loss 0.686765    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.128198    
2024-04-23 23:00:28,123 - --- validate (epoch=402)-----------
2024-04-23 23:00:28,124 - 3925 samples (32 per mini-batch)
2024-04-23 23:00:42,437 - Epoch: [402][  100/  123]    Loss 0.673570    Top1 78.281250    Top5 97.593750    
2024-04-23 23:00:44,770 - Epoch: [402][  123/  123]    Loss 0.668114    Top1 78.369427    Top5 97.579618    
2024-04-23 23:00:44,966 - ==> Top1: 78.369    Top5: 97.580    Loss: 0.668

2024-04-23 23:00:44,976 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:00:44,977 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:00:45,022 - 

2024-04-23 23:00:45,023 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:00:56,072 - Epoch: [403][  100/  296]    Overall Loss 0.704155    Objective Loss 0.704155                                        LR 0.000005    Time 0.110327    
2024-04-23 23:01:11,041 - Epoch: [403][  200/  296]    Overall Loss 0.687259    Objective Loss 0.687259                                        LR 0.000005    Time 0.129940    
2024-04-23 23:01:23,559 - Epoch: [403][  296/  296]    Overall Loss 0.688142    Objective Loss 0.688142    Top1 86.885246    Top5 100.000000    LR 0.000005    Time 0.130037    
2024-04-23 23:01:23,795 - --- validate (epoch=403)-----------
2024-04-23 23:01:23,796 - 3925 samples (32 per mini-batch)
2024-04-23 23:01:39,598 - Epoch: [403][  100/  123]    Loss 0.673886    Top1 78.281250    Top5 97.468750    
2024-04-23 23:01:42,667 - Epoch: [403][  123/  123]    Loss 0.669376    Top1 78.216561    Top5 97.477707    
2024-04-23 23:01:42,867 - ==> Top1: 78.217    Top5: 97.478    Loss: 0.669

2024-04-23 23:01:42,877 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:01:42,878 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:01:42,922 - 

2024-04-23 23:01:42,923 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:01:56,779 - Epoch: [404][  100/  296]    Overall Loss 0.690345    Objective Loss 0.690345                                        LR 0.000005    Time 0.138393    
2024-04-23 23:02:08,152 - Epoch: [404][  200/  296]    Overall Loss 0.688915    Objective Loss 0.688915                                        LR 0.000005    Time 0.125990    
2024-04-23 23:02:20,156 - Epoch: [404][  296/  296]    Overall Loss 0.677955    Objective Loss 0.677955    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.125630    
2024-04-23 23:02:20,396 - --- validate (epoch=404)-----------
2024-04-23 23:02:20,397 - 3925 samples (32 per mini-batch)
2024-04-23 23:02:36,842 - Epoch: [404][  100/  123]    Loss 0.677462    Top1 77.968750    Top5 97.281250    
2024-04-23 23:02:39,931 - Epoch: [404][  123/  123]    Loss 0.668439    Top1 78.216561    Top5 97.375796    
2024-04-23 23:02:40,135 - ==> Top1: 78.217    Top5: 97.376    Loss: 0.668

2024-04-23 23:02:40,146 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:02:40,146 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:02:40,207 - 

2024-04-23 23:02:40,207 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:02:49,496 - Epoch: [405][  100/  296]    Overall Loss 0.656246    Objective Loss 0.656246                                        LR 0.000005    Time 0.092733    
2024-04-23 23:02:57,474 - Epoch: [405][  200/  296]    Overall Loss 0.669656    Objective Loss 0.669656                                        LR 0.000005    Time 0.086184    
2024-04-23 23:03:06,546 - Epoch: [405][  296/  296]    Overall Loss 0.676337    Objective Loss 0.676337    Top1 78.688525    Top5 91.803279    LR 0.000005    Time 0.088835    
2024-04-23 23:03:06,745 - --- validate (epoch=405)-----------
2024-04-23 23:03:06,746 - 3925 samples (32 per mini-batch)
2024-04-23 23:03:22,822 - Epoch: [405][  100/  123]    Loss 0.664623    Top1 78.531250    Top5 97.750000    
2024-04-23 23:03:24,900 - Epoch: [405][  123/  123]    Loss 0.672479    Top1 78.242038    Top5 97.554140    
2024-04-23 23:03:25,060 - ==> Top1: 78.242    Top5: 97.554    Loss: 0.672

2024-04-23 23:03:25,070 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:03:25,071 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:03:25,114 - 

2024-04-23 23:03:25,114 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:03:38,675 - Epoch: [406][  100/  296]    Overall Loss 0.669308    Objective Loss 0.669308                                        LR 0.000005    Time 0.135434    
2024-04-23 23:03:49,073 - Epoch: [406][  200/  296]    Overall Loss 0.660317    Objective Loss 0.660317                                        LR 0.000005    Time 0.119624    
2024-04-23 23:04:02,801 - Epoch: [406][  296/  296]    Overall Loss 0.661435    Objective Loss 0.661435    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.127147    
2024-04-23 23:04:02,991 - --- validate (epoch=406)-----------
2024-04-23 23:04:02,992 - 3925 samples (32 per mini-batch)
2024-04-23 23:04:19,072 - Epoch: [406][  100/  123]    Loss 0.661883    Top1 78.968750    Top5 97.437500    
2024-04-23 23:04:22,938 - Epoch: [406][  123/  123]    Loss 0.670524    Top1 78.471338    Top5 97.579618    
2024-04-23 23:04:23,116 - ==> Top1: 78.471    Top5: 97.580    Loss: 0.671

2024-04-23 23:04:23,126 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:04:23,127 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:04:23,175 - 

2024-04-23 23:04:23,176 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:04:39,487 - Epoch: [407][  100/  296]    Overall Loss 0.648649    Objective Loss 0.648649                                        LR 0.000005    Time 0.162963    
2024-04-23 23:04:50,570 - Epoch: [407][  200/  296]    Overall Loss 0.664686    Objective Loss 0.664686                                        LR 0.000005    Time 0.136816    
2024-04-23 23:05:01,424 - Epoch: [407][  296/  296]    Overall Loss 0.680626    Objective Loss 0.680626    Top1 65.573770    Top5 96.721311    LR 0.000005    Time 0.129058    
2024-04-23 23:05:01,608 - --- validate (epoch=407)-----------
2024-04-23 23:05:01,609 - 3925 samples (32 per mini-batch)
2024-04-23 23:05:18,624 - Epoch: [407][  100/  123]    Loss 0.670006    Top1 78.437500    Top5 97.312500    
2024-04-23 23:05:22,107 - Epoch: [407][  123/  123]    Loss 0.669544    Top1 78.242038    Top5 97.350318    
2024-04-23 23:05:22,317 - ==> Top1: 78.242    Top5: 97.350    Loss: 0.670

2024-04-23 23:05:22,328 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:05:22,328 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:05:22,372 - 

2024-04-23 23:05:22,372 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:05:37,060 - Epoch: [408][  100/  296]    Overall Loss 0.671789    Objective Loss 0.671789                                        LR 0.000005    Time 0.146720    
2024-04-23 23:05:52,676 - Epoch: [408][  200/  296]    Overall Loss 0.682670    Objective Loss 0.682670                                        LR 0.000005    Time 0.151352    
2024-04-23 23:06:04,701 - Epoch: [408][  296/  296]    Overall Loss 0.681061    Objective Loss 0.681061    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.142834    
2024-04-23 23:06:04,855 - --- validate (epoch=408)-----------
2024-04-23 23:06:04,856 - 3925 samples (32 per mini-batch)
2024-04-23 23:06:21,338 - Epoch: [408][  100/  123]    Loss 0.670450    Top1 78.312500    Top5 97.406250    
2024-04-23 23:06:23,971 - Epoch: [408][  123/  123]    Loss 0.670495    Top1 78.318471    Top5 97.528662    
2024-04-23 23:06:24,135 - ==> Top1: 78.318    Top5: 97.529    Loss: 0.670

2024-04-23 23:06:24,146 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:06:24,147 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:06:24,197 - 

2024-04-23 23:06:24,198 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:06:42,048 - Epoch: [409][  100/  296]    Overall Loss 0.693104    Objective Loss 0.693104                                        LR 0.000005    Time 0.178350    
2024-04-23 23:06:56,414 - Epoch: [409][  200/  296]    Overall Loss 0.692440    Objective Loss 0.692440                                        LR 0.000005    Time 0.160931    
2024-04-23 23:07:11,674 - Epoch: [409][  296/  296]    Overall Loss 0.685700    Objective Loss 0.685700    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.160245    
2024-04-23 23:07:11,926 - --- validate (epoch=409)-----------
2024-04-23 23:07:11,927 - 3925 samples (32 per mini-batch)
2024-04-23 23:07:29,198 - Epoch: [409][  100/  123]    Loss 0.671327    Top1 78.062500    Top5 97.281250    
2024-04-23 23:07:32,352 - Epoch: [409][  123/  123]    Loss 0.670570    Top1 78.089172    Top5 97.426752    
2024-04-23 23:07:32,560 - ==> Top1: 78.089    Top5: 97.427    Loss: 0.671

2024-04-23 23:07:32,573 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:07:32,573 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:07:32,629 - 

2024-04-23 23:07:32,630 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:07:44,584 - Epoch: [410][  100/  296]    Overall Loss 0.704935    Objective Loss 0.704935                                        LR 0.000005    Time 0.119378    
2024-04-23 23:07:58,231 - Epoch: [410][  200/  296]    Overall Loss 0.679654    Objective Loss 0.679654                                        LR 0.000005    Time 0.127842    
2024-04-23 23:08:13,006 - Epoch: [410][  296/  296]    Overall Loss 0.680026    Objective Loss 0.680026    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.136240    
2024-04-23 23:08:13,160 - --- validate (epoch=410)-----------
2024-04-23 23:08:13,161 - 3925 samples (32 per mini-batch)
2024-04-23 23:08:29,908 - Epoch: [410][  100/  123]    Loss 0.663658    Top1 78.062500    Top5 97.593750    
2024-04-23 23:08:33,181 - Epoch: [410][  123/  123]    Loss 0.669058    Top1 78.216561    Top5 97.554140    
2024-04-23 23:08:33,330 - ==> Top1: 78.217    Top5: 97.554    Loss: 0.669

2024-04-23 23:08:33,342 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:08:33,343 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:08:33,395 - 

2024-04-23 23:08:33,395 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:08:48,372 - Epoch: [411][  100/  296]    Overall Loss 0.662632    Objective Loss 0.662632                                        LR 0.000005    Time 0.149604    
2024-04-23 23:09:01,800 - Epoch: [411][  200/  296]    Overall Loss 0.671097    Objective Loss 0.671097                                        LR 0.000005    Time 0.141852    
2024-04-23 23:09:12,168 - Epoch: [411][  296/  296]    Overall Loss 0.675780    Objective Loss 0.675780    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.130827    
2024-04-23 23:09:12,374 - --- validate (epoch=411)-----------
2024-04-23 23:09:12,375 - 3925 samples (32 per mini-batch)
2024-04-23 23:09:29,188 - Epoch: [411][  100/  123]    Loss 0.672824    Top1 78.500000    Top5 97.531250    
2024-04-23 23:09:32,703 - Epoch: [411][  123/  123]    Loss 0.670974    Top1 78.318471    Top5 97.579618    
2024-04-23 23:09:32,862 - ==> Top1: 78.318    Top5: 97.580    Loss: 0.671

2024-04-23 23:09:32,867 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:09:32,868 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:09:32,897 - 

2024-04-23 23:09:32,898 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:09:48,203 - Epoch: [412][  100/  296]    Overall Loss 0.699374    Objective Loss 0.699374                                        LR 0.000005    Time 0.152895    
2024-04-23 23:10:01,222 - Epoch: [412][  200/  296]    Overall Loss 0.694657    Objective Loss 0.694657                                        LR 0.000005    Time 0.141460    
2024-04-23 23:10:14,201 - Epoch: [412][  296/  296]    Overall Loss 0.680229    Objective Loss 0.680229    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.139374    
2024-04-23 23:10:14,439 - --- validate (epoch=412)-----------
2024-04-23 23:10:14,440 - 3925 samples (32 per mini-batch)
2024-04-23 23:10:31,247 - Epoch: [412][  100/  123]    Loss 0.659354    Top1 78.968750    Top5 97.468750    
2024-04-23 23:10:35,503 - Epoch: [412][  123/  123]    Loss 0.668186    Top1 78.267516    Top5 97.528662    
2024-04-23 23:10:35,696 - ==> Top1: 78.268    Top5: 97.529    Loss: 0.668

2024-04-23 23:10:35,709 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:10:35,710 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:10:35,757 - 

2024-04-23 23:10:35,758 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:10:56,561 - Epoch: [413][  100/  296]    Overall Loss 0.653393    Objective Loss 0.653393                                        LR 0.000005    Time 0.207836    
2024-04-23 23:11:11,863 - Epoch: [413][  200/  296]    Overall Loss 0.662578    Objective Loss 0.662578                                        LR 0.000005    Time 0.180339    
2024-04-23 23:11:26,790 - Epoch: [413][  296/  296]    Overall Loss 0.661992    Objective Loss 0.661992    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.172234    
2024-04-23 23:11:27,035 - --- validate (epoch=413)-----------
2024-04-23 23:11:27,036 - 3925 samples (32 per mini-batch)
2024-04-23 23:11:39,946 - Epoch: [413][  100/  123]    Loss 0.665163    Top1 78.593750    Top5 97.593750    
2024-04-23 23:11:42,323 - Epoch: [413][  123/  123]    Loss 0.669675    Top1 78.292994    Top5 97.503185    
2024-04-23 23:11:42,515 - ==> Top1: 78.293    Top5: 97.503    Loss: 0.670

2024-04-23 23:11:42,525 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:11:42,525 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:11:42,567 - 

2024-04-23 23:11:42,568 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:11:53,471 - Epoch: [414][  100/  296]    Overall Loss 0.686892    Objective Loss 0.686892                                        LR 0.000005    Time 0.108861    
2024-04-23 23:12:04,169 - Epoch: [414][  200/  296]    Overall Loss 0.673536    Objective Loss 0.673536                                        LR 0.000005    Time 0.107843    
2024-04-23 23:12:13,061 - Epoch: [414][  296/  296]    Overall Loss 0.672690    Objective Loss 0.672690    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.102856    
2024-04-23 23:12:13,265 - --- validate (epoch=414)-----------
2024-04-23 23:12:13,265 - 3925 samples (32 per mini-batch)
2024-04-23 23:12:26,139 - Epoch: [414][  100/  123]    Loss 0.661165    Top1 78.125000    Top5 97.593750    
2024-04-23 23:12:28,207 - Epoch: [414][  123/  123]    Loss 0.670809    Top1 78.012739    Top5 97.630573    
2024-04-23 23:12:28,365 - ==> Top1: 78.013    Top5: 97.631    Loss: 0.671

2024-04-23 23:12:28,374 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:12:28,375 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:12:28,411 - 

2024-04-23 23:12:28,411 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:12:40,985 - Epoch: [415][  100/  296]    Overall Loss 0.657026    Objective Loss 0.657026                                        LR 0.000005    Time 0.125558    
2024-04-23 23:12:51,735 - Epoch: [415][  200/  296]    Overall Loss 0.666777    Objective Loss 0.666777                                        LR 0.000005    Time 0.116437    
2024-04-23 23:13:02,246 - Epoch: [415][  296/  296]    Overall Loss 0.661395    Objective Loss 0.661395    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.114128    
2024-04-23 23:13:02,433 - --- validate (epoch=415)-----------
2024-04-23 23:13:02,433 - 3925 samples (32 per mini-batch)
2024-04-23 23:13:20,141 - Epoch: [415][  100/  123]    Loss 0.670413    Top1 78.218750    Top5 97.500000    
2024-04-23 23:13:24,342 - Epoch: [415][  123/  123]    Loss 0.670362    Top1 78.318471    Top5 97.528662    
2024-04-23 23:13:24,519 - ==> Top1: 78.318    Top5: 97.529    Loss: 0.670

2024-04-23 23:13:24,532 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:13:24,532 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:13:24,578 - 

2024-04-23 23:13:24,578 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:13:40,406 - Epoch: [416][  100/  296]    Overall Loss 0.691820    Objective Loss 0.691820                                        LR 0.000005    Time 0.158102    
2024-04-23 23:13:54,442 - Epoch: [416][  200/  296]    Overall Loss 0.687955    Objective Loss 0.687955                                        LR 0.000005    Time 0.149151    
2024-04-23 23:14:08,114 - Epoch: [416][  296/  296]    Overall Loss 0.678875    Objective Loss 0.678875    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.146916    
2024-04-23 23:14:08,361 - --- validate (epoch=416)-----------
2024-04-23 23:14:08,361 - 3925 samples (32 per mini-batch)
2024-04-23 23:14:24,700 - Epoch: [416][  100/  123]    Loss 0.674593    Top1 77.968750    Top5 97.437500    
2024-04-23 23:14:28,434 - Epoch: [416][  123/  123]    Loss 0.668269    Top1 78.114650    Top5 97.503185    
2024-04-23 23:14:28,649 - ==> Top1: 78.115    Top5: 97.503    Loss: 0.668

2024-04-23 23:14:28,662 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:14:28,663 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:14:28,722 - 

2024-04-23 23:14:28,723 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:14:45,817 - Epoch: [417][  100/  296]    Overall Loss 0.697706    Objective Loss 0.697706                                        LR 0.000005    Time 0.170749    
2024-04-23 23:15:01,903 - Epoch: [417][  200/  296]    Overall Loss 0.690311    Objective Loss 0.690311                                        LR 0.000005    Time 0.165713    
2024-04-23 23:15:15,162 - Epoch: [417][  296/  296]    Overall Loss 0.680888    Objective Loss 0.680888    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.156709    
2024-04-23 23:15:15,375 - --- validate (epoch=417)-----------
2024-04-23 23:15:15,376 - 3925 samples (32 per mini-batch)
2024-04-23 23:15:30,512 - Epoch: [417][  100/  123]    Loss 0.671711    Top1 78.250000    Top5 97.562500    
2024-04-23 23:15:33,391 - Epoch: [417][  123/  123]    Loss 0.670035    Top1 78.191083    Top5 97.477707    
2024-04-23 23:15:33,532 - ==> Top1: 78.191    Top5: 97.478    Loss: 0.670

2024-04-23 23:15:33,543 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:15:33,544 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:15:33,592 - 

2024-04-23 23:15:33,593 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:15:48,476 - Epoch: [418][  100/  296]    Overall Loss 0.661766    Objective Loss 0.661766                                        LR 0.000005    Time 0.148666    
2024-04-23 23:16:01,790 - Epoch: [418][  200/  296]    Overall Loss 0.675903    Objective Loss 0.675903                                        LR 0.000005    Time 0.140818    
2024-04-23 23:16:14,966 - Epoch: [418][  296/  296]    Overall Loss 0.669330    Objective Loss 0.669330    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.139610    
2024-04-23 23:16:15,222 - --- validate (epoch=418)-----------
2024-04-23 23:16:15,223 - 3925 samples (32 per mini-batch)
2024-04-23 23:16:31,159 - Epoch: [418][  100/  123]    Loss 0.670222    Top1 78.218750    Top5 97.625000    
2024-04-23 23:16:34,526 - Epoch: [418][  123/  123]    Loss 0.670335    Top1 78.038217    Top5 97.630573    
2024-04-23 23:16:34,678 - ==> Top1: 78.038    Top5: 97.631    Loss: 0.670

2024-04-23 23:16:34,690 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:16:34,690 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:16:34,740 - 

2024-04-23 23:16:34,740 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:16:48,525 - Epoch: [419][  100/  296]    Overall Loss 0.707775    Objective Loss 0.707775                                        LR 0.000005    Time 0.137685    
2024-04-23 23:17:02,886 - Epoch: [419][  200/  296]    Overall Loss 0.695029    Objective Loss 0.695029                                        LR 0.000005    Time 0.140563    
2024-04-23 23:17:15,404 - Epoch: [419][  296/  296]    Overall Loss 0.686970    Objective Loss 0.686970    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.137217    
2024-04-23 23:17:15,618 - --- validate (epoch=419)-----------
2024-04-23 23:17:15,619 - 3925 samples (32 per mini-batch)
2024-04-23 23:17:33,428 - Epoch: [419][  100/  123]    Loss 0.673525    Top1 77.718750    Top5 97.625000    
2024-04-23 23:17:37,177 - Epoch: [419][  123/  123]    Loss 0.666539    Top1 78.114650    Top5 97.656051    
2024-04-23 23:17:37,323 - ==> Top1: 78.115    Top5: 97.656    Loss: 0.667

2024-04-23 23:17:37,331 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:17:37,332 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:17:37,377 - 

2024-04-23 23:17:37,378 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:17:51,327 - Epoch: [420][  100/  296]    Overall Loss 0.698136    Objective Loss 0.698136                                        LR 0.000005    Time 0.139323    
2024-04-23 23:18:06,343 - Epoch: [420][  200/  296]    Overall Loss 0.682733    Objective Loss 0.682733                                        LR 0.000005    Time 0.144660    
2024-04-23 23:18:20,885 - Epoch: [420][  296/  296]    Overall Loss 0.690600    Objective Loss 0.690600    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.146814    
2024-04-23 23:18:21,126 - --- validate (epoch=420)-----------
2024-04-23 23:18:21,127 - 3925 samples (32 per mini-batch)
2024-04-23 23:18:39,033 - Epoch: [420][  100/  123]    Loss 0.672015    Top1 78.500000    Top5 97.468750    
2024-04-23 23:18:42,753 - Epoch: [420][  123/  123]    Loss 0.669916    Top1 78.318471    Top5 97.528662    
2024-04-23 23:18:42,916 - ==> Top1: 78.318    Top5: 97.529    Loss: 0.670

2024-04-23 23:18:42,928 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:18:42,929 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:18:42,976 - 

2024-04-23 23:18:42,977 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:18:59,726 - Epoch: [421][  100/  296]    Overall Loss 0.680672    Objective Loss 0.680672                                        LR 0.000005    Time 0.167320    
2024-04-23 23:19:11,658 - Epoch: [421][  200/  296]    Overall Loss 0.684884    Objective Loss 0.684884                                        LR 0.000005    Time 0.143249    
2024-04-23 23:19:23,830 - Epoch: [421][  296/  296]    Overall Loss 0.673106    Objective Loss 0.673106    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.137859    
2024-04-23 23:19:24,036 - --- validate (epoch=421)-----------
2024-04-23 23:19:24,037 - 3925 samples (32 per mini-batch)
2024-04-23 23:19:43,447 - Epoch: [421][  100/  123]    Loss 0.673250    Top1 77.437500    Top5 97.718750    
2024-04-23 23:19:47,128 - Epoch: [421][  123/  123]    Loss 0.670340    Top1 77.910828    Top5 97.503185    
2024-04-23 23:19:47,363 - ==> Top1: 77.911    Top5: 97.503    Loss: 0.670

2024-04-23 23:19:47,371 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:19:47,372 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:19:47,409 - 

2024-04-23 23:19:47,410 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:19:59,458 - Epoch: [422][  100/  296]    Overall Loss 0.689661    Objective Loss 0.689661                                        LR 0.000005    Time 0.120313    
2024-04-23 23:20:09,332 - Epoch: [422][  200/  296]    Overall Loss 0.682461    Objective Loss 0.682461                                        LR 0.000005    Time 0.109446    
2024-04-23 23:20:22,566 - Epoch: [422][  296/  296]    Overall Loss 0.685664    Objective Loss 0.685664    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.118612    
2024-04-23 23:20:22,729 - --- validate (epoch=422)-----------
2024-04-23 23:20:22,730 - 3925 samples (32 per mini-batch)
2024-04-23 23:20:36,613 - Epoch: [422][  100/  123]    Loss 0.658255    Top1 78.562500    Top5 97.375000    
2024-04-23 23:20:41,517 - Epoch: [422][  123/  123]    Loss 0.669855    Top1 78.420382    Top5 97.452229    
2024-04-23 23:20:41,759 - ==> Top1: 78.420    Top5: 97.452    Loss: 0.670

2024-04-23 23:20:41,777 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:20:41,778 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:20:41,834 - 

2024-04-23 23:20:41,835 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:21:02,419 - Epoch: [423][  100/  296]    Overall Loss 0.670636    Objective Loss 0.670636                                        LR 0.000005    Time 0.205737    
2024-04-23 23:21:17,797 - Epoch: [423][  200/  296]    Overall Loss 0.686510    Objective Loss 0.686510                                        LR 0.000005    Time 0.179692    
2024-04-23 23:21:31,284 - Epoch: [423][  296/  296]    Overall Loss 0.678279    Objective Loss 0.678279    Top1 90.163934    Top5 98.360656    LR 0.000005    Time 0.166934    
2024-04-23 23:21:31,468 - --- validate (epoch=423)-----------
2024-04-23 23:21:31,469 - 3925 samples (32 per mini-batch)
2024-04-23 23:21:47,124 - Epoch: [423][  100/  123]    Loss 0.681131    Top1 78.375000    Top5 97.468750    
2024-04-23 23:21:50,870 - Epoch: [423][  123/  123]    Loss 0.671282    Top1 78.292994    Top5 97.477707    
2024-04-23 23:21:51,059 - ==> Top1: 78.293    Top5: 97.478    Loss: 0.671

2024-04-23 23:21:51,070 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:21:51,070 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:21:51,115 - 

2024-04-23 23:21:51,115 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:22:06,982 - Epoch: [424][  100/  296]    Overall Loss 0.670108    Objective Loss 0.670108                                        LR 0.000005    Time 0.158555    
2024-04-23 23:22:18,703 - Epoch: [424][  200/  296]    Overall Loss 0.663518    Objective Loss 0.663518                                        LR 0.000005    Time 0.137826    
2024-04-23 23:22:31,193 - Epoch: [424][  296/  296]    Overall Loss 0.667319    Objective Loss 0.667319    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.135278    
2024-04-23 23:22:31,417 - --- validate (epoch=424)-----------
2024-04-23 23:22:31,418 - 3925 samples (32 per mini-batch)
2024-04-23 23:22:47,642 - Epoch: [424][  100/  123]    Loss 0.653564    Top1 78.750000    Top5 97.406250    
2024-04-23 23:22:51,642 - Epoch: [424][  123/  123]    Loss 0.665991    Top1 78.369427    Top5 97.477707    
2024-04-23 23:22:51,782 - ==> Top1: 78.369    Top5: 97.478    Loss: 0.666

2024-04-23 23:22:51,793 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:22:51,793 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:22:51,845 - 

2024-04-23 23:22:51,846 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:23:06,558 - Epoch: [425][  100/  296]    Overall Loss 0.661551    Objective Loss 0.661551                                        LR 0.000005    Time 0.146970    
2024-04-23 23:23:20,698 - Epoch: [425][  200/  296]    Overall Loss 0.648607    Objective Loss 0.648607                                        LR 0.000005    Time 0.144107    
2024-04-23 23:23:33,466 - Epoch: [425][  296/  296]    Overall Loss 0.664791    Objective Loss 0.664791    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.140458    
2024-04-23 23:23:33,628 - --- validate (epoch=425)-----------
2024-04-23 23:23:33,629 - 3925 samples (32 per mini-batch)
2024-04-23 23:23:49,353 - Epoch: [425][  100/  123]    Loss 0.673216    Top1 78.500000    Top5 97.500000    
2024-04-23 23:23:53,024 - Epoch: [425][  123/  123]    Loss 0.673583    Top1 78.369427    Top5 97.477707    
2024-04-23 23:23:53,262 - ==> Top1: 78.369    Top5: 97.478    Loss: 0.674

2024-04-23 23:23:53,272 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:23:53,273 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:23:53,313 - 

2024-04-23 23:23:53,314 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:24:04,151 - Epoch: [426][  100/  296]    Overall Loss 0.682462    Objective Loss 0.682462                                        LR 0.000005    Time 0.108186    
2024-04-23 23:24:13,388 - Epoch: [426][  200/  296]    Overall Loss 0.672652    Objective Loss 0.672652                                        LR 0.000005    Time 0.100199    
2024-04-23 23:24:22,483 - Epoch: [426][  296/  296]    Overall Loss 0.673744    Objective Loss 0.673744    Top1 77.049180    Top5 91.803279    LR 0.000005    Time 0.098378    
2024-04-23 23:24:22,631 - --- validate (epoch=426)-----------
2024-04-23 23:24:22,632 - 3925 samples (32 per mini-batch)
2024-04-23 23:24:38,914 - Epoch: [426][  100/  123]    Loss 0.676655    Top1 77.718750    Top5 97.343750    
2024-04-23 23:24:42,265 - Epoch: [426][  123/  123]    Loss 0.668568    Top1 78.140127    Top5 97.375796    
2024-04-23 23:24:42,452 - ==> Top1: 78.140    Top5: 97.376    Loss: 0.669

2024-04-23 23:24:42,463 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:24:42,463 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:24:42,508 - 

2024-04-23 23:24:42,508 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:24:56,727 - Epoch: [427][  100/  296]    Overall Loss 0.640719    Objective Loss 0.640719                                        LR 0.000005    Time 0.141995    
2024-04-23 23:25:12,292 - Epoch: [427][  200/  296]    Overall Loss 0.647181    Objective Loss 0.647181                                        LR 0.000005    Time 0.148749    
2024-04-23 23:25:24,979 - Epoch: [427][  296/  296]    Overall Loss 0.667126    Objective Loss 0.667126    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.143312    
2024-04-23 23:25:25,173 - --- validate (epoch=427)-----------
2024-04-23 23:25:25,174 - 3925 samples (32 per mini-batch)
2024-04-23 23:25:42,424 - Epoch: [427][  100/  123]    Loss 0.667411    Top1 78.375000    Top5 97.281250    
2024-04-23 23:25:45,293 - Epoch: [427][  123/  123]    Loss 0.668395    Top1 78.216561    Top5 97.528662    
2024-04-23 23:25:45,473 - ==> Top1: 78.217    Top5: 97.529    Loss: 0.668

2024-04-23 23:25:45,484 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:25:45,485 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:25:45,532 - 

2024-04-23 23:25:45,533 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:25:59,089 - Epoch: [428][  100/  296]    Overall Loss 0.690249    Objective Loss 0.690249                                        LR 0.000005    Time 0.135388    
2024-04-23 23:26:11,516 - Epoch: [428][  200/  296]    Overall Loss 0.666854    Objective Loss 0.666854                                        LR 0.000005    Time 0.129743    
2024-04-23 23:26:23,363 - Epoch: [428][  296/  296]    Overall Loss 0.663513    Objective Loss 0.663513    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.127637    
2024-04-23 23:26:23,518 - --- validate (epoch=428)-----------
2024-04-23 23:26:23,519 - 3925 samples (32 per mini-batch)
2024-04-23 23:26:35,319 - Epoch: [428][  100/  123]    Loss 0.665904    Top1 78.187500    Top5 97.531250    
2024-04-23 23:26:38,265 - Epoch: [428][  123/  123]    Loss 0.669258    Top1 78.063694    Top5 97.528662    
2024-04-23 23:26:38,420 - ==> Top1: 78.064    Top5: 97.529    Loss: 0.669

2024-04-23 23:26:38,425 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:26:38,425 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:26:38,452 - 

2024-04-23 23:26:38,453 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:26:48,735 - Epoch: [429][  100/  296]    Overall Loss 0.673005    Objective Loss 0.673005                                        LR 0.000005    Time 0.102652    
2024-04-23 23:26:59,585 - Epoch: [429][  200/  296]    Overall Loss 0.670439    Objective Loss 0.670439                                        LR 0.000005    Time 0.105496    
2024-04-23 23:27:14,131 - Epoch: [429][  296/  296]    Overall Loss 0.677234    Objective Loss 0.677234    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.120375    
2024-04-23 23:27:14,344 - --- validate (epoch=429)-----------
2024-04-23 23:27:14,345 - 3925 samples (32 per mini-batch)
2024-04-23 23:27:30,669 - Epoch: [429][  100/  123]    Loss 0.667714    Top1 78.312500    Top5 97.437500    
2024-04-23 23:27:33,239 - Epoch: [429][  123/  123]    Loss 0.667332    Top1 78.420382    Top5 97.528662    
2024-04-23 23:27:33,412 - ==> Top1: 78.420    Top5: 97.529    Loss: 0.667

2024-04-23 23:27:33,421 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:27:33,422 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:27:33,468 - 

2024-04-23 23:27:33,469 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:27:46,698 - Epoch: [430][  100/  296]    Overall Loss 0.668240    Objective Loss 0.668240                                        LR 0.000005    Time 0.132142    
2024-04-23 23:27:57,218 - Epoch: [430][  200/  296]    Overall Loss 0.667043    Objective Loss 0.667043                                        LR 0.000005    Time 0.118593    
2024-04-23 23:28:08,874 - Epoch: [430][  296/  296]    Overall Loss 0.677993    Objective Loss 0.677993    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.119456    
2024-04-23 23:28:09,089 - --- validate (epoch=430)-----------
2024-04-23 23:28:09,090 - 3925 samples (32 per mini-batch)
2024-04-23 23:28:25,455 - Epoch: [430][  100/  123]    Loss 0.666365    Top1 78.093750    Top5 97.687500    
2024-04-23 23:28:27,917 - Epoch: [430][  123/  123]    Loss 0.668342    Top1 78.242038    Top5 97.452229    
2024-04-23 23:28:28,082 - ==> Top1: 78.242    Top5: 97.452    Loss: 0.668

2024-04-23 23:28:28,087 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:28:28,087 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:28:28,125 - 

2024-04-23 23:28:28,125 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:28:41,379 - Epoch: [431][  100/  296]    Overall Loss 0.671328    Objective Loss 0.671328                                        LR 0.000005    Time 0.132375    
2024-04-23 23:28:51,748 - Epoch: [431][  200/  296]    Overall Loss 0.672074    Objective Loss 0.672074                                        LR 0.000005    Time 0.117963    
2024-04-23 23:29:01,963 - Epoch: [431][  296/  296]    Overall Loss 0.674550    Objective Loss 0.674550    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.114166    
2024-04-23 23:29:02,190 - --- validate (epoch=431)-----------
2024-04-23 23:29:02,191 - 3925 samples (32 per mini-batch)
2024-04-23 23:29:18,979 - Epoch: [431][  100/  123]    Loss 0.664594    Top1 78.625000    Top5 97.687500    
2024-04-23 23:29:22,453 - Epoch: [431][  123/  123]    Loss 0.668516    Top1 78.522293    Top5 97.426752    
2024-04-23 23:29:22,681 - ==> Top1: 78.522    Top5: 97.427    Loss: 0.669

2024-04-23 23:29:22,693 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:29:22,694 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:29:22,740 - 

2024-04-23 23:29:22,741 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:29:35,298 - Epoch: [432][  100/  296]    Overall Loss 0.672618    Objective Loss 0.672618                                        LR 0.000005    Time 0.125408    
2024-04-23 23:29:48,419 - Epoch: [432][  200/  296]    Overall Loss 0.677435    Objective Loss 0.677435                                        LR 0.000005    Time 0.128228    
2024-04-23 23:29:58,515 - Epoch: [432][  296/  296]    Overall Loss 0.674710    Objective Loss 0.674710    Top1 65.573770    Top5 96.721311    LR 0.000005    Time 0.120688    
2024-04-23 23:29:58,692 - --- validate (epoch=432)-----------
2024-04-23 23:29:58,692 - 3925 samples (32 per mini-batch)
2024-04-23 23:30:11,740 - Epoch: [432][  100/  123]    Loss 0.667227    Top1 78.093750    Top5 97.562500    
2024-04-23 23:30:14,796 - Epoch: [432][  123/  123]    Loss 0.667891    Top1 78.114650    Top5 97.503185    
2024-04-23 23:30:14,964 - ==> Top1: 78.115    Top5: 97.503    Loss: 0.668

2024-04-23 23:30:14,975 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:30:14,976 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:30:15,018 - 

2024-04-23 23:30:15,019 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:30:27,449 - Epoch: [433][  100/  296]    Overall Loss 0.675656    Objective Loss 0.675656                                        LR 0.000005    Time 0.124131    
2024-04-23 23:30:37,457 - Epoch: [433][  200/  296]    Overall Loss 0.677914    Objective Loss 0.677914                                        LR 0.000005    Time 0.112027    
2024-04-23 23:30:46,894 - Epoch: [433][  296/  296]    Overall Loss 0.679536    Objective Loss 0.679536    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.107530    
2024-04-23 23:30:47,063 - --- validate (epoch=433)-----------
2024-04-23 23:30:47,063 - 3925 samples (32 per mini-batch)
2024-04-23 23:31:00,645 - Epoch: [433][  100/  123]    Loss 0.672349    Top1 78.312500    Top5 97.437500    
2024-04-23 23:31:02,823 - Epoch: [433][  123/  123]    Loss 0.668370    Top1 78.242038    Top5 97.528662    
2024-04-23 23:31:02,992 - ==> Top1: 78.242    Top5: 97.529    Loss: 0.668

2024-04-23 23:31:03,003 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:31:03,003 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:31:03,045 - 

2024-04-23 23:31:03,046 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:31:19,169 - Epoch: [434][  100/  296]    Overall Loss 0.701617    Objective Loss 0.701617                                        LR 0.000005    Time 0.161057    
2024-04-23 23:31:28,752 - Epoch: [434][  200/  296]    Overall Loss 0.682076    Objective Loss 0.682076                                        LR 0.000005    Time 0.128371    
2024-04-23 23:31:37,699 - Epoch: [434][  296/  296]    Overall Loss 0.674450    Objective Loss 0.674450    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.116915    
2024-04-23 23:31:37,940 - --- validate (epoch=434)-----------
2024-04-23 23:31:37,941 - 3925 samples (32 per mini-batch)
2024-04-23 23:31:48,686 - Epoch: [434][  100/  123]    Loss 0.665932    Top1 78.218750    Top5 97.562500    
2024-04-23 23:31:50,906 - Epoch: [434][  123/  123]    Loss 0.669230    Top1 78.216561    Top5 97.401274    
2024-04-23 23:31:51,097 - ==> Top1: 78.217    Top5: 97.401    Loss: 0.669

2024-04-23 23:31:51,107 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:31:51,107 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:31:51,148 - 

2024-04-23 23:31:51,149 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:32:00,280 - Epoch: [435][  100/  296]    Overall Loss 0.672697    Objective Loss 0.672697                                        LR 0.000005    Time 0.091160    
2024-04-23 23:32:08,417 - Epoch: [435][  200/  296]    Overall Loss 0.672006    Objective Loss 0.672006                                        LR 0.000005    Time 0.086192    
2024-04-23 23:32:15,177 - Epoch: [435][  296/  296]    Overall Loss 0.664520    Objective Loss 0.664520    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.081039    
2024-04-23 23:32:15,345 - --- validate (epoch=435)-----------
2024-04-23 23:32:15,345 - 3925 samples (32 per mini-batch)
2024-04-23 23:32:25,991 - Epoch: [435][  100/  123]    Loss 0.671849    Top1 78.375000    Top5 97.343750    
2024-04-23 23:32:28,100 - Epoch: [435][  123/  123]    Loss 0.671191    Top1 78.165605    Top5 97.299363    
2024-04-23 23:32:28,205 - ==> Top1: 78.166    Top5: 97.299    Loss: 0.671

2024-04-23 23:32:28,214 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:32:28,215 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:32:28,251 - 

2024-04-23 23:32:28,252 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:32:41,026 - Epoch: [436][  100/  296]    Overall Loss 0.677632    Objective Loss 0.677632                                        LR 0.000005    Time 0.127606    
2024-04-23 23:32:52,215 - Epoch: [436][  200/  296]    Overall Loss 0.677792    Objective Loss 0.677792                                        LR 0.000005    Time 0.119685    
2024-04-23 23:32:59,110 - Epoch: [436][  296/  296]    Overall Loss 0.683305    Objective Loss 0.683305    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.104121    
2024-04-23 23:32:59,302 - --- validate (epoch=436)-----------
2024-04-23 23:32:59,303 - 3925 samples (32 per mini-batch)
2024-04-23 23:33:11,281 - Epoch: [436][  100/  123]    Loss 0.669540    Top1 78.062500    Top5 97.531250    
2024-04-23 23:33:13,529 - Epoch: [436][  123/  123]    Loss 0.669221    Top1 78.267516    Top5 97.554140    
2024-04-23 23:33:13,649 - ==> Top1: 78.268    Top5: 97.554    Loss: 0.669

2024-04-23 23:33:13,657 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:33:13,657 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:33:13,692 - 

2024-04-23 23:33:13,692 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:33:22,834 - Epoch: [437][  100/  296]    Overall Loss 0.655621    Objective Loss 0.655621                                        LR 0.000005    Time 0.091281    
2024-04-23 23:33:31,756 - Epoch: [437][  200/  296]    Overall Loss 0.671713    Objective Loss 0.671713                                        LR 0.000005    Time 0.090186    
2024-04-23 23:33:42,635 - Epoch: [437][  296/  296]    Overall Loss 0.673526    Objective Loss 0.673526    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.097645    
2024-04-23 23:33:42,785 - --- validate (epoch=437)-----------
2024-04-23 23:33:42,786 - 3925 samples (32 per mini-batch)
2024-04-23 23:33:55,759 - Epoch: [437][  100/  123]    Loss 0.652814    Top1 78.375000    Top5 97.593750    
2024-04-23 23:33:57,783 - Epoch: [437][  123/  123]    Loss 0.667652    Top1 78.292994    Top5 97.503185    
2024-04-23 23:33:57,926 - ==> Top1: 78.293    Top5: 97.503    Loss: 0.668

2024-04-23 23:33:57,935 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:33:57,936 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:33:57,970 - 

2024-04-23 23:33:57,971 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:34:07,925 - Epoch: [438][  100/  296]    Overall Loss 0.639656    Objective Loss 0.639656                                        LR 0.000005    Time 0.099406    
2024-04-23 23:34:18,335 - Epoch: [438][  200/  296]    Overall Loss 0.667414    Objective Loss 0.667414                                        LR 0.000005    Time 0.101687    
2024-04-23 23:34:25,672 - Epoch: [438][  296/  296]    Overall Loss 0.680865    Objective Loss 0.680865    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.093453    
2024-04-23 23:34:25,807 - --- validate (epoch=438)-----------
2024-04-23 23:34:25,807 - 3925 samples (32 per mini-batch)
2024-04-23 23:34:38,520 - Epoch: [438][  100/  123]    Loss 0.668017    Top1 78.000000    Top5 97.625000    
2024-04-23 23:34:41,297 - Epoch: [438][  123/  123]    Loss 0.666547    Top1 78.165605    Top5 97.579618    
2024-04-23 23:34:41,440 - ==> Top1: 78.166    Top5: 97.580    Loss: 0.667

2024-04-23 23:34:41,449 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:34:41,450 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:34:41,492 - 

2024-04-23 23:34:41,493 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:34:52,978 - Epoch: [439][  100/  296]    Overall Loss 0.664324    Objective Loss 0.664324                                        LR 0.000005    Time 0.114706    
2024-04-23 23:35:03,208 - Epoch: [439][  200/  296]    Overall Loss 0.675554    Objective Loss 0.675554                                        LR 0.000005    Time 0.108447    
2024-04-23 23:35:13,904 - Epoch: [439][  296/  296]    Overall Loss 0.665588    Objective Loss 0.665588    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.109366    
2024-04-23 23:35:14,076 - --- validate (epoch=439)-----------
2024-04-23 23:35:14,076 - 3925 samples (32 per mini-batch)
2024-04-23 23:35:27,172 - Epoch: [439][  100/  123]    Loss 0.656293    Top1 78.531250    Top5 97.562500    
2024-04-23 23:35:29,789 - Epoch: [439][  123/  123]    Loss 0.669549    Top1 78.267516    Top5 97.477707    
2024-04-23 23:35:29,904 - ==> Top1: 78.268    Top5: 97.478    Loss: 0.670

2024-04-23 23:35:29,910 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:35:29,910 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:35:29,943 - 

2024-04-23 23:35:29,943 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:35:42,190 - Epoch: [440][  100/  296]    Overall Loss 0.685588    Objective Loss 0.685588                                        LR 0.000005    Time 0.122335    
2024-04-23 23:35:51,662 - Epoch: [440][  200/  296]    Overall Loss 0.671731    Objective Loss 0.671731                                        LR 0.000005    Time 0.108462    
2024-04-23 23:36:01,025 - Epoch: [440][  296/  296]    Overall Loss 0.670142    Objective Loss 0.670142    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.104879    
2024-04-23 23:36:01,159 - --- validate (epoch=440)-----------
2024-04-23 23:36:01,160 - 3925 samples (32 per mini-batch)
2024-04-23 23:36:14,004 - Epoch: [440][  100/  123]    Loss 0.683445    Top1 77.750000    Top5 97.343750    
2024-04-23 23:36:17,481 - Epoch: [440][  123/  123]    Loss 0.665725    Top1 78.343949    Top5 97.528662    
2024-04-23 23:36:17,614 - ==> Top1: 78.344    Top5: 97.529    Loss: 0.666

2024-04-23 23:36:17,624 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:36:17,625 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:36:17,667 - 

2024-04-23 23:36:17,667 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:36:28,404 - Epoch: [441][  100/  296]    Overall Loss 0.657034    Objective Loss 0.657034                                        LR 0.000005    Time 0.107230    
2024-04-23 23:36:36,493 - Epoch: [441][  200/  296]    Overall Loss 0.663120    Objective Loss 0.663120                                        LR 0.000005    Time 0.093996    
2024-04-23 23:36:43,568 - Epoch: [441][  296/  296]    Overall Loss 0.666971    Objective Loss 0.666971    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.087375    
2024-04-23 23:36:43,708 - --- validate (epoch=441)-----------
2024-04-23 23:36:43,709 - 3925 samples (32 per mini-batch)
2024-04-23 23:36:55,116 - Epoch: [441][  100/  123]    Loss 0.662092    Top1 78.687500    Top5 97.500000    
2024-04-23 23:36:58,019 - Epoch: [441][  123/  123]    Loss 0.669011    Top1 78.420382    Top5 97.299363    
2024-04-23 23:36:58,172 - ==> Top1: 78.420    Top5: 97.299    Loss: 0.669

2024-04-23 23:36:58,181 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:36:58,182 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:36:58,223 - 

2024-04-23 23:36:58,223 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:37:11,694 - Epoch: [442][  100/  296]    Overall Loss 0.686488    Objective Loss 0.686488                                        LR 0.000005    Time 0.134580    
2024-04-23 23:37:22,734 - Epoch: [442][  200/  296]    Overall Loss 0.663146    Objective Loss 0.663146                                        LR 0.000005    Time 0.122425    
2024-04-23 23:37:33,518 - Epoch: [442][  296/  296]    Overall Loss 0.675004    Objective Loss 0.675004    Top1 65.573770    Top5 98.360656    LR 0.000005    Time 0.119113    
2024-04-23 23:37:33,700 - --- validate (epoch=442)-----------
2024-04-23 23:37:33,702 - 3925 samples (32 per mini-batch)
2024-04-23 23:37:47,379 - Epoch: [442][  100/  123]    Loss 0.666270    Top1 78.750000    Top5 97.500000    
2024-04-23 23:37:49,872 - Epoch: [442][  123/  123]    Loss 0.672586    Top1 78.598726    Top5 97.401274    
2024-04-23 23:37:50,014 - ==> Top1: 78.599    Top5: 97.401    Loss: 0.673

2024-04-23 23:37:50,022 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:37:50,022 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:37:50,059 - 

2024-04-23 23:37:50,059 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:38:01,854 - Epoch: [443][  100/  296]    Overall Loss 0.690064    Objective Loss 0.690064                                        LR 0.000005    Time 0.117823    
2024-04-23 23:38:11,988 - Epoch: [443][  200/  296]    Overall Loss 0.680594    Objective Loss 0.680594                                        LR 0.000005    Time 0.109514    
2024-04-23 23:38:22,591 - Epoch: [443][  296/  296]    Overall Loss 0.679728    Objective Loss 0.679728    Top1 68.852459    Top5 100.000000    LR 0.000005    Time 0.109773    
2024-04-23 23:38:22,759 - --- validate (epoch=443)-----------
2024-04-23 23:38:22,760 - 3925 samples (32 per mini-batch)
2024-04-23 23:38:34,583 - Epoch: [443][  100/  123]    Loss 0.668240    Top1 78.843750    Top5 97.593750    
2024-04-23 23:38:37,186 - Epoch: [443][  123/  123]    Loss 0.669935    Top1 78.471338    Top5 97.503185    
2024-04-23 23:38:37,292 - ==> Top1: 78.471    Top5: 97.503    Loss: 0.670

2024-04-23 23:38:37,302 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:38:37,302 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:38:37,348 - 

2024-04-23 23:38:37,349 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:38:48,196 - Epoch: [444][  100/  296]    Overall Loss 0.677195    Objective Loss 0.677195                                        LR 0.000005    Time 0.108334    
2024-04-23 23:38:57,344 - Epoch: [444][  200/  296]    Overall Loss 0.679925    Objective Loss 0.679925                                        LR 0.000005    Time 0.099834    
2024-04-23 23:39:07,494 - Epoch: [444][  296/  296]    Overall Loss 0.671206    Objective Loss 0.671206    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.101699    
2024-04-23 23:39:07,644 - --- validate (epoch=444)-----------
2024-04-23 23:39:07,645 - 3925 samples (32 per mini-batch)
2024-04-23 23:39:20,941 - Epoch: [444][  100/  123]    Loss 0.684541    Top1 77.875000    Top5 97.406250    
2024-04-23 23:39:22,925 - Epoch: [444][  123/  123]    Loss 0.670041    Top1 78.522293    Top5 97.375796    
2024-04-23 23:39:23,042 - ==> Top1: 78.522    Top5: 97.376    Loss: 0.670

2024-04-23 23:39:23,052 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:39:23,052 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:39:23,090 - 

2024-04-23 23:39:23,090 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:39:36,106 - Epoch: [445][  100/  296]    Overall Loss 0.663530    Objective Loss 0.663530                                        LR 0.000005    Time 0.130021    
2024-04-23 23:39:47,960 - Epoch: [445][  200/  296]    Overall Loss 0.686900    Objective Loss 0.686900                                        LR 0.000005    Time 0.124217    
2024-04-23 23:39:58,237 - Epoch: [445][  296/  296]    Overall Loss 0.691807    Objective Loss 0.691807    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.118602    
2024-04-23 23:39:58,422 - --- validate (epoch=445)-----------
2024-04-23 23:39:58,423 - 3925 samples (32 per mini-batch)
2024-04-23 23:40:12,740 - Epoch: [445][  100/  123]    Loss 0.663877    Top1 79.031250    Top5 97.500000    
2024-04-23 23:40:15,337 - Epoch: [445][  123/  123]    Loss 0.668808    Top1 78.496815    Top5 97.554140    
2024-04-23 23:40:15,501 - ==> Top1: 78.497    Top5: 97.554    Loss: 0.669

2024-04-23 23:40:15,511 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:40:15,511 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:40:15,555 - 

2024-04-23 23:40:15,556 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:40:29,921 - Epoch: [446][  100/  296]    Overall Loss 0.669655    Objective Loss 0.669655                                        LR 0.000005    Time 0.143515    
2024-04-23 23:40:42,590 - Epoch: [446][  200/  296]    Overall Loss 0.664514    Objective Loss 0.664514                                        LR 0.000005    Time 0.135037    
2024-04-23 23:40:50,587 - Epoch: [446][  296/  296]    Overall Loss 0.669692    Objective Loss 0.669692    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.118216    
2024-04-23 23:40:50,764 - --- validate (epoch=446)-----------
2024-04-23 23:40:50,765 - 3925 samples (32 per mini-batch)
2024-04-23 23:41:01,334 - Epoch: [446][  100/  123]    Loss 0.656282    Top1 78.906250    Top5 97.562500    
2024-04-23 23:41:04,015 - Epoch: [446][  123/  123]    Loss 0.673730    Top1 78.343949    Top5 97.528662    
2024-04-23 23:41:04,159 - ==> Top1: 78.344    Top5: 97.529    Loss: 0.674

2024-04-23 23:41:04,164 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:41:04,165 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:41:04,194 - 

2024-04-23 23:41:04,194 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:41:12,767 - Epoch: [447][  100/  296]    Overall Loss 0.669011    Objective Loss 0.669011                                        LR 0.000005    Time 0.085612    
2024-04-23 23:41:21,426 - Epoch: [447][  200/  296]    Overall Loss 0.687295    Objective Loss 0.687295                                        LR 0.000005    Time 0.086040    
2024-04-23 23:41:29,604 - Epoch: [447][  296/  296]    Overall Loss 0.688320    Objective Loss 0.688320    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.085717    
2024-04-23 23:41:29,768 - --- validate (epoch=447)-----------
2024-04-23 23:41:29,769 - 3925 samples (32 per mini-batch)
2024-04-23 23:41:43,576 - Epoch: [447][  100/  123]    Loss 0.681496    Top1 78.031250    Top5 97.781250    
2024-04-23 23:41:46,670 - Epoch: [447][  123/  123]    Loss 0.668622    Top1 78.471338    Top5 97.707006    
2024-04-23 23:41:46,828 - ==> Top1: 78.471    Top5: 97.707    Loss: 0.669

2024-04-23 23:41:46,838 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:41:46,838 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:41:46,881 - 

2024-04-23 23:41:46,881 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:41:58,518 - Epoch: [448][  100/  296]    Overall Loss 0.674583    Objective Loss 0.674583                                        LR 0.000005    Time 0.116231    
2024-04-23 23:42:09,760 - Epoch: [448][  200/  296]    Overall Loss 0.665376    Objective Loss 0.665376                                        LR 0.000005    Time 0.114255    
2024-04-23 23:42:20,818 - Epoch: [448][  296/  296]    Overall Loss 0.679131    Objective Loss 0.679131    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.114517    
2024-04-23 23:42:20,910 - --- validate (epoch=448)-----------
2024-04-23 23:42:20,910 - 3925 samples (32 per mini-batch)
2024-04-23 23:42:33,110 - Epoch: [448][  100/  123]    Loss 0.641608    Top1 79.062500    Top5 97.812500    
2024-04-23 23:42:35,700 - Epoch: [448][  123/  123]    Loss 0.670665    Top1 78.394904    Top5 97.401274    
2024-04-23 23:42:35,852 - ==> Top1: 78.395    Top5: 97.401    Loss: 0.671

2024-04-23 23:42:35,861 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:42:35,862 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:42:35,903 - 

2024-04-23 23:42:35,904 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:42:44,862 - Epoch: [449][  100/  296]    Overall Loss 0.699582    Objective Loss 0.699582                                        LR 0.000005    Time 0.089456    
2024-04-23 23:42:55,015 - Epoch: [449][  200/  296]    Overall Loss 0.683379    Objective Loss 0.683379                                        LR 0.000005    Time 0.095421    
2024-04-23 23:43:04,312 - Epoch: [449][  296/  296]    Overall Loss 0.679216    Objective Loss 0.679216    Top1 88.524590    Top5 100.000000    LR 0.000005    Time 0.095838    
2024-04-23 23:43:04,426 - --- validate (epoch=449)-----------
2024-04-23 23:43:04,427 - 3925 samples (32 per mini-batch)
2024-04-23 23:43:15,867 - Epoch: [449][  100/  123]    Loss 0.653554    Top1 78.593750    Top5 97.500000    
2024-04-23 23:43:17,732 - Epoch: [449][  123/  123]    Loss 0.670469    Top1 78.191083    Top5 97.452229    
2024-04-23 23:43:17,838 - ==> Top1: 78.191    Top5: 97.452    Loss: 0.670

2024-04-23 23:43:17,847 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:43:17,848 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:43:17,884 - 

2024-04-23 23:43:17,885 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:43:25,709 - Epoch: [450][  100/  296]    Overall Loss 0.664508    Objective Loss 0.664508                                        LR 0.000005    Time 0.078133    
2024-04-23 23:43:33,014 - Epoch: [450][  200/  296]    Overall Loss 0.672759    Objective Loss 0.672759                                        LR 0.000005    Time 0.075540    
2024-04-23 23:43:39,301 - Epoch: [450][  296/  296]    Overall Loss 0.670266    Objective Loss 0.670266    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.072250    
2024-04-23 23:43:39,421 - --- validate (epoch=450)-----------
2024-04-23 23:43:39,422 - 3925 samples (32 per mini-batch)
2024-04-23 23:43:48,286 - Epoch: [450][  100/  123]    Loss 0.656561    Top1 78.531250    Top5 97.562500    
2024-04-23 23:43:49,947 - Epoch: [450][  123/  123]    Loss 0.669041    Top1 78.445860    Top5 97.452229    
2024-04-23 23:43:50,053 - ==> Top1: 78.446    Top5: 97.452    Loss: 0.669

2024-04-23 23:43:50,063 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:43:50,063 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:43:50,102 - 

2024-04-23 23:43:50,102 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:43:57,976 - Epoch: [451][  100/  296]    Overall Loss 0.663825    Objective Loss 0.663825                                        LR 0.000005    Time 0.078624    
2024-04-23 23:44:04,668 - Epoch: [451][  200/  296]    Overall Loss 0.663413    Objective Loss 0.663413                                        LR 0.000005    Time 0.072722    
2024-04-23 23:44:10,016 - Epoch: [451][  296/  296]    Overall Loss 0.663565    Objective Loss 0.663565    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.067169    
2024-04-23 23:44:10,120 - --- validate (epoch=451)-----------
2024-04-23 23:44:10,121 - 3925 samples (32 per mini-batch)
2024-04-23 23:44:19,978 - Epoch: [451][  100/  123]    Loss 0.672986    Top1 78.625000    Top5 97.406250    
2024-04-23 23:44:22,133 - Epoch: [451][  123/  123]    Loss 0.670774    Top1 78.445860    Top5 97.452229    
2024-04-23 23:44:22,245 - ==> Top1: 78.446    Top5: 97.452    Loss: 0.671

2024-04-23 23:44:22,253 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:44:22,254 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:44:22,288 - 

2024-04-23 23:44:22,288 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:44:33,206 - Epoch: [452][  100/  296]    Overall Loss 0.664060    Objective Loss 0.664060                                        LR 0.000005    Time 0.109047    
2024-04-23 23:44:47,323 - Epoch: [452][  200/  296]    Overall Loss 0.653649    Objective Loss 0.653649                                        LR 0.000005    Time 0.125035    
2024-04-23 23:44:59,487 - Epoch: [452][  296/  296]    Overall Loss 0.648171    Objective Loss 0.648171    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.125537    
2024-04-23 23:44:59,746 - --- validate (epoch=452)-----------
2024-04-23 23:44:59,747 - 3925 samples (32 per mini-batch)
2024-04-23 23:45:17,024 - Epoch: [452][  100/  123]    Loss 0.672255    Top1 77.875000    Top5 97.531250    
2024-04-23 23:45:19,734 - Epoch: [452][  123/  123]    Loss 0.672417    Top1 78.114650    Top5 97.477707    
2024-04-23 23:45:19,927 - ==> Top1: 78.115    Top5: 97.478    Loss: 0.672

2024-04-23 23:45:19,939 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:45:19,939 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:45:19,982 - 

2024-04-23 23:45:19,982 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:45:33,160 - Epoch: [453][  100/  296]    Overall Loss 0.664709    Objective Loss 0.664709                                        LR 0.000005    Time 0.131639    
2024-04-23 23:45:41,117 - Epoch: [453][  200/  296]    Overall Loss 0.659272    Objective Loss 0.659272                                        LR 0.000005    Time 0.105535    
2024-04-23 23:45:49,886 - Epoch: [453][  296/  296]    Overall Loss 0.658710    Objective Loss 0.658710    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.100891    
2024-04-23 23:45:50,048 - --- validate (epoch=453)-----------
2024-04-23 23:45:50,048 - 3925 samples (32 per mini-batch)
2024-04-23 23:46:01,281 - Epoch: [453][  100/  123]    Loss 0.675774    Top1 78.343750    Top5 97.312500    
2024-04-23 23:46:03,060 - Epoch: [453][  123/  123]    Loss 0.672548    Top1 78.369427    Top5 97.477707    
2024-04-23 23:46:03,199 - ==> Top1: 78.369    Top5: 97.478    Loss: 0.673

2024-04-23 23:46:03,204 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:46:03,204 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:46:03,237 - 

2024-04-23 23:46:03,238 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:46:13,531 - Epoch: [454][  100/  296]    Overall Loss 0.692201    Objective Loss 0.692201                                        LR 0.000005    Time 0.102795    
2024-04-23 23:46:24,594 - Epoch: [454][  200/  296]    Overall Loss 0.690035    Objective Loss 0.690035                                        LR 0.000005    Time 0.106643    
2024-04-23 23:46:31,712 - Epoch: [454][  296/  296]    Overall Loss 0.686980    Objective Loss 0.686980    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.096059    
2024-04-23 23:46:31,936 - --- validate (epoch=454)-----------
2024-04-23 23:46:31,937 - 3925 samples (32 per mini-batch)
2024-04-23 23:46:43,875 - Epoch: [454][  100/  123]    Loss 0.647379    Top1 79.343750    Top5 97.625000    
2024-04-23 23:46:46,395 - Epoch: [454][  123/  123]    Loss 0.669690    Top1 78.547771    Top5 97.477707    
2024-04-23 23:46:46,507 - ==> Top1: 78.548    Top5: 97.478    Loss: 0.670

2024-04-23 23:46:46,516 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:46:46,517 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:46:46,555 - 

2024-04-23 23:46:46,555 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:46:59,481 - Epoch: [455][  100/  296]    Overall Loss 0.667885    Objective Loss 0.667885                                        LR 0.000005    Time 0.129129    
2024-04-23 23:47:10,535 - Epoch: [455][  200/  296]    Overall Loss 0.680574    Objective Loss 0.680574                                        LR 0.000005    Time 0.119766    
2024-04-23 23:47:19,742 - Epoch: [455][  296/  296]    Overall Loss 0.672819    Objective Loss 0.672819    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.111989    
2024-04-23 23:47:19,950 - --- validate (epoch=455)-----------
2024-04-23 23:47:19,951 - 3925 samples (32 per mini-batch)
2024-04-23 23:47:32,024 - Epoch: [455][  100/  123]    Loss 0.684708    Top1 77.906250    Top5 97.406250    
2024-04-23 23:47:34,154 - Epoch: [455][  123/  123]    Loss 0.671753    Top1 78.267516    Top5 97.477707    
2024-04-23 23:47:34,332 - ==> Top1: 78.268    Top5: 97.478    Loss: 0.672

2024-04-23 23:47:34,341 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:47:34,342 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:47:34,385 - 

2024-04-23 23:47:34,385 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:47:46,738 - Epoch: [456][  100/  296]    Overall Loss 0.682421    Objective Loss 0.682421                                        LR 0.000005    Time 0.123385    
2024-04-23 23:47:57,101 - Epoch: [456][  200/  296]    Overall Loss 0.677937    Objective Loss 0.677937                                        LR 0.000005    Time 0.113439    
2024-04-23 23:48:07,727 - Epoch: [456][  296/  296]    Overall Loss 0.685478    Objective Loss 0.685478    Top1 73.770492    Top5 93.442623    LR 0.000005    Time 0.112506    
2024-04-23 23:48:07,890 - --- validate (epoch=456)-----------
2024-04-23 23:48:07,892 - 3925 samples (32 per mini-batch)
2024-04-23 23:48:19,766 - Epoch: [456][  100/  123]    Loss 0.670113    Top1 78.125000    Top5 97.750000    
2024-04-23 23:48:21,857 - Epoch: [456][  123/  123]    Loss 0.671124    Top1 78.369427    Top5 97.503185    
2024-04-23 23:48:22,040 - ==> Top1: 78.369    Top5: 97.503    Loss: 0.671

2024-04-23 23:48:22,050 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:48:22,050 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:48:22,091 - 

2024-04-23 23:48:22,091 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:48:33,989 - Epoch: [457][  100/  296]    Overall Loss 0.642407    Objective Loss 0.642407                                        LR 0.000005    Time 0.118835    
2024-04-23 23:48:42,754 - Epoch: [457][  200/  296]    Overall Loss 0.646754    Objective Loss 0.646754                                        LR 0.000005    Time 0.103185    
2024-04-23 23:48:53,745 - Epoch: [457][  296/  296]    Overall Loss 0.677024    Objective Loss 0.677024    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.106812    
2024-04-23 23:48:53,867 - --- validate (epoch=457)-----------
2024-04-23 23:48:53,868 - 3925 samples (32 per mini-batch)
2024-04-23 23:49:04,667 - Epoch: [457][  100/  123]    Loss 0.670383    Top1 78.406250    Top5 97.531250    
2024-04-23 23:49:07,265 - Epoch: [457][  123/  123]    Loss 0.673115    Top1 78.369427    Top5 97.630573    
2024-04-23 23:49:07,469 - ==> Top1: 78.369    Top5: 97.631    Loss: 0.673

2024-04-23 23:49:07,474 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:49:07,475 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:49:07,506 - 

2024-04-23 23:49:07,507 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:49:17,262 - Epoch: [458][  100/  296]    Overall Loss 0.691633    Objective Loss 0.691633                                        LR 0.000005    Time 0.097399    
2024-04-23 23:49:25,881 - Epoch: [458][  200/  296]    Overall Loss 0.689260    Objective Loss 0.689260                                        LR 0.000005    Time 0.091714    
2024-04-23 23:49:35,213 - Epoch: [458][  296/  296]    Overall Loss 0.686106    Objective Loss 0.686106    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.093461    
2024-04-23 23:49:35,411 - --- validate (epoch=458)-----------
2024-04-23 23:49:35,411 - 3925 samples (32 per mini-batch)
2024-04-23 23:49:47,440 - Epoch: [458][  100/  123]    Loss 0.674240    Top1 78.437500    Top5 97.343750    
2024-04-23 23:49:50,806 - Epoch: [458][  123/  123]    Loss 0.670319    Top1 78.292994    Top5 97.452229    
2024-04-23 23:49:50,979 - ==> Top1: 78.293    Top5: 97.452    Loss: 0.670

2024-04-23 23:49:50,988 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:49:50,988 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:49:51,027 - 

2024-04-23 23:49:51,027 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:50:02,762 - Epoch: [459][  100/  296]    Overall Loss 0.657187    Objective Loss 0.657187                                        LR 0.000005    Time 0.117225    
2024-04-23 23:50:14,790 - Epoch: [459][  200/  296]    Overall Loss 0.667144    Objective Loss 0.667144                                        LR 0.000005    Time 0.118682    
2024-04-23 23:50:27,541 - Epoch: [459][  296/  296]    Overall Loss 0.674611    Objective Loss 0.674611    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.123230    
2024-04-23 23:50:27,697 - --- validate (epoch=459)-----------
2024-04-23 23:50:27,697 - 3925 samples (32 per mini-batch)
2024-04-23 23:50:42,141 - Epoch: [459][  100/  123]    Loss 0.677044    Top1 77.843750    Top5 97.406250    
2024-04-23 23:50:44,743 - Epoch: [459][  123/  123]    Loss 0.671906    Top1 78.191083    Top5 97.477707    
2024-04-23 23:50:44,891 - ==> Top1: 78.191    Top5: 97.478    Loss: 0.672

2024-04-23 23:50:44,899 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:50:44,900 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:50:44,937 - 

2024-04-23 23:50:44,937 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:50:56,571 - Epoch: [460][  100/  296]    Overall Loss 0.681108    Objective Loss 0.681108                                        LR 0.000005    Time 0.116217    
2024-04-23 23:51:07,325 - Epoch: [460][  200/  296]    Overall Loss 0.679514    Objective Loss 0.679514                                        LR 0.000005    Time 0.111814    
2024-04-23 23:51:18,141 - Epoch: [460][  296/  296]    Overall Loss 0.678229    Objective Loss 0.678229    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.112047    
2024-04-23 23:51:18,342 - --- validate (epoch=460)-----------
2024-04-23 23:51:18,343 - 3925 samples (32 per mini-batch)
2024-04-23 23:51:30,121 - Epoch: [460][  100/  123]    Loss 0.657126    Top1 79.000000    Top5 97.500000    
2024-04-23 23:51:32,601 - Epoch: [460][  123/  123]    Loss 0.672978    Top1 78.496815    Top5 97.401274    
2024-04-23 23:51:32,786 - ==> Top1: 78.497    Top5: 97.401    Loss: 0.673

2024-04-23 23:51:32,793 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:51:32,793 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:51:32,837 - 

2024-04-23 23:51:32,838 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:51:45,532 - Epoch: [461][  100/  296]    Overall Loss 0.658825    Objective Loss 0.658825                                        LR 0.000005    Time 0.126818    
2024-04-23 23:51:56,809 - Epoch: [461][  200/  296]    Overall Loss 0.669657    Objective Loss 0.669657                                        LR 0.000005    Time 0.119737    
2024-04-23 23:52:10,072 - Epoch: [461][  296/  296]    Overall Loss 0.674574    Objective Loss 0.674574    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.125672    
2024-04-23 23:52:10,273 - --- validate (epoch=461)-----------
2024-04-23 23:52:10,274 - 3925 samples (32 per mini-batch)
2024-04-23 23:52:23,605 - Epoch: [461][  100/  123]    Loss 0.664318    Top1 78.500000    Top5 97.750000    
2024-04-23 23:52:26,031 - Epoch: [461][  123/  123]    Loss 0.671272    Top1 78.267516    Top5 97.579618    
2024-04-23 23:52:26,185 - ==> Top1: 78.268    Top5: 97.580    Loss: 0.671

2024-04-23 23:52:26,194 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:52:26,195 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:52:26,235 - 

2024-04-23 23:52:26,235 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:52:38,736 - Epoch: [462][  100/  296]    Overall Loss 0.673944    Objective Loss 0.673944                                        LR 0.000005    Time 0.124867    
2024-04-23 23:52:49,497 - Epoch: [462][  200/  296]    Overall Loss 0.673597    Objective Loss 0.673597                                        LR 0.000005    Time 0.116169    
2024-04-23 23:53:00,332 - Epoch: [462][  296/  296]    Overall Loss 0.678265    Objective Loss 0.678265    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.115058    
2024-04-23 23:53:00,561 - --- validate (epoch=462)-----------
2024-04-23 23:53:00,561 - 3925 samples (32 per mini-batch)
2024-04-23 23:53:13,368 - Epoch: [462][  100/  123]    Loss 0.675427    Top1 77.937500    Top5 97.343750    
2024-04-23 23:53:15,833 - Epoch: [462][  123/  123]    Loss 0.674241    Top1 78.114650    Top5 97.375796    
2024-04-23 23:53:15,992 - ==> Top1: 78.115    Top5: 97.376    Loss: 0.674

2024-04-23 23:53:15,998 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:53:15,999 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:53:16,033 - 

2024-04-23 23:53:16,033 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:53:27,754 - Epoch: [463][  100/  296]    Overall Loss 0.667568    Objective Loss 0.667568                                        LR 0.000005    Time 0.117066    
2024-04-23 23:53:36,648 - Epoch: [463][  200/  296]    Overall Loss 0.679028    Objective Loss 0.679028                                        LR 0.000005    Time 0.102937    
2024-04-23 23:53:46,350 - Epoch: [463][  296/  296]    Overall Loss 0.674100    Objective Loss 0.674100    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.102289    
2024-04-23 23:53:46,474 - --- validate (epoch=463)-----------
2024-04-23 23:53:46,475 - 3925 samples (32 per mini-batch)
2024-04-23 23:54:00,528 - Epoch: [463][  100/  123]    Loss 0.665452    Top1 78.593750    Top5 97.406250    
2024-04-23 23:54:03,114 - Epoch: [463][  123/  123]    Loss 0.672940    Top1 78.292994    Top5 97.452229    
2024-04-23 23:54:03,230 - ==> Top1: 78.293    Top5: 97.452    Loss: 0.673

2024-04-23 23:54:03,234 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:54:03,234 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:54:03,261 - 

2024-04-23 23:54:03,261 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:54:14,218 - Epoch: [464][  100/  296]    Overall Loss 0.679531    Objective Loss 0.679531                                        LR 0.000005    Time 0.109419    
2024-04-23 23:54:24,249 - Epoch: [464][  200/  296]    Overall Loss 0.676955    Objective Loss 0.676955                                        LR 0.000005    Time 0.104788    
2024-04-23 23:54:36,452 - Epoch: [464][  296/  296]    Overall Loss 0.677229    Objective Loss 0.677229    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.111989    
2024-04-23 23:54:36,568 - --- validate (epoch=464)-----------
2024-04-23 23:54:36,568 - 3925 samples (32 per mini-batch)
2024-04-23 23:54:48,429 - Epoch: [464][  100/  123]    Loss 0.680902    Top1 78.156250    Top5 97.312500    
2024-04-23 23:54:51,273 - Epoch: [464][  123/  123]    Loss 0.672558    Top1 78.267516    Top5 97.375796    
2024-04-23 23:54:51,408 - ==> Top1: 78.268    Top5: 97.376    Loss: 0.673

2024-04-23 23:54:51,418 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:54:51,419 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:54:51,459 - 

2024-04-23 23:54:51,459 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:55:01,039 - Epoch: [465][  100/  296]    Overall Loss 0.667675    Objective Loss 0.667675                                        LR 0.000005    Time 0.095649    
2024-04-23 23:55:10,047 - Epoch: [465][  200/  296]    Overall Loss 0.656443    Objective Loss 0.656443                                        LR 0.000005    Time 0.092792    
2024-04-23 23:55:21,274 - Epoch: [465][  296/  296]    Overall Loss 0.678317    Objective Loss 0.678317    Top1 62.295082    Top5 93.442623    LR 0.000005    Time 0.100585    
2024-04-23 23:55:21,425 - --- validate (epoch=465)-----------
2024-04-23 23:55:21,426 - 3925 samples (32 per mini-batch)
2024-04-23 23:55:35,201 - Epoch: [465][  100/  123]    Loss 0.676911    Top1 78.625000    Top5 97.406250    
2024-04-23 23:55:37,194 - Epoch: [465][  123/  123]    Loss 0.673043    Top1 78.420382    Top5 97.375796    
2024-04-23 23:55:37,356 - ==> Top1: 78.420    Top5: 97.376    Loss: 0.673

2024-04-23 23:55:37,361 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:55:37,362 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:55:37,397 - 

2024-04-23 23:55:37,397 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:55:47,426 - Epoch: [466][  100/  296]    Overall Loss 0.701230    Objective Loss 0.701230                                        LR 0.000005    Time 0.100151    
2024-04-23 23:55:57,671 - Epoch: [466][  200/  296]    Overall Loss 0.696838    Objective Loss 0.696838                                        LR 0.000005    Time 0.101242    
2024-04-23 23:56:09,970 - Epoch: [466][  296/  296]    Overall Loss 0.689834    Objective Loss 0.689834    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.109918    
2024-04-23 23:56:10,139 - --- validate (epoch=466)-----------
2024-04-23 23:56:10,140 - 3925 samples (32 per mini-batch)
2024-04-23 23:56:25,220 - Epoch: [466][  100/  123]    Loss 0.662334    Top1 78.125000    Top5 97.656250    
2024-04-23 23:56:28,306 - Epoch: [466][  123/  123]    Loss 0.669538    Top1 78.114650    Top5 97.477707    
2024-04-23 23:56:28,492 - ==> Top1: 78.115    Top5: 97.478    Loss: 0.670

2024-04-23 23:56:28,501 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:56:28,502 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:56:28,541 - 

2024-04-23 23:56:28,542 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:56:40,174 - Epoch: [467][  100/  296]    Overall Loss 0.677410    Objective Loss 0.677410                                        LR 0.000005    Time 0.116191    
2024-04-23 23:56:52,047 - Epoch: [467][  200/  296]    Overall Loss 0.675525    Objective Loss 0.675525                                        LR 0.000005    Time 0.117405    
2024-04-23 23:57:02,607 - Epoch: [467][  296/  296]    Overall Loss 0.679259    Objective Loss 0.679259    Top1 78.688525    Top5 93.442623    LR 0.000005    Time 0.114963    
2024-04-23 23:57:02,715 - --- validate (epoch=467)-----------
2024-04-23 23:57:02,715 - 3925 samples (32 per mini-batch)
2024-04-23 23:57:17,073 - Epoch: [467][  100/  123]    Loss 0.670131    Top1 78.218750    Top5 97.500000    
2024-04-23 23:57:19,472 - Epoch: [467][  123/  123]    Loss 0.670890    Top1 78.216561    Top5 97.375796    
2024-04-23 23:57:19,615 - ==> Top1: 78.217    Top5: 97.376    Loss: 0.671

2024-04-23 23:57:19,623 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:57:19,624 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:57:19,666 - 

2024-04-23 23:57:19,666 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:57:31,706 - Epoch: [468][  100/  296]    Overall Loss 0.673155    Objective Loss 0.673155                                        LR 0.000005    Time 0.120258    
2024-04-23 23:57:42,698 - Epoch: [468][  200/  296]    Overall Loss 0.676545    Objective Loss 0.676545                                        LR 0.000005    Time 0.115023    
2024-04-23 23:57:53,847 - Epoch: [468][  296/  296]    Overall Loss 0.679275    Objective Loss 0.679275    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.115350    
2024-04-23 23:57:53,943 - --- validate (epoch=468)-----------
2024-04-23 23:57:53,944 - 3925 samples (32 per mini-batch)
2024-04-23 23:58:08,103 - Epoch: [468][  100/  123]    Loss 0.671201    Top1 78.437500    Top5 97.625000    
2024-04-23 23:58:11,076 - Epoch: [468][  123/  123]    Loss 0.670310    Top1 78.343949    Top5 97.401274    
2024-04-23 23:58:11,238 - ==> Top1: 78.344    Top5: 97.401    Loss: 0.670

2024-04-23 23:58:11,246 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:58:11,246 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:58:11,297 - 

2024-04-23 23:58:11,297 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:58:24,315 - Epoch: [469][  100/  296]    Overall Loss 0.687711    Objective Loss 0.687711                                        LR 0.000005    Time 0.130012    
2024-04-23 23:58:34,495 - Epoch: [469][  200/  296]    Overall Loss 0.679245    Objective Loss 0.679245                                        LR 0.000005    Time 0.115837    
2024-04-23 23:58:45,246 - Epoch: [469][  296/  296]    Overall Loss 0.675515    Objective Loss 0.675515    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.114546    
2024-04-23 23:58:45,613 - --- validate (epoch=469)-----------
2024-04-23 23:58:45,613 - 3925 samples (32 per mini-batch)
2024-04-23 23:58:56,645 - Epoch: [469][  100/  123]    Loss 0.672305    Top1 78.625000    Top5 97.531250    
2024-04-23 23:58:58,267 - Epoch: [469][  123/  123]    Loss 0.670882    Top1 78.343949    Top5 97.528662    
2024-04-23 23:58:58,399 - ==> Top1: 78.344    Top5: 97.529    Loss: 0.671

2024-04-23 23:58:58,409 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:58:58,409 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:58:58,446 - 

2024-04-23 23:58:58,446 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:59:06,966 - Epoch: [470][  100/  296]    Overall Loss 0.679176    Objective Loss 0.679176                                        LR 0.000005    Time 0.085073    
2024-04-23 23:59:17,791 - Epoch: [470][  200/  296]    Overall Loss 0.683009    Objective Loss 0.683009                                        LR 0.000005    Time 0.096605    
2024-04-23 23:59:28,010 - Epoch: [470][  296/  296]    Overall Loss 0.673171    Objective Loss 0.673171    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.099760    
2024-04-23 23:59:28,140 - --- validate (epoch=470)-----------
2024-04-23 23:59:28,140 - 3925 samples (32 per mini-batch)
2024-04-23 23:59:42,200 - Epoch: [470][  100/  123]    Loss 0.667100    Top1 78.656250    Top5 97.531250    
2024-04-23 23:59:44,834 - Epoch: [470][  123/  123]    Loss 0.671052    Top1 78.547771    Top5 97.528662    
2024-04-23 23:59:44,953 - ==> Top1: 78.548    Top5: 97.529    Loss: 0.671

2024-04-23 23:59:44,962 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-23 23:59:44,963 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-23 23:59:45,002 - 

2024-04-23 23:59:45,003 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:59:55,957 - Epoch: [471][  100/  296]    Overall Loss 0.680071    Objective Loss 0.680071                                        LR 0.000005    Time 0.109417    
2024-04-24 00:00:08,334 - Epoch: [471][  200/  296]    Overall Loss 0.661356    Objective Loss 0.661356                                        LR 0.000005    Time 0.116531    
2024-04-24 00:00:19,224 - Epoch: [471][  296/  296]    Overall Loss 0.668563    Objective Loss 0.668563    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.115492    
2024-04-24 00:00:19,412 - --- validate (epoch=471)-----------
2024-04-24 00:00:19,413 - 3925 samples (32 per mini-batch)
2024-04-24 00:00:35,840 - Epoch: [471][  100/  123]    Loss 0.671823    Top1 78.156250    Top5 97.656250    
2024-04-24 00:00:39,255 - Epoch: [471][  123/  123]    Loss 0.668799    Top1 78.343949    Top5 97.554140    
2024-04-24 00:00:39,439 - ==> Top1: 78.344    Top5: 97.554    Loss: 0.669

2024-04-24 00:00:39,449 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:00:39,450 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:00:39,494 - 

2024-04-24 00:00:39,495 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:00:51,647 - Epoch: [472][  100/  296]    Overall Loss 0.664093    Objective Loss 0.664093                                        LR 0.000005    Time 0.121378    
2024-04-24 00:01:01,570 - Epoch: [472][  200/  296]    Overall Loss 0.668425    Objective Loss 0.668425                                        LR 0.000005    Time 0.110243    
2024-04-24 00:01:13,501 - Epoch: [472][  296/  296]    Overall Loss 0.668056    Objective Loss 0.668056    Top1 67.213115    Top5 100.000000    LR 0.000005    Time 0.114759    
2024-04-24 00:01:13,644 - --- validate (epoch=472)-----------
2024-04-24 00:01:13,645 - 3925 samples (32 per mini-batch)
2024-04-24 00:01:28,700 - Epoch: [472][  100/  123]    Loss 0.647069    Top1 78.843750    Top5 97.875000    
2024-04-24 00:01:32,432 - Epoch: [472][  123/  123]    Loss 0.668317    Top1 78.445860    Top5 97.503185    
2024-04-24 00:01:32,595 - ==> Top1: 78.446    Top5: 97.503    Loss: 0.668

2024-04-24 00:01:32,605 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:01:32,606 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:01:32,647 - 

2024-04-24 00:01:32,647 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:01:41,873 - Epoch: [473][  100/  296]    Overall Loss 0.665050    Objective Loss 0.665050                                        LR 0.000005    Time 0.092118    
2024-04-24 00:01:47,880 - Epoch: [473][  200/  296]    Overall Loss 0.670423    Objective Loss 0.670423                                        LR 0.000005    Time 0.076032    
2024-04-24 00:01:54,154 - Epoch: [473][  296/  296]    Overall Loss 0.678336    Objective Loss 0.678336    Top1 65.573770    Top5 96.721311    LR 0.000005    Time 0.072537    
2024-04-24 00:01:54,246 - --- validate (epoch=473)-----------
2024-04-24 00:01:54,246 - 3925 samples (32 per mini-batch)
2024-04-24 00:02:04,220 - Epoch: [473][  100/  123]    Loss 0.661744    Top1 78.656250    Top5 97.406250    
2024-04-24 00:02:05,922 - Epoch: [473][  123/  123]    Loss 0.668094    Top1 78.496815    Top5 97.528662    
2024-04-24 00:02:06,033 - ==> Top1: 78.497    Top5: 97.529    Loss: 0.668

2024-04-24 00:02:06,044 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:02:06,045 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:02:06,088 - 

2024-04-24 00:02:06,088 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:02:15,028 - Epoch: [474][  100/  296]    Overall Loss 0.693889    Objective Loss 0.693889                                        LR 0.000005    Time 0.089274    
2024-04-24 00:02:22,800 - Epoch: [474][  200/  296]    Overall Loss 0.684274    Objective Loss 0.684274                                        LR 0.000005    Time 0.083442    
2024-04-24 00:02:30,804 - Epoch: [474][  296/  296]    Overall Loss 0.672799    Objective Loss 0.672799    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.083384    
2024-04-24 00:02:30,933 - --- validate (epoch=474)-----------
2024-04-24 00:02:30,933 - 3925 samples (32 per mini-batch)
2024-04-24 00:02:42,480 - Epoch: [474][  100/  123]    Loss 0.673648    Top1 78.250000    Top5 97.343750    
2024-04-24 00:02:44,429 - Epoch: [474][  123/  123]    Loss 0.669279    Top1 78.343949    Top5 97.426752    
2024-04-24 00:02:44,542 - ==> Top1: 78.344    Top5: 97.427    Loss: 0.669

2024-04-24 00:02:44,555 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:02:44,556 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:02:44,602 - 

2024-04-24 00:02:44,603 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:02:58,072 - Epoch: [475][  100/  296]    Overall Loss 0.688294    Objective Loss 0.688294                                        LR 0.000005    Time 0.134561    
2024-04-24 00:03:10,585 - Epoch: [475][  200/  296]    Overall Loss 0.669426    Objective Loss 0.669426                                        LR 0.000005    Time 0.129798    
2024-04-24 00:03:20,602 - Epoch: [475][  296/  296]    Overall Loss 0.659564    Objective Loss 0.659564    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.121496    
2024-04-24 00:03:20,764 - --- validate (epoch=475)-----------
2024-04-24 00:03:20,765 - 3925 samples (32 per mini-batch)
2024-04-24 00:03:32,918 - Epoch: [475][  100/  123]    Loss 0.662540    Top1 78.750000    Top5 97.343750    
2024-04-24 00:03:35,434 - Epoch: [475][  123/  123]    Loss 0.671756    Top1 78.292994    Top5 97.350318    
2024-04-24 00:03:35,573 - ==> Top1: 78.293    Top5: 97.350    Loss: 0.672

2024-04-24 00:03:35,579 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:03:35,579 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:03:35,620 - 

2024-04-24 00:03:35,621 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:03:46,146 - Epoch: [476][  100/  296]    Overall Loss 0.684474    Objective Loss 0.684474                                        LR 0.000005    Time 0.105122    
2024-04-24 00:03:56,693 - Epoch: [476][  200/  296]    Overall Loss 0.672265    Objective Loss 0.672265                                        LR 0.000005    Time 0.105224    
2024-04-24 00:04:05,660 - Epoch: [476][  296/  296]    Overall Loss 0.669944    Objective Loss 0.669944    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.101350    
2024-04-24 00:04:05,786 - --- validate (epoch=476)-----------
2024-04-24 00:04:05,787 - 3925 samples (32 per mini-batch)
2024-04-24 00:04:18,933 - Epoch: [476][  100/  123]    Loss 0.680892    Top1 78.125000    Top5 97.406250    
2024-04-24 00:04:21,354 - Epoch: [476][  123/  123]    Loss 0.670984    Top1 78.343949    Top5 97.401274    
2024-04-24 00:04:21,531 - ==> Top1: 78.344    Top5: 97.401    Loss: 0.671

2024-04-24 00:04:21,541 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:04:21,541 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:04:21,580 - 

2024-04-24 00:04:21,580 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:04:30,595 - Epoch: [477][  100/  296]    Overall Loss 0.647307    Objective Loss 0.647307                                        LR 0.000005    Time 0.090021    
2024-04-24 00:04:38,085 - Epoch: [477][  200/  296]    Overall Loss 0.679338    Objective Loss 0.679338                                        LR 0.000005    Time 0.082393    
2024-04-24 00:04:45,355 - Epoch: [477][  296/  296]    Overall Loss 0.679368    Objective Loss 0.679368    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.080191    
2024-04-24 00:04:45,504 - --- validate (epoch=477)-----------
2024-04-24 00:04:45,505 - 3925 samples (32 per mini-batch)
2024-04-24 00:04:56,580 - Epoch: [477][  100/  123]    Loss 0.670111    Top1 78.406250    Top5 97.437500    
2024-04-24 00:04:58,314 - Epoch: [477][  123/  123]    Loss 0.676125    Top1 78.063694    Top5 97.452229    
2024-04-24 00:04:58,496 - ==> Top1: 78.064    Top5: 97.452    Loss: 0.676

2024-04-24 00:04:58,506 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:04:58,506 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:04:58,549 - 

2024-04-24 00:04:58,549 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:05:09,146 - Epoch: [478][  100/  296]    Overall Loss 0.670058    Objective Loss 0.670058                                        LR 0.000005    Time 0.105833    
2024-04-24 00:05:18,728 - Epoch: [478][  200/  296]    Overall Loss 0.664685    Objective Loss 0.664685                                        LR 0.000005    Time 0.100766    
2024-04-24 00:05:27,822 - Epoch: [478][  296/  296]    Overall Loss 0.672148    Objective Loss 0.672148    Top1 65.573770    Top5 96.721311    LR 0.000005    Time 0.098771    
2024-04-24 00:05:27,988 - --- validate (epoch=478)-----------
2024-04-24 00:05:27,989 - 3925 samples (32 per mini-batch)
2024-04-24 00:05:42,275 - Epoch: [478][  100/  123]    Loss 0.650423    Top1 78.687500    Top5 97.656250    
2024-04-24 00:05:44,955 - Epoch: [478][  123/  123]    Loss 0.671588    Top1 78.343949    Top5 97.579618    
2024-04-24 00:05:45,137 - ==> Top1: 78.344    Top5: 97.580    Loss: 0.672

2024-04-24 00:05:45,147 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:05:45,147 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:05:45,185 - 

2024-04-24 00:05:45,185 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:05:56,900 - Epoch: [479][  100/  296]    Overall Loss 0.663104    Objective Loss 0.663104                                        LR 0.000005    Time 0.117010    
2024-04-24 00:06:08,020 - Epoch: [479][  200/  296]    Overall Loss 0.666843    Objective Loss 0.666843                                        LR 0.000005    Time 0.114036    
2024-04-24 00:06:17,447 - Epoch: [479][  296/  296]    Overall Loss 0.672640    Objective Loss 0.672640    Top1 93.442623    Top5 100.000000    LR 0.000005    Time 0.108858    
2024-04-24 00:06:17,622 - --- validate (epoch=479)-----------
2024-04-24 00:06:17,623 - 3925 samples (32 per mini-batch)
2024-04-24 00:06:28,046 - Epoch: [479][  100/  123]    Loss 0.653094    Top1 78.843750    Top5 97.812500    
2024-04-24 00:06:30,151 - Epoch: [479][  123/  123]    Loss 0.669472    Top1 78.394904    Top5 97.579618    
2024-04-24 00:06:30,244 - ==> Top1: 78.395    Top5: 97.580    Loss: 0.669

2024-04-24 00:06:30,252 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:06:30,253 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:06:30,287 - 

2024-04-24 00:06:30,288 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:06:42,617 - Epoch: [480][  100/  296]    Overall Loss 0.679574    Objective Loss 0.679574                                        LR 0.000005    Time 0.123152    
2024-04-24 00:06:53,510 - Epoch: [480][  200/  296]    Overall Loss 0.672996    Objective Loss 0.672996                                        LR 0.000005    Time 0.115965    
2024-04-24 00:07:02,084 - Epoch: [480][  296/  296]    Overall Loss 0.668447    Objective Loss 0.668447    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.107277    
2024-04-24 00:07:02,230 - --- validate (epoch=480)-----------
2024-04-24 00:07:02,230 - 3925 samples (32 per mini-batch)
2024-04-24 00:07:14,480 - Epoch: [480][  100/  123]    Loss 0.660692    Top1 78.625000    Top5 97.656250    
2024-04-24 00:07:17,904 - Epoch: [480][  123/  123]    Loss 0.666964    Top1 78.471338    Top5 97.528662    
2024-04-24 00:07:18,048 - ==> Top1: 78.471    Top5: 97.529    Loss: 0.667

2024-04-24 00:07:18,058 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:07:18,058 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:07:18,099 - 

2024-04-24 00:07:18,100 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:07:30,448 - Epoch: [481][  100/  296]    Overall Loss 0.659128    Objective Loss 0.659128                                        LR 0.000005    Time 0.123357    
2024-04-24 00:07:40,928 - Epoch: [481][  200/  296]    Overall Loss 0.669948    Objective Loss 0.669948                                        LR 0.000005    Time 0.114020    
2024-04-24 00:07:50,838 - Epoch: [481][  296/  296]    Overall Loss 0.668812    Objective Loss 0.668812    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.110482    
2024-04-24 00:07:51,020 - --- validate (epoch=481)-----------
2024-04-24 00:07:51,020 - 3925 samples (32 per mini-batch)
2024-04-24 00:08:04,222 - Epoch: [481][  100/  123]    Loss 0.675853    Top1 78.156250    Top5 97.562500    
2024-04-24 00:08:06,536 - Epoch: [481][  123/  123]    Loss 0.671776    Top1 78.216561    Top5 97.503185    
2024-04-24 00:08:06,712 - ==> Top1: 78.217    Top5: 97.503    Loss: 0.672

2024-04-24 00:08:06,719 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:08:06,720 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:08:06,762 - 

2024-04-24 00:08:06,762 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:08:18,012 - Epoch: [482][  100/  296]    Overall Loss 0.677586    Objective Loss 0.677586                                        LR 0.000005    Time 0.112370    
2024-04-24 00:08:30,125 - Epoch: [482][  200/  296]    Overall Loss 0.681954    Objective Loss 0.681954                                        LR 0.000005    Time 0.116686    
2024-04-24 00:08:40,529 - Epoch: [482][  296/  296]    Overall Loss 0.676175    Objective Loss 0.676175    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.113949    
2024-04-24 00:08:40,697 - --- validate (epoch=482)-----------
2024-04-24 00:08:40,698 - 3925 samples (32 per mini-batch)
2024-04-24 00:08:55,935 - Epoch: [482][  100/  123]    Loss 0.659624    Top1 78.281250    Top5 97.687500    
2024-04-24 00:08:59,017 - Epoch: [482][  123/  123]    Loss 0.672176    Top1 78.140127    Top5 97.503185    
2024-04-24 00:08:59,199 - ==> Top1: 78.140    Top5: 97.503    Loss: 0.672

2024-04-24 00:08:59,209 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:08:59,210 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:08:59,250 - 

2024-04-24 00:08:59,251 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:09:12,684 - Epoch: [483][  100/  296]    Overall Loss 0.663095    Objective Loss 0.663095                                        LR 0.000005    Time 0.134179    
2024-04-24 00:09:24,612 - Epoch: [483][  200/  296]    Overall Loss 0.663443    Objective Loss 0.663443                                        LR 0.000005    Time 0.126659    
2024-04-24 00:09:34,970 - Epoch: [483][  296/  296]    Overall Loss 0.673081    Objective Loss 0.673081    Top1 86.885246    Top5 100.000000    LR 0.000005    Time 0.120535    
2024-04-24 00:09:35,095 - --- validate (epoch=483)-----------
2024-04-24 00:09:35,096 - 3925 samples (32 per mini-batch)
2024-04-24 00:09:49,836 - Epoch: [483][  100/  123]    Loss 0.675434    Top1 78.343750    Top5 97.437500    
2024-04-24 00:09:52,871 - Epoch: [483][  123/  123]    Loss 0.668616    Top1 78.496815    Top5 97.579618    
2024-04-24 00:09:53,050 - ==> Top1: 78.497    Top5: 97.580    Loss: 0.669

2024-04-24 00:09:53,060 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:09:53,060 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:09:53,102 - 

2024-04-24 00:09:53,102 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:10:03,897 - Epoch: [484][  100/  296]    Overall Loss 0.672308    Objective Loss 0.672308                                        LR 0.000005    Time 0.107810    
2024-04-24 00:10:15,409 - Epoch: [484][  200/  296]    Overall Loss 0.665962    Objective Loss 0.665962                                        LR 0.000005    Time 0.111399    
2024-04-24 00:10:26,191 - Epoch: [484][  296/  296]    Overall Loss 0.665696    Objective Loss 0.665696    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.111651    
2024-04-24 00:10:26,399 - --- validate (epoch=484)-----------
2024-04-24 00:10:26,400 - 3925 samples (32 per mini-batch)
2024-04-24 00:10:39,236 - Epoch: [484][  100/  123]    Loss 0.673599    Top1 78.218750    Top5 97.562500    
2024-04-24 00:10:42,863 - Epoch: [484][  123/  123]    Loss 0.669393    Top1 78.369427    Top5 97.528662    
2024-04-24 00:10:43,052 - ==> Top1: 78.369    Top5: 97.529    Loss: 0.669

2024-04-24 00:10:43,061 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:10:43,061 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:10:43,098 - 

2024-04-24 00:10:43,099 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:10:52,666 - Epoch: [485][  100/  296]    Overall Loss 0.643824    Objective Loss 0.643824                                        LR 0.000005    Time 0.095537    
2024-04-24 00:11:02,308 - Epoch: [485][  200/  296]    Overall Loss 0.678527    Objective Loss 0.678527                                        LR 0.000005    Time 0.095910    
2024-04-24 00:11:09,919 - Epoch: [485][  296/  296]    Overall Loss 0.676234    Objective Loss 0.676234    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.090477    
2024-04-24 00:11:10,067 - --- validate (epoch=485)-----------
2024-04-24 00:11:10,068 - 3925 samples (32 per mini-batch)
2024-04-24 00:11:21,097 - Epoch: [485][  100/  123]    Loss 0.665080    Top1 78.687500    Top5 97.531250    
2024-04-24 00:11:23,514 - Epoch: [485][  123/  123]    Loss 0.673548    Top1 78.191083    Top5 97.477707    
2024-04-24 00:11:23,679 - ==> Top1: 78.191    Top5: 97.478    Loss: 0.674

2024-04-24 00:11:23,688 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:11:23,688 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:11:23,727 - 

2024-04-24 00:11:23,727 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:11:33,414 - Epoch: [486][  100/  296]    Overall Loss 0.667721    Objective Loss 0.667721                                        LR 0.000005    Time 0.096711    
2024-04-24 00:11:42,539 - Epoch: [486][  200/  296]    Overall Loss 0.658126    Objective Loss 0.658126                                        LR 0.000005    Time 0.093911    
2024-04-24 00:11:50,321 - Epoch: [486][  296/  296]    Overall Loss 0.665077    Objective Loss 0.665077    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.089710    
2024-04-24 00:11:50,456 - --- validate (epoch=486)-----------
2024-04-24 00:11:50,456 - 3925 samples (32 per mini-batch)
2024-04-24 00:12:00,385 - Epoch: [486][  100/  123]    Loss 0.642780    Top1 78.625000    Top5 97.875000    
2024-04-24 00:12:02,515 - Epoch: [486][  123/  123]    Loss 0.669674    Top1 78.292994    Top5 97.579618    
2024-04-24 00:12:02,657 - ==> Top1: 78.293    Top5: 97.580    Loss: 0.670

2024-04-24 00:12:02,667 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:12:02,667 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:12:02,702 - 

2024-04-24 00:12:02,703 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:12:12,642 - Epoch: [487][  100/  296]    Overall Loss 0.651854    Objective Loss 0.651854                                        LR 0.000005    Time 0.099250    
2024-04-24 00:12:21,127 - Epoch: [487][  200/  296]    Overall Loss 0.669839    Objective Loss 0.669839                                        LR 0.000005    Time 0.091979    
2024-04-24 00:12:29,752 - Epoch: [487][  296/  296]    Overall Loss 0.677393    Objective Loss 0.677393    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.091240    
2024-04-24 00:12:29,926 - --- validate (epoch=487)-----------
2024-04-24 00:12:29,927 - 3925 samples (32 per mini-batch)
2024-04-24 00:12:40,470 - Epoch: [487][  100/  123]    Loss 0.680452    Top1 78.031250    Top5 97.406250    
2024-04-24 00:12:42,300 - Epoch: [487][  123/  123]    Loss 0.671623    Top1 78.343949    Top5 97.452229    
2024-04-24 00:12:42,551 - ==> Top1: 78.344    Top5: 97.452    Loss: 0.672

2024-04-24 00:12:42,560 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:12:42,560 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:12:42,595 - 

2024-04-24 00:12:42,595 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:12:51,485 - Epoch: [488][  100/  296]    Overall Loss 0.702697    Objective Loss 0.702697                                        LR 0.000005    Time 0.088783    
2024-04-24 00:12:59,443 - Epoch: [488][  200/  296]    Overall Loss 0.686008    Objective Loss 0.686008                                        LR 0.000005    Time 0.084125    
2024-04-24 00:13:07,164 - Epoch: [488][  296/  296]    Overall Loss 0.688159    Objective Loss 0.688159    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.082889    
2024-04-24 00:13:07,354 - --- validate (epoch=488)-----------
2024-04-24 00:13:07,355 - 3925 samples (32 per mini-batch)
2024-04-24 00:13:18,023 - Epoch: [488][  100/  123]    Loss 0.665867    Top1 78.281250    Top5 97.250000    
2024-04-24 00:13:20,440 - Epoch: [488][  123/  123]    Loss 0.672901    Top1 78.292994    Top5 97.350318    
2024-04-24 00:13:20,597 - ==> Top1: 78.293    Top5: 97.350    Loss: 0.673

2024-04-24 00:13:20,606 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:13:20,607 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:13:20,643 - 

2024-04-24 00:13:20,644 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:13:29,838 - Epoch: [489][  100/  296]    Overall Loss 0.667562    Objective Loss 0.667562                                        LR 0.000005    Time 0.091809    
2024-04-24 00:13:37,416 - Epoch: [489][  200/  296]    Overall Loss 0.677365    Objective Loss 0.677365                                        LR 0.000005    Time 0.083725    
2024-04-24 00:13:43,401 - Epoch: [489][  296/  296]    Overall Loss 0.680568    Objective Loss 0.680568    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.076748    
2024-04-24 00:13:43,547 - --- validate (epoch=489)-----------
2024-04-24 00:13:43,548 - 3925 samples (32 per mini-batch)
2024-04-24 00:13:54,395 - Epoch: [489][  100/  123]    Loss 0.668645    Top1 78.531250    Top5 97.531250    
2024-04-24 00:13:56,691 - Epoch: [489][  123/  123]    Loss 0.670240    Top1 78.267516    Top5 97.426752    
2024-04-24 00:13:56,818 - ==> Top1: 78.268    Top5: 97.427    Loss: 0.670

2024-04-24 00:13:56,824 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:13:56,825 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:13:56,857 - 

2024-04-24 00:13:56,857 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:14:06,769 - Epoch: [490][  100/  296]    Overall Loss 0.682681    Objective Loss 0.682681                                        LR 0.000005    Time 0.098978    
2024-04-24 00:14:17,665 - Epoch: [490][  200/  296]    Overall Loss 0.674925    Objective Loss 0.674925                                        LR 0.000005    Time 0.103908    
2024-04-24 00:14:28,097 - Epoch: [490][  296/  296]    Overall Loss 0.670784    Objective Loss 0.670784    Top1 70.491803    Top5 100.000000    LR 0.000005    Time 0.105411    
2024-04-24 00:14:28,236 - --- validate (epoch=490)-----------
2024-04-24 00:14:28,237 - 3925 samples (32 per mini-batch)
2024-04-24 00:14:39,418 - Epoch: [490][  100/  123]    Loss 0.658219    Top1 78.562500    Top5 97.718750    
2024-04-24 00:14:41,474 - Epoch: [490][  123/  123]    Loss 0.667233    Top1 78.216561    Top5 97.579618    
2024-04-24 00:14:41,628 - ==> Top1: 78.217    Top5: 97.580    Loss: 0.667

2024-04-24 00:14:41,637 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:14:41,637 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:14:41,678 - 

2024-04-24 00:14:41,679 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:14:56,446 - Epoch: [491][  100/  296]    Overall Loss 0.636877    Objective Loss 0.636877                                        LR 0.000005    Time 0.147560    
2024-04-24 00:15:06,716 - Epoch: [491][  200/  296]    Overall Loss 0.667701    Objective Loss 0.667701                                        LR 0.000005    Time 0.125068    
2024-04-24 00:15:17,366 - Epoch: [491][  296/  296]    Overall Loss 0.672784    Objective Loss 0.672784    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.120443    
2024-04-24 00:15:17,579 - --- validate (epoch=491)-----------
2024-04-24 00:15:17,580 - 3925 samples (32 per mini-batch)
2024-04-24 00:15:31,557 - Epoch: [491][  100/  123]    Loss 0.656193    Top1 78.531250    Top5 97.843750    
2024-04-24 00:15:34,095 - Epoch: [491][  123/  123]    Loss 0.669378    Top1 78.292994    Top5 97.579618    
2024-04-24 00:15:34,274 - ==> Top1: 78.293    Top5: 97.580    Loss: 0.669

2024-04-24 00:15:34,283 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:15:34,284 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:15:34,321 - 

2024-04-24 00:15:34,321 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:15:46,936 - Epoch: [492][  100/  296]    Overall Loss 0.662192    Objective Loss 0.662192                                        LR 0.000005    Time 0.126004    
2024-04-24 00:15:54,077 - Epoch: [492][  200/  296]    Overall Loss 0.662509    Objective Loss 0.662509                                        LR 0.000005    Time 0.098646    
2024-04-24 00:16:00,681 - Epoch: [492][  296/  296]    Overall Loss 0.667042    Objective Loss 0.667042    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.088924    
2024-04-24 00:16:00,875 - --- validate (epoch=492)-----------
2024-04-24 00:16:00,876 - 3925 samples (32 per mini-batch)
2024-04-24 00:16:09,937 - Epoch: [492][  100/  123]    Loss 0.665745    Top1 77.906250    Top5 97.500000    
2024-04-24 00:16:12,245 - Epoch: [492][  123/  123]    Loss 0.671396    Top1 77.961783    Top5 97.452229    
2024-04-24 00:16:12,402 - ==> Top1: 77.962    Top5: 97.452    Loss: 0.671

2024-04-24 00:16:12,409 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:16:12,410 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:16:12,443 - 

2024-04-24 00:16:12,443 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:16:21,474 - Epoch: [493][  100/  296]    Overall Loss 0.679666    Objective Loss 0.679666                                        LR 0.000005    Time 0.090174    
2024-04-24 00:16:30,990 - Epoch: [493][  200/  296]    Overall Loss 0.662055    Objective Loss 0.662055                                        LR 0.000005    Time 0.092608    
2024-04-24 00:16:38,073 - Epoch: [493][  296/  296]    Overall Loss 0.673755    Objective Loss 0.673755    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.086462    
2024-04-24 00:16:38,253 - --- validate (epoch=493)-----------
2024-04-24 00:16:38,254 - 3925 samples (32 per mini-batch)
2024-04-24 00:16:49,811 - Epoch: [493][  100/  123]    Loss 0.673836    Top1 78.500000    Top5 97.437500    
2024-04-24 00:16:52,325 - Epoch: [493][  123/  123]    Loss 0.672450    Top1 78.216561    Top5 97.401274    
2024-04-24 00:16:52,484 - ==> Top1: 78.217    Top5: 97.401    Loss: 0.672

2024-04-24 00:16:52,493 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:16:52,494 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:16:52,535 - 

2024-04-24 00:16:52,535 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:17:01,780 - Epoch: [494][  100/  296]    Overall Loss 0.688619    Objective Loss 0.688619                                        LR 0.000005    Time 0.092308    
2024-04-24 00:17:10,934 - Epoch: [494][  200/  296]    Overall Loss 0.672213    Objective Loss 0.672213                                        LR 0.000005    Time 0.091860    
2024-04-24 00:17:22,267 - Epoch: [494][  296/  296]    Overall Loss 0.670742    Objective Loss 0.670742    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.100318    
2024-04-24 00:17:22,385 - --- validate (epoch=494)-----------
2024-04-24 00:17:22,385 - 3925 samples (32 per mini-batch)
2024-04-24 00:17:33,419 - Epoch: [494][  100/  123]    Loss 0.669429    Top1 78.375000    Top5 97.312500    
2024-04-24 00:17:36,699 - Epoch: [494][  123/  123]    Loss 0.672074    Top1 78.242038    Top5 97.477707    
2024-04-24 00:17:36,872 - ==> Top1: 78.242    Top5: 97.478    Loss: 0.672

2024-04-24 00:17:36,879 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:17:36,880 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:17:36,918 - 

2024-04-24 00:17:36,919 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:17:51,980 - Epoch: [495][  100/  296]    Overall Loss 0.678948    Objective Loss 0.678948                                        LR 0.000005    Time 0.150458    
2024-04-24 00:18:05,276 - Epoch: [495][  200/  296]    Overall Loss 0.675472    Objective Loss 0.675472                                        LR 0.000005    Time 0.141641    
2024-04-24 00:18:17,083 - Epoch: [495][  296/  296]    Overall Loss 0.678742    Objective Loss 0.678742    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.135556    
2024-04-24 00:18:17,256 - --- validate (epoch=495)-----------
2024-04-24 00:18:17,257 - 3925 samples (32 per mini-batch)
2024-04-24 00:18:32,013 - Epoch: [495][  100/  123]    Loss 0.677145    Top1 78.093750    Top5 97.468750    
2024-04-24 00:18:35,334 - Epoch: [495][  123/  123]    Loss 0.671117    Top1 78.318471    Top5 97.452229    
2024-04-24 00:18:35,518 - ==> Top1: 78.318    Top5: 97.452    Loss: 0.671

2024-04-24 00:18:35,527 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:18:35,527 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:18:35,572 - 

2024-04-24 00:18:35,573 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:18:48,177 - Epoch: [496][  100/  296]    Overall Loss 0.701720    Objective Loss 0.701720                                        LR 0.000005    Time 0.125899    
2024-04-24 00:19:00,410 - Epoch: [496][  200/  296]    Overall Loss 0.686894    Objective Loss 0.686894                                        LR 0.000005    Time 0.124047    
2024-04-24 00:19:11,073 - Epoch: [496][  296/  296]    Overall Loss 0.684332    Objective Loss 0.684332    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.119798    
2024-04-24 00:19:11,221 - --- validate (epoch=496)-----------
2024-04-24 00:19:11,221 - 3925 samples (32 per mini-batch)
2024-04-24 00:19:25,901 - Epoch: [496][  100/  123]    Loss 0.666619    Top1 78.812500    Top5 97.375000    
2024-04-24 00:19:28,916 - Epoch: [496][  123/  123]    Loss 0.669647    Top1 78.445860    Top5 97.528662    
2024-04-24 00:19:29,097 - ==> Top1: 78.446    Top5: 97.529    Loss: 0.670

2024-04-24 00:19:29,108 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:19:29,108 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:19:29,149 - 

2024-04-24 00:19:29,149 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:19:41,249 - Epoch: [497][  100/  296]    Overall Loss 0.653039    Objective Loss 0.653039                                        LR 0.000005    Time 0.120866    
2024-04-24 00:19:53,662 - Epoch: [497][  200/  296]    Overall Loss 0.677745    Objective Loss 0.677745                                        LR 0.000005    Time 0.122441    
2024-04-24 00:20:03,977 - Epoch: [497][  296/  296]    Overall Loss 0.663906    Objective Loss 0.663906    Top1 68.852459    Top5 98.360656    LR 0.000005    Time 0.117545    
2024-04-24 00:20:04,121 - --- validate (epoch=497)-----------
2024-04-24 00:20:04,121 - 3925 samples (32 per mini-batch)
2024-04-24 00:20:16,996 - Epoch: [497][  100/  123]    Loss 0.669459    Top1 78.406250    Top5 97.437500    
2024-04-24 00:20:19,406 - Epoch: [497][  123/  123]    Loss 0.669212    Top1 78.216561    Top5 97.503185    
2024-04-24 00:20:19,562 - ==> Top1: 78.217    Top5: 97.503    Loss: 0.669

2024-04-24 00:20:19,570 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:20:19,571 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:20:19,608 - 

2024-04-24 00:20:19,609 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:20:31,088 - Epoch: [498][  100/  296]    Overall Loss 0.666814    Objective Loss 0.666814                                        LR 0.000005    Time 0.114661    
2024-04-24 00:20:42,087 - Epoch: [498][  200/  296]    Overall Loss 0.658573    Objective Loss 0.658573                                        LR 0.000005    Time 0.112257    
2024-04-24 00:20:53,691 - Epoch: [498][  296/  296]    Overall Loss 0.671289    Objective Loss 0.671289    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.115009    
2024-04-24 00:20:53,855 - --- validate (epoch=498)-----------
2024-04-24 00:20:53,856 - 3925 samples (32 per mini-batch)
2024-04-24 00:21:07,861 - Epoch: [498][  100/  123]    Loss 0.665211    Top1 78.343750    Top5 97.500000    
2024-04-24 00:21:10,884 - Epoch: [498][  123/  123]    Loss 0.670927    Top1 78.089172    Top5 97.477707    
2024-04-24 00:21:11,009 - ==> Top1: 78.089    Top5: 97.478    Loss: 0.671

2024-04-24 00:21:11,017 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:21:11,018 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:21:11,061 - 

2024-04-24 00:21:11,062 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:21:24,250 - Epoch: [499][  100/  296]    Overall Loss 0.674440    Objective Loss 0.674440                                        LR 0.000005    Time 0.131757    
2024-04-24 00:21:34,873 - Epoch: [499][  200/  296]    Overall Loss 0.664231    Objective Loss 0.664231                                        LR 0.000005    Time 0.118929    
2024-04-24 00:21:44,642 - Epoch: [499][  296/  296]    Overall Loss 0.672298    Objective Loss 0.672298    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.113323    
2024-04-24 00:21:44,794 - --- validate (epoch=499)-----------
2024-04-24 00:21:44,795 - 3925 samples (32 per mini-batch)
2024-04-24 00:21:58,256 - Epoch: [499][  100/  123]    Loss 0.666741    Top1 78.687500    Top5 97.750000    
2024-04-24 00:22:01,194 - Epoch: [499][  123/  123]    Loss 0.671727    Top1 78.292994    Top5 97.528662    
2024-04-24 00:22:01,323 - ==> Top1: 78.293    Top5: 97.529    Loss: 0.672

2024-04-24 00:22:01,334 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:22:01,335 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:22:01,378 - 

2024-04-24 00:22:01,379 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:22:14,500 - Epoch: [500][  100/  296]    Overall Loss 0.707662    Objective Loss 0.707662                                        LR 0.000005    Time 0.131093    
2024-04-24 00:22:25,573 - Epoch: [500][  200/  296]    Overall Loss 0.701987    Objective Loss 0.701987                                        LR 0.000005    Time 0.120848    
2024-04-24 00:22:36,919 - Epoch: [500][  296/  296]    Overall Loss 0.690157    Objective Loss 0.690157    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.119948    
2024-04-24 00:22:37,059 - --- validate (epoch=500)-----------
2024-04-24 00:22:37,060 - 3925 samples (32 per mini-batch)
2024-04-24 00:22:50,774 - Epoch: [500][  100/  123]    Loss 0.668452    Top1 78.312500    Top5 97.500000    
2024-04-24 00:22:52,816 - Epoch: [500][  123/  123]    Loss 0.670977    Top1 78.191083    Top5 97.503185    
2024-04-24 00:22:53,026 - ==> Top1: 78.191    Top5: 97.503    Loss: 0.671

2024-04-24 00:22:53,035 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:22:53,036 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:22:53,072 - 

2024-04-24 00:22:53,073 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:23:01,182 - Epoch: [501][  100/  296]    Overall Loss 0.690205    Objective Loss 0.690205                                        LR 0.000005    Time 0.080973    
2024-04-24 00:23:07,283 - Epoch: [501][  200/  296]    Overall Loss 0.680863    Objective Loss 0.680863                                        LR 0.000005    Time 0.070929    
2024-04-24 00:23:13,540 - Epoch: [501][  296/  296]    Overall Loss 0.680585    Objective Loss 0.680585    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.069024    
2024-04-24 00:23:13,662 - --- validate (epoch=501)-----------
2024-04-24 00:23:13,662 - 3925 samples (32 per mini-batch)
2024-04-24 00:23:23,716 - Epoch: [501][  100/  123]    Loss 0.661420    Top1 78.875000    Top5 97.593750    
2024-04-24 00:23:25,126 - Epoch: [501][  123/  123]    Loss 0.666054    Top1 78.394904    Top5 97.528662    
2024-04-24 00:23:25,274 - ==> Top1: 78.395    Top5: 97.529    Loss: 0.666

2024-04-24 00:23:25,284 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:23:25,284 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:23:25,320 - 

2024-04-24 00:23:25,320 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:23:36,432 - Epoch: [502][  100/  296]    Overall Loss 0.643880    Objective Loss 0.643880                                        LR 0.000005    Time 0.110986    
2024-04-24 00:23:46,242 - Epoch: [502][  200/  296]    Overall Loss 0.662314    Objective Loss 0.662314                                        LR 0.000005    Time 0.104483    
2024-04-24 00:23:59,298 - Epoch: [502][  296/  296]    Overall Loss 0.664381    Objective Loss 0.664381    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.114664    
2024-04-24 00:23:59,423 - --- validate (epoch=502)-----------
2024-04-24 00:23:59,424 - 3925 samples (32 per mini-batch)
2024-04-24 00:24:14,453 - Epoch: [502][  100/  123]    Loss 0.666093    Top1 78.687500    Top5 97.250000    
2024-04-24 00:24:17,013 - Epoch: [502][  123/  123]    Loss 0.672425    Top1 78.445860    Top5 97.401274    
2024-04-24 00:24:17,190 - ==> Top1: 78.446    Top5: 97.401    Loss: 0.672

2024-04-24 00:24:17,200 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:24:17,201 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:24:17,238 - 

2024-04-24 00:24:17,239 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:24:26,423 - Epoch: [503][  100/  296]    Overall Loss 0.672342    Objective Loss 0.672342                                        LR 0.000005    Time 0.091711    
2024-04-24 00:24:35,649 - Epoch: [503][  200/  296]    Overall Loss 0.669393    Objective Loss 0.669393                                        LR 0.000005    Time 0.091918    
2024-04-24 00:24:45,619 - Epoch: [503][  296/  296]    Overall Loss 0.670730    Objective Loss 0.670730    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.095744    
2024-04-24 00:24:45,808 - --- validate (epoch=503)-----------
2024-04-24 00:24:45,808 - 3925 samples (32 per mini-batch)
2024-04-24 00:24:58,811 - Epoch: [503][  100/  123]    Loss 0.668774    Top1 78.593750    Top5 97.375000    
2024-04-24 00:25:02,522 - Epoch: [503][  123/  123]    Loss 0.670551    Top1 78.522293    Top5 97.477707    
2024-04-24 00:25:02,693 - ==> Top1: 78.522    Top5: 97.478    Loss: 0.671

2024-04-24 00:25:02,702 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:25:02,702 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:25:02,737 - 

2024-04-24 00:25:02,737 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:25:11,953 - Epoch: [504][  100/  296]    Overall Loss 0.638895    Objective Loss 0.638895                                        LR 0.000005    Time 0.092024    
2024-04-24 00:25:21,140 - Epoch: [504][  200/  296]    Overall Loss 0.659549    Objective Loss 0.659549                                        LR 0.000005    Time 0.091882    
2024-04-24 00:25:30,228 - Epoch: [504][  296/  296]    Overall Loss 0.668052    Objective Loss 0.668052    Top1 86.885246    Top5 95.081967    LR 0.000005    Time 0.092742    
2024-04-24 00:25:30,392 - --- validate (epoch=504)-----------
2024-04-24 00:25:30,393 - 3925 samples (32 per mini-batch)
2024-04-24 00:25:42,883 - Epoch: [504][  100/  123]    Loss 0.663246    Top1 78.562500    Top5 97.468750    
2024-04-24 00:25:45,311 - Epoch: [504][  123/  123]    Loss 0.667168    Top1 78.267516    Top5 97.579618    
2024-04-24 00:25:45,457 - ==> Top1: 78.268    Top5: 97.580    Loss: 0.667

2024-04-24 00:25:45,466 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:25:45,466 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:25:45,507 - 

2024-04-24 00:25:45,507 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:25:55,946 - Epoch: [505][  100/  296]    Overall Loss 0.666152    Objective Loss 0.666152                                        LR 0.000005    Time 0.104251    
2024-04-24 00:26:07,802 - Epoch: [505][  200/  296]    Overall Loss 0.661438    Objective Loss 0.661438                                        LR 0.000005    Time 0.111347    
2024-04-24 00:26:19,752 - Epoch: [505][  296/  296]    Overall Loss 0.674401    Objective Loss 0.674401    Top1 68.852459    Top5 93.442623    LR 0.000005    Time 0.115565    
2024-04-24 00:26:19,933 - --- validate (epoch=505)-----------
2024-04-24 00:26:19,933 - 3925 samples (32 per mini-batch)
2024-04-24 00:26:30,273 - Epoch: [505][  100/  123]    Loss 0.672449    Top1 77.343750    Top5 97.468750    
2024-04-24 00:26:32,253 - Epoch: [505][  123/  123]    Loss 0.672503    Top1 77.961783    Top5 97.503185    
2024-04-24 00:26:32,474 - ==> Top1: 77.962    Top5: 97.503    Loss: 0.673

2024-04-24 00:26:32,485 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:26:32,485 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:26:32,522 - 

2024-04-24 00:26:32,522 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:26:42,356 - Epoch: [506][  100/  296]    Overall Loss 0.671058    Objective Loss 0.671058                                        LR 0.000005    Time 0.098205    
2024-04-24 00:26:51,417 - Epoch: [506][  200/  296]    Overall Loss 0.668440    Objective Loss 0.668440                                        LR 0.000005    Time 0.094339    
2024-04-24 00:27:00,190 - Epoch: [506][  296/  296]    Overall Loss 0.675585    Objective Loss 0.675585    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.093339    
2024-04-24 00:27:00,340 - --- validate (epoch=506)-----------
2024-04-24 00:27:00,341 - 3925 samples (32 per mini-batch)
2024-04-24 00:27:13,342 - Epoch: [506][  100/  123]    Loss 0.672205    Top1 78.281250    Top5 97.625000    
2024-04-24 00:27:15,338 - Epoch: [506][  123/  123]    Loss 0.671492    Top1 78.292994    Top5 97.554140    
2024-04-24 00:27:15,510 - ==> Top1: 78.293    Top5: 97.554    Loss: 0.671

2024-04-24 00:27:15,515 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:27:15,515 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:27:15,550 - 

2024-04-24 00:27:15,550 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:27:24,638 - Epoch: [507][  100/  296]    Overall Loss 0.691215    Objective Loss 0.691215                                        LR 0.000005    Time 0.090737    
2024-04-24 00:27:34,849 - Epoch: [507][  200/  296]    Overall Loss 0.685370    Objective Loss 0.685370                                        LR 0.000005    Time 0.096363    
2024-04-24 00:27:43,850 - Epoch: [507][  296/  296]    Overall Loss 0.676095    Objective Loss 0.676095    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.095473    
2024-04-24 00:27:44,026 - --- validate (epoch=507)-----------
2024-04-24 00:27:44,027 - 3925 samples (32 per mini-batch)
2024-04-24 00:27:56,807 - Epoch: [507][  100/  123]    Loss 0.672165    Top1 77.718750    Top5 97.468750    
2024-04-24 00:28:00,311 - Epoch: [507][  123/  123]    Loss 0.669989    Top1 78.114650    Top5 97.426752    
2024-04-24 00:28:00,478 - ==> Top1: 78.115    Top5: 97.427    Loss: 0.670

2024-04-24 00:28:00,488 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:28:00,488 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:28:00,537 - 

2024-04-24 00:28:00,538 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:28:13,131 - Epoch: [508][  100/  296]    Overall Loss 0.684960    Objective Loss 0.684960                                        LR 0.000005    Time 0.125783    
2024-04-24 00:28:25,594 - Epoch: [508][  200/  296]    Overall Loss 0.679862    Objective Loss 0.679862                                        LR 0.000005    Time 0.125143    
2024-04-24 00:28:37,093 - Epoch: [508][  296/  296]    Overall Loss 0.666557    Objective Loss 0.666557    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.123369    
2024-04-24 00:28:37,247 - --- validate (epoch=508)-----------
2024-04-24 00:28:37,248 - 3925 samples (32 per mini-batch)
2024-04-24 00:28:50,903 - Epoch: [508][  100/  123]    Loss 0.669736    Top1 78.187500    Top5 97.500000    
2024-04-24 00:28:53,468 - Epoch: [508][  123/  123]    Loss 0.669940    Top1 78.394904    Top5 97.528662    
2024-04-24 00:28:53,586 - ==> Top1: 78.395    Top5: 97.529    Loss: 0.670

2024-04-24 00:28:53,596 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:28:53,596 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:28:53,633 - 

2024-04-24 00:28:53,634 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:29:06,601 - Epoch: [509][  100/  296]    Overall Loss 0.682653    Objective Loss 0.682653                                        LR 0.000005    Time 0.129545    
2024-04-24 00:29:18,434 - Epoch: [509][  200/  296]    Overall Loss 0.672247    Objective Loss 0.672247                                        LR 0.000005    Time 0.123871    
2024-04-24 00:29:28,976 - Epoch: [509][  296/  296]    Overall Loss 0.666989    Objective Loss 0.666989    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.119269    
2024-04-24 00:29:29,154 - --- validate (epoch=509)-----------
2024-04-24 00:29:29,154 - 3925 samples (32 per mini-batch)
2024-04-24 00:29:39,251 - Epoch: [509][  100/  123]    Loss 0.664838    Top1 79.000000    Top5 97.437500    
2024-04-24 00:29:41,501 - Epoch: [509][  123/  123]    Loss 0.668434    Top1 78.522293    Top5 97.528662    
2024-04-24 00:29:41,633 - ==> Top1: 78.522    Top5: 97.529    Loss: 0.668

2024-04-24 00:29:41,642 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:29:41,643 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:29:41,684 - 

2024-04-24 00:29:41,685 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:29:54,770 - Epoch: [510][  100/  296]    Overall Loss 0.662367    Objective Loss 0.662367                                        LR 0.000005    Time 0.130707    
2024-04-24 00:30:02,215 - Epoch: [510][  200/  296]    Overall Loss 0.670450    Objective Loss 0.670450                                        LR 0.000005    Time 0.102503    
2024-04-24 00:30:10,209 - Epoch: [510][  296/  296]    Overall Loss 0.672127    Objective Loss 0.672127    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.096221    
2024-04-24 00:30:10,391 - --- validate (epoch=510)-----------
2024-04-24 00:30:10,392 - 3925 samples (32 per mini-batch)
2024-04-24 00:30:20,977 - Epoch: [510][  100/  123]    Loss 0.656954    Top1 78.750000    Top5 97.562500    
2024-04-24 00:30:23,074 - Epoch: [510][  123/  123]    Loss 0.670736    Top1 78.292994    Top5 97.503185    
2024-04-24 00:30:23,193 - ==> Top1: 78.293    Top5: 97.503    Loss: 0.671

2024-04-24 00:30:23,199 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:30:23,199 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:30:23,236 - 

2024-04-24 00:30:23,236 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:30:35,855 - Epoch: [511][  100/  296]    Overall Loss 0.689190    Objective Loss 0.689190                                        LR 0.000005    Time 0.126057    
2024-04-24 00:30:45,372 - Epoch: [511][  200/  296]    Overall Loss 0.688383    Objective Loss 0.688383                                        LR 0.000005    Time 0.110544    
2024-04-24 00:30:52,784 - Epoch: [511][  296/  296]    Overall Loss 0.687191    Objective Loss 0.687191    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.099691    
2024-04-24 00:30:52,930 - --- validate (epoch=511)-----------
2024-04-24 00:30:52,931 - 3925 samples (32 per mini-batch)
2024-04-24 00:31:05,196 - Epoch: [511][  100/  123]    Loss 0.665443    Top1 78.531250    Top5 97.562500    
2024-04-24 00:31:08,094 - Epoch: [511][  123/  123]    Loss 0.668803    Top1 78.343949    Top5 97.528662    
2024-04-24 00:31:08,242 - ==> Top1: 78.344    Top5: 97.529    Loss: 0.669

2024-04-24 00:31:08,252 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:31:08,253 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:31:08,292 - 

2024-04-24 00:31:08,292 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:31:21,207 - Epoch: [512][  100/  296]    Overall Loss 0.639624    Objective Loss 0.639624                                        LR 0.000005    Time 0.129020    
2024-04-24 00:31:31,952 - Epoch: [512][  200/  296]    Overall Loss 0.674355    Objective Loss 0.674355                                        LR 0.000005    Time 0.118167    
2024-04-24 00:31:42,273 - Epoch: [512][  296/  296]    Overall Loss 0.673804    Objective Loss 0.673804    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.114665    
2024-04-24 00:31:42,424 - --- validate (epoch=512)-----------
2024-04-24 00:31:42,425 - 3925 samples (32 per mini-batch)
2024-04-24 00:31:57,287 - Epoch: [512][  100/  123]    Loss 0.669937    Top1 78.500000    Top5 97.375000    
2024-04-24 00:32:00,055 - Epoch: [512][  123/  123]    Loss 0.667203    Top1 78.471338    Top5 97.503185    
2024-04-24 00:32:00,255 - ==> Top1: 78.471    Top5: 97.503    Loss: 0.667

2024-04-24 00:32:00,266 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:32:00,266 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:32:00,306 - 

2024-04-24 00:32:00,307 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:32:14,307 - Epoch: [513][  100/  296]    Overall Loss 0.648715    Objective Loss 0.648715                                        LR 0.000005    Time 0.139861    
2024-04-24 00:32:25,336 - Epoch: [513][  200/  296]    Overall Loss 0.677778    Objective Loss 0.677778                                        LR 0.000005    Time 0.125000    
2024-04-24 00:32:35,197 - Epoch: [513][  296/  296]    Overall Loss 0.673696    Objective Loss 0.673696    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.117736    
2024-04-24 00:32:35,370 - --- validate (epoch=513)-----------
2024-04-24 00:32:35,371 - 3925 samples (32 per mini-batch)
2024-04-24 00:32:48,427 - Epoch: [513][  100/  123]    Loss 0.664186    Top1 78.656250    Top5 97.468750    
2024-04-24 00:32:51,388 - Epoch: [513][  123/  123]    Loss 0.670195    Top1 78.420382    Top5 97.503185    
2024-04-24 00:32:51,481 - ==> Top1: 78.420    Top5: 97.503    Loss: 0.670

2024-04-24 00:32:51,490 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:32:51,491 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:32:51,527 - 

2024-04-24 00:32:51,527 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:33:03,167 - Epoch: [514][  100/  296]    Overall Loss 0.657669    Objective Loss 0.657669                                        LR 0.000005    Time 0.116256    
2024-04-24 00:33:13,177 - Epoch: [514][  200/  296]    Overall Loss 0.660690    Objective Loss 0.660690                                        LR 0.000005    Time 0.108101    
2024-04-24 00:33:23,282 - Epoch: [514][  296/  296]    Overall Loss 0.658888    Objective Loss 0.658888    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.107137    
2024-04-24 00:33:23,395 - --- validate (epoch=514)-----------
2024-04-24 00:33:23,395 - 3925 samples (32 per mini-batch)
2024-04-24 00:33:38,448 - Epoch: [514][  100/  123]    Loss 0.664834    Top1 78.531250    Top5 97.375000    
2024-04-24 00:33:41,569 - Epoch: [514][  123/  123]    Loss 0.669202    Top1 78.343949    Top5 97.452229    
2024-04-24 00:33:41,757 - ==> Top1: 78.344    Top5: 97.452    Loss: 0.669

2024-04-24 00:33:41,763 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:33:41,763 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:33:41,798 - 

2024-04-24 00:33:41,798 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:33:53,314 - Epoch: [515][  100/  296]    Overall Loss 0.667442    Objective Loss 0.667442                                        LR 0.000005    Time 0.115009    
2024-04-24 00:34:03,891 - Epoch: [515][  200/  296]    Overall Loss 0.662225    Objective Loss 0.662225                                        LR 0.000005    Time 0.110316    
2024-04-24 00:34:12,839 - Epoch: [515][  296/  296]    Overall Loss 0.668137    Objective Loss 0.668137    Top1 68.852459    Top5 98.360656    LR 0.000005    Time 0.104724    
2024-04-24 00:34:12,997 - --- validate (epoch=515)-----------
2024-04-24 00:34:12,998 - 3925 samples (32 per mini-batch)
2024-04-24 00:34:27,374 - Epoch: [515][  100/  123]    Loss 0.673000    Top1 77.687500    Top5 97.562500    
2024-04-24 00:34:30,674 - Epoch: [515][  123/  123]    Loss 0.670279    Top1 77.885350    Top5 97.452229    
2024-04-24 00:34:30,891 - ==> Top1: 77.885    Top5: 97.452    Loss: 0.670

2024-04-24 00:34:30,902 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:34:30,902 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:34:30,943 - 

2024-04-24 00:34:30,943 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:34:43,050 - Epoch: [516][  100/  296]    Overall Loss 0.661232    Objective Loss 0.661232                                        LR 0.000005    Time 0.120948    
2024-04-24 00:34:55,334 - Epoch: [516][  200/  296]    Overall Loss 0.680783    Objective Loss 0.680783                                        LR 0.000005    Time 0.121827    
2024-04-24 00:35:06,182 - Epoch: [516][  296/  296]    Overall Loss 0.686515    Objective Loss 0.686515    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.118912    
2024-04-24 00:35:06,399 - --- validate (epoch=516)-----------
2024-04-24 00:35:06,399 - 3925 samples (32 per mini-batch)
2024-04-24 00:35:22,049 - Epoch: [516][  100/  123]    Loss 0.670151    Top1 78.062500    Top5 97.500000    
2024-04-24 00:35:25,054 - Epoch: [516][  123/  123]    Loss 0.673493    Top1 78.191083    Top5 97.528662    
2024-04-24 00:35:25,178 - ==> Top1: 78.191    Top5: 97.529    Loss: 0.673

2024-04-24 00:35:25,187 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:35:25,188 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:35:25,225 - 

2024-04-24 00:35:25,225 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:35:36,883 - Epoch: [517][  100/  296]    Overall Loss 0.637542    Objective Loss 0.637542                                        LR 0.000005    Time 0.116453    
2024-04-24 00:35:47,688 - Epoch: [517][  200/  296]    Overall Loss 0.636751    Objective Loss 0.636751                                        LR 0.000005    Time 0.112193    
2024-04-24 00:35:57,852 - Epoch: [517][  296/  296]    Overall Loss 0.653898    Objective Loss 0.653898    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.110103    
2024-04-24 00:35:58,001 - --- validate (epoch=517)-----------
2024-04-24 00:35:58,002 - 3925 samples (32 per mini-batch)
2024-04-24 00:36:12,180 - Epoch: [517][  100/  123]    Loss 0.665679    Top1 78.312500    Top5 97.187500    
2024-04-24 00:36:15,061 - Epoch: [517][  123/  123]    Loss 0.674436    Top1 78.063694    Top5 97.324841    
2024-04-24 00:36:15,230 - ==> Top1: 78.064    Top5: 97.325    Loss: 0.674

2024-04-24 00:36:15,237 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:36:15,238 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:36:15,278 - 

2024-04-24 00:36:15,279 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:36:31,228 - Epoch: [518][  100/  296]    Overall Loss 0.658342    Objective Loss 0.658342                                        LR 0.000005    Time 0.159341    
2024-04-24 00:36:44,762 - Epoch: [518][  200/  296]    Overall Loss 0.642442    Objective Loss 0.642442                                        LR 0.000005    Time 0.147268    
2024-04-24 00:36:54,980 - Epoch: [518][  296/  296]    Overall Loss 0.662716    Objective Loss 0.662716    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.133981    
2024-04-24 00:36:55,189 - --- validate (epoch=518)-----------
2024-04-24 00:36:55,190 - 3925 samples (32 per mini-batch)
2024-04-24 00:37:09,619 - Epoch: [518][  100/  123]    Loss 0.674113    Top1 78.250000    Top5 97.375000    
2024-04-24 00:37:12,496 - Epoch: [518][  123/  123]    Loss 0.668915    Top1 78.420382    Top5 97.350318    
2024-04-24 00:37:12,751 - ==> Top1: 78.420    Top5: 97.350    Loss: 0.669

2024-04-24 00:37:12,759 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:37:12,759 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:37:12,802 - 

2024-04-24 00:37:12,803 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:37:22,183 - Epoch: [519][  100/  296]    Overall Loss 0.645319    Objective Loss 0.645319                                        LR 0.000005    Time 0.093664    
2024-04-24 00:37:33,786 - Epoch: [519][  200/  296]    Overall Loss 0.677630    Objective Loss 0.677630                                        LR 0.000005    Time 0.104779    
2024-04-24 00:37:43,293 - Epoch: [519][  296/  296]    Overall Loss 0.675903    Objective Loss 0.675903    Top1 77.049180    Top5 93.442623    LR 0.000005    Time 0.102872    
2024-04-24 00:37:43,519 - --- validate (epoch=519)-----------
2024-04-24 00:37:43,520 - 3925 samples (32 per mini-batch)
2024-04-24 00:37:57,131 - Epoch: [519][  100/  123]    Loss 0.664757    Top1 78.468750    Top5 97.593750    
2024-04-24 00:37:59,702 - Epoch: [519][  123/  123]    Loss 0.668317    Top1 78.369427    Top5 97.426752    
2024-04-24 00:38:00,047 - ==> Top1: 78.369    Top5: 97.427    Loss: 0.668

2024-04-24 00:38:00,056 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:38:00,056 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:38:00,091 - 

2024-04-24 00:38:00,091 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:38:11,516 - Epoch: [520][  100/  296]    Overall Loss 0.684110    Objective Loss 0.684110                                        LR 0.000005    Time 0.114117    
2024-04-24 00:38:22,565 - Epoch: [520][  200/  296]    Overall Loss 0.674005    Objective Loss 0.674005                                        LR 0.000005    Time 0.112234    
2024-04-24 00:38:32,599 - Epoch: [520][  296/  296]    Overall Loss 0.671843    Objective Loss 0.671843    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.109689    
2024-04-24 00:38:32,770 - --- validate (epoch=520)-----------
2024-04-24 00:38:32,771 - 3925 samples (32 per mini-batch)
2024-04-24 00:38:48,380 - Epoch: [520][  100/  123]    Loss 0.669809    Top1 78.062500    Top5 97.625000    
2024-04-24 00:38:50,866 - Epoch: [520][  123/  123]    Loss 0.667061    Top1 78.165605    Top5 97.528662    
2024-04-24 00:38:51,038 - ==> Top1: 78.166    Top5: 97.529    Loss: 0.667

2024-04-24 00:38:51,048 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:38:51,048 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:38:51,084 - 

2024-04-24 00:38:51,085 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:39:02,679 - Epoch: [521][  100/  296]    Overall Loss 0.666131    Objective Loss 0.666131                                        LR 0.000005    Time 0.115796    
2024-04-24 00:39:11,305 - Epoch: [521][  200/  296]    Overall Loss 0.675359    Objective Loss 0.675359                                        LR 0.000005    Time 0.100961    
2024-04-24 00:39:18,583 - Epoch: [521][  296/  296]    Overall Loss 0.669168    Objective Loss 0.669168    Top1 90.163934    Top5 96.721311    LR 0.000005    Time 0.092761    
2024-04-24 00:39:18,749 - --- validate (epoch=521)-----------
2024-04-24 00:39:18,750 - 3925 samples (32 per mini-batch)
2024-04-24 00:39:28,528 - Epoch: [521][  100/  123]    Loss 0.664046    Top1 78.156250    Top5 97.656250    
2024-04-24 00:39:30,687 - Epoch: [521][  123/  123]    Loss 0.669228    Top1 78.369427    Top5 97.656051    
2024-04-24 00:39:30,896 - ==> Top1: 78.369    Top5: 97.656    Loss: 0.669

2024-04-24 00:39:30,907 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:39:30,908 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:39:30,944 - 

2024-04-24 00:39:30,945 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:39:42,029 - Epoch: [522][  100/  296]    Overall Loss 0.664160    Objective Loss 0.664160                                        LR 0.000005    Time 0.110709    
2024-04-24 00:39:52,728 - Epoch: [522][  200/  296]    Overall Loss 0.652817    Objective Loss 0.652817                                        LR 0.000005    Time 0.108772    
2024-04-24 00:40:02,677 - Epoch: [522][  296/  296]    Overall Loss 0.659354    Objective Loss 0.659354    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.107064    
2024-04-24 00:40:02,822 - --- validate (epoch=522)-----------
2024-04-24 00:40:02,822 - 3925 samples (32 per mini-batch)
2024-04-24 00:40:16,528 - Epoch: [522][  100/  123]    Loss 0.682959    Top1 78.031250    Top5 97.562500    
2024-04-24 00:40:18,819 - Epoch: [522][  123/  123]    Loss 0.668838    Top1 78.369427    Top5 97.605096    
2024-04-24 00:40:18,977 - ==> Top1: 78.369    Top5: 97.605    Loss: 0.669

2024-04-24 00:40:18,982 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:40:18,982 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:40:19,013 - 

2024-04-24 00:40:19,014 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:40:29,658 - Epoch: [523][  100/  296]    Overall Loss 0.641316    Objective Loss 0.641316                                        LR 0.000005    Time 0.106286    
2024-04-24 00:40:38,682 - Epoch: [523][  200/  296]    Overall Loss 0.666279    Objective Loss 0.666279                                        LR 0.000005    Time 0.098200    
2024-04-24 00:40:49,362 - Epoch: [523][  296/  296]    Overall Loss 0.669554    Objective Loss 0.669554    Top1 65.573770    Top5 96.721311    LR 0.000005    Time 0.102392    
2024-04-24 00:40:49,492 - --- validate (epoch=523)-----------
2024-04-24 00:40:49,493 - 3925 samples (32 per mini-batch)
2024-04-24 00:41:03,436 - Epoch: [523][  100/  123]    Loss 0.670639    Top1 78.218750    Top5 97.531250    
2024-04-24 00:41:06,254 - Epoch: [523][  123/  123]    Loss 0.671498    Top1 78.191083    Top5 97.528662    
2024-04-24 00:41:06,409 - ==> Top1: 78.191    Top5: 97.529    Loss: 0.671

2024-04-24 00:41:06,419 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:41:06,419 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:41:06,458 - 

2024-04-24 00:41:06,458 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:41:17,166 - Epoch: [524][  100/  296]    Overall Loss 0.677232    Objective Loss 0.677232                                        LR 0.000005    Time 0.106946    
2024-04-24 00:41:25,328 - Epoch: [524][  200/  296]    Overall Loss 0.673109    Objective Loss 0.673109                                        LR 0.000005    Time 0.094231    
2024-04-24 00:41:33,366 - Epoch: [524][  296/  296]    Overall Loss 0.668543    Objective Loss 0.668543    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.090796    
2024-04-24 00:41:33,550 - --- validate (epoch=524)-----------
2024-04-24 00:41:33,551 - 3925 samples (32 per mini-batch)
2024-04-24 00:41:44,525 - Epoch: [524][  100/  123]    Loss 0.675102    Top1 78.031250    Top5 97.687500    
2024-04-24 00:41:46,796 - Epoch: [524][  123/  123]    Loss 0.668539    Top1 78.471338    Top5 97.579618    
2024-04-24 00:41:46,980 - ==> Top1: 78.471    Top5: 97.580    Loss: 0.669

2024-04-24 00:41:46,989 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:41:46,990 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:41:47,024 - 

2024-04-24 00:41:47,024 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:41:54,794 - Epoch: [525][  100/  296]    Overall Loss 0.685752    Objective Loss 0.685752                                        LR 0.000005    Time 0.077591    
2024-04-24 00:42:00,740 - Epoch: [525][  200/  296]    Overall Loss 0.668409    Objective Loss 0.668409                                        LR 0.000005    Time 0.068471    
2024-04-24 00:42:06,477 - Epoch: [525][  296/  296]    Overall Loss 0.666514    Objective Loss 0.666514    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.065612    
2024-04-24 00:42:06,654 - --- validate (epoch=525)-----------
2024-04-24 00:42:06,655 - 3925 samples (32 per mini-batch)
2024-04-24 00:42:15,963 - Epoch: [525][  100/  123]    Loss 0.670840    Top1 78.093750    Top5 97.593750    
2024-04-24 00:42:18,478 - Epoch: [525][  123/  123]    Loss 0.672850    Top1 78.292994    Top5 97.554140    
2024-04-24 00:42:18,618 - ==> Top1: 78.293    Top5: 97.554    Loss: 0.673

2024-04-24 00:42:18,628 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:42:18,628 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:42:18,667 - 

2024-04-24 00:42:18,667 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:42:27,835 - Epoch: [526][  100/  296]    Overall Loss 0.653564    Objective Loss 0.653564                                        LR 0.000005    Time 0.091566    
2024-04-24 00:42:35,480 - Epoch: [526][  200/  296]    Overall Loss 0.667982    Objective Loss 0.667982                                        LR 0.000005    Time 0.083956    
2024-04-24 00:42:42,990 - Epoch: [526][  296/  296]    Overall Loss 0.669057    Objective Loss 0.669057    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.082072    
2024-04-24 00:42:43,113 - --- validate (epoch=526)-----------
2024-04-24 00:42:43,114 - 3925 samples (32 per mini-batch)
2024-04-24 00:42:53,831 - Epoch: [526][  100/  123]    Loss 0.674186    Top1 78.031250    Top5 97.437500    
2024-04-24 00:42:55,718 - Epoch: [526][  123/  123]    Loss 0.667519    Top1 78.242038    Top5 97.477707    
2024-04-24 00:42:56,109 - ==> Top1: 78.242    Top5: 97.478    Loss: 0.668

2024-04-24 00:42:56,115 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:42:56,115 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:42:56,147 - 

2024-04-24 00:42:56,147 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:43:06,787 - Epoch: [527][  100/  296]    Overall Loss 0.721096    Objective Loss 0.721096                                        LR 0.000005    Time 0.106299    
2024-04-24 00:43:15,826 - Epoch: [527][  200/  296]    Overall Loss 0.695079    Objective Loss 0.695079                                        LR 0.000005    Time 0.098296    
2024-04-24 00:43:22,739 - Epoch: [527][  296/  296]    Overall Loss 0.689589    Objective Loss 0.689589    Top1 83.606557    Top5 95.081967    LR 0.000005    Time 0.089740    
2024-04-24 00:43:22,904 - --- validate (epoch=527)-----------
2024-04-24 00:43:22,905 - 3925 samples (32 per mini-batch)
2024-04-24 00:43:33,123 - Epoch: [527][  100/  123]    Loss 0.670159    Top1 78.375000    Top5 97.281250    
2024-04-24 00:43:35,504 - Epoch: [527][  123/  123]    Loss 0.667365    Top1 78.343949    Top5 97.350318    
2024-04-24 00:43:35,636 - ==> Top1: 78.344    Top5: 97.350    Loss: 0.667

2024-04-24 00:43:35,645 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:43:35,646 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:43:35,682 - 

2024-04-24 00:43:35,682 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:43:46,486 - Epoch: [528][  100/  296]    Overall Loss 0.655263    Objective Loss 0.655263                                        LR 0.000005    Time 0.107929    
2024-04-24 00:43:55,621 - Epoch: [528][  200/  296]    Overall Loss 0.655593    Objective Loss 0.655593                                        LR 0.000005    Time 0.099587    
2024-04-24 00:44:04,413 - Epoch: [528][  296/  296]    Overall Loss 0.666569    Objective Loss 0.666569    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.096959    
2024-04-24 00:44:04,575 - --- validate (epoch=528)-----------
2024-04-24 00:44:04,576 - 3925 samples (32 per mini-batch)
2024-04-24 00:44:15,574 - Epoch: [528][  100/  123]    Loss 0.674743    Top1 78.718750    Top5 97.500000    
2024-04-24 00:44:17,670 - Epoch: [528][  123/  123]    Loss 0.669386    Top1 78.649682    Top5 97.630573    
2024-04-24 00:44:17,838 - ==> Top1: 78.650    Top5: 97.631    Loss: 0.669

2024-04-24 00:44:17,848 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:44:17,849 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:44:17,888 - 

2024-04-24 00:44:17,888 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:44:28,352 - Epoch: [529][  100/  296]    Overall Loss 0.699222    Objective Loss 0.699222                                        LR 0.000005    Time 0.104515    
2024-04-24 00:44:37,304 - Epoch: [529][  200/  296]    Overall Loss 0.694438    Objective Loss 0.694438                                        LR 0.000005    Time 0.096962    
2024-04-24 00:44:45,145 - Epoch: [529][  296/  296]    Overall Loss 0.688576    Objective Loss 0.688576    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.091971    
2024-04-24 00:44:45,349 - --- validate (epoch=529)-----------
2024-04-24 00:44:45,350 - 3925 samples (32 per mini-batch)
2024-04-24 00:44:55,549 - Epoch: [529][  100/  123]    Loss 0.665348    Top1 78.687500    Top5 97.531250    
2024-04-24 00:44:57,467 - Epoch: [529][  123/  123]    Loss 0.667950    Top1 78.547771    Top5 97.579618    
2024-04-24 00:44:57,576 - ==> Top1: 78.548    Top5: 97.580    Loss: 0.668

2024-04-24 00:44:57,581 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:44:57,581 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:44:57,611 - 

2024-04-24 00:44:57,611 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:45:06,036 - Epoch: [530][  100/  296]    Overall Loss 0.670057    Objective Loss 0.670057                                        LR 0.000005    Time 0.084151    
2024-04-24 00:45:12,746 - Epoch: [530][  200/  296]    Overall Loss 0.666934    Objective Loss 0.666934                                        LR 0.000005    Time 0.075576    
2024-04-24 00:45:18,100 - Epoch: [530][  296/  296]    Overall Loss 0.671208    Objective Loss 0.671208    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.069119    
2024-04-24 00:45:18,222 - --- validate (epoch=530)-----------
2024-04-24 00:45:18,223 - 3925 samples (32 per mini-batch)
2024-04-24 00:45:27,479 - Epoch: [530][  100/  123]    Loss 0.659300    Top1 79.000000    Top5 97.531250    
2024-04-24 00:45:29,248 - Epoch: [530][  123/  123]    Loss 0.669756    Top1 78.649682    Top5 97.477707    
2024-04-24 00:45:29,372 - ==> Top1: 78.650    Top5: 97.478    Loss: 0.670

2024-04-24 00:45:29,380 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:45:29,381 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:45:29,416 - 

2024-04-24 00:45:29,417 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:45:40,195 - Epoch: [531][  100/  296]    Overall Loss 0.677162    Objective Loss 0.677162                                        LR 0.000005    Time 0.107678    
2024-04-24 00:45:49,171 - Epoch: [531][  200/  296]    Overall Loss 0.670918    Objective Loss 0.670918                                        LR 0.000005    Time 0.098675    
2024-04-24 00:45:58,035 - Epoch: [531][  296/  296]    Overall Loss 0.672288    Objective Loss 0.672288    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.096586    
2024-04-24 00:45:58,139 - --- validate (epoch=531)-----------
2024-04-24 00:45:58,139 - 3925 samples (32 per mini-batch)
2024-04-24 00:46:07,015 - Epoch: [531][  100/  123]    Loss 0.685331    Top1 77.875000    Top5 97.531250    
2024-04-24 00:46:08,667 - Epoch: [531][  123/  123]    Loss 0.667503    Top1 78.394904    Top5 97.503185    
2024-04-24 00:46:08,767 - ==> Top1: 78.395    Top5: 97.503    Loss: 0.668

2024-04-24 00:46:08,775 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:46:08,775 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:46:08,810 - 

2024-04-24 00:46:08,810 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:46:17,619 - Epoch: [532][  100/  296]    Overall Loss 0.675412    Objective Loss 0.675412                                        LR 0.000005    Time 0.088012    
2024-04-24 00:46:25,019 - Epoch: [532][  200/  296]    Overall Loss 0.669389    Objective Loss 0.669389                                        LR 0.000005    Time 0.080970    
2024-04-24 00:46:30,035 - Epoch: [532][  296/  296]    Overall Loss 0.673238    Objective Loss 0.673238    Top1 88.524590    Top5 100.000000    LR 0.000005    Time 0.071633    
2024-04-24 00:46:30,157 - --- validate (epoch=532)-----------
2024-04-24 00:46:30,157 - 3925 samples (32 per mini-batch)
2024-04-24 00:46:38,527 - Epoch: [532][  100/  123]    Loss 0.667104    Top1 78.343750    Top5 97.312500    
2024-04-24 00:46:40,494 - Epoch: [532][  123/  123]    Loss 0.670298    Top1 78.394904    Top5 97.401274    
2024-04-24 00:46:40,610 - ==> Top1: 78.395    Top5: 97.401    Loss: 0.670

2024-04-24 00:46:40,619 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:46:40,619 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:46:40,654 - 

2024-04-24 00:46:40,654 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:46:46,862 - Epoch: [533][  100/  296]    Overall Loss 0.665316    Objective Loss 0.665316                                        LR 0.000005    Time 0.062006    
2024-04-24 00:46:52,097 - Epoch: [533][  200/  296]    Overall Loss 0.670184    Objective Loss 0.670184                                        LR 0.000005    Time 0.057141    
2024-04-24 00:46:57,237 - Epoch: [533][  296/  296]    Overall Loss 0.669895    Objective Loss 0.669895    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.055950    
2024-04-24 00:46:57,345 - --- validate (epoch=533)-----------
2024-04-24 00:46:57,345 - 3925 samples (32 per mini-batch)
2024-04-24 00:47:05,053 - Epoch: [533][  100/  123]    Loss 0.686772    Top1 77.593750    Top5 97.187500    
2024-04-24 00:47:07,025 - Epoch: [533][  123/  123]    Loss 0.672498    Top1 78.165605    Top5 97.426752    
2024-04-24 00:47:07,141 - ==> Top1: 78.166    Top5: 97.427    Loss: 0.672

2024-04-24 00:47:07,149 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:47:07,150 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:47:07,184 - 

2024-04-24 00:47:07,184 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:47:13,784 - Epoch: [534][  100/  296]    Overall Loss 0.690129    Objective Loss 0.690129                                        LR 0.000005    Time 0.065927    
2024-04-24 00:47:19,601 - Epoch: [534][  200/  296]    Overall Loss 0.676866    Objective Loss 0.676866                                        LR 0.000005    Time 0.062014    
2024-04-24 00:47:25,319 - Epoch: [534][  296/  296]    Overall Loss 0.678401    Objective Loss 0.678401    Top1 70.491803    Top5 95.081967    LR 0.000005    Time 0.061201    
2024-04-24 00:47:25,427 - --- validate (epoch=534)-----------
2024-04-24 00:47:25,427 - 3925 samples (32 per mini-batch)
2024-04-24 00:47:33,464 - Epoch: [534][  100/  123]    Loss 0.666138    Top1 78.562500    Top5 97.468750    
2024-04-24 00:47:34,917 - Epoch: [534][  123/  123]    Loss 0.668803    Top1 78.394904    Top5 97.528662    
2024-04-24 00:47:35,009 - ==> Top1: 78.395    Top5: 97.529    Loss: 0.669

2024-04-24 00:47:35,017 - ==> Best [Top1: 78.701   Top5: 97.376   Sparsity:0.00   Params: 371568 on epoch: 289]
2024-04-24 00:47:35,017 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:47:35,050 - 

2024-04-24 00:47:35,051 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:47:41,890 - Epoch: [535][  100/  296]    Overall Loss 0.676126    Objective Loss 0.676126                                        LR 0.000005    Time 0.068331    
2024-04-24 00:47:50,052 - Epoch: [535][  200/  296]    Overall Loss 0.660799    Objective Loss 0.660799                                        LR 0.000005    Time 0.074938    
2024-04-24 00:47:56,625 - Epoch: [535][  296/  296]    Overall Loss 0.664827    Objective Loss 0.664827    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.072818    
2024-04-24 00:47:56,767 - --- validate (epoch=535)-----------
2024-04-24 00:47:56,769 - 3925 samples (32 per mini-batch)
2024-04-24 00:48:04,924 - Epoch: [535][  100/  123]    Loss 0.670505    Top1 78.656250    Top5 97.593750    
2024-04-24 00:48:06,658 - Epoch: [535][  123/  123]    Loss 0.664683    Top1 78.802548    Top5 97.630573    
2024-04-24 00:48:06,783 - ==> Top1: 78.803    Top5: 97.631    Loss: 0.665

2024-04-24 00:48:06,792 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:48:06,793 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:48:06,842 - 

2024-04-24 00:48:06,843 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:48:13,727 - Epoch: [536][  100/  296]    Overall Loss 0.674637    Objective Loss 0.674637                                        LR 0.000005    Time 0.068778    
2024-04-24 00:48:18,945 - Epoch: [536][  200/  296]    Overall Loss 0.672129    Objective Loss 0.672129                                        LR 0.000005    Time 0.060443    
2024-04-24 00:48:23,865 - Epoch: [536][  296/  296]    Overall Loss 0.665962    Objective Loss 0.665962    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.057437    
2024-04-24 00:48:23,972 - --- validate (epoch=536)-----------
2024-04-24 00:48:23,973 - 3925 samples (32 per mini-batch)
2024-04-24 00:48:33,174 - Epoch: [536][  100/  123]    Loss 0.661695    Top1 78.906250    Top5 97.312500    
2024-04-24 00:48:34,943 - Epoch: [536][  123/  123]    Loss 0.668049    Top1 78.547771    Top5 97.299363    
2024-04-24 00:48:35,035 - ==> Top1: 78.548    Top5: 97.299    Loss: 0.668

2024-04-24 00:48:35,044 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:48:35,044 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:48:35,079 - 

2024-04-24 00:48:35,079 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:48:41,646 - Epoch: [537][  100/  296]    Overall Loss 0.663717    Objective Loss 0.663717                                        LR 0.000005    Time 0.065603    
2024-04-24 00:48:47,312 - Epoch: [537][  200/  296]    Overall Loss 0.676303    Objective Loss 0.676303                                        LR 0.000005    Time 0.061096    
2024-04-24 00:48:54,374 - Epoch: [537][  296/  296]    Overall Loss 0.678112    Objective Loss 0.678112    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.065113    
2024-04-24 00:48:54,481 - --- validate (epoch=537)-----------
2024-04-24 00:48:54,481 - 3925 samples (32 per mini-batch)
2024-04-24 00:49:02,901 - Epoch: [537][  100/  123]    Loss 0.672015    Top1 78.281250    Top5 97.375000    
2024-04-24 00:49:04,542 - Epoch: [537][  123/  123]    Loss 0.669422    Top1 78.547771    Top5 97.401274    
2024-04-24 00:49:04,634 - ==> Top1: 78.548    Top5: 97.401    Loss: 0.669

2024-04-24 00:49:04,647 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:49:04,648 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:49:04,683 - 

2024-04-24 00:49:04,684 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:49:12,378 - Epoch: [538][  100/  296]    Overall Loss 0.650749    Objective Loss 0.650749                                        LR 0.000005    Time 0.076872    
2024-04-24 00:49:19,225 - Epoch: [538][  200/  296]    Overall Loss 0.665305    Objective Loss 0.665305                                        LR 0.000005    Time 0.072634    
2024-04-24 00:49:25,327 - Epoch: [538][  296/  296]    Overall Loss 0.671365    Objective Loss 0.671365    Top1 70.491803    Top5 98.360656    LR 0.000005    Time 0.069671    
2024-04-24 00:49:25,451 - --- validate (epoch=538)-----------
2024-04-24 00:49:25,452 - 3925 samples (32 per mini-batch)
2024-04-24 00:49:35,042 - Epoch: [538][  100/  123]    Loss 0.665589    Top1 78.562500    Top5 97.437500    
2024-04-24 00:49:36,729 - Epoch: [538][  123/  123]    Loss 0.669029    Top1 78.420382    Top5 97.401274    
2024-04-24 00:49:36,887 - ==> Top1: 78.420    Top5: 97.401    Loss: 0.669

2024-04-24 00:49:36,896 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:49:36,896 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:49:36,932 - 

2024-04-24 00:49:36,932 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:49:44,675 - Epoch: [539][  100/  296]    Overall Loss 0.690618    Objective Loss 0.690618                                        LR 0.000005    Time 0.077358    
2024-04-24 00:49:51,043 - Epoch: [539][  200/  296]    Overall Loss 0.672248    Objective Loss 0.672248                                        LR 0.000005    Time 0.070482    
2024-04-24 00:49:59,154 - Epoch: [539][  296/  296]    Overall Loss 0.664014    Objective Loss 0.664014    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.075002    
2024-04-24 00:49:59,265 - --- validate (epoch=539)-----------
2024-04-24 00:49:59,266 - 3925 samples (32 per mini-batch)
2024-04-24 00:50:09,586 - Epoch: [539][  100/  123]    Loss 0.669821    Top1 78.468750    Top5 97.281250    
2024-04-24 00:50:11,799 - Epoch: [539][  123/  123]    Loss 0.669387    Top1 78.394904    Top5 97.426752    
2024-04-24 00:50:11,883 - ==> Top1: 78.395    Top5: 97.427    Loss: 0.669

2024-04-24 00:50:11,892 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:50:11,893 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:50:11,931 - 

2024-04-24 00:50:11,932 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:50:21,961 - Epoch: [540][  100/  296]    Overall Loss 0.673501    Objective Loss 0.673501                                        LR 0.000005    Time 0.100220    
2024-04-24 00:50:29,613 - Epoch: [540][  200/  296]    Overall Loss 0.684283    Objective Loss 0.684283                                        LR 0.000005    Time 0.088332    
2024-04-24 00:50:36,329 - Epoch: [540][  296/  296]    Overall Loss 0.678214    Objective Loss 0.678214    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.082353    
2024-04-24 00:50:36,446 - --- validate (epoch=540)-----------
2024-04-24 00:50:36,447 - 3925 samples (32 per mini-batch)
2024-04-24 00:50:45,872 - Epoch: [540][  100/  123]    Loss 0.676259    Top1 78.000000    Top5 97.562500    
2024-04-24 00:50:48,333 - Epoch: [540][  123/  123]    Loss 0.667039    Top1 78.445860    Top5 97.528662    
2024-04-24 00:50:48,464 - ==> Top1: 78.446    Top5: 97.529    Loss: 0.667

2024-04-24 00:50:48,474 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:50:48,474 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:50:48,513 - 

2024-04-24 00:50:48,513 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:50:58,783 - Epoch: [541][  100/  296]    Overall Loss 0.674907    Objective Loss 0.674907                                        LR 0.000005    Time 0.102625    
2024-04-24 00:51:06,310 - Epoch: [541][  200/  296]    Overall Loss 0.675546    Objective Loss 0.675546                                        LR 0.000005    Time 0.088906    
2024-04-24 00:51:12,587 - Epoch: [541][  296/  296]    Overall Loss 0.685112    Objective Loss 0.685112    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.081256    
2024-04-24 00:51:12,744 - --- validate (epoch=541)-----------
2024-04-24 00:51:12,745 - 3925 samples (32 per mini-batch)
2024-04-24 00:51:21,628 - Epoch: [541][  100/  123]    Loss 0.673564    Top1 78.218750    Top5 97.250000    
2024-04-24 00:51:23,574 - Epoch: [541][  123/  123]    Loss 0.673610    Top1 78.242038    Top5 97.273885    
2024-04-24 00:51:23,752 - ==> Top1: 78.242    Top5: 97.274    Loss: 0.674

2024-04-24 00:51:23,761 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:51:23,761 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:51:23,795 - 

2024-04-24 00:51:23,795 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:51:31,214 - Epoch: [542][  100/  296]    Overall Loss 0.687342    Objective Loss 0.687342                                        LR 0.000005    Time 0.074120    
2024-04-24 00:51:36,805 - Epoch: [542][  200/  296]    Overall Loss 0.673982    Objective Loss 0.673982                                        LR 0.000005    Time 0.064979    
2024-04-24 00:51:42,236 - Epoch: [542][  296/  296]    Overall Loss 0.679795    Objective Loss 0.679795    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.062230    
2024-04-24 00:51:42,387 - --- validate (epoch=542)-----------
2024-04-24 00:51:42,388 - 3925 samples (32 per mini-batch)
2024-04-24 00:51:50,782 - Epoch: [542][  100/  123]    Loss 0.679946    Top1 78.000000    Top5 97.437500    
2024-04-24 00:51:52,458 - Epoch: [542][  123/  123]    Loss 0.668959    Top1 78.343949    Top5 97.579618    
2024-04-24 00:51:52,556 - ==> Top1: 78.344    Top5: 97.580    Loss: 0.669

2024-04-24 00:51:52,562 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:51:52,562 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:51:52,594 - 

2024-04-24 00:51:52,594 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:51:59,703 - Epoch: [543][  100/  296]    Overall Loss 0.664144    Objective Loss 0.664144                                        LR 0.000005    Time 0.071024    
2024-04-24 00:52:06,947 - Epoch: [543][  200/  296]    Overall Loss 0.661758    Objective Loss 0.661758                                        LR 0.000005    Time 0.071698    
2024-04-24 00:52:13,691 - Epoch: [543][  296/  296]    Overall Loss 0.659722    Objective Loss 0.659722    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.071205    
2024-04-24 00:52:13,802 - --- validate (epoch=543)-----------
2024-04-24 00:52:13,803 - 3925 samples (32 per mini-batch)
2024-04-24 00:52:24,305 - Epoch: [543][  100/  123]    Loss 0.667923    Top1 78.218750    Top5 97.437500    
2024-04-24 00:52:26,143 - Epoch: [543][  123/  123]    Loss 0.668664    Top1 78.318471    Top5 97.401274    
2024-04-24 00:52:26,274 - ==> Top1: 78.318    Top5: 97.401    Loss: 0.669

2024-04-24 00:52:26,283 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:52:26,283 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:52:26,319 - 

2024-04-24 00:52:26,320 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:52:35,010 - Epoch: [544][  100/  296]    Overall Loss 0.666916    Objective Loss 0.666916                                        LR 0.000005    Time 0.086825    
2024-04-24 00:52:41,703 - Epoch: [544][  200/  296]    Overall Loss 0.675669    Objective Loss 0.675669                                        LR 0.000005    Time 0.076850    
2024-04-24 00:52:47,662 - Epoch: [544][  296/  296]    Overall Loss 0.668496    Objective Loss 0.668496    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.072040    
2024-04-24 00:52:47,777 - --- validate (epoch=544)-----------
2024-04-24 00:52:47,778 - 3925 samples (32 per mini-batch)
2024-04-24 00:52:55,656 - Epoch: [544][  100/  123]    Loss 0.663563    Top1 78.187500    Top5 97.562500    
2024-04-24 00:52:57,397 - Epoch: [544][  123/  123]    Loss 0.668320    Top1 78.165605    Top5 97.579618    
2024-04-24 00:52:57,512 - ==> Top1: 78.166    Top5: 97.580    Loss: 0.668

2024-04-24 00:52:57,523 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:52:57,523 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:52:57,558 - 

2024-04-24 00:52:57,558 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:53:03,968 - Epoch: [545][  100/  296]    Overall Loss 0.671252    Objective Loss 0.671252                                        LR 0.000005    Time 0.064029    
2024-04-24 00:53:09,930 - Epoch: [545][  200/  296]    Overall Loss 0.682676    Objective Loss 0.682676                                        LR 0.000005    Time 0.061791    
2024-04-24 00:53:14,534 - Epoch: [545][  296/  296]    Overall Loss 0.669038    Objective Loss 0.669038    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.057283    
2024-04-24 00:53:14,627 - --- validate (epoch=545)-----------
2024-04-24 00:53:14,628 - 3925 samples (32 per mini-batch)
2024-04-24 00:53:24,178 - Epoch: [545][  100/  123]    Loss 0.665327    Top1 78.406250    Top5 97.562500    
2024-04-24 00:53:26,295 - Epoch: [545][  123/  123]    Loss 0.667180    Top1 78.292994    Top5 97.630573    
2024-04-24 00:53:26,397 - ==> Top1: 78.293    Top5: 97.631    Loss: 0.667

2024-04-24 00:53:26,406 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:53:26,406 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:53:26,441 - 

2024-04-24 00:53:26,441 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:53:32,957 - Epoch: [546][  100/  296]    Overall Loss 0.686595    Objective Loss 0.686595                                        LR 0.000005    Time 0.065084    
2024-04-24 00:53:38,152 - Epoch: [546][  200/  296]    Overall Loss 0.680320    Objective Loss 0.680320                                        LR 0.000005    Time 0.058484    
2024-04-24 00:53:42,698 - Epoch: [546][  296/  296]    Overall Loss 0.677113    Objective Loss 0.677113    Top1 88.524590    Top5 100.000000    LR 0.000005    Time 0.054850    
2024-04-24 00:53:42,779 - --- validate (epoch=546)-----------
2024-04-24 00:53:42,780 - 3925 samples (32 per mini-batch)
2024-04-24 00:53:50,418 - Epoch: [546][  100/  123]    Loss 0.671777    Top1 78.125000    Top5 97.343750    
2024-04-24 00:53:51,934 - Epoch: [546][  123/  123]    Loss 0.668822    Top1 78.496815    Top5 97.350318    
2024-04-24 00:53:52,024 - ==> Top1: 78.497    Top5: 97.350    Loss: 0.669

2024-04-24 00:53:52,033 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:53:52,033 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:53:52,078 - 

2024-04-24 00:53:52,078 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:53:59,916 - Epoch: [547][  100/  296]    Overall Loss 0.686655    Objective Loss 0.686655                                        LR 0.000005    Time 0.078312    
2024-04-24 00:54:06,267 - Epoch: [547][  200/  296]    Overall Loss 0.686510    Objective Loss 0.686510                                        LR 0.000005    Time 0.070879    
2024-04-24 00:54:12,742 - Epoch: [547][  296/  296]    Overall Loss 0.685865    Objective Loss 0.685865    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.069741    
2024-04-24 00:54:12,870 - --- validate (epoch=547)-----------
2024-04-24 00:54:12,870 - 3925 samples (32 per mini-batch)
2024-04-24 00:54:23,588 - Epoch: [547][  100/  123]    Loss 0.666591    Top1 78.250000    Top5 97.406250    
2024-04-24 00:54:25,829 - Epoch: [547][  123/  123]    Loss 0.669834    Top1 78.165605    Top5 97.528662    
2024-04-24 00:54:25,925 - ==> Top1: 78.166    Top5: 97.529    Loss: 0.670

2024-04-24 00:54:25,934 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:54:25,934 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:54:25,969 - 

2024-04-24 00:54:25,969 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:54:35,271 - Epoch: [548][  100/  296]    Overall Loss 0.724920    Objective Loss 0.724920                                        LR 0.000005    Time 0.092932    
2024-04-24 00:54:42,625 - Epoch: [548][  200/  296]    Overall Loss 0.680392    Objective Loss 0.680392                                        LR 0.000005    Time 0.083200    
2024-04-24 00:54:49,465 - Epoch: [548][  296/  296]    Overall Loss 0.674836    Objective Loss 0.674836    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.079301    
2024-04-24 00:54:49,554 - --- validate (epoch=548)-----------
2024-04-24 00:54:49,555 - 3925 samples (32 per mini-batch)
2024-04-24 00:54:58,523 - Epoch: [548][  100/  123]    Loss 0.653340    Top1 78.906250    Top5 97.562500    
2024-04-24 00:55:00,428 - Epoch: [548][  123/  123]    Loss 0.667729    Top1 78.318471    Top5 97.452229    
2024-04-24 00:55:00,496 - ==> Top1: 78.318    Top5: 97.452    Loss: 0.668

2024-04-24 00:55:00,499 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:55:00,499 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:55:00,524 - 

2024-04-24 00:55:00,525 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:55:08,160 - Epoch: [549][  100/  296]    Overall Loss 0.665234    Objective Loss 0.665234                                        LR 0.000005    Time 0.076278    
2024-04-24 00:55:14,361 - Epoch: [549][  200/  296]    Overall Loss 0.658893    Objective Loss 0.658893                                        LR 0.000005    Time 0.069108    
2024-04-24 00:55:21,002 - Epoch: [549][  296/  296]    Overall Loss 0.669326    Objective Loss 0.669326    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.069110    
2024-04-24 00:55:21,118 - --- validate (epoch=549)-----------
2024-04-24 00:55:21,119 - 3925 samples (32 per mini-batch)
2024-04-24 00:55:29,864 - Epoch: [549][  100/  123]    Loss 0.670908    Top1 79.000000    Top5 97.187500    
2024-04-24 00:55:31,313 - Epoch: [549][  123/  123]    Loss 0.668161    Top1 78.726115    Top5 97.401274    
2024-04-24 00:55:31,411 - ==> Top1: 78.726    Top5: 97.401    Loss: 0.668

2024-04-24 00:55:31,419 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:55:31,420 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:55:31,456 - 

2024-04-24 00:55:31,456 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:55:37,608 - Epoch: [550][  100/  296]    Overall Loss 0.661912    Objective Loss 0.661912                                        LR 0.000005    Time 0.061434    
2024-04-24 00:55:43,344 - Epoch: [550][  200/  296]    Overall Loss 0.670661    Objective Loss 0.670661                                        LR 0.000005    Time 0.059367    
2024-04-24 00:55:48,958 - Epoch: [550][  296/  296]    Overall Loss 0.667922    Objective Loss 0.667922    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.059056    
2024-04-24 00:55:49,054 - --- validate (epoch=550)-----------
2024-04-24 00:55:49,055 - 3925 samples (32 per mini-batch)
2024-04-24 00:55:59,193 - Epoch: [550][  100/  123]    Loss 0.674987    Top1 78.437500    Top5 97.437500    
2024-04-24 00:56:01,128 - Epoch: [550][  123/  123]    Loss 0.670559    Top1 78.547771    Top5 97.426752    
2024-04-24 00:56:01,240 - ==> Top1: 78.548    Top5: 97.427    Loss: 0.671

2024-04-24 00:56:01,248 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:56:01,249 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:56:01,284 - 

2024-04-24 00:56:01,284 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:56:09,391 - Epoch: [551][  100/  296]    Overall Loss 0.681959    Objective Loss 0.681959                                        LR 0.000005    Time 0.080984    
2024-04-24 00:56:15,491 - Epoch: [551][  200/  296]    Overall Loss 0.669849    Objective Loss 0.669849                                        LR 0.000005    Time 0.070959    
2024-04-24 00:56:22,515 - Epoch: [551][  296/  296]    Overall Loss 0.676818    Objective Loss 0.676818    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.071648    
2024-04-24 00:56:22,616 - --- validate (epoch=551)-----------
2024-04-24 00:56:22,617 - 3925 samples (32 per mini-batch)
2024-04-24 00:56:33,281 - Epoch: [551][  100/  123]    Loss 0.671761    Top1 78.187500    Top5 97.375000    
2024-04-24 00:56:35,699 - Epoch: [551][  123/  123]    Loss 0.667906    Top1 78.267516    Top5 97.401274    
2024-04-24 00:56:35,790 - ==> Top1: 78.268    Top5: 97.401    Loss: 0.668

2024-04-24 00:56:35,799 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:56:35,799 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:56:35,834 - 

2024-04-24 00:56:35,834 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:56:44,663 - Epoch: [552][  100/  296]    Overall Loss 0.664095    Objective Loss 0.664095                                        LR 0.000005    Time 0.088202    
2024-04-24 00:56:51,677 - Epoch: [552][  200/  296]    Overall Loss 0.656165    Objective Loss 0.656165                                        LR 0.000005    Time 0.079136    
2024-04-24 00:56:58,688 - Epoch: [552][  296/  296]    Overall Loss 0.672339    Objective Loss 0.672339    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.077135    
2024-04-24 00:56:58,776 - --- validate (epoch=552)-----------
2024-04-24 00:56:58,777 - 3925 samples (32 per mini-batch)
2024-04-24 00:57:08,223 - Epoch: [552][  100/  123]    Loss 0.667859    Top1 78.343750    Top5 97.500000    
2024-04-24 00:57:09,786 - Epoch: [552][  123/  123]    Loss 0.674915    Top1 78.063694    Top5 97.503185    
2024-04-24 00:57:09,881 - ==> Top1: 78.064    Top5: 97.503    Loss: 0.675

2024-04-24 00:57:09,890 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:57:09,890 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:57:09,926 - 

2024-04-24 00:57:09,926 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:57:20,003 - Epoch: [553][  100/  296]    Overall Loss 0.678378    Objective Loss 0.678378                                        LR 0.000005    Time 0.100671    
2024-04-24 00:57:27,236 - Epoch: [553][  200/  296]    Overall Loss 0.680019    Objective Loss 0.680019                                        LR 0.000005    Time 0.086455    
2024-04-24 00:57:34,626 - Epoch: [553][  296/  296]    Overall Loss 0.678190    Objective Loss 0.678190    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.083361    
2024-04-24 00:57:34,864 - --- validate (epoch=553)-----------
2024-04-24 00:57:34,864 - 3925 samples (32 per mini-batch)
2024-04-24 00:57:43,801 - Epoch: [553][  100/  123]    Loss 0.675988    Top1 77.812500    Top5 97.406250    
2024-04-24 00:57:45,589 - Epoch: [553][  123/  123]    Loss 0.669584    Top1 78.420382    Top5 97.375796    
2024-04-24 00:57:45,706 - ==> Top1: 78.420    Top5: 97.376    Loss: 0.670

2024-04-24 00:57:45,715 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:57:45,716 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:57:45,753 - 

2024-04-24 00:57:45,754 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:57:54,425 - Epoch: [554][  100/  296]    Overall Loss 0.625322    Objective Loss 0.625322                                        LR 0.000005    Time 0.086651    
2024-04-24 00:58:01,076 - Epoch: [554][  200/  296]    Overall Loss 0.657536    Objective Loss 0.657536                                        LR 0.000005    Time 0.076550    
2024-04-24 00:58:06,800 - Epoch: [554][  296/  296]    Overall Loss 0.661343    Objective Loss 0.661343    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.071037    
2024-04-24 00:58:06,922 - --- validate (epoch=554)-----------
2024-04-24 00:58:06,923 - 3925 samples (32 per mini-batch)
2024-04-24 00:58:17,249 - Epoch: [554][  100/  123]    Loss 0.668383    Top1 77.937500    Top5 97.656250    
2024-04-24 00:58:19,121 - Epoch: [554][  123/  123]    Loss 0.668666    Top1 78.114650    Top5 97.503185    
2024-04-24 00:58:19,215 - ==> Top1: 78.115    Top5: 97.503    Loss: 0.669

2024-04-24 00:58:19,223 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:58:19,224 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:58:19,260 - 

2024-04-24 00:58:19,260 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:58:27,789 - Epoch: [555][  100/  296]    Overall Loss 0.684857    Objective Loss 0.684857                                        LR 0.000005    Time 0.085212    
2024-04-24 00:58:35,169 - Epoch: [555][  200/  296]    Overall Loss 0.676739    Objective Loss 0.676739                                        LR 0.000005    Time 0.079470    
2024-04-24 00:58:41,423 - Epoch: [555][  296/  296]    Overall Loss 0.671212    Objective Loss 0.671212    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.074806    
2024-04-24 00:58:41,552 - --- validate (epoch=555)-----------
2024-04-24 00:58:41,553 - 3925 samples (32 per mini-batch)
2024-04-24 00:58:52,066 - Epoch: [555][  100/  123]    Loss 0.679658    Top1 78.062500    Top5 97.218750    
2024-04-24 00:58:53,906 - Epoch: [555][  123/  123]    Loss 0.669045    Top1 78.343949    Top5 97.350318    
2024-04-24 00:58:53,992 - ==> Top1: 78.344    Top5: 97.350    Loss: 0.669

2024-04-24 00:58:54,001 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:58:54,001 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:58:54,035 - 

2024-04-24 00:58:54,035 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:59:01,881 - Epoch: [556][  100/  296]    Overall Loss 0.677350    Objective Loss 0.677350                                        LR 0.000005    Time 0.078399    
2024-04-24 00:59:09,585 - Epoch: [556][  200/  296]    Overall Loss 0.689269    Objective Loss 0.689269                                        LR 0.000005    Time 0.077682    
2024-04-24 00:59:16,689 - Epoch: [556][  296/  296]    Overall Loss 0.677558    Objective Loss 0.677558    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.076468    
2024-04-24 00:59:16,780 - --- validate (epoch=556)-----------
2024-04-24 00:59:16,780 - 3925 samples (32 per mini-batch)
2024-04-24 00:59:25,899 - Epoch: [556][  100/  123]    Loss 0.673260    Top1 77.875000    Top5 97.468750    
2024-04-24 00:59:27,532 - Epoch: [556][  123/  123]    Loss 0.668283    Top1 77.961783    Top5 97.579618    
2024-04-24 00:59:27,666 - ==> Top1: 77.962    Top5: 97.580    Loss: 0.668

2024-04-24 00:59:27,674 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:59:27,674 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:59:27,708 - 

2024-04-24 00:59:27,708 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:59:35,283 - Epoch: [557][  100/  296]    Overall Loss 0.671933    Objective Loss 0.671933                                        LR 0.000005    Time 0.075671    
2024-04-24 00:59:40,802 - Epoch: [557][  200/  296]    Overall Loss 0.675282    Objective Loss 0.675282                                        LR 0.000005    Time 0.065399    
2024-04-24 00:59:48,244 - Epoch: [557][  296/  296]    Overall Loss 0.672355    Objective Loss 0.672355    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.069311    
2024-04-24 00:59:48,338 - --- validate (epoch=557)-----------
2024-04-24 00:59:48,339 - 3925 samples (32 per mini-batch)
2024-04-24 00:59:56,265 - Epoch: [557][  100/  123]    Loss 0.666435    Top1 78.343750    Top5 97.500000    
2024-04-24 00:59:57,991 - Epoch: [557][  123/  123]    Loss 0.667374    Top1 78.369427    Top5 97.401274    
2024-04-24 00:59:58,110 - ==> Top1: 78.369    Top5: 97.401    Loss: 0.667

2024-04-24 00:59:58,119 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 00:59:58,119 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 00:59:58,157 - 

2024-04-24 00:59:58,157 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:00:04,613 - Epoch: [558][  100/  296]    Overall Loss 0.636782    Objective Loss 0.636782                                        LR 0.000005    Time 0.064475    
2024-04-24 01:00:10,267 - Epoch: [558][  200/  296]    Overall Loss 0.651306    Objective Loss 0.651306                                        LR 0.000005    Time 0.060470    
2024-04-24 01:00:15,063 - Epoch: [558][  296/  296]    Overall Loss 0.657006    Objective Loss 0.657006    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.057040    
2024-04-24 01:00:15,195 - --- validate (epoch=558)-----------
2024-04-24 01:00:15,195 - 3925 samples (32 per mini-batch)
2024-04-24 01:00:23,815 - Epoch: [558][  100/  123]    Loss 0.669168    Top1 78.218750    Top5 97.406250    
2024-04-24 01:00:25,687 - Epoch: [558][  123/  123]    Loss 0.668594    Top1 78.343949    Top5 97.324841    
2024-04-24 01:00:25,786 - ==> Top1: 78.344    Top5: 97.325    Loss: 0.669

2024-04-24 01:00:25,794 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 01:00:25,795 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:00:25,830 - 

2024-04-24 01:00:25,830 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:00:34,254 - Epoch: [559][  100/  296]    Overall Loss 0.660899    Objective Loss 0.660899                                        LR 0.000005    Time 0.084161    
2024-04-24 01:00:41,201 - Epoch: [559][  200/  296]    Overall Loss 0.648584    Objective Loss 0.648584                                        LR 0.000005    Time 0.076788    
2024-04-24 01:00:46,771 - Epoch: [559][  296/  296]    Overall Loss 0.654420    Objective Loss 0.654420    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.070677    
2024-04-24 01:00:46,913 - --- validate (epoch=559)-----------
2024-04-24 01:00:46,913 - 3925 samples (32 per mini-batch)
2024-04-24 01:00:55,913 - Epoch: [559][  100/  123]    Loss 0.664127    Top1 79.000000    Top5 97.468750    
2024-04-24 01:00:57,521 - Epoch: [559][  123/  123]    Loss 0.667774    Top1 78.598726    Top5 97.350318    
2024-04-24 01:00:57,618 - ==> Top1: 78.599    Top5: 97.350    Loss: 0.668

2024-04-24 01:00:57,627 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 01:00:57,628 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:00:57,666 - 

2024-04-24 01:00:57,667 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:01:05,620 - Epoch: [560][  100/  296]    Overall Loss 0.626352    Objective Loss 0.626352                                        LR 0.000005    Time 0.079460    
2024-04-24 01:01:12,562 - Epoch: [560][  200/  296]    Overall Loss 0.653370    Objective Loss 0.653370                                        LR 0.000005    Time 0.074401    
2024-04-24 01:01:18,879 - Epoch: [560][  296/  296]    Overall Loss 0.660799    Objective Loss 0.660799    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.071589    
2024-04-24 01:01:18,991 - --- validate (epoch=560)-----------
2024-04-24 01:01:18,992 - 3925 samples (32 per mini-batch)
2024-04-24 01:01:27,441 - Epoch: [560][  100/  123]    Loss 0.668929    Top1 78.562500    Top5 97.375000    
2024-04-24 01:01:29,304 - Epoch: [560][  123/  123]    Loss 0.669418    Top1 78.343949    Top5 97.452229    
2024-04-24 01:01:29,410 - ==> Top1: 78.344    Top5: 97.452    Loss: 0.669

2024-04-24 01:01:29,419 - ==> Best [Top1: 78.803   Top5: 97.631   Sparsity:0.00   Params: 371568 on epoch: 535]
2024-04-24 01:01:29,419 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:01:29,454 - 

2024-04-24 01:01:29,454 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:01:36,995 - Epoch: [561][  100/  296]    Overall Loss 0.680653    Objective Loss 0.680653                                        LR 0.000005    Time 0.075330    
2024-04-24 01:01:42,261 - Epoch: [561][  200/  296]    Overall Loss 0.672229    Objective Loss 0.672229                                        LR 0.000005    Time 0.063968    
2024-04-24 01:01:47,827 - Epoch: [561][  296/  296]    Overall Loss 0.658664    Objective Loss 0.658664    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.062006    
2024-04-24 01:01:47,924 - --- validate (epoch=561)-----------
2024-04-24 01:01:47,924 - 3925 samples (32 per mini-batch)
2024-04-24 01:01:56,667 - Epoch: [561][  100/  123]    Loss 0.644509    Top1 79.375000    Top5 97.875000    
2024-04-24 01:01:58,430 - Epoch: [561][  123/  123]    Loss 0.663981    Top1 78.853503    Top5 97.605096    
2024-04-24 01:01:58,514 - ==> Top1: 78.854    Top5: 97.605    Loss: 0.664

2024-04-24 01:01:58,518 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:01:58,519 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:01:58,549 - 

2024-04-24 01:01:58,550 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:02:05,138 - Epoch: [562][  100/  296]    Overall Loss 0.685646    Objective Loss 0.685646                                        LR 0.000005    Time 0.065800    
2024-04-24 01:02:10,458 - Epoch: [562][  200/  296]    Overall Loss 0.686786    Objective Loss 0.686786                                        LR 0.000005    Time 0.059467    
2024-04-24 01:02:15,209 - Epoch: [562][  296/  296]    Overall Loss 0.673486    Objective Loss 0.673486    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.056206    
2024-04-24 01:02:15,340 - --- validate (epoch=562)-----------
2024-04-24 01:02:15,340 - 3925 samples (32 per mini-batch)
2024-04-24 01:02:23,556 - Epoch: [562][  100/  123]    Loss 0.661333    Top1 78.875000    Top5 97.500000    
2024-04-24 01:02:25,341 - Epoch: [562][  123/  123]    Loss 0.668620    Top1 78.802548    Top5 97.375796    
2024-04-24 01:02:25,438 - ==> Top1: 78.803    Top5: 97.376    Loss: 0.669

2024-04-24 01:02:25,447 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:02:25,448 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:02:25,481 - 

2024-04-24 01:02:25,482 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:02:32,354 - Epoch: [563][  100/  296]    Overall Loss 0.678291    Objective Loss 0.678291                                        LR 0.000005    Time 0.068652    
2024-04-24 01:02:38,885 - Epoch: [563][  200/  296]    Overall Loss 0.677563    Objective Loss 0.677563                                        LR 0.000005    Time 0.066944    
2024-04-24 01:02:43,596 - Epoch: [563][  296/  296]    Overall Loss 0.677207    Objective Loss 0.677207    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.061125    
2024-04-24 01:02:43,702 - --- validate (epoch=563)-----------
2024-04-24 01:02:43,703 - 3925 samples (32 per mini-batch)
2024-04-24 01:02:52,511 - Epoch: [563][  100/  123]    Loss 0.656851    Top1 79.375000    Top5 97.500000    
2024-04-24 01:02:54,272 - Epoch: [563][  123/  123]    Loss 0.670135    Top1 78.573248    Top5 97.350318    
2024-04-24 01:02:54,367 - ==> Top1: 78.573    Top5: 97.350    Loss: 0.670

2024-04-24 01:02:54,373 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:02:54,373 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:02:54,398 - 

2024-04-24 01:02:54,399 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:03:02,271 - Epoch: [564][  100/  296]    Overall Loss 0.655329    Objective Loss 0.655329                                        LR 0.000005    Time 0.078655    
2024-04-24 01:03:08,748 - Epoch: [564][  200/  296]    Overall Loss 0.677192    Objective Loss 0.677192                                        LR 0.000005    Time 0.071676    
2024-04-24 01:03:14,494 - Epoch: [564][  296/  296]    Overall Loss 0.672729    Objective Loss 0.672729    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.067820    
2024-04-24 01:03:14,605 - --- validate (epoch=564)-----------
2024-04-24 01:03:14,606 - 3925 samples (32 per mini-batch)
2024-04-24 01:03:23,662 - Epoch: [564][  100/  123]    Loss 0.661677    Top1 78.906250    Top5 97.437500    
2024-04-24 01:03:25,608 - Epoch: [564][  123/  123]    Loss 0.666852    Top1 78.547771    Top5 97.452229    
2024-04-24 01:03:25,742 - ==> Top1: 78.548    Top5: 97.452    Loss: 0.667

2024-04-24 01:03:25,749 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:03:25,749 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:03:25,790 - 

2024-04-24 01:03:25,790 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:03:35,787 - Epoch: [565][  100/  296]    Overall Loss 0.635703    Objective Loss 0.635703                                        LR 0.000005    Time 0.099873    
2024-04-24 01:03:43,837 - Epoch: [565][  200/  296]    Overall Loss 0.667323    Objective Loss 0.667323                                        LR 0.000005    Time 0.090151    
2024-04-24 01:03:49,628 - Epoch: [565][  296/  296]    Overall Loss 0.670051    Objective Loss 0.670051    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.080454    
2024-04-24 01:03:49,729 - --- validate (epoch=565)-----------
2024-04-24 01:03:49,730 - 3925 samples (32 per mini-batch)
2024-04-24 01:03:59,765 - Epoch: [565][  100/  123]    Loss 0.665369    Top1 78.312500    Top5 97.468750    
2024-04-24 01:04:01,366 - Epoch: [565][  123/  123]    Loss 0.665563    Top1 78.471338    Top5 97.401274    
2024-04-24 01:04:01,481 - ==> Top1: 78.471    Top5: 97.401    Loss: 0.666

2024-04-24 01:04:01,489 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:04:01,489 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:04:01,523 - 

2024-04-24 01:04:01,523 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:04:10,968 - Epoch: [566][  100/  296]    Overall Loss 0.629098    Objective Loss 0.629098                                        LR 0.000005    Time 0.094372    
2024-04-24 01:04:19,875 - Epoch: [566][  200/  296]    Overall Loss 0.637337    Objective Loss 0.637337                                        LR 0.000005    Time 0.091695    
2024-04-24 01:04:26,863 - Epoch: [566][  296/  296]    Overall Loss 0.650092    Objective Loss 0.650092    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.085548    
2024-04-24 01:04:26,953 - --- validate (epoch=566)-----------
2024-04-24 01:04:26,954 - 3925 samples (32 per mini-batch)
2024-04-24 01:04:36,442 - Epoch: [566][  100/  123]    Loss 0.667301    Top1 78.656250    Top5 97.500000    
2024-04-24 01:04:38,082 - Epoch: [566][  123/  123]    Loss 0.673090    Top1 78.369427    Top5 97.273885    
2024-04-24 01:04:38,186 - ==> Top1: 78.369    Top5: 97.274    Loss: 0.673

2024-04-24 01:04:38,194 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:04:38,195 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:04:38,230 - 

2024-04-24 01:04:38,230 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:04:46,409 - Epoch: [567][  100/  296]    Overall Loss 0.656000    Objective Loss 0.656000                                        LR 0.000005    Time 0.081708    
2024-04-24 01:04:54,198 - Epoch: [567][  200/  296]    Overall Loss 0.666556    Objective Loss 0.666556                                        LR 0.000005    Time 0.079762    
2024-04-24 01:05:01,897 - Epoch: [567][  296/  296]    Overall Loss 0.660955    Objective Loss 0.660955    Top1 80.327869    Top5 91.803279    LR 0.000005    Time 0.079880    
2024-04-24 01:05:02,009 - --- validate (epoch=567)-----------
2024-04-24 01:05:02,010 - 3925 samples (32 per mini-batch)
2024-04-24 01:05:11,633 - Epoch: [567][  100/  123]    Loss 0.677927    Top1 77.593750    Top5 97.468750    
2024-04-24 01:05:13,376 - Epoch: [567][  123/  123]    Loss 0.668971    Top1 78.140127    Top5 97.452229    
2024-04-24 01:05:13,469 - ==> Top1: 78.140    Top5: 97.452    Loss: 0.669

2024-04-24 01:05:13,478 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:05:13,478 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:05:13,514 - 

2024-04-24 01:05:13,515 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:05:22,077 - Epoch: [568][  100/  296]    Overall Loss 0.685963    Objective Loss 0.685963                                        LR 0.000005    Time 0.085541    
2024-04-24 01:05:28,151 - Epoch: [568][  200/  296]    Overall Loss 0.676185    Objective Loss 0.676185                                        LR 0.000005    Time 0.073108    
2024-04-24 01:05:33,147 - Epoch: [568][  296/  296]    Overall Loss 0.675836    Objective Loss 0.675836    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.066250    
2024-04-24 01:05:33,249 - --- validate (epoch=568)-----------
2024-04-24 01:05:33,249 - 3925 samples (32 per mini-batch)
2024-04-24 01:05:40,372 - Epoch: [568][  100/  123]    Loss 0.657467    Top1 78.937500    Top5 97.687500    
2024-04-24 01:05:41,847 - Epoch: [568][  123/  123]    Loss 0.667523    Top1 78.700637    Top5 97.528662    
2024-04-24 01:05:41,943 - ==> Top1: 78.701    Top5: 97.529    Loss: 0.668

2024-04-24 01:05:41,952 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:05:41,952 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:05:41,988 - 

2024-04-24 01:05:41,988 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:05:48,734 - Epoch: [569][  100/  296]    Overall Loss 0.694653    Objective Loss 0.694653                                        LR 0.000005    Time 0.067378    
2024-04-24 01:05:54,403 - Epoch: [569][  200/  296]    Overall Loss 0.688959    Objective Loss 0.688959                                        LR 0.000005    Time 0.062004    
2024-04-24 01:05:59,650 - Epoch: [569][  296/  296]    Overall Loss 0.683553    Objective Loss 0.683553    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.059599    
2024-04-24 01:05:59,768 - --- validate (epoch=569)-----------
2024-04-24 01:05:59,769 - 3925 samples (32 per mini-batch)
2024-04-24 01:06:07,979 - Epoch: [569][  100/  123]    Loss 0.688051    Top1 78.500000    Top5 97.031250    
2024-04-24 01:06:09,716 - Epoch: [569][  123/  123]    Loss 0.670819    Top1 78.700637    Top5 97.273885    
2024-04-24 01:06:09,808 - ==> Top1: 78.701    Top5: 97.274    Loss: 0.671

2024-04-24 01:06:09,818 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:06:09,818 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:06:09,855 - 

2024-04-24 01:06:09,855 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:06:16,887 - Epoch: [570][  100/  296]    Overall Loss 0.673950    Objective Loss 0.673950                                        LR 0.000005    Time 0.070246    
2024-04-24 01:06:22,461 - Epoch: [570][  200/  296]    Overall Loss 0.679078    Objective Loss 0.679078                                        LR 0.000005    Time 0.062955    
2024-04-24 01:06:26,942 - Epoch: [570][  296/  296]    Overall Loss 0.672495    Objective Loss 0.672495    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.057652    
2024-04-24 01:06:27,064 - --- validate (epoch=570)-----------
2024-04-24 01:06:27,065 - 3925 samples (32 per mini-batch)
2024-04-24 01:06:34,893 - Epoch: [570][  100/  123]    Loss 0.666077    Top1 78.468750    Top5 97.781250    
2024-04-24 01:06:36,496 - Epoch: [570][  123/  123]    Loss 0.667221    Top1 78.675159    Top5 97.605096    
2024-04-24 01:06:36,609 - ==> Top1: 78.675    Top5: 97.605    Loss: 0.667

2024-04-24 01:06:36,618 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:06:36,619 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:06:36,660 - 

2024-04-24 01:06:36,660 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:06:43,436 - Epoch: [571][  100/  296]    Overall Loss 0.665094    Objective Loss 0.665094                                        LR 0.000005    Time 0.067681    
2024-04-24 01:06:49,964 - Epoch: [571][  200/  296]    Overall Loss 0.656142    Objective Loss 0.656142                                        LR 0.000005    Time 0.066450    
2024-04-24 01:06:56,468 - Epoch: [571][  296/  296]    Overall Loss 0.661542    Objective Loss 0.661542    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.066852    
2024-04-24 01:06:56,554 - --- validate (epoch=571)-----------
2024-04-24 01:06:56,554 - 3925 samples (32 per mini-batch)
2024-04-24 01:07:06,173 - Epoch: [571][  100/  123]    Loss 0.680516    Top1 77.843750    Top5 97.437500    
2024-04-24 01:07:08,181 - Epoch: [571][  123/  123]    Loss 0.665661    Top1 78.496815    Top5 97.605096    
2024-04-24 01:07:08,299 - ==> Top1: 78.497    Top5: 97.605    Loss: 0.666

2024-04-24 01:07:08,307 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:07:08,308 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:07:08,342 - 

2024-04-24 01:07:08,342 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:07:16,114 - Epoch: [572][  100/  296]    Overall Loss 0.633271    Objective Loss 0.633271                                        LR 0.000005    Time 0.077630    
2024-04-24 01:07:22,145 - Epoch: [572][  200/  296]    Overall Loss 0.650483    Objective Loss 0.650483                                        LR 0.000005    Time 0.068936    
2024-04-24 01:07:29,010 - Epoch: [572][  296/  296]    Overall Loss 0.657014    Objective Loss 0.657014    Top1 86.885246    Top5 96.721311    LR 0.000005    Time 0.069750    
2024-04-24 01:07:29,103 - --- validate (epoch=572)-----------
2024-04-24 01:07:29,104 - 3925 samples (32 per mini-batch)
2024-04-24 01:07:38,404 - Epoch: [572][  100/  123]    Loss 0.679554    Top1 77.843750    Top5 97.250000    
2024-04-24 01:07:40,437 - Epoch: [572][  123/  123]    Loss 0.671402    Top1 78.394904    Top5 97.299363    
2024-04-24 01:07:40,547 - ==> Top1: 78.395    Top5: 97.299    Loss: 0.671

2024-04-24 01:07:40,556 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:07:40,556 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:07:40,590 - 

2024-04-24 01:07:40,590 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:07:48,185 - Epoch: [573][  100/  296]    Overall Loss 0.662883    Objective Loss 0.662883                                        LR 0.000005    Time 0.075862    
2024-04-24 01:07:54,889 - Epoch: [573][  200/  296]    Overall Loss 0.654560    Objective Loss 0.654560                                        LR 0.000005    Time 0.071411    
2024-04-24 01:08:02,183 - Epoch: [573][  296/  296]    Overall Loss 0.654788    Objective Loss 0.654788    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.072864    
2024-04-24 01:08:02,288 - --- validate (epoch=573)-----------
2024-04-24 01:08:02,288 - 3925 samples (32 per mini-batch)
2024-04-24 01:08:11,248 - Epoch: [573][  100/  123]    Loss 0.658545    Top1 78.906250    Top5 97.218750    
2024-04-24 01:08:13,156 - Epoch: [573][  123/  123]    Loss 0.671078    Top1 78.496815    Top5 97.426752    
2024-04-24 01:08:13,249 - ==> Top1: 78.497    Top5: 97.427    Loss: 0.671

2024-04-24 01:08:13,257 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:08:13,258 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:08:13,293 - 

2024-04-24 01:08:13,293 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:08:20,996 - Epoch: [574][  100/  296]    Overall Loss 0.667439    Objective Loss 0.667439                                        LR 0.000005    Time 0.076953    
2024-04-24 01:08:27,441 - Epoch: [574][  200/  296]    Overall Loss 0.670245    Objective Loss 0.670245                                        LR 0.000005    Time 0.070661    
2024-04-24 01:08:33,136 - Epoch: [574][  296/  296]    Overall Loss 0.679206    Objective Loss 0.679206    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.066963    
2024-04-24 01:08:33,226 - --- validate (epoch=574)-----------
2024-04-24 01:08:33,227 - 3925 samples (32 per mini-batch)
2024-04-24 01:08:41,247 - Epoch: [574][  100/  123]    Loss 0.668241    Top1 78.281250    Top5 97.468750    
2024-04-24 01:08:42,807 - Epoch: [574][  123/  123]    Loss 0.669977    Top1 78.318471    Top5 97.477707    
2024-04-24 01:08:42,898 - ==> Top1: 78.318    Top5: 97.478    Loss: 0.670

2024-04-24 01:08:42,908 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:08:42,908 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:08:42,942 - 

2024-04-24 01:08:42,942 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:08:49,599 - Epoch: [575][  100/  296]    Overall Loss 0.659387    Objective Loss 0.659387                                        LR 0.000005    Time 0.066503    
2024-04-24 01:08:54,501 - Epoch: [575][  200/  296]    Overall Loss 0.638734    Objective Loss 0.638734                                        LR 0.000005    Time 0.057730    
2024-04-24 01:09:00,111 - Epoch: [575][  296/  296]    Overall Loss 0.644154    Objective Loss 0.644154    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.057936    
2024-04-24 01:09:00,214 - --- validate (epoch=575)-----------
2024-04-24 01:09:00,215 - 3925 samples (32 per mini-batch)
2024-04-24 01:09:07,353 - Epoch: [575][  100/  123]    Loss 0.670333    Top1 78.437500    Top5 97.406250    
2024-04-24 01:09:08,811 - Epoch: [575][  123/  123]    Loss 0.666449    Top1 78.624204    Top5 97.401274    
2024-04-24 01:09:08,898 - ==> Top1: 78.624    Top5: 97.401    Loss: 0.666

2024-04-24 01:09:08,908 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:09:08,908 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:09:08,943 - 

2024-04-24 01:09:08,943 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:09:15,757 - Epoch: [576][  100/  296]    Overall Loss 0.629088    Objective Loss 0.629088                                        LR 0.000005    Time 0.068071    
2024-04-24 01:09:21,379 - Epoch: [576][  200/  296]    Overall Loss 0.664803    Objective Loss 0.664803                                        LR 0.000005    Time 0.062109    
2024-04-24 01:09:27,452 - Epoch: [576][  296/  296]    Overall Loss 0.650050    Objective Loss 0.650050    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.062459    
2024-04-24 01:09:27,561 - --- validate (epoch=576)-----------
2024-04-24 01:09:27,562 - 3925 samples (32 per mini-batch)
2024-04-24 01:09:37,951 - Epoch: [576][  100/  123]    Loss 0.664217    Top1 78.250000    Top5 97.437500    
2024-04-24 01:09:40,109 - Epoch: [576][  123/  123]    Loss 0.668251    Top1 78.343949    Top5 97.426752    
2024-04-24 01:09:40,209 - ==> Top1: 78.344    Top5: 97.427    Loss: 0.668

2024-04-24 01:09:40,218 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:09:40,218 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:09:40,259 - 

2024-04-24 01:09:40,259 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:09:47,429 - Epoch: [577][  100/  296]    Overall Loss 0.640226    Objective Loss 0.640226                                        LR 0.000005    Time 0.071620    
2024-04-24 01:09:53,779 - Epoch: [577][  200/  296]    Overall Loss 0.657440    Objective Loss 0.657440                                        LR 0.000005    Time 0.067526    
2024-04-24 01:10:00,742 - Epoch: [577][  296/  296]    Overall Loss 0.659615    Objective Loss 0.659615    Top1 70.491803    Top5 100.000000    LR 0.000005    Time 0.069133    
2024-04-24 01:10:00,843 - --- validate (epoch=577)-----------
2024-04-24 01:10:00,844 - 3925 samples (32 per mini-batch)
2024-04-24 01:10:10,982 - Epoch: [577][  100/  123]    Loss 0.685545    Top1 78.406250    Top5 97.312500    
2024-04-24 01:10:13,051 - Epoch: [577][  123/  123]    Loss 0.671715    Top1 78.369427    Top5 97.375796    
2024-04-24 01:10:13,146 - ==> Top1: 78.369    Top5: 97.376    Loss: 0.672

2024-04-24 01:10:13,156 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:10:13,157 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:10:13,191 - 

2024-04-24 01:10:13,191 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:10:20,906 - Epoch: [578][  100/  296]    Overall Loss 0.667626    Objective Loss 0.667626                                        LR 0.000005    Time 0.077072    
2024-04-24 01:10:27,438 - Epoch: [578][  200/  296]    Overall Loss 0.676720    Objective Loss 0.676720                                        LR 0.000005    Time 0.071155    
2024-04-24 01:10:33,687 - Epoch: [578][  296/  296]    Overall Loss 0.684113    Objective Loss 0.684113    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.069165    
2024-04-24 01:10:33,792 - --- validate (epoch=578)-----------
2024-04-24 01:10:33,793 - 3925 samples (32 per mini-batch)
2024-04-24 01:10:43,256 - Epoch: [578][  100/  123]    Loss 0.656926    Top1 78.781250    Top5 97.531250    
2024-04-24 01:10:45,313 - Epoch: [578][  123/  123]    Loss 0.666482    Top1 78.445860    Top5 97.503185    
2024-04-24 01:10:45,410 - ==> Top1: 78.446    Top5: 97.503    Loss: 0.666

2024-04-24 01:10:45,418 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:10:45,419 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:10:45,455 - 

2024-04-24 01:10:45,455 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:10:53,968 - Epoch: [579][  100/  296]    Overall Loss 0.646591    Objective Loss 0.646591                                        LR 0.000005    Time 0.085056    
2024-04-24 01:11:00,701 - Epoch: [579][  200/  296]    Overall Loss 0.658882    Objective Loss 0.658882                                        LR 0.000005    Time 0.076156    
2024-04-24 01:11:06,735 - Epoch: [579][  296/  296]    Overall Loss 0.666593    Objective Loss 0.666593    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.071817    
2024-04-24 01:11:06,894 - --- validate (epoch=579)-----------
2024-04-24 01:11:06,894 - 3925 samples (32 per mini-batch)
2024-04-24 01:11:17,083 - Epoch: [579][  100/  123]    Loss 0.671247    Top1 78.187500    Top5 97.437500    
2024-04-24 01:11:19,165 - Epoch: [579][  123/  123]    Loss 0.669306    Top1 78.267516    Top5 97.401274    
2024-04-24 01:11:19,248 - ==> Top1: 78.268    Top5: 97.401    Loss: 0.669

2024-04-24 01:11:19,257 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:11:19,257 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:11:19,290 - 

2024-04-24 01:11:19,291 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:11:26,767 - Epoch: [580][  100/  296]    Overall Loss 0.687045    Objective Loss 0.687045                                        LR 0.000005    Time 0.074691    
2024-04-24 01:11:31,790 - Epoch: [580][  200/  296]    Overall Loss 0.683359    Objective Loss 0.683359                                        LR 0.000005    Time 0.062423    
2024-04-24 01:11:37,102 - Epoch: [580][  296/  296]    Overall Loss 0.676945    Objective Loss 0.676945    Top1 85.245902    Top5 93.442623    LR 0.000005    Time 0.060103    
2024-04-24 01:11:37,198 - --- validate (epoch=580)-----------
2024-04-24 01:11:37,198 - 3925 samples (32 per mini-batch)
2024-04-24 01:11:45,226 - Epoch: [580][  100/  123]    Loss 0.657604    Top1 78.500000    Top5 97.500000    
2024-04-24 01:11:47,282 - Epoch: [580][  123/  123]    Loss 0.672115    Top1 78.242038    Top5 97.350318    
2024-04-24 01:11:47,375 - ==> Top1: 78.242    Top5: 97.350    Loss: 0.672

2024-04-24 01:11:47,384 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:11:47,384 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:11:47,418 - 

2024-04-24 01:11:47,418 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:11:54,754 - Epoch: [581][  100/  296]    Overall Loss 0.656815    Objective Loss 0.656815                                        LR 0.000005    Time 0.073288    
2024-04-24 01:12:01,046 - Epoch: [581][  200/  296]    Overall Loss 0.655832    Objective Loss 0.655832                                        LR 0.000005    Time 0.068068    
2024-04-24 01:12:08,702 - Epoch: [581][  296/  296]    Overall Loss 0.662153    Objective Loss 0.662153    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.071835    
2024-04-24 01:12:08,780 - --- validate (epoch=581)-----------
2024-04-24 01:12:08,780 - 3925 samples (32 per mini-batch)
2024-04-24 01:12:18,994 - Epoch: [581][  100/  123]    Loss 0.671223    Top1 78.468750    Top5 97.468750    
2024-04-24 01:12:20,759 - Epoch: [581][  123/  123]    Loss 0.668807    Top1 78.242038    Top5 97.554140    
2024-04-24 01:12:20,855 - ==> Top1: 78.242    Top5: 97.554    Loss: 0.669

2024-04-24 01:12:20,864 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:12:20,864 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:12:20,900 - 

2024-04-24 01:12:20,900 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:12:29,787 - Epoch: [582][  100/  296]    Overall Loss 0.656296    Objective Loss 0.656296                                        LR 0.000005    Time 0.088783    
2024-04-24 01:12:36,201 - Epoch: [582][  200/  296]    Overall Loss 0.651639    Objective Loss 0.651639                                        LR 0.000005    Time 0.076425    
2024-04-24 01:12:43,211 - Epoch: [582][  296/  296]    Overall Loss 0.658201    Objective Loss 0.658201    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.075297    
2024-04-24 01:12:43,326 - --- validate (epoch=582)-----------
2024-04-24 01:12:43,326 - 3925 samples (32 per mini-batch)
2024-04-24 01:12:52,323 - Epoch: [582][  100/  123]    Loss 0.677680    Top1 78.093750    Top5 97.375000    
2024-04-24 01:12:54,090 - Epoch: [582][  123/  123]    Loss 0.671239    Top1 78.420382    Top5 97.477707    
2024-04-24 01:12:54,196 - ==> Top1: 78.420    Top5: 97.478    Loss: 0.671

2024-04-24 01:12:54,204 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:12:54,204 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:12:54,239 - 

2024-04-24 01:12:54,239 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:13:01,644 - Epoch: [583][  100/  296]    Overall Loss 0.657454    Objective Loss 0.657454                                        LR 0.000005    Time 0.073985    
2024-04-24 01:13:08,635 - Epoch: [583][  200/  296]    Overall Loss 0.671414    Objective Loss 0.671414                                        LR 0.000005    Time 0.071916    
2024-04-24 01:13:16,440 - Epoch: [583][  296/  296]    Overall Loss 0.672569    Objective Loss 0.672569    Top1 72.131148    Top5 100.000000    LR 0.000005    Time 0.074946    
2024-04-24 01:13:16,575 - --- validate (epoch=583)-----------
2024-04-24 01:13:16,575 - 3925 samples (32 per mini-batch)
2024-04-24 01:13:24,885 - Epoch: [583][  100/  123]    Loss 0.682279    Top1 78.375000    Top5 97.343750    
2024-04-24 01:13:26,030 - Epoch: [583][  123/  123]    Loss 0.674089    Top1 78.445860    Top5 97.503185    
2024-04-24 01:13:26,118 - ==> Top1: 78.446    Top5: 97.503    Loss: 0.674

2024-04-24 01:13:26,127 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:13:26,128 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:13:26,163 - 

2024-04-24 01:13:26,163 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:13:32,967 - Epoch: [584][  100/  296]    Overall Loss 0.682209    Objective Loss 0.682209                                        LR 0.000005    Time 0.067964    
2024-04-24 01:13:38,309 - Epoch: [584][  200/  296]    Overall Loss 0.672602    Objective Loss 0.672602                                        LR 0.000005    Time 0.060662    
2024-04-24 01:13:43,595 - Epoch: [584][  296/  296]    Overall Loss 0.667090    Objective Loss 0.667090    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.058825    
2024-04-24 01:13:43,726 - --- validate (epoch=584)-----------
2024-04-24 01:13:43,727 - 3925 samples (32 per mini-batch)
2024-04-24 01:13:51,614 - Epoch: [584][  100/  123]    Loss 0.656085    Top1 78.593750    Top5 97.750000    
2024-04-24 01:13:53,224 - Epoch: [584][  123/  123]    Loss 0.669073    Top1 78.318471    Top5 97.630573    
2024-04-24 01:13:53,336 - ==> Top1: 78.318    Top5: 97.631    Loss: 0.669

2024-04-24 01:13:53,345 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:13:53,346 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:13:53,386 - 

2024-04-24 01:13:53,386 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:14:01,310 - Epoch: [585][  100/  296]    Overall Loss 0.674110    Objective Loss 0.674110                                        LR 0.000005    Time 0.079165    
2024-04-24 01:14:08,723 - Epoch: [585][  200/  296]    Overall Loss 0.668928    Objective Loss 0.668928                                        LR 0.000005    Time 0.076607    
2024-04-24 01:14:13,609 - Epoch: [585][  296/  296]    Overall Loss 0.673019    Objective Loss 0.673019    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.068247    
2024-04-24 01:14:13,688 - --- validate (epoch=585)-----------
2024-04-24 01:14:13,689 - 3925 samples (32 per mini-batch)
2024-04-24 01:14:22,201 - Epoch: [585][  100/  123]    Loss 0.660410    Top1 78.406250    Top5 97.531250    
2024-04-24 01:14:23,951 - Epoch: [585][  123/  123]    Loss 0.667522    Top1 78.369427    Top5 97.554140    
2024-04-24 01:14:24,056 - ==> Top1: 78.369    Top5: 97.554    Loss: 0.668

2024-04-24 01:14:24,065 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:14:24,065 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:14:24,101 - 

2024-04-24 01:14:24,101 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:14:31,311 - Epoch: [586][  100/  296]    Overall Loss 0.643691    Objective Loss 0.643691                                        LR 0.000005    Time 0.072025    
2024-04-24 01:14:37,897 - Epoch: [586][  200/  296]    Overall Loss 0.650152    Objective Loss 0.650152                                        LR 0.000005    Time 0.068910    
2024-04-24 01:14:44,823 - Epoch: [586][  296/  296]    Overall Loss 0.660686    Objective Loss 0.660686    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.069933    
2024-04-24 01:14:44,929 - --- validate (epoch=586)-----------
2024-04-24 01:14:44,929 - 3925 samples (32 per mini-batch)
2024-04-24 01:14:53,106 - Epoch: [586][  100/  123]    Loss 0.671547    Top1 77.750000    Top5 97.437500    
2024-04-24 01:14:55,002 - Epoch: [586][  123/  123]    Loss 0.671656    Top1 77.885350    Top5 97.528662    
2024-04-24 01:14:55,107 - ==> Top1: 77.885    Top5: 97.529    Loss: 0.672

2024-04-24 01:14:55,116 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:14:55,116 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:14:55,151 - 

2024-04-24 01:14:55,151 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:15:02,222 - Epoch: [587][  100/  296]    Overall Loss 0.667496    Objective Loss 0.667496                                        LR 0.000005    Time 0.070636    
2024-04-24 01:15:07,746 - Epoch: [587][  200/  296]    Overall Loss 0.678399    Objective Loss 0.678399                                        LR 0.000005    Time 0.062902    
2024-04-24 01:15:13,033 - Epoch: [587][  296/  296]    Overall Loss 0.682419    Objective Loss 0.682419    Top1 75.409836    Top5 93.442623    LR 0.000005    Time 0.060340    
2024-04-24 01:15:13,108 - --- validate (epoch=587)-----------
2024-04-24 01:15:13,108 - 3925 samples (32 per mini-batch)
2024-04-24 01:15:22,459 - Epoch: [587][  100/  123]    Loss 0.675634    Top1 78.218750    Top5 97.625000    
2024-04-24 01:15:24,315 - Epoch: [587][  123/  123]    Loss 0.667817    Top1 78.471338    Top5 97.528662    
2024-04-24 01:15:24,396 - ==> Top1: 78.471    Top5: 97.529    Loss: 0.668

2024-04-24 01:15:24,405 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:15:24,405 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:15:24,441 - 

2024-04-24 01:15:24,441 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:15:32,317 - Epoch: [588][  100/  296]    Overall Loss 0.685973    Objective Loss 0.685973                                        LR 0.000005    Time 0.078682    
2024-04-24 01:15:38,528 - Epoch: [588][  200/  296]    Overall Loss 0.680938    Objective Loss 0.680938                                        LR 0.000005    Time 0.070359    
2024-04-24 01:15:43,927 - Epoch: [588][  296/  296]    Overall Loss 0.669137    Objective Loss 0.669137    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.065758    
2024-04-24 01:15:44,013 - --- validate (epoch=588)-----------
2024-04-24 01:15:44,014 - 3925 samples (32 per mini-batch)
2024-04-24 01:15:53,350 - Epoch: [588][  100/  123]    Loss 0.676819    Top1 78.218750    Top5 97.500000    
2024-04-24 01:15:55,311 - Epoch: [588][  123/  123]    Loss 0.670878    Top1 78.343949    Top5 97.528662    
2024-04-24 01:15:55,400 - ==> Top1: 78.344    Top5: 97.529    Loss: 0.671

2024-04-24 01:15:55,404 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:15:55,404 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:15:55,433 - 

2024-04-24 01:15:55,433 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:16:03,617 - Epoch: [589][  100/  296]    Overall Loss 0.687561    Objective Loss 0.687561                                        LR 0.000005    Time 0.081764    
2024-04-24 01:16:11,254 - Epoch: [589][  200/  296]    Overall Loss 0.696389    Objective Loss 0.696389                                        LR 0.000005    Time 0.079028    
2024-04-24 01:16:17,638 - Epoch: [589][  296/  296]    Overall Loss 0.680475    Objective Loss 0.680475    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.074941    
2024-04-24 01:16:17,734 - --- validate (epoch=589)-----------
2024-04-24 01:16:17,735 - 3925 samples (32 per mini-batch)
2024-04-24 01:16:27,357 - Epoch: [589][  100/  123]    Loss 0.676360    Top1 78.312500    Top5 97.468750    
2024-04-24 01:16:28,654 - Epoch: [589][  123/  123]    Loss 0.670465    Top1 78.343949    Top5 97.605096    
2024-04-24 01:16:28,777 - ==> Top1: 78.344    Top5: 97.605    Loss: 0.670

2024-04-24 01:16:28,786 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:16:28,787 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:16:28,822 - 

2024-04-24 01:16:28,822 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:16:35,681 - Epoch: [590][  100/  296]    Overall Loss 0.657539    Objective Loss 0.657539                                        LR 0.000005    Time 0.068516    
2024-04-24 01:16:41,932 - Epoch: [590][  200/  296]    Overall Loss 0.666847    Objective Loss 0.666847                                        LR 0.000005    Time 0.065477    
2024-04-24 01:16:47,299 - Epoch: [590][  296/  296]    Overall Loss 0.664776    Objective Loss 0.664776    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.062354    
2024-04-24 01:16:47,380 - --- validate (epoch=590)-----------
2024-04-24 01:16:47,381 - 3925 samples (32 per mini-batch)
2024-04-24 01:16:56,124 - Epoch: [590][  100/  123]    Loss 0.672579    Top1 78.406250    Top5 97.468750    
2024-04-24 01:16:57,703 - Epoch: [590][  123/  123]    Loss 0.670663    Top1 78.292994    Top5 97.503185    
2024-04-24 01:16:57,818 - ==> Top1: 78.293    Top5: 97.503    Loss: 0.671

2024-04-24 01:16:57,827 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:16:57,827 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:16:57,862 - 

2024-04-24 01:16:57,862 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:17:04,790 - Epoch: [591][  100/  296]    Overall Loss 0.651666    Objective Loss 0.651666                                        LR 0.000005    Time 0.069208    
2024-04-24 01:17:12,137 - Epoch: [591][  200/  296]    Overall Loss 0.660273    Objective Loss 0.660273                                        LR 0.000005    Time 0.071300    
2024-04-24 01:17:18,411 - Epoch: [591][  296/  296]    Overall Loss 0.667536    Objective Loss 0.667536    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.069350    
2024-04-24 01:17:18,501 - --- validate (epoch=591)-----------
2024-04-24 01:17:18,502 - 3925 samples (32 per mini-batch)
2024-04-24 01:17:28,193 - Epoch: [591][  100/  123]    Loss 0.665500    Top1 78.062500    Top5 97.343750    
2024-04-24 01:17:29,976 - Epoch: [591][  123/  123]    Loss 0.671282    Top1 78.063694    Top5 97.477707    
2024-04-24 01:17:30,088 - ==> Top1: 78.064    Top5: 97.478    Loss: 0.671

2024-04-24 01:17:30,097 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:17:30,098 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:17:30,133 - 

2024-04-24 01:17:30,133 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:17:37,793 - Epoch: [592][  100/  296]    Overall Loss 0.668484    Objective Loss 0.668484                                        LR 0.000005    Time 0.076517    
2024-04-24 01:17:43,856 - Epoch: [592][  200/  296]    Overall Loss 0.663396    Objective Loss 0.663396                                        LR 0.000005    Time 0.068541    
2024-04-24 01:17:50,341 - Epoch: [592][  296/  296]    Overall Loss 0.662278    Objective Loss 0.662278    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.068202    
2024-04-24 01:17:50,433 - --- validate (epoch=592)-----------
2024-04-24 01:17:50,433 - 3925 samples (32 per mini-batch)
2024-04-24 01:18:00,154 - Epoch: [592][  100/  123]    Loss 0.673942    Top1 78.000000    Top5 97.562500    
2024-04-24 01:18:02,070 - Epoch: [592][  123/  123]    Loss 0.674498    Top1 78.343949    Top5 97.452229    
2024-04-24 01:18:02,157 - ==> Top1: 78.344    Top5: 97.452    Loss: 0.674

2024-04-24 01:18:02,166 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:18:02,166 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:18:02,201 - 

2024-04-24 01:18:02,201 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:18:09,841 - Epoch: [593][  100/  296]    Overall Loss 0.651852    Objective Loss 0.651852                                        LR 0.000005    Time 0.076320    
2024-04-24 01:18:16,522 - Epoch: [593][  200/  296]    Overall Loss 0.681646    Objective Loss 0.681646                                        LR 0.000005    Time 0.071531    
2024-04-24 01:18:23,135 - Epoch: [593][  296/  296]    Overall Loss 0.685144    Objective Loss 0.685144    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.070653    
2024-04-24 01:18:23,219 - --- validate (epoch=593)-----------
2024-04-24 01:18:23,220 - 3925 samples (32 per mini-batch)
2024-04-24 01:18:32,976 - Epoch: [593][  100/  123]    Loss 0.654286    Top1 78.656250    Top5 97.812500    
2024-04-24 01:18:35,382 - Epoch: [593][  123/  123]    Loss 0.671312    Top1 78.267516    Top5 97.528662    
2024-04-24 01:18:35,648 - ==> Top1: 78.268    Top5: 97.529    Loss: 0.671

2024-04-24 01:18:35,659 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:18:35,660 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:18:35,697 - 

2024-04-24 01:18:35,697 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:18:44,092 - Epoch: [594][  100/  296]    Overall Loss 0.661867    Objective Loss 0.661867                                        LR 0.000005    Time 0.083865    
2024-04-24 01:18:51,877 - Epoch: [594][  200/  296]    Overall Loss 0.647974    Objective Loss 0.647974                                        LR 0.000005    Time 0.080817    
2024-04-24 01:18:59,489 - Epoch: [594][  296/  296]    Overall Loss 0.649537    Objective Loss 0.649537    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.080295    
2024-04-24 01:18:59,566 - --- validate (epoch=594)-----------
2024-04-24 01:18:59,566 - 3925 samples (32 per mini-batch)
2024-04-24 01:19:07,931 - Epoch: [594][  100/  123]    Loss 0.680214    Top1 78.218750    Top5 97.437500    
2024-04-24 01:19:09,901 - Epoch: [594][  123/  123]    Loss 0.668280    Top1 78.242038    Top5 97.579618    
2024-04-24 01:19:10,047 - ==> Top1: 78.242    Top5: 97.580    Loss: 0.668

2024-04-24 01:19:10,056 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:19:10,056 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:19:10,090 - 

2024-04-24 01:19:10,090 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:19:19,258 - Epoch: [595][  100/  296]    Overall Loss 0.674703    Objective Loss 0.674703                                        LR 0.000005    Time 0.091604    
2024-04-24 01:19:25,666 - Epoch: [595][  200/  296]    Overall Loss 0.658997    Objective Loss 0.658997                                        LR 0.000005    Time 0.077806    
2024-04-24 01:19:32,624 - Epoch: [595][  296/  296]    Overall Loss 0.662667    Objective Loss 0.662667    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.076059    
2024-04-24 01:19:32,725 - --- validate (epoch=595)-----------
2024-04-24 01:19:32,725 - 3925 samples (32 per mini-batch)
2024-04-24 01:19:41,700 - Epoch: [595][  100/  123]    Loss 0.673246    Top1 77.937500    Top5 97.375000    
2024-04-24 01:19:43,607 - Epoch: [595][  123/  123]    Loss 0.672236    Top1 78.140127    Top5 97.375796    
2024-04-24 01:19:43,752 - ==> Top1: 78.140    Top5: 97.376    Loss: 0.672

2024-04-24 01:19:43,761 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:19:43,761 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:19:43,797 - 

2024-04-24 01:19:43,797 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:19:51,606 - Epoch: [596][  100/  296]    Overall Loss 0.658079    Objective Loss 0.658079                                        LR 0.000005    Time 0.078027    
2024-04-24 01:19:58,539 - Epoch: [596][  200/  296]    Overall Loss 0.652336    Objective Loss 0.652336                                        LR 0.000005    Time 0.073640    
2024-04-24 01:20:05,011 - Epoch: [596][  296/  296]    Overall Loss 0.659461    Objective Loss 0.659461    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.071598    
2024-04-24 01:20:05,119 - --- validate (epoch=596)-----------
2024-04-24 01:20:05,120 - 3925 samples (32 per mini-batch)
2024-04-24 01:20:15,425 - Epoch: [596][  100/  123]    Loss 0.663892    Top1 78.500000    Top5 97.562500    
2024-04-24 01:20:17,510 - Epoch: [596][  123/  123]    Loss 0.671194    Top1 78.343949    Top5 97.426752    
2024-04-24 01:20:17,620 - ==> Top1: 78.344    Top5: 97.427    Loss: 0.671

2024-04-24 01:20:17,628 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:20:17,628 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:20:17,665 - 

2024-04-24 01:20:17,666 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:20:25,969 - Epoch: [597][  100/  296]    Overall Loss 0.668562    Objective Loss 0.668562                                        LR 0.000005    Time 0.082958    
2024-04-24 01:20:33,586 - Epoch: [597][  200/  296]    Overall Loss 0.656780    Objective Loss 0.656780                                        LR 0.000005    Time 0.079534    
2024-04-24 01:20:40,005 - Epoch: [597][  296/  296]    Overall Loss 0.660322    Objective Loss 0.660322    Top1 65.573770    Top5 96.721311    LR 0.000005    Time 0.075402    
2024-04-24 01:20:40,142 - --- validate (epoch=597)-----------
2024-04-24 01:20:40,142 - 3925 samples (32 per mini-batch)
2024-04-24 01:20:49,293 - Epoch: [597][  100/  123]    Loss 0.656408    Top1 79.062500    Top5 97.687500    
2024-04-24 01:20:51,251 - Epoch: [597][  123/  123]    Loss 0.673452    Top1 78.267516    Top5 97.452229    
2024-04-24 01:20:51,350 - ==> Top1: 78.268    Top5: 97.452    Loss: 0.673

2024-04-24 01:20:51,359 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:20:51,360 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:20:51,410 - 

2024-04-24 01:20:51,411 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:21:00,031 - Epoch: [598][  100/  296]    Overall Loss 0.670236    Objective Loss 0.670236                                        LR 0.000005    Time 0.086114    
2024-04-24 01:21:06,689 - Epoch: [598][  200/  296]    Overall Loss 0.674183    Objective Loss 0.674183                                        LR 0.000005    Time 0.076315    
2024-04-24 01:21:12,991 - Epoch: [598][  296/  296]    Overall Loss 0.670690    Objective Loss 0.670690    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.072829    
2024-04-24 01:21:13,128 - --- validate (epoch=598)-----------
2024-04-24 01:21:13,128 - 3925 samples (32 per mini-batch)
2024-04-24 01:21:23,074 - Epoch: [598][  100/  123]    Loss 0.669464    Top1 78.000000    Top5 97.562500    
2024-04-24 01:21:24,624 - Epoch: [598][  123/  123]    Loss 0.667629    Top1 78.267516    Top5 97.452229    
2024-04-24 01:21:24,699 - ==> Top1: 78.268    Top5: 97.452    Loss: 0.668

2024-04-24 01:21:24,704 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:21:24,704 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:21:24,730 - 

2024-04-24 01:21:24,730 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:21:32,634 - Epoch: [599][  100/  296]    Overall Loss 0.683043    Objective Loss 0.683043                                        LR 0.000005    Time 0.078955    
2024-04-24 01:21:40,465 - Epoch: [599][  200/  296]    Overall Loss 0.671252    Objective Loss 0.671252                                        LR 0.000005    Time 0.078586    
2024-04-24 01:21:46,702 - Epoch: [599][  296/  296]    Overall Loss 0.656244    Objective Loss 0.656244    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.074146    
2024-04-24 01:21:46,790 - --- validate (epoch=599)-----------
2024-04-24 01:21:46,790 - 3925 samples (32 per mini-batch)
2024-04-24 01:21:55,566 - Epoch: [599][  100/  123]    Loss 0.669468    Top1 78.437500    Top5 97.500000    
2024-04-24 01:21:57,382 - Epoch: [599][  123/  123]    Loss 0.665958    Top1 78.394904    Top5 97.554140    
2024-04-24 01:21:57,490 - ==> Top1: 78.395    Top5: 97.554    Loss: 0.666

2024-04-24 01:21:57,498 - ==> Best [Top1: 78.854   Top5: 97.605   Sparsity:0.00   Params: 371568 on epoch: 561]
2024-04-24 01:21:57,499 - Saving checkpoint to: logs/2024.04.23-154954/checkpoint.pth.tar
2024-04-24 01:21:57,532 - --- test ---------------------
2024-04-24 01:21:57,532 - 3925 samples (32 per mini-batch)
2024-04-24 01:22:07,370 - Test: [  100/  123]    Loss 0.674244    Top1 78.250000    Top5 97.562500    
2024-04-24 01:22:09,371 - Test: [  123/  123]    Loss 0.666547    Top1 78.394904    Top5 97.554140    
2024-04-24 01:22:09,484 - ==> Top1: 78.395    Top5: 97.554    Loss: 0.667

2024-04-24 01:22:09,492 - 
2024-04-24 01:22:09,493 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.23-154954/2024.04.23-154954.log
