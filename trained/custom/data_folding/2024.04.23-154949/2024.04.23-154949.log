2024-04-23 15:49:49,502 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.23-154949/2024.04.23-154949.log
2024-04-23 15:49:53,506 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-04-23 15:49:53,507 - Optimizer Args: {'lr': 0.00032, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-04-23 15:49:53,616 - Dataset sizes:
	training=9469
	validation=3925
	test=3925
2024-04-23 15:49:53,616 - Reading compression schedule from: policies/schedule-cifar100.yaml
2024-04-23 15:49:53,623 - 

2024-04-23 15:49:53,623 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:50:02,557 - Epoch: [0][  100/  296]    Overall Loss 2.222188    Objective Loss 2.222188                                        LR 0.000320    Time 0.089233    
2024-04-23 15:50:17,323 - Epoch: [0][  200/  296]    Overall Loss 2.162136    Objective Loss 2.162136                                        LR 0.000320    Time 0.118346    
2024-04-23 15:50:32,810 - Epoch: [0][  296/  296]    Overall Loss 2.107771    Objective Loss 2.107771    Top1 42.622951    Top5 86.885246    LR 0.000320    Time 0.132216    
2024-04-23 15:50:33,136 - --- validate (epoch=0)-----------
2024-04-23 15:50:33,137 - 3925 samples (32 per mini-batch)
2024-04-23 15:50:53,172 - Epoch: [0][  100/  123]    Loss 1.874660    Top1 37.468750    Top5 83.531250    
2024-04-23 15:50:56,775 - Epoch: [0][  123/  123]    Loss 1.876533    Top1 37.375796    Top5 83.286624    
2024-04-23 15:50:57,112 - ==> Top1: 37.376    Top5: 83.287    Loss: 1.877

2024-04-23 15:50:57,123 - ==> Best [Top1: 37.376   Top5: 83.287   Sparsity:0.00   Params: 370272 on epoch: 0]
2024-04-23 15:50:57,124 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 15:50:57,193 - 

2024-04-23 15:50:57,194 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:51:16,272 - Epoch: [1][  100/  296]    Overall Loss 1.905327    Objective Loss 1.905327                                        LR 0.000320    Time 0.190544    
2024-04-23 15:51:31,044 - Epoch: [1][  200/  296]    Overall Loss 1.870925    Objective Loss 1.870925                                        LR 0.000320    Time 0.169025    
2024-04-23 15:51:50,141 - Epoch: [1][  296/  296]    Overall Loss 1.835716    Objective Loss 1.835716    Top1 45.901639    Top5 90.163934    LR 0.000320    Time 0.178639    
2024-04-23 15:51:50,469 - --- validate (epoch=1)-----------
2024-04-23 15:51:50,471 - 3925 samples (32 per mini-batch)
2024-04-23 15:52:09,642 - Epoch: [1][  100/  123]    Loss 1.694121    Top1 43.093750    Top5 87.250000    
2024-04-23 15:52:13,807 - Epoch: [1][  123/  123]    Loss 1.701493    Top1 42.573248    Top5 87.210191    
2024-04-23 15:52:14,057 - ==> Top1: 42.573    Top5: 87.210    Loss: 1.701

2024-04-23 15:52:14,067 - ==> Best [Top1: 42.573   Top5: 87.210   Sparsity:0.00   Params: 370272 on epoch: 1]
2024-04-23 15:52:14,069 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 15:52:14,153 - 

2024-04-23 15:52:14,154 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:52:33,741 - Epoch: [2][  100/  296]    Overall Loss 1.703063    Objective Loss 1.703063                                        LR 0.000320    Time 0.195623    
2024-04-23 15:52:43,792 - Epoch: [2][  200/  296]    Overall Loss 1.683026    Objective Loss 1.683026                                        LR 0.000320    Time 0.147974    
2024-04-23 15:52:52,461 - Epoch: [2][  296/  296]    Overall Loss 1.671335    Objective Loss 1.671335    Top1 42.622951    Top5 86.885246    LR 0.000320    Time 0.129222    
2024-04-23 15:52:52,581 - --- validate (epoch=2)-----------
2024-04-23 15:52:52,581 - 3925 samples (32 per mini-batch)
2024-04-23 15:53:06,322 - Epoch: [2][  100/  123]    Loss 1.630828    Top1 45.906250    Top5 85.000000    
2024-04-23 15:53:10,318 - Epoch: [2][  123/  123]    Loss 1.618955    Top1 46.547771    Top5 85.375796    
2024-04-23 15:53:10,514 - ==> Top1: 46.548    Top5: 85.376    Loss: 1.619

2024-04-23 15:53:10,522 - ==> Best [Top1: 46.548   Top5: 85.376   Sparsity:0.00   Params: 370272 on epoch: 2]
2024-04-23 15:53:10,523 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 15:53:10,587 - 

2024-04-23 15:53:10,588 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:53:26,257 - Epoch: [3][  100/  296]    Overall Loss 1.600867    Objective Loss 1.600867                                        LR 0.000320    Time 0.156459    
2024-04-23 15:53:39,515 - Epoch: [3][  200/  296]    Overall Loss 1.597807    Objective Loss 1.597807                                        LR 0.000320    Time 0.144415    
2024-04-23 15:53:52,233 - Epoch: [3][  296/  296]    Overall Loss 1.590162    Objective Loss 1.590162    Top1 52.459016    Top5 91.803279    LR 0.000320    Time 0.140477    
2024-04-23 15:53:52,378 - --- validate (epoch=3)-----------
2024-04-23 15:53:52,379 - 3925 samples (32 per mini-batch)
2024-04-23 15:54:08,991 - Epoch: [3][  100/  123]    Loss 1.575159    Top1 47.312500    Top5 86.843750    
2024-04-23 15:54:11,568 - Epoch: [3][  123/  123]    Loss 1.577401    Top1 47.337580    Top5 86.394904    
2024-04-23 15:54:11,821 - ==> Top1: 47.338    Top5: 86.395    Loss: 1.577

2024-04-23 15:54:11,828 - ==> Best [Top1: 47.338   Top5: 86.395   Sparsity:0.00   Params: 370272 on epoch: 3]
2024-04-23 15:54:11,828 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 15:54:11,880 - 

2024-04-23 15:54:11,881 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:54:28,854 - Epoch: [4][  100/  296]    Overall Loss 1.534826    Objective Loss 1.534826                                        LR 0.000320    Time 0.169503    
2024-04-23 15:54:45,286 - Epoch: [4][  200/  296]    Overall Loss 1.530690    Objective Loss 1.530690                                        LR 0.000320    Time 0.166809    
2024-04-23 15:55:00,908 - Epoch: [4][  296/  296]    Overall Loss 1.514894    Objective Loss 1.514894    Top1 55.737705    Top5 90.163934    LR 0.000320    Time 0.165420    
2024-04-23 15:55:01,243 - --- validate (epoch=4)-----------
2024-04-23 15:55:01,244 - 3925 samples (32 per mini-batch)
2024-04-23 15:55:19,603 - Epoch: [4][  100/  123]    Loss 1.411285    Top1 52.656250    Top5 90.656250    
2024-04-23 15:55:23,669 - Epoch: [4][  123/  123]    Loss 1.396717    Top1 53.528662    Top5 90.853503    
2024-04-23 15:55:23,970 - ==> Top1: 53.529    Top5: 90.854    Loss: 1.397

2024-04-23 15:55:23,983 - ==> Best [Top1: 53.529   Top5: 90.854   Sparsity:0.00   Params: 370272 on epoch: 4]
2024-04-23 15:55:23,984 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 15:55:24,064 - 

2024-04-23 15:55:24,065 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:55:41,465 - Epoch: [5][  100/  296]    Overall Loss 1.478098    Objective Loss 1.478098                                        LR 0.000320    Time 0.173779    
2024-04-23 15:55:57,545 - Epoch: [5][  200/  296]    Overall Loss 1.467214    Objective Loss 1.467214                                        LR 0.000320    Time 0.167196    
2024-04-23 15:56:12,453 - Epoch: [5][  296/  296]    Overall Loss 1.477287    Objective Loss 1.477287    Top1 44.262295    Top5 86.885246    LR 0.000320    Time 0.163273    
2024-04-23 15:56:12,907 - --- validate (epoch=5)-----------
2024-04-23 15:56:12,909 - 3925 samples (32 per mini-batch)
2024-04-23 15:56:31,553 - Epoch: [5][  100/  123]    Loss 1.315875    Top1 56.625000    Top5 92.125000    
2024-04-23 15:56:35,231 - Epoch: [5][  123/  123]    Loss 1.315833    Top1 56.407643    Top5 92.000000    
2024-04-23 15:56:35,417 - ==> Top1: 56.408    Top5: 92.000    Loss: 1.316

2024-04-23 15:56:35,425 - ==> Best [Top1: 56.408   Top5: 92.000   Sparsity:0.00   Params: 370272 on epoch: 5]
2024-04-23 15:56:35,426 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 15:56:35,507 - 

2024-04-23 15:56:35,508 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:56:50,001 - Epoch: [6][  100/  296]    Overall Loss 1.474329    Objective Loss 1.474329                                        LR 0.000320    Time 0.144722    
2024-04-23 15:57:05,667 - Epoch: [6][  200/  296]    Overall Loss 1.436905    Objective Loss 1.436905                                        LR 0.000320    Time 0.150591    
2024-04-23 15:57:20,604 - Epoch: [6][  296/  296]    Overall Loss 1.441274    Objective Loss 1.441274    Top1 54.098361    Top5 93.442623    LR 0.000320    Time 0.152150    
2024-04-23 15:57:20,927 - --- validate (epoch=6)-----------
2024-04-23 15:57:20,928 - 3925 samples (32 per mini-batch)
2024-04-23 15:57:36,326 - Epoch: [6][  100/  123]    Loss 1.317208    Top1 56.187500    Top5 92.125000    
2024-04-23 15:57:40,264 - Epoch: [6][  123/  123]    Loss 1.325268    Top1 55.414013    Top5 92.152866    
2024-04-23 15:57:40,521 - ==> Top1: 55.414    Top5: 92.153    Loss: 1.325

2024-04-23 15:57:40,531 - ==> Best [Top1: 56.408   Top5: 92.000   Sparsity:0.00   Params: 370272 on epoch: 5]
2024-04-23 15:57:40,532 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 15:57:40,612 - 

2024-04-23 15:57:40,613 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:57:58,084 - Epoch: [7][  100/  296]    Overall Loss 1.444744    Objective Loss 1.444744                                        LR 0.000320    Time 0.174469    
2024-04-23 15:58:11,520 - Epoch: [7][  200/  296]    Overall Loss 1.437116    Objective Loss 1.437116                                        LR 0.000320    Time 0.154316    
2024-04-23 15:58:22,505 - Epoch: [7][  296/  296]    Overall Loss 1.427456    Objective Loss 1.427456    Top1 42.622951    Top5 86.885246    LR 0.000320    Time 0.141323    
2024-04-23 15:58:22,733 - --- validate (epoch=7)-----------
2024-04-23 15:58:22,734 - 3925 samples (32 per mini-batch)
2024-04-23 15:58:40,583 - Epoch: [7][  100/  123]    Loss 1.323367    Top1 56.406250    Top5 91.531250    
2024-04-23 15:58:43,599 - Epoch: [7][  123/  123]    Loss 1.330845    Top1 56.127389    Top5 91.312102    
2024-04-23 15:58:43,776 - ==> Top1: 56.127    Top5: 91.312    Loss: 1.331

2024-04-23 15:58:43,785 - ==> Best [Top1: 56.408   Top5: 92.000   Sparsity:0.00   Params: 370272 on epoch: 5]
2024-04-23 15:58:43,786 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 15:58:43,836 - 

2024-04-23 15:58:43,837 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:58:59,203 - Epoch: [8][  100/  296]    Overall Loss 1.396613    Objective Loss 1.396613                                        LR 0.000320    Time 0.153436    
2024-04-23 15:59:15,247 - Epoch: [8][  200/  296]    Overall Loss 1.401841    Objective Loss 1.401841                                        LR 0.000320    Time 0.156829    
2024-04-23 15:59:31,090 - Epoch: [8][  296/  296]    Overall Loss 1.402218    Objective Loss 1.402218    Top1 59.016393    Top5 95.081967    LR 0.000320    Time 0.159422    
2024-04-23 15:59:31,451 - --- validate (epoch=8)-----------
2024-04-23 15:59:31,454 - 3925 samples (32 per mini-batch)
2024-04-23 15:59:51,031 - Epoch: [8][  100/  123]    Loss 1.282083    Top1 57.468750    Top5 92.500000    
2024-04-23 15:59:55,295 - Epoch: [8][  123/  123]    Loss 1.282528    Top1 57.401274    Top5 92.484076    
2024-04-23 15:59:55,591 - ==> Top1: 57.401    Top5: 92.484    Loss: 1.283

2024-04-23 15:59:55,601 - ==> Best [Top1: 57.401   Top5: 92.484   Sparsity:0.00   Params: 370272 on epoch: 8]
2024-04-23 15:59:55,602 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 15:59:55,690 - 

2024-04-23 15:59:55,691 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:00:13,610 - Epoch: [9][  100/  296]    Overall Loss 1.383253    Objective Loss 1.383253                                        LR 0.000320    Time 0.178938    
2024-04-23 16:00:31,199 - Epoch: [9][  200/  296]    Overall Loss 1.364024    Objective Loss 1.364024                                        LR 0.000320    Time 0.177311    
2024-04-23 16:00:45,867 - Epoch: [9][  296/  296]    Overall Loss 1.354591    Objective Loss 1.354591    Top1 54.098361    Top5 90.163934    LR 0.000320    Time 0.169288    
2024-04-23 16:00:46,216 - --- validate (epoch=9)-----------
2024-04-23 16:00:46,218 - 3925 samples (32 per mini-batch)
2024-04-23 16:01:05,011 - Epoch: [9][  100/  123]    Loss 1.141596    Top1 62.375000    Top5 93.937500    
2024-04-23 16:01:09,186 - Epoch: [9][  123/  123]    Loss 1.137452    Top1 62.496815    Top5 93.961783    
2024-04-23 16:01:09,545 - ==> Top1: 62.497    Top5: 93.962    Loss: 1.137

2024-04-23 16:01:09,556 - ==> Best [Top1: 62.497   Top5: 93.962   Sparsity:0.00   Params: 370272 on epoch: 9]
2024-04-23 16:01:09,557 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:01:09,666 - 

2024-04-23 16:01:09,668 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:01:27,720 - Epoch: [10][  100/  296]    Overall Loss 1.380565    Objective Loss 1.380565                                        LR 0.000320    Time 0.180281    
2024-04-23 16:01:46,179 - Epoch: [10][  200/  296]    Overall Loss 1.353785    Objective Loss 1.353785                                        LR 0.000320    Time 0.182331    
2024-04-23 16:02:00,664 - Epoch: [10][  296/  296]    Overall Loss 1.349011    Objective Loss 1.349011    Top1 42.622951    Top5 90.163934    LR 0.000320    Time 0.172058    
2024-04-23 16:02:01,167 - --- validate (epoch=10)-----------
2024-04-23 16:02:01,168 - 3925 samples (32 per mini-batch)
2024-04-23 16:02:23,180 - Epoch: [10][  100/  123]    Loss 1.214594    Top1 58.906250    Top5 93.000000    
2024-04-23 16:02:26,794 - Epoch: [10][  123/  123]    Loss 1.199878    Top1 59.388535    Top5 93.299363    
2024-04-23 16:02:26,944 - ==> Top1: 59.389    Top5: 93.299    Loss: 1.200

2024-04-23 16:02:26,957 - ==> Best [Top1: 62.497   Top5: 93.962   Sparsity:0.00   Params: 370272 on epoch: 9]
2024-04-23 16:02:26,958 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:02:27,059 - 

2024-04-23 16:02:27,060 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:02:46,594 - Epoch: [11][  100/  296]    Overall Loss 1.298678    Objective Loss 1.298678                                        LR 0.000320    Time 0.195132    
2024-04-23 16:03:04,043 - Epoch: [11][  200/  296]    Overall Loss 1.314901    Objective Loss 1.314901                                        LR 0.000320    Time 0.184700    
2024-04-23 16:03:20,323 - Epoch: [11][  296/  296]    Overall Loss 1.321779    Objective Loss 1.321779    Top1 50.819672    Top5 93.442623    LR 0.000320    Time 0.179727    
2024-04-23 16:03:20,690 - --- validate (epoch=11)-----------
2024-04-23 16:03:20,692 - 3925 samples (32 per mini-batch)
2024-04-23 16:03:40,456 - Epoch: [11][  100/  123]    Loss 1.081444    Top1 64.531250    Top5 94.656250    
2024-04-23 16:03:45,228 - Epoch: [11][  123/  123]    Loss 1.097970    Top1 64.203822    Top5 94.420382    
2024-04-23 16:03:45,584 - ==> Top1: 64.204    Top5: 94.420    Loss: 1.098

2024-04-23 16:03:45,600 - ==> Best [Top1: 64.204   Top5: 94.420   Sparsity:0.00   Params: 370272 on epoch: 11]
2024-04-23 16:03:45,602 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:03:45,736 - 

2024-04-23 16:03:45,738 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:04:04,718 - Epoch: [12][  100/  296]    Overall Loss 1.316517    Objective Loss 1.316517                                        LR 0.000320    Time 0.189528    
2024-04-23 16:04:20,121 - Epoch: [12][  200/  296]    Overall Loss 1.295995    Objective Loss 1.295995                                        LR 0.000320    Time 0.171678    
2024-04-23 16:04:34,010 - Epoch: [12][  296/  296]    Overall Loss 1.307238    Objective Loss 1.307238    Top1 57.377049    Top5 90.163934    LR 0.000320    Time 0.162852    
2024-04-23 16:04:34,339 - --- validate (epoch=12)-----------
2024-04-23 16:04:34,341 - 3925 samples (32 per mini-batch)
2024-04-23 16:04:52,384 - Epoch: [12][  100/  123]    Loss 1.131532    Top1 63.593750    Top5 93.593750    
2024-04-23 16:04:55,885 - Epoch: [12][  123/  123]    Loss 1.128922    Top1 63.719745    Top5 93.656051    
2024-04-23 16:04:56,214 - ==> Top1: 63.720    Top5: 93.656    Loss: 1.129

2024-04-23 16:04:56,222 - ==> Best [Top1: 64.204   Top5: 94.420   Sparsity:0.00   Params: 370272 on epoch: 11]
2024-04-23 16:04:56,223 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:04:56,280 - 

2024-04-23 16:04:56,282 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:05:12,531 - Epoch: [13][  100/  296]    Overall Loss 1.250626    Objective Loss 1.250626                                        LR 0.000320    Time 0.162260    
2024-04-23 16:05:24,996 - Epoch: [13][  200/  296]    Overall Loss 1.274525    Objective Loss 1.274525                                        LR 0.000320    Time 0.143352    
2024-04-23 16:05:39,274 - Epoch: [13][  296/  296]    Overall Loss 1.275710    Objective Loss 1.275710    Top1 54.098361    Top5 95.081967    LR 0.000320    Time 0.145026    
2024-04-23 16:05:39,586 - --- validate (epoch=13)-----------
2024-04-23 16:05:39,587 - 3925 samples (32 per mini-batch)
2024-04-23 16:05:55,989 - Epoch: [13][  100/  123]    Loss 1.112473    Top1 63.187500    Top5 93.656250    
2024-04-23 16:05:59,819 - Epoch: [13][  123/  123]    Loss 1.117057    Top1 62.828025    Top5 93.656051    
2024-04-23 16:06:00,106 - ==> Top1: 62.828    Top5: 93.656    Loss: 1.117

2024-04-23 16:06:00,118 - ==> Best [Top1: 64.204   Top5: 94.420   Sparsity:0.00   Params: 370272 on epoch: 11]
2024-04-23 16:06:00,119 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:06:00,173 - 

2024-04-23 16:06:00,175 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:06:15,807 - Epoch: [14][  100/  296]    Overall Loss 1.288231    Objective Loss 1.288231                                        LR 0.000320    Time 0.156100    
2024-04-23 16:06:29,113 - Epoch: [14][  200/  296]    Overall Loss 1.270728    Objective Loss 1.270728                                        LR 0.000320    Time 0.144468    
2024-04-23 16:06:42,971 - Epoch: [14][  296/  296]    Overall Loss 1.275207    Objective Loss 1.275207    Top1 45.901639    Top5 91.803279    LR 0.000320    Time 0.144354    
2024-04-23 16:06:43,266 - --- validate (epoch=14)-----------
2024-04-23 16:06:43,269 - 3925 samples (32 per mini-batch)
2024-04-23 16:07:00,693 - Epoch: [14][  100/  123]    Loss 1.145040    Top1 61.343750    Top5 93.531250    
2024-04-23 16:07:04,130 - Epoch: [14][  123/  123]    Loss 1.140885    Top1 61.579618    Top5 93.503185    
2024-04-23 16:07:04,433 - ==> Top1: 61.580    Top5: 93.503    Loss: 1.141

2024-04-23 16:07:04,449 - ==> Best [Top1: 64.204   Top5: 94.420   Sparsity:0.00   Params: 370272 on epoch: 11]
2024-04-23 16:07:04,450 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:07:04,501 - 

2024-04-23 16:07:04,502 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:07:21,238 - Epoch: [15][  100/  296]    Overall Loss 1.255458    Objective Loss 1.255458                                        LR 0.000320    Time 0.167129    
2024-04-23 16:07:35,285 - Epoch: [15][  200/  296]    Overall Loss 1.247584    Objective Loss 1.247584                                        LR 0.000320    Time 0.153695    
2024-04-23 16:07:48,987 - Epoch: [15][  296/  296]    Overall Loss 1.238494    Objective Loss 1.238494    Top1 60.655738    Top5 93.442623    LR 0.000320    Time 0.150067    
2024-04-23 16:07:49,257 - --- validate (epoch=15)-----------
2024-04-23 16:07:49,258 - 3925 samples (32 per mini-batch)
2024-04-23 16:08:06,507 - Epoch: [15][  100/  123]    Loss 1.140040    Top1 61.531250    Top5 93.437500    
2024-04-23 16:08:09,899 - Epoch: [15][  123/  123]    Loss 1.139640    Top1 61.834395    Top5 93.477707    
2024-04-23 16:08:10,189 - ==> Top1: 61.834    Top5: 93.478    Loss: 1.140

2024-04-23 16:08:10,200 - ==> Best [Top1: 64.204   Top5: 94.420   Sparsity:0.00   Params: 370272 on epoch: 11]
2024-04-23 16:08:10,201 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:08:10,257 - 

2024-04-23 16:08:10,258 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:08:25,961 - Epoch: [16][  100/  296]    Overall Loss 1.179940    Objective Loss 1.179940                                        LR 0.000320    Time 0.156801    
2024-04-23 16:08:39,967 - Epoch: [16][  200/  296]    Overall Loss 1.214207    Objective Loss 1.214207                                        LR 0.000320    Time 0.148309    
2024-04-23 16:08:53,232 - Epoch: [16][  296/  296]    Overall Loss 1.220743    Objective Loss 1.220743    Top1 67.213115    Top5 90.163934    LR 0.000320    Time 0.144946    
2024-04-23 16:08:53,555 - --- validate (epoch=16)-----------
2024-04-23 16:08:53,557 - 3925 samples (32 per mini-batch)
2024-04-23 16:09:10,435 - Epoch: [16][  100/  123]    Loss 1.101622    Top1 63.187500    Top5 94.531250    
2024-04-23 16:09:14,050 - Epoch: [16][  123/  123]    Loss 1.095800    Top1 63.210191    Top5 94.522293    
2024-04-23 16:09:14,336 - ==> Top1: 63.210    Top5: 94.522    Loss: 1.096

2024-04-23 16:09:14,344 - ==> Best [Top1: 64.204   Top5: 94.420   Sparsity:0.00   Params: 370272 on epoch: 11]
2024-04-23 16:09:14,344 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:09:14,402 - 

2024-04-23 16:09:14,403 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:09:31,031 - Epoch: [17][  100/  296]    Overall Loss 1.225345    Objective Loss 1.225345                                        LR 0.000320    Time 0.166041    
2024-04-23 16:09:45,070 - Epoch: [17][  200/  296]    Overall Loss 1.218281    Objective Loss 1.218281                                        LR 0.000320    Time 0.153106    
2024-04-23 16:09:57,690 - Epoch: [17][  296/  296]    Overall Loss 1.222198    Objective Loss 1.222198    Top1 57.377049    Top5 91.803279    LR 0.000320    Time 0.146012    
2024-04-23 16:09:58,014 - --- validate (epoch=17)-----------
2024-04-23 16:09:58,016 - 3925 samples (32 per mini-batch)
2024-04-23 16:10:15,775 - Epoch: [17][  100/  123]    Loss 1.191155    Top1 60.187500    Top5 92.531250    
2024-04-23 16:10:19,558 - Epoch: [17][  123/  123]    Loss 1.173206    Top1 60.993631    Top5 92.764331    
2024-04-23 16:10:19,930 - ==> Top1: 60.994    Top5: 92.764    Loss: 1.173

2024-04-23 16:10:19,942 - ==> Best [Top1: 64.204   Top5: 94.420   Sparsity:0.00   Params: 370272 on epoch: 11]
2024-04-23 16:10:19,943 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:10:20,023 - 

2024-04-23 16:10:20,025 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:10:36,543 - Epoch: [18][  100/  296]    Overall Loss 1.229682    Objective Loss 1.229682                                        LR 0.000320    Time 0.164921    
2024-04-23 16:10:48,904 - Epoch: [18][  200/  296]    Overall Loss 1.221604    Objective Loss 1.221604                                        LR 0.000320    Time 0.144156    
2024-04-23 16:11:03,108 - Epoch: [18][  296/  296]    Overall Loss 1.217739    Objective Loss 1.217739    Top1 68.852459    Top5 93.442623    LR 0.000320    Time 0.145319    
2024-04-23 16:11:03,443 - --- validate (epoch=18)-----------
2024-04-23 16:11:03,445 - 3925 samples (32 per mini-batch)
2024-04-23 16:11:21,841 - Epoch: [18][  100/  123]    Loss 1.010642    Top1 66.937500    Top5 95.125000    
2024-04-23 16:11:25,528 - Epoch: [18][  123/  123]    Loss 1.012712    Top1 67.133758    Top5 95.031847    
2024-04-23 16:11:25,854 - ==> Top1: 67.134    Top5: 95.032    Loss: 1.013

2024-04-23 16:11:25,869 - ==> Best [Top1: 67.134   Top5: 95.032   Sparsity:0.00   Params: 370272 on epoch: 18]
2024-04-23 16:11:25,870 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:11:25,968 - 

2024-04-23 16:11:25,969 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:11:41,963 - Epoch: [19][  100/  296]    Overall Loss 1.218180    Objective Loss 1.218180                                        LR 0.000320    Time 0.159726    
2024-04-23 16:11:55,952 - Epoch: [19][  200/  296]    Overall Loss 1.206629    Objective Loss 1.206629                                        LR 0.000320    Time 0.149693    
2024-04-23 16:12:09,260 - Epoch: [19][  296/  296]    Overall Loss 1.201479    Objective Loss 1.201479    Top1 70.491803    Top5 98.360656    LR 0.000320    Time 0.146035    
2024-04-23 16:12:09,588 - --- validate (epoch=19)-----------
2024-04-23 16:12:09,589 - 3925 samples (32 per mini-batch)
2024-04-23 16:12:29,024 - Epoch: [19][  100/  123]    Loss 1.034342    Top1 65.937500    Top5 94.875000    
2024-04-23 16:12:33,406 - Epoch: [19][  123/  123]    Loss 1.027310    Top1 66.471338    Top5 94.904459    
2024-04-23 16:12:33,692 - ==> Top1: 66.471    Top5: 94.904    Loss: 1.027

2024-04-23 16:12:33,702 - ==> Best [Top1: 67.134   Top5: 95.032   Sparsity:0.00   Params: 370272 on epoch: 18]
2024-04-23 16:12:33,702 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:12:33,747 - 

2024-04-23 16:12:33,747 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:12:50,284 - Epoch: [20][  100/  296]    Overall Loss 1.225469    Objective Loss 1.225469                                        LR 0.000320    Time 0.165141    
2024-04-23 16:13:05,185 - Epoch: [20][  200/  296]    Overall Loss 1.202618    Objective Loss 1.202618                                        LR 0.000320    Time 0.156961    
2024-04-23 16:13:17,625 - Epoch: [20][  296/  296]    Overall Loss 1.198886    Objective Loss 1.198886    Top1 60.655738    Top5 91.803279    LR 0.000320    Time 0.148010    
2024-04-23 16:13:17,963 - --- validate (epoch=20)-----------
2024-04-23 16:13:17,964 - 3925 samples (32 per mini-batch)
2024-04-23 16:13:35,731 - Epoch: [20][  100/  123]    Loss 1.001612    Top1 67.187500    Top5 95.343750    
2024-04-23 16:13:39,041 - Epoch: [20][  123/  123]    Loss 0.999063    Top1 67.108280    Top5 95.337580    
2024-04-23 16:13:39,346 - ==> Top1: 67.108    Top5: 95.338    Loss: 0.999

2024-04-23 16:13:39,358 - ==> Best [Top1: 67.134   Top5: 95.032   Sparsity:0.00   Params: 370272 on epoch: 18]
2024-04-23 16:13:39,358 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:13:39,423 - 

2024-04-23 16:13:39,424 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:13:55,211 - Epoch: [21][  100/  296]    Overall Loss 1.188904    Objective Loss 1.188904                                        LR 0.000320    Time 0.157638    
2024-04-23 16:14:10,428 - Epoch: [21][  200/  296]    Overall Loss 1.207585    Objective Loss 1.207585                                        LR 0.000320    Time 0.154784    
2024-04-23 16:14:22,751 - Epoch: [21][  296/  296]    Overall Loss 1.199936    Objective Loss 1.199936    Top1 70.491803    Top5 96.721311    LR 0.000320    Time 0.146152    
2024-04-23 16:14:23,062 - --- validate (epoch=21)-----------
2024-04-23 16:14:23,063 - 3925 samples (32 per mini-batch)
2024-04-23 16:14:40,793 - Epoch: [21][  100/  123]    Loss 1.017959    Top1 66.437500    Top5 95.000000    
2024-04-23 16:14:44,296 - Epoch: [21][  123/  123]    Loss 1.033617    Top1 66.063694    Top5 94.828025    
2024-04-23 16:14:44,582 - ==> Top1: 66.064    Top5: 94.828    Loss: 1.034

2024-04-23 16:14:44,589 - ==> Best [Top1: 67.134   Top5: 95.032   Sparsity:0.00   Params: 370272 on epoch: 18]
2024-04-23 16:14:44,590 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:14:44,653 - 

2024-04-23 16:14:44,654 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:15:00,020 - Epoch: [22][  100/  296]    Overall Loss 1.180213    Objective Loss 1.180213                                        LR 0.000320    Time 0.153431    
2024-04-23 16:15:14,009 - Epoch: [22][  200/  296]    Overall Loss 1.172419    Objective Loss 1.172419                                        LR 0.000320    Time 0.146551    
2024-04-23 16:15:26,236 - Epoch: [22][  296/  296]    Overall Loss 1.179671    Objective Loss 1.179671    Top1 65.573770    Top5 91.803279    LR 0.000320    Time 0.140258    
2024-04-23 16:15:26,672 - --- validate (epoch=22)-----------
2024-04-23 16:15:26,674 - 3925 samples (32 per mini-batch)
2024-04-23 16:15:44,949 - Epoch: [22][  100/  123]    Loss 1.054280    Top1 65.062500    Top5 94.968750    
2024-04-23 16:15:48,508 - Epoch: [22][  123/  123]    Loss 1.053713    Top1 65.019108    Top5 94.649682    
2024-04-23 16:15:48,753 - ==> Top1: 65.019    Top5: 94.650    Loss: 1.054

2024-04-23 16:15:48,760 - ==> Best [Top1: 67.134   Top5: 95.032   Sparsity:0.00   Params: 370272 on epoch: 18]
2024-04-23 16:15:48,761 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:15:48,808 - 

2024-04-23 16:15:48,809 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:16:03,868 - Epoch: [23][  100/  296]    Overall Loss 1.160924    Objective Loss 1.160924                                        LR 0.000320    Time 0.150365    
2024-04-23 16:16:17,710 - Epoch: [23][  200/  296]    Overall Loss 1.160399    Objective Loss 1.160399                                        LR 0.000320    Time 0.144278    
2024-04-23 16:16:30,411 - Epoch: [23][  296/  296]    Overall Loss 1.169115    Objective Loss 1.169115    Top1 57.377049    Top5 90.163934    LR 0.000320    Time 0.140323    
2024-04-23 16:16:30,654 - --- validate (epoch=23)-----------
2024-04-23 16:16:30,655 - 3925 samples (32 per mini-batch)
2024-04-23 16:16:48,493 - Epoch: [23][  100/  123]    Loss 1.180390    Top1 61.656250    Top5 92.968750    
2024-04-23 16:16:51,627 - Epoch: [23][  123/  123]    Loss 1.180551    Top1 61.528662    Top5 92.917197    
2024-04-23 16:16:51,911 - ==> Top1: 61.529    Top5: 92.917    Loss: 1.181

2024-04-23 16:16:51,920 - ==> Best [Top1: 67.134   Top5: 95.032   Sparsity:0.00   Params: 370272 on epoch: 18]
2024-04-23 16:16:51,921 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:16:51,985 - 

2024-04-23 16:16:51,986 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:17:04,804 - Epoch: [24][  100/  296]    Overall Loss 1.151837    Objective Loss 1.151837                                        LR 0.000320    Time 0.127947    
2024-04-23 16:17:18,272 - Epoch: [24][  200/  296]    Overall Loss 1.156513    Objective Loss 1.156513                                        LR 0.000320    Time 0.131211    
2024-04-23 16:17:29,711 - Epoch: [24][  296/  296]    Overall Loss 1.154226    Objective Loss 1.154226    Top1 60.655738    Top5 90.163934    LR 0.000320    Time 0.127237    
2024-04-23 16:17:30,063 - --- validate (epoch=24)-----------
2024-04-23 16:17:30,065 - 3925 samples (32 per mini-batch)
2024-04-23 16:17:46,844 - Epoch: [24][  100/  123]    Loss 0.980882    Top1 67.031250    Top5 95.218750    
2024-04-23 16:17:50,229 - Epoch: [24][  123/  123]    Loss 0.975936    Top1 67.210191    Top5 95.210191    
2024-04-23 16:17:50,476 - ==> Top1: 67.210    Top5: 95.210    Loss: 0.976

2024-04-23 16:17:50,486 - ==> Best [Top1: 67.210   Top5: 95.210   Sparsity:0.00   Params: 370272 on epoch: 24]
2024-04-23 16:17:50,487 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:17:50,555 - 

2024-04-23 16:17:50,556 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:18:05,556 - Epoch: [25][  100/  296]    Overall Loss 1.160989    Objective Loss 1.160989                                        LR 0.000320    Time 0.149768    
2024-04-23 16:18:20,349 - Epoch: [25][  200/  296]    Overall Loss 1.157147    Objective Loss 1.157147                                        LR 0.000320    Time 0.148708    
2024-04-23 16:18:33,025 - Epoch: [25][  296/  296]    Overall Loss 1.157099    Objective Loss 1.157099    Top1 54.098361    Top5 93.442623    LR 0.000320    Time 0.143230    
2024-04-23 16:18:33,382 - --- validate (epoch=25)-----------
2024-04-23 16:18:33,384 - 3925 samples (32 per mini-batch)
2024-04-23 16:18:49,968 - Epoch: [25][  100/  123]    Loss 0.996368    Top1 67.437500    Top5 95.312500    
2024-04-23 16:18:52,741 - Epoch: [25][  123/  123]    Loss 0.986730    Top1 67.745223    Top5 95.439490    
2024-04-23 16:18:53,019 - ==> Top1: 67.745    Top5: 95.439    Loss: 0.987

2024-04-23 16:18:53,029 - ==> Best [Top1: 67.745   Top5: 95.439   Sparsity:0.00   Params: 370272 on epoch: 25]
2024-04-23 16:18:53,030 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:18:53,092 - 

2024-04-23 16:18:53,093 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:19:06,698 - Epoch: [26][  100/  296]    Overall Loss 1.141682    Objective Loss 1.141682                                        LR 0.000320    Time 0.135810    
2024-04-23 16:19:19,600 - Epoch: [26][  200/  296]    Overall Loss 1.140830    Objective Loss 1.140830                                        LR 0.000320    Time 0.132304    
2024-04-23 16:19:30,017 - Epoch: [26][  296/  296]    Overall Loss 1.145090    Objective Loss 1.145090    Top1 63.934426    Top5 93.442623    LR 0.000320    Time 0.124521    
2024-04-23 16:19:30,336 - --- validate (epoch=26)-----------
2024-04-23 16:19:30,337 - 3925 samples (32 per mini-batch)
2024-04-23 16:19:48,977 - Epoch: [26][  100/  123]    Loss 1.060375    Top1 65.093750    Top5 94.500000    
2024-04-23 16:19:51,782 - Epoch: [26][  123/  123]    Loss 1.046414    Top1 65.528662    Top5 94.598726    
2024-04-23 16:19:52,013 - ==> Top1: 65.529    Top5: 94.599    Loss: 1.046

2024-04-23 16:19:52,022 - ==> Best [Top1: 67.745   Top5: 95.439   Sparsity:0.00   Params: 370272 on epoch: 25]
2024-04-23 16:19:52,022 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:19:52,065 - 

2024-04-23 16:19:52,066 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:20:04,705 - Epoch: [27][  100/  296]    Overall Loss 1.139385    Objective Loss 1.139385                                        LR 0.000320    Time 0.126159    
2024-04-23 16:20:20,478 - Epoch: [27][  200/  296]    Overall Loss 1.136954    Objective Loss 1.136954                                        LR 0.000320    Time 0.141834    
2024-04-23 16:20:34,230 - Epoch: [27][  296/  296]    Overall Loss 1.136541    Objective Loss 1.136541    Top1 75.409836    Top5 98.360656    LR 0.000320    Time 0.142224    
2024-04-23 16:20:34,557 - --- validate (epoch=27)-----------
2024-04-23 16:20:34,558 - 3925 samples (32 per mini-batch)
2024-04-23 16:20:51,858 - Epoch: [27][  100/  123]    Loss 1.012058    Top1 66.750000    Top5 94.656250    
2024-04-23 16:20:55,462 - Epoch: [27][  123/  123]    Loss 1.010042    Top1 66.980892    Top5 94.598726    
2024-04-23 16:20:55,744 - ==> Top1: 66.981    Top5: 94.599    Loss: 1.010

2024-04-23 16:20:55,756 - ==> Best [Top1: 67.745   Top5: 95.439   Sparsity:0.00   Params: 370272 on epoch: 25]
2024-04-23 16:20:55,757 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:20:55,815 - 

2024-04-23 16:20:55,816 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:21:09,857 - Epoch: [28][  100/  296]    Overall Loss 1.109973    Objective Loss 1.109973                                        LR 0.000320    Time 0.140181    
2024-04-23 16:21:24,121 - Epoch: [28][  200/  296]    Overall Loss 1.103457    Objective Loss 1.103457                                        LR 0.000320    Time 0.141304    
2024-04-23 16:21:36,808 - Epoch: [28][  296/  296]    Overall Loss 1.110013    Objective Loss 1.110013    Top1 50.819672    Top5 86.885246    LR 0.000320    Time 0.138265    
2024-04-23 16:21:37,112 - --- validate (epoch=28)-----------
2024-04-23 16:21:37,114 - 3925 samples (32 per mini-batch)
2024-04-23 16:21:54,822 - Epoch: [28][  100/  123]    Loss 0.945192    Top1 68.281250    Top5 95.625000    
2024-04-23 16:21:58,426 - Epoch: [28][  123/  123]    Loss 0.945405    Top1 68.458599    Top5 95.363057    
2024-04-23 16:21:58,714 - ==> Top1: 68.459    Top5: 95.363    Loss: 0.945

2024-04-23 16:21:58,725 - ==> Best [Top1: 68.459   Top5: 95.363   Sparsity:0.00   Params: 370272 on epoch: 28]
2024-04-23 16:21:58,725 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:21:58,799 - 

2024-04-23 16:21:58,800 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:22:15,296 - Epoch: [29][  100/  296]    Overall Loss 1.100110    Objective Loss 1.100110                                        LR 0.000320    Time 0.164721    
2024-04-23 16:22:29,923 - Epoch: [29][  200/  296]    Overall Loss 1.110717    Objective Loss 1.110717                                        LR 0.000320    Time 0.155382    
2024-04-23 16:22:42,889 - Epoch: [29][  296/  296]    Overall Loss 1.116756    Objective Loss 1.116756    Top1 57.377049    Top5 85.245902    LR 0.000320    Time 0.148723    
2024-04-23 16:22:43,208 - --- validate (epoch=29)-----------
2024-04-23 16:22:43,210 - 3925 samples (32 per mini-batch)
2024-04-23 16:23:01,045 - Epoch: [29][  100/  123]    Loss 1.235555    Top1 58.906250    Top5 93.906250    
2024-04-23 16:23:04,693 - Epoch: [29][  123/  123]    Loss 1.256714    Top1 58.649682    Top5 93.579618    
2024-04-23 16:23:05,064 - ==> Top1: 58.650    Top5: 93.580    Loss: 1.257

2024-04-23 16:23:05,076 - ==> Best [Top1: 68.459   Top5: 95.363   Sparsity:0.00   Params: 370272 on epoch: 28]
2024-04-23 16:23:05,077 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:23:05,136 - 

2024-04-23 16:23:05,137 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:23:20,972 - Epoch: [30][  100/  296]    Overall Loss 1.108997    Objective Loss 1.108997                                        LR 0.000320    Time 0.158073    
2024-04-23 16:23:36,171 - Epoch: [30][  200/  296]    Overall Loss 1.110333    Objective Loss 1.110333                                        LR 0.000320    Time 0.154925    
2024-04-23 16:23:49,445 - Epoch: [30][  296/  296]    Overall Loss 1.107294    Objective Loss 1.107294    Top1 60.655738    Top5 96.721311    LR 0.000320    Time 0.149450    
2024-04-23 16:23:49,762 - --- validate (epoch=30)-----------
2024-04-23 16:23:49,764 - 3925 samples (32 per mini-batch)
2024-04-23 16:24:06,970 - Epoch: [30][  100/  123]    Loss 0.980533    Top1 68.593750    Top5 95.281250    
2024-04-23 16:24:10,620 - Epoch: [30][  123/  123]    Loss 0.972369    Top1 68.687898    Top5 95.312102    
2024-04-23 16:24:10,875 - ==> Top1: 68.688    Top5: 95.312    Loss: 0.972

2024-04-23 16:24:10,886 - ==> Best [Top1: 68.688   Top5: 95.312   Sparsity:0.00   Params: 370272 on epoch: 30]
2024-04-23 16:24:10,887 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:24:10,958 - 

2024-04-23 16:24:10,959 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:24:27,235 - Epoch: [31][  100/  296]    Overall Loss 1.075188    Objective Loss 1.075188                                        LR 0.000320    Time 0.162521    
2024-04-23 16:24:41,521 - Epoch: [31][  200/  296]    Overall Loss 1.095695    Objective Loss 1.095695                                        LR 0.000320    Time 0.152579    
2024-04-23 16:24:54,858 - Epoch: [31][  296/  296]    Overall Loss 1.099047    Objective Loss 1.099047    Top1 54.098361    Top5 93.442623    LR 0.000320    Time 0.148086    
2024-04-23 16:24:55,185 - --- validate (epoch=31)-----------
2024-04-23 16:24:55,186 - 3925 samples (32 per mini-batch)
2024-04-23 16:25:11,380 - Epoch: [31][  100/  123]    Loss 0.977755    Top1 68.437500    Top5 95.250000    
2024-04-23 16:25:14,671 - Epoch: [31][  123/  123]    Loss 0.969448    Top1 68.738854    Top5 95.388535    
2024-04-23 16:25:14,946 - ==> Top1: 68.739    Top5: 95.389    Loss: 0.969

2024-04-23 16:25:14,955 - ==> Best [Top1: 68.739   Top5: 95.389   Sparsity:0.00   Params: 370272 on epoch: 31]
2024-04-23 16:25:14,955 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:25:15,023 - 

2024-04-23 16:25:15,024 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:25:31,619 - Epoch: [32][  100/  296]    Overall Loss 1.102891    Objective Loss 1.102891                                        LR 0.000320    Time 0.165721    
2024-04-23 16:25:45,477 - Epoch: [32][  200/  296]    Overall Loss 1.107097    Objective Loss 1.107097                                        LR 0.000320    Time 0.152044    
2024-04-23 16:25:59,893 - Epoch: [32][  296/  296]    Overall Loss 1.100562    Objective Loss 1.100562    Top1 63.934426    Top5 91.803279    LR 0.000320    Time 0.151363    
2024-04-23 16:26:00,275 - --- validate (epoch=32)-----------
2024-04-23 16:26:00,276 - 3925 samples (32 per mini-batch)
2024-04-23 16:26:22,012 - Epoch: [32][  100/  123]    Loss 0.966189    Top1 66.968750    Top5 95.906250    
2024-04-23 16:26:25,670 - Epoch: [32][  123/  123]    Loss 0.965005    Top1 67.006369    Top5 95.770701    
2024-04-23 16:26:26,012 - ==> Top1: 67.006    Top5: 95.771    Loss: 0.965

2024-04-23 16:26:26,025 - ==> Best [Top1: 68.739   Top5: 95.389   Sparsity:0.00   Params: 370272 on epoch: 31]
2024-04-23 16:26:26,026 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:26:26,083 - 

2024-04-23 16:26:26,085 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:26:44,454 - Epoch: [33][  100/  296]    Overall Loss 1.102612    Objective Loss 1.102612                                        LR 0.000320    Time 0.183462    
2024-04-23 16:27:01,172 - Epoch: [33][  200/  296]    Overall Loss 1.082157    Objective Loss 1.082157                                        LR 0.000320    Time 0.175203    
2024-04-23 16:27:16,246 - Epoch: [33][  296/  296]    Overall Loss 1.094569    Objective Loss 1.094569    Top1 63.934426    Top5 90.163934    LR 0.000320    Time 0.169236    
2024-04-23 16:27:16,618 - --- validate (epoch=33)-----------
2024-04-23 16:27:16,620 - 3925 samples (32 per mini-batch)
2024-04-23 16:27:33,644 - Epoch: [33][  100/  123]    Loss 0.947394    Top1 68.812500    Top5 95.687500    
2024-04-23 16:27:36,621 - Epoch: [33][  123/  123]    Loss 0.948571    Top1 68.968153    Top5 95.617834    
2024-04-23 16:27:36,959 - ==> Top1: 68.968    Top5: 95.618    Loss: 0.949

2024-04-23 16:27:36,968 - ==> Best [Top1: 68.968   Top5: 95.618   Sparsity:0.00   Params: 370272 on epoch: 33]
2024-04-23 16:27:36,968 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:27:37,014 - 

2024-04-23 16:27:37,015 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:27:54,022 - Epoch: [34][  100/  296]    Overall Loss 1.065205    Objective Loss 1.065205                                        LR 0.000320    Time 0.169836    
2024-04-23 16:28:06,979 - Epoch: [34][  200/  296]    Overall Loss 1.070920    Objective Loss 1.070920                                        LR 0.000320    Time 0.149596    
2024-04-23 16:28:20,558 - Epoch: [34][  296/  296]    Overall Loss 1.068748    Objective Loss 1.068748    Top1 65.573770    Top5 93.442623    LR 0.000320    Time 0.146881    
2024-04-23 16:28:20,873 - --- validate (epoch=34)-----------
2024-04-23 16:28:20,875 - 3925 samples (32 per mini-batch)
2024-04-23 16:28:37,674 - Epoch: [34][  100/  123]    Loss 0.927857    Top1 70.000000    Top5 95.656250    
2024-04-23 16:28:41,221 - Epoch: [34][  123/  123]    Loss 0.927873    Top1 69.987261    Top5 95.898089    
2024-04-23 16:28:41,494 - ==> Top1: 69.987    Top5: 95.898    Loss: 0.928

2024-04-23 16:28:41,501 - ==> Best [Top1: 69.987   Top5: 95.898   Sparsity:0.00   Params: 370272 on epoch: 34]
2024-04-23 16:28:41,502 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:28:41,566 - 

2024-04-23 16:28:41,566 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:28:54,850 - Epoch: [35][  100/  296]    Overall Loss 1.081349    Objective Loss 1.081349                                        LR 0.000320    Time 0.132609    
2024-04-23 16:29:05,614 - Epoch: [35][  200/  296]    Overall Loss 1.073621    Objective Loss 1.073621                                        LR 0.000320    Time 0.119998    
2024-04-23 16:29:18,023 - Epoch: [35][  296/  296]    Overall Loss 1.081139    Objective Loss 1.081139    Top1 70.491803    Top5 95.081967    LR 0.000320    Time 0.122928    
2024-04-23 16:29:18,339 - --- validate (epoch=35)-----------
2024-04-23 16:29:18,340 - 3925 samples (32 per mini-batch)
2024-04-23 16:29:35,216 - Epoch: [35][  100/  123]    Loss 0.948023    Top1 69.406250    Top5 95.250000    
2024-04-23 16:29:39,089 - Epoch: [35][  123/  123]    Loss 0.953217    Top1 68.815287    Top5 95.286624    
2024-04-23 16:29:39,377 - ==> Top1: 68.815    Top5: 95.287    Loss: 0.953

2024-04-23 16:29:39,388 - ==> Best [Top1: 69.987   Top5: 95.898   Sparsity:0.00   Params: 370272 on epoch: 34]
2024-04-23 16:29:39,389 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:29:39,445 - 

2024-04-23 16:29:39,445 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:29:55,479 - Epoch: [36][  100/  296]    Overall Loss 1.079632    Objective Loss 1.079632                                        LR 0.000320    Time 0.160118    
2024-04-23 16:30:08,470 - Epoch: [36][  200/  296]    Overall Loss 1.074280    Objective Loss 1.074280                                        LR 0.000320    Time 0.144897    
2024-04-23 16:30:19,057 - Epoch: [36][  296/  296]    Overall Loss 1.082459    Objective Loss 1.082459    Top1 62.295082    Top5 96.721311    LR 0.000320    Time 0.133597    
2024-04-23 16:30:19,379 - --- validate (epoch=36)-----------
2024-04-23 16:30:19,380 - 3925 samples (32 per mini-batch)
2024-04-23 16:30:36,610 - Epoch: [36][  100/  123]    Loss 0.905578    Top1 69.968750    Top5 96.093750    
2024-04-23 16:30:39,225 - Epoch: [36][  123/  123]    Loss 0.898030    Top1 70.292994    Top5 96.127389    
2024-04-23 16:30:39,501 - ==> Top1: 70.293    Top5: 96.127    Loss: 0.898

2024-04-23 16:30:39,509 - ==> Best [Top1: 70.293   Top5: 96.127   Sparsity:0.00   Params: 370272 on epoch: 36]
2024-04-23 16:30:39,509 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:30:39,561 - 

2024-04-23 16:30:39,562 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:30:53,471 - Epoch: [37][  100/  296]    Overall Loss 1.075985    Objective Loss 1.075985                                        LR 0.000320    Time 0.138872    
2024-04-23 16:31:03,975 - Epoch: [37][  200/  296]    Overall Loss 1.070834    Objective Loss 1.070834                                        LR 0.000320    Time 0.121864    
2024-04-23 16:31:15,088 - Epoch: [37][  296/  296]    Overall Loss 1.075068    Objective Loss 1.075068    Top1 67.213115    Top5 96.721311    LR 0.000320    Time 0.119814    
2024-04-23 16:31:15,346 - --- validate (epoch=37)-----------
2024-04-23 16:31:15,347 - 3925 samples (32 per mini-batch)
2024-04-23 16:31:30,837 - Epoch: [37][  100/  123]    Loss 0.905623    Top1 70.718750    Top5 96.031250    
2024-04-23 16:31:33,798 - Epoch: [37][  123/  123]    Loss 0.909786    Top1 70.292994    Top5 96.076433    
2024-04-23 16:31:34,118 - ==> Top1: 70.293    Top5: 96.076    Loss: 0.910

2024-04-23 16:31:34,126 - ==> Best [Top1: 70.293   Top5: 96.127   Sparsity:0.00   Params: 370272 on epoch: 36]
2024-04-23 16:31:34,126 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:31:34,187 - 

2024-04-23 16:31:34,188 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:31:47,573 - Epoch: [38][  100/  296]    Overall Loss 1.090760    Objective Loss 1.090760                                        LR 0.000320    Time 0.133642    
2024-04-23 16:31:59,255 - Epoch: [38][  200/  296]    Overall Loss 1.080446    Objective Loss 1.080446                                        LR 0.000320    Time 0.125124    
2024-04-23 16:32:10,596 - Epoch: [38][  296/  296]    Overall Loss 1.069802    Objective Loss 1.069802    Top1 65.573770    Top5 95.081967    LR 0.000320    Time 0.122787    
2024-04-23 16:32:10,936 - --- validate (epoch=38)-----------
2024-04-23 16:32:10,937 - 3925 samples (32 per mini-batch)
2024-04-23 16:32:25,022 - Epoch: [38][  100/  123]    Loss 0.896126    Top1 70.968750    Top5 96.093750    
2024-04-23 16:32:29,557 - Epoch: [38][  123/  123]    Loss 0.894121    Top1 71.057325    Top5 96.000000    
2024-04-23 16:32:29,845 - ==> Top1: 71.057    Top5: 96.000    Loss: 0.894

2024-04-23 16:32:29,858 - ==> Best [Top1: 71.057   Top5: 96.000   Sparsity:0.00   Params: 370272 on epoch: 38]
2024-04-23 16:32:29,859 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:32:29,969 - 

2024-04-23 16:32:29,971 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:32:46,022 - Epoch: [39][  100/  296]    Overall Loss 1.062025    Objective Loss 1.062025                                        LR 0.000320    Time 0.160261    
2024-04-23 16:32:58,512 - Epoch: [39][  200/  296]    Overall Loss 1.042611    Objective Loss 1.042611                                        LR 0.000320    Time 0.142475    
2024-04-23 16:33:09,693 - Epoch: [39][  296/  296]    Overall Loss 1.059461    Objective Loss 1.059461    Top1 57.377049    Top5 91.803279    LR 0.000320    Time 0.133972    
2024-04-23 16:33:09,986 - --- validate (epoch=39)-----------
2024-04-23 16:33:09,987 - 3925 samples (32 per mini-batch)
2024-04-23 16:33:28,182 - Epoch: [39][  100/  123]    Loss 0.908722    Top1 69.812500    Top5 96.031250    
2024-04-23 16:33:31,183 - Epoch: [39][  123/  123]    Loss 0.909250    Top1 69.987261    Top5 95.898089    
2024-04-23 16:33:31,439 - ==> Top1: 69.987    Top5: 95.898    Loss: 0.909

2024-04-23 16:33:31,449 - ==> Best [Top1: 71.057   Top5: 96.000   Sparsity:0.00   Params: 370272 on epoch: 38]
2024-04-23 16:33:31,450 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:33:31,494 - 

2024-04-23 16:33:31,495 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:33:47,469 - Epoch: [40][  100/  296]    Overall Loss 1.050349    Objective Loss 1.050349                                        LR 0.000320    Time 0.159501    
2024-04-23 16:34:01,981 - Epoch: [40][  200/  296]    Overall Loss 1.044172    Objective Loss 1.044172                                        LR 0.000320    Time 0.152192    
2024-04-23 16:34:16,062 - Epoch: [40][  296/  296]    Overall Loss 1.050512    Objective Loss 1.050512    Top1 54.098361    Top5 93.442623    LR 0.000320    Time 0.150333    
2024-04-23 16:34:16,349 - --- validate (epoch=40)-----------
2024-04-23 16:34:16,350 - 3925 samples (32 per mini-batch)
2024-04-23 16:34:33,266 - Epoch: [40][  100/  123]    Loss 0.896897    Top1 70.687500    Top5 95.843750    
2024-04-23 16:34:36,696 - Epoch: [40][  123/  123]    Loss 0.889729    Top1 70.878981    Top5 95.923567    
2024-04-23 16:34:37,002 - ==> Top1: 70.879    Top5: 95.924    Loss: 0.890

2024-04-23 16:34:37,011 - ==> Best [Top1: 71.057   Top5: 96.000   Sparsity:0.00   Params: 370272 on epoch: 38]
2024-04-23 16:34:37,012 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:34:37,066 - 

2024-04-23 16:34:37,068 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:34:53,001 - Epoch: [41][  100/  296]    Overall Loss 1.060059    Objective Loss 1.060059                                        LR 0.000320    Time 0.159099    
2024-04-23 16:35:06,314 - Epoch: [41][  200/  296]    Overall Loss 1.061491    Objective Loss 1.061491                                        LR 0.000320    Time 0.146008    
2024-04-23 16:35:20,255 - Epoch: [41][  296/  296]    Overall Loss 1.058124    Objective Loss 1.058124    Top1 72.131148    Top5 96.721311    LR 0.000320    Time 0.145681    
2024-04-23 16:35:20,574 - --- validate (epoch=41)-----------
2024-04-23 16:35:20,575 - 3925 samples (32 per mini-batch)
2024-04-23 16:35:37,570 - Epoch: [41][  100/  123]    Loss 0.933798    Top1 69.500000    Top5 95.437500    
2024-04-23 16:35:40,681 - Epoch: [41][  123/  123]    Loss 0.937097    Top1 69.401274    Top5 95.388535    
2024-04-23 16:35:40,948 - ==> Top1: 69.401    Top5: 95.389    Loss: 0.937

2024-04-23 16:35:40,956 - ==> Best [Top1: 71.057   Top5: 96.000   Sparsity:0.00   Params: 370272 on epoch: 38]
2024-04-23 16:35:40,957 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:35:41,008 - 

2024-04-23 16:35:41,009 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:35:57,152 - Epoch: [42][  100/  296]    Overall Loss 1.066223    Objective Loss 1.066223                                        LR 0.000320    Time 0.161196    
2024-04-23 16:36:11,930 - Epoch: [42][  200/  296]    Overall Loss 1.045394    Objective Loss 1.045394                                        LR 0.000320    Time 0.154374    
2024-04-23 16:36:26,135 - Epoch: [42][  296/  296]    Overall Loss 1.047538    Objective Loss 1.047538    Top1 57.377049    Top5 93.442623    LR 0.000320    Time 0.152228    
2024-04-23 16:36:26,473 - --- validate (epoch=42)-----------
2024-04-23 16:36:26,474 - 3925 samples (32 per mini-batch)
2024-04-23 16:36:44,613 - Epoch: [42][  100/  123]    Loss 0.873048    Top1 71.250000    Top5 96.531250    
2024-04-23 16:36:47,818 - Epoch: [42][  123/  123]    Loss 0.872437    Top1 71.159236    Top5 96.331210    
2024-04-23 16:36:48,081 - ==> Top1: 71.159    Top5: 96.331    Loss: 0.872

2024-04-23 16:36:48,092 - ==> Best [Top1: 71.159   Top5: 96.331   Sparsity:0.00   Params: 370272 on epoch: 42]
2024-04-23 16:36:48,093 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:36:48,162 - 

2024-04-23 16:36:48,163 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:37:03,506 - Epoch: [43][  100/  296]    Overall Loss 1.024746    Objective Loss 1.024746                                        LR 0.000320    Time 0.153186    
2024-04-23 16:37:18,089 - Epoch: [43][  200/  296]    Overall Loss 1.033542    Objective Loss 1.033542                                        LR 0.000320    Time 0.149394    
2024-04-23 16:37:31,895 - Epoch: [43][  296/  296]    Overall Loss 1.031446    Objective Loss 1.031446    Top1 67.213115    Top5 93.442623    LR 0.000320    Time 0.147514    
2024-04-23 16:37:32,238 - --- validate (epoch=43)-----------
2024-04-23 16:37:32,239 - 3925 samples (32 per mini-batch)
2024-04-23 16:37:50,049 - Epoch: [43][  100/  123]    Loss 0.882392    Top1 71.625000    Top5 96.312500    
2024-04-23 16:37:53,672 - Epoch: [43][  123/  123]    Loss 0.890519    Top1 71.337580    Top5 96.076433    
2024-04-23 16:37:53,984 - ==> Top1: 71.338    Top5: 96.076    Loss: 0.891

2024-04-23 16:37:53,996 - ==> Best [Top1: 71.338   Top5: 96.076   Sparsity:0.00   Params: 370272 on epoch: 43]
2024-04-23 16:37:53,997 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:37:54,069 - 

2024-04-23 16:37:54,071 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:38:09,765 - Epoch: [44][  100/  296]    Overall Loss 1.018778    Objective Loss 1.018778                                        LR 0.000320    Time 0.156706    
2024-04-23 16:38:23,844 - Epoch: [44][  200/  296]    Overall Loss 1.034595    Objective Loss 1.034595                                        LR 0.000320    Time 0.148639    
2024-04-23 16:38:37,984 - Epoch: [44][  296/  296]    Overall Loss 1.033906    Objective Loss 1.033906    Top1 62.295082    Top5 96.721311    LR 0.000320    Time 0.148128    
2024-04-23 16:38:38,249 - --- validate (epoch=44)-----------
2024-04-23 16:38:38,250 - 3925 samples (32 per mini-batch)
2024-04-23 16:38:54,365 - Epoch: [44][  100/  123]    Loss 0.933190    Top1 69.187500    Top5 96.156250    
2024-04-23 16:38:57,061 - Epoch: [44][  123/  123]    Loss 0.944266    Top1 68.866242    Top5 95.923567    
2024-04-23 16:38:57,360 - ==> Top1: 68.866    Top5: 95.924    Loss: 0.944

2024-04-23 16:38:57,372 - ==> Best [Top1: 71.338   Top5: 96.076   Sparsity:0.00   Params: 370272 on epoch: 43]
2024-04-23 16:38:57,373 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:38:57,428 - 

2024-04-23 16:38:57,430 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:39:12,266 - Epoch: [45][  100/  296]    Overall Loss 1.028224    Objective Loss 1.028224                                        LR 0.000320    Time 0.148131    
2024-04-23 16:39:26,357 - Epoch: [45][  200/  296]    Overall Loss 1.033380    Objective Loss 1.033380                                        LR 0.000320    Time 0.144411    
2024-04-23 16:39:40,781 - Epoch: [45][  296/  296]    Overall Loss 1.031982    Objective Loss 1.031982    Top1 62.295082    Top5 90.163934    LR 0.000320    Time 0.146231    
2024-04-23 16:39:41,099 - --- validate (epoch=45)-----------
2024-04-23 16:39:41,100 - 3925 samples (32 per mini-batch)
2024-04-23 16:39:58,927 - Epoch: [45][  100/  123]    Loss 0.965958    Top1 68.906250    Top5 94.750000    
2024-04-23 16:40:03,106 - Epoch: [45][  123/  123]    Loss 0.982013    Top1 68.509554    Top5 94.624204    
2024-04-23 16:40:03,533 - ==> Top1: 68.510    Top5: 94.624    Loss: 0.982

2024-04-23 16:40:03,544 - ==> Best [Top1: 71.338   Top5: 96.076   Sparsity:0.00   Params: 370272 on epoch: 43]
2024-04-23 16:40:03,545 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:40:03,596 - 

2024-04-23 16:40:03,597 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:40:18,575 - Epoch: [46][  100/  296]    Overall Loss 1.024012    Objective Loss 1.024012                                        LR 0.000320    Time 0.149545    
2024-04-23 16:40:31,600 - Epoch: [46][  200/  296]    Overall Loss 1.042074    Objective Loss 1.042074                                        LR 0.000320    Time 0.139790    
2024-04-23 16:40:44,520 - Epoch: [46][  296/  296]    Overall Loss 1.039919    Objective Loss 1.039919    Top1 65.573770    Top5 98.360656    LR 0.000320    Time 0.138025    
2024-04-23 16:40:44,968 - --- validate (epoch=46)-----------
2024-04-23 16:40:44,970 - 3925 samples (32 per mini-batch)
2024-04-23 16:41:02,407 - Epoch: [46][  100/  123]    Loss 0.882432    Top1 72.281250    Top5 96.062500    
2024-04-23 16:41:05,979 - Epoch: [46][  123/  123]    Loss 0.874634    Top1 72.101911    Top5 96.152866    
2024-04-23 16:41:06,255 - ==> Top1: 72.102    Top5: 96.153    Loss: 0.875

2024-04-23 16:41:06,266 - ==> Best [Top1: 72.102   Top5: 96.153   Sparsity:0.00   Params: 370272 on epoch: 46]
2024-04-23 16:41:06,267 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:41:06,363 - 

2024-04-23 16:41:06,364 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:41:20,298 - Epoch: [47][  100/  296]    Overall Loss 1.030124    Objective Loss 1.030124                                        LR 0.000320    Time 0.139102    
2024-04-23 16:41:32,773 - Epoch: [47][  200/  296]    Overall Loss 1.029720    Objective Loss 1.029720                                        LR 0.000320    Time 0.131808    
2024-04-23 16:41:44,949 - Epoch: [47][  296/  296]    Overall Loss 1.020707    Objective Loss 1.020707    Top1 70.491803    Top5 96.721311    LR 0.000320    Time 0.130131    
2024-04-23 16:41:45,182 - --- validate (epoch=47)-----------
2024-04-23 16:41:45,183 - 3925 samples (32 per mini-batch)
2024-04-23 16:41:59,906 - Epoch: [47][  100/  123]    Loss 0.863326    Top1 72.187500    Top5 95.968750    
2024-04-23 16:42:02,918 - Epoch: [47][  123/  123]    Loss 0.865657    Top1 71.974522    Top5 96.000000    
2024-04-23 16:42:03,204 - ==> Top1: 71.975    Top5: 96.000    Loss: 0.866

2024-04-23 16:42:03,213 - ==> Best [Top1: 72.102   Top5: 96.153   Sparsity:0.00   Params: 370272 on epoch: 46]
2024-04-23 16:42:03,213 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:42:03,260 - 

2024-04-23 16:42:03,261 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:42:16,897 - Epoch: [48][  100/  296]    Overall Loss 1.022105    Objective Loss 1.022105                                        LR 0.000320    Time 0.136108    
2024-04-23 16:42:29,779 - Epoch: [48][  200/  296]    Overall Loss 1.027596    Objective Loss 1.027596                                        LR 0.000320    Time 0.132353    
2024-04-23 16:42:42,287 - Epoch: [48][  296/  296]    Overall Loss 1.014530    Objective Loss 1.014530    Top1 75.409836    Top5 95.081967    LR 0.000320    Time 0.131613    
2024-04-23 16:42:42,673 - --- validate (epoch=48)-----------
2024-04-23 16:42:42,674 - 3925 samples (32 per mini-batch)
2024-04-23 16:42:57,777 - Epoch: [48][  100/  123]    Loss 0.917746    Top1 69.843750    Top5 95.593750    
2024-04-23 16:43:00,652 - Epoch: [48][  123/  123]    Loss 0.901338    Top1 70.598726    Top5 95.719745    
2024-04-23 16:43:00,986 - ==> Top1: 70.599    Top5: 95.720    Loss: 0.901

2024-04-23 16:43:00,995 - ==> Best [Top1: 72.102   Top5: 96.153   Sparsity:0.00   Params: 370272 on epoch: 46]
2024-04-23 16:43:00,996 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:43:01,058 - 

2024-04-23 16:43:01,059 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:43:21,198 - Epoch: [49][  100/  296]    Overall Loss 0.974409    Objective Loss 0.974409                                        LR 0.000320    Time 0.201143    
2024-04-23 16:43:37,023 - Epoch: [49][  200/  296]    Overall Loss 0.995330    Objective Loss 0.995330                                        LR 0.000320    Time 0.179584    
2024-04-23 16:43:54,414 - Epoch: [49][  296/  296]    Overall Loss 1.013691    Objective Loss 1.013691    Top1 65.573770    Top5 91.803279    LR 0.000320    Time 0.180029    
2024-04-23 16:43:54,778 - --- validate (epoch=49)-----------
2024-04-23 16:43:54,779 - 3925 samples (32 per mini-batch)
2024-04-23 16:44:17,748 - Epoch: [49][  100/  123]    Loss 0.906856    Top1 70.375000    Top5 96.000000    
2024-04-23 16:44:20,716 - Epoch: [49][  123/  123]    Loss 0.893714    Top1 70.649682    Top5 96.050955    
2024-04-23 16:44:20,911 - ==> Top1: 70.650    Top5: 96.051    Loss: 0.894

2024-04-23 16:44:20,925 - ==> Best [Top1: 72.102   Top5: 96.153   Sparsity:0.00   Params: 370272 on epoch: 46]
2024-04-23 16:44:20,926 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:44:21,001 - 

2024-04-23 16:44:21,002 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:44:35,340 - Epoch: [50][  100/  296]    Overall Loss 0.983749    Objective Loss 0.983749                                        LR 0.000320    Time 0.143161    
2024-04-23 16:44:52,322 - Epoch: [50][  200/  296]    Overall Loss 0.988572    Objective Loss 0.988572                                        LR 0.000320    Time 0.156374    
2024-04-23 16:45:06,559 - Epoch: [50][  296/  296]    Overall Loss 1.005432    Objective Loss 1.005432    Top1 72.131148    Top5 98.360656    LR 0.000320    Time 0.153678    
2024-04-23 16:45:06,817 - --- validate (epoch=50)-----------
2024-04-23 16:45:06,819 - 3925 samples (32 per mini-batch)
2024-04-23 16:45:23,501 - Epoch: [50][  100/  123]    Loss 0.931304    Top1 69.125000    Top5 95.625000    
2024-04-23 16:45:26,948 - Epoch: [50][  123/  123]    Loss 0.927332    Top1 69.401274    Top5 95.668790    
2024-04-23 16:45:27,096 - ==> Top1: 69.401    Top5: 95.669    Loss: 0.927

2024-04-23 16:45:27,106 - ==> Best [Top1: 72.102   Top5: 96.153   Sparsity:0.00   Params: 370272 on epoch: 46]
2024-04-23 16:45:27,107 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:45:27,148 - 

2024-04-23 16:45:27,149 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:45:42,682 - Epoch: [51][  100/  296]    Overall Loss 0.994370    Objective Loss 0.994370                                        LR 0.000320    Time 0.155113    
2024-04-23 16:45:55,377 - Epoch: [51][  200/  296]    Overall Loss 1.000473    Objective Loss 1.000473                                        LR 0.000320    Time 0.140931    
2024-04-23 16:46:09,172 - Epoch: [51][  296/  296]    Overall Loss 1.010728    Objective Loss 1.010728    Top1 59.016393    Top5 91.803279    LR 0.000320    Time 0.141760    
2024-04-23 16:46:09,298 - --- validate (epoch=51)-----------
2024-04-23 16:46:09,299 - 3925 samples (32 per mini-batch)
2024-04-23 16:46:24,308 - Epoch: [51][  100/  123]    Loss 0.942522    Top1 68.343750    Top5 95.718750    
2024-04-23 16:46:27,003 - Epoch: [51][  123/  123]    Loss 0.918059    Top1 68.993631    Top5 95.821656    
2024-04-23 16:46:27,219 - ==> Top1: 68.994    Top5: 95.822    Loss: 0.918

2024-04-23 16:46:27,228 - ==> Best [Top1: 72.102   Top5: 96.153   Sparsity:0.00   Params: 370272 on epoch: 46]
2024-04-23 16:46:27,229 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:46:27,282 - 

2024-04-23 16:46:27,283 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:46:43,438 - Epoch: [52][  100/  296]    Overall Loss 1.011116    Objective Loss 1.011116                                        LR 0.000320    Time 0.161329    
2024-04-23 16:46:57,937 - Epoch: [52][  200/  296]    Overall Loss 0.985121    Objective Loss 0.985121                                        LR 0.000320    Time 0.153053    
2024-04-23 16:47:11,503 - Epoch: [52][  296/  296]    Overall Loss 0.994599    Objective Loss 0.994599    Top1 63.934426    Top5 96.721311    LR 0.000320    Time 0.149178    
2024-04-23 16:47:11,685 - --- validate (epoch=52)-----------
2024-04-23 16:47:11,686 - 3925 samples (32 per mini-batch)
2024-04-23 16:47:28,571 - Epoch: [52][  100/  123]    Loss 0.894803    Top1 71.031250    Top5 95.500000    
2024-04-23 16:47:32,420 - Epoch: [52][  123/  123]    Loss 0.889023    Top1 71.210191    Top5 95.668790    
2024-04-23 16:47:32,631 - ==> Top1: 71.210    Top5: 95.669    Loss: 0.889

2024-04-23 16:47:32,636 - ==> Best [Top1: 72.102   Top5: 96.153   Sparsity:0.00   Params: 370272 on epoch: 46]
2024-04-23 16:47:32,637 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:47:32,681 - 

2024-04-23 16:47:32,682 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:47:48,165 - Epoch: [53][  100/  296]    Overall Loss 0.998511    Objective Loss 0.998511                                        LR 0.000320    Time 0.154604    
2024-04-23 16:48:03,956 - Epoch: [53][  200/  296]    Overall Loss 1.001411    Objective Loss 1.001411                                        LR 0.000320    Time 0.156149    
2024-04-23 16:48:17,996 - Epoch: [53][  296/  296]    Overall Loss 1.005002    Objective Loss 1.005002    Top1 57.377049    Top5 93.442623    LR 0.000320    Time 0.152874    
2024-04-23 16:48:18,242 - --- validate (epoch=53)-----------
2024-04-23 16:48:18,243 - 3925 samples (32 per mini-batch)
2024-04-23 16:48:33,907 - Epoch: [53][  100/  123]    Loss 0.861556    Top1 71.468750    Top5 96.093750    
2024-04-23 16:48:37,650 - Epoch: [53][  123/  123]    Loss 0.845765    Top1 72.229299    Top5 96.280255    
2024-04-23 16:48:37,854 - ==> Top1: 72.229    Top5: 96.280    Loss: 0.846

2024-04-23 16:48:37,864 - ==> Best [Top1: 72.229   Top5: 96.280   Sparsity:0.00   Params: 370272 on epoch: 53]
2024-04-23 16:48:37,865 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:48:37,948 - 

2024-04-23 16:48:37,949 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:48:53,550 - Epoch: [54][  100/  296]    Overall Loss 1.003521    Objective Loss 1.003521                                        LR 0.000320    Time 0.155779    
2024-04-23 16:49:09,789 - Epoch: [54][  200/  296]    Overall Loss 1.000778    Objective Loss 1.000778                                        LR 0.000320    Time 0.158974    
2024-04-23 16:49:24,689 - Epoch: [54][  296/  296]    Overall Loss 0.999622    Objective Loss 0.999622    Top1 70.491803    Top5 96.721311    LR 0.000320    Time 0.157686    
2024-04-23 16:49:24,938 - --- validate (epoch=54)-----------
2024-04-23 16:49:24,939 - 3925 samples (32 per mini-batch)
2024-04-23 16:49:43,298 - Epoch: [54][  100/  123]    Loss 0.848768    Top1 72.500000    Top5 96.250000    
2024-04-23 16:49:47,516 - Epoch: [54][  123/  123]    Loss 0.860232    Top1 72.203822    Top5 96.101911    
2024-04-23 16:49:47,706 - ==> Top1: 72.204    Top5: 96.102    Loss: 0.860

2024-04-23 16:49:47,715 - ==> Best [Top1: 72.229   Top5: 96.280   Sparsity:0.00   Params: 370272 on epoch: 53]
2024-04-23 16:49:47,715 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:49:47,771 - 

2024-04-23 16:49:47,772 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:50:03,223 - Epoch: [55][  100/  296]    Overall Loss 0.971776    Objective Loss 0.971776                                        LR 0.000320    Time 0.154265    
2024-04-23 16:50:16,104 - Epoch: [55][  200/  296]    Overall Loss 0.975582    Objective Loss 0.975582                                        LR 0.000320    Time 0.141442    
2024-04-23 16:50:30,532 - Epoch: [55][  296/  296]    Overall Loss 0.978671    Objective Loss 0.978671    Top1 68.852459    Top5 95.081967    LR 0.000320    Time 0.144241    
2024-04-23 16:50:30,791 - --- validate (epoch=55)-----------
2024-04-23 16:50:30,792 - 3925 samples (32 per mini-batch)
2024-04-23 16:50:49,222 - Epoch: [55][  100/  123]    Loss 0.872161    Top1 71.437500    Top5 96.312500    
2024-04-23 16:50:53,174 - Epoch: [55][  123/  123]    Loss 0.875715    Top1 71.184713    Top5 96.433121    
2024-04-23 16:50:53,387 - ==> Top1: 71.185    Top5: 96.433    Loss: 0.876

2024-04-23 16:50:53,396 - ==> Best [Top1: 72.229   Top5: 96.280   Sparsity:0.00   Params: 370272 on epoch: 53]
2024-04-23 16:50:53,397 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:50:53,448 - 

2024-04-23 16:50:53,449 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:51:08,886 - Epoch: [56][  100/  296]    Overall Loss 0.996011    Objective Loss 0.996011                                        LR 0.000320    Time 0.154154    
2024-04-23 16:51:24,553 - Epoch: [56][  200/  296]    Overall Loss 0.979162    Objective Loss 0.979162                                        LR 0.000320    Time 0.155292    
2024-04-23 16:51:36,378 - Epoch: [56][  296/  296]    Overall Loss 0.982289    Objective Loss 0.982289    Top1 72.131148    Top5 96.721311    LR 0.000320    Time 0.144807    
2024-04-23 16:51:36,616 - --- validate (epoch=56)-----------
2024-04-23 16:51:36,617 - 3925 samples (32 per mini-batch)
2024-04-23 16:51:49,330 - Epoch: [56][  100/  123]    Loss 0.899386    Top1 70.875000    Top5 96.093750    
2024-04-23 16:51:52,533 - Epoch: [56][  123/  123]    Loss 0.902910    Top1 70.853503    Top5 96.025478    
2024-04-23 16:51:52,761 - ==> Top1: 70.854    Top5: 96.025    Loss: 0.903

2024-04-23 16:51:52,772 - ==> Best [Top1: 72.229   Top5: 96.280   Sparsity:0.00   Params: 370272 on epoch: 53]
2024-04-23 16:51:52,773 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:51:52,845 - 

2024-04-23 16:51:52,846 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:52:07,300 - Epoch: [57][  100/  296]    Overall Loss 0.966964    Objective Loss 0.966964                                        LR 0.000320    Time 0.144328    
2024-04-23 16:52:19,738 - Epoch: [57][  200/  296]    Overall Loss 0.970045    Objective Loss 0.970045                                        LR 0.000320    Time 0.134257    
2024-04-23 16:52:32,941 - Epoch: [57][  296/  296]    Overall Loss 0.967803    Objective Loss 0.967803    Top1 75.409836    Top5 93.442623    LR 0.000320    Time 0.135250    
2024-04-23 16:52:33,136 - --- validate (epoch=57)-----------
2024-04-23 16:52:33,138 - 3925 samples (32 per mini-batch)
2024-04-23 16:52:48,246 - Epoch: [57][  100/  123]    Loss 0.850670    Top1 71.906250    Top5 96.156250    
2024-04-23 16:52:51,944 - Epoch: [57][  123/  123]    Loss 0.858775    Top1 72.025478    Top5 96.000000    
2024-04-23 16:52:52,240 - ==> Top1: 72.025    Top5: 96.000    Loss: 0.859

2024-04-23 16:52:52,248 - ==> Best [Top1: 72.229   Top5: 96.280   Sparsity:0.00   Params: 370272 on epoch: 53]
2024-04-23 16:52:52,249 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:52:52,293 - 

2024-04-23 16:52:52,294 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:53:10,443 - Epoch: [58][  100/  296]    Overall Loss 0.948971    Objective Loss 0.948971                                        LR 0.000320    Time 0.181273    
2024-04-23 16:53:27,967 - Epoch: [58][  200/  296]    Overall Loss 0.968646    Objective Loss 0.968646                                        LR 0.000320    Time 0.178130    
2024-04-23 16:53:43,011 - Epoch: [58][  296/  296]    Overall Loss 0.977891    Objective Loss 0.977891    Top1 72.131148    Top5 98.360656    LR 0.000320    Time 0.171101    
2024-04-23 16:53:43,341 - --- validate (epoch=58)-----------
2024-04-23 16:53:43,342 - 3925 samples (32 per mini-batch)
2024-04-23 16:54:00,105 - Epoch: [58][  100/  123]    Loss 0.881755    Top1 70.781250    Top5 96.218750    
2024-04-23 16:54:03,566 - Epoch: [58][  123/  123]    Loss 0.865889    Top1 71.515924    Top5 96.280255    
2024-04-23 16:54:03,803 - ==> Top1: 71.516    Top5: 96.280    Loss: 0.866

2024-04-23 16:54:03,813 - ==> Best [Top1: 72.229   Top5: 96.280   Sparsity:0.00   Params: 370272 on epoch: 53]
2024-04-23 16:54:03,814 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:54:03,873 - 

2024-04-23 16:54:03,875 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:54:21,949 - Epoch: [59][  100/  296]    Overall Loss 1.012569    Objective Loss 1.012569                                        LR 0.000320    Time 0.180510    
2024-04-23 16:54:39,930 - Epoch: [59][  200/  296]    Overall Loss 0.996401    Objective Loss 0.996401                                        LR 0.000320    Time 0.180039    
2024-04-23 16:54:56,377 - Epoch: [59][  296/  296]    Overall Loss 1.003325    Objective Loss 1.003325    Top1 67.213115    Top5 98.360656    LR 0.000320    Time 0.177142    
2024-04-23 16:54:56,633 - --- validate (epoch=59)-----------
2024-04-23 16:54:56,634 - 3925 samples (32 per mini-batch)
2024-04-23 16:55:16,726 - Epoch: [59][  100/  123]    Loss 0.848006    Top1 72.593750    Top5 96.250000    
2024-04-23 16:55:21,432 - Epoch: [59][  123/  123]    Loss 0.835459    Top1 73.044586    Top5 96.280255    
2024-04-23 16:55:21,769 - ==> Top1: 73.045    Top5: 96.280    Loss: 0.835

2024-04-23 16:55:21,781 - ==> Best [Top1: 73.045   Top5: 96.280   Sparsity:0.00   Params: 370272 on epoch: 59]
2024-04-23 16:55:21,782 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:55:21,861 - 

2024-04-23 16:55:21,863 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:55:40,232 - Epoch: [60][  100/  296]    Overall Loss 0.967870    Objective Loss 0.967870                                        LR 0.000320    Time 0.183455    
2024-04-23 16:55:57,405 - Epoch: [60][  200/  296]    Overall Loss 0.971908    Objective Loss 0.971908                                        LR 0.000320    Time 0.177480    
2024-04-23 16:56:12,892 - Epoch: [60][  296/  296]    Overall Loss 0.964516    Objective Loss 0.964516    Top1 73.770492    Top5 96.721311    LR 0.000320    Time 0.172157    
2024-04-23 16:56:13,182 - --- validate (epoch=60)-----------
2024-04-23 16:56:13,184 - 3925 samples (32 per mini-batch)
2024-04-23 16:56:32,491 - Epoch: [60][  100/  123]    Loss 0.831934    Top1 73.406250    Top5 96.375000    
2024-04-23 16:56:36,215 - Epoch: [60][  123/  123]    Loss 0.845728    Top1 73.019108    Top5 96.382166    
2024-04-23 16:56:36,542 - ==> Top1: 73.019    Top5: 96.382    Loss: 0.846

2024-04-23 16:56:36,553 - ==> Best [Top1: 73.045   Top5: 96.280   Sparsity:0.00   Params: 370272 on epoch: 59]
2024-04-23 16:56:36,554 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:56:36,665 - 

2024-04-23 16:56:36,667 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:56:54,408 - Epoch: [61][  100/  296]    Overall Loss 0.969759    Objective Loss 0.969759                                        LR 0.000320    Time 0.177130    
2024-04-23 16:57:09,734 - Epoch: [61][  200/  296]    Overall Loss 0.959572    Objective Loss 0.959572                                        LR 0.000320    Time 0.165091    
2024-04-23 16:57:26,702 - Epoch: [61][  296/  296]    Overall Loss 0.962472    Objective Loss 0.962472    Top1 73.770492    Top5 96.721311    LR 0.000320    Time 0.168799    
2024-04-23 16:57:27,047 - --- validate (epoch=61)-----------
2024-04-23 16:57:27,049 - 3925 samples (32 per mini-batch)
2024-04-23 16:57:46,711 - Epoch: [61][  100/  123]    Loss 0.857221    Top1 72.031250    Top5 95.750000    
2024-04-23 16:57:50,999 - Epoch: [61][  123/  123]    Loss 0.853297    Top1 72.382166    Top5 95.745223    
2024-04-23 16:57:51,353 - ==> Top1: 72.382    Top5: 95.745    Loss: 0.853

2024-04-23 16:57:51,362 - ==> Best [Top1: 73.045   Top5: 96.280   Sparsity:0.00   Params: 370272 on epoch: 59]
2024-04-23 16:57:51,363 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:57:51,407 - 

2024-04-23 16:57:51,408 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:58:09,225 - Epoch: [62][  100/  296]    Overall Loss 0.965654    Objective Loss 0.965654                                        LR 0.000320    Time 0.177923    
2024-04-23 16:58:25,932 - Epoch: [62][  200/  296]    Overall Loss 0.963768    Objective Loss 0.963768                                        LR 0.000320    Time 0.172381    
2024-04-23 16:58:40,849 - Epoch: [62][  296/  296]    Overall Loss 0.973382    Objective Loss 0.973382    Top1 70.491803    Top5 88.524590    LR 0.000320    Time 0.166804    
2024-04-23 16:58:41,213 - --- validate (epoch=62)-----------
2024-04-23 16:58:41,215 - 3925 samples (32 per mini-batch)
2024-04-23 16:58:58,381 - Epoch: [62][  100/  123]    Loss 0.856097    Top1 72.625000    Top5 95.906250    
2024-04-23 16:59:01,712 - Epoch: [62][  123/  123]    Loss 0.850564    Top1 72.815287    Top5 95.974522    
2024-04-23 16:59:02,021 - ==> Top1: 72.815    Top5: 95.975    Loss: 0.851

2024-04-23 16:59:02,032 - ==> Best [Top1: 73.045   Top5: 96.280   Sparsity:0.00   Params: 370272 on epoch: 59]
2024-04-23 16:59:02,033 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:59:02,097 - 

2024-04-23 16:59:02,098 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:59:14,956 - Epoch: [63][  100/  296]    Overall Loss 0.950438    Objective Loss 0.950438                                        LR 0.000320    Time 0.128347    
2024-04-23 16:59:26,255 - Epoch: [63][  200/  296]    Overall Loss 0.958330    Objective Loss 0.958330                                        LR 0.000320    Time 0.120564    
2024-04-23 16:59:38,624 - Epoch: [63][  296/  296]    Overall Loss 0.956963    Objective Loss 0.956963    Top1 67.213115    Top5 98.360656    LR 0.000320    Time 0.123181    
2024-04-23 16:59:38,966 - --- validate (epoch=63)-----------
2024-04-23 16:59:38,966 - 3925 samples (32 per mini-batch)
2024-04-23 16:59:54,500 - Epoch: [63][  100/  123]    Loss 0.866211    Top1 72.031250    Top5 95.781250    
2024-04-23 16:59:57,770 - Epoch: [63][  123/  123]    Loss 0.890098    Top1 71.286624    Top5 95.643312    
2024-04-23 16:59:58,076 - ==> Top1: 71.287    Top5: 95.643    Loss: 0.890

2024-04-23 16:59:58,087 - ==> Best [Top1: 73.045   Top5: 96.280   Sparsity:0.00   Params: 370272 on epoch: 59]
2024-04-23 16:59:58,087 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 16:59:58,136 - 

2024-04-23 16:59:58,137 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:00:10,766 - Epoch: [64][  100/  296]    Overall Loss 0.956874    Objective Loss 0.956874                                        LR 0.000320    Time 0.126054    
2024-04-23 17:00:21,400 - Epoch: [64][  200/  296]    Overall Loss 0.953424    Objective Loss 0.953424                                        LR 0.000320    Time 0.116089    
2024-04-23 17:00:31,334 - Epoch: [64][  296/  296]    Overall Loss 0.962314    Objective Loss 0.962314    Top1 60.655738    Top5 93.442623    LR 0.000320    Time 0.111932    
2024-04-23 17:00:31,673 - --- validate (epoch=64)-----------
2024-04-23 17:00:31,674 - 3925 samples (32 per mini-batch)
2024-04-23 17:00:48,029 - Epoch: [64][  100/  123]    Loss 0.828726    Top1 73.500000    Top5 96.218750    
2024-04-23 17:00:51,195 - Epoch: [64][  123/  123]    Loss 0.836948    Top1 73.146497    Top5 96.178344    
2024-04-23 17:00:51,469 - ==> Top1: 73.146    Top5: 96.178    Loss: 0.837

2024-04-23 17:00:51,480 - ==> Best [Top1: 73.146   Top5: 96.178   Sparsity:0.00   Params: 370272 on epoch: 64]
2024-04-23 17:00:51,481 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:00:51,547 - 

2024-04-23 17:00:51,548 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:01:05,134 - Epoch: [65][  100/  296]    Overall Loss 0.954565    Objective Loss 0.954565                                        LR 0.000320    Time 0.135640    
2024-04-23 17:01:15,313 - Epoch: [65][  200/  296]    Overall Loss 0.963541    Objective Loss 0.963541                                        LR 0.000320    Time 0.118613    
2024-04-23 17:01:25,761 - Epoch: [65][  296/  296]    Overall Loss 0.976615    Objective Loss 0.976615    Top1 65.573770    Top5 95.081967    LR 0.000320    Time 0.115353    
2024-04-23 17:01:26,109 - --- validate (epoch=65)-----------
2024-04-23 17:01:26,111 - 3925 samples (32 per mini-batch)
2024-04-23 17:01:40,114 - Epoch: [65][  100/  123]    Loss 0.828279    Top1 72.687500    Top5 96.343750    
2024-04-23 17:01:43,051 - Epoch: [65][  123/  123]    Loss 0.839254    Top1 72.560510    Top5 96.178344    
2024-04-23 17:01:43,333 - ==> Top1: 72.561    Top5: 96.178    Loss: 0.839

2024-04-23 17:01:43,344 - ==> Best [Top1: 73.146   Top5: 96.178   Sparsity:0.00   Params: 370272 on epoch: 64]
2024-04-23 17:01:43,344 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:01:43,395 - 

2024-04-23 17:01:43,396 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:01:56,463 - Epoch: [66][  100/  296]    Overall Loss 0.949923    Objective Loss 0.949923                                        LR 0.000320    Time 0.130450    
2024-04-23 17:02:08,181 - Epoch: [66][  200/  296]    Overall Loss 0.944642    Objective Loss 0.944642                                        LR 0.000320    Time 0.123662    
2024-04-23 17:02:16,742 - Epoch: [66][  296/  296]    Overall Loss 0.970859    Objective Loss 0.970859    Top1 65.573770    Top5 88.524590    LR 0.000320    Time 0.112407    
2024-04-23 17:02:17,016 - --- validate (epoch=66)-----------
2024-04-23 17:02:17,017 - 3925 samples (32 per mini-batch)
2024-04-23 17:02:30,442 - Epoch: [66][  100/  123]    Loss 0.828323    Top1 73.843750    Top5 96.375000    
2024-04-23 17:02:33,302 - Epoch: [66][  123/  123]    Loss 0.834913    Top1 73.732484    Top5 96.356688    
2024-04-23 17:02:33,560 - ==> Top1: 73.732    Top5: 96.357    Loss: 0.835

2024-04-23 17:02:33,566 - ==> Best [Top1: 73.732   Top5: 96.357   Sparsity:0.00   Params: 370272 on epoch: 66]
2024-04-23 17:02:33,566 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:02:33,617 - 

2024-04-23 17:02:33,618 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:02:46,445 - Epoch: [67][  100/  296]    Overall Loss 0.939066    Objective Loss 0.939066                                        LR 0.000320    Time 0.128064    
2024-04-23 17:02:58,017 - Epoch: [67][  200/  296]    Overall Loss 0.960249    Objective Loss 0.960249                                        LR 0.000320    Time 0.121778    
2024-04-23 17:03:07,096 - Epoch: [67][  296/  296]    Overall Loss 0.951533    Objective Loss 0.951533    Top1 62.295082    Top5 95.081967    LR 0.000320    Time 0.112891    
2024-04-23 17:03:07,387 - --- validate (epoch=67)-----------
2024-04-23 17:03:07,389 - 3925 samples (32 per mini-batch)
2024-04-23 17:03:25,375 - Epoch: [67][  100/  123]    Loss 0.836288    Top1 72.812500    Top5 95.968750    
2024-04-23 17:03:28,501 - Epoch: [67][  123/  123]    Loss 0.832679    Top1 72.968153    Top5 96.025478    
2024-04-23 17:03:28,762 - ==> Top1: 72.968    Top5: 96.025    Loss: 0.833

2024-04-23 17:03:28,773 - ==> Best [Top1: 73.732   Top5: 96.357   Sparsity:0.00   Params: 370272 on epoch: 66]
2024-04-23 17:03:28,773 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:03:28,839 - 

2024-04-23 17:03:28,840 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:03:49,676 - Epoch: [68][  100/  296]    Overall Loss 0.956177    Objective Loss 0.956177                                        LR 0.000320    Time 0.208121    
2024-04-23 17:04:05,245 - Epoch: [68][  200/  296]    Overall Loss 0.948979    Objective Loss 0.948979                                        LR 0.000320    Time 0.181791    
2024-04-23 17:04:19,614 - Epoch: [68][  296/  296]    Overall Loss 0.942279    Objective Loss 0.942279    Top1 62.295082    Top5 95.081967    LR 0.000320    Time 0.171305    
2024-04-23 17:04:19,992 - --- validate (epoch=68)-----------
2024-04-23 17:04:19,993 - 3925 samples (32 per mini-batch)
2024-04-23 17:04:43,145 - Epoch: [68][  100/  123]    Loss 0.813614    Top1 73.656250    Top5 96.593750    
2024-04-23 17:04:47,409 - Epoch: [68][  123/  123]    Loss 0.829888    Top1 73.171975    Top5 96.382166    
2024-04-23 17:04:47,759 - ==> Top1: 73.172    Top5: 96.382    Loss: 0.830

2024-04-23 17:04:47,772 - ==> Best [Top1: 73.732   Top5: 96.357   Sparsity:0.00   Params: 370272 on epoch: 66]
2024-04-23 17:04:47,773 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:04:47,836 - 

2024-04-23 17:04:47,837 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:05:08,720 - Epoch: [69][  100/  296]    Overall Loss 0.943973    Objective Loss 0.943973                                        LR 0.000320    Time 0.208574    
2024-04-23 17:05:25,584 - Epoch: [69][  200/  296]    Overall Loss 0.955641    Objective Loss 0.955641                                        LR 0.000320    Time 0.188483    
2024-04-23 17:05:43,723 - Epoch: [69][  296/  296]    Overall Loss 0.952773    Objective Loss 0.952773    Top1 67.213115    Top5 91.803279    LR 0.000320    Time 0.188558    
2024-04-23 17:05:44,059 - --- validate (epoch=69)-----------
2024-04-23 17:05:44,061 - 3925 samples (32 per mini-batch)
2024-04-23 17:06:09,988 - Epoch: [69][  100/  123]    Loss 0.800063    Top1 74.718750    Top5 96.343750    
2024-04-23 17:06:14,549 - Epoch: [69][  123/  123]    Loss 0.814916    Top1 74.318471    Top5 96.229299    
2024-04-23 17:06:14,890 - ==> Top1: 74.318    Top5: 96.229    Loss: 0.815

2024-04-23 17:06:14,906 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:06:14,907 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:06:15,034 - 

2024-04-23 17:06:15,035 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:06:35,591 - Epoch: [70][  100/  296]    Overall Loss 0.944604    Objective Loss 0.944604                                        LR 0.000320    Time 0.205319    
2024-04-23 17:06:52,883 - Epoch: [70][  200/  296]    Overall Loss 0.940577    Objective Loss 0.940577                                        LR 0.000320    Time 0.189007    
2024-04-23 17:07:10,329 - Epoch: [70][  296/  296]    Overall Loss 0.945813    Objective Loss 0.945813    Top1 75.409836    Top5 96.721311    LR 0.000320    Time 0.186567    
2024-04-23 17:07:10,718 - --- validate (epoch=70)-----------
2024-04-23 17:07:10,720 - 3925 samples (32 per mini-batch)
2024-04-23 17:07:29,606 - Epoch: [70][  100/  123]    Loss 0.818463    Top1 73.218750    Top5 96.593750    
2024-04-23 17:07:32,803 - Epoch: [70][  123/  123]    Loss 0.822989    Top1 72.993631    Top5 96.458599    
2024-04-23 17:07:32,946 - ==> Top1: 72.994    Top5: 96.459    Loss: 0.823

2024-04-23 17:07:32,950 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:07:32,950 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:07:32,985 - 

2024-04-23 17:07:32,986 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:07:50,239 - Epoch: [71][  100/  296]    Overall Loss 0.928609    Objective Loss 0.928609                                        LR 0.000320    Time 0.172319    
2024-04-23 17:08:04,495 - Epoch: [71][  200/  296]    Overall Loss 0.954333    Objective Loss 0.954333                                        LR 0.000320    Time 0.157339    
2024-04-23 17:08:19,977 - Epoch: [71][  296/  296]    Overall Loss 0.940223    Objective Loss 0.940223    Top1 67.213115    Top5 93.442623    LR 0.000320    Time 0.158516    
2024-04-23 17:08:20,316 - --- validate (epoch=71)-----------
2024-04-23 17:08:20,318 - 3925 samples (32 per mini-batch)
2024-04-23 17:08:42,728 - Epoch: [71][  100/  123]    Loss 0.800620    Top1 73.593750    Top5 96.687500    
2024-04-23 17:08:46,769 - Epoch: [71][  123/  123]    Loss 0.819128    Top1 73.299363    Top5 96.331210    
2024-04-23 17:08:47,100 - ==> Top1: 73.299    Top5: 96.331    Loss: 0.819

2024-04-23 17:08:47,112 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:08:47,113 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:08:47,228 - 

2024-04-23 17:08:47,229 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:09:04,109 - Epoch: [72][  100/  296]    Overall Loss 0.939904    Objective Loss 0.939904                                        LR 0.000320    Time 0.168438    
2024-04-23 17:09:20,709 - Epoch: [72][  200/  296]    Overall Loss 0.947137    Objective Loss 0.947137                                        LR 0.000320    Time 0.167101    
2024-04-23 17:09:36,826 - Epoch: [72][  296/  296]    Overall Loss 0.949055    Objective Loss 0.949055    Top1 68.852459    Top5 93.442623    LR 0.000320    Time 0.167284    
2024-04-23 17:09:37,069 - --- validate (epoch=72)-----------
2024-04-23 17:09:37,071 - 3925 samples (32 per mini-batch)
2024-04-23 17:09:56,037 - Epoch: [72][  100/  123]    Loss 0.880376    Top1 71.718750    Top5 95.437500    
2024-04-23 17:09:59,617 - Epoch: [72][  123/  123]    Loss 0.877163    Top1 71.363057    Top5 95.490446    
2024-04-23 17:09:59,880 - ==> Top1: 71.363    Top5: 95.490    Loss: 0.877

2024-04-23 17:09:59,895 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:09:59,896 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:09:59,989 - 

2024-04-23 17:09:59,990 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:10:17,889 - Epoch: [73][  100/  296]    Overall Loss 0.952860    Objective Loss 0.952860                                        LR 0.000320    Time 0.178737    
2024-04-23 17:10:34,072 - Epoch: [73][  200/  296]    Overall Loss 0.955454    Objective Loss 0.955454                                        LR 0.000320    Time 0.170171    
2024-04-23 17:10:48,737 - Epoch: [73][  296/  296]    Overall Loss 0.946050    Objective Loss 0.946050    Top1 77.049180    Top5 100.000000    LR 0.000320    Time 0.164446    
2024-04-23 17:10:49,110 - --- validate (epoch=73)-----------
2024-04-23 17:10:49,111 - 3925 samples (32 per mini-batch)
2024-04-23 17:11:06,130 - Epoch: [73][  100/  123]    Loss 0.850395    Top1 72.937500    Top5 96.218750    
2024-04-23 17:11:09,626 - Epoch: [73][  123/  123]    Loss 0.847325    Top1 72.560510    Top5 96.305732    
2024-04-23 17:11:09,952 - ==> Top1: 72.561    Top5: 96.306    Loss: 0.847

2024-04-23 17:11:09,963 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:11:09,964 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:11:10,029 - 

2024-04-23 17:11:10,032 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:11:29,540 - Epoch: [74][  100/  296]    Overall Loss 0.964282    Objective Loss 0.964282                                        LR 0.000320    Time 0.194812    
2024-04-23 17:11:44,330 - Epoch: [74][  200/  296]    Overall Loss 0.956919    Objective Loss 0.956919                                        LR 0.000320    Time 0.171250    
2024-04-23 17:11:59,046 - Epoch: [74][  296/  296]    Overall Loss 0.958423    Objective Loss 0.958423    Top1 68.852459    Top5 95.081967    LR 0.000320    Time 0.165355    
2024-04-23 17:11:59,401 - --- validate (epoch=74)-----------
2024-04-23 17:11:59,402 - 3925 samples (32 per mini-batch)
2024-04-23 17:12:17,820 - Epoch: [74][  100/  123]    Loss 0.816504    Top1 73.625000    Top5 96.718750    
2024-04-23 17:12:21,623 - Epoch: [74][  123/  123]    Loss 0.821404    Top1 73.273885    Top5 96.738854    
2024-04-23 17:12:21,918 - ==> Top1: 73.274    Top5: 96.739    Loss: 0.821

2024-04-23 17:12:21,926 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:12:21,927 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:12:21,984 - 

2024-04-23 17:12:21,985 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:12:40,254 - Epoch: [75][  100/  296]    Overall Loss 0.931792    Objective Loss 0.931792                                        LR 0.000320    Time 0.182412    
2024-04-23 17:12:56,370 - Epoch: [75][  200/  296]    Overall Loss 0.918475    Objective Loss 0.918475                                        LR 0.000320    Time 0.171658    
2024-04-23 17:13:11,081 - Epoch: [75][  296/  296]    Overall Loss 0.908283    Objective Loss 0.908283    Top1 60.655738    Top5 95.081967    LR 0.000320    Time 0.165607    
2024-04-23 17:13:11,417 - --- validate (epoch=75)-----------
2024-04-23 17:13:11,419 - 3925 samples (32 per mini-batch)
2024-04-23 17:13:32,291 - Epoch: [75][  100/  123]    Loss 0.879057    Top1 71.406250    Top5 95.593750    
2024-04-23 17:13:36,726 - Epoch: [75][  123/  123]    Loss 0.868399    Top1 72.025478    Top5 95.719745    
2024-04-23 17:13:37,015 - ==> Top1: 72.025    Top5: 95.720    Loss: 0.868

2024-04-23 17:13:37,028 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:13:37,029 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:13:37,105 - 

2024-04-23 17:13:37,106 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:13:57,533 - Epoch: [76][  100/  296]    Overall Loss 0.970521    Objective Loss 0.970521                                        LR 0.000320    Time 0.204018    
2024-04-23 17:14:15,616 - Epoch: [76][  200/  296]    Overall Loss 0.950262    Objective Loss 0.950262                                        LR 0.000320    Time 0.192311    
2024-04-23 17:14:30,753 - Epoch: [76][  296/  296]    Overall Loss 0.954967    Objective Loss 0.954967    Top1 72.131148    Top5 93.442623    LR 0.000320    Time 0.181006    
2024-04-23 17:14:31,066 - --- validate (epoch=76)-----------
2024-04-23 17:14:31,068 - 3925 samples (32 per mini-batch)
2024-04-23 17:14:51,384 - Epoch: [76][  100/  123]    Loss 0.922967    Top1 70.531250    Top5 96.218750    
2024-04-23 17:14:55,300 - Epoch: [76][  123/  123]    Loss 0.930245    Top1 70.165605    Top5 96.280255    
2024-04-23 17:14:55,664 - ==> Top1: 70.166    Top5: 96.280    Loss: 0.930

2024-04-23 17:14:55,675 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:14:55,676 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:14:55,755 - 

2024-04-23 17:14:55,756 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:15:14,773 - Epoch: [77][  100/  296]    Overall Loss 0.908341    Objective Loss 0.908341                                        LR 0.000320    Time 0.189906    
2024-04-23 17:15:30,251 - Epoch: [77][  200/  296]    Overall Loss 0.915098    Objective Loss 0.915098                                        LR 0.000320    Time 0.172238    
2024-04-23 17:15:45,146 - Epoch: [77][  296/  296]    Overall Loss 0.930751    Objective Loss 0.930751    Top1 59.016393    Top5 93.442623    LR 0.000320    Time 0.166627    
2024-04-23 17:15:45,485 - --- validate (epoch=77)-----------
2024-04-23 17:15:45,487 - 3925 samples (32 per mini-batch)
2024-04-23 17:16:05,829 - Epoch: [77][  100/  123]    Loss 0.850630    Top1 73.250000    Top5 96.093750    
2024-04-23 17:16:10,292 - Epoch: [77][  123/  123]    Loss 0.849503    Top1 73.146497    Top5 96.050955    
2024-04-23 17:16:10,590 - ==> Top1: 73.146    Top5: 96.051    Loss: 0.850

2024-04-23 17:16:10,599 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:16:10,600 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:16:10,651 - 

2024-04-23 17:16:10,652 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:16:27,476 - Epoch: [78][  100/  296]    Overall Loss 0.901502    Objective Loss 0.901502                                        LR 0.000320    Time 0.167991    
2024-04-23 17:16:40,918 - Epoch: [78][  200/  296]    Overall Loss 0.907418    Objective Loss 0.907418                                        LR 0.000320    Time 0.151089    
2024-04-23 17:16:56,376 - Epoch: [78][  296/  296]    Overall Loss 0.917907    Objective Loss 0.917907    Top1 60.655738    Top5 90.163934    LR 0.000320    Time 0.154234    
2024-04-23 17:16:56,744 - --- validate (epoch=78)-----------
2024-04-23 17:16:56,746 - 3925 samples (32 per mini-batch)
2024-04-23 17:17:16,387 - Epoch: [78][  100/  123]    Loss 0.870086    Top1 72.125000    Top5 95.625000    
2024-04-23 17:17:20,128 - Epoch: [78][  123/  123]    Loss 0.872246    Top1 71.898089    Top5 95.745223    
2024-04-23 17:17:20,430 - ==> Top1: 71.898    Top5: 95.745    Loss: 0.872

2024-04-23 17:17:20,446 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:17:20,447 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:17:20,537 - 

2024-04-23 17:17:20,539 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:17:38,094 - Epoch: [79][  100/  296]    Overall Loss 0.948635    Objective Loss 0.948635                                        LR 0.000320    Time 0.175307    
2024-04-23 17:17:53,944 - Epoch: [79][  200/  296]    Overall Loss 0.929619    Objective Loss 0.929619                                        LR 0.000320    Time 0.166791    
2024-04-23 17:18:08,539 - Epoch: [79][  296/  296]    Overall Loss 0.932903    Objective Loss 0.932903    Top1 70.491803    Top5 95.081967    LR 0.000320    Time 0.161929    
2024-04-23 17:18:08,913 - --- validate (epoch=79)-----------
2024-04-23 17:18:08,914 - 3925 samples (32 per mini-batch)
2024-04-23 17:18:26,168 - Epoch: [79][  100/  123]    Loss 0.796951    Top1 74.218750    Top5 96.156250    
2024-04-23 17:18:29,731 - Epoch: [79][  123/  123]    Loss 0.811537    Top1 73.732484    Top5 96.076433    
2024-04-23 17:18:30,071 - ==> Top1: 73.732    Top5: 96.076    Loss: 0.812

2024-04-23 17:18:30,082 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:18:30,083 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:18:30,138 - 

2024-04-23 17:18:30,139 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:18:41,527 - Epoch: [80][  100/  296]    Overall Loss 0.898233    Objective Loss 0.898233                                        LR 0.000320    Time 0.113656    
2024-04-23 17:18:55,100 - Epoch: [80][  200/  296]    Overall Loss 0.918437    Objective Loss 0.918437                                        LR 0.000320    Time 0.124577    
2024-04-23 17:19:09,236 - Epoch: [80][  296/  296]    Overall Loss 0.918751    Objective Loss 0.918751    Top1 60.655738    Top5 93.442623    LR 0.000320    Time 0.131865    
2024-04-23 17:19:09,564 - --- validate (epoch=80)-----------
2024-04-23 17:19:09,565 - 3925 samples (32 per mini-batch)
2024-04-23 17:19:26,493 - Epoch: [80][  100/  123]    Loss 0.805624    Top1 73.937500    Top5 97.000000    
2024-04-23 17:19:29,200 - Epoch: [80][  123/  123]    Loss 0.809763    Top1 73.732484    Top5 96.815287    
2024-04-23 17:19:29,536 - ==> Top1: 73.732    Top5: 96.815    Loss: 0.810

2024-04-23 17:19:29,547 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:19:29,547 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:19:29,605 - 

2024-04-23 17:19:29,606 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:19:47,869 - Epoch: [81][  100/  296]    Overall Loss 0.922359    Objective Loss 0.922359                                        LR 0.000320    Time 0.182377    
2024-04-23 17:20:02,901 - Epoch: [81][  200/  296]    Overall Loss 0.924906    Objective Loss 0.924906                                        LR 0.000320    Time 0.166240    
2024-04-23 17:20:16,967 - Epoch: [81][  296/  296]    Overall Loss 0.909974    Objective Loss 0.909974    Top1 67.213115    Top5 93.442623    LR 0.000320    Time 0.159778    
2024-04-23 17:20:17,149 - --- validate (epoch=81)-----------
2024-04-23 17:20:17,149 - 3925 samples (32 per mini-batch)
2024-04-23 17:20:37,044 - Epoch: [81][  100/  123]    Loss 0.823533    Top1 74.031250    Top5 96.500000    
2024-04-23 17:20:40,685 - Epoch: [81][  123/  123]    Loss 0.827254    Top1 73.961783    Top5 96.382166    
2024-04-23 17:20:40,953 - ==> Top1: 73.962    Top5: 96.382    Loss: 0.827

2024-04-23 17:20:40,961 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:20:40,962 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:20:41,012 - 

2024-04-23 17:20:41,013 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:20:57,397 - Epoch: [82][  100/  296]    Overall Loss 0.914812    Objective Loss 0.914812                                        LR 0.000320    Time 0.163610    
2024-04-23 17:21:11,789 - Epoch: [82][  200/  296]    Overall Loss 0.904677    Objective Loss 0.904677                                        LR 0.000320    Time 0.153661    
2024-04-23 17:21:25,960 - Epoch: [82][  296/  296]    Overall Loss 0.915786    Objective Loss 0.915786    Top1 75.409836    Top5 91.803279    LR 0.000320    Time 0.151630    
2024-04-23 17:21:26,323 - --- validate (epoch=82)-----------
2024-04-23 17:21:26,324 - 3925 samples (32 per mini-batch)
2024-04-23 17:21:43,224 - Epoch: [82][  100/  123]    Loss 0.829376    Top1 73.312500    Top5 96.218750    
2024-04-23 17:21:46,530 - Epoch: [82][  123/  123]    Loss 0.813063    Top1 73.656051    Top5 96.407643    
2024-04-23 17:21:46,913 - ==> Top1: 73.656    Top5: 96.408    Loss: 0.813

2024-04-23 17:21:46,924 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:21:46,925 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:21:46,971 - 

2024-04-23 17:21:46,972 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:22:01,606 - Epoch: [83][  100/  296]    Overall Loss 0.887071    Objective Loss 0.887071                                        LR 0.000320    Time 0.146131    
2024-04-23 17:22:16,463 - Epoch: [83][  200/  296]    Overall Loss 0.914310    Objective Loss 0.914310                                        LR 0.000320    Time 0.147229    
2024-04-23 17:22:31,822 - Epoch: [83][  296/  296]    Overall Loss 0.922569    Objective Loss 0.922569    Top1 72.131148    Top5 96.721311    LR 0.000320    Time 0.151297    
2024-04-23 17:22:32,117 - --- validate (epoch=83)-----------
2024-04-23 17:22:32,119 - 3925 samples (32 per mini-batch)
2024-04-23 17:22:48,028 - Epoch: [83][  100/  123]    Loss 0.831099    Top1 73.031250    Top5 96.312500    
2024-04-23 17:22:50,407 - Epoch: [83][  123/  123]    Loss 0.836501    Top1 72.968153    Top5 96.305732    
2024-04-23 17:22:50,721 - ==> Top1: 72.968    Top5: 96.306    Loss: 0.837

2024-04-23 17:22:50,731 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:22:50,732 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:22:50,773 - 

2024-04-23 17:22:50,773 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:23:04,294 - Epoch: [84][  100/  296]    Overall Loss 0.920152    Objective Loss 0.920152                                        LR 0.000320    Time 0.134980    
2024-04-23 17:23:17,441 - Epoch: [84][  200/  296]    Overall Loss 0.925411    Objective Loss 0.925411                                        LR 0.000320    Time 0.133112    
2024-04-23 17:23:31,771 - Epoch: [84][  296/  296]    Overall Loss 0.920100    Objective Loss 0.920100    Top1 63.934426    Top5 90.163934    LR 0.000320    Time 0.138282    
2024-04-23 17:23:32,146 - --- validate (epoch=84)-----------
2024-04-23 17:23:32,147 - 3925 samples (32 per mini-batch)
2024-04-23 17:23:52,461 - Epoch: [84][  100/  123]    Loss 0.904874    Top1 71.156250    Top5 95.718750    
2024-04-23 17:23:56,597 - Epoch: [84][  123/  123]    Loss 0.889824    Top1 71.694268    Top5 95.872611    
2024-04-23 17:23:56,928 - ==> Top1: 71.694    Top5: 95.873    Loss: 0.890

2024-04-23 17:23:56,944 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:23:56,945 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:23:57,024 - 

2024-04-23 17:23:57,025 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:24:14,560 - Epoch: [85][  100/  296]    Overall Loss 0.908474    Objective Loss 0.908474                                        LR 0.000320    Time 0.175100    
2024-04-23 17:24:29,203 - Epoch: [85][  200/  296]    Overall Loss 0.900976    Objective Loss 0.900976                                        LR 0.000320    Time 0.160656    
2024-04-23 17:24:44,405 - Epoch: [85][  296/  296]    Overall Loss 0.903528    Objective Loss 0.903528    Top1 67.213115    Top5 95.081967    LR 0.000320    Time 0.159840    
2024-04-23 17:24:44,711 - --- validate (epoch=85)-----------
2024-04-23 17:24:44,713 - 3925 samples (32 per mini-batch)
2024-04-23 17:25:03,918 - Epoch: [85][  100/  123]    Loss 0.821491    Top1 73.093750    Top5 96.562500    
2024-04-23 17:25:08,178 - Epoch: [85][  123/  123]    Loss 0.822684    Top1 73.095541    Top5 96.484076    
2024-04-23 17:25:08,544 - ==> Top1: 73.096    Top5: 96.484    Loss: 0.823

2024-04-23 17:25:08,554 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:25:08,554 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:25:08,608 - 

2024-04-23 17:25:08,609 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:25:24,287 - Epoch: [86][  100/  296]    Overall Loss 0.895064    Objective Loss 0.895064                                        LR 0.000320    Time 0.156549    
2024-04-23 17:25:40,102 - Epoch: [86][  200/  296]    Overall Loss 0.911205    Objective Loss 0.911205                                        LR 0.000320    Time 0.157244    
2024-04-23 17:25:53,725 - Epoch: [86][  296/  296]    Overall Loss 0.913571    Objective Loss 0.913571    Top1 63.934426    Top5 96.721311    LR 0.000320    Time 0.152196    
2024-04-23 17:25:54,072 - --- validate (epoch=86)-----------
2024-04-23 17:25:54,073 - 3925 samples (32 per mini-batch)
2024-04-23 17:26:08,803 - Epoch: [86][  100/  123]    Loss 0.817127    Top1 73.500000    Top5 96.437500    
2024-04-23 17:26:11,078 - Epoch: [86][  123/  123]    Loss 0.804688    Top1 73.605096    Top5 96.560510    
2024-04-23 17:26:11,386 - ==> Top1: 73.605    Top5: 96.561    Loss: 0.805

2024-04-23 17:26:11,397 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:26:11,398 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:26:11,439 - 

2024-04-23 17:26:11,440 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:26:25,921 - Epoch: [87][  100/  296]    Overall Loss 0.921742    Objective Loss 0.921742                                        LR 0.000320    Time 0.144579    
2024-04-23 17:26:37,653 - Epoch: [87][  200/  296]    Overall Loss 0.899563    Objective Loss 0.899563                                        LR 0.000320    Time 0.130847    
2024-04-23 17:26:49,532 - Epoch: [87][  296/  296]    Overall Loss 0.897491    Objective Loss 0.897491    Top1 70.491803    Top5 98.360656    LR 0.000320    Time 0.128470    
2024-04-23 17:26:49,844 - --- validate (epoch=87)-----------
2024-04-23 17:26:49,846 - 3925 samples (32 per mini-batch)
2024-04-23 17:27:06,596 - Epoch: [87][  100/  123]    Loss 0.818589    Top1 72.781250    Top5 96.656250    
2024-04-23 17:27:09,583 - Epoch: [87][  123/  123]    Loss 0.808153    Top1 73.375796    Top5 96.713376    
2024-04-23 17:27:09,916 - ==> Top1: 73.376    Top5: 96.713    Loss: 0.808

2024-04-23 17:27:09,927 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:27:09,928 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:27:09,975 - 

2024-04-23 17:27:09,976 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:27:22,988 - Epoch: [88][  100/  296]    Overall Loss 0.890127    Objective Loss 0.890127                                        LR 0.000320    Time 0.129911    
2024-04-23 17:27:35,294 - Epoch: [88][  200/  296]    Overall Loss 0.903628    Objective Loss 0.903628                                        LR 0.000320    Time 0.126375    
2024-04-23 17:27:46,618 - Epoch: [88][  296/  296]    Overall Loss 0.899412    Objective Loss 0.899412    Top1 62.295082    Top5 96.721311    LR 0.000320    Time 0.123579    
2024-04-23 17:27:46,863 - --- validate (epoch=88)-----------
2024-04-23 17:27:46,864 - 3925 samples (32 per mini-batch)
2024-04-23 17:28:02,213 - Epoch: [88][  100/  123]    Loss 0.815771    Top1 73.281250    Top5 96.562500    
2024-04-23 17:28:04,828 - Epoch: [88][  123/  123]    Loss 0.814418    Top1 73.554140    Top5 96.458599    
2024-04-23 17:28:05,153 - ==> Top1: 73.554    Top5: 96.459    Loss: 0.814

2024-04-23 17:28:05,163 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:28:05,163 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:28:05,206 - 

2024-04-23 17:28:05,207 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:28:18,188 - Epoch: [89][  100/  296]    Overall Loss 0.885856    Objective Loss 0.885856                                        LR 0.000320    Time 0.129597    
2024-04-23 17:28:29,676 - Epoch: [89][  200/  296]    Overall Loss 0.898038    Objective Loss 0.898038                                        LR 0.000320    Time 0.122134    
2024-04-23 17:28:40,209 - Epoch: [89][  296/  296]    Overall Loss 0.885541    Objective Loss 0.885541    Top1 78.688525    Top5 98.360656    LR 0.000320    Time 0.118044    
2024-04-23 17:28:40,482 - --- validate (epoch=89)-----------
2024-04-23 17:28:40,483 - 3925 samples (32 per mini-batch)
2024-04-23 17:28:56,016 - Epoch: [89][  100/  123]    Loss 0.888673    Top1 71.500000    Top5 95.968750    
2024-04-23 17:28:59,259 - Epoch: [89][  123/  123]    Loss 0.903694    Top1 71.057325    Top5 95.872611    
2024-04-23 17:28:59,534 - ==> Top1: 71.057    Top5: 95.873    Loss: 0.904

2024-04-23 17:28:59,542 - ==> Best [Top1: 74.318   Top5: 96.229   Sparsity:0.00   Params: 370272 on epoch: 69]
2024-04-23 17:28:59,543 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:28:59,590 - 

2024-04-23 17:28:59,591 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:29:15,447 - Epoch: [90][  100/  296]    Overall Loss 0.899320    Objective Loss 0.899320                                        LR 0.000320    Time 0.158324    
2024-04-23 17:29:28,750 - Epoch: [90][  200/  296]    Overall Loss 0.913022    Objective Loss 0.913022                                        LR 0.000320    Time 0.145568    
2024-04-23 17:29:40,362 - Epoch: [90][  296/  296]    Overall Loss 0.913122    Objective Loss 0.913122    Top1 78.688525    Top5 95.081967    LR 0.000320    Time 0.137519    
2024-04-23 17:29:40,684 - --- validate (epoch=90)-----------
2024-04-23 17:29:40,685 - 3925 samples (32 per mini-batch)
2024-04-23 17:29:57,470 - Epoch: [90][  100/  123]    Loss 0.791512    Top1 74.562500    Top5 96.531250    
2024-04-23 17:30:00,350 - Epoch: [90][  123/  123]    Loss 0.786186    Top1 74.802548    Top5 96.560510    
2024-04-23 17:30:00,687 - ==> Top1: 74.803    Top5: 96.561    Loss: 0.786

2024-04-23 17:30:00,694 - ==> Best [Top1: 74.803   Top5: 96.561   Sparsity:0.00   Params: 370272 on epoch: 90]
2024-04-23 17:30:00,695 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:30:00,763 - 

2024-04-23 17:30:00,764 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:30:17,017 - Epoch: [91][  100/  296]    Overall Loss 0.884820    Objective Loss 0.884820                                        LR 0.000320    Time 0.162297    
2024-04-23 17:30:30,434 - Epoch: [91][  200/  296]    Overall Loss 0.887697    Objective Loss 0.887697                                        LR 0.000320    Time 0.148114    
2024-04-23 17:30:43,229 - Epoch: [91][  296/  296]    Overall Loss 0.890905    Objective Loss 0.890905    Top1 77.049180    Top5 91.803279    LR 0.000320    Time 0.143232    
2024-04-23 17:30:43,507 - --- validate (epoch=91)-----------
2024-04-23 17:30:43,508 - 3925 samples (32 per mini-batch)
2024-04-23 17:31:00,367 - Epoch: [91][  100/  123]    Loss 0.764507    Top1 75.281250    Top5 96.687500    
2024-04-23 17:31:03,846 - Epoch: [91][  123/  123]    Loss 0.781841    Top1 74.700637    Top5 96.560510    
2024-04-23 17:31:04,155 - ==> Top1: 74.701    Top5: 96.561    Loss: 0.782

2024-04-23 17:31:04,168 - ==> Best [Top1: 74.803   Top5: 96.561   Sparsity:0.00   Params: 370272 on epoch: 90]
2024-04-23 17:31:04,168 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:31:04,234 - 

2024-04-23 17:31:04,244 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:31:19,750 - Epoch: [92][  100/  296]    Overall Loss 0.881775    Objective Loss 0.881775                                        LR 0.000320    Time 0.154749    
2024-04-23 17:31:32,455 - Epoch: [92][  200/  296]    Overall Loss 0.883791    Objective Loss 0.883791                                        LR 0.000320    Time 0.140792    
2024-04-23 17:31:46,373 - Epoch: [92][  296/  296]    Overall Loss 0.892404    Objective Loss 0.892404    Top1 63.934426    Top5 91.803279    LR 0.000320    Time 0.142082    
2024-04-23 17:31:46,726 - --- validate (epoch=92)-----------
2024-04-23 17:31:46,727 - 3925 samples (32 per mini-batch)
2024-04-23 17:32:03,822 - Epoch: [92][  100/  123]    Loss 0.757039    Top1 75.531250    Top5 96.593750    
2024-04-23 17:32:07,323 - Epoch: [92][  123/  123]    Loss 0.767325    Top1 75.439490    Top5 96.509554    
2024-04-23 17:32:07,593 - ==> Top1: 75.439    Top5: 96.510    Loss: 0.767

2024-04-23 17:32:07,601 - ==> Best [Top1: 75.439   Top5: 96.510   Sparsity:0.00   Params: 370272 on epoch: 92]
2024-04-23 17:32:07,602 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:32:07,668 - 

2024-04-23 17:32:07,669 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:32:22,894 - Epoch: [93][  100/  296]    Overall Loss 0.870501    Objective Loss 0.870501                                        LR 0.000320    Time 0.152017    
2024-04-23 17:32:34,892 - Epoch: [93][  200/  296]    Overall Loss 0.871925    Objective Loss 0.871925                                        LR 0.000320    Time 0.135896    
2024-04-23 17:32:48,421 - Epoch: [93][  296/  296]    Overall Loss 0.889192    Objective Loss 0.889192    Top1 65.573770    Top5 98.360656    LR 0.000320    Time 0.137458    
2024-04-23 17:32:48,746 - --- validate (epoch=93)-----------
2024-04-23 17:32:48,747 - 3925 samples (32 per mini-batch)
2024-04-23 17:33:05,053 - Epoch: [93][  100/  123]    Loss 0.779532    Top1 75.437500    Top5 96.343750    
2024-04-23 17:33:07,834 - Epoch: [93][  123/  123]    Loss 0.766643    Top1 75.541401    Top5 96.611465    
2024-04-23 17:33:08,086 - ==> Top1: 75.541    Top5: 96.611    Loss: 0.767

2024-04-23 17:33:08,093 - ==> Best [Top1: 75.541   Top5: 96.611   Sparsity:0.00   Params: 370272 on epoch: 93]
2024-04-23 17:33:08,094 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:33:08,144 - 

2024-04-23 17:33:08,145 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:33:21,414 - Epoch: [94][  100/  296]    Overall Loss 0.858096    Objective Loss 0.858096                                        LR 0.000320    Time 0.132474    
2024-04-23 17:33:35,945 - Epoch: [94][  200/  296]    Overall Loss 0.875269    Objective Loss 0.875269                                        LR 0.000320    Time 0.138793    
2024-04-23 17:33:50,612 - Epoch: [94][  296/  296]    Overall Loss 0.887488    Objective Loss 0.887488    Top1 72.131148    Top5 98.360656    LR 0.000320    Time 0.143255    
2024-04-23 17:33:50,924 - --- validate (epoch=94)-----------
2024-04-23 17:33:50,925 - 3925 samples (32 per mini-batch)
2024-04-23 17:34:06,588 - Epoch: [94][  100/  123]    Loss 0.814274    Top1 73.500000    Top5 96.718750    
2024-04-23 17:34:09,930 - Epoch: [94][  123/  123]    Loss 0.820547    Top1 73.273885    Top5 96.636943    
2024-04-23 17:34:10,208 - ==> Top1: 73.274    Top5: 96.637    Loss: 0.821

2024-04-23 17:34:10,216 - ==> Best [Top1: 75.541   Top5: 96.611   Sparsity:0.00   Params: 370272 on epoch: 93]
2024-04-23 17:34:10,217 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:34:10,273 - 

2024-04-23 17:34:10,274 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:34:26,699 - Epoch: [95][  100/  296]    Overall Loss 0.886473    Objective Loss 0.886473                                        LR 0.000320    Time 0.164029    
2024-04-23 17:34:42,088 - Epoch: [95][  200/  296]    Overall Loss 0.890362    Objective Loss 0.890362                                        LR 0.000320    Time 0.158846    
2024-04-23 17:34:55,814 - Epoch: [95][  296/  296]    Overall Loss 0.907178    Objective Loss 0.907178    Top1 73.770492    Top5 100.000000    LR 0.000320    Time 0.153629    
2024-04-23 17:34:56,060 - --- validate (epoch=95)-----------
2024-04-23 17:34:56,061 - 3925 samples (32 per mini-batch)
2024-04-23 17:35:16,401 - Epoch: [95][  100/  123]    Loss 0.791689    Top1 74.781250    Top5 96.750000    
2024-04-23 17:35:21,091 - Epoch: [95][  123/  123]    Loss 0.785863    Top1 75.031847    Top5 96.585987    
2024-04-23 17:35:21,343 - ==> Top1: 75.032    Top5: 96.586    Loss: 0.786

2024-04-23 17:35:21,354 - ==> Best [Top1: 75.541   Top5: 96.611   Sparsity:0.00   Params: 370272 on epoch: 93]
2024-04-23 17:35:21,355 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:35:21,413 - 

2024-04-23 17:35:21,414 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:35:38,558 - Epoch: [96][  100/  296]    Overall Loss 0.922117    Objective Loss 0.922117                                        LR 0.000320    Time 0.171200    
2024-04-23 17:35:50,012 - Epoch: [96][  200/  296]    Overall Loss 0.896455    Objective Loss 0.896455                                        LR 0.000320    Time 0.142759    
2024-04-23 17:36:03,441 - Epoch: [96][  296/  296]    Overall Loss 0.892962    Objective Loss 0.892962    Top1 70.491803    Top5 93.442623    LR 0.000320    Time 0.141759    
2024-04-23 17:36:03,749 - --- validate (epoch=96)-----------
2024-04-23 17:36:03,750 - 3925 samples (32 per mini-batch)
2024-04-23 17:36:21,807 - Epoch: [96][  100/  123]    Loss 0.771427    Top1 75.625000    Top5 96.781250    
2024-04-23 17:36:25,746 - Epoch: [96][  123/  123]    Loss 0.776971    Top1 75.439490    Top5 96.764331    
2024-04-23 17:36:26,074 - ==> Top1: 75.439    Top5: 96.764    Loss: 0.777

2024-04-23 17:36:26,083 - ==> Best [Top1: 75.541   Top5: 96.611   Sparsity:0.00   Params: 370272 on epoch: 93]
2024-04-23 17:36:26,085 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:36:26,173 - 

2024-04-23 17:36:26,175 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:36:44,751 - Epoch: [97][  100/  296]    Overall Loss 0.884413    Objective Loss 0.884413                                        LR 0.000320    Time 0.185522    
2024-04-23 17:37:02,399 - Epoch: [97][  200/  296]    Overall Loss 0.877782    Objective Loss 0.877782                                        LR 0.000320    Time 0.180888    
2024-04-23 17:37:16,603 - Epoch: [97][  296/  296]    Overall Loss 0.883292    Objective Loss 0.883292    Top1 60.655738    Top5 96.721311    LR 0.000320    Time 0.170136    
2024-04-23 17:37:16,925 - --- validate (epoch=97)-----------
2024-04-23 17:37:16,926 - 3925 samples (32 per mini-batch)
2024-04-23 17:37:34,957 - Epoch: [97][  100/  123]    Loss 0.785877    Top1 75.125000    Top5 96.843750    
2024-04-23 17:37:38,725 - Epoch: [97][  123/  123]    Loss 0.794375    Top1 74.828025    Top5 96.891720    
2024-04-23 17:37:38,989 - ==> Top1: 74.828    Top5: 96.892    Loss: 0.794

2024-04-23 17:37:39,004 - ==> Best [Top1: 75.541   Top5: 96.611   Sparsity:0.00   Params: 370272 on epoch: 93]
2024-04-23 17:37:39,005 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:37:39,101 - 

2024-04-23 17:37:39,102 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:37:55,898 - Epoch: [98][  100/  296]    Overall Loss 0.899331    Objective Loss 0.899331                                        LR 0.000320    Time 0.167693    
2024-04-23 17:38:11,107 - Epoch: [98][  200/  296]    Overall Loss 0.903518    Objective Loss 0.903518                                        LR 0.000320    Time 0.159774    
2024-04-23 17:38:24,240 - Epoch: [98][  296/  296]    Overall Loss 0.899179    Objective Loss 0.899179    Top1 75.409836    Top5 91.803279    LR 0.000320    Time 0.152254    
2024-04-23 17:38:24,573 - --- validate (epoch=98)-----------
2024-04-23 17:38:24,575 - 3925 samples (32 per mini-batch)
2024-04-23 17:38:42,156 - Epoch: [98][  100/  123]    Loss 0.755521    Top1 76.125000    Top5 96.531250    
2024-04-23 17:38:45,202 - Epoch: [98][  123/  123]    Loss 0.770888    Top1 75.515924    Top5 96.356688    
2024-04-23 17:38:45,412 - ==> Top1: 75.516    Top5: 96.357    Loss: 0.771

2024-04-23 17:38:45,424 - ==> Best [Top1: 75.541   Top5: 96.611   Sparsity:0.00   Params: 370272 on epoch: 93]
2024-04-23 17:38:45,425 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:38:45,495 - 

2024-04-23 17:38:45,496 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:39:03,905 - Epoch: [99][  100/  296]    Overall Loss 0.899029    Objective Loss 0.899029                                        LR 0.000320    Time 0.183829    
2024-04-23 17:39:18,658 - Epoch: [99][  200/  296]    Overall Loss 0.891472    Objective Loss 0.891472                                        LR 0.000320    Time 0.165566    
2024-04-23 17:39:28,134 - Epoch: [99][  296/  296]    Overall Loss 0.886500    Objective Loss 0.886500    Top1 67.213115    Top5 98.360656    LR 0.000320    Time 0.143815    
2024-04-23 17:39:28,424 - --- validate (epoch=99)-----------
2024-04-23 17:39:28,424 - 3925 samples (32 per mini-batch)
2024-04-23 17:39:42,604 - Epoch: [99][  100/  123]    Loss 0.782842    Top1 74.281250    Top5 96.531250    
2024-04-23 17:39:44,962 - Epoch: [99][  123/  123]    Loss 0.784253    Top1 74.471338    Top5 96.382166    
2024-04-23 17:39:45,201 - ==> Top1: 74.471    Top5: 96.382    Loss: 0.784

2024-04-23 17:39:45,209 - ==> Best [Top1: 75.541   Top5: 96.611   Sparsity:0.00   Params: 370272 on epoch: 93]
2024-04-23 17:39:45,209 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:39:45,255 - 

2024-04-23 17:39:45,256 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:40:00,116 - Epoch: [100][  100/  296]    Overall Loss 0.853980    Objective Loss 0.853980                                        LR 0.000080    Time 0.148364    
2024-04-23 17:40:14,217 - Epoch: [100][  200/  296]    Overall Loss 0.841421    Objective Loss 0.841421                                        LR 0.000080    Time 0.144577    
2024-04-23 17:40:26,460 - Epoch: [100][  296/  296]    Overall Loss 0.836356    Objective Loss 0.836356    Top1 72.131148    Top5 96.721311    LR 0.000080    Time 0.138955    
2024-04-23 17:40:26,767 - --- validate (epoch=100)-----------
2024-04-23 17:40:26,768 - 3925 samples (32 per mini-batch)
2024-04-23 17:40:41,652 - Epoch: [100][  100/  123]    Loss 0.721764    Top1 76.375000    Top5 97.281250    
2024-04-23 17:40:44,525 - Epoch: [100][  123/  123]    Loss 0.719289    Top1 76.611465    Top5 97.222930    
2024-04-23 17:40:44,825 - ==> Top1: 76.611    Top5: 97.223    Loss: 0.719

2024-04-23 17:40:44,837 - ==> Best [Top1: 76.611   Top5: 97.223   Sparsity:0.00   Params: 370272 on epoch: 100]
2024-04-23 17:40:44,838 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:40:44,900 - 

2024-04-23 17:40:44,902 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:41:00,960 - Epoch: [101][  100/  296]    Overall Loss 0.827327    Objective Loss 0.827327                                        LR 0.000080    Time 0.160355    
2024-04-23 17:41:14,100 - Epoch: [101][  200/  296]    Overall Loss 0.833225    Objective Loss 0.833225                                        LR 0.000080    Time 0.145769    
2024-04-23 17:41:26,641 - Epoch: [101][  296/  296]    Overall Loss 0.832458    Objective Loss 0.832458    Top1 70.491803    Top5 93.442623    LR 0.000080    Time 0.140790    
2024-04-23 17:41:26,970 - --- validate (epoch=101)-----------
2024-04-23 17:41:26,971 - 3925 samples (32 per mini-batch)
2024-04-23 17:41:44,446 - Epoch: [101][  100/  123]    Loss 0.733959    Top1 76.437500    Top5 96.968750    
2024-04-23 17:41:48,282 - Epoch: [101][  123/  123]    Loss 0.723099    Top1 76.687898    Top5 96.968153    
2024-04-23 17:41:48,596 - ==> Top1: 76.688    Top5: 96.968    Loss: 0.723

2024-04-23 17:41:48,607 - ==> Best [Top1: 76.688   Top5: 96.968   Sparsity:0.00   Params: 370272 on epoch: 101]
2024-04-23 17:41:48,607 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:41:48,674 - 

2024-04-23 17:41:48,675 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:42:04,141 - Epoch: [102][  100/  296]    Overall Loss 0.825911    Objective Loss 0.825911                                        LR 0.000080    Time 0.154428    
2024-04-23 17:42:18,184 - Epoch: [102][  200/  296]    Overall Loss 0.828365    Objective Loss 0.828365                                        LR 0.000080    Time 0.147315    
2024-04-23 17:42:32,111 - Epoch: [102][  296/  296]    Overall Loss 0.823719    Objective Loss 0.823719    Top1 60.655738    Top5 98.360656    LR 0.000080    Time 0.146513    
2024-04-23 17:42:32,487 - --- validate (epoch=102)-----------
2024-04-23 17:42:32,489 - 3925 samples (32 per mini-batch)
2024-04-23 17:42:49,440 - Epoch: [102][  100/  123]    Loss 0.720457    Top1 76.718750    Top5 97.093750    
2024-04-23 17:42:53,605 - Epoch: [102][  123/  123]    Loss 0.729287    Top1 76.687898    Top5 96.942675    
2024-04-23 17:42:53,930 - ==> Top1: 76.688    Top5: 96.943    Loss: 0.729

2024-04-23 17:42:53,938 - ==> Best [Top1: 76.688   Top5: 96.968   Sparsity:0.00   Params: 370272 on epoch: 101]
2024-04-23 17:42:53,939 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:42:54,004 - 

2024-04-23 17:42:54,005 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:43:07,244 - Epoch: [103][  100/  296]    Overall Loss 0.844845    Objective Loss 0.844845                                        LR 0.000080    Time 0.132177    
2024-04-23 17:43:21,981 - Epoch: [103][  200/  296]    Overall Loss 0.830634    Objective Loss 0.830634                                        LR 0.000080    Time 0.139659    
2024-04-23 17:43:35,545 - Epoch: [103][  296/  296]    Overall Loss 0.810162    Objective Loss 0.810162    Top1 67.213115    Top5 95.081967    LR 0.000080    Time 0.140116    
2024-04-23 17:43:35,891 - --- validate (epoch=103)-----------
2024-04-23 17:43:35,893 - 3925 samples (32 per mini-batch)
2024-04-23 17:43:53,334 - Epoch: [103][  100/  123]    Loss 0.719949    Top1 77.250000    Top5 97.031250    
2024-04-23 17:43:56,725 - Epoch: [103][  123/  123]    Loss 0.721155    Top1 77.222930    Top5 97.044586    
2024-04-23 17:43:57,000 - ==> Top1: 77.223    Top5: 97.045    Loss: 0.721

2024-04-23 17:43:57,009 - ==> Best [Top1: 77.223   Top5: 97.045   Sparsity:0.00   Params: 370272 on epoch: 103]
2024-04-23 17:43:57,010 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:43:57,081 - 

2024-04-23 17:43:57,082 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:44:12,116 - Epoch: [104][  100/  296]    Overall Loss 0.835607    Objective Loss 0.835607                                        LR 0.000080    Time 0.150092    
2024-04-23 17:44:24,443 - Epoch: [104][  200/  296]    Overall Loss 0.826070    Objective Loss 0.826070                                        LR 0.000080    Time 0.136570    
2024-04-23 17:44:37,544 - Epoch: [104][  296/  296]    Overall Loss 0.817544    Objective Loss 0.817544    Top1 70.491803    Top5 96.721311    LR 0.000080    Time 0.136462    
2024-04-23 17:44:37,878 - --- validate (epoch=104)-----------
2024-04-23 17:44:37,880 - 3925 samples (32 per mini-batch)
2024-04-23 17:44:53,892 - Epoch: [104][  100/  123]    Loss 0.721249    Top1 76.875000    Top5 97.062500    
2024-04-23 17:44:57,276 - Epoch: [104][  123/  123]    Loss 0.713156    Top1 77.146497    Top5 97.121019    
2024-04-23 17:44:57,560 - ==> Top1: 77.146    Top5: 97.121    Loss: 0.713

2024-04-23 17:44:57,568 - ==> Best [Top1: 77.223   Top5: 97.045   Sparsity:0.00   Params: 370272 on epoch: 103]
2024-04-23 17:44:57,569 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:44:57,620 - 

2024-04-23 17:44:57,621 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:45:12,655 - Epoch: [105][  100/  296]    Overall Loss 0.820292    Objective Loss 0.820292                                        LR 0.000080    Time 0.150100    
2024-04-23 17:45:27,440 - Epoch: [105][  200/  296]    Overall Loss 0.816896    Objective Loss 0.816896                                        LR 0.000080    Time 0.148859    
2024-04-23 17:45:38,076 - Epoch: [105][  296/  296]    Overall Loss 0.816481    Objective Loss 0.816481    Top1 72.131148    Top5 96.721311    LR 0.000080    Time 0.136446    
2024-04-23 17:45:38,282 - --- validate (epoch=105)-----------
2024-04-23 17:45:38,283 - 3925 samples (32 per mini-batch)
2024-04-23 17:45:52,554 - Epoch: [105][  100/  123]    Loss 0.718934    Top1 77.406250    Top5 97.000000    
2024-04-23 17:45:55,743 - Epoch: [105][  123/  123]    Loss 0.722767    Top1 77.146497    Top5 97.019108    
2024-04-23 17:45:56,057 - ==> Top1: 77.146    Top5: 97.019    Loss: 0.723

2024-04-23 17:45:56,066 - ==> Best [Top1: 77.223   Top5: 97.045   Sparsity:0.00   Params: 370272 on epoch: 103]
2024-04-23 17:45:56,066 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:45:56,140 - 

2024-04-23 17:45:56,141 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:46:10,545 - Epoch: [106][  100/  296]    Overall Loss 0.822741    Objective Loss 0.822741                                        LR 0.000080    Time 0.143793    
2024-04-23 17:46:22,743 - Epoch: [106][  200/  296]    Overall Loss 0.802505    Objective Loss 0.802505                                        LR 0.000080    Time 0.132775    
2024-04-23 17:46:34,295 - Epoch: [106][  296/  296]    Overall Loss 0.797621    Objective Loss 0.797621    Top1 80.327869    Top5 96.721311    LR 0.000080    Time 0.128676    
2024-04-23 17:46:34,540 - --- validate (epoch=106)-----------
2024-04-23 17:46:34,541 - 3925 samples (32 per mini-batch)
2024-04-23 17:46:48,111 - Epoch: [106][  100/  123]    Loss 0.717511    Top1 76.968750    Top5 97.500000    
2024-04-23 17:46:51,047 - Epoch: [106][  123/  123]    Loss 0.715525    Top1 77.222930    Top5 97.324841    
2024-04-23 17:46:51,362 - ==> Top1: 77.223    Top5: 97.325    Loss: 0.716

2024-04-23 17:46:51,370 - ==> Best [Top1: 77.223   Top5: 97.325   Sparsity:0.00   Params: 370272 on epoch: 106]
2024-04-23 17:46:51,370 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:46:51,429 - 

2024-04-23 17:46:51,429 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:47:03,630 - Epoch: [107][  100/  296]    Overall Loss 0.781636    Objective Loss 0.781636                                        LR 0.000080    Time 0.121788    
2024-04-23 17:47:15,779 - Epoch: [107][  200/  296]    Overall Loss 0.789018    Objective Loss 0.789018                                        LR 0.000080    Time 0.121523    
2024-04-23 17:47:28,588 - Epoch: [107][  296/  296]    Overall Loss 0.792837    Objective Loss 0.792837    Top1 73.770492    Top5 95.081967    LR 0.000080    Time 0.125317    
2024-04-23 17:47:28,859 - --- validate (epoch=107)-----------
2024-04-23 17:47:28,861 - 3925 samples (32 per mini-batch)
2024-04-23 17:47:42,505 - Epoch: [107][  100/  123]    Loss 0.701390    Top1 77.218750    Top5 97.375000    
2024-04-23 17:47:45,155 - Epoch: [107][  123/  123]    Loss 0.715354    Top1 76.891720    Top5 97.299363    
2024-04-23 17:47:45,546 - ==> Top1: 76.892    Top5: 97.299    Loss: 0.715

2024-04-23 17:47:45,554 - ==> Best [Top1: 77.223   Top5: 97.325   Sparsity:0.00   Params: 370272 on epoch: 106]
2024-04-23 17:47:45,555 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:47:45,596 - 

2024-04-23 17:47:45,597 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:47:58,008 - Epoch: [108][  100/  296]    Overall Loss 0.763374    Objective Loss 0.763374                                        LR 0.000080    Time 0.123896    
2024-04-23 17:48:10,890 - Epoch: [108][  200/  296]    Overall Loss 0.789827    Objective Loss 0.789827                                        LR 0.000080    Time 0.126245    
2024-04-23 17:48:23,689 - Epoch: [108][  296/  296]    Overall Loss 0.802034    Objective Loss 0.802034    Top1 67.213115    Top5 100.000000    LR 0.000080    Time 0.128472    
2024-04-23 17:48:24,067 - --- validate (epoch=108)-----------
2024-04-23 17:48:24,068 - 3925 samples (32 per mini-batch)
2024-04-23 17:48:38,509 - Epoch: [108][  100/  123]    Loss 0.719448    Top1 77.187500    Top5 97.000000    
2024-04-23 17:48:42,328 - Epoch: [108][  123/  123]    Loss 0.724497    Top1 76.993631    Top5 97.044586    
2024-04-23 17:48:42,623 - ==> Top1: 76.994    Top5: 97.045    Loss: 0.724

2024-04-23 17:48:42,635 - ==> Best [Top1: 77.223   Top5: 97.325   Sparsity:0.00   Params: 370272 on epoch: 106]
2024-04-23 17:48:42,636 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:48:42,688 - 

2024-04-23 17:48:42,689 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:48:59,278 - Epoch: [109][  100/  296]    Overall Loss 0.793569    Objective Loss 0.793569                                        LR 0.000080    Time 0.165638    
2024-04-23 17:49:13,717 - Epoch: [109][  200/  296]    Overall Loss 0.806799    Objective Loss 0.806799                                        LR 0.000080    Time 0.154909    
2024-04-23 17:49:26,503 - Epoch: [109][  296/  296]    Overall Loss 0.814496    Objective Loss 0.814496    Top1 73.770492    Top5 100.000000    LR 0.000080    Time 0.147793    
2024-04-23 17:49:26,819 - --- validate (epoch=109)-----------
2024-04-23 17:49:26,820 - 3925 samples (32 per mini-batch)
2024-04-23 17:49:43,233 - Epoch: [109][  100/  123]    Loss 0.720432    Top1 77.093750    Top5 97.031250    
2024-04-23 17:49:46,526 - Epoch: [109][  123/  123]    Loss 0.721208    Top1 77.146497    Top5 97.121019    
2024-04-23 17:49:46,795 - ==> Top1: 77.146    Top5: 97.121    Loss: 0.721

2024-04-23 17:49:46,808 - ==> Best [Top1: 77.223   Top5: 97.325   Sparsity:0.00   Params: 370272 on epoch: 106]
2024-04-23 17:49:46,809 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:49:46,884 - 

2024-04-23 17:49:46,885 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:50:02,584 - Epoch: [110][  100/  296]    Overall Loss 0.828720    Objective Loss 0.828720                                        LR 0.000080    Time 0.156751    
2024-04-23 17:50:16,139 - Epoch: [110][  200/  296]    Overall Loss 0.813137    Objective Loss 0.813137                                        LR 0.000080    Time 0.146042    
2024-04-23 17:50:29,887 - Epoch: [110][  296/  296]    Overall Loss 0.815042    Objective Loss 0.815042    Top1 73.770492    Top5 96.721311    LR 0.000080    Time 0.145052    
2024-04-23 17:50:30,219 - --- validate (epoch=110)-----------
2024-04-23 17:50:30,221 - 3925 samples (32 per mini-batch)
2024-04-23 17:50:47,398 - Epoch: [110][  100/  123]    Loss 0.743435    Top1 76.281250    Top5 96.687500    
2024-04-23 17:50:49,885 - Epoch: [110][  123/  123]    Loss 0.730467    Top1 76.713376    Top5 96.968153    
2024-04-23 17:50:50,167 - ==> Top1: 76.713    Top5: 96.968    Loss: 0.730

2024-04-23 17:50:50,177 - ==> Best [Top1: 77.223   Top5: 97.325   Sparsity:0.00   Params: 370272 on epoch: 106]
2024-04-23 17:50:50,178 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:50:50,223 - 

2024-04-23 17:50:50,224 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:51:05,536 - Epoch: [111][  100/  296]    Overall Loss 0.825944    Objective Loss 0.825944                                        LR 0.000080    Time 0.152891    
2024-04-23 17:51:19,711 - Epoch: [111][  200/  296]    Overall Loss 0.811076    Objective Loss 0.811076                                        LR 0.000080    Time 0.147212    
2024-04-23 17:51:33,196 - Epoch: [111][  296/  296]    Overall Loss 0.807101    Objective Loss 0.807101    Top1 75.409836    Top5 95.081967    LR 0.000080    Time 0.144954    
2024-04-23 17:51:33,527 - --- validate (epoch=111)-----------
2024-04-23 17:51:33,529 - 3925 samples (32 per mini-batch)
2024-04-23 17:51:50,699 - Epoch: [111][  100/  123]    Loss 0.703062    Top1 77.656250    Top5 97.000000    
2024-04-23 17:51:54,286 - Epoch: [111][  123/  123]    Loss 0.714094    Top1 77.222930    Top5 97.095541    
2024-04-23 17:51:54,578 - ==> Top1: 77.223    Top5: 97.096    Loss: 0.714

2024-04-23 17:51:54,587 - ==> Best [Top1: 77.223   Top5: 97.325   Sparsity:0.00   Params: 370272 on epoch: 106]
2024-04-23 17:51:54,588 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:51:54,638 - 

2024-04-23 17:51:54,638 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:52:09,152 - Epoch: [112][  100/  296]    Overall Loss 0.831600    Objective Loss 0.831600                                        LR 0.000080    Time 0.144918    
2024-04-23 17:52:23,594 - Epoch: [112][  200/  296]    Overall Loss 0.809865    Objective Loss 0.809865                                        LR 0.000080    Time 0.144559    
2024-04-23 17:52:37,947 - Epoch: [112][  296/  296]    Overall Loss 0.808857    Objective Loss 0.808857    Top1 81.967213    Top5 100.000000    LR 0.000080    Time 0.146095    
2024-04-23 17:52:38,288 - --- validate (epoch=112)-----------
2024-04-23 17:52:38,291 - 3925 samples (32 per mini-batch)
2024-04-23 17:52:54,608 - Epoch: [112][  100/  123]    Loss 0.708927    Top1 77.656250    Top5 97.281250    
2024-04-23 17:52:57,874 - Epoch: [112][  123/  123]    Loss 0.713523    Top1 77.350318    Top5 97.248408    
2024-04-23 17:52:58,143 - ==> Top1: 77.350    Top5: 97.248    Loss: 0.714

2024-04-23 17:52:58,153 - ==> Best [Top1: 77.350   Top5: 97.248   Sparsity:0.00   Params: 370272 on epoch: 112]
2024-04-23 17:52:58,154 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:52:58,218 - 

2024-04-23 17:52:58,219 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:53:17,061 - Epoch: [113][  100/  296]    Overall Loss 0.812825    Objective Loss 0.812825                                        LR 0.000080    Time 0.188190    
2024-04-23 17:53:32,174 - Epoch: [113][  200/  296]    Overall Loss 0.795358    Objective Loss 0.795358                                        LR 0.000080    Time 0.169551    
2024-04-23 17:53:47,102 - Epoch: [113][  296/  296]    Overall Loss 0.801488    Objective Loss 0.801488    Top1 68.852459    Top5 98.360656    LR 0.000080    Time 0.164922    
2024-04-23 17:53:47,427 - --- validate (epoch=113)-----------
2024-04-23 17:53:47,428 - 3925 samples (32 per mini-batch)
2024-04-23 17:54:04,468 - Epoch: [113][  100/  123]    Loss 0.706082    Top1 76.781250    Top5 97.187500    
2024-04-23 17:54:08,178 - Epoch: [113][  123/  123]    Loss 0.712150    Top1 76.789809    Top5 97.121019    
2024-04-23 17:54:08,438 - ==> Top1: 76.790    Top5: 97.121    Loss: 0.712

2024-04-23 17:54:08,450 - ==> Best [Top1: 77.350   Top5: 97.248   Sparsity:0.00   Params: 370272 on epoch: 112]
2024-04-23 17:54:08,451 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:54:08,533 - 

2024-04-23 17:54:08,534 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:54:26,069 - Epoch: [114][  100/  296]    Overall Loss 0.785985    Objective Loss 0.785985                                        LR 0.000080    Time 0.175108    
2024-04-23 17:54:40,906 - Epoch: [114][  200/  296]    Overall Loss 0.784236    Objective Loss 0.784236                                        LR 0.000080    Time 0.161627    
2024-04-23 17:54:55,373 - Epoch: [114][  296/  296]    Overall Loss 0.798259    Objective Loss 0.798259    Top1 72.131148    Top5 98.360656    LR 0.000080    Time 0.158012    
2024-04-23 17:54:55,737 - --- validate (epoch=114)-----------
2024-04-23 17:54:55,738 - 3925 samples (32 per mini-batch)
2024-04-23 17:55:14,844 - Epoch: [114][  100/  123]    Loss 0.719851    Top1 76.656250    Top5 97.093750    
2024-04-23 17:55:18,882 - Epoch: [114][  123/  123]    Loss 0.723749    Top1 76.636943    Top5 97.019108    
2024-04-23 17:55:19,151 - ==> Top1: 76.637    Top5: 97.019    Loss: 0.724

2024-04-23 17:55:19,163 - ==> Best [Top1: 77.350   Top5: 97.248   Sparsity:0.00   Params: 370272 on epoch: 112]
2024-04-23 17:55:19,164 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:55:19,247 - 

2024-04-23 17:55:19,248 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:55:36,462 - Epoch: [115][  100/  296]    Overall Loss 0.804405    Objective Loss 0.804405                                        LR 0.000080    Time 0.171906    
2024-04-23 17:55:50,560 - Epoch: [115][  200/  296]    Overall Loss 0.795478    Objective Loss 0.795478                                        LR 0.000080    Time 0.156334    
2024-04-23 17:56:04,819 - Epoch: [115][  296/  296]    Overall Loss 0.796836    Objective Loss 0.796836    Top1 65.573770    Top5 98.360656    LR 0.000080    Time 0.153728    
2024-04-23 17:56:05,190 - --- validate (epoch=115)-----------
2024-04-23 17:56:05,192 - 3925 samples (32 per mini-batch)
2024-04-23 17:56:24,768 - Epoch: [115][  100/  123]    Loss 0.701373    Top1 77.562500    Top5 97.031250    
2024-04-23 17:56:28,560 - Epoch: [115][  123/  123]    Loss 0.709683    Top1 77.273885    Top5 97.070064    
2024-04-23 17:56:28,926 - ==> Top1: 77.274    Top5: 97.070    Loss: 0.710

2024-04-23 17:56:28,939 - ==> Best [Top1: 77.350   Top5: 97.248   Sparsity:0.00   Params: 370272 on epoch: 112]
2024-04-23 17:56:28,940 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:56:29,003 - 

2024-04-23 17:56:29,004 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:56:44,670 - Epoch: [116][  100/  296]    Overall Loss 0.793310    Objective Loss 0.793310                                        LR 0.000080    Time 0.156419    
2024-04-23 17:57:01,429 - Epoch: [116][  200/  296]    Overall Loss 0.805078    Objective Loss 0.805078                                        LR 0.000080    Time 0.161876    
2024-04-23 17:57:16,569 - Epoch: [116][  296/  296]    Overall Loss 0.803558    Objective Loss 0.803558    Top1 80.327869    Top5 98.360656    LR 0.000080    Time 0.160455    
2024-04-23 17:57:16,916 - --- validate (epoch=116)-----------
2024-04-23 17:57:16,918 - 3925 samples (32 per mini-batch)
2024-04-23 17:57:35,692 - Epoch: [116][  100/  123]    Loss 0.719341    Top1 77.093750    Top5 97.000000    
2024-04-23 17:57:39,415 - Epoch: [116][  123/  123]    Loss 0.717860    Top1 77.095541    Top5 97.044586    
2024-04-23 17:57:39,755 - ==> Top1: 77.096    Top5: 97.045    Loss: 0.718

2024-04-23 17:57:39,769 - ==> Best [Top1: 77.350   Top5: 97.248   Sparsity:0.00   Params: 370272 on epoch: 112]
2024-04-23 17:57:39,770 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:57:39,825 - 

2024-04-23 17:57:39,826 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:57:54,630 - Epoch: [117][  100/  296]    Overall Loss 0.796580    Objective Loss 0.796580                                        LR 0.000080    Time 0.147811    
2024-04-23 17:58:07,100 - Epoch: [117][  200/  296]    Overall Loss 0.789396    Objective Loss 0.789396                                        LR 0.000080    Time 0.136153    
2024-04-23 17:58:21,327 - Epoch: [117][  296/  296]    Overall Loss 0.794719    Objective Loss 0.794719    Top1 78.688525    Top5 98.360656    LR 0.000080    Time 0.139991    
2024-04-23 17:58:21,598 - --- validate (epoch=117)-----------
2024-04-23 17:58:21,599 - 3925 samples (32 per mini-batch)
2024-04-23 17:58:38,351 - Epoch: [117][  100/  123]    Loss 0.704163    Top1 77.718750    Top5 97.218750    
2024-04-23 17:58:41,558 - Epoch: [117][  123/  123]    Loss 0.716162    Top1 77.299363    Top5 97.095541    
2024-04-23 17:58:41,854 - ==> Top1: 77.299    Top5: 97.096    Loss: 0.716

2024-04-23 17:58:41,865 - ==> Best [Top1: 77.350   Top5: 97.248   Sparsity:0.00   Params: 370272 on epoch: 112]
2024-04-23 17:58:41,866 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:58:41,951 - 

2024-04-23 17:58:41,953 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:58:57,809 - Epoch: [118][  100/  296]    Overall Loss 0.762967    Objective Loss 0.762967                                        LR 0.000080    Time 0.158307    
2024-04-23 17:59:12,341 - Epoch: [118][  200/  296]    Overall Loss 0.778802    Objective Loss 0.778802                                        LR 0.000080    Time 0.151703    
2024-04-23 17:59:23,823 - Epoch: [118][  296/  296]    Overall Loss 0.787383    Objective Loss 0.787383    Top1 72.131148    Top5 100.000000    LR 0.000080    Time 0.141230    
2024-04-23 17:59:24,128 - --- validate (epoch=118)-----------
2024-04-23 17:59:24,129 - 3925 samples (32 per mini-batch)
2024-04-23 17:59:41,363 - Epoch: [118][  100/  123]    Loss 0.725238    Top1 76.656250    Top5 97.000000    
2024-04-23 17:59:45,172 - Epoch: [118][  123/  123]    Loss 0.718353    Top1 76.866242    Top5 97.121019    
2024-04-23 17:59:45,455 - ==> Top1: 76.866    Top5: 97.121    Loss: 0.718

2024-04-23 17:59:45,469 - ==> Best [Top1: 77.350   Top5: 97.248   Sparsity:0.00   Params: 370272 on epoch: 112]
2024-04-23 17:59:45,470 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 17:59:45,558 - 

2024-04-23 17:59:45,560 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:00:01,142 - Epoch: [119][  100/  296]    Overall Loss 0.789463    Objective Loss 0.789463                                        LR 0.000080    Time 0.155579    
2024-04-23 18:00:15,851 - Epoch: [119][  200/  296]    Overall Loss 0.782150    Objective Loss 0.782150                                        LR 0.000080    Time 0.151234    
2024-04-23 18:00:29,600 - Epoch: [119][  296/  296]    Overall Loss 0.787994    Objective Loss 0.787994    Top1 72.131148    Top5 96.721311    LR 0.000080    Time 0.148571    
2024-04-23 18:00:29,930 - --- validate (epoch=119)-----------
2024-04-23 18:00:29,931 - 3925 samples (32 per mini-batch)
2024-04-23 18:00:47,046 - Epoch: [119][  100/  123]    Loss 0.702943    Top1 77.562500    Top5 97.437500    
2024-04-23 18:00:50,517 - Epoch: [119][  123/  123]    Loss 0.722081    Top1 77.044586    Top5 97.248408    
2024-04-23 18:00:50,789 - ==> Top1: 77.045    Top5: 97.248    Loss: 0.722

2024-04-23 18:00:50,799 - ==> Best [Top1: 77.350   Top5: 97.248   Sparsity:0.00   Params: 370272 on epoch: 112]
2024-04-23 18:00:50,799 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:00:50,849 - 

2024-04-23 18:00:50,850 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:01:05,582 - Epoch: [120][  100/  296]    Overall Loss 0.790797    Objective Loss 0.790797                                        LR 0.000080    Time 0.147076    
2024-04-23 18:01:20,048 - Epoch: [120][  200/  296]    Overall Loss 0.794838    Objective Loss 0.794838                                        LR 0.000080    Time 0.145764    
2024-04-23 18:01:33,496 - Epoch: [120][  296/  296]    Overall Loss 0.799956    Objective Loss 0.799956    Top1 67.213115    Top5 98.360656    LR 0.000080    Time 0.143852    
2024-04-23 18:01:33,798 - --- validate (epoch=120)-----------
2024-04-23 18:01:33,799 - 3925 samples (32 per mini-batch)
2024-04-23 18:01:50,700 - Epoch: [120][  100/  123]    Loss 0.716387    Top1 77.531250    Top5 97.187500    
2024-04-23 18:01:53,664 - Epoch: [120][  123/  123]    Loss 0.711500    Top1 77.579618    Top5 97.222930    
2024-04-23 18:01:54,005 - ==> Top1: 77.580    Top5: 97.223    Loss: 0.711

2024-04-23 18:01:54,016 - ==> Best [Top1: 77.580   Top5: 97.223   Sparsity:0.00   Params: 370272 on epoch: 120]
2024-04-23 18:01:54,017 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:01:54,118 - 

2024-04-23 18:01:54,120 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:02:11,194 - Epoch: [121][  100/  296]    Overall Loss 0.813465    Objective Loss 0.813465                                        LR 0.000080    Time 0.170497    
2024-04-23 18:02:25,504 - Epoch: [121][  200/  296]    Overall Loss 0.793557    Objective Loss 0.793557                                        LR 0.000080    Time 0.156692    
2024-04-23 18:02:38,966 - Epoch: [121][  296/  296]    Overall Loss 0.790978    Objective Loss 0.790978    Top1 75.409836    Top5 100.000000    LR 0.000080    Time 0.151285    
2024-04-23 18:02:39,248 - --- validate (epoch=121)-----------
2024-04-23 18:02:39,249 - 3925 samples (32 per mini-batch)
2024-04-23 18:02:56,291 - Epoch: [121][  100/  123]    Loss 0.737325    Top1 76.406250    Top5 96.843750    
2024-04-23 18:02:59,476 - Epoch: [121][  123/  123]    Loss 0.722997    Top1 76.764331    Top5 97.044586    
2024-04-23 18:02:59,737 - ==> Top1: 76.764    Top5: 97.045    Loss: 0.723

2024-04-23 18:02:59,745 - ==> Best [Top1: 77.580   Top5: 97.223   Sparsity:0.00   Params: 370272 on epoch: 120]
2024-04-23 18:02:59,745 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:02:59,820 - 

2024-04-23 18:02:59,821 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:03:15,464 - Epoch: [122][  100/  296]    Overall Loss 0.766338    Objective Loss 0.766338                                        LR 0.000080    Time 0.156200    
2024-04-23 18:03:30,378 - Epoch: [122][  200/  296]    Overall Loss 0.783143    Objective Loss 0.783143                                        LR 0.000080    Time 0.152553    
2024-04-23 18:03:43,458 - Epoch: [122][  296/  296]    Overall Loss 0.783815    Objective Loss 0.783815    Top1 72.131148    Top5 98.360656    LR 0.000080    Time 0.147182    
2024-04-23 18:03:43,762 - --- validate (epoch=122)-----------
2024-04-23 18:03:43,764 - 3925 samples (32 per mini-batch)
2024-04-23 18:03:57,691 - Epoch: [122][  100/  123]    Loss 0.726369    Top1 76.937500    Top5 96.937500    
2024-04-23 18:04:00,440 - Epoch: [122][  123/  123]    Loss 0.704818    Top1 77.732484    Top5 97.095541    
2024-04-23 18:04:00,713 - ==> Top1: 77.732    Top5: 97.096    Loss: 0.705

2024-04-23 18:04:00,723 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:04:00,724 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:04:00,784 - 

2024-04-23 18:04:00,784 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:04:14,976 - Epoch: [123][  100/  296]    Overall Loss 0.791726    Objective Loss 0.791726                                        LR 0.000080    Time 0.141693    
2024-04-23 18:04:27,273 - Epoch: [123][  200/  296]    Overall Loss 0.784687    Objective Loss 0.784687                                        LR 0.000080    Time 0.132233    
2024-04-23 18:04:42,776 - Epoch: [123][  296/  296]    Overall Loss 0.780301    Objective Loss 0.780301    Top1 77.049180    Top5 98.360656    LR 0.000080    Time 0.141648    
2024-04-23 18:04:43,160 - --- validate (epoch=123)-----------
2024-04-23 18:04:43,161 - 3925 samples (32 per mini-batch)
2024-04-23 18:05:02,740 - Epoch: [123][  100/  123]    Loss 0.710319    Top1 77.093750    Top5 96.968750    
2024-04-23 18:05:07,112 - Epoch: [123][  123/  123]    Loss 0.706923    Top1 77.299363    Top5 97.019108    
2024-04-23 18:05:07,415 - ==> Top1: 77.299    Top5: 97.019    Loss: 0.707

2024-04-23 18:05:07,427 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:05:07,428 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:05:07,494 - 

2024-04-23 18:05:07,495 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:05:23,508 - Epoch: [124][  100/  296]    Overall Loss 0.771579    Objective Loss 0.771579                                        LR 0.000080    Time 0.159887    
2024-04-23 18:05:37,829 - Epoch: [124][  200/  296]    Overall Loss 0.778946    Objective Loss 0.778946                                        LR 0.000080    Time 0.151435    
2024-04-23 18:05:49,770 - Epoch: [124][  296/  296]    Overall Loss 0.773511    Objective Loss 0.773511    Top1 77.049180    Top5 96.721311    LR 0.000080    Time 0.142593    
2024-04-23 18:05:50,158 - --- validate (epoch=124)-----------
2024-04-23 18:05:50,159 - 3925 samples (32 per mini-batch)
2024-04-23 18:06:03,100 - Epoch: [124][  100/  123]    Loss 0.711676    Top1 77.062500    Top5 97.062500    
2024-04-23 18:06:05,915 - Epoch: [124][  123/  123]    Loss 0.713672    Top1 76.942675    Top5 97.019108    
2024-04-23 18:06:06,218 - ==> Top1: 76.943    Top5: 97.019    Loss: 0.714

2024-04-23 18:06:06,227 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:06:06,227 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:06:06,265 - 

2024-04-23 18:06:06,266 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:06:24,122 - Epoch: [125][  100/  296]    Overall Loss 0.771256    Objective Loss 0.771256                                        LR 0.000080    Time 0.178331    
2024-04-23 18:06:40,941 - Epoch: [125][  200/  296]    Overall Loss 0.769551    Objective Loss 0.769551                                        LR 0.000080    Time 0.173146    
2024-04-23 18:06:55,341 - Epoch: [125][  296/  296]    Overall Loss 0.778049    Objective Loss 0.778049    Top1 80.327869    Top5 98.360656    LR 0.000080    Time 0.165567    
2024-04-23 18:06:55,671 - --- validate (epoch=125)-----------
2024-04-23 18:06:55,672 - 3925 samples (32 per mini-batch)
2024-04-23 18:07:14,909 - Epoch: [125][  100/  123]    Loss 0.698822    Top1 77.437500    Top5 97.437500    
2024-04-23 18:07:17,914 - Epoch: [125][  123/  123]    Loss 0.703764    Top1 77.324841    Top5 97.171975    
2024-04-23 18:07:18,298 - ==> Top1: 77.325    Top5: 97.172    Loss: 0.704

2024-04-23 18:07:18,310 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:07:18,311 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:07:18,371 - 

2024-04-23 18:07:18,373 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:07:32,256 - Epoch: [126][  100/  296]    Overall Loss 0.800450    Objective Loss 0.800450                                        LR 0.000080    Time 0.138610    
2024-04-23 18:07:39,772 - Epoch: [126][  200/  296]    Overall Loss 0.794191    Objective Loss 0.794191                                        LR 0.000080    Time 0.106780    
2024-04-23 18:07:48,179 - Epoch: [126][  296/  296]    Overall Loss 0.786493    Objective Loss 0.786493    Top1 77.049180    Top5 96.721311    LR 0.000080    Time 0.100488    
2024-04-23 18:07:48,518 - --- validate (epoch=126)-----------
2024-04-23 18:07:48,519 - 3925 samples (32 per mini-batch)
2024-04-23 18:08:01,595 - Epoch: [126][  100/  123]    Loss 0.739303    Top1 76.593750    Top5 96.843750    
2024-04-23 18:08:04,099 - Epoch: [126][  123/  123]    Loss 0.724382    Top1 76.917197    Top5 96.866242    
2024-04-23 18:08:04,349 - ==> Top1: 76.917    Top5: 96.866    Loss: 0.724

2024-04-23 18:08:04,359 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:08:04,360 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:08:04,400 - 

2024-04-23 18:08:04,401 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:08:15,342 - Epoch: [127][  100/  296]    Overall Loss 0.779171    Objective Loss 0.779171                                        LR 0.000080    Time 0.109172    
2024-04-23 18:08:27,478 - Epoch: [127][  200/  296]    Overall Loss 0.798460    Objective Loss 0.798460                                        LR 0.000080    Time 0.115165    
2024-04-23 18:08:40,847 - Epoch: [127][  296/  296]    Overall Loss 0.791836    Objective Loss 0.791836    Top1 81.967213    Top5 98.360656    LR 0.000080    Time 0.122909    
2024-04-23 18:08:41,071 - --- validate (epoch=127)-----------
2024-04-23 18:08:41,072 - 3925 samples (32 per mini-batch)
2024-04-23 18:08:54,425 - Epoch: [127][  100/  123]    Loss 0.708077    Top1 77.906250    Top5 97.250000    
2024-04-23 18:08:57,269 - Epoch: [127][  123/  123]    Loss 0.711322    Top1 77.630573    Top5 97.197452    
2024-04-23 18:08:57,528 - ==> Top1: 77.631    Top5: 97.197    Loss: 0.711

2024-04-23 18:08:57,534 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:08:57,535 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:08:57,579 - 

2024-04-23 18:08:57,579 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:09:14,605 - Epoch: [128][  100/  296]    Overall Loss 0.791813    Objective Loss 0.791813                                        LR 0.000080    Time 0.170034    
2024-04-23 18:09:29,355 - Epoch: [128][  200/  296]    Overall Loss 0.792405    Objective Loss 0.792405                                        LR 0.000080    Time 0.158657    
2024-04-23 18:09:39,790 - Epoch: [128][  296/  296]    Overall Loss 0.787561    Objective Loss 0.787561    Top1 77.049180    Top5 98.360656    LR 0.000080    Time 0.142391    
2024-04-23 18:09:40,123 - --- validate (epoch=128)-----------
2024-04-23 18:09:40,124 - 3925 samples (32 per mini-batch)
2024-04-23 18:09:59,671 - Epoch: [128][  100/  123]    Loss 0.709350    Top1 77.312500    Top5 96.718750    
2024-04-23 18:10:03,217 - Epoch: [128][  123/  123]    Loss 0.708009    Top1 77.248408    Top5 96.840764    
2024-04-23 18:10:03,518 - ==> Top1: 77.248    Top5: 96.841    Loss: 0.708

2024-04-23 18:10:03,527 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:10:03,528 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:10:03,578 - 

2024-04-23 18:10:03,579 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:10:21,458 - Epoch: [129][  100/  296]    Overall Loss 0.759875    Objective Loss 0.759875                                        LR 0.000080    Time 0.178555    
2024-04-23 18:10:35,271 - Epoch: [129][  200/  296]    Overall Loss 0.758339    Objective Loss 0.758339                                        LR 0.000080    Time 0.158241    
2024-04-23 18:10:49,734 - Epoch: [129][  296/  296]    Overall Loss 0.768045    Objective Loss 0.768045    Top1 72.131148    Top5 98.360656    LR 0.000080    Time 0.155713    
2024-04-23 18:10:50,163 - --- validate (epoch=129)-----------
2024-04-23 18:10:50,164 - 3925 samples (32 per mini-batch)
2024-04-23 18:11:06,498 - Epoch: [129][  100/  123]    Loss 0.718915    Top1 77.093750    Top5 96.843750    
2024-04-23 18:11:10,532 - Epoch: [129][  123/  123]    Loss 0.708077    Top1 77.656051    Top5 97.121019    
2024-04-23 18:11:10,746 - ==> Top1: 77.656    Top5: 97.121    Loss: 0.708

2024-04-23 18:11:10,759 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:11:10,760 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:11:10,828 - 

2024-04-23 18:11:10,829 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:11:27,281 - Epoch: [130][  100/  296]    Overall Loss 0.799773    Objective Loss 0.799773                                        LR 0.000080    Time 0.164275    
2024-04-23 18:11:41,755 - Epoch: [130][  200/  296]    Overall Loss 0.810584    Objective Loss 0.810584                                        LR 0.000080    Time 0.154403    
2024-04-23 18:11:56,307 - Epoch: [130][  296/  296]    Overall Loss 0.799440    Objective Loss 0.799440    Top1 81.967213    Top5 96.721311    LR 0.000080    Time 0.153417    
2024-04-23 18:11:56,589 - --- validate (epoch=130)-----------
2024-04-23 18:11:56,591 - 3925 samples (32 per mini-batch)
2024-04-23 18:12:14,260 - Epoch: [130][  100/  123]    Loss 0.712319    Top1 77.281250    Top5 97.281250    
2024-04-23 18:12:18,428 - Epoch: [130][  123/  123]    Loss 0.721691    Top1 76.968153    Top5 97.095541    
2024-04-23 18:12:18,703 - ==> Top1: 76.968    Top5: 97.096    Loss: 0.722

2024-04-23 18:12:18,711 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:12:18,712 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:12:18,769 - 

2024-04-23 18:12:18,770 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:12:34,496 - Epoch: [131][  100/  296]    Overall Loss 0.746983    Objective Loss 0.746983                                        LR 0.000080    Time 0.157013    
2024-04-23 18:12:48,252 - Epoch: [131][  200/  296]    Overall Loss 0.759991    Objective Loss 0.759991                                        LR 0.000080    Time 0.147174    
2024-04-23 18:13:04,849 - Epoch: [131][  296/  296]    Overall Loss 0.771665    Objective Loss 0.771665    Top1 65.573770    Top5 95.081967    LR 0.000080    Time 0.155442    
2024-04-23 18:13:05,198 - --- validate (epoch=131)-----------
2024-04-23 18:13:05,199 - 3925 samples (32 per mini-batch)
2024-04-23 18:13:23,404 - Epoch: [131][  100/  123]    Loss 0.723161    Top1 77.031250    Top5 97.062500    
2024-04-23 18:13:27,125 - Epoch: [131][  123/  123]    Loss 0.717400    Top1 77.477707    Top5 97.095541    
2024-04-23 18:13:27,461 - ==> Top1: 77.478    Top5: 97.096    Loss: 0.717

2024-04-23 18:13:27,477 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:13:27,478 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:13:27,565 - 

2024-04-23 18:13:27,566 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:13:43,891 - Epoch: [132][  100/  296]    Overall Loss 0.743567    Objective Loss 0.743567                                        LR 0.000080    Time 0.163003    
2024-04-23 18:13:55,949 - Epoch: [132][  200/  296]    Overall Loss 0.771617    Objective Loss 0.771617                                        LR 0.000080    Time 0.141688    
2024-04-23 18:14:10,613 - Epoch: [132][  296/  296]    Overall Loss 0.775426    Objective Loss 0.775426    Top1 73.770492    Top5 98.360656    LR 0.000080    Time 0.145209    
2024-04-23 18:14:10,910 - --- validate (epoch=132)-----------
2024-04-23 18:14:10,912 - 3925 samples (32 per mini-batch)
2024-04-23 18:14:31,696 - Epoch: [132][  100/  123]    Loss 0.722801    Top1 76.875000    Top5 96.843750    
2024-04-23 18:14:35,131 - Epoch: [132][  123/  123]    Loss 0.721135    Top1 76.891720    Top5 97.070064    
2024-04-23 18:14:35,403 - ==> Top1: 76.892    Top5: 97.070    Loss: 0.721

2024-04-23 18:14:35,415 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:14:35,416 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:14:35,479 - 

2024-04-23 18:14:35,480 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:14:51,865 - Epoch: [133][  100/  296]    Overall Loss 0.761975    Objective Loss 0.761975                                        LR 0.000080    Time 0.163617    
2024-04-23 18:15:08,320 - Epoch: [133][  200/  296]    Overall Loss 0.766743    Objective Loss 0.766743                                        LR 0.000080    Time 0.163974    
2024-04-23 18:15:23,178 - Epoch: [133][  296/  296]    Overall Loss 0.768628    Objective Loss 0.768628    Top1 81.967213    Top5 100.000000    LR 0.000080    Time 0.160917    
2024-04-23 18:15:23,516 - --- validate (epoch=133)-----------
2024-04-23 18:15:23,517 - 3925 samples (32 per mini-batch)
2024-04-23 18:15:45,333 - Epoch: [133][  100/  123]    Loss 0.709683    Top1 77.812500    Top5 97.125000    
2024-04-23 18:15:48,951 - Epoch: [133][  123/  123]    Loss 0.712671    Top1 77.426752    Top5 97.222930    
2024-04-23 18:15:49,552 - ==> Top1: 77.427    Top5: 97.223    Loss: 0.713

2024-04-23 18:15:49,561 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:15:49,562 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:15:49,617 - 

2024-04-23 18:15:49,618 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:16:06,141 - Epoch: [134][  100/  296]    Overall Loss 0.775941    Objective Loss 0.775941                                        LR 0.000080    Time 0.165011    
2024-04-23 18:16:20,431 - Epoch: [134][  200/  296]    Overall Loss 0.767805    Objective Loss 0.767805                                        LR 0.000080    Time 0.153848    
2024-04-23 18:16:38,131 - Epoch: [134][  296/  296]    Overall Loss 0.774976    Objective Loss 0.774976    Top1 73.770492    Top5 96.721311    LR 0.000080    Time 0.163673    
2024-04-23 18:16:38,517 - --- validate (epoch=134)-----------
2024-04-23 18:16:38,518 - 3925 samples (32 per mini-batch)
2024-04-23 18:16:57,214 - Epoch: [134][  100/  123]    Loss 0.730630    Top1 76.531250    Top5 97.125000    
2024-04-23 18:17:01,198 - Epoch: [134][  123/  123]    Loss 0.717606    Top1 77.044586    Top5 97.222930    
2024-04-23 18:17:01,448 - ==> Top1: 77.045    Top5: 97.223    Loss: 0.718

2024-04-23 18:17:01,460 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:17:01,462 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:17:01,529 - 

2024-04-23 18:17:01,530 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:17:19,166 - Epoch: [135][  100/  296]    Overall Loss 0.772932    Objective Loss 0.772932                                        LR 0.000080    Time 0.176111    
2024-04-23 18:17:35,976 - Epoch: [135][  200/  296]    Overall Loss 0.751179    Objective Loss 0.751179                                        LR 0.000080    Time 0.171999    
2024-04-23 18:17:52,114 - Epoch: [135][  296/  296]    Overall Loss 0.753231    Objective Loss 0.753231    Top1 73.770492    Top5 98.360656    LR 0.000080    Time 0.170668    
2024-04-23 18:17:52,382 - --- validate (epoch=135)-----------
2024-04-23 18:17:52,385 - 3925 samples (32 per mini-batch)
2024-04-23 18:18:09,339 - Epoch: [135][  100/  123]    Loss 0.727861    Top1 76.218750    Top5 97.000000    
2024-04-23 18:18:12,741 - Epoch: [135][  123/  123]    Loss 0.719893    Top1 76.611465    Top5 97.044586    
2024-04-23 18:18:12,991 - ==> Top1: 76.611    Top5: 97.045    Loss: 0.720

2024-04-23 18:18:13,005 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:18:13,006 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:18:13,071 - 

2024-04-23 18:18:13,073 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:18:33,841 - Epoch: [136][  100/  296]    Overall Loss 0.772170    Objective Loss 0.772170                                        LR 0.000080    Time 0.207451    
2024-04-23 18:18:49,884 - Epoch: [136][  200/  296]    Overall Loss 0.767876    Objective Loss 0.767876                                        LR 0.000080    Time 0.183836    
2024-04-23 18:19:03,589 - Epoch: [136][  296/  296]    Overall Loss 0.764676    Objective Loss 0.764676    Top1 70.491803    Top5 96.721311    LR 0.000080    Time 0.170445    
2024-04-23 18:19:03,883 - --- validate (epoch=136)-----------
2024-04-23 18:19:03,884 - 3925 samples (32 per mini-batch)
2024-04-23 18:19:21,084 - Epoch: [136][  100/  123]    Loss 0.709155    Top1 77.250000    Top5 97.125000    
2024-04-23 18:19:24,680 - Epoch: [136][  123/  123]    Loss 0.715794    Top1 76.866242    Top5 97.044586    
2024-04-23 18:19:24,906 - ==> Top1: 76.866    Top5: 97.045    Loss: 0.716

2024-04-23 18:19:24,923 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:19:24,924 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:19:25,025 - 

2024-04-23 18:19:25,027 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:19:40,301 - Epoch: [137][  100/  296]    Overall Loss 0.754434    Objective Loss 0.754434                                        LR 0.000080    Time 0.152492    
2024-04-23 18:19:53,178 - Epoch: [137][  200/  296]    Overall Loss 0.765142    Objective Loss 0.765142                                        LR 0.000080    Time 0.140522    
2024-04-23 18:20:07,144 - Epoch: [137][  296/  296]    Overall Loss 0.767006    Objective Loss 0.767006    Top1 72.131148    Top5 91.803279    LR 0.000080    Time 0.142046    
2024-04-23 18:20:07,422 - --- validate (epoch=137)-----------
2024-04-23 18:20:07,424 - 3925 samples (32 per mini-batch)
2024-04-23 18:20:25,734 - Epoch: [137][  100/  123]    Loss 0.713635    Top1 76.687500    Top5 97.062500    
2024-04-23 18:20:29,609 - Epoch: [137][  123/  123]    Loss 0.712257    Top1 76.738854    Top5 97.222930    
2024-04-23 18:20:29,935 - ==> Top1: 76.739    Top5: 97.223    Loss: 0.712

2024-04-23 18:20:29,948 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:20:29,949 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:20:30,012 - 

2024-04-23 18:20:30,013 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:20:49,310 - Epoch: [138][  100/  296]    Overall Loss 0.808964    Objective Loss 0.808964                                        LR 0.000080    Time 0.192744    
2024-04-23 18:21:05,486 - Epoch: [138][  200/  296]    Overall Loss 0.793529    Objective Loss 0.793529                                        LR 0.000080    Time 0.177141    
2024-04-23 18:21:20,218 - Epoch: [138][  296/  296]    Overall Loss 0.783474    Objective Loss 0.783474    Top1 72.131148    Top5 96.721311    LR 0.000080    Time 0.169386    
2024-04-23 18:21:20,527 - --- validate (epoch=138)-----------
2024-04-23 18:21:20,529 - 3925 samples (32 per mini-batch)
2024-04-23 18:21:39,571 - Epoch: [138][  100/  123]    Loss 0.718738    Top1 76.406250    Top5 96.937500    
2024-04-23 18:21:42,737 - Epoch: [138][  123/  123]    Loss 0.722615    Top1 76.152866    Top5 97.019108    
2024-04-23 18:21:43,023 - ==> Top1: 76.153    Top5: 97.019    Loss: 0.723

2024-04-23 18:21:43,034 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:21:43,035 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:21:43,090 - 

2024-04-23 18:21:43,091 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:21:57,475 - Epoch: [139][  100/  296]    Overall Loss 0.809623    Objective Loss 0.809623                                        LR 0.000080    Time 0.143613    
2024-04-23 18:22:11,807 - Epoch: [139][  200/  296]    Overall Loss 0.789412    Objective Loss 0.789412                                        LR 0.000080    Time 0.143368    
2024-04-23 18:22:25,235 - Epoch: [139][  296/  296]    Overall Loss 0.784825    Objective Loss 0.784825    Top1 72.131148    Top5 100.000000    LR 0.000080    Time 0.142163    
2024-04-23 18:22:25,669 - --- validate (epoch=139)-----------
2024-04-23 18:22:25,670 - 3925 samples (32 per mini-batch)
2024-04-23 18:22:42,999 - Epoch: [139][  100/  123]    Loss 0.720698    Top1 77.000000    Top5 97.031250    
2024-04-23 18:22:46,692 - Epoch: [139][  123/  123]    Loss 0.716017    Top1 77.121019    Top5 96.993631    
2024-04-23 18:22:47,120 - ==> Top1: 77.121    Top5: 96.994    Loss: 0.716

2024-04-23 18:22:47,130 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:22:47,130 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:22:47,174 - 

2024-04-23 18:22:47,175 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:23:03,412 - Epoch: [140][  100/  296]    Overall Loss 0.778209    Objective Loss 0.778209                                        LR 0.000080    Time 0.162153    
2024-04-23 18:23:18,358 - Epoch: [140][  200/  296]    Overall Loss 0.749658    Objective Loss 0.749658                                        LR 0.000080    Time 0.155699    
2024-04-23 18:23:30,254 - Epoch: [140][  296/  296]    Overall Loss 0.756676    Objective Loss 0.756676    Top1 70.491803    Top5 95.081967    LR 0.000080    Time 0.145326    
2024-04-23 18:23:30,530 - --- validate (epoch=140)-----------
2024-04-23 18:23:30,531 - 3925 samples (32 per mini-batch)
2024-04-23 18:23:47,674 - Epoch: [140][  100/  123]    Loss 0.701220    Top1 76.968750    Top5 97.312500    
2024-04-23 18:23:51,110 - Epoch: [140][  123/  123]    Loss 0.706953    Top1 77.070064    Top5 97.273885    
2024-04-23 18:23:51,423 - ==> Top1: 77.070    Top5: 97.274    Loss: 0.707

2024-04-23 18:23:51,434 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:23:51,435 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:23:51,489 - 

2024-04-23 18:23:51,490 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:24:07,296 - Epoch: [141][  100/  296]    Overall Loss 0.748549    Objective Loss 0.748549                                        LR 0.000080    Time 0.157858    
2024-04-23 18:24:21,194 - Epoch: [141][  200/  296]    Overall Loss 0.758605    Objective Loss 0.758605                                        LR 0.000080    Time 0.148310    
2024-04-23 18:24:35,040 - Epoch: [141][  296/  296]    Overall Loss 0.757605    Objective Loss 0.757605    Top1 77.049180    Top5 100.000000    LR 0.000080    Time 0.146916    
2024-04-23 18:24:35,287 - --- validate (epoch=141)-----------
2024-04-23 18:24:35,288 - 3925 samples (32 per mini-batch)
2024-04-23 18:24:52,590 - Epoch: [141][  100/  123]    Loss 0.698546    Top1 77.656250    Top5 96.937500    
2024-04-23 18:24:55,866 - Epoch: [141][  123/  123]    Loss 0.714527    Top1 77.095541    Top5 96.993631    
2024-04-23 18:24:56,085 - ==> Top1: 77.096    Top5: 96.994    Loss: 0.715

2024-04-23 18:24:56,092 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:24:56,093 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:24:56,141 - 

2024-04-23 18:24:56,142 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:25:11,072 - Epoch: [142][  100/  296]    Overall Loss 0.759551    Objective Loss 0.759551                                        LR 0.000080    Time 0.149090    
2024-04-23 18:25:24,885 - Epoch: [142][  200/  296]    Overall Loss 0.750938    Objective Loss 0.750938                                        LR 0.000080    Time 0.143504    
2024-04-23 18:25:37,331 - Epoch: [142][  296/  296]    Overall Loss 0.753604    Objective Loss 0.753604    Top1 75.409836    Top5 95.081967    LR 0.000080    Time 0.138937    
2024-04-23 18:25:37,445 - --- validate (epoch=142)-----------
2024-04-23 18:25:37,446 - 3925 samples (32 per mini-batch)
2024-04-23 18:25:54,429 - Epoch: [142][  100/  123]    Loss 0.723390    Top1 77.281250    Top5 96.750000    
2024-04-23 18:25:57,933 - Epoch: [142][  123/  123]    Loss 0.719529    Top1 77.044586    Top5 96.993631    
2024-04-23 18:25:58,176 - ==> Top1: 77.045    Top5: 96.994    Loss: 0.720

2024-04-23 18:25:58,187 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:25:58,188 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:25:58,254 - 

2024-04-23 18:25:58,254 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:26:14,306 - Epoch: [143][  100/  296]    Overall Loss 0.742722    Objective Loss 0.742722                                        LR 0.000080    Time 0.160283    
2024-04-23 18:26:28,117 - Epoch: [143][  200/  296]    Overall Loss 0.757016    Objective Loss 0.757016                                        LR 0.000080    Time 0.149095    
2024-04-23 18:26:42,612 - Epoch: [143][  296/  296]    Overall Loss 0.767700    Objective Loss 0.767700    Top1 77.049180    Top5 95.081967    LR 0.000080    Time 0.149637    
2024-04-23 18:26:42,929 - --- validate (epoch=143)-----------
2024-04-23 18:26:42,932 - 3925 samples (32 per mini-batch)
2024-04-23 18:27:03,236 - Epoch: [143][  100/  123]    Loss 0.721878    Top1 76.875000    Top5 96.968750    
2024-04-23 18:27:07,598 - Epoch: [143][  123/  123]    Loss 0.714218    Top1 77.044586    Top5 97.121019    
2024-04-23 18:27:07,790 - ==> Top1: 77.045    Top5: 97.121    Loss: 0.714

2024-04-23 18:27:07,801 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:27:07,802 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:27:07,859 - 

2024-04-23 18:27:07,860 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:27:27,949 - Epoch: [144][  100/  296]    Overall Loss 0.800831    Objective Loss 0.800831                                        LR 0.000080    Time 0.200674    
2024-04-23 18:27:42,775 - Epoch: [144][  200/  296]    Overall Loss 0.768416    Objective Loss 0.768416                                        LR 0.000080    Time 0.174363    
2024-04-23 18:27:57,011 - Epoch: [144][  296/  296]    Overall Loss 0.761025    Objective Loss 0.761025    Top1 77.049180    Top5 98.360656    LR 0.000080    Time 0.165836    
2024-04-23 18:27:57,425 - --- validate (epoch=144)-----------
2024-04-23 18:27:57,427 - 3925 samples (32 per mini-batch)
2024-04-23 18:28:19,069 - Epoch: [144][  100/  123]    Loss 0.692480    Top1 77.375000    Top5 97.500000    
2024-04-23 18:28:23,389 - Epoch: [144][  123/  123]    Loss 0.712637    Top1 76.993631    Top5 97.197452    
2024-04-23 18:28:23,787 - ==> Top1: 76.994    Top5: 97.197    Loss: 0.713

2024-04-23 18:28:23,805 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:28:23,806 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:28:23,882 - 

2024-04-23 18:28:23,884 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:28:42,644 - Epoch: [145][  100/  296]    Overall Loss 0.743767    Objective Loss 0.743767                                        LR 0.000080    Time 0.187368    
2024-04-23 18:28:58,770 - Epoch: [145][  200/  296]    Overall Loss 0.744670    Objective Loss 0.744670                                        LR 0.000080    Time 0.174195    
2024-04-23 18:29:13,744 - Epoch: [145][  296/  296]    Overall Loss 0.745454    Objective Loss 0.745454    Top1 70.491803    Top5 93.442623    LR 0.000080    Time 0.168217    
2024-04-23 18:29:13,966 - --- validate (epoch=145)-----------
2024-04-23 18:29:13,967 - 3925 samples (32 per mini-batch)
2024-04-23 18:29:34,190 - Epoch: [145][  100/  123]    Loss 0.734216    Top1 77.312500    Top5 96.968750    
2024-04-23 18:29:38,300 - Epoch: [145][  123/  123]    Loss 0.713000    Top1 77.605096    Top5 97.146497    
2024-04-23 18:29:38,642 - ==> Top1: 77.605    Top5: 97.146    Loss: 0.713

2024-04-23 18:29:38,656 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:29:38,657 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:29:38,728 - 

2024-04-23 18:29:38,729 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:29:56,134 - Epoch: [146][  100/  296]    Overall Loss 0.722348    Objective Loss 0.722348                                        LR 0.000080    Time 0.173808    
2024-04-23 18:30:13,657 - Epoch: [146][  200/  296]    Overall Loss 0.749679    Objective Loss 0.749679                                        LR 0.000080    Time 0.174411    
2024-04-23 18:30:28,157 - Epoch: [146][  296/  296]    Overall Loss 0.757170    Objective Loss 0.757170    Top1 73.770492    Top5 96.721311    LR 0.000080    Time 0.166765    
2024-04-23 18:30:28,488 - --- validate (epoch=146)-----------
2024-04-23 18:30:28,491 - 3925 samples (32 per mini-batch)
2024-04-23 18:30:49,203 - Epoch: [146][  100/  123]    Loss 0.688737    Top1 77.968750    Top5 97.375000    
2024-04-23 18:30:53,207 - Epoch: [146][  123/  123]    Loss 0.716877    Top1 77.197452    Top5 97.146497    
2024-04-23 18:30:53,355 - ==> Top1: 77.197    Top5: 97.146    Loss: 0.717

2024-04-23 18:30:53,365 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:30:53,366 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:30:53,414 - 

2024-04-23 18:30:53,415 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:31:11,076 - Epoch: [147][  100/  296]    Overall Loss 0.768656    Objective Loss 0.768656                                        LR 0.000080    Time 0.176375    
2024-04-23 18:31:29,951 - Epoch: [147][  200/  296]    Overall Loss 0.764573    Objective Loss 0.764573                                        LR 0.000080    Time 0.182450    
2024-04-23 18:31:45,957 - Epoch: [147][  296/  296]    Overall Loss 0.755821    Objective Loss 0.755821    Top1 68.852459    Top5 96.721311    LR 0.000080    Time 0.177284    
2024-04-23 18:31:46,280 - --- validate (epoch=147)-----------
2024-04-23 18:31:46,281 - 3925 samples (32 per mini-batch)
2024-04-23 18:32:05,343 - Epoch: [147][  100/  123]    Loss 0.712524    Top1 77.625000    Top5 97.062500    
2024-04-23 18:32:09,653 - Epoch: [147][  123/  123]    Loss 0.718237    Top1 77.070064    Top5 97.121019    
2024-04-23 18:32:09,997 - ==> Top1: 77.070    Top5: 97.121    Loss: 0.718

2024-04-23 18:32:10,005 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:32:10,006 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:32:10,055 - 

2024-04-23 18:32:10,056 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:32:24,403 - Epoch: [148][  100/  296]    Overall Loss 0.754201    Objective Loss 0.754201                                        LR 0.000080    Time 0.143261    
2024-04-23 18:32:37,951 - Epoch: [148][  200/  296]    Overall Loss 0.763868    Objective Loss 0.763868                                        LR 0.000080    Time 0.139256    
2024-04-23 18:32:48,277 - Epoch: [148][  296/  296]    Overall Loss 0.762728    Objective Loss 0.762728    Top1 75.409836    Top5 98.360656    LR 0.000080    Time 0.128914    
2024-04-23 18:32:48,505 - --- validate (epoch=148)-----------
2024-04-23 18:32:48,507 - 3925 samples (32 per mini-batch)
2024-04-23 18:33:07,860 - Epoch: [148][  100/  123]    Loss 0.715207    Top1 77.250000    Top5 97.093750    
2024-04-23 18:33:11,839 - Epoch: [148][  123/  123]    Loss 0.731148    Top1 76.891720    Top5 96.815287    
2024-04-23 18:33:12,185 - ==> Top1: 76.892    Top5: 96.815    Loss: 0.731

2024-04-23 18:33:12,199 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:33:12,200 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:33:12,262 - 

2024-04-23 18:33:12,263 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:33:31,172 - Epoch: [149][  100/  296]    Overall Loss 0.749265    Objective Loss 0.749265                                        LR 0.000080    Time 0.188854    
2024-04-23 18:33:47,985 - Epoch: [149][  200/  296]    Overall Loss 0.758005    Objective Loss 0.758005                                        LR 0.000080    Time 0.178378    
2024-04-23 18:34:04,215 - Epoch: [149][  296/  296]    Overall Loss 0.758472    Objective Loss 0.758472    Top1 72.131148    Top5 100.000000    LR 0.000080    Time 0.175285    
2024-04-23 18:34:04,572 - --- validate (epoch=149)-----------
2024-04-23 18:34:04,574 - 3925 samples (32 per mini-batch)
2024-04-23 18:34:25,871 - Epoch: [149][  100/  123]    Loss 0.732026    Top1 76.312500    Top5 96.937500    
2024-04-23 18:34:30,297 - Epoch: [149][  123/  123]    Loss 0.723083    Top1 76.560510    Top5 97.044586    
2024-04-23 18:34:30,602 - ==> Top1: 76.561    Top5: 97.045    Loss: 0.723

2024-04-23 18:34:30,613 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:34:30,615 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:34:30,713 - 

2024-04-23 18:34:30,714 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:34:48,288 - Epoch: [150][  100/  296]    Overall Loss 0.743657    Objective Loss 0.743657                                        LR 0.000020    Time 0.175480    
2024-04-23 18:35:03,755 - Epoch: [150][  200/  296]    Overall Loss 0.751419    Objective Loss 0.751419                                        LR 0.000020    Time 0.164964    
2024-04-23 18:35:21,676 - Epoch: [150][  296/  296]    Overall Loss 0.761532    Objective Loss 0.761532    Top1 65.573770    Top5 96.721311    LR 0.000020    Time 0.171937    
2024-04-23 18:35:22,032 - --- validate (epoch=150)-----------
2024-04-23 18:35:22,033 - 3925 samples (32 per mini-batch)
2024-04-23 18:35:38,903 - Epoch: [150][  100/  123]    Loss 0.695208    Top1 77.531250    Top5 97.343750    
2024-04-23 18:35:42,837 - Epoch: [150][  123/  123]    Loss 0.708619    Top1 77.019108    Top5 97.273885    
2024-04-23 18:35:43,215 - ==> Top1: 77.019    Top5: 97.274    Loss: 0.709

2024-04-23 18:35:43,231 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:35:43,233 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:35:43,321 - 

2024-04-23 18:35:43,322 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:36:00,516 - Epoch: [151][  100/  296]    Overall Loss 0.755350    Objective Loss 0.755350                                        LR 0.000020    Time 0.171678    
2024-04-23 18:36:16,251 - Epoch: [151][  200/  296]    Overall Loss 0.762049    Objective Loss 0.762049                                        LR 0.000020    Time 0.164401    
2024-04-23 18:36:30,867 - Epoch: [151][  296/  296]    Overall Loss 0.752222    Objective Loss 0.752222    Top1 75.409836    Top5 95.081967    LR 0.000020    Time 0.160387    
2024-04-23 18:36:31,221 - --- validate (epoch=151)-----------
2024-04-23 18:36:31,222 - 3925 samples (32 per mini-batch)
2024-04-23 18:36:49,416 - Epoch: [151][  100/  123]    Loss 0.692652    Top1 77.593750    Top5 97.281250    
2024-04-23 18:36:53,169 - Epoch: [151][  123/  123]    Loss 0.710443    Top1 76.815287    Top5 97.197452    
2024-04-23 18:36:53,416 - ==> Top1: 76.815    Top5: 97.197    Loss: 0.710

2024-04-23 18:36:53,427 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:36:53,428 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:36:53,477 - 

2024-04-23 18:36:53,478 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:37:08,407 - Epoch: [152][  100/  296]    Overall Loss 0.729379    Objective Loss 0.729379                                        LR 0.000020    Time 0.149052    
2024-04-23 18:37:22,508 - Epoch: [152][  200/  296]    Overall Loss 0.738556    Objective Loss 0.738556                                        LR 0.000020    Time 0.144918    
2024-04-23 18:37:34,244 - Epoch: [152][  296/  296]    Overall Loss 0.748831    Objective Loss 0.748831    Top1 73.770492    Top5 96.721311    LR 0.000020    Time 0.137497    
2024-04-23 18:37:34,573 - --- validate (epoch=152)-----------
2024-04-23 18:37:34,575 - 3925 samples (32 per mini-batch)
2024-04-23 18:37:51,701 - Epoch: [152][  100/  123]    Loss 0.698683    Top1 77.281250    Top5 97.406250    
2024-04-23 18:37:55,186 - Epoch: [152][  123/  123]    Loss 0.703708    Top1 77.222930    Top5 97.273885    
2024-04-23 18:37:55,550 - ==> Top1: 77.223    Top5: 97.274    Loss: 0.704

2024-04-23 18:37:55,562 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:37:55,563 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:37:55,620 - 

2024-04-23 18:37:55,621 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:38:12,647 - Epoch: [153][  100/  296]    Overall Loss 0.755105    Objective Loss 0.755105                                        LR 0.000020    Time 0.170017    
2024-04-23 18:38:27,014 - Epoch: [153][  200/  296]    Overall Loss 0.754539    Objective Loss 0.754539                                        LR 0.000020    Time 0.156739    
2024-04-23 18:38:41,250 - Epoch: [153][  296/  296]    Overall Loss 0.745594    Objective Loss 0.745594    Top1 85.245902    Top5 96.721311    LR 0.000020    Time 0.153925    
2024-04-23 18:38:41,597 - --- validate (epoch=153)-----------
2024-04-23 18:38:41,598 - 3925 samples (32 per mini-batch)
2024-04-23 18:39:00,270 - Epoch: [153][  100/  123]    Loss 0.724203    Top1 77.125000    Top5 96.875000    
2024-04-23 18:39:04,819 - Epoch: [153][  123/  123]    Loss 0.709043    Top1 77.248408    Top5 97.197452    
2024-04-23 18:39:05,111 - ==> Top1: 77.248    Top5: 97.197    Loss: 0.709

2024-04-23 18:39:05,124 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:39:05,125 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:39:05,191 - 

2024-04-23 18:39:05,192 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:39:22,506 - Epoch: [154][  100/  296]    Overall Loss 0.736243    Objective Loss 0.736243                                        LR 0.000020    Time 0.172883    
2024-04-23 18:39:39,379 - Epoch: [154][  200/  296]    Overall Loss 0.736670    Objective Loss 0.736670                                        LR 0.000020    Time 0.170697    
2024-04-23 18:39:54,041 - Epoch: [154][  296/  296]    Overall Loss 0.736328    Objective Loss 0.736328    Top1 70.491803    Top5 95.081967    LR 0.000020    Time 0.164789    
2024-04-23 18:39:54,394 - --- validate (epoch=154)-----------
2024-04-23 18:39:54,395 - 3925 samples (32 per mini-batch)
2024-04-23 18:40:09,576 - Epoch: [154][  100/  123]    Loss 0.708818    Top1 77.406250    Top5 97.156250    
2024-04-23 18:40:12,222 - Epoch: [154][  123/  123]    Loss 0.709809    Top1 77.503185    Top5 97.222930    
2024-04-23 18:40:12,505 - ==> Top1: 77.503    Top5: 97.223    Loss: 0.710

2024-04-23 18:40:12,516 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:40:12,517 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:40:12,568 - 

2024-04-23 18:40:12,569 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:40:25,780 - Epoch: [155][  100/  296]    Overall Loss 0.734934    Objective Loss 0.734934                                        LR 0.000020    Time 0.131871    
2024-04-23 18:40:39,762 - Epoch: [155][  200/  296]    Overall Loss 0.749709    Objective Loss 0.749709                                        LR 0.000020    Time 0.135736    
2024-04-23 18:40:52,868 - Epoch: [155][  296/  296]    Overall Loss 0.761818    Objective Loss 0.761818    Top1 80.327869    Top5 100.000000    LR 0.000020    Time 0.135922    
2024-04-23 18:40:53,209 - --- validate (epoch=155)-----------
2024-04-23 18:40:53,210 - 3925 samples (32 per mini-batch)
2024-04-23 18:41:10,509 - Epoch: [155][  100/  123]    Loss 0.698391    Top1 77.500000    Top5 97.468750    
2024-04-23 18:41:14,394 - Epoch: [155][  123/  123]    Loss 0.705826    Top1 77.350318    Top5 97.324841    
2024-04-23 18:41:14,730 - ==> Top1: 77.350    Top5: 97.325    Loss: 0.706

2024-04-23 18:41:14,738 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:41:14,739 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:41:14,789 - 

2024-04-23 18:41:14,790 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:41:30,539 - Epoch: [156][  100/  296]    Overall Loss 0.768057    Objective Loss 0.768057                                        LR 0.000020    Time 0.157251    
2024-04-23 18:41:43,805 - Epoch: [156][  200/  296]    Overall Loss 0.747497    Objective Loss 0.747497                                        LR 0.000020    Time 0.144849    
2024-04-23 18:41:56,611 - Epoch: [156][  296/  296]    Overall Loss 0.750653    Objective Loss 0.750653    Top1 77.049180    Top5 96.721311    LR 0.000020    Time 0.141061    
2024-04-23 18:41:56,908 - --- validate (epoch=156)-----------
2024-04-23 18:41:56,910 - 3925 samples (32 per mini-batch)
2024-04-23 18:42:13,625 - Epoch: [156][  100/  123]    Loss 0.706628    Top1 77.187500    Top5 97.093750    
2024-04-23 18:42:17,334 - Epoch: [156][  123/  123]    Loss 0.710983    Top1 77.350318    Top5 97.171975    
2024-04-23 18:42:17,635 - ==> Top1: 77.350    Top5: 97.172    Loss: 0.711

2024-04-23 18:42:17,646 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:42:17,647 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:42:17,699 - 

2024-04-23 18:42:17,700 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:42:32,503 - Epoch: [157][  100/  296]    Overall Loss 0.749126    Objective Loss 0.749126                                        LR 0.000020    Time 0.147809    
2024-04-23 18:42:45,133 - Epoch: [157][  200/  296]    Overall Loss 0.761145    Objective Loss 0.761145                                        LR 0.000020    Time 0.136947    
2024-04-23 18:42:57,475 - Epoch: [157][  296/  296]    Overall Loss 0.756972    Objective Loss 0.756972    Top1 70.491803    Top5 98.360656    LR 0.000020    Time 0.134155    
2024-04-23 18:42:57,747 - --- validate (epoch=157)-----------
2024-04-23 18:42:57,749 - 3925 samples (32 per mini-batch)
2024-04-23 18:43:14,529 - Epoch: [157][  100/  123]    Loss 0.694770    Top1 77.875000    Top5 97.375000    
2024-04-23 18:43:17,631 - Epoch: [157][  123/  123]    Loss 0.709010    Top1 77.401274    Top5 97.222930    
2024-04-23 18:43:17,937 - ==> Top1: 77.401    Top5: 97.223    Loss: 0.709

2024-04-23 18:43:17,949 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:43:17,950 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:43:17,999 - 

2024-04-23 18:43:18,001 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:43:33,114 - Epoch: [158][  100/  296]    Overall Loss 0.747440    Objective Loss 0.747440                                        LR 0.000020    Time 0.150913    
2024-04-23 18:43:46,269 - Epoch: [158][  200/  296]    Overall Loss 0.753308    Objective Loss 0.753308                                        LR 0.000020    Time 0.141110    
2024-04-23 18:44:00,049 - Epoch: [158][  296/  296]    Overall Loss 0.757850    Objective Loss 0.757850    Top1 60.655738    Top5 95.081967    LR 0.000020    Time 0.141826    
2024-04-23 18:44:00,334 - --- validate (epoch=158)-----------
2024-04-23 18:44:00,336 - 3925 samples (32 per mini-batch)
2024-04-23 18:44:14,197 - Epoch: [158][  100/  123]    Loss 0.690402    Top1 77.812500    Top5 97.281250    
2024-04-23 18:44:16,228 - Epoch: [158][  123/  123]    Loss 0.701761    Top1 77.554140    Top5 97.375796    
2024-04-23 18:44:16,486 - ==> Top1: 77.554    Top5: 97.376    Loss: 0.702

2024-04-23 18:44:16,495 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:44:16,496 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:44:16,537 - 

2024-04-23 18:44:16,538 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:44:26,229 - Epoch: [159][  100/  296]    Overall Loss 0.715557    Objective Loss 0.715557                                        LR 0.000020    Time 0.096715    
2024-04-23 18:44:34,557 - Epoch: [159][  200/  296]    Overall Loss 0.727320    Objective Loss 0.727320                                        LR 0.000020    Time 0.089907    
2024-04-23 18:44:45,648 - Epoch: [159][  296/  296]    Overall Loss 0.736277    Objective Loss 0.736277    Top1 78.688525    Top5 93.442623    LR 0.000020    Time 0.098151    
2024-04-23 18:44:45,942 - --- validate (epoch=159)-----------
2024-04-23 18:44:45,943 - 3925 samples (32 per mini-batch)
2024-04-23 18:45:00,516 - Epoch: [159][  100/  123]    Loss 0.684277    Top1 78.156250    Top5 97.218750    
2024-04-23 18:45:02,398 - Epoch: [159][  123/  123]    Loss 0.704958    Top1 77.171975    Top5 97.273885    
2024-04-23 18:45:02,607 - ==> Top1: 77.172    Top5: 97.274    Loss: 0.705

2024-04-23 18:45:02,615 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:45:02,616 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:45:02,652 - 

2024-04-23 18:45:02,653 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:45:14,425 - Epoch: [160][  100/  296]    Overall Loss 0.729014    Objective Loss 0.729014                                        LR 0.000020    Time 0.117507    
2024-04-23 18:45:26,075 - Epoch: [160][  200/  296]    Overall Loss 0.730070    Objective Loss 0.730070                                        LR 0.000020    Time 0.116894    
2024-04-23 18:45:40,467 - Epoch: [160][  296/  296]    Overall Loss 0.730346    Objective Loss 0.730346    Top1 70.491803    Top5 95.081967    LR 0.000020    Time 0.127534    
2024-04-23 18:45:40,769 - --- validate (epoch=160)-----------
2024-04-23 18:45:40,771 - 3925 samples (32 per mini-batch)
2024-04-23 18:45:57,120 - Epoch: [160][  100/  123]    Loss 0.692826    Top1 77.875000    Top5 97.375000    
2024-04-23 18:46:00,535 - Epoch: [160][  123/  123]    Loss 0.707213    Top1 77.503185    Top5 97.248408    
2024-04-23 18:46:00,793 - ==> Top1: 77.503    Top5: 97.248    Loss: 0.707

2024-04-23 18:46:00,803 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:46:00,804 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:46:00,852 - 

2024-04-23 18:46:00,853 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:46:17,268 - Epoch: [161][  100/  296]    Overall Loss 0.740387    Objective Loss 0.740387                                        LR 0.000020    Time 0.163917    
2024-04-23 18:46:32,458 - Epoch: [161][  200/  296]    Overall Loss 0.739095    Objective Loss 0.739095                                        LR 0.000020    Time 0.157795    
2024-04-23 18:46:47,170 - Epoch: [161][  296/  296]    Overall Loss 0.735543    Objective Loss 0.735543    Top1 77.049180    Top5 98.360656    LR 0.000020    Time 0.156244    
2024-04-23 18:46:47,562 - --- validate (epoch=161)-----------
2024-04-23 18:46:47,564 - 3925 samples (32 per mini-batch)
2024-04-23 18:47:06,998 - Epoch: [161][  100/  123]    Loss 0.691225    Top1 77.718750    Top5 97.250000    
2024-04-23 18:47:11,168 - Epoch: [161][  123/  123]    Loss 0.709610    Top1 77.350318    Top5 97.222930    
2024-04-23 18:47:11,476 - ==> Top1: 77.350    Top5: 97.223    Loss: 0.710

2024-04-23 18:47:11,487 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:47:11,488 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:47:11,543 - 

2024-04-23 18:47:11,544 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:47:28,848 - Epoch: [162][  100/  296]    Overall Loss 0.704754    Objective Loss 0.704754                                        LR 0.000020    Time 0.172773    
2024-04-23 18:47:44,538 - Epoch: [162][  200/  296]    Overall Loss 0.726320    Objective Loss 0.726320                                        LR 0.000020    Time 0.164727    
2024-04-23 18:48:03,549 - Epoch: [162][  296/  296]    Overall Loss 0.729514    Objective Loss 0.729514    Top1 63.934426    Top5 95.081967    LR 0.000020    Time 0.175459    
2024-04-23 18:48:03,749 - --- validate (epoch=162)-----------
2024-04-23 18:48:03,751 - 3925 samples (32 per mini-batch)
2024-04-23 18:48:21,118 - Epoch: [162][  100/  123]    Loss 0.701028    Top1 77.812500    Top5 97.156250    
2024-04-23 18:48:24,177 - Epoch: [162][  123/  123]    Loss 0.708061    Top1 77.324841    Top5 97.273885    
2024-04-23 18:48:24,443 - ==> Top1: 77.325    Top5: 97.274    Loss: 0.708

2024-04-23 18:48:24,454 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:48:24,454 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:48:24,513 - 

2024-04-23 18:48:24,515 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:48:41,078 - Epoch: [163][  100/  296]    Overall Loss 0.739266    Objective Loss 0.739266                                        LR 0.000020    Time 0.165397    
2024-04-23 18:48:57,115 - Epoch: [163][  200/  296]    Overall Loss 0.731001    Objective Loss 0.731001                                        LR 0.000020    Time 0.162747    
2024-04-23 18:49:13,645 - Epoch: [163][  296/  296]    Overall Loss 0.728301    Objective Loss 0.728301    Top1 80.327869    Top5 98.360656    LR 0.000020    Time 0.165730    
2024-04-23 18:49:13,963 - --- validate (epoch=163)-----------
2024-04-23 18:49:13,964 - 3925 samples (32 per mini-batch)
2024-04-23 18:49:33,876 - Epoch: [163][  100/  123]    Loss 0.702419    Top1 77.937500    Top5 97.250000    
2024-04-23 18:49:37,081 - Epoch: [163][  123/  123]    Loss 0.704177    Top1 77.528662    Top5 97.324841    
2024-04-23 18:49:37,408 - ==> Top1: 77.529    Top5: 97.325    Loss: 0.704

2024-04-23 18:49:37,417 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:49:37,418 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:49:37,478 - 

2024-04-23 18:49:37,479 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:49:52,997 - Epoch: [164][  100/  296]    Overall Loss 0.740430    Objective Loss 0.740430                                        LR 0.000020    Time 0.154936    
2024-04-23 18:50:06,271 - Epoch: [164][  200/  296]    Overall Loss 0.742884    Objective Loss 0.742884                                        LR 0.000020    Time 0.143726    
2024-04-23 18:50:18,502 - Epoch: [164][  296/  296]    Overall Loss 0.741262    Objective Loss 0.741262    Top1 78.688525    Top5 96.721311    LR 0.000020    Time 0.138366    
2024-04-23 18:50:18,758 - --- validate (epoch=164)-----------
2024-04-23 18:50:18,759 - 3925 samples (32 per mini-batch)
2024-04-23 18:50:35,627 - Epoch: [164][  100/  123]    Loss 0.718364    Top1 76.906250    Top5 97.312500    
2024-04-23 18:50:38,814 - Epoch: [164][  123/  123]    Loss 0.703216    Top1 77.350318    Top5 97.426752    
2024-04-23 18:50:39,094 - ==> Top1: 77.350    Top5: 97.427    Loss: 0.703

2024-04-23 18:50:39,105 - ==> Best [Top1: 77.732   Top5: 97.096   Sparsity:0.00   Params: 370272 on epoch: 122]
2024-04-23 18:50:39,106 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:50:39,155 - 

2024-04-23 18:50:39,156 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:50:59,654 - Epoch: [165][  100/  296]    Overall Loss 0.747929    Objective Loss 0.747929                                        LR 0.000020    Time 0.204781    
2024-04-23 18:51:16,976 - Epoch: [165][  200/  296]    Overall Loss 0.732539    Objective Loss 0.732539                                        LR 0.000020    Time 0.188891    
2024-04-23 18:51:32,943 - Epoch: [165][  296/  296]    Overall Loss 0.729854    Objective Loss 0.729854    Top1 72.131148    Top5 96.721311    LR 0.000020    Time 0.181501    
2024-04-23 18:51:33,274 - --- validate (epoch=165)-----------
2024-04-23 18:51:33,275 - 3925 samples (32 per mini-batch)
2024-04-23 18:51:50,550 - Epoch: [165][  100/  123]    Loss 0.707586    Top1 78.000000    Top5 97.218750    
2024-04-23 18:51:55,076 - Epoch: [165][  123/  123]    Loss 0.702265    Top1 77.834395    Top5 97.375796    
2024-04-23 18:51:55,294 - ==> Top1: 77.834    Top5: 97.376    Loss: 0.702

2024-04-23 18:51:55,310 - ==> Best [Top1: 77.834   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 165]
2024-04-23 18:51:55,311 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:51:55,425 - 

2024-04-23 18:51:55,426 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:52:13,202 - Epoch: [166][  100/  296]    Overall Loss 0.768758    Objective Loss 0.768758                                        LR 0.000020    Time 0.177506    
2024-04-23 18:52:27,667 - Epoch: [166][  200/  296]    Overall Loss 0.764760    Objective Loss 0.764760                                        LR 0.000020    Time 0.160966    
2024-04-23 18:52:44,059 - Epoch: [166][  296/  296]    Overall Loss 0.753803    Objective Loss 0.753803    Top1 60.655738    Top5 91.803279    LR 0.000020    Time 0.164060    
2024-04-23 18:52:44,378 - --- validate (epoch=166)-----------
2024-04-23 18:52:44,380 - 3925 samples (32 per mini-batch)
2024-04-23 18:53:02,259 - Epoch: [166][  100/  123]    Loss 0.703272    Top1 77.531250    Top5 97.156250    
2024-04-23 18:53:04,774 - Epoch: [166][  123/  123]    Loss 0.705134    Top1 77.579618    Top5 97.171975    
2024-04-23 18:53:05,211 - ==> Top1: 77.580    Top5: 97.172    Loss: 0.705

2024-04-23 18:53:05,222 - ==> Best [Top1: 77.834   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 165]
2024-04-23 18:53:05,223 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:53:05,270 - 

2024-04-23 18:53:05,271 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:53:20,796 - Epoch: [167][  100/  296]    Overall Loss 0.742157    Objective Loss 0.742157                                        LR 0.000020    Time 0.155001    
2024-04-23 18:53:35,296 - Epoch: [167][  200/  296]    Overall Loss 0.741613    Objective Loss 0.741613                                        LR 0.000020    Time 0.149891    
2024-04-23 18:53:48,943 - Epoch: [167][  296/  296]    Overall Loss 0.736083    Objective Loss 0.736083    Top1 77.049180    Top5 96.721311    LR 0.000020    Time 0.147310    
2024-04-23 18:53:49,241 - --- validate (epoch=167)-----------
2024-04-23 18:53:49,242 - 3925 samples (32 per mini-batch)
2024-04-23 18:54:06,690 - Epoch: [167][  100/  123]    Loss 0.696580    Top1 77.656250    Top5 97.468750    
2024-04-23 18:54:09,101 - Epoch: [167][  123/  123]    Loss 0.705019    Top1 77.503185    Top5 97.350318    
2024-04-23 18:54:09,379 - ==> Top1: 77.503    Top5: 97.350    Loss: 0.705

2024-04-23 18:54:09,389 - ==> Best [Top1: 77.834   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 165]
2024-04-23 18:54:09,389 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:54:09,433 - 

2024-04-23 18:54:09,434 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:54:20,340 - Epoch: [168][  100/  296]    Overall Loss 0.758481    Objective Loss 0.758481                                        LR 0.000020    Time 0.108855    
2024-04-23 18:54:30,919 - Epoch: [168][  200/  296]    Overall Loss 0.737096    Objective Loss 0.737096                                        LR 0.000020    Time 0.107236    
2024-04-23 18:54:43,559 - Epoch: [168][  296/  296]    Overall Loss 0.732631    Objective Loss 0.732631    Top1 73.770492    Top5 96.721311    LR 0.000020    Time 0.115094    
2024-04-23 18:54:43,876 - --- validate (epoch=168)-----------
2024-04-23 18:54:43,878 - 3925 samples (32 per mini-batch)
2024-04-23 18:55:02,167 - Epoch: [168][  100/  123]    Loss 0.717050    Top1 77.218750    Top5 97.031250    
2024-04-23 18:55:05,163 - Epoch: [168][  123/  123]    Loss 0.705634    Top1 77.783439    Top5 97.324841    
2024-04-23 18:55:05,485 - ==> Top1: 77.783    Top5: 97.325    Loss: 0.706

2024-04-23 18:55:05,495 - ==> Best [Top1: 77.834   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 165]
2024-04-23 18:55:05,497 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:55:05,576 - 

2024-04-23 18:55:05,578 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:55:19,700 - Epoch: [169][  100/  296]    Overall Loss 0.738215    Objective Loss 0.738215                                        LR 0.000020    Time 0.140997    
2024-04-23 18:55:32,524 - Epoch: [169][  200/  296]    Overall Loss 0.730632    Objective Loss 0.730632                                        LR 0.000020    Time 0.134515    
2024-04-23 18:55:45,389 - Epoch: [169][  296/  296]    Overall Loss 0.722388    Objective Loss 0.722388    Top1 68.852459    Top5 96.721311    LR 0.000020    Time 0.134284    
2024-04-23 18:55:45,742 - --- validate (epoch=169)-----------
2024-04-23 18:55:45,743 - 3925 samples (32 per mini-batch)
2024-04-23 18:56:00,652 - Epoch: [169][  100/  123]    Loss 0.712062    Top1 77.375000    Top5 97.218750    
2024-04-23 18:56:03,624 - Epoch: [169][  123/  123]    Loss 0.703956    Top1 77.452229    Top5 97.350318    
2024-04-23 18:56:03,836 - ==> Top1: 77.452    Top5: 97.350    Loss: 0.704

2024-04-23 18:56:03,847 - ==> Best [Top1: 77.834   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 165]
2024-04-23 18:56:03,847 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:56:03,897 - 

2024-04-23 18:56:03,897 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:56:18,553 - Epoch: [170][  100/  296]    Overall Loss 0.717581    Objective Loss 0.717581                                        LR 0.000020    Time 0.146340    
2024-04-23 18:56:29,355 - Epoch: [170][  200/  296]    Overall Loss 0.722509    Objective Loss 0.722509                                        LR 0.000020    Time 0.127079    
2024-04-23 18:56:41,245 - Epoch: [170][  296/  296]    Overall Loss 0.722095    Objective Loss 0.722095    Top1 65.573770    Top5 96.721311    LR 0.000020    Time 0.125968    
2024-04-23 18:56:41,556 - --- validate (epoch=170)-----------
2024-04-23 18:56:41,558 - 3925 samples (32 per mini-batch)
2024-04-23 18:56:57,531 - Epoch: [170][  100/  123]    Loss 0.700126    Top1 77.937500    Top5 97.250000    
2024-04-23 18:57:00,258 - Epoch: [170][  123/  123]    Loss 0.698683    Top1 77.910828    Top5 97.350318    
2024-04-23 18:57:00,579 - ==> Top1: 77.911    Top5: 97.350    Loss: 0.699

2024-04-23 18:57:00,586 - ==> Best [Top1: 77.911   Top5: 97.350   Sparsity:0.00   Params: 370272 on epoch: 170]
2024-04-23 18:57:00,586 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:57:00,638 - 

2024-04-23 18:57:00,639 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:57:12,397 - Epoch: [171][  100/  296]    Overall Loss 0.736772    Objective Loss 0.736772                                        LR 0.000020    Time 0.117367    
2024-04-23 18:57:24,010 - Epoch: [171][  200/  296]    Overall Loss 0.747308    Objective Loss 0.747308                                        LR 0.000020    Time 0.116643    
2024-04-23 18:57:33,369 - Epoch: [171][  296/  296]    Overall Loss 0.753871    Objective Loss 0.753871    Top1 81.967213    Top5 100.000000    LR 0.000020    Time 0.110373    
2024-04-23 18:57:33,676 - --- validate (epoch=171)-----------
2024-04-23 18:57:33,677 - 3925 samples (32 per mini-batch)
2024-04-23 18:57:47,954 - Epoch: [171][  100/  123]    Loss 0.698992    Top1 78.187500    Top5 97.281250    
2024-04-23 18:57:51,139 - Epoch: [171][  123/  123]    Loss 0.703646    Top1 78.089172    Top5 97.401274    
2024-04-23 18:57:51,393 - ==> Top1: 78.089    Top5: 97.401    Loss: 0.704

2024-04-23 18:57:51,402 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 18:57:51,403 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:57:51,475 - 

2024-04-23 18:57:51,476 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:58:03,373 - Epoch: [172][  100/  296]    Overall Loss 0.727569    Objective Loss 0.727569                                        LR 0.000020    Time 0.118747    
2024-04-23 18:58:12,820 - Epoch: [172][  200/  296]    Overall Loss 0.725469    Objective Loss 0.725469                                        LR 0.000020    Time 0.106512    
2024-04-23 18:58:21,620 - Epoch: [172][  296/  296]    Overall Loss 0.732006    Objective Loss 0.732006    Top1 70.491803    Top5 96.721311    LR 0.000020    Time 0.101630    
2024-04-23 18:58:21,882 - --- validate (epoch=172)-----------
2024-04-23 18:58:21,883 - 3925 samples (32 per mini-batch)
2024-04-23 18:58:36,381 - Epoch: [172][  100/  123]    Loss 0.693652    Top1 78.062500    Top5 97.406250    
2024-04-23 18:58:39,261 - Epoch: [172][  123/  123]    Loss 0.700709    Top1 77.961783    Top5 97.299363    
2024-04-23 18:58:39,512 - ==> Top1: 77.962    Top5: 97.299    Loss: 0.701

2024-04-23 18:58:39,523 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 18:58:39,524 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:58:39,569 - 

2024-04-23 18:58:39,570 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:58:51,697 - Epoch: [173][  100/  296]    Overall Loss 0.752405    Objective Loss 0.752405                                        LR 0.000020    Time 0.121066    
2024-04-23 18:59:01,725 - Epoch: [173][  200/  296]    Overall Loss 0.734850    Objective Loss 0.734850                                        LR 0.000020    Time 0.110574    
2024-04-23 18:59:15,704 - Epoch: [173][  296/  296]    Overall Loss 0.734970    Objective Loss 0.734970    Top1 72.131148    Top5 98.360656    LR 0.000020    Time 0.121874    
2024-04-23 18:59:15,938 - --- validate (epoch=173)-----------
2024-04-23 18:59:15,939 - 3925 samples (32 per mini-batch)
2024-04-23 18:59:32,088 - Epoch: [173][  100/  123]    Loss 0.689364    Top1 78.375000    Top5 97.468750    
2024-04-23 18:59:34,884 - Epoch: [173][  123/  123]    Loss 0.703266    Top1 77.681529    Top5 97.401274    
2024-04-23 18:59:35,204 - ==> Top1: 77.682    Top5: 97.401    Loss: 0.703

2024-04-23 18:59:35,213 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 18:59:35,214 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 18:59:35,257 - 

2024-04-23 18:59:35,258 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:59:47,940 - Epoch: [174][  100/  296]    Overall Loss 0.750743    Objective Loss 0.750743                                        LR 0.000020    Time 0.126616    
2024-04-23 19:00:00,526 - Epoch: [174][  200/  296]    Overall Loss 0.736040    Objective Loss 0.736040                                        LR 0.000020    Time 0.126131    
2024-04-23 19:00:10,797 - Epoch: [174][  296/  296]    Overall Loss 0.727315    Objective Loss 0.727315    Top1 73.770492    Top5 98.360656    LR 0.000020    Time 0.119860    
2024-04-23 19:00:11,058 - --- validate (epoch=174)-----------
2024-04-23 19:00:11,059 - 3925 samples (32 per mini-batch)
2024-04-23 19:00:26,100 - Epoch: [174][  100/  123]    Loss 0.703775    Top1 77.812500    Top5 97.218750    
2024-04-23 19:00:30,342 - Epoch: [174][  123/  123]    Loss 0.701707    Top1 77.732484    Top5 97.197452    
2024-04-23 19:00:30,610 - ==> Top1: 77.732    Top5: 97.197    Loss: 0.702

2024-04-23 19:00:30,621 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:00:30,622 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:00:30,680 - 

2024-04-23 19:00:30,680 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:00:45,924 - Epoch: [175][  100/  296]    Overall Loss 0.741692    Objective Loss 0.741692                                        LR 0.000020    Time 0.152203    
2024-04-23 19:00:57,800 - Epoch: [175][  200/  296]    Overall Loss 0.728200    Objective Loss 0.728200                                        LR 0.000020    Time 0.135378    
2024-04-23 19:01:11,954 - Epoch: [175][  296/  296]    Overall Loss 0.729284    Objective Loss 0.729284    Top1 80.327869    Top5 100.000000    LR 0.000020    Time 0.139230    
2024-04-23 19:01:12,150 - --- validate (epoch=175)-----------
2024-04-23 19:01:12,152 - 3925 samples (32 per mini-batch)
2024-04-23 19:01:30,555 - Epoch: [175][  100/  123]    Loss 0.702738    Top1 77.437500    Top5 97.093750    
2024-04-23 19:01:34,295 - Epoch: [175][  123/  123]    Loss 0.704420    Top1 77.401274    Top5 97.273885    
2024-04-23 19:01:34,615 - ==> Top1: 77.401    Top5: 97.274    Loss: 0.704

2024-04-23 19:01:34,626 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:01:34,627 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:01:34,679 - 

2024-04-23 19:01:34,680 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:01:49,124 - Epoch: [176][  100/  296]    Overall Loss 0.745626    Objective Loss 0.745626                                        LR 0.000020    Time 0.144226    
2024-04-23 19:02:01,898 - Epoch: [176][  200/  296]    Overall Loss 0.720302    Objective Loss 0.720302                                        LR 0.000020    Time 0.135884    
2024-04-23 19:02:12,981 - Epoch: [176][  296/  296]    Overall Loss 0.729326    Objective Loss 0.729326    Top1 81.967213    Top5 98.360656    LR 0.000020    Time 0.129193    
2024-04-23 19:02:13,170 - --- validate (epoch=176)-----------
2024-04-23 19:02:13,172 - 3925 samples (32 per mini-batch)
2024-04-23 19:02:29,687 - Epoch: [176][  100/  123]    Loss 0.706028    Top1 77.156250    Top5 97.218750    
2024-04-23 19:02:33,076 - Epoch: [176][  123/  123]    Loss 0.704020    Top1 77.197452    Top5 97.324841    
2024-04-23 19:02:33,260 - ==> Top1: 77.197    Top5: 97.325    Loss: 0.704

2024-04-23 19:02:33,270 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:02:33,271 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:02:33,321 - 

2024-04-23 19:02:33,322 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:02:47,663 - Epoch: [177][  100/  296]    Overall Loss 0.710799    Objective Loss 0.710799                                        LR 0.000020    Time 0.143190    
2024-04-23 19:03:02,226 - Epoch: [177][  200/  296]    Overall Loss 0.715298    Objective Loss 0.715298                                        LR 0.000020    Time 0.144304    
2024-04-23 19:03:16,188 - Epoch: [177][  296/  296]    Overall Loss 0.725852    Objective Loss 0.725852    Top1 77.049180    Top5 100.000000    LR 0.000020    Time 0.144601    
2024-04-23 19:03:16,485 - --- validate (epoch=177)-----------
2024-04-23 19:03:16,486 - 3925 samples (32 per mini-batch)
2024-04-23 19:03:33,831 - Epoch: [177][  100/  123]    Loss 0.707580    Top1 77.093750    Top5 97.375000    
2024-04-23 19:03:37,285 - Epoch: [177][  123/  123]    Loss 0.705959    Top1 77.299363    Top5 97.477707    
2024-04-23 19:03:37,543 - ==> Top1: 77.299    Top5: 97.478    Loss: 0.706

2024-04-23 19:03:37,552 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:03:37,553 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:03:37,609 - 

2024-04-23 19:03:37,610 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:03:53,972 - Epoch: [178][  100/  296]    Overall Loss 0.753778    Objective Loss 0.753778                                        LR 0.000020    Time 0.163405    
2024-04-23 19:04:07,728 - Epoch: [178][  200/  296]    Overall Loss 0.746325    Objective Loss 0.746325                                        LR 0.000020    Time 0.150377    
2024-04-23 19:04:21,419 - Epoch: [178][  296/  296]    Overall Loss 0.737088    Objective Loss 0.737088    Top1 80.327869    Top5 100.000000    LR 0.000020    Time 0.147795    
2024-04-23 19:04:21,743 - --- validate (epoch=178)-----------
2024-04-23 19:04:21,745 - 3925 samples (32 per mini-batch)
2024-04-23 19:04:38,790 - Epoch: [178][  100/  123]    Loss 0.688378    Top1 77.531250    Top5 97.406250    
2024-04-23 19:04:42,083 - Epoch: [178][  123/  123]    Loss 0.703054    Top1 77.426752    Top5 97.299363    
2024-04-23 19:04:42,342 - ==> Top1: 77.427    Top5: 97.299    Loss: 0.703

2024-04-23 19:04:42,353 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:04:42,354 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:04:42,406 - 

2024-04-23 19:04:42,407 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:04:55,624 - Epoch: [179][  100/  296]    Overall Loss 0.727794    Objective Loss 0.727794                                        LR 0.000020    Time 0.131940    
2024-04-23 19:05:08,669 - Epoch: [179][  200/  296]    Overall Loss 0.706975    Objective Loss 0.706975                                        LR 0.000020    Time 0.131087    
2024-04-23 19:05:23,734 - Epoch: [179][  296/  296]    Overall Loss 0.718996    Objective Loss 0.718996    Top1 78.688525    Top5 98.360656    LR 0.000020    Time 0.139401    
2024-04-23 19:05:24,115 - --- validate (epoch=179)-----------
2024-04-23 19:05:24,116 - 3925 samples (32 per mini-batch)
2024-04-23 19:05:39,210 - Epoch: [179][  100/  123]    Loss 0.688648    Top1 78.437500    Top5 97.406250    
2024-04-23 19:05:42,338 - Epoch: [179][  123/  123]    Loss 0.702899    Top1 78.063694    Top5 97.452229    
2024-04-23 19:05:42,641 - ==> Top1: 78.064    Top5: 97.452    Loss: 0.703

2024-04-23 19:05:42,652 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:05:42,653 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:05:42,698 - 

2024-04-23 19:05:42,699 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:05:54,823 - Epoch: [180][  100/  296]    Overall Loss 0.715124    Objective Loss 0.715124                                        LR 0.000020    Time 0.121029    
2024-04-23 19:06:03,921 - Epoch: [180][  200/  296]    Overall Loss 0.722582    Objective Loss 0.722582                                        LR 0.000020    Time 0.105903    
2024-04-23 19:06:13,169 - Epoch: [180][  296/  296]    Overall Loss 0.727356    Objective Loss 0.727356    Top1 83.606557    Top5 98.360656    LR 0.000020    Time 0.102738    
2024-04-23 19:06:13,498 - --- validate (epoch=180)-----------
2024-04-23 19:06:13,499 - 3925 samples (32 per mini-batch)
2024-04-23 19:06:27,756 - Epoch: [180][  100/  123]    Loss 0.699533    Top1 77.906250    Top5 97.312500    
2024-04-23 19:06:31,152 - Epoch: [180][  123/  123]    Loss 0.701511    Top1 77.630573    Top5 97.324841    
2024-04-23 19:06:31,385 - ==> Top1: 77.631    Top5: 97.325    Loss: 0.702

2024-04-23 19:06:31,399 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:06:31,399 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:06:31,464 - 

2024-04-23 19:06:31,466 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:06:46,728 - Epoch: [181][  100/  296]    Overall Loss 0.767979    Objective Loss 0.767979                                        LR 0.000020    Time 0.152398    
2024-04-23 19:07:00,393 - Epoch: [181][  200/  296]    Overall Loss 0.737366    Objective Loss 0.737366                                        LR 0.000020    Time 0.144419    
2024-04-23 19:07:13,227 - Epoch: [181][  296/  296]    Overall Loss 0.736134    Objective Loss 0.736134    Top1 68.852459    Top5 96.721311    LR 0.000020    Time 0.140869    
2024-04-23 19:07:13,562 - --- validate (epoch=181)-----------
2024-04-23 19:07:13,563 - 3925 samples (32 per mini-batch)
2024-04-23 19:07:30,856 - Epoch: [181][  100/  123]    Loss 0.701855    Top1 77.500000    Top5 97.500000    
2024-04-23 19:07:34,028 - Epoch: [181][  123/  123]    Loss 0.700413    Top1 77.656051    Top5 97.401274    
2024-04-23 19:07:34,226 - ==> Top1: 77.656    Top5: 97.401    Loss: 0.700

2024-04-23 19:07:34,235 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:07:34,235 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:07:34,282 - 

2024-04-23 19:07:34,282 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:07:45,629 - Epoch: [182][  100/  296]    Overall Loss 0.732681    Objective Loss 0.732681                                        LR 0.000020    Time 0.113264    
2024-04-23 19:07:56,438 - Epoch: [182][  200/  296]    Overall Loss 0.732215    Objective Loss 0.732215                                        LR 0.000020    Time 0.110585    
2024-04-23 19:08:09,692 - Epoch: [182][  296/  296]    Overall Loss 0.731505    Objective Loss 0.731505    Top1 75.409836    Top5 100.000000    LR 0.000020    Time 0.119437    
2024-04-23 19:08:09,943 - --- validate (epoch=182)-----------
2024-04-23 19:08:09,945 - 3925 samples (32 per mini-batch)
2024-04-23 19:08:27,749 - Epoch: [182][  100/  123]    Loss 0.700209    Top1 78.187500    Top5 97.375000    
2024-04-23 19:08:31,969 - Epoch: [182][  123/  123]    Loss 0.704992    Top1 77.656051    Top5 97.324841    
2024-04-23 19:08:32,292 - ==> Top1: 77.656    Top5: 97.325    Loss: 0.705

2024-04-23 19:08:32,303 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:08:32,304 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:08:32,376 - 

2024-04-23 19:08:32,376 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:08:49,014 - Epoch: [183][  100/  296]    Overall Loss 0.731080    Objective Loss 0.731080                                        LR 0.000020    Time 0.166138    
2024-04-23 19:09:03,314 - Epoch: [183][  200/  296]    Overall Loss 0.729083    Objective Loss 0.729083                                        LR 0.000020    Time 0.154469    
2024-04-23 19:09:17,342 - Epoch: [183][  296/  296]    Overall Loss 0.733767    Objective Loss 0.733767    Top1 81.967213    Top5 98.360656    LR 0.000020    Time 0.151701    
2024-04-23 19:09:17,625 - --- validate (epoch=183)-----------
2024-04-23 19:09:17,626 - 3925 samples (32 per mini-batch)
2024-04-23 19:09:36,526 - Epoch: [183][  100/  123]    Loss 0.695966    Top1 78.125000    Top5 97.375000    
2024-04-23 19:09:40,135 - Epoch: [183][  123/  123]    Loss 0.704623    Top1 77.656051    Top5 97.248408    
2024-04-23 19:09:40,462 - ==> Top1: 77.656    Top5: 97.248    Loss: 0.705

2024-04-23 19:09:40,474 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:09:40,475 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:09:40,525 - 

2024-04-23 19:09:40,526 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:09:56,758 - Epoch: [184][  100/  296]    Overall Loss 0.716775    Objective Loss 0.716775                                        LR 0.000020    Time 0.162106    
2024-04-23 19:10:11,635 - Epoch: [184][  200/  296]    Overall Loss 0.734602    Objective Loss 0.734602                                        LR 0.000020    Time 0.155338    
2024-04-23 19:10:26,406 - Epoch: [184][  296/  296]    Overall Loss 0.728797    Objective Loss 0.728797    Top1 68.852459    Top5 96.721311    LR 0.000020    Time 0.154797    
2024-04-23 19:10:26,732 - --- validate (epoch=184)-----------
2024-04-23 19:10:26,733 - 3925 samples (32 per mini-batch)
2024-04-23 19:10:43,350 - Epoch: [184][  100/  123]    Loss 0.707309    Top1 77.781250    Top5 97.000000    
2024-04-23 19:10:46,465 - Epoch: [184][  123/  123]    Loss 0.702017    Top1 77.834395    Top5 97.197452    
2024-04-23 19:10:46,745 - ==> Top1: 77.834    Top5: 97.197    Loss: 0.702

2024-04-23 19:10:46,758 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:10:46,759 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:10:46,852 - 

2024-04-23 19:10:46,853 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:11:00,639 - Epoch: [185][  100/  296]    Overall Loss 0.714462    Objective Loss 0.714462                                        LR 0.000020    Time 0.137632    
2024-04-23 19:11:13,553 - Epoch: [185][  200/  296]    Overall Loss 0.724393    Objective Loss 0.724393                                        LR 0.000020    Time 0.133277    
2024-04-23 19:11:25,129 - Epoch: [185][  296/  296]    Overall Loss 0.734639    Objective Loss 0.734639    Top1 68.852459    Top5 98.360656    LR 0.000020    Time 0.129097    
2024-04-23 19:11:25,347 - --- validate (epoch=185)-----------
2024-04-23 19:11:25,348 - 3925 samples (32 per mini-batch)
2024-04-23 19:11:42,205 - Epoch: [185][  100/  123]    Loss 0.711189    Top1 77.281250    Top5 97.468750    
2024-04-23 19:11:45,500 - Epoch: [185][  123/  123]    Loss 0.706410    Top1 77.656051    Top5 97.375796    
2024-04-23 19:11:45,722 - ==> Top1: 77.656    Top5: 97.376    Loss: 0.706

2024-04-23 19:11:45,731 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:11:45,732 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:11:45,787 - 

2024-04-23 19:11:45,788 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:12:02,653 - Epoch: [186][  100/  296]    Overall Loss 0.743049    Objective Loss 0.743049                                        LR 0.000020    Time 0.168440    
2024-04-23 19:12:15,931 - Epoch: [186][  200/  296]    Overall Loss 0.734648    Objective Loss 0.734648                                        LR 0.000020    Time 0.150512    
2024-04-23 19:12:30,512 - Epoch: [186][  296/  296]    Overall Loss 0.734603    Objective Loss 0.734603    Top1 80.327869    Top5 100.000000    LR 0.000020    Time 0.150890    
2024-04-23 19:12:30,788 - --- validate (epoch=186)-----------
2024-04-23 19:12:30,789 - 3925 samples (32 per mini-batch)
2024-04-23 19:12:49,523 - Epoch: [186][  100/  123]    Loss 0.711313    Top1 77.093750    Top5 97.281250    
2024-04-23 19:12:53,634 - Epoch: [186][  123/  123]    Loss 0.711210    Top1 77.324841    Top5 97.197452    
2024-04-23 19:12:53,882 - ==> Top1: 77.325    Top5: 97.197    Loss: 0.711

2024-04-23 19:12:53,890 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:12:53,891 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:12:53,961 - 

2024-04-23 19:12:53,962 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:13:05,788 - Epoch: [187][  100/  296]    Overall Loss 0.734733    Objective Loss 0.734733                                        LR 0.000020    Time 0.118051    
2024-04-23 19:13:17,449 - Epoch: [187][  200/  296]    Overall Loss 0.735997    Objective Loss 0.735997                                        LR 0.000020    Time 0.117230    
2024-04-23 19:13:28,242 - Epoch: [187][  296/  296]    Overall Loss 0.739021    Objective Loss 0.739021    Top1 80.327869    Top5 100.000000    LR 0.000020    Time 0.115605    
2024-04-23 19:13:28,546 - --- validate (epoch=187)-----------
2024-04-23 19:13:28,547 - 3925 samples (32 per mini-batch)
2024-04-23 19:13:41,050 - Epoch: [187][  100/  123]    Loss 0.690504    Top1 77.906250    Top5 97.406250    
2024-04-23 19:13:43,732 - Epoch: [187][  123/  123]    Loss 0.706332    Top1 77.350318    Top5 97.350318    
2024-04-23 19:13:44,025 - ==> Top1: 77.350    Top5: 97.350    Loss: 0.706

2024-04-23 19:13:44,034 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:13:44,035 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:13:44,096 - 

2024-04-23 19:13:44,096 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:13:57,583 - Epoch: [188][  100/  296]    Overall Loss 0.765244    Objective Loss 0.765244                                        LR 0.000020    Time 0.134639    
2024-04-23 19:14:10,699 - Epoch: [188][  200/  296]    Overall Loss 0.760369    Objective Loss 0.760369                                        LR 0.000020    Time 0.132804    
2024-04-23 19:14:21,809 - Epoch: [188][  296/  296]    Overall Loss 0.745775    Objective Loss 0.745775    Top1 72.131148    Top5 93.442623    LR 0.000020    Time 0.127197    
2024-04-23 19:14:22,055 - --- validate (epoch=188)-----------
2024-04-23 19:14:22,057 - 3925 samples (32 per mini-batch)
2024-04-23 19:14:39,076 - Epoch: [188][  100/  123]    Loss 0.701956    Top1 77.250000    Top5 97.343750    
2024-04-23 19:14:42,824 - Epoch: [188][  123/  123]    Loss 0.701084    Top1 77.554140    Top5 97.324841    
2024-04-23 19:14:43,183 - ==> Top1: 77.554    Top5: 97.325    Loss: 0.701

2024-04-23 19:14:43,196 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:14:43,197 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:14:43,248 - 

2024-04-23 19:14:43,249 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:14:59,983 - Epoch: [189][  100/  296]    Overall Loss 0.739835    Objective Loss 0.739835                                        LR 0.000020    Time 0.167116    
2024-04-23 19:15:14,147 - Epoch: [189][  200/  296]    Overall Loss 0.736813    Objective Loss 0.736813                                        LR 0.000020    Time 0.154273    
2024-04-23 19:15:27,823 - Epoch: [189][  296/  296]    Overall Loss 0.732494    Objective Loss 0.732494    Top1 78.688525    Top5 96.721311    LR 0.000020    Time 0.150377    
2024-04-23 19:15:28,132 - --- validate (epoch=189)-----------
2024-04-23 19:15:28,133 - 3925 samples (32 per mini-batch)
2024-04-23 19:15:42,461 - Epoch: [189][  100/  123]    Loss 0.710219    Top1 77.187500    Top5 97.250000    
2024-04-23 19:15:45,460 - Epoch: [189][  123/  123]    Loss 0.705564    Top1 77.299363    Top5 97.350318    
2024-04-23 19:15:45,795 - ==> Top1: 77.299    Top5: 97.350    Loss: 0.706

2024-04-23 19:15:45,801 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:15:45,802 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:15:45,852 - 

2024-04-23 19:15:45,853 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:15:59,231 - Epoch: [190][  100/  296]    Overall Loss 0.735109    Objective Loss 0.735109                                        LR 0.000020    Time 0.133557    
2024-04-23 19:16:11,002 - Epoch: [190][  200/  296]    Overall Loss 0.730783    Objective Loss 0.730783                                        LR 0.000020    Time 0.125535    
2024-04-23 19:16:19,519 - Epoch: [190][  296/  296]    Overall Loss 0.739206    Objective Loss 0.739206    Top1 63.934426    Top5 95.081967    LR 0.000020    Time 0.113532    
2024-04-23 19:16:19,852 - --- validate (epoch=190)-----------
2024-04-23 19:16:19,852 - 3925 samples (32 per mini-batch)
2024-04-23 19:16:34,487 - Epoch: [190][  100/  123]    Loss 0.703552    Top1 77.625000    Top5 97.406250    
2024-04-23 19:16:37,751 - Epoch: [190][  123/  123]    Loss 0.700016    Top1 77.528662    Top5 97.426752    
2024-04-23 19:16:38,100 - ==> Top1: 77.529    Top5: 97.427    Loss: 0.700

2024-04-23 19:16:38,107 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:16:38,107 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:16:38,147 - 

2024-04-23 19:16:38,148 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:16:51,820 - Epoch: [191][  100/  296]    Overall Loss 0.741905    Objective Loss 0.741905                                        LR 0.000020    Time 0.136503    
2024-04-23 19:17:01,703 - Epoch: [191][  200/  296]    Overall Loss 0.730704    Objective Loss 0.730704                                        LR 0.000020    Time 0.117564    
2024-04-23 19:17:11,634 - Epoch: [191][  296/  296]    Overall Loss 0.729925    Objective Loss 0.729925    Top1 83.606557    Top5 98.360656    LR 0.000020    Time 0.112924    
2024-04-23 19:17:11,907 - --- validate (epoch=191)-----------
2024-04-23 19:17:11,908 - 3925 samples (32 per mini-batch)
2024-04-23 19:17:26,815 - Epoch: [191][  100/  123]    Loss 0.702224    Top1 77.343750    Top5 97.218750    
2024-04-23 19:17:29,766 - Epoch: [191][  123/  123]    Loss 0.701776    Top1 77.732484    Top5 97.324841    
2024-04-23 19:17:29,986 - ==> Top1: 77.732    Top5: 97.325    Loss: 0.702

2024-04-23 19:17:29,996 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:17:29,996 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:17:30,048 - 

2024-04-23 19:17:30,048 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:17:41,628 - Epoch: [192][  100/  296]    Overall Loss 0.735791    Objective Loss 0.735791                                        LR 0.000020    Time 0.115597    
2024-04-23 19:17:53,907 - Epoch: [192][  200/  296]    Overall Loss 0.745667    Objective Loss 0.745667                                        LR 0.000020    Time 0.119094    
2024-04-23 19:18:06,154 - Epoch: [192][  296/  296]    Overall Loss 0.737529    Objective Loss 0.737529    Top1 75.409836    Top5 98.360656    LR 0.000020    Time 0.121781    
2024-04-23 19:18:06,467 - --- validate (epoch=192)-----------
2024-04-23 19:18:06,468 - 3925 samples (32 per mini-batch)
2024-04-23 19:18:20,317 - Epoch: [192][  100/  123]    Loss 0.700562    Top1 77.500000    Top5 97.343750    
2024-04-23 19:18:23,147 - Epoch: [192][  123/  123]    Loss 0.698886    Top1 77.375796    Top5 97.375796    
2024-04-23 19:18:23,441 - ==> Top1: 77.376    Top5: 97.376    Loss: 0.699

2024-04-23 19:18:23,448 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:18:23,449 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:18:23,497 - 

2024-04-23 19:18:23,498 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:18:36,840 - Epoch: [193][  100/  296]    Overall Loss 0.728089    Objective Loss 0.728089                                        LR 0.000020    Time 0.133205    
2024-04-23 19:18:49,097 - Epoch: [193][  200/  296]    Overall Loss 0.736861    Objective Loss 0.736861                                        LR 0.000020    Time 0.127782    
2024-04-23 19:18:59,456 - Epoch: [193][  296/  296]    Overall Loss 0.737393    Objective Loss 0.737393    Top1 78.688525    Top5 96.721311    LR 0.000020    Time 0.121269    
2024-04-23 19:18:59,743 - --- validate (epoch=193)-----------
2024-04-23 19:18:59,745 - 3925 samples (32 per mini-batch)
2024-04-23 19:19:15,344 - Epoch: [193][  100/  123]    Loss 0.684881    Top1 77.593750    Top5 97.281250    
2024-04-23 19:19:18,510 - Epoch: [193][  123/  123]    Loss 0.703235    Top1 77.197452    Top5 97.197452    
2024-04-23 19:19:18,766 - ==> Top1: 77.197    Top5: 97.197    Loss: 0.703

2024-04-23 19:19:18,774 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:19:18,775 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:19:18,844 - 

2024-04-23 19:19:18,846 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:19:35,118 - Epoch: [194][  100/  296]    Overall Loss 0.712260    Objective Loss 0.712260                                        LR 0.000020    Time 0.162479    
2024-04-23 19:19:47,674 - Epoch: [194][  200/  296]    Overall Loss 0.713661    Objective Loss 0.713661                                        LR 0.000020    Time 0.143922    
2024-04-23 19:19:54,471 - Epoch: [194][  296/  296]    Overall Loss 0.710410    Objective Loss 0.710410    Top1 80.327869    Top5 98.360656    LR 0.000020    Time 0.120149    
2024-04-23 19:19:54,749 - --- validate (epoch=194)-----------
2024-04-23 19:19:54,750 - 3925 samples (32 per mini-batch)
2024-04-23 19:20:05,862 - Epoch: [194][  100/  123]    Loss 0.698403    Top1 77.531250    Top5 97.343750    
2024-04-23 19:20:08,005 - Epoch: [194][  123/  123]    Loss 0.702535    Top1 77.401274    Top5 97.324841    
2024-04-23 19:20:08,243 - ==> Top1: 77.401    Top5: 97.325    Loss: 0.703

2024-04-23 19:20:08,249 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:20:08,249 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:20:08,283 - 

2024-04-23 19:20:08,283 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:20:23,589 - Epoch: [195][  100/  296]    Overall Loss 0.756572    Objective Loss 0.756572                                        LR 0.000020    Time 0.152837    
2024-04-23 19:20:34,962 - Epoch: [195][  200/  296]    Overall Loss 0.746154    Objective Loss 0.746154                                        LR 0.000020    Time 0.133178    
2024-04-23 19:20:45,161 - Epoch: [195][  296/  296]    Overall Loss 0.751164    Objective Loss 0.751164    Top1 70.491803    Top5 91.803279    LR 0.000020    Time 0.124379    
2024-04-23 19:20:45,389 - --- validate (epoch=195)-----------
2024-04-23 19:20:45,390 - 3925 samples (32 per mini-batch)
2024-04-23 19:20:57,420 - Epoch: [195][  100/  123]    Loss 0.703411    Top1 77.437500    Top5 97.343750    
2024-04-23 19:20:59,736 - Epoch: [195][  123/  123]    Loss 0.703079    Top1 77.350318    Top5 97.324841    
2024-04-23 19:20:59,974 - ==> Top1: 77.350    Top5: 97.325    Loss: 0.703

2024-04-23 19:20:59,983 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:20:59,983 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:21:00,023 - 

2024-04-23 19:21:00,023 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:21:11,153 - Epoch: [196][  100/  296]    Overall Loss 0.730465    Objective Loss 0.730465                                        LR 0.000020    Time 0.111117    
2024-04-23 19:21:20,553 - Epoch: [196][  200/  296]    Overall Loss 0.715624    Objective Loss 0.715624                                        LR 0.000020    Time 0.102461    
2024-04-23 19:21:29,641 - Epoch: [196][  296/  296]    Overall Loss 0.715482    Objective Loss 0.715482    Top1 85.245902    Top5 100.000000    LR 0.000020    Time 0.099871    
2024-04-23 19:21:29,920 - --- validate (epoch=196)-----------
2024-04-23 19:21:29,921 - 3925 samples (32 per mini-batch)
2024-04-23 19:21:43,553 - Epoch: [196][  100/  123]    Loss 0.688208    Top1 78.218750    Top5 97.375000    
2024-04-23 19:21:46,430 - Epoch: [196][  123/  123]    Loss 0.699814    Top1 77.554140    Top5 97.452229    
2024-04-23 19:21:46,762 - ==> Top1: 77.554    Top5: 97.452    Loss: 0.700

2024-04-23 19:21:46,777 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:21:46,777 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:21:46,837 - 

2024-04-23 19:21:46,837 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:21:59,613 - Epoch: [197][  100/  296]    Overall Loss 0.745446    Objective Loss 0.745446                                        LR 0.000020    Time 0.127533    
2024-04-23 19:22:11,487 - Epoch: [197][  200/  296]    Overall Loss 0.738138    Objective Loss 0.738138                                        LR 0.000020    Time 0.123033    
2024-04-23 19:22:22,238 - Epoch: [197][  296/  296]    Overall Loss 0.730482    Objective Loss 0.730482    Top1 86.885246    Top5 96.721311    LR 0.000020    Time 0.119392    
2024-04-23 19:22:22,449 - --- validate (epoch=197)-----------
2024-04-23 19:22:22,450 - 3925 samples (32 per mini-batch)
2024-04-23 19:22:37,741 - Epoch: [197][  100/  123]    Loss 0.710728    Top1 76.687500    Top5 97.375000    
2024-04-23 19:22:40,921 - Epoch: [197][  123/  123]    Loss 0.701416    Top1 77.375796    Top5 97.350318    
2024-04-23 19:22:41,243 - ==> Top1: 77.376    Top5: 97.350    Loss: 0.701

2024-04-23 19:22:41,250 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:22:41,251 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:22:41,295 - 

2024-04-23 19:22:41,296 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:22:57,688 - Epoch: [198][  100/  296]    Overall Loss 0.731254    Objective Loss 0.731254                                        LR 0.000020    Time 0.163726    
2024-04-23 19:23:12,557 - Epoch: [198][  200/  296]    Overall Loss 0.740484    Objective Loss 0.740484                                        LR 0.000020    Time 0.156099    
2024-04-23 19:23:26,721 - Epoch: [198][  296/  296]    Overall Loss 0.735183    Objective Loss 0.735183    Top1 78.688525    Top5 93.442623    LR 0.000020    Time 0.153270    
2024-04-23 19:23:27,047 - --- validate (epoch=198)-----------
2024-04-23 19:23:27,048 - 3925 samples (32 per mini-batch)
2024-04-23 19:23:43,641 - Epoch: [198][  100/  123]    Loss 0.704668    Top1 77.187500    Top5 97.562500    
2024-04-23 19:23:47,020 - Epoch: [198][  123/  123]    Loss 0.707277    Top1 77.248408    Top5 97.426752    
2024-04-23 19:23:47,238 - ==> Top1: 77.248    Top5: 97.427    Loss: 0.707

2024-04-23 19:23:47,250 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:23:47,251 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:23:47,310 - 

2024-04-23 19:23:47,311 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:24:03,626 - Epoch: [199][  100/  296]    Overall Loss 0.739849    Objective Loss 0.739849                                        LR 0.000020    Time 0.162924    
2024-04-23 19:24:19,254 - Epoch: [199][  200/  296]    Overall Loss 0.737384    Objective Loss 0.737384                                        LR 0.000020    Time 0.159507    
2024-04-23 19:24:30,358 - Epoch: [199][  296/  296]    Overall Loss 0.736802    Objective Loss 0.736802    Top1 75.409836    Top5 100.000000    LR 0.000020    Time 0.145225    
2024-04-23 19:24:30,649 - --- validate (epoch=199)-----------
2024-04-23 19:24:30,650 - 3925 samples (32 per mini-batch)
2024-04-23 19:24:43,462 - Epoch: [199][  100/  123]    Loss 0.702661    Top1 77.281250    Top5 97.250000    
2024-04-23 19:24:46,328 - Epoch: [199][  123/  123]    Loss 0.700948    Top1 77.401274    Top5 97.299363    
2024-04-23 19:24:46,662 - ==> Top1: 77.401    Top5: 97.299    Loss: 0.701

2024-04-23 19:24:46,674 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:24:46,674 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:24:46,722 - 

2024-04-23 19:24:46,723 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:24:59,160 - Epoch: [200][  100/  296]    Overall Loss 0.723406    Objective Loss 0.723406                                        LR 0.000005    Time 0.124161    
2024-04-23 19:25:08,036 - Epoch: [200][  200/  296]    Overall Loss 0.727100    Objective Loss 0.727100                                        LR 0.000005    Time 0.106370    
2024-04-23 19:25:20,767 - Epoch: [200][  296/  296]    Overall Loss 0.728858    Objective Loss 0.728858    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.114812    
2024-04-23 19:25:21,101 - --- validate (epoch=200)-----------
2024-04-23 19:25:21,102 - 3925 samples (32 per mini-batch)
2024-04-23 19:25:37,237 - Epoch: [200][  100/  123]    Loss 0.690489    Top1 77.593750    Top5 97.531250    
2024-04-23 19:25:40,774 - Epoch: [200][  123/  123]    Loss 0.703288    Top1 77.375796    Top5 97.401274    
2024-04-23 19:25:41,129 - ==> Top1: 77.376    Top5: 97.401    Loss: 0.703

2024-04-23 19:25:41,140 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:25:41,141 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:25:41,194 - 

2024-04-23 19:25:41,195 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:25:54,615 - Epoch: [201][  100/  296]    Overall Loss 0.707341    Objective Loss 0.707341                                        LR 0.000005    Time 0.133977    
2024-04-23 19:26:04,622 - Epoch: [201][  200/  296]    Overall Loss 0.710604    Objective Loss 0.710604                                        LR 0.000005    Time 0.116918    
2024-04-23 19:26:13,895 - Epoch: [201][  296/  296]    Overall Loss 0.719804    Objective Loss 0.719804    Top1 73.770492    Top5 93.442623    LR 0.000005    Time 0.110267    
2024-04-23 19:26:14,180 - --- validate (epoch=201)-----------
2024-04-23 19:26:14,181 - 3925 samples (32 per mini-batch)
2024-04-23 19:26:28,087 - Epoch: [201][  100/  123]    Loss 0.700733    Top1 77.343750    Top5 97.437500    
2024-04-23 19:26:30,690 - Epoch: [201][  123/  123]    Loss 0.700576    Top1 77.656051    Top5 97.452229    
2024-04-23 19:26:30,989 - ==> Top1: 77.656    Top5: 97.452    Loss: 0.701

2024-04-23 19:26:30,998 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:26:30,998 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:26:31,042 - 

2024-04-23 19:26:31,043 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:26:44,629 - Epoch: [202][  100/  296]    Overall Loss 0.719558    Objective Loss 0.719558                                        LR 0.000005    Time 0.135671    
2024-04-23 19:26:58,386 - Epoch: [202][  200/  296]    Overall Loss 0.705639    Objective Loss 0.705639                                        LR 0.000005    Time 0.136519    
2024-04-23 19:27:12,096 - Epoch: [202][  296/  296]    Overall Loss 0.726673    Objective Loss 0.726673    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.138496    
2024-04-23 19:27:12,419 - --- validate (epoch=202)-----------
2024-04-23 19:27:12,421 - 3925 samples (32 per mini-batch)
2024-04-23 19:27:29,495 - Epoch: [202][  100/  123]    Loss 0.704750    Top1 77.562500    Top5 97.312500    
2024-04-23 19:27:30,988 - Epoch: [202][  123/  123]    Loss 0.699953    Top1 77.605096    Top5 97.375796    
2024-04-23 19:27:31,341 - ==> Top1: 77.605    Top5: 97.376    Loss: 0.700

2024-04-23 19:27:31,353 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:27:31,354 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:27:31,405 - 

2024-04-23 19:27:31,406 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:27:47,861 - Epoch: [203][  100/  296]    Overall Loss 0.740864    Objective Loss 0.740864                                        LR 0.000005    Time 0.164338    
2024-04-23 19:28:03,797 - Epoch: [203][  200/  296]    Overall Loss 0.740606    Objective Loss 0.740606                                        LR 0.000005    Time 0.161745    
2024-04-23 19:28:17,273 - Epoch: [203][  296/  296]    Overall Loss 0.741478    Objective Loss 0.741478    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.154747    
2024-04-23 19:28:17,573 - --- validate (epoch=203)-----------
2024-04-23 19:28:17,575 - 3925 samples (32 per mini-batch)
2024-04-23 19:28:37,178 - Epoch: [203][  100/  123]    Loss 0.702999    Top1 77.750000    Top5 97.312500    
2024-04-23 19:28:40,907 - Epoch: [203][  123/  123]    Loss 0.700195    Top1 77.910828    Top5 97.324841    
2024-04-23 19:28:41,218 - ==> Top1: 77.911    Top5: 97.325    Loss: 0.700

2024-04-23 19:28:41,226 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:28:41,227 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:28:41,283 - 

2024-04-23 19:28:41,285 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:28:59,026 - Epoch: [204][  100/  296]    Overall Loss 0.725058    Objective Loss 0.725058                                        LR 0.000005    Time 0.177210    
2024-04-23 19:29:14,301 - Epoch: [204][  200/  296]    Overall Loss 0.722600    Objective Loss 0.722600                                        LR 0.000005    Time 0.164882    
2024-04-23 19:29:27,792 - Epoch: [204][  296/  296]    Overall Loss 0.733357    Objective Loss 0.733357    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.156917    
2024-04-23 19:29:28,067 - --- validate (epoch=204)-----------
2024-04-23 19:29:28,069 - 3925 samples (32 per mini-batch)
2024-04-23 19:29:44,602 - Epoch: [204][  100/  123]    Loss 0.695283    Top1 77.656250    Top5 97.406250    
2024-04-23 19:29:47,609 - Epoch: [204][  123/  123]    Loss 0.698808    Top1 77.681529    Top5 97.324841    
2024-04-23 19:29:47,832 - ==> Top1: 77.682    Top5: 97.325    Loss: 0.699

2024-04-23 19:29:47,840 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:29:47,840 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:29:47,879 - 

2024-04-23 19:29:47,880 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:29:59,965 - Epoch: [205][  100/  296]    Overall Loss 0.736017    Objective Loss 0.736017                                        LR 0.000005    Time 0.120663    
2024-04-23 19:30:12,318 - Epoch: [205][  200/  296]    Overall Loss 0.744223    Objective Loss 0.744223                                        LR 0.000005    Time 0.121999    
2024-04-23 19:30:25,429 - Epoch: [205][  296/  296]    Overall Loss 0.733932    Objective Loss 0.733932    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.126662    
2024-04-23 19:30:25,842 - --- validate (epoch=205)-----------
2024-04-23 19:30:25,843 - 3925 samples (32 per mini-batch)
2024-04-23 19:30:44,570 - Epoch: [205][  100/  123]    Loss 0.701371    Top1 77.437500    Top5 97.250000    
2024-04-23 19:30:47,884 - Epoch: [205][  123/  123]    Loss 0.700471    Top1 77.579618    Top5 97.350318    
2024-04-23 19:30:48,112 - ==> Top1: 77.580    Top5: 97.350    Loss: 0.700

2024-04-23 19:30:48,124 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:30:48,125 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:30:48,186 - 

2024-04-23 19:30:48,187 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:31:04,047 - Epoch: [206][  100/  296]    Overall Loss 0.706776    Objective Loss 0.706776                                        LR 0.000005    Time 0.158384    
2024-04-23 19:31:16,232 - Epoch: [206][  200/  296]    Overall Loss 0.714189    Objective Loss 0.714189                                        LR 0.000005    Time 0.140021    
2024-04-23 19:31:31,157 - Epoch: [206][  296/  296]    Overall Loss 0.721676    Objective Loss 0.721676    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.144960    
2024-04-23 19:31:31,453 - --- validate (epoch=206)-----------
2024-04-23 19:31:31,454 - 3925 samples (32 per mini-batch)
2024-04-23 19:31:46,065 - Epoch: [206][  100/  123]    Loss 0.702232    Top1 77.750000    Top5 97.093750    
2024-04-23 19:31:48,239 - Epoch: [206][  123/  123]    Loss 0.699547    Top1 77.732484    Top5 97.273885    
2024-04-23 19:31:48,535 - ==> Top1: 77.732    Top5: 97.274    Loss: 0.700

2024-04-23 19:31:48,545 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:31:48,545 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:31:48,588 - 

2024-04-23 19:31:48,589 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:32:03,542 - Epoch: [207][  100/  296]    Overall Loss 0.701045    Objective Loss 0.701045                                        LR 0.000005    Time 0.149316    
2024-04-23 19:32:16,836 - Epoch: [207][  200/  296]    Overall Loss 0.732155    Objective Loss 0.732155                                        LR 0.000005    Time 0.141028    
2024-04-23 19:32:28,947 - Epoch: [207][  296/  296]    Overall Loss 0.735134    Objective Loss 0.735134    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.136138    
2024-04-23 19:32:29,235 - --- validate (epoch=207)-----------
2024-04-23 19:32:29,236 - 3925 samples (32 per mini-batch)
2024-04-23 19:32:43,214 - Epoch: [207][  100/  123]    Loss 0.687665    Top1 77.781250    Top5 97.437500    
2024-04-23 19:32:45,959 - Epoch: [207][  123/  123]    Loss 0.699534    Top1 77.401274    Top5 97.248408    
2024-04-23 19:32:46,211 - ==> Top1: 77.401    Top5: 97.248    Loss: 0.700

2024-04-23 19:32:46,220 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:32:46,221 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:32:46,265 - 

2024-04-23 19:32:46,266 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:33:01,716 - Epoch: [208][  100/  296]    Overall Loss 0.732682    Objective Loss 0.732682                                        LR 0.000005    Time 0.154294    
2024-04-23 19:33:15,370 - Epoch: [208][  200/  296]    Overall Loss 0.728001    Objective Loss 0.728001                                        LR 0.000005    Time 0.145304    
2024-04-23 19:33:28,481 - Epoch: [208][  296/  296]    Overall Loss 0.721963    Objective Loss 0.721963    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.142409    
2024-04-23 19:33:28,776 - --- validate (epoch=208)-----------
2024-04-23 19:33:28,777 - 3925 samples (32 per mini-batch)
2024-04-23 19:33:44,708 - Epoch: [208][  100/  123]    Loss 0.699689    Top1 77.375000    Top5 97.156250    
2024-04-23 19:33:47,414 - Epoch: [208][  123/  123]    Loss 0.700300    Top1 77.528662    Top5 97.248408    
2024-04-23 19:33:47,646 - ==> Top1: 77.529    Top5: 97.248    Loss: 0.700

2024-04-23 19:33:47,655 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:33:47,655 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:33:47,707 - 

2024-04-23 19:33:47,708 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:34:02,424 - Epoch: [209][  100/  296]    Overall Loss 0.717184    Objective Loss 0.717184                                        LR 0.000005    Time 0.146940    
2024-04-23 19:34:15,183 - Epoch: [209][  200/  296]    Overall Loss 0.710095    Objective Loss 0.710095                                        LR 0.000005    Time 0.137161    
2024-04-23 19:34:26,322 - Epoch: [209][  296/  296]    Overall Loss 0.720731    Objective Loss 0.720731    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.130242    
2024-04-23 19:34:26,579 - --- validate (epoch=209)-----------
2024-04-23 19:34:26,579 - 3925 samples (32 per mini-batch)
2024-04-23 19:34:40,868 - Epoch: [209][  100/  123]    Loss 0.701651    Top1 77.687500    Top5 97.375000    
2024-04-23 19:34:43,407 - Epoch: [209][  123/  123]    Loss 0.697346    Top1 77.528662    Top5 97.426752    
2024-04-23 19:34:43,755 - ==> Top1: 77.529    Top5: 97.427    Loss: 0.697

2024-04-23 19:34:43,766 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:34:43,767 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:34:43,807 - 

2024-04-23 19:34:43,808 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:34:56,824 - Epoch: [210][  100/  296]    Overall Loss 0.741351    Objective Loss 0.741351                                        LR 0.000005    Time 0.129948    
2024-04-23 19:35:11,387 - Epoch: [210][  200/  296]    Overall Loss 0.738538    Objective Loss 0.738538                                        LR 0.000005    Time 0.137690    
2024-04-23 19:35:24,748 - Epoch: [210][  296/  296]    Overall Loss 0.721916    Objective Loss 0.721916    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.138115    
2024-04-23 19:35:25,090 - --- validate (epoch=210)-----------
2024-04-23 19:35:25,091 - 3925 samples (32 per mini-batch)
2024-04-23 19:35:38,370 - Epoch: [210][  100/  123]    Loss 0.713819    Top1 77.062500    Top5 97.312500    
2024-04-23 19:35:41,215 - Epoch: [210][  123/  123]    Loss 0.699906    Top1 77.656051    Top5 97.222930    
2024-04-23 19:35:41,478 - ==> Top1: 77.656    Top5: 97.223    Loss: 0.700

2024-04-23 19:35:41,485 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:35:41,485 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:35:41,517 - 

2024-04-23 19:35:41,518 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:35:55,600 - Epoch: [211][  100/  296]    Overall Loss 0.722061    Objective Loss 0.722061                                        LR 0.000005    Time 0.140588    
2024-04-23 19:36:05,789 - Epoch: [211][  200/  296]    Overall Loss 0.735655    Objective Loss 0.735655                                        LR 0.000005    Time 0.121143    
2024-04-23 19:36:16,885 - Epoch: [211][  296/  296]    Overall Loss 0.728220    Objective Loss 0.728220    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.119275    
2024-04-23 19:36:17,221 - --- validate (epoch=211)-----------
2024-04-23 19:36:17,222 - 3925 samples (32 per mini-batch)
2024-04-23 19:36:31,860 - Epoch: [211][  100/  123]    Loss 0.702196    Top1 77.875000    Top5 97.281250    
2024-04-23 19:36:34,914 - Epoch: [211][  123/  123]    Loss 0.697754    Top1 77.859873    Top5 97.350318    
2024-04-23 19:36:35,133 - ==> Top1: 77.860    Top5: 97.350    Loss: 0.698

2024-04-23 19:36:35,141 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:36:35,141 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:36:35,174 - 

2024-04-23 19:36:35,174 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:36:47,965 - Epoch: [212][  100/  296]    Overall Loss 0.725594    Objective Loss 0.725594                                        LR 0.000005    Time 0.127709    
2024-04-23 19:36:55,990 - Epoch: [212][  200/  296]    Overall Loss 0.712909    Objective Loss 0.712909                                        LR 0.000005    Time 0.103878    
2024-04-23 19:37:05,785 - Epoch: [212][  296/  296]    Overall Loss 0.718304    Objective Loss 0.718304    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.103212    
2024-04-23 19:37:06,083 - --- validate (epoch=212)-----------
2024-04-23 19:37:06,084 - 3925 samples (32 per mini-batch)
2024-04-23 19:37:22,082 - Epoch: [212][  100/  123]    Loss 0.698884    Top1 77.906250    Top5 97.500000    
2024-04-23 19:37:25,945 - Epoch: [212][  123/  123]    Loss 0.698982    Top1 77.757962    Top5 97.350318    
2024-04-23 19:37:26,322 - ==> Top1: 77.758    Top5: 97.350    Loss: 0.699

2024-04-23 19:37:26,333 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:37:26,334 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:37:26,388 - 

2024-04-23 19:37:26,389 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:37:40,445 - Epoch: [213][  100/  296]    Overall Loss 0.734541    Objective Loss 0.734541                                        LR 0.000005    Time 0.140344    
2024-04-23 19:37:53,873 - Epoch: [213][  200/  296]    Overall Loss 0.740530    Objective Loss 0.740530                                        LR 0.000005    Time 0.137211    
2024-04-23 19:38:05,481 - Epoch: [213][  296/  296]    Overall Loss 0.735536    Objective Loss 0.735536    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.131860    
2024-04-23 19:38:05,730 - --- validate (epoch=213)-----------
2024-04-23 19:38:05,731 - 3925 samples (32 per mini-batch)
2024-04-23 19:38:23,129 - Epoch: [213][  100/  123]    Loss 0.685740    Top1 78.062500    Top5 97.406250    
2024-04-23 19:38:26,783 - Epoch: [213][  123/  123]    Loss 0.698501    Top1 77.503185    Top5 97.324841    
2024-04-23 19:38:27,086 - ==> Top1: 77.503    Top5: 97.325    Loss: 0.699

2024-04-23 19:38:27,102 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:38:27,103 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:38:27,186 - 

2024-04-23 19:38:27,188 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:38:44,148 - Epoch: [214][  100/  296]    Overall Loss 0.729664    Objective Loss 0.729664                                        LR 0.000005    Time 0.169360    
2024-04-23 19:38:55,003 - Epoch: [214][  200/  296]    Overall Loss 0.713738    Objective Loss 0.713738                                        LR 0.000005    Time 0.138849    
2024-04-23 19:39:05,515 - Epoch: [214][  296/  296]    Overall Loss 0.718279    Objective Loss 0.718279    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.129261    
2024-04-23 19:39:05,828 - --- validate (epoch=214)-----------
2024-04-23 19:39:05,830 - 3925 samples (32 per mini-batch)
2024-04-23 19:39:18,160 - Epoch: [214][  100/  123]    Loss 0.699070    Top1 77.468750    Top5 97.562500    
2024-04-23 19:39:21,253 - Epoch: [214][  123/  123]    Loss 0.698158    Top1 77.630573    Top5 97.324841    
2024-04-23 19:39:21,529 - ==> Top1: 77.631    Top5: 97.325    Loss: 0.698

2024-04-23 19:39:21,540 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:39:21,541 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:39:21,593 - 

2024-04-23 19:39:21,594 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:39:34,514 - Epoch: [215][  100/  296]    Overall Loss 0.742606    Objective Loss 0.742606                                        LR 0.000005    Time 0.128962    
2024-04-23 19:39:46,716 - Epoch: [215][  200/  296]    Overall Loss 0.739486    Objective Loss 0.739486                                        LR 0.000005    Time 0.125389    
2024-04-23 19:39:56,031 - Epoch: [215][  296/  296]    Overall Loss 0.731051    Objective Loss 0.731051    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.116120    
2024-04-23 19:39:56,322 - --- validate (epoch=215)-----------
2024-04-23 19:39:56,323 - 3925 samples (32 per mini-batch)
2024-04-23 19:40:10,132 - Epoch: [215][  100/  123]    Loss 0.709828    Top1 77.250000    Top5 97.281250    
2024-04-23 19:40:12,576 - Epoch: [215][  123/  123]    Loss 0.702192    Top1 77.605096    Top5 97.299363    
2024-04-23 19:40:12,908 - ==> Top1: 77.605    Top5: 97.299    Loss: 0.702

2024-04-23 19:40:12,918 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:40:12,918 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:40:12,965 - 

2024-04-23 19:40:12,966 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:40:25,650 - Epoch: [216][  100/  296]    Overall Loss 0.709820    Objective Loss 0.709820                                        LR 0.000005    Time 0.126622    
2024-04-23 19:40:37,144 - Epoch: [216][  200/  296]    Overall Loss 0.715485    Objective Loss 0.715485                                        LR 0.000005    Time 0.120677    
2024-04-23 19:40:46,917 - Epoch: [216][  296/  296]    Overall Loss 0.719785    Objective Loss 0.719785    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.114484    
2024-04-23 19:40:47,180 - --- validate (epoch=216)-----------
2024-04-23 19:40:47,181 - 3925 samples (32 per mini-batch)
2024-04-23 19:41:01,104 - Epoch: [216][  100/  123]    Loss 0.710880    Top1 77.593750    Top5 97.000000    
2024-04-23 19:41:04,201 - Epoch: [216][  123/  123]    Loss 0.701747    Top1 77.859873    Top5 97.222930    
2024-04-23 19:41:04,534 - ==> Top1: 77.860    Top5: 97.223    Loss: 0.702

2024-04-23 19:41:04,544 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:41:04,545 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:41:04,594 - 

2024-04-23 19:41:04,594 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:41:15,011 - Epoch: [217][  100/  296]    Overall Loss 0.715544    Objective Loss 0.715544                                        LR 0.000005    Time 0.103952    
2024-04-23 19:41:28,313 - Epoch: [217][  200/  296]    Overall Loss 0.717499    Objective Loss 0.717499                                        LR 0.000005    Time 0.118382    
2024-04-23 19:41:42,485 - Epoch: [217][  296/  296]    Overall Loss 0.721806    Objective Loss 0.721806    Top1 67.213115    Top5 90.163934    LR 0.000005    Time 0.127797    
2024-04-23 19:41:42,806 - --- validate (epoch=217)-----------
2024-04-23 19:41:42,807 - 3925 samples (32 per mini-batch)
2024-04-23 19:41:57,627 - Epoch: [217][  100/  123]    Loss 0.698036    Top1 77.687500    Top5 97.343750    
2024-04-23 19:42:00,786 - Epoch: [217][  123/  123]    Loss 0.694428    Top1 77.579618    Top5 97.350318    
2024-04-23 19:42:01,102 - ==> Top1: 77.580    Top5: 97.350    Loss: 0.694

2024-04-23 19:42:01,108 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:42:01,109 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:42:01,154 - 

2024-04-23 19:42:01,154 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:42:17,148 - Epoch: [218][  100/  296]    Overall Loss 0.723625    Objective Loss 0.723625                                        LR 0.000005    Time 0.159705    
2024-04-23 19:42:31,717 - Epoch: [218][  200/  296]    Overall Loss 0.718079    Objective Loss 0.718079                                        LR 0.000005    Time 0.152594    
2024-04-23 19:42:44,951 - Epoch: [218][  296/  296]    Overall Loss 0.712422    Objective Loss 0.712422    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.147750    
2024-04-23 19:42:45,223 - --- validate (epoch=218)-----------
2024-04-23 19:42:45,224 - 3925 samples (32 per mini-batch)
2024-04-23 19:43:02,385 - Epoch: [218][  100/  123]    Loss 0.700180    Top1 77.656250    Top5 97.125000    
2024-04-23 19:43:05,104 - Epoch: [218][  123/  123]    Loss 0.698418    Top1 77.808917    Top5 97.273885    
2024-04-23 19:43:05,329 - ==> Top1: 77.809    Top5: 97.274    Loss: 0.698

2024-04-23 19:43:05,338 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:43:05,339 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:43:05,375 - 

2024-04-23 19:43:05,375 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:43:15,047 - Epoch: [219][  100/  296]    Overall Loss 0.781283    Objective Loss 0.781283                                        LR 0.000005    Time 0.096539    
2024-04-23 19:43:22,743 - Epoch: [219][  200/  296]    Overall Loss 0.750019    Objective Loss 0.750019                                        LR 0.000005    Time 0.086674    
2024-04-23 19:43:32,400 - Epoch: [219][  296/  296]    Overall Loss 0.749987    Objective Loss 0.749987    Top1 70.491803    Top5 93.442623    LR 0.000005    Time 0.091128    
2024-04-23 19:43:32,652 - --- validate (epoch=219)-----------
2024-04-23 19:43:32,653 - 3925 samples (32 per mini-batch)
2024-04-23 19:43:48,655 - Epoch: [219][  100/  123]    Loss 0.696172    Top1 77.875000    Top5 97.531250    
2024-04-23 19:43:52,122 - Epoch: [219][  123/  123]    Loss 0.699749    Top1 77.732484    Top5 97.401274    
2024-04-23 19:43:52,386 - ==> Top1: 77.732    Top5: 97.401    Loss: 0.700

2024-04-23 19:43:52,398 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:43:52,399 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:43:52,452 - 

2024-04-23 19:43:52,453 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:44:06,578 - Epoch: [220][  100/  296]    Overall Loss 0.744462    Objective Loss 0.744462                                        LR 0.000005    Time 0.141050    
2024-04-23 19:44:18,923 - Epoch: [220][  200/  296]    Overall Loss 0.728702    Objective Loss 0.728702                                        LR 0.000005    Time 0.132146    
2024-04-23 19:44:29,260 - Epoch: [220][  296/  296]    Overall Loss 0.727999    Objective Loss 0.727999    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.124146    
2024-04-23 19:44:29,523 - --- validate (epoch=220)-----------
2024-04-23 19:44:29,524 - 3925 samples (32 per mini-batch)
2024-04-23 19:44:46,056 - Epoch: [220][  100/  123]    Loss 0.698670    Top1 77.656250    Top5 97.375000    
2024-04-23 19:44:48,949 - Epoch: [220][  123/  123]    Loss 0.700740    Top1 77.452229    Top5 97.324841    
2024-04-23 19:44:49,228 - ==> Top1: 77.452    Top5: 97.325    Loss: 0.701

2024-04-23 19:44:49,239 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:44:49,240 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:44:49,292 - 

2024-04-23 19:44:49,293 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:45:02,750 - Epoch: [221][  100/  296]    Overall Loss 0.725029    Objective Loss 0.725029                                        LR 0.000005    Time 0.134362    
2024-04-23 19:45:13,304 - Epoch: [221][  200/  296]    Overall Loss 0.738011    Objective Loss 0.738011                                        LR 0.000005    Time 0.119860    
2024-04-23 19:45:21,472 - Epoch: [221][  296/  296]    Overall Loss 0.735596    Objective Loss 0.735596    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.108525    
2024-04-23 19:45:21,808 - --- validate (epoch=221)-----------
2024-04-23 19:45:21,809 - 3925 samples (32 per mini-batch)
2024-04-23 19:45:35,539 - Epoch: [221][  100/  123]    Loss 0.702807    Top1 78.156250    Top5 97.343750    
2024-04-23 19:45:39,402 - Epoch: [221][  123/  123]    Loss 0.698501    Top1 77.707006    Top5 97.401274    
2024-04-23 19:45:39,633 - ==> Top1: 77.707    Top5: 97.401    Loss: 0.699

2024-04-23 19:45:39,644 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:45:39,645 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:45:39,693 - 

2024-04-23 19:45:39,693 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:45:53,512 - Epoch: [222][  100/  296]    Overall Loss 0.730121    Objective Loss 0.730121                                        LR 0.000005    Time 0.137977    
2024-04-23 19:46:04,551 - Epoch: [222][  200/  296]    Overall Loss 0.702978    Objective Loss 0.702978                                        LR 0.000005    Time 0.124088    
2024-04-23 19:46:14,675 - Epoch: [222][  296/  296]    Overall Loss 0.708089    Objective Loss 0.708089    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.117983    
2024-04-23 19:46:14,910 - --- validate (epoch=222)-----------
2024-04-23 19:46:14,911 - 3925 samples (32 per mini-batch)
2024-04-23 19:46:28,773 - Epoch: [222][  100/  123]    Loss 0.694579    Top1 77.906250    Top5 97.343750    
2024-04-23 19:46:31,519 - Epoch: [222][  123/  123]    Loss 0.700141    Top1 77.732484    Top5 97.273885    
2024-04-23 19:46:31,814 - ==> Top1: 77.732    Top5: 97.274    Loss: 0.700

2024-04-23 19:46:31,824 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:46:31,825 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:46:31,875 - 

2024-04-23 19:46:31,875 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:46:43,661 - Epoch: [223][  100/  296]    Overall Loss 0.688857    Objective Loss 0.688857                                        LR 0.000005    Time 0.117637    
2024-04-23 19:46:51,600 - Epoch: [223][  200/  296]    Overall Loss 0.715130    Objective Loss 0.715130                                        LR 0.000005    Time 0.098426    
2024-04-23 19:47:02,976 - Epoch: [223][  296/  296]    Overall Loss 0.719790    Objective Loss 0.719790    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.104868    
2024-04-23 19:47:03,226 - --- validate (epoch=223)-----------
2024-04-23 19:47:03,227 - 3925 samples (32 per mini-batch)
2024-04-23 19:47:18,966 - Epoch: [223][  100/  123]    Loss 0.696669    Top1 77.500000    Top5 97.343750    
2024-04-23 19:47:21,380 - Epoch: [223][  123/  123]    Loss 0.700678    Top1 77.452229    Top5 97.324841    
2024-04-23 19:47:21,630 - ==> Top1: 77.452    Top5: 97.325    Loss: 0.701

2024-04-23 19:47:21,635 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:47:21,635 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:47:21,670 - 

2024-04-23 19:47:21,671 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:47:32,060 - Epoch: [224][  100/  296]    Overall Loss 0.709111    Objective Loss 0.709111                                        LR 0.000005    Time 0.103680    
2024-04-23 19:47:41,248 - Epoch: [224][  200/  296]    Overall Loss 0.722143    Objective Loss 0.722143                                        LR 0.000005    Time 0.097689    
2024-04-23 19:47:50,327 - Epoch: [224][  296/  296]    Overall Loss 0.722630    Objective Loss 0.722630    Top1 72.131148    Top5 100.000000    LR 0.000005    Time 0.096620    
2024-04-23 19:47:50,583 - --- validate (epoch=224)-----------
2024-04-23 19:47:50,585 - 3925 samples (32 per mini-batch)
2024-04-23 19:48:03,763 - Epoch: [224][  100/  123]    Loss 0.685753    Top1 78.406250    Top5 97.375000    
2024-04-23 19:48:06,196 - Epoch: [224][  123/  123]    Loss 0.698167    Top1 77.834395    Top5 97.375796    
2024-04-23 19:48:06,448 - ==> Top1: 77.834    Top5: 97.376    Loss: 0.698

2024-04-23 19:48:06,457 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:48:06,458 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:48:06,503 - 

2024-04-23 19:48:06,504 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:48:16,836 - Epoch: [225][  100/  296]    Overall Loss 0.724895    Objective Loss 0.724895                                        LR 0.000005    Time 0.103128    
2024-04-23 19:48:27,071 - Epoch: [225][  200/  296]    Overall Loss 0.737003    Objective Loss 0.737003                                        LR 0.000005    Time 0.102638    
2024-04-23 19:48:37,892 - Epoch: [225][  296/  296]    Overall Loss 0.719002    Objective Loss 0.719002    Top1 68.852459    Top5 98.360656    LR 0.000005    Time 0.105841    
2024-04-23 19:48:38,129 - --- validate (epoch=225)-----------
2024-04-23 19:48:38,130 - 3925 samples (32 per mini-batch)
2024-04-23 19:48:53,506 - Epoch: [225][  100/  123]    Loss 0.688274    Top1 78.156250    Top5 97.281250    
2024-04-23 19:48:56,970 - Epoch: [225][  123/  123]    Loss 0.698888    Top1 77.783439    Top5 97.273885    
2024-04-23 19:48:57,139 - ==> Top1: 77.783    Top5: 97.274    Loss: 0.699

2024-04-23 19:48:57,145 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:48:57,145 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:48:57,187 - 

2024-04-23 19:48:57,188 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:49:11,659 - Epoch: [226][  100/  296]    Overall Loss 0.753621    Objective Loss 0.753621                                        LR 0.000005    Time 0.144496    
2024-04-23 19:49:23,745 - Epoch: [226][  200/  296]    Overall Loss 0.744314    Objective Loss 0.744314                                        LR 0.000005    Time 0.132573    
2024-04-23 19:49:33,981 - Epoch: [226][  296/  296]    Overall Loss 0.728202    Objective Loss 0.728202    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.124091    
2024-04-23 19:49:34,271 - --- validate (epoch=226)-----------
2024-04-23 19:49:34,272 - 3925 samples (32 per mini-batch)
2024-04-23 19:49:46,325 - Epoch: [226][  100/  123]    Loss 0.705805    Top1 77.281250    Top5 97.312500    
2024-04-23 19:49:48,579 - Epoch: [226][  123/  123]    Loss 0.698815    Top1 77.528662    Top5 97.401274    
2024-04-23 19:49:48,822 - ==> Top1: 77.529    Top5: 97.401    Loss: 0.699

2024-04-23 19:49:48,827 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:49:48,827 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:49:48,862 - 

2024-04-23 19:49:48,862 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:49:59,314 - Epoch: [227][  100/  296]    Overall Loss 0.714666    Objective Loss 0.714666                                        LR 0.000005    Time 0.104325    
2024-04-23 19:50:08,842 - Epoch: [227][  200/  296]    Overall Loss 0.734990    Objective Loss 0.734990                                        LR 0.000005    Time 0.099701    
2024-04-23 19:50:16,794 - Epoch: [227][  296/  296]    Overall Loss 0.725073    Objective Loss 0.725073    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.094178    
2024-04-23 19:50:17,039 - --- validate (epoch=227)-----------
2024-04-23 19:50:17,039 - 3925 samples (32 per mini-batch)
2024-04-23 19:50:28,390 - Epoch: [227][  100/  123]    Loss 0.696388    Top1 77.437500    Top5 97.343750    
2024-04-23 19:50:31,223 - Epoch: [227][  123/  123]    Loss 0.703359    Top1 77.350318    Top5 97.197452    
2024-04-23 19:50:31,449 - ==> Top1: 77.350    Top5: 97.197    Loss: 0.703

2024-04-23 19:50:31,454 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:50:31,454 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:50:31,490 - 

2024-04-23 19:50:31,491 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:50:43,663 - Epoch: [228][  100/  296]    Overall Loss 0.736054    Objective Loss 0.736054                                        LR 0.000005    Time 0.121520    
2024-04-23 19:50:54,220 - Epoch: [228][  200/  296]    Overall Loss 0.735585    Objective Loss 0.735585                                        LR 0.000005    Time 0.113455    
2024-04-23 19:51:03,036 - Epoch: [228][  296/  296]    Overall Loss 0.725489    Objective Loss 0.725489    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.106380    
2024-04-23 19:51:03,339 - --- validate (epoch=228)-----------
2024-04-23 19:51:03,340 - 3925 samples (32 per mini-batch)
2024-04-23 19:51:17,332 - Epoch: [228][  100/  123]    Loss 0.688721    Top1 77.593750    Top5 97.593750    
2024-04-23 19:51:19,397 - Epoch: [228][  123/  123]    Loss 0.697022    Top1 77.299363    Top5 97.452229    
2024-04-23 19:51:19,644 - ==> Top1: 77.299    Top5: 97.452    Loss: 0.697

2024-04-23 19:51:19,653 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:51:19,654 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:51:19,695 - 

2024-04-23 19:51:19,695 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:51:32,050 - Epoch: [229][  100/  296]    Overall Loss 0.717567    Objective Loss 0.717567                                        LR 0.000005    Time 0.123352    
2024-04-23 19:51:41,953 - Epoch: [229][  200/  296]    Overall Loss 0.726576    Objective Loss 0.726576                                        LR 0.000005    Time 0.111100    
2024-04-23 19:51:52,207 - Epoch: [229][  296/  296]    Overall Loss 0.720383    Objective Loss 0.720383    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.109645    
2024-04-23 19:51:52,456 - --- validate (epoch=229)-----------
2024-04-23 19:51:52,457 - 3925 samples (32 per mini-batch)
2024-04-23 19:52:03,507 - Epoch: [229][  100/  123]    Loss 0.680232    Top1 78.187500    Top5 97.250000    
2024-04-23 19:52:05,372 - Epoch: [229][  123/  123]    Loss 0.700714    Top1 77.554140    Top5 97.197452    
2024-04-23 19:52:05,619 - ==> Top1: 77.554    Top5: 97.197    Loss: 0.701

2024-04-23 19:52:05,628 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:52:05,628 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:52:05,666 - 

2024-04-23 19:52:05,666 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:52:14,687 - Epoch: [230][  100/  296]    Overall Loss 0.735872    Objective Loss 0.735872                                        LR 0.000005    Time 0.090034    
2024-04-23 19:52:22,052 - Epoch: [230][  200/  296]    Overall Loss 0.723233    Objective Loss 0.723233                                        LR 0.000005    Time 0.081762    
2024-04-23 19:52:33,688 - Epoch: [230][  296/  296]    Overall Loss 0.709732    Objective Loss 0.709732    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.094493    
2024-04-23 19:52:34,005 - --- validate (epoch=230)-----------
2024-04-23 19:52:34,006 - 3925 samples (32 per mini-batch)
2024-04-23 19:52:50,521 - Epoch: [230][  100/  123]    Loss 0.710214    Top1 77.562500    Top5 97.250000    
2024-04-23 19:52:54,128 - Epoch: [230][  123/  123]    Loss 0.696467    Top1 77.681529    Top5 97.401274    
2024-04-23 19:52:54,391 - ==> Top1: 77.682    Top5: 97.401    Loss: 0.696

2024-04-23 19:52:54,402 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:52:54,403 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:52:54,459 - 

2024-04-23 19:52:54,460 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:53:10,951 - Epoch: [231][  100/  296]    Overall Loss 0.739671    Objective Loss 0.739671                                        LR 0.000005    Time 0.164696    
2024-04-23 19:53:25,508 - Epoch: [231][  200/  296]    Overall Loss 0.730390    Objective Loss 0.730390                                        LR 0.000005    Time 0.155026    
2024-04-23 19:53:37,915 - Epoch: [231][  296/  296]    Overall Loss 0.728085    Objective Loss 0.728085    Top1 65.573770    Top5 96.721311    LR 0.000005    Time 0.146595    
2024-04-23 19:53:38,149 - --- validate (epoch=231)-----------
2024-04-23 19:53:38,150 - 3925 samples (32 per mini-batch)
2024-04-23 19:53:53,355 - Epoch: [231][  100/  123]    Loss 0.687975    Top1 78.125000    Top5 97.562500    
2024-04-23 19:53:55,855 - Epoch: [231][  123/  123]    Loss 0.698041    Top1 77.681529    Top5 97.375796    
2024-04-23 19:53:56,094 - ==> Top1: 77.682    Top5: 97.376    Loss: 0.698

2024-04-23 19:53:56,105 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:53:56,106 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:53:56,168 - 

2024-04-23 19:53:56,168 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:54:06,080 - Epoch: [232][  100/  296]    Overall Loss 0.736730    Objective Loss 0.736730                                        LR 0.000005    Time 0.098930    
2024-04-23 19:54:19,135 - Epoch: [232][  200/  296]    Overall Loss 0.725687    Objective Loss 0.725687                                        LR 0.000005    Time 0.114649    
2024-04-23 19:54:29,138 - Epoch: [232][  296/  296]    Overall Loss 0.714255    Objective Loss 0.714255    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.111201    
2024-04-23 19:54:29,438 - --- validate (epoch=232)-----------
2024-04-23 19:54:29,439 - 3925 samples (32 per mini-batch)
2024-04-23 19:54:44,499 - Epoch: [232][  100/  123]    Loss 0.703405    Top1 77.406250    Top5 97.468750    
2024-04-23 19:54:47,631 - Epoch: [232][  123/  123]    Loss 0.699783    Top1 77.477707    Top5 97.401274    
2024-04-23 19:54:47,895 - ==> Top1: 77.478    Top5: 97.401    Loss: 0.700

2024-04-23 19:54:47,903 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:54:47,903 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:54:47,951 - 

2024-04-23 19:54:47,952 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:55:01,788 - Epoch: [233][  100/  296]    Overall Loss 0.724602    Objective Loss 0.724602                                        LR 0.000005    Time 0.138151    
2024-04-23 19:55:12,546 - Epoch: [233][  200/  296]    Overall Loss 0.725721    Objective Loss 0.725721                                        LR 0.000005    Time 0.122765    
2024-04-23 19:55:21,552 - Epoch: [233][  296/  296]    Overall Loss 0.717955    Objective Loss 0.717955    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.113316    
2024-04-23 19:55:21,795 - --- validate (epoch=233)-----------
2024-04-23 19:55:21,796 - 3925 samples (32 per mini-batch)
2024-04-23 19:55:33,542 - Epoch: [233][  100/  123]    Loss 0.699349    Top1 77.687500    Top5 97.437500    
2024-04-23 19:55:35,273 - Epoch: [233][  123/  123]    Loss 0.701181    Top1 77.477707    Top5 97.401274    
2024-04-23 19:55:35,504 - ==> Top1: 77.478    Top5: 97.401    Loss: 0.701

2024-04-23 19:55:35,515 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:55:35,515 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:55:35,559 - 

2024-04-23 19:55:35,560 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:55:50,691 - Epoch: [234][  100/  296]    Overall Loss 0.704184    Objective Loss 0.704184                                        LR 0.000005    Time 0.151091    
2024-04-23 19:56:03,485 - Epoch: [234][  200/  296]    Overall Loss 0.729016    Objective Loss 0.729016                                        LR 0.000005    Time 0.139412    
2024-04-23 19:56:14,971 - Epoch: [234][  296/  296]    Overall Loss 0.716277    Objective Loss 0.716277    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.132940    
2024-04-23 19:56:15,222 - --- validate (epoch=234)-----------
2024-04-23 19:56:15,223 - 3925 samples (32 per mini-batch)
2024-04-23 19:56:26,589 - Epoch: [234][  100/  123]    Loss 0.706574    Top1 77.281250    Top5 97.375000    
2024-04-23 19:56:28,571 - Epoch: [234][  123/  123]    Loss 0.704815    Top1 77.503185    Top5 97.401274    
2024-04-23 19:56:28,944 - ==> Top1: 77.503    Top5: 97.401    Loss: 0.705

2024-04-23 19:56:28,952 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:56:28,952 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:56:28,987 - 

2024-04-23 19:56:28,988 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:56:40,350 - Epoch: [235][  100/  296]    Overall Loss 0.739352    Objective Loss 0.739352                                        LR 0.000005    Time 0.113450    
2024-04-23 19:56:53,816 - Epoch: [235][  200/  296]    Overall Loss 0.712775    Objective Loss 0.712775                                        LR 0.000005    Time 0.123949    
2024-04-23 19:57:02,694 - Epoch: [235][  296/  296]    Overall Loss 0.716410    Objective Loss 0.716410    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.113679    
2024-04-23 19:57:02,924 - --- validate (epoch=235)-----------
2024-04-23 19:57:02,925 - 3925 samples (32 per mini-batch)
2024-04-23 19:57:15,933 - Epoch: [235][  100/  123]    Loss 0.708173    Top1 77.468750    Top5 97.312500    
2024-04-23 19:57:18,145 - Epoch: [235][  123/  123]    Loss 0.698305    Top1 77.605096    Top5 97.248408    
2024-04-23 19:57:18,398 - ==> Top1: 77.605    Top5: 97.248    Loss: 0.698

2024-04-23 19:57:18,408 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:57:18,409 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:57:18,470 - 

2024-04-23 19:57:18,471 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:57:32,979 - Epoch: [236][  100/  296]    Overall Loss 0.716768    Objective Loss 0.716768                                        LR 0.000005    Time 0.144850    
2024-04-23 19:57:43,253 - Epoch: [236][  200/  296]    Overall Loss 0.735976    Objective Loss 0.735976                                        LR 0.000005    Time 0.123695    
2024-04-23 19:57:57,054 - Epoch: [236][  296/  296]    Overall Loss 0.729126    Objective Loss 0.729126    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.130138    
2024-04-23 19:57:57,360 - --- validate (epoch=236)-----------
2024-04-23 19:57:57,361 - 3925 samples (32 per mini-batch)
2024-04-23 19:58:15,015 - Epoch: [236][  100/  123]    Loss 0.691836    Top1 78.093750    Top5 97.625000    
2024-04-23 19:58:17,728 - Epoch: [236][  123/  123]    Loss 0.707082    Top1 77.503185    Top5 97.401274    
2024-04-23 19:58:18,014 - ==> Top1: 77.503    Top5: 97.401    Loss: 0.707

2024-04-23 19:58:18,019 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:58:18,019 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:58:18,055 - 

2024-04-23 19:58:18,055 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:58:28,910 - Epoch: [237][  100/  296]    Overall Loss 0.720851    Objective Loss 0.720851                                        LR 0.000005    Time 0.108341    
2024-04-23 19:58:40,096 - Epoch: [237][  200/  296]    Overall Loss 0.738548    Objective Loss 0.738548                                        LR 0.000005    Time 0.110000    
2024-04-23 19:58:50,166 - Epoch: [237][  296/  296]    Overall Loss 0.726709    Objective Loss 0.726709    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.108280    
2024-04-23 19:58:50,410 - --- validate (epoch=237)-----------
2024-04-23 19:58:50,411 - 3925 samples (32 per mini-batch)
2024-04-23 19:59:04,537 - Epoch: [237][  100/  123]    Loss 0.710233    Top1 77.375000    Top5 97.062500    
2024-04-23 19:59:07,756 - Epoch: [237][  123/  123]    Loss 0.701218    Top1 77.783439    Top5 97.248408    
2024-04-23 19:59:07,992 - ==> Top1: 77.783    Top5: 97.248    Loss: 0.701

2024-04-23 19:59:07,997 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 19:59:07,998 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 19:59:08,042 - 

2024-04-23 19:59:08,043 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:59:24,657 - Epoch: [238][  100/  296]    Overall Loss 0.710802    Objective Loss 0.710802                                        LR 0.000005    Time 0.165932    
2024-04-23 19:59:35,750 - Epoch: [238][  200/  296]    Overall Loss 0.720228    Objective Loss 0.720228                                        LR 0.000005    Time 0.138339    
2024-04-23 19:59:47,258 - Epoch: [238][  296/  296]    Overall Loss 0.736493    Objective Loss 0.736493    Top1 73.770492    Top5 93.442623    LR 0.000005    Time 0.132299    
2024-04-23 19:59:47,526 - --- validate (epoch=238)-----------
2024-04-23 19:59:47,527 - 3925 samples (32 per mini-batch)
2024-04-23 20:00:03,963 - Epoch: [238][  100/  123]    Loss 0.702421    Top1 77.718750    Top5 97.375000    
2024-04-23 20:00:07,820 - Epoch: [238][  123/  123]    Loss 0.703297    Top1 77.681529    Top5 97.248408    
2024-04-23 20:00:07,971 - ==> Top1: 77.682    Top5: 97.248    Loss: 0.703

2024-04-23 20:00:07,981 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:00:07,981 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:00:08,029 - 

2024-04-23 20:00:08,030 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:00:21,659 - Epoch: [239][  100/  296]    Overall Loss 0.710101    Objective Loss 0.710101                                        LR 0.000005    Time 0.136111    
2024-04-23 20:00:33,637 - Epoch: [239][  200/  296]    Overall Loss 0.707526    Objective Loss 0.707526                                        LR 0.000005    Time 0.127855    
2024-04-23 20:00:45,076 - Epoch: [239][  296/  296]    Overall Loss 0.699211    Objective Loss 0.699211    Top1 63.934426    Top5 100.000000    LR 0.000005    Time 0.124983    
2024-04-23 20:00:45,266 - --- validate (epoch=239)-----------
2024-04-23 20:00:45,268 - 3925 samples (32 per mini-batch)
2024-04-23 20:01:01,915 - Epoch: [239][  100/  123]    Loss 0.679810    Top1 78.125000    Top5 97.593750    
2024-04-23 20:01:05,666 - Epoch: [239][  123/  123]    Loss 0.698356    Top1 77.579618    Top5 97.375796    
2024-04-23 20:01:05,873 - ==> Top1: 77.580    Top5: 97.376    Loss: 0.698

2024-04-23 20:01:05,881 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:01:05,881 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:01:05,920 - 

2024-04-23 20:01:05,921 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:01:18,753 - Epoch: [240][  100/  296]    Overall Loss 0.747098    Objective Loss 0.747098                                        LR 0.000005    Time 0.128177    
2024-04-23 20:01:29,322 - Epoch: [240][  200/  296]    Overall Loss 0.721303    Objective Loss 0.721303                                        LR 0.000005    Time 0.116863    
2024-04-23 20:01:41,074 - Epoch: [240][  296/  296]    Overall Loss 0.723403    Objective Loss 0.723403    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.118617    
2024-04-23 20:01:41,369 - --- validate (epoch=240)-----------
2024-04-23 20:01:41,370 - 3925 samples (32 per mini-batch)
2024-04-23 20:01:55,985 - Epoch: [240][  100/  123]    Loss 0.704722    Top1 77.656250    Top5 97.187500    
2024-04-23 20:01:58,649 - Epoch: [240][  123/  123]    Loss 0.702918    Top1 77.732484    Top5 97.324841    
2024-04-23 20:01:58,894 - ==> Top1: 77.732    Top5: 97.325    Loss: 0.703

2024-04-23 20:01:58,901 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:01:58,901 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:01:58,949 - 

2024-04-23 20:01:58,950 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:02:10,804 - Epoch: [241][  100/  296]    Overall Loss 0.711836    Objective Loss 0.711836                                        LR 0.000005    Time 0.118371    
2024-04-23 20:02:21,643 - Epoch: [241][  200/  296]    Overall Loss 0.713523    Objective Loss 0.713523                                        LR 0.000005    Time 0.113295    
2024-04-23 20:02:29,529 - Epoch: [241][  296/  296]    Overall Loss 0.711281    Objective Loss 0.711281    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.103145    
2024-04-23 20:02:29,795 - --- validate (epoch=241)-----------
2024-04-23 20:02:29,796 - 3925 samples (32 per mini-batch)
2024-04-23 20:02:40,205 - Epoch: [241][  100/  123]    Loss 0.703903    Top1 78.187500    Top5 97.218750    
2024-04-23 20:02:42,209 - Epoch: [241][  123/  123]    Loss 0.700121    Top1 77.834395    Top5 97.401274    
2024-04-23 20:02:42,435 - ==> Top1: 77.834    Top5: 97.401    Loss: 0.700

2024-04-23 20:02:42,446 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:02:42,447 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:02:42,515 - 

2024-04-23 20:02:42,516 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:02:55,952 - Epoch: [242][  100/  296]    Overall Loss 0.710734    Objective Loss 0.710734                                        LR 0.000005    Time 0.134165    
2024-04-23 20:03:07,144 - Epoch: [242][  200/  296]    Overall Loss 0.718270    Objective Loss 0.718270                                        LR 0.000005    Time 0.122959    
2024-04-23 20:03:17,684 - Epoch: [242][  296/  296]    Overall Loss 0.720253    Objective Loss 0.720253    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.118642    
2024-04-23 20:03:17,972 - --- validate (epoch=242)-----------
2024-04-23 20:03:17,973 - 3925 samples (32 per mini-batch)
2024-04-23 20:03:28,864 - Epoch: [242][  100/  123]    Loss 0.709496    Top1 77.656250    Top5 97.312500    
2024-04-23 20:03:30,862 - Epoch: [242][  123/  123]    Loss 0.697240    Top1 77.885350    Top5 97.426752    
2024-04-23 20:03:31,055 - ==> Top1: 77.885    Top5: 97.427    Loss: 0.697

2024-04-23 20:03:31,060 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:03:31,060 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:03:31,090 - 

2024-04-23 20:03:31,091 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:03:43,266 - Epoch: [243][  100/  296]    Overall Loss 0.724461    Objective Loss 0.724461                                        LR 0.000005    Time 0.121575    
2024-04-23 20:03:55,330 - Epoch: [243][  200/  296]    Overall Loss 0.726434    Objective Loss 0.726434                                        LR 0.000005    Time 0.121028    
2024-04-23 20:04:05,630 - Epoch: [243][  296/  296]    Overall Loss 0.724764    Objective Loss 0.724764    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.116524    
2024-04-23 20:04:05,854 - --- validate (epoch=243)-----------
2024-04-23 20:04:05,855 - 3925 samples (32 per mini-batch)
2024-04-23 20:04:22,380 - Epoch: [243][  100/  123]    Loss 0.671773    Top1 78.437500    Top5 97.531250    
2024-04-23 20:04:26,261 - Epoch: [243][  123/  123]    Loss 0.698946    Top1 77.732484    Top5 97.452229    
2024-04-23 20:04:26,396 - ==> Top1: 77.732    Top5: 97.452    Loss: 0.699

2024-04-23 20:04:26,408 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:04:26,409 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:04:26,460 - 

2024-04-23 20:04:26,461 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:04:40,655 - Epoch: [244][  100/  296]    Overall Loss 0.729004    Objective Loss 0.729004                                        LR 0.000005    Time 0.141766    
2024-04-23 20:04:54,195 - Epoch: [244][  200/  296]    Overall Loss 0.729278    Objective Loss 0.729278                                        LR 0.000005    Time 0.138497    
2024-04-23 20:05:04,268 - Epoch: [244][  296/  296]    Overall Loss 0.726103    Objective Loss 0.726103    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.127556    
2024-04-23 20:05:04,535 - --- validate (epoch=244)-----------
2024-04-23 20:05:04,536 - 3925 samples (32 per mini-batch)
2024-04-23 20:05:19,844 - Epoch: [244][  100/  123]    Loss 0.708789    Top1 77.406250    Top5 97.218750    
2024-04-23 20:05:23,095 - Epoch: [244][  123/  123]    Loss 0.698782    Top1 77.426752    Top5 97.426752    
2024-04-23 20:05:23,261 - ==> Top1: 77.427    Top5: 97.427    Loss: 0.699

2024-04-23 20:05:23,271 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:05:23,271 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:05:23,315 - 

2024-04-23 20:05:23,315 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:05:37,709 - Epoch: [245][  100/  296]    Overall Loss 0.731090    Objective Loss 0.731090                                        LR 0.000005    Time 0.143771    
2024-04-23 20:05:49,456 - Epoch: [245][  200/  296]    Overall Loss 0.729886    Objective Loss 0.729886                                        LR 0.000005    Time 0.130528    
2024-04-23 20:06:00,772 - Epoch: [245][  296/  296]    Overall Loss 0.725140    Objective Loss 0.725140    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.126366    
2024-04-23 20:06:01,079 - --- validate (epoch=245)-----------
2024-04-23 20:06:01,080 - 3925 samples (32 per mini-batch)
2024-04-23 20:06:16,037 - Epoch: [245][  100/  123]    Loss 0.700983    Top1 77.437500    Top5 97.406250    
2024-04-23 20:06:19,101 - Epoch: [245][  123/  123]    Loss 0.698959    Top1 77.630573    Top5 97.324841    
2024-04-23 20:06:19,379 - ==> Top1: 77.631    Top5: 97.325    Loss: 0.699

2024-04-23 20:06:19,389 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:06:19,390 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:06:19,448 - 

2024-04-23 20:06:19,449 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:06:32,221 - Epoch: [246][  100/  296]    Overall Loss 0.704592    Objective Loss 0.704592                                        LR 0.000005    Time 0.127542    
2024-04-23 20:06:44,439 - Epoch: [246][  200/  296]    Overall Loss 0.718375    Objective Loss 0.718375                                        LR 0.000005    Time 0.124779    
2024-04-23 20:06:55,343 - Epoch: [246][  296/  296]    Overall Loss 0.716626    Objective Loss 0.716626    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.121093    
2024-04-23 20:06:55,712 - --- validate (epoch=246)-----------
2024-04-23 20:06:55,713 - 3925 samples (32 per mini-batch)
2024-04-23 20:07:07,521 - Epoch: [246][  100/  123]    Loss 0.699191    Top1 77.625000    Top5 97.281250    
2024-04-23 20:07:09,991 - Epoch: [246][  123/  123]    Loss 0.704470    Top1 77.350318    Top5 97.324841    
2024-04-23 20:07:10,275 - ==> Top1: 77.350    Top5: 97.325    Loss: 0.704

2024-04-23 20:07:10,285 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:07:10,286 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:07:10,339 - 

2024-04-23 20:07:10,340 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:07:23,792 - Epoch: [247][  100/  296]    Overall Loss 0.698437    Objective Loss 0.698437                                        LR 0.000005    Time 0.134344    
2024-04-23 20:07:34,493 - Epoch: [247][  200/  296]    Overall Loss 0.721626    Objective Loss 0.721626                                        LR 0.000005    Time 0.120584    
2024-04-23 20:07:45,166 - Epoch: [247][  296/  296]    Overall Loss 0.730276    Objective Loss 0.730276    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.117483    
2024-04-23 20:07:45,501 - --- validate (epoch=247)-----------
2024-04-23 20:07:45,502 - 3925 samples (32 per mini-batch)
2024-04-23 20:08:00,962 - Epoch: [247][  100/  123]    Loss 0.702142    Top1 77.937500    Top5 97.218750    
2024-04-23 20:08:04,028 - Epoch: [247][  123/  123]    Loss 0.700185    Top1 77.808917    Top5 97.273885    
2024-04-23 20:08:04,360 - ==> Top1: 77.809    Top5: 97.274    Loss: 0.700

2024-04-23 20:08:04,372 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:08:04,373 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:08:04,426 - 

2024-04-23 20:08:04,427 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:08:22,287 - Epoch: [248][  100/  296]    Overall Loss 0.712142    Objective Loss 0.712142                                        LR 0.000005    Time 0.178419    
2024-04-23 20:08:35,884 - Epoch: [248][  200/  296]    Overall Loss 0.726794    Objective Loss 0.726794                                        LR 0.000005    Time 0.157127    
2024-04-23 20:08:47,981 - Epoch: [248][  296/  296]    Overall Loss 0.725412    Objective Loss 0.725412    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.146985    
2024-04-23 20:08:48,269 - --- validate (epoch=248)-----------
2024-04-23 20:08:48,270 - 3925 samples (32 per mini-batch)
2024-04-23 20:09:02,226 - Epoch: [248][  100/  123]    Loss 0.714707    Top1 76.968750    Top5 97.218750    
2024-04-23 20:09:05,188 - Epoch: [248][  123/  123]    Loss 0.699853    Top1 77.579618    Top5 97.324841    
2024-04-23 20:09:05,436 - ==> Top1: 77.580    Top5: 97.325    Loss: 0.700

2024-04-23 20:09:05,445 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:09:05,446 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:09:05,487 - 

2024-04-23 20:09:05,488 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:09:16,462 - Epoch: [249][  100/  296]    Overall Loss 0.669979    Objective Loss 0.669979                                        LR 0.000005    Time 0.109571    
2024-04-23 20:09:26,001 - Epoch: [249][  200/  296]    Overall Loss 0.710480    Objective Loss 0.710480                                        LR 0.000005    Time 0.102394    
2024-04-23 20:09:35,769 - Epoch: [249][  296/  296]    Overall Loss 0.715738    Objective Loss 0.715738    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.102130    
2024-04-23 20:09:36,024 - --- validate (epoch=249)-----------
2024-04-23 20:09:36,025 - 3925 samples (32 per mini-batch)
2024-04-23 20:09:50,896 - Epoch: [249][  100/  123]    Loss 0.702361    Top1 77.468750    Top5 97.125000    
2024-04-23 20:09:53,839 - Epoch: [249][  123/  123]    Loss 0.705440    Top1 77.452229    Top5 97.146497    
2024-04-23 20:09:54,127 - ==> Top1: 77.452    Top5: 97.146    Loss: 0.705

2024-04-23 20:09:54,137 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:09:54,137 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:09:54,180 - 

2024-04-23 20:09:54,181 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:10:07,550 - Epoch: [250][  100/  296]    Overall Loss 0.706279    Objective Loss 0.706279                                        LR 0.000005    Time 0.133538    
2024-04-23 20:10:19,442 - Epoch: [250][  200/  296]    Overall Loss 0.716931    Objective Loss 0.716931                                        LR 0.000005    Time 0.126143    
2024-04-23 20:10:30,253 - Epoch: [250][  296/  296]    Overall Loss 0.717682    Objective Loss 0.717682    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.121702    
2024-04-23 20:10:30,456 - --- validate (epoch=250)-----------
2024-04-23 20:10:30,457 - 3925 samples (32 per mini-batch)
2024-04-23 20:10:45,786 - Epoch: [250][  100/  123]    Loss 0.687364    Top1 78.062500    Top5 97.343750    
2024-04-23 20:10:49,022 - Epoch: [250][  123/  123]    Loss 0.698271    Top1 77.783439    Top5 97.248408    
2024-04-23 20:10:49,294 - ==> Top1: 77.783    Top5: 97.248    Loss: 0.698

2024-04-23 20:10:49,302 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:10:49,302 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:10:49,352 - 

2024-04-23 20:10:49,353 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:11:01,032 - Epoch: [251][  100/  296]    Overall Loss 0.720668    Objective Loss 0.720668                                        LR 0.000005    Time 0.116603    
2024-04-23 20:11:09,439 - Epoch: [251][  200/  296]    Overall Loss 0.723051    Objective Loss 0.723051                                        LR 0.000005    Time 0.100252    
2024-04-23 20:11:18,713 - Epoch: [251][  296/  296]    Overall Loss 0.728439    Objective Loss 0.728439    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.099013    
2024-04-23 20:11:18,945 - --- validate (epoch=251)-----------
2024-04-23 20:11:18,946 - 3925 samples (32 per mini-batch)
2024-04-23 20:11:29,660 - Epoch: [251][  100/  123]    Loss 0.701868    Top1 77.906250    Top5 97.312500    
2024-04-23 20:11:31,388 - Epoch: [251][  123/  123]    Loss 0.696727    Top1 77.808917    Top5 97.426752    
2024-04-23 20:11:31,685 - ==> Top1: 77.809    Top5: 97.427    Loss: 0.697

2024-04-23 20:11:31,694 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:11:31,695 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:11:31,733 - 

2024-04-23 20:11:31,733 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:11:40,499 - Epoch: [252][  100/  296]    Overall Loss 0.738502    Objective Loss 0.738502                                        LR 0.000005    Time 0.087504    
2024-04-23 20:11:47,298 - Epoch: [252][  200/  296]    Overall Loss 0.722496    Objective Loss 0.722496                                        LR 0.000005    Time 0.077676    
2024-04-23 20:11:56,129 - Epoch: [252][  296/  296]    Overall Loss 0.724177    Objective Loss 0.724177    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.082268    
2024-04-23 20:11:56,423 - --- validate (epoch=252)-----------
2024-04-23 20:11:56,424 - 3925 samples (32 per mini-batch)
2024-04-23 20:12:09,187 - Epoch: [252][  100/  123]    Loss 0.685349    Top1 77.812500    Top5 97.437500    
2024-04-23 20:12:11,312 - Epoch: [252][  123/  123]    Loss 0.700533    Top1 77.605096    Top5 97.299363    
2024-04-23 20:12:11,518 - ==> Top1: 77.605    Top5: 97.299    Loss: 0.701

2024-04-23 20:12:11,528 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:12:11,528 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:12:11,570 - 

2024-04-23 20:12:11,571 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:12:22,737 - Epoch: [253][  100/  296]    Overall Loss 0.751345    Objective Loss 0.751345                                        LR 0.000005    Time 0.111488    
2024-04-23 20:12:32,078 - Epoch: [253][  200/  296]    Overall Loss 0.724132    Objective Loss 0.724132                                        LR 0.000005    Time 0.102374    
2024-04-23 20:12:43,003 - Epoch: [253][  296/  296]    Overall Loss 0.713067    Objective Loss 0.713067    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.106033    
2024-04-23 20:12:43,293 - --- validate (epoch=253)-----------
2024-04-23 20:12:43,294 - 3925 samples (32 per mini-batch)
2024-04-23 20:12:55,918 - Epoch: [253][  100/  123]    Loss 0.684245    Top1 78.093750    Top5 97.593750    
2024-04-23 20:12:57,856 - Epoch: [253][  123/  123]    Loss 0.698799    Top1 77.579618    Top5 97.401274    
2024-04-23 20:12:58,105 - ==> Top1: 77.580    Top5: 97.401    Loss: 0.699

2024-04-23 20:12:58,112 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:12:58,112 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:12:58,152 - 

2024-04-23 20:12:58,152 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:13:08,532 - Epoch: [254][  100/  296]    Overall Loss 0.721444    Objective Loss 0.721444                                        LR 0.000005    Time 0.103622    
2024-04-23 20:13:17,558 - Epoch: [254][  200/  296]    Overall Loss 0.704480    Objective Loss 0.704480                                        LR 0.000005    Time 0.096863    
2024-04-23 20:13:25,686 - Epoch: [254][  296/  296]    Overall Loss 0.715636    Objective Loss 0.715636    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.092858    
2024-04-23 20:13:25,879 - --- validate (epoch=254)-----------
2024-04-23 20:13:25,880 - 3925 samples (32 per mini-batch)
2024-04-23 20:13:38,877 - Epoch: [254][  100/  123]    Loss 0.691301    Top1 77.781250    Top5 97.343750    
2024-04-23 20:13:41,259 - Epoch: [254][  123/  123]    Loss 0.700537    Top1 77.732484    Top5 97.273885    
2024-04-23 20:13:41,469 - ==> Top1: 77.732    Top5: 97.274    Loss: 0.701

2024-04-23 20:13:41,478 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:13:41,479 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:13:41,516 - 

2024-04-23 20:13:41,516 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:13:52,210 - Epoch: [255][  100/  296]    Overall Loss 0.721093    Objective Loss 0.721093                                        LR 0.000005    Time 0.106758    
2024-04-23 20:14:01,685 - Epoch: [255][  200/  296]    Overall Loss 0.726088    Objective Loss 0.726088                                        LR 0.000005    Time 0.100672    
2024-04-23 20:14:10,646 - Epoch: [255][  296/  296]    Overall Loss 0.723737    Objective Loss 0.723737    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.098242    
2024-04-23 20:14:10,925 - --- validate (epoch=255)-----------
2024-04-23 20:14:10,926 - 3925 samples (32 per mini-batch)
2024-04-23 20:14:23,459 - Epoch: [255][  100/  123]    Loss 0.707598    Top1 77.125000    Top5 97.187500    
2024-04-23 20:14:25,909 - Epoch: [255][  123/  123]    Loss 0.699130    Top1 77.605096    Top5 97.324841    
2024-04-23 20:14:26,142 - ==> Top1: 77.605    Top5: 97.325    Loss: 0.699

2024-04-23 20:14:26,151 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:14:26,152 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:14:26,199 - 

2024-04-23 20:14:26,200 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:14:38,132 - Epoch: [256][  100/  296]    Overall Loss 0.721701    Objective Loss 0.721701                                        LR 0.000005    Time 0.119155    
2024-04-23 20:14:47,622 - Epoch: [256][  200/  296]    Overall Loss 0.720061    Objective Loss 0.720061                                        LR 0.000005    Time 0.106953    
2024-04-23 20:14:57,016 - Epoch: [256][  296/  296]    Overall Loss 0.720948    Objective Loss 0.720948    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.103949    
2024-04-23 20:14:57,293 - --- validate (epoch=256)-----------
2024-04-23 20:14:57,294 - 3925 samples (32 per mini-batch)
2024-04-23 20:15:09,877 - Epoch: [256][  100/  123]    Loss 0.730479    Top1 76.843750    Top5 97.031250    
2024-04-23 20:15:12,344 - Epoch: [256][  123/  123]    Loss 0.698750    Top1 77.579618    Top5 97.324841    
2024-04-23 20:15:12,607 - ==> Top1: 77.580    Top5: 97.325    Loss: 0.699

2024-04-23 20:15:12,616 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:15:12,616 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:15:12,658 - 

2024-04-23 20:15:12,659 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:15:25,103 - Epoch: [257][  100/  296]    Overall Loss 0.710973    Objective Loss 0.710973                                        LR 0.000005    Time 0.124247    
2024-04-23 20:15:35,814 - Epoch: [257][  200/  296]    Overall Loss 0.697127    Objective Loss 0.697127                                        LR 0.000005    Time 0.115602    
2024-04-23 20:15:45,443 - Epoch: [257][  296/  296]    Overall Loss 0.707850    Objective Loss 0.707850    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.110589    
2024-04-23 20:15:45,695 - --- validate (epoch=257)-----------
2024-04-23 20:15:45,696 - 3925 samples (32 per mini-batch)
2024-04-23 20:15:57,041 - Epoch: [257][  100/  123]    Loss 0.695080    Top1 77.750000    Top5 97.406250    
2024-04-23 20:15:58,890 - Epoch: [257][  123/  123]    Loss 0.699072    Top1 77.732484    Top5 97.273885    
2024-04-23 20:15:59,121 - ==> Top1: 77.732    Top5: 97.274    Loss: 0.699

2024-04-23 20:15:59,126 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:15:59,127 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:15:59,163 - 

2024-04-23 20:15:59,164 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:16:09,707 - Epoch: [258][  100/  296]    Overall Loss 0.740176    Objective Loss 0.740176                                        LR 0.000005    Time 0.105261    
2024-04-23 20:16:16,953 - Epoch: [258][  200/  296]    Overall Loss 0.743846    Objective Loss 0.743846                                        LR 0.000005    Time 0.088783    
2024-04-23 20:16:25,591 - Epoch: [258][  296/  296]    Overall Loss 0.734375    Objective Loss 0.734375    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.089116    
2024-04-23 20:16:25,793 - --- validate (epoch=258)-----------
2024-04-23 20:16:25,794 - 3925 samples (32 per mini-batch)
2024-04-23 20:16:38,552 - Epoch: [258][  100/  123]    Loss 0.695783    Top1 77.750000    Top5 97.312500    
2024-04-23 20:16:41,008 - Epoch: [258][  123/  123]    Loss 0.699438    Top1 77.554140    Top5 97.197452    
2024-04-23 20:16:41,248 - ==> Top1: 77.554    Top5: 97.197    Loss: 0.699

2024-04-23 20:16:41,257 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:16:41,258 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:16:41,300 - 

2024-04-23 20:16:41,302 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:16:50,205 - Epoch: [259][  100/  296]    Overall Loss 0.702721    Objective Loss 0.702721                                        LR 0.000005    Time 0.088867    
2024-04-23 20:16:58,956 - Epoch: [259][  200/  296]    Overall Loss 0.717402    Objective Loss 0.717402                                        LR 0.000005    Time 0.088110    
2024-04-23 20:17:07,759 - Epoch: [259][  296/  296]    Overall Loss 0.718436    Objective Loss 0.718436    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.089229    
2024-04-23 20:17:08,002 - --- validate (epoch=259)-----------
2024-04-23 20:17:08,003 - 3925 samples (32 per mini-batch)
2024-04-23 20:17:19,513 - Epoch: [259][  100/  123]    Loss 0.705434    Top1 77.437500    Top5 97.281250    
2024-04-23 20:17:22,255 - Epoch: [259][  123/  123]    Loss 0.696950    Top1 77.732484    Top5 97.426752    
2024-04-23 20:17:22,467 - ==> Top1: 77.732    Top5: 97.427    Loss: 0.697

2024-04-23 20:17:22,477 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:17:22,477 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:17:22,514 - 

2024-04-23 20:17:22,515 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:17:33,084 - Epoch: [260][  100/  296]    Overall Loss 0.721516    Objective Loss 0.721516                                        LR 0.000005    Time 0.105521    
2024-04-23 20:17:45,764 - Epoch: [260][  200/  296]    Overall Loss 0.708395    Objective Loss 0.708395                                        LR 0.000005    Time 0.116086    
2024-04-23 20:17:57,153 - Epoch: [260][  296/  296]    Overall Loss 0.710840    Objective Loss 0.710840    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.116862    
2024-04-23 20:17:57,456 - --- validate (epoch=260)-----------
2024-04-23 20:17:57,457 - 3925 samples (32 per mini-batch)
2024-04-23 20:18:10,416 - Epoch: [260][  100/  123]    Loss 0.695415    Top1 77.687500    Top5 97.406250    
2024-04-23 20:18:12,918 - Epoch: [260][  123/  123]    Loss 0.697830    Top1 77.885350    Top5 97.324841    
2024-04-23 20:18:13,157 - ==> Top1: 77.885    Top5: 97.325    Loss: 0.698

2024-04-23 20:18:13,162 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:18:13,162 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:18:13,200 - 

2024-04-23 20:18:13,200 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:18:24,134 - Epoch: [261][  100/  296]    Overall Loss 0.734836    Objective Loss 0.734836                                        LR 0.000005    Time 0.109167    
2024-04-23 20:18:33,117 - Epoch: [261][  200/  296]    Overall Loss 0.724660    Objective Loss 0.724660                                        LR 0.000005    Time 0.099412    
2024-04-23 20:18:40,828 - Epoch: [261][  296/  296]    Overall Loss 0.718285    Objective Loss 0.718285    Top1 67.213115    Top5 91.803279    LR 0.000005    Time 0.093169    
2024-04-23 20:18:41,136 - --- validate (epoch=261)-----------
2024-04-23 20:18:41,137 - 3925 samples (32 per mini-batch)
2024-04-23 20:18:53,141 - Epoch: [261][  100/  123]    Loss 0.693186    Top1 77.812500    Top5 97.500000    
2024-04-23 20:18:54,965 - Epoch: [261][  123/  123]    Loss 0.697718    Top1 77.656051    Top5 97.452229    
2024-04-23 20:18:55,257 - ==> Top1: 77.656    Top5: 97.452    Loss: 0.698

2024-04-23 20:18:55,266 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:18:55,266 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:18:55,306 - 

2024-04-23 20:18:55,307 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:19:06,527 - Epoch: [262][  100/  296]    Overall Loss 0.717423    Objective Loss 0.717423                                        LR 0.000005    Time 0.112026    
2024-04-23 20:19:16,287 - Epoch: [262][  200/  296]    Overall Loss 0.724881    Objective Loss 0.724881                                        LR 0.000005    Time 0.104725    
2024-04-23 20:19:24,555 - Epoch: [262][  296/  296]    Overall Loss 0.725949    Objective Loss 0.725949    Top1 86.885246    Top5 96.721311    LR 0.000005    Time 0.098646    
2024-04-23 20:19:24,824 - --- validate (epoch=262)-----------
2024-04-23 20:19:24,825 - 3925 samples (32 per mini-batch)
2024-04-23 20:19:36,553 - Epoch: [262][  100/  123]    Loss 0.691505    Top1 77.625000    Top5 97.531250    
2024-04-23 20:19:38,359 - Epoch: [262][  123/  123]    Loss 0.700912    Top1 77.528662    Top5 97.299363    
2024-04-23 20:19:38,565 - ==> Top1: 77.529    Top5: 97.299    Loss: 0.701

2024-04-23 20:19:38,573 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:19:38,574 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:19:38,611 - 

2024-04-23 20:19:38,611 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:19:48,807 - Epoch: [263][  100/  296]    Overall Loss 0.710021    Objective Loss 0.710021                                        LR 0.000005    Time 0.101782    
2024-04-23 20:19:58,460 - Epoch: [263][  200/  296]    Overall Loss 0.725345    Objective Loss 0.725345                                        LR 0.000005    Time 0.099078    
2024-04-23 20:20:08,468 - Epoch: [263][  296/  296]    Overall Loss 0.724746    Objective Loss 0.724746    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.100691    
2024-04-23 20:20:08,691 - --- validate (epoch=263)-----------
2024-04-23 20:20:08,692 - 3925 samples (32 per mini-batch)
2024-04-23 20:20:18,965 - Epoch: [263][  100/  123]    Loss 0.705837    Top1 77.250000    Top5 97.187500    
2024-04-23 20:20:21,066 - Epoch: [263][  123/  123]    Loss 0.699524    Top1 77.732484    Top5 97.222930    
2024-04-23 20:20:21,294 - ==> Top1: 77.732    Top5: 97.223    Loss: 0.700

2024-04-23 20:20:21,301 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:20:21,301 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:20:21,342 - 

2024-04-23 20:20:21,343 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:20:31,971 - Epoch: [264][  100/  296]    Overall Loss 0.713450    Objective Loss 0.713450                                        LR 0.000005    Time 0.106097    
2024-04-23 20:20:40,537 - Epoch: [264][  200/  296]    Overall Loss 0.705752    Objective Loss 0.705752                                        LR 0.000005    Time 0.095803    
2024-04-23 20:20:46,533 - Epoch: [264][  296/  296]    Overall Loss 0.713951    Objective Loss 0.713951    Top1 67.213115    Top5 93.442623    LR 0.000005    Time 0.084942    
2024-04-23 20:20:46,760 - --- validate (epoch=264)-----------
2024-04-23 20:20:46,761 - 3925 samples (32 per mini-batch)
2024-04-23 20:20:58,676 - Epoch: [264][  100/  123]    Loss 0.702386    Top1 77.593750    Top5 97.281250    
2024-04-23 20:21:01,584 - Epoch: [264][  123/  123]    Loss 0.700231    Top1 77.732484    Top5 97.299363    
2024-04-23 20:21:01,849 - ==> Top1: 77.732    Top5: 97.299    Loss: 0.700

2024-04-23 20:21:01,859 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:21:01,859 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:21:01,907 - 

2024-04-23 20:21:01,908 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:21:14,002 - Epoch: [265][  100/  296]    Overall Loss 0.729443    Objective Loss 0.729443                                        LR 0.000005    Time 0.120763    
2024-04-23 20:21:26,011 - Epoch: [265][  200/  296]    Overall Loss 0.719975    Objective Loss 0.719975                                        LR 0.000005    Time 0.120329    
2024-04-23 20:21:35,913 - Epoch: [265][  296/  296]    Overall Loss 0.721511    Objective Loss 0.721511    Top1 86.885246    Top5 100.000000    LR 0.000005    Time 0.114700    
2024-04-23 20:21:36,089 - --- validate (epoch=265)-----------
2024-04-23 20:21:36,090 - 3925 samples (32 per mini-batch)
2024-04-23 20:21:49,375 - Epoch: [265][  100/  123]    Loss 0.702114    Top1 77.875000    Top5 97.156250    
2024-04-23 20:21:52,391 - Epoch: [265][  123/  123]    Loss 0.701354    Top1 77.630573    Top5 97.248408    
2024-04-23 20:21:52,682 - ==> Top1: 77.631    Top5: 97.248    Loss: 0.701

2024-04-23 20:21:52,691 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:21:52,691 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:21:52,733 - 

2024-04-23 20:21:52,734 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:22:01,451 - Epoch: [266][  100/  296]    Overall Loss 0.737951    Objective Loss 0.737951                                        LR 0.000005    Time 0.087015    
2024-04-23 20:22:08,864 - Epoch: [266][  200/  296]    Overall Loss 0.734756    Objective Loss 0.734756                                        LR 0.000005    Time 0.080497    
2024-04-23 20:22:16,778 - Epoch: [266][  296/  296]    Overall Loss 0.728600    Objective Loss 0.728600    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.081072    
2024-04-23 20:22:17,049 - --- validate (epoch=266)-----------
2024-04-23 20:22:17,050 - 3925 samples (32 per mini-batch)
2024-04-23 20:22:27,965 - Epoch: [266][  100/  123]    Loss 0.702668    Top1 77.406250    Top5 97.156250    
2024-04-23 20:22:30,187 - Epoch: [266][  123/  123]    Loss 0.699609    Top1 77.681529    Top5 97.222930    
2024-04-23 20:22:30,392 - ==> Top1: 77.682    Top5: 97.223    Loss: 0.700

2024-04-23 20:22:30,398 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:22:30,398 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:22:30,433 - 

2024-04-23 20:22:30,434 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:22:40,248 - Epoch: [267][  100/  296]    Overall Loss 0.713913    Objective Loss 0.713913                                        LR 0.000005    Time 0.097963    
2024-04-23 20:22:53,931 - Epoch: [267][  200/  296]    Overall Loss 0.715880    Objective Loss 0.715880                                        LR 0.000005    Time 0.117318    
2024-04-23 20:23:06,552 - Epoch: [267][  296/  296]    Overall Loss 0.724961    Objective Loss 0.724961    Top1 73.770492    Top5 90.163934    LR 0.000005    Time 0.121854    
2024-04-23 20:23:06,805 - --- validate (epoch=267)-----------
2024-04-23 20:23:06,806 - 3925 samples (32 per mini-batch)
2024-04-23 20:23:21,616 - Epoch: [267][  100/  123]    Loss 0.683360    Top1 77.968750    Top5 97.468750    
2024-04-23 20:23:24,777 - Epoch: [267][  123/  123]    Loss 0.699555    Top1 77.681529    Top5 97.248408    
2024-04-23 20:23:25,007 - ==> Top1: 77.682    Top5: 97.248    Loss: 0.700

2024-04-23 20:23:25,018 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:23:25,019 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:23:25,079 - 

2024-04-23 20:23:25,080 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:23:37,973 - Epoch: [268][  100/  296]    Overall Loss 0.719242    Objective Loss 0.719242                                        LR 0.000005    Time 0.128744    
2024-04-23 20:23:48,503 - Epoch: [268][  200/  296]    Overall Loss 0.728676    Objective Loss 0.728676                                        LR 0.000005    Time 0.116940    
2024-04-23 20:23:59,608 - Epoch: [268][  296/  296]    Overall Loss 0.726208    Objective Loss 0.726208    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.116475    
2024-04-23 20:23:59,918 - --- validate (epoch=268)-----------
2024-04-23 20:23:59,919 - 3925 samples (32 per mini-batch)
2024-04-23 20:24:15,220 - Epoch: [268][  100/  123]    Loss 0.695510    Top1 77.750000    Top5 97.250000    
2024-04-23 20:24:18,274 - Epoch: [268][  123/  123]    Loss 0.698820    Top1 77.707006    Top5 97.222930    
2024-04-23 20:24:18,518 - ==> Top1: 77.707    Top5: 97.223    Loss: 0.699

2024-04-23 20:24:18,529 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:24:18,530 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:24:18,581 - 

2024-04-23 20:24:18,582 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:24:33,483 - Epoch: [269][  100/  296]    Overall Loss 0.719875    Objective Loss 0.719875                                        LR 0.000005    Time 0.148833    
2024-04-23 20:24:45,054 - Epoch: [269][  200/  296]    Overall Loss 0.717141    Objective Loss 0.717141                                        LR 0.000005    Time 0.132187    
2024-04-23 20:24:56,324 - Epoch: [269][  296/  296]    Overall Loss 0.721366    Objective Loss 0.721366    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.127336    
2024-04-23 20:24:56,642 - --- validate (epoch=269)-----------
2024-04-23 20:24:56,643 - 3925 samples (32 per mini-batch)
2024-04-23 20:25:11,864 - Epoch: [269][  100/  123]    Loss 0.702776    Top1 77.562500    Top5 97.468750    
2024-04-23 20:25:13,473 - Epoch: [269][  123/  123]    Loss 0.698951    Top1 77.477707    Top5 97.401274    
2024-04-23 20:25:13,572 - ==> Top1: 77.478    Top5: 97.401    Loss: 0.699

2024-04-23 20:25:13,581 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:25:13,581 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:25:13,623 - 

2024-04-23 20:25:13,623 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:25:28,815 - Epoch: [270][  100/  296]    Overall Loss 0.713167    Objective Loss 0.713167                                        LR 0.000005    Time 0.151770    
2024-04-23 20:25:40,637 - Epoch: [270][  200/  296]    Overall Loss 0.713356    Objective Loss 0.713356                                        LR 0.000005    Time 0.134918    
2024-04-23 20:25:51,649 - Epoch: [270][  296/  296]    Overall Loss 0.714759    Objective Loss 0.714759    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.128313    
2024-04-23 20:25:51,946 - --- validate (epoch=270)-----------
2024-04-23 20:25:51,947 - 3925 samples (32 per mini-batch)
2024-04-23 20:26:05,316 - Epoch: [270][  100/  123]    Loss 0.701848    Top1 77.750000    Top5 97.125000    
2024-04-23 20:26:07,968 - Epoch: [270][  123/  123]    Loss 0.700409    Top1 77.936306    Top5 97.222930    
2024-04-23 20:26:08,180 - ==> Top1: 77.936    Top5: 97.223    Loss: 0.700

2024-04-23 20:26:08,189 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:26:08,189 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:26:08,233 - 

2024-04-23 20:26:08,234 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:26:17,591 - Epoch: [271][  100/  296]    Overall Loss 0.747737    Objective Loss 0.747737                                        LR 0.000005    Time 0.093415    
2024-04-23 20:26:27,557 - Epoch: [271][  200/  296]    Overall Loss 0.740353    Objective Loss 0.740353                                        LR 0.000005    Time 0.096461    
2024-04-23 20:26:36,744 - Epoch: [271][  296/  296]    Overall Loss 0.738817    Objective Loss 0.738817    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.096163    
2024-04-23 20:26:36,960 - --- validate (epoch=271)-----------
2024-04-23 20:26:36,961 - 3925 samples (32 per mini-batch)
2024-04-23 20:26:48,794 - Epoch: [271][  100/  123]    Loss 0.707726    Top1 77.750000    Top5 97.000000    
2024-04-23 20:26:50,550 - Epoch: [271][  123/  123]    Loss 0.698721    Top1 77.757962    Top5 97.222930    
2024-04-23 20:26:50,775 - ==> Top1: 77.758    Top5: 97.223    Loss: 0.699

2024-04-23 20:26:50,784 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:26:50,784 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:26:50,826 - 

2024-04-23 20:26:50,827 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:27:00,808 - Epoch: [272][  100/  296]    Overall Loss 0.712229    Objective Loss 0.712229                                        LR 0.000005    Time 0.099639    
2024-04-23 20:27:08,111 - Epoch: [272][  200/  296]    Overall Loss 0.725360    Objective Loss 0.725360                                        LR 0.000005    Time 0.086250    
2024-04-23 20:27:15,417 - Epoch: [272][  296/  296]    Overall Loss 0.724250    Objective Loss 0.724250    Top1 68.852459    Top5 90.163934    LR 0.000005    Time 0.082912    
2024-04-23 20:27:15,633 - --- validate (epoch=272)-----------
2024-04-23 20:27:15,634 - 3925 samples (32 per mini-batch)
2024-04-23 20:27:30,472 - Epoch: [272][  100/  123]    Loss 0.705759    Top1 77.593750    Top5 97.156250    
2024-04-23 20:27:33,764 - Epoch: [272][  123/  123]    Loss 0.703649    Top1 77.554140    Top5 97.222930    
2024-04-23 20:27:33,966 - ==> Top1: 77.554    Top5: 97.223    Loss: 0.704

2024-04-23 20:27:33,974 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:27:33,974 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:27:34,024 - 

2024-04-23 20:27:34,025 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:27:47,235 - Epoch: [273][  100/  296]    Overall Loss 0.730294    Objective Loss 0.730294                                        LR 0.000005    Time 0.131961    
2024-04-23 20:27:57,265 - Epoch: [273][  200/  296]    Overall Loss 0.724884    Objective Loss 0.724884                                        LR 0.000005    Time 0.116052    
2024-04-23 20:28:07,803 - Epoch: [273][  296/  296]    Overall Loss 0.735769    Objective Loss 0.735769    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.113959    
2024-04-23 20:28:08,088 - --- validate (epoch=273)-----------
2024-04-23 20:28:08,089 - 3925 samples (32 per mini-batch)
2024-04-23 20:28:20,096 - Epoch: [273][  100/  123]    Loss 0.696577    Top1 77.906250    Top5 97.156250    
2024-04-23 20:28:23,034 - Epoch: [273][  123/  123]    Loss 0.698469    Top1 77.885350    Top5 97.197452    
2024-04-23 20:28:23,236 - ==> Top1: 77.885    Top5: 97.197    Loss: 0.698

2024-04-23 20:28:23,245 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:28:23,245 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:28:23,287 - 

2024-04-23 20:28:23,288 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:28:35,783 - Epoch: [274][  100/  296]    Overall Loss 0.721710    Objective Loss 0.721710                                        LR 0.000005    Time 0.124772    
2024-04-23 20:28:47,177 - Epoch: [274][  200/  296]    Overall Loss 0.716698    Objective Loss 0.716698                                        LR 0.000005    Time 0.119265    
2024-04-23 20:28:56,088 - Epoch: [274][  296/  296]    Overall Loss 0.707498    Objective Loss 0.707498    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.110641    
2024-04-23 20:28:56,288 - --- validate (epoch=274)-----------
2024-04-23 20:28:56,289 - 3925 samples (32 per mini-batch)
2024-04-23 20:29:13,030 - Epoch: [274][  100/  123]    Loss 0.706055    Top1 77.750000    Top5 97.093750    
2024-04-23 20:29:16,453 - Epoch: [274][  123/  123]    Loss 0.699469    Top1 77.757962    Top5 97.197452    
2024-04-23 20:29:16,610 - ==> Top1: 77.758    Top5: 97.197    Loss: 0.699

2024-04-23 20:29:16,620 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:29:16,621 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:29:16,667 - 

2024-04-23 20:29:16,667 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:29:28,234 - Epoch: [275][  100/  296]    Overall Loss 0.745977    Objective Loss 0.745977                                        LR 0.000005    Time 0.115505    
2024-04-23 20:29:39,551 - Epoch: [275][  200/  296]    Overall Loss 0.729899    Objective Loss 0.729899                                        LR 0.000005    Time 0.114249    
2024-04-23 20:29:50,168 - Epoch: [275][  296/  296]    Overall Loss 0.721745    Objective Loss 0.721745    Top1 72.131148    Top5 91.803279    LR 0.000005    Time 0.113009    
2024-04-23 20:29:50,465 - --- validate (epoch=275)-----------
2024-04-23 20:29:50,466 - 3925 samples (32 per mini-batch)
2024-04-23 20:30:05,597 - Epoch: [275][  100/  123]    Loss 0.724187    Top1 76.781250    Top5 97.187500    
2024-04-23 20:30:08,793 - Epoch: [275][  123/  123]    Loss 0.702605    Top1 77.554140    Top5 97.222930    
2024-04-23 20:30:09,322 - ==> Top1: 77.554    Top5: 97.223    Loss: 0.703

2024-04-23 20:30:09,330 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:30:09,331 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:30:09,385 - 

2024-04-23 20:30:09,385 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:30:22,591 - Epoch: [276][  100/  296]    Overall Loss 0.720436    Objective Loss 0.720436                                        LR 0.000005    Time 0.131886    
2024-04-23 20:30:34,069 - Epoch: [276][  200/  296]    Overall Loss 0.719808    Objective Loss 0.719808                                        LR 0.000005    Time 0.123243    
2024-04-23 20:30:44,821 - Epoch: [276][  296/  296]    Overall Loss 0.720129    Objective Loss 0.720129    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.119546    
2024-04-23 20:30:45,222 - --- validate (epoch=276)-----------
2024-04-23 20:30:45,223 - 3925 samples (32 per mini-batch)
2024-04-23 20:30:58,533 - Epoch: [276][  100/  123]    Loss 0.707690    Top1 77.625000    Top5 97.156250    
2024-04-23 20:31:00,830 - Epoch: [276][  123/  123]    Loss 0.702515    Top1 77.783439    Top5 97.248408    
2024-04-23 20:31:01,060 - ==> Top1: 77.783    Top5: 97.248    Loss: 0.703

2024-04-23 20:31:01,068 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:31:01,069 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:31:01,113 - 

2024-04-23 20:31:01,113 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:31:11,388 - Epoch: [277][  100/  296]    Overall Loss 0.706232    Objective Loss 0.706232                                        LR 0.000005    Time 0.102597    
2024-04-23 20:31:23,447 - Epoch: [277][  200/  296]    Overall Loss 0.709754    Objective Loss 0.709754                                        LR 0.000005    Time 0.111497    
2024-04-23 20:31:33,720 - Epoch: [277][  296/  296]    Overall Loss 0.716175    Objective Loss 0.716175    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.109992    
2024-04-23 20:31:33,906 - --- validate (epoch=277)-----------
2024-04-23 20:31:33,907 - 3925 samples (32 per mini-batch)
2024-04-23 20:31:46,952 - Epoch: [277][  100/  123]    Loss 0.688942    Top1 78.218750    Top5 97.187500    
2024-04-23 20:31:49,710 - Epoch: [277][  123/  123]    Loss 0.698807    Top1 77.808917    Top5 97.299363    
2024-04-23 20:31:49,862 - ==> Top1: 77.809    Top5: 97.299    Loss: 0.699

2024-04-23 20:31:49,870 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:31:49,871 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:31:49,914 - 

2024-04-23 20:31:49,915 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:32:02,891 - Epoch: [278][  100/  296]    Overall Loss 0.724865    Objective Loss 0.724865                                        LR 0.000005    Time 0.129573    
2024-04-23 20:32:11,818 - Epoch: [278][  200/  296]    Overall Loss 0.712313    Objective Loss 0.712313                                        LR 0.000005    Time 0.109343    
2024-04-23 20:32:20,290 - Epoch: [278][  296/  296]    Overall Loss 0.706183    Objective Loss 0.706183    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.102449    
2024-04-23 20:32:20,403 - --- validate (epoch=278)-----------
2024-04-23 20:32:20,404 - 3925 samples (32 per mini-batch)
2024-04-23 20:32:34,867 - Epoch: [278][  100/  123]    Loss 0.706440    Top1 77.750000    Top5 97.437500    
2024-04-23 20:32:37,143 - Epoch: [278][  123/  123]    Loss 0.696468    Top1 77.987261    Top5 97.401274    
2024-04-23 20:32:37,294 - ==> Top1: 77.987    Top5: 97.401    Loss: 0.696

2024-04-23 20:32:37,308 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:32:37,309 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:32:37,351 - 

2024-04-23 20:32:37,352 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:32:47,783 - Epoch: [279][  100/  296]    Overall Loss 0.718606    Objective Loss 0.718606                                        LR 0.000005    Time 0.104151    
2024-04-23 20:32:55,908 - Epoch: [279][  200/  296]    Overall Loss 0.718517    Objective Loss 0.718517                                        LR 0.000005    Time 0.092617    
2024-04-23 20:33:03,975 - Epoch: [279][  296/  296]    Overall Loss 0.717231    Objective Loss 0.717231    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.089789    
2024-04-23 20:33:04,108 - --- validate (epoch=279)-----------
2024-04-23 20:33:04,109 - 3925 samples (32 per mini-batch)
2024-04-23 20:33:14,871 - Epoch: [279][  100/  123]    Loss 0.687610    Top1 78.593750    Top5 97.375000    
2024-04-23 20:33:16,944 - Epoch: [279][  123/  123]    Loss 0.698293    Top1 77.910828    Top5 97.350318    
2024-04-23 20:33:17,061 - ==> Top1: 77.911    Top5: 97.350    Loss: 0.698

2024-04-23 20:33:17,069 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:33:17,070 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:33:17,107 - 

2024-04-23 20:33:17,108 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:33:25,254 - Epoch: [280][  100/  296]    Overall Loss 0.746304    Objective Loss 0.746304                                        LR 0.000005    Time 0.081332    
2024-04-23 20:33:36,378 - Epoch: [280][  200/  296]    Overall Loss 0.730051    Objective Loss 0.730051                                        LR 0.000005    Time 0.096192    
2024-04-23 20:33:46,274 - Epoch: [280][  296/  296]    Overall Loss 0.715953    Objective Loss 0.715953    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.098373    
2024-04-23 20:33:46,410 - --- validate (epoch=280)-----------
2024-04-23 20:33:46,411 - 3925 samples (32 per mini-batch)
2024-04-23 20:34:00,947 - Epoch: [280][  100/  123]    Loss 0.711554    Top1 77.562500    Top5 97.343750    
2024-04-23 20:34:03,854 - Epoch: [280][  123/  123]    Loss 0.700540    Top1 77.605096    Top5 97.299363    
2024-04-23 20:34:04,498 - ==> Top1: 77.605    Top5: 97.299    Loss: 0.701

2024-04-23 20:34:04,507 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:34:04,508 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:34:04,567 - 

2024-04-23 20:34:04,568 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:34:19,093 - Epoch: [281][  100/  296]    Overall Loss 0.730794    Objective Loss 0.730794                                        LR 0.000005    Time 0.145064    
2024-04-23 20:34:29,966 - Epoch: [281][  200/  296]    Overall Loss 0.709339    Objective Loss 0.709339                                        LR 0.000005    Time 0.126825    
2024-04-23 20:34:43,013 - Epoch: [281][  296/  296]    Overall Loss 0.701059    Objective Loss 0.701059    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.129711    
2024-04-23 20:34:43,338 - --- validate (epoch=281)-----------
2024-04-23 20:34:43,339 - 3925 samples (32 per mini-batch)
2024-04-23 20:35:00,262 - Epoch: [281][  100/  123]    Loss 0.710806    Top1 77.406250    Top5 97.375000    
2024-04-23 20:35:03,196 - Epoch: [281][  123/  123]    Loss 0.698136    Top1 77.732484    Top5 97.299363    
2024-04-23 20:35:03,461 - ==> Top1: 77.732    Top5: 97.299    Loss: 0.698

2024-04-23 20:35:03,472 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:35:03,473 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:35:03,521 - 

2024-04-23 20:35:03,522 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:35:17,639 - Epoch: [282][  100/  296]    Overall Loss 0.702544    Objective Loss 0.702544                                        LR 0.000005    Time 0.140990    
2024-04-23 20:35:29,479 - Epoch: [282][  200/  296]    Overall Loss 0.704744    Objective Loss 0.704744                                        LR 0.000005    Time 0.129623    
2024-04-23 20:35:42,287 - Epoch: [282][  296/  296]    Overall Loss 0.714327    Objective Loss 0.714327    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.130803    
2024-04-23 20:35:42,431 - --- validate (epoch=282)-----------
2024-04-23 20:35:42,432 - 3925 samples (32 per mini-batch)
2024-04-23 20:35:56,915 - Epoch: [282][  100/  123]    Loss 0.699323    Top1 77.781250    Top5 97.218750    
2024-04-23 20:35:59,909 - Epoch: [282][  123/  123]    Loss 0.699978    Top1 77.757962    Top5 97.299363    
2024-04-23 20:36:00,120 - ==> Top1: 77.758    Top5: 97.299    Loss: 0.700

2024-04-23 20:36:00,130 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:36:00,131 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:36:00,183 - 

2024-04-23 20:36:00,184 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:36:15,030 - Epoch: [283][  100/  296]    Overall Loss 0.741190    Objective Loss 0.741190                                        LR 0.000005    Time 0.148285    
2024-04-23 20:36:26,872 - Epoch: [283][  200/  296]    Overall Loss 0.724980    Objective Loss 0.724980                                        LR 0.000005    Time 0.133268    
2024-04-23 20:36:38,419 - Epoch: [283][  296/  296]    Overall Loss 0.724702    Objective Loss 0.724702    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.129006    
2024-04-23 20:36:38,766 - --- validate (epoch=283)-----------
2024-04-23 20:36:38,767 - 3925 samples (32 per mini-batch)
2024-04-23 20:36:55,253 - Epoch: [283][  100/  123]    Loss 0.699414    Top1 77.593750    Top5 97.187500    
2024-04-23 20:36:58,089 - Epoch: [283][  123/  123]    Loss 0.698554    Top1 77.503185    Top5 97.350318    
2024-04-23 20:36:58,423 - ==> Top1: 77.503    Top5: 97.350    Loss: 0.699

2024-04-23 20:36:58,436 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:36:58,437 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:36:58,491 - 

2024-04-23 20:36:58,492 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:37:08,719 - Epoch: [284][  100/  296]    Overall Loss 0.717495    Objective Loss 0.717495                                        LR 0.000005    Time 0.102088    
2024-04-23 20:37:18,001 - Epoch: [284][  200/  296]    Overall Loss 0.701198    Objective Loss 0.701198                                        LR 0.000005    Time 0.097366    
2024-04-23 20:37:29,608 - Epoch: [284][  296/  296]    Overall Loss 0.709144    Objective Loss 0.709144    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.104950    
2024-04-23 20:37:29,813 - --- validate (epoch=284)-----------
2024-04-23 20:37:29,815 - 3925 samples (32 per mini-batch)
2024-04-23 20:37:44,220 - Epoch: [284][  100/  123]    Loss 0.690255    Top1 77.906250    Top5 97.343750    
2024-04-23 20:37:47,117 - Epoch: [284][  123/  123]    Loss 0.697287    Top1 77.707006    Top5 97.350318    
2024-04-23 20:37:47,407 - ==> Top1: 77.707    Top5: 97.350    Loss: 0.697

2024-04-23 20:37:47,415 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:37:47,416 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:37:47,462 - 

2024-04-23 20:37:47,463 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:38:00,513 - Epoch: [285][  100/  296]    Overall Loss 0.701528    Objective Loss 0.701528                                        LR 0.000005    Time 0.130329    
2024-04-23 20:38:09,487 - Epoch: [285][  200/  296]    Overall Loss 0.720053    Objective Loss 0.720053                                        LR 0.000005    Time 0.109955    
2024-04-23 20:38:18,217 - Epoch: [285][  296/  296]    Overall Loss 0.729414    Objective Loss 0.729414    Top1 88.524590    Top5 98.360656    LR 0.000005    Time 0.103735    
2024-04-23 20:38:18,543 - --- validate (epoch=285)-----------
2024-04-23 20:38:18,544 - 3925 samples (32 per mini-batch)
2024-04-23 20:38:30,912 - Epoch: [285][  100/  123]    Loss 0.715728    Top1 77.281250    Top5 97.000000    
2024-04-23 20:38:33,670 - Epoch: [285][  123/  123]    Loss 0.698117    Top1 77.859873    Top5 97.197452    
2024-04-23 20:38:33,935 - ==> Top1: 77.860    Top5: 97.197    Loss: 0.698

2024-04-23 20:38:33,945 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:38:33,946 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:38:33,992 - 

2024-04-23 20:38:33,992 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:38:44,377 - Epoch: [286][  100/  296]    Overall Loss 0.725772    Objective Loss 0.725772                                        LR 0.000005    Time 0.103666    
2024-04-23 20:38:53,834 - Epoch: [286][  200/  296]    Overall Loss 0.711153    Objective Loss 0.711153                                        LR 0.000005    Time 0.099033    
2024-04-23 20:39:01,494 - Epoch: [286][  296/  296]    Overall Loss 0.708585    Objective Loss 0.708585    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.092740    
2024-04-23 20:39:01,768 - --- validate (epoch=286)-----------
2024-04-23 20:39:01,768 - 3925 samples (32 per mini-batch)
2024-04-23 20:39:14,754 - Epoch: [286][  100/  123]    Loss 0.698153    Top1 77.906250    Top5 97.218750    
2024-04-23 20:39:17,188 - Epoch: [286][  123/  123]    Loss 0.701973    Top1 77.732484    Top5 97.273885    
2024-04-23 20:39:17,501 - ==> Top1: 77.732    Top5: 97.274    Loss: 0.702

2024-04-23 20:39:17,511 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:39:17,512 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:39:17,558 - 

2024-04-23 20:39:17,559 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:39:27,655 - Epoch: [287][  100/  296]    Overall Loss 0.741118    Objective Loss 0.741118                                        LR 0.000005    Time 0.100794    
2024-04-23 20:39:36,629 - Epoch: [287][  200/  296]    Overall Loss 0.717924    Objective Loss 0.717924                                        LR 0.000005    Time 0.095177    
2024-04-23 20:39:43,705 - Epoch: [287][  296/  296]    Overall Loss 0.716614    Objective Loss 0.716614    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.088164    
2024-04-23 20:39:43,963 - --- validate (epoch=287)-----------
2024-04-23 20:39:43,964 - 3925 samples (32 per mini-batch)
2024-04-23 20:39:57,892 - Epoch: [287][  100/  123]    Loss 0.684531    Top1 77.812500    Top5 97.468750    
2024-04-23 20:40:00,288 - Epoch: [287][  123/  123]    Loss 0.700955    Top1 77.630573    Top5 97.350318    
2024-04-23 20:40:00,513 - ==> Top1: 77.631    Top5: 97.350    Loss: 0.701

2024-04-23 20:40:00,520 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:40:00,521 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:40:00,581 - 

2024-04-23 20:40:00,582 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:40:10,096 - Epoch: [288][  100/  296]    Overall Loss 0.729276    Objective Loss 0.729276                                        LR 0.000005    Time 0.094968    
2024-04-23 20:40:17,424 - Epoch: [288][  200/  296]    Overall Loss 0.726236    Objective Loss 0.726236                                        LR 0.000005    Time 0.084042    
2024-04-23 20:40:24,482 - Epoch: [288][  296/  296]    Overall Loss 0.727549    Objective Loss 0.727549    Top1 72.131148    Top5 100.000000    LR 0.000005    Time 0.080573    
2024-04-23 20:40:24,711 - --- validate (epoch=288)-----------
2024-04-23 20:40:24,712 - 3925 samples (32 per mini-batch)
2024-04-23 20:40:35,265 - Epoch: [288][  100/  123]    Loss 0.700391    Top1 78.093750    Top5 97.250000    
2024-04-23 20:40:38,196 - Epoch: [288][  123/  123]    Loss 0.700600    Top1 77.732484    Top5 97.197452    
2024-04-23 20:40:38,364 - ==> Top1: 77.732    Top5: 97.197    Loss: 0.701

2024-04-23 20:40:38,377 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:40:38,377 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:40:38,445 - 

2024-04-23 20:40:38,447 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:40:49,500 - Epoch: [289][  100/  296]    Overall Loss 0.724841    Objective Loss 0.724841                                        LR 0.000005    Time 0.110334    
2024-04-23 20:40:58,517 - Epoch: [289][  200/  296]    Overall Loss 0.725787    Objective Loss 0.725787                                        LR 0.000005    Time 0.100171    
2024-04-23 20:41:07,467 - Epoch: [289][  296/  296]    Overall Loss 0.724529    Objective Loss 0.724529    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.097864    
2024-04-23 20:41:07,711 - --- validate (epoch=289)-----------
2024-04-23 20:41:07,712 - 3925 samples (32 per mini-batch)
2024-04-23 20:41:20,203 - Epoch: [289][  100/  123]    Loss 0.693615    Top1 77.906250    Top5 97.312500    
2024-04-23 20:41:22,928 - Epoch: [289][  123/  123]    Loss 0.699955    Top1 77.757962    Top5 97.171975    
2024-04-23 20:41:23,196 - ==> Top1: 77.758    Top5: 97.172    Loss: 0.700

2024-04-23 20:41:23,204 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:41:23,205 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:41:23,246 - 

2024-04-23 20:41:23,247 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:41:34,043 - Epoch: [290][  100/  296]    Overall Loss 0.715744    Objective Loss 0.715744                                        LR 0.000005    Time 0.107805    
2024-04-23 20:41:43,083 - Epoch: [290][  200/  296]    Overall Loss 0.727715    Objective Loss 0.727715                                        LR 0.000005    Time 0.099025    
2024-04-23 20:41:51,698 - Epoch: [290][  296/  296]    Overall Loss 0.713657    Objective Loss 0.713657    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.095956    
2024-04-23 20:41:51,938 - --- validate (epoch=290)-----------
2024-04-23 20:41:51,939 - 3925 samples (32 per mini-batch)
2024-04-23 20:42:06,264 - Epoch: [290][  100/  123]    Loss 0.689816    Top1 77.718750    Top5 97.343750    
2024-04-23 20:42:08,508 - Epoch: [290][  123/  123]    Loss 0.700169    Top1 77.808917    Top5 97.146497    
2024-04-23 20:42:08,774 - ==> Top1: 77.809    Top5: 97.146    Loss: 0.700

2024-04-23 20:42:08,784 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:42:08,784 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:42:08,825 - 

2024-04-23 20:42:08,826 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:42:21,318 - Epoch: [291][  100/  296]    Overall Loss 0.703722    Objective Loss 0.703722                                        LR 0.000005    Time 0.124750    
2024-04-23 20:42:32,224 - Epoch: [291][  200/  296]    Overall Loss 0.720162    Objective Loss 0.720162                                        LR 0.000005    Time 0.116816    
2024-04-23 20:42:43,071 - Epoch: [291][  296/  296]    Overall Loss 0.723371    Objective Loss 0.723371    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.115516    
2024-04-23 20:42:43,353 - --- validate (epoch=291)-----------
2024-04-23 20:42:43,354 - 3925 samples (32 per mini-batch)
2024-04-23 20:42:57,398 - Epoch: [291][  100/  123]    Loss 0.687595    Top1 77.718750    Top5 97.531250    
2024-04-23 20:42:59,670 - Epoch: [291][  123/  123]    Loss 0.698805    Top1 77.707006    Top5 97.375796    
2024-04-23 20:42:59,943 - ==> Top1: 77.707    Top5: 97.376    Loss: 0.699

2024-04-23 20:42:59,953 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:42:59,953 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:42:59,997 - 

2024-04-23 20:42:59,998 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:43:10,302 - Epoch: [292][  100/  296]    Overall Loss 0.721346    Objective Loss 0.721346                                        LR 0.000005    Time 0.102874    
2024-04-23 20:43:19,994 - Epoch: [292][  200/  296]    Overall Loss 0.710680    Objective Loss 0.710680                                        LR 0.000005    Time 0.099815    
2024-04-23 20:43:28,069 - Epoch: [292][  296/  296]    Overall Loss 0.709186    Objective Loss 0.709186    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.094672    
2024-04-23 20:43:28,301 - --- validate (epoch=292)-----------
2024-04-23 20:43:28,302 - 3925 samples (32 per mini-batch)
2024-04-23 20:43:40,525 - Epoch: [292][  100/  123]    Loss 0.693256    Top1 77.875000    Top5 97.250000    
2024-04-23 20:43:42,920 - Epoch: [292][  123/  123]    Loss 0.701023    Top1 77.834395    Top5 97.222930    
2024-04-23 20:43:43,150 - ==> Top1: 77.834    Top5: 97.223    Loss: 0.701

2024-04-23 20:43:43,159 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:43:43,159 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:43:43,203 - 

2024-04-23 20:43:43,204 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:43:59,358 - Epoch: [293][  100/  296]    Overall Loss 0.702763    Objective Loss 0.702763                                        LR 0.000005    Time 0.161367    
2024-04-23 20:44:13,112 - Epoch: [293][  200/  296]    Overall Loss 0.704522    Objective Loss 0.704522                                        LR 0.000005    Time 0.149368    
2024-04-23 20:44:25,022 - Epoch: [293][  296/  296]    Overall Loss 0.710077    Objective Loss 0.710077    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.141110    
2024-04-23 20:44:25,282 - --- validate (epoch=293)-----------
2024-04-23 20:44:25,283 - 3925 samples (32 per mini-batch)
2024-04-23 20:44:39,581 - Epoch: [293][  100/  123]    Loss 0.704378    Top1 77.593750    Top5 97.343750    
2024-04-23 20:44:43,058 - Epoch: [293][  123/  123]    Loss 0.697093    Top1 77.630573    Top5 97.350318    
2024-04-23 20:44:43,288 - ==> Top1: 77.631    Top5: 97.350    Loss: 0.697

2024-04-23 20:44:43,294 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:44:43,294 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:44:43,330 - 

2024-04-23 20:44:43,331 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:44:54,598 - Epoch: [294][  100/  296]    Overall Loss 0.714496    Objective Loss 0.714496                                        LR 0.000005    Time 0.112512    
2024-04-23 20:45:01,690 - Epoch: [294][  200/  296]    Overall Loss 0.718248    Objective Loss 0.718248                                        LR 0.000005    Time 0.091629    
2024-04-23 20:45:09,386 - Epoch: [294][  296/  296]    Overall Loss 0.720615    Objective Loss 0.720615    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.087860    
2024-04-23 20:45:09,632 - --- validate (epoch=294)-----------
2024-04-23 20:45:09,633 - 3925 samples (32 per mini-batch)
2024-04-23 20:45:20,753 - Epoch: [294][  100/  123]    Loss 0.699390    Top1 77.812500    Top5 97.218750    
2024-04-23 20:45:22,980 - Epoch: [294][  123/  123]    Loss 0.702407    Top1 77.528662    Top5 97.197452    
2024-04-23 20:45:23,198 - ==> Top1: 77.529    Top5: 97.197    Loss: 0.702

2024-04-23 20:45:23,206 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:45:23,207 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:45:23,243 - 

2024-04-23 20:45:23,244 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:45:34,981 - Epoch: [295][  100/  296]    Overall Loss 0.726366    Objective Loss 0.726366                                        LR 0.000005    Time 0.117206    
2024-04-23 20:45:43,317 - Epoch: [295][  200/  296]    Overall Loss 0.717221    Objective Loss 0.717221                                        LR 0.000005    Time 0.100201    
2024-04-23 20:45:51,107 - Epoch: [295][  296/  296]    Overall Loss 0.711525    Objective Loss 0.711525    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.093971    
2024-04-23 20:45:51,441 - --- validate (epoch=295)-----------
2024-04-23 20:45:51,442 - 3925 samples (32 per mini-batch)
2024-04-23 20:46:01,893 - Epoch: [295][  100/  123]    Loss 0.705573    Top1 77.718750    Top5 97.218750    
2024-04-23 20:46:03,959 - Epoch: [295][  123/  123]    Loss 0.699952    Top1 77.757962    Top5 97.324841    
2024-04-23 20:46:04,203 - ==> Top1: 77.758    Top5: 97.325    Loss: 0.700

2024-04-23 20:46:04,208 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:46:04,208 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:46:04,246 - 

2024-04-23 20:46:04,246 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:46:14,509 - Epoch: [296][  100/  296]    Overall Loss 0.741779    Objective Loss 0.741779                                        LR 0.000005    Time 0.102457    
2024-04-23 20:46:24,954 - Epoch: [296][  200/  296]    Overall Loss 0.723217    Objective Loss 0.723217                                        LR 0.000005    Time 0.103372    
2024-04-23 20:46:35,347 - Epoch: [296][  296/  296]    Overall Loss 0.720868    Objective Loss 0.720868    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.104906    
2024-04-23 20:46:35,510 - --- validate (epoch=296)-----------
2024-04-23 20:46:35,511 - 3925 samples (32 per mini-batch)
2024-04-23 20:46:49,469 - Epoch: [296][  100/  123]    Loss 0.695052    Top1 77.906250    Top5 97.343750    
2024-04-23 20:46:52,330 - Epoch: [296][  123/  123]    Loss 0.700964    Top1 77.885350    Top5 97.375796    
2024-04-23 20:46:52,627 - ==> Top1: 77.885    Top5: 97.376    Loss: 0.701

2024-04-23 20:46:52,631 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:46:52,631 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:46:52,658 - 

2024-04-23 20:46:52,658 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:47:05,096 - Epoch: [297][  100/  296]    Overall Loss 0.701301    Objective Loss 0.701301                                        LR 0.000005    Time 0.124217    
2024-04-23 20:47:15,883 - Epoch: [297][  200/  296]    Overall Loss 0.725654    Objective Loss 0.725654                                        LR 0.000005    Time 0.115957    
2024-04-23 20:47:24,268 - Epoch: [297][  296/  296]    Overall Loss 0.725107    Objective Loss 0.725107    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.106625    
2024-04-23 20:47:24,493 - --- validate (epoch=297)-----------
2024-04-23 20:47:24,494 - 3925 samples (32 per mini-batch)
2024-04-23 20:47:36,661 - Epoch: [297][  100/  123]    Loss 0.686963    Top1 78.062500    Top5 97.312500    
2024-04-23 20:47:39,034 - Epoch: [297][  123/  123]    Loss 0.698261    Top1 77.630573    Top5 97.324841    
2024-04-23 20:47:39,300 - ==> Top1: 77.631    Top5: 97.325    Loss: 0.698

2024-04-23 20:47:39,309 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:47:39,310 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:47:39,349 - 

2024-04-23 20:47:39,350 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:47:51,853 - Epoch: [298][  100/  296]    Overall Loss 0.712916    Objective Loss 0.712916                                        LR 0.000005    Time 0.124869    
2024-04-23 20:48:02,582 - Epoch: [298][  200/  296]    Overall Loss 0.704981    Objective Loss 0.704981                                        LR 0.000005    Time 0.115976    
2024-04-23 20:48:10,227 - Epoch: [298][  296/  296]    Overall Loss 0.708515    Objective Loss 0.708515    Top1 67.213115    Top5 96.721311    LR 0.000005    Time 0.104143    
2024-04-23 20:48:10,512 - --- validate (epoch=298)-----------
2024-04-23 20:48:10,513 - 3925 samples (32 per mini-batch)
2024-04-23 20:48:24,016 - Epoch: [298][  100/  123]    Loss 0.708357    Top1 77.750000    Top5 97.250000    
2024-04-23 20:48:26,773 - Epoch: [298][  123/  123]    Loss 0.702153    Top1 77.707006    Top5 97.299363    
2024-04-23 20:48:26,957 - ==> Top1: 77.707    Top5: 97.299    Loss: 0.702

2024-04-23 20:48:26,966 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:48:26,967 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:48:27,012 - 

2024-04-23 20:48:27,013 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:48:41,375 - Epoch: [299][  100/  296]    Overall Loss 0.723907    Objective Loss 0.723907                                        LR 0.000005    Time 0.143440    
2024-04-23 20:48:52,723 - Epoch: [299][  200/  296]    Overall Loss 0.714933    Objective Loss 0.714933                                        LR 0.000005    Time 0.128375    
2024-04-23 20:49:02,503 - Epoch: [299][  296/  296]    Overall Loss 0.709529    Objective Loss 0.709529    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.119732    
2024-04-23 20:49:02,735 - --- validate (epoch=299)-----------
2024-04-23 20:49:02,736 - 3925 samples (32 per mini-batch)
2024-04-23 20:49:11,180 - Epoch: [299][  100/  123]    Loss 0.696201    Top1 77.750000    Top5 97.531250    
2024-04-23 20:49:12,756 - Epoch: [299][  123/  123]    Loss 0.702131    Top1 77.656051    Top5 97.401274    
2024-04-23 20:49:13,046 - ==> Top1: 77.656    Top5: 97.401    Loss: 0.702

2024-04-23 20:49:13,055 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:49:13,056 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:49:13,093 - 

2024-04-23 20:49:13,094 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:49:21,455 - Epoch: [300][  100/  296]    Overall Loss 0.739922    Objective Loss 0.739922                                        LR 0.000005    Time 0.083459    
2024-04-23 20:49:28,343 - Epoch: [300][  200/  296]    Overall Loss 0.729380    Objective Loss 0.729380                                        LR 0.000005    Time 0.076094    
2024-04-23 20:49:35,354 - Epoch: [300][  296/  296]    Overall Loss 0.728828    Objective Loss 0.728828    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.075050    
2024-04-23 20:49:35,562 - --- validate (epoch=300)-----------
2024-04-23 20:49:35,563 - 3925 samples (32 per mini-batch)
2024-04-23 20:49:44,599 - Epoch: [300][  100/  123]    Loss 0.703158    Top1 77.593750    Top5 97.343750    
2024-04-23 20:49:46,376 - Epoch: [300][  123/  123]    Loss 0.699173    Top1 77.630573    Top5 97.299363    
2024-04-23 20:49:46,567 - ==> Top1: 77.631    Top5: 97.299    Loss: 0.699

2024-04-23 20:49:46,572 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:49:46,572 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:49:46,600 - 

2024-04-23 20:49:46,601 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:49:56,050 - Epoch: [301][  100/  296]    Overall Loss 0.727858    Objective Loss 0.727858                                        LR 0.000005    Time 0.094342    
2024-04-23 20:50:05,559 - Epoch: [301][  200/  296]    Overall Loss 0.707743    Objective Loss 0.707743                                        LR 0.000005    Time 0.094627    
2024-04-23 20:50:12,908 - Epoch: [301][  296/  296]    Overall Loss 0.709416    Objective Loss 0.709416    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.088715    
2024-04-23 20:50:13,145 - --- validate (epoch=301)-----------
2024-04-23 20:50:13,146 - 3925 samples (32 per mini-batch)
2024-04-23 20:50:23,431 - Epoch: [301][  100/  123]    Loss 0.699290    Top1 77.406250    Top5 97.218750    
2024-04-23 20:50:26,918 - Epoch: [301][  123/  123]    Loss 0.698321    Top1 77.681529    Top5 97.299363    
2024-04-23 20:50:27,105 - ==> Top1: 77.682    Top5: 97.299    Loss: 0.698

2024-04-23 20:50:27,112 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:50:27,113 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:50:27,157 - 

2024-04-23 20:50:27,158 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:50:41,514 - Epoch: [302][  100/  296]    Overall Loss 0.691428    Objective Loss 0.691428                                        LR 0.000005    Time 0.143389    
2024-04-23 20:50:54,137 - Epoch: [302][  200/  296]    Overall Loss 0.711805    Objective Loss 0.711805                                        LR 0.000005    Time 0.134725    
2024-04-23 20:51:05,234 - Epoch: [302][  296/  296]    Overall Loss 0.715128    Objective Loss 0.715128    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.128461    
2024-04-23 20:51:05,512 - --- validate (epoch=302)-----------
2024-04-23 20:51:05,513 - 3925 samples (32 per mini-batch)
2024-04-23 20:51:20,408 - Epoch: [302][  100/  123]    Loss 0.691447    Top1 77.656250    Top5 97.468750    
2024-04-23 20:51:23,341 - Epoch: [302][  123/  123]    Loss 0.703480    Top1 77.477707    Top5 97.350318    
2024-04-23 20:51:23,708 - ==> Top1: 77.478    Top5: 97.350    Loss: 0.703

2024-04-23 20:51:23,716 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:51:23,716 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:51:23,772 - 

2024-04-23 20:51:23,773 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:51:38,960 - Epoch: [303][  100/  296]    Overall Loss 0.719446    Objective Loss 0.719446                                        LR 0.000005    Time 0.151692    
2024-04-23 20:51:51,452 - Epoch: [303][  200/  296]    Overall Loss 0.707192    Objective Loss 0.707192                                        LR 0.000005    Time 0.138231    
2024-04-23 20:52:02,485 - Epoch: [303][  296/  296]    Overall Loss 0.715007    Objective Loss 0.715007    Top1 70.491803    Top5 98.360656    LR 0.000005    Time 0.130617    
2024-04-23 20:52:02,758 - --- validate (epoch=303)-----------
2024-04-23 20:52:02,759 - 3925 samples (32 per mini-batch)
2024-04-23 20:52:17,691 - Epoch: [303][  100/  123]    Loss 0.697390    Top1 77.437500    Top5 97.406250    
2024-04-23 20:52:20,418 - Epoch: [303][  123/  123]    Loss 0.700188    Top1 77.554140    Top5 97.324841    
2024-04-23 20:52:20,680 - ==> Top1: 77.554    Top5: 97.325    Loss: 0.700

2024-04-23 20:52:20,690 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:52:20,691 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:52:20,736 - 

2024-04-23 20:52:20,737 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:52:32,348 - Epoch: [304][  100/  296]    Overall Loss 0.705925    Objective Loss 0.705925                                        LR 0.000005    Time 0.115930    
2024-04-23 20:52:42,779 - Epoch: [304][  200/  296]    Overall Loss 0.706481    Objective Loss 0.706481                                        LR 0.000005    Time 0.110037    
2024-04-23 20:52:50,218 - Epoch: [304][  296/  296]    Overall Loss 0.706643    Objective Loss 0.706643    Top1 68.852459    Top5 95.081967    LR 0.000005    Time 0.099432    
2024-04-23 20:52:50,467 - --- validate (epoch=304)-----------
2024-04-23 20:52:50,468 - 3925 samples (32 per mini-batch)
2024-04-23 20:53:02,118 - Epoch: [304][  100/  123]    Loss 0.705087    Top1 77.468750    Top5 97.281250    
2024-04-23 20:53:04,151 - Epoch: [304][  123/  123]    Loss 0.699915    Top1 77.630573    Top5 97.273885    
2024-04-23 20:53:04,391 - ==> Top1: 77.631    Top5: 97.274    Loss: 0.700

2024-04-23 20:53:04,400 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:53:04,400 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:53:04,437 - 

2024-04-23 20:53:04,438 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:53:15,265 - Epoch: [305][  100/  296]    Overall Loss 0.698686    Objective Loss 0.698686                                        LR 0.000005    Time 0.108087    
2024-04-23 20:53:25,918 - Epoch: [305][  200/  296]    Overall Loss 0.704249    Objective Loss 0.704249                                        LR 0.000005    Time 0.107223    
2024-04-23 20:53:34,646 - Epoch: [305][  296/  296]    Overall Loss 0.716875    Objective Loss 0.716875    Top1 72.131148    Top5 100.000000    LR 0.000005    Time 0.101889    
2024-04-23 20:53:34,918 - --- validate (epoch=305)-----------
2024-04-23 20:53:34,920 - 3925 samples (32 per mini-batch)
2024-04-23 20:53:46,985 - Epoch: [305][  100/  123]    Loss 0.705958    Top1 77.625000    Top5 97.156250    
2024-04-23 20:53:49,300 - Epoch: [305][  123/  123]    Loss 0.700779    Top1 77.732484    Top5 97.095541    
2024-04-23 20:53:49,501 - ==> Top1: 77.732    Top5: 97.096    Loss: 0.701

2024-04-23 20:53:49,508 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:53:49,509 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:53:49,556 - 

2024-04-23 20:53:49,557 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:53:59,577 - Epoch: [306][  100/  296]    Overall Loss 0.724460    Objective Loss 0.724460                                        LR 0.000005    Time 0.100045    
2024-04-23 20:54:08,121 - Epoch: [306][  200/  296]    Overall Loss 0.723096    Objective Loss 0.723096                                        LR 0.000005    Time 0.092662    
2024-04-23 20:54:17,962 - Epoch: [306][  296/  296]    Overall Loss 0.718567    Objective Loss 0.718567    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.095808    
2024-04-23 20:54:18,182 - --- validate (epoch=306)-----------
2024-04-23 20:54:18,183 - 3925 samples (32 per mini-batch)
2024-04-23 20:54:31,481 - Epoch: [306][  100/  123]    Loss 0.701542    Top1 77.375000    Top5 97.312500    
2024-04-23 20:54:33,648 - Epoch: [306][  123/  123]    Loss 0.699829    Top1 77.554140    Top5 97.273885    
2024-04-23 20:54:33,857 - ==> Top1: 77.554    Top5: 97.274    Loss: 0.700

2024-04-23 20:54:33,867 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:54:33,868 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:54:33,908 - 

2024-04-23 20:54:33,908 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:54:45,039 - Epoch: [307][  100/  296]    Overall Loss 0.715447    Objective Loss 0.715447                                        LR 0.000005    Time 0.111131    
2024-04-23 20:54:52,772 - Epoch: [307][  200/  296]    Overall Loss 0.731702    Objective Loss 0.731702                                        LR 0.000005    Time 0.094153    
2024-04-23 20:54:59,963 - Epoch: [307][  296/  296]    Overall Loss 0.717716    Objective Loss 0.717716    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.087859    
2024-04-23 20:55:00,167 - --- validate (epoch=307)-----------
2024-04-23 20:55:00,168 - 3925 samples (32 per mini-batch)
2024-04-23 20:55:13,240 - Epoch: [307][  100/  123]    Loss 0.697163    Top1 78.093750    Top5 97.250000    
2024-04-23 20:55:15,717 - Epoch: [307][  123/  123]    Loss 0.698886    Top1 77.961783    Top5 97.350318    
2024-04-23 20:55:15,994 - ==> Top1: 77.962    Top5: 97.350    Loss: 0.699

2024-04-23 20:55:15,999 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:55:15,999 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:55:16,028 - 

2024-04-23 20:55:16,029 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:55:26,887 - Epoch: [308][  100/  296]    Overall Loss 0.730254    Objective Loss 0.730254                                        LR 0.000005    Time 0.108412    
2024-04-23 20:55:35,683 - Epoch: [308][  200/  296]    Overall Loss 0.717346    Objective Loss 0.717346                                        LR 0.000005    Time 0.098104    
2024-04-23 20:55:43,807 - Epoch: [308][  296/  296]    Overall Loss 0.721446    Objective Loss 0.721446    Top1 88.524590    Top5 100.000000    LR 0.000005    Time 0.093690    
2024-04-23 20:55:44,016 - --- validate (epoch=308)-----------
2024-04-23 20:55:44,017 - 3925 samples (32 per mini-batch)
2024-04-23 20:55:54,490 - Epoch: [308][  100/  123]    Loss 0.698043    Top1 77.875000    Top5 97.156250    
2024-04-23 20:55:56,312 - Epoch: [308][  123/  123]    Loss 0.697792    Top1 77.885350    Top5 97.248408    
2024-04-23 20:55:56,518 - ==> Top1: 77.885    Top5: 97.248    Loss: 0.698

2024-04-23 20:55:56,527 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:55:56,527 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:55:56,565 - 

2024-04-23 20:55:56,565 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:56:07,248 - Epoch: [309][  100/  296]    Overall Loss 0.743281    Objective Loss 0.743281                                        LR 0.000005    Time 0.106654    
2024-04-23 20:56:14,688 - Epoch: [309][  200/  296]    Overall Loss 0.722810    Objective Loss 0.722810                                        LR 0.000005    Time 0.090451    
2024-04-23 20:56:21,924 - Epoch: [309][  296/  296]    Overall Loss 0.729848    Objective Loss 0.729848    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.085512    
2024-04-23 20:56:22,138 - --- validate (epoch=309)-----------
2024-04-23 20:56:22,138 - 3925 samples (32 per mini-batch)
2024-04-23 20:56:33,474 - Epoch: [309][  100/  123]    Loss 0.698558    Top1 77.906250    Top5 97.187500    
2024-04-23 20:56:36,030 - Epoch: [309][  123/  123]    Loss 0.701347    Top1 77.732484    Top5 97.222930    
2024-04-23 20:56:36,255 - ==> Top1: 77.732    Top5: 97.223    Loss: 0.701

2024-04-23 20:56:36,261 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:56:36,261 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:56:36,294 - 

2024-04-23 20:56:36,295 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:56:48,178 - Epoch: [310][  100/  296]    Overall Loss 0.703758    Objective Loss 0.703758                                        LR 0.000005    Time 0.118658    
2024-04-23 20:56:57,939 - Epoch: [310][  200/  296]    Overall Loss 0.700420    Objective Loss 0.700420                                        LR 0.000005    Time 0.108056    
2024-04-23 20:57:06,123 - Epoch: [310][  296/  296]    Overall Loss 0.697438    Objective Loss 0.697438    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.100613    
2024-04-23 20:57:06,334 - --- validate (epoch=310)-----------
2024-04-23 20:57:06,335 - 3925 samples (32 per mini-batch)
2024-04-23 20:57:19,467 - Epoch: [310][  100/  123]    Loss 0.700340    Top1 77.875000    Top5 97.187500    
2024-04-23 20:57:22,273 - Epoch: [310][  123/  123]    Loss 0.701277    Top1 77.656051    Top5 97.222930    
2024-04-23 20:57:22,540 - ==> Top1: 77.656    Top5: 97.223    Loss: 0.701

2024-04-23 20:57:22,546 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:57:22,546 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:57:22,588 - 

2024-04-23 20:57:22,588 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:57:32,754 - Epoch: [311][  100/  296]    Overall Loss 0.746340    Objective Loss 0.746340                                        LR 0.000005    Time 0.101475    
2024-04-23 20:57:41,459 - Epoch: [311][  200/  296]    Overall Loss 0.728781    Objective Loss 0.728781                                        LR 0.000005    Time 0.094179    
2024-04-23 20:57:50,443 - Epoch: [311][  296/  296]    Overall Loss 0.727263    Objective Loss 0.727263    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.093930    
2024-04-23 20:57:50,694 - --- validate (epoch=311)-----------
2024-04-23 20:57:50,695 - 3925 samples (32 per mini-batch)
2024-04-23 20:58:02,571 - Epoch: [311][  100/  123]    Loss 0.706056    Top1 77.687500    Top5 97.437500    
2024-04-23 20:58:05,170 - Epoch: [311][  123/  123]    Loss 0.700638    Top1 77.757962    Top5 97.401274    
2024-04-23 20:58:05,416 - ==> Top1: 77.758    Top5: 97.401    Loss: 0.701

2024-04-23 20:58:05,426 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:58:05,427 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:58:05,480 - 

2024-04-23 20:58:05,481 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:58:16,630 - Epoch: [312][  100/  296]    Overall Loss 0.671717    Objective Loss 0.671717                                        LR 0.000005    Time 0.111324    
2024-04-23 20:58:26,703 - Epoch: [312][  200/  296]    Overall Loss 0.696706    Objective Loss 0.696706                                        LR 0.000005    Time 0.105937    
2024-04-23 20:58:34,682 - Epoch: [312][  296/  296]    Overall Loss 0.695534    Objective Loss 0.695534    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.098491    
2024-04-23 20:58:34,960 - --- validate (epoch=312)-----------
2024-04-23 20:58:34,961 - 3925 samples (32 per mini-batch)
2024-04-23 20:58:45,261 - Epoch: [312][  100/  123]    Loss 0.692265    Top1 77.218750    Top5 97.531250    
2024-04-23 20:58:47,436 - Epoch: [312][  123/  123]    Loss 0.698941    Top1 77.503185    Top5 97.324841    
2024-04-23 20:58:47,669 - ==> Top1: 77.503    Top5: 97.325    Loss: 0.699

2024-04-23 20:58:47,679 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:58:47,680 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:58:47,717 - 

2024-04-23 20:58:47,718 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:59:00,316 - Epoch: [313][  100/  296]    Overall Loss 0.715475    Objective Loss 0.715475                                        LR 0.000005    Time 0.125796    
2024-04-23 20:59:11,011 - Epoch: [313][  200/  296]    Overall Loss 0.700824    Objective Loss 0.700824                                        LR 0.000005    Time 0.116285    
2024-04-23 20:59:20,313 - Epoch: [313][  296/  296]    Overall Loss 0.703446    Objective Loss 0.703446    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.109940    
2024-04-23 20:59:20,581 - --- validate (epoch=313)-----------
2024-04-23 20:59:20,582 - 3925 samples (32 per mini-batch)
2024-04-23 20:59:33,469 - Epoch: [313][  100/  123]    Loss 0.691080    Top1 78.031250    Top5 97.281250    
2024-04-23 20:59:36,228 - Epoch: [313][  123/  123]    Loss 0.703500    Top1 77.477707    Top5 97.146497    
2024-04-23 20:59:36,531 - ==> Top1: 77.478    Top5: 97.146    Loss: 0.704

2024-04-23 20:59:36,540 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 20:59:36,541 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 20:59:36,576 - 

2024-04-23 20:59:36,576 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:59:49,164 - Epoch: [314][  100/  296]    Overall Loss 0.717353    Objective Loss 0.717353                                        LR 0.000005    Time 0.125701    
2024-04-23 20:59:59,244 - Epoch: [314][  200/  296]    Overall Loss 0.708744    Objective Loss 0.708744                                        LR 0.000005    Time 0.113166    
2024-04-23 21:00:09,141 - Epoch: [314][  296/  296]    Overall Loss 0.715179    Objective Loss 0.715179    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.109842    
2024-04-23 21:00:09,375 - --- validate (epoch=314)-----------
2024-04-23 21:00:09,376 - 3925 samples (32 per mini-batch)
2024-04-23 21:00:21,354 - Epoch: [314][  100/  123]    Loss 0.698417    Top1 77.875000    Top5 97.312500    
2024-04-23 21:00:23,364 - Epoch: [314][  123/  123]    Loss 0.698949    Top1 77.987261    Top5 97.350318    
2024-04-23 21:00:23,599 - ==> Top1: 77.987    Top5: 97.350    Loss: 0.699

2024-04-23 21:00:23,611 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:00:23,612 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:00:23,655 - 

2024-04-23 21:00:23,656 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:00:34,038 - Epoch: [315][  100/  296]    Overall Loss 0.729490    Objective Loss 0.729490                                        LR 0.000005    Time 0.103627    
2024-04-23 21:00:42,964 - Epoch: [315][  200/  296]    Overall Loss 0.717594    Objective Loss 0.717594                                        LR 0.000005    Time 0.096363    
2024-04-23 21:00:50,484 - Epoch: [315][  296/  296]    Overall Loss 0.724456    Objective Loss 0.724456    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.090465    
2024-04-23 21:00:50,705 - --- validate (epoch=315)-----------
2024-04-23 21:00:50,706 - 3925 samples (32 per mini-batch)
2024-04-23 21:01:01,173 - Epoch: [315][  100/  123]    Loss 0.701832    Top1 77.718750    Top5 97.312500    
2024-04-23 21:01:03,625 - Epoch: [315][  123/  123]    Loss 0.700451    Top1 77.528662    Top5 97.401274    
2024-04-23 21:01:03,829 - ==> Top1: 77.529    Top5: 97.401    Loss: 0.700

2024-04-23 21:01:03,839 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:01:03,840 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:01:03,890 - 

2024-04-23 21:01:03,891 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:01:14,907 - Epoch: [316][  100/  296]    Overall Loss 0.717081    Objective Loss 0.717081                                        LR 0.000005    Time 0.109990    
2024-04-23 21:01:24,210 - Epoch: [316][  200/  296]    Overall Loss 0.724376    Objective Loss 0.724376                                        LR 0.000005    Time 0.101439    
2024-04-23 21:01:34,517 - Epoch: [316][  296/  296]    Overall Loss 0.716965    Objective Loss 0.716965    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.103305    
2024-04-23 21:01:34,767 - --- validate (epoch=316)-----------
2024-04-23 21:01:34,768 - 3925 samples (32 per mini-batch)
2024-04-23 21:01:46,151 - Epoch: [316][  100/  123]    Loss 0.683784    Top1 78.125000    Top5 97.531250    
2024-04-23 21:01:48,549 - Epoch: [316][  123/  123]    Loss 0.699174    Top1 77.707006    Top5 97.350318    
2024-04-23 21:01:48,830 - ==> Top1: 77.707    Top5: 97.350    Loss: 0.699

2024-04-23 21:01:48,837 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:01:48,837 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:01:48,880 - 

2024-04-23 21:01:48,881 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:02:02,214 - Epoch: [317][  100/  296]    Overall Loss 0.717612    Objective Loss 0.717612                                        LR 0.000005    Time 0.133137    
2024-04-23 21:02:12,610 - Epoch: [317][  200/  296]    Overall Loss 0.714311    Objective Loss 0.714311                                        LR 0.000005    Time 0.118473    
2024-04-23 21:02:21,673 - Epoch: [317][  296/  296]    Overall Loss 0.709871    Objective Loss 0.709871    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.110618    
2024-04-23 21:02:21,960 - --- validate (epoch=317)-----------
2024-04-23 21:02:21,961 - 3925 samples (32 per mini-batch)
2024-04-23 21:02:33,059 - Epoch: [317][  100/  123]    Loss 0.693347    Top1 77.500000    Top5 97.500000    
2024-04-23 21:02:35,163 - Epoch: [317][  123/  123]    Loss 0.701654    Top1 77.681529    Top5 97.273885    
2024-04-23 21:02:35,389 - ==> Top1: 77.682    Top5: 97.274    Loss: 0.702

2024-04-23 21:02:35,396 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:02:35,397 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:02:35,445 - 

2024-04-23 21:02:35,446 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:02:44,357 - Epoch: [318][  100/  296]    Overall Loss 0.725289    Objective Loss 0.725289                                        LR 0.000005    Time 0.088946    
2024-04-23 21:02:50,511 - Epoch: [318][  200/  296]    Overall Loss 0.728168    Objective Loss 0.728168                                        LR 0.000005    Time 0.075171    
2024-04-23 21:02:56,642 - Epoch: [318][  296/  296]    Overall Loss 0.728807    Objective Loss 0.728807    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.071457    
2024-04-23 21:02:56,868 - --- validate (epoch=318)-----------
2024-04-23 21:02:56,869 - 3925 samples (32 per mini-batch)
2024-04-23 21:03:07,110 - Epoch: [318][  100/  123]    Loss 0.695298    Top1 77.906250    Top5 97.281250    
2024-04-23 21:03:09,150 - Epoch: [318][  123/  123]    Loss 0.700554    Top1 77.579618    Top5 97.273885    
2024-04-23 21:03:09,378 - ==> Top1: 77.580    Top5: 97.274    Loss: 0.701

2024-04-23 21:03:09,387 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:03:09,388 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:03:09,424 - 

2024-04-23 21:03:09,425 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:03:18,393 - Epoch: [319][  100/  296]    Overall Loss 0.715873    Objective Loss 0.715873                                        LR 0.000005    Time 0.089515    
2024-04-23 21:03:24,576 - Epoch: [319][  200/  296]    Overall Loss 0.718648    Objective Loss 0.718648                                        LR 0.000005    Time 0.075600    
2024-04-23 21:03:31,755 - Epoch: [319][  296/  296]    Overall Loss 0.715982    Objective Loss 0.715982    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.075290    
2024-04-23 21:03:31,980 - --- validate (epoch=319)-----------
2024-04-23 21:03:31,980 - 3925 samples (32 per mini-batch)
2024-04-23 21:03:41,389 - Epoch: [319][  100/  123]    Loss 0.687234    Top1 78.000000    Top5 97.343750    
2024-04-23 21:03:43,571 - Epoch: [319][  123/  123]    Loss 0.699754    Top1 77.630573    Top5 97.375796    
2024-04-23 21:03:43,820 - ==> Top1: 77.631    Top5: 97.376    Loss: 0.700

2024-04-23 21:03:43,830 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:03:43,831 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:03:43,875 - 

2024-04-23 21:03:43,876 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:03:53,163 - Epoch: [320][  100/  296]    Overall Loss 0.708491    Objective Loss 0.708491                                        LR 0.000005    Time 0.092724    
2024-04-23 21:04:00,299 - Epoch: [320][  200/  296]    Overall Loss 0.714879    Objective Loss 0.714879                                        LR 0.000005    Time 0.081974    
2024-04-23 21:04:08,884 - Epoch: [320][  296/  296]    Overall Loss 0.721661    Objective Loss 0.721661    Top1 63.934426    Top5 93.442623    LR 0.000005    Time 0.084345    
2024-04-23 21:04:09,098 - --- validate (epoch=320)-----------
2024-04-23 21:04:09,099 - 3925 samples (32 per mini-batch)
2024-04-23 21:04:22,266 - Epoch: [320][  100/  123]    Loss 0.693372    Top1 77.812500    Top5 97.562500    
2024-04-23 21:04:24,919 - Epoch: [320][  123/  123]    Loss 0.699019    Top1 77.808917    Top5 97.350318    
2024-04-23 21:04:25,248 - ==> Top1: 77.809    Top5: 97.350    Loss: 0.699

2024-04-23 21:04:25,259 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:04:25,260 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:04:25,304 - 

2024-04-23 21:04:25,304 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:04:36,911 - Epoch: [321][  100/  296]    Overall Loss 0.733214    Objective Loss 0.733214                                        LR 0.000005    Time 0.115887    
2024-04-23 21:04:48,845 - Epoch: [321][  200/  296]    Overall Loss 0.735254    Objective Loss 0.735254                                        LR 0.000005    Time 0.117521    
2024-04-23 21:05:01,915 - Epoch: [321][  296/  296]    Overall Loss 0.725407    Objective Loss 0.725407    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.123520    
2024-04-23 21:05:02,167 - --- validate (epoch=321)-----------
2024-04-23 21:05:02,168 - 3925 samples (32 per mini-batch)
2024-04-23 21:05:13,437 - Epoch: [321][  100/  123]    Loss 0.710954    Top1 77.500000    Top5 97.250000    
2024-04-23 21:05:15,309 - Epoch: [321][  123/  123]    Loss 0.704591    Top1 77.681529    Top5 97.171975    
2024-04-23 21:05:15,586 - ==> Top1: 77.682    Top5: 97.172    Loss: 0.705

2024-04-23 21:05:15,596 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:05:15,597 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:05:15,642 - 

2024-04-23 21:05:15,643 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:05:33,620 - Epoch: [322][  100/  296]    Overall Loss 0.699085    Objective Loss 0.699085                                        LR 0.000005    Time 0.179620    
2024-04-23 21:05:45,951 - Epoch: [322][  200/  296]    Overall Loss 0.714261    Objective Loss 0.714261                                        LR 0.000005    Time 0.151396    
2024-04-23 21:05:57,273 - Epoch: [322][  296/  296]    Overall Loss 0.718137    Objective Loss 0.718137    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.140493    
2024-04-23 21:05:57,517 - --- validate (epoch=322)-----------
2024-04-23 21:05:57,518 - 3925 samples (32 per mini-batch)
2024-04-23 21:06:13,072 - Epoch: [322][  100/  123]    Loss 0.703534    Top1 77.843750    Top5 97.375000    
2024-04-23 21:06:16,650 - Epoch: [322][  123/  123]    Loss 0.701136    Top1 77.783439    Top5 97.375796    
2024-04-23 21:06:16,825 - ==> Top1: 77.783    Top5: 97.376    Loss: 0.701

2024-04-23 21:06:16,835 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:06:16,836 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:06:16,887 - 

2024-04-23 21:06:16,888 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:06:31,492 - Epoch: [323][  100/  296]    Overall Loss 0.723235    Objective Loss 0.723235                                        LR 0.000005    Time 0.145863    
2024-04-23 21:06:44,384 - Epoch: [323][  200/  296]    Overall Loss 0.718865    Objective Loss 0.718865                                        LR 0.000005    Time 0.137303    
2024-04-23 21:06:55,093 - Epoch: [323][  296/  296]    Overall Loss 0.716604    Objective Loss 0.716604    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.128894    
2024-04-23 21:06:55,330 - --- validate (epoch=323)-----------
2024-04-23 21:06:55,331 - 3925 samples (32 per mini-batch)
2024-04-23 21:07:10,267 - Epoch: [323][  100/  123]    Loss 0.683628    Top1 78.062500    Top5 97.187500    
2024-04-23 21:07:13,686 - Epoch: [323][  123/  123]    Loss 0.699687    Top1 77.579618    Top5 97.222930    
2024-04-23 21:07:14,045 - ==> Top1: 77.580    Top5: 97.223    Loss: 0.700

2024-04-23 21:07:14,053 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:07:14,053 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:07:14,098 - 

2024-04-23 21:07:14,099 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:07:27,601 - Epoch: [324][  100/  296]    Overall Loss 0.711608    Objective Loss 0.711608                                        LR 0.000005    Time 0.134831    
2024-04-23 21:07:38,932 - Epoch: [324][  200/  296]    Overall Loss 0.711418    Objective Loss 0.711418                                        LR 0.000005    Time 0.123982    
2024-04-23 21:07:50,979 - Epoch: [324][  296/  296]    Overall Loss 0.716078    Objective Loss 0.716078    Top1 63.934426    Top5 95.081967    LR 0.000005    Time 0.124420    
2024-04-23 21:07:51,111 - --- validate (epoch=324)-----------
2024-04-23 21:07:51,112 - 3925 samples (32 per mini-batch)
2024-04-23 21:08:04,634 - Epoch: [324][  100/  123]    Loss 0.715885    Top1 77.343750    Top5 97.406250    
2024-04-23 21:08:07,411 - Epoch: [324][  123/  123]    Loss 0.696617    Top1 77.808917    Top5 97.477707    
2024-04-23 21:08:07,719 - ==> Top1: 77.809    Top5: 97.478    Loss: 0.697

2024-04-23 21:08:07,730 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:08:07,730 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:08:07,778 - 

2024-04-23 21:08:07,779 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:08:22,614 - Epoch: [325][  100/  296]    Overall Loss 0.709598    Objective Loss 0.709598                                        LR 0.000005    Time 0.148159    
2024-04-23 21:08:34,386 - Epoch: [325][  200/  296]    Overall Loss 0.697667    Objective Loss 0.697667                                        LR 0.000005    Time 0.132847    
2024-04-23 21:08:45,850 - Epoch: [325][  296/  296]    Overall Loss 0.709190    Objective Loss 0.709190    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.128435    
2024-04-23 21:08:46,048 - --- validate (epoch=325)-----------
2024-04-23 21:08:46,049 - 3925 samples (32 per mini-batch)
2024-04-23 21:08:55,607 - Epoch: [325][  100/  123]    Loss 0.705582    Top1 77.468750    Top5 97.093750    
2024-04-23 21:08:57,119 - Epoch: [325][  123/  123]    Loss 0.705479    Top1 77.401274    Top5 97.171975    
2024-04-23 21:08:57,236 - ==> Top1: 77.401    Top5: 97.172    Loss: 0.705

2024-04-23 21:08:57,241 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:08:57,241 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:08:57,277 - 

2024-04-23 21:08:57,277 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:09:05,189 - Epoch: [326][  100/  296]    Overall Loss 0.716763    Objective Loss 0.716763                                        LR 0.000005    Time 0.078970    
2024-04-23 21:09:12,695 - Epoch: [326][  200/  296]    Overall Loss 0.696865    Objective Loss 0.696865                                        LR 0.000005    Time 0.076949    
2024-04-23 21:09:22,450 - Epoch: [326][  296/  296]    Overall Loss 0.704860    Objective Loss 0.704860    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.084901    
2024-04-23 21:09:22,578 - --- validate (epoch=326)-----------
2024-04-23 21:09:22,579 - 3925 samples (32 per mini-batch)
2024-04-23 21:09:34,274 - Epoch: [326][  100/  123]    Loss 0.700469    Top1 77.937500    Top5 97.093750    
2024-04-23 21:09:36,852 - Epoch: [326][  123/  123]    Loss 0.700995    Top1 77.961783    Top5 97.197452    
2024-04-23 21:09:36,990 - ==> Top1: 77.962    Top5: 97.197    Loss: 0.701

2024-04-23 21:09:37,000 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:09:37,001 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:09:37,050 - 

2024-04-23 21:09:37,050 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:09:49,195 - Epoch: [327][  100/  296]    Overall Loss 0.750828    Objective Loss 0.750828                                        LR 0.000005    Time 0.121255    
2024-04-23 21:09:58,780 - Epoch: [327][  200/  296]    Overall Loss 0.721316    Objective Loss 0.721316                                        LR 0.000005    Time 0.108471    
2024-04-23 21:10:09,601 - Epoch: [327][  296/  296]    Overall Loss 0.712802    Objective Loss 0.712802    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.109796    
2024-04-23 21:10:09,782 - --- validate (epoch=327)-----------
2024-04-23 21:10:09,783 - 3925 samples (32 per mini-batch)
2024-04-23 21:10:23,871 - Epoch: [327][  100/  123]    Loss 0.704445    Top1 77.437500    Top5 97.218750    
2024-04-23 21:10:26,580 - Epoch: [327][  123/  123]    Loss 0.705022    Top1 77.401274    Top5 97.171975    
2024-04-23 21:10:26,840 - ==> Top1: 77.401    Top5: 97.172    Loss: 0.705

2024-04-23 21:10:26,853 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:10:26,854 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:10:26,903 - 

2024-04-23 21:10:26,904 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:10:39,307 - Epoch: [328][  100/  296]    Overall Loss 0.742550    Objective Loss 0.742550                                        LR 0.000005    Time 0.123850    
2024-04-23 21:10:49,706 - Epoch: [328][  200/  296]    Overall Loss 0.719035    Objective Loss 0.719035                                        LR 0.000005    Time 0.113831    
2024-04-23 21:11:00,150 - Epoch: [328][  296/  296]    Overall Loss 0.721754    Objective Loss 0.721754    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.112141    
2024-04-23 21:11:00,662 - --- validate (epoch=328)-----------
2024-04-23 21:11:00,663 - 3925 samples (32 per mini-batch)
2024-04-23 21:11:14,742 - Epoch: [328][  100/  123]    Loss 0.703952    Top1 77.406250    Top5 97.375000    
2024-04-23 21:11:17,681 - Epoch: [328][  123/  123]    Loss 0.701135    Top1 77.554140    Top5 97.401274    
2024-04-23 21:11:17,928 - ==> Top1: 77.554    Top5: 97.401    Loss: 0.701

2024-04-23 21:11:17,940 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:11:17,941 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:11:17,984 - 

2024-04-23 21:11:17,985 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:11:31,285 - Epoch: [329][  100/  296]    Overall Loss 0.705036    Objective Loss 0.705036                                        LR 0.000005    Time 0.132821    
2024-04-23 21:11:42,757 - Epoch: [329][  200/  296]    Overall Loss 0.710677    Objective Loss 0.710677                                        LR 0.000005    Time 0.123688    
2024-04-23 21:11:53,963 - Epoch: [329][  296/  296]    Overall Loss 0.707910    Objective Loss 0.707910    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.121375    
2024-04-23 21:11:54,240 - --- validate (epoch=329)-----------
2024-04-23 21:11:54,241 - 3925 samples (32 per mini-batch)
2024-04-23 21:12:10,110 - Epoch: [329][  100/  123]    Loss 0.707524    Top1 76.968750    Top5 97.375000    
2024-04-23 21:12:12,872 - Epoch: [329][  123/  123]    Loss 0.702034    Top1 77.681529    Top5 97.299363    
2024-04-23 21:12:13,149 - ==> Top1: 77.682    Top5: 97.299    Loss: 0.702

2024-04-23 21:12:13,157 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:12:13,158 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:12:13,202 - 

2024-04-23 21:12:13,203 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:12:29,462 - Epoch: [330][  100/  296]    Overall Loss 0.735543    Objective Loss 0.735543                                        LR 0.000005    Time 0.162389    
2024-04-23 21:12:42,519 - Epoch: [330][  200/  296]    Overall Loss 0.721183    Objective Loss 0.721183                                        LR 0.000005    Time 0.146398    
2024-04-23 21:12:54,673 - Epoch: [330][  296/  296]    Overall Loss 0.722482    Objective Loss 0.722482    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.139930    
2024-04-23 21:12:54,953 - --- validate (epoch=330)-----------
2024-04-23 21:12:54,953 - 3925 samples (32 per mini-batch)
2024-04-23 21:13:10,402 - Epoch: [330][  100/  123]    Loss 0.694190    Top1 77.906250    Top5 97.375000    
2024-04-23 21:13:13,583 - Epoch: [330][  123/  123]    Loss 0.702632    Top1 77.579618    Top5 97.350318    
2024-04-23 21:13:13,995 - ==> Top1: 77.580    Top5: 97.350    Loss: 0.703

2024-04-23 21:13:14,006 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:13:14,006 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:13:14,056 - 

2024-04-23 21:13:14,057 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:13:27,678 - Epoch: [331][  100/  296]    Overall Loss 0.702422    Objective Loss 0.702422                                        LR 0.000005    Time 0.136035    
2024-04-23 21:13:40,032 - Epoch: [331][  200/  296]    Overall Loss 0.715293    Objective Loss 0.715293                                        LR 0.000005    Time 0.129709    
2024-04-23 21:13:52,157 - Epoch: [331][  296/  296]    Overall Loss 0.713450    Objective Loss 0.713450    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.128552    
2024-04-23 21:13:52,453 - --- validate (epoch=331)-----------
2024-04-23 21:13:52,454 - 3925 samples (32 per mini-batch)
2024-04-23 21:14:07,380 - Epoch: [331][  100/  123]    Loss 0.679856    Top1 78.656250    Top5 97.375000    
2024-04-23 21:14:10,177 - Epoch: [331][  123/  123]    Loss 0.700339    Top1 77.757962    Top5 97.222930    
2024-04-23 21:14:10,475 - ==> Top1: 77.758    Top5: 97.223    Loss: 0.700

2024-04-23 21:14:10,486 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:14:10,487 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:14:10,528 - 

2024-04-23 21:14:10,528 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:14:20,581 - Epoch: [332][  100/  296]    Overall Loss 0.718866    Objective Loss 0.718866                                        LR 0.000005    Time 0.100355    
2024-04-23 21:14:30,518 - Epoch: [332][  200/  296]    Overall Loss 0.723045    Objective Loss 0.723045                                        LR 0.000005    Time 0.099777    
2024-04-23 21:14:41,049 - Epoch: [332][  296/  296]    Overall Loss 0.723304    Objective Loss 0.723304    Top1 68.852459    Top5 91.803279    LR 0.000005    Time 0.102940    
2024-04-23 21:14:41,320 - --- validate (epoch=332)-----------
2024-04-23 21:14:41,321 - 3925 samples (32 per mini-batch)
2024-04-23 21:14:50,912 - Epoch: [332][  100/  123]    Loss 0.710611    Top1 77.250000    Top5 97.093750    
2024-04-23 21:14:52,651 - Epoch: [332][  123/  123]    Loss 0.701413    Top1 77.579618    Top5 97.299363    
2024-04-23 21:14:52,944 - ==> Top1: 77.580    Top5: 97.299    Loss: 0.701

2024-04-23 21:14:52,954 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:14:52,954 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:14:52,994 - 

2024-04-23 21:14:52,994 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:15:01,006 - Epoch: [333][  100/  296]    Overall Loss 0.729164    Objective Loss 0.729164                                        LR 0.000005    Time 0.079966    
2024-04-23 21:15:07,248 - Epoch: [333][  200/  296]    Overall Loss 0.726666    Objective Loss 0.726666                                        LR 0.000005    Time 0.071127    
2024-04-23 21:15:12,524 - Epoch: [333][  296/  296]    Overall Loss 0.734206    Objective Loss 0.734206    Top1 67.213115    Top5 96.721311    LR 0.000005    Time 0.065839    
2024-04-23 21:15:12,757 - --- validate (epoch=333)-----------
2024-04-23 21:15:12,758 - 3925 samples (32 per mini-batch)
2024-04-23 21:15:21,981 - Epoch: [333][  100/  123]    Loss 0.716040    Top1 77.406250    Top5 96.968750    
2024-04-23 21:15:23,439 - Epoch: [333][  123/  123]    Loss 0.702072    Top1 77.681529    Top5 97.248408    
2024-04-23 21:15:23,653 - ==> Top1: 77.682    Top5: 97.248    Loss: 0.702

2024-04-23 21:15:23,662 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:15:23,663 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:15:23,703 - 

2024-04-23 21:15:23,703 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:15:32,497 - Epoch: [334][  100/  296]    Overall Loss 0.692287    Objective Loss 0.692287                                        LR 0.000005    Time 0.087787    
2024-04-23 21:15:41,014 - Epoch: [334][  200/  296]    Overall Loss 0.692093    Objective Loss 0.692093                                        LR 0.000005    Time 0.086408    
2024-04-23 21:15:49,448 - Epoch: [334][  296/  296]    Overall Loss 0.712497    Objective Loss 0.712497    Top1 67.213115    Top5 91.803279    LR 0.000005    Time 0.086826    
2024-04-23 21:15:49,692 - --- validate (epoch=334)-----------
2024-04-23 21:15:49,693 - 3925 samples (32 per mini-batch)
2024-04-23 21:16:00,987 - Epoch: [334][  100/  123]    Loss 0.697005    Top1 77.500000    Top5 97.406250    
2024-04-23 21:16:02,867 - Epoch: [334][  123/  123]    Loss 0.699449    Top1 77.605096    Top5 97.222930    
2024-04-23 21:16:03,155 - ==> Top1: 77.605    Top5: 97.223    Loss: 0.699

2024-04-23 21:16:03,161 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:16:03,161 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:16:03,198 - 

2024-04-23 21:16:03,199 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:16:15,437 - Epoch: [335][  100/  296]    Overall Loss 0.699928    Objective Loss 0.699928                                        LR 0.000005    Time 0.122225    
2024-04-23 21:16:26,680 - Epoch: [335][  200/  296]    Overall Loss 0.699402    Objective Loss 0.699402                                        LR 0.000005    Time 0.117240    
2024-04-23 21:16:36,921 - Epoch: [335][  296/  296]    Overall Loss 0.704694    Objective Loss 0.704694    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.113764    
2024-04-23 21:16:37,199 - --- validate (epoch=335)-----------
2024-04-23 21:16:37,200 - 3925 samples (32 per mini-batch)
2024-04-23 21:16:52,254 - Epoch: [335][  100/  123]    Loss 0.691189    Top1 78.375000    Top5 97.312500    
2024-04-23 21:16:55,278 - Epoch: [335][  123/  123]    Loss 0.703411    Top1 77.732484    Top5 97.324841    
2024-04-23 21:16:55,515 - ==> Top1: 77.732    Top5: 97.325    Loss: 0.703

2024-04-23 21:16:55,524 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:16:55,525 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:16:55,568 - 

2024-04-23 21:16:55,568 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:17:08,795 - Epoch: [336][  100/  296]    Overall Loss 0.735552    Objective Loss 0.735552                                        LR 0.000005    Time 0.132108    
2024-04-23 21:17:20,736 - Epoch: [336][  200/  296]    Overall Loss 0.729305    Objective Loss 0.729305                                        LR 0.000005    Time 0.125677    
2024-04-23 21:17:30,861 - Epoch: [336][  296/  296]    Overall Loss 0.717902    Objective Loss 0.717902    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.119081    
2024-04-23 21:17:31,137 - --- validate (epoch=336)-----------
2024-04-23 21:17:31,138 - 3925 samples (32 per mini-batch)
2024-04-23 21:17:41,949 - Epoch: [336][  100/  123]    Loss 0.705850    Top1 77.437500    Top5 97.250000    
2024-04-23 21:17:44,351 - Epoch: [336][  123/  123]    Loss 0.703499    Top1 77.605096    Top5 97.299363    
2024-04-23 21:17:44,556 - ==> Top1: 77.605    Top5: 97.299    Loss: 0.703

2024-04-23 21:17:44,564 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:17:44,564 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:17:44,604 - 

2024-04-23 21:17:44,604 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:17:52,791 - Epoch: [337][  100/  296]    Overall Loss 0.715380    Objective Loss 0.715380                                        LR 0.000005    Time 0.081722    
2024-04-23 21:18:02,136 - Epoch: [337][  200/  296]    Overall Loss 0.703190    Objective Loss 0.703190                                        LR 0.000005    Time 0.087519    
2024-04-23 21:18:10,292 - Epoch: [337][  296/  296]    Overall Loss 0.699400    Objective Loss 0.699400    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.086637    
2024-04-23 21:18:10,502 - --- validate (epoch=337)-----------
2024-04-23 21:18:10,503 - 3925 samples (32 per mini-batch)
2024-04-23 21:18:21,709 - Epoch: [337][  100/  123]    Loss 0.695467    Top1 77.937500    Top5 97.218750    
2024-04-23 21:18:23,867 - Epoch: [337][  123/  123]    Loss 0.706501    Top1 77.605096    Top5 97.171975    
2024-04-23 21:18:24,093 - ==> Top1: 77.605    Top5: 97.172    Loss: 0.707

2024-04-23 21:18:24,104 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:18:24,104 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:18:24,151 - 

2024-04-23 21:18:24,152 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:18:35,316 - Epoch: [338][  100/  296]    Overall Loss 0.659509    Objective Loss 0.659509                                        LR 0.000005    Time 0.111450    
2024-04-23 21:18:44,573 - Epoch: [338][  200/  296]    Overall Loss 0.683379    Objective Loss 0.683379                                        LR 0.000005    Time 0.101936    
2024-04-23 21:18:54,039 - Epoch: [338][  296/  296]    Overall Loss 0.688291    Objective Loss 0.688291    Top1 70.491803    Top5 98.360656    LR 0.000005    Time 0.100801    
2024-04-23 21:18:54,287 - --- validate (epoch=338)-----------
2024-04-23 21:18:54,288 - 3925 samples (32 per mini-batch)
2024-04-23 21:19:06,302 - Epoch: [338][  100/  123]    Loss 0.703160    Top1 77.375000    Top5 97.250000    
2024-04-23 21:19:08,726 - Epoch: [338][  123/  123]    Loss 0.702604    Top1 77.554140    Top5 97.248408    
2024-04-23 21:19:08,890 - ==> Top1: 77.554    Top5: 97.248    Loss: 0.703

2024-04-23 21:19:08,899 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:19:08,899 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:19:08,935 - 

2024-04-23 21:19:08,935 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:19:18,559 - Epoch: [339][  100/  296]    Overall Loss 0.739662    Objective Loss 0.739662                                        LR 0.000005    Time 0.096078    
2024-04-23 21:19:27,588 - Epoch: [339][  200/  296]    Overall Loss 0.718814    Objective Loss 0.718814                                        LR 0.000005    Time 0.093097    
2024-04-23 21:19:35,247 - Epoch: [339][  296/  296]    Overall Loss 0.717024    Objective Loss 0.717024    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.088728    
2024-04-23 21:19:35,497 - --- validate (epoch=339)-----------
2024-04-23 21:19:35,498 - 3925 samples (32 per mini-batch)
2024-04-23 21:19:48,808 - Epoch: [339][  100/  123]    Loss 0.697313    Top1 77.375000    Top5 97.281250    
2024-04-23 21:19:51,836 - Epoch: [339][  123/  123]    Loss 0.701438    Top1 77.554140    Top5 97.350318    
2024-04-23 21:19:52,056 - ==> Top1: 77.554    Top5: 97.350    Loss: 0.701

2024-04-23 21:19:52,066 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:19:52,067 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:19:52,106 - 

2024-04-23 21:19:52,107 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:20:04,325 - Epoch: [340][  100/  296]    Overall Loss 0.714142    Objective Loss 0.714142                                        LR 0.000005    Time 0.122023    
2024-04-23 21:20:12,229 - Epoch: [340][  200/  296]    Overall Loss 0.713555    Objective Loss 0.713555                                        LR 0.000005    Time 0.100456    
2024-04-23 21:20:19,597 - Epoch: [340][  296/  296]    Overall Loss 0.712385    Objective Loss 0.712385    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.092715    
2024-04-23 21:20:19,879 - --- validate (epoch=340)-----------
2024-04-23 21:20:19,881 - 3925 samples (32 per mini-batch)
2024-04-23 21:20:31,213 - Epoch: [340][  100/  123]    Loss 0.682365    Top1 78.625000    Top5 97.437500    
2024-04-23 21:20:33,529 - Epoch: [340][  123/  123]    Loss 0.700981    Top1 77.859873    Top5 97.273885    
2024-04-23 21:20:33,818 - ==> Top1: 77.860    Top5: 97.274    Loss: 0.701

2024-04-23 21:20:33,827 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:20:33,828 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:20:33,862 - 

2024-04-23 21:20:33,863 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:20:44,217 - Epoch: [341][  100/  296]    Overall Loss 0.704031    Objective Loss 0.704031                                        LR 0.000005    Time 0.103371    
2024-04-23 21:20:52,682 - Epoch: [341][  200/  296]    Overall Loss 0.714907    Objective Loss 0.714907                                        LR 0.000005    Time 0.093935    
2024-04-23 21:21:00,910 - Epoch: [341][  296/  296]    Overall Loss 0.714056    Objective Loss 0.714056    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.091215    
2024-04-23 21:21:01,139 - --- validate (epoch=341)-----------
2024-04-23 21:21:01,140 - 3925 samples (32 per mini-batch)
2024-04-23 21:21:14,475 - Epoch: [341][  100/  123]    Loss 0.713559    Top1 77.125000    Top5 97.343750    
2024-04-23 21:21:17,964 - Epoch: [341][  123/  123]    Loss 0.702284    Top1 77.477707    Top5 97.350318    
2024-04-23 21:21:18,221 - ==> Top1: 77.478    Top5: 97.350    Loss: 0.702

2024-04-23 21:21:18,231 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:21:18,231 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:21:18,273 - 

2024-04-23 21:21:18,274 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:21:29,350 - Epoch: [342][  100/  296]    Overall Loss 0.734372    Objective Loss 0.734372                                        LR 0.000005    Time 0.110598    
2024-04-23 21:21:39,556 - Epoch: [342][  200/  296]    Overall Loss 0.726844    Objective Loss 0.726844                                        LR 0.000005    Time 0.106253    
2024-04-23 21:21:49,357 - Epoch: [342][  296/  296]    Overall Loss 0.708228    Objective Loss 0.708228    Top1 72.131148    Top5 93.442623    LR 0.000005    Time 0.104850    
2024-04-23 21:21:49,527 - --- validate (epoch=342)-----------
2024-04-23 21:21:49,528 - 3925 samples (32 per mini-batch)
2024-04-23 21:22:02,942 - Epoch: [342][  100/  123]    Loss 0.709341    Top1 77.031250    Top5 97.250000    
2024-04-23 21:22:05,544 - Epoch: [342][  123/  123]    Loss 0.698891    Top1 77.681529    Top5 97.273885    
2024-04-23 21:22:05,757 - ==> Top1: 77.682    Top5: 97.274    Loss: 0.699

2024-04-23 21:22:05,766 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:22:05,767 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:22:05,808 - 

2024-04-23 21:22:05,808 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:22:15,262 - Epoch: [343][  100/  296]    Overall Loss 0.690627    Objective Loss 0.690627                                        LR 0.000005    Time 0.094372    
2024-04-23 21:22:24,276 - Epoch: [343][  200/  296]    Overall Loss 0.704628    Objective Loss 0.704628                                        LR 0.000005    Time 0.092166    
2024-04-23 21:22:32,252 - Epoch: [343][  296/  296]    Overall Loss 0.703283    Objective Loss 0.703283    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.089174    
2024-04-23 21:22:32,508 - --- validate (epoch=343)-----------
2024-04-23 21:22:32,509 - 3925 samples (32 per mini-batch)
2024-04-23 21:22:45,698 - Epoch: [343][  100/  123]    Loss 0.696371    Top1 78.031250    Top5 97.312500    
2024-04-23 21:22:48,376 - Epoch: [343][  123/  123]    Loss 0.701706    Top1 77.783439    Top5 97.273885    
2024-04-23 21:22:48,577 - ==> Top1: 77.783    Top5: 97.274    Loss: 0.702

2024-04-23 21:22:48,586 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:22:48,587 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:22:48,635 - 

2024-04-23 21:22:48,635 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:23:00,389 - Epoch: [344][  100/  296]    Overall Loss 0.727948    Objective Loss 0.727948                                        LR 0.000005    Time 0.117356    
2024-04-23 21:23:09,492 - Epoch: [344][  200/  296]    Overall Loss 0.735180    Objective Loss 0.735180                                        LR 0.000005    Time 0.104105    
2024-04-23 21:23:17,132 - Epoch: [344][  296/  296]    Overall Loss 0.735843    Objective Loss 0.735843    Top1 80.327869    Top5 93.442623    LR 0.000005    Time 0.096106    
2024-04-23 21:23:17,362 - --- validate (epoch=344)-----------
2024-04-23 21:23:17,363 - 3925 samples (32 per mini-batch)
2024-04-23 21:23:28,035 - Epoch: [344][  100/  123]    Loss 0.700126    Top1 77.531250    Top5 97.375000    
2024-04-23 21:23:29,864 - Epoch: [344][  123/  123]    Loss 0.705307    Top1 77.401274    Top5 97.350318    
2024-04-23 21:23:30,069 - ==> Top1: 77.401    Top5: 97.350    Loss: 0.705

2024-04-23 21:23:30,078 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:23:30,078 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:23:30,117 - 

2024-04-23 21:23:30,117 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:23:40,836 - Epoch: [345][  100/  296]    Overall Loss 0.707891    Objective Loss 0.707891                                        LR 0.000005    Time 0.107010    
2024-04-23 21:23:49,046 - Epoch: [345][  200/  296]    Overall Loss 0.714126    Objective Loss 0.714126                                        LR 0.000005    Time 0.094485    
2024-04-23 21:23:57,001 - Epoch: [345][  296/  296]    Overall Loss 0.709290    Objective Loss 0.709290    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.090665    
2024-04-23 21:23:57,242 - --- validate (epoch=345)-----------
2024-04-23 21:23:57,242 - 3925 samples (32 per mini-batch)
2024-04-23 21:24:08,442 - Epoch: [345][  100/  123]    Loss 0.707407    Top1 77.187500    Top5 97.281250    
2024-04-23 21:24:11,771 - Epoch: [345][  123/  123]    Loss 0.700752    Top1 77.605096    Top5 97.324841    
2024-04-23 21:24:11,990 - ==> Top1: 77.605    Top5: 97.325    Loss: 0.701

2024-04-23 21:24:11,996 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:24:11,997 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:24:12,037 - 

2024-04-23 21:24:12,038 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:24:23,259 - Epoch: [346][  100/  296]    Overall Loss 0.739191    Objective Loss 0.739191                                        LR 0.000005    Time 0.112041    
2024-04-23 21:24:32,107 - Epoch: [346][  200/  296]    Overall Loss 0.732464    Objective Loss 0.732464                                        LR 0.000005    Time 0.100180    
2024-04-23 21:24:39,487 - Epoch: [346][  296/  296]    Overall Loss 0.733372    Objective Loss 0.733372    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.092575    
2024-04-23 21:24:39,724 - --- validate (epoch=346)-----------
2024-04-23 21:24:39,725 - 3925 samples (32 per mini-batch)
2024-04-23 21:24:51,383 - Epoch: [346][  100/  123]    Loss 0.695302    Top1 77.687500    Top5 97.468750    
2024-04-23 21:24:53,213 - Epoch: [346][  123/  123]    Loss 0.700246    Top1 77.808917    Top5 97.477707    
2024-04-23 21:24:53,467 - ==> Top1: 77.809    Top5: 97.478    Loss: 0.700

2024-04-23 21:24:53,473 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:24:53,473 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:24:53,507 - 

2024-04-23 21:24:53,508 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:25:03,949 - Epoch: [347][  100/  296]    Overall Loss 0.717968    Objective Loss 0.717968                                        LR 0.000005    Time 0.104231    
2024-04-23 21:25:11,912 - Epoch: [347][  200/  296]    Overall Loss 0.728902    Objective Loss 0.728902                                        LR 0.000005    Time 0.091853    
2024-04-23 21:25:19,833 - Epoch: [347][  296/  296]    Overall Loss 0.734257    Objective Loss 0.734257    Top1 65.573770    Top5 98.360656    LR 0.000005    Time 0.088774    
2024-04-23 21:25:20,070 - --- validate (epoch=347)-----------
2024-04-23 21:25:20,070 - 3925 samples (32 per mini-batch)
2024-04-23 21:25:31,221 - Epoch: [347][  100/  123]    Loss 0.713178    Top1 77.718750    Top5 97.250000    
2024-04-23 21:25:34,022 - Epoch: [347][  123/  123]    Loss 0.702393    Top1 77.808917    Top5 97.350318    
2024-04-23 21:25:34,318 - ==> Top1: 77.809    Top5: 97.350    Loss: 0.702

2024-04-23 21:25:34,326 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:25:34,327 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:25:34,365 - 

2024-04-23 21:25:34,365 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:25:45,140 - Epoch: [348][  100/  296]    Overall Loss 0.733832    Objective Loss 0.733832                                        LR 0.000005    Time 0.107575    
2024-04-23 21:25:55,237 - Epoch: [348][  200/  296]    Overall Loss 0.717742    Objective Loss 0.717742                                        LR 0.000005    Time 0.104184    
2024-04-23 21:26:03,268 - Epoch: [348][  296/  296]    Overall Loss 0.710894    Objective Loss 0.710894    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.097477    
2024-04-23 21:26:03,524 - --- validate (epoch=348)-----------
2024-04-23 21:26:03,524 - 3925 samples (32 per mini-batch)
2024-04-23 21:26:14,169 - Epoch: [348][  100/  123]    Loss 0.685255    Top1 78.000000    Top5 97.343750    
2024-04-23 21:26:16,201 - Epoch: [348][  123/  123]    Loss 0.698643    Top1 77.656051    Top5 97.350318    
2024-04-23 21:26:16,450 - ==> Top1: 77.656    Top5: 97.350    Loss: 0.699

2024-04-23 21:26:16,459 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:26:16,460 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:26:16,498 - 

2024-04-23 21:26:16,498 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:26:25,480 - Epoch: [349][  100/  296]    Overall Loss 0.750040    Objective Loss 0.750040                                        LR 0.000005    Time 0.089661    
2024-04-23 21:26:33,036 - Epoch: [349][  200/  296]    Overall Loss 0.736669    Objective Loss 0.736669                                        LR 0.000005    Time 0.082534    
2024-04-23 21:26:40,932 - Epoch: [349][  296/  296]    Overall Loss 0.728967    Objective Loss 0.728967    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.082392    
2024-04-23 21:26:41,181 - --- validate (epoch=349)-----------
2024-04-23 21:26:41,182 - 3925 samples (32 per mini-batch)
2024-04-23 21:26:51,253 - Epoch: [349][  100/  123]    Loss 0.681796    Top1 78.343750    Top5 97.187500    
2024-04-23 21:26:53,249 - Epoch: [349][  123/  123]    Loss 0.705491    Top1 77.528662    Top5 97.146497    
2024-04-23 21:26:53,473 - ==> Top1: 77.529    Top5: 97.146    Loss: 0.705

2024-04-23 21:26:53,482 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:26:53,483 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:26:53,525 - 

2024-04-23 21:26:53,526 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:27:03,823 - Epoch: [350][  100/  296]    Overall Loss 0.723648    Objective Loss 0.723648                                        LR 0.000005    Time 0.102811    
2024-04-23 21:27:12,054 - Epoch: [350][  200/  296]    Overall Loss 0.718701    Objective Loss 0.718701                                        LR 0.000005    Time 0.092482    
2024-04-23 21:27:23,461 - Epoch: [350][  296/  296]    Overall Loss 0.711219    Objective Loss 0.711219    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.100968    
2024-04-23 21:27:23,683 - --- validate (epoch=350)-----------
2024-04-23 21:27:23,684 - 3925 samples (32 per mini-batch)
2024-04-23 21:27:37,788 - Epoch: [350][  100/  123]    Loss 0.673444    Top1 78.000000    Top5 97.437500    
2024-04-23 21:27:40,741 - Epoch: [350][  123/  123]    Loss 0.701125    Top1 77.681529    Top5 97.299363    
2024-04-23 21:27:40,940 - ==> Top1: 77.682    Top5: 97.299    Loss: 0.701

2024-04-23 21:27:40,948 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:27:40,948 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:27:41,002 - 

2024-04-23 21:27:41,004 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:27:56,322 - Epoch: [351][  100/  296]    Overall Loss 0.714904    Objective Loss 0.714904                                        LR 0.000005    Time 0.152996    
2024-04-23 21:28:09,911 - Epoch: [351][  200/  296]    Overall Loss 0.713969    Objective Loss 0.713969                                        LR 0.000005    Time 0.144361    
2024-04-23 21:28:21,937 - Epoch: [351][  296/  296]    Overall Loss 0.720314    Objective Loss 0.720314    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.138116    
2024-04-23 21:28:22,236 - --- validate (epoch=351)-----------
2024-04-23 21:28:22,237 - 3925 samples (32 per mini-batch)
2024-04-23 21:28:34,908 - Epoch: [351][  100/  123]    Loss 0.706251    Top1 77.281250    Top5 97.343750    
2024-04-23 21:28:37,888 - Epoch: [351][  123/  123]    Loss 0.701914    Top1 77.783439    Top5 97.273885    
2024-04-23 21:28:38,125 - ==> Top1: 77.783    Top5: 97.274    Loss: 0.702

2024-04-23 21:28:38,136 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:28:38,137 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:28:38,188 - 

2024-04-23 21:28:38,188 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:28:52,284 - Epoch: [352][  100/  296]    Overall Loss 0.687243    Objective Loss 0.687243                                        LR 0.000005    Time 0.140771    
2024-04-23 21:29:05,067 - Epoch: [352][  200/  296]    Overall Loss 0.716038    Objective Loss 0.716038                                        LR 0.000005    Time 0.134214    
2024-04-23 21:29:18,037 - Epoch: [352][  296/  296]    Overall Loss 0.714963    Objective Loss 0.714963    Top1 81.967213    Top5 95.081967    LR 0.000005    Time 0.134451    
2024-04-23 21:29:18,253 - --- validate (epoch=352)-----------
2024-04-23 21:29:18,254 - 3925 samples (32 per mini-batch)
2024-04-23 21:29:33,080 - Epoch: [352][  100/  123]    Loss 0.693626    Top1 77.687500    Top5 97.562500    
2024-04-23 21:29:35,989 - Epoch: [352][  123/  123]    Loss 0.702871    Top1 77.503185    Top5 97.299363    
2024-04-23 21:29:36,240 - ==> Top1: 77.503    Top5: 97.299    Loss: 0.703

2024-04-23 21:29:36,251 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:29:36,251 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:29:36,326 - 

2024-04-23 21:29:36,328 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:29:49,596 - Epoch: [353][  100/  296]    Overall Loss 0.667745    Objective Loss 0.667745                                        LR 0.000005    Time 0.132496    
2024-04-23 21:30:00,080 - Epoch: [353][  200/  296]    Overall Loss 0.680457    Objective Loss 0.680457                                        LR 0.000005    Time 0.118579    
2024-04-23 21:30:10,552 - Epoch: [353][  296/  296]    Overall Loss 0.700793    Objective Loss 0.700793    Top1 67.213115    Top5 96.721311    LR 0.000005    Time 0.115445    
2024-04-23 21:30:10,928 - --- validate (epoch=353)-----------
2024-04-23 21:30:10,929 - 3925 samples (32 per mini-batch)
2024-04-23 21:30:26,312 - Epoch: [353][  100/  123]    Loss 0.677926    Top1 78.125000    Top5 97.500000    
2024-04-23 21:30:29,312 - Epoch: [353][  123/  123]    Loss 0.698794    Top1 77.859873    Top5 97.222930    
2024-04-23 21:30:29,608 - ==> Top1: 77.860    Top5: 97.223    Loss: 0.699

2024-04-23 21:30:29,621 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:30:29,622 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:30:29,670 - 

2024-04-23 21:30:29,671 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:30:39,570 - Epoch: [354][  100/  296]    Overall Loss 0.717899    Objective Loss 0.717899                                        LR 0.000005    Time 0.098810    
2024-04-23 21:30:46,580 - Epoch: [354][  200/  296]    Overall Loss 0.701740    Objective Loss 0.701740                                        LR 0.000005    Time 0.084377    
2024-04-23 21:30:53,922 - Epoch: [354][  296/  296]    Overall Loss 0.701402    Objective Loss 0.701402    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.081767    
2024-04-23 21:30:54,169 - --- validate (epoch=354)-----------
2024-04-23 21:30:54,170 - 3925 samples (32 per mini-batch)
2024-04-23 21:31:06,922 - Epoch: [354][  100/  123]    Loss 0.725097    Top1 76.906250    Top5 97.156250    
2024-04-23 21:31:09,183 - Epoch: [354][  123/  123]    Loss 0.705093    Top1 77.452229    Top5 97.273885    
2024-04-23 21:31:09,520 - ==> Top1: 77.452    Top5: 97.274    Loss: 0.705

2024-04-23 21:31:09,530 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:31:09,531 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:31:09,573 - 

2024-04-23 21:31:09,573 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:31:18,714 - Epoch: [355][  100/  296]    Overall Loss 0.734037    Objective Loss 0.734037                                        LR 0.000005    Time 0.091242    
2024-04-23 21:31:27,544 - Epoch: [355][  200/  296]    Overall Loss 0.729761    Objective Loss 0.729761                                        LR 0.000005    Time 0.089691    
2024-04-23 21:31:37,102 - Epoch: [355][  296/  296]    Overall Loss 0.728706    Objective Loss 0.728706    Top1 72.131148    Top5 93.442623    LR 0.000005    Time 0.092836    
2024-04-23 21:31:37,321 - --- validate (epoch=355)-----------
2024-04-23 21:31:37,322 - 3925 samples (32 per mini-batch)
2024-04-23 21:31:49,656 - Epoch: [355][  100/  123]    Loss 0.714755    Top1 77.406250    Top5 97.156250    
2024-04-23 21:31:52,282 - Epoch: [355][  123/  123]    Loss 0.701946    Top1 77.783439    Top5 97.299363    
2024-04-23 21:31:52,504 - ==> Top1: 77.783    Top5: 97.299    Loss: 0.702

2024-04-23 21:31:52,512 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:31:52,512 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:31:52,552 - 

2024-04-23 21:31:52,552 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:32:03,320 - Epoch: [356][  100/  296]    Overall Loss 0.703854    Objective Loss 0.703854                                        LR 0.000005    Time 0.107511    
2024-04-23 21:32:12,012 - Epoch: [356][  200/  296]    Overall Loss 0.709700    Objective Loss 0.709700                                        LR 0.000005    Time 0.097129    
2024-04-23 21:32:20,248 - Epoch: [356][  296/  296]    Overall Loss 0.714482    Objective Loss 0.714482    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.093401    
2024-04-23 21:32:20,481 - --- validate (epoch=356)-----------
2024-04-23 21:32:20,482 - 3925 samples (32 per mini-batch)
2024-04-23 21:32:31,033 - Epoch: [356][  100/  123]    Loss 0.715390    Top1 77.281250    Top5 97.125000    
2024-04-23 21:32:33,349 - Epoch: [356][  123/  123]    Loss 0.705654    Top1 77.554140    Top5 97.222930    
2024-04-23 21:32:33,546 - ==> Top1: 77.554    Top5: 97.223    Loss: 0.706

2024-04-23 21:32:33,553 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:32:33,553 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:32:33,598 - 

2024-04-23 21:32:33,599 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:32:43,868 - Epoch: [357][  100/  296]    Overall Loss 0.688792    Objective Loss 0.688792                                        LR 0.000005    Time 0.102513    
2024-04-23 21:32:53,099 - Epoch: [357][  200/  296]    Overall Loss 0.703830    Objective Loss 0.703830                                        LR 0.000005    Time 0.097333    
2024-04-23 21:33:01,941 - Epoch: [357][  296/  296]    Overall Loss 0.703907    Objective Loss 0.703907    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.095584    
2024-04-23 21:33:02,185 - --- validate (epoch=357)-----------
2024-04-23 21:33:02,185 - 3925 samples (32 per mini-batch)
2024-04-23 21:33:14,348 - Epoch: [357][  100/  123]    Loss 0.692408    Top1 78.000000    Top5 97.562500    
2024-04-23 21:33:16,361 - Epoch: [357][  123/  123]    Loss 0.702021    Top1 77.656051    Top5 97.299363    
2024-04-23 21:33:16,589 - ==> Top1: 77.656    Top5: 97.299    Loss: 0.702

2024-04-23 21:33:16,598 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:33:16,599 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:33:16,634 - 

2024-04-23 21:33:16,635 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:33:26,858 - Epoch: [358][  100/  296]    Overall Loss 0.699341    Objective Loss 0.699341                                        LR 0.000005    Time 0.102062    
2024-04-23 21:33:33,538 - Epoch: [358][  200/  296]    Overall Loss 0.705334    Objective Loss 0.705334                                        LR 0.000005    Time 0.084355    
2024-04-23 21:33:39,775 - Epoch: [358][  296/  296]    Overall Loss 0.696036    Objective Loss 0.696036    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.078029    
2024-04-23 21:33:40,041 - --- validate (epoch=358)-----------
2024-04-23 21:33:40,042 - 3925 samples (32 per mini-batch)
2024-04-23 21:33:52,138 - Epoch: [358][  100/  123]    Loss 0.690484    Top1 78.250000    Top5 97.281250    
2024-04-23 21:33:54,441 - Epoch: [358][  123/  123]    Loss 0.706000    Top1 77.681529    Top5 97.324841    
2024-04-23 21:33:54,651 - ==> Top1: 77.682    Top5: 97.325    Loss: 0.706

2024-04-23 21:33:54,660 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:33:54,661 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:33:54,703 - 

2024-04-23 21:33:54,703 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:34:05,719 - Epoch: [359][  100/  296]    Overall Loss 0.704547    Objective Loss 0.704547                                        LR 0.000005    Time 0.109993    
2024-04-23 21:34:16,326 - Epoch: [359][  200/  296]    Overall Loss 0.712166    Objective Loss 0.712166                                        LR 0.000005    Time 0.107949    
2024-04-23 21:34:27,221 - Epoch: [359][  296/  296]    Overall Loss 0.716334    Objective Loss 0.716334    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.109692    
2024-04-23 21:34:27,443 - --- validate (epoch=359)-----------
2024-04-23 21:34:27,444 - 3925 samples (32 per mini-batch)
2024-04-23 21:34:39,968 - Epoch: [359][  100/  123]    Loss 0.711451    Top1 77.312500    Top5 97.281250    
2024-04-23 21:34:42,752 - Epoch: [359][  123/  123]    Loss 0.699413    Top1 77.605096    Top5 97.426752    
2024-04-23 21:34:42,963 - ==> Top1: 77.605    Top5: 97.427    Loss: 0.699

2024-04-23 21:34:42,972 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:34:42,973 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:34:43,012 - 

2024-04-23 21:34:43,012 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:34:53,090 - Epoch: [360][  100/  296]    Overall Loss 0.690443    Objective Loss 0.690443                                        LR 0.000005    Time 0.100610    
2024-04-23 21:35:05,467 - Epoch: [360][  200/  296]    Overall Loss 0.690170    Objective Loss 0.690170                                        LR 0.000005    Time 0.112105    
2024-04-23 21:35:18,507 - Epoch: [360][  296/  296]    Overall Loss 0.698225    Objective Loss 0.698225    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.119748    
2024-04-23 21:35:18,775 - --- validate (epoch=360)-----------
2024-04-23 21:35:18,776 - 3925 samples (32 per mini-batch)
2024-04-23 21:35:35,891 - Epoch: [360][  100/  123]    Loss 0.709541    Top1 77.562500    Top5 97.250000    
2024-04-23 21:35:39,706 - Epoch: [360][  123/  123]    Loss 0.702505    Top1 77.681529    Top5 97.375796    
2024-04-23 21:35:40,009 - ==> Top1: 77.682    Top5: 97.376    Loss: 0.703

2024-04-23 21:35:40,020 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:35:40,021 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:35:40,073 - 

2024-04-23 21:35:40,074 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:35:55,826 - Epoch: [361][  100/  296]    Overall Loss 0.708425    Objective Loss 0.708425                                        LR 0.000005    Time 0.157316    
2024-04-23 21:36:08,302 - Epoch: [361][  200/  296]    Overall Loss 0.723811    Objective Loss 0.723811                                        LR 0.000005    Time 0.140951    
2024-04-23 21:36:20,786 - Epoch: [361][  296/  296]    Overall Loss 0.718199    Objective Loss 0.718199    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.137354    
2024-04-23 21:36:21,064 - --- validate (epoch=361)-----------
2024-04-23 21:36:21,065 - 3925 samples (32 per mini-batch)
2024-04-23 21:36:35,592 - Epoch: [361][  100/  123]    Loss 0.702299    Top1 78.062500    Top5 97.187500    
2024-04-23 21:36:38,324 - Epoch: [361][  123/  123]    Loss 0.699409    Top1 77.936306    Top5 97.273885    
2024-04-23 21:36:38,476 - ==> Top1: 77.936    Top5: 97.274    Loss: 0.699

2024-04-23 21:36:38,486 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:36:38,486 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:36:38,533 - 

2024-04-23 21:36:38,534 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:36:49,356 - Epoch: [362][  100/  296]    Overall Loss 0.709638    Objective Loss 0.709638                                        LR 0.000005    Time 0.108061    
2024-04-23 21:37:00,635 - Epoch: [362][  200/  296]    Overall Loss 0.701726    Objective Loss 0.701726                                        LR 0.000005    Time 0.110344    
2024-04-23 21:37:10,529 - Epoch: [362][  296/  296]    Overall Loss 0.697117    Objective Loss 0.697117    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.107926    
2024-04-23 21:37:10,698 - --- validate (epoch=362)-----------
2024-04-23 21:37:10,699 - 3925 samples (32 per mini-batch)
2024-04-23 21:37:24,052 - Epoch: [362][  100/  123]    Loss 0.706978    Top1 77.437500    Top5 97.281250    
2024-04-23 21:37:27,153 - Epoch: [362][  123/  123]    Loss 0.704065    Top1 77.630573    Top5 97.222930    
2024-04-23 21:37:27,301 - ==> Top1: 77.631    Top5: 97.223    Loss: 0.704

2024-04-23 21:37:27,306 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:37:27,307 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:37:27,342 - 

2024-04-23 21:37:27,343 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:37:37,403 - Epoch: [363][  100/  296]    Overall Loss 0.706890    Objective Loss 0.706890                                        LR 0.000005    Time 0.100448    
2024-04-23 21:37:45,581 - Epoch: [363][  200/  296]    Overall Loss 0.714157    Objective Loss 0.714157                                        LR 0.000005    Time 0.091033    
2024-04-23 21:37:54,373 - Epoch: [363][  296/  296]    Overall Loss 0.708609    Objective Loss 0.708609    Top1 70.491803    Top5 98.360656    LR 0.000005    Time 0.091170    
2024-04-23 21:37:54,500 - --- validate (epoch=363)-----------
2024-04-23 21:37:54,501 - 3925 samples (32 per mini-batch)
2024-04-23 21:38:04,537 - Epoch: [363][  100/  123]    Loss 0.698563    Top1 77.562500    Top5 97.312500    
2024-04-23 21:38:06,589 - Epoch: [363][  123/  123]    Loss 0.703133    Top1 77.681529    Top5 97.273885    
2024-04-23 21:38:06,712 - ==> Top1: 77.682    Top5: 97.274    Loss: 0.703

2024-04-23 21:38:06,721 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:38:06,721 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:38:06,794 - 

2024-04-23 21:38:06,794 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:38:15,709 - Epoch: [364][  100/  296]    Overall Loss 0.693640    Objective Loss 0.693640                                        LR 0.000005    Time 0.088994    
2024-04-23 21:38:24,201 - Epoch: [364][  200/  296]    Overall Loss 0.708834    Objective Loss 0.708834                                        LR 0.000005    Time 0.086889    
2024-04-23 21:38:31,723 - Epoch: [364][  296/  296]    Overall Loss 0.714251    Objective Loss 0.714251    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.084073    
2024-04-23 21:38:31,833 - --- validate (epoch=364)-----------
2024-04-23 21:38:31,834 - 3925 samples (32 per mini-batch)
2024-04-23 21:38:41,752 - Epoch: [364][  100/  123]    Loss 0.714138    Top1 77.093750    Top5 97.031250    
2024-04-23 21:38:44,562 - Epoch: [364][  123/  123]    Loss 0.702344    Top1 77.757962    Top5 97.222930    
2024-04-23 21:38:44,708 - ==> Top1: 77.758    Top5: 97.223    Loss: 0.702

2024-04-23 21:38:44,716 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:38:44,717 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:38:44,763 - 

2024-04-23 21:38:44,764 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:38:56,323 - Epoch: [365][  100/  296]    Overall Loss 0.704767    Objective Loss 0.704767                                        LR 0.000005    Time 0.115439    
2024-04-23 21:39:08,288 - Epoch: [365][  200/  296]    Overall Loss 0.723648    Objective Loss 0.723648                                        LR 0.000005    Time 0.117465    
2024-04-23 21:39:18,382 - Epoch: [365][  296/  296]    Overall Loss 0.710405    Objective Loss 0.710405    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.113414    
2024-04-23 21:39:18,691 - --- validate (epoch=365)-----------
2024-04-23 21:39:18,692 - 3925 samples (32 per mini-batch)
2024-04-23 21:39:33,699 - Epoch: [365][  100/  123]    Loss 0.701818    Top1 77.875000    Top5 97.062500    
2024-04-23 21:39:37,356 - Epoch: [365][  123/  123]    Loss 0.702640    Top1 77.757962    Top5 97.197452    
2024-04-23 21:39:37,548 - ==> Top1: 77.758    Top5: 97.197    Loss: 0.703

2024-04-23 21:39:37,563 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:39:37,564 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:39:37,622 - 

2024-04-23 21:39:37,622 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:39:51,304 - Epoch: [366][  100/  296]    Overall Loss 0.736894    Objective Loss 0.736894                                        LR 0.000005    Time 0.136626    
2024-04-23 21:40:03,017 - Epoch: [366][  200/  296]    Overall Loss 0.712878    Objective Loss 0.712878                                        LR 0.000005    Time 0.126798    
2024-04-23 21:40:15,255 - Epoch: [366][  296/  296]    Overall Loss 0.712852    Objective Loss 0.712852    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.126968    
2024-04-23 21:40:15,460 - --- validate (epoch=366)-----------
2024-04-23 21:40:15,461 - 3925 samples (32 per mini-batch)
2024-04-23 21:40:30,234 - Epoch: [366][  100/  123]    Loss 0.711837    Top1 77.312500    Top5 97.343750    
2024-04-23 21:40:33,254 - Epoch: [366][  123/  123]    Loss 0.703263    Top1 77.554140    Top5 97.375796    
2024-04-23 21:40:33,452 - ==> Top1: 77.554    Top5: 97.376    Loss: 0.703

2024-04-23 21:40:33,462 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:40:33,462 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:40:33,500 - 

2024-04-23 21:40:33,501 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:40:46,612 - Epoch: [367][  100/  296]    Overall Loss 0.733506    Objective Loss 0.733506                                        LR 0.000005    Time 0.130907    
2024-04-23 21:40:58,993 - Epoch: [367][  200/  296]    Overall Loss 0.711921    Objective Loss 0.711921                                        LR 0.000005    Time 0.127285    
2024-04-23 21:41:10,516 - Epoch: [367][  296/  296]    Overall Loss 0.710008    Objective Loss 0.710008    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.124892    
2024-04-23 21:41:10,824 - --- validate (epoch=367)-----------
2024-04-23 21:41:10,825 - 3925 samples (32 per mini-batch)
2024-04-23 21:41:26,360 - Epoch: [367][  100/  123]    Loss 0.702011    Top1 77.812500    Top5 97.593750    
2024-04-23 21:41:29,612 - Epoch: [367][  123/  123]    Loss 0.700725    Top1 77.936306    Top5 97.401274    
2024-04-23 21:41:29,823 - ==> Top1: 77.936    Top5: 97.401    Loss: 0.701

2024-04-23 21:41:29,832 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:41:29,833 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:41:29,893 - 

2024-04-23 21:41:29,894 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:41:40,307 - Epoch: [368][  100/  296]    Overall Loss 0.701772    Objective Loss 0.701772                                        LR 0.000005    Time 0.103958    
2024-04-23 21:41:47,902 - Epoch: [368][  200/  296]    Overall Loss 0.712920    Objective Loss 0.712920                                        LR 0.000005    Time 0.089879    
2024-04-23 21:41:55,869 - Epoch: [368][  296/  296]    Overall Loss 0.708056    Objective Loss 0.708056    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.087593    
2024-04-23 21:41:56,187 - --- validate (epoch=368)-----------
2024-04-23 21:41:56,188 - 3925 samples (32 per mini-batch)
2024-04-23 21:42:08,393 - Epoch: [368][  100/  123]    Loss 0.705077    Top1 77.531250    Top5 97.406250    
2024-04-23 21:42:11,246 - Epoch: [368][  123/  123]    Loss 0.699628    Top1 77.579618    Top5 97.401274    
2024-04-23 21:42:11,532 - ==> Top1: 77.580    Top5: 97.401    Loss: 0.700

2024-04-23 21:42:11,543 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:42:11,543 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:42:11,598 - 

2024-04-23 21:42:11,599 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:42:23,321 - Epoch: [369][  100/  296]    Overall Loss 0.758460    Objective Loss 0.758460                                        LR 0.000005    Time 0.117043    
2024-04-23 21:42:30,879 - Epoch: [369][  200/  296]    Overall Loss 0.750341    Objective Loss 0.750341                                        LR 0.000005    Time 0.096232    
2024-04-23 21:42:39,798 - Epoch: [369][  296/  296]    Overall Loss 0.742932    Objective Loss 0.742932    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.095098    
2024-04-23 21:42:40,081 - --- validate (epoch=369)-----------
2024-04-23 21:42:40,082 - 3925 samples (32 per mini-batch)
2024-04-23 21:42:53,958 - Epoch: [369][  100/  123]    Loss 0.695811    Top1 78.156250    Top5 97.000000    
2024-04-23 21:42:56,969 - Epoch: [369][  123/  123]    Loss 0.701349    Top1 77.681529    Top5 97.222930    
2024-04-23 21:42:57,197 - ==> Top1: 77.682    Top5: 97.223    Loss: 0.701

2024-04-23 21:42:57,209 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:42:57,209 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:42:57,258 - 

2024-04-23 21:42:57,259 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:43:10,499 - Epoch: [370][  100/  296]    Overall Loss 0.728356    Objective Loss 0.728356                                        LR 0.000005    Time 0.132232    
2024-04-23 21:43:21,961 - Epoch: [370][  200/  296]    Overall Loss 0.721762    Objective Loss 0.721762                                        LR 0.000005    Time 0.123345    
2024-04-23 21:43:34,773 - Epoch: [370][  296/  296]    Overall Loss 0.712367    Objective Loss 0.712367    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.126570    
2024-04-23 21:43:35,162 - --- validate (epoch=370)-----------
2024-04-23 21:43:35,163 - 3925 samples (32 per mini-batch)
2024-04-23 21:43:47,328 - Epoch: [370][  100/  123]    Loss 0.705418    Top1 77.812500    Top5 97.312500    
2024-04-23 21:43:49,899 - Epoch: [370][  123/  123]    Loss 0.701782    Top1 77.808917    Top5 97.401274    
2024-04-23 21:43:50,173 - ==> Top1: 77.809    Top5: 97.401    Loss: 0.702

2024-04-23 21:43:50,181 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:43:50,181 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:43:50,230 - 

2024-04-23 21:43:50,231 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:44:03,351 - Epoch: [371][  100/  296]    Overall Loss 0.708320    Objective Loss 0.708320                                        LR 0.000005    Time 0.131037    
2024-04-23 21:44:13,465 - Epoch: [371][  200/  296]    Overall Loss 0.716544    Objective Loss 0.716544                                        LR 0.000005    Time 0.116002    
2024-04-23 21:44:22,522 - Epoch: [371][  296/  296]    Overall Loss 0.715054    Objective Loss 0.715054    Top1 72.131148    Top5 100.000000    LR 0.000005    Time 0.108920    
2024-04-23 21:44:22,784 - --- validate (epoch=371)-----------
2024-04-23 21:44:22,785 - 3925 samples (32 per mini-batch)
2024-04-23 21:44:35,649 - Epoch: [371][  100/  123]    Loss 0.712686    Top1 77.312500    Top5 97.343750    
2024-04-23 21:44:39,052 - Epoch: [371][  123/  123]    Loss 0.704128    Top1 77.426752    Top5 97.273885    
2024-04-23 21:44:39,300 - ==> Top1: 77.427    Top5: 97.274    Loss: 0.704

2024-04-23 21:44:39,309 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:44:39,309 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:44:39,351 - 

2024-04-23 21:44:39,351 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:44:51,092 - Epoch: [372][  100/  296]    Overall Loss 0.747794    Objective Loss 0.747794                                        LR 0.000005    Time 0.117228    
2024-04-23 21:45:02,065 - Epoch: [372][  200/  296]    Overall Loss 0.725121    Objective Loss 0.725121                                        LR 0.000005    Time 0.113397    
2024-04-23 21:45:12,528 - Epoch: [372][  296/  296]    Overall Loss 0.723725    Objective Loss 0.723725    Top1 77.049180    Top5 93.442623    LR 0.000005    Time 0.111913    
2024-04-23 21:45:12,816 - --- validate (epoch=372)-----------
2024-04-23 21:45:12,818 - 3925 samples (32 per mini-batch)
2024-04-23 21:45:28,634 - Epoch: [372][  100/  123]    Loss 0.697442    Top1 77.656250    Top5 97.250000    
2024-04-23 21:45:32,098 - Epoch: [372][  123/  123]    Loss 0.700055    Top1 77.783439    Top5 97.324841    
2024-04-23 21:45:32,366 - ==> Top1: 77.783    Top5: 97.325    Loss: 0.700

2024-04-23 21:45:32,373 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:45:32,374 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:45:32,417 - 

2024-04-23 21:45:32,418 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:45:46,307 - Epoch: [373][  100/  296]    Overall Loss 0.704829    Objective Loss 0.704829                                        LR 0.000005    Time 0.138710    
2024-04-23 21:45:58,318 - Epoch: [373][  200/  296]    Overall Loss 0.721318    Objective Loss 0.721318                                        LR 0.000005    Time 0.129324    
2024-04-23 21:46:09,457 - Epoch: [373][  296/  296]    Overall Loss 0.712846    Objective Loss 0.712846    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.124952    
2024-04-23 21:46:09,803 - --- validate (epoch=373)-----------
2024-04-23 21:46:09,804 - 3925 samples (32 per mini-batch)
2024-04-23 21:46:27,129 - Epoch: [373][  100/  123]    Loss 0.710656    Top1 77.406250    Top5 97.218750    
2024-04-23 21:46:31,564 - Epoch: [373][  123/  123]    Loss 0.699548    Top1 77.554140    Top5 97.324841    
2024-04-23 21:46:31,732 - ==> Top1: 77.554    Top5: 97.325    Loss: 0.700

2024-04-23 21:46:31,744 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:46:31,744 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:46:31,787 - 

2024-04-23 21:46:31,788 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:46:40,768 - Epoch: [374][  100/  296]    Overall Loss 0.710395    Objective Loss 0.710395                                        LR 0.000005    Time 0.089641    
2024-04-23 21:46:49,225 - Epoch: [374][  200/  296]    Overall Loss 0.705713    Objective Loss 0.705713                                        LR 0.000005    Time 0.087036    
2024-04-23 21:46:55,908 - Epoch: [374][  296/  296]    Overall Loss 0.707031    Objective Loss 0.707031    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.081333    
2024-04-23 21:46:56,018 - --- validate (epoch=374)-----------
2024-04-23 21:46:56,019 - 3925 samples (32 per mini-batch)
2024-04-23 21:47:05,247 - Epoch: [374][  100/  123]    Loss 0.689136    Top1 78.500000    Top5 97.406250    
2024-04-23 21:47:07,407 - Epoch: [374][  123/  123]    Loss 0.701349    Top1 77.732484    Top5 97.401274    
2024-04-23 21:47:07,493 - ==> Top1: 77.732    Top5: 97.401    Loss: 0.701

2024-04-23 21:47:07,502 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:47:07,502 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:47:07,540 - 

2024-04-23 21:47:07,540 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:47:15,920 - Epoch: [375][  100/  296]    Overall Loss 0.702885    Objective Loss 0.702885                                        LR 0.000005    Time 0.083662    
2024-04-23 21:47:27,270 - Epoch: [375][  200/  296]    Overall Loss 0.710089    Objective Loss 0.710089                                        LR 0.000005    Time 0.098504    
2024-04-23 21:47:37,450 - Epoch: [375][  296/  296]    Overall Loss 0.713749    Objective Loss 0.713749    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.100895    
2024-04-23 21:47:37,655 - --- validate (epoch=375)-----------
2024-04-23 21:47:37,656 - 3925 samples (32 per mini-batch)
2024-04-23 21:47:51,823 - Epoch: [375][  100/  123]    Loss 0.714645    Top1 77.437500    Top5 97.281250    
2024-04-23 21:47:54,948 - Epoch: [375][  123/  123]    Loss 0.704095    Top1 77.605096    Top5 97.324841    
2024-04-23 21:47:55,136 - ==> Top1: 77.605    Top5: 97.325    Loss: 0.704

2024-04-23 21:47:55,144 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:47:55,145 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:47:55,191 - 

2024-04-23 21:47:55,191 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:48:08,888 - Epoch: [376][  100/  296]    Overall Loss 0.677643    Objective Loss 0.677643                                        LR 0.000005    Time 0.136791    
2024-04-23 21:48:18,651 - Epoch: [376][  200/  296]    Overall Loss 0.704231    Objective Loss 0.704231                                        LR 0.000005    Time 0.117128    
2024-04-23 21:48:29,170 - Epoch: [376][  296/  296]    Overall Loss 0.700211    Objective Loss 0.700211    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.114623    
2024-04-23 21:48:29,337 - --- validate (epoch=376)-----------
2024-04-23 21:48:29,338 - 3925 samples (32 per mini-batch)
2024-04-23 21:48:40,960 - Epoch: [376][  100/  123]    Loss 0.707726    Top1 77.718750    Top5 97.343750    
2024-04-23 21:48:42,532 - Epoch: [376][  123/  123]    Loss 0.701583    Top1 77.936306    Top5 97.197452    
2024-04-23 21:48:42,618 - ==> Top1: 77.936    Top5: 97.197    Loss: 0.702

2024-04-23 21:48:42,627 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:48:42,628 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:48:42,665 - 

2024-04-23 21:48:42,665 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:48:50,653 - Epoch: [377][  100/  296]    Overall Loss 0.730519    Objective Loss 0.730519                                        LR 0.000005    Time 0.079738    
2024-04-23 21:48:58,890 - Epoch: [377][  200/  296]    Overall Loss 0.723844    Objective Loss 0.723844                                        LR 0.000005    Time 0.080987    
2024-04-23 21:49:10,094 - Epoch: [377][  296/  296]    Overall Loss 0.718306    Objective Loss 0.718306    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.092523    
2024-04-23 21:49:10,185 - --- validate (epoch=377)-----------
2024-04-23 21:49:10,185 - 3925 samples (32 per mini-batch)
2024-04-23 21:49:18,797 - Epoch: [377][  100/  123]    Loss 0.710538    Top1 77.500000    Top5 97.531250    
2024-04-23 21:49:20,527 - Epoch: [377][  123/  123]    Loss 0.700663    Top1 77.707006    Top5 97.503185    
2024-04-23 21:49:20,639 - ==> Top1: 77.707    Top5: 97.503    Loss: 0.701

2024-04-23 21:49:20,648 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:49:20,648 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:49:20,686 - 

2024-04-23 21:49:20,687 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:49:29,212 - Epoch: [378][  100/  296]    Overall Loss 0.702870    Objective Loss 0.702870                                        LR 0.000005    Time 0.085112    
2024-04-23 21:49:35,084 - Epoch: [378][  200/  296]    Overall Loss 0.708284    Objective Loss 0.708284                                        LR 0.000005    Time 0.071844    
2024-04-23 21:49:45,000 - Epoch: [378][  296/  296]    Overall Loss 0.709799    Objective Loss 0.709799    Top1 85.245902    Top5 96.721311    LR 0.000005    Time 0.081988    
2024-04-23 21:49:45,141 - --- validate (epoch=378)-----------
2024-04-23 21:49:45,142 - 3925 samples (32 per mini-batch)
2024-04-23 21:49:53,693 - Epoch: [378][  100/  123]    Loss 0.687393    Top1 78.218750    Top5 97.406250    
2024-04-23 21:49:56,060 - Epoch: [378][  123/  123]    Loss 0.704126    Top1 77.605096    Top5 97.197452    
2024-04-23 21:49:56,198 - ==> Top1: 77.605    Top5: 97.197    Loss: 0.704

2024-04-23 21:49:56,205 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:49:56,206 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:49:56,279 - 

2024-04-23 21:49:56,280 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:50:09,765 - Epoch: [379][  100/  296]    Overall Loss 0.708197    Objective Loss 0.708197                                        LR 0.000005    Time 0.134698    
2024-04-23 21:50:20,937 - Epoch: [379][  200/  296]    Overall Loss 0.712388    Objective Loss 0.712388                                        LR 0.000005    Time 0.123122    
2024-04-23 21:50:30,810 - Epoch: [379][  296/  296]    Overall Loss 0.721345    Objective Loss 0.721345    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.116493    
2024-04-23 21:50:31,083 - --- validate (epoch=379)-----------
2024-04-23 21:50:31,084 - 3925 samples (32 per mini-batch)
2024-04-23 21:50:46,617 - Epoch: [379][  100/  123]    Loss 0.693801    Top1 78.281250    Top5 97.343750    
2024-04-23 21:50:49,197 - Epoch: [379][  123/  123]    Loss 0.703969    Top1 77.783439    Top5 97.299363    
2024-04-23 21:50:49,458 - ==> Top1: 77.783    Top5: 97.299    Loss: 0.704

2024-04-23 21:50:49,469 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:50:49,470 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:50:49,516 - 

2024-04-23 21:50:49,516 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:51:02,464 - Epoch: [380][  100/  296]    Overall Loss 0.731286    Objective Loss 0.731286                                        LR 0.000005    Time 0.129295    
2024-04-23 21:51:13,954 - Epoch: [380][  200/  296]    Overall Loss 0.713086    Objective Loss 0.713086                                        LR 0.000005    Time 0.122009    
2024-04-23 21:51:25,007 - Epoch: [380][  296/  296]    Overall Loss 0.714783    Objective Loss 0.714783    Top1 86.885246    Top5 96.721311    LR 0.000005    Time 0.119724    
2024-04-23 21:51:25,236 - --- validate (epoch=380)-----------
2024-04-23 21:51:25,237 - 3925 samples (32 per mini-batch)
2024-04-23 21:51:38,051 - Epoch: [380][  100/  123]    Loss 0.684676    Top1 78.750000    Top5 97.468750    
2024-04-23 21:51:40,442 - Epoch: [380][  123/  123]    Loss 0.703208    Top1 78.063694    Top5 97.375796    
2024-04-23 21:51:40,832 - ==> Top1: 78.064    Top5: 97.376    Loss: 0.703

2024-04-23 21:51:40,843 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:51:40,843 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:51:40,888 - 

2024-04-23 21:51:40,889 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:51:49,928 - Epoch: [381][  100/  296]    Overall Loss 0.724694    Objective Loss 0.724694                                        LR 0.000005    Time 0.090245    
2024-04-23 21:52:02,405 - Epoch: [381][  200/  296]    Overall Loss 0.737238    Objective Loss 0.737238                                        LR 0.000005    Time 0.107427    
2024-04-23 21:52:14,623 - Epoch: [381][  296/  296]    Overall Loss 0.721150    Objective Loss 0.721150    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.113809    
2024-04-23 21:52:14,895 - --- validate (epoch=381)-----------
2024-04-23 21:52:14,896 - 3925 samples (32 per mini-batch)
2024-04-23 21:52:29,469 - Epoch: [381][  100/  123]    Loss 0.694118    Top1 78.312500    Top5 97.593750    
2024-04-23 21:52:32,586 - Epoch: [381][  123/  123]    Loss 0.706038    Top1 77.757962    Top5 97.299363    
2024-04-23 21:52:32,846 - ==> Top1: 77.758    Top5: 97.299    Loss: 0.706

2024-04-23 21:52:32,857 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:52:32,858 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:52:32,903 - 

2024-04-23 21:52:32,904 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:52:45,798 - Epoch: [382][  100/  296]    Overall Loss 0.711578    Objective Loss 0.711578                                        LR 0.000005    Time 0.128788    
2024-04-23 21:52:57,604 - Epoch: [382][  200/  296]    Overall Loss 0.717261    Objective Loss 0.717261                                        LR 0.000005    Time 0.123333    
2024-04-23 21:53:08,152 - Epoch: [382][  296/  296]    Overall Loss 0.717506    Objective Loss 0.717506    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.118915    
2024-04-23 21:53:08,374 - --- validate (epoch=382)-----------
2024-04-23 21:53:08,375 - 3925 samples (32 per mini-batch)
2024-04-23 21:53:22,957 - Epoch: [382][  100/  123]    Loss 0.700584    Top1 77.656250    Top5 97.312500    
2024-04-23 21:53:25,868 - Epoch: [382][  123/  123]    Loss 0.702511    Top1 77.732484    Top5 97.197452    
2024-04-23 21:53:26,115 - ==> Top1: 77.732    Top5: 97.197    Loss: 0.703

2024-04-23 21:53:26,125 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:53:26,126 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:53:26,167 - 

2024-04-23 21:53:26,168 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:53:38,226 - Epoch: [383][  100/  296]    Overall Loss 0.704825    Objective Loss 0.704825                                        LR 0.000005    Time 0.120422    
2024-04-23 21:53:50,780 - Epoch: [383][  200/  296]    Overall Loss 0.698753    Objective Loss 0.698753                                        LR 0.000005    Time 0.122895    
2024-04-23 21:54:01,100 - Epoch: [383][  296/  296]    Overall Loss 0.703915    Objective Loss 0.703915    Top1 90.163934    Top5 98.360656    LR 0.000005    Time 0.117846    
2024-04-23 21:54:01,403 - --- validate (epoch=383)-----------
2024-04-23 21:54:01,404 - 3925 samples (32 per mini-batch)
2024-04-23 21:54:12,181 - Epoch: [383][  100/  123]    Loss 0.704389    Top1 77.843750    Top5 97.250000    
2024-04-23 21:54:14,429 - Epoch: [383][  123/  123]    Loss 0.706335    Top1 77.554140    Top5 97.273885    
2024-04-23 21:54:14,699 - ==> Top1: 77.554    Top5: 97.274    Loss: 0.706

2024-04-23 21:54:14,709 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:54:14,710 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:54:14,761 - 

2024-04-23 21:54:14,762 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:54:23,273 - Epoch: [384][  100/  296]    Overall Loss 0.716215    Objective Loss 0.716215                                        LR 0.000005    Time 0.084918    
2024-04-23 21:54:33,409 - Epoch: [384][  200/  296]    Overall Loss 0.702493    Objective Loss 0.702493                                        LR 0.000005    Time 0.093046    
2024-04-23 21:54:42,099 - Epoch: [384][  296/  296]    Overall Loss 0.713994    Objective Loss 0.713994    Top1 65.573770    Top5 98.360656    LR 0.000005    Time 0.092174    
2024-04-23 21:54:42,334 - --- validate (epoch=384)-----------
2024-04-23 21:54:42,334 - 3925 samples (32 per mini-batch)
2024-04-23 21:54:56,082 - Epoch: [384][  100/  123]    Loss 0.695727    Top1 77.906250    Top5 97.343750    
2024-04-23 21:54:59,610 - Epoch: [384][  123/  123]    Loss 0.706152    Top1 77.554140    Top5 97.273885    
2024-04-23 21:54:59,893 - ==> Top1: 77.554    Top5: 97.274    Loss: 0.706

2024-04-23 21:54:59,907 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:54:59,908 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:54:59,950 - 

2024-04-23 21:54:59,950 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:55:08,720 - Epoch: [385][  100/  296]    Overall Loss 0.747303    Objective Loss 0.747303                                        LR 0.000005    Time 0.087541    
2024-04-23 21:55:17,035 - Epoch: [385][  200/  296]    Overall Loss 0.718294    Objective Loss 0.718294                                        LR 0.000005    Time 0.085259    
2024-04-23 21:55:24,849 - Epoch: [385][  296/  296]    Overall Loss 0.723375    Objective Loss 0.723375    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.083957    
2024-04-23 21:55:25,100 - --- validate (epoch=385)-----------
2024-04-23 21:55:25,100 - 3925 samples (32 per mini-batch)
2024-04-23 21:55:38,253 - Epoch: [385][  100/  123]    Loss 0.702948    Top1 77.625000    Top5 97.125000    
2024-04-23 21:55:40,932 - Epoch: [385][  123/  123]    Loss 0.701941    Top1 77.910828    Top5 97.248408    
2024-04-23 21:55:41,118 - ==> Top1: 77.911    Top5: 97.248    Loss: 0.702

2024-04-23 21:55:41,128 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:55:41,129 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:55:41,176 - 

2024-04-23 21:55:41,177 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:55:54,999 - Epoch: [386][  100/  296]    Overall Loss 0.662279    Objective Loss 0.662279                                        LR 0.000005    Time 0.138048    
2024-04-23 21:56:03,518 - Epoch: [386][  200/  296]    Overall Loss 0.691235    Objective Loss 0.691235                                        LR 0.000005    Time 0.111549    
2024-04-23 21:56:14,208 - Epoch: [386][  296/  296]    Overall Loss 0.703434    Objective Loss 0.703434    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.111434    
2024-04-23 21:56:14,388 - --- validate (epoch=386)-----------
2024-04-23 21:56:14,388 - 3925 samples (32 per mini-batch)
2024-04-23 21:56:28,353 - Epoch: [386][  100/  123]    Loss 0.681244    Top1 78.312500    Top5 97.406250    
2024-04-23 21:56:30,882 - Epoch: [386][  123/  123]    Loss 0.704178    Top1 77.605096    Top5 97.248408    
2024-04-23 21:56:31,174 - ==> Top1: 77.605    Top5: 97.248    Loss: 0.704

2024-04-23 21:56:31,182 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:56:31,182 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:56:31,244 - 

2024-04-23 21:56:31,245 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:56:45,500 - Epoch: [387][  100/  296]    Overall Loss 0.686856    Objective Loss 0.686856                                        LR 0.000005    Time 0.142373    
2024-04-23 21:56:57,128 - Epoch: [387][  200/  296]    Overall Loss 0.692280    Objective Loss 0.692280                                        LR 0.000005    Time 0.129244    
2024-04-23 21:57:08,468 - Epoch: [387][  296/  296]    Overall Loss 0.700363    Objective Loss 0.700363    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.125583    
2024-04-23 21:57:08,734 - --- validate (epoch=387)-----------
2024-04-23 21:57:08,735 - 3925 samples (32 per mini-batch)
2024-04-23 21:57:24,209 - Epoch: [387][  100/  123]    Loss 0.689371    Top1 78.281250    Top5 97.500000    
2024-04-23 21:57:27,582 - Epoch: [387][  123/  123]    Loss 0.703361    Top1 77.707006    Top5 97.171975    
2024-04-23 21:57:27,766 - ==> Top1: 77.707    Top5: 97.172    Loss: 0.703

2024-04-23 21:57:27,777 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:57:27,778 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:57:27,826 - 

2024-04-23 21:57:27,827 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:57:43,245 - Epoch: [388][  100/  296]    Overall Loss 0.740842    Objective Loss 0.740842                                        LR 0.000005    Time 0.154008    
2024-04-23 21:57:55,136 - Epoch: [388][  200/  296]    Overall Loss 0.720721    Objective Loss 0.720721                                        LR 0.000005    Time 0.136370    
2024-04-23 21:58:05,465 - Epoch: [388][  296/  296]    Overall Loss 0.722909    Objective Loss 0.722909    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.126986    
2024-04-23 21:58:05,616 - --- validate (epoch=388)-----------
2024-04-23 21:58:05,617 - 3925 samples (32 per mini-batch)
2024-04-23 21:58:22,468 - Epoch: [388][  100/  123]    Loss 0.710629    Top1 77.375000    Top5 97.500000    
2024-04-23 21:58:25,059 - Epoch: [388][  123/  123]    Loss 0.699398    Top1 77.757962    Top5 97.375796    
2024-04-23 21:58:25,332 - ==> Top1: 77.758    Top5: 97.376    Loss: 0.699

2024-04-23 21:58:25,341 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:58:25,341 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:58:25,390 - 

2024-04-23 21:58:25,391 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:58:39,517 - Epoch: [389][  100/  296]    Overall Loss 0.714985    Objective Loss 0.714985                                        LR 0.000005    Time 0.141100    
2024-04-23 21:58:50,357 - Epoch: [389][  200/  296]    Overall Loss 0.712032    Objective Loss 0.712032                                        LR 0.000005    Time 0.124661    
2024-04-23 21:58:56,724 - Epoch: [389][  296/  296]    Overall Loss 0.706790    Objective Loss 0.706790    Top1 88.524590    Top5 98.360656    LR 0.000005    Time 0.105697    
2024-04-23 21:58:56,979 - --- validate (epoch=389)-----------
2024-04-23 21:58:56,980 - 3925 samples (32 per mini-batch)
2024-04-23 21:59:10,990 - Epoch: [389][  100/  123]    Loss 0.708642    Top1 77.125000    Top5 97.125000    
2024-04-23 21:59:14,622 - Epoch: [389][  123/  123]    Loss 0.705563    Top1 77.401274    Top5 97.197452    
2024-04-23 21:59:14,853 - ==> Top1: 77.401    Top5: 97.197    Loss: 0.706

2024-04-23 21:59:14,860 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 21:59:14,861 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 21:59:14,905 - 

2024-04-23 21:59:14,905 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:59:28,134 - Epoch: [390][  100/  296]    Overall Loss 0.701662    Objective Loss 0.701662                                        LR 0.000005    Time 0.132145    
2024-04-23 21:59:40,507 - Epoch: [390][  200/  296]    Overall Loss 0.723487    Objective Loss 0.723487                                        LR 0.000005    Time 0.127869    
2024-04-23 21:59:51,750 - Epoch: [390][  296/  296]    Overall Loss 0.726977    Objective Loss 0.726977    Top1 67.213115    Top5 93.442623    LR 0.000005    Time 0.124337    
2024-04-23 21:59:52,034 - --- validate (epoch=390)-----------
2024-04-23 21:59:52,035 - 3925 samples (32 per mini-batch)
2024-04-23 22:00:05,209 - Epoch: [390][  100/  123]    Loss 0.690092    Top1 77.781250    Top5 97.281250    
2024-04-23 22:00:07,018 - Epoch: [390][  123/  123]    Loss 0.701888    Top1 77.528662    Top5 97.222930    
2024-04-23 22:00:07,231 - ==> Top1: 77.529    Top5: 97.223    Loss: 0.702

2024-04-23 22:00:07,236 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:00:07,237 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:00:07,273 - 

2024-04-23 22:00:07,274 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:00:18,567 - Epoch: [391][  100/  296]    Overall Loss 0.709142    Objective Loss 0.709142                                        LR 0.000005    Time 0.112767    
2024-04-23 22:00:33,285 - Epoch: [391][  200/  296]    Overall Loss 0.704198    Objective Loss 0.704198                                        LR 0.000005    Time 0.129887    
2024-04-23 22:00:46,802 - Epoch: [391][  296/  296]    Overall Loss 0.712452    Objective Loss 0.712452    Top1 75.409836    Top5 93.442623    LR 0.000005    Time 0.133378    
2024-04-23 22:00:47,048 - --- validate (epoch=391)-----------
2024-04-23 22:00:47,049 - 3925 samples (32 per mini-batch)
2024-04-23 22:00:57,635 - Epoch: [391][  100/  123]    Loss 0.712257    Top1 77.125000    Top5 97.343750    
2024-04-23 22:00:59,681 - Epoch: [391][  123/  123]    Loss 0.700733    Top1 77.401274    Top5 97.350318    
2024-04-23 22:00:59,948 - ==> Top1: 77.401    Top5: 97.350    Loss: 0.701

2024-04-23 22:00:59,956 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:00:59,956 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:00:59,992 - 

2024-04-23 22:00:59,992 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:01:10,274 - Epoch: [392][  100/  296]    Overall Loss 0.717460    Objective Loss 0.717460                                        LR 0.000005    Time 0.102650    
2024-04-23 22:01:19,790 - Epoch: [392][  200/  296]    Overall Loss 0.726721    Objective Loss 0.726721                                        LR 0.000005    Time 0.098823    
2024-04-23 22:01:30,618 - Epoch: [392][  296/  296]    Overall Loss 0.717072    Objective Loss 0.717072    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.103295    
2024-04-23 22:01:30,865 - --- validate (epoch=392)-----------
2024-04-23 22:01:30,865 - 3925 samples (32 per mini-batch)
2024-04-23 22:01:44,356 - Epoch: [392][  100/  123]    Loss 0.686255    Top1 78.000000    Top5 97.250000    
2024-04-23 22:01:47,100 - Epoch: [392][  123/  123]    Loss 0.701691    Top1 77.605096    Top5 97.222930    
2024-04-23 22:01:47,302 - ==> Top1: 77.605    Top5: 97.223    Loss: 0.702

2024-04-23 22:01:47,309 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:01:47,309 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:01:47,356 - 

2024-04-23 22:01:47,357 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:01:58,380 - Epoch: [393][  100/  296]    Overall Loss 0.699175    Objective Loss 0.699175                                        LR 0.000005    Time 0.110054    
2024-04-23 22:02:06,624 - Epoch: [393][  200/  296]    Overall Loss 0.718675    Objective Loss 0.718675                                        LR 0.000005    Time 0.096169    
2024-04-23 22:02:17,359 - Epoch: [393][  296/  296]    Overall Loss 0.721060    Objective Loss 0.721060    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.101195    
2024-04-23 22:02:17,660 - --- validate (epoch=393)-----------
2024-04-23 22:02:17,661 - 3925 samples (32 per mini-batch)
2024-04-23 22:02:33,354 - Epoch: [393][  100/  123]    Loss 0.696132    Top1 78.125000    Top5 97.156250    
2024-04-23 22:02:36,043 - Epoch: [393][  123/  123]    Loss 0.704588    Top1 77.528662    Top5 97.197452    
2024-04-23 22:02:36,271 - ==> Top1: 77.529    Top5: 97.197    Loss: 0.705

2024-04-23 22:02:36,283 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:02:36,283 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:02:36,321 - 

2024-04-23 22:02:36,322 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:02:48,015 - Epoch: [394][  100/  296]    Overall Loss 0.704147    Objective Loss 0.704147                                        LR 0.000005    Time 0.116747    
2024-04-23 22:02:56,976 - Epoch: [394][  200/  296]    Overall Loss 0.679555    Objective Loss 0.679555                                        LR 0.000005    Time 0.103097    
2024-04-23 22:03:06,170 - Epoch: [394][  296/  296]    Overall Loss 0.691515    Objective Loss 0.691515    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.100672    
2024-04-23 22:03:06,395 - --- validate (epoch=394)-----------
2024-04-23 22:03:06,396 - 3925 samples (32 per mini-batch)
2024-04-23 22:03:21,529 - Epoch: [394][  100/  123]    Loss 0.692372    Top1 77.625000    Top5 97.343750    
2024-04-23 22:03:24,549 - Epoch: [394][  123/  123]    Loss 0.699664    Top1 77.681529    Top5 97.273885    
2024-04-23 22:03:24,753 - ==> Top1: 77.682    Top5: 97.274    Loss: 0.700

2024-04-23 22:03:24,764 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:03:24,765 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:03:24,817 - 

2024-04-23 22:03:24,818 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:03:38,503 - Epoch: [395][  100/  296]    Overall Loss 0.706370    Objective Loss 0.706370                                        LR 0.000005    Time 0.136681    
2024-04-23 22:03:49,289 - Epoch: [395][  200/  296]    Overall Loss 0.722722    Objective Loss 0.722722                                        LR 0.000005    Time 0.122178    
2024-04-23 22:03:59,053 - Epoch: [395][  296/  296]    Overall Loss 0.717586    Objective Loss 0.717586    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.115492    
2024-04-23 22:03:59,345 - --- validate (epoch=395)-----------
2024-04-23 22:03:59,346 - 3925 samples (32 per mini-batch)
2024-04-23 22:04:11,034 - Epoch: [395][  100/  123]    Loss 0.699650    Top1 77.687500    Top5 97.312500    
2024-04-23 22:04:13,429 - Epoch: [395][  123/  123]    Loss 0.702899    Top1 77.605096    Top5 97.350318    
2024-04-23 22:04:13,629 - ==> Top1: 77.605    Top5: 97.350    Loss: 0.703

2024-04-23 22:04:13,639 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:04:13,639 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:04:13,681 - 

2024-04-23 22:04:13,682 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:04:27,244 - Epoch: [396][  100/  296]    Overall Loss 0.663602    Objective Loss 0.663602                                        LR 0.000005    Time 0.135477    
2024-04-23 22:04:38,483 - Epoch: [396][  200/  296]    Overall Loss 0.697801    Objective Loss 0.697801                                        LR 0.000005    Time 0.123853    
2024-04-23 22:04:49,931 - Epoch: [396][  296/  296]    Overall Loss 0.699752    Objective Loss 0.699752    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.122322    
2024-04-23 22:04:50,207 - --- validate (epoch=396)-----------
2024-04-23 22:04:50,208 - 3925 samples (32 per mini-batch)
2024-04-23 22:05:04,437 - Epoch: [396][  100/  123]    Loss 0.700681    Top1 77.531250    Top5 97.281250    
2024-04-23 22:05:08,432 - Epoch: [396][  123/  123]    Loss 0.703405    Top1 77.426752    Top5 97.324841    
2024-04-23 22:05:08,749 - ==> Top1: 77.427    Top5: 97.325    Loss: 0.703

2024-04-23 22:05:08,762 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:05:08,763 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:05:08,828 - 

2024-04-23 22:05:08,828 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:05:21,531 - Epoch: [397][  100/  296]    Overall Loss 0.715689    Objective Loss 0.715689                                        LR 0.000005    Time 0.126849    
2024-04-23 22:05:32,903 - Epoch: [397][  200/  296]    Overall Loss 0.702601    Objective Loss 0.702601                                        LR 0.000005    Time 0.120191    
2024-04-23 22:05:42,756 - Epoch: [397][  296/  296]    Overall Loss 0.706829    Objective Loss 0.706829    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.114448    
2024-04-23 22:05:43,002 - --- validate (epoch=397)-----------
2024-04-23 22:05:43,003 - 3925 samples (32 per mini-batch)
2024-04-23 22:05:57,949 - Epoch: [397][  100/  123]    Loss 0.703620    Top1 77.156250    Top5 97.187500    
2024-04-23 22:06:00,601 - Epoch: [397][  123/  123]    Loss 0.699209    Top1 77.656051    Top5 97.273885    
2024-04-23 22:06:00,804 - ==> Top1: 77.656    Top5: 97.274    Loss: 0.699

2024-04-23 22:06:00,816 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:06:00,816 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:06:00,872 - 

2024-04-23 22:06:00,872 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:06:14,492 - Epoch: [398][  100/  296]    Overall Loss 0.717964    Objective Loss 0.717964                                        LR 0.000005    Time 0.136012    
2024-04-23 22:06:27,423 - Epoch: [398][  200/  296]    Overall Loss 0.715522    Objective Loss 0.715522                                        LR 0.000005    Time 0.132578    
2024-04-23 22:06:37,696 - Epoch: [398][  296/  296]    Overall Loss 0.718994    Objective Loss 0.718994    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.124230    
2024-04-23 22:06:37,929 - --- validate (epoch=398)-----------
2024-04-23 22:06:37,930 - 3925 samples (32 per mini-batch)
2024-04-23 22:06:48,861 - Epoch: [398][  100/  123]    Loss 0.703504    Top1 77.531250    Top5 97.406250    
2024-04-23 22:06:51,545 - Epoch: [398][  123/  123]    Loss 0.700272    Top1 77.681529    Top5 97.452229    
2024-04-23 22:06:51,746 - ==> Top1: 77.682    Top5: 97.452    Loss: 0.700

2024-04-23 22:06:51,756 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:06:51,757 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:06:51,800 - 

2024-04-23 22:06:51,801 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:07:00,092 - Epoch: [399][  100/  296]    Overall Loss 0.685339    Objective Loss 0.685339                                        LR 0.000005    Time 0.082753    
2024-04-23 22:07:12,411 - Epoch: [399][  200/  296]    Overall Loss 0.707940    Objective Loss 0.707940                                        LR 0.000005    Time 0.102893    
2024-04-23 22:07:23,693 - Epoch: [399][  296/  296]    Overall Loss 0.704187    Objective Loss 0.704187    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.107583    
2024-04-23 22:07:23,916 - --- validate (epoch=399)-----------
2024-04-23 22:07:23,917 - 3925 samples (32 per mini-batch)
2024-04-23 22:07:38,903 - Epoch: [399][  100/  123]    Loss 0.703873    Top1 77.343750    Top5 97.406250    
2024-04-23 22:07:41,947 - Epoch: [399][  123/  123]    Loss 0.704063    Top1 77.426752    Top5 97.299363    
2024-04-23 22:07:42,147 - ==> Top1: 77.427    Top5: 97.299    Loss: 0.704

2024-04-23 22:07:42,157 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:07:42,158 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:07:42,208 - 

2024-04-23 22:07:42,209 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:07:57,037 - Epoch: [400][  100/  296]    Overall Loss 0.731403    Objective Loss 0.731403                                        LR 0.000005    Time 0.148107    
2024-04-23 22:08:08,560 - Epoch: [400][  200/  296]    Overall Loss 0.724604    Objective Loss 0.724604                                        LR 0.000005    Time 0.131587    
2024-04-23 22:08:20,268 - Epoch: [400][  296/  296]    Overall Loss 0.717418    Objective Loss 0.717418    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.128414    
2024-04-23 22:08:20,583 - --- validate (epoch=400)-----------
2024-04-23 22:08:20,584 - 3925 samples (32 per mini-batch)
2024-04-23 22:08:35,028 - Epoch: [400][  100/  123]    Loss 0.700963    Top1 77.218750    Top5 97.437500    
2024-04-23 22:08:37,720 - Epoch: [400][  123/  123]    Loss 0.702710    Top1 77.299363    Top5 97.503185    
2024-04-23 22:08:37,902 - ==> Top1: 77.299    Top5: 97.503    Loss: 0.703

2024-04-23 22:08:37,913 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:08:37,914 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:08:37,964 - 

2024-04-23 22:08:37,965 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:08:46,853 - Epoch: [401][  100/  296]    Overall Loss 0.698035    Objective Loss 0.698035                                        LR 0.000005    Time 0.088717    
2024-04-23 22:08:57,086 - Epoch: [401][  200/  296]    Overall Loss 0.699228    Objective Loss 0.699228                                        LR 0.000005    Time 0.095443    
2024-04-23 22:09:10,342 - Epoch: [401][  296/  296]    Overall Loss 0.701870    Objective Loss 0.701870    Top1 70.491803    Top5 98.360656    LR 0.000005    Time 0.109215    
2024-04-23 22:09:10,564 - --- validate (epoch=401)-----------
2024-04-23 22:09:10,565 - 3925 samples (32 per mini-batch)
2024-04-23 22:09:25,698 - Epoch: [401][  100/  123]    Loss 0.704811    Top1 77.531250    Top5 97.406250    
2024-04-23 22:09:28,493 - Epoch: [401][  123/  123]    Loss 0.701613    Top1 77.630573    Top5 97.273885    
2024-04-23 22:09:28,743 - ==> Top1: 77.631    Top5: 97.274    Loss: 0.702

2024-04-23 22:09:28,749 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:09:28,749 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:09:28,790 - 

2024-04-23 22:09:28,791 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:09:45,130 - Epoch: [402][  100/  296]    Overall Loss 0.701684    Objective Loss 0.701684                                        LR 0.000005    Time 0.163219    
2024-04-23 22:09:57,549 - Epoch: [402][  200/  296]    Overall Loss 0.700363    Objective Loss 0.700363                                        LR 0.000005    Time 0.143619    
2024-04-23 22:10:09,699 - Epoch: [402][  296/  296]    Overall Loss 0.700054    Objective Loss 0.700054    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.138037    
2024-04-23 22:10:09,955 - --- validate (epoch=402)-----------
2024-04-23 22:10:09,956 - 3925 samples (32 per mini-batch)
2024-04-23 22:10:24,739 - Epoch: [402][  100/  123]    Loss 0.697908    Top1 77.562500    Top5 97.156250    
2024-04-23 22:10:27,257 - Epoch: [402][  123/  123]    Loss 0.700807    Top1 77.961783    Top5 97.222930    
2024-04-23 22:10:27,369 - ==> Top1: 77.962    Top5: 97.223    Loss: 0.701

2024-04-23 22:10:27,374 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:10:27,374 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:10:27,408 - 

2024-04-23 22:10:27,408 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:10:40,785 - Epoch: [403][  100/  296]    Overall Loss 0.726698    Objective Loss 0.726698                                        LR 0.000005    Time 0.133589    
2024-04-23 22:10:54,424 - Epoch: [403][  200/  296]    Overall Loss 0.704113    Objective Loss 0.704113                                        LR 0.000005    Time 0.134908    
2024-04-23 22:11:03,836 - Epoch: [403][  296/  296]    Overall Loss 0.702103    Objective Loss 0.702103    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.122901    
2024-04-23 22:11:04,001 - --- validate (epoch=403)-----------
2024-04-23 22:11:04,002 - 3925 samples (32 per mini-batch)
2024-04-23 22:11:17,254 - Epoch: [403][  100/  123]    Loss 0.702393    Top1 78.000000    Top5 97.250000    
2024-04-23 22:11:20,035 - Epoch: [403][  123/  123]    Loss 0.702345    Top1 77.808917    Top5 97.401274    
2024-04-23 22:11:20,184 - ==> Top1: 77.809    Top5: 97.401    Loss: 0.702

2024-04-23 22:11:20,195 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:11:20,196 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:11:20,237 - 

2024-04-23 22:11:20,238 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:11:33,317 - Epoch: [404][  100/  296]    Overall Loss 0.742134    Objective Loss 0.742134                                        LR 0.000005    Time 0.130613    
2024-04-23 22:11:44,360 - Epoch: [404][  200/  296]    Overall Loss 0.733795    Objective Loss 0.733795                                        LR 0.000005    Time 0.120447    
2024-04-23 22:11:50,972 - Epoch: [404][  296/  296]    Overall Loss 0.730169    Objective Loss 0.730169    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.103681    
2024-04-23 22:11:51,100 - --- validate (epoch=404)-----------
2024-04-23 22:11:51,101 - 3925 samples (32 per mini-batch)
2024-04-23 22:11:59,943 - Epoch: [404][  100/  123]    Loss 0.698391    Top1 77.812500    Top5 97.125000    
2024-04-23 22:12:02,495 - Epoch: [404][  123/  123]    Loss 0.700794    Top1 77.605096    Top5 97.171975    
2024-04-23 22:12:02,643 - ==> Top1: 77.605    Top5: 97.172    Loss: 0.701

2024-04-23 22:12:02,652 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:12:02,653 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:12:02,700 - 

2024-04-23 22:12:02,700 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:12:16,582 - Epoch: [405][  100/  296]    Overall Loss 0.723536    Objective Loss 0.723536                                        LR 0.000005    Time 0.138668    
2024-04-23 22:12:28,858 - Epoch: [405][  200/  296]    Overall Loss 0.710672    Objective Loss 0.710672                                        LR 0.000005    Time 0.130643    
2024-04-23 22:12:39,783 - Epoch: [405][  296/  296]    Overall Loss 0.700075    Objective Loss 0.700075    Top1 68.852459    Top5 95.081967    LR 0.000005    Time 0.125141    
2024-04-23 22:12:40,273 - --- validate (epoch=405)-----------
2024-04-23 22:12:40,273 - 3925 samples (32 per mini-batch)
2024-04-23 22:12:50,625 - Epoch: [405][  100/  123]    Loss 0.714257    Top1 76.625000    Top5 97.218750    
2024-04-23 22:12:53,139 - Epoch: [405][  123/  123]    Loss 0.701568    Top1 77.452229    Top5 97.375796    
2024-04-23 22:12:53,241 - ==> Top1: 77.452    Top5: 97.376    Loss: 0.702

2024-04-23 22:12:53,250 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:12:53,250 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:12:53,298 - 

2024-04-23 22:12:53,299 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:13:01,398 - Epoch: [406][  100/  296]    Overall Loss 0.709389    Objective Loss 0.709389                                        LR 0.000005    Time 0.080860    
2024-04-23 22:13:08,514 - Epoch: [406][  200/  296]    Overall Loss 0.712507    Objective Loss 0.712507                                        LR 0.000005    Time 0.075951    
2024-04-23 22:13:16,861 - Epoch: [406][  296/  296]    Overall Loss 0.702363    Objective Loss 0.702363    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.079467    
2024-04-23 22:13:17,098 - --- validate (epoch=406)-----------
2024-04-23 22:13:17,098 - 3925 samples (32 per mini-batch)
2024-04-23 22:13:30,446 - Epoch: [406][  100/  123]    Loss 0.699210    Top1 77.406250    Top5 97.562500    
2024-04-23 22:13:32,510 - Epoch: [406][  123/  123]    Loss 0.704026    Top1 77.477707    Top5 97.452229    
2024-04-23 22:13:32,658 - ==> Top1: 77.478    Top5: 97.452    Loss: 0.704

2024-04-23 22:13:32,667 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:13:32,668 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:13:32,706 - 

2024-04-23 22:13:32,707 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:13:45,121 - Epoch: [407][  100/  296]    Overall Loss 0.687985    Objective Loss 0.687985                                        LR 0.000005    Time 0.123979    
2024-04-23 22:13:58,518 - Epoch: [407][  200/  296]    Overall Loss 0.709397    Objective Loss 0.709397                                        LR 0.000005    Time 0.128886    
2024-04-23 22:14:08,650 - Epoch: [407][  296/  296]    Overall Loss 0.714481    Objective Loss 0.714481    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.121259    
2024-04-23 22:14:08,844 - --- validate (epoch=407)-----------
2024-04-23 22:14:08,844 - 3925 samples (32 per mini-batch)
2024-04-23 22:14:23,216 - Epoch: [407][  100/  123]    Loss 0.697962    Top1 77.937500    Top5 97.406250    
2024-04-23 22:14:26,257 - Epoch: [407][  123/  123]    Loss 0.702605    Top1 77.859873    Top5 97.299363    
2024-04-23 22:14:26,420 - ==> Top1: 77.860    Top5: 97.299    Loss: 0.703

2024-04-23 22:14:26,432 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:14:26,432 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:14:26,477 - 

2024-04-23 22:14:26,478 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:14:39,423 - Epoch: [408][  100/  296]    Overall Loss 0.727915    Objective Loss 0.727915                                        LR 0.000005    Time 0.129290    
2024-04-23 22:14:53,369 - Epoch: [408][  200/  296]    Overall Loss 0.713162    Objective Loss 0.713162                                        LR 0.000005    Time 0.134284    
2024-04-23 22:15:05,118 - Epoch: [408][  296/  296]    Overall Loss 0.710058    Objective Loss 0.710058    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.130373    
2024-04-23 22:15:05,498 - --- validate (epoch=408)-----------
2024-04-23 22:15:05,498 - 3925 samples (32 per mini-batch)
2024-04-23 22:15:20,533 - Epoch: [408][  100/  123]    Loss 0.693666    Top1 77.343750    Top5 97.437500    
2024-04-23 22:15:23,668 - Epoch: [408][  123/  123]    Loss 0.700219    Top1 77.554140    Top5 97.324841    
2024-04-23 22:15:23,925 - ==> Top1: 77.554    Top5: 97.325    Loss: 0.700

2024-04-23 22:15:23,932 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:15:23,933 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:15:23,969 - 

2024-04-23 22:15:23,970 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:15:34,288 - Epoch: [409][  100/  296]    Overall Loss 0.713879    Objective Loss 0.713879                                        LR 0.000005    Time 0.102989    
2024-04-23 22:15:45,818 - Epoch: [409][  200/  296]    Overall Loss 0.703861    Objective Loss 0.703861                                        LR 0.000005    Time 0.109061    
2024-04-23 22:15:53,164 - Epoch: [409][  296/  296]    Overall Loss 0.703974    Objective Loss 0.703974    Top1 81.967213    Top5 95.081967    LR 0.000005    Time 0.098454    
2024-04-23 22:15:53,385 - --- validate (epoch=409)-----------
2024-04-23 22:15:53,386 - 3925 samples (32 per mini-batch)
2024-04-23 22:16:07,503 - Epoch: [409][  100/  123]    Loss 0.702619    Top1 77.625000    Top5 97.312500    
2024-04-23 22:16:11,234 - Epoch: [409][  123/  123]    Loss 0.702907    Top1 77.503185    Top5 97.299363    
2024-04-23 22:16:11,535 - ==> Top1: 77.503    Top5: 97.299    Loss: 0.703

2024-04-23 22:16:11,546 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:16:11,546 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:16:11,618 - 

2024-04-23 22:16:11,618 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:16:24,407 - Epoch: [410][  100/  296]    Overall Loss 0.697728    Objective Loss 0.697728                                        LR 0.000005    Time 0.127695    
2024-04-23 22:16:32,969 - Epoch: [410][  200/  296]    Overall Loss 0.695125    Objective Loss 0.695125                                        LR 0.000005    Time 0.106581    
2024-04-23 22:16:42,352 - Epoch: [410][  296/  296]    Overall Loss 0.704512    Objective Loss 0.704512    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.103658    
2024-04-23 22:16:42,495 - --- validate (epoch=410)-----------
2024-04-23 22:16:42,496 - 3925 samples (32 per mini-batch)
2024-04-23 22:16:51,807 - Epoch: [410][  100/  123]    Loss 0.698959    Top1 77.562500    Top5 97.281250    
2024-04-23 22:16:54,320 - Epoch: [410][  123/  123]    Loss 0.699407    Top1 77.681529    Top5 97.273885    
2024-04-23 22:16:54,449 - ==> Top1: 77.682    Top5: 97.274    Loss: 0.699

2024-04-23 22:16:54,460 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:16:54,460 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:16:54,505 - 

2024-04-23 22:16:54,506 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:17:05,768 - Epoch: [411][  100/  296]    Overall Loss 0.696412    Objective Loss 0.696412                                        LR 0.000005    Time 0.112465    
2024-04-23 22:17:15,772 - Epoch: [411][  200/  296]    Overall Loss 0.700926    Objective Loss 0.700926                                        LR 0.000005    Time 0.106164    
2024-04-23 22:17:26,906 - Epoch: [411][  296/  296]    Overall Loss 0.699151    Objective Loss 0.699151    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.109295    
2024-04-23 22:17:27,075 - --- validate (epoch=411)-----------
2024-04-23 22:17:27,076 - 3925 samples (32 per mini-batch)
2024-04-23 22:17:42,454 - Epoch: [411][  100/  123]    Loss 0.684695    Top1 78.375000    Top5 97.312500    
2024-04-23 22:17:45,673 - Epoch: [411][  123/  123]    Loss 0.699677    Top1 77.783439    Top5 97.324841    
2024-04-23 22:17:45,978 - ==> Top1: 77.783    Top5: 97.325    Loss: 0.700

2024-04-23 22:17:45,988 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:17:45,988 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:17:46,037 - 

2024-04-23 22:17:46,038 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:18:00,124 - Epoch: [412][  100/  296]    Overall Loss 0.711379    Objective Loss 0.711379                                        LR 0.000005    Time 0.140668    
2024-04-23 22:18:12,882 - Epoch: [412][  200/  296]    Overall Loss 0.716912    Objective Loss 0.716912                                        LR 0.000005    Time 0.134039    
2024-04-23 22:18:23,354 - Epoch: [412][  296/  296]    Overall Loss 0.713057    Objective Loss 0.713057    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.125891    
2024-04-23 22:18:23,628 - --- validate (epoch=412)-----------
2024-04-23 22:18:23,629 - 3925 samples (32 per mini-batch)
2024-04-23 22:18:38,562 - Epoch: [412][  100/  123]    Loss 0.713459    Top1 77.250000    Top5 97.375000    
2024-04-23 22:18:41,277 - Epoch: [412][  123/  123]    Loss 0.702370    Top1 77.503185    Top5 97.401274    
2024-04-23 22:18:41,519 - ==> Top1: 77.503    Top5: 97.401    Loss: 0.702

2024-04-23 22:18:41,527 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:18:41,528 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:18:41,578 - 

2024-04-23 22:18:41,580 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:18:54,308 - Epoch: [413][  100/  296]    Overall Loss 0.673188    Objective Loss 0.673188                                        LR 0.000005    Time 0.127072    
2024-04-23 22:19:01,807 - Epoch: [413][  200/  296]    Overall Loss 0.691033    Objective Loss 0.691033                                        LR 0.000005    Time 0.100954    
2024-04-23 22:19:11,456 - Epoch: [413][  296/  296]    Overall Loss 0.697722    Objective Loss 0.697722    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.100759    
2024-04-23 22:19:11,585 - --- validate (epoch=413)-----------
2024-04-23 22:19:11,586 - 3925 samples (32 per mini-batch)
2024-04-23 22:19:21,959 - Epoch: [413][  100/  123]    Loss 0.700439    Top1 78.312500    Top5 97.343750    
2024-04-23 22:19:24,228 - Epoch: [413][  123/  123]    Loss 0.699122    Top1 78.063694    Top5 97.273885    
2024-04-23 22:19:24,343 - ==> Top1: 78.064    Top5: 97.274    Loss: 0.699

2024-04-23 22:19:24,348 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:19:24,348 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:19:24,384 - 

2024-04-23 22:19:24,384 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:19:32,556 - Epoch: [414][  100/  296]    Overall Loss 0.716252    Objective Loss 0.716252                                        LR 0.000005    Time 0.081589    
2024-04-23 22:19:39,790 - Epoch: [414][  200/  296]    Overall Loss 0.719711    Objective Loss 0.719711                                        LR 0.000005    Time 0.076898    
2024-04-23 22:19:48,503 - Epoch: [414][  296/  296]    Overall Loss 0.709403    Objective Loss 0.709403    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.081346    
2024-04-23 22:19:48,807 - --- validate (epoch=414)-----------
2024-04-23 22:19:48,808 - 3925 samples (32 per mini-batch)
2024-04-23 22:20:03,698 - Epoch: [414][  100/  123]    Loss 0.705266    Top1 77.906250    Top5 97.312500    
2024-04-23 22:20:06,510 - Epoch: [414][  123/  123]    Loss 0.701320    Top1 77.834395    Top5 97.401274    
2024-04-23 22:20:06,707 - ==> Top1: 77.834    Top5: 97.401    Loss: 0.701

2024-04-23 22:20:06,715 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:20:06,715 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:20:06,757 - 

2024-04-23 22:20:06,758 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:20:20,717 - Epoch: [415][  100/  296]    Overall Loss 0.693941    Objective Loss 0.693941                                        LR 0.000005    Time 0.139423    
2024-04-23 22:20:32,871 - Epoch: [415][  200/  296]    Overall Loss 0.700360    Objective Loss 0.700360                                        LR 0.000005    Time 0.130399    
2024-04-23 22:20:43,762 - Epoch: [415][  296/  296]    Overall Loss 0.697927    Objective Loss 0.697927    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.124849    
2024-04-23 22:20:43,977 - --- validate (epoch=415)-----------
2024-04-23 22:20:43,978 - 3925 samples (32 per mini-batch)
2024-04-23 22:20:56,923 - Epoch: [415][  100/  123]    Loss 0.707636    Top1 77.781250    Top5 97.343750    
2024-04-23 22:20:58,741 - Epoch: [415][  123/  123]    Loss 0.703904    Top1 77.757962    Top5 97.324841    
2024-04-23 22:20:58,830 - ==> Top1: 77.758    Top5: 97.325    Loss: 0.704

2024-04-23 22:20:58,839 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:20:58,840 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:20:58,882 - 

2024-04-23 22:20:58,882 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:21:09,132 - Epoch: [416][  100/  296]    Overall Loss 0.710720    Objective Loss 0.710720                                        LR 0.000005    Time 0.102343    
2024-04-23 22:21:19,684 - Epoch: [416][  200/  296]    Overall Loss 0.700946    Objective Loss 0.700946                                        LR 0.000005    Time 0.103840    
2024-04-23 22:21:29,175 - Epoch: [416][  296/  296]    Overall Loss 0.707617    Objective Loss 0.707617    Top1 81.967213    Top5 93.442623    LR 0.000005    Time 0.102174    
2024-04-23 22:21:29,671 - --- validate (epoch=416)-----------
2024-04-23 22:21:29,672 - 3925 samples (32 per mini-batch)
2024-04-23 22:21:44,150 - Epoch: [416][  100/  123]    Loss 0.706421    Top1 77.500000    Top5 97.343750    
2024-04-23 22:21:47,258 - Epoch: [416][  123/  123]    Loss 0.703608    Top1 77.630573    Top5 97.375796    
2024-04-23 22:21:47,532 - ==> Top1: 77.631    Top5: 97.376    Loss: 0.704

2024-04-23 22:21:47,543 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:21:47,544 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:21:47,592 - 

2024-04-23 22:21:47,593 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:22:00,370 - Epoch: [417][  100/  296]    Overall Loss 0.683381    Objective Loss 0.683381                                        LR 0.000005    Time 0.127601    
2024-04-23 22:22:12,406 - Epoch: [417][  200/  296]    Overall Loss 0.692843    Objective Loss 0.692843                                        LR 0.000005    Time 0.123895    
2024-04-23 22:22:22,995 - Epoch: [417][  296/  296]    Overall Loss 0.706339    Objective Loss 0.706339    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.119436    
2024-04-23 22:22:23,218 - --- validate (epoch=417)-----------
2024-04-23 22:22:23,219 - 3925 samples (32 per mini-batch)
2024-04-23 22:22:36,892 - Epoch: [417][  100/  123]    Loss 0.695705    Top1 78.250000    Top5 97.500000    
2024-04-23 22:22:38,813 - Epoch: [417][  123/  123]    Loss 0.698896    Top1 77.987261    Top5 97.426752    
2024-04-23 22:22:38,914 - ==> Top1: 77.987    Top5: 97.427    Loss: 0.699

2024-04-23 22:22:38,924 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:22:38,924 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:22:38,969 - 

2024-04-23 22:22:38,970 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:22:53,528 - Epoch: [418][  100/  296]    Overall Loss 0.724861    Objective Loss 0.724861                                        LR 0.000005    Time 0.145429    
2024-04-23 22:23:04,428 - Epoch: [418][  200/  296]    Overall Loss 0.714164    Objective Loss 0.714164                                        LR 0.000005    Time 0.127130    
2024-04-23 22:23:15,208 - Epoch: [418][  296/  296]    Overall Loss 0.711540    Objective Loss 0.711540    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.122265    
2024-04-23 22:23:15,715 - --- validate (epoch=418)-----------
2024-04-23 22:23:15,716 - 3925 samples (32 per mini-batch)
2024-04-23 22:23:29,216 - Epoch: [418][  100/  123]    Loss 0.713875    Top1 77.437500    Top5 97.312500    
2024-04-23 22:23:31,400 - Epoch: [418][  123/  123]    Loss 0.706505    Top1 77.426752    Top5 97.299363    
2024-04-23 22:23:31,626 - ==> Top1: 77.427    Top5: 97.299    Loss: 0.707

2024-04-23 22:23:31,635 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:23:31,636 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:23:31,681 - 

2024-04-23 22:23:31,681 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:23:43,702 - Epoch: [419][  100/  296]    Overall Loss 0.725224    Objective Loss 0.725224                                        LR 0.000005    Time 0.120006    
2024-04-23 22:23:52,579 - Epoch: [419][  200/  296]    Overall Loss 0.710353    Objective Loss 0.710353                                        LR 0.000005    Time 0.104302    
2024-04-23 22:24:02,604 - Epoch: [419][  296/  296]    Overall Loss 0.711747    Objective Loss 0.711747    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.104284    
2024-04-23 22:24:02,866 - --- validate (epoch=419)-----------
2024-04-23 22:24:02,867 - 3925 samples (32 per mini-batch)
2024-04-23 22:24:18,812 - Epoch: [419][  100/  123]    Loss 0.708347    Top1 77.218750    Top5 97.125000    
2024-04-23 22:24:22,158 - Epoch: [419][  123/  123]    Loss 0.707250    Top1 77.426752    Top5 97.197452    
2024-04-23 22:24:22,424 - ==> Top1: 77.427    Top5: 97.197    Loss: 0.707

2024-04-23 22:24:22,434 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:24:22,434 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:24:22,473 - 

2024-04-23 22:24:22,474 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:24:32,983 - Epoch: [420][  100/  296]    Overall Loss 0.724754    Objective Loss 0.724754                                        LR 0.000005    Time 0.104942    
2024-04-23 22:24:45,793 - Epoch: [420][  200/  296]    Overall Loss 0.711545    Objective Loss 0.711545                                        LR 0.000005    Time 0.116423    
2024-04-23 22:24:55,091 - Epoch: [420][  296/  296]    Overall Loss 0.712501    Objective Loss 0.712501    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.110017    
2024-04-23 22:24:55,313 - --- validate (epoch=420)-----------
2024-04-23 22:24:55,314 - 3925 samples (32 per mini-batch)
2024-04-23 22:25:08,486 - Epoch: [420][  100/  123]    Loss 0.702633    Top1 77.687500    Top5 97.281250    
2024-04-23 22:25:11,210 - Epoch: [420][  123/  123]    Loss 0.703229    Top1 77.477707    Top5 97.273885    
2024-04-23 22:25:11,389 - ==> Top1: 77.478    Top5: 97.274    Loss: 0.703

2024-04-23 22:25:11,399 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:25:11,400 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:25:11,452 - 

2024-04-23 22:25:11,452 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:25:24,493 - Epoch: [421][  100/  296]    Overall Loss 0.700747    Objective Loss 0.700747                                        LR 0.000005    Time 0.130231    
2024-04-23 22:25:34,785 - Epoch: [421][  200/  296]    Overall Loss 0.687759    Objective Loss 0.687759                                        LR 0.000005    Time 0.116492    
2024-04-23 22:25:43,345 - Epoch: [421][  296/  296]    Overall Loss 0.697405    Objective Loss 0.697405    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.107579    
2024-04-23 22:25:43,586 - --- validate (epoch=421)-----------
2024-04-23 22:25:43,587 - 3925 samples (32 per mini-batch)
2024-04-23 22:25:54,789 - Epoch: [421][  100/  123]    Loss 0.705260    Top1 77.750000    Top5 97.218750    
2024-04-23 22:25:56,635 - Epoch: [421][  123/  123]    Loss 0.701906    Top1 77.757962    Top5 97.324841    
2024-04-23 22:25:56,861 - ==> Top1: 77.758    Top5: 97.325    Loss: 0.702

2024-04-23 22:25:56,872 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:25:56,872 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:25:56,910 - 

2024-04-23 22:25:56,911 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:26:05,683 - Epoch: [422][  100/  296]    Overall Loss 0.671378    Objective Loss 0.671378                                        LR 0.000005    Time 0.087563    
2024-04-23 22:26:12,620 - Epoch: [422][  200/  296]    Overall Loss 0.693057    Objective Loss 0.693057                                        LR 0.000005    Time 0.078381    
2024-04-23 22:26:20,688 - Epoch: [422][  296/  296]    Overall Loss 0.702019    Objective Loss 0.702019    Top1 67.213115    Top5 98.360656    LR 0.000005    Time 0.080162    
2024-04-23 22:26:20,976 - --- validate (epoch=422)-----------
2024-04-23 22:26:20,977 - 3925 samples (32 per mini-batch)
2024-04-23 22:26:32,575 - Epoch: [422][  100/  123]    Loss 0.705894    Top1 77.187500    Top5 97.562500    
2024-04-23 22:26:34,765 - Epoch: [422][  123/  123]    Loss 0.702237    Top1 77.350318    Top5 97.375796    
2024-04-23 22:26:34,999 - ==> Top1: 77.350    Top5: 97.376    Loss: 0.702

2024-04-23 22:26:35,004 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:26:35,004 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:26:35,033 - 

2024-04-23 22:26:35,034 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:26:43,929 - Epoch: [423][  100/  296]    Overall Loss 0.714641    Objective Loss 0.714641                                        LR 0.000005    Time 0.088788    
2024-04-23 22:26:51,012 - Epoch: [423][  200/  296]    Overall Loss 0.732215    Objective Loss 0.732215                                        LR 0.000005    Time 0.079736    
2024-04-23 22:27:02,523 - Epoch: [423][  296/  296]    Overall Loss 0.727726    Objective Loss 0.727726    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.092711    
2024-04-23 22:27:02,762 - --- validate (epoch=423)-----------
2024-04-23 22:27:02,763 - 3925 samples (32 per mini-batch)
2024-04-23 22:27:17,078 - Epoch: [423][  100/  123]    Loss 0.694581    Top1 77.937500    Top5 97.250000    
2024-04-23 22:27:20,403 - Epoch: [423][  123/  123]    Loss 0.700996    Top1 77.681529    Top5 97.350318    
2024-04-23 22:27:20,692 - ==> Top1: 77.682    Top5: 97.350    Loss: 0.701

2024-04-23 22:27:20,698 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:27:20,701 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:27:20,737 - 

2024-04-23 22:27:20,738 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:27:30,435 - Epoch: [424][  100/  296]    Overall Loss 0.705251    Objective Loss 0.705251                                        LR 0.000005    Time 0.096805    
2024-04-23 22:27:39,234 - Epoch: [424][  200/  296]    Overall Loss 0.696681    Objective Loss 0.696681                                        LR 0.000005    Time 0.092314    
2024-04-23 22:27:46,329 - Epoch: [424][  296/  296]    Overall Loss 0.693097    Objective Loss 0.693097    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.086294    
2024-04-23 22:27:46,592 - --- validate (epoch=424)-----------
2024-04-23 22:27:46,593 - 3925 samples (32 per mini-batch)
2024-04-23 22:28:02,046 - Epoch: [424][  100/  123]    Loss 0.695339    Top1 77.750000    Top5 97.281250    
2024-04-23 22:28:05,687 - Epoch: [424][  123/  123]    Loss 0.701728    Top1 77.554140    Top5 97.273885    
2024-04-23 22:28:05,842 - ==> Top1: 77.554    Top5: 97.274    Loss: 0.702

2024-04-23 22:28:05,853 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:28:05,853 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:28:05,911 - 

2024-04-23 22:28:05,911 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:28:17,265 - Epoch: [425][  100/  296]    Overall Loss 0.714093    Objective Loss 0.714093                                        LR 0.000005    Time 0.113374    
2024-04-23 22:28:28,272 - Epoch: [425][  200/  296]    Overall Loss 0.719012    Objective Loss 0.719012                                        LR 0.000005    Time 0.111633    
2024-04-23 22:28:38,936 - Epoch: [425][  296/  296]    Overall Loss 0.721576    Objective Loss 0.721576    Top1 67.213115    Top5 98.360656    LR 0.000005    Time 0.111397    
2024-04-23 22:28:39,250 - --- validate (epoch=425)-----------
2024-04-23 22:28:39,251 - 3925 samples (32 per mini-batch)
2024-04-23 22:28:54,497 - Epoch: [425][  100/  123]    Loss 0.704641    Top1 77.500000    Top5 97.156250    
2024-04-23 22:28:57,095 - Epoch: [425][  123/  123]    Loss 0.700053    Top1 77.426752    Top5 97.324841    
2024-04-23 22:28:57,399 - ==> Top1: 77.427    Top5: 97.325    Loss: 0.700

2024-04-23 22:28:57,412 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:28:57,413 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:28:57,484 - 

2024-04-23 22:28:57,485 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:29:11,151 - Epoch: [426][  100/  296]    Overall Loss 0.715523    Objective Loss 0.715523                                        LR 0.000005    Time 0.136468    
2024-04-23 22:29:22,780 - Epoch: [426][  200/  296]    Overall Loss 0.700011    Objective Loss 0.700011                                        LR 0.000005    Time 0.126295    
2024-04-23 22:29:33,209 - Epoch: [426][  296/  296]    Overall Loss 0.694626    Objective Loss 0.694626    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.120518    
2024-04-23 22:29:33,452 - --- validate (epoch=426)-----------
2024-04-23 22:29:33,453 - 3925 samples (32 per mini-batch)
2024-04-23 22:29:48,930 - Epoch: [426][  100/  123]    Loss 0.717371    Top1 77.093750    Top5 97.062500    
2024-04-23 22:29:52,426 - Epoch: [426][  123/  123]    Loss 0.703197    Top1 77.528662    Top5 97.273885    
2024-04-23 22:29:52,617 - ==> Top1: 77.529    Top5: 97.274    Loss: 0.703

2024-04-23 22:29:52,627 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:29:52,628 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:29:52,669 - 

2024-04-23 22:29:52,670 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:30:07,129 - Epoch: [427][  100/  296]    Overall Loss 0.726968    Objective Loss 0.726968                                        LR 0.000005    Time 0.144402    
2024-04-23 22:30:19,502 - Epoch: [427][  200/  296]    Overall Loss 0.717718    Objective Loss 0.717718                                        LR 0.000005    Time 0.133978    
2024-04-23 22:30:30,212 - Epoch: [427][  296/  296]    Overall Loss 0.710683    Objective Loss 0.710683    Top1 90.163934    Top5 100.000000    LR 0.000005    Time 0.126655    
2024-04-23 22:30:30,425 - --- validate (epoch=427)-----------
2024-04-23 22:30:30,426 - 3925 samples (32 per mini-batch)
2024-04-23 22:30:43,402 - Epoch: [427][  100/  123]    Loss 0.700923    Top1 77.531250    Top5 97.375000    
2024-04-23 22:30:46,860 - Epoch: [427][  123/  123]    Loss 0.703560    Top1 77.605096    Top5 97.273885    
2024-04-23 22:30:47,060 - ==> Top1: 77.605    Top5: 97.274    Loss: 0.704

2024-04-23 22:30:47,070 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:30:47,071 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:30:47,115 - 

2024-04-23 22:30:47,116 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:31:00,801 - Epoch: [428][  100/  296]    Overall Loss 0.711349    Objective Loss 0.711349                                        LR 0.000005    Time 0.136683    
2024-04-23 22:31:11,090 - Epoch: [428][  200/  296]    Overall Loss 0.706804    Objective Loss 0.706804                                        LR 0.000005    Time 0.119702    
2024-04-23 22:31:19,273 - Epoch: [428][  296/  296]    Overall Loss 0.703844    Objective Loss 0.703844    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.108473    
2024-04-23 22:31:19,492 - --- validate (epoch=428)-----------
2024-04-23 22:31:19,494 - 3925 samples (32 per mini-batch)
2024-04-23 22:31:34,203 - Epoch: [428][  100/  123]    Loss 0.697794    Top1 77.718750    Top5 97.375000    
2024-04-23 22:31:36,645 - Epoch: [428][  123/  123]    Loss 0.705181    Top1 77.554140    Top5 97.248408    
2024-04-23 22:31:36,865 - ==> Top1: 77.554    Top5: 97.248    Loss: 0.705

2024-04-23 22:31:36,874 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:31:36,874 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:31:36,919 - 

2024-04-23 22:31:36,919 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:31:48,806 - Epoch: [429][  100/  296]    Overall Loss 0.697845    Objective Loss 0.697845                                        LR 0.000005    Time 0.118677    
2024-04-23 22:31:59,536 - Epoch: [429][  200/  296]    Overall Loss 0.692734    Objective Loss 0.692734                                        LR 0.000005    Time 0.112909    
2024-04-23 22:32:07,889 - Epoch: [429][  296/  296]    Overall Loss 0.712488    Objective Loss 0.712488    Top1 78.688525    Top5 93.442623    LR 0.000005    Time 0.104457    
2024-04-23 22:32:08,153 - --- validate (epoch=429)-----------
2024-04-23 22:32:08,153 - 3925 samples (32 per mini-batch)
2024-04-23 22:32:19,435 - Epoch: [429][  100/  123]    Loss 0.701122    Top1 77.812500    Top5 97.500000    
2024-04-23 22:32:21,139 - Epoch: [429][  123/  123]    Loss 0.702876    Top1 77.707006    Top5 97.299363    
2024-04-23 22:32:21,327 - ==> Top1: 77.707    Top5: 97.299    Loss: 0.703

2024-04-23 22:32:21,336 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:32:21,337 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:32:21,374 - 

2024-04-23 22:32:21,375 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:32:29,691 - Epoch: [430][  100/  296]    Overall Loss 0.723126    Objective Loss 0.723126                                        LR 0.000005    Time 0.082982    
2024-04-23 22:32:36,886 - Epoch: [430][  200/  296]    Overall Loss 0.724199    Objective Loss 0.724199                                        LR 0.000005    Time 0.077385    
2024-04-23 22:32:43,486 - Epoch: [430][  296/  296]    Overall Loss 0.727696    Objective Loss 0.727696    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.074540    
2024-04-23 22:32:43,692 - --- validate (epoch=430)-----------
2024-04-23 22:32:43,693 - 3925 samples (32 per mini-batch)
2024-04-23 22:32:54,075 - Epoch: [430][  100/  123]    Loss 0.698990    Top1 77.718750    Top5 97.281250    
2024-04-23 22:32:56,131 - Epoch: [430][  123/  123]    Loss 0.701895    Top1 77.808917    Top5 97.273885    
2024-04-23 22:32:56,367 - ==> Top1: 77.809    Top5: 97.274    Loss: 0.702

2024-04-23 22:32:56,377 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:32:56,377 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:32:56,424 - 

2024-04-23 22:32:56,425 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:33:05,884 - Epoch: [431][  100/  296]    Overall Loss 0.719526    Objective Loss 0.719526                                        LR 0.000005    Time 0.094436    
2024-04-23 22:33:13,636 - Epoch: [431][  200/  296]    Overall Loss 0.717468    Objective Loss 0.717468                                        LR 0.000005    Time 0.085900    
2024-04-23 22:33:20,419 - Epoch: [431][  296/  296]    Overall Loss 0.712150    Objective Loss 0.712150    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.080908    
2024-04-23 22:33:20,633 - --- validate (epoch=431)-----------
2024-04-23 22:33:20,634 - 3925 samples (32 per mini-batch)
2024-04-23 22:33:29,994 - Epoch: [431][  100/  123]    Loss 0.702105    Top1 77.812500    Top5 97.281250    
2024-04-23 22:33:31,812 - Epoch: [431][  123/  123]    Loss 0.701249    Top1 77.732484    Top5 97.222930    
2024-04-23 22:33:32,017 - ==> Top1: 77.732    Top5: 97.223    Loss: 0.701

2024-04-23 22:33:32,024 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:33:32,024 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:33:32,055 - 

2024-04-23 22:33:32,055 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:33:42,746 - Epoch: [432][  100/  296]    Overall Loss 0.688515    Objective Loss 0.688515                                        LR 0.000005    Time 0.106732    
2024-04-23 22:33:52,150 - Epoch: [432][  200/  296]    Overall Loss 0.701876    Objective Loss 0.701876                                        LR 0.000005    Time 0.100302    
2024-04-23 22:34:01,045 - Epoch: [432][  296/  296]    Overall Loss 0.691701    Objective Loss 0.691701    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.097771    
2024-04-23 22:34:01,307 - --- validate (epoch=432)-----------
2024-04-23 22:34:01,307 - 3925 samples (32 per mini-batch)
2024-04-23 22:34:11,774 - Epoch: [432][  100/  123]    Loss 0.697290    Top1 77.500000    Top5 97.531250    
2024-04-23 22:34:13,542 - Epoch: [432][  123/  123]    Loss 0.702333    Top1 77.579618    Top5 97.273885    
2024-04-23 22:34:13,861 - ==> Top1: 77.580    Top5: 97.274    Loss: 0.702

2024-04-23 22:34:13,871 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:34:13,872 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:34:13,907 - 

2024-04-23 22:34:13,908 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:34:22,299 - Epoch: [433][  100/  296]    Overall Loss 0.702950    Objective Loss 0.702950                                        LR 0.000005    Time 0.083779    
2024-04-23 22:34:28,749 - Epoch: [433][  200/  296]    Overall Loss 0.706335    Objective Loss 0.706335                                        LR 0.000005    Time 0.074074    
2024-04-23 22:34:35,862 - Epoch: [433][  296/  296]    Overall Loss 0.711549    Objective Loss 0.711549    Top1 70.491803    Top5 95.081967    LR 0.000005    Time 0.074030    
2024-04-23 22:34:36,129 - --- validate (epoch=433)-----------
2024-04-23 22:34:36,130 - 3925 samples (32 per mini-batch)
2024-04-23 22:34:45,958 - Epoch: [433][  100/  123]    Loss 0.706013    Top1 77.500000    Top5 97.218750    
2024-04-23 22:34:47,637 - Epoch: [433][  123/  123]    Loss 0.704579    Top1 77.375796    Top5 97.248408    
2024-04-23 22:34:47,904 - ==> Top1: 77.376    Top5: 97.248    Loss: 0.705

2024-04-23 22:34:47,916 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:34:47,917 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:34:47,962 - 

2024-04-23 22:34:47,963 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:35:03,162 - Epoch: [434][  100/  296]    Overall Loss 0.722743    Objective Loss 0.722743                                        LR 0.000005    Time 0.151826    
2024-04-23 22:35:16,559 - Epoch: [434][  200/  296]    Overall Loss 0.709748    Objective Loss 0.709748                                        LR 0.000005    Time 0.142812    
2024-04-23 22:35:26,311 - Epoch: [434][  296/  296]    Overall Loss 0.707971    Objective Loss 0.707971    Top1 70.491803    Top5 95.081967    LR 0.000005    Time 0.129390    
2024-04-23 22:35:26,543 - --- validate (epoch=434)-----------
2024-04-23 22:35:26,544 - 3925 samples (32 per mini-batch)
2024-04-23 22:35:40,427 - Epoch: [434][  100/  123]    Loss 0.696964    Top1 78.125000    Top5 97.312500    
2024-04-23 22:35:43,779 - Epoch: [434][  123/  123]    Loss 0.700988    Top1 77.732484    Top5 97.222930    
2024-04-23 22:35:44,028 - ==> Top1: 77.732    Top5: 97.223    Loss: 0.701

2024-04-23 22:35:44,033 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:35:44,034 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:35:44,063 - 

2024-04-23 22:35:44,063 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:35:57,648 - Epoch: [435][  100/  296]    Overall Loss 0.719427    Objective Loss 0.719427                                        LR 0.000005    Time 0.135695    
2024-04-23 22:36:09,322 - Epoch: [435][  200/  296]    Overall Loss 0.729366    Objective Loss 0.729366                                        LR 0.000005    Time 0.126137    
2024-04-23 22:36:20,903 - Epoch: [435][  296/  296]    Overall Loss 0.712502    Objective Loss 0.712502    Top1 85.245902    Top5 96.721311    LR 0.000005    Time 0.124300    
2024-04-23 22:36:21,053 - --- validate (epoch=435)-----------
2024-04-23 22:36:21,054 - 3925 samples (32 per mini-batch)
2024-04-23 22:36:35,633 - Epoch: [435][  100/  123]    Loss 0.696523    Top1 78.250000    Top5 97.312500    
2024-04-23 22:36:39,170 - Epoch: [435][  123/  123]    Loss 0.702952    Top1 77.707006    Top5 97.299363    
2024-04-23 22:36:39,369 - ==> Top1: 77.707    Top5: 97.299    Loss: 0.703

2024-04-23 22:36:39,382 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:36:39,382 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:36:39,428 - 

2024-04-23 22:36:39,429 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:36:52,879 - Epoch: [436][  100/  296]    Overall Loss 0.728411    Objective Loss 0.728411                                        LR 0.000005    Time 0.134325    
2024-04-23 22:37:03,626 - Epoch: [436][  200/  296]    Overall Loss 0.715994    Objective Loss 0.715994                                        LR 0.000005    Time 0.120810    
2024-04-23 22:37:13,096 - Epoch: [436][  296/  296]    Overall Loss 0.710223    Objective Loss 0.710223    Top1 65.573770    Top5 95.081967    LR 0.000005    Time 0.113561    
2024-04-23 22:37:13,312 - --- validate (epoch=436)-----------
2024-04-23 22:37:13,313 - 3925 samples (32 per mini-batch)
2024-04-23 22:37:27,479 - Epoch: [436][  100/  123]    Loss 0.694166    Top1 77.906250    Top5 97.187500    
2024-04-23 22:37:30,155 - Epoch: [436][  123/  123]    Loss 0.698920    Top1 77.732484    Top5 97.299363    
2024-04-23 22:37:30,304 - ==> Top1: 77.732    Top5: 97.299    Loss: 0.699

2024-04-23 22:37:30,314 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:37:30,314 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:37:30,352 - 

2024-04-23 22:37:30,352 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:37:39,075 - Epoch: [437][  100/  296]    Overall Loss 0.687902    Objective Loss 0.687902                                        LR 0.000005    Time 0.087076    
2024-04-23 22:37:47,353 - Epoch: [437][  200/  296]    Overall Loss 0.707367    Objective Loss 0.707367                                        LR 0.000005    Time 0.084848    
2024-04-23 22:37:54,398 - Epoch: [437][  296/  296]    Overall Loss 0.717360    Objective Loss 0.717360    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.081077    
2024-04-23 22:37:54,648 - --- validate (epoch=437)-----------
2024-04-23 22:37:54,649 - 3925 samples (32 per mini-batch)
2024-04-23 22:38:08,714 - Epoch: [437][  100/  123]    Loss 0.691993    Top1 78.093750    Top5 97.187500    
2024-04-23 22:38:11,326 - Epoch: [437][  123/  123]    Loss 0.703890    Top1 77.630573    Top5 97.324841    
2024-04-23 22:38:11,536 - ==> Top1: 77.631    Top5: 97.325    Loss: 0.704

2024-04-23 22:38:11,547 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:38:11,548 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:38:11,594 - 

2024-04-23 22:38:11,594 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:38:23,356 - Epoch: [438][  100/  296]    Overall Loss 0.680145    Objective Loss 0.680145                                        LR 0.000005    Time 0.117435    
2024-04-23 22:38:32,058 - Epoch: [438][  200/  296]    Overall Loss 0.698345    Objective Loss 0.698345                                        LR 0.000005    Time 0.102150    
2024-04-23 22:38:41,801 - Epoch: [438][  296/  296]    Overall Loss 0.701726    Objective Loss 0.701726    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.101886    
2024-04-23 22:38:42,054 - --- validate (epoch=438)-----------
2024-04-23 22:38:42,055 - 3925 samples (32 per mini-batch)
2024-04-23 22:38:56,670 - Epoch: [438][  100/  123]    Loss 0.706027    Top1 77.468750    Top5 97.312500    
2024-04-23 22:38:59,315 - Epoch: [438][  123/  123]    Loss 0.702801    Top1 77.503185    Top5 97.273885    
2024-04-23 22:38:59,560 - ==> Top1: 77.503    Top5: 97.274    Loss: 0.703

2024-04-23 22:38:59,572 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:38:59,573 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:38:59,608 - 

2024-04-23 22:38:59,609 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:39:11,966 - Epoch: [439][  100/  296]    Overall Loss 0.737475    Objective Loss 0.737475                                        LR 0.000005    Time 0.123394    
2024-04-23 22:39:20,534 - Epoch: [439][  200/  296]    Overall Loss 0.728164    Objective Loss 0.728164                                        LR 0.000005    Time 0.104459    
2024-04-23 22:39:27,443 - Epoch: [439][  296/  296]    Overall Loss 0.718193    Objective Loss 0.718193    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.093870    
2024-04-23 22:39:27,728 - --- validate (epoch=439)-----------
2024-04-23 22:39:27,729 - 3925 samples (32 per mini-batch)
2024-04-23 22:39:41,808 - Epoch: [439][  100/  123]    Loss 0.705326    Top1 77.593750    Top5 97.187500    
2024-04-23 22:39:44,962 - Epoch: [439][  123/  123]    Loss 0.700053    Top1 77.910828    Top5 97.273885    
2024-04-23 22:39:45,163 - ==> Top1: 77.911    Top5: 97.274    Loss: 0.700

2024-04-23 22:39:45,169 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:39:45,169 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:39:45,199 - 

2024-04-23 22:39:45,200 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:39:56,403 - Epoch: [440][  100/  296]    Overall Loss 0.704629    Objective Loss 0.704629                                        LR 0.000005    Time 0.111874    
2024-04-23 22:40:03,780 - Epoch: [440][  200/  296]    Overall Loss 0.716866    Objective Loss 0.716866                                        LR 0.000005    Time 0.092748    
2024-04-23 22:40:12,459 - Epoch: [440][  296/  296]    Overall Loss 0.709403    Objective Loss 0.709403    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.091943    
2024-04-23 22:40:12,717 - --- validate (epoch=440)-----------
2024-04-23 22:40:12,718 - 3925 samples (32 per mini-batch)
2024-04-23 22:40:23,585 - Epoch: [440][  100/  123]    Loss 0.696664    Top1 77.750000    Top5 97.375000    
2024-04-23 22:40:25,723 - Epoch: [440][  123/  123]    Loss 0.701784    Top1 77.401274    Top5 97.222930    
2024-04-23 22:40:26,008 - ==> Top1: 77.401    Top5: 97.223    Loss: 0.702

2024-04-23 22:40:26,018 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:40:26,019 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:40:26,058 - 

2024-04-23 22:40:26,058 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:40:38,741 - Epoch: [441][  100/  296]    Overall Loss 0.684882    Objective Loss 0.684882                                        LR 0.000005    Time 0.126641    
2024-04-23 22:40:50,811 - Epoch: [441][  200/  296]    Overall Loss 0.700998    Objective Loss 0.700998                                        LR 0.000005    Time 0.123582    
2024-04-23 22:41:03,278 - Epoch: [441][  296/  296]    Overall Loss 0.711477    Objective Loss 0.711477    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.125565    
2024-04-23 22:41:03,562 - --- validate (epoch=441)-----------
2024-04-23 22:41:03,563 - 3925 samples (32 per mini-batch)
2024-04-23 22:41:19,242 - Epoch: [441][  100/  123]    Loss 0.689794    Top1 78.187500    Top5 97.468750    
2024-04-23 22:41:22,113 - Epoch: [441][  123/  123]    Loss 0.704783    Top1 77.656051    Top5 97.299363    
2024-04-23 22:41:22,333 - ==> Top1: 77.656    Top5: 97.299    Loss: 0.705

2024-04-23 22:41:22,344 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:41:22,345 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:41:22,389 - 

2024-04-23 22:41:22,390 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:41:35,479 - Epoch: [442][  100/  296]    Overall Loss 0.720586    Objective Loss 0.720586                                        LR 0.000005    Time 0.130718    
2024-04-23 22:41:43,014 - Epoch: [442][  200/  296]    Overall Loss 0.703268    Objective Loss 0.703268                                        LR 0.000005    Time 0.102957    
2024-04-23 22:41:51,923 - Epoch: [442][  296/  296]    Overall Loss 0.704877    Objective Loss 0.704877    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.099609    
2024-04-23 22:41:52,173 - --- validate (epoch=442)-----------
2024-04-23 22:41:52,174 - 3925 samples (32 per mini-batch)
2024-04-23 22:42:02,943 - Epoch: [442][  100/  123]    Loss 0.700371    Top1 77.531250    Top5 97.218750    
2024-04-23 22:42:05,009 - Epoch: [442][  123/  123]    Loss 0.703748    Top1 77.554140    Top5 97.222930    
2024-04-23 22:42:05,283 - ==> Top1: 77.554    Top5: 97.223    Loss: 0.704

2024-04-23 22:42:05,295 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:42:05,296 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:42:05,337 - 

2024-04-23 22:42:05,337 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:42:16,384 - Epoch: [443][  100/  296]    Overall Loss 0.699604    Objective Loss 0.699604                                        LR 0.000005    Time 0.110293    
2024-04-23 22:42:29,422 - Epoch: [443][  200/  296]    Overall Loss 0.692245    Objective Loss 0.692245                                        LR 0.000005    Time 0.120253    
2024-04-23 22:42:38,588 - Epoch: [443][  296/  296]    Overall Loss 0.696294    Objective Loss 0.696294    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.112172    
2024-04-23 22:42:38,846 - --- validate (epoch=443)-----------
2024-04-23 22:42:38,847 - 3925 samples (32 per mini-batch)
2024-04-23 22:42:55,066 - Epoch: [443][  100/  123]    Loss 0.725220    Top1 76.781250    Top5 97.093750    
2024-04-23 22:42:57,759 - Epoch: [443][  123/  123]    Loss 0.703935    Top1 77.477707    Top5 97.248408    
2024-04-23 22:42:58,047 - ==> Top1: 77.478    Top5: 97.248    Loss: 0.704

2024-04-23 22:42:58,058 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:42:58,058 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:42:58,108 - 

2024-04-23 22:42:58,109 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:43:11,750 - Epoch: [444][  100/  296]    Overall Loss 0.704989    Objective Loss 0.704989                                        LR 0.000005    Time 0.136216    
2024-04-23 22:43:22,254 - Epoch: [444][  200/  296]    Overall Loss 0.690733    Objective Loss 0.690733                                        LR 0.000005    Time 0.120547    
2024-04-23 22:43:33,086 - Epoch: [444][  296/  296]    Overall Loss 0.707137    Objective Loss 0.707137    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.117993    
2024-04-23 22:43:33,374 - --- validate (epoch=444)-----------
2024-04-23 22:43:33,375 - 3925 samples (32 per mini-batch)
2024-04-23 22:43:48,233 - Epoch: [444][  100/  123]    Loss 0.700341    Top1 77.625000    Top5 97.500000    
2024-04-23 22:43:50,611 - Epoch: [444][  123/  123]    Loss 0.706144    Top1 77.452229    Top5 97.503185    
2024-04-23 22:43:50,899 - ==> Top1: 77.452    Top5: 97.503    Loss: 0.706

2024-04-23 22:43:50,908 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:43:50,909 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:43:50,971 - 

2024-04-23 22:43:50,972 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:44:00,145 - Epoch: [445][  100/  296]    Overall Loss 0.725048    Objective Loss 0.725048                                        LR 0.000005    Time 0.091576    
2024-04-23 22:44:06,608 - Epoch: [445][  200/  296]    Overall Loss 0.721778    Objective Loss 0.721778                                        LR 0.000005    Time 0.078025    
2024-04-23 22:44:13,830 - Epoch: [445][  296/  296]    Overall Loss 0.707813    Objective Loss 0.707813    Top1 70.491803    Top5 98.360656    LR 0.000005    Time 0.077073    
2024-04-23 22:44:14,037 - --- validate (epoch=445)-----------
2024-04-23 22:44:14,038 - 3925 samples (32 per mini-batch)
2024-04-23 22:44:29,908 - Epoch: [445][  100/  123]    Loss 0.703795    Top1 77.437500    Top5 97.156250    
2024-04-23 22:44:32,999 - Epoch: [445][  123/  123]    Loss 0.707077    Top1 77.222930    Top5 97.273885    
2024-04-23 22:44:33,274 - ==> Top1: 77.223    Top5: 97.274    Loss: 0.707

2024-04-23 22:44:33,285 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:44:33,286 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:44:33,327 - 

2024-04-23 22:44:33,327 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:44:42,107 - Epoch: [446][  100/  296]    Overall Loss 0.726717    Objective Loss 0.726717                                        LR 0.000005    Time 0.087638    
2024-04-23 22:44:50,623 - Epoch: [446][  200/  296]    Overall Loss 0.724218    Objective Loss 0.724218                                        LR 0.000005    Time 0.086323    
2024-04-23 22:44:57,750 - Epoch: [446][  296/  296]    Overall Loss 0.713363    Objective Loss 0.713363    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.082358    
2024-04-23 22:44:57,995 - --- validate (epoch=446)-----------
2024-04-23 22:44:57,996 - 3925 samples (32 per mini-batch)
2024-04-23 22:45:09,350 - Epoch: [446][  100/  123]    Loss 0.713872    Top1 77.187500    Top5 97.281250    
2024-04-23 22:45:11,417 - Epoch: [446][  123/  123]    Loss 0.701828    Top1 77.834395    Top5 97.350318    
2024-04-23 22:45:11,586 - ==> Top1: 77.834    Top5: 97.350    Loss: 0.702

2024-04-23 22:45:11,596 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:45:11,597 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:45:11,645 - 

2024-04-23 22:45:11,646 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:45:27,757 - Epoch: [447][  100/  296]    Overall Loss 0.725812    Objective Loss 0.725812                                        LR 0.000005    Time 0.160937    
2024-04-23 22:45:39,966 - Epoch: [447][  200/  296]    Overall Loss 0.722479    Objective Loss 0.722479                                        LR 0.000005    Time 0.141426    
2024-04-23 22:45:50,505 - Epoch: [447][  296/  296]    Overall Loss 0.717811    Objective Loss 0.717811    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.131106    
2024-04-23 22:45:50,792 - --- validate (epoch=447)-----------
2024-04-23 22:45:50,793 - 3925 samples (32 per mini-batch)
2024-04-23 22:46:04,940 - Epoch: [447][  100/  123]    Loss 0.713421    Top1 77.281250    Top5 97.156250    
2024-04-23 22:46:07,031 - Epoch: [447][  123/  123]    Loss 0.702319    Top1 77.656051    Top5 97.299363    
2024-04-23 22:46:07,188 - ==> Top1: 77.656    Top5: 97.299    Loss: 0.702

2024-04-23 22:46:07,197 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:46:07,198 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:46:07,233 - 

2024-04-23 22:46:07,233 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:46:18,571 - Epoch: [448][  100/  296]    Overall Loss 0.723977    Objective Loss 0.723977                                        LR 0.000005    Time 0.113217    
2024-04-23 22:46:27,319 - Epoch: [448][  200/  296]    Overall Loss 0.714042    Objective Loss 0.714042                                        LR 0.000005    Time 0.100269    
2024-04-23 22:46:37,512 - Epoch: [448][  296/  296]    Overall Loss 0.701335    Objective Loss 0.701335    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.102141    
2024-04-23 22:46:37,766 - --- validate (epoch=448)-----------
2024-04-23 22:46:37,768 - 3925 samples (32 per mini-batch)
2024-04-23 22:46:50,837 - Epoch: [448][  100/  123]    Loss 0.709590    Top1 77.000000    Top5 97.343750    
2024-04-23 22:46:53,421 - Epoch: [448][  123/  123]    Loss 0.702355    Top1 77.656051    Top5 97.299363    
2024-04-23 22:46:53,649 - ==> Top1: 77.656    Top5: 97.299    Loss: 0.702

2024-04-23 22:46:53,660 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:46:53,661 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:46:53,704 - 

2024-04-23 22:46:53,705 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:47:05,313 - Epoch: [449][  100/  296]    Overall Loss 0.696414    Objective Loss 0.696414                                        LR 0.000005    Time 0.115906    
2024-04-23 22:47:15,301 - Epoch: [449][  200/  296]    Overall Loss 0.713675    Objective Loss 0.713675                                        LR 0.000005    Time 0.107815    
2024-04-23 22:47:24,162 - Epoch: [449][  296/  296]    Overall Loss 0.703447    Objective Loss 0.703447    Top1 83.606557    Top5 95.081967    LR 0.000005    Time 0.102724    
2024-04-23 22:47:24,406 - --- validate (epoch=449)-----------
2024-04-23 22:47:24,408 - 3925 samples (32 per mini-batch)
2024-04-23 22:47:38,179 - Epoch: [449][  100/  123]    Loss 0.706018    Top1 77.406250    Top5 97.156250    
2024-04-23 22:47:40,555 - Epoch: [449][  123/  123]    Loss 0.703427    Top1 77.477707    Top5 97.350318    
2024-04-23 22:47:40,774 - ==> Top1: 77.478    Top5: 97.350    Loss: 0.703

2024-04-23 22:47:40,784 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:47:40,785 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:47:40,821 - 

2024-04-23 22:47:40,822 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:47:52,745 - Epoch: [450][  100/  296]    Overall Loss 0.712010    Objective Loss 0.712010                                        LR 0.000005    Time 0.119078    
2024-04-23 22:48:05,898 - Epoch: [450][  200/  296]    Overall Loss 0.716573    Objective Loss 0.716573                                        LR 0.000005    Time 0.125217    
2024-04-23 22:48:17,518 - Epoch: [450][  296/  296]    Overall Loss 0.715736    Objective Loss 0.715736    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.123808    
2024-04-23 22:48:17,775 - --- validate (epoch=450)-----------
2024-04-23 22:48:17,777 - 3925 samples (32 per mini-batch)
2024-04-23 22:48:32,346 - Epoch: [450][  100/  123]    Loss 0.696488    Top1 77.468750    Top5 97.437500    
2024-04-23 22:48:34,347 - Epoch: [450][  123/  123]    Loss 0.700060    Top1 77.528662    Top5 97.401274    
2024-04-23 22:48:34,645 - ==> Top1: 77.529    Top5: 97.401    Loss: 0.700

2024-04-23 22:48:34,654 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:48:34,655 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:48:34,691 - 

2024-04-23 22:48:34,692 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:48:44,345 - Epoch: [451][  100/  296]    Overall Loss 0.669231    Objective Loss 0.669231                                        LR 0.000005    Time 0.096363    
2024-04-23 22:48:51,643 - Epoch: [451][  200/  296]    Overall Loss 0.710998    Objective Loss 0.710998                                        LR 0.000005    Time 0.084603    
2024-04-23 22:49:01,968 - Epoch: [451][  296/  296]    Overall Loss 0.719124    Objective Loss 0.719124    Top1 73.770492    Top5 90.163934    LR 0.000005    Time 0.091991    
2024-04-23 22:49:02,146 - --- validate (epoch=451)-----------
2024-04-23 22:49:02,147 - 3925 samples (32 per mini-batch)
2024-04-23 22:49:12,194 - Epoch: [451][  100/  123]    Loss 0.692296    Top1 78.156250    Top5 97.593750    
2024-04-23 22:49:14,051 - Epoch: [451][  123/  123]    Loss 0.704579    Top1 77.605096    Top5 97.426752    
2024-04-23 22:49:14,306 - ==> Top1: 77.605    Top5: 97.427    Loss: 0.705

2024-04-23 22:49:14,314 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:49:14,315 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:49:14,367 - 

2024-04-23 22:49:14,369 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:49:22,744 - Epoch: [452][  100/  296]    Overall Loss 0.738728    Objective Loss 0.738728                                        LR 0.000005    Time 0.083578    
2024-04-23 22:49:30,744 - Epoch: [452][  200/  296]    Overall Loss 0.727993    Objective Loss 0.727993                                        LR 0.000005    Time 0.081712    
2024-04-23 22:49:39,368 - Epoch: [452][  296/  296]    Overall Loss 0.723834    Objective Loss 0.723834    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.084297    
2024-04-23 22:49:39,611 - --- validate (epoch=452)-----------
2024-04-23 22:49:39,612 - 3925 samples (32 per mini-batch)
2024-04-23 22:49:49,925 - Epoch: [452][  100/  123]    Loss 0.697722    Top1 78.093750    Top5 97.437500    
2024-04-23 22:49:51,834 - Epoch: [452][  123/  123]    Loss 0.701008    Top1 77.885350    Top5 97.350318    
2024-04-23 22:49:52,052 - ==> Top1: 77.885    Top5: 97.350    Loss: 0.701

2024-04-23 22:49:52,062 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:49:52,063 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:49:52,103 - 

2024-04-23 22:49:52,104 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:50:04,363 - Epoch: [453][  100/  296]    Overall Loss 0.697100    Objective Loss 0.697100                                        LR 0.000005    Time 0.122404    
2024-04-23 22:50:13,493 - Epoch: [453][  200/  296]    Overall Loss 0.688045    Objective Loss 0.688045                                        LR 0.000005    Time 0.106779    
2024-04-23 22:50:21,669 - Epoch: [453][  296/  296]    Overall Loss 0.700966    Objective Loss 0.700966    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.099724    
2024-04-23 22:50:21,835 - --- validate (epoch=453)-----------
2024-04-23 22:50:21,836 - 3925 samples (32 per mini-batch)
2024-04-23 22:50:32,825 - Epoch: [453][  100/  123]    Loss 0.697796    Top1 78.000000    Top5 97.531250    
2024-04-23 22:50:34,875 - Epoch: [453][  123/  123]    Loss 0.698414    Top1 77.885350    Top5 97.452229    
2024-04-23 22:50:35,093 - ==> Top1: 77.885    Top5: 97.452    Loss: 0.698

2024-04-23 22:50:35,103 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:50:35,103 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:50:35,156 - 

2024-04-23 22:50:35,157 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:50:51,328 - Epoch: [454][  100/  296]    Overall Loss 0.734969    Objective Loss 0.734969                                        LR 0.000005    Time 0.161539    
2024-04-23 22:51:05,474 - Epoch: [454][  200/  296]    Overall Loss 0.726577    Objective Loss 0.726577                                        LR 0.000005    Time 0.151413    
2024-04-23 22:51:17,168 - Epoch: [454][  296/  296]    Overall Loss 0.715646    Objective Loss 0.715646    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.141763    
2024-04-23 22:51:17,463 - --- validate (epoch=454)-----------
2024-04-23 22:51:17,464 - 3925 samples (32 per mini-batch)
2024-04-23 22:51:32,373 - Epoch: [454][  100/  123]    Loss 0.709201    Top1 77.250000    Top5 97.500000    
2024-04-23 22:51:35,350 - Epoch: [454][  123/  123]    Loss 0.698071    Top1 77.630573    Top5 97.375796    
2024-04-23 22:51:35,625 - ==> Top1: 77.631    Top5: 97.376    Loss: 0.698

2024-04-23 22:51:35,634 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:51:35,634 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:51:35,693 - 

2024-04-23 22:51:35,694 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:51:50,560 - Epoch: [455][  100/  296]    Overall Loss 0.713039    Objective Loss 0.713039                                        LR 0.000005    Time 0.148500    
2024-04-23 22:52:02,579 - Epoch: [455][  200/  296]    Overall Loss 0.700442    Objective Loss 0.700442                                        LR 0.000005    Time 0.134263    
2024-04-23 22:52:13,543 - Epoch: [455][  296/  296]    Overall Loss 0.703746    Objective Loss 0.703746    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.127708    
2024-04-23 22:52:13,789 - --- validate (epoch=455)-----------
2024-04-23 22:52:13,790 - 3925 samples (32 per mini-batch)
2024-04-23 22:52:27,213 - Epoch: [455][  100/  123]    Loss 0.692574    Top1 77.468750    Top5 97.500000    
2024-04-23 22:52:29,803 - Epoch: [455][  123/  123]    Loss 0.700288    Top1 77.732484    Top5 97.350318    
2024-04-23 22:52:30,011 - ==> Top1: 77.732    Top5: 97.350    Loss: 0.700

2024-04-23 22:52:30,019 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:52:30,020 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:52:30,068 - 

2024-04-23 22:52:30,069 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:52:41,433 - Epoch: [456][  100/  296]    Overall Loss 0.694614    Objective Loss 0.694614                                        LR 0.000005    Time 0.113456    
2024-04-23 22:52:52,933 - Epoch: [456][  200/  296]    Overall Loss 0.700857    Objective Loss 0.700857                                        LR 0.000005    Time 0.114137    
2024-04-23 22:53:03,902 - Epoch: [456][  296/  296]    Overall Loss 0.701657    Objective Loss 0.701657    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.114131    
2024-04-23 22:53:04,120 - --- validate (epoch=456)-----------
2024-04-23 22:53:04,121 - 3925 samples (32 per mini-batch)
2024-04-23 22:53:16,724 - Epoch: [456][  100/  123]    Loss 0.681914    Top1 78.156250    Top5 97.281250    
2024-04-23 22:53:18,718 - Epoch: [456][  123/  123]    Loss 0.700581    Top1 77.783439    Top5 97.324841    
2024-04-23 22:53:18,903 - ==> Top1: 77.783    Top5: 97.325    Loss: 0.701

2024-04-23 22:53:18,911 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:53:18,911 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:53:18,953 - 

2024-04-23 22:53:18,953 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:53:29,150 - Epoch: [457][  100/  296]    Overall Loss 0.710954    Objective Loss 0.710954                                        LR 0.000005    Time 0.101804    
2024-04-23 22:53:38,632 - Epoch: [457][  200/  296]    Overall Loss 0.731926    Objective Loss 0.731926                                        LR 0.000005    Time 0.098228    
2024-04-23 22:53:46,606 - Epoch: [457][  296/  296]    Overall Loss 0.726106    Objective Loss 0.726106    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.093257    
2024-04-23 22:53:46,898 - --- validate (epoch=457)-----------
2024-04-23 22:53:46,900 - 3925 samples (32 per mini-batch)
2024-04-23 22:54:01,769 - Epoch: [457][  100/  123]    Loss 0.702986    Top1 77.625000    Top5 97.281250    
2024-04-23 22:54:04,279 - Epoch: [457][  123/  123]    Loss 0.698954    Top1 77.681529    Top5 97.324841    
2024-04-23 22:54:04,510 - ==> Top1: 77.682    Top5: 97.325    Loss: 0.699

2024-04-23 22:54:04,523 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:54:04,523 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:54:04,563 - 

2024-04-23 22:54:04,564 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:54:13,838 - Epoch: [458][  100/  296]    Overall Loss 0.701529    Objective Loss 0.701529                                        LR 0.000005    Time 0.092565    
2024-04-23 22:54:20,790 - Epoch: [458][  200/  296]    Overall Loss 0.718064    Objective Loss 0.718064                                        LR 0.000005    Time 0.080978    
2024-04-23 22:54:30,118 - Epoch: [458][  296/  296]    Overall Loss 0.716479    Objective Loss 0.716479    Top1 81.967213    Top5 95.081967    LR 0.000005    Time 0.086183    
2024-04-23 22:54:30,331 - --- validate (epoch=458)-----------
2024-04-23 22:54:30,332 - 3925 samples (32 per mini-batch)
2024-04-23 22:54:42,883 - Epoch: [458][  100/  123]    Loss 0.696962    Top1 77.781250    Top5 97.468750    
2024-04-23 22:54:44,883 - Epoch: [458][  123/  123]    Loss 0.704546    Top1 77.375796    Top5 97.452229    
2024-04-23 22:54:45,090 - ==> Top1: 77.376    Top5: 97.452    Loss: 0.705

2024-04-23 22:54:45,100 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:54:45,101 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:54:45,137 - 

2024-04-23 22:54:45,137 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:54:54,057 - Epoch: [459][  100/  296]    Overall Loss 0.699951    Objective Loss 0.699951                                        LR 0.000005    Time 0.089029    
2024-04-23 22:55:01,981 - Epoch: [459][  200/  296]    Overall Loss 0.695937    Objective Loss 0.695937                                        LR 0.000005    Time 0.084058    
2024-04-23 22:55:10,032 - Epoch: [459][  296/  296]    Overall Loss 0.698265    Objective Loss 0.698265    Top1 70.491803    Top5 95.081967    LR 0.000005    Time 0.083949    
2024-04-23 22:55:10,247 - --- validate (epoch=459)-----------
2024-04-23 22:55:10,247 - 3925 samples (32 per mini-batch)
2024-04-23 22:55:22,984 - Epoch: [459][  100/  123]    Loss 0.702361    Top1 77.843750    Top5 97.437500    
2024-04-23 22:55:25,404 - Epoch: [459][  123/  123]    Loss 0.703197    Top1 77.834395    Top5 97.375796    
2024-04-23 22:55:25,675 - ==> Top1: 77.834    Top5: 97.376    Loss: 0.703

2024-04-23 22:55:25,685 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:55:25,686 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:55:25,735 - 

2024-04-23 22:55:25,735 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:55:39,882 - Epoch: [460][  100/  296]    Overall Loss 0.730569    Objective Loss 0.730569                                        LR 0.000005    Time 0.141295    
2024-04-23 22:55:51,383 - Epoch: [460][  200/  296]    Overall Loss 0.713005    Objective Loss 0.713005                                        LR 0.000005    Time 0.128073    
2024-04-23 22:56:03,174 - Epoch: [460][  296/  296]    Overall Loss 0.707394    Objective Loss 0.707394    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.126322    
2024-04-23 22:56:03,457 - --- validate (epoch=460)-----------
2024-04-23 22:56:03,458 - 3925 samples (32 per mini-batch)
2024-04-23 22:56:18,017 - Epoch: [460][  100/  123]    Loss 0.699967    Top1 77.812500    Top5 97.281250    
2024-04-23 22:56:20,947 - Epoch: [460][  123/  123]    Loss 0.699097    Top1 77.732484    Top5 97.350318    
2024-04-23 22:56:21,192 - ==> Top1: 77.732    Top5: 97.350    Loss: 0.699

2024-04-23 22:56:21,204 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:56:21,205 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:56:21,253 - 

2024-04-23 22:56:21,254 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:56:35,230 - Epoch: [461][  100/  296]    Overall Loss 0.733182    Objective Loss 0.733182                                        LR 0.000005    Time 0.139592    
2024-04-23 22:56:48,369 - Epoch: [461][  200/  296]    Overall Loss 0.722997    Objective Loss 0.722997                                        LR 0.000005    Time 0.135408    
2024-04-23 22:56:58,799 - Epoch: [461][  296/  296]    Overall Loss 0.723324    Objective Loss 0.723324    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.126680    
2024-04-23 22:56:59,089 - --- validate (epoch=461)-----------
2024-04-23 22:56:59,090 - 3925 samples (32 per mini-batch)
2024-04-23 22:57:12,163 - Epoch: [461][  100/  123]    Loss 0.684204    Top1 78.250000    Top5 97.343750    
2024-04-23 22:57:15,237 - Epoch: [461][  123/  123]    Loss 0.705675    Top1 77.477707    Top5 97.273885    
2024-04-23 22:57:15,456 - ==> Top1: 77.478    Top5: 97.274    Loss: 0.706

2024-04-23 22:57:15,467 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:57:15,467 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:57:15,507 - 

2024-04-23 22:57:15,507 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:57:26,682 - Epoch: [462][  100/  296]    Overall Loss 0.676071    Objective Loss 0.676071                                        LR 0.000005    Time 0.111570    
2024-04-23 22:57:35,344 - Epoch: [462][  200/  296]    Overall Loss 0.699276    Objective Loss 0.699276                                        LR 0.000005    Time 0.099016    
2024-04-23 22:57:43,920 - Epoch: [462][  296/  296]    Overall Loss 0.698034    Objective Loss 0.698034    Top1 68.852459    Top5 98.360656    LR 0.000005    Time 0.095826    
2024-04-23 22:57:44,162 - --- validate (epoch=462)-----------
2024-04-23 22:57:44,163 - 3925 samples (32 per mini-batch)
2024-04-23 22:57:56,249 - Epoch: [462][  100/  123]    Loss 0.699218    Top1 77.968750    Top5 97.312500    
2024-04-23 22:57:58,864 - Epoch: [462][  123/  123]    Loss 0.700621    Top1 77.732484    Top5 97.299363    
2024-04-23 22:57:59,082 - ==> Top1: 77.732    Top5: 97.299    Loss: 0.701

2024-04-23 22:57:59,092 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:57:59,092 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:57:59,134 - 

2024-04-23 22:57:59,135 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:58:09,752 - Epoch: [463][  100/  296]    Overall Loss 0.694876    Objective Loss 0.694876                                        LR 0.000005    Time 0.106002    
2024-04-23 22:58:19,519 - Epoch: [463][  200/  296]    Overall Loss 0.701175    Objective Loss 0.701175                                        LR 0.000005    Time 0.101756    
2024-04-23 22:58:31,303 - Epoch: [463][  296/  296]    Overall Loss 0.699434    Objective Loss 0.699434    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.108513    
2024-04-23 22:58:31,607 - --- validate (epoch=463)-----------
2024-04-23 22:58:31,608 - 3925 samples (32 per mini-batch)
2024-04-23 22:58:43,755 - Epoch: [463][  100/  123]    Loss 0.720546    Top1 77.156250    Top5 97.125000    
2024-04-23 22:58:46,118 - Epoch: [463][  123/  123]    Loss 0.703625    Top1 77.554140    Top5 97.299363    
2024-04-23 22:58:46,337 - ==> Top1: 77.554    Top5: 97.299    Loss: 0.704

2024-04-23 22:58:46,348 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:58:46,349 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:58:46,388 - 

2024-04-23 22:58:46,389 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:58:57,162 - Epoch: [464][  100/  296]    Overall Loss 0.705233    Objective Loss 0.705233                                        LR 0.000005    Time 0.107554    
2024-04-23 22:59:08,319 - Epoch: [464][  200/  296]    Overall Loss 0.699646    Objective Loss 0.699646                                        LR 0.000005    Time 0.109475    
2024-04-23 22:59:18,432 - Epoch: [464][  296/  296]    Overall Loss 0.694557    Objective Loss 0.694557    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.108079    
2024-04-23 22:59:18,612 - --- validate (epoch=464)-----------
2024-04-23 22:59:18,614 - 3925 samples (32 per mini-batch)
2024-04-23 22:59:34,271 - Epoch: [464][  100/  123]    Loss 0.687179    Top1 78.250000    Top5 97.531250    
2024-04-23 22:59:38,153 - Epoch: [464][  123/  123]    Loss 0.703994    Top1 77.605096    Top5 97.401274    
2024-04-23 22:59:38,419 - ==> Top1: 77.605    Top5: 97.401    Loss: 0.704

2024-04-23 22:59:38,431 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 22:59:38,432 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 22:59:38,482 - 

2024-04-23 22:59:38,483 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:59:53,858 - Epoch: [465][  100/  296]    Overall Loss 0.705653    Objective Loss 0.705653                                        LR 0.000005    Time 0.153569    
2024-04-23 23:00:06,900 - Epoch: [465][  200/  296]    Overall Loss 0.714305    Objective Loss 0.714305                                        LR 0.000005    Time 0.141910    
2024-04-23 23:00:18,220 - Epoch: [465][  296/  296]    Overall Loss 0.711438    Objective Loss 0.711438    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.134072    
2024-04-23 23:00:18,360 - --- validate (epoch=465)-----------
2024-04-23 23:00:18,361 - 3925 samples (32 per mini-batch)
2024-04-23 23:00:33,380 - Epoch: [465][  100/  123]    Loss 0.716997    Top1 77.156250    Top5 97.125000    
2024-04-23 23:00:36,152 - Epoch: [465][  123/  123]    Loss 0.705254    Top1 77.707006    Top5 97.222930    
2024-04-23 23:00:36,393 - ==> Top1: 77.707    Top5: 97.223    Loss: 0.705

2024-04-23 23:00:36,405 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:00:36,405 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:00:36,456 - 

2024-04-23 23:00:36,457 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:00:50,658 - Epoch: [466][  100/  296]    Overall Loss 0.721995    Objective Loss 0.721995                                        LR 0.000005    Time 0.141825    
2024-04-23 23:01:02,521 - Epoch: [466][  200/  296]    Overall Loss 0.722092    Objective Loss 0.722092                                        LR 0.000005    Time 0.130155    
2024-04-23 23:01:14,736 - Epoch: [466][  296/  296]    Overall Loss 0.725636    Objective Loss 0.725636    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.129164    
2024-04-23 23:01:15,255 - --- validate (epoch=466)-----------
2024-04-23 23:01:15,255 - 3925 samples (32 per mini-batch)
2024-04-23 23:01:29,356 - Epoch: [466][  100/  123]    Loss 0.709407    Top1 77.281250    Top5 97.187500    
2024-04-23 23:01:32,158 - Epoch: [466][  123/  123]    Loss 0.700120    Top1 77.477707    Top5 97.299363    
2024-04-23 23:01:32,403 - ==> Top1: 77.478    Top5: 97.299    Loss: 0.700

2024-04-23 23:01:32,414 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:01:32,415 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:01:32,465 - 

2024-04-23 23:01:32,466 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:01:45,312 - Epoch: [467][  100/  296]    Overall Loss 0.710576    Objective Loss 0.710576                                        LR 0.000005    Time 0.128287    
2024-04-23 23:01:57,481 - Epoch: [467][  200/  296]    Overall Loss 0.700927    Objective Loss 0.700927                                        LR 0.000005    Time 0.124904    
2024-04-23 23:02:07,921 - Epoch: [467][  296/  296]    Overall Loss 0.689040    Objective Loss 0.689040    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.119616    
2024-04-23 23:02:08,187 - --- validate (epoch=467)-----------
2024-04-23 23:02:08,189 - 3925 samples (32 per mini-batch)
2024-04-23 23:02:22,311 - Epoch: [467][  100/  123]    Loss 0.717137    Top1 77.687500    Top5 96.968750    
2024-04-23 23:02:25,066 - Epoch: [467][  123/  123]    Loss 0.698366    Top1 77.885350    Top5 97.273885    
2024-04-23 23:02:25,355 - ==> Top1: 77.885    Top5: 97.274    Loss: 0.698

2024-04-23 23:02:25,366 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:02:25,367 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:02:25,414 - 

2024-04-23 23:02:25,414 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:02:38,698 - Epoch: [468][  100/  296]    Overall Loss 0.715731    Objective Loss 0.715731                                        LR 0.000005    Time 0.132651    
2024-04-23 23:02:50,563 - Epoch: [468][  200/  296]    Overall Loss 0.714466    Objective Loss 0.714466                                        LR 0.000005    Time 0.125568    
2024-04-23 23:03:01,454 - Epoch: [468][  296/  296]    Overall Loss 0.713703    Objective Loss 0.713703    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.121589    
2024-04-23 23:03:01,764 - --- validate (epoch=468)-----------
2024-04-23 23:03:01,765 - 3925 samples (32 per mini-batch)
2024-04-23 23:03:16,211 - Epoch: [468][  100/  123]    Loss 0.707912    Top1 77.937500    Top5 97.312500    
2024-04-23 23:03:19,157 - Epoch: [468][  123/  123]    Loss 0.704770    Top1 77.656051    Top5 97.452229    
2024-04-23 23:03:19,359 - ==> Top1: 77.656    Top5: 97.452    Loss: 0.705

2024-04-23 23:03:19,369 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:03:19,370 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:03:19,426 - 

2024-04-23 23:03:19,427 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:03:30,394 - Epoch: [469][  100/  296]    Overall Loss 0.733349    Objective Loss 0.733349                                        LR 0.000005    Time 0.109502    
2024-04-23 23:03:42,290 - Epoch: [469][  200/  296]    Overall Loss 0.711129    Objective Loss 0.711129                                        LR 0.000005    Time 0.114145    
2024-04-23 23:03:54,645 - Epoch: [469][  296/  296]    Overall Loss 0.707706    Objective Loss 0.707706    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.118809    
2024-04-23 23:03:54,882 - --- validate (epoch=469)-----------
2024-04-23 23:03:54,883 - 3925 samples (32 per mini-batch)
2024-04-23 23:04:09,157 - Epoch: [469][  100/  123]    Loss 0.718191    Top1 77.093750    Top5 97.343750    
2024-04-23 23:04:12,400 - Epoch: [469][  123/  123]    Loss 0.707085    Top1 77.477707    Top5 97.375796    
2024-04-23 23:04:12,640 - ==> Top1: 77.478    Top5: 97.376    Loss: 0.707

2024-04-23 23:04:12,652 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:04:12,653 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:04:12,705 - 

2024-04-23 23:04:12,706 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:04:27,541 - Epoch: [470][  100/  296]    Overall Loss 0.739112    Objective Loss 0.739112                                        LR 0.000005    Time 0.148198    
2024-04-23 23:04:40,725 - Epoch: [470][  200/  296]    Overall Loss 0.714655    Objective Loss 0.714655                                        LR 0.000005    Time 0.139950    
2024-04-23 23:04:51,251 - Epoch: [470][  296/  296]    Overall Loss 0.717030    Objective Loss 0.717030    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.130067    
2024-04-23 23:04:51,542 - --- validate (epoch=470)-----------
2024-04-23 23:04:51,543 - 3925 samples (32 per mini-batch)
2024-04-23 23:05:06,658 - Epoch: [470][  100/  123]    Loss 0.696702    Top1 78.000000    Top5 97.281250    
2024-04-23 23:05:09,614 - Epoch: [470][  123/  123]    Loss 0.704195    Top1 77.681529    Top5 97.375796    
2024-04-23 23:05:09,907 - ==> Top1: 77.682    Top5: 97.376    Loss: 0.704

2024-04-23 23:05:09,919 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:05:09,919 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:05:09,959 - 

2024-04-23 23:05:09,960 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:05:24,454 - Epoch: [471][  100/  296]    Overall Loss 0.702222    Objective Loss 0.702222                                        LR 0.000005    Time 0.144780    
2024-04-23 23:05:35,496 - Epoch: [471][  200/  296]    Overall Loss 0.712988    Objective Loss 0.712988                                        LR 0.000005    Time 0.127516    
2024-04-23 23:05:46,795 - Epoch: [471][  296/  296]    Overall Loss 0.713622    Objective Loss 0.713622    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.124283    
2024-04-23 23:05:47,079 - --- validate (epoch=471)-----------
2024-04-23 23:05:47,081 - 3925 samples (32 per mini-batch)
2024-04-23 23:06:02,261 - Epoch: [471][  100/  123]    Loss 0.692954    Top1 78.000000    Top5 97.281250    
2024-04-23 23:06:04,826 - Epoch: [471][  123/  123]    Loss 0.699894    Top1 77.961783    Top5 97.324841    
2024-04-23 23:06:05,016 - ==> Top1: 77.962    Top5: 97.325    Loss: 0.700

2024-04-23 23:06:05,024 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:06:05,024 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:06:05,078 - 

2024-04-23 23:06:05,079 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:06:18,119 - Epoch: [472][  100/  296]    Overall Loss 0.676828    Objective Loss 0.676828                                        LR 0.000005    Time 0.130225    
2024-04-23 23:06:28,524 - Epoch: [472][  200/  296]    Overall Loss 0.683309    Objective Loss 0.683309                                        LR 0.000005    Time 0.117053    
2024-04-23 23:06:36,167 - Epoch: [472][  296/  296]    Overall Loss 0.694336    Objective Loss 0.694336    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.104865    
2024-04-23 23:06:36,279 - --- validate (epoch=472)-----------
2024-04-23 23:06:36,280 - 3925 samples (32 per mini-batch)
2024-04-23 23:06:52,533 - Epoch: [472][  100/  123]    Loss 0.700904    Top1 77.625000    Top5 97.250000    
2024-04-23 23:06:55,321 - Epoch: [472][  123/  123]    Loss 0.703199    Top1 77.757962    Top5 97.401274    
2024-04-23 23:06:55,574 - ==> Top1: 77.758    Top5: 97.401    Loss: 0.703

2024-04-23 23:06:55,585 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:06:55,586 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:06:55,630 - 

2024-04-23 23:06:55,631 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:07:10,461 - Epoch: [473][  100/  296]    Overall Loss 0.711321    Objective Loss 0.711321                                        LR 0.000005    Time 0.148136    
2024-04-23 23:07:22,054 - Epoch: [473][  200/  296]    Overall Loss 0.705179    Objective Loss 0.705179                                        LR 0.000005    Time 0.131961    
2024-04-23 23:07:33,380 - Epoch: [473][  296/  296]    Overall Loss 0.705580    Objective Loss 0.705580    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.127375    
2024-04-23 23:07:33,650 - --- validate (epoch=473)-----------
2024-04-23 23:07:33,651 - 3925 samples (32 per mini-batch)
2024-04-23 23:07:47,482 - Epoch: [473][  100/  123]    Loss 0.712697    Top1 77.781250    Top5 97.375000    
2024-04-23 23:07:49,257 - Epoch: [473][  123/  123]    Loss 0.703847    Top1 77.783439    Top5 97.350318    
2024-04-23 23:07:49,524 - ==> Top1: 77.783    Top5: 97.350    Loss: 0.704

2024-04-23 23:07:49,536 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:07:49,537 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:07:49,588 - 

2024-04-23 23:07:49,589 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:08:03,962 - Epoch: [474][  100/  296]    Overall Loss 0.716644    Objective Loss 0.716644                                        LR 0.000005    Time 0.143534    
2024-04-23 23:08:14,845 - Epoch: [474][  200/  296]    Overall Loss 0.704013    Objective Loss 0.704013                                        LR 0.000005    Time 0.126104    
2024-04-23 23:08:26,036 - Epoch: [474][  296/  296]    Overall Loss 0.713220    Objective Loss 0.713220    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.122955    
2024-04-23 23:08:26,312 - --- validate (epoch=474)-----------
2024-04-23 23:08:26,313 - 3925 samples (32 per mini-batch)
2024-04-23 23:08:40,117 - Epoch: [474][  100/  123]    Loss 0.694252    Top1 77.656250    Top5 97.406250    
2024-04-23 23:08:42,492 - Epoch: [474][  123/  123]    Loss 0.704280    Top1 77.452229    Top5 97.375796    
2024-04-23 23:08:42,682 - ==> Top1: 77.452    Top5: 97.376    Loss: 0.704

2024-04-23 23:08:42,691 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:08:42,691 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:08:42,729 - 

2024-04-23 23:08:42,729 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:08:55,578 - Epoch: [475][  100/  296]    Overall Loss 0.684692    Objective Loss 0.684692                                        LR 0.000005    Time 0.128309    
2024-04-23 23:09:06,952 - Epoch: [475][  200/  296]    Overall Loss 0.705485    Objective Loss 0.705485                                        LR 0.000005    Time 0.120940    
2024-04-23 23:09:17,877 - Epoch: [475][  296/  296]    Overall Loss 0.700558    Objective Loss 0.700558    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.118572    
2024-04-23 23:09:18,157 - --- validate (epoch=475)-----------
2024-04-23 23:09:18,158 - 3925 samples (32 per mini-batch)
2024-04-23 23:09:29,993 - Epoch: [475][  100/  123]    Loss 0.706496    Top1 78.093750    Top5 97.218750    
2024-04-23 23:09:32,603 - Epoch: [475][  123/  123]    Loss 0.700914    Top1 77.936306    Top5 97.273885    
2024-04-23 23:09:32,785 - ==> Top1: 77.936    Top5: 97.274    Loss: 0.701

2024-04-23 23:09:32,791 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:09:32,792 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:09:32,833 - 

2024-04-23 23:09:32,834 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:09:45,910 - Epoch: [476][  100/  296]    Overall Loss 0.723377    Objective Loss 0.723377                                        LR 0.000005    Time 0.130588    
2024-04-23 23:09:57,266 - Epoch: [476][  200/  296]    Overall Loss 0.708249    Objective Loss 0.708249                                        LR 0.000005    Time 0.121985    
2024-04-23 23:10:08,265 - Epoch: [476][  296/  296]    Overall Loss 0.697734    Objective Loss 0.697734    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.119526    
2024-04-23 23:10:08,482 - --- validate (epoch=476)-----------
2024-04-23 23:10:08,482 - 3925 samples (32 per mini-batch)
2024-04-23 23:10:23,855 - Epoch: [476][  100/  123]    Loss 0.703229    Top1 77.500000    Top5 97.343750    
2024-04-23 23:10:27,066 - Epoch: [476][  123/  123]    Loss 0.707958    Top1 77.477707    Top5 97.273885    
2024-04-23 23:10:27,359 - ==> Top1: 77.478    Top5: 97.274    Loss: 0.708

2024-04-23 23:10:27,370 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:10:27,371 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:10:27,419 - 

2024-04-23 23:10:27,420 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:10:43,590 - Epoch: [477][  100/  296]    Overall Loss 0.697352    Objective Loss 0.697352                                        LR 0.000005    Time 0.161563    
2024-04-23 23:10:58,523 - Epoch: [477][  200/  296]    Overall Loss 0.699766    Objective Loss 0.699766                                        LR 0.000005    Time 0.155367    
2024-04-23 23:11:09,942 - Epoch: [477][  296/  296]    Overall Loss 0.698275    Objective Loss 0.698275    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.143505    
2024-04-23 23:11:10,234 - --- validate (epoch=477)-----------
2024-04-23 23:11:10,235 - 3925 samples (32 per mini-batch)
2024-04-23 23:11:27,409 - Epoch: [477][  100/  123]    Loss 0.705029    Top1 77.968750    Top5 97.281250    
2024-04-23 23:11:30,085 - Epoch: [477][  123/  123]    Loss 0.703759    Top1 77.732484    Top5 97.324841    
2024-04-23 23:11:30,424 - ==> Top1: 77.732    Top5: 97.325    Loss: 0.704

2024-04-23 23:11:30,435 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:11:30,436 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:11:30,475 - 

2024-04-23 23:11:30,476 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:11:45,039 - Epoch: [478][  100/  296]    Overall Loss 0.695093    Objective Loss 0.695093                                        LR 0.000005    Time 0.145445    
2024-04-23 23:11:59,540 - Epoch: [478][  200/  296]    Overall Loss 0.706558    Objective Loss 0.706558                                        LR 0.000005    Time 0.145134    
2024-04-23 23:12:07,979 - Epoch: [478][  296/  296]    Overall Loss 0.704118    Objective Loss 0.704118    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.126525    
2024-04-23 23:12:08,209 - --- validate (epoch=478)-----------
2024-04-23 23:12:08,210 - 3925 samples (32 per mini-batch)
2024-04-23 23:12:23,991 - Epoch: [478][  100/  123]    Loss 0.712301    Top1 77.437500    Top5 97.468750    
2024-04-23 23:12:27,003 - Epoch: [478][  123/  123]    Loss 0.705957    Top1 77.681529    Top5 97.324841    
2024-04-23 23:12:27,266 - ==> Top1: 77.682    Top5: 97.325    Loss: 0.706

2024-04-23 23:12:27,276 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:12:27,276 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:12:27,322 - 

2024-04-23 23:12:27,322 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:12:41,148 - Epoch: [479][  100/  296]    Overall Loss 0.720212    Objective Loss 0.720212                                        LR 0.000005    Time 0.138079    
2024-04-23 23:12:53,321 - Epoch: [479][  200/  296]    Overall Loss 0.715535    Objective Loss 0.715535                                        LR 0.000005    Time 0.129810    
2024-04-23 23:13:03,489 - Epoch: [479][  296/  296]    Overall Loss 0.714476    Objective Loss 0.714476    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.122009    
2024-04-23 23:13:03,668 - --- validate (epoch=479)-----------
2024-04-23 23:13:03,669 - 3925 samples (32 per mini-batch)
2024-04-23 23:13:14,276 - Epoch: [479][  100/  123]    Loss 0.700979    Top1 78.125000    Top5 97.343750    
2024-04-23 23:13:15,832 - Epoch: [479][  123/  123]    Loss 0.702548    Top1 77.834395    Top5 97.299363    
2024-04-23 23:13:15,916 - ==> Top1: 77.834    Top5: 97.299    Loss: 0.703

2024-04-23 23:13:15,925 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:13:15,925 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:13:15,962 - 

2024-04-23 23:13:15,962 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:13:24,579 - Epoch: [480][  100/  296]    Overall Loss 0.706245    Objective Loss 0.706245                                        LR 0.000005    Time 0.086021    
2024-04-23 23:13:32,669 - Epoch: [480][  200/  296]    Overall Loss 0.717531    Objective Loss 0.717531                                        LR 0.000005    Time 0.083380    
2024-04-23 23:13:41,985 - Epoch: [480][  296/  296]    Overall Loss 0.708556    Objective Loss 0.708556    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.087758    
2024-04-23 23:13:42,161 - --- validate (epoch=480)-----------
2024-04-23 23:13:42,162 - 3925 samples (32 per mini-batch)
2024-04-23 23:13:56,811 - Epoch: [480][  100/  123]    Loss 0.691946    Top1 77.718750    Top5 97.437500    
2024-04-23 23:14:00,137 - Epoch: [480][  123/  123]    Loss 0.701595    Top1 77.605096    Top5 97.324841    
2024-04-23 23:14:00,302 - ==> Top1: 77.605    Top5: 97.325    Loss: 0.702

2024-04-23 23:14:00,314 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:14:00,314 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:14:00,354 - 

2024-04-23 23:14:00,355 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:14:13,386 - Epoch: [481][  100/  296]    Overall Loss 0.676446    Objective Loss 0.676446                                        LR 0.000005    Time 0.130144    
2024-04-23 23:14:24,539 - Epoch: [481][  200/  296]    Overall Loss 0.685860    Objective Loss 0.685860                                        LR 0.000005    Time 0.120756    
2024-04-23 23:14:34,593 - Epoch: [481][  296/  296]    Overall Loss 0.700646    Objective Loss 0.700646    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.115507    
2024-04-23 23:14:34,717 - --- validate (epoch=481)-----------
2024-04-23 23:14:34,718 - 3925 samples (32 per mini-batch)
2024-04-23 23:14:50,794 - Epoch: [481][  100/  123]    Loss 0.690997    Top1 77.875000    Top5 97.468750    
2024-04-23 23:14:53,942 - Epoch: [481][  123/  123]    Loss 0.704525    Top1 77.554140    Top5 97.375796    
2024-04-23 23:14:54,254 - ==> Top1: 77.554    Top5: 97.376    Loss: 0.705

2024-04-23 23:14:54,266 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:14:54,267 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:14:54,319 - 

2024-04-23 23:14:54,320 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:15:08,850 - Epoch: [482][  100/  296]    Overall Loss 0.728988    Objective Loss 0.728988                                        LR 0.000005    Time 0.145131    
2024-04-23 23:15:19,883 - Epoch: [482][  200/  296]    Overall Loss 0.721601    Objective Loss 0.721601                                        LR 0.000005    Time 0.127653    
2024-04-23 23:15:31,799 - Epoch: [482][  296/  296]    Overall Loss 0.730023    Objective Loss 0.730023    Top1 72.131148    Top5 93.442623    LR 0.000005    Time 0.126459    
2024-04-23 23:15:32,038 - --- validate (epoch=482)-----------
2024-04-23 23:15:32,039 - 3925 samples (32 per mini-batch)
2024-04-23 23:15:46,199 - Epoch: [482][  100/  123]    Loss 0.707964    Top1 77.812500    Top5 97.156250    
2024-04-23 23:15:49,122 - Epoch: [482][  123/  123]    Loss 0.702230    Top1 77.987261    Top5 97.248408    
2024-04-23 23:15:49,462 - ==> Top1: 77.987    Top5: 97.248    Loss: 0.702

2024-04-23 23:15:49,473 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:15:49,474 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:15:49,539 - 

2024-04-23 23:15:49,541 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:16:03,124 - Epoch: [483][  100/  296]    Overall Loss 0.689530    Objective Loss 0.689530                                        LR 0.000005    Time 0.135622    
2024-04-23 23:16:14,394 - Epoch: [483][  200/  296]    Overall Loss 0.689787    Objective Loss 0.689787                                        LR 0.000005    Time 0.124083    
2024-04-23 23:16:25,419 - Epoch: [483][  296/  296]    Overall Loss 0.702086    Objective Loss 0.702086    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.121031    
2024-04-23 23:16:25,541 - --- validate (epoch=483)-----------
2024-04-23 23:16:25,541 - 3925 samples (32 per mini-batch)
2024-04-23 23:16:39,865 - Epoch: [483][  100/  123]    Loss 0.714567    Top1 77.187500    Top5 97.125000    
2024-04-23 23:16:42,705 - Epoch: [483][  123/  123]    Loss 0.702144    Top1 77.630573    Top5 97.273885    
2024-04-23 23:16:42,968 - ==> Top1: 77.631    Top5: 97.274    Loss: 0.702

2024-04-23 23:16:42,976 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:16:42,976 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:16:43,022 - 

2024-04-23 23:16:43,022 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:16:54,491 - Epoch: [484][  100/  296]    Overall Loss 0.692687    Objective Loss 0.692687                                        LR 0.000005    Time 0.114514    
2024-04-23 23:17:04,217 - Epoch: [484][  200/  296]    Overall Loss 0.691912    Objective Loss 0.691912                                        LR 0.000005    Time 0.105807    
2024-04-23 23:17:14,727 - Epoch: [484][  296/  296]    Overall Loss 0.704523    Objective Loss 0.704523    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.106947    
2024-04-23 23:17:14,984 - --- validate (epoch=484)-----------
2024-04-23 23:17:14,985 - 3925 samples (32 per mini-batch)
2024-04-23 23:17:30,092 - Epoch: [484][  100/  123]    Loss 0.696679    Top1 78.187500    Top5 97.437500    
2024-04-23 23:17:32,840 - Epoch: [484][  123/  123]    Loss 0.702194    Top1 77.961783    Top5 97.248408    
2024-04-23 23:17:33,087 - ==> Top1: 77.962    Top5: 97.248    Loss: 0.702

2024-04-23 23:17:33,100 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:17:33,101 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:17:33,151 - 

2024-04-23 23:17:33,152 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:17:45,753 - Epoch: [485][  100/  296]    Overall Loss 0.726736    Objective Loss 0.726736                                        LR 0.000005    Time 0.125837    
2024-04-23 23:17:53,146 - Epoch: [485][  200/  296]    Overall Loss 0.725521    Objective Loss 0.725521                                        LR 0.000005    Time 0.099818    
2024-04-23 23:18:00,467 - Epoch: [485][  296/  296]    Overall Loss 0.720569    Objective Loss 0.720569    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.092133    
2024-04-23 23:18:00,701 - --- validate (epoch=485)-----------
2024-04-23 23:18:00,702 - 3925 samples (32 per mini-batch)
2024-04-23 23:18:10,721 - Epoch: [485][  100/  123]    Loss 0.696889    Top1 77.968750    Top5 97.156250    
2024-04-23 23:18:12,869 - Epoch: [485][  123/  123]    Loss 0.705893    Top1 77.528662    Top5 97.171975    
2024-04-23 23:18:13,162 - ==> Top1: 77.529    Top5: 97.172    Loss: 0.706

2024-04-23 23:18:13,173 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:18:13,173 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:18:13,217 - 

2024-04-23 23:18:13,217 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:18:24,910 - Epoch: [486][  100/  296]    Overall Loss 0.711673    Objective Loss 0.711673                                        LR 0.000005    Time 0.116744    
2024-04-23 23:18:34,035 - Epoch: [486][  200/  296]    Overall Loss 0.702798    Objective Loss 0.702798                                        LR 0.000005    Time 0.103909    
2024-04-23 23:18:41,917 - Epoch: [486][  296/  296]    Overall Loss 0.708356    Objective Loss 0.708356    Top1 73.770492    Top5 93.442623    LR 0.000005    Time 0.096782    
2024-04-23 23:18:42,137 - --- validate (epoch=486)-----------
2024-04-23 23:18:42,137 - 3925 samples (32 per mini-batch)
2024-04-23 23:18:58,184 - Epoch: [486][  100/  123]    Loss 0.713754    Top1 77.343750    Top5 97.343750    
2024-04-23 23:19:00,969 - Epoch: [486][  123/  123]    Loss 0.699896    Top1 77.783439    Top5 97.350318    
2024-04-23 23:19:01,179 - ==> Top1: 77.783    Top5: 97.350    Loss: 0.700

2024-04-23 23:19:01,191 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:19:01,191 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:19:01,242 - 

2024-04-23 23:19:01,243 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:19:13,882 - Epoch: [487][  100/  296]    Overall Loss 0.722359    Objective Loss 0.722359                                        LR 0.000005    Time 0.126213    
2024-04-23 23:19:25,694 - Epoch: [487][  200/  296]    Overall Loss 0.707954    Objective Loss 0.707954                                        LR 0.000005    Time 0.122080    
2024-04-23 23:19:39,230 - Epoch: [487][  296/  296]    Overall Loss 0.705827    Objective Loss 0.705827    Top1 81.967213    Top5 93.442623    LR 0.000005    Time 0.128166    
2024-04-23 23:19:39,527 - --- validate (epoch=487)-----------
2024-04-23 23:19:39,529 - 3925 samples (32 per mini-batch)
2024-04-23 23:19:50,371 - Epoch: [487][  100/  123]    Loss 0.696662    Top1 77.843750    Top5 97.187500    
2024-04-23 23:19:52,868 - Epoch: [487][  123/  123]    Loss 0.706310    Top1 77.605096    Top5 97.197452    
2024-04-23 23:19:53,073 - ==> Top1: 77.605    Top5: 97.197    Loss: 0.706

2024-04-23 23:19:53,085 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:19:53,086 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:19:53,137 - 

2024-04-23 23:19:53,138 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:20:07,421 - Epoch: [488][  100/  296]    Overall Loss 0.690115    Objective Loss 0.690115                                        LR 0.000005    Time 0.142658    
2024-04-23 23:20:19,897 - Epoch: [488][  200/  296]    Overall Loss 0.694406    Objective Loss 0.694406                                        LR 0.000005    Time 0.133630    
2024-04-23 23:20:30,896 - Epoch: [488][  296/  296]    Overall Loss 0.700136    Objective Loss 0.700136    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.127400    
2024-04-23 23:20:31,286 - --- validate (epoch=488)-----------
2024-04-23 23:20:31,287 - 3925 samples (32 per mini-batch)
2024-04-23 23:20:48,557 - Epoch: [488][  100/  123]    Loss 0.700471    Top1 77.406250    Top5 97.500000    
2024-04-23 23:20:52,523 - Epoch: [488][  123/  123]    Loss 0.700737    Top1 77.579618    Top5 97.324841    
2024-04-23 23:20:52,720 - ==> Top1: 77.580    Top5: 97.325    Loss: 0.701

2024-04-23 23:20:52,732 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:20:52,732 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:20:52,782 - 

2024-04-23 23:20:52,782 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:21:01,880 - Epoch: [489][  100/  296]    Overall Loss 0.696003    Objective Loss 0.696003                                        LR 0.000005    Time 0.090823    
2024-04-23 23:21:08,917 - Epoch: [489][  200/  296]    Overall Loss 0.694193    Objective Loss 0.694193                                        LR 0.000005    Time 0.080514    
2024-04-23 23:21:16,063 - Epoch: [489][  296/  296]    Overall Loss 0.688850    Objective Loss 0.688850    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.078497    
2024-04-23 23:21:16,174 - --- validate (epoch=489)-----------
2024-04-23 23:21:16,175 - 3925 samples (32 per mini-batch)
2024-04-23 23:21:26,130 - Epoch: [489][  100/  123]    Loss 0.717424    Top1 77.281250    Top5 97.156250    
2024-04-23 23:21:27,743 - Epoch: [489][  123/  123]    Loss 0.699777    Top1 77.783439    Top5 97.299363    
2024-04-23 23:21:27,862 - ==> Top1: 77.783    Top5: 97.299    Loss: 0.700

2024-04-23 23:21:27,870 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:21:27,871 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:21:27,911 - 

2024-04-23 23:21:27,912 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:21:40,893 - Epoch: [490][  100/  296]    Overall Loss 0.721275    Objective Loss 0.721275                                        LR 0.000005    Time 0.129632    
2024-04-23 23:21:48,659 - Epoch: [490][  200/  296]    Overall Loss 0.707435    Objective Loss 0.707435                                        LR 0.000005    Time 0.103574    
2024-04-23 23:21:55,371 - Epoch: [490][  296/  296]    Overall Loss 0.703361    Objective Loss 0.703361    Top1 65.573770    Top5 91.803279    LR 0.000005    Time 0.092617    
2024-04-23 23:21:55,478 - --- validate (epoch=490)-----------
2024-04-23 23:21:55,479 - 3925 samples (32 per mini-batch)
2024-04-23 23:22:09,120 - Epoch: [490][  100/  123]    Loss 0.703386    Top1 77.687500    Top5 97.218750    
2024-04-23 23:22:11,804 - Epoch: [490][  123/  123]    Loss 0.703326    Top1 77.656051    Top5 97.299363    
2024-04-23 23:22:11,948 - ==> Top1: 77.656    Top5: 97.299    Loss: 0.703

2024-04-23 23:22:11,958 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:22:11,959 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:22:12,031 - 

2024-04-23 23:22:12,032 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:22:23,560 - Epoch: [491][  100/  296]    Overall Loss 0.690047    Objective Loss 0.690047                                        LR 0.000005    Time 0.115110    
2024-04-23 23:22:34,895 - Epoch: [491][  200/  296]    Overall Loss 0.707978    Objective Loss 0.707978                                        LR 0.000005    Time 0.114145    
2024-04-23 23:22:45,494 - Epoch: [491][  296/  296]    Overall Loss 0.705945    Objective Loss 0.705945    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.112872    
2024-04-23 23:22:45,800 - --- validate (epoch=491)-----------
2024-04-23 23:22:45,801 - 3925 samples (32 per mini-batch)
2024-04-23 23:22:53,866 - Epoch: [491][  100/  123]    Loss 0.694120    Top1 78.437500    Top5 97.281250    
2024-04-23 23:22:55,606 - Epoch: [491][  123/  123]    Loss 0.702739    Top1 77.834395    Top5 97.350318    
2024-04-23 23:22:55,716 - ==> Top1: 77.834    Top5: 97.350    Loss: 0.703

2024-04-23 23:22:55,725 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:22:55,726 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:22:55,764 - 

2024-04-23 23:22:55,765 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:23:04,581 - Epoch: [492][  100/  296]    Overall Loss 0.683457    Objective Loss 0.683457                                        LR 0.000005    Time 0.088005    
2024-04-23 23:23:14,475 - Epoch: [492][  200/  296]    Overall Loss 0.696147    Objective Loss 0.696147                                        LR 0.000005    Time 0.093394    
2024-04-23 23:23:22,070 - Epoch: [492][  296/  296]    Overall Loss 0.705108    Objective Loss 0.705108    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.088721    
2024-04-23 23:23:22,248 - --- validate (epoch=492)-----------
2024-04-23 23:23:22,249 - 3925 samples (32 per mini-batch)
2024-04-23 23:23:36,304 - Epoch: [492][  100/  123]    Loss 0.715488    Top1 77.437500    Top5 97.000000    
2024-04-23 23:23:39,046 - Epoch: [492][  123/  123]    Loss 0.704846    Top1 77.783439    Top5 97.095541    
2024-04-23 23:23:39,305 - ==> Top1: 77.783    Top5: 97.096    Loss: 0.705

2024-04-23 23:23:39,317 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:23:39,317 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:23:39,366 - 

2024-04-23 23:23:39,367 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:23:54,469 - Epoch: [493][  100/  296]    Overall Loss 0.702261    Objective Loss 0.702261                                        LR 0.000005    Time 0.150854    
2024-04-23 23:24:08,041 - Epoch: [493][  200/  296]    Overall Loss 0.692337    Objective Loss 0.692337                                        LR 0.000005    Time 0.143194    
2024-04-23 23:24:20,673 - Epoch: [493][  296/  296]    Overall Loss 0.702495    Objective Loss 0.702495    Top1 70.491803    Top5 93.442623    LR 0.000005    Time 0.139372    
2024-04-23 23:24:20,929 - --- validate (epoch=493)-----------
2024-04-23 23:24:20,930 - 3925 samples (32 per mini-batch)
2024-04-23 23:24:34,102 - Epoch: [493][  100/  123]    Loss 0.721387    Top1 77.031250    Top5 96.937500    
2024-04-23 23:24:35,739 - Epoch: [493][  123/  123]    Loss 0.705825    Top1 77.503185    Top5 97.044586    
2024-04-23 23:24:35,819 - ==> Top1: 77.503    Top5: 97.045    Loss: 0.706

2024-04-23 23:24:35,828 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:24:35,829 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:24:35,864 - 

2024-04-23 23:24:35,865 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:24:45,326 - Epoch: [494][  100/  296]    Overall Loss 0.711357    Objective Loss 0.711357                                        LR 0.000005    Time 0.094461    
2024-04-23 23:24:56,183 - Epoch: [494][  200/  296]    Overall Loss 0.701957    Objective Loss 0.701957                                        LR 0.000005    Time 0.101427    
2024-04-23 23:25:03,052 - Epoch: [494][  296/  296]    Overall Loss 0.705583    Objective Loss 0.705583    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.091692    
2024-04-23 23:25:03,164 - --- validate (epoch=494)-----------
2024-04-23 23:25:03,165 - 3925 samples (32 per mini-batch)
2024-04-23 23:25:12,483 - Epoch: [494][  100/  123]    Loss 0.721490    Top1 76.781250    Top5 97.343750    
2024-04-23 23:25:14,443 - Epoch: [494][  123/  123]    Loss 0.699492    Top1 77.579618    Top5 97.350318    
2024-04-23 23:25:14,551 - ==> Top1: 77.580    Top5: 97.350    Loss: 0.699

2024-04-23 23:25:14,561 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:25:14,561 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:25:14,598 - 

2024-04-23 23:25:14,599 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:25:25,535 - Epoch: [495][  100/  296]    Overall Loss 0.726676    Objective Loss 0.726676                                        LR 0.000005    Time 0.109190    
2024-04-23 23:25:34,956 - Epoch: [495][  200/  296]    Overall Loss 0.695070    Objective Loss 0.695070                                        LR 0.000005    Time 0.101617    
2024-04-23 23:25:44,717 - Epoch: [495][  296/  296]    Overall Loss 0.692625    Objective Loss 0.692625    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.101580    
2024-04-23 23:25:44,812 - --- validate (epoch=495)-----------
2024-04-23 23:25:44,813 - 3925 samples (32 per mini-batch)
2024-04-23 23:25:57,133 - Epoch: [495][  100/  123]    Loss 0.700308    Top1 77.781250    Top5 97.218750    
2024-04-23 23:25:59,827 - Epoch: [495][  123/  123]    Loss 0.697616    Top1 77.757962    Top5 97.248408    
2024-04-23 23:26:00,074 - ==> Top1: 77.758    Top5: 97.248    Loss: 0.698

2024-04-23 23:26:00,086 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:26:00,087 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:26:00,138 - 

2024-04-23 23:26:00,139 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:26:12,261 - Epoch: [496][  100/  296]    Overall Loss 0.700861    Objective Loss 0.700861                                        LR 0.000005    Time 0.121043    
2024-04-23 23:26:25,184 - Epoch: [496][  200/  296]    Overall Loss 0.710614    Objective Loss 0.710614                                        LR 0.000005    Time 0.125045    
2024-04-23 23:26:38,196 - Epoch: [496][  296/  296]    Overall Loss 0.706387    Objective Loss 0.706387    Top1 62.295082    Top5 91.803279    LR 0.000005    Time 0.128394    
2024-04-23 23:26:38,469 - --- validate (epoch=496)-----------
2024-04-23 23:26:38,470 - 3925 samples (32 per mini-batch)
2024-04-23 23:26:54,039 - Epoch: [496][  100/  123]    Loss 0.703237    Top1 77.625000    Top5 97.281250    
2024-04-23 23:26:56,389 - Epoch: [496][  123/  123]    Loss 0.704500    Top1 77.605096    Top5 97.299363    
2024-04-23 23:26:56,520 - ==> Top1: 77.605    Top5: 97.299    Loss: 0.704

2024-04-23 23:26:56,529 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:26:56,529 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:26:56,571 - 

2024-04-23 23:26:56,571 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:27:09,168 - Epoch: [497][  100/  296]    Overall Loss 0.689781    Objective Loss 0.689781                                        LR 0.000005    Time 0.125824    
2024-04-23 23:27:19,527 - Epoch: [497][  200/  296]    Overall Loss 0.708011    Objective Loss 0.708011                                        LR 0.000005    Time 0.114639    
2024-04-23 23:27:30,996 - Epoch: [497][  296/  296]    Overall Loss 0.713881    Objective Loss 0.713881    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.116154    
2024-04-23 23:27:31,255 - --- validate (epoch=497)-----------
2024-04-23 23:27:31,256 - 3925 samples (32 per mini-batch)
2024-04-23 23:27:46,287 - Epoch: [497][  100/  123]    Loss 0.710543    Top1 77.125000    Top5 97.343750    
2024-04-23 23:27:49,663 - Epoch: [497][  123/  123]    Loss 0.699970    Top1 77.707006    Top5 97.401274    
2024-04-23 23:27:49,918 - ==> Top1: 77.707    Top5: 97.401    Loss: 0.700

2024-04-23 23:27:49,926 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:27:49,927 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:27:49,981 - 

2024-04-23 23:27:49,982 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:28:01,619 - Epoch: [498][  100/  296]    Overall Loss 0.665156    Objective Loss 0.665156                                        LR 0.000005    Time 0.116181    
2024-04-23 23:28:12,432 - Epoch: [498][  200/  296]    Overall Loss 0.686359    Objective Loss 0.686359                                        LR 0.000005    Time 0.112071    
2024-04-23 23:28:23,725 - Epoch: [498][  296/  296]    Overall Loss 0.696816    Objective Loss 0.696816    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.113815    
2024-04-23 23:28:23,978 - --- validate (epoch=498)-----------
2024-04-23 23:28:23,979 - 3925 samples (32 per mini-batch)
2024-04-23 23:28:37,129 - Epoch: [498][  100/  123]    Loss 0.708439    Top1 77.593750    Top5 97.218750    
2024-04-23 23:28:39,934 - Epoch: [498][  123/  123]    Loss 0.702725    Top1 77.656051    Top5 97.401274    
2024-04-23 23:28:40,229 - ==> Top1: 77.656    Top5: 97.401    Loss: 0.703

2024-04-23 23:28:40,242 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:28:40,243 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:28:40,289 - 

2024-04-23 23:28:40,290 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:28:53,293 - Epoch: [499][  100/  296]    Overall Loss 0.705874    Objective Loss 0.705874                                        LR 0.000005    Time 0.129856    
2024-04-23 23:29:02,500 - Epoch: [499][  200/  296]    Overall Loss 0.712614    Objective Loss 0.712614                                        LR 0.000005    Time 0.110885    
2024-04-23 23:29:13,783 - Epoch: [499][  296/  296]    Overall Loss 0.701206    Objective Loss 0.701206    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.112984    
2024-04-23 23:29:14,058 - --- validate (epoch=499)-----------
2024-04-23 23:29:14,060 - 3925 samples (32 per mini-batch)
2024-04-23 23:29:29,402 - Epoch: [499][  100/  123]    Loss 0.707749    Top1 77.375000    Top5 97.187500    
2024-04-23 23:29:32,065 - Epoch: [499][  123/  123]    Loss 0.700694    Top1 77.630573    Top5 97.273885    
2024-04-23 23:29:32,289 - ==> Top1: 77.631    Top5: 97.274    Loss: 0.701

2024-04-23 23:29:32,301 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:29:32,302 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:29:32,345 - 

2024-04-23 23:29:32,346 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:29:44,889 - Epoch: [500][  100/  296]    Overall Loss 0.703314    Objective Loss 0.703314                                        LR 0.000005    Time 0.125248    
2024-04-23 23:29:56,492 - Epoch: [500][  200/  296]    Overall Loss 0.705447    Objective Loss 0.705447                                        LR 0.000005    Time 0.120552    
2024-04-23 23:30:08,817 - Epoch: [500][  296/  296]    Overall Loss 0.698498    Objective Loss 0.698498    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.123039    
2024-04-23 23:30:09,096 - --- validate (epoch=500)-----------
2024-04-23 23:30:09,097 - 3925 samples (32 per mini-batch)
2024-04-23 23:30:22,492 - Epoch: [500][  100/  123]    Loss 0.725356    Top1 77.062500    Top5 97.343750    
2024-04-23 23:30:25,426 - Epoch: [500][  123/  123]    Loss 0.707326    Top1 77.579618    Top5 97.350318    
2024-04-23 23:30:25,653 - ==> Top1: 77.580    Top5: 97.350    Loss: 0.707

2024-04-23 23:30:25,661 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:30:25,662 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:30:25,707 - 

2024-04-23 23:30:25,708 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:30:38,541 - Epoch: [501][  100/  296]    Overall Loss 0.695105    Objective Loss 0.695105                                        LR 0.000005    Time 0.128164    
2024-04-23 23:30:49,560 - Epoch: [501][  200/  296]    Overall Loss 0.702088    Objective Loss 0.702088                                        LR 0.000005    Time 0.119095    
2024-04-23 23:31:01,564 - Epoch: [501][  296/  296]    Overall Loss 0.709615    Objective Loss 0.709615    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.120970    
2024-04-23 23:31:01,799 - --- validate (epoch=501)-----------
2024-04-23 23:31:01,799 - 3925 samples (32 per mini-batch)
2024-04-23 23:31:16,718 - Epoch: [501][  100/  123]    Loss 0.689129    Top1 78.187500    Top5 97.593750    
2024-04-23 23:31:19,535 - Epoch: [501][  123/  123]    Loss 0.703049    Top1 77.656051    Top5 97.273885    
2024-04-23 23:31:19,740 - ==> Top1: 77.656    Top5: 97.274    Loss: 0.703

2024-04-23 23:31:19,750 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:31:19,750 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:31:19,797 - 

2024-04-23 23:31:19,798 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:31:33,909 - Epoch: [502][  100/  296]    Overall Loss 0.731409    Objective Loss 0.731409                                        LR 0.000005    Time 0.140930    
2024-04-23 23:31:46,964 - Epoch: [502][  200/  296]    Overall Loss 0.730277    Objective Loss 0.730277                                        LR 0.000005    Time 0.135658    
2024-04-23 23:32:00,473 - Epoch: [502][  296/  296]    Overall Loss 0.730846    Objective Loss 0.730846    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.137240    
2024-04-23 23:32:00,741 - --- validate (epoch=502)-----------
2024-04-23 23:32:00,742 - 3925 samples (32 per mini-batch)
2024-04-23 23:32:17,658 - Epoch: [502][  100/  123]    Loss 0.703508    Top1 77.875000    Top5 97.437500    
2024-04-23 23:32:20,322 - Epoch: [502][  123/  123]    Loss 0.705880    Top1 77.681529    Top5 97.299363    
2024-04-23 23:32:20,526 - ==> Top1: 77.682    Top5: 97.299    Loss: 0.706

2024-04-23 23:32:20,533 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:32:20,533 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:32:20,591 - 

2024-04-23 23:32:20,592 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:32:30,715 - Epoch: [503][  100/  296]    Overall Loss 0.720729    Objective Loss 0.720729                                        LR 0.000005    Time 0.101099    
2024-04-23 23:32:39,061 - Epoch: [503][  200/  296]    Overall Loss 0.716935    Objective Loss 0.716935                                        LR 0.000005    Time 0.092209    
2024-04-23 23:32:46,724 - Epoch: [503][  296/  296]    Overall Loss 0.704197    Objective Loss 0.704197    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.088149    
2024-04-23 23:32:46,937 - --- validate (epoch=503)-----------
2024-04-23 23:32:46,938 - 3925 samples (32 per mini-batch)
2024-04-23 23:32:59,832 - Epoch: [503][  100/  123]    Loss 0.694087    Top1 77.468750    Top5 97.718750    
2024-04-23 23:33:02,231 - Epoch: [503][  123/  123]    Loss 0.703286    Top1 77.477707    Top5 97.350318    
2024-04-23 23:33:02,468 - ==> Top1: 77.478    Top5: 97.350    Loss: 0.703

2024-04-23 23:33:02,477 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:33:02,478 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:33:02,522 - 

2024-04-23 23:33:02,523 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:33:14,332 - Epoch: [504][  100/  296]    Overall Loss 0.698276    Objective Loss 0.698276                                        LR 0.000005    Time 0.117956    
2024-04-23 23:33:24,837 - Epoch: [504][  200/  296]    Overall Loss 0.710976    Objective Loss 0.710976                                        LR 0.000005    Time 0.111424    
2024-04-23 23:33:35,185 - Epoch: [504][  296/  296]    Overall Loss 0.704931    Objective Loss 0.704931    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.110200    
2024-04-23 23:33:35,398 - --- validate (epoch=504)-----------
2024-04-23 23:33:35,399 - 3925 samples (32 per mini-batch)
2024-04-23 23:33:48,192 - Epoch: [504][  100/  123]    Loss 0.720908    Top1 77.406250    Top5 97.093750    
2024-04-23 23:33:50,748 - Epoch: [504][  123/  123]    Loss 0.707182    Top1 77.834395    Top5 97.222930    
2024-04-23 23:33:50,916 - ==> Top1: 77.834    Top5: 97.223    Loss: 0.707

2024-04-23 23:33:50,924 - ==> Best [Top1: 78.089   Top5: 97.401   Sparsity:0.00   Params: 370272 on epoch: 171]
2024-04-23 23:33:50,925 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:33:50,967 - 

2024-04-23 23:33:50,967 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:34:00,041 - Epoch: [505][  100/  296]    Overall Loss 0.716416    Objective Loss 0.716416                                        LR 0.000005    Time 0.090611    
2024-04-23 23:34:08,283 - Epoch: [505][  200/  296]    Overall Loss 0.720340    Objective Loss 0.720340                                        LR 0.000005    Time 0.086451    
2024-04-23 23:34:17,326 - Epoch: [505][  296/  296]    Overall Loss 0.712327    Objective Loss 0.712327    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.088920    
2024-04-23 23:34:17,491 - --- validate (epoch=505)-----------
2024-04-23 23:34:17,492 - 3925 samples (32 per mini-batch)
2024-04-23 23:34:28,980 - Epoch: [505][  100/  123]    Loss 0.702586    Top1 77.812500    Top5 97.343750    
2024-04-23 23:34:31,456 - Epoch: [505][  123/  123]    Loss 0.701592    Top1 78.114650    Top5 97.299363    
2024-04-23 23:34:31,624 - ==> Top1: 78.115    Top5: 97.299    Loss: 0.702

2024-04-23 23:34:31,634 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:34:31,634 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:34:31,681 - 

2024-04-23 23:34:31,681 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:34:41,922 - Epoch: [506][  100/  296]    Overall Loss 0.736073    Objective Loss 0.736073                                        LR 0.000005    Time 0.102274    
2024-04-23 23:34:50,078 - Epoch: [506][  200/  296]    Overall Loss 0.715134    Objective Loss 0.715134                                        LR 0.000005    Time 0.091853    
2024-04-23 23:34:57,352 - Epoch: [506][  296/  296]    Overall Loss 0.703967    Objective Loss 0.703967    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.086598    
2024-04-23 23:34:57,474 - --- validate (epoch=506)-----------
2024-04-23 23:34:57,475 - 3925 samples (32 per mini-batch)
2024-04-23 23:35:11,255 - Epoch: [506][  100/  123]    Loss 0.695574    Top1 78.093750    Top5 97.343750    
2024-04-23 23:35:13,454 - Epoch: [506][  123/  123]    Loss 0.702453    Top1 77.961783    Top5 97.324841    
2024-04-23 23:35:13,678 - ==> Top1: 77.962    Top5: 97.325    Loss: 0.702

2024-04-23 23:35:13,685 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:35:13,686 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:35:13,742 - 

2024-04-23 23:35:13,743 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:35:23,379 - Epoch: [507][  100/  296]    Overall Loss 0.689874    Objective Loss 0.689874                                        LR 0.000005    Time 0.096216    
2024-04-23 23:35:33,779 - Epoch: [507][  200/  296]    Overall Loss 0.686823    Objective Loss 0.686823                                        LR 0.000005    Time 0.100041    
2024-04-23 23:35:43,238 - Epoch: [507][  296/  296]    Overall Loss 0.686788    Objective Loss 0.686788    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.099511    
2024-04-23 23:35:43,391 - --- validate (epoch=507)-----------
2024-04-23 23:35:43,392 - 3925 samples (32 per mini-batch)
2024-04-23 23:35:55,192 - Epoch: [507][  100/  123]    Loss 0.687984    Top1 78.500000    Top5 97.437500    
2024-04-23 23:35:57,572 - Epoch: [507][  123/  123]    Loss 0.701004    Top1 77.936306    Top5 97.350318    
2024-04-23 23:35:57,762 - ==> Top1: 77.936    Top5: 97.350    Loss: 0.701

2024-04-23 23:35:57,772 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:35:57,772 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:35:57,812 - 

2024-04-23 23:35:57,812 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:36:09,150 - Epoch: [508][  100/  296]    Overall Loss 0.704726    Objective Loss 0.704726                                        LR 0.000005    Time 0.113239    
2024-04-23 23:36:19,284 - Epoch: [508][  200/  296]    Overall Loss 0.683526    Objective Loss 0.683526                                        LR 0.000005    Time 0.107227    
2024-04-23 23:36:29,656 - Epoch: [508][  296/  296]    Overall Loss 0.700030    Objective Loss 0.700030    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.107449    
2024-04-23 23:36:29,939 - --- validate (epoch=508)-----------
2024-04-23 23:36:29,940 - 3925 samples (32 per mini-batch)
2024-04-23 23:36:41,290 - Epoch: [508][  100/  123]    Loss 0.703373    Top1 77.687500    Top5 97.250000    
2024-04-23 23:36:43,863 - Epoch: [508][  123/  123]    Loss 0.702304    Top1 77.732484    Top5 97.222930    
2024-04-23 23:36:44,114 - ==> Top1: 77.732    Top5: 97.223    Loss: 0.702

2024-04-23 23:36:44,124 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:36:44,124 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:36:44,159 - 

2024-04-23 23:36:44,159 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:36:52,731 - Epoch: [509][  100/  296]    Overall Loss 0.673938    Objective Loss 0.673938                                        LR 0.000005    Time 0.085582    
2024-04-23 23:37:02,740 - Epoch: [509][  200/  296]    Overall Loss 0.688170    Objective Loss 0.688170                                        LR 0.000005    Time 0.092769    
2024-04-23 23:37:11,627 - Epoch: [509][  296/  296]    Overall Loss 0.694967    Objective Loss 0.694967    Top1 72.131148    Top5 91.803279    LR 0.000005    Time 0.092665    
2024-04-23 23:37:11,736 - --- validate (epoch=509)-----------
2024-04-23 23:37:11,736 - 3925 samples (32 per mini-batch)
2024-04-23 23:37:21,933 - Epoch: [509][  100/  123]    Loss 0.700381    Top1 77.843750    Top5 97.406250    
2024-04-23 23:37:24,144 - Epoch: [509][  123/  123]    Loss 0.704491    Top1 77.656051    Top5 97.222930    
2024-04-23 23:37:24,288 - ==> Top1: 77.656    Top5: 97.223    Loss: 0.704

2024-04-23 23:37:24,298 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:37:24,298 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:37:24,343 - 

2024-04-23 23:37:24,344 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:37:34,733 - Epoch: [510][  100/  296]    Overall Loss 0.717013    Objective Loss 0.717013                                        LR 0.000005    Time 0.103758    
2024-04-23 23:37:45,430 - Epoch: [510][  200/  296]    Overall Loss 0.706431    Objective Loss 0.706431                                        LR 0.000005    Time 0.105297    
2024-04-23 23:37:54,641 - Epoch: [510][  296/  296]    Overall Loss 0.706147    Objective Loss 0.706147    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.102224    
2024-04-23 23:37:54,875 - --- validate (epoch=510)-----------
2024-04-23 23:37:54,875 - 3925 samples (32 per mini-batch)
2024-04-23 23:38:08,032 - Epoch: [510][  100/  123]    Loss 0.687365    Top1 78.125000    Top5 97.250000    
2024-04-23 23:38:10,295 - Epoch: [510][  123/  123]    Loss 0.702933    Top1 77.630573    Top5 97.248408    
2024-04-23 23:38:10,529 - ==> Top1: 77.631    Top5: 97.248    Loss: 0.703

2024-04-23 23:38:10,540 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:38:10,540 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:38:10,579 - 

2024-04-23 23:38:10,579 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:38:20,298 - Epoch: [511][  100/  296]    Overall Loss 0.700623    Objective Loss 0.700623                                        LR 0.000005    Time 0.097038    
2024-04-23 23:38:28,074 - Epoch: [511][  200/  296]    Overall Loss 0.703513    Objective Loss 0.703513                                        LR 0.000005    Time 0.087329    
2024-04-23 23:38:36,835 - Epoch: [511][  296/  296]    Overall Loss 0.703991    Objective Loss 0.703991    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.088564    
2024-04-23 23:38:37,016 - --- validate (epoch=511)-----------
2024-04-23 23:38:37,017 - 3925 samples (32 per mini-batch)
2024-04-23 23:38:50,036 - Epoch: [511][  100/  123]    Loss 0.702706    Top1 77.718750    Top5 97.031250    
2024-04-23 23:38:52,353 - Epoch: [511][  123/  123]    Loss 0.706680    Top1 77.401274    Top5 97.171975    
2024-04-23 23:38:52,579 - ==> Top1: 77.401    Top5: 97.172    Loss: 0.707

2024-04-23 23:38:52,589 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:38:52,589 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:38:52,631 - 

2024-04-23 23:38:52,632 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:39:03,989 - Epoch: [512][  100/  296]    Overall Loss 0.702823    Objective Loss 0.702823                                        LR 0.000005    Time 0.113418    
2024-04-23 23:39:13,865 - Epoch: [512][  200/  296]    Overall Loss 0.725640    Objective Loss 0.725640                                        LR 0.000005    Time 0.106014    
2024-04-23 23:39:22,525 - Epoch: [512][  296/  296]    Overall Loss 0.726797    Objective Loss 0.726797    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.100846    
2024-04-23 23:39:22,793 - --- validate (epoch=512)-----------
2024-04-23 23:39:22,794 - 3925 samples (32 per mini-batch)
2024-04-23 23:39:34,857 - Epoch: [512][  100/  123]    Loss 0.706898    Top1 77.812500    Top5 97.406250    
2024-04-23 23:39:37,387 - Epoch: [512][  123/  123]    Loss 0.700404    Top1 77.936306    Top5 97.299363    
2024-04-23 23:39:37,619 - ==> Top1: 77.936    Top5: 97.299    Loss: 0.700

2024-04-23 23:39:37,628 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:39:37,628 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:39:37,673 - 

2024-04-23 23:39:37,674 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:39:48,500 - Epoch: [513][  100/  296]    Overall Loss 0.715532    Objective Loss 0.715532                                        LR 0.000005    Time 0.108133    
2024-04-23 23:39:57,964 - Epoch: [513][  200/  296]    Overall Loss 0.714889    Objective Loss 0.714889                                        LR 0.000005    Time 0.101320    
2024-04-23 23:40:05,976 - Epoch: [513][  296/  296]    Overall Loss 0.701121    Objective Loss 0.701121    Top1 70.491803    Top5 95.081967    LR 0.000005    Time 0.095483    
2024-04-23 23:40:06,129 - --- validate (epoch=513)-----------
2024-04-23 23:40:06,130 - 3925 samples (32 per mini-batch)
2024-04-23 23:40:19,012 - Epoch: [513][  100/  123]    Loss 0.688467    Top1 78.437500    Top5 97.406250    
2024-04-23 23:40:21,327 - Epoch: [513][  123/  123]    Loss 0.699192    Top1 77.961783    Top5 97.299363    
2024-04-23 23:40:21,478 - ==> Top1: 77.962    Top5: 97.299    Loss: 0.699

2024-04-23 23:40:21,488 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:40:21,488 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:40:21,534 - 

2024-04-23 23:40:21,535 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:40:35,738 - Epoch: [514][  100/  296]    Overall Loss 0.711658    Objective Loss 0.711658                                        LR 0.000005    Time 0.141879    
2024-04-23 23:40:45,314 - Epoch: [514][  200/  296]    Overall Loss 0.698941    Objective Loss 0.698941                                        LR 0.000005    Time 0.118751    
2024-04-23 23:40:55,621 - Epoch: [514][  296/  296]    Overall Loss 0.707494    Objective Loss 0.707494    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.115020    
2024-04-23 23:40:55,854 - --- validate (epoch=514)-----------
2024-04-23 23:40:55,855 - 3925 samples (32 per mini-batch)
2024-04-23 23:41:09,114 - Epoch: [514][  100/  123]    Loss 0.708663    Top1 77.625000    Top5 97.250000    
2024-04-23 23:41:11,724 - Epoch: [514][  123/  123]    Loss 0.703660    Top1 77.707006    Top5 97.350318    
2024-04-23 23:41:11,926 - ==> Top1: 77.707    Top5: 97.350    Loss: 0.704

2024-04-23 23:41:11,936 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:41:11,936 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:41:11,981 - 

2024-04-23 23:41:11,982 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:41:20,835 - Epoch: [515][  100/  296]    Overall Loss 0.729694    Objective Loss 0.729694                                        LR 0.000005    Time 0.088388    
2024-04-23 23:41:29,769 - Epoch: [515][  200/  296]    Overall Loss 0.699086    Objective Loss 0.699086                                        LR 0.000005    Time 0.088793    
2024-04-23 23:41:39,308 - Epoch: [515][  296/  296]    Overall Loss 0.700693    Objective Loss 0.700693    Top1 62.295082    Top5 96.721311    LR 0.000005    Time 0.092183    
2024-04-23 23:41:39,443 - --- validate (epoch=515)-----------
2024-04-23 23:41:39,444 - 3925 samples (32 per mini-batch)
2024-04-23 23:41:52,116 - Epoch: [515][  100/  123]    Loss 0.716630    Top1 77.375000    Top5 97.312500    
2024-04-23 23:41:54,332 - Epoch: [515][  123/  123]    Loss 0.706156    Top1 77.605096    Top5 97.273885    
2024-04-23 23:41:54,528 - ==> Top1: 77.605    Top5: 97.274    Loss: 0.706

2024-04-23 23:41:54,538 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:41:54,538 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:41:54,580 - 

2024-04-23 23:41:54,581 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:42:04,277 - Epoch: [516][  100/  296]    Overall Loss 0.717305    Objective Loss 0.717305                                        LR 0.000005    Time 0.096820    
2024-04-23 23:42:13,069 - Epoch: [516][  200/  296]    Overall Loss 0.697980    Objective Loss 0.697980                                        LR 0.000005    Time 0.092296    
2024-04-23 23:42:20,349 - Epoch: [516][  296/  296]    Overall Loss 0.699236    Objective Loss 0.699236    Top1 65.573770    Top5 95.081967    LR 0.000005    Time 0.086919    
2024-04-23 23:42:20,520 - --- validate (epoch=516)-----------
2024-04-23 23:42:20,521 - 3925 samples (32 per mini-batch)
2024-04-23 23:42:31,555 - Epoch: [516][  100/  123]    Loss 0.693967    Top1 78.125000    Top5 97.281250    
2024-04-23 23:42:33,628 - Epoch: [516][  123/  123]    Loss 0.704466    Top1 77.987261    Top5 97.248408    
2024-04-23 23:42:33,808 - ==> Top1: 77.987    Top5: 97.248    Loss: 0.704

2024-04-23 23:42:33,818 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:42:33,818 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:42:33,860 - 

2024-04-23 23:42:33,861 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:42:45,922 - Epoch: [517][  100/  296]    Overall Loss 0.668990    Objective Loss 0.668990                                        LR 0.000005    Time 0.120473    
2024-04-23 23:42:54,765 - Epoch: [517][  200/  296]    Overall Loss 0.677622    Objective Loss 0.677622                                        LR 0.000005    Time 0.104382    
2024-04-23 23:43:03,929 - Epoch: [517][  296/  296]    Overall Loss 0.686136    Objective Loss 0.686136    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.101443    
2024-04-23 23:43:04,121 - --- validate (epoch=517)-----------
2024-04-23 23:43:04,122 - 3925 samples (32 per mini-batch)
2024-04-23 23:43:17,424 - Epoch: [517][  100/  123]    Loss 0.697356    Top1 78.125000    Top5 97.125000    
2024-04-23 23:43:19,915 - Epoch: [517][  123/  123]    Loss 0.707100    Top1 77.605096    Top5 97.146497    
2024-04-23 23:43:20,086 - ==> Top1: 77.605    Top5: 97.146    Loss: 0.707

2024-04-23 23:43:20,096 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:43:20,096 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:43:20,138 - 

2024-04-23 23:43:20,138 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:43:31,765 - Epoch: [518][  100/  296]    Overall Loss 0.684528    Objective Loss 0.684528                                        LR 0.000005    Time 0.116133    
2024-04-23 23:43:43,147 - Epoch: [518][  200/  296]    Overall Loss 0.699293    Objective Loss 0.699293                                        LR 0.000005    Time 0.114910    
2024-04-23 23:43:54,041 - Epoch: [518][  296/  296]    Overall Loss 0.700105    Objective Loss 0.700105    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.114402    
2024-04-23 23:43:54,230 - --- validate (epoch=518)-----------
2024-04-23 23:43:54,231 - 3925 samples (32 per mini-batch)
2024-04-23 23:44:06,535 - Epoch: [518][  100/  123]    Loss 0.707686    Top1 77.156250    Top5 97.343750    
2024-04-23 23:44:09,246 - Epoch: [518][  123/  123]    Loss 0.702551    Top1 77.681529    Top5 97.324841    
2024-04-23 23:44:09,403 - ==> Top1: 77.682    Top5: 97.325    Loss: 0.703

2024-04-23 23:44:09,415 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:44:09,415 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:44:09,461 - 

2024-04-23 23:44:09,462 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:44:21,282 - Epoch: [519][  100/  296]    Overall Loss 0.717916    Objective Loss 0.717916                                        LR 0.000005    Time 0.118055    
2024-04-23 23:44:29,893 - Epoch: [519][  200/  296]    Overall Loss 0.722839    Objective Loss 0.722839                                        LR 0.000005    Time 0.102017    
2024-04-23 23:44:35,922 - Epoch: [519][  296/  296]    Overall Loss 0.725569    Objective Loss 0.725569    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.089261    
2024-04-23 23:44:36,155 - --- validate (epoch=519)-----------
2024-04-23 23:44:36,156 - 3925 samples (32 per mini-batch)
2024-04-23 23:44:44,758 - Epoch: [519][  100/  123]    Loss 0.707594    Top1 78.000000    Top5 97.218750    
2024-04-23 23:44:46,350 - Epoch: [519][  123/  123]    Loss 0.704504    Top1 78.012739    Top5 97.197452    
2024-04-23 23:44:46,544 - ==> Top1: 78.013    Top5: 97.197    Loss: 0.705

2024-04-23 23:44:46,555 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:44:46,556 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:44:46,591 - 

2024-04-23 23:44:46,591 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:44:53,788 - Epoch: [520][  100/  296]    Overall Loss 0.671186    Objective Loss 0.671186                                        LR 0.000005    Time 0.071840    
2024-04-23 23:44:59,172 - Epoch: [520][  200/  296]    Overall Loss 0.689071    Objective Loss 0.689071                                        LR 0.000005    Time 0.062790    
2024-04-23 23:45:04,779 - Epoch: [520][  296/  296]    Overall Loss 0.704044    Objective Loss 0.704044    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.061332    
2024-04-23 23:45:04,984 - --- validate (epoch=520)-----------
2024-04-23 23:45:04,985 - 3925 samples (32 per mini-batch)
2024-04-23 23:45:12,961 - Epoch: [520][  100/  123]    Loss 0.711550    Top1 77.250000    Top5 97.343750    
2024-04-23 23:45:14,458 - Epoch: [520][  123/  123]    Loss 0.709336    Top1 77.605096    Top5 97.197452    
2024-04-23 23:45:14,670 - ==> Top1: 77.605    Top5: 97.197    Loss: 0.709

2024-04-23 23:45:14,680 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:45:14,681 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:45:14,717 - 

2024-04-23 23:45:14,717 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:45:23,545 - Epoch: [521][  100/  296]    Overall Loss 0.706217    Objective Loss 0.706217                                        LR 0.000005    Time 0.088145    
2024-04-23 23:45:33,277 - Epoch: [521][  200/  296]    Overall Loss 0.706688    Objective Loss 0.706688                                        LR 0.000005    Time 0.092667    
2024-04-23 23:45:42,239 - Epoch: [521][  296/  296]    Overall Loss 0.700525    Objective Loss 0.700525    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.092850    
2024-04-23 23:45:42,494 - --- validate (epoch=521)-----------
2024-04-23 23:45:42,495 - 3925 samples (32 per mini-batch)
2024-04-23 23:45:53,479 - Epoch: [521][  100/  123]    Loss 0.717227    Top1 77.062500    Top5 97.593750    
2024-04-23 23:45:55,870 - Epoch: [521][  123/  123]    Loss 0.703436    Top1 77.681529    Top5 97.324841    
2024-04-23 23:45:55,995 - ==> Top1: 77.682    Top5: 97.325    Loss: 0.703

2024-04-23 23:45:56,006 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:45:56,007 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:45:56,046 - 

2024-04-23 23:45:56,047 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:46:07,884 - Epoch: [522][  100/  296]    Overall Loss 0.702739    Objective Loss 0.702739                                        LR 0.000005    Time 0.118246    
2024-04-23 23:46:17,790 - Epoch: [522][  200/  296]    Overall Loss 0.702271    Objective Loss 0.702271                                        LR 0.000005    Time 0.108584    
2024-04-23 23:46:27,354 - Epoch: [522][  296/  296]    Overall Loss 0.704253    Objective Loss 0.704253    Top1 67.213115    Top5 98.360656    LR 0.000005    Time 0.105632    
2024-04-23 23:46:27,589 - --- validate (epoch=522)-----------
2024-04-23 23:46:27,590 - 3925 samples (32 per mini-batch)
2024-04-23 23:46:39,378 - Epoch: [522][  100/  123]    Loss 0.703378    Top1 77.312500    Top5 97.593750    
2024-04-23 23:46:41,724 - Epoch: [522][  123/  123]    Loss 0.702548    Top1 77.681529    Top5 97.299363    
2024-04-23 23:46:41,921 - ==> Top1: 77.682    Top5: 97.299    Loss: 0.703

2024-04-23 23:46:41,931 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:46:41,931 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:46:41,988 - 

2024-04-23 23:46:41,988 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:46:52,786 - Epoch: [523][  100/  296]    Overall Loss 0.704766    Objective Loss 0.704766                                        LR 0.000005    Time 0.107844    
2024-04-23 23:47:02,493 - Epoch: [523][  200/  296]    Overall Loss 0.698379    Objective Loss 0.698379                                        LR 0.000005    Time 0.102394    
2024-04-23 23:47:11,114 - Epoch: [523][  296/  296]    Overall Loss 0.702044    Objective Loss 0.702044    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.098266    
2024-04-23 23:47:11,313 - --- validate (epoch=523)-----------
2024-04-23 23:47:11,313 - 3925 samples (32 per mini-batch)
2024-04-23 23:47:22,510 - Epoch: [523][  100/  123]    Loss 0.708836    Top1 78.000000    Top5 97.156250    
2024-04-23 23:47:25,190 - Epoch: [523][  123/  123]    Loss 0.704818    Top1 77.987261    Top5 97.248408    
2024-04-23 23:47:25,460 - ==> Top1: 77.987    Top5: 97.248    Loss: 0.705

2024-04-23 23:47:25,470 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:47:25,470 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:47:25,517 - 

2024-04-23 23:47:25,518 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:47:38,026 - Epoch: [524][  100/  296]    Overall Loss 0.713872    Objective Loss 0.713872                                        LR 0.000005    Time 0.124934    
2024-04-23 23:47:47,963 - Epoch: [524][  200/  296]    Overall Loss 0.714286    Objective Loss 0.714286                                        LR 0.000005    Time 0.112091    
2024-04-23 23:47:56,572 - Epoch: [524][  296/  296]    Overall Loss 0.719819    Objective Loss 0.719819    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.104779    
2024-04-23 23:47:56,824 - --- validate (epoch=524)-----------
2024-04-23 23:47:56,825 - 3925 samples (32 per mini-batch)
2024-04-23 23:48:09,785 - Epoch: [524][  100/  123]    Loss 0.695927    Top1 77.750000    Top5 97.218750    
2024-04-23 23:48:12,084 - Epoch: [524][  123/  123]    Loss 0.705820    Top1 77.707006    Top5 97.273885    
2024-04-23 23:48:12,231 - ==> Top1: 77.707    Top5: 97.274    Loss: 0.706

2024-04-23 23:48:12,238 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:48:12,239 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:48:12,298 - 

2024-04-23 23:48:12,298 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:48:23,578 - Epoch: [525][  100/  296]    Overall Loss 0.704308    Objective Loss 0.704308                                        LR 0.000005    Time 0.112649    
2024-04-23 23:48:32,305 - Epoch: [525][  200/  296]    Overall Loss 0.710685    Objective Loss 0.710685                                        LR 0.000005    Time 0.099892    
2024-04-23 23:48:40,629 - Epoch: [525][  296/  296]    Overall Loss 0.720880    Objective Loss 0.720880    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.095577    
2024-04-23 23:48:40,825 - --- validate (epoch=525)-----------
2024-04-23 23:48:40,826 - 3925 samples (32 per mini-batch)
2024-04-23 23:48:53,448 - Epoch: [525][  100/  123]    Loss 0.715780    Top1 77.125000    Top5 97.218750    
2024-04-23 23:48:55,490 - Epoch: [525][  123/  123]    Loss 0.707595    Top1 77.477707    Top5 97.171975    
2024-04-23 23:48:55,683 - ==> Top1: 77.478    Top5: 97.172    Loss: 0.708

2024-04-23 23:48:55,695 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:48:55,695 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:48:55,733 - 

2024-04-23 23:48:55,734 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:49:07,222 - Epoch: [526][  100/  296]    Overall Loss 0.703564    Objective Loss 0.703564                                        LR 0.000005    Time 0.114732    
2024-04-23 23:49:17,496 - Epoch: [526][  200/  296]    Overall Loss 0.705365    Objective Loss 0.705365                                        LR 0.000005    Time 0.108648    
2024-04-23 23:49:26,901 - Epoch: [526][  296/  296]    Overall Loss 0.702703    Objective Loss 0.702703    Top1 70.491803    Top5 93.442623    LR 0.000005    Time 0.105139    
2024-04-23 23:49:27,143 - --- validate (epoch=526)-----------
2024-04-23 23:49:27,144 - 3925 samples (32 per mini-batch)
2024-04-23 23:49:38,324 - Epoch: [526][  100/  123]    Loss 0.713526    Top1 77.812500    Top5 97.406250    
2024-04-23 23:49:40,848 - Epoch: [526][  123/  123]    Loss 0.701491    Top1 78.063694    Top5 97.426752    
2024-04-23 23:49:41,082 - ==> Top1: 78.064    Top5: 97.427    Loss: 0.701

2024-04-23 23:49:41,087 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:49:41,087 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:49:41,121 - 

2024-04-23 23:49:41,122 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:49:50,531 - Epoch: [527][  100/  296]    Overall Loss 0.733926    Objective Loss 0.733926                                        LR 0.000005    Time 0.093957    
2024-04-23 23:49:58,544 - Epoch: [527][  200/  296]    Overall Loss 0.727229    Objective Loss 0.727229                                        LR 0.000005    Time 0.086984    
2024-04-23 23:50:05,889 - Epoch: [527][  296/  296]    Overall Loss 0.719350    Objective Loss 0.719350    Top1 88.524590    Top5 98.360656    LR 0.000005    Time 0.083541    
2024-04-23 23:50:06,197 - --- validate (epoch=527)-----------
2024-04-23 23:50:06,198 - 3925 samples (32 per mini-batch)
2024-04-23 23:50:16,118 - Epoch: [527][  100/  123]    Loss 0.707860    Top1 77.531250    Top5 97.250000    
2024-04-23 23:50:18,358 - Epoch: [527][  123/  123]    Loss 0.702684    Top1 77.605096    Top5 97.375796    
2024-04-23 23:50:18,461 - ==> Top1: 77.605    Top5: 97.376    Loss: 0.703

2024-04-23 23:50:18,473 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:50:18,473 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:50:18,513 - 

2024-04-23 23:50:18,514 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:50:30,566 - Epoch: [528][  100/  296]    Overall Loss 0.682268    Objective Loss 0.682268                                        LR 0.000005    Time 0.120385    
2024-04-23 23:50:40,520 - Epoch: [528][  200/  296]    Overall Loss 0.697686    Objective Loss 0.697686                                        LR 0.000005    Time 0.109906    
2024-04-23 23:50:49,707 - Epoch: [528][  296/  296]    Overall Loss 0.692971    Objective Loss 0.692971    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.105255    
2024-04-23 23:50:50,006 - --- validate (epoch=528)-----------
2024-04-23 23:50:50,006 - 3925 samples (32 per mini-batch)
2024-04-23 23:51:03,150 - Epoch: [528][  100/  123]    Loss 0.691491    Top1 78.250000    Top5 97.250000    
2024-04-23 23:51:05,591 - Epoch: [528][  123/  123]    Loss 0.707232    Top1 77.783439    Top5 97.248408    
2024-04-23 23:51:06,057 - ==> Top1: 77.783    Top5: 97.248    Loss: 0.707

2024-04-23 23:51:06,068 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:51:06,069 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:51:06,111 - 

2024-04-23 23:51:06,111 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:51:16,827 - Epoch: [529][  100/  296]    Overall Loss 0.717894    Objective Loss 0.717894                                        LR 0.000005    Time 0.107016    
2024-04-23 23:51:26,468 - Epoch: [529][  200/  296]    Overall Loss 0.721446    Objective Loss 0.721446                                        LR 0.000005    Time 0.101634    
2024-04-23 23:51:35,758 - Epoch: [529][  296/  296]    Overall Loss 0.717829    Objective Loss 0.717829    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.100015    
2024-04-23 23:51:36,038 - --- validate (epoch=529)-----------
2024-04-23 23:51:36,039 - 3925 samples (32 per mini-batch)
2024-04-23 23:51:48,637 - Epoch: [529][  100/  123]    Loss 0.713227    Top1 77.531250    Top5 97.218750    
2024-04-23 23:51:51,091 - Epoch: [529][  123/  123]    Loss 0.701121    Top1 77.910828    Top5 97.324841    
2024-04-23 23:51:51,306 - ==> Top1: 77.911    Top5: 97.325    Loss: 0.701

2024-04-23 23:51:51,316 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:51:51,317 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:51:51,368 - 

2024-04-23 23:51:51,369 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:52:03,382 - Epoch: [530][  100/  296]    Overall Loss 0.714401    Objective Loss 0.714401                                        LR 0.000005    Time 0.119972    
2024-04-23 23:52:13,749 - Epoch: [530][  200/  296]    Overall Loss 0.708921    Objective Loss 0.708921                                        LR 0.000005    Time 0.111744    
2024-04-23 23:52:23,339 - Epoch: [530][  296/  296]    Overall Loss 0.705357    Objective Loss 0.705357    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.107856    
2024-04-23 23:52:23,564 - --- validate (epoch=530)-----------
2024-04-23 23:52:23,565 - 3925 samples (32 per mini-batch)
2024-04-23 23:52:33,694 - Epoch: [530][  100/  123]    Loss 0.710550    Top1 77.656250    Top5 97.156250    
2024-04-23 23:52:36,046 - Epoch: [530][  123/  123]    Loss 0.700298    Top1 77.910828    Top5 97.324841    
2024-04-23 23:52:36,227 - ==> Top1: 77.911    Top5: 97.325    Loss: 0.700

2024-04-23 23:52:36,239 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:52:36,240 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:52:36,282 - 

2024-04-23 23:52:36,282 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:52:46,216 - Epoch: [531][  100/  296]    Overall Loss 0.675754    Objective Loss 0.675754                                        LR 0.000005    Time 0.099180    
2024-04-23 23:52:53,530 - Epoch: [531][  200/  296]    Overall Loss 0.684210    Objective Loss 0.684210                                        LR 0.000005    Time 0.086102    
2024-04-23 23:53:03,110 - Epoch: [531][  296/  296]    Overall Loss 0.681826    Objective Loss 0.681826    Top1 75.409836    Top5 93.442623    LR 0.000005    Time 0.090500    
2024-04-23 23:53:03,254 - --- validate (epoch=531)-----------
2024-04-23 23:53:03,254 - 3925 samples (32 per mini-batch)
2024-04-23 23:53:15,991 - Epoch: [531][  100/  123]    Loss 0.696816    Top1 77.968750    Top5 97.375000    
2024-04-23 23:53:18,327 - Epoch: [531][  123/  123]    Loss 0.705134    Top1 77.630573    Top5 97.248408    
2024-04-23 23:53:18,551 - ==> Top1: 77.631    Top5: 97.248    Loss: 0.705

2024-04-23 23:53:18,562 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:53:18,563 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:53:18,607 - 

2024-04-23 23:53:18,608 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:53:29,903 - Epoch: [532][  100/  296]    Overall Loss 0.677474    Objective Loss 0.677474                                        LR 0.000005    Time 0.112795    
2024-04-23 23:53:38,859 - Epoch: [532][  200/  296]    Overall Loss 0.688619    Objective Loss 0.688619                                        LR 0.000005    Time 0.101112    
2024-04-23 23:53:47,680 - Epoch: [532][  296/  296]    Overall Loss 0.693439    Objective Loss 0.693439    Top1 70.491803    Top5 95.081967    LR 0.000005    Time 0.098081    
2024-04-23 23:53:47,866 - --- validate (epoch=532)-----------
2024-04-23 23:53:47,866 - 3925 samples (32 per mini-batch)
2024-04-23 23:54:01,358 - Epoch: [532][  100/  123]    Loss 0.724182    Top1 77.000000    Top5 97.125000    
2024-04-23 23:54:03,995 - Epoch: [532][  123/  123]    Loss 0.704708    Top1 77.910828    Top5 97.222930    
2024-04-23 23:54:04,241 - ==> Top1: 77.911    Top5: 97.223    Loss: 0.705

2024-04-23 23:54:04,251 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:54:04,251 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:54:04,291 - 

2024-04-23 23:54:04,292 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:54:15,171 - Epoch: [533][  100/  296]    Overall Loss 0.675373    Objective Loss 0.675373                                        LR 0.000005    Time 0.108642    
2024-04-23 23:54:24,332 - Epoch: [533][  200/  296]    Overall Loss 0.667655    Objective Loss 0.667655                                        LR 0.000005    Time 0.100051    
2024-04-23 23:54:34,044 - Epoch: [533][  296/  296]    Overall Loss 0.676244    Objective Loss 0.676244    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.100366    
2024-04-23 23:54:34,219 - --- validate (epoch=533)-----------
2024-04-23 23:54:34,220 - 3925 samples (32 per mini-batch)
2024-04-23 23:54:46,346 - Epoch: [533][  100/  123]    Loss 0.704538    Top1 77.437500    Top5 97.187500    
2024-04-23 23:54:48,762 - Epoch: [533][  123/  123]    Loss 0.703607    Top1 77.757962    Top5 97.248408    
2024-04-23 23:54:48,897 - ==> Top1: 77.758    Top5: 97.248    Loss: 0.704

2024-04-23 23:54:48,907 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:54:48,908 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:54:48,943 - 

2024-04-23 23:54:48,943 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:54:59,028 - Epoch: [534][  100/  296]    Overall Loss 0.717339    Objective Loss 0.717339                                        LR 0.000005    Time 0.100708    
2024-04-23 23:55:08,952 - Epoch: [534][  200/  296]    Overall Loss 0.716250    Objective Loss 0.716250                                        LR 0.000005    Time 0.099895    
2024-04-23 23:55:15,230 - Epoch: [534][  296/  296]    Overall Loss 0.701146    Objective Loss 0.701146    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.088668    
2024-04-23 23:55:15,340 - --- validate (epoch=534)-----------
2024-04-23 23:55:15,341 - 3925 samples (32 per mini-batch)
2024-04-23 23:55:25,444 - Epoch: [534][  100/  123]    Loss 0.708776    Top1 77.218750    Top5 97.375000    
2024-04-23 23:55:27,270 - Epoch: [534][  123/  123]    Loss 0.703065    Top1 77.528662    Top5 97.401274    
2024-04-23 23:55:27,372 - ==> Top1: 77.529    Top5: 97.401    Loss: 0.703

2024-04-23 23:55:27,381 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:55:27,382 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:55:27,416 - 

2024-04-23 23:55:27,417 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:55:35,878 - Epoch: [535][  100/  296]    Overall Loss 0.714274    Objective Loss 0.714274                                        LR 0.000005    Time 0.084480    
2024-04-23 23:55:45,815 - Epoch: [535][  200/  296]    Overall Loss 0.707695    Objective Loss 0.707695                                        LR 0.000005    Time 0.091856    
2024-04-23 23:55:54,582 - Epoch: [535][  296/  296]    Overall Loss 0.708762    Objective Loss 0.708762    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.091648    
2024-04-23 23:55:54,699 - --- validate (epoch=535)-----------
2024-04-23 23:55:54,700 - 3925 samples (32 per mini-batch)
2024-04-23 23:56:02,653 - Epoch: [535][  100/  123]    Loss 0.694944    Top1 78.125000    Top5 97.343750    
2024-04-23 23:56:04,512 - Epoch: [535][  123/  123]    Loss 0.701924    Top1 77.834395    Top5 97.350318    
2024-04-23 23:56:04,609 - ==> Top1: 77.834    Top5: 97.350    Loss: 0.702

2024-04-23 23:56:04,618 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:56:04,618 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:56:04,654 - 

2024-04-23 23:56:04,654 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:56:12,416 - Epoch: [536][  100/  296]    Overall Loss 0.710718    Objective Loss 0.710718                                        LR 0.000005    Time 0.077522    
2024-04-23 23:56:18,268 - Epoch: [536][  200/  296]    Overall Loss 0.691767    Objective Loss 0.691767                                        LR 0.000005    Time 0.067966    
2024-04-23 23:56:24,555 - Epoch: [536][  296/  296]    Overall Loss 0.701720    Objective Loss 0.701720    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.067125    
2024-04-23 23:56:24,637 - --- validate (epoch=536)-----------
2024-04-23 23:56:24,637 - 3925 samples (32 per mini-batch)
2024-04-23 23:56:34,199 - Epoch: [536][  100/  123]    Loss 0.716942    Top1 77.750000    Top5 97.156250    
2024-04-23 23:56:35,724 - Epoch: [536][  123/  123]    Loss 0.708134    Top1 77.783439    Top5 97.324841    
2024-04-23 23:56:35,822 - ==> Top1: 77.783    Top5: 97.325    Loss: 0.708

2024-04-23 23:56:35,832 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:56:35,832 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:56:35,870 - 

2024-04-23 23:56:35,870 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:56:43,185 - Epoch: [537][  100/  296]    Overall Loss 0.710469    Objective Loss 0.710469                                        LR 0.000005    Time 0.073031    
2024-04-23 23:56:48,241 - Epoch: [537][  200/  296]    Overall Loss 0.701362    Objective Loss 0.701362                                        LR 0.000005    Time 0.061744    
2024-04-23 23:56:54,087 - Epoch: [537][  296/  296]    Overall Loss 0.706002    Objective Loss 0.706002    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.061434    
2024-04-23 23:56:54,163 - --- validate (epoch=537)-----------
2024-04-23 23:56:54,163 - 3925 samples (32 per mini-batch)
2024-04-23 23:57:04,288 - Epoch: [537][  100/  123]    Loss 0.717674    Top1 77.343750    Top5 97.125000    
2024-04-23 23:57:06,842 - Epoch: [537][  123/  123]    Loss 0.702907    Top1 77.681529    Top5 97.324841    
2024-04-23 23:57:06,941 - ==> Top1: 77.682    Top5: 97.325    Loss: 0.703

2024-04-23 23:57:06,951 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:57:06,951 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:57:06,986 - 

2024-04-23 23:57:06,986 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:57:14,327 - Epoch: [538][  100/  296]    Overall Loss 0.685179    Objective Loss 0.685179                                        LR 0.000005    Time 0.073299    
2024-04-23 23:57:21,760 - Epoch: [538][  200/  296]    Overall Loss 0.674345    Objective Loss 0.674345                                        LR 0.000005    Time 0.073747    
2024-04-23 23:57:29,491 - Epoch: [538][  296/  296]    Overall Loss 0.681643    Objective Loss 0.681643    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.075902    
2024-04-23 23:57:29,593 - --- validate (epoch=538)-----------
2024-04-23 23:57:29,593 - 3925 samples (32 per mini-batch)
2024-04-23 23:57:39,038 - Epoch: [538][  100/  123]    Loss 0.707580    Top1 77.812500    Top5 97.375000    
2024-04-23 23:57:40,920 - Epoch: [538][  123/  123]    Loss 0.705031    Top1 77.885350    Top5 97.375796    
2024-04-23 23:57:41,002 - ==> Top1: 77.885    Top5: 97.376    Loss: 0.705

2024-04-23 23:57:41,012 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:57:41,012 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:57:41,047 - 

2024-04-23 23:57:41,047 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:57:47,835 - Epoch: [539][  100/  296]    Overall Loss 0.699890    Objective Loss 0.699890                                        LR 0.000005    Time 0.067771    
2024-04-23 23:57:53,433 - Epoch: [539][  200/  296]    Overall Loss 0.693886    Objective Loss 0.693886                                        LR 0.000005    Time 0.061821    
2024-04-23 23:58:00,229 - Epoch: [539][  296/  296]    Overall Loss 0.693997    Objective Loss 0.693997    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.064698    
2024-04-23 23:58:00,324 - --- validate (epoch=539)-----------
2024-04-23 23:58:00,325 - 3925 samples (32 per mini-batch)
2024-04-23 23:58:08,754 - Epoch: [539][  100/  123]    Loss 0.699844    Top1 77.937500    Top5 97.312500    
2024-04-23 23:58:10,913 - Epoch: [539][  123/  123]    Loss 0.702993    Top1 77.936306    Top5 97.350318    
2024-04-23 23:58:11,030 - ==> Top1: 77.936    Top5: 97.350    Loss: 0.703

2024-04-23 23:58:11,043 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:58:11,043 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:58:11,079 - 

2024-04-23 23:58:11,080 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:58:21,624 - Epoch: [540][  100/  296]    Overall Loss 0.711096    Objective Loss 0.711096                                        LR 0.000005    Time 0.105279    
2024-04-23 23:58:30,348 - Epoch: [540][  200/  296]    Overall Loss 0.704631    Objective Loss 0.704631                                        LR 0.000005    Time 0.096181    
2024-04-23 23:58:38,678 - Epoch: [540][  296/  296]    Overall Loss 0.709545    Objective Loss 0.709545    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.093083    
2024-04-23 23:58:38,813 - --- validate (epoch=540)-----------
2024-04-23 23:58:38,813 - 3925 samples (32 per mini-batch)
2024-04-23 23:58:51,182 - Epoch: [540][  100/  123]    Loss 0.698403    Top1 77.968750    Top5 97.593750    
2024-04-23 23:58:53,278 - Epoch: [540][  123/  123]    Loss 0.705056    Top1 77.732484    Top5 97.299363    
2024-04-23 23:58:53,460 - ==> Top1: 77.732    Top5: 97.299    Loss: 0.705

2024-04-23 23:58:53,468 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:58:53,468 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:58:53,509 - 

2024-04-23 23:58:53,509 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:59:05,511 - Epoch: [541][  100/  296]    Overall Loss 0.709891    Objective Loss 0.709891                                        LR 0.000005    Time 0.119894    
2024-04-23 23:59:13,480 - Epoch: [541][  200/  296]    Overall Loss 0.701026    Objective Loss 0.701026                                        LR 0.000005    Time 0.099728    
2024-04-23 23:59:21,794 - Epoch: [541][  296/  296]    Overall Loss 0.703130    Objective Loss 0.703130    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.095433    
2024-04-23 23:59:21,964 - --- validate (epoch=541)-----------
2024-04-23 23:59:21,965 - 3925 samples (32 per mini-batch)
2024-04-23 23:59:33,410 - Epoch: [541][  100/  123]    Loss 0.705400    Top1 77.562500    Top5 97.250000    
2024-04-23 23:59:35,446 - Epoch: [541][  123/  123]    Loss 0.700033    Top1 77.936306    Top5 97.401274    
2024-04-23 23:59:35,625 - ==> Top1: 77.936    Top5: 97.401    Loss: 0.700

2024-04-23 23:59:35,635 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-23 23:59:35,636 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-23 23:59:35,677 - 

2024-04-23 23:59:35,678 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:59:45,400 - Epoch: [542][  100/  296]    Overall Loss 0.733105    Objective Loss 0.733105                                        LR 0.000005    Time 0.097101    
2024-04-23 23:59:53,999 - Epoch: [542][  200/  296]    Overall Loss 0.723535    Objective Loss 0.723535                                        LR 0.000005    Time 0.091479    
2024-04-24 00:00:00,938 - Epoch: [542][  296/  296]    Overall Loss 0.712606    Objective Loss 0.712606    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.085213    
2024-04-24 00:00:01,133 - --- validate (epoch=542)-----------
2024-04-24 00:00:01,134 - 3925 samples (32 per mini-batch)
2024-04-24 00:00:12,839 - Epoch: [542][  100/  123]    Loss 0.705150    Top1 77.343750    Top5 97.250000    
2024-04-24 00:00:14,871 - Epoch: [542][  123/  123]    Loss 0.705523    Top1 77.426752    Top5 97.273885    
2024-04-24 00:00:15,157 - ==> Top1: 77.427    Top5: 97.274    Loss: 0.706

2024-04-24 00:00:15,168 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-24 00:00:15,168 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:00:15,204 - 

2024-04-24 00:00:15,204 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:00:23,704 - Epoch: [543][  100/  296]    Overall Loss 0.694474    Objective Loss 0.694474                                        LR 0.000005    Time 0.084865    
2024-04-24 00:00:29,070 - Epoch: [543][  200/  296]    Overall Loss 0.709251    Objective Loss 0.709251                                        LR 0.000005    Time 0.069198    
2024-04-24 00:00:34,819 - Epoch: [543][  296/  296]    Overall Loss 0.705995    Objective Loss 0.705995    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.066134    
2024-04-24 00:00:35,023 - --- validate (epoch=543)-----------
2024-04-24 00:00:35,024 - 3925 samples (32 per mini-batch)
2024-04-24 00:00:47,030 - Epoch: [543][  100/  123]    Loss 0.708721    Top1 77.625000    Top5 97.093750    
2024-04-24 00:00:48,822 - Epoch: [543][  123/  123]    Loss 0.705135    Top1 77.885350    Top5 97.222930    
2024-04-24 00:00:49,040 - ==> Top1: 77.885    Top5: 97.223    Loss: 0.705

2024-04-24 00:00:49,049 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-24 00:00:49,049 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:00:49,088 - 

2024-04-24 00:00:49,088 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:00:59,417 - Epoch: [544][  100/  296]    Overall Loss 0.726869    Objective Loss 0.726869                                        LR 0.000005    Time 0.103144    
2024-04-24 00:01:10,651 - Epoch: [544][  200/  296]    Overall Loss 0.710644    Objective Loss 0.710644                                        LR 0.000005    Time 0.107685    
2024-04-24 00:01:19,472 - Epoch: [544][  296/  296]    Overall Loss 0.710134    Objective Loss 0.710134    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.102517    
2024-04-24 00:01:19,854 - --- validate (epoch=544)-----------
2024-04-24 00:01:19,854 - 3925 samples (32 per mini-batch)
2024-04-24 00:01:33,968 - Epoch: [544][  100/  123]    Loss 0.708258    Top1 77.718750    Top5 97.437500    
2024-04-24 00:01:35,953 - Epoch: [544][  123/  123]    Loss 0.705686    Top1 77.936306    Top5 97.324841    
2024-04-24 00:01:36,171 - ==> Top1: 77.936    Top5: 97.325    Loss: 0.706

2024-04-24 00:01:36,179 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-24 00:01:36,179 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:01:36,239 - 

2024-04-24 00:01:36,239 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:01:48,138 - Epoch: [545][  100/  296]    Overall Loss 0.676189    Objective Loss 0.676189                                        LR 0.000005    Time 0.118851    
2024-04-24 00:01:58,453 - Epoch: [545][  200/  296]    Overall Loss 0.697100    Objective Loss 0.697100                                        LR 0.000005    Time 0.110942    
2024-04-24 00:02:07,287 - Epoch: [545][  296/  296]    Overall Loss 0.701180    Objective Loss 0.701180    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.104773    
2024-04-24 00:02:07,457 - --- validate (epoch=545)-----------
2024-04-24 00:02:07,458 - 3925 samples (32 per mini-batch)
2024-04-24 00:02:17,644 - Epoch: [545][  100/  123]    Loss 0.716230    Top1 77.062500    Top5 97.312500    
2024-04-24 00:02:19,593 - Epoch: [545][  123/  123]    Loss 0.703854    Top1 77.630573    Top5 97.299363    
2024-04-24 00:02:19,726 - ==> Top1: 77.631    Top5: 97.299    Loss: 0.704

2024-04-24 00:02:19,736 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-24 00:02:19,737 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:02:19,779 - 

2024-04-24 00:02:19,780 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:02:31,393 - Epoch: [546][  100/  296]    Overall Loss 0.698238    Objective Loss 0.698238                                        LR 0.000005    Time 0.115993    
2024-04-24 00:02:40,828 - Epoch: [546][  200/  296]    Overall Loss 0.698090    Objective Loss 0.698090                                        LR 0.000005    Time 0.105114    
2024-04-24 00:02:50,924 - Epoch: [546][  296/  296]    Overall Loss 0.693946    Objective Loss 0.693946    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.105101    
2024-04-24 00:02:51,055 - --- validate (epoch=546)-----------
2024-04-24 00:02:51,056 - 3925 samples (32 per mini-batch)
2024-04-24 00:03:03,899 - Epoch: [546][  100/  123]    Loss 0.701061    Top1 78.375000    Top5 97.062500    
2024-04-24 00:03:06,530 - Epoch: [546][  123/  123]    Loss 0.704146    Top1 78.063694    Top5 97.248408    
2024-04-24 00:03:06,658 - ==> Top1: 78.064    Top5: 97.248    Loss: 0.704

2024-04-24 00:03:06,669 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-24 00:03:06,670 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:03:06,711 - 

2024-04-24 00:03:06,712 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:03:14,274 - Epoch: [547][  100/  296]    Overall Loss 0.699365    Objective Loss 0.699365                                        LR 0.000005    Time 0.075512    
2024-04-24 00:03:21,605 - Epoch: [547][  200/  296]    Overall Loss 0.698919    Objective Loss 0.698919                                        LR 0.000005    Time 0.074345    
2024-04-24 00:03:27,770 - Epoch: [547][  296/  296]    Overall Loss 0.702929    Objective Loss 0.702929    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.071028    
2024-04-24 00:03:27,894 - --- validate (epoch=547)-----------
2024-04-24 00:03:27,894 - 3925 samples (32 per mini-batch)
2024-04-24 00:03:40,271 - Epoch: [547][  100/  123]    Loss 0.702135    Top1 77.656250    Top5 97.218750    
2024-04-24 00:03:42,774 - Epoch: [547][  123/  123]    Loss 0.705634    Top1 77.757962    Top5 97.197452    
2024-04-24 00:03:43,155 - ==> Top1: 77.758    Top5: 97.197    Loss: 0.706

2024-04-24 00:03:43,165 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-24 00:03:43,166 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:03:43,207 - 

2024-04-24 00:03:43,208 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:03:53,200 - Epoch: [548][  100/  296]    Overall Loss 0.689149    Objective Loss 0.689149                                        LR 0.000005    Time 0.099782    
2024-04-24 00:04:02,808 - Epoch: [548][  200/  296]    Overall Loss 0.695087    Objective Loss 0.695087                                        LR 0.000005    Time 0.097855    
2024-04-24 00:04:10,278 - Epoch: [548][  296/  296]    Overall Loss 0.701832    Objective Loss 0.701832    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.091319    
2024-04-24 00:04:10,364 - --- validate (epoch=548)-----------
2024-04-24 00:04:10,364 - 3925 samples (32 per mini-batch)
2024-04-24 00:04:22,329 - Epoch: [548][  100/  123]    Loss 0.692532    Top1 77.781250    Top5 97.625000    
2024-04-24 00:04:25,259 - Epoch: [548][  123/  123]    Loss 0.703030    Top1 77.885350    Top5 97.350318    
2024-04-24 00:04:25,388 - ==> Top1: 77.885    Top5: 97.350    Loss: 0.703

2024-04-24 00:04:25,392 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-24 00:04:25,392 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:04:25,421 - 

2024-04-24 00:04:25,421 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:04:37,518 - Epoch: [549][  100/  296]    Overall Loss 0.710224    Objective Loss 0.710224                                        LR 0.000005    Time 0.120816    
2024-04-24 00:04:48,577 - Epoch: [549][  200/  296]    Overall Loss 0.719736    Objective Loss 0.719736                                        LR 0.000005    Time 0.115630    
2024-04-24 00:04:59,364 - Epoch: [549][  296/  296]    Overall Loss 0.714590    Objective Loss 0.714590    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.114524    
2024-04-24 00:04:59,551 - --- validate (epoch=549)-----------
2024-04-24 00:04:59,552 - 3925 samples (32 per mini-batch)
2024-04-24 00:05:10,679 - Epoch: [549][  100/  123]    Loss 0.702669    Top1 77.437500    Top5 97.156250    
2024-04-24 00:05:13,041 - Epoch: [549][  123/  123]    Loss 0.702884    Top1 77.656051    Top5 97.248408    
2024-04-24 00:05:13,428 - ==> Top1: 77.656    Top5: 97.248    Loss: 0.703

2024-04-24 00:05:13,438 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-24 00:05:13,439 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:05:13,480 - 

2024-04-24 00:05:13,480 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:05:23,746 - Epoch: [550][  100/  296]    Overall Loss 0.717129    Objective Loss 0.717129                                        LR 0.000005    Time 0.102518    
2024-04-24 00:05:32,280 - Epoch: [550][  200/  296]    Overall Loss 0.712100    Objective Loss 0.712100                                        LR 0.000005    Time 0.093867    
2024-04-24 00:05:39,207 - Epoch: [550][  296/  296]    Overall Loss 0.703750    Objective Loss 0.703750    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.086787    
2024-04-24 00:05:39,317 - --- validate (epoch=550)-----------
2024-04-24 00:05:39,318 - 3925 samples (32 per mini-batch)
2024-04-24 00:05:49,661 - Epoch: [550][  100/  123]    Loss 0.693713    Top1 78.031250    Top5 97.312500    
2024-04-24 00:05:51,847 - Epoch: [550][  123/  123]    Loss 0.702220    Top1 77.808917    Top5 97.299363    
2024-04-24 00:05:51,964 - ==> Top1: 77.809    Top5: 97.299    Loss: 0.702

2024-04-24 00:05:51,974 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-24 00:05:51,975 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:05:52,011 - 

2024-04-24 00:05:52,012 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:06:00,766 - Epoch: [551][  100/  296]    Overall Loss 0.702238    Objective Loss 0.702238                                        LR 0.000005    Time 0.087412    
2024-04-24 00:06:08,131 - Epoch: [551][  200/  296]    Overall Loss 0.699359    Objective Loss 0.699359                                        LR 0.000005    Time 0.080462    
2024-04-24 00:06:14,908 - Epoch: [551][  296/  296]    Overall Loss 0.706405    Objective Loss 0.706405    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.077220    
2024-04-24 00:06:15,032 - --- validate (epoch=551)-----------
2024-04-24 00:06:15,033 - 3925 samples (32 per mini-batch)
2024-04-24 00:06:27,456 - Epoch: [551][  100/  123]    Loss 0.703850    Top1 78.062500    Top5 97.593750    
2024-04-24 00:06:29,988 - Epoch: [551][  123/  123]    Loss 0.706423    Top1 77.987261    Top5 97.324841    
2024-04-24 00:06:30,120 - ==> Top1: 77.987    Top5: 97.325    Loss: 0.706

2024-04-24 00:06:30,132 - ==> Best [Top1: 78.115   Top5: 97.299   Sparsity:0.00   Params: 370272 on epoch: 505]
2024-04-24 00:06:30,132 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:06:30,169 - 

2024-04-24 00:06:30,169 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:06:40,383 - Epoch: [552][  100/  296]    Overall Loss 0.693945    Objective Loss 0.693945                                        LR 0.000005    Time 0.101991    
2024-04-24 00:06:49,382 - Epoch: [552][  200/  296]    Overall Loss 0.702266    Objective Loss 0.702266                                        LR 0.000005    Time 0.095917    
2024-04-24 00:06:58,435 - Epoch: [552][  296/  296]    Overall Loss 0.708397    Objective Loss 0.708397    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.095346    
2024-04-24 00:06:58,621 - --- validate (epoch=552)-----------
2024-04-24 00:06:58,622 - 3925 samples (32 per mini-batch)
2024-04-24 00:07:10,727 - Epoch: [552][  100/  123]    Loss 0.711767    Top1 77.750000    Top5 97.281250    
2024-04-24 00:07:13,080 - Epoch: [552][  123/  123]    Loss 0.701450    Top1 78.165605    Top5 97.324841    
2024-04-24 00:07:13,212 - ==> Top1: 78.166    Top5: 97.325    Loss: 0.701

2024-04-24 00:07:13,222 - ==> Best [Top1: 78.166   Top5: 97.325   Sparsity:0.00   Params: 370272 on epoch: 552]
2024-04-24 00:07:13,222 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:07:13,268 - 

2024-04-24 00:07:13,268 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:07:22,024 - Epoch: [553][  100/  296]    Overall Loss 0.745198    Objective Loss 0.745198                                        LR 0.000005    Time 0.087452    
2024-04-24 00:07:31,823 - Epoch: [553][  200/  296]    Overall Loss 0.723107    Objective Loss 0.723107                                        LR 0.000005    Time 0.092656    
2024-04-24 00:07:41,212 - Epoch: [553][  296/  296]    Overall Loss 0.727252    Objective Loss 0.727252    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.094292    
2024-04-24 00:07:41,324 - --- validate (epoch=553)-----------
2024-04-24 00:07:41,325 - 3925 samples (32 per mini-batch)
2024-04-24 00:07:54,548 - Epoch: [553][  100/  123]    Loss 0.712594    Top1 77.500000    Top5 97.312500    
2024-04-24 00:07:56,955 - Epoch: [553][  123/  123]    Loss 0.705828    Top1 77.961783    Top5 97.273885    
2024-04-24 00:07:57,078 - ==> Top1: 77.962    Top5: 97.274    Loss: 0.706

2024-04-24 00:07:57,089 - ==> Best [Top1: 78.166   Top5: 97.325   Sparsity:0.00   Params: 370272 on epoch: 552]
2024-04-24 00:07:57,090 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:07:57,130 - 

2024-04-24 00:07:57,131 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:08:07,104 - Epoch: [554][  100/  296]    Overall Loss 0.688258    Objective Loss 0.688258                                        LR 0.000005    Time 0.099619    
2024-04-24 00:08:16,148 - Epoch: [554][  200/  296]    Overall Loss 0.689145    Objective Loss 0.689145                                        LR 0.000005    Time 0.094967    
2024-04-24 00:08:27,795 - Epoch: [554][  296/  296]    Overall Loss 0.686631    Objective Loss 0.686631    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.103475    
2024-04-24 00:08:28,270 - --- validate (epoch=554)-----------
2024-04-24 00:08:28,271 - 3925 samples (32 per mini-batch)
2024-04-24 00:08:39,283 - Epoch: [554][  100/  123]    Loss 0.709608    Top1 77.625000    Top5 97.187500    
2024-04-24 00:08:41,801 - Epoch: [554][  123/  123]    Loss 0.706042    Top1 77.808917    Top5 97.273885    
2024-04-24 00:08:41,968 - ==> Top1: 77.809    Top5: 97.274    Loss: 0.706

2024-04-24 00:08:41,979 - ==> Best [Top1: 78.166   Top5: 97.325   Sparsity:0.00   Params: 370272 on epoch: 552]
2024-04-24 00:08:41,980 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:08:42,025 - 

2024-04-24 00:08:42,026 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:08:51,212 - Epoch: [555][  100/  296]    Overall Loss 0.743367    Objective Loss 0.743367                                        LR 0.000005    Time 0.091720    
2024-04-24 00:08:58,325 - Epoch: [555][  200/  296]    Overall Loss 0.720596    Objective Loss 0.720596                                        LR 0.000005    Time 0.081355    
2024-04-24 00:09:05,077 - Epoch: [555][  296/  296]    Overall Loss 0.721399    Objective Loss 0.721399    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.077732    
2024-04-24 00:09:05,190 - --- validate (epoch=555)-----------
2024-04-24 00:09:05,191 - 3925 samples (32 per mini-batch)
2024-04-24 00:09:15,346 - Epoch: [555][  100/  123]    Loss 0.705595    Top1 77.812500    Top5 97.468750    
2024-04-24 00:09:17,209 - Epoch: [555][  123/  123]    Loss 0.704954    Top1 78.165605    Top5 97.375796    
2024-04-24 00:09:17,372 - ==> Top1: 78.166    Top5: 97.376    Loss: 0.705

2024-04-24 00:09:17,381 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:09:17,381 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:09:17,449 - 

2024-04-24 00:09:17,450 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:09:28,803 - Epoch: [556][  100/  296]    Overall Loss 0.710048    Objective Loss 0.710048                                        LR 0.000005    Time 0.113402    
2024-04-24 00:09:38,469 - Epoch: [556][  200/  296]    Overall Loss 0.704645    Objective Loss 0.704645                                        LR 0.000005    Time 0.104969    
2024-04-24 00:09:47,319 - Epoch: [556][  296/  296]    Overall Loss 0.699332    Objective Loss 0.699332    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.100786    
2024-04-24 00:09:47,427 - --- validate (epoch=556)-----------
2024-04-24 00:09:47,427 - 3925 samples (32 per mini-batch)
2024-04-24 00:09:58,556 - Epoch: [556][  100/  123]    Loss 0.714772    Top1 77.375000    Top5 97.187500    
2024-04-24 00:10:00,922 - Epoch: [556][  123/  123]    Loss 0.705892    Top1 77.783439    Top5 97.324841    
2024-04-24 00:10:01,181 - ==> Top1: 77.783    Top5: 97.325    Loss: 0.706

2024-04-24 00:10:01,191 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:10:01,192 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:10:01,237 - 

2024-04-24 00:10:01,237 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:10:11,949 - Epoch: [557][  100/  296]    Overall Loss 0.681620    Objective Loss 0.681620                                        LR 0.000005    Time 0.106975    
2024-04-24 00:10:21,924 - Epoch: [557][  200/  296]    Overall Loss 0.677210    Objective Loss 0.677210                                        LR 0.000005    Time 0.103297    
2024-04-24 00:10:30,113 - Epoch: [557][  296/  296]    Overall Loss 0.687020    Objective Loss 0.687020    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.097417    
2024-04-24 00:10:30,283 - --- validate (epoch=557)-----------
2024-04-24 00:10:30,283 - 3925 samples (32 per mini-batch)
2024-04-24 00:10:39,724 - Epoch: [557][  100/  123]    Loss 0.700224    Top1 77.750000    Top5 97.250000    
2024-04-24 00:10:41,650 - Epoch: [557][  123/  123]    Loss 0.706066    Top1 77.707006    Top5 97.222930    
2024-04-24 00:10:41,852 - ==> Top1: 77.707    Top5: 97.223    Loss: 0.706

2024-04-24 00:10:41,862 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:10:41,863 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:10:41,898 - 

2024-04-24 00:10:41,898 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:10:50,410 - Epoch: [558][  100/  296]    Overall Loss 0.715420    Objective Loss 0.715420                                        LR 0.000005    Time 0.085002    
2024-04-24 00:10:58,372 - Epoch: [558][  200/  296]    Overall Loss 0.703304    Objective Loss 0.703304                                        LR 0.000005    Time 0.082250    
2024-04-24 00:11:06,225 - Epoch: [558][  296/  296]    Overall Loss 0.715238    Objective Loss 0.715238    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.082063    
2024-04-24 00:11:06,463 - --- validate (epoch=558)-----------
2024-04-24 00:11:06,464 - 3925 samples (32 per mini-batch)
2024-04-24 00:11:16,448 - Epoch: [558][  100/  123]    Loss 0.704013    Top1 78.000000    Top5 97.125000    
2024-04-24 00:11:18,652 - Epoch: [558][  123/  123]    Loss 0.703224    Top1 77.808917    Top5 97.171975    
2024-04-24 00:11:18,818 - ==> Top1: 77.809    Top5: 97.172    Loss: 0.703

2024-04-24 00:11:18,828 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:11:18,829 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:11:18,867 - 

2024-04-24 00:11:18,867 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:11:27,388 - Epoch: [559][  100/  296]    Overall Loss 0.719666    Objective Loss 0.719666                                        LR 0.000005    Time 0.085069    
2024-04-24 00:11:34,905 - Epoch: [559][  200/  296]    Overall Loss 0.719970    Objective Loss 0.719970                                        LR 0.000005    Time 0.080046    
2024-04-24 00:11:42,491 - Epoch: [559][  296/  296]    Overall Loss 0.716307    Objective Loss 0.716307    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.079673    
2024-04-24 00:11:42,687 - --- validate (epoch=559)-----------
2024-04-24 00:11:42,688 - 3925 samples (32 per mini-batch)
2024-04-24 00:11:52,846 - Epoch: [559][  100/  123]    Loss 0.683980    Top1 78.593750    Top5 97.406250    
2024-04-24 00:11:54,553 - Epoch: [559][  123/  123]    Loss 0.703278    Top1 77.987261    Top5 97.324841    
2024-04-24 00:11:54,766 - ==> Top1: 77.987    Top5: 97.325    Loss: 0.703

2024-04-24 00:11:54,776 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:11:54,777 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:11:54,817 - 

2024-04-24 00:11:54,818 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:12:03,014 - Epoch: [560][  100/  296]    Overall Loss 0.711895    Objective Loss 0.711895                                        LR 0.000005    Time 0.081815    
2024-04-24 00:12:09,961 - Epoch: [560][  200/  296]    Overall Loss 0.704727    Objective Loss 0.704727                                        LR 0.000005    Time 0.075578    
2024-04-24 00:12:17,453 - Epoch: [560][  296/  296]    Overall Loss 0.703290    Objective Loss 0.703290    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.076328    
2024-04-24 00:12:17,639 - --- validate (epoch=560)-----------
2024-04-24 00:12:17,640 - 3925 samples (32 per mini-batch)
2024-04-24 00:12:28,687 - Epoch: [560][  100/  123]    Loss 0.705186    Top1 77.562500    Top5 97.375000    
2024-04-24 00:12:30,484 - Epoch: [560][  123/  123]    Loss 0.704226    Top1 77.681529    Top5 97.324841    
2024-04-24 00:12:30,646 - ==> Top1: 77.682    Top5: 97.325    Loss: 0.704

2024-04-24 00:12:30,655 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:12:30,656 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:12:30,714 - 

2024-04-24 00:12:30,715 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:12:40,058 - Epoch: [561][  100/  296]    Overall Loss 0.695162    Objective Loss 0.695162                                        LR 0.000005    Time 0.093287    
2024-04-24 00:12:47,025 - Epoch: [561][  200/  296]    Overall Loss 0.705555    Objective Loss 0.705555                                        LR 0.000005    Time 0.081413    
2024-04-24 00:12:53,381 - Epoch: [561][  296/  296]    Overall Loss 0.716664    Objective Loss 0.716664    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.076440    
2024-04-24 00:12:53,619 - --- validate (epoch=561)-----------
2024-04-24 00:12:53,620 - 3925 samples (32 per mini-batch)
2024-04-24 00:13:04,030 - Epoch: [561][  100/  123]    Loss 0.689659    Top1 78.125000    Top5 97.531250    
2024-04-24 00:13:05,767 - Epoch: [561][  123/  123]    Loss 0.707477    Top1 77.910828    Top5 97.375796    
2024-04-24 00:13:05,961 - ==> Top1: 77.911    Top5: 97.376    Loss: 0.707

2024-04-24 00:13:05,970 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:13:05,970 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:13:06,005 - 

2024-04-24 00:13:06,005 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:13:13,429 - Epoch: [562][  100/  296]    Overall Loss 0.716406    Objective Loss 0.716406                                        LR 0.000005    Time 0.074109    
2024-04-24 00:13:20,039 - Epoch: [562][  200/  296]    Overall Loss 0.704109    Objective Loss 0.704109                                        LR 0.000005    Time 0.070038    
2024-04-24 00:13:26,201 - Epoch: [562][  296/  296]    Overall Loss 0.713330    Objective Loss 0.713330    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.068103    
2024-04-24 00:13:26,371 - --- validate (epoch=562)-----------
2024-04-24 00:13:26,372 - 3925 samples (32 per mini-batch)
2024-04-24 00:13:36,579 - Epoch: [562][  100/  123]    Loss 0.709298    Top1 77.875000    Top5 97.250000    
2024-04-24 00:13:38,559 - Epoch: [562][  123/  123]    Loss 0.702901    Top1 77.987261    Top5 97.324841    
2024-04-24 00:13:38,816 - ==> Top1: 77.987    Top5: 97.325    Loss: 0.703

2024-04-24 00:13:38,826 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:13:38,827 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:13:38,864 - 

2024-04-24 00:13:38,865 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:13:46,995 - Epoch: [563][  100/  296]    Overall Loss 0.702860    Objective Loss 0.702860                                        LR 0.000005    Time 0.081165    
2024-04-24 00:13:54,530 - Epoch: [563][  200/  296]    Overall Loss 0.695320    Objective Loss 0.695320                                        LR 0.000005    Time 0.078197    
2024-04-24 00:14:01,741 - Epoch: [563][  296/  296]    Overall Loss 0.714921    Objective Loss 0.714921    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.077160    
2024-04-24 00:14:01,937 - --- validate (epoch=563)-----------
2024-04-24 00:14:01,938 - 3925 samples (32 per mini-batch)
2024-04-24 00:14:12,479 - Epoch: [563][  100/  123]    Loss 0.695051    Top1 78.468750    Top5 97.437500    
2024-04-24 00:14:15,147 - Epoch: [563][  123/  123]    Loss 0.702599    Top1 77.961783    Top5 97.426752    
2024-04-24 00:14:15,344 - ==> Top1: 77.962    Top5: 97.427    Loss: 0.703

2024-04-24 00:14:15,354 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:14:15,355 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:14:15,395 - 

2024-04-24 00:14:15,396 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:14:26,366 - Epoch: [564][  100/  296]    Overall Loss 0.674648    Objective Loss 0.674648                                        LR 0.000005    Time 0.109545    
2024-04-24 00:14:35,140 - Epoch: [564][  200/  296]    Overall Loss 0.690047    Objective Loss 0.690047                                        LR 0.000005    Time 0.098578    
2024-04-24 00:14:43,898 - Epoch: [564][  296/  296]    Overall Loss 0.688136    Objective Loss 0.688136    Top1 88.524590    Top5 100.000000    LR 0.000005    Time 0.096155    
2024-04-24 00:14:44,182 - --- validate (epoch=564)-----------
2024-04-24 00:14:44,183 - 3925 samples (32 per mini-batch)
2024-04-24 00:14:56,419 - Epoch: [564][  100/  123]    Loss 0.689808    Top1 78.062500    Top5 97.625000    
2024-04-24 00:14:58,543 - Epoch: [564][  123/  123]    Loss 0.706010    Top1 77.707006    Top5 97.350318    
2024-04-24 00:14:58,780 - ==> Top1: 77.707    Top5: 97.350    Loss: 0.706

2024-04-24 00:14:58,787 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:14:58,788 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:14:58,830 - 

2024-04-24 00:14:58,831 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:15:09,821 - Epoch: [565][  100/  296]    Overall Loss 0.654080    Objective Loss 0.654080                                        LR 0.000005    Time 0.109775    
2024-04-24 00:15:16,969 - Epoch: [565][  200/  296]    Overall Loss 0.688692    Objective Loss 0.688692                                        LR 0.000005    Time 0.090563    
2024-04-24 00:15:23,312 - Epoch: [565][  296/  296]    Overall Loss 0.696009    Objective Loss 0.696009    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.082575    
2024-04-24 00:15:23,530 - --- validate (epoch=565)-----------
2024-04-24 00:15:23,531 - 3925 samples (32 per mini-batch)
2024-04-24 00:15:35,648 - Epoch: [565][  100/  123]    Loss 0.700656    Top1 77.906250    Top5 97.468750    
2024-04-24 00:15:38,667 - Epoch: [565][  123/  123]    Loss 0.704404    Top1 77.859873    Top5 97.426752    
2024-04-24 00:15:38,839 - ==> Top1: 77.860    Top5: 97.427    Loss: 0.704

2024-04-24 00:15:38,848 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:15:38,848 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:15:38,886 - 

2024-04-24 00:15:38,887 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:15:49,556 - Epoch: [566][  100/  296]    Overall Loss 0.725049    Objective Loss 0.725049                                        LR 0.000005    Time 0.106564    
2024-04-24 00:16:00,081 - Epoch: [566][  200/  296]    Overall Loss 0.706351    Objective Loss 0.706351                                        LR 0.000005    Time 0.105851    
2024-04-24 00:16:08,917 - Epoch: [566][  296/  296]    Overall Loss 0.694165    Objective Loss 0.694165    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.101340    
2024-04-24 00:16:09,102 - --- validate (epoch=566)-----------
2024-04-24 00:16:09,103 - 3925 samples (32 per mini-batch)
2024-04-24 00:16:19,471 - Epoch: [566][  100/  123]    Loss 0.698165    Top1 77.750000    Top5 97.437500    
2024-04-24 00:16:21,461 - Epoch: [566][  123/  123]    Loss 0.704809    Top1 78.063694    Top5 97.248408    
2024-04-24 00:16:21,642 - ==> Top1: 78.064    Top5: 97.248    Loss: 0.705

2024-04-24 00:16:21,648 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:16:21,648 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:16:21,681 - 

2024-04-24 00:16:21,682 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:16:31,548 - Epoch: [567][  100/  296]    Overall Loss 0.679631    Objective Loss 0.679631                                        LR 0.000005    Time 0.098527    
2024-04-24 00:16:37,950 - Epoch: [567][  200/  296]    Overall Loss 0.690039    Objective Loss 0.690039                                        LR 0.000005    Time 0.081206    
2024-04-24 00:16:43,712 - Epoch: [567][  296/  296]    Overall Loss 0.694919    Objective Loss 0.694919    Top1 88.524590    Top5 98.360656    LR 0.000005    Time 0.074298    
2024-04-24 00:16:43,913 - --- validate (epoch=567)-----------
2024-04-24 00:16:43,913 - 3925 samples (32 per mini-batch)
2024-04-24 00:16:54,754 - Epoch: [567][  100/  123]    Loss 0.699238    Top1 77.968750    Top5 97.062500    
2024-04-24 00:16:56,941 - Epoch: [567][  123/  123]    Loss 0.704011    Top1 77.859873    Top5 97.197452    
2024-04-24 00:16:57,160 - ==> Top1: 77.860    Top5: 97.197    Loss: 0.704

2024-04-24 00:16:57,170 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:16:57,171 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:16:57,207 - 

2024-04-24 00:16:57,208 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:17:06,349 - Epoch: [568][  100/  296]    Overall Loss 0.706440    Objective Loss 0.706440                                        LR 0.000005    Time 0.091275    
2024-04-24 00:17:15,159 - Epoch: [568][  200/  296]    Overall Loss 0.708421    Objective Loss 0.708421                                        LR 0.000005    Time 0.089619    
2024-04-24 00:17:25,057 - Epoch: [568][  296/  296]    Overall Loss 0.707386    Objective Loss 0.707386    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.093954    
2024-04-24 00:17:25,267 - --- validate (epoch=568)-----------
2024-04-24 00:17:25,268 - 3925 samples (32 per mini-batch)
2024-04-24 00:17:36,602 - Epoch: [568][  100/  123]    Loss 0.708571    Top1 77.718750    Top5 97.187500    
2024-04-24 00:17:40,052 - Epoch: [568][  123/  123]    Loss 0.701546    Top1 77.910828    Top5 97.324841    
2024-04-24 00:17:40,230 - ==> Top1: 77.911    Top5: 97.325    Loss: 0.702

2024-04-24 00:17:40,241 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:17:40,242 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:17:40,290 - 

2024-04-24 00:17:40,290 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:17:51,167 - Epoch: [569][  100/  296]    Overall Loss 0.698287    Objective Loss 0.698287                                        LR 0.000005    Time 0.108620    
2024-04-24 00:18:01,375 - Epoch: [569][  200/  296]    Overall Loss 0.716981    Objective Loss 0.716981                                        LR 0.000005    Time 0.105288    
2024-04-24 00:18:12,285 - Epoch: [569][  296/  296]    Overall Loss 0.695147    Objective Loss 0.695147    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.107964    
2024-04-24 00:18:12,423 - --- validate (epoch=569)-----------
2024-04-24 00:18:12,424 - 3925 samples (32 per mini-batch)
2024-04-24 00:18:21,167 - Epoch: [569][  100/  123]    Loss 0.688359    Top1 78.218750    Top5 97.031250    
2024-04-24 00:18:23,994 - Epoch: [569][  123/  123]    Loss 0.704664    Top1 77.528662    Top5 97.146497    
2024-04-24 00:18:24,207 - ==> Top1: 77.529    Top5: 97.146    Loss: 0.705

2024-04-24 00:18:24,217 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:18:24,218 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:18:24,258 - 

2024-04-24 00:18:24,259 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:18:36,056 - Epoch: [570][  100/  296]    Overall Loss 0.682242    Objective Loss 0.682242                                        LR 0.000005    Time 0.117841    
2024-04-24 00:18:45,942 - Epoch: [570][  200/  296]    Overall Loss 0.684855    Objective Loss 0.684855                                        LR 0.000005    Time 0.108286    
2024-04-24 00:18:54,089 - Epoch: [570][  296/  296]    Overall Loss 0.687515    Objective Loss 0.687515    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.100651    
2024-04-24 00:18:54,401 - --- validate (epoch=570)-----------
2024-04-24 00:18:54,402 - 3925 samples (32 per mini-batch)
2024-04-24 00:19:08,078 - Epoch: [570][  100/  123]    Loss 0.713733    Top1 77.718750    Top5 97.031250    
2024-04-24 00:19:10,764 - Epoch: [570][  123/  123]    Loss 0.703001    Top1 77.936306    Top5 97.222930    
2024-04-24 00:19:11,010 - ==> Top1: 77.936    Top5: 97.223    Loss: 0.703

2024-04-24 00:19:11,019 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:19:11,020 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:19:11,058 - 

2024-04-24 00:19:11,058 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:19:21,395 - Epoch: [571][  100/  296]    Overall Loss 0.674408    Objective Loss 0.674408                                        LR 0.000005    Time 0.103231    
2024-04-24 00:19:32,681 - Epoch: [571][  200/  296]    Overall Loss 0.691376    Objective Loss 0.691376                                        LR 0.000005    Time 0.107985    
2024-04-24 00:19:41,640 - Epoch: [571][  296/  296]    Overall Loss 0.701907    Objective Loss 0.701907    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.103185    
2024-04-24 00:19:41,950 - --- validate (epoch=571)-----------
2024-04-24 00:19:41,951 - 3925 samples (32 per mini-batch)
2024-04-24 00:19:55,959 - Epoch: [571][  100/  123]    Loss 0.688492    Top1 78.156250    Top5 97.687500    
2024-04-24 00:19:58,347 - Epoch: [571][  123/  123]    Loss 0.705843    Top1 77.783439    Top5 97.401274    
2024-04-24 00:19:58,462 - ==> Top1: 77.783    Top5: 97.401    Loss: 0.706

2024-04-24 00:19:58,472 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:19:58,472 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:19:58,520 - 

2024-04-24 00:19:58,521 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:20:09,578 - Epoch: [572][  100/  296]    Overall Loss 0.713577    Objective Loss 0.713577                                        LR 0.000005    Time 0.110436    
2024-04-24 00:20:18,462 - Epoch: [572][  200/  296]    Overall Loss 0.713774    Objective Loss 0.713774                                        LR 0.000005    Time 0.099565    
2024-04-24 00:20:27,642 - Epoch: [572][  296/  296]    Overall Loss 0.699252    Objective Loss 0.699252    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.098245    
2024-04-24 00:20:27,752 - --- validate (epoch=572)-----------
2024-04-24 00:20:27,752 - 3925 samples (32 per mini-batch)
2024-04-24 00:20:37,815 - Epoch: [572][  100/  123]    Loss 0.698511    Top1 77.781250    Top5 97.375000    
2024-04-24 00:20:40,419 - Epoch: [572][  123/  123]    Loss 0.703506    Top1 77.707006    Top5 97.375796    
2024-04-24 00:20:40,663 - ==> Top1: 77.707    Top5: 97.376    Loss: 0.704

2024-04-24 00:20:40,674 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:20:40,674 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:20:40,716 - 

2024-04-24 00:20:40,716 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:20:52,266 - Epoch: [573][  100/  296]    Overall Loss 0.741200    Objective Loss 0.741200                                        LR 0.000005    Time 0.115354    
2024-04-24 00:21:01,581 - Epoch: [573][  200/  296]    Overall Loss 0.727199    Objective Loss 0.727199                                        LR 0.000005    Time 0.104178    
2024-04-24 00:21:11,226 - Epoch: [573][  296/  296]    Overall Loss 0.714027    Objective Loss 0.714027    Top1 67.213115    Top5 98.360656    LR 0.000005    Time 0.102940    
2024-04-24 00:21:11,524 - --- validate (epoch=573)-----------
2024-04-24 00:21:11,525 - 3925 samples (32 per mini-batch)
2024-04-24 00:21:23,300 - Epoch: [573][  100/  123]    Loss 0.701477    Top1 78.093750    Top5 97.312500    
2024-04-24 00:21:25,905 - Epoch: [573][  123/  123]    Loss 0.703930    Top1 77.885350    Top5 97.299363    
2024-04-24 00:21:26,428 - ==> Top1: 77.885    Top5: 97.299    Loss: 0.704

2024-04-24 00:21:26,437 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:21:26,438 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:21:26,477 - 

2024-04-24 00:21:26,478 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:21:36,671 - Epoch: [574][  100/  296]    Overall Loss 0.684461    Objective Loss 0.684461                                        LR 0.000005    Time 0.101788    
2024-04-24 00:21:44,904 - Epoch: [574][  200/  296]    Overall Loss 0.708400    Objective Loss 0.708400                                        LR 0.000005    Time 0.091998    
2024-04-24 00:21:54,878 - Epoch: [574][  296/  296]    Overall Loss 0.701911    Objective Loss 0.701911    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.095818    
2024-04-24 00:21:55,095 - --- validate (epoch=574)-----------
2024-04-24 00:21:55,096 - 3925 samples (32 per mini-batch)
2024-04-24 00:22:08,176 - Epoch: [574][  100/  123]    Loss 0.698878    Top1 77.656250    Top5 97.031250    
2024-04-24 00:22:10,881 - Epoch: [574][  123/  123]    Loss 0.703493    Top1 77.656051    Top5 97.222930    
2024-04-24 00:22:11,001 - ==> Top1: 77.656    Top5: 97.223    Loss: 0.703

2024-04-24 00:22:11,012 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:22:11,013 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:22:11,054 - 

2024-04-24 00:22:11,055 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:22:22,154 - Epoch: [575][  100/  296]    Overall Loss 0.704671    Objective Loss 0.704671                                        LR 0.000005    Time 0.110858    
2024-04-24 00:22:31,964 - Epoch: [575][  200/  296]    Overall Loss 0.710645    Objective Loss 0.710645                                        LR 0.000005    Time 0.104414    
2024-04-24 00:22:41,939 - Epoch: [575][  296/  296]    Overall Loss 0.715403    Objective Loss 0.715403    Top1 62.295082    Top5 95.081967    LR 0.000005    Time 0.104213    
2024-04-24 00:22:42,148 - --- validate (epoch=575)-----------
2024-04-24 00:22:42,149 - 3925 samples (32 per mini-batch)
2024-04-24 00:22:55,161 - Epoch: [575][  100/  123]    Loss 0.707204    Top1 78.031250    Top5 97.250000    
2024-04-24 00:22:57,679 - Epoch: [575][  123/  123]    Loss 0.702703    Top1 77.859873    Top5 97.299363    
2024-04-24 00:22:57,919 - ==> Top1: 77.860    Top5: 97.299    Loss: 0.703

2024-04-24 00:22:57,926 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:22:57,927 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:22:57,971 - 

2024-04-24 00:22:57,972 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:23:09,505 - Epoch: [576][  100/  296]    Overall Loss 0.682974    Objective Loss 0.682974                                        LR 0.000005    Time 0.115191    
2024-04-24 00:23:18,872 - Epoch: [576][  200/  296]    Overall Loss 0.692194    Objective Loss 0.692194                                        LR 0.000005    Time 0.104361    
2024-04-24 00:23:28,393 - Epoch: [576][  296/  296]    Overall Loss 0.699719    Objective Loss 0.699719    Top1 72.131148    Top5 91.803279    LR 0.000005    Time 0.102638    
2024-04-24 00:23:28,613 - --- validate (epoch=576)-----------
2024-04-24 00:23:28,614 - 3925 samples (32 per mini-batch)
2024-04-24 00:23:41,225 - Epoch: [576][  100/  123]    Loss 0.700386    Top1 78.625000    Top5 97.218750    
2024-04-24 00:23:43,530 - Epoch: [576][  123/  123]    Loss 0.705476    Top1 78.140127    Top5 97.299363    
2024-04-24 00:23:43,668 - ==> Top1: 78.140    Top5: 97.299    Loss: 0.705

2024-04-24 00:23:43,679 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:23:43,679 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:23:43,716 - 

2024-04-24 00:23:43,716 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:23:54,550 - Epoch: [577][  100/  296]    Overall Loss 0.692252    Objective Loss 0.692252                                        LR 0.000005    Time 0.108226    
2024-04-24 00:24:05,510 - Epoch: [577][  200/  296]    Overall Loss 0.705917    Objective Loss 0.705917                                        LR 0.000005    Time 0.108868    
2024-04-24 00:24:15,039 - Epoch: [577][  296/  296]    Overall Loss 0.713516    Objective Loss 0.713516    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.105714    
2024-04-24 00:24:15,283 - --- validate (epoch=577)-----------
2024-04-24 00:24:15,284 - 3925 samples (32 per mini-batch)
2024-04-24 00:24:27,514 - Epoch: [577][  100/  123]    Loss 0.700630    Top1 78.406250    Top5 97.437500    
2024-04-24 00:24:29,843 - Epoch: [577][  123/  123]    Loss 0.702625    Top1 77.961783    Top5 97.375796    
2024-04-24 00:24:30,049 - ==> Top1: 77.962    Top5: 97.376    Loss: 0.703

2024-04-24 00:24:30,060 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:24:30,060 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:24:30,104 - 

2024-04-24 00:24:30,104 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:24:39,437 - Epoch: [578][  100/  296]    Overall Loss 0.676816    Objective Loss 0.676816                                        LR 0.000005    Time 0.093183    
2024-04-24 00:24:48,719 - Epoch: [578][  200/  296]    Overall Loss 0.691283    Objective Loss 0.691283                                        LR 0.000005    Time 0.092935    
2024-04-24 00:24:58,300 - Epoch: [578][  296/  296]    Overall Loss 0.700103    Objective Loss 0.700103    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.095119    
2024-04-24 00:24:58,468 - --- validate (epoch=578)-----------
2024-04-24 00:24:58,469 - 3925 samples (32 per mini-batch)
2024-04-24 00:25:13,074 - Epoch: [578][  100/  123]    Loss 0.694554    Top1 77.843750    Top5 97.593750    
2024-04-24 00:25:15,820 - Epoch: [578][  123/  123]    Loss 0.705982    Top1 77.757962    Top5 97.554140    
2024-04-24 00:25:16,075 - ==> Top1: 77.758    Top5: 97.554    Loss: 0.706

2024-04-24 00:25:16,084 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:25:16,084 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:25:16,134 - 

2024-04-24 00:25:16,135 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:25:25,994 - Epoch: [579][  100/  296]    Overall Loss 0.712804    Objective Loss 0.712804                                        LR 0.000005    Time 0.098438    
2024-04-24 00:25:36,757 - Epoch: [579][  200/  296]    Overall Loss 0.720351    Objective Loss 0.720351                                        LR 0.000005    Time 0.102967    
2024-04-24 00:25:46,614 - Epoch: [579][  296/  296]    Overall Loss 0.706702    Objective Loss 0.706702    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.102831    
2024-04-24 00:25:46,802 - --- validate (epoch=579)-----------
2024-04-24 00:25:46,803 - 3925 samples (32 per mini-batch)
2024-04-24 00:25:58,831 - Epoch: [579][  100/  123]    Loss 0.700408    Top1 77.593750    Top5 97.312500    
2024-04-24 00:26:00,648 - Epoch: [579][  123/  123]    Loss 0.703929    Top1 77.707006    Top5 97.273885    
2024-04-24 00:26:00,760 - ==> Top1: 77.707    Top5: 97.274    Loss: 0.704

2024-04-24 00:26:00,772 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:26:00,772 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:26:00,817 - 

2024-04-24 00:26:00,817 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:26:09,639 - Epoch: [580][  100/  296]    Overall Loss 0.702836    Objective Loss 0.702836                                        LR 0.000005    Time 0.088074    
2024-04-24 00:26:16,685 - Epoch: [580][  200/  296]    Overall Loss 0.691105    Objective Loss 0.691105                                        LR 0.000005    Time 0.079208    
2024-04-24 00:26:23,944 - Epoch: [580][  296/  296]    Overall Loss 0.681954    Objective Loss 0.681954    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.078005    
2024-04-24 00:26:24,092 - --- validate (epoch=580)-----------
2024-04-24 00:26:24,093 - 3925 samples (32 per mini-batch)
2024-04-24 00:26:37,710 - Epoch: [580][  100/  123]    Loss 0.716812    Top1 77.968750    Top5 97.125000    
2024-04-24 00:26:40,167 - Epoch: [580][  123/  123]    Loss 0.709144    Top1 77.859873    Top5 97.222930    
2024-04-24 00:26:40,404 - ==> Top1: 77.860    Top5: 97.223    Loss: 0.709

2024-04-24 00:26:40,415 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:26:40,415 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:26:40,459 - 

2024-04-24 00:26:40,460 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:26:51,905 - Epoch: [581][  100/  296]    Overall Loss 0.715888    Objective Loss 0.715888                                        LR 0.000005    Time 0.114306    
2024-04-24 00:27:01,276 - Epoch: [581][  200/  296]    Overall Loss 0.710036    Objective Loss 0.710036                                        LR 0.000005    Time 0.103946    
2024-04-24 00:27:08,489 - Epoch: [581][  296/  296]    Overall Loss 0.714416    Objective Loss 0.714416    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.094561    
2024-04-24 00:27:08,948 - --- validate (epoch=581)-----------
2024-04-24 00:27:08,948 - 3925 samples (32 per mini-batch)
2024-04-24 00:27:22,409 - Epoch: [581][  100/  123]    Loss 0.694238    Top1 78.156250    Top5 97.468750    
2024-04-24 00:27:25,447 - Epoch: [581][  123/  123]    Loss 0.703789    Top1 77.808917    Top5 97.299363    
2024-04-24 00:27:25,601 - ==> Top1: 77.809    Top5: 97.299    Loss: 0.704

2024-04-24 00:27:25,611 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:27:25,611 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:27:25,651 - 

2024-04-24 00:27:25,651 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:27:36,983 - Epoch: [582][  100/  296]    Overall Loss 0.695044    Objective Loss 0.695044                                        LR 0.000005    Time 0.113175    
2024-04-24 00:27:46,337 - Epoch: [582][  200/  296]    Overall Loss 0.707213    Objective Loss 0.707213                                        LR 0.000005    Time 0.103286    
2024-04-24 00:27:55,309 - Epoch: [582][  296/  296]    Overall Loss 0.707103    Objective Loss 0.707103    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.100059    
2024-04-24 00:27:55,479 - --- validate (epoch=582)-----------
2024-04-24 00:27:55,480 - 3925 samples (32 per mini-batch)
2024-04-24 00:28:08,801 - Epoch: [582][  100/  123]    Loss 0.704844    Top1 77.718750    Top5 97.031250    
2024-04-24 00:28:11,300 - Epoch: [582][  123/  123]    Loss 0.706900    Top1 77.707006    Top5 97.171975    
2024-04-24 00:28:11,544 - ==> Top1: 77.707    Top5: 97.172    Loss: 0.707

2024-04-24 00:28:11,555 - ==> Best [Top1: 78.166   Top5: 97.376   Sparsity:0.00   Params: 370272 on epoch: 555]
2024-04-24 00:28:11,555 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:28:11,600 - 

2024-04-24 00:28:11,600 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:28:23,650 - Epoch: [583][  100/  296]    Overall Loss 0.701110    Objective Loss 0.701110                                        LR 0.000005    Time 0.120377    
2024-04-24 00:28:33,315 - Epoch: [583][  200/  296]    Overall Loss 0.687465    Objective Loss 0.687465                                        LR 0.000005    Time 0.108456    
2024-04-24 00:28:42,945 - Epoch: [583][  296/  296]    Overall Loss 0.688365    Objective Loss 0.688365    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.105776    
2024-04-24 00:28:43,606 - --- validate (epoch=583)-----------
2024-04-24 00:28:43,607 - 3925 samples (32 per mini-batch)
2024-04-24 00:28:56,630 - Epoch: [583][  100/  123]    Loss 0.701771    Top1 77.968750    Top5 97.156250    
2024-04-24 00:28:59,631 - Epoch: [583][  123/  123]    Loss 0.702383    Top1 78.191083    Top5 97.273885    
2024-04-24 00:28:59,738 - ==> Top1: 78.191    Top5: 97.274    Loss: 0.702

2024-04-24 00:28:59,749 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:28:59,749 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:28:59,800 - 

2024-04-24 00:28:59,801 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:29:10,817 - Epoch: [584][  100/  296]    Overall Loss 0.700877    Objective Loss 0.700877                                        LR 0.000005    Time 0.110036    
2024-04-24 00:29:20,675 - Epoch: [584][  200/  296]    Overall Loss 0.687245    Objective Loss 0.687245                                        LR 0.000005    Time 0.104251    
2024-04-24 00:29:29,016 - Epoch: [584][  296/  296]    Overall Loss 0.695691    Objective Loss 0.695691    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.098575    
2024-04-24 00:29:29,255 - --- validate (epoch=584)-----------
2024-04-24 00:29:29,256 - 3925 samples (32 per mini-batch)
2024-04-24 00:29:41,989 - Epoch: [584][  100/  123]    Loss 0.710860    Top1 77.468750    Top5 97.156250    
2024-04-24 00:29:44,127 - Epoch: [584][  123/  123]    Loss 0.700061    Top1 77.859873    Top5 97.324841    
2024-04-24 00:29:44,305 - ==> Top1: 77.860    Top5: 97.325    Loss: 0.700

2024-04-24 00:29:44,317 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:29:44,317 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:29:44,356 - 

2024-04-24 00:29:44,356 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:29:57,147 - Epoch: [585][  100/  296]    Overall Loss 0.687241    Objective Loss 0.687241                                        LR 0.000005    Time 0.127763    
2024-04-24 00:30:05,641 - Epoch: [585][  200/  296]    Overall Loss 0.708445    Objective Loss 0.708445                                        LR 0.000005    Time 0.106274    
2024-04-24 00:30:13,760 - Epoch: [585][  296/  296]    Overall Loss 0.697008    Objective Loss 0.697008    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.099194    
2024-04-24 00:30:14,041 - --- validate (epoch=585)-----------
2024-04-24 00:30:14,042 - 3925 samples (32 per mini-batch)
2024-04-24 00:30:26,128 - Epoch: [585][  100/  123]    Loss 0.704323    Top1 78.093750    Top5 97.156250    
2024-04-24 00:30:28,984 - Epoch: [585][  123/  123]    Loss 0.703887    Top1 77.859873    Top5 97.248408    
2024-04-24 00:30:29,162 - ==> Top1: 77.860    Top5: 97.248    Loss: 0.704

2024-04-24 00:30:29,169 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:30:29,170 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:30:29,205 - 

2024-04-24 00:30:29,205 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:30:39,548 - Epoch: [586][  100/  296]    Overall Loss 0.685498    Objective Loss 0.685498                                        LR 0.000005    Time 0.103283    
2024-04-24 00:30:48,202 - Epoch: [586][  200/  296]    Overall Loss 0.675354    Objective Loss 0.675354                                        LR 0.000005    Time 0.094841    
2024-04-24 00:30:58,004 - Epoch: [586][  296/  296]    Overall Loss 0.694170    Objective Loss 0.694170    Top1 73.770492    Top5 93.442623    LR 0.000005    Time 0.097156    
2024-04-24 00:30:58,224 - --- validate (epoch=586)-----------
2024-04-24 00:30:58,226 - 3925 samples (32 per mini-batch)
2024-04-24 00:31:10,967 - Epoch: [586][  100/  123]    Loss 0.706025    Top1 78.187500    Top5 97.187500    
2024-04-24 00:31:13,824 - Epoch: [586][  123/  123]    Loss 0.706125    Top1 77.808917    Top5 97.324841    
2024-04-24 00:31:14,030 - ==> Top1: 77.809    Top5: 97.325    Loss: 0.706

2024-04-24 00:31:14,041 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:31:14,041 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:31:14,080 - 

2024-04-24 00:31:14,081 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:31:23,867 - Epoch: [587][  100/  296]    Overall Loss 0.712804    Objective Loss 0.712804                                        LR 0.000005    Time 0.097735    
2024-04-24 00:31:32,879 - Epoch: [587][  200/  296]    Overall Loss 0.718955    Objective Loss 0.718955                                        LR 0.000005    Time 0.093857    
2024-04-24 00:31:41,928 - Epoch: [587][  296/  296]    Overall Loss 0.704973    Objective Loss 0.704973    Top1 72.131148    Top5 100.000000    LR 0.000005    Time 0.093940    
2024-04-24 00:31:42,054 - --- validate (epoch=587)-----------
2024-04-24 00:31:42,054 - 3925 samples (32 per mini-batch)
2024-04-24 00:31:54,853 - Epoch: [587][  100/  123]    Loss 0.721677    Top1 77.468750    Top5 97.468750    
2024-04-24 00:31:58,006 - Epoch: [587][  123/  123]    Loss 0.703189    Top1 77.859873    Top5 97.350318    
2024-04-24 00:31:58,157 - ==> Top1: 77.860    Top5: 97.350    Loss: 0.703

2024-04-24 00:31:58,163 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:31:58,164 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:31:58,198 - 

2024-04-24 00:31:58,199 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:32:09,593 - Epoch: [588][  100/  296]    Overall Loss 0.705886    Objective Loss 0.705886                                        LR 0.000005    Time 0.113802    
2024-04-24 00:32:19,654 - Epoch: [588][  200/  296]    Overall Loss 0.696064    Objective Loss 0.696064                                        LR 0.000005    Time 0.107136    
2024-04-24 00:32:27,978 - Epoch: [588][  296/  296]    Overall Loss 0.695166    Objective Loss 0.695166    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.100467    
2024-04-24 00:32:28,205 - --- validate (epoch=588)-----------
2024-04-24 00:32:28,206 - 3925 samples (32 per mini-batch)
2024-04-24 00:32:40,553 - Epoch: [588][  100/  123]    Loss 0.704767    Top1 77.750000    Top5 97.343750    
2024-04-24 00:32:42,980 - Epoch: [588][  123/  123]    Loss 0.703893    Top1 77.579618    Top5 97.375796    
2024-04-24 00:32:43,118 - ==> Top1: 77.580    Top5: 97.376    Loss: 0.704

2024-04-24 00:32:43,123 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:32:43,123 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:32:43,152 - 

2024-04-24 00:32:43,153 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:32:55,064 - Epoch: [589][  100/  296]    Overall Loss 0.701972    Objective Loss 0.701972                                        LR 0.000005    Time 0.118969    
2024-04-24 00:33:05,037 - Epoch: [589][  200/  296]    Overall Loss 0.706354    Objective Loss 0.706354                                        LR 0.000005    Time 0.109280    
2024-04-24 00:33:13,514 - Epoch: [589][  296/  296]    Overall Loss 0.699286    Objective Loss 0.699286    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.102429    
2024-04-24 00:33:13,803 - --- validate (epoch=589)-----------
2024-04-24 00:33:13,804 - 3925 samples (32 per mini-batch)
2024-04-24 00:33:25,646 - Epoch: [589][  100/  123]    Loss 0.695485    Top1 77.625000    Top5 97.562500    
2024-04-24 00:33:28,103 - Epoch: [589][  123/  123]    Loss 0.701645    Top1 77.630573    Top5 97.477707    
2024-04-24 00:33:28,293 - ==> Top1: 77.631    Top5: 97.478    Loss: 0.702

2024-04-24 00:33:28,301 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:33:28,302 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:33:28,354 - 

2024-04-24 00:33:28,354 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:33:41,956 - Epoch: [590][  100/  296]    Overall Loss 0.725775    Objective Loss 0.725775                                        LR 0.000005    Time 0.135881    
2024-04-24 00:33:50,658 - Epoch: [590][  200/  296]    Overall Loss 0.713071    Objective Loss 0.713071                                        LR 0.000005    Time 0.111384    
2024-04-24 00:33:59,646 - Epoch: [590][  296/  296]    Overall Loss 0.709743    Objective Loss 0.709743    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.105582    
2024-04-24 00:33:59,887 - --- validate (epoch=590)-----------
2024-04-24 00:33:59,888 - 3925 samples (32 per mini-batch)
2024-04-24 00:34:12,010 - Epoch: [590][  100/  123]    Loss 0.711362    Top1 77.406250    Top5 97.125000    
2024-04-24 00:34:14,246 - Epoch: [590][  123/  123]    Loss 0.703221    Top1 77.579618    Top5 97.273885    
2024-04-24 00:34:14,482 - ==> Top1: 77.580    Top5: 97.274    Loss: 0.703

2024-04-24 00:34:14,491 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:34:14,492 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:34:14,542 - 

2024-04-24 00:34:14,542 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:34:24,582 - Epoch: [591][  100/  296]    Overall Loss 0.702740    Objective Loss 0.702740                                        LR 0.000005    Time 0.100252    
2024-04-24 00:34:34,312 - Epoch: [591][  200/  296]    Overall Loss 0.703943    Objective Loss 0.703943                                        LR 0.000005    Time 0.098716    
2024-04-24 00:34:42,719 - Epoch: [591][  296/  296]    Overall Loss 0.696470    Objective Loss 0.696470    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.095063    
2024-04-24 00:34:42,914 - --- validate (epoch=591)-----------
2024-04-24 00:34:42,915 - 3925 samples (32 per mini-batch)
2024-04-24 00:34:55,532 - Epoch: [591][  100/  123]    Loss 0.696586    Top1 77.906250    Top5 97.375000    
2024-04-24 00:34:58,065 - Epoch: [591][  123/  123]    Loss 0.700652    Top1 77.808917    Top5 97.350318    
2024-04-24 00:34:58,300 - ==> Top1: 77.809    Top5: 97.350    Loss: 0.701

2024-04-24 00:34:58,315 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:34:58,315 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:34:58,356 - 

2024-04-24 00:34:58,356 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:35:09,439 - Epoch: [592][  100/  296]    Overall Loss 0.701280    Objective Loss 0.701280                                        LR 0.000005    Time 0.110680    
2024-04-24 00:35:21,449 - Epoch: [592][  200/  296]    Overall Loss 0.699830    Objective Loss 0.699830                                        LR 0.000005    Time 0.115322    
2024-04-24 00:35:30,757 - Epoch: [592][  296/  296]    Overall Loss 0.706068    Objective Loss 0.706068    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.109329    
2024-04-24 00:35:30,973 - --- validate (epoch=592)-----------
2024-04-24 00:35:30,974 - 3925 samples (32 per mini-batch)
2024-04-24 00:35:44,374 - Epoch: [592][  100/  123]    Loss 0.704563    Top1 77.781250    Top5 97.375000    
2024-04-24 00:35:46,768 - Epoch: [592][  123/  123]    Loss 0.706376    Top1 77.477707    Top5 97.299363    
2024-04-24 00:35:47,230 - ==> Top1: 77.478    Top5: 97.299    Loss: 0.706

2024-04-24 00:35:47,241 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:35:47,241 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:35:47,279 - 

2024-04-24 00:35:47,279 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:35:56,330 - Epoch: [593][  100/  296]    Overall Loss 0.689393    Objective Loss 0.689393                                        LR 0.000005    Time 0.090364    
2024-04-24 00:36:03,460 - Epoch: [593][  200/  296]    Overall Loss 0.708691    Objective Loss 0.708691                                        LR 0.000005    Time 0.080765    
2024-04-24 00:36:12,311 - Epoch: [593][  296/  296]    Overall Loss 0.704884    Objective Loss 0.704884    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.084429    
2024-04-24 00:36:12,520 - --- validate (epoch=593)-----------
2024-04-24 00:36:12,521 - 3925 samples (32 per mini-batch)
2024-04-24 00:36:25,324 - Epoch: [593][  100/  123]    Loss 0.707321    Top1 77.781250    Top5 97.343750    
2024-04-24 00:36:27,468 - Epoch: [593][  123/  123]    Loss 0.702513    Top1 77.885350    Top5 97.350318    
2024-04-24 00:36:27,654 - ==> Top1: 77.885    Top5: 97.350    Loss: 0.703

2024-04-24 00:36:27,663 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:36:27,664 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:36:27,700 - 

2024-04-24 00:36:27,701 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:36:41,842 - Epoch: [594][  100/  296]    Overall Loss 0.678284    Objective Loss 0.678284                                        LR 0.000005    Time 0.141270    
2024-04-24 00:36:51,166 - Epoch: [594][  200/  296]    Overall Loss 0.690700    Objective Loss 0.690700                                        LR 0.000005    Time 0.117186    
2024-04-24 00:36:59,830 - Epoch: [594][  296/  296]    Overall Loss 0.696520    Objective Loss 0.696520    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.108408    
2024-04-24 00:37:00,118 - --- validate (epoch=594)-----------
2024-04-24 00:37:00,119 - 3925 samples (32 per mini-batch)
2024-04-24 00:37:13,530 - Epoch: [594][  100/  123]    Loss 0.701395    Top1 77.812500    Top5 97.281250    
2024-04-24 00:37:15,517 - Epoch: [594][  123/  123]    Loss 0.706385    Top1 77.426752    Top5 97.273885    
2024-04-24 00:37:15,772 - ==> Top1: 77.427    Top5: 97.274    Loss: 0.706

2024-04-24 00:37:15,777 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:37:15,778 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:37:15,816 - 

2024-04-24 00:37:15,817 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:37:27,574 - Epoch: [595][  100/  296]    Overall Loss 0.697660    Objective Loss 0.697660                                        LR 0.000005    Time 0.117431    
2024-04-24 00:37:36,810 - Epoch: [595][  200/  296]    Overall Loss 0.700252    Objective Loss 0.700252                                        LR 0.000005    Time 0.104820    
2024-04-24 00:37:44,941 - Epoch: [595][  296/  296]    Overall Loss 0.702299    Objective Loss 0.702299    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.098253    
2024-04-24 00:37:45,141 - --- validate (epoch=595)-----------
2024-04-24 00:37:45,142 - 3925 samples (32 per mini-batch)
2024-04-24 00:37:57,174 - Epoch: [595][  100/  123]    Loss 0.695857    Top1 77.906250    Top5 97.500000    
2024-04-24 00:37:59,802 - Epoch: [595][  123/  123]    Loss 0.700383    Top1 77.961783    Top5 97.375796    
2024-04-24 00:37:59,968 - ==> Top1: 77.962    Top5: 97.376    Loss: 0.700

2024-04-24 00:37:59,976 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:37:59,976 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:38:00,010 - 

2024-04-24 00:38:00,011 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:38:12,387 - Epoch: [596][  100/  296]    Overall Loss 0.705547    Objective Loss 0.705547                                        LR 0.000005    Time 0.123630    
2024-04-24 00:38:21,615 - Epoch: [596][  200/  296]    Overall Loss 0.691426    Objective Loss 0.691426                                        LR 0.000005    Time 0.107883    
2024-04-24 00:38:30,553 - Epoch: [596][  296/  296]    Overall Loss 0.699255    Objective Loss 0.699255    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.103046    
2024-04-24 00:38:30,770 - --- validate (epoch=596)-----------
2024-04-24 00:38:30,771 - 3925 samples (32 per mini-batch)
2024-04-24 00:38:43,804 - Epoch: [596][  100/  123]    Loss 0.696898    Top1 77.843750    Top5 97.281250    
2024-04-24 00:38:46,196 - Epoch: [596][  123/  123]    Loss 0.706265    Top1 77.808917    Top5 97.299363    
2024-04-24 00:38:46,411 - ==> Top1: 77.809    Top5: 97.299    Loss: 0.706

2024-04-24 00:38:46,422 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:38:46,422 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:38:46,463 - 

2024-04-24 00:38:46,464 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:38:57,424 - Epoch: [597][  100/  296]    Overall Loss 0.681108    Objective Loss 0.681108                                        LR 0.000005    Time 0.109463    
2024-04-24 00:39:05,885 - Epoch: [597][  200/  296]    Overall Loss 0.699382    Objective Loss 0.699382                                        LR 0.000005    Time 0.096961    
2024-04-24 00:39:13,665 - Epoch: [597][  296/  296]    Overall Loss 0.694898    Objective Loss 0.694898    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.091760    
2024-04-24 00:39:13,910 - --- validate (epoch=597)-----------
2024-04-24 00:39:13,910 - 3925 samples (32 per mini-batch)
2024-04-24 00:39:23,714 - Epoch: [597][  100/  123]    Loss 0.719054    Top1 77.031250    Top5 97.250000    
2024-04-24 00:39:26,070 - Epoch: [597][  123/  123]    Loss 0.702567    Top1 77.808917    Top5 97.324841    
2024-04-24 00:39:26,293 - ==> Top1: 77.809    Top5: 97.325    Loss: 0.703

2024-04-24 00:39:26,298 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:39:26,299 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:39:26,335 - 

2024-04-24 00:39:26,336 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:39:34,124 - Epoch: [598][  100/  296]    Overall Loss 0.679430    Objective Loss 0.679430                                        LR 0.000005    Time 0.077735    
2024-04-24 00:39:45,314 - Epoch: [598][  200/  296]    Overall Loss 0.687277    Objective Loss 0.687277                                        LR 0.000005    Time 0.094755    
2024-04-24 00:39:55,140 - Epoch: [598][  296/  296]    Overall Loss 0.698711    Objective Loss 0.698711    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.097177    
2024-04-24 00:39:55,365 - --- validate (epoch=598)-----------
2024-04-24 00:39:55,365 - 3925 samples (32 per mini-batch)
2024-04-24 00:40:07,882 - Epoch: [598][  100/  123]    Loss 0.696814    Top1 78.000000    Top5 97.562500    
2024-04-24 00:40:10,131 - Epoch: [598][  123/  123]    Loss 0.705123    Top1 77.681529    Top5 97.477707    
2024-04-24 00:40:10,332 - ==> Top1: 77.682    Top5: 97.478    Loss: 0.705

2024-04-24 00:40:10,348 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:40:10,348 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:40:10,400 - 

2024-04-24 00:40:10,401 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:40:21,228 - Epoch: [599][  100/  296]    Overall Loss 0.726276    Objective Loss 0.726276                                        LR 0.000005    Time 0.108128    
2024-04-24 00:40:30,813 - Epoch: [599][  200/  296]    Overall Loss 0.714822    Objective Loss 0.714822                                        LR 0.000005    Time 0.101913    
2024-04-24 00:40:39,069 - Epoch: [599][  296/  296]    Overall Loss 0.713144    Objective Loss 0.713144    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.096712    
2024-04-24 00:40:39,292 - --- validate (epoch=599)-----------
2024-04-24 00:40:39,293 - 3925 samples (32 per mini-batch)
2024-04-24 00:40:51,872 - Epoch: [599][  100/  123]    Loss 0.716713    Top1 77.656250    Top5 97.375000    
2024-04-24 00:40:54,300 - Epoch: [599][  123/  123]    Loss 0.709850    Top1 77.656051    Top5 97.426752    
2024-04-24 00:40:54,517 - ==> Top1: 77.656    Top5: 97.427    Loss: 0.710

2024-04-24 00:40:54,531 - ==> Best [Top1: 78.191   Top5: 97.274   Sparsity:0.00   Params: 370272 on epoch: 583]
2024-04-24 00:40:54,532 - Saving checkpoint to: logs/2024.04.23-154949/checkpoint.pth.tar
2024-04-24 00:40:54,569 - --- test ---------------------
2024-04-24 00:40:54,569 - 3925 samples (32 per mini-batch)
2024-04-24 00:41:07,939 - Test: [  100/  123]    Loss 0.718340    Top1 77.093750    Top5 97.500000    
2024-04-24 00:41:10,533 - Test: [  123/  123]    Loss 0.710710    Top1 77.656051    Top5 97.426752    
2024-04-24 00:41:10,752 - ==> Top1: 77.656    Top5: 97.427    Loss: 0.711

2024-04-24 00:41:10,762 - 
2024-04-24 00:41:10,763 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.23-154949/2024.04.23-154949.log
