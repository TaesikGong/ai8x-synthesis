2024-05-04 16:54:10,226 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.05.04-165410/2024.05.04-165410.log
2024-05-04 16:54:14,379 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-05-04 16:54:14,380 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-05-04 16:54:14,471 - Dataset sizes:
	training=6941
	validation=1736
	test=1736
2024-05-04 16:54:14,472 - Reading compression schedule from: policies/schedule-cifar100.yaml
2024-05-04 16:54:14,479 - 

2024-05-04 16:54:14,480 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 16:55:07,168 - Epoch: [0][  100/  217]    Overall Loss 3.995161    Objective Loss 3.995161                                        LR 0.001000    Time 0.526819    
2024-05-04 16:55:57,068 - Epoch: [0][  200/  217]    Overall Loss 3.756370    Objective Loss 3.756370                                        LR 0.001000    Time 0.512885    
2024-05-04 16:56:04,029 - Epoch: [0][  217/  217]    Overall Loss 3.727270    Objective Loss 3.727270    Top1 32.786885    Top5 40.983607    LR 0.001000    Time 0.504776    
2024-05-04 16:56:04,181 - --- validate (epoch=0)-----------
2024-05-04 16:56:04,182 - 1736 samples (32 per mini-batch)
2024-05-04 16:56:34,024 - Epoch: [0][   55/   55]    Loss 3.437094    Top1 27.764977    Top5 36.693548    
2024-05-04 16:56:34,217 - ==> Top1: 27.765    Top5: 36.694    Loss: 3.437

2024-05-04 16:56:34,223 - ==> Best [Top1: 27.765   Top5: 36.694   Sparsity:0.00   Params: 384080 on epoch: 0]
2024-05-04 16:56:34,223 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 16:56:34,286 - 

2024-05-04 16:56:34,287 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 16:57:28,991 - Epoch: [1][  100/  217]    Overall Loss 3.294204    Objective Loss 3.294204                                        LR 0.001000    Time 0.546971    
2024-05-04 16:58:23,880 - Epoch: [1][  200/  217]    Overall Loss 3.219745    Objective Loss 3.219745                                        LR 0.001000    Time 0.547900    
2024-05-04 16:58:30,307 - Epoch: [1][  217/  217]    Overall Loss 3.206893    Objective Loss 3.206893    Top1 32.786885    Top5 42.622951    LR 0.001000    Time 0.534588    
2024-05-04 16:58:30,522 - --- validate (epoch=1)-----------
2024-05-04 16:58:30,523 - 1736 samples (32 per mini-batch)
2024-05-04 16:59:00,168 - Epoch: [1][   55/   55]    Loss 3.208268    Top1 32.776498    Top5 41.129032    
2024-05-04 16:59:00,298 - ==> Top1: 32.776    Top5: 41.129    Loss: 3.208

2024-05-04 16:59:00,304 - ==> Best [Top1: 32.776   Top5: 41.129   Sparsity:0.00   Params: 384080 on epoch: 1]
2024-05-04 16:59:00,304 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 16:59:00,390 - 

2024-05-04 16:59:00,391 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 16:59:52,511 - Epoch: [2][  100/  217]    Overall Loss 2.949875    Objective Loss 2.949875                                        LR 0.001000    Time 0.521136    
2024-05-04 17:00:42,159 - Epoch: [2][  200/  217]    Overall Loss 2.917067    Objective Loss 2.917067                                        LR 0.001000    Time 0.508663    
2024-05-04 17:00:50,300 - Epoch: [2][  217/  217]    Overall Loss 2.901408    Objective Loss 2.901408    Top1 39.344262    Top5 59.016393    LR 0.001000    Time 0.506324    
2024-05-04 17:00:50,494 - --- validate (epoch=2)-----------
2024-05-04 17:00:50,494 - 1736 samples (32 per mini-batch)
2024-05-04 17:01:19,975 - Epoch: [2][   55/   55]    Loss 2.934783    Top1 36.808756    Top5 50.000000    
2024-05-04 17:01:20,199 - ==> Top1: 36.809    Top5: 50.000    Loss: 2.935

2024-05-04 17:01:20,206 - ==> Best [Top1: 36.809   Top5: 50.000   Sparsity:0.00   Params: 384080 on epoch: 2]
2024-05-04 17:01:20,206 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:01:20,278 - 

2024-05-04 17:01:20,278 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:02:11,067 - Epoch: [3][  100/  217]    Overall Loss 2.666481    Objective Loss 2.666481                                        LR 0.001000    Time 0.507815    
2024-05-04 17:03:03,532 - Epoch: [3][  200/  217]    Overall Loss 2.608733    Objective Loss 2.608733                                        LR 0.001000    Time 0.515498    
2024-05-04 17:03:12,317 - Epoch: [3][  217/  217]    Overall Loss 2.603062    Objective Loss 2.603062    Top1 49.180328    Top5 60.655738    LR 0.001000    Time 0.515591    
2024-05-04 17:03:12,483 - --- validate (epoch=3)-----------
2024-05-04 17:03:12,484 - 1736 samples (32 per mini-batch)
2024-05-04 17:03:40,922 - Epoch: [3][   55/   55]    Loss 2.638030    Top1 40.668203    Top5 57.373272    
2024-05-04 17:03:41,044 - ==> Top1: 40.668    Top5: 57.373    Loss: 2.638

2024-05-04 17:03:41,050 - ==> Best [Top1: 40.668   Top5: 57.373   Sparsity:0.00   Params: 384080 on epoch: 3]
2024-05-04 17:03:41,050 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:03:41,132 - 

2024-05-04 17:03:41,133 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:04:29,904 - Epoch: [4][  100/  217]    Overall Loss 2.300134    Objective Loss 2.300134                                        LR 0.001000    Time 0.487642    
2024-05-04 17:05:19,325 - Epoch: [4][  200/  217]    Overall Loss 2.332537    Objective Loss 2.332537                                        LR 0.001000    Time 0.490894    
2024-05-04 17:05:26,701 - Epoch: [4][  217/  217]    Overall Loss 2.330668    Objective Loss 2.330668    Top1 67.213115    Top5 80.327869    LR 0.001000    Time 0.486423    
2024-05-04 17:05:26,883 - --- validate (epoch=4)-----------
2024-05-04 17:05:26,884 - 1736 samples (32 per mini-batch)
2024-05-04 17:06:00,336 - Epoch: [4][   55/   55]    Loss 2.624719    Top1 40.437788    Top5 57.430876    
2024-05-04 17:06:00,486 - ==> Top1: 40.438    Top5: 57.431    Loss: 2.625

2024-05-04 17:06:00,493 - ==> Best [Top1: 40.668   Top5: 57.373   Sparsity:0.00   Params: 384080 on epoch: 3]
2024-05-04 17:06:00,493 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:06:00,560 - 

2024-05-04 17:06:00,561 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:06:53,532 - Epoch: [5][  100/  217]    Overall Loss 2.062916    Objective Loss 2.062916                                        LR 0.001000    Time 0.529643    
2024-05-04 17:07:35,375 - Epoch: [5][  200/  217]    Overall Loss 2.077463    Objective Loss 2.077463                                        LR 0.001000    Time 0.474014    
2024-05-04 17:07:42,339 - Epoch: [5][  217/  217]    Overall Loss 2.072736    Objective Loss 2.072736    Top1 47.540984    Top5 70.491803    LR 0.001000    Time 0.468964    
2024-05-04 17:07:42,461 - --- validate (epoch=5)-----------
2024-05-04 17:07:42,461 - 1736 samples (32 per mini-batch)
2024-05-04 17:08:11,788 - Epoch: [5][   55/   55]    Loss 2.313011    Top1 47.868664    Top5 65.034562    
2024-05-04 17:08:11,895 - ==> Top1: 47.869    Top5: 65.035    Loss: 2.313

2024-05-04 17:08:11,901 - ==> Best [Top1: 47.869   Top5: 65.035   Sparsity:0.00   Params: 384080 on epoch: 5]
2024-05-04 17:08:11,901 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:08:11,978 - 

2024-05-04 17:08:11,978 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:09:03,473 - Epoch: [6][  100/  217]    Overall Loss 1.848731    Objective Loss 1.848731                                        LR 0.001000    Time 0.514886    
2024-05-04 17:10:01,243 - Epoch: [6][  200/  217]    Overall Loss 1.843534    Objective Loss 1.843534                                        LR 0.001000    Time 0.546265    
2024-05-04 17:10:08,300 - Epoch: [6][  217/  217]    Overall Loss 1.836163    Objective Loss 1.836163    Top1 59.016393    Top5 81.967213    LR 0.001000    Time 0.535986    
2024-05-04 17:10:08,401 - --- validate (epoch=6)-----------
2024-05-04 17:10:08,402 - 1736 samples (32 per mini-batch)
2024-05-04 17:10:39,113 - Epoch: [6][   55/   55]    Loss 2.174919    Top1 49.884793    Top5 68.721198    
2024-05-04 17:10:39,246 - ==> Top1: 49.885    Top5: 68.721    Loss: 2.175

2024-05-04 17:10:39,252 - ==> Best [Top1: 49.885   Top5: 68.721   Sparsity:0.00   Params: 384080 on epoch: 6]
2024-05-04 17:10:39,252 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:10:39,323 - 

2024-05-04 17:10:39,323 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:11:33,401 - Epoch: [7][  100/  217]    Overall Loss 1.607008    Objective Loss 1.607008                                        LR 0.001000    Time 0.540710    
2024-05-04 17:12:18,816 - Epoch: [7][  200/  217]    Overall Loss 1.605733    Objective Loss 1.605733                                        LR 0.001000    Time 0.497405    
2024-05-04 17:12:26,448 - Epoch: [7][  217/  217]    Overall Loss 1.606238    Objective Loss 1.606238    Top1 52.459016    Top5 78.688525    LR 0.001000    Time 0.493600    
2024-05-04 17:12:26,583 - --- validate (epoch=7)-----------
2024-05-04 17:12:26,583 - 1736 samples (32 per mini-batch)
2024-05-04 17:12:57,833 - Epoch: [7][   55/   55]    Loss 2.235432    Top1 49.366359    Top5 66.935484    
2024-05-04 17:12:57,959 - ==> Top1: 49.366    Top5: 66.935    Loss: 2.235

2024-05-04 17:12:57,963 - ==> Best [Top1: 49.885   Top5: 68.721   Sparsity:0.00   Params: 384080 on epoch: 6]
2024-05-04 17:12:57,964 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:12:58,005 - 

2024-05-04 17:12:58,005 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:13:51,271 - Epoch: [8][  100/  217]    Overall Loss 1.340753    Objective Loss 1.340753                                        LR 0.001000    Time 0.532597    
2024-05-04 17:14:40,300 - Epoch: [8][  200/  217]    Overall Loss 1.392373    Objective Loss 1.392373                                        LR 0.001000    Time 0.511421    
2024-05-04 17:14:48,015 - Epoch: [8][  217/  217]    Overall Loss 1.393472    Objective Loss 1.393472    Top1 62.295082    Top5 83.606557    LR 0.001000    Time 0.506899    
2024-05-04 17:14:48,133 - --- validate (epoch=8)-----------
2024-05-04 17:14:48,133 - 1736 samples (32 per mini-batch)
2024-05-04 17:15:13,730 - Epoch: [8][   55/   55]    Loss 2.112030    Top1 51.152074    Top5 69.873272    
2024-05-04 17:15:13,848 - ==> Top1: 51.152    Top5: 69.873    Loss: 2.112

2024-05-04 17:15:13,854 - ==> Best [Top1: 51.152   Top5: 69.873   Sparsity:0.00   Params: 384080 on epoch: 8]
2024-05-04 17:15:13,854 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:15:13,927 - 

2024-05-04 17:15:13,927 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:16:06,110 - Epoch: [9][  100/  217]    Overall Loss 1.160334    Objective Loss 1.160334                                        LR 0.001000    Time 0.521760    
2024-05-04 17:16:56,647 - Epoch: [9][  200/  217]    Overall Loss 1.199547    Objective Loss 1.199547                                        LR 0.001000    Time 0.513538    
2024-05-04 17:17:03,093 - Epoch: [9][  217/  217]    Overall Loss 1.193599    Objective Loss 1.193599    Top1 77.049180    Top5 91.803279    LR 0.001000    Time 0.503009    
2024-05-04 17:17:03,209 - --- validate (epoch=9)-----------
2024-05-04 17:17:03,209 - 1736 samples (32 per mini-batch)
2024-05-04 17:17:34,357 - Epoch: [9][   55/   55]    Loss 2.089992    Top1 52.592166    Top5 70.103687    
2024-05-04 17:17:34,464 - ==> Top1: 52.592    Top5: 70.104    Loss: 2.090

2024-05-04 17:17:34,470 - ==> Best [Top1: 52.592   Top5: 70.104   Sparsity:0.00   Params: 384080 on epoch: 9]
2024-05-04 17:17:34,470 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:17:34,543 - 

2024-05-04 17:17:34,544 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:18:22,090 - Epoch: [10][  100/  217]    Overall Loss 0.962175    Objective Loss 0.962175                                        LR 0.001000    Time 0.475394    
2024-05-04 17:19:19,460 - Epoch: [10][  200/  217]    Overall Loss 0.989900    Objective Loss 0.989900                                        LR 0.001000    Time 0.524523    
2024-05-04 17:19:27,922 - Epoch: [10][  217/  217]    Overall Loss 0.994092    Objective Loss 0.994092    Top1 70.491803    Top5 90.163934    LR 0.001000    Time 0.522422    
2024-05-04 17:19:28,023 - --- validate (epoch=10)-----------
2024-05-04 17:19:28,024 - 1736 samples (32 per mini-batch)
2024-05-04 17:19:58,850 - Epoch: [10][   55/   55]    Loss 2.068998    Top1 52.995392    Top5 71.025346    
2024-05-04 17:19:58,980 - ==> Top1: 52.995    Top5: 71.025    Loss: 2.069

2024-05-04 17:19:58,986 - ==> Best [Top1: 52.995   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 10]
2024-05-04 17:19:58,987 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:19:59,062 - 

2024-05-04 17:19:59,062 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:20:48,321 - Epoch: [11][  100/  217]    Overall Loss 0.776428    Objective Loss 0.776428                                        LR 0.001000    Time 0.492520    
2024-05-04 17:21:36,620 - Epoch: [11][  200/  217]    Overall Loss 0.801979    Objective Loss 0.801979                                        LR 0.001000    Time 0.487731    
2024-05-04 17:21:44,451 - Epoch: [11][  217/  217]    Overall Loss 0.813950    Objective Loss 0.813950    Top1 81.967213    Top5 95.081967    LR 0.001000    Time 0.485601    
2024-05-04 17:21:44,571 - --- validate (epoch=11)-----------
2024-05-04 17:21:44,572 - 1736 samples (32 per mini-batch)
2024-05-04 17:22:12,920 - Epoch: [11][   55/   55]    Loss 2.159332    Top1 51.785714    Top5 70.276498    
2024-05-04 17:22:13,040 - ==> Top1: 51.786    Top5: 70.276    Loss: 2.159

2024-05-04 17:22:13,046 - ==> Best [Top1: 52.995   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 10]
2024-05-04 17:22:13,046 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:22:13,110 - 

2024-05-04 17:22:13,111 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:23:03,695 - Epoch: [12][  100/  217]    Overall Loss 0.612025    Objective Loss 0.612025                                        LR 0.001000    Time 0.505776    
2024-05-04 17:23:55,864 - Epoch: [12][  200/  217]    Overall Loss 0.630694    Objective Loss 0.630694                                        LR 0.001000    Time 0.513703    
2024-05-04 17:24:04,839 - Epoch: [12][  217/  217]    Overall Loss 0.644197    Objective Loss 0.644197    Top1 73.770492    Top5 93.442623    LR 0.001000    Time 0.514812    
2024-05-04 17:24:04,970 - --- validate (epoch=12)-----------
2024-05-04 17:24:04,971 - 1736 samples (32 per mini-batch)
2024-05-04 17:24:33,309 - Epoch: [12][   55/   55]    Loss 2.162492    Top1 51.670507    Top5 70.794931    
2024-05-04 17:24:33,407 - ==> Top1: 51.671    Top5: 70.795    Loss: 2.162

2024-05-04 17:24:33,413 - ==> Best [Top1: 52.995   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 10]
2024-05-04 17:24:33,413 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:24:33,477 - 

2024-05-04 17:24:33,477 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:25:26,368 - Epoch: [13][  100/  217]    Overall Loss 0.491969    Objective Loss 0.491969                                        LR 0.001000    Time 0.528833    
2024-05-04 17:26:13,122 - Epoch: [13][  200/  217]    Overall Loss 0.529938    Objective Loss 0.529938                                        LR 0.001000    Time 0.498160    
2024-05-04 17:26:19,197 - Epoch: [13][  217/  217]    Overall Loss 0.532562    Objective Loss 0.532562    Top1 83.606557    Top5 96.721311    LR 0.001000    Time 0.487121    
2024-05-04 17:26:19,330 - --- validate (epoch=13)-----------
2024-05-04 17:26:19,330 - 1736 samples (32 per mini-batch)
2024-05-04 17:26:51,062 - Epoch: [13][   55/   55]    Loss 2.090559    Top1 53.398618    Top5 71.947005    
2024-05-04 17:26:51,190 - ==> Top1: 53.399    Top5: 71.947    Loss: 2.091

2024-05-04 17:26:51,196 - ==> Best [Top1: 53.399   Top5: 71.947   Sparsity:0.00   Params: 384080 on epoch: 13]
2024-05-04 17:26:51,196 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:26:51,268 - 

2024-05-04 17:26:51,269 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:27:45,957 - Epoch: [14][  100/  217]    Overall Loss 0.400452    Objective Loss 0.400452                                        LR 0.001000    Time 0.546805    
2024-05-04 17:28:29,679 - Epoch: [14][  200/  217]    Overall Loss 0.406294    Objective Loss 0.406294                                        LR 0.001000    Time 0.491988    
2024-05-04 17:28:36,397 - Epoch: [14][  217/  217]    Overall Loss 0.412204    Objective Loss 0.412204    Top1 93.442623    Top5 98.360656    LR 0.001000    Time 0.484400    
2024-05-04 17:28:36,506 - --- validate (epoch=14)-----------
2024-05-04 17:28:36,507 - 1736 samples (32 per mini-batch)
2024-05-04 17:29:01,537 - Epoch: [14][   55/   55]    Loss 2.214240    Top1 51.843318    Top5 70.794931    
2024-05-04 17:29:01,647 - ==> Top1: 51.843    Top5: 70.795    Loss: 2.214

2024-05-04 17:29:01,652 - ==> Best [Top1: 53.399   Top5: 71.947   Sparsity:0.00   Params: 384080 on epoch: 13]
2024-05-04 17:29:01,652 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:29:01,695 - 

2024-05-04 17:29:01,696 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:30:04,321 - Epoch: [15][  100/  217]    Overall Loss 0.273998    Objective Loss 0.273998                                        LR 0.001000    Time 0.626170    
2024-05-04 17:30:52,930 - Epoch: [15][  200/  217]    Overall Loss 0.281033    Objective Loss 0.281033                                        LR 0.001000    Time 0.556106    
2024-05-04 17:30:58,254 - Epoch: [15][  217/  217]    Overall Loss 0.287965    Objective Loss 0.287965    Top1 98.360656    Top5 100.000000    LR 0.001000    Time 0.537068    
2024-05-04 17:30:58,417 - --- validate (epoch=15)-----------
2024-05-04 17:30:58,418 - 1736 samples (32 per mini-batch)
2024-05-04 17:31:26,596 - Epoch: [15][   55/   55]    Loss 2.177002    Top1 53.974654    Top5 71.313364    
2024-05-04 17:31:26,710 - ==> Top1: 53.975    Top5: 71.313    Loss: 2.177

2024-05-04 17:31:26,716 - ==> Best [Top1: 53.975   Top5: 71.313   Sparsity:0.00   Params: 384080 on epoch: 15]
2024-05-04 17:31:26,716 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:31:26,768 - 

2024-05-04 17:31:26,768 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:32:18,804 - Epoch: [16][  100/  217]    Overall Loss 0.218369    Objective Loss 0.218369                                        LR 0.001000    Time 0.520292    
2024-05-04 17:33:05,300 - Epoch: [16][  200/  217]    Overall Loss 0.224654    Objective Loss 0.224654                                        LR 0.001000    Time 0.492603    
2024-05-04 17:33:16,044 - Epoch: [16][  217/  217]    Overall Loss 0.227700    Objective Loss 0.227700    Top1 93.442623    Top5 100.000000    LR 0.001000    Time 0.503516    
2024-05-04 17:33:16,182 - --- validate (epoch=16)-----------
2024-05-04 17:33:16,183 - 1736 samples (32 per mini-batch)
2024-05-04 17:33:46,682 - Epoch: [16][   55/   55]    Loss 2.235648    Top1 52.995392    Top5 70.967742    
2024-05-04 17:33:46,822 - ==> Top1: 52.995    Top5: 70.968    Loss: 2.236

2024-05-04 17:33:46,826 - ==> Best [Top1: 53.975   Top5: 71.313   Sparsity:0.00   Params: 384080 on epoch: 15]
2024-05-04 17:33:46,826 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:33:46,873 - 

2024-05-04 17:33:46,873 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:34:42,961 - Epoch: [17][  100/  217]    Overall Loss 0.149393    Objective Loss 0.149393                                        LR 0.001000    Time 0.560818    
2024-05-04 17:35:32,519 - Epoch: [17][  200/  217]    Overall Loss 0.158057    Objective Loss 0.158057                                        LR 0.001000    Time 0.528171    
2024-05-04 17:35:40,039 - Epoch: [17][  217/  217]    Overall Loss 0.161451    Objective Loss 0.161451    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.521442    
2024-05-04 17:35:40,216 - --- validate (epoch=17)-----------
2024-05-04 17:35:40,216 - 1736 samples (32 per mini-batch)
2024-05-04 17:36:07,283 - Epoch: [17][   55/   55]    Loss 2.276153    Top1 53.341014    Top5 71.198157    
2024-05-04 17:36:07,425 - ==> Top1: 53.341    Top5: 71.198    Loss: 2.276

2024-05-04 17:36:07,432 - ==> Best [Top1: 53.975   Top5: 71.313   Sparsity:0.00   Params: 384080 on epoch: 15]
2024-05-04 17:36:07,432 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:36:07,498 - 

2024-05-04 17:36:07,499 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:37:00,841 - Epoch: [18][  100/  217]    Overall Loss 0.118141    Objective Loss 0.118141                                        LR 0.001000    Time 0.533350    
2024-05-04 17:37:52,205 - Epoch: [18][  200/  217]    Overall Loss 0.117858    Objective Loss 0.117858                                        LR 0.001000    Time 0.523468    
2024-05-04 17:37:59,905 - Epoch: [18][  217/  217]    Overall Loss 0.116276    Objective Loss 0.116276    Top1 96.721311    Top5 100.000000    LR 0.001000    Time 0.517935    
2024-05-04 17:38:00,141 - --- validate (epoch=18)-----------
2024-05-04 17:38:00,142 - 1736 samples (32 per mini-batch)
2024-05-04 17:38:32,048 - Epoch: [18][   55/   55]    Loss 2.265818    Top1 55.357143    Top5 71.370968    
2024-05-04 17:38:32,240 - ==> Top1: 55.357    Top5: 71.371    Loss: 2.266

2024-05-04 17:38:32,244 - ==> Best [Top1: 55.357   Top5: 71.371   Sparsity:0.00   Params: 384080 on epoch: 18]
2024-05-04 17:38:32,245 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:38:32,294 - 

2024-05-04 17:38:32,295 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:39:28,097 - Epoch: [19][  100/  217]    Overall Loss 0.079961    Objective Loss 0.079961                                        LR 0.001000    Time 0.557951    
2024-05-04 17:40:18,089 - Epoch: [19][  200/  217]    Overall Loss 0.078439    Objective Loss 0.078439                                        LR 0.001000    Time 0.528913    
2024-05-04 17:40:23,815 - Epoch: [19][  217/  217]    Overall Loss 0.079091    Objective Loss 0.079091    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.513856    
2024-05-04 17:40:23,945 - --- validate (epoch=19)-----------
2024-05-04 17:40:23,946 - 1736 samples (32 per mini-batch)
2024-05-04 17:40:54,785 - Epoch: [19][   55/   55]    Loss 2.277039    Top1 54.608295    Top5 72.235023    
2024-05-04 17:40:54,937 - ==> Top1: 54.608    Top5: 72.235    Loss: 2.277

2024-05-04 17:40:54,943 - ==> Best [Top1: 55.357   Top5: 71.371   Sparsity:0.00   Params: 384080 on epoch: 18]
2024-05-04 17:40:54,943 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:40:55,007 - 

2024-05-04 17:40:55,007 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:41:48,676 - Epoch: [20][  100/  217]    Overall Loss 0.057319    Objective Loss 0.057319                                        LR 0.001000    Time 0.536616    
2024-05-04 17:42:42,615 - Epoch: [20][  200/  217]    Overall Loss 0.057715    Objective Loss 0.057715                                        LR 0.001000    Time 0.537975    
2024-05-04 17:42:49,153 - Epoch: [20][  217/  217]    Overall Loss 0.057766    Objective Loss 0.057766    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.525950    
2024-05-04 17:42:49,388 - --- validate (epoch=20)-----------
2024-05-04 17:42:49,388 - 1736 samples (32 per mini-batch)
2024-05-04 17:43:19,587 - Epoch: [20][   55/   55]    Loss 2.217042    Top1 55.875576    Top5 72.235023    
2024-05-04 17:43:19,733 - ==> Top1: 55.876    Top5: 72.235    Loss: 2.217

2024-05-04 17:43:19,738 - ==> Best [Top1: 55.876   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 20]
2024-05-04 17:43:19,739 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:43:19,797 - 

2024-05-04 17:43:19,798 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:44:16,350 - Epoch: [21][  100/  217]    Overall Loss 0.041198    Objective Loss 0.041198                                        LR 0.001000    Time 0.565459    
2024-05-04 17:45:06,818 - Epoch: [21][  200/  217]    Overall Loss 0.045489    Objective Loss 0.045489                                        LR 0.001000    Time 0.535040    
2024-05-04 17:45:15,530 - Epoch: [21][  217/  217]    Overall Loss 0.046211    Objective Loss 0.046211    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.533266    
2024-05-04 17:45:15,725 - --- validate (epoch=21)-----------
2024-05-04 17:45:15,725 - 1736 samples (32 per mini-batch)
2024-05-04 17:45:45,274 - Epoch: [21][   55/   55]    Loss 2.378042    Top1 55.126728    Top5 71.140553    
2024-05-04 17:45:45,425 - ==> Top1: 55.127    Top5: 71.141    Loss: 2.378

2024-05-04 17:45:45,430 - ==> Best [Top1: 55.876   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 20]
2024-05-04 17:45:45,431 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:45:45,481 - 

2024-05-04 17:45:45,481 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:46:39,144 - Epoch: [22][  100/  217]    Overall Loss 0.038969    Objective Loss 0.038969                                        LR 0.001000    Time 0.536568    
2024-05-04 17:47:24,554 - Epoch: [22][  200/  217]    Overall Loss 0.041528    Objective Loss 0.041528                                        LR 0.001000    Time 0.495289    
2024-05-04 17:47:31,612 - Epoch: [22][  217/  217]    Overall Loss 0.041899    Objective Loss 0.041899    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.489008    
2024-05-04 17:47:31,738 - --- validate (epoch=22)-----------
2024-05-04 17:47:31,738 - 1736 samples (32 per mini-batch)
2024-05-04 17:48:02,307 - Epoch: [22][   55/   55]    Loss 2.300448    Top1 55.299539    Top5 72.119816    
2024-05-04 17:48:02,443 - ==> Top1: 55.300    Top5: 72.120    Loss: 2.300

2024-05-04 17:48:02,450 - ==> Best [Top1: 55.876   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 20]
2024-05-04 17:48:02,450 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:48:02,519 - 

2024-05-04 17:48:02,519 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:48:56,598 - Epoch: [23][  100/  217]    Overall Loss 0.036052    Objective Loss 0.036052                                        LR 0.001000    Time 0.540715    
2024-05-04 17:49:51,066 - Epoch: [23][  200/  217]    Overall Loss 0.038222    Objective Loss 0.038222                                        LR 0.001000    Time 0.542670    
2024-05-04 17:50:00,872 - Epoch: [23][  217/  217]    Overall Loss 0.040261    Objective Loss 0.040261    Top1 98.360656    Top5 100.000000    LR 0.001000    Time 0.545338    
2024-05-04 17:50:01,043 - --- validate (epoch=23)-----------
2024-05-04 17:50:01,044 - 1736 samples (32 per mini-batch)
2024-05-04 17:50:29,482 - Epoch: [23][   55/   55]    Loss 2.421294    Top1 54.089862    Top5 71.140553    
2024-05-04 17:50:29,610 - ==> Top1: 54.090    Top5: 71.141    Loss: 2.421

2024-05-04 17:50:29,616 - ==> Best [Top1: 55.876   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 20]
2024-05-04 17:50:29,616 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:50:29,680 - 

2024-05-04 17:50:29,681 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:51:23,311 - Epoch: [24][  100/  217]    Overall Loss 0.153202    Objective Loss 0.153202                                        LR 0.001000    Time 0.536234    
2024-05-04 17:52:14,071 - Epoch: [24][  200/  217]    Overall Loss 0.516031    Objective Loss 0.516031                                        LR 0.001000    Time 0.521891    
2024-05-04 17:52:20,439 - Epoch: [24][  217/  217]    Overall Loss 0.551064    Objective Loss 0.551064    Top1 68.852459    Top5 85.245902    LR 0.001000    Time 0.510345    
2024-05-04 17:52:20,550 - --- validate (epoch=24)-----------
2024-05-04 17:52:20,550 - 1736 samples (32 per mini-batch)
2024-05-04 17:52:45,230 - Epoch: [24][   55/   55]    Loss 2.660226    Top1 47.465438    Top5 67.050691    
2024-05-04 17:52:45,332 - ==> Top1: 47.465    Top5: 67.051    Loss: 2.660

2024-05-04 17:52:45,338 - ==> Best [Top1: 55.876   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 20]
2024-05-04 17:52:45,339 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:52:45,397 - 

2024-05-04 17:52:45,398 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:53:36,177 - Epoch: [25][  100/  217]    Overall Loss 0.547941    Objective Loss 0.547941                                        LR 0.001000    Time 0.507724    
2024-05-04 17:54:29,949 - Epoch: [25][  200/  217]    Overall Loss 0.499247    Objective Loss 0.499247                                        LR 0.001000    Time 0.522699    
2024-05-04 17:54:38,363 - Epoch: [25][  217/  217]    Overall Loss 0.488520    Objective Loss 0.488520    Top1 85.245902    Top5 100.000000    LR 0.001000    Time 0.520521    
2024-05-04 17:54:38,474 - --- validate (epoch=25)-----------
2024-05-04 17:54:38,475 - 1736 samples (32 per mini-batch)
2024-05-04 17:55:07,016 - Epoch: [25][   55/   55]    Loss 2.396741    Top1 53.398618    Top5 70.622120    
2024-05-04 17:55:07,132 - ==> Top1: 53.399    Top5: 70.622    Loss: 2.397

2024-05-04 17:55:07,136 - ==> Best [Top1: 55.876   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 20]
2024-05-04 17:55:07,136 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:55:07,180 - 

2024-05-04 17:55:07,181 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:55:49,680 - Epoch: [26][  100/  217]    Overall Loss 0.172829    Objective Loss 0.172829                                        LR 0.001000    Time 0.424937    
2024-05-04 17:56:39,066 - Epoch: [26][  200/  217]    Overall Loss 0.163850    Objective Loss 0.163850                                        LR 0.001000    Time 0.459367    
2024-05-04 17:56:44,803 - Epoch: [26][  217/  217]    Overall Loss 0.163241    Objective Loss 0.163241    Top1 95.081967    Top5 100.000000    LR 0.001000    Time 0.449814    
2024-05-04 17:56:44,926 - --- validate (epoch=26)-----------
2024-05-04 17:56:44,926 - 1736 samples (32 per mini-batch)
2024-05-04 17:57:15,712 - Epoch: [26][   55/   55]    Loss 2.355759    Top1 54.089862    Top5 72.119816    
2024-05-04 17:57:15,840 - ==> Top1: 54.090    Top5: 72.120    Loss: 2.356

2024-05-04 17:57:15,847 - ==> Best [Top1: 55.876   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 20]
2024-05-04 17:57:15,847 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:57:15,912 - 

2024-05-04 17:57:15,912 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 17:58:10,025 - Epoch: [27][  100/  217]    Overall Loss 0.066780    Objective Loss 0.066780                                        LR 0.001000    Time 0.541053    
2024-05-04 17:59:01,163 - Epoch: [27][  200/  217]    Overall Loss 0.058772    Objective Loss 0.058772                                        LR 0.001000    Time 0.526192    
2024-05-04 17:59:06,640 - Epoch: [27][  217/  217]    Overall Loss 0.058069    Objective Loss 0.058069    Top1 96.721311    Top5 100.000000    LR 0.001000    Time 0.510201    
2024-05-04 17:59:06,764 - --- validate (epoch=27)-----------
2024-05-04 17:59:06,765 - 1736 samples (32 per mini-batch)
2024-05-04 17:59:33,947 - Epoch: [27][   55/   55]    Loss 2.319128    Top1 56.221198    Top5 73.329493    
2024-05-04 17:59:34,046 - ==> Top1: 56.221    Top5: 73.329    Loss: 2.319

2024-05-04 17:59:34,050 - ==> Best [Top1: 56.221   Top5: 73.329   Sparsity:0.00   Params: 384080 on epoch: 27]
2024-05-04 17:59:34,050 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 17:59:34,099 - 

2024-05-04 17:59:34,099 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:00:23,390 - Epoch: [28][  100/  217]    Overall Loss 0.027596    Objective Loss 0.027596                                        LR 0.001000    Time 0.492846    
2024-05-04 18:01:12,190 - Epoch: [28][  200/  217]    Overall Loss 0.030314    Objective Loss 0.030314                                        LR 0.001000    Time 0.490397    
2024-05-04 18:01:18,479 - Epoch: [28][  217/  217]    Overall Loss 0.030345    Objective Loss 0.030345    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.480957    
2024-05-04 18:01:18,590 - --- validate (epoch=28)-----------
2024-05-04 18:01:18,590 - 1736 samples (32 per mini-batch)
2024-05-04 18:01:52,708 - Epoch: [28][   55/   55]    Loss 2.343780    Top1 55.933180    Top5 71.716590    
2024-05-04 18:01:52,833 - ==> Top1: 55.933    Top5: 71.717    Loss: 2.344

2024-05-04 18:01:52,839 - ==> Best [Top1: 56.221   Top5: 73.329   Sparsity:0.00   Params: 384080 on epoch: 27]
2024-05-04 18:01:52,840 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:01:52,906 - 

2024-05-04 18:01:52,907 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:02:50,440 - Epoch: [29][  100/  217]    Overall Loss 0.023479    Objective Loss 0.023479                                        LR 0.001000    Time 0.575259    
2024-05-04 18:03:32,774 - Epoch: [29][  200/  217]    Overall Loss 0.021705    Objective Loss 0.021705                                        LR 0.001000    Time 0.499278    
2024-05-04 18:03:41,639 - Epoch: [29][  217/  217]    Overall Loss 0.021355    Objective Loss 0.021355    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.501009    
2024-05-04 18:03:41,835 - --- validate (epoch=29)-----------
2024-05-04 18:03:41,835 - 1736 samples (32 per mini-batch)
2024-05-04 18:04:11,433 - Epoch: [29][   55/   55]    Loss 2.283670    Top1 55.760369    Top5 73.271889    
2024-05-04 18:04:11,550 - ==> Top1: 55.760    Top5: 73.272    Loss: 2.284

2024-05-04 18:04:11,556 - ==> Best [Top1: 56.221   Top5: 73.329   Sparsity:0.00   Params: 384080 on epoch: 27]
2024-05-04 18:04:11,557 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:04:11,619 - 

2024-05-04 18:04:11,619 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:05:01,526 - Epoch: [30][  100/  217]    Overall Loss 0.015583    Objective Loss 0.015583                                        LR 0.001000    Time 0.498997    
2024-05-04 18:05:51,774 - Epoch: [30][  200/  217]    Overall Loss 0.015997    Objective Loss 0.015997                                        LR 0.001000    Time 0.500713    
2024-05-04 18:05:58,355 - Epoch: [30][  217/  217]    Overall Loss 0.016347    Objective Loss 0.016347    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.491806    
2024-05-04 18:05:58,486 - --- validate (epoch=30)-----------
2024-05-04 18:05:58,486 - 1736 samples (32 per mini-batch)
2024-05-04 18:06:27,802 - Epoch: [30][   55/   55]    Loss 2.332879    Top1 55.933180    Top5 73.156682    
2024-05-04 18:06:27,938 - ==> Top1: 55.933    Top5: 73.157    Loss: 2.333

2024-05-04 18:06:27,945 - ==> Best [Top1: 56.221   Top5: 73.329   Sparsity:0.00   Params: 384080 on epoch: 27]
2024-05-04 18:06:27,945 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:06:28,005 - 

2024-05-04 18:06:28,006 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:07:18,614 - Epoch: [31][  100/  217]    Overall Loss 0.010913    Objective Loss 0.010913                                        LR 0.001000    Time 0.506010    
2024-05-04 18:08:08,834 - Epoch: [31][  200/  217]    Overall Loss 0.012504    Objective Loss 0.012504                                        LR 0.001000    Time 0.504070    
2024-05-04 18:08:15,781 - Epoch: [31][  217/  217]    Overall Loss 0.012254    Objective Loss 0.012254    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.496587    
2024-05-04 18:08:15,890 - --- validate (epoch=31)-----------
2024-05-04 18:08:15,890 - 1736 samples (32 per mini-batch)
2024-05-04 18:08:42,695 - Epoch: [31][   55/   55]    Loss 2.377366    Top1 56.048387    Top5 73.271889    
2024-05-04 18:08:42,849 - ==> Top1: 56.048    Top5: 73.272    Loss: 2.377

2024-05-04 18:08:42,853 - ==> Best [Top1: 56.221   Top5: 73.329   Sparsity:0.00   Params: 384080 on epoch: 27]
2024-05-04 18:08:42,853 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:08:42,894 - 

2024-05-04 18:08:42,895 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:09:36,212 - Epoch: [32][  100/  217]    Overall Loss 0.009199    Objective Loss 0.009199                                        LR 0.001000    Time 0.533110    
2024-05-04 18:10:28,130 - Epoch: [32][  200/  217]    Overall Loss 0.010506    Objective Loss 0.010506                                        LR 0.001000    Time 0.526092    
2024-05-04 18:10:37,645 - Epoch: [32][  217/  217]    Overall Loss 0.010537    Objective Loss 0.010537    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.528716    
2024-05-04 18:10:37,809 - --- validate (epoch=32)-----------
2024-05-04 18:10:37,809 - 1736 samples (32 per mini-batch)
2024-05-04 18:11:04,711 - Epoch: [32][   55/   55]    Loss 2.415130    Top1 55.990783    Top5 72.983871    
2024-05-04 18:11:04,860 - ==> Top1: 55.991    Top5: 72.984    Loss: 2.415

2024-05-04 18:11:04,866 - ==> Best [Top1: 56.221   Top5: 73.329   Sparsity:0.00   Params: 384080 on epoch: 27]
2024-05-04 18:11:04,866 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:11:04,933 - 

2024-05-04 18:11:04,933 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:11:53,466 - Epoch: [33][  100/  217]    Overall Loss 0.011139    Objective Loss 0.011139                                        LR 0.001000    Time 0.485250    
2024-05-04 18:12:44,859 - Epoch: [33][  200/  217]    Overall Loss 0.010551    Objective Loss 0.010551                                        LR 0.001000    Time 0.499568    
2024-05-04 18:12:51,139 - Epoch: [33][  217/  217]    Overall Loss 0.010555    Objective Loss 0.010555    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.489365    
2024-05-04 18:12:51,287 - --- validate (epoch=33)-----------
2024-05-04 18:12:51,287 - 1736 samples (32 per mini-batch)
2024-05-04 18:13:22,052 - Epoch: [33][   55/   55]    Loss 2.404103    Top1 55.184332    Top5 72.983871    
2024-05-04 18:13:22,233 - ==> Top1: 55.184    Top5: 72.984    Loss: 2.404

2024-05-04 18:13:22,239 - ==> Best [Top1: 56.221   Top5: 73.329   Sparsity:0.00   Params: 384080 on epoch: 27]
2024-05-04 18:13:22,239 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:13:22,303 - 

2024-05-04 18:13:22,303 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:14:14,535 - Epoch: [34][  100/  217]    Overall Loss 0.008518    Objective Loss 0.008518                                        LR 0.001000    Time 0.522244    
2024-05-04 18:15:01,399 - Epoch: [34][  200/  217]    Overall Loss 0.008685    Objective Loss 0.008685                                        LR 0.001000    Time 0.495413    
2024-05-04 18:15:09,770 - Epoch: [34][  217/  217]    Overall Loss 0.008555    Objective Loss 0.008555    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.495175    
2024-05-04 18:15:09,927 - --- validate (epoch=34)-----------
2024-05-04 18:15:09,927 - 1736 samples (32 per mini-batch)
2024-05-04 18:15:39,772 - Epoch: [34][   55/   55]    Loss 2.398904    Top1 55.529954    Top5 73.156682    
2024-05-04 18:15:39,912 - ==> Top1: 55.530    Top5: 73.157    Loss: 2.399

2024-05-04 18:15:39,917 - ==> Best [Top1: 56.221   Top5: 73.329   Sparsity:0.00   Params: 384080 on epoch: 27]
2024-05-04 18:15:39,917 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:15:39,962 - 

2024-05-04 18:15:39,962 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:16:30,546 - Epoch: [35][  100/  217]    Overall Loss 0.008858    Objective Loss 0.008858                                        LR 0.001000    Time 0.505773    
2024-05-04 18:17:17,070 - Epoch: [35][  200/  217]    Overall Loss 0.008339    Objective Loss 0.008339                                        LR 0.001000    Time 0.485479    
2024-05-04 18:17:25,796 - Epoch: [35][  217/  217]    Overall Loss 0.008267    Objective Loss 0.008267    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.487654    
2024-05-04 18:17:25,941 - --- validate (epoch=35)-----------
2024-05-04 18:17:25,942 - 1736 samples (32 per mini-batch)
2024-05-04 18:17:55,773 - Epoch: [35][   55/   55]    Loss 2.424350    Top1 55.299539    Top5 72.695853    
2024-05-04 18:17:55,897 - ==> Top1: 55.300    Top5: 72.696    Loss: 2.424

2024-05-04 18:17:55,903 - ==> Best [Top1: 56.221   Top5: 73.329   Sparsity:0.00   Params: 384080 on epoch: 27]
2024-05-04 18:17:55,903 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:17:55,966 - 

2024-05-04 18:17:55,967 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:18:48,848 - Epoch: [36][  100/  217]    Overall Loss 0.005678    Objective Loss 0.005678                                        LR 0.001000    Time 0.528740    
2024-05-04 18:19:29,867 - Epoch: [36][  200/  217]    Overall Loss 0.006495    Objective Loss 0.006495                                        LR 0.001000    Time 0.469440    
2024-05-04 18:19:35,762 - Epoch: [36][  217/  217]    Overall Loss 0.006638    Objective Loss 0.006638    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.459821    
2024-05-04 18:19:35,870 - --- validate (epoch=36)-----------
2024-05-04 18:19:35,870 - 1736 samples (32 per mini-batch)
2024-05-04 18:20:07,330 - Epoch: [36][   55/   55]    Loss 2.432626    Top1 55.357143    Top5 72.983871    
2024-05-04 18:20:07,462 - ==> Top1: 55.357    Top5: 72.984    Loss: 2.433

2024-05-04 18:20:07,468 - ==> Best [Top1: 56.221   Top5: 73.329   Sparsity:0.00   Params: 384080 on epoch: 27]
2024-05-04 18:20:07,469 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:20:07,534 - 

2024-05-04 18:20:07,535 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:21:02,218 - Epoch: [37][  100/  217]    Overall Loss 0.007204    Objective Loss 0.007204                                        LR 0.001000    Time 0.546764    
2024-05-04 18:21:47,433 - Epoch: [37][  200/  217]    Overall Loss 0.006553    Objective Loss 0.006553                                        LR 0.001000    Time 0.499431    
2024-05-04 18:21:54,910 - Epoch: [37][  217/  217]    Overall Loss 0.007038    Objective Loss 0.007038    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.494756    
2024-05-04 18:21:55,053 - --- validate (epoch=37)-----------
2024-05-04 18:21:55,053 - 1736 samples (32 per mini-batch)
2024-05-04 18:22:21,751 - Epoch: [37][   55/   55]    Loss 2.535363    Top1 55.587558    Top5 72.638249    
2024-05-04 18:22:21,873 - ==> Top1: 55.588    Top5: 72.638    Loss: 2.535

2024-05-04 18:22:21,879 - ==> Best [Top1: 56.221   Top5: 73.329   Sparsity:0.00   Params: 384080 on epoch: 27]
2024-05-04 18:22:21,879 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:22:21,943 - 

2024-05-04 18:22:21,943 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:23:15,205 - Epoch: [38][  100/  217]    Overall Loss 0.004773    Objective Loss 0.004773                                        LR 0.001000    Time 0.532549    
2024-05-04 18:24:00,855 - Epoch: [38][  200/  217]    Overall Loss 0.005902    Objective Loss 0.005902                                        LR 0.001000    Time 0.494492    
2024-05-04 18:24:09,047 - Epoch: [38][  217/  217]    Overall Loss 0.006075    Objective Loss 0.006075    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.493496    
2024-05-04 18:24:09,151 - --- validate (epoch=38)-----------
2024-05-04 18:24:09,151 - 1736 samples (32 per mini-batch)
2024-05-04 18:24:41,027 - Epoch: [38][   55/   55]    Loss 2.504326    Top1 56.336406    Top5 72.235023    
2024-05-04 18:24:41,152 - ==> Top1: 56.336    Top5: 72.235    Loss: 2.504

2024-05-04 18:24:41,158 - ==> Best [Top1: 56.336   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 38]
2024-05-04 18:24:41,158 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:24:41,233 - 

2024-05-04 18:24:41,233 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:25:36,235 - Epoch: [39][  100/  217]    Overall Loss 0.005196    Objective Loss 0.005196                                        LR 0.001000    Time 0.549943    
2024-05-04 18:26:29,292 - Epoch: [39][  200/  217]    Overall Loss 0.005614    Objective Loss 0.005614                                        LR 0.001000    Time 0.540228    
2024-05-04 18:26:38,945 - Epoch: [39][  217/  217]    Overall Loss 0.005452    Objective Loss 0.005452    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.542382    
2024-05-04 18:26:39,080 - --- validate (epoch=39)-----------
2024-05-04 18:26:39,081 - 1736 samples (32 per mini-batch)
2024-05-04 18:27:07,466 - Epoch: [39][   55/   55]    Loss 2.456875    Top1 55.529954    Top5 72.580645    
2024-05-04 18:27:07,574 - ==> Top1: 55.530    Top5: 72.581    Loss: 2.457

2024-05-04 18:27:07,578 - ==> Best [Top1: 56.336   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 38]
2024-05-04 18:27:07,579 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:27:07,623 - 

2024-05-04 18:27:07,623 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:27:55,907 - Epoch: [40][  100/  217]    Overall Loss 0.005834    Objective Loss 0.005834                                        LR 0.001000    Time 0.482780    
2024-05-04 18:28:41,508 - Epoch: [40][  200/  217]    Overall Loss 0.007836    Objective Loss 0.007836                                        LR 0.001000    Time 0.469367    
2024-05-04 18:28:51,308 - Epoch: [40][  217/  217]    Overall Loss 0.010153    Objective Loss 0.010153    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.477751    
2024-05-04 18:28:51,450 - --- validate (epoch=40)-----------
2024-05-04 18:28:51,451 - 1736 samples (32 per mini-batch)
2024-05-04 18:29:23,021 - Epoch: [40][   55/   55]    Loss 2.862766    Top1 51.382488    Top5 68.490783    
2024-05-04 18:29:23,185 - ==> Top1: 51.382    Top5: 68.491    Loss: 2.863

2024-05-04 18:29:23,191 - ==> Best [Top1: 56.336   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 38]
2024-05-04 18:29:23,192 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:29:23,257 - 

2024-05-04 18:29:23,258 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:30:12,687 - Epoch: [41][  100/  217]    Overall Loss 1.330489    Objective Loss 1.330489                                        LR 0.001000    Time 0.494217    
2024-05-04 18:30:56,358 - Epoch: [41][  200/  217]    Overall Loss 1.281950    Objective Loss 1.281950                                        LR 0.001000    Time 0.465438    
2024-05-04 18:31:05,393 - Epoch: [41][  217/  217]    Overall Loss 1.270067    Objective Loss 1.270067    Top1 73.770492    Top5 95.081967    LR 0.001000    Time 0.470606    
2024-05-04 18:31:05,548 - --- validate (epoch=41)-----------
2024-05-04 18:31:05,549 - 1736 samples (32 per mini-batch)
2024-05-04 18:31:39,797 - Epoch: [41][   55/   55]    Loss 2.503665    Top1 52.304147    Top5 69.527650    
2024-05-04 18:31:39,918 - ==> Top1: 52.304    Top5: 69.528    Loss: 2.504

2024-05-04 18:31:39,922 - ==> Best [Top1: 56.336   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 38]
2024-05-04 18:31:39,923 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:31:39,966 - 

2024-05-04 18:31:39,969 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:32:29,861 - Epoch: [42][  100/  217]    Overall Loss 0.499694    Objective Loss 0.499694                                        LR 0.001000    Time 0.498854    
2024-05-04 18:33:15,423 - Epoch: [42][  200/  217]    Overall Loss 0.440130    Objective Loss 0.440130                                        LR 0.001000    Time 0.477210    
2024-05-04 18:33:23,699 - Epoch: [42][  217/  217]    Overall Loss 0.432942    Objective Loss 0.432942    Top1 81.967213    Top5 98.360656    LR 0.001000    Time 0.477958    
2024-05-04 18:33:23,819 - --- validate (epoch=42)-----------
2024-05-04 18:33:23,819 - 1736 samples (32 per mini-batch)
2024-05-04 18:33:53,276 - Epoch: [42][   55/   55]    Loss 2.322520    Top1 53.744240    Top5 71.774194    
2024-05-04 18:33:53,417 - ==> Top1: 53.744    Top5: 71.774    Loss: 2.323

2024-05-04 18:33:53,424 - ==> Best [Top1: 56.336   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 38]
2024-05-04 18:33:53,424 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:33:53,488 - 

2024-05-04 18:33:53,488 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:34:48,549 - Epoch: [43][  100/  217]    Overall Loss 0.140890    Objective Loss 0.140890                                        LR 0.001000    Time 0.550535    
2024-05-04 18:35:37,865 - Epoch: [43][  200/  217]    Overall Loss 0.131092    Objective Loss 0.131092                                        LR 0.001000    Time 0.521818    
2024-05-04 18:35:48,370 - Epoch: [43][  217/  217]    Overall Loss 0.129494    Objective Loss 0.129494    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.529333    
2024-05-04 18:35:48,510 - --- validate (epoch=43)-----------
2024-05-04 18:35:48,510 - 1736 samples (32 per mini-batch)
2024-05-04 18:36:18,059 - Epoch: [43][   55/   55]    Loss 2.417119    Top1 54.435484    Top5 73.156682    
2024-05-04 18:36:18,192 - ==> Top1: 54.435    Top5: 73.157    Loss: 2.417

2024-05-04 18:36:18,198 - ==> Best [Top1: 56.336   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 38]
2024-05-04 18:36:18,199 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:36:18,262 - 

2024-05-04 18:36:18,263 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:37:18,513 - Epoch: [44][  100/  217]    Overall Loss 0.047949    Objective Loss 0.047949                                        LR 0.001000    Time 0.602435    
2024-05-04 18:38:01,401 - Epoch: [44][  200/  217]    Overall Loss 0.047744    Objective Loss 0.047744                                        LR 0.001000    Time 0.515630    
2024-05-04 18:38:08,710 - Epoch: [44][  217/  217]    Overall Loss 0.048864    Objective Loss 0.048864    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.508912    
2024-05-04 18:38:08,849 - --- validate (epoch=44)-----------
2024-05-04 18:38:08,849 - 1736 samples (32 per mini-batch)
2024-05-04 18:38:38,675 - Epoch: [44][   55/   55]    Loss 2.395034    Top1 55.645161    Top5 73.502304    
2024-05-04 18:38:38,800 - ==> Top1: 55.645    Top5: 73.502    Loss: 2.395

2024-05-04 18:38:38,807 - ==> Best [Top1: 56.336   Top5: 72.235   Sparsity:0.00   Params: 384080 on epoch: 38]
2024-05-04 18:38:38,807 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:38:38,872 - 

2024-05-04 18:38:38,873 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:39:32,258 - Epoch: [45][  100/  217]    Overall Loss 0.026686    Objective Loss 0.026686                                        LR 0.001000    Time 0.533779    
2024-05-04 18:40:19,644 - Epoch: [45][  200/  217]    Overall Loss 0.025159    Objective Loss 0.025159                                        LR 0.001000    Time 0.503796    
2024-05-04 18:40:26,480 - Epoch: [45][  217/  217]    Overall Loss 0.025534    Objective Loss 0.025534    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.495823    
2024-05-04 18:40:26,618 - --- validate (epoch=45)-----------
2024-05-04 18:40:26,618 - 1736 samples (32 per mini-batch)
2024-05-04 18:40:57,735 - Epoch: [45][   55/   55]    Loss 2.346215    Top1 56.394009    Top5 73.675115    
2024-05-04 18:40:57,877 - ==> Top1: 56.394    Top5: 73.675    Loss: 2.346

2024-05-04 18:40:57,884 - ==> Best [Top1: 56.394   Top5: 73.675   Sparsity:0.00   Params: 384080 on epoch: 45]
2024-05-04 18:40:57,884 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:40:57,941 - 

2024-05-04 18:40:57,941 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:41:47,141 - Epoch: [46][  100/  217]    Overall Loss 0.018863    Objective Loss 0.018863                                        LR 0.001000    Time 0.491940    
2024-05-04 18:42:33,352 - Epoch: [46][  200/  217]    Overall Loss 0.018848    Objective Loss 0.018848                                        LR 0.001000    Time 0.476998    
2024-05-04 18:42:40,368 - Epoch: [46][  217/  217]    Overall Loss 0.018800    Objective Loss 0.018800    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.471958    
2024-05-04 18:42:40,477 - --- validate (epoch=46)-----------
2024-05-04 18:42:40,477 - 1736 samples (32 per mini-batch)
2024-05-04 18:43:09,941 - Epoch: [46][   55/   55]    Loss 2.392817    Top1 55.990783    Top5 73.790323    
2024-05-04 18:43:10,108 - ==> Top1: 55.991    Top5: 73.790    Loss: 2.393

2024-05-04 18:43:10,114 - ==> Best [Top1: 56.394   Top5: 73.675   Sparsity:0.00   Params: 384080 on epoch: 45]
2024-05-04 18:43:10,114 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:43:10,178 - 

2024-05-04 18:43:10,179 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:44:09,294 - Epoch: [47][  100/  217]    Overall Loss 0.013691    Objective Loss 0.013691                                        LR 0.001000    Time 0.591089    
2024-05-04 18:45:00,968 - Epoch: [47][  200/  217]    Overall Loss 0.014319    Objective Loss 0.014319                                        LR 0.001000    Time 0.553883    
2024-05-04 18:45:08,589 - Epoch: [47][  217/  217]    Overall Loss 0.014396    Objective Loss 0.014396    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.545608    
2024-05-04 18:45:08,830 - --- validate (epoch=47)-----------
2024-05-04 18:45:08,830 - 1736 samples (32 per mini-batch)
2024-05-04 18:45:37,209 - Epoch: [47][   55/   55]    Loss 2.452204    Top1 56.394009    Top5 72.580645    
2024-05-04 18:45:37,378 - ==> Top1: 56.394    Top5: 72.581    Loss: 2.452

2024-05-04 18:45:37,384 - ==> Best [Top1: 56.394   Top5: 73.675   Sparsity:0.00   Params: 384080 on epoch: 45]
2024-05-04 18:45:37,384 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:45:37,443 - 

2024-05-04 18:45:37,444 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:46:32,543 - Epoch: [48][  100/  217]    Overall Loss 0.011529    Objective Loss 0.011529                                        LR 0.001000    Time 0.550928    
2024-05-04 18:47:22,939 - Epoch: [48][  200/  217]    Overall Loss 0.012216    Objective Loss 0.012216                                        LR 0.001000    Time 0.527413    
2024-05-04 18:47:33,126 - Epoch: [48][  217/  217]    Overall Loss 0.012090    Objective Loss 0.012090    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.533034    
2024-05-04 18:47:33,284 - --- validate (epoch=48)-----------
2024-05-04 18:47:33,284 - 1736 samples (32 per mini-batch)
2024-05-04 18:48:01,010 - Epoch: [48][   55/   55]    Loss 2.417803    Top1 56.336406    Top5 73.041475    
2024-05-04 18:48:01,178 - ==> Top1: 56.336    Top5: 73.041    Loss: 2.418

2024-05-04 18:48:01,185 - ==> Best [Top1: 56.394   Top5: 73.675   Sparsity:0.00   Params: 384080 on epoch: 45]
2024-05-04 18:48:01,185 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:48:01,247 - 

2024-05-04 18:48:01,248 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:48:55,750 - Epoch: [49][  100/  217]    Overall Loss 0.010630    Objective Loss 0.010630                                        LR 0.001000    Time 0.544955    
2024-05-04 18:49:43,027 - Epoch: [49][  200/  217]    Overall Loss 0.010178    Objective Loss 0.010178                                        LR 0.001000    Time 0.508836    
2024-05-04 18:49:52,894 - Epoch: [49][  217/  217]    Overall Loss 0.010491    Objective Loss 0.010491    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.514439    
2024-05-04 18:49:53,061 - --- validate (epoch=49)-----------
2024-05-04 18:49:53,062 - 1736 samples (32 per mini-batch)
2024-05-04 18:50:23,579 - Epoch: [49][   55/   55]    Loss 2.430839    Top1 56.739631    Top5 73.214286    
2024-05-04 18:50:23,726 - ==> Top1: 56.740    Top5: 73.214    Loss: 2.431

2024-05-04 18:50:23,733 - ==> Best [Top1: 56.740   Top5: 73.214   Sparsity:0.00   Params: 384080 on epoch: 49]
2024-05-04 18:50:23,733 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:50:23,969 - 

2024-05-04 18:50:23,969 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:51:16,093 - Epoch: [50][  100/  217]    Overall Loss 0.009131    Objective Loss 0.009131                                        LR 0.001000    Time 0.521163    
2024-05-04 18:52:04,566 - Epoch: [50][  200/  217]    Overall Loss 0.010172    Objective Loss 0.010172                                        LR 0.001000    Time 0.502921    
2024-05-04 18:52:11,521 - Epoch: [50][  217/  217]    Overall Loss 0.010024    Objective Loss 0.010024    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.495568    
2024-05-04 18:52:11,680 - --- validate (epoch=50)-----------
2024-05-04 18:52:11,680 - 1736 samples (32 per mini-batch)
2024-05-04 18:52:42,837 - Epoch: [50][   55/   55]    Loss 2.451987    Top1 56.797235    Top5 72.811060    
2024-05-04 18:52:42,968 - ==> Top1: 56.797    Top5: 72.811    Loss: 2.452

2024-05-04 18:52:42,974 - ==> Best [Top1: 56.797   Top5: 72.811   Sparsity:0.00   Params: 384080 on epoch: 50]
2024-05-04 18:52:42,974 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:52:43,026 - 

2024-05-04 18:52:43,027 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:53:40,249 - Epoch: [51][  100/  217]    Overall Loss 0.006886    Objective Loss 0.006886                                        LR 0.001000    Time 0.572159    
2024-05-04 18:54:23,922 - Epoch: [51][  200/  217]    Overall Loss 0.007781    Objective Loss 0.007781                                        LR 0.001000    Time 0.504419    
2024-05-04 18:54:31,777 - Epoch: [51][  217/  217]    Overall Loss 0.008089    Objective Loss 0.008089    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.501093    
2024-05-04 18:54:31,953 - --- validate (epoch=51)-----------
2024-05-04 18:54:31,953 - 1736 samples (32 per mini-batch)
2024-05-04 18:55:04,040 - Epoch: [51][   55/   55]    Loss 2.483671    Top1 56.451613    Top5 72.695853    
2024-05-04 18:55:04,258 - ==> Top1: 56.452    Top5: 72.696    Loss: 2.484

2024-05-04 18:55:04,262 - ==> Best [Top1: 56.797   Top5: 72.811   Sparsity:0.00   Params: 384080 on epoch: 50]
2024-05-04 18:55:04,262 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:55:04,303 - 

2024-05-04 18:55:04,304 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:55:57,558 - Epoch: [52][  100/  217]    Overall Loss 0.007252    Objective Loss 0.007252                                        LR 0.001000    Time 0.532480    
2024-05-04 18:56:46,446 - Epoch: [52][  200/  217]    Overall Loss 0.007230    Objective Loss 0.007230                                        LR 0.001000    Time 0.510651    
2024-05-04 18:56:54,772 - Epoch: [52][  217/  217]    Overall Loss 0.007546    Objective Loss 0.007546    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.509010    
2024-05-04 18:56:54,944 - --- validate (epoch=52)-----------
2024-05-04 18:56:54,945 - 1736 samples (32 per mini-batch)
2024-05-04 18:57:23,713 - Epoch: [52][   55/   55]    Loss 2.508412    Top1 56.451613    Top5 73.559908    
2024-05-04 18:57:23,852 - ==> Top1: 56.452    Top5: 73.560    Loss: 2.508

2024-05-04 18:57:23,859 - ==> Best [Top1: 56.797   Top5: 72.811   Sparsity:0.00   Params: 384080 on epoch: 50]
2024-05-04 18:57:23,859 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:57:23,922 - 

2024-05-04 18:57:23,922 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 18:58:18,643 - Epoch: [53][  100/  217]    Overall Loss 0.007283    Objective Loss 0.007283                                        LR 0.001000    Time 0.547136    
2024-05-04 18:59:11,998 - Epoch: [53][  200/  217]    Overall Loss 0.007201    Objective Loss 0.007201                                        LR 0.001000    Time 0.540312    
2024-05-04 18:59:19,865 - Epoch: [53][  217/  217]    Overall Loss 0.007194    Objective Loss 0.007194    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.534232    
2024-05-04 18:59:19,987 - --- validate (epoch=53)-----------
2024-05-04 18:59:19,987 - 1736 samples (32 per mini-batch)
2024-05-04 18:59:47,077 - Epoch: [53][   55/   55]    Loss 2.505454    Top1 56.278802    Top5 73.041475    
2024-05-04 18:59:47,189 - ==> Top1: 56.279    Top5: 73.041    Loss: 2.505

2024-05-04 18:59:47,193 - ==> Best [Top1: 56.797   Top5: 72.811   Sparsity:0.00   Params: 384080 on epoch: 50]
2024-05-04 18:59:47,193 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 18:59:47,234 - 

2024-05-04 18:59:47,234 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:00:36,721 - Epoch: [54][  100/  217]    Overall Loss 0.005124    Objective Loss 0.005124                                        LR 0.001000    Time 0.494801    
2024-05-04 19:01:36,473 - Epoch: [54][  200/  217]    Overall Loss 0.005936    Objective Loss 0.005936                                        LR 0.001000    Time 0.546076    
2024-05-04 19:01:43,423 - Epoch: [54][  217/  217]    Overall Loss 0.005773    Objective Loss 0.005773    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.535317    
2024-05-04 19:01:43,566 - --- validate (epoch=54)-----------
2024-05-04 19:01:43,566 - 1736 samples (32 per mini-batch)
2024-05-04 19:02:12,772 - Epoch: [54][   55/   55]    Loss 2.484501    Top1 56.336406    Top5 73.156682    
2024-05-04 19:02:12,945 - ==> Top1: 56.336    Top5: 73.157    Loss: 2.485

2024-05-04 19:02:12,950 - ==> Best [Top1: 56.797   Top5: 72.811   Sparsity:0.00   Params: 384080 on epoch: 50]
2024-05-04 19:02:12,950 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:02:12,995 - 

2024-05-04 19:02:12,995 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:03:00,633 - Epoch: [55][  100/  217]    Overall Loss 0.005956    Objective Loss 0.005956                                        LR 0.001000    Time 0.476310    
2024-05-04 19:03:47,877 - Epoch: [55][  200/  217]    Overall Loss 0.005925    Objective Loss 0.005925                                        LR 0.001000    Time 0.474236    
2024-05-04 19:03:56,337 - Epoch: [55][  217/  217]    Overall Loss 0.005756    Objective Loss 0.005756    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.476063    
2024-05-04 19:03:56,451 - --- validate (epoch=55)-----------
2024-05-04 19:03:56,451 - 1736 samples (32 per mini-batch)
2024-05-04 19:04:25,471 - Epoch: [55][   55/   55]    Loss 2.505117    Top1 57.027650    Top5 73.790323    
2024-05-04 19:04:25,590 - ==> Top1: 57.028    Top5: 73.790    Loss: 2.505

2024-05-04 19:04:25,597 - ==> Best [Top1: 57.028   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 55]
2024-05-04 19:04:25,597 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:04:25,671 - 

2024-05-04 19:04:25,672 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:05:17,604 - Epoch: [56][  100/  217]    Overall Loss 0.006535    Objective Loss 0.006535                                        LR 0.001000    Time 0.519214    
2024-05-04 19:06:04,134 - Epoch: [56][  200/  217]    Overall Loss 0.006349    Objective Loss 0.006349                                        LR 0.001000    Time 0.492228    
2024-05-04 19:06:16,087 - Epoch: [56][  217/  217]    Overall Loss 0.006375    Objective Loss 0.006375    Top1 98.360656    Top5 100.000000    LR 0.001000    Time 0.508748    
2024-05-04 19:06:16,224 - --- validate (epoch=56)-----------
2024-05-04 19:06:16,225 - 1736 samples (32 per mini-batch)
2024-05-04 19:06:44,421 - Epoch: [56][   55/   55]    Loss 2.557042    Top1 55.875576    Top5 72.926267    
2024-05-04 19:06:44,552 - ==> Top1: 55.876    Top5: 72.926    Loss: 2.557

2024-05-04 19:06:44,559 - ==> Best [Top1: 57.028   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 55]
2024-05-04 19:06:44,559 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:06:44,621 - 

2024-05-04 19:06:44,622 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:07:37,764 - Epoch: [57][  100/  217]    Overall Loss 0.006128    Objective Loss 0.006128                                        LR 0.001000    Time 0.531356    
2024-05-04 19:08:21,966 - Epoch: [57][  200/  217]    Overall Loss 0.009713    Objective Loss 0.009713                                        LR 0.001000    Time 0.486663    
2024-05-04 19:08:27,174 - Epoch: [57][  217/  217]    Overall Loss 0.010622    Objective Loss 0.010622    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.472528    
2024-05-04 19:08:27,306 - --- validate (epoch=57)-----------
2024-05-04 19:08:27,306 - 1736 samples (32 per mini-batch)
2024-05-04 19:08:56,825 - Epoch: [57][   55/   55]    Loss 2.875435    Top1 53.341014    Top5 70.449309    
2024-05-04 19:08:56,963 - ==> Top1: 53.341    Top5: 70.449    Loss: 2.875

2024-05-04 19:08:56,969 - ==> Best [Top1: 57.028   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 55]
2024-05-04 19:08:56,969 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:08:57,035 - 

2024-05-04 19:08:57,035 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:09:47,080 - Epoch: [58][  100/  217]    Overall Loss 0.720679    Objective Loss 0.720679                                        LR 0.001000    Time 0.500375    
2024-05-04 19:10:34,952 - Epoch: [58][  200/  217]    Overall Loss 0.892099    Objective Loss 0.892099                                        LR 0.001000    Time 0.489514    
2024-05-04 19:10:40,763 - Epoch: [58][  217/  217]    Overall Loss 0.884499    Objective Loss 0.884499    Top1 68.852459    Top5 88.524590    LR 0.001000    Time 0.477941    
2024-05-04 19:10:40,894 - --- validate (epoch=58)-----------
2024-05-04 19:10:40,895 - 1736 samples (32 per mini-batch)
2024-05-04 19:11:11,614 - Epoch: [58][   55/   55]    Loss 2.685336    Top1 52.361751    Top5 69.642857    
2024-05-04 19:11:11,743 - ==> Top1: 52.362    Top5: 69.643    Loss: 2.685

2024-05-04 19:11:11,750 - ==> Best [Top1: 57.028   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 55]
2024-05-04 19:11:11,750 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:11:11,814 - 

2024-05-04 19:11:11,815 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:12:04,306 - Epoch: [59][  100/  217]    Overall Loss 0.342829    Objective Loss 0.342829                                        LR 0.001000    Time 0.524847    
2024-05-04 19:12:48,141 - Epoch: [59][  200/  217]    Overall Loss 0.307711    Objective Loss 0.307711                                        LR 0.001000    Time 0.481573    
2024-05-04 19:12:56,867 - Epoch: [59][  217/  217]    Overall Loss 0.298193    Objective Loss 0.298193    Top1 91.803279    Top5 100.000000    LR 0.001000    Time 0.484050    
2024-05-04 19:12:56,991 - --- validate (epoch=59)-----------
2024-05-04 19:12:56,991 - 1736 samples (32 per mini-batch)
2024-05-04 19:13:23,508 - Epoch: [59][   55/   55]    Loss 2.509621    Top1 55.645161    Top5 72.407834    
2024-05-04 19:13:23,610 - ==> Top1: 55.645    Top5: 72.408    Loss: 2.510

2024-05-04 19:13:23,616 - ==> Best [Top1: 57.028   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 55]
2024-05-04 19:13:23,616 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:13:23,663 - 

2024-05-04 19:13:23,663 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:14:23,797 - Epoch: [60][  100/  217]    Overall Loss 0.084832    Objective Loss 0.084832                                        LR 0.001000    Time 0.601276    
2024-05-04 19:15:10,479 - Epoch: [60][  200/  217]    Overall Loss 0.077441    Objective Loss 0.077441                                        LR 0.001000    Time 0.534021    
2024-05-04 19:15:17,354 - Epoch: [60][  217/  217]    Overall Loss 0.078021    Objective Loss 0.078021    Top1 93.442623    Top5 100.000000    LR 0.001000    Time 0.523864    
2024-05-04 19:15:17,458 - --- validate (epoch=60)-----------
2024-05-04 19:15:17,458 - 1736 samples (32 per mini-batch)
2024-05-04 19:15:49,263 - Epoch: [60][   55/   55]    Loss 2.496688    Top1 55.760369    Top5 73.732719    
2024-05-04 19:15:49,377 - ==> Top1: 55.760    Top5: 73.733    Loss: 2.497

2024-05-04 19:15:49,383 - ==> Best [Top1: 57.028   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 55]
2024-05-04 19:15:49,384 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:15:49,575 - 

2024-05-04 19:15:49,575 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:16:39,930 - Epoch: [61][  100/  217]    Overall Loss 0.041072    Objective Loss 0.041072                                        LR 0.001000    Time 0.503487    
2024-05-04 19:17:24,880 - Epoch: [61][  200/  217]    Overall Loss 0.036846    Objective Loss 0.036846                                        LR 0.001000    Time 0.476461    
2024-05-04 19:17:32,026 - Epoch: [61][  217/  217]    Overall Loss 0.036100    Objective Loss 0.036100    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.472061    
2024-05-04 19:17:32,232 - --- validate (epoch=61)-----------
2024-05-04 19:17:32,233 - 1736 samples (32 per mini-batch)
2024-05-04 19:18:01,858 - Epoch: [61][   55/   55]    Loss 2.406100    Top1 57.200461    Top5 74.423963    
2024-05-04 19:18:01,993 - ==> Top1: 57.200    Top5: 74.424    Loss: 2.406

2024-05-04 19:18:02,000 - ==> Best [Top1: 57.200   Top5: 74.424   Sparsity:0.00   Params: 384080 on epoch: 61]
2024-05-04 19:18:02,000 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:18:02,075 - 

2024-05-04 19:18:02,075 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:18:56,867 - Epoch: [62][  100/  217]    Overall Loss 0.018105    Objective Loss 0.018105                                        LR 0.001000    Time 0.547839    
2024-05-04 19:19:49,982 - Epoch: [62][  200/  217]    Overall Loss 0.019630    Objective Loss 0.019630                                        LR 0.001000    Time 0.539469    
2024-05-04 19:19:57,036 - Epoch: [62][  217/  217]    Overall Loss 0.019886    Objective Loss 0.019886    Top1 98.360656    Top5 100.000000    LR 0.001000    Time 0.529704    
2024-05-04 19:19:57,216 - --- validate (epoch=62)-----------
2024-05-04 19:19:57,216 - 1736 samples (32 per mini-batch)
2024-05-04 19:20:24,146 - Epoch: [62][   55/   55]    Loss 2.446061    Top1 56.970046    Top5 74.135945    
2024-05-04 19:20:24,341 - ==> Top1: 56.970    Top5: 74.136    Loss: 2.446

2024-05-04 19:20:24,347 - ==> Best [Top1: 57.200   Top5: 74.424   Sparsity:0.00   Params: 384080 on epoch: 61]
2024-05-04 19:20:24,348 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:20:24,412 - 

2024-05-04 19:20:24,412 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:21:14,576 - Epoch: [63][  100/  217]    Overall Loss 0.013694    Objective Loss 0.013694                                        LR 0.001000    Time 0.501564    
2024-05-04 19:21:57,898 - Epoch: [63][  200/  217]    Overall Loss 0.013992    Objective Loss 0.013992                                        LR 0.001000    Time 0.467365    
2024-05-04 19:22:06,145 - Epoch: [63][  217/  217]    Overall Loss 0.014010    Objective Loss 0.014010    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.468751    
2024-05-04 19:22:06,255 - --- validate (epoch=63)-----------
2024-05-04 19:22:06,256 - 1736 samples (32 per mini-batch)
2024-05-04 19:22:37,047 - Epoch: [63][   55/   55]    Loss 2.476312    Top1 58.122120    Top5 73.444700    
2024-05-04 19:22:37,158 - ==> Top1: 58.122    Top5: 73.445    Loss: 2.476

2024-05-04 19:22:37,163 - ==> Best [Top1: 58.122   Top5: 73.445   Sparsity:0.00   Params: 384080 on epoch: 63]
2024-05-04 19:22:37,163 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:22:37,216 - 

2024-05-04 19:22:37,217 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:23:34,002 - Epoch: [64][  100/  217]    Overall Loss 0.010846    Objective Loss 0.010846                                        LR 0.001000    Time 0.567788    
2024-05-04 19:24:21,356 - Epoch: [64][  200/  217]    Overall Loss 0.010962    Objective Loss 0.010962                                        LR 0.001000    Time 0.520639    
2024-05-04 19:24:30,100 - Epoch: [64][  217/  217]    Overall Loss 0.010796    Objective Loss 0.010796    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.520141    
2024-05-04 19:24:30,252 - --- validate (epoch=64)-----------
2024-05-04 19:24:30,252 - 1736 samples (32 per mini-batch)
2024-05-04 19:24:59,466 - Epoch: [64][   55/   55]    Loss 2.473685    Top1 57.258065    Top5 74.366359    
2024-05-04 19:24:59,624 - ==> Top1: 57.258    Top5: 74.366    Loss: 2.474

2024-05-04 19:24:59,629 - ==> Best [Top1: 58.122   Top5: 73.445   Sparsity:0.00   Params: 384080 on epoch: 63]
2024-05-04 19:24:59,629 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:24:59,913 - 

2024-05-04 19:24:59,913 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:25:54,545 - Epoch: [65][  100/  217]    Overall Loss 0.007183    Objective Loss 0.007183                                        LR 0.001000    Time 0.546258    
2024-05-04 19:26:43,568 - Epoch: [65][  200/  217]    Overall Loss 0.007851    Objective Loss 0.007851                                        LR 0.001000    Time 0.518217    
2024-05-04 19:26:48,492 - Epoch: [65][  217/  217]    Overall Loss 0.008360    Objective Loss 0.008360    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.500306    
2024-05-04 19:26:48,595 - --- validate (epoch=65)-----------
2024-05-04 19:26:48,595 - 1736 samples (32 per mini-batch)
2024-05-04 19:27:18,822 - Epoch: [65][   55/   55]    Loss 2.498827    Top1 57.200461    Top5 74.308756    
2024-05-04 19:27:18,924 - ==> Top1: 57.200    Top5: 74.309    Loss: 2.499

2024-05-04 19:27:18,930 - ==> Best [Top1: 58.122   Top5: 73.445   Sparsity:0.00   Params: 384080 on epoch: 63]
2024-05-04 19:27:18,930 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:27:18,991 - 

2024-05-04 19:27:18,992 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:28:15,959 - Epoch: [66][  100/  217]    Overall Loss 0.007311    Objective Loss 0.007311                                        LR 0.001000    Time 0.569609    
2024-05-04 19:29:02,445 - Epoch: [66][  200/  217]    Overall Loss 0.008399    Objective Loss 0.008399                                        LR 0.001000    Time 0.517206    
2024-05-04 19:29:08,604 - Epoch: [66][  217/  217]    Overall Loss 0.008224    Objective Loss 0.008224    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.505063    
2024-05-04 19:29:08,721 - --- validate (epoch=66)-----------
2024-05-04 19:29:08,721 - 1736 samples (32 per mini-batch)
2024-05-04 19:29:37,486 - Epoch: [66][   55/   55]    Loss 2.498957    Top1 57.776498    Top5 73.502304    
2024-05-04 19:29:37,621 - ==> Top1: 57.776    Top5: 73.502    Loss: 2.499

2024-05-04 19:29:37,627 - ==> Best [Top1: 58.122   Top5: 73.445   Sparsity:0.00   Params: 384080 on epoch: 63]
2024-05-04 19:29:37,628 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:29:37,693 - 

2024-05-04 19:29:37,694 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:30:33,973 - Epoch: [67][  100/  217]    Overall Loss 0.006312    Objective Loss 0.006312                                        LR 0.001000    Time 0.562714    
2024-05-04 19:31:25,262 - Epoch: [67][  200/  217]    Overall Loss 0.008212    Objective Loss 0.008212                                        LR 0.001000    Time 0.537775    
2024-05-04 19:31:34,692 - Epoch: [67][  217/  217]    Overall Loss 0.008288    Objective Loss 0.008288    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.539090    
2024-05-04 19:31:34,916 - --- validate (epoch=67)-----------
2024-05-04 19:31:34,916 - 1736 samples (32 per mini-batch)
2024-05-04 19:32:04,654 - Epoch: [67][   55/   55]    Loss 2.495077    Top1 57.315668    Top5 73.617512    
2024-05-04 19:32:05,302 - ==> Top1: 57.316    Top5: 73.618    Loss: 2.495

2024-05-04 19:32:05,308 - ==> Best [Top1: 58.122   Top5: 73.445   Sparsity:0.00   Params: 384080 on epoch: 63]
2024-05-04 19:32:05,308 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:32:05,375 - 

2024-05-04 19:32:05,375 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:32:56,574 - Epoch: [68][  100/  217]    Overall Loss 0.007646    Objective Loss 0.007646                                        LR 0.001000    Time 0.511911    
2024-05-04 19:33:44,627 - Epoch: [68][  200/  217]    Overall Loss 0.006584    Objective Loss 0.006584                                        LR 0.001000    Time 0.496191    
2024-05-04 19:33:51,768 - Epoch: [68][  217/  217]    Overall Loss 0.006938    Objective Loss 0.006938    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.490220    
2024-05-04 19:33:51,941 - --- validate (epoch=68)-----------
2024-05-04 19:33:51,942 - 1736 samples (32 per mini-batch)
2024-05-04 19:34:20,887 - Epoch: [68][   55/   55]    Loss 2.511649    Top1 58.122120    Top5 73.732719    
2024-05-04 19:34:21,073 - ==> Top1: 58.122    Top5: 73.733    Loss: 2.512

2024-05-04 19:34:21,085 - ==> Best [Top1: 58.122   Top5: 73.733   Sparsity:0.00   Params: 384080 on epoch: 68]
2024-05-04 19:34:21,085 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:34:21,162 - 

2024-05-04 19:34:21,162 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:35:12,976 - Epoch: [69][  100/  217]    Overall Loss 0.005272    Objective Loss 0.005272                                        LR 0.001000    Time 0.518068    
2024-05-04 19:36:08,191 - Epoch: [69][  200/  217]    Overall Loss 0.005415    Objective Loss 0.005415                                        LR 0.001000    Time 0.535082    
2024-05-04 19:36:16,443 - Epoch: [69][  217/  217]    Overall Loss 0.005343    Objective Loss 0.005343    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.531188    
2024-05-04 19:36:16,570 - --- validate (epoch=69)-----------
2024-05-04 19:36:16,570 - 1736 samples (32 per mini-batch)
2024-05-04 19:36:44,334 - Epoch: [69][   55/   55]    Loss 2.512442    Top1 58.410138    Top5 74.251152    
2024-05-04 19:36:44,481 - ==> Top1: 58.410    Top5: 74.251    Loss: 2.512

2024-05-04 19:36:44,487 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 19:36:44,488 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:36:44,566 - 

2024-05-04 19:36:44,566 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:37:39,608 - Epoch: [70][  100/  217]    Overall Loss 0.005269    Objective Loss 0.005269                                        LR 0.001000    Time 0.550346    
2024-05-04 19:38:28,263 - Epoch: [70][  200/  217]    Overall Loss 0.006042    Objective Loss 0.006042                                        LR 0.001000    Time 0.518418    
2024-05-04 19:38:36,941 - Epoch: [70][  217/  217]    Overall Loss 0.006312    Objective Loss 0.006312    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.517789    
2024-05-04 19:38:37,106 - --- validate (epoch=70)-----------
2024-05-04 19:38:37,107 - 1736 samples (32 per mini-batch)
2024-05-04 19:39:09,182 - Epoch: [70][   55/   55]    Loss 2.573421    Top1 57.603687    Top5 73.905530    
2024-05-04 19:39:09,347 - ==> Top1: 57.604    Top5: 73.906    Loss: 2.573

2024-05-04 19:39:09,354 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 19:39:09,354 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:39:09,418 - 

2024-05-04 19:39:09,418 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:40:04,861 - Epoch: [71][  100/  217]    Overall Loss 0.004451    Objective Loss 0.004451                                        LR 0.001000    Time 0.554347    
2024-05-04 19:40:54,676 - Epoch: [71][  200/  217]    Overall Loss 0.005099    Objective Loss 0.005099                                        LR 0.001000    Time 0.526221    
2024-05-04 19:41:03,547 - Epoch: [71][  217/  217]    Overall Loss 0.005129    Objective Loss 0.005129    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.525872    
2024-05-04 19:41:03,685 - --- validate (epoch=71)-----------
2024-05-04 19:41:03,686 - 1736 samples (32 per mini-batch)
2024-05-04 19:41:32,930 - Epoch: [71][   55/   55]    Loss 2.568887    Top1 57.891705    Top5 74.193548    
2024-05-04 19:41:33,040 - ==> Top1: 57.892    Top5: 74.194    Loss: 2.569

2024-05-04 19:41:33,047 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 19:41:33,047 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:41:33,111 - 

2024-05-04 19:41:33,112 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:42:21,595 - Epoch: [72][  100/  217]    Overall Loss 0.004842    Objective Loss 0.004842                                        LR 0.001000    Time 0.484761    
2024-05-04 19:43:09,933 - Epoch: [72][  200/  217]    Overall Loss 0.004596    Objective Loss 0.004596                                        LR 0.001000    Time 0.484041    
2024-05-04 19:43:17,323 - Epoch: [72][  217/  217]    Overall Loss 0.004451    Objective Loss 0.004451    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.480171    
2024-05-04 19:43:17,489 - --- validate (epoch=72)-----------
2024-05-04 19:43:17,489 - 1736 samples (32 per mini-batch)
2024-05-04 19:43:48,803 - Epoch: [72][   55/   55]    Loss 2.538302    Top1 58.179724    Top5 74.827189    
2024-05-04 19:43:49,030 - ==> Top1: 58.180    Top5: 74.827    Loss: 2.538

2024-05-04 19:43:49,037 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 19:43:49,038 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:43:49,104 - 

2024-05-04 19:43:49,105 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:44:41,622 - Epoch: [73][  100/  217]    Overall Loss 0.003425    Objective Loss 0.003425                                        LR 0.001000    Time 0.525097    
2024-05-04 19:45:31,065 - Epoch: [73][  200/  217]    Overall Loss 0.003783    Objective Loss 0.003783                                        LR 0.001000    Time 0.509737    
2024-05-04 19:45:40,113 - Epoch: [73][  217/  217]    Overall Loss 0.004183    Objective Loss 0.004183    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.511495    
2024-05-04 19:45:40,319 - --- validate (epoch=73)-----------
2024-05-04 19:45:40,319 - 1736 samples (32 per mini-batch)
2024-05-04 19:46:11,305 - Epoch: [73][   55/   55]    Loss 2.595711    Top1 57.373272    Top5 73.329493    
2024-05-04 19:46:11,439 - ==> Top1: 57.373    Top5: 73.329    Loss: 2.596

2024-05-04 19:46:11,444 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 19:46:11,444 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:46:11,485 - 

2024-05-04 19:46:11,486 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:47:05,322 - Epoch: [74][  100/  217]    Overall Loss 0.017944    Objective Loss 0.017944                                        LR 0.001000    Time 0.538296    
2024-05-04 19:47:55,094 - Epoch: [74][  200/  217]    Overall Loss 0.424378    Objective Loss 0.424378                                        LR 0.001000    Time 0.517981    
2024-05-04 19:48:01,648 - Epoch: [74][  217/  217]    Overall Loss 0.485270    Objective Loss 0.485270    Top1 68.852459    Top5 91.803279    LR 0.001000    Time 0.507597    
2024-05-04 19:48:01,871 - --- validate (epoch=74)-----------
2024-05-04 19:48:01,872 - 1736 samples (32 per mini-batch)
2024-05-04 19:48:33,152 - Epoch: [74][   55/   55]    Loss 3.145840    Top1 49.308756    Top5 66.935484    
2024-05-04 19:48:33,313 - ==> Top1: 49.309    Top5: 66.935    Loss: 3.146

2024-05-04 19:48:33,319 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 19:48:33,319 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:48:33,365 - 

2024-05-04 19:48:33,366 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:49:26,054 - Epoch: [75][  100/  217]    Overall Loss 0.477041    Objective Loss 0.477041                                        LR 0.001000    Time 0.526809    
2024-05-04 19:50:15,565 - Epoch: [75][  200/  217]    Overall Loss 0.411216    Objective Loss 0.411216                                        LR 0.001000    Time 0.510926    
2024-05-04 19:50:22,216 - Epoch: [75][  217/  217]    Overall Loss 0.399807    Objective Loss 0.399807    Top1 88.524590    Top5 98.360656    LR 0.001000    Time 0.501541    
2024-05-04 19:50:22,356 - --- validate (epoch=75)-----------
2024-05-04 19:50:22,357 - 1736 samples (32 per mini-batch)
2024-05-04 19:50:53,649 - Epoch: [75][   55/   55]    Loss 2.580701    Top1 56.739631    Top5 72.926267    
2024-05-04 19:50:53,794 - ==> Top1: 56.740    Top5: 72.926    Loss: 2.581

2024-05-04 19:50:53,801 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 19:50:53,802 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:50:53,868 - 

2024-05-04 19:50:53,868 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:51:45,885 - Epoch: [76][  100/  217]    Overall Loss 0.089860    Objective Loss 0.089860                                        LR 0.001000    Time 0.520097    
2024-05-04 19:52:34,311 - Epoch: [76][  200/  217]    Overall Loss 0.082829    Objective Loss 0.082829                                        LR 0.001000    Time 0.502154    
2024-05-04 19:52:40,307 - Epoch: [76][  217/  217]    Overall Loss 0.081453    Objective Loss 0.081453    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.490433    
2024-05-04 19:52:40,452 - --- validate (epoch=76)-----------
2024-05-04 19:52:40,452 - 1736 samples (32 per mini-batch)
2024-05-04 19:53:11,139 - Epoch: [76][   55/   55]    Loss 2.533818    Top1 56.336406    Top5 73.214286    
2024-05-04 19:53:11,268 - ==> Top1: 56.336    Top5: 73.214    Loss: 2.534

2024-05-04 19:53:11,273 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 19:53:11,273 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:53:11,317 - 

2024-05-04 19:53:11,317 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:54:03,505 - Epoch: [77][  100/  217]    Overall Loss 0.027969    Objective Loss 0.027969                                        LR 0.001000    Time 0.521813    
2024-05-04 19:54:53,748 - Epoch: [77][  200/  217]    Overall Loss 0.025165    Objective Loss 0.025165                                        LR 0.001000    Time 0.512092    
2024-05-04 19:55:01,189 - Epoch: [77][  217/  217]    Overall Loss 0.025065    Objective Loss 0.025065    Top1 98.360656    Top5 100.000000    LR 0.001000    Time 0.506261    
2024-05-04 19:55:01,299 - --- validate (epoch=77)-----------
2024-05-04 19:55:01,299 - 1736 samples (32 per mini-batch)
2024-05-04 19:55:31,144 - Epoch: [77][   55/   55]    Loss 2.503644    Top1 57.603687    Top5 74.078341    
2024-05-04 19:55:31,268 - ==> Top1: 57.604    Top5: 74.078    Loss: 2.504

2024-05-04 19:55:31,272 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 19:55:31,272 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:55:31,319 - 

2024-05-04 19:55:31,319 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:56:30,257 - Epoch: [78][  100/  217]    Overall Loss 0.014084    Objective Loss 0.014084                                        LR 0.001000    Time 0.589315    
2024-05-04 19:57:17,465 - Epoch: [78][  200/  217]    Overall Loss 0.016261    Objective Loss 0.016261                                        LR 0.001000    Time 0.530670    
2024-05-04 19:57:26,588 - Epoch: [78][  217/  217]    Overall Loss 0.015882    Objective Loss 0.015882    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.531134    
2024-05-04 19:57:26,716 - --- validate (epoch=78)-----------
2024-05-04 19:57:26,717 - 1736 samples (32 per mini-batch)
2024-05-04 19:57:56,202 - Epoch: [78][   55/   55]    Loss 2.544364    Top1 57.834101    Top5 74.020737    
2024-05-04 19:57:56,321 - ==> Top1: 57.834    Top5: 74.021    Loss: 2.544

2024-05-04 19:57:56,328 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 19:57:56,328 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 19:57:56,389 - 

2024-05-04 19:57:56,390 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 19:58:47,004 - Epoch: [79][  100/  217]    Overall Loss 0.009403    Objective Loss 0.009403                                        LR 0.001000    Time 0.506067    
2024-05-04 19:59:36,432 - Epoch: [79][  200/  217]    Overall Loss 0.011139    Objective Loss 0.011139                                        LR 0.001000    Time 0.500150    
2024-05-04 19:59:43,661 - Epoch: [79][  217/  217]    Overall Loss 0.011187    Objective Loss 0.011187    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.494274    
2024-05-04 19:59:43,816 - --- validate (epoch=79)-----------
2024-05-04 19:59:43,817 - 1736 samples (32 per mini-batch)
2024-05-04 20:00:16,206 - Epoch: [79][   55/   55]    Loss 2.557313    Top1 57.776498    Top5 73.905530    
2024-05-04 20:00:16,342 - ==> Top1: 57.776    Top5: 73.906    Loss: 2.557

2024-05-04 20:00:16,348 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:00:16,349 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:00:16,411 - 

2024-05-04 20:00:16,411 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:01:10,988 - Epoch: [80][  100/  217]    Overall Loss 0.010210    Objective Loss 0.010210                                        LR 0.001000    Time 0.545692    
2024-05-04 20:01:55,523 - Epoch: [80][  200/  217]    Overall Loss 0.010301    Objective Loss 0.010301                                        LR 0.001000    Time 0.495498    
2024-05-04 20:02:01,526 - Epoch: [80][  217/  217]    Overall Loss 0.010029    Objective Loss 0.010029    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.484338    
2024-05-04 20:02:01,689 - --- validate (epoch=80)-----------
2024-05-04 20:02:01,689 - 1736 samples (32 per mini-batch)
2024-05-04 20:02:31,811 - Epoch: [80][   55/   55]    Loss 2.538471    Top1 57.834101    Top5 73.617512    
2024-05-04 20:02:31,934 - ==> Top1: 57.834    Top5: 73.618    Loss: 2.538

2024-05-04 20:02:31,940 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:02:31,940 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:02:32,002 - 

2024-05-04 20:02:32,003 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:03:23,755 - Epoch: [81][  100/  217]    Overall Loss 0.006513    Objective Loss 0.006513                                        LR 0.001000    Time 0.517453    
2024-05-04 20:04:08,123 - Epoch: [81][  200/  217]    Overall Loss 0.007663    Objective Loss 0.007663                                        LR 0.001000    Time 0.480542    
2024-05-04 20:04:16,082 - Epoch: [81][  217/  217]    Overall Loss 0.007623    Objective Loss 0.007623    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.479568    
2024-05-04 20:04:16,188 - --- validate (epoch=81)-----------
2024-05-04 20:04:16,188 - 1736 samples (32 per mini-batch)
2024-05-04 20:04:47,922 - Epoch: [81][   55/   55]    Loss 2.573474    Top1 57.718894    Top5 73.963134    
2024-05-04 20:04:48,054 - ==> Top1: 57.719    Top5: 73.963    Loss: 2.573

2024-05-04 20:04:48,060 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:04:48,060 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:04:48,126 - 

2024-05-04 20:04:48,126 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:05:38,676 - Epoch: [82][  100/  217]    Overall Loss 0.006817    Objective Loss 0.006817                                        LR 0.001000    Time 0.505430    
2024-05-04 20:06:34,483 - Epoch: [82][  200/  217]    Overall Loss 0.006480    Objective Loss 0.006480                                        LR 0.001000    Time 0.531723    
2024-05-04 20:06:43,397 - Epoch: [82][  217/  217]    Overall Loss 0.006658    Objective Loss 0.006658    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.531140    
2024-05-04 20:06:43,556 - --- validate (epoch=82)-----------
2024-05-04 20:06:43,557 - 1736 samples (32 per mini-batch)
2024-05-04 20:07:14,331 - Epoch: [82][   55/   55]    Loss 2.617541    Top1 57.315668    Top5 73.617512    
2024-05-04 20:07:14,490 - ==> Top1: 57.316    Top5: 73.618    Loss: 2.618

2024-05-04 20:07:14,497 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:07:14,497 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:07:14,561 - 

2024-05-04 20:07:14,562 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:08:09,444 - Epoch: [83][  100/  217]    Overall Loss 0.007068    Objective Loss 0.007068                                        LR 0.001000    Time 0.548756    
2024-05-04 20:08:59,997 - Epoch: [83][  200/  217]    Overall Loss 0.007058    Objective Loss 0.007058                                        LR 0.001000    Time 0.527117    
2024-05-04 20:09:08,991 - Epoch: [83][  217/  217]    Overall Loss 0.006961    Objective Loss 0.006961    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.527260    
2024-05-04 20:09:09,141 - --- validate (epoch=83)-----------
2024-05-04 20:09:09,141 - 1736 samples (32 per mini-batch)
2024-05-04 20:09:40,133 - Epoch: [83][   55/   55]    Loss 2.589704    Top1 58.122120    Top5 74.078341    
2024-05-04 20:09:40,308 - ==> Top1: 58.122    Top5: 74.078    Loss: 2.590

2024-05-04 20:09:40,314 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:09:40,314 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:09:40,376 - 

2024-05-04 20:09:40,377 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:10:33,039 - Epoch: [84][  100/  217]    Overall Loss 0.004584    Objective Loss 0.004584                                        LR 0.001000    Time 0.526547    
2024-05-04 20:11:19,975 - Epoch: [84][  200/  217]    Overall Loss 0.005276    Objective Loss 0.005276                                        LR 0.001000    Time 0.497925    
2024-05-04 20:11:26,756 - Epoch: [84][  217/  217]    Overall Loss 0.005238    Objective Loss 0.005238    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.490157    
2024-05-04 20:11:26,915 - --- validate (epoch=84)-----------
2024-05-04 20:11:26,916 - 1736 samples (32 per mini-batch)
2024-05-04 20:11:56,001 - Epoch: [84][   55/   55]    Loss 2.586924    Top1 58.006912    Top5 74.135945    
2024-05-04 20:11:56,154 - ==> Top1: 58.007    Top5: 74.136    Loss: 2.587

2024-05-04 20:11:56,161 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:11:56,161 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:11:56,227 - 

2024-05-04 20:11:56,227 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:12:49,278 - Epoch: [85][  100/  217]    Overall Loss 0.004637    Objective Loss 0.004637                                        LR 0.001000    Time 0.530439    
2024-05-04 20:13:37,286 - Epoch: [85][  200/  217]    Overall Loss 0.005677    Objective Loss 0.005677                                        LR 0.001000    Time 0.505230    
2024-05-04 20:13:43,953 - Epoch: [85][  217/  217]    Overall Loss 0.005528    Objective Loss 0.005528    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.496368    
2024-05-04 20:13:44,115 - --- validate (epoch=85)-----------
2024-05-04 20:13:44,116 - 1736 samples (32 per mini-batch)
2024-05-04 20:14:12,662 - Epoch: [85][   55/   55]    Loss 2.609047    Top1 57.546083    Top5 73.675115    
2024-05-04 20:14:12,802 - ==> Top1: 57.546    Top5: 73.675    Loss: 2.609

2024-05-04 20:14:12,809 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:14:12,809 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:14:12,872 - 

2024-05-04 20:14:12,872 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:15:07,110 - Epoch: [86][  100/  217]    Overall Loss 0.004080    Objective Loss 0.004080                                        LR 0.001000    Time 0.542306    
2024-05-04 20:15:54,873 - Epoch: [86][  200/  217]    Overall Loss 0.004614    Objective Loss 0.004614                                        LR 0.001000    Time 0.509944    
2024-05-04 20:16:08,436 - Epoch: [86][  217/  217]    Overall Loss 0.004491    Objective Loss 0.004491    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.532489    
2024-05-04 20:16:08,553 - --- validate (epoch=86)-----------
2024-05-04 20:16:08,554 - 1736 samples (32 per mini-batch)
2024-05-04 20:16:38,357 - Epoch: [86][   55/   55]    Loss 2.654192    Top1 57.834101    Top5 73.847926    
2024-05-04 20:16:38,479 - ==> Top1: 57.834    Top5: 73.848    Loss: 2.654

2024-05-04 20:16:38,484 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:16:38,484 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:16:38,525 - 

2024-05-04 20:16:38,525 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:17:28,938 - Epoch: [87][  100/  217]    Overall Loss 0.003965    Objective Loss 0.003965                                        LR 0.001000    Time 0.504058    
2024-05-04 20:18:27,115 - Epoch: [87][  200/  217]    Overall Loss 0.003895    Objective Loss 0.003895                                        LR 0.001000    Time 0.542890    
2024-05-04 20:18:32,810 - Epoch: [87][  217/  217]    Overall Loss 0.003953    Objective Loss 0.003953    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.526592    
2024-05-04 20:18:32,935 - --- validate (epoch=87)-----------
2024-05-04 20:18:32,935 - 1736 samples (32 per mini-batch)
2024-05-04 20:19:01,783 - Epoch: [87][   55/   55]    Loss 2.616571    Top1 57.603687    Top5 74.020737    
2024-05-04 20:19:01,917 - ==> Top1: 57.604    Top5: 74.021    Loss: 2.617

2024-05-04 20:19:01,922 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:19:01,922 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:19:01,968 - 

2024-05-04 20:19:01,968 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:19:56,870 - Epoch: [88][  100/  217]    Overall Loss 0.003627    Objective Loss 0.003627                                        LR 0.001000    Time 0.548955    
2024-05-04 20:20:39,422 - Epoch: [88][  200/  217]    Overall Loss 0.003596    Objective Loss 0.003596                                        LR 0.001000    Time 0.487215    
2024-05-04 20:20:47,720 - Epoch: [88][  217/  217]    Overall Loss 0.004029    Objective Loss 0.004029    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.487278    
2024-05-04 20:20:47,847 - --- validate (epoch=88)-----------
2024-05-04 20:20:47,848 - 1736 samples (32 per mini-batch)
2024-05-04 20:21:17,615 - Epoch: [88][   55/   55]    Loss 2.680958    Top1 57.200461    Top5 73.675115    
2024-05-04 20:21:17,718 - ==> Top1: 57.200    Top5: 73.675    Loss: 2.681

2024-05-04 20:21:17,725 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:21:17,725 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:21:17,791 - 

2024-05-04 20:21:17,792 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:22:08,336 - Epoch: [89][  100/  217]    Overall Loss 0.008123    Objective Loss 0.008123                                        LR 0.001000    Time 0.505373    
2024-05-04 20:22:56,566 - Epoch: [89][  200/  217]    Overall Loss 0.067196    Objective Loss 0.067196                                        LR 0.001000    Time 0.493808    
2024-05-04 20:23:09,744 - Epoch: [89][  217/  217]    Overall Loss 0.104543    Objective Loss 0.104543    Top1 83.606557    Top5 95.081967    LR 0.001000    Time 0.515846    
2024-05-04 20:23:09,885 - --- validate (epoch=89)-----------
2024-05-04 20:23:09,886 - 1736 samples (32 per mini-batch)
2024-05-04 20:23:39,783 - Epoch: [89][   55/   55]    Loss 3.840209    Top1 42.799539    Top5 62.500000    
2024-05-04 20:23:39,912 - ==> Top1: 42.800    Top5: 62.500    Loss: 3.840

2024-05-04 20:23:39,917 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:23:39,917 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:23:39,964 - 

2024-05-04 20:23:39,965 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:24:35,182 - Epoch: [90][  100/  217]    Overall Loss 0.565871    Objective Loss 0.565871                                        LR 0.001000    Time 0.552107    
2024-05-04 20:25:20,404 - Epoch: [90][  200/  217]    Overall Loss 0.446650    Objective Loss 0.446650                                        LR 0.001000    Time 0.502138    
2024-05-04 20:25:26,873 - Epoch: [90][  217/  217]    Overall Loss 0.429408    Objective Loss 0.429408    Top1 90.163934    Top5 100.000000    LR 0.001000    Time 0.492604    
2024-05-04 20:25:26,980 - --- validate (epoch=90)-----------
2024-05-04 20:25:26,981 - 1736 samples (32 per mini-batch)
2024-05-04 20:25:57,547 - Epoch: [90][   55/   55]    Loss 2.831762    Top1 54.550691    Top5 71.428571    
2024-05-04 20:25:57,667 - ==> Top1: 54.551    Top5: 71.429    Loss: 2.832

2024-05-04 20:25:57,674 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:25:57,674 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:25:57,739 - 

2024-05-04 20:25:57,740 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:26:49,682 - Epoch: [91][  100/  217]    Overall Loss 0.084400    Objective Loss 0.084400                                        LR 0.001000    Time 0.519354    
2024-05-04 20:27:36,806 - Epoch: [91][  200/  217]    Overall Loss 0.078191    Objective Loss 0.078191                                        LR 0.001000    Time 0.495272    
2024-05-04 20:27:46,942 - Epoch: [91][  217/  217]    Overall Loss 0.076288    Objective Loss 0.076288    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.503172    
2024-05-04 20:27:47,077 - --- validate (epoch=91)-----------
2024-05-04 20:27:47,078 - 1736 samples (32 per mini-batch)
2024-05-04 20:28:20,014 - Epoch: [91][   55/   55]    Loss 2.641759    Top1 56.509217    Top5 73.041475    
2024-05-04 20:28:20,174 - ==> Top1: 56.509    Top5: 73.041    Loss: 2.642

2024-05-04 20:28:20,180 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:28:20,180 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:28:20,246 - 

2024-05-04 20:28:20,246 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:29:21,413 - Epoch: [92][  100/  217]    Overall Loss 0.028455    Objective Loss 0.028455                                        LR 0.001000    Time 0.611599    
2024-05-04 20:30:09,585 - Epoch: [92][  200/  217]    Overall Loss 0.027668    Objective Loss 0.027668                                        LR 0.001000    Time 0.546633    
2024-05-04 20:30:16,479 - Epoch: [92][  217/  217]    Overall Loss 0.027576    Objective Loss 0.027576    Top1 98.360656    Top5 100.000000    LR 0.001000    Time 0.535571    
2024-05-04 20:30:16,655 - --- validate (epoch=92)-----------
2024-05-04 20:30:16,655 - 1736 samples (32 per mini-batch)
2024-05-04 20:30:42,642 - Epoch: [92][   55/   55]    Loss 2.661676    Top1 57.430876    Top5 72.753456    
2024-05-04 20:30:42,820 - ==> Top1: 57.431    Top5: 72.753    Loss: 2.662

2024-05-04 20:30:42,827 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:30:42,827 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:30:42,892 - 

2024-05-04 20:30:42,893 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:31:38,720 - Epoch: [93][  100/  217]    Overall Loss 0.014658    Objective Loss 0.014658                                        LR 0.001000    Time 0.558170    
2024-05-04 20:32:29,836 - Epoch: [93][  200/  217]    Overall Loss 0.012838    Objective Loss 0.012838                                        LR 0.001000    Time 0.534641    
2024-05-04 20:32:36,537 - Epoch: [93][  217/  217]    Overall Loss 0.013064    Objective Loss 0.013064    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.523628    
2024-05-04 20:32:36,669 - --- validate (epoch=93)-----------
2024-05-04 20:32:36,670 - 1736 samples (32 per mini-batch)
2024-05-04 20:33:05,147 - Epoch: [93][   55/   55]    Loss 2.666303    Top1 57.027650    Top5 73.675115    
2024-05-04 20:33:05,273 - ==> Top1: 57.028    Top5: 73.675    Loss: 2.666

2024-05-04 20:33:05,279 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:33:05,279 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:33:05,345 - 

2024-05-04 20:33:05,346 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:33:59,893 - Epoch: [94][  100/  217]    Overall Loss 0.008019    Objective Loss 0.008019                                        LR 0.001000    Time 0.545406    
2024-05-04 20:34:46,854 - Epoch: [94][  200/  217]    Overall Loss 0.008587    Objective Loss 0.008587                                        LR 0.001000    Time 0.507486    
2024-05-04 20:34:54,265 - Epoch: [94][  217/  217]    Overall Loss 0.008485    Objective Loss 0.008485    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.501875    
2024-05-04 20:34:54,352 - --- validate (epoch=94)-----------
2024-05-04 20:34:54,352 - 1736 samples (32 per mini-batch)
2024-05-04 20:35:23,456 - Epoch: [94][   55/   55]    Loss 2.655901    Top1 56.739631    Top5 73.675115    
2024-05-04 20:35:23,575 - ==> Top1: 56.740    Top5: 73.675    Loss: 2.656

2024-05-04 20:35:23,579 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:35:23,579 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:35:23,624 - 

2024-05-04 20:35:23,625 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:36:13,750 - Epoch: [95][  100/  217]    Overall Loss 0.006576    Objective Loss 0.006576                                        LR 0.001000    Time 0.501191    
2024-05-04 20:37:14,336 - Epoch: [95][  200/  217]    Overall Loss 0.007165    Objective Loss 0.007165                                        LR 0.001000    Time 0.553498    
2024-05-04 20:37:19,376 - Epoch: [95][  217/  217]    Overall Loss 0.007045    Objective Loss 0.007045    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.533355    
2024-05-04 20:37:19,516 - --- validate (epoch=95)-----------
2024-05-04 20:37:19,516 - 1736 samples (32 per mini-batch)
2024-05-04 20:37:49,935 - Epoch: [95][   55/   55]    Loss 2.639381    Top1 56.624424    Top5 73.675115    
2024-05-04 20:37:50,100 - ==> Top1: 56.624    Top5: 73.675    Loss: 2.639

2024-05-04 20:37:50,107 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:37:50,107 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:37:50,170 - 

2024-05-04 20:37:50,171 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:38:41,631 - Epoch: [96][  100/  217]    Overall Loss 0.005725    Objective Loss 0.005725                                        LR 0.001000    Time 0.514535    
2024-05-04 20:39:29,851 - Epoch: [96][  200/  217]    Overall Loss 0.006168    Objective Loss 0.006168                                        LR 0.001000    Time 0.498338    
2024-05-04 20:39:38,115 - Epoch: [96][  217/  217]    Overall Loss 0.006283    Objective Loss 0.006283    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.497361    
2024-05-04 20:39:38,266 - --- validate (epoch=96)-----------
2024-05-04 20:39:38,267 - 1736 samples (32 per mini-batch)
2024-05-04 20:40:08,104 - Epoch: [96][   55/   55]    Loss 2.609647    Top1 57.200461    Top5 73.617512    
2024-05-04 20:40:08,232 - ==> Top1: 57.200    Top5: 73.618    Loss: 2.610

2024-05-04 20:40:08,238 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:40:08,239 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:40:08,304 - 

2024-05-04 20:40:08,304 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:40:57,568 - Epoch: [97][  100/  217]    Overall Loss 0.004285    Objective Loss 0.004285                                        LR 0.001000    Time 0.492567    
2024-05-04 20:41:48,309 - Epoch: [97][  200/  217]    Overall Loss 0.004898    Objective Loss 0.004898                                        LR 0.001000    Time 0.499964    
2024-05-04 20:41:56,456 - Epoch: [97][  217/  217]    Overall Loss 0.004737    Objective Loss 0.004737    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.498333    
2024-05-04 20:41:56,596 - --- validate (epoch=97)-----------
2024-05-04 20:41:56,597 - 1736 samples (32 per mini-batch)
2024-05-04 20:42:27,999 - Epoch: [97][   55/   55]    Loss 2.651516    Top1 57.603687    Top5 73.617512    
2024-05-04 20:42:28,106 - ==> Top1: 57.604    Top5: 73.618    Loss: 2.652

2024-05-04 20:42:28,112 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:42:28,113 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:42:28,175 - 

2024-05-04 20:42:28,175 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:43:16,280 - Epoch: [98][  100/  217]    Overall Loss 0.004403    Objective Loss 0.004403                                        LR 0.001000    Time 0.480981    
2024-05-04 20:44:04,893 - Epoch: [98][  200/  217]    Overall Loss 0.004354    Objective Loss 0.004354                                        LR 0.001000    Time 0.483533    
2024-05-04 20:44:11,703 - Epoch: [98][  217/  217]    Overall Loss 0.004340    Objective Loss 0.004340    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.477026    
2024-05-04 20:44:11,815 - --- validate (epoch=98)-----------
2024-05-04 20:44:11,816 - 1736 samples (32 per mini-batch)
2024-05-04 20:44:42,107 - Epoch: [98][   55/   55]    Loss 2.643677    Top1 57.834101    Top5 73.617512    
2024-05-04 20:44:42,240 - ==> Top1: 57.834    Top5: 73.618    Loss: 2.644

2024-05-04 20:44:42,245 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:44:42,246 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:44:42,290 - 

2024-05-04 20:44:42,290 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:45:38,318 - Epoch: [99][  100/  217]    Overall Loss 0.003577    Objective Loss 0.003577                                        LR 0.001000    Time 0.560211    
2024-05-04 20:46:22,152 - Epoch: [99][  200/  217]    Overall Loss 0.003909    Objective Loss 0.003909                                        LR 0.001000    Time 0.499252    
2024-05-04 20:46:30,825 - Epoch: [99][  217/  217]    Overall Loss 0.003896    Objective Loss 0.003896    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.500101    
2024-05-04 20:46:30,957 - --- validate (epoch=99)-----------
2024-05-04 20:46:30,958 - 1736 samples (32 per mini-batch)
2024-05-04 20:46:57,103 - Epoch: [99][   55/   55]    Loss 2.672512    Top1 57.949309    Top5 73.790323    
2024-05-04 20:46:57,225 - ==> Top1: 57.949    Top5: 73.790    Loss: 2.673

2024-05-04 20:46:57,231 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:46:57,231 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:46:57,303 - 

2024-05-04 20:46:57,304 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:47:48,466 - Epoch: [100][  100/  217]    Overall Loss 0.003340    Objective Loss 0.003340                                        LR 0.000250    Time 0.511559    
2024-05-04 20:48:34,520 - Epoch: [100][  200/  217]    Overall Loss 0.003233    Objective Loss 0.003233                                        LR 0.000250    Time 0.486022    
2024-05-04 20:48:42,487 - Epoch: [100][  217/  217]    Overall Loss 0.003120    Objective Loss 0.003120    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.484656    
2024-05-04 20:48:42,590 - --- validate (epoch=100)-----------
2024-05-04 20:48:42,590 - 1736 samples (32 per mini-batch)
2024-05-04 20:49:11,253 - Epoch: [100][   55/   55]    Loss 2.660740    Top1 58.294931    Top5 73.675115    
2024-05-04 20:49:11,407 - ==> Top1: 58.295    Top5: 73.675    Loss: 2.661

2024-05-04 20:49:11,413 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:49:11,414 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:49:11,478 - 

2024-05-04 20:49:11,478 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:50:04,582 - Epoch: [101][  100/  217]    Overall Loss 0.003640    Objective Loss 0.003640                                        LR 0.000250    Time 0.530969    
2024-05-04 20:50:48,055 - Epoch: [101][  200/  217]    Overall Loss 0.002998    Objective Loss 0.002998                                        LR 0.000250    Time 0.482822    
2024-05-04 20:50:54,065 - Epoch: [101][  217/  217]    Overall Loss 0.002945    Objective Loss 0.002945    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.472691    
2024-05-04 20:50:54,174 - --- validate (epoch=101)-----------
2024-05-04 20:50:54,175 - 1736 samples (32 per mini-batch)
2024-05-04 20:51:21,462 - Epoch: [101][   55/   55]    Loss 2.686043    Top1 58.179724    Top5 73.502304    
2024-05-04 20:51:21,570 - ==> Top1: 58.180    Top5: 73.502    Loss: 2.686

2024-05-04 20:51:21,576 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:51:21,577 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:51:21,642 - 

2024-05-04 20:51:21,642 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:52:12,277 - Epoch: [102][  100/  217]    Overall Loss 0.002424    Objective Loss 0.002424                                        LR 0.000250    Time 0.506276    
2024-05-04 20:53:02,471 - Epoch: [102][  200/  217]    Overall Loss 0.002755    Objective Loss 0.002755                                        LR 0.000250    Time 0.504081    
2024-05-04 20:53:10,036 - Epoch: [102][  217/  217]    Overall Loss 0.002777    Objective Loss 0.002777    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.499448    
2024-05-04 20:53:10,163 - --- validate (epoch=102)-----------
2024-05-04 20:53:10,163 - 1736 samples (32 per mini-batch)
2024-05-04 20:53:36,053 - Epoch: [102][   55/   55]    Loss 2.627349    Top1 57.891705    Top5 73.559908    
2024-05-04 20:53:36,181 - ==> Top1: 57.892    Top5: 73.560    Loss: 2.627

2024-05-04 20:53:36,187 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:53:36,188 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:53:36,252 - 

2024-05-04 20:53:36,253 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:54:31,500 - Epoch: [103][  100/  217]    Overall Loss 0.003332    Objective Loss 0.003332                                        LR 0.000250    Time 0.552405    
2024-05-04 20:55:19,183 - Epoch: [103][  200/  217]    Overall Loss 0.003000    Objective Loss 0.003000                                        LR 0.000250    Time 0.514590    
2024-05-04 20:55:27,844 - Epoch: [103][  217/  217]    Overall Loss 0.002894    Objective Loss 0.002894    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.514184    
2024-05-04 20:55:27,985 - --- validate (epoch=103)-----------
2024-05-04 20:55:27,985 - 1736 samples (32 per mini-batch)
2024-05-04 20:55:55,126 - Epoch: [103][   55/   55]    Loss 2.634243    Top1 57.891705    Top5 73.675115    
2024-05-04 20:55:55,233 - ==> Top1: 57.892    Top5: 73.675    Loss: 2.634

2024-05-04 20:55:55,237 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:55:55,238 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:55:55,281 - 

2024-05-04 20:55:55,281 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:56:44,971 - Epoch: [104][  100/  217]    Overall Loss 0.002662    Objective Loss 0.002662                                        LR 0.000250    Time 0.496837    
2024-05-04 20:57:31,444 - Epoch: [104][  200/  217]    Overall Loss 0.002468    Objective Loss 0.002468                                        LR 0.000250    Time 0.480756    
2024-05-04 20:57:37,854 - Epoch: [104][  217/  217]    Overall Loss 0.002576    Objective Loss 0.002576    Top1 98.360656    Top5 100.000000    LR 0.000250    Time 0.472629    
2024-05-04 20:57:38,020 - --- validate (epoch=104)-----------
2024-05-04 20:57:38,020 - 1736 samples (32 per mini-batch)
2024-05-04 20:58:07,327 - Epoch: [104][   55/   55]    Loss 2.674120    Top1 57.834101    Top5 73.617512    
2024-05-04 20:58:07,524 - ==> Top1: 57.834    Top5: 73.618    Loss: 2.674

2024-05-04 20:58:07,532 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 20:58:07,532 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 20:58:07,600 - 

2024-05-04 20:58:07,601 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 20:58:55,120 - Epoch: [105][  100/  217]    Overall Loss 0.002393    Objective Loss 0.002393                                        LR 0.000250    Time 0.475111    
2024-05-04 20:59:49,627 - Epoch: [105][  200/  217]    Overall Loss 0.002504    Objective Loss 0.002504                                        LR 0.000250    Time 0.510062    
2024-05-04 20:59:57,419 - Epoch: [105][  217/  217]    Overall Loss 0.002577    Objective Loss 0.002577    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.506001    
2024-05-04 20:59:57,590 - --- validate (epoch=105)-----------
2024-05-04 20:59:57,591 - 1736 samples (32 per mini-batch)
2024-05-04 21:00:25,527 - Epoch: [105][   55/   55]    Loss 2.674347    Top1 57.949309    Top5 73.847926    
2024-05-04 21:00:25,685 - ==> Top1: 57.949    Top5: 73.848    Loss: 2.674

2024-05-04 21:00:25,692 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:00:25,692 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:00:25,755 - 

2024-05-04 21:00:25,756 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:01:19,492 - Epoch: [106][  100/  217]    Overall Loss 0.002790    Objective Loss 0.002790                                        LR 0.000250    Time 0.537285    
2024-05-04 21:02:12,598 - Epoch: [106][  200/  217]    Overall Loss 0.002508    Objective Loss 0.002508                                        LR 0.000250    Time 0.534149    
2024-05-04 21:02:21,470 - Epoch: [106][  217/  217]    Overall Loss 0.002412    Objective Loss 0.002412    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.533182    
2024-05-04 21:02:21,639 - --- validate (epoch=106)-----------
2024-05-04 21:02:21,640 - 1736 samples (32 per mini-batch)
2024-05-04 21:02:52,261 - Epoch: [106][   55/   55]    Loss 2.686083    Top1 58.006912    Top5 73.790323    
2024-05-04 21:02:52,381 - ==> Top1: 58.007    Top5: 73.790    Loss: 2.686

2024-05-04 21:02:52,388 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:02:52,389 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:02:52,456 - 

2024-05-04 21:02:52,457 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:03:45,382 - Epoch: [107][  100/  217]    Overall Loss 0.003011    Objective Loss 0.003011                                        LR 0.000250    Time 0.529144    
2024-05-04 21:04:40,034 - Epoch: [107][  200/  217]    Overall Loss 0.002582    Objective Loss 0.002582                                        LR 0.000250    Time 0.537805    
2024-05-04 21:04:46,770 - Epoch: [107][  217/  217]    Overall Loss 0.002488    Objective Loss 0.002488    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.526707    
2024-05-04 21:04:46,909 - --- validate (epoch=107)-----------
2024-05-04 21:04:46,910 - 1736 samples (32 per mini-batch)
2024-05-04 21:05:15,375 - Epoch: [107][   55/   55]    Loss 2.662602    Top1 58.122120    Top5 73.790323    
2024-05-04 21:05:15,497 - ==> Top1: 58.122    Top5: 73.790    Loss: 2.663

2024-05-04 21:05:15,505 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:05:15,505 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:05:15,570 - 

2024-05-04 21:05:15,571 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:06:15,095 - Epoch: [108][  100/  217]    Overall Loss 0.001949    Objective Loss 0.001949                                        LR 0.000250    Time 0.595177    
2024-05-04 21:07:01,424 - Epoch: [108][  200/  217]    Overall Loss 0.002475    Objective Loss 0.002475                                        LR 0.000250    Time 0.529207    
2024-05-04 21:07:07,985 - Epoch: [108][  217/  217]    Overall Loss 0.002443    Objective Loss 0.002443    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.517977    
2024-05-04 21:07:08,117 - --- validate (epoch=108)-----------
2024-05-04 21:07:08,118 - 1736 samples (32 per mini-batch)
2024-05-04 21:07:34,390 - Epoch: [108][   55/   55]    Loss 2.656090    Top1 58.064516    Top5 74.020737    
2024-05-04 21:07:34,490 - ==> Top1: 58.065    Top5: 74.021    Loss: 2.656

2024-05-04 21:07:34,497 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:07:34,498 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:07:34,563 - 

2024-05-04 21:07:34,563 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:08:24,320 - Epoch: [109][  100/  217]    Overall Loss 0.001933    Objective Loss 0.001933                                        LR 0.000250    Time 0.497503    
2024-05-04 21:09:17,662 - Epoch: [109][  200/  217]    Overall Loss 0.002520    Objective Loss 0.002520                                        LR 0.000250    Time 0.515437    
2024-05-04 21:09:26,671 - Epoch: [109][  217/  217]    Overall Loss 0.002435    Objective Loss 0.002435    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.516569    
2024-05-04 21:09:26,807 - --- validate (epoch=109)-----------
2024-05-04 21:09:26,807 - 1736 samples (32 per mini-batch)
2024-05-04 21:09:56,561 - Epoch: [109][   55/   55]    Loss 2.671751    Top1 57.430876    Top5 74.078341    
2024-05-04 21:09:56,716 - ==> Top1: 57.431    Top5: 74.078    Loss: 2.672

2024-05-04 21:09:56,730 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:09:56,731 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:09:56,797 - 

2024-05-04 21:09:56,798 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:10:51,274 - Epoch: [110][  100/  217]    Overall Loss 0.002588    Objective Loss 0.002588                                        LR 0.000250    Time 0.544699    
2024-05-04 21:11:40,749 - Epoch: [110][  200/  217]    Overall Loss 0.002347    Objective Loss 0.002347                                        LR 0.000250    Time 0.519695    
2024-05-04 21:11:47,973 - Epoch: [110][  217/  217]    Overall Loss 0.002298    Objective Loss 0.002298    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.512269    
2024-05-04 21:11:48,163 - --- validate (epoch=110)-----------
2024-05-04 21:11:48,163 - 1736 samples (32 per mini-batch)
2024-05-04 21:12:18,416 - Epoch: [110][   55/   55]    Loss 2.672860    Top1 57.776498    Top5 74.078341    
2024-05-04 21:12:18,577 - ==> Top1: 57.776    Top5: 74.078    Loss: 2.673

2024-05-04 21:12:18,584 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:12:18,584 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:12:18,648 - 

2024-05-04 21:12:18,648 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:13:11,628 - Epoch: [111][  100/  217]    Overall Loss 0.002576    Objective Loss 0.002576                                        LR 0.000250    Time 0.529730    
2024-05-04 21:13:56,554 - Epoch: [111][  200/  217]    Overall Loss 0.002178    Objective Loss 0.002178                                        LR 0.000250    Time 0.489469    
2024-05-04 21:14:03,805 - Epoch: [111][  217/  217]    Overall Loss 0.002091    Objective Loss 0.002091    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.484531    
2024-05-04 21:14:03,967 - --- validate (epoch=111)-----------
2024-05-04 21:14:03,968 - 1736 samples (32 per mini-batch)
2024-05-04 21:14:32,730 - Epoch: [111][   55/   55]    Loss 2.633700    Top1 57.834101    Top5 73.963134    
2024-05-04 21:14:32,856 - ==> Top1: 57.834    Top5: 73.963    Loss: 2.634

2024-05-04 21:14:32,863 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:14:32,863 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:14:32,926 - 

2024-05-04 21:14:32,926 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:15:24,204 - Epoch: [112][  100/  217]    Overall Loss 0.002245    Objective Loss 0.002245                                        LR 0.000250    Time 0.512718    
2024-05-04 21:16:10,023 - Epoch: [112][  200/  217]    Overall Loss 0.002096    Objective Loss 0.002096                                        LR 0.000250    Time 0.485431    
2024-05-04 21:16:18,896 - Epoch: [112][  217/  217]    Overall Loss 0.002033    Objective Loss 0.002033    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.488285    
2024-05-04 21:16:19,001 - --- validate (epoch=112)-----------
2024-05-04 21:16:19,001 - 1736 samples (32 per mini-batch)
2024-05-04 21:16:51,476 - Epoch: [112][   55/   55]    Loss 2.685660    Top1 58.006912    Top5 74.078341    
2024-05-04 21:16:51,601 - ==> Top1: 58.007    Top5: 74.078    Loss: 2.686

2024-05-04 21:16:51,607 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:16:51,608 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:16:51,669 - 

2024-05-04 21:16:51,670 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:17:49,967 - Epoch: [113][  100/  217]    Overall Loss 0.001451    Objective Loss 0.001451                                        LR 0.000250    Time 0.582904    
2024-05-04 21:18:34,692 - Epoch: [113][  200/  217]    Overall Loss 0.001933    Objective Loss 0.001933                                        LR 0.000250    Time 0.515056    
2024-05-04 21:18:45,141 - Epoch: [113][  217/  217]    Overall Loss 0.001863    Objective Loss 0.001863    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.522854    
2024-05-04 21:18:45,280 - --- validate (epoch=113)-----------
2024-05-04 21:18:45,281 - 1736 samples (32 per mini-batch)
2024-05-04 21:19:11,735 - Epoch: [113][   55/   55]    Loss 2.709469    Top1 58.179724    Top5 73.963134    
2024-05-04 21:19:11,866 - ==> Top1: 58.180    Top5: 73.963    Loss: 2.709

2024-05-04 21:19:11,873 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:19:11,873 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:19:11,935 - 

2024-05-04 21:19:11,935 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:20:03,435 - Epoch: [114][  100/  217]    Overall Loss 0.002214    Objective Loss 0.002214                                        LR 0.000250    Time 0.514931    
2024-05-04 21:20:53,020 - Epoch: [114][  200/  217]    Overall Loss 0.001956    Objective Loss 0.001956                                        LR 0.000250    Time 0.505364    
2024-05-04 21:21:03,462 - Epoch: [114][  217/  217]    Overall Loss 0.001895    Objective Loss 0.001895    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.513890    
2024-05-04 21:21:03,644 - --- validate (epoch=114)-----------
2024-05-04 21:21:03,644 - 1736 samples (32 per mini-batch)
2024-05-04 21:21:31,255 - Epoch: [114][   55/   55]    Loss 2.699149    Top1 57.891705    Top5 74.078341    
2024-05-04 21:21:31,393 - ==> Top1: 57.892    Top5: 74.078    Loss: 2.699

2024-05-04 21:21:31,403 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:21:31,403 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:21:31,465 - 

2024-05-04 21:21:31,466 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:22:21,335 - Epoch: [115][  100/  217]    Overall Loss 0.002132    Objective Loss 0.002132                                        LR 0.000250    Time 0.498628    
2024-05-04 21:23:08,501 - Epoch: [115][  200/  217]    Overall Loss 0.001584    Objective Loss 0.001584                                        LR 0.000250    Time 0.485095    
2024-05-04 21:23:16,203 - Epoch: [115][  217/  217]    Overall Loss 0.001737    Objective Loss 0.001737    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.482581    
2024-05-04 21:23:16,305 - --- validate (epoch=115)-----------
2024-05-04 21:23:16,305 - 1736 samples (32 per mini-batch)
2024-05-04 21:23:46,986 - Epoch: [115][   55/   55]    Loss 2.680850    Top1 58.237327    Top5 73.444700    
2024-05-04 21:23:47,114 - ==> Top1: 58.237    Top5: 73.445    Loss: 2.681

2024-05-04 21:23:47,119 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:23:47,119 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:23:47,162 - 

2024-05-04 21:23:47,162 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:24:41,030 - Epoch: [116][  100/  217]    Overall Loss 0.001225    Objective Loss 0.001225                                        LR 0.000250    Time 0.538612    
2024-05-04 21:25:29,313 - Epoch: [116][  200/  217]    Overall Loss 0.001917    Objective Loss 0.001917                                        LR 0.000250    Time 0.510697    
2024-05-04 21:25:35,952 - Epoch: [116][  217/  217]    Overall Loss 0.001923    Objective Loss 0.001923    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.501266    
2024-05-04 21:25:36,076 - --- validate (epoch=116)-----------
2024-05-04 21:25:36,076 - 1736 samples (32 per mini-batch)
2024-05-04 21:26:04,602 - Epoch: [116][   55/   55]    Loss 2.666676    Top1 58.064516    Top5 73.502304    
2024-05-04 21:26:04,715 - ==> Top1: 58.065    Top5: 73.502    Loss: 2.667

2024-05-04 21:26:04,721 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:26:04,721 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:26:04,783 - 

2024-05-04 21:26:04,783 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:26:58,242 - Epoch: [117][  100/  217]    Overall Loss 0.001987    Objective Loss 0.001987                                        LR 0.000250    Time 0.534516    
2024-05-04 21:27:49,399 - Epoch: [117][  200/  217]    Overall Loss 0.003289    Objective Loss 0.003289                                        LR 0.000250    Time 0.523018    
2024-05-04 21:28:02,483 - Epoch: [117][  217/  217]    Overall Loss 0.003393    Objective Loss 0.003393    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.542333    
2024-05-04 21:28:02,732 - --- validate (epoch=117)-----------
2024-05-04 21:28:02,733 - 1736 samples (32 per mini-batch)
2024-05-04 21:28:30,238 - Epoch: [117][   55/   55]    Loss 2.730739    Top1 57.546083    Top5 73.387097    
2024-05-04 21:28:30,349 - ==> Top1: 57.546    Top5: 73.387    Loss: 2.731

2024-05-04 21:28:30,354 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:28:30,354 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:28:30,395 - 

2024-05-04 21:28:30,395 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:29:18,088 - Epoch: [118][  100/  217]    Overall Loss 0.003628    Objective Loss 0.003628                                        LR 0.000250    Time 0.476869    
2024-05-04 21:30:02,993 - Epoch: [118][  200/  217]    Overall Loss 0.002978    Objective Loss 0.002978                                        LR 0.000250    Time 0.462935    
2024-05-04 21:30:12,403 - Epoch: [118][  217/  217]    Overall Loss 0.003343    Objective Loss 0.003343    Top1 98.360656    Top5 100.000000    LR 0.000250    Time 0.470025    
2024-05-04 21:30:12,531 - --- validate (epoch=118)-----------
2024-05-04 21:30:12,532 - 1736 samples (32 per mini-batch)
2024-05-04 21:30:40,876 - Epoch: [118][   55/   55]    Loss 2.737201    Top1 57.546083    Top5 73.675115    
2024-05-04 21:30:40,988 - ==> Top1: 57.546    Top5: 73.675    Loss: 2.737

2024-05-04 21:30:40,995 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:30:40,995 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:30:41,058 - 

2024-05-04 21:30:41,059 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:31:36,050 - Epoch: [119][  100/  217]    Overall Loss 0.002133    Objective Loss 0.002133                                        LR 0.000250    Time 0.549851    
2024-05-04 21:32:21,353 - Epoch: [119][  200/  217]    Overall Loss 0.002049    Objective Loss 0.002049                                        LR 0.000250    Time 0.501411    
2024-05-04 21:32:29,642 - Epoch: [119][  217/  217]    Overall Loss 0.002034    Objective Loss 0.002034    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.500323    
2024-05-04 21:32:29,767 - --- validate (epoch=119)-----------
2024-05-04 21:32:29,767 - 1736 samples (32 per mini-batch)
2024-05-04 21:32:59,485 - Epoch: [119][   55/   55]    Loss 2.715492    Top1 57.373272    Top5 73.732719    
2024-05-04 21:32:59,597 - ==> Top1: 57.373    Top5: 73.733    Loss: 2.715

2024-05-04 21:32:59,602 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:32:59,602 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:32:59,650 - 

2024-05-04 21:32:59,650 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:33:51,893 - Epoch: [120][  100/  217]    Overall Loss 0.001820    Objective Loss 0.001820                                        LR 0.000250    Time 0.522364    
2024-05-04 21:34:51,161 - Epoch: [120][  200/  217]    Overall Loss 0.002023    Objective Loss 0.002023                                        LR 0.000250    Time 0.557495    
2024-05-04 21:35:01,290 - Epoch: [120][  217/  217]    Overall Loss 0.001929    Objective Loss 0.001929    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.560491    
2024-05-04 21:35:01,415 - --- validate (epoch=120)-----------
2024-05-04 21:35:01,415 - 1736 samples (32 per mini-batch)
2024-05-04 21:35:32,643 - Epoch: [120][   55/   55]    Loss 2.734890    Top1 58.179724    Top5 73.732719    
2024-05-04 21:35:32,862 - ==> Top1: 58.180    Top5: 73.733    Loss: 2.735

2024-05-04 21:35:32,868 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:35:32,869 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:35:32,934 - 

2024-05-04 21:35:32,935 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:36:29,892 - Epoch: [121][  100/  217]    Overall Loss 0.001658    Objective Loss 0.001658                                        LR 0.000250    Time 0.569495    
2024-05-04 21:37:12,415 - Epoch: [121][  200/  217]    Overall Loss 0.002937    Objective Loss 0.002937                                        LR 0.000250    Time 0.497332    
2024-05-04 21:37:20,604 - Epoch: [121][  217/  217]    Overall Loss 0.002947    Objective Loss 0.002947    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.496101    
2024-05-04 21:37:20,746 - --- validate (epoch=121)-----------
2024-05-04 21:37:20,747 - 1736 samples (32 per mini-batch)
2024-05-04 21:37:51,584 - Epoch: [121][   55/   55]    Loss 2.786135    Top1 57.027650    Top5 73.675115    
2024-05-04 21:37:51,719 - ==> Top1: 57.028    Top5: 73.675    Loss: 2.786

2024-05-04 21:37:51,726 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:37:51,726 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:37:51,771 - 

2024-05-04 21:37:51,771 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:38:43,961 - Epoch: [122][  100/  217]    Overall Loss 0.001920    Objective Loss 0.001920                                        LR 0.000250    Time 0.521836    
2024-05-04 21:39:32,036 - Epoch: [122][  200/  217]    Overall Loss 0.002522    Objective Loss 0.002522                                        LR 0.000250    Time 0.501262    
2024-05-04 21:39:39,785 - Epoch: [122][  217/  217]    Overall Loss 0.002417    Objective Loss 0.002417    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.497701    
2024-05-04 21:39:39,911 - --- validate (epoch=122)-----------
2024-05-04 21:39:39,912 - 1736 samples (32 per mini-batch)
2024-05-04 21:40:08,122 - Epoch: [122][   55/   55]    Loss 2.752160    Top1 57.834101    Top5 73.387097    
2024-05-04 21:40:08,243 - ==> Top1: 57.834    Top5: 73.387    Loss: 2.752

2024-05-04 21:40:08,250 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:40:08,250 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:40:08,292 - 

2024-05-04 21:40:08,293 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:40:54,294 - Epoch: [123][  100/  217]    Overall Loss 0.002301    Objective Loss 0.002301                                        LR 0.000250    Time 0.459947    
2024-05-04 21:41:41,977 - Epoch: [123][  200/  217]    Overall Loss 0.001797    Objective Loss 0.001797                                        LR 0.000250    Time 0.468364    
2024-05-04 21:41:46,724 - Epoch: [123][  217/  217]    Overall Loss 0.001903    Objective Loss 0.001903    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.453545    
2024-05-04 21:41:46,844 - --- validate (epoch=123)-----------
2024-05-04 21:41:46,844 - 1736 samples (32 per mini-batch)
2024-05-04 21:42:17,658 - Epoch: [123][   55/   55]    Loss 2.779436    Top1 57.258065    Top5 73.444700    
2024-05-04 21:42:17,762 - ==> Top1: 57.258    Top5: 73.445    Loss: 2.779

2024-05-04 21:42:17,769 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:42:17,769 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:42:17,836 - 

2024-05-04 21:42:17,837 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:43:10,882 - Epoch: [124][  100/  217]    Overall Loss 0.002117    Objective Loss 0.002117                                        LR 0.000250    Time 0.530382    
2024-05-04 21:44:02,741 - Epoch: [124][  200/  217]    Overall Loss 0.001642    Objective Loss 0.001642                                        LR 0.000250    Time 0.524434    
2024-05-04 21:44:10,941 - Epoch: [124][  217/  217]    Overall Loss 0.001765    Objective Loss 0.001765    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.521132    
2024-05-04 21:44:11,130 - --- validate (epoch=124)-----------
2024-05-04 21:44:11,130 - 1736 samples (32 per mini-batch)
2024-05-04 21:44:39,933 - Epoch: [124][   55/   55]    Loss 2.780760    Top1 57.718894    Top5 73.559908    
2024-05-04 21:44:40,104 - ==> Top1: 57.719    Top5: 73.560    Loss: 2.781

2024-05-04 21:44:40,111 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:44:40,112 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:44:40,185 - 

2024-05-04 21:44:40,185 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:45:30,183 - Epoch: [125][  100/  217]    Overall Loss 0.002078    Objective Loss 0.002078                                        LR 0.000250    Time 0.499897    
2024-05-04 21:46:21,686 - Epoch: [125][  200/  217]    Overall Loss 0.001639    Objective Loss 0.001639                                        LR 0.000250    Time 0.507438    
2024-05-04 21:46:30,464 - Epoch: [125][  217/  217]    Overall Loss 0.001565    Objective Loss 0.001565    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.508127    
2024-05-04 21:46:30,586 - --- validate (epoch=125)-----------
2024-05-04 21:46:30,586 - 1736 samples (32 per mini-batch)
2024-05-04 21:47:00,368 - Epoch: [125][   55/   55]    Loss 2.729216    Top1 58.064516    Top5 74.193548    
2024-05-04 21:47:00,518 - ==> Top1: 58.065    Top5: 74.194    Loss: 2.729

2024-05-04 21:47:00,525 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:47:00,525 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:47:00,593 - 

2024-05-04 21:47:00,593 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:47:49,844 - Epoch: [126][  100/  217]    Overall Loss 0.001024    Objective Loss 0.001024                                        LR 0.000250    Time 0.492441    
2024-05-04 21:48:41,239 - Epoch: [126][  200/  217]    Overall Loss 0.001473    Objective Loss 0.001473                                        LR 0.000250    Time 0.503167    
2024-05-04 21:48:49,653 - Epoch: [126][  217/  217]    Overall Loss 0.001582    Objective Loss 0.001582    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.502520    
2024-05-04 21:48:49,858 - --- validate (epoch=126)-----------
2024-05-04 21:48:49,859 - 1736 samples (32 per mini-batch)
2024-05-04 21:49:21,249 - Epoch: [126][   55/   55]    Loss 2.796163    Top1 57.430876    Top5 73.444700    
2024-05-04 21:49:21,411 - ==> Top1: 57.431    Top5: 73.445    Loss: 2.796

2024-05-04 21:49:21,419 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:49:21,419 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:49:21,487 - 

2024-05-04 21:49:21,488 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:50:14,272 - Epoch: [127][  100/  217]    Overall Loss 0.001562    Objective Loss 0.001562                                        LR 0.000250    Time 0.527772    
2024-05-04 21:51:05,383 - Epoch: [127][  200/  217]    Overall Loss 0.001637    Objective Loss 0.001637                                        LR 0.000250    Time 0.519411    
2024-05-04 21:51:14,336 - Epoch: [127][  217/  217]    Overall Loss 0.001569    Objective Loss 0.001569    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.519975    
2024-05-04 21:51:14,516 - --- validate (epoch=127)-----------
2024-05-04 21:51:14,516 - 1736 samples (32 per mini-batch)
2024-05-04 21:51:48,256 - Epoch: [127][   55/   55]    Loss 2.760992    Top1 57.546083    Top5 73.963134    
2024-05-04 21:51:48,361 - ==> Top1: 57.546    Top5: 73.963    Loss: 2.761

2024-05-04 21:51:48,369 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:51:48,369 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:51:48,434 - 

2024-05-04 21:51:48,435 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:52:42,082 - Epoch: [128][  100/  217]    Overall Loss 0.001094    Objective Loss 0.001094                                        LR 0.000250    Time 0.536396    
2024-05-04 21:53:27,198 - Epoch: [128][  200/  217]    Overall Loss 0.001062    Objective Loss 0.001062                                        LR 0.000250    Time 0.493751    
2024-05-04 21:53:35,018 - Epoch: [128][  217/  217]    Overall Loss 0.001322    Objective Loss 0.001322    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.491103    
2024-05-04 21:53:35,186 - --- validate (epoch=128)-----------
2024-05-04 21:53:35,187 - 1736 samples (32 per mini-batch)
2024-05-04 21:54:05,701 - Epoch: [128][   55/   55]    Loss 2.798390    Top1 57.834101    Top5 73.329493    
2024-05-04 21:54:05,829 - ==> Top1: 57.834    Top5: 73.329    Loss: 2.798

2024-05-04 21:54:05,836 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:54:05,836 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:54:05,899 - 

2024-05-04 21:54:05,900 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:54:55,312 - Epoch: [129][  100/  217]    Overall Loss 0.001602    Objective Loss 0.001602                                        LR 0.000250    Time 0.494061    
2024-05-04 21:55:42,106 - Epoch: [129][  200/  217]    Overall Loss 0.002191    Objective Loss 0.002191                                        LR 0.000250    Time 0.480970    
2024-05-04 21:55:50,287 - Epoch: [129][  217/  217]    Overall Loss 0.002309    Objective Loss 0.002309    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.480987    
2024-05-04 21:55:50,382 - --- validate (epoch=129)-----------
2024-05-04 21:55:50,382 - 1736 samples (32 per mini-batch)
2024-05-04 21:56:21,441 - Epoch: [129][   55/   55]    Loss 2.788910    Top1 57.603687    Top5 73.559908    
2024-05-04 21:56:21,599 - ==> Top1: 57.604    Top5: 73.560    Loss: 2.789

2024-05-04 21:56:21,606 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:56:21,606 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:56:21,670 - 

2024-05-04 21:56:21,670 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:57:16,041 - Epoch: [130][  100/  217]    Overall Loss 0.002036    Objective Loss 0.002036                                        LR 0.000250    Time 0.543637    
2024-05-04 21:58:06,157 - Epoch: [130][  200/  217]    Overall Loss 0.001850    Objective Loss 0.001850                                        LR 0.000250    Time 0.522372    
2024-05-04 21:58:12,010 - Epoch: [130][  217/  217]    Overall Loss 0.002483    Objective Loss 0.002483    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.508415    
2024-05-04 21:58:12,125 - --- validate (epoch=130)-----------
2024-05-04 21:58:12,126 - 1736 samples (32 per mini-batch)
2024-05-04 21:58:40,951 - Epoch: [130][   55/   55]    Loss 3.185923    Top1 54.953917    Top5 71.313364    
2024-05-04 21:58:41,090 - ==> Top1: 54.954    Top5: 71.313    Loss: 3.186

2024-05-04 21:58:41,094 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 21:58:41,095 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 21:58:41,138 - 

2024-05-04 21:58:41,138 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 21:59:30,108 - Epoch: [131][  100/  217]    Overall Loss 0.009086    Objective Loss 0.009086                                        LR 0.000250    Time 0.489632    
2024-05-04 22:00:22,549 - Epoch: [131][  200/  217]    Overall Loss 0.009644    Objective Loss 0.009644                                        LR 0.000250    Time 0.507001    
2024-05-04 22:00:27,527 - Epoch: [131][  217/  217]    Overall Loss 0.009141    Objective Loss 0.009141    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.490215    
2024-05-04 22:00:27,648 - --- validate (epoch=131)-----------
2024-05-04 22:00:27,648 - 1736 samples (32 per mini-batch)
2024-05-04 22:00:56,722 - Epoch: [131][   55/   55]    Loss 2.848176    Top1 57.603687    Top5 73.041475    
2024-05-04 22:00:56,826 - ==> Top1: 57.604    Top5: 73.041    Loss: 2.848

2024-05-04 22:00:56,835 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:00:56,835 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:00:56,897 - 

2024-05-04 22:00:56,897 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:01:47,141 - Epoch: [132][  100/  217]    Overall Loss 0.003309    Objective Loss 0.003309                                        LR 0.000250    Time 0.502373    
2024-05-04 22:02:38,775 - Epoch: [132][  200/  217]    Overall Loss 0.003187    Objective Loss 0.003187                                        LR 0.000250    Time 0.509328    
2024-05-04 22:02:44,872 - Epoch: [132][  217/  217]    Overall Loss 0.003165    Objective Loss 0.003165    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.497518    
2024-05-04 22:02:44,984 - --- validate (epoch=132)-----------
2024-05-04 22:02:44,985 - 1736 samples (32 per mini-batch)
2024-05-04 22:03:11,972 - Epoch: [132][   55/   55]    Loss 2.827763    Top1 57.718894    Top5 73.387097    
2024-05-04 22:03:12,078 - ==> Top1: 57.719    Top5: 73.387    Loss: 2.828

2024-05-04 22:03:12,085 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:03:12,085 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:03:12,150 - 

2024-05-04 22:03:12,151 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:04:04,035 - Epoch: [133][  100/  217]    Overall Loss 0.001678    Objective Loss 0.001678                                        LR 0.000250    Time 0.518773    
2024-05-04 22:04:53,340 - Epoch: [133][  200/  217]    Overall Loss 0.002160    Objective Loss 0.002160                                        LR 0.000250    Time 0.505882    
2024-05-04 22:05:01,672 - Epoch: [133][  217/  217]    Overall Loss 0.002117    Objective Loss 0.002117    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.504640    
2024-05-04 22:05:01,806 - --- validate (epoch=133)-----------
2024-05-04 22:05:01,806 - 1736 samples (32 per mini-batch)
2024-05-04 22:05:34,109 - Epoch: [133][   55/   55]    Loss 2.814642    Top1 57.661290    Top5 74.193548    
2024-05-04 22:05:34,238 - ==> Top1: 57.661    Top5: 74.194    Loss: 2.815

2024-05-04 22:05:34,245 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:05:34,245 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:05:34,307 - 

2024-05-04 22:05:34,308 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:06:29,009 - Epoch: [134][  100/  217]    Overall Loss 0.001881    Objective Loss 0.001881                                        LR 0.000250    Time 0.546944    
2024-05-04 22:07:12,511 - Epoch: [134][  200/  217]    Overall Loss 0.001660    Objective Loss 0.001660                                        LR 0.000250    Time 0.490957    
2024-05-04 22:07:20,111 - Epoch: [134][  217/  217]    Overall Loss 0.001651    Objective Loss 0.001651    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.487512    
2024-05-04 22:07:20,262 - --- validate (epoch=134)-----------
2024-05-04 22:07:20,262 - 1736 samples (32 per mini-batch)
2024-05-04 22:07:52,312 - Epoch: [134][   55/   55]    Loss 2.860634    Top1 57.430876    Top5 73.617512    
2024-05-04 22:07:52,451 - ==> Top1: 57.431    Top5: 73.618    Loss: 2.861

2024-05-04 22:07:52,457 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:07:52,458 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:07:52,524 - 

2024-05-04 22:07:52,524 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:08:48,571 - Epoch: [135][  100/  217]    Overall Loss 0.001651    Objective Loss 0.001651                                        LR 0.000250    Time 0.560401    
2024-05-04 22:09:37,231 - Epoch: [135][  200/  217]    Overall Loss 0.001613    Objective Loss 0.001613                                        LR 0.000250    Time 0.523475    
2024-05-04 22:09:49,812 - Epoch: [135][  217/  217]    Overall Loss 0.001543    Objective Loss 0.001543    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.540419    
2024-05-04 22:09:49,943 - --- validate (epoch=135)-----------
2024-05-04 22:09:49,943 - 1736 samples (32 per mini-batch)
2024-05-04 22:10:25,259 - Epoch: [135][   55/   55]    Loss 2.850983    Top1 57.834101    Top5 73.675115    
2024-05-04 22:10:25,418 - ==> Top1: 57.834    Top5: 73.675    Loss: 2.851

2024-05-04 22:10:25,427 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:10:25,428 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:10:25,497 - 

2024-05-04 22:10:25,497 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:11:19,275 - Epoch: [136][  100/  217]    Overall Loss 0.001086    Objective Loss 0.001086                                        LR 0.000250    Time 0.537713    
2024-05-04 22:12:18,141 - Epoch: [136][  200/  217]    Overall Loss 0.001393    Objective Loss 0.001393                                        LR 0.000250    Time 0.563162    
2024-05-04 22:12:28,886 - Epoch: [136][  217/  217]    Overall Loss 0.001581    Objective Loss 0.001581    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.568551    
2024-05-04 22:12:29,018 - --- validate (epoch=136)-----------
2024-05-04 22:12:29,019 - 1736 samples (32 per mini-batch)
2024-05-04 22:13:01,332 - Epoch: [136][   55/   55]    Loss 2.839723    Top1 57.891705    Top5 73.502304    
2024-05-04 22:13:01,434 - ==> Top1: 57.892    Top5: 73.502    Loss: 2.840

2024-05-04 22:13:01,439 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:13:01,439 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:13:01,484 - 

2024-05-04 22:13:01,484 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:13:44,050 - Epoch: [137][  100/  217]    Overall Loss 0.001081    Objective Loss 0.001081                                        LR 0.000250    Time 0.425606    
2024-05-04 22:14:33,760 - Epoch: [137][  200/  217]    Overall Loss 0.001242    Objective Loss 0.001242                                        LR 0.000250    Time 0.461313    
2024-05-04 22:14:43,183 - Epoch: [137][  217/  217]    Overall Loss 0.001215    Objective Loss 0.001215    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.468589    
2024-05-04 22:14:43,286 - --- validate (epoch=137)-----------
2024-05-04 22:14:43,286 - 1736 samples (32 per mini-batch)
2024-05-04 22:15:12,433 - Epoch: [137][   55/   55]    Loss 2.870806    Top1 57.603687    Top5 73.444700    
2024-05-04 22:15:12,576 - ==> Top1: 57.604    Top5: 73.445    Loss: 2.871

2024-05-04 22:15:12,584 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:15:12,584 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:15:12,651 - 

2024-05-04 22:15:12,651 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:16:08,716 - Epoch: [138][  100/  217]    Overall Loss 0.001307    Objective Loss 0.001307                                        LR 0.000250    Time 0.560578    
2024-05-04 22:17:01,859 - Epoch: [138][  200/  217]    Overall Loss 0.001111    Objective Loss 0.001111                                        LR 0.000250    Time 0.545976    
2024-05-04 22:17:11,193 - Epoch: [138][  217/  217]    Overall Loss 0.001067    Objective Loss 0.001067    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.546208    
2024-05-04 22:17:11,342 - --- validate (epoch=138)-----------
2024-05-04 22:17:11,343 - 1736 samples (32 per mini-batch)
2024-05-04 22:17:42,755 - Epoch: [138][   55/   55]    Loss 2.881707    Top1 57.488479    Top5 73.963134    
2024-05-04 22:17:42,866 - ==> Top1: 57.488    Top5: 73.963    Loss: 2.882

2024-05-04 22:17:42,872 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:17:42,873 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:17:42,934 - 

2024-05-04 22:17:42,934 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:18:40,304 - Epoch: [139][  100/  217]    Overall Loss 0.000782    Objective Loss 0.000782                                        LR 0.000250    Time 0.573635    
2024-05-04 22:19:29,731 - Epoch: [139][  200/  217]    Overall Loss 0.001083    Objective Loss 0.001083                                        LR 0.000250    Time 0.533926    
2024-05-04 22:19:39,576 - Epoch: [139][  217/  217]    Overall Loss 0.001204    Objective Loss 0.001204    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.537458    
2024-05-04 22:19:39,706 - --- validate (epoch=139)-----------
2024-05-04 22:19:39,706 - 1736 samples (32 per mini-batch)
2024-05-04 22:20:12,467 - Epoch: [139][   55/   55]    Loss 2.889278    Top1 57.546083    Top5 73.790323    
2024-05-04 22:20:12,581 - ==> Top1: 57.546    Top5: 73.790    Loss: 2.889

2024-05-04 22:20:12,585 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:20:12,586 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:20:12,628 - 

2024-05-04 22:20:12,629 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:21:14,860 - Epoch: [140][  100/  217]    Overall Loss 0.000896    Objective Loss 0.000896                                        LR 0.000250    Time 0.622249    
2024-05-04 22:22:11,382 - Epoch: [140][  200/  217]    Overall Loss 0.001195    Objective Loss 0.001195                                        LR 0.000250    Time 0.593708    
2024-05-04 22:22:16,610 - Epoch: [140][  217/  217]    Overall Loss 0.001159    Objective Loss 0.001159    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.571281    
2024-05-04 22:22:16,721 - --- validate (epoch=140)-----------
2024-05-04 22:22:16,722 - 1736 samples (32 per mini-batch)
2024-05-04 22:22:45,434 - Epoch: [140][   55/   55]    Loss 2.905880    Top1 57.603687    Top5 73.559908    
2024-05-04 22:22:45,590 - ==> Top1: 57.604    Top5: 73.560    Loss: 2.906

2024-05-04 22:22:45,597 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:22:45,597 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:22:45,659 - 

2024-05-04 22:22:45,660 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:23:37,075 - Epoch: [141][  100/  217]    Overall Loss 0.001076    Objective Loss 0.001076                                        LR 0.000250    Time 0.514087    
2024-05-04 22:24:25,439 - Epoch: [141][  200/  217]    Overall Loss 0.001090    Objective Loss 0.001090                                        LR 0.000250    Time 0.498836    
2024-05-04 22:24:33,385 - Epoch: [141][  217/  217]    Overall Loss 0.001043    Objective Loss 0.001043    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.496362    
2024-05-04 22:24:33,568 - --- validate (epoch=141)-----------
2024-05-04 22:24:33,568 - 1736 samples (32 per mini-batch)
2024-05-04 22:25:05,388 - Epoch: [141][   55/   55]    Loss 2.866217    Top1 58.064516    Top5 73.847926    
2024-05-04 22:25:05,519 - ==> Top1: 58.065    Top5: 73.848    Loss: 2.866

2024-05-04 22:25:05,526 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:25:05,526 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:25:05,593 - 

2024-05-04 22:25:05,593 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:25:59,990 - Epoch: [142][  100/  217]    Overall Loss 0.000751    Objective Loss 0.000751                                        LR 0.000250    Time 0.543897    
2024-05-04 22:26:46,036 - Epoch: [142][  200/  217]    Overall Loss 0.001042    Objective Loss 0.001042                                        LR 0.000250    Time 0.502153    
2024-05-04 22:26:52,566 - Epoch: [142][  217/  217]    Overall Loss 0.000997    Objective Loss 0.000997    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.492900    
2024-05-04 22:26:52,703 - --- validate (epoch=142)-----------
2024-05-04 22:26:52,704 - 1736 samples (32 per mini-batch)
2024-05-04 22:27:21,805 - Epoch: [142][   55/   55]    Loss 2.860657    Top1 57.891705    Top5 73.675115    
2024-05-04 22:27:21,969 - ==> Top1: 57.892    Top5: 73.675    Loss: 2.861

2024-05-04 22:27:21,976 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:27:21,977 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:27:22,039 - 

2024-05-04 22:27:22,039 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:28:16,316 - Epoch: [143][  100/  217]    Overall Loss 0.001244    Objective Loss 0.001244                                        LR 0.000250    Time 0.542698    
2024-05-04 22:29:04,409 - Epoch: [143][  200/  217]    Overall Loss 0.000967    Objective Loss 0.000967                                        LR 0.000250    Time 0.511788    
2024-05-04 22:29:13,257 - Epoch: [143][  217/  217]    Overall Loss 0.000944    Objective Loss 0.000944    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.512459    
2024-05-04 22:29:13,442 - --- validate (epoch=143)-----------
2024-05-04 22:29:13,443 - 1736 samples (32 per mini-batch)
2024-05-04 22:29:44,008 - Epoch: [143][   55/   55]    Loss 2.890752    Top1 58.064516    Top5 74.193548    
2024-05-04 22:29:44,171 - ==> Top1: 58.065    Top5: 74.194    Loss: 2.891

2024-05-04 22:29:44,178 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:29:44,179 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:29:44,242 - 

2024-05-04 22:29:44,243 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:30:37,117 - Epoch: [144][  100/  217]    Overall Loss 0.000862    Objective Loss 0.000862                                        LR 0.000250    Time 0.528671    
2024-05-04 22:31:25,995 - Epoch: [144][  200/  217]    Overall Loss 0.000870    Objective Loss 0.000870                                        LR 0.000250    Time 0.508699    
2024-05-04 22:31:33,046 - Epoch: [144][  217/  217]    Overall Loss 0.000838    Objective Loss 0.000838    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.501332    
2024-05-04 22:31:33,166 - --- validate (epoch=144)-----------
2024-05-04 22:31:33,166 - 1736 samples (32 per mini-batch)
2024-05-04 22:32:04,245 - Epoch: [144][   55/   55]    Loss 2.846182    Top1 57.949309    Top5 73.732719    
2024-05-04 22:32:04,424 - ==> Top1: 57.949    Top5: 73.733    Loss: 2.846

2024-05-04 22:32:04,433 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:32:04,433 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:32:04,490 - 

2024-05-04 22:32:04,490 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:32:58,940 - Epoch: [145][  100/  217]    Overall Loss 0.001661    Objective Loss 0.001661                                        LR 0.000250    Time 0.544437    
2024-05-04 22:33:43,533 - Epoch: [145][  200/  217]    Overall Loss 0.001008    Objective Loss 0.001008                                        LR 0.000250    Time 0.495154    
2024-05-04 22:33:52,429 - Epoch: [145][  217/  217]    Overall Loss 0.000963    Objective Loss 0.000963    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.497351    
2024-05-04 22:33:52,641 - --- validate (epoch=145)-----------
2024-05-04 22:33:52,641 - 1736 samples (32 per mini-batch)
2024-05-04 22:34:20,233 - Epoch: [145][   55/   55]    Loss 2.879321    Top1 58.410138    Top5 73.559908    
2024-05-04 22:34:20,441 - ==> Top1: 58.410    Top5: 73.560    Loss: 2.879

2024-05-04 22:34:20,448 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:34:20,449 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:34:20,519 - 

2024-05-04 22:34:20,520 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:35:12,703 - Epoch: [146][  100/  217]    Overall Loss 0.000519    Objective Loss 0.000519                                        LR 0.000250    Time 0.521758    
2024-05-04 22:35:58,092 - Epoch: [146][  200/  217]    Overall Loss 0.001108    Objective Loss 0.001108                                        LR 0.000250    Time 0.487794    
2024-05-04 22:36:05,034 - Epoch: [146][  217/  217]    Overall Loss 0.001045    Objective Loss 0.001045    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.481567    
2024-05-04 22:36:05,190 - --- validate (epoch=146)-----------
2024-05-04 22:36:05,191 - 1736 samples (32 per mini-batch)
2024-05-04 22:36:34,352 - Epoch: [146][   55/   55]    Loss 2.845976    Top1 58.006912    Top5 74.251152    
2024-05-04 22:36:34,506 - ==> Top1: 58.007    Top5: 74.251    Loss: 2.846

2024-05-04 22:36:34,516 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:36:34,517 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:36:34,581 - 

2024-05-04 22:36:34,581 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:37:33,430 - Epoch: [147][  100/  217]    Overall Loss 0.001025    Objective Loss 0.001025                                        LR 0.000250    Time 0.588420    
2024-05-04 22:38:21,582 - Epoch: [147][  200/  217]    Overall Loss 0.001216    Objective Loss 0.001216                                        LR 0.000250    Time 0.534941    
2024-05-04 22:38:32,721 - Epoch: [147][  217/  217]    Overall Loss 0.001144    Objective Loss 0.001144    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.544358    
2024-05-04 22:38:32,906 - --- validate (epoch=147)-----------
2024-05-04 22:38:32,907 - 1736 samples (32 per mini-batch)
2024-05-04 22:39:03,297 - Epoch: [147][   55/   55]    Loss 2.890081    Top1 57.891705    Top5 74.135945    
2024-05-04 22:39:03,429 - ==> Top1: 57.892    Top5: 74.136    Loss: 2.890

2024-05-04 22:39:03,436 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:39:03,436 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:39:03,498 - 

2024-05-04 22:39:03,498 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:39:58,212 - Epoch: [148][  100/  217]    Overall Loss 0.001024    Objective Loss 0.001024                                        LR 0.000250    Time 0.547066    
2024-05-04 22:40:48,514 - Epoch: [148][  200/  217]    Overall Loss 0.001009    Objective Loss 0.001009                                        LR 0.000250    Time 0.525015    
2024-05-04 22:40:56,669 - Epoch: [148][  217/  217]    Overall Loss 0.000956    Objective Loss 0.000956    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.521461    
2024-05-04 22:40:56,803 - --- validate (epoch=148)-----------
2024-05-04 22:40:56,803 - 1736 samples (32 per mini-batch)
2024-05-04 22:41:30,440 - Epoch: [148][   55/   55]    Loss 2.876109    Top1 58.237327    Top5 74.251152    
2024-05-04 22:41:30,574 - ==> Top1: 58.237    Top5: 74.251    Loss: 2.876

2024-05-04 22:41:30,578 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:41:30,578 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:41:30,624 - 

2024-05-04 22:41:30,624 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:42:25,787 - Epoch: [149][  100/  217]    Overall Loss 0.000820    Objective Loss 0.000820                                        LR 0.000250    Time 0.551568    
2024-05-04 22:43:16,487 - Epoch: [149][  200/  217]    Overall Loss 0.000686    Objective Loss 0.000686                                        LR 0.000250    Time 0.529245    
2024-05-04 22:43:23,092 - Epoch: [149][  217/  217]    Overall Loss 0.000891    Objective Loss 0.000891    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.518214    
2024-05-04 22:43:23,209 - --- validate (epoch=149)-----------
2024-05-04 22:43:23,210 - 1736 samples (32 per mini-batch)
2024-05-04 22:43:51,780 - Epoch: [149][   55/   55]    Loss 2.887108    Top1 57.488479    Top5 74.078341    
2024-05-04 22:43:51,908 - ==> Top1: 57.488    Top5: 74.078    Loss: 2.887

2024-05-04 22:43:51,914 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:43:51,914 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:43:51,981 - 

2024-05-04 22:43:51,982 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:44:45,296 - Epoch: [150][  100/  217]    Overall Loss 0.000640    Objective Loss 0.000640                                        LR 0.000063    Time 0.533072    
2024-05-04 22:45:41,189 - Epoch: [150][  200/  217]    Overall Loss 0.000598    Objective Loss 0.000598                                        LR 0.000063    Time 0.545977    
2024-05-04 22:45:50,044 - Epoch: [150][  217/  217]    Overall Loss 0.000721    Objective Loss 0.000721    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.544003    
2024-05-04 22:45:50,170 - --- validate (epoch=150)-----------
2024-05-04 22:45:50,171 - 1736 samples (32 per mini-batch)
2024-05-04 22:46:21,172 - Epoch: [150][   55/   55]    Loss 2.881928    Top1 57.027650    Top5 74.193548    
2024-05-04 22:46:21,291 - ==> Top1: 57.028    Top5: 74.194    Loss: 2.882

2024-05-04 22:46:21,298 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:46:21,298 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:46:21,359 - 

2024-05-04 22:46:21,359 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:47:16,972 - Epoch: [151][  100/  217]    Overall Loss 0.000741    Objective Loss 0.000741                                        LR 0.000063    Time 0.556061    
2024-05-04 22:48:08,550 - Epoch: [151][  200/  217]    Overall Loss 0.000704    Objective Loss 0.000704                                        LR 0.000063    Time 0.535892    
2024-05-04 22:48:17,313 - Epoch: [151][  217/  217]    Overall Loss 0.000678    Objective Loss 0.000678    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.534283    
2024-05-04 22:48:17,463 - --- validate (epoch=151)-----------
2024-05-04 22:48:17,463 - 1736 samples (32 per mini-batch)
2024-05-04 22:48:47,537 - Epoch: [151][   55/   55]    Loss 2.854189    Top1 57.546083    Top5 74.423963    
2024-05-04 22:48:47,701 - ==> Top1: 57.546    Top5: 74.424    Loss: 2.854

2024-05-04 22:48:47,706 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:48:47,706 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:48:47,752 - 

2024-05-04 22:48:47,752 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:49:41,620 - Epoch: [152][  100/  217]    Overall Loss 0.000677    Objective Loss 0.000677                                        LR 0.000063    Time 0.538618    
2024-05-04 22:50:30,879 - Epoch: [152][  200/  217]    Overall Loss 0.000751    Objective Loss 0.000751                                        LR 0.000063    Time 0.515576    
2024-05-04 22:50:39,370 - Epoch: [152][  217/  217]    Overall Loss 0.000716    Objective Loss 0.000716    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.514313    
2024-05-04 22:50:39,482 - --- validate (epoch=152)-----------
2024-05-04 22:50:39,483 - 1736 samples (32 per mini-batch)
2024-05-04 22:51:12,729 - Epoch: [152][   55/   55]    Loss 2.859643    Top1 57.027650    Top5 74.078341    
2024-05-04 22:51:12,850 - ==> Top1: 57.028    Top5: 74.078    Loss: 2.860

2024-05-04 22:51:12,854 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:51:12,855 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:51:12,900 - 

2024-05-04 22:51:12,900 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:52:06,990 - Epoch: [153][  100/  217]    Overall Loss 0.000732    Objective Loss 0.000732                                        LR 0.000063    Time 0.540834    
2024-05-04 22:52:59,008 - Epoch: [153][  200/  217]    Overall Loss 0.000598    Objective Loss 0.000598                                        LR 0.000063    Time 0.530482    
2024-05-04 22:53:03,889 - Epoch: [153][  217/  217]    Overall Loss 0.000679    Objective Loss 0.000679    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.511414    
2024-05-04 22:53:04,005 - --- validate (epoch=153)-----------
2024-05-04 22:53:04,005 - 1736 samples (32 per mini-batch)
2024-05-04 22:53:31,150 - Epoch: [153][   55/   55]    Loss 2.855380    Top1 57.200461    Top5 74.308756    
2024-05-04 22:53:31,264 - ==> Top1: 57.200    Top5: 74.309    Loss: 2.855

2024-05-04 22:53:31,268 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:53:31,269 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:53:31,316 - 

2024-05-04 22:53:31,317 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:54:27,424 - Epoch: [154][  100/  217]    Overall Loss 0.000571    Objective Loss 0.000571                                        LR 0.000063    Time 0.561011    
2024-05-04 22:55:13,904 - Epoch: [154][  200/  217]    Overall Loss 0.000747    Objective Loss 0.000747                                        LR 0.000063    Time 0.512880    
2024-05-04 22:55:21,845 - Epoch: [154][  217/  217]    Overall Loss 0.000710    Objective Loss 0.000710    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.509289    
2024-05-04 22:55:22,005 - --- validate (epoch=154)-----------
2024-05-04 22:55:22,006 - 1736 samples (32 per mini-batch)
2024-05-04 22:55:53,543 - Epoch: [154][   55/   55]    Loss 2.895411    Top1 57.200461    Top5 74.135945    
2024-05-04 22:55:53,676 - ==> Top1: 57.200    Top5: 74.136    Loss: 2.895

2024-05-04 22:55:53,681 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:55:53,681 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:55:53,723 - 

2024-05-04 22:55:53,723 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:56:48,917 - Epoch: [155][  100/  217]    Overall Loss 0.000487    Objective Loss 0.000487                                        LR 0.000063    Time 0.551867    
2024-05-04 22:57:31,950 - Epoch: [155][  200/  217]    Overall Loss 0.000708    Objective Loss 0.000708                                        LR 0.000063    Time 0.491075    
2024-05-04 22:57:37,258 - Epoch: [155][  217/  217]    Overall Loss 0.000683    Objective Loss 0.000683    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.477059    
2024-05-04 22:57:37,436 - --- validate (epoch=155)-----------
2024-05-04 22:57:37,436 - 1736 samples (32 per mini-batch)
2024-05-04 22:58:06,995 - Epoch: [155][   55/   55]    Loss 2.864937    Top1 57.373272    Top5 74.020737    
2024-05-04 22:58:07,118 - ==> Top1: 57.373    Top5: 74.021    Loss: 2.865

2024-05-04 22:58:07,123 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 22:58:07,123 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 22:58:07,166 - 

2024-05-04 22:58:07,166 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 22:59:00,597 - Epoch: [156][  100/  217]    Overall Loss 0.000922    Objective Loss 0.000922                                        LR 0.000063    Time 0.534249    
2024-05-04 22:59:43,401 - Epoch: [156][  200/  217]    Overall Loss 0.000696    Objective Loss 0.000696                                        LR 0.000063    Time 0.481122    
2024-05-04 22:59:51,231 - Epoch: [156][  217/  217]    Overall Loss 0.000656    Objective Loss 0.000656    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.479508    
2024-05-04 22:59:51,347 - --- validate (epoch=156)-----------
2024-05-04 22:59:51,347 - 1736 samples (32 per mini-batch)
2024-05-04 23:00:26,191 - Epoch: [156][   55/   55]    Loss 2.911235    Top1 57.546083    Top5 74.135945    
2024-05-04 23:00:26,315 - ==> Top1: 57.546    Top5: 74.136    Loss: 2.911

2024-05-04 23:00:26,322 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:00:26,322 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:00:26,386 - 

2024-05-04 23:00:26,386 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:01:21,226 - Epoch: [157][  100/  217]    Overall Loss 0.000688    Objective Loss 0.000688                                        LR 0.000063    Time 0.548332    
2024-05-04 23:02:16,745 - Epoch: [157][  200/  217]    Overall Loss 0.000694    Objective Loss 0.000694                                        LR 0.000063    Time 0.551737    
2024-05-04 23:02:26,619 - Epoch: [157][  217/  217]    Overall Loss 0.000656    Objective Loss 0.000656    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.554009    
2024-05-04 23:02:26,730 - --- validate (epoch=157)-----------
2024-05-04 23:02:26,730 - 1736 samples (32 per mini-batch)
2024-05-04 23:02:55,891 - Epoch: [157][   55/   55]    Loss 2.899188    Top1 57.488479    Top5 73.847926    
2024-05-04 23:02:56,050 - ==> Top1: 57.488    Top5: 73.848    Loss: 2.899

2024-05-04 23:02:56,057 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:02:56,057 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:02:56,125 - 

2024-05-04 23:02:56,125 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:03:51,829 - Epoch: [158][  100/  217]    Overall Loss 0.000883    Objective Loss 0.000883                                        LR 0.000063    Time 0.556961    
2024-05-04 23:04:39,081 - Epoch: [158][  200/  217]    Overall Loss 0.000819    Objective Loss 0.000819                                        LR 0.000063    Time 0.514713    
2024-05-04 23:04:46,326 - Epoch: [158][  217/  217]    Overall Loss 0.000776    Objective Loss 0.000776    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.507772    
2024-05-04 23:04:46,494 - --- validate (epoch=158)-----------
2024-05-04 23:04:46,494 - 1736 samples (32 per mini-batch)
2024-05-04 23:05:14,326 - Epoch: [158][   55/   55]    Loss 2.904359    Top1 58.294931    Top5 73.790323    
2024-05-04 23:05:14,508 - ==> Top1: 58.295    Top5: 73.790    Loss: 2.904

2024-05-04 23:05:14,515 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:05:14,515 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:05:14,579 - 

2024-05-04 23:05:14,579 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:06:08,906 - Epoch: [159][  100/  217]    Overall Loss 0.000947    Objective Loss 0.000947                                        LR 0.000063    Time 0.543201    
2024-05-04 23:06:55,953 - Epoch: [159][  200/  217]    Overall Loss 0.000629    Objective Loss 0.000629                                        LR 0.000063    Time 0.506804    
2024-05-04 23:07:03,977 - Epoch: [159][  217/  217]    Overall Loss 0.000713    Objective Loss 0.000713    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.504070    
2024-05-04 23:07:04,103 - --- validate (epoch=159)-----------
2024-05-04 23:07:04,103 - 1736 samples (32 per mini-batch)
2024-05-04 23:07:34,438 - Epoch: [159][   55/   55]    Loss 2.904833    Top1 58.179724    Top5 74.193548    
2024-05-04 23:07:34,619 - ==> Top1: 58.180    Top5: 74.194    Loss: 2.905

2024-05-04 23:07:34,626 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:07:34,626 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:07:34,696 - 

2024-05-04 23:07:34,697 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:08:27,762 - Epoch: [160][  100/  217]    Overall Loss 0.000504    Objective Loss 0.000504                                        LR 0.000063    Time 0.530582    
2024-05-04 23:09:18,765 - Epoch: [160][  200/  217]    Overall Loss 0.000653    Objective Loss 0.000653                                        LR 0.000063    Time 0.520283    
2024-05-04 23:09:27,381 - Epoch: [160][  217/  217]    Overall Loss 0.000757    Objective Loss 0.000757    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.519222    
2024-05-04 23:09:27,529 - --- validate (epoch=160)-----------
2024-05-04 23:09:27,530 - 1736 samples (32 per mini-batch)
2024-05-04 23:09:55,118 - Epoch: [160][   55/   55]    Loss 2.916700    Top1 57.949309    Top5 73.847926    
2024-05-04 23:09:55,255 - ==> Top1: 57.949    Top5: 73.848    Loss: 2.917

2024-05-04 23:09:55,260 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:09:55,260 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:09:55,308 - 

2024-05-04 23:09:55,309 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:10:45,345 - Epoch: [161][  100/  217]    Overall Loss 0.000940    Objective Loss 0.000940                                        LR 0.000063    Time 0.500293    
2024-05-04 23:11:28,683 - Epoch: [161][  200/  217]    Overall Loss 0.000701    Objective Loss 0.000701                                        LR 0.000063    Time 0.466804    
2024-05-04 23:11:36,475 - Epoch: [161][  217/  217]    Overall Loss 0.000678    Objective Loss 0.000678    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.466140    
2024-05-04 23:11:36,585 - --- validate (epoch=161)-----------
2024-05-04 23:11:36,586 - 1736 samples (32 per mini-batch)
2024-05-04 23:12:07,679 - Epoch: [161][   55/   55]    Loss 2.947258    Top1 57.603687    Top5 73.790323    
2024-05-04 23:12:07,790 - ==> Top1: 57.604    Top5: 73.790    Loss: 2.947

2024-05-04 23:12:07,795 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:12:07,795 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:12:07,837 - 

2024-05-04 23:12:07,837 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:13:02,024 - Epoch: [162][  100/  217]    Overall Loss 0.000422    Objective Loss 0.000422                                        LR 0.000063    Time 0.541801    
2024-05-04 23:13:50,950 - Epoch: [162][  200/  217]    Overall Loss 0.000669    Objective Loss 0.000669                                        LR 0.000063    Time 0.515504    
2024-05-04 23:14:00,207 - Epoch: [162][  217/  217]    Overall Loss 0.000634    Objective Loss 0.000634    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.517771    
2024-05-04 23:14:00,403 - --- validate (epoch=162)-----------
2024-05-04 23:14:00,404 - 1736 samples (32 per mini-batch)
2024-05-04 23:14:32,032 - Epoch: [162][   55/   55]    Loss 2.934047    Top1 57.661290    Top5 74.135945    
2024-05-04 23:14:32,199 - ==> Top1: 57.661    Top5: 74.136    Loss: 2.934

2024-05-04 23:14:32,204 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:14:32,205 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:14:32,251 - 

2024-05-04 23:14:32,251 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:15:29,686 - Epoch: [163][  100/  217]    Overall Loss 0.000436    Objective Loss 0.000436                                        LR 0.000063    Time 0.574281    
2024-05-04 23:16:17,928 - Epoch: [163][  200/  217]    Overall Loss 0.000538    Objective Loss 0.000538                                        LR 0.000063    Time 0.528318    
2024-05-04 23:16:26,925 - Epoch: [163][  217/  217]    Overall Loss 0.000638    Objective Loss 0.000638    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.528384    
2024-05-04 23:16:27,073 - --- validate (epoch=163)-----------
2024-05-04 23:16:27,074 - 1736 samples (32 per mini-batch)
2024-05-04 23:16:59,136 - Epoch: [163][   55/   55]    Loss 2.923355    Top1 57.891705    Top5 73.963134    
2024-05-04 23:16:59,293 - ==> Top1: 57.892    Top5: 73.963    Loss: 2.923

2024-05-04 23:16:59,300 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:16:59,301 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:16:59,362 - 

2024-05-04 23:16:59,363 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:17:54,516 - Epoch: [164][  100/  217]    Overall Loss 0.000402    Objective Loss 0.000402                                        LR 0.000063    Time 0.551461    
2024-05-04 23:18:42,282 - Epoch: [164][  200/  217]    Overall Loss 0.000686    Objective Loss 0.000686                                        LR 0.000063    Time 0.514533    
2024-05-04 23:18:53,375 - Epoch: [164][  217/  217]    Overall Loss 0.000645    Objective Loss 0.000645    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.525336    
2024-05-04 23:18:53,535 - --- validate (epoch=164)-----------
2024-05-04 23:18:53,536 - 1736 samples (32 per mini-batch)
2024-05-04 23:19:24,551 - Epoch: [164][   55/   55]    Loss 2.905824    Top1 57.891705    Top5 73.905530    
2024-05-04 23:19:24,713 - ==> Top1: 57.892    Top5: 73.906    Loss: 2.906

2024-05-04 23:19:24,719 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:19:24,720 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:19:24,780 - 

2024-05-04 23:19:24,780 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:20:15,248 - Epoch: [165][  100/  217]    Overall Loss 0.000597    Objective Loss 0.000597                                        LR 0.000063    Time 0.504600    
2024-05-04 23:21:05,088 - Epoch: [165][  200/  217]    Overall Loss 0.000642    Objective Loss 0.000642                                        LR 0.000063    Time 0.501467    
2024-05-04 23:21:13,600 - Epoch: [165][  217/  217]    Overall Loss 0.000604    Objective Loss 0.000604    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.501402    
2024-05-04 23:21:13,763 - --- validate (epoch=165)-----------
2024-05-04 23:21:13,763 - 1736 samples (32 per mini-batch)
2024-05-04 23:21:42,400 - Epoch: [165][   55/   55]    Loss 2.944770    Top1 57.891705    Top5 73.617512    
2024-05-04 23:21:42,549 - ==> Top1: 57.892    Top5: 73.618    Loss: 2.945

2024-05-04 23:21:42,556 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:21:42,556 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:21:42,619 - 

2024-05-04 23:21:42,619 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:22:34,531 - Epoch: [166][  100/  217]    Overall Loss 0.000615    Objective Loss 0.000615                                        LR 0.000063    Time 0.519041    
2024-05-04 23:23:23,753 - Epoch: [166][  200/  217]    Overall Loss 0.000639    Objective Loss 0.000639                                        LR 0.000063    Time 0.505603    
2024-05-04 23:23:31,718 - Epoch: [166][  217/  217]    Overall Loss 0.000606    Objective Loss 0.000606    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.502694    
2024-05-04 23:23:31,903 - --- validate (epoch=166)-----------
2024-05-04 23:23:31,904 - 1736 samples (32 per mini-batch)
2024-05-04 23:24:05,923 - Epoch: [166][   55/   55]    Loss 2.922308    Top1 58.006912    Top5 73.675115    
2024-05-04 23:24:06,080 - ==> Top1: 58.007    Top5: 73.675    Loss: 2.922

2024-05-04 23:24:06,088 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:24:06,088 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:24:06,157 - 

2024-05-04 23:24:06,158 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:25:03,820 - Epoch: [167][  100/  217]    Overall Loss 0.000375    Objective Loss 0.000375                                        LR 0.000063    Time 0.576557    
2024-05-04 23:25:51,052 - Epoch: [167][  200/  217]    Overall Loss 0.000623    Objective Loss 0.000623                                        LR 0.000063    Time 0.524408    
2024-05-04 23:25:59,001 - Epoch: [167][  217/  217]    Overall Loss 0.000588    Objective Loss 0.000588    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.519952    
2024-05-04 23:25:59,164 - --- validate (epoch=167)-----------
2024-05-04 23:25:59,165 - 1736 samples (32 per mini-batch)
2024-05-04 23:26:28,700 - Epoch: [167][   55/   55]    Loss 2.949145    Top1 57.661290    Top5 73.559908    
2024-05-04 23:26:28,912 - ==> Top1: 57.661    Top5: 73.560    Loss: 2.949

2024-05-04 23:26:28,917 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:26:28,917 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:26:28,960 - 

2024-05-04 23:26:28,960 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:27:22,884 - Epoch: [168][  100/  217]    Overall Loss 0.000390    Objective Loss 0.000390                                        LR 0.000063    Time 0.539171    
2024-05-04 23:28:14,325 - Epoch: [168][  200/  217]    Overall Loss 0.000667    Objective Loss 0.000667                                        LR 0.000063    Time 0.526723    
2024-05-04 23:28:24,371 - Epoch: [168][  217/  217]    Overall Loss 0.000629    Objective Loss 0.000629    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.531746    
2024-05-04 23:28:24,497 - --- validate (epoch=168)-----------
2024-05-04 23:28:24,497 - 1736 samples (32 per mini-batch)
2024-05-04 23:28:56,026 - Epoch: [168][   55/   55]    Loss 2.921966    Top1 57.949309    Top5 73.790323    
2024-05-04 23:28:56,177 - ==> Top1: 57.949    Top5: 73.790    Loss: 2.922

2024-05-04 23:28:56,184 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:28:56,184 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:28:56,251 - 

2024-05-04 23:28:56,251 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:29:49,709 - Epoch: [169][  100/  217]    Overall Loss 0.000402    Objective Loss 0.000402                                        LR 0.000063    Time 0.534503    
2024-05-04 23:30:36,607 - Epoch: [169][  200/  217]    Overall Loss 0.000671    Objective Loss 0.000671                                        LR 0.000063    Time 0.501716    
2024-05-04 23:30:45,805 - Epoch: [169][  217/  217]    Overall Loss 0.000633    Objective Loss 0.000633    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.504790    
2024-05-04 23:30:46,015 - --- validate (epoch=169)-----------
2024-05-04 23:30:46,015 - 1736 samples (32 per mini-batch)
2024-05-04 23:31:18,633 - Epoch: [169][   55/   55]    Loss 2.942246    Top1 57.603687    Top5 73.675115    
2024-05-04 23:31:18,771 - ==> Top1: 57.604    Top5: 73.675    Loss: 2.942

2024-05-04 23:31:18,779 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:31:18,779 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:31:18,846 - 

2024-05-04 23:31:18,847 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:32:10,759 - Epoch: [170][  100/  217]    Overall Loss 0.001080    Objective Loss 0.001080                                        LR 0.000063    Time 0.519053    
2024-05-04 23:33:04,959 - Epoch: [170][  200/  217]    Overall Loss 0.000630    Objective Loss 0.000630                                        LR 0.000063    Time 0.530500    
2024-05-04 23:33:13,796 - Epoch: [170][  217/  217]    Overall Loss 0.000593    Objective Loss 0.000593    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.529657    
2024-05-04 23:33:13,983 - --- validate (epoch=170)-----------
2024-05-04 23:33:13,984 - 1736 samples (32 per mini-batch)
2024-05-04 23:33:47,337 - Epoch: [170][   55/   55]    Loss 2.952141    Top1 57.603687    Top5 73.963134    
2024-05-04 23:33:47,455 - ==> Top1: 57.604    Top5: 73.963    Loss: 2.952

2024-05-04 23:33:47,460 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:33:47,460 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:33:47,506 - 

2024-05-04 23:33:47,506 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:34:37,351 - Epoch: [171][  100/  217]    Overall Loss 0.000859    Objective Loss 0.000859                                        LR 0.000063    Time 0.498391    
2024-05-04 23:35:29,373 - Epoch: [171][  200/  217]    Overall Loss 0.000634    Objective Loss 0.000634                                        LR 0.000063    Time 0.509215    
2024-05-04 23:35:36,075 - Epoch: [171][  217/  217]    Overall Loss 0.000595    Objective Loss 0.000595    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.500201    
2024-05-04 23:35:36,196 - --- validate (epoch=171)-----------
2024-05-04 23:35:36,196 - 1736 samples (32 per mini-batch)
2024-05-04 23:36:07,837 - Epoch: [171][   55/   55]    Loss 2.962765    Top1 57.891705    Top5 74.135945    
2024-05-04 23:36:07,981 - ==> Top1: 57.892    Top5: 74.136    Loss: 2.963

2024-05-04 23:36:07,988 - ==> Best [Top1: 58.410   Top5: 74.251   Sparsity:0.00   Params: 384080 on epoch: 69]
2024-05-04 23:36:07,988 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:36:08,053 - 

2024-05-04 23:36:08,053 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:36:59,757 - Epoch: [172][  100/  217]    Overall Loss 0.000589    Objective Loss 0.000589                                        LR 0.000063    Time 0.516969    
2024-05-04 23:37:44,022 - Epoch: [172][  200/  217]    Overall Loss 0.000494    Objective Loss 0.000494                                        LR 0.000063    Time 0.479779    
2024-05-04 23:37:52,366 - Epoch: [172][  217/  217]    Overall Loss 0.000588    Objective Loss 0.000588    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.480641    
2024-05-04 23:37:52,519 - --- validate (epoch=172)-----------
2024-05-04 23:37:52,520 - 1736 samples (32 per mini-batch)
2024-05-04 23:38:20,972 - Epoch: [172][   55/   55]    Loss 2.958125    Top1 58.525346    Top5 73.905530    
2024-05-04 23:38:21,080 - ==> Top1: 58.525    Top5: 73.906    Loss: 2.958

2024-05-04 23:38:21,085 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-04 23:38:21,085 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:38:21,137 - 

2024-05-04 23:38:21,138 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:39:16,588 - Epoch: [173][  100/  217]    Overall Loss 0.000870    Objective Loss 0.000870                                        LR 0.000063    Time 0.554446    
2024-05-04 23:40:00,962 - Epoch: [173][  200/  217]    Overall Loss 0.000612    Objective Loss 0.000612                                        LR 0.000063    Time 0.499064    
2024-05-04 23:40:07,635 - Epoch: [173][  217/  217]    Overall Loss 0.000579    Objective Loss 0.000579    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.490714    
2024-05-04 23:40:07,731 - --- validate (epoch=173)-----------
2024-05-04 23:40:07,732 - 1736 samples (32 per mini-batch)
2024-05-04 23:40:43,229 - Epoch: [173][   55/   55]    Loss 2.952272    Top1 58.006912    Top5 73.963134    
2024-05-04 23:40:43,354 - ==> Top1: 58.007    Top5: 73.963    Loss: 2.952

2024-05-04 23:40:43,361 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-04 23:40:43,361 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:40:43,424 - 

2024-05-04 23:40:43,425 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:41:40,247 - Epoch: [174][  100/  217]    Overall Loss 0.000584    Objective Loss 0.000584                                        LR 0.000063    Time 0.568150    
2024-05-04 23:42:22,039 - Epoch: [174][  200/  217]    Overall Loss 0.000621    Objective Loss 0.000621                                        LR 0.000063    Time 0.492890    
2024-05-04 23:42:29,779 - Epoch: [174][  217/  217]    Overall Loss 0.000584    Objective Loss 0.000584    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.489937    
2024-05-04 23:42:30,033 - --- validate (epoch=174)-----------
2024-05-04 23:42:30,034 - 1736 samples (32 per mini-batch)
2024-05-04 23:43:02,416 - Epoch: [174][   55/   55]    Loss 2.956240    Top1 57.546083    Top5 73.790323    
2024-05-04 23:43:02,584 - ==> Top1: 57.546    Top5: 73.790    Loss: 2.956

2024-05-04 23:43:02,592 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-04 23:43:02,592 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:43:02,665 - 

2024-05-04 23:43:02,665 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:43:59,802 - Epoch: [175][  100/  217]    Overall Loss 0.000571    Objective Loss 0.000571                                        LR 0.000063    Time 0.571288    
2024-05-04 23:44:43,596 - Epoch: [175][  200/  217]    Overall Loss 0.000615    Objective Loss 0.000615                                        LR 0.000063    Time 0.504580    
2024-05-04 23:44:50,507 - Epoch: [175][  217/  217]    Overall Loss 0.000578    Objective Loss 0.000578    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.496889    
2024-05-04 23:44:50,658 - --- validate (epoch=175)-----------
2024-05-04 23:44:50,658 - 1736 samples (32 per mini-batch)
2024-05-04 23:45:21,707 - Epoch: [175][   55/   55]    Loss 2.992304    Top1 57.027650    Top5 73.963134    
2024-05-04 23:45:21,889 - ==> Top1: 57.028    Top5: 73.963    Loss: 2.992

2024-05-04 23:45:21,894 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-04 23:45:21,894 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:45:21,935 - 

2024-05-04 23:45:21,936 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:46:16,488 - Epoch: [176][  100/  217]    Overall Loss 0.001071    Objective Loss 0.001071                                        LR 0.000063    Time 0.545461    
2024-05-04 23:47:04,056 - Epoch: [176][  200/  217]    Overall Loss 0.000608    Objective Loss 0.000608                                        LR 0.000063    Time 0.510546    
2024-05-04 23:47:12,513 - Epoch: [176][  217/  217]    Overall Loss 0.000571    Objective Loss 0.000571    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.509512    
2024-05-04 23:47:12,632 - --- validate (epoch=176)-----------
2024-05-04 23:47:12,633 - 1736 samples (32 per mini-batch)
2024-05-04 23:47:39,249 - Epoch: [176][   55/   55]    Loss 2.973152    Top1 57.546083    Top5 73.617512    
2024-05-04 23:47:39,395 - ==> Top1: 57.546    Top5: 73.618    Loss: 2.973

2024-05-04 23:47:39,402 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-04 23:47:39,402 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:47:39,468 - 

2024-05-04 23:47:39,468 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:48:31,711 - Epoch: [177][  100/  217]    Overall Loss 0.000598    Objective Loss 0.000598                                        LR 0.000063    Time 0.522352    
2024-05-04 23:49:19,369 - Epoch: [177][  200/  217]    Overall Loss 0.000618    Objective Loss 0.000618                                        LR 0.000063    Time 0.499440    
2024-05-04 23:49:24,616 - Epoch: [177][  217/  217]    Overall Loss 0.000584    Objective Loss 0.000584    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.484485    
2024-05-04 23:49:24,764 - --- validate (epoch=177)-----------
2024-05-04 23:49:24,764 - 1736 samples (32 per mini-batch)
2024-05-04 23:49:54,012 - Epoch: [177][   55/   55]    Loss 2.971735    Top1 57.488479    Top5 73.847926    
2024-05-04 23:49:54,141 - ==> Top1: 57.488    Top5: 73.848    Loss: 2.972

2024-05-04 23:49:54,148 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-04 23:49:54,148 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:49:54,215 - 

2024-05-04 23:49:54,215 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:50:44,497 - Epoch: [178][  100/  217]    Overall Loss 0.000146    Objective Loss 0.000146                                        LR 0.000063    Time 0.502742    
2024-05-04 23:51:29,803 - Epoch: [178][  200/  217]    Overall Loss 0.000883    Objective Loss 0.000883                                        LR 0.000063    Time 0.477880    
2024-05-04 23:51:35,637 - Epoch: [178][  217/  217]    Overall Loss 0.000828    Objective Loss 0.000828    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.467320    
2024-05-04 23:51:35,741 - --- validate (epoch=178)-----------
2024-05-04 23:51:35,742 - 1736 samples (32 per mini-batch)
2024-05-04 23:52:04,354 - Epoch: [178][   55/   55]    Loss 3.006107    Top1 58.006912    Top5 73.675115    
2024-05-04 23:52:04,477 - ==> Top1: 58.007    Top5: 73.675    Loss: 3.006

2024-05-04 23:52:04,482 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-04 23:52:04,482 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:52:04,527 - 

2024-05-04 23:52:04,527 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:52:57,947 - Epoch: [179][  100/  217]    Overall Loss 0.000793    Objective Loss 0.000793                                        LR 0.000063    Time 0.534133    
2024-05-04 23:53:46,317 - Epoch: [179][  200/  217]    Overall Loss 0.000741    Objective Loss 0.000741                                        LR 0.000063    Time 0.508891    
2024-05-04 23:53:54,403 - Epoch: [179][  217/  217]    Overall Loss 0.000697    Objective Loss 0.000697    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.506284    
2024-05-04 23:53:54,540 - --- validate (epoch=179)-----------
2024-05-04 23:53:54,540 - 1736 samples (32 per mini-batch)
2024-05-04 23:54:23,478 - Epoch: [179][   55/   55]    Loss 2.960069    Top1 58.122120    Top5 73.847926    
2024-05-04 23:54:23,627 - ==> Top1: 58.122    Top5: 73.848    Loss: 2.960

2024-05-04 23:54:23,634 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-04 23:54:23,634 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:54:23,697 - 

2024-05-04 23:54:23,697 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:55:16,372 - Epoch: [180][  100/  217]    Overall Loss 0.000347    Objective Loss 0.000347                                        LR 0.000063    Time 0.526679    
2024-05-04 23:56:10,619 - Epoch: [180][  200/  217]    Overall Loss 0.000607    Objective Loss 0.000607                                        LR 0.000063    Time 0.534545    
2024-05-04 23:56:16,589 - Epoch: [180][  217/  217]    Overall Loss 0.000571    Objective Loss 0.000571    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.520177    
2024-05-04 23:56:16,752 - --- validate (epoch=180)-----------
2024-05-04 23:56:16,752 - 1736 samples (32 per mini-batch)
2024-05-04 23:56:45,654 - Epoch: [180][   55/   55]    Loss 3.015701    Top1 57.891705    Top5 73.905530    
2024-05-04 23:56:45,789 - ==> Top1: 57.892    Top5: 73.906    Loss: 3.016

2024-05-04 23:56:45,796 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-04 23:56:45,796 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:56:45,858 - 

2024-05-04 23:56:45,858 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-04 23:57:44,539 - Epoch: [181][  100/  217]    Overall Loss 0.000123    Objective Loss 0.000123                                        LR 0.000063    Time 0.586738    
2024-05-04 23:58:35,925 - Epoch: [181][  200/  217]    Overall Loss 0.000817    Objective Loss 0.000817                                        LR 0.000063    Time 0.550270    
2024-05-04 23:58:43,040 - Epoch: [181][  217/  217]    Overall Loss 0.000869    Objective Loss 0.000869    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.539943    
2024-05-04 23:58:43,220 - --- validate (epoch=181)-----------
2024-05-04 23:58:43,220 - 1736 samples (32 per mini-batch)
2024-05-04 23:59:10,897 - Epoch: [181][   55/   55]    Loss 2.985293    Top1 58.525346    Top5 73.271889    
2024-05-04 23:59:11,013 - ==> Top1: 58.525    Top5: 73.272    Loss: 2.985

2024-05-04 23:59:11,020 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-04 23:59:11,020 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-04 23:59:11,081 - 

2024-05-04 23:59:11,082 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:00:00,349 - Epoch: [182][  100/  217]    Overall Loss 0.000372    Objective Loss 0.000372                                        LR 0.000063    Time 0.492607    
2024-05-05 00:00:52,860 - Epoch: [182][  200/  217]    Overall Loss 0.000575    Objective Loss 0.000575                                        LR 0.000063    Time 0.508835    
2024-05-05 00:00:59,507 - Epoch: [182][  217/  217]    Overall Loss 0.000661    Objective Loss 0.000661    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.499598    
2024-05-05 00:00:59,644 - --- validate (epoch=182)-----------
2024-05-05 00:00:59,645 - 1736 samples (32 per mini-batch)
2024-05-05 00:01:22,922 - Epoch: [182][   55/   55]    Loss 3.021616    Top1 57.949309    Top5 74.193548    
2024-05-05 00:01:23,025 - ==> Top1: 57.949    Top5: 74.194    Loss: 3.022

2024-05-05 00:01:23,032 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:01:23,032 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:01:23,098 - 

2024-05-05 00:01:23,098 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:02:22,094 - Epoch: [183][  100/  217]    Overall Loss 0.000578    Objective Loss 0.000578                                        LR 0.000063    Time 0.589887    
2024-05-05 00:03:08,972 - Epoch: [183][  200/  217]    Overall Loss 0.000581    Objective Loss 0.000581                                        LR 0.000063    Time 0.529310    
2024-05-05 00:03:15,294 - Epoch: [183][  217/  217]    Overall Loss 0.000545    Objective Loss 0.000545    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.516973    
2024-05-05 00:03:15,435 - --- validate (epoch=183)-----------
2024-05-05 00:03:15,435 - 1736 samples (32 per mini-batch)
2024-05-05 00:03:46,008 - Epoch: [183][   55/   55]    Loss 2.963833    Top1 57.834101    Top5 74.539171    
2024-05-05 00:03:46,125 - ==> Top1: 57.834    Top5: 74.539    Loss: 2.964

2024-05-05 00:03:46,131 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:03:46,131 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:03:46,181 - 

2024-05-05 00:03:46,182 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:04:38,818 - Epoch: [184][  100/  217]    Overall Loss 0.000573    Objective Loss 0.000573                                        LR 0.000063    Time 0.526301    
2024-05-05 00:05:29,146 - Epoch: [184][  200/  217]    Overall Loss 0.000609    Objective Loss 0.000609                                        LR 0.000063    Time 0.514768    
2024-05-05 00:05:37,719 - Epoch: [184][  217/  217]    Overall Loss 0.000570    Objective Loss 0.000570    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.513936    
2024-05-05 00:05:37,830 - --- validate (epoch=184)-----------
2024-05-05 00:05:37,831 - 1736 samples (32 per mini-batch)
2024-05-05 00:06:06,360 - Epoch: [184][   55/   55]    Loss 2.983609    Top1 57.718894    Top5 74.078341    
2024-05-05 00:06:06,514 - ==> Top1: 57.719    Top5: 74.078    Loss: 2.984

2024-05-05 00:06:06,522 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:06:06,523 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:06:06,592 - 

2024-05-05 00:06:06,593 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:06:57,989 - Epoch: [185][  100/  217]    Overall Loss 0.000628    Objective Loss 0.000628                                        LR 0.000063    Time 0.513893    
2024-05-05 00:07:47,288 - Epoch: [185][  200/  217]    Overall Loss 0.000629    Objective Loss 0.000629                                        LR 0.000063    Time 0.503413    
2024-05-05 00:07:56,253 - Epoch: [185][  217/  217]    Overall Loss 0.000589    Objective Loss 0.000589    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.505284    
2024-05-05 00:07:56,433 - --- validate (epoch=185)-----------
2024-05-05 00:07:56,434 - 1736 samples (32 per mini-batch)
2024-05-05 00:08:29,231 - Epoch: [185][   55/   55]    Loss 2.998471    Top1 57.834101    Top5 73.675115    
2024-05-05 00:08:29,331 - ==> Top1: 57.834    Top5: 73.675    Loss: 2.998

2024-05-05 00:08:29,337 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:08:29,337 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:08:29,384 - 

2024-05-05 00:08:29,384 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:09:21,397 - Epoch: [186][  100/  217]    Overall Loss 0.000595    Objective Loss 0.000595                                        LR 0.000063    Time 0.520074    
2024-05-05 00:10:04,687 - Epoch: [186][  200/  217]    Overall Loss 0.000456    Objective Loss 0.000456                                        LR 0.000063    Time 0.476460    
2024-05-05 00:10:11,986 - Epoch: [186][  217/  217]    Overall Loss 0.000541    Objective Loss 0.000541    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.472766    
2024-05-05 00:10:12,109 - --- validate (epoch=186)-----------
2024-05-05 00:10:12,109 - 1736 samples (32 per mini-batch)
2024-05-05 00:10:40,934 - Epoch: [186][   55/   55]    Loss 3.024363    Top1 57.949309    Top5 74.251152    
2024-05-05 00:10:41,040 - ==> Top1: 57.949    Top5: 74.251    Loss: 3.024

2024-05-05 00:10:41,047 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:10:41,047 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:10:41,115 - 

2024-05-05 00:10:41,116 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:11:36,901 - Epoch: [187][  100/  217]    Overall Loss 0.000778    Objective Loss 0.000778                                        LR 0.000063    Time 0.557780    
2024-05-05 00:12:23,769 - Epoch: [187][  200/  217]    Overall Loss 0.000562    Objective Loss 0.000562                                        LR 0.000063    Time 0.513206    
2024-05-05 00:12:31,814 - Epoch: [187][  217/  217]    Overall Loss 0.000526    Objective Loss 0.000526    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.510067    
2024-05-05 00:12:31,935 - --- validate (epoch=187)-----------
2024-05-05 00:12:31,935 - 1736 samples (32 per mini-batch)
2024-05-05 00:13:02,979 - Epoch: [187][   55/   55]    Loss 2.992058    Top1 57.891705    Top5 73.732719    
2024-05-05 00:13:03,113 - ==> Top1: 57.892    Top5: 73.733    Loss: 2.992

2024-05-05 00:13:03,120 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:13:03,120 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:13:03,183 - 

2024-05-05 00:13:03,183 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:14:03,468 - Epoch: [188][  100/  217]    Overall Loss 0.000563    Objective Loss 0.000563                                        LR 0.000063    Time 0.602779    
2024-05-05 00:14:46,212 - Epoch: [188][  200/  217]    Overall Loss 0.000446    Objective Loss 0.000446                                        LR 0.000063    Time 0.515083    
2024-05-05 00:14:52,736 - Epoch: [188][  217/  217]    Overall Loss 0.000538    Objective Loss 0.000538    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.504789    
2024-05-05 00:14:52,949 - --- validate (epoch=188)-----------
2024-05-05 00:14:52,949 - 1736 samples (32 per mini-batch)
2024-05-05 00:15:24,989 - Epoch: [188][   55/   55]    Loss 3.020629    Top1 57.603687    Top5 74.078341    
2024-05-05 00:15:25,137 - ==> Top1: 57.604    Top5: 74.078    Loss: 3.021

2024-05-05 00:15:25,145 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:15:25,145 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:15:25,215 - 

2024-05-05 00:15:25,215 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:16:19,404 - Epoch: [189][  100/  217]    Overall Loss 0.000550    Objective Loss 0.000550                                        LR 0.000063    Time 0.541812    
2024-05-05 00:17:11,338 - Epoch: [189][  200/  217]    Overall Loss 0.000579    Objective Loss 0.000579                                        LR 0.000063    Time 0.530554    
2024-05-05 00:17:17,494 - Epoch: [189][  217/  217]    Overall Loss 0.000540    Objective Loss 0.000540    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.517349    
2024-05-05 00:17:17,657 - --- validate (epoch=189)-----------
2024-05-05 00:17:17,657 - 1736 samples (32 per mini-batch)
2024-05-05 00:17:47,579 - Epoch: [189][   55/   55]    Loss 3.003742    Top1 57.891705    Top5 74.251152    
2024-05-05 00:17:47,717 - ==> Top1: 57.892    Top5: 74.251    Loss: 3.004

2024-05-05 00:17:47,727 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:17:47,727 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:17:47,788 - 

2024-05-05 00:17:47,789 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:18:45,596 - Epoch: [190][  100/  217]    Overall Loss 0.000528    Objective Loss 0.000528                                        LR 0.000063    Time 0.578010    
2024-05-05 00:19:32,043 - Epoch: [190][  200/  217]    Overall Loss 0.000437    Objective Loss 0.000437                                        LR 0.000063    Time 0.521217    
2024-05-05 00:19:39,264 - Epoch: [190][  217/  217]    Overall Loss 0.000519    Objective Loss 0.000519    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.513655    
2024-05-05 00:19:39,410 - --- validate (epoch=190)-----------
2024-05-05 00:19:39,411 - 1736 samples (32 per mini-batch)
2024-05-05 00:20:12,561 - Epoch: [190][   55/   55]    Loss 3.030300    Top1 57.718894    Top5 74.251152    
2024-05-05 00:20:12,711 - ==> Top1: 57.719    Top5: 74.251    Loss: 3.030

2024-05-05 00:20:12,718 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:20:12,718 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:20:12,783 - 

2024-05-05 00:20:12,784 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:21:04,902 - Epoch: [191][  100/  217]    Overall Loss 0.000549    Objective Loss 0.000549                                        LR 0.000063    Time 0.521072    
2024-05-05 00:21:55,416 - Epoch: [191][  200/  217]    Overall Loss 0.000578    Objective Loss 0.000578                                        LR 0.000063    Time 0.513078    
2024-05-05 00:22:03,571 - Epoch: [191][  217/  217]    Overall Loss 0.000541    Objective Loss 0.000541    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.510457    
2024-05-05 00:22:03,747 - --- validate (epoch=191)-----------
2024-05-05 00:22:03,747 - 1736 samples (32 per mini-batch)
2024-05-05 00:22:32,691 - Epoch: [191][   55/   55]    Loss 3.007116    Top1 58.179724    Top5 73.963134    
2024-05-05 00:22:32,842 - ==> Top1: 58.180    Top5: 73.963    Loss: 3.007

2024-05-05 00:22:32,849 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:22:32,849 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:22:32,914 - 

2024-05-05 00:22:32,914 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:23:25,897 - Epoch: [192][  100/  217]    Overall Loss 0.000575    Objective Loss 0.000575                                        LR 0.000063    Time 0.529753    
2024-05-05 00:24:28,999 - Epoch: [192][  200/  217]    Overall Loss 0.000574    Objective Loss 0.000574                                        LR 0.000063    Time 0.580364    
2024-05-05 00:24:36,751 - Epoch: [192][  217/  217]    Overall Loss 0.000536    Objective Loss 0.000536    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.570618    
2024-05-05 00:24:36,880 - --- validate (epoch=192)-----------
2024-05-05 00:24:36,880 - 1736 samples (32 per mini-batch)
2024-05-05 00:25:03,352 - Epoch: [192][   55/   55]    Loss 3.002018    Top1 57.949309    Top5 74.135945    
2024-05-05 00:25:03,452 - ==> Top1: 57.949    Top5: 74.136    Loss: 3.002

2024-05-05 00:25:03,459 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:25:03,459 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:25:03,524 - 

2024-05-05 00:25:03,525 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:25:53,319 - Epoch: [193][  100/  217]    Overall Loss 0.000754    Objective Loss 0.000754                                        LR 0.000063    Time 0.497873    
2024-05-05 00:26:44,833 - Epoch: [193][  200/  217]    Overall Loss 0.000546    Objective Loss 0.000546                                        LR 0.000063    Time 0.506479    
2024-05-05 00:26:53,938 - Epoch: [193][  217/  217]    Overall Loss 0.000511    Objective Loss 0.000511    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.508753    
2024-05-05 00:26:54,057 - --- validate (epoch=193)-----------
2024-05-05 00:26:54,057 - 1736 samples (32 per mini-batch)
2024-05-05 00:27:22,288 - Epoch: [193][   55/   55]    Loss 3.046345    Top1 57.949309    Top5 73.905530    
2024-05-05 00:27:22,411 - ==> Top1: 57.949    Top5: 73.906    Loss: 3.046

2024-05-05 00:27:22,418 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:27:22,418 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:27:22,487 - 

2024-05-05 00:27:22,488 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:28:12,536 - Epoch: [194][  100/  217]    Overall Loss 0.000321    Objective Loss 0.000321                                        LR 0.000063    Time 0.500410    
2024-05-05 00:28:55,698 - Epoch: [194][  200/  217]    Overall Loss 0.000536    Objective Loss 0.000536                                        LR 0.000063    Time 0.465992    
2024-05-05 00:29:04,547 - Epoch: [194][  217/  217]    Overall Loss 0.000499    Objective Loss 0.000499    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.470259    
2024-05-05 00:29:04,670 - --- validate (epoch=194)-----------
2024-05-05 00:29:04,670 - 1736 samples (32 per mini-batch)
2024-05-05 00:29:34,476 - Epoch: [194][   55/   55]    Loss 3.001913    Top1 58.294931    Top5 73.963134    
2024-05-05 00:29:34,581 - ==> Top1: 58.295    Top5: 73.963    Loss: 3.002

2024-05-05 00:29:34,586 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:29:34,586 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:29:34,647 - 

2024-05-05 00:29:34,648 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:30:33,191 - Epoch: [195][  100/  217]    Overall Loss 0.000520    Objective Loss 0.000520                                        LR 0.000063    Time 0.585367    
2024-05-05 00:31:28,183 - Epoch: [195][  200/  217]    Overall Loss 0.000422    Objective Loss 0.000422                                        LR 0.000063    Time 0.567600    
2024-05-05 00:31:33,884 - Epoch: [195][  217/  217]    Overall Loss 0.000505    Objective Loss 0.000505    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.549400    
2024-05-05 00:31:34,004 - --- validate (epoch=195)-----------
2024-05-05 00:31:34,004 - 1736 samples (32 per mini-batch)
2024-05-05 00:32:04,607 - Epoch: [195][   55/   55]    Loss 3.037866    Top1 58.122120    Top5 73.905530    
2024-05-05 00:32:04,760 - ==> Top1: 58.122    Top5: 73.906    Loss: 3.038

2024-05-05 00:32:04,765 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:32:04,765 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:32:04,814 - 

2024-05-05 00:32:04,814 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:33:01,629 - Epoch: [196][  100/  217]    Overall Loss 0.000358    Objective Loss 0.000358                                        LR 0.000063    Time 0.568079    
2024-05-05 00:33:52,982 - Epoch: [196][  200/  217]    Overall Loss 0.000470    Objective Loss 0.000470                                        LR 0.000063    Time 0.540779    
2024-05-05 00:33:59,265 - Epoch: [196][  217/  217]    Overall Loss 0.000538    Objective Loss 0.000538    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.527365    
2024-05-05 00:33:59,481 - --- validate (epoch=196)-----------
2024-05-05 00:33:59,482 - 1736 samples (32 per mini-batch)
2024-05-05 00:34:31,900 - Epoch: [196][   55/   55]    Loss 3.051071    Top1 58.352535    Top5 73.156682    
2024-05-05 00:34:32,008 - ==> Top1: 58.353    Top5: 73.157    Loss: 3.051

2024-05-05 00:34:32,013 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:34:32,013 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:34:32,056 - 

2024-05-05 00:34:32,057 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:35:25,514 - Epoch: [197][  100/  217]    Overall Loss 0.000332    Objective Loss 0.000332                                        LR 0.000063    Time 0.534509    
2024-05-05 00:36:13,685 - Epoch: [197][  200/  217]    Overall Loss 0.000317    Objective Loss 0.000317                                        LR 0.000063    Time 0.508083    
2024-05-05 00:36:21,570 - Epoch: [197][  217/  217]    Overall Loss 0.000502    Objective Loss 0.000502    Top1 98.360656    Top5 100.000000    LR 0.000063    Time 0.504608    
2024-05-05 00:36:21,678 - --- validate (epoch=197)-----------
2024-05-05 00:36:21,678 - 1736 samples (32 per mini-batch)
2024-05-05 00:36:49,167 - Epoch: [197][   55/   55]    Loss 3.070136    Top1 58.237327    Top5 73.675115    
2024-05-05 00:36:49,306 - ==> Top1: 58.237    Top5: 73.675    Loss: 3.070

2024-05-05 00:36:49,311 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:36:49,311 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:36:49,355 - 

2024-05-05 00:36:49,355 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:37:42,172 - Epoch: [198][  100/  217]    Overall Loss 0.000297    Objective Loss 0.000297                                        LR 0.000063    Time 0.528107    
2024-05-05 00:38:25,602 - Epoch: [198][  200/  217]    Overall Loss 0.000510    Objective Loss 0.000510                                        LR 0.000063    Time 0.481177    
2024-05-05 00:38:31,036 - Epoch: [198][  217/  217]    Overall Loss 0.000477    Objective Loss 0.000477    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.468516    
2024-05-05 00:38:31,138 - --- validate (epoch=198)-----------
2024-05-05 00:38:31,139 - 1736 samples (32 per mini-batch)
2024-05-05 00:38:59,658 - Epoch: [198][   55/   55]    Loss 3.085798    Top1 58.237327    Top5 74.020737    
2024-05-05 00:38:59,789 - ==> Top1: 58.237    Top5: 74.021    Loss: 3.086

2024-05-05 00:38:59,794 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:38:59,794 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:38:59,839 - 

2024-05-05 00:38:59,840 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:39:52,429 - Epoch: [199][  100/  217]    Overall Loss 0.000073    Objective Loss 0.000073                                        LR 0.000063    Time 0.525830    
2024-05-05 00:40:41,047 - Epoch: [199][  200/  217]    Overall Loss 0.000562    Objective Loss 0.000562                                        LR 0.000063    Time 0.505981    
2024-05-05 00:40:51,494 - Epoch: [199][  217/  217]    Overall Loss 0.000524    Objective Loss 0.000524    Top1 100.000000    Top5 100.000000    LR 0.000063    Time 0.514481    
2024-05-05 00:40:51,625 - --- validate (epoch=199)-----------
2024-05-05 00:40:51,625 - 1736 samples (32 per mini-batch)
2024-05-05 00:41:21,270 - Epoch: [199][   55/   55]    Loss 3.078530    Top1 58.467742    Top5 73.963134    
2024-05-05 00:41:21,412 - ==> Top1: 58.468    Top5: 73.963    Loss: 3.079

2024-05-05 00:41:21,418 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:41:21,418 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:41:21,464 - 

2024-05-05 00:41:21,464 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:42:15,265 - Epoch: [200][  100/  217]    Overall Loss 0.000332    Objective Loss 0.000332                                        LR 0.000016    Time 0.537937    
2024-05-05 00:43:08,026 - Epoch: [200][  200/  217]    Overall Loss 0.000443    Objective Loss 0.000443                                        LR 0.000016    Time 0.532745    
2024-05-05 00:43:15,768 - Epoch: [200][  217/  217]    Overall Loss 0.000510    Objective Loss 0.000510    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.526684    
2024-05-05 00:43:15,906 - --- validate (epoch=200)-----------
2024-05-05 00:43:15,907 - 1736 samples (32 per mini-batch)
2024-05-05 00:43:46,652 - Epoch: [200][   55/   55]    Loss 3.097253    Top1 58.294931    Top5 73.847926    
2024-05-05 00:43:46,843 - ==> Top1: 58.295    Top5: 73.848    Loss: 3.097

2024-05-05 00:43:46,849 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:43:46,849 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:43:46,897 - 

2024-05-05 00:43:46,897 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:44:41,736 - Epoch: [201][  100/  217]    Overall Loss 0.000769    Objective Loss 0.000769                                        LR 0.000016    Time 0.548316    
2024-05-05 00:45:29,513 - Epoch: [201][  200/  217]    Overall Loss 0.000550    Objective Loss 0.000550                                        LR 0.000016    Time 0.513013    
2024-05-05 00:45:38,318 - Epoch: [201][  217/  217]    Overall Loss 0.000512    Objective Loss 0.000512    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.513391    
2024-05-05 00:45:38,534 - --- validate (epoch=201)-----------
2024-05-05 00:45:38,534 - 1736 samples (32 per mini-batch)
2024-05-05 00:46:04,850 - Epoch: [201][   55/   55]    Loss 3.042856    Top1 58.064516    Top5 74.020737    
2024-05-05 00:46:04,992 - ==> Top1: 58.065    Top5: 74.021    Loss: 3.043

2024-05-05 00:46:05,000 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:46:05,000 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:46:05,065 - 

2024-05-05 00:46:05,066 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:46:52,253 - Epoch: [202][  100/  217]    Overall Loss 0.000772    Objective Loss 0.000772                                        LR 0.000016    Time 0.471804    
2024-05-05 00:47:43,334 - Epoch: [202][  200/  217]    Overall Loss 0.000541    Objective Loss 0.000541                                        LR 0.000016    Time 0.491274    
2024-05-05 00:47:55,110 - Epoch: [202][  217/  217]    Overall Loss 0.000504    Objective Loss 0.000504    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.507046    
2024-05-05 00:47:55,234 - --- validate (epoch=202)-----------
2024-05-05 00:47:55,234 - 1736 samples (32 per mini-batch)
2024-05-05 00:48:26,657 - Epoch: [202][   55/   55]    Loss 3.108131    Top1 58.237327    Top5 74.193548    
2024-05-05 00:48:26,826 - ==> Top1: 58.237    Top5: 74.194    Loss: 3.108

2024-05-05 00:48:26,834 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:48:26,834 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:48:26,902 - 

2024-05-05 00:48:26,903 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:49:16,475 - Epoch: [203][  100/  217]    Overall Loss 0.000803    Objective Loss 0.000803                                        LR 0.000016    Time 0.495645    
2024-05-05 00:50:03,858 - Epoch: [203][  200/  217]    Overall Loss 0.000536    Objective Loss 0.000536                                        LR 0.000016    Time 0.484709    
2024-05-05 00:50:12,160 - Epoch: [203][  217/  217]    Overall Loss 0.000501    Objective Loss 0.000501    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.484989    
2024-05-05 00:50:12,298 - --- validate (epoch=203)-----------
2024-05-05 00:50:12,299 - 1736 samples (32 per mini-batch)
2024-05-05 00:50:40,661 - Epoch: [203][   55/   55]    Loss 3.050358    Top1 58.410138    Top5 73.502304    
2024-05-05 00:50:40,780 - ==> Top1: 58.410    Top5: 73.502    Loss: 3.050

2024-05-05 00:50:40,788 - ==> Best [Top1: 58.525   Top5: 73.906   Sparsity:0.00   Params: 384080 on epoch: 172]
2024-05-05 00:50:40,789 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:50:40,855 - 

2024-05-05 00:50:40,855 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:51:32,945 - Epoch: [204][  100/  217]    Overall Loss 0.000320    Objective Loss 0.000320                                        LR 0.000016    Time 0.520824    
2024-05-05 00:52:18,498 - Epoch: [204][  200/  217]    Overall Loss 0.000536    Objective Loss 0.000536                                        LR 0.000016    Time 0.488146    
2024-05-05 00:52:26,832 - Epoch: [204][  217/  217]    Overall Loss 0.000500    Objective Loss 0.000500    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.488299    
2024-05-05 00:52:26,956 - --- validate (epoch=204)-----------
2024-05-05 00:52:26,956 - 1736 samples (32 per mini-batch)
2024-05-05 00:52:57,580 - Epoch: [204][   55/   55]    Loss 3.031231    Top1 58.640553    Top5 73.790323    
2024-05-05 00:52:57,721 - ==> Top1: 58.641    Top5: 73.790    Loss: 3.031

2024-05-05 00:52:57,729 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 00:52:57,729 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:52:57,809 - 

2024-05-05 00:52:57,810 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:53:49,131 - Epoch: [205][  100/  217]    Overall Loss 0.000403    Objective Loss 0.000403                                        LR 0.000016    Time 0.513146    
2024-05-05 00:54:34,735 - Epoch: [205][  200/  217]    Overall Loss 0.000520    Objective Loss 0.000520                                        LR 0.000016    Time 0.484543    
2024-05-05 00:54:45,529 - Epoch: [205][  217/  217]    Overall Loss 0.000484    Objective Loss 0.000484    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.496317    
2024-05-05 00:54:45,703 - --- validate (epoch=205)-----------
2024-05-05 00:54:45,704 - 1736 samples (32 per mini-batch)
2024-05-05 00:55:14,304 - Epoch: [205][   55/   55]    Loss 3.092302    Top1 58.352535    Top5 74.020737    
2024-05-05 00:55:14,480 - ==> Top1: 58.353    Top5: 74.021    Loss: 3.092

2024-05-05 00:55:14,488 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 00:55:14,488 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:55:14,553 - 

2024-05-05 00:55:14,554 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:56:11,083 - Epoch: [206][  100/  217]    Overall Loss 0.000403    Objective Loss 0.000403                                        LR 0.000016    Time 0.565214    
2024-05-05 00:56:56,263 - Epoch: [206][  200/  217]    Overall Loss 0.000520    Objective Loss 0.000520                                        LR 0.000016    Time 0.508481    
2024-05-05 00:57:05,672 - Epoch: [206][  217/  217]    Overall Loss 0.000486    Objective Loss 0.000486    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.511999    
2024-05-05 00:57:05,887 - --- validate (epoch=206)-----------
2024-05-05 00:57:05,887 - 1736 samples (32 per mini-batch)
2024-05-05 00:57:36,980 - Epoch: [206][   55/   55]    Loss 3.093933    Top1 58.294931    Top5 74.078341    
2024-05-05 00:57:37,167 - ==> Top1: 58.295    Top5: 74.078    Loss: 3.094

2024-05-05 00:57:37,174 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 00:57:37,174 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:57:37,245 - 

2024-05-05 00:57:37,246 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 00:58:30,460 - Epoch: [207][  100/  217]    Overall Loss 0.000698    Objective Loss 0.000698                                        LR 0.000016    Time 0.532066    
2024-05-05 00:59:16,640 - Epoch: [207][  200/  217]    Overall Loss 0.000555    Objective Loss 0.000555                                        LR 0.000016    Time 0.496907    
2024-05-05 00:59:24,406 - Epoch: [207][  217/  217]    Overall Loss 0.000517    Objective Loss 0.000517    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.493758    
2024-05-05 00:59:24,607 - --- validate (epoch=207)-----------
2024-05-05 00:59:24,608 - 1736 samples (32 per mini-batch)
2024-05-05 00:59:55,083 - Epoch: [207][   55/   55]    Loss 3.048633    Top1 58.352535    Top5 73.963134    
2024-05-05 00:59:55,243 - ==> Top1: 58.353    Top5: 73.963    Loss: 3.049

2024-05-05 00:59:55,250 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 00:59:55,251 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 00:59:55,316 - 

2024-05-05 00:59:55,316 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:00:49,559 - Epoch: [208][  100/  217]    Overall Loss 0.000382    Objective Loss 0.000382                                        LR 0.000016    Time 0.542362    
2024-05-05 01:01:35,404 - Epoch: [208][  200/  217]    Overall Loss 0.000533    Objective Loss 0.000533                                        LR 0.000016    Time 0.500367    
2024-05-05 01:01:42,245 - Epoch: [208][  217/  217]    Overall Loss 0.000497    Objective Loss 0.000497    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.492685    
2024-05-05 01:01:42,384 - --- validate (epoch=208)-----------
2024-05-05 01:01:42,384 - 1736 samples (32 per mini-batch)
2024-05-05 01:02:13,841 - Epoch: [208][   55/   55]    Loss 3.080628    Top1 57.891705    Top5 73.790323    
2024-05-05 01:02:13,963 - ==> Top1: 57.892    Top5: 73.790    Loss: 3.081

2024-05-05 01:02:13,970 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:02:13,970 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:02:14,032 - 

2024-05-05 01:02:14,033 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:03:11,068 - Epoch: [209][  100/  217]    Overall Loss 0.000576    Objective Loss 0.000576                                        LR 0.000016    Time 0.570286    
2024-05-05 01:03:58,508 - Epoch: [209][  200/  217]    Overall Loss 0.000545    Objective Loss 0.000545                                        LR 0.000016    Time 0.522313    
2024-05-05 01:04:04,897 - Epoch: [209][  217/  217]    Overall Loss 0.000509    Objective Loss 0.000509    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.510828    
2024-05-05 01:04:05,055 - --- validate (epoch=209)-----------
2024-05-05 01:04:05,056 - 1736 samples (32 per mini-batch)
2024-05-05 01:04:36,378 - Epoch: [209][   55/   55]    Loss 3.061507    Top1 57.949309    Top5 73.905530    
2024-05-05 01:04:36,521 - ==> Top1: 57.949    Top5: 73.906    Loss: 3.062

2024-05-05 01:04:36,528 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:04:36,528 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:04:36,590 - 

2024-05-05 01:04:36,591 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:05:30,695 - Epoch: [210][  100/  217]    Overall Loss 0.000464    Objective Loss 0.000464                                        LR 0.000016    Time 0.540968    
2024-05-05 01:06:22,093 - Epoch: [210][  200/  217]    Overall Loss 0.000528    Objective Loss 0.000528                                        LR 0.000016    Time 0.527449    
2024-05-05 01:06:27,981 - Epoch: [210][  217/  217]    Overall Loss 0.000493    Objective Loss 0.000493    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.513257    
2024-05-05 01:06:28,107 - --- validate (epoch=210)-----------
2024-05-05 01:06:28,108 - 1736 samples (32 per mini-batch)
2024-05-05 01:06:58,879 - Epoch: [210][   55/   55]    Loss 3.063975    Top1 58.122120    Top5 73.847926    
2024-05-05 01:06:59,019 - ==> Top1: 58.122    Top5: 73.848    Loss: 3.064

2024-05-05 01:06:59,026 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:06:59,026 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:06:59,091 - 

2024-05-05 01:06:59,091 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:07:57,465 - Epoch: [211][  100/  217]    Overall Loss 0.000071    Objective Loss 0.000071                                        LR 0.000016    Time 0.583673    
2024-05-05 01:08:44,966 - Epoch: [211][  200/  217]    Overall Loss 0.000515    Objective Loss 0.000515                                        LR 0.000016    Time 0.529315    
2024-05-05 01:08:51,998 - Epoch: [211][  217/  217]    Overall Loss 0.000481    Objective Loss 0.000481    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.520247    
2024-05-05 01:08:52,106 - --- validate (epoch=211)-----------
2024-05-05 01:08:52,107 - 1736 samples (32 per mini-batch)
2024-05-05 01:09:17,163 - Epoch: [211][   55/   55]    Loss 3.059058    Top1 58.525346    Top5 73.675115    
2024-05-05 01:09:17,276 - ==> Top1: 58.525    Top5: 73.675    Loss: 3.059

2024-05-05 01:09:17,283 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:09:17,283 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:09:17,350 - 

2024-05-05 01:09:17,387 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:10:10,473 - Epoch: [212][  100/  217]    Overall Loss 0.000338    Objective Loss 0.000338                                        LR 0.000016    Time 0.530791    
2024-05-05 01:10:56,492 - Epoch: [212][  200/  217]    Overall Loss 0.000580    Objective Loss 0.000580                                        LR 0.000016    Time 0.495466    
2024-05-05 01:11:04,612 - Epoch: [212][  217/  217]    Overall Loss 0.000540    Objective Loss 0.000540    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.494064    
2024-05-05 01:11:04,745 - --- validate (epoch=212)-----------
2024-05-05 01:11:04,746 - 1736 samples (32 per mini-batch)
2024-05-05 01:11:31,893 - Epoch: [212][   55/   55]    Loss 3.129997    Top1 57.776498    Top5 73.905530    
2024-05-05 01:11:32,027 - ==> Top1: 57.776    Top5: 73.906    Loss: 3.130

2024-05-05 01:11:32,034 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:11:32,034 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:11:32,098 - 

2024-05-05 01:11:32,098 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:12:28,509 - Epoch: [213][  100/  217]    Overall Loss 0.000487    Objective Loss 0.000487                                        LR 0.000016    Time 0.564032    
2024-05-05 01:13:21,206 - Epoch: [213][  200/  217]    Overall Loss 0.000539    Objective Loss 0.000539                                        LR 0.000016    Time 0.545474    
2024-05-05 01:13:28,950 - Epoch: [213][  217/  217]    Overall Loss 0.000503    Objective Loss 0.000503    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.538423    
2024-05-05 01:13:29,106 - --- validate (epoch=213)-----------
2024-05-05 01:13:29,107 - 1736 samples (32 per mini-batch)
2024-05-05 01:14:03,528 - Epoch: [213][   55/   55]    Loss 3.098789    Top1 57.488479    Top5 73.905530    
2024-05-05 01:14:03,668 - ==> Top1: 57.488    Top5: 73.906    Loss: 3.099

2024-05-05 01:14:03,673 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:14:03,673 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:14:03,719 - 

2024-05-05 01:14:03,719 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:14:54,812 - Epoch: [214][  100/  217]    Overall Loss 0.000542    Objective Loss 0.000542                                        LR 0.000016    Time 0.510874    
2024-05-05 01:15:46,322 - Epoch: [214][  200/  217]    Overall Loss 0.000504    Objective Loss 0.000504                                        LR 0.000016    Time 0.512960    
2024-05-05 01:15:51,579 - Epoch: [214][  217/  217]    Overall Loss 0.000469    Objective Loss 0.000469    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.496992    
2024-05-05 01:15:51,694 - --- validate (epoch=214)-----------
2024-05-05 01:15:51,695 - 1736 samples (32 per mini-batch)
2024-05-05 01:16:18,237 - Epoch: [214][   55/   55]    Loss 3.050453    Top1 58.006912    Top5 73.847926    
2024-05-05 01:16:18,364 - ==> Top1: 58.007    Top5: 73.848    Loss: 3.050

2024-05-05 01:16:18,369 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:16:18,369 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:16:18,410 - 

2024-05-05 01:16:18,411 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:17:09,370 - Epoch: [215][  100/  217]    Overall Loss 0.000060    Objective Loss 0.000060                                        LR 0.000016    Time 0.509538    
2024-05-05 01:18:02,865 - Epoch: [215][  200/  217]    Overall Loss 0.000528    Objective Loss 0.000528                                        LR 0.000016    Time 0.522219    
2024-05-05 01:18:11,713 - Epoch: [215][  217/  217]    Overall Loss 0.000491    Objective Loss 0.000491    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.522075    
2024-05-05 01:18:11,836 - --- validate (epoch=215)-----------
2024-05-05 01:18:11,837 - 1736 samples (32 per mini-batch)
2024-05-05 01:18:39,391 - Epoch: [215][   55/   55]    Loss 3.107354    Top1 58.064516    Top5 73.559908    
2024-05-05 01:18:39,497 - ==> Top1: 58.065    Top5: 73.560    Loss: 3.107

2024-05-05 01:18:39,502 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:18:39,502 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:18:39,550 - 

2024-05-05 01:18:39,551 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:19:37,453 - Epoch: [216][  100/  217]    Overall Loss 0.000465    Objective Loss 0.000465                                        LR 0.000016    Time 0.578973    
2024-05-05 01:20:38,110 - Epoch: [216][  200/  217]    Overall Loss 0.000523    Objective Loss 0.000523                                        LR 0.000016    Time 0.592743    
2024-05-05 01:20:46,615 - Epoch: [216][  217/  217]    Overall Loss 0.000487    Objective Loss 0.000487    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.585496    
2024-05-05 01:20:46,741 - --- validate (epoch=216)-----------
2024-05-05 01:20:46,742 - 1736 samples (32 per mini-batch)
2024-05-05 01:21:13,121 - Epoch: [216][   55/   55]    Loss 3.078701    Top1 58.122120    Top5 73.847926    
2024-05-05 01:21:13,224 - ==> Top1: 58.122    Top5: 73.848    Loss: 3.079

2024-05-05 01:21:13,229 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:21:13,229 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:21:13,274 - 

2024-05-05 01:21:13,274 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:22:02,559 - Epoch: [217][  100/  217]    Overall Loss 0.000622    Objective Loss 0.000622                                        LR 0.000016    Time 0.492786    
2024-05-05 01:22:49,670 - Epoch: [217][  200/  217]    Overall Loss 0.000446    Objective Loss 0.000446                                        LR 0.000016    Time 0.481919    
2024-05-05 01:22:57,420 - Epoch: [217][  217/  217]    Overall Loss 0.000497    Objective Loss 0.000497    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.479872    
2024-05-05 01:22:57,553 - --- validate (epoch=217)-----------
2024-05-05 01:22:57,553 - 1736 samples (32 per mini-batch)
2024-05-05 01:23:28,378 - Epoch: [217][   55/   55]    Loss 3.080919    Top1 57.718894    Top5 73.905530    
2024-05-05 01:23:28,505 - ==> Top1: 57.719    Top5: 73.906    Loss: 3.081

2024-05-05 01:23:28,512 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:23:28,513 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:23:28,579 - 

2024-05-05 01:23:28,579 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:24:19,769 - Epoch: [218][  100/  217]    Overall Loss 0.000523    Objective Loss 0.000523                                        LR 0.000016    Time 0.511822    
2024-05-05 01:25:10,830 - Epoch: [218][  200/  217]    Overall Loss 0.000524    Objective Loss 0.000524                                        LR 0.000016    Time 0.511192    
2024-05-05 01:25:19,979 - Epoch: [218][  217/  217]    Overall Loss 0.000514    Objective Loss 0.000514    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.513300    
2024-05-05 01:25:20,113 - --- validate (epoch=218)-----------
2024-05-05 01:25:20,114 - 1736 samples (32 per mini-batch)
2024-05-05 01:25:50,969 - Epoch: [218][   55/   55]    Loss 3.069403    Top1 58.237327    Top5 73.732719    
2024-05-05 01:25:51,123 - ==> Top1: 58.237    Top5: 73.733    Loss: 3.069

2024-05-05 01:25:51,130 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:25:51,130 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:25:51,196 - 

2024-05-05 01:25:51,196 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:26:43,607 - Epoch: [219][  100/  217]    Overall Loss 0.000425    Objective Loss 0.000425                                        LR 0.000016    Time 0.524038    
2024-05-05 01:27:36,301 - Epoch: [219][  200/  217]    Overall Loss 0.000396    Objective Loss 0.000396                                        LR 0.000016    Time 0.525446    
2024-05-05 01:27:42,908 - Epoch: [219][  217/  217]    Overall Loss 0.000495    Objective Loss 0.000495    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.514722    
2024-05-05 01:27:43,099 - --- validate (epoch=219)-----------
2024-05-05 01:27:43,100 - 1736 samples (32 per mini-batch)
2024-05-05 01:28:14,701 - Epoch: [219][   55/   55]    Loss 3.097698    Top1 57.891705    Top5 73.559908    
2024-05-05 01:28:14,873 - ==> Top1: 57.892    Top5: 73.560    Loss: 3.098

2024-05-05 01:28:14,880 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:28:14,880 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:28:14,944 - 

2024-05-05 01:28:14,945 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:29:09,742 - Epoch: [220][  100/  217]    Overall Loss 0.000405    Objective Loss 0.000405                                        LR 0.000016    Time 0.547906    
2024-05-05 01:30:02,766 - Epoch: [220][  200/  217]    Overall Loss 0.000518    Objective Loss 0.000518                                        LR 0.000016    Time 0.539046    
2024-05-05 01:30:11,499 - Epoch: [220][  217/  217]    Overall Loss 0.000483    Objective Loss 0.000483    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.537055    
2024-05-05 01:30:11,770 - --- validate (epoch=220)-----------
2024-05-05 01:30:11,771 - 1736 samples (32 per mini-batch)
2024-05-05 01:30:43,399 - Epoch: [220][   55/   55]    Loss 3.077956    Top1 57.891705    Top5 73.790323    
2024-05-05 01:30:43,555 - ==> Top1: 57.892    Top5: 73.790    Loss: 3.078

2024-05-05 01:30:43,561 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:30:43,561 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:30:43,607 - 

2024-05-05 01:30:43,608 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:31:39,187 - Epoch: [221][  100/  217]    Overall Loss 0.000455    Objective Loss 0.000455                                        LR 0.000016    Time 0.555724    
2024-05-05 01:32:23,853 - Epoch: [221][  200/  217]    Overall Loss 0.000511    Objective Loss 0.000511                                        LR 0.000016    Time 0.501166    
2024-05-05 01:32:33,907 - Epoch: [221][  217/  217]    Overall Loss 0.000477    Objective Loss 0.000477    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.508226    
2024-05-05 01:32:34,062 - --- validate (epoch=221)-----------
2024-05-05 01:32:34,063 - 1736 samples (32 per mini-batch)
2024-05-05 01:33:04,952 - Epoch: [221][   55/   55]    Loss 3.099476    Top1 58.006912    Top5 73.790323    
2024-05-05 01:33:05,087 - ==> Top1: 58.007    Top5: 73.790    Loss: 3.099

2024-05-05 01:33:05,093 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:33:05,093 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:33:05,137 - 

2024-05-05 01:33:05,137 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:33:51,947 - Epoch: [222][  100/  217]    Overall Loss 0.000561    Objective Loss 0.000561                                        LR 0.000016    Time 0.468024    
2024-05-05 01:34:43,689 - Epoch: [222][  200/  217]    Overall Loss 0.000508    Objective Loss 0.000508                                        LR 0.000016    Time 0.492694    
2024-05-05 01:34:51,709 - Epoch: [222][  217/  217]    Overall Loss 0.000473    Objective Loss 0.000473    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.491051    
2024-05-05 01:34:51,891 - --- validate (epoch=222)-----------
2024-05-05 01:34:51,892 - 1736 samples (32 per mini-batch)
2024-05-05 01:35:20,856 - Epoch: [222][   55/   55]    Loss 3.115221    Top1 57.603687    Top5 73.444700    
2024-05-05 01:35:20,999 - ==> Top1: 57.604    Top5: 73.445    Loss: 3.115

2024-05-05 01:35:21,006 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:35:21,007 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:35:21,067 - 

2024-05-05 01:35:21,068 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:36:23,384 - Epoch: [223][  100/  217]    Overall Loss 0.000257    Objective Loss 0.000257                                        LR 0.000016    Time 0.623093    
2024-05-05 01:37:14,664 - Epoch: [223][  200/  217]    Overall Loss 0.000506    Objective Loss 0.000506                                        LR 0.000016    Time 0.567921    
2024-05-05 01:37:21,724 - Epoch: [223][  217/  217]    Overall Loss 0.000471    Objective Loss 0.000471    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.555956    
2024-05-05 01:37:21,879 - --- validate (epoch=223)-----------
2024-05-05 01:37:21,880 - 1736 samples (32 per mini-batch)
2024-05-05 01:37:53,980 - Epoch: [223][   55/   55]    Loss 3.110642    Top1 57.949309    Top5 73.444700    
2024-05-05 01:37:54,169 - ==> Top1: 57.949    Top5: 73.445    Loss: 3.111

2024-05-05 01:37:54,177 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:37:54,177 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:37:54,244 - 

2024-05-05 01:37:54,244 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:38:48,179 - Epoch: [224][  100/  217]    Overall Loss 0.000304    Objective Loss 0.000304                                        LR 0.000016    Time 0.539280    
2024-05-05 01:39:40,079 - Epoch: [224][  200/  217]    Overall Loss 0.000511    Objective Loss 0.000511                                        LR 0.000016    Time 0.529110    
2024-05-05 01:39:48,139 - Epoch: [224][  217/  217]    Overall Loss 0.000476    Objective Loss 0.000476    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.524798    
2024-05-05 01:39:48,310 - --- validate (epoch=224)-----------
2024-05-05 01:39:48,311 - 1736 samples (32 per mini-batch)
2024-05-05 01:40:19,110 - Epoch: [224][   55/   55]    Loss 3.079990    Top1 57.949309    Top5 73.617512    
2024-05-05 01:40:19,298 - ==> Top1: 57.949    Top5: 73.618    Loss: 3.080

2024-05-05 01:40:19,303 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:40:19,303 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:40:19,348 - 

2024-05-05 01:40:19,348 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:41:14,521 - Epoch: [225][  100/  217]    Overall Loss 0.000943    Objective Loss 0.000943                                        LR 0.000016    Time 0.551671    
2024-05-05 01:42:00,803 - Epoch: [225][  200/  217]    Overall Loss 0.000500    Objective Loss 0.000500                                        LR 0.000016    Time 0.507218    
2024-05-05 01:42:08,315 - Epoch: [225][  217/  217]    Overall Loss 0.000467    Objective Loss 0.000467    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.502092    
2024-05-05 01:42:08,491 - --- validate (epoch=225)-----------
2024-05-05 01:42:08,492 - 1736 samples (32 per mini-batch)
2024-05-05 01:42:36,484 - Epoch: [225][   55/   55]    Loss 3.074039    Top1 58.410138    Top5 73.675115    
2024-05-05 01:42:36,612 - ==> Top1: 58.410    Top5: 73.675    Loss: 3.074

2024-05-05 01:42:36,620 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:42:36,620 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:42:36,691 - 

2024-05-05 01:42:36,692 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:43:28,562 - Epoch: [226][  100/  217]    Overall Loss 0.000542    Objective Loss 0.000542                                        LR 0.000016    Time 0.518626    
2024-05-05 01:44:18,451 - Epoch: [226][  200/  217]    Overall Loss 0.000425    Objective Loss 0.000425                                        LR 0.000016    Time 0.508728    
2024-05-05 01:44:32,219 - Epoch: [226][  217/  217]    Overall Loss 0.000487    Objective Loss 0.000487    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.532316    
2024-05-05 01:44:32,385 - --- validate (epoch=226)-----------
2024-05-05 01:44:32,386 - 1736 samples (32 per mini-batch)
2024-05-05 01:45:01,926 - Epoch: [226][   55/   55]    Loss 3.076854    Top1 58.237327    Top5 73.732719    
2024-05-05 01:45:02,064 - ==> Top1: 58.237    Top5: 73.733    Loss: 3.077

2024-05-05 01:45:02,069 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:45:02,069 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:45:02,114 - 

2024-05-05 01:45:02,115 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:45:54,505 - Epoch: [227][  100/  217]    Overall Loss 0.000212    Objective Loss 0.000212                                        LR 0.000016    Time 0.523840    
2024-05-05 01:46:43,357 - Epoch: [227][  200/  217]    Overall Loss 0.000498    Objective Loss 0.000498                                        LR 0.000016    Time 0.506152    
2024-05-05 01:46:48,220 - Epoch: [227][  217/  217]    Overall Loss 0.000464    Objective Loss 0.000464    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.488903    
2024-05-05 01:46:48,338 - --- validate (epoch=227)-----------
2024-05-05 01:46:48,338 - 1736 samples (32 per mini-batch)
2024-05-05 01:47:20,100 - Epoch: [227][   55/   55]    Loss 3.081909    Top1 57.891705    Top5 73.847926    
2024-05-05 01:47:20,238 - ==> Top1: 57.892    Top5: 73.848    Loss: 3.082

2024-05-05 01:47:20,245 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:47:20,245 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:47:20,307 - 

2024-05-05 01:47:20,308 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:48:11,214 - Epoch: [228][  100/  217]    Overall Loss 0.000502    Objective Loss 0.000502                                        LR 0.000016    Time 0.508992    
2024-05-05 01:49:00,168 - Epoch: [228][  200/  217]    Overall Loss 0.000404    Objective Loss 0.000404                                        LR 0.000016    Time 0.499241    
2024-05-05 01:49:06,307 - Epoch: [228][  217/  217]    Overall Loss 0.000466    Objective Loss 0.000466    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.488415    
2024-05-05 01:49:06,425 - --- validate (epoch=228)-----------
2024-05-05 01:49:06,425 - 1736 samples (32 per mini-batch)
2024-05-05 01:49:35,924 - Epoch: [228][   55/   55]    Loss 3.066484    Top1 57.718894    Top5 73.329493    
2024-05-05 01:49:36,032 - ==> Top1: 57.719    Top5: 73.329    Loss: 3.066

2024-05-05 01:49:36,037 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:49:36,037 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:49:36,080 - 

2024-05-05 01:49:36,080 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:50:26,830 - Epoch: [229][  100/  217]    Overall Loss 0.000798    Objective Loss 0.000798                                        LR 0.000016    Time 0.507434    
2024-05-05 01:51:13,706 - Epoch: [229][  200/  217]    Overall Loss 0.000517    Objective Loss 0.000517                                        LR 0.000016    Time 0.488074    
2024-05-05 01:51:20,331 - Epoch: [229][  217/  217]    Overall Loss 0.000482    Objective Loss 0.000482    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.480362    
2024-05-05 01:51:20,445 - --- validate (epoch=229)-----------
2024-05-05 01:51:20,445 - 1736 samples (32 per mini-batch)
2024-05-05 01:51:47,514 - Epoch: [229][   55/   55]    Loss 3.090774    Top1 58.122120    Top5 73.732719    
2024-05-05 01:51:47,617 - ==> Top1: 58.122    Top5: 73.733    Loss: 3.091

2024-05-05 01:51:47,625 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:51:47,625 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:51:47,688 - 

2024-05-05 01:51:47,689 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:52:45,214 - Epoch: [230][  100/  217]    Overall Loss 0.000799    Objective Loss 0.000799                                        LR 0.000016    Time 0.575184    
2024-05-05 01:53:30,071 - Epoch: [230][  200/  217]    Overall Loss 0.000507    Objective Loss 0.000507                                        LR 0.000016    Time 0.511846    
2024-05-05 01:53:36,515 - Epoch: [230][  217/  217]    Overall Loss 0.000471    Objective Loss 0.000471    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.501439    
2024-05-05 01:53:36,617 - --- validate (epoch=230)-----------
2024-05-05 01:53:36,618 - 1736 samples (32 per mini-batch)
2024-05-05 01:54:05,908 - Epoch: [230][   55/   55]    Loss 3.056408    Top1 57.546083    Top5 73.617512    
2024-05-05 01:54:06,035 - ==> Top1: 57.546    Top5: 73.618    Loss: 3.056

2024-05-05 01:54:06,042 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:54:06,042 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:54:06,105 - 

2024-05-05 01:54:06,105 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:54:57,212 - Epoch: [231][  100/  217]    Overall Loss 0.000507    Objective Loss 0.000507                                        LR 0.000016    Time 0.510994    
2024-05-05 01:55:49,957 - Epoch: [231][  200/  217]    Overall Loss 0.000496    Objective Loss 0.000496                                        LR 0.000016    Time 0.519194    
2024-05-05 01:55:57,414 - Epoch: [231][  217/  217]    Overall Loss 0.000463    Objective Loss 0.000463    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.512881    
2024-05-05 01:55:57,540 - --- validate (epoch=231)-----------
2024-05-05 01:55:57,540 - 1736 samples (32 per mini-batch)
2024-05-05 01:56:29,445 - Epoch: [231][   55/   55]    Loss 3.094672    Top1 57.661290    Top5 73.617512    
2024-05-05 01:56:29,552 - ==> Top1: 57.661    Top5: 73.618    Loss: 3.095

2024-05-05 01:56:29,559 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:56:29,559 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:56:29,624 - 

2024-05-05 01:56:29,625 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:57:15,006 - Epoch: [232][  100/  217]    Overall Loss 0.000238    Objective Loss 0.000238                                        LR 0.000016    Time 0.453743    
2024-05-05 01:58:03,525 - Epoch: [232][  200/  217]    Overall Loss 0.000512    Objective Loss 0.000512                                        LR 0.000016    Time 0.469442    
2024-05-05 01:58:11,318 - Epoch: [232][  217/  217]    Overall Loss 0.000477    Objective Loss 0.000477    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.468572    
2024-05-05 01:58:11,447 - --- validate (epoch=232)-----------
2024-05-05 01:58:11,447 - 1736 samples (32 per mini-batch)
2024-05-05 01:58:38,688 - Epoch: [232][   55/   55]    Loss 3.067514    Top1 57.834101    Top5 73.732719    
2024-05-05 01:58:38,816 - ==> Top1: 57.834    Top5: 73.733    Loss: 3.068

2024-05-05 01:58:38,823 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 01:58:38,824 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 01:58:38,891 - 

2024-05-05 01:58:38,891 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 01:59:34,644 - Epoch: [233][  100/  217]    Overall Loss 0.000611    Objective Loss 0.000611                                        LR 0.000016    Time 0.557458    
2024-05-05 02:00:23,455 - Epoch: [233][  200/  217]    Overall Loss 0.000519    Objective Loss 0.000519                                        LR 0.000016    Time 0.522764    
2024-05-05 02:00:28,500 - Epoch: [233][  217/  217]    Overall Loss 0.000484    Objective Loss 0.000484    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.505051    
2024-05-05 02:00:28,599 - --- validate (epoch=233)-----------
2024-05-05 02:00:28,599 - 1736 samples (32 per mini-batch)
2024-05-05 02:01:00,365 - Epoch: [233][   55/   55]    Loss 3.099853    Top1 57.718894    Top5 74.078341    
2024-05-05 02:01:00,504 - ==> Top1: 57.719    Top5: 74.078    Loss: 3.100

2024-05-05 02:01:00,513 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 02:01:00,513 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 02:01:00,571 - 

2024-05-05 02:01:00,571 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:01:52,143 - Epoch: [234][  100/  217]    Overall Loss 0.000513    Objective Loss 0.000513                                        LR 0.000016    Time 0.515651    
2024-05-05 02:02:35,327 - Epoch: [234][  200/  217]    Overall Loss 0.000514    Objective Loss 0.000514                                        LR 0.000016    Time 0.473715    
2024-05-05 02:02:45,093 - Epoch: [234][  217/  217]    Overall Loss 0.000479    Objective Loss 0.000479    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.481599    
2024-05-05 02:02:45,320 - --- validate (epoch=234)-----------
2024-05-05 02:02:45,320 - 1736 samples (32 per mini-batch)
2024-05-05 02:03:15,176 - Epoch: [234][   55/   55]    Loss 3.115250    Top1 57.258065    Top5 73.675115    
2024-05-05 02:03:15,291 - ==> Top1: 57.258    Top5: 73.675    Loss: 3.115

2024-05-05 02:03:15,298 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 02:03:15,298 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 02:03:15,361 - 

2024-05-05 02:03:15,362 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:04:04,921 - Epoch: [235][  100/  217]    Overall Loss 0.000745    Objective Loss 0.000745                                        LR 0.000016    Time 0.495528    
2024-05-05 02:04:50,450 - Epoch: [235][  200/  217]    Overall Loss 0.000496    Objective Loss 0.000496                                        LR 0.000016    Time 0.475383    
2024-05-05 02:04:58,733 - Epoch: [235][  217/  217]    Overall Loss 0.000462    Objective Loss 0.000462    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.476307    
2024-05-05 02:04:58,836 - --- validate (epoch=235)-----------
2024-05-05 02:04:58,837 - 1736 samples (32 per mini-batch)
2024-05-05 02:05:25,332 - Epoch: [235][   55/   55]    Loss 3.127193    Top1 58.064516    Top5 73.617512    
2024-05-05 02:05:25,461 - ==> Top1: 58.065    Top5: 73.618    Loss: 3.127

2024-05-05 02:05:25,468 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 02:05:25,468 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 02:05:25,531 - 

2024-05-05 02:05:25,532 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:06:18,386 - Epoch: [236][  100/  217]    Overall Loss 0.000404    Objective Loss 0.000404                                        LR 0.000016    Time 0.528471    
2024-05-05 02:07:05,724 - Epoch: [236][  200/  217]    Overall Loss 0.000510    Objective Loss 0.000510                                        LR 0.000016    Time 0.500904    
2024-05-05 02:07:14,551 - Epoch: [236][  217/  217]    Overall Loss 0.000475    Objective Loss 0.000475    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.502335    
2024-05-05 02:07:14,692 - --- validate (epoch=236)-----------
2024-05-05 02:07:14,692 - 1736 samples (32 per mini-batch)
2024-05-05 02:07:44,654 - Epoch: [236][   55/   55]    Loss 3.114340    Top1 57.603687    Top5 73.732719    
2024-05-05 02:07:44,783 - ==> Top1: 57.604    Top5: 73.733    Loss: 3.114

2024-05-05 02:07:44,788 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 02:07:44,788 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 02:07:44,831 - 

2024-05-05 02:07:44,832 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:08:37,593 - Epoch: [237][  100/  217]    Overall Loss 0.000781    Objective Loss 0.000781                                        LR 0.000016    Time 0.527547    
2024-05-05 02:09:26,477 - Epoch: [237][  200/  217]    Overall Loss 0.000503    Objective Loss 0.000503                                        LR 0.000016    Time 0.508169    
2024-05-05 02:09:34,481 - Epoch: [237][  217/  217]    Overall Loss 0.000468    Objective Loss 0.000468    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.505237    
2024-05-05 02:09:34,681 - --- validate (epoch=237)-----------
2024-05-05 02:09:34,681 - 1736 samples (32 per mini-batch)
2024-05-05 02:10:04,348 - Epoch: [237][   55/   55]    Loss 3.087561    Top1 57.834101    Top5 74.020737    
2024-05-05 02:10:04,522 - ==> Top1: 57.834    Top5: 74.021    Loss: 3.088

2024-05-05 02:10:04,529 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 02:10:04,530 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 02:10:04,596 - 

2024-05-05 02:10:04,597 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:10:59,591 - Epoch: [238][  100/  217]    Overall Loss 0.000695    Objective Loss 0.000695                                        LR 0.000016    Time 0.549867    
2024-05-05 02:11:46,451 - Epoch: [238][  200/  217]    Overall Loss 0.000498    Objective Loss 0.000498                                        LR 0.000016    Time 0.509211    
2024-05-05 02:11:53,238 - Epoch: [238][  217/  217]    Overall Loss 0.000463    Objective Loss 0.000463    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.500586    
2024-05-05 02:11:53,377 - --- validate (epoch=238)-----------
2024-05-05 02:11:53,377 - 1736 samples (32 per mini-batch)
2024-05-05 02:12:19,994 - Epoch: [238][   55/   55]    Loss 3.051421    Top1 57.776498    Top5 74.078341    
2024-05-05 02:12:20,101 - ==> Top1: 57.776    Top5: 74.078    Loss: 3.051

2024-05-05 02:12:20,108 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 02:12:20,109 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 02:12:20,162 - 

2024-05-05 02:12:20,163 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:13:13,795 - Epoch: [239][  100/  217]    Overall Loss 0.000296    Objective Loss 0.000296                                        LR 0.000016    Time 0.536251    
2024-05-05 02:14:02,844 - Epoch: [239][  200/  217]    Overall Loss 0.000481    Objective Loss 0.000481                                        LR 0.000016    Time 0.513346    
2024-05-05 02:14:11,712 - Epoch: [239][  217/  217]    Overall Loss 0.000448    Objective Loss 0.000448    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.513989    
2024-05-05 02:14:11,847 - --- validate (epoch=239)-----------
2024-05-05 02:14:11,847 - 1736 samples (32 per mini-batch)
2024-05-05 02:14:40,579 - Epoch: [239][   55/   55]    Loss 3.084753    Top1 57.891705    Top5 74.251152    
2024-05-05 02:14:40,691 - ==> Top1: 57.892    Top5: 74.251    Loss: 3.085

2024-05-05 02:14:40,696 - ==> Best [Top1: 58.641   Top5: 73.790   Sparsity:0.00   Params: 384080 on epoch: 204]
2024-05-05 02:14:40,696 - Saving checkpoint to: logs/2024.05.04-165410/checkpoint.pth.tar
2024-05-05 02:14:40,740 - 

2024-05-05 02:14:40,740 - Initiating quantization aware training (QAT)...
2024-05-05 02:14:40,807 - 

2024-05-05 02:14:40,808 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:15:40,598 - Epoch: [240][  100/  217]    Overall Loss 1.885747    Objective Loss 1.885747                                        LR 0.000016    Time 0.597849    
2024-05-05 02:16:32,945 - Epoch: [240][  200/  217]    Overall Loss 1.443847    Objective Loss 1.443847                                        LR 0.000016    Time 0.560637    
2024-05-05 02:16:40,645 - Epoch: [240][  217/  217]    Overall Loss 1.398523    Objective Loss 1.398523    Top1 78.688525    Top5 95.081967    LR 0.000016    Time 0.552194    
2024-05-05 02:16:40,749 - --- validate (epoch=240)-----------
2024-05-05 02:16:40,750 - 1736 samples (32 per mini-batch)
2024-05-05 02:17:06,864 - Epoch: [240][   55/   55]    Loss 2.229922    Top1 51.036866    Top5 67.626728    
2024-05-05 02:17:06,988 - ==> Top1: 51.037    Top5: 67.627    Loss: 2.230

2024-05-05 02:17:06,992 - ==> Best [Top1: 51.037   Top5: 67.627   Sparsity:0.00   Params: 384080 on epoch: 240]
2024-05-05 02:17:06,992 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:17:07,032 - 

2024-05-05 02:17:07,033 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:17:58,399 - Epoch: [241][  100/  217]    Overall Loss 0.768558    Objective Loss 0.768558                                        LR 0.000016    Time 0.513603    
2024-05-05 02:18:56,403 - Epoch: [241][  200/  217]    Overall Loss 0.741004    Objective Loss 0.741004                                        LR 0.000016    Time 0.546800    
2024-05-05 02:19:05,745 - Epoch: [241][  217/  217]    Overall Loss 0.733745    Objective Loss 0.733745    Top1 83.606557    Top5 98.360656    LR 0.000016    Time 0.547005    
2024-05-05 02:19:05,881 - --- validate (epoch=241)-----------
2024-05-05 02:19:05,881 - 1736 samples (32 per mini-batch)
2024-05-05 02:19:39,556 - Epoch: [241][   55/   55]    Loss 2.227926    Top1 51.728111    Top5 69.182028    
2024-05-05 02:19:39,691 - ==> Top1: 51.728    Top5: 69.182    Loss: 2.228

2024-05-05 02:19:39,695 - ==> Best [Top1: 51.728   Top5: 69.182   Sparsity:0.00   Params: 384080 on epoch: 241]
2024-05-05 02:19:39,695 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:19:39,738 - 

2024-05-05 02:19:39,738 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:20:33,198 - Epoch: [242][  100/  217]    Overall Loss 0.589622    Objective Loss 0.589622                                        LR 0.000016    Time 0.534540    
2024-05-05 02:21:20,652 - Epoch: [242][  200/  217]    Overall Loss 0.590056    Objective Loss 0.590056                                        LR 0.000016    Time 0.504515    
2024-05-05 02:21:29,316 - Epoch: [242][  217/  217]    Overall Loss 0.589123    Objective Loss 0.589123    Top1 88.524590    Top5 98.360656    LR 0.000016    Time 0.504906    
2024-05-05 02:21:29,459 - --- validate (epoch=242)-----------
2024-05-05 02:21:29,460 - 1736 samples (32 per mini-batch)
2024-05-05 02:21:58,571 - Epoch: [242][   55/   55]    Loss 2.162175    Top1 52.419355    Top5 70.161290    
2024-05-05 02:21:58,703 - ==> Top1: 52.419    Top5: 70.161    Loss: 2.162

2024-05-05 02:21:58,710 - ==> Best [Top1: 52.419   Top5: 70.161   Sparsity:0.00   Params: 384080 on epoch: 242]
2024-05-05 02:21:58,710 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:21:58,770 - 

2024-05-05 02:21:58,770 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:22:53,376 - Epoch: [243][  100/  217]    Overall Loss 0.515815    Objective Loss 0.515815                                        LR 0.000016    Time 0.545989    
2024-05-05 02:23:43,520 - Epoch: [243][  200/  217]    Overall Loss 0.502521    Objective Loss 0.502521                                        LR 0.000016    Time 0.523690    
2024-05-05 02:23:49,915 - Epoch: [243][  217/  217]    Overall Loss 0.499575    Objective Loss 0.499575    Top1 88.524590    Top5 100.000000    LR 0.000016    Time 0.512130    
2024-05-05 02:23:50,060 - --- validate (epoch=243)-----------
2024-05-05 02:23:50,061 - 1736 samples (32 per mini-batch)
2024-05-05 02:24:23,440 - Epoch: [243][   55/   55]    Loss 2.178534    Top1 53.168203    Top5 70.391705    
2024-05-05 02:24:23,553 - ==> Top1: 53.168    Top5: 70.392    Loss: 2.179

2024-05-05 02:24:23,558 - ==> Best [Top1: 53.168   Top5: 70.392   Sparsity:0.00   Params: 384080 on epoch: 243]
2024-05-05 02:24:23,558 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:24:23,599 - 

2024-05-05 02:24:23,600 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:25:10,210 - Epoch: [244][  100/  217]    Overall Loss 0.448633    Objective Loss 0.448633                                        LR 0.000016    Time 0.466047    
2024-05-05 02:26:01,922 - Epoch: [244][  200/  217]    Overall Loss 0.443289    Objective Loss 0.443289                                        LR 0.000016    Time 0.491561    
2024-05-05 02:26:09,112 - Epoch: [244][  217/  217]    Overall Loss 0.442197    Objective Loss 0.442197    Top1 91.803279    Top5 100.000000    LR 0.000016    Time 0.486181    
2024-05-05 02:26:09,224 - --- validate (epoch=244)-----------
2024-05-05 02:26:09,224 - 1736 samples (32 per mini-batch)
2024-05-05 02:26:39,330 - Epoch: [244][   55/   55]    Loss 2.174007    Top1 52.937788    Top5 70.161290    
2024-05-05 02:26:39,474 - ==> Top1: 52.938    Top5: 70.161    Loss: 2.174

2024-05-05 02:26:39,477 - ==> Best [Top1: 53.168   Top5: 70.392   Sparsity:0.00   Params: 384080 on epoch: 243]
2024-05-05 02:26:39,478 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:26:39,508 - 

2024-05-05 02:26:39,509 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:27:33,138 - Epoch: [245][  100/  217]    Overall Loss 0.404156    Objective Loss 0.404156                                        LR 0.000016    Time 0.536230    
2024-05-05 02:28:21,725 - Epoch: [245][  200/  217]    Overall Loss 0.405885    Objective Loss 0.405885                                        LR 0.000016    Time 0.511026    
2024-05-05 02:28:32,752 - Epoch: [245][  217/  217]    Overall Loss 0.405440    Objective Loss 0.405440    Top1 96.721311    Top5 100.000000    LR 0.000016    Time 0.521803    
2024-05-05 02:28:32,904 - --- validate (epoch=245)-----------
2024-05-05 02:28:32,904 - 1736 samples (32 per mini-batch)
2024-05-05 02:29:02,742 - Epoch: [245][   55/   55]    Loss 2.149610    Top1 53.513825    Top5 71.313364    
2024-05-05 02:29:02,884 - ==> Top1: 53.514    Top5: 71.313    Loss: 2.150

2024-05-05 02:29:02,890 - ==> Best [Top1: 53.514   Top5: 71.313   Sparsity:0.00   Params: 384080 on epoch: 245]
2024-05-05 02:29:02,890 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:29:02,948 - 

2024-05-05 02:29:02,948 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:29:54,960 - Epoch: [246][  100/  217]    Overall Loss 0.363910    Objective Loss 0.363910                                        LR 0.000016    Time 0.520052    
2024-05-05 02:30:46,481 - Epoch: [246][  200/  217]    Overall Loss 0.371406    Objective Loss 0.371406                                        LR 0.000016    Time 0.517607    
2024-05-05 02:30:55,891 - Epoch: [246][  217/  217]    Overall Loss 0.369205    Objective Loss 0.369205    Top1 95.081967    Top5 100.000000    LR 0.000016    Time 0.520416    
2024-05-05 02:30:56,025 - --- validate (epoch=246)-----------
2024-05-05 02:30:56,025 - 1736 samples (32 per mini-batch)
2024-05-05 02:31:22,847 - Epoch: [246][   55/   55]    Loss 2.166269    Top1 53.225806    Top5 71.370968    
2024-05-05 02:31:23,009 - ==> Top1: 53.226    Top5: 71.371    Loss: 2.166

2024-05-05 02:31:23,014 - ==> Best [Top1: 53.514   Top5: 71.313   Sparsity:0.00   Params: 384080 on epoch: 245]
2024-05-05 02:31:23,015 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:31:23,060 - 

2024-05-05 02:31:23,061 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:32:21,369 - Epoch: [247][  100/  217]    Overall Loss 0.334428    Objective Loss 0.334428                                        LR 0.000016    Time 0.583014    
2024-05-05 02:33:13,854 - Epoch: [247][  200/  217]    Overall Loss 0.346686    Objective Loss 0.346686                                        LR 0.000016    Time 0.553916    
2024-05-05 02:33:21,359 - Epoch: [247][  217/  217]    Overall Loss 0.343632    Objective Loss 0.343632    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.545099    
2024-05-05 02:33:21,465 - --- validate (epoch=247)-----------
2024-05-05 02:33:21,466 - 1736 samples (32 per mini-batch)
2024-05-05 02:33:51,421 - Epoch: [247][   55/   55]    Loss 2.134560    Top1 53.801843    Top5 71.947005    
2024-05-05 02:33:51,556 - ==> Top1: 53.802    Top5: 71.947    Loss: 2.135

2024-05-05 02:33:51,560 - ==> Best [Top1: 53.802   Top5: 71.947   Sparsity:0.00   Params: 384080 on epoch: 247]
2024-05-05 02:33:51,560 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:33:51,600 - 

2024-05-05 02:33:51,600 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:34:49,702 - Epoch: [248][  100/  217]    Overall Loss 0.320730    Objective Loss 0.320730                                        LR 0.000016    Time 0.580957    
2024-05-05 02:35:34,689 - Epoch: [248][  200/  217]    Overall Loss 0.322038    Objective Loss 0.322038                                        LR 0.000016    Time 0.515394    
2024-05-05 02:35:42,809 - Epoch: [248][  217/  217]    Overall Loss 0.323778    Objective Loss 0.323778    Top1 85.245902    Top5 100.000000    LR 0.000016    Time 0.512430    
2024-05-05 02:35:42,927 - --- validate (epoch=248)-----------
2024-05-05 02:35:42,928 - 1736 samples (32 per mini-batch)
2024-05-05 02:36:13,893 - Epoch: [248][   55/   55]    Loss 2.170331    Top1 53.456221    Top5 71.543779    
2024-05-05 02:36:14,022 - ==> Top1: 53.456    Top5: 71.544    Loss: 2.170

2024-05-05 02:36:14,026 - ==> Best [Top1: 53.802   Top5: 71.947   Sparsity:0.00   Params: 384080 on epoch: 247]
2024-05-05 02:36:14,026 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:36:14,062 - 

2024-05-05 02:36:14,062 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:37:05,487 - Epoch: [249][  100/  217]    Overall Loss 0.302582    Objective Loss 0.302582                                        LR 0.000016    Time 0.514186    
2024-05-05 02:37:51,759 - Epoch: [249][  200/  217]    Overall Loss 0.315396    Objective Loss 0.315396                                        LR 0.000016    Time 0.488433    
2024-05-05 02:37:57,939 - Epoch: [249][  217/  217]    Overall Loss 0.315462    Objective Loss 0.315462    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.478640    
2024-05-05 02:37:58,047 - --- validate (epoch=249)-----------
2024-05-05 02:37:58,047 - 1736 samples (32 per mini-batch)
2024-05-05 02:38:27,390 - Epoch: [249][   55/   55]    Loss 2.216171    Top1 52.822581    Top5 70.622120    
2024-05-05 02:38:27,491 - ==> Top1: 52.823    Top5: 70.622    Loss: 2.216

2024-05-05 02:38:27,497 - ==> Best [Top1: 53.802   Top5: 71.947   Sparsity:0.00   Params: 384080 on epoch: 247]
2024-05-05 02:38:27,497 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:38:27,542 - 

2024-05-05 02:38:27,542 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:39:19,522 - Epoch: [250][  100/  217]    Overall Loss 0.273540    Objective Loss 0.273540                                        LR 0.000016    Time 0.519736    
2024-05-05 02:40:15,285 - Epoch: [250][  200/  217]    Overall Loss 0.284771    Objective Loss 0.284771                                        LR 0.000016    Time 0.538654    
2024-05-05 02:40:22,726 - Epoch: [250][  217/  217]    Overall Loss 0.284196    Objective Loss 0.284196    Top1 95.081967    Top5 100.000000    LR 0.000016    Time 0.530739    
2024-05-05 02:40:22,959 - --- validate (epoch=250)-----------
2024-05-05 02:40:22,960 - 1736 samples (32 per mini-batch)
2024-05-05 02:40:52,872 - Epoch: [250][   55/   55]    Loss 2.187857    Top1 53.686636    Top5 71.428571    
2024-05-05 02:40:53,048 - ==> Top1: 53.687    Top5: 71.429    Loss: 2.188

2024-05-05 02:40:53,057 - ==> Best [Top1: 53.802   Top5: 71.947   Sparsity:0.00   Params: 384080 on epoch: 247]
2024-05-05 02:40:53,057 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:40:53,105 - 

2024-05-05 02:40:53,106 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:41:44,011 - Epoch: [251][  100/  217]    Overall Loss 0.265379    Objective Loss 0.265379                                        LR 0.000016    Time 0.508981    
2024-05-05 02:42:30,151 - Epoch: [251][  200/  217]    Overall Loss 0.276827    Objective Loss 0.276827                                        LR 0.000016    Time 0.485168    
2024-05-05 02:42:41,266 - Epoch: [251][  217/  217]    Overall Loss 0.276113    Objective Loss 0.276113    Top1 96.721311    Top5 100.000000    LR 0.000016    Time 0.498374    
2024-05-05 02:42:41,426 - --- validate (epoch=251)-----------
2024-05-05 02:42:41,427 - 1736 samples (32 per mini-batch)
2024-05-05 02:43:12,589 - Epoch: [251][   55/   55]    Loss 2.190423    Top1 53.571429    Top5 70.334101    
2024-05-05 02:43:12,719 - ==> Top1: 53.571    Top5: 70.334    Loss: 2.190

2024-05-05 02:43:12,724 - ==> Best [Top1: 53.802   Top5: 71.947   Sparsity:0.00   Params: 384080 on epoch: 247]
2024-05-05 02:43:12,724 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:43:12,756 - 

2024-05-05 02:43:12,756 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:44:04,713 - Epoch: [252][  100/  217]    Overall Loss 0.253127    Objective Loss 0.253127                                        LR 0.000016    Time 0.519514    
2024-05-05 02:44:46,805 - Epoch: [252][  200/  217]    Overall Loss 0.263628    Objective Loss 0.263628                                        LR 0.000016    Time 0.470193    
2024-05-05 02:44:53,418 - Epoch: [252][  217/  217]    Overall Loss 0.264698    Objective Loss 0.264698    Top1 96.721311    Top5 100.000000    LR 0.000016    Time 0.463827    
2024-05-05 02:44:53,521 - --- validate (epoch=252)-----------
2024-05-05 02:44:53,522 - 1736 samples (32 per mini-batch)
2024-05-05 02:45:21,538 - Epoch: [252][   55/   55]    Loss 2.136869    Top1 53.341014    Top5 71.428571    
2024-05-05 02:45:21,648 - ==> Top1: 53.341    Top5: 71.429    Loss: 2.137

2024-05-05 02:45:21,653 - ==> Best [Top1: 53.802   Top5: 71.947   Sparsity:0.00   Params: 384080 on epoch: 247]
2024-05-05 02:45:21,654 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:45:21,700 - 

2024-05-05 02:45:21,701 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:46:09,218 - Epoch: [253][  100/  217]    Overall Loss 0.246518    Objective Loss 0.246518                                        LR 0.000016    Time 0.475115    
2024-05-05 02:46:55,289 - Epoch: [253][  200/  217]    Overall Loss 0.247596    Objective Loss 0.247596                                        LR 0.000016    Time 0.467890    
2024-05-05 02:47:02,135 - Epoch: [253][  217/  217]    Overall Loss 0.247430    Objective Loss 0.247430    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.462778    
2024-05-05 02:47:02,261 - --- validate (epoch=253)-----------
2024-05-05 02:47:02,262 - 1736 samples (32 per mini-batch)
2024-05-05 02:47:29,613 - Epoch: [253][   55/   55]    Loss 2.176117    Top1 54.262673    Top5 71.486175    
2024-05-05 02:47:29,747 - ==> Top1: 54.263    Top5: 71.486    Loss: 2.176

2024-05-05 02:47:29,753 - ==> Best [Top1: 54.263   Top5: 71.486   Sparsity:0.00   Params: 384080 on epoch: 253]
2024-05-05 02:47:29,753 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:47:29,812 - 

2024-05-05 02:47:29,813 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:48:21,632 - Epoch: [254][  100/  217]    Overall Loss 0.231914    Objective Loss 0.231914                                        LR 0.000016    Time 0.518128    
2024-05-05 02:49:05,544 - Epoch: [254][  200/  217]    Overall Loss 0.230918    Objective Loss 0.230918                                        LR 0.000016    Time 0.478602    
2024-05-05 02:49:14,020 - Epoch: [254][  217/  217]    Overall Loss 0.232716    Objective Loss 0.232716    Top1 93.442623    Top5 100.000000    LR 0.000016    Time 0.480159    
2024-05-05 02:49:14,149 - --- validate (epoch=254)-----------
2024-05-05 02:49:14,149 - 1736 samples (32 per mini-batch)
2024-05-05 02:49:47,285 - Epoch: [254][   55/   55]    Loss 2.168231    Top1 53.801843    Top5 70.622120    
2024-05-05 02:49:47,472 - ==> Top1: 53.802    Top5: 70.622    Loss: 2.168

2024-05-05 02:49:47,478 - ==> Best [Top1: 54.263   Top5: 71.486   Sparsity:0.00   Params: 384080 on epoch: 253]
2024-05-05 02:49:47,478 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:49:47,532 - 

2024-05-05 02:49:47,532 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:50:46,593 - Epoch: [255][  100/  217]    Overall Loss 0.213927    Objective Loss 0.213927                                        LR 0.000016    Time 0.590551    
2024-05-05 02:51:39,042 - Epoch: [255][  200/  217]    Overall Loss 0.224661    Objective Loss 0.224661                                        LR 0.000016    Time 0.557494    
2024-05-05 02:51:45,125 - Epoch: [255][  217/  217]    Overall Loss 0.223626    Objective Loss 0.223626    Top1 96.721311    Top5 100.000000    LR 0.000016    Time 0.541848    
2024-05-05 02:51:45,292 - --- validate (epoch=255)-----------
2024-05-05 02:51:45,293 - 1736 samples (32 per mini-batch)
2024-05-05 02:52:16,208 - Epoch: [255][   55/   55]    Loss 2.176394    Top1 54.493088    Top5 70.910138    
2024-05-05 02:52:16,348 - ==> Top1: 54.493    Top5: 70.910    Loss: 2.176

2024-05-05 02:52:16,355 - ==> Best [Top1: 54.493   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 255]
2024-05-05 02:52:16,355 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:52:16,412 - 

2024-05-05 02:52:16,412 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:53:10,171 - Epoch: [256][  100/  217]    Overall Loss 0.217185    Objective Loss 0.217185                                        LR 0.000016    Time 0.537515    
2024-05-05 02:54:10,706 - Epoch: [256][  200/  217]    Overall Loss 0.220041    Objective Loss 0.220041                                        LR 0.000016    Time 0.571409    
2024-05-05 02:54:18,295 - Epoch: [256][  217/  217]    Overall Loss 0.221014    Objective Loss 0.221014    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.561613    
2024-05-05 02:54:18,526 - --- validate (epoch=256)-----------
2024-05-05 02:54:18,527 - 1736 samples (32 per mini-batch)
2024-05-05 02:54:48,578 - Epoch: [256][   55/   55]    Loss 2.210812    Top1 53.801843    Top5 71.198157    
2024-05-05 02:54:48,717 - ==> Top1: 53.802    Top5: 71.198    Loss: 2.211

2024-05-05 02:54:48,720 - ==> Best [Top1: 54.493   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 255]
2024-05-05 02:54:48,721 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:54:48,752 - 

2024-05-05 02:54:48,753 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:55:40,952 - Epoch: [257][  100/  217]    Overall Loss 0.217770    Objective Loss 0.217770                                        LR 0.000016    Time 0.521935    
2024-05-05 02:56:24,207 - Epoch: [257][  200/  217]    Overall Loss 0.222724    Objective Loss 0.222724                                        LR 0.000016    Time 0.477223    
2024-05-05 02:56:32,842 - Epoch: [257][  217/  217]    Overall Loss 0.221993    Objective Loss 0.221993    Top1 96.721311    Top5 100.000000    LR 0.000016    Time 0.479626    
2024-05-05 02:56:32,954 - --- validate (epoch=257)-----------
2024-05-05 02:56:32,954 - 1736 samples (32 per mini-batch)
2024-05-05 02:56:59,177 - Epoch: [257][   55/   55]    Loss 2.236199    Top1 55.299539    Top5 70.910138    
2024-05-05 02:56:59,266 - ==> Top1: 55.300    Top5: 70.910    Loss: 2.236

2024-05-05 02:56:59,270 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 02:56:59,270 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:56:59,312 - 

2024-05-05 02:56:59,312 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 02:57:54,628 - Epoch: [258][  100/  217]    Overall Loss 0.203380    Objective Loss 0.203380                                        LR 0.000016    Time 0.553094    
2024-05-05 02:58:41,518 - Epoch: [258][  200/  217]    Overall Loss 0.209946    Objective Loss 0.209946                                        LR 0.000016    Time 0.510976    
2024-05-05 02:58:51,893 - Epoch: [258][  217/  217]    Overall Loss 0.210470    Objective Loss 0.210470    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.518748    
2024-05-05 02:58:52,039 - --- validate (epoch=258)-----------
2024-05-05 02:58:52,040 - 1736 samples (32 per mini-batch)
2024-05-05 02:59:23,142 - Epoch: [258][   55/   55]    Loss 2.164040    Top1 54.377880    Top5 71.543779    
2024-05-05 02:59:23,329 - ==> Top1: 54.378    Top5: 71.544    Loss: 2.164

2024-05-05 02:59:23,333 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 02:59:23,333 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 02:59:23,365 - 

2024-05-05 02:59:23,366 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:00:10,928 - Epoch: [259][  100/  217]    Overall Loss 0.185674    Objective Loss 0.185674                                        LR 0.000016    Time 0.475561    
2024-05-05 03:00:53,362 - Epoch: [259][  200/  217]    Overall Loss 0.198917    Objective Loss 0.198917                                        LR 0.000016    Time 0.449934    
2024-05-05 03:00:59,458 - Epoch: [259][  217/  217]    Overall Loss 0.199996    Objective Loss 0.199996    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.442770    
2024-05-05 03:00:59,591 - --- validate (epoch=259)-----------
2024-05-05 03:00:59,591 - 1736 samples (32 per mini-batch)
2024-05-05 03:01:31,981 - Epoch: [259][   55/   55]    Loss 2.196553    Top1 54.665899    Top5 70.622120    
2024-05-05 03:01:32,113 - ==> Top1: 54.666    Top5: 70.622    Loss: 2.197

2024-05-05 03:01:32,118 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:01:32,119 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:01:32,167 - 

2024-05-05 03:01:32,167 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:02:25,921 - Epoch: [260][  100/  217]    Overall Loss 0.198765    Objective Loss 0.198765                                        LR 0.000016    Time 0.537477    
2024-05-05 03:03:13,564 - Epoch: [260][  200/  217]    Overall Loss 0.193886    Objective Loss 0.193886                                        LR 0.000016    Time 0.506930    
2024-05-05 03:03:24,625 - Epoch: [260][  217/  217]    Overall Loss 0.193953    Objective Loss 0.193953    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.518183    
2024-05-05 03:03:24,745 - --- validate (epoch=260)-----------
2024-05-05 03:03:24,745 - 1736 samples (32 per mini-batch)
2024-05-05 03:03:52,034 - Epoch: [260][   55/   55]    Loss 2.181692    Top1 54.953917    Top5 70.967742    
2024-05-05 03:03:52,143 - ==> Top1: 54.954    Top5: 70.968    Loss: 2.182

2024-05-05 03:03:52,148 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:03:52,148 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:03:52,193 - 

2024-05-05 03:03:52,194 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:04:46,855 - Epoch: [261][  100/  217]    Overall Loss 0.172439    Objective Loss 0.172439                                        LR 0.000016    Time 0.546545    
2024-05-05 03:05:35,863 - Epoch: [261][  200/  217]    Overall Loss 0.185495    Objective Loss 0.185495                                        LR 0.000016    Time 0.518292    
2024-05-05 03:05:44,324 - Epoch: [261][  217/  217]    Overall Loss 0.185300    Objective Loss 0.185300    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.516672    
2024-05-05 03:05:44,458 - --- validate (epoch=261)-----------
2024-05-05 03:05:44,459 - 1736 samples (32 per mini-batch)
2024-05-05 03:06:12,746 - Epoch: [261][   55/   55]    Loss 2.161493    Top1 55.069124    Top5 71.198157    
2024-05-05 03:06:12,868 - ==> Top1: 55.069    Top5: 71.198    Loss: 2.161

2024-05-05 03:06:12,873 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:06:12,874 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:06:12,920 - 

2024-05-05 03:06:12,921 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:07:13,199 - Epoch: [262][  100/  217]    Overall Loss 0.176003    Objective Loss 0.176003                                        LR 0.000016    Time 0.602727    
2024-05-05 03:08:09,212 - Epoch: [262][  200/  217]    Overall Loss 0.175157    Objective Loss 0.175157                                        LR 0.000016    Time 0.581404    
2024-05-05 03:08:17,131 - Epoch: [262][  217/  217]    Overall Loss 0.175735    Objective Loss 0.175735    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.572343    
2024-05-05 03:08:17,247 - --- validate (epoch=262)-----------
2024-05-05 03:08:17,247 - 1736 samples (32 per mini-batch)
2024-05-05 03:08:48,318 - Epoch: [262][   55/   55]    Loss 2.176088    Top1 54.723502    Top5 71.543779    
2024-05-05 03:08:48,455 - ==> Top1: 54.724    Top5: 71.544    Loss: 2.176

2024-05-05 03:08:48,461 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:08:48,461 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:08:48,506 - 

2024-05-05 03:08:48,507 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:09:43,141 - Epoch: [263][  100/  217]    Overall Loss 0.156021    Objective Loss 0.156021                                        LR 0.000016    Time 0.546278    
2024-05-05 03:10:34,577 - Epoch: [263][  200/  217]    Overall Loss 0.171961    Objective Loss 0.171961                                        LR 0.000016    Time 0.530295    
2024-05-05 03:10:44,715 - Epoch: [263][  217/  217]    Overall Loss 0.172188    Objective Loss 0.172188    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.535465    
2024-05-05 03:10:44,929 - --- validate (epoch=263)-----------
2024-05-05 03:10:44,929 - 1736 samples (32 per mini-batch)
2024-05-05 03:11:17,733 - Epoch: [263][   55/   55]    Loss 2.205809    Top1 54.320276    Top5 71.082949    
2024-05-05 03:11:17,913 - ==> Top1: 54.320    Top5: 71.083    Loss: 2.206

2024-05-05 03:11:17,919 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:11:17,919 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:11:17,965 - 

2024-05-05 03:11:17,966 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:12:16,158 - Epoch: [264][  100/  217]    Overall Loss 0.166687    Objective Loss 0.166687                                        LR 0.000016    Time 0.581862    
2024-05-05 03:13:04,825 - Epoch: [264][  200/  217]    Overall Loss 0.175091    Objective Loss 0.175091                                        LR 0.000016    Time 0.534241    
2024-05-05 03:13:14,888 - Epoch: [264][  217/  217]    Overall Loss 0.177008    Objective Loss 0.177008    Top1 96.721311    Top5 100.000000    LR 0.000016    Time 0.538753    
2024-05-05 03:13:15,059 - --- validate (epoch=264)-----------
2024-05-05 03:13:15,059 - 1736 samples (32 per mini-batch)
2024-05-05 03:13:45,886 - Epoch: [264][   55/   55]    Loss 2.211080    Top1 54.953917    Top5 70.737327    
2024-05-05 03:13:46,075 - ==> Top1: 54.954    Top5: 70.737    Loss: 2.211

2024-05-05 03:13:46,081 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:13:46,081 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:13:46,131 - 

2024-05-05 03:13:46,132 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:14:42,546 - Epoch: [265][  100/  217]    Overall Loss 0.160050    Objective Loss 0.160050                                        LR 0.000016    Time 0.564078    
2024-05-05 03:15:30,603 - Epoch: [265][  200/  217]    Overall Loss 0.165371    Objective Loss 0.165371                                        LR 0.000016    Time 0.522302    
2024-05-05 03:15:37,059 - Epoch: [265][  217/  217]    Overall Loss 0.167309    Objective Loss 0.167309    Top1 96.721311    Top5 100.000000    LR 0.000016    Time 0.511127    
2024-05-05 03:15:37,192 - --- validate (epoch=265)-----------
2024-05-05 03:15:37,192 - 1736 samples (32 per mini-batch)
2024-05-05 03:16:07,968 - Epoch: [265][   55/   55]    Loss 2.212557    Top1 54.608295    Top5 70.794931    
2024-05-05 03:16:08,218 - ==> Top1: 54.608    Top5: 70.795    Loss: 2.213

2024-05-05 03:16:08,222 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:16:08,222 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:16:08,252 - 

2024-05-05 03:16:08,252 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:17:03,553 - Epoch: [266][  100/  217]    Overall Loss 0.154687    Objective Loss 0.154687                                        LR 0.000016    Time 0.552953    
2024-05-05 03:17:53,240 - Epoch: [266][  200/  217]    Overall Loss 0.163706    Objective Loss 0.163706                                        LR 0.000016    Time 0.524889    
2024-05-05 03:17:59,147 - Epoch: [266][  217/  217]    Overall Loss 0.164733    Objective Loss 0.164733    Top1 96.721311    Top5 100.000000    LR 0.000016    Time 0.510983    
2024-05-05 03:17:59,262 - --- validate (epoch=266)-----------
2024-05-05 03:17:59,263 - 1736 samples (32 per mini-batch)
2024-05-05 03:18:29,963 - Epoch: [266][   55/   55]    Loss 2.230997    Top1 53.283410    Top5 70.794931    
2024-05-05 03:18:30,096 - ==> Top1: 53.283    Top5: 70.795    Loss: 2.231

2024-05-05 03:18:30,100 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:18:30,100 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:18:30,130 - 

2024-05-05 03:18:30,131 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:19:18,687 - Epoch: [267][  100/  217]    Overall Loss 0.150357    Objective Loss 0.150357                                        LR 0.000016    Time 0.485505    
2024-05-05 03:20:10,207 - Epoch: [267][  200/  217]    Overall Loss 0.153919    Objective Loss 0.153919                                        LR 0.000016    Time 0.500329    
2024-05-05 03:20:17,642 - Epoch: [267][  217/  217]    Overall Loss 0.153412    Objective Loss 0.153412    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.495389    
2024-05-05 03:20:17,823 - --- validate (epoch=267)-----------
2024-05-05 03:20:17,823 - 1736 samples (32 per mini-batch)
2024-05-05 03:20:47,440 - Epoch: [267][   55/   55]    Loss 2.191255    Top1 54.838710    Top5 71.255760    
2024-05-05 03:20:47,581 - ==> Top1: 54.839    Top5: 71.256    Loss: 2.191

2024-05-05 03:20:47,585 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:20:47,585 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:20:47,618 - 

2024-05-05 03:20:47,618 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:21:42,215 - Epoch: [268][  100/  217]    Overall Loss 0.143310    Objective Loss 0.143310                                        LR 0.000016    Time 0.545913    
2024-05-05 03:22:30,316 - Epoch: [268][  200/  217]    Overall Loss 0.152520    Objective Loss 0.152520                                        LR 0.000016    Time 0.513435    
2024-05-05 03:22:38,998 - Epoch: [268][  217/  217]    Overall Loss 0.153171    Objective Loss 0.153171    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.513215    
2024-05-05 03:22:39,128 - --- validate (epoch=268)-----------
2024-05-05 03:22:39,128 - 1736 samples (32 per mini-batch)
2024-05-05 03:23:07,897 - Epoch: [268][   55/   55]    Loss 2.189710    Top1 54.781106    Top5 71.198157    
2024-05-05 03:23:08,039 - ==> Top1: 54.781    Top5: 71.198    Loss: 2.190

2024-05-05 03:23:08,044 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:23:08,044 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:23:08,091 - 

2024-05-05 03:23:08,091 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:23:59,257 - Epoch: [269][  100/  217]    Overall Loss 0.138075    Objective Loss 0.138075                                        LR 0.000016    Time 0.511590    
2024-05-05 03:24:52,303 - Epoch: [269][  200/  217]    Overall Loss 0.151491    Objective Loss 0.151491                                        LR 0.000016    Time 0.521000    
2024-05-05 03:25:00,642 - Epoch: [269][  217/  217]    Overall Loss 0.153975    Objective Loss 0.153975    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.518611    
2024-05-05 03:25:00,828 - --- validate (epoch=269)-----------
2024-05-05 03:25:00,828 - 1736 samples (32 per mini-batch)
2024-05-05 03:25:35,381 - Epoch: [269][   55/   55]    Loss 2.190752    Top1 54.377880    Top5 71.082949    
2024-05-05 03:25:35,494 - ==> Top1: 54.378    Top5: 71.083    Loss: 2.191

2024-05-05 03:25:35,499 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:25:35,499 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:25:35,532 - 

2024-05-05 03:25:35,532 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:26:37,355 - Epoch: [270][  100/  217]    Overall Loss 0.139961    Objective Loss 0.139961                                        LR 0.000016    Time 0.618176    
2024-05-05 03:27:23,351 - Epoch: [270][  200/  217]    Overall Loss 0.153689    Objective Loss 0.153689                                        LR 0.000016    Time 0.539045    
2024-05-05 03:27:32,082 - Epoch: [270][  217/  217]    Overall Loss 0.154430    Objective Loss 0.154430    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.537042    
2024-05-05 03:27:32,311 - --- validate (epoch=270)-----------
2024-05-05 03:27:32,311 - 1736 samples (32 per mini-batch)
2024-05-05 03:28:01,650 - Epoch: [270][   55/   55]    Loss 2.208391    Top1 55.184332    Top5 72.407834    
2024-05-05 03:28:01,832 - ==> Top1: 55.184    Top5: 72.408    Loss: 2.208

2024-05-05 03:28:01,836 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:28:01,836 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:28:01,869 - 

2024-05-05 03:28:01,869 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:28:53,162 - Epoch: [271][  100/  217]    Overall Loss 0.129837    Objective Loss 0.129837                                        LR 0.000016    Time 0.512877    
2024-05-05 03:29:39,948 - Epoch: [271][  200/  217]    Overall Loss 0.138524    Objective Loss 0.138524                                        LR 0.000016    Time 0.490350    
2024-05-05 03:29:46,214 - Epoch: [271][  217/  217]    Overall Loss 0.141641    Objective Loss 0.141641    Top1 96.721311    Top5 100.000000    LR 0.000016    Time 0.480805    
2024-05-05 03:29:46,321 - --- validate (epoch=271)-----------
2024-05-05 03:29:46,322 - 1736 samples (32 per mini-batch)
2024-05-05 03:30:10,689 - Epoch: [271][   55/   55]    Loss 2.220675    Top1 54.377880    Top5 71.543779    
2024-05-05 03:30:10,798 - ==> Top1: 54.378    Top5: 71.544    Loss: 2.221

2024-05-05 03:30:10,804 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:30:10,804 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:30:10,849 - 

2024-05-05 03:30:10,850 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:31:00,470 - Epoch: [272][  100/  217]    Overall Loss 0.125864    Objective Loss 0.125864                                        LR 0.000016    Time 0.496139    
2024-05-05 03:31:43,589 - Epoch: [272][  200/  217]    Overall Loss 0.129581    Objective Loss 0.129581                                        LR 0.000016    Time 0.463647    
2024-05-05 03:31:51,950 - Epoch: [272][  217/  217]    Overall Loss 0.132291    Objective Loss 0.132291    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.465849    
2024-05-05 03:31:52,091 - --- validate (epoch=272)-----------
2024-05-05 03:31:52,091 - 1736 samples (32 per mini-batch)
2024-05-05 03:32:26,565 - Epoch: [272][   55/   55]    Loss 2.235206    Top1 53.571429    Top5 70.046083    
2024-05-05 03:32:26,678 - ==> Top1: 53.571    Top5: 70.046    Loss: 2.235

2024-05-05 03:32:26,682 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:32:26,682 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:32:26,713 - 

2024-05-05 03:32:26,713 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:33:20,694 - Epoch: [273][  100/  217]    Overall Loss 0.149017    Objective Loss 0.149017                                        LR 0.000016    Time 0.539756    
2024-05-05 03:34:11,425 - Epoch: [273][  200/  217]    Overall Loss 0.151975    Objective Loss 0.151975                                        LR 0.000016    Time 0.523511    
2024-05-05 03:34:20,323 - Epoch: [273][  217/  217]    Overall Loss 0.151866    Objective Loss 0.151866    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.523497    
2024-05-05 03:34:20,464 - --- validate (epoch=273)-----------
2024-05-05 03:34:20,464 - 1736 samples (32 per mini-batch)
2024-05-05 03:34:48,031 - Epoch: [273][   55/   55]    Loss 2.238776    Top1 53.456221    Top5 70.852535    
2024-05-05 03:34:48,135 - ==> Top1: 53.456    Top5: 70.853    Loss: 2.239

2024-05-05 03:34:48,140 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:34:48,141 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:34:48,187 - 

2024-05-05 03:34:48,187 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:35:37,546 - Epoch: [274][  100/  217]    Overall Loss 0.137917    Objective Loss 0.137917                                        LR 0.000016    Time 0.493531    
2024-05-05 03:36:28,454 - Epoch: [274][  200/  217]    Overall Loss 0.139102    Objective Loss 0.139102                                        LR 0.000016    Time 0.501276    
2024-05-05 03:36:37,238 - Epoch: [274][  217/  217]    Overall Loss 0.138595    Objective Loss 0.138595    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.502477    
2024-05-05 03:36:37,429 - --- validate (epoch=274)-----------
2024-05-05 03:36:37,430 - 1736 samples (32 per mini-batch)
2024-05-05 03:37:08,999 - Epoch: [274][   55/   55]    Loss 2.248496    Top1 54.781106    Top5 70.852535    
2024-05-05 03:37:09,185 - ==> Top1: 54.781    Top5: 70.853    Loss: 2.248

2024-05-05 03:37:09,191 - ==> Best [Top1: 55.300   Top5: 70.910   Sparsity:0.00   Params: 384080 on epoch: 257]
2024-05-05 03:37:09,191 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:37:09,237 - 

2024-05-05 03:37:09,237 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:37:59,734 - Epoch: [275][  100/  217]    Overall Loss 0.130591    Objective Loss 0.130591                                        LR 0.000016    Time 0.504907    
2024-05-05 03:38:52,600 - Epoch: [275][  200/  217]    Overall Loss 0.138042    Objective Loss 0.138042                                        LR 0.000016    Time 0.516755    
2024-05-05 03:39:01,854 - Epoch: [275][  217/  217]    Overall Loss 0.137828    Objective Loss 0.137828    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.518909    
2024-05-05 03:39:02,043 - --- validate (epoch=275)-----------
2024-05-05 03:39:02,043 - 1736 samples (32 per mini-batch)
2024-05-05 03:39:31,145 - Epoch: [275][   55/   55]    Loss 2.197908    Top1 55.357143    Top5 71.313364    
2024-05-05 03:39:31,274 - ==> Top1: 55.357    Top5: 71.313    Loss: 2.198

2024-05-05 03:39:31,281 - ==> Best [Top1: 55.357   Top5: 71.313   Sparsity:0.00   Params: 384080 on epoch: 275]
2024-05-05 03:39:31,281 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:39:31,341 - 

2024-05-05 03:39:31,342 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:40:19,238 - Epoch: [276][  100/  217]    Overall Loss 0.116491    Objective Loss 0.116491                                        LR 0.000016    Time 0.478896    
2024-05-05 03:41:11,506 - Epoch: [276][  200/  217]    Overall Loss 0.126511    Objective Loss 0.126511                                        LR 0.000016    Time 0.500767    
2024-05-05 03:41:18,731 - Epoch: [276][  217/  217]    Overall Loss 0.128848    Objective Loss 0.128848    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.494824    
2024-05-05 03:41:18,876 - --- validate (epoch=276)-----------
2024-05-05 03:41:18,877 - 1736 samples (32 per mini-batch)
2024-05-05 03:41:50,754 - Epoch: [276][   55/   55]    Loss 2.285989    Top1 53.744240    Top5 70.679724    
2024-05-05 03:41:50,884 - ==> Top1: 53.744    Top5: 70.680    Loss: 2.286

2024-05-05 03:41:50,890 - ==> Best [Top1: 55.357   Top5: 71.313   Sparsity:0.00   Params: 384080 on epoch: 275]
2024-05-05 03:41:50,890 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:41:50,937 - 

2024-05-05 03:41:50,938 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:42:45,528 - Epoch: [277][  100/  217]    Overall Loss 0.120733    Objective Loss 0.120733                                        LR 0.000016    Time 0.545836    
2024-05-05 03:43:34,013 - Epoch: [277][  200/  217]    Overall Loss 0.130572    Objective Loss 0.130572                                        LR 0.000016    Time 0.515324    
2024-05-05 03:43:41,332 - Epoch: [277][  217/  217]    Overall Loss 0.130330    Objective Loss 0.130330    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.508672    
2024-05-05 03:43:41,515 - --- validate (epoch=277)-----------
2024-05-05 03:43:41,515 - 1736 samples (32 per mini-batch)
2024-05-05 03:44:13,496 - Epoch: [277][   55/   55]    Loss 2.168069    Top1 54.435484    Top5 71.543779    
2024-05-05 03:44:13,600 - ==> Top1: 54.435    Top5: 71.544    Loss: 2.168

2024-05-05 03:44:13,606 - ==> Best [Top1: 55.357   Top5: 71.313   Sparsity:0.00   Params: 384080 on epoch: 275]
2024-05-05 03:44:13,606 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:44:13,652 - 

2024-05-05 03:44:13,652 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:45:06,093 - Epoch: [278][  100/  217]    Overall Loss 0.113307    Objective Loss 0.113307                                        LR 0.000016    Time 0.524342    
2024-05-05 03:46:02,778 - Epoch: [278][  200/  217]    Overall Loss 0.126637    Objective Loss 0.126637                                        LR 0.000016    Time 0.545573    
2024-05-05 03:46:13,603 - Epoch: [278][  217/  217]    Overall Loss 0.127324    Objective Loss 0.127324    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.552713    
2024-05-05 03:46:13,740 - --- validate (epoch=278)-----------
2024-05-05 03:46:13,741 - 1736 samples (32 per mini-batch)
2024-05-05 03:46:43,023 - Epoch: [278][   55/   55]    Loss 2.183952    Top1 54.435484    Top5 72.177419    
2024-05-05 03:46:43,152 - ==> Top1: 54.435    Top5: 72.177    Loss: 2.184

2024-05-05 03:46:43,158 - ==> Best [Top1: 55.357   Top5: 71.313   Sparsity:0.00   Params: 384080 on epoch: 275]
2024-05-05 03:46:43,159 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:46:43,210 - 

2024-05-05 03:46:43,210 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:47:37,051 - Epoch: [279][  100/  217]    Overall Loss 0.125814    Objective Loss 0.125814                                        LR 0.000016    Time 0.538341    
2024-05-05 03:48:21,783 - Epoch: [279][  200/  217]    Overall Loss 0.130484    Objective Loss 0.130484                                        LR 0.000016    Time 0.492810    
2024-05-05 03:48:32,350 - Epoch: [279][  217/  217]    Overall Loss 0.130303    Objective Loss 0.130303    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.502894    
2024-05-05 03:48:32,482 - --- validate (epoch=279)-----------
2024-05-05 03:48:32,482 - 1736 samples (32 per mini-batch)
2024-05-05 03:49:03,344 - Epoch: [279][   55/   55]    Loss 2.257097    Top1 53.744240    Top5 70.334101    
2024-05-05 03:49:03,531 - ==> Top1: 53.744    Top5: 70.334    Loss: 2.257

2024-05-05 03:49:03,537 - ==> Best [Top1: 55.357   Top5: 71.313   Sparsity:0.00   Params: 384080 on epoch: 275]
2024-05-05 03:49:03,537 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:49:03,584 - 

2024-05-05 03:49:03,584 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:49:59,226 - Epoch: [280][  100/  217]    Overall Loss 0.117217    Objective Loss 0.117217                                        LR 0.000016    Time 0.556354    
2024-05-05 03:50:47,966 - Epoch: [280][  200/  217]    Overall Loss 0.120986    Objective Loss 0.120986                                        LR 0.000016    Time 0.521848    
2024-05-05 03:50:55,081 - Epoch: [280][  217/  217]    Overall Loss 0.121891    Objective Loss 0.121891    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.513752    
2024-05-05 03:50:55,235 - --- validate (epoch=280)-----------
2024-05-05 03:50:55,236 - 1736 samples (32 per mini-batch)
2024-05-05 03:51:26,074 - Epoch: [280][   55/   55]    Loss 2.154426    Top1 55.817972    Top5 71.774194    
2024-05-05 03:51:26,224 - ==> Top1: 55.818    Top5: 71.774    Loss: 2.154

2024-05-05 03:51:26,232 - ==> Best [Top1: 55.818   Top5: 71.774   Sparsity:0.00   Params: 384080 on epoch: 280]
2024-05-05 03:51:26,232 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:51:26,275 - 

2024-05-05 03:51:26,275 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:52:18,533 - Epoch: [281][  100/  217]    Overall Loss 0.109952    Objective Loss 0.109952                                        LR 0.000016    Time 0.522518    
2024-05-05 03:53:08,166 - Epoch: [281][  200/  217]    Overall Loss 0.115232    Objective Loss 0.115232                                        LR 0.000016    Time 0.509395    
2024-05-05 03:53:18,820 - Epoch: [281][  217/  217]    Overall Loss 0.116307    Objective Loss 0.116307    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.518578    
2024-05-05 03:53:18,990 - --- validate (epoch=281)-----------
2024-05-05 03:53:18,990 - 1736 samples (32 per mini-batch)
2024-05-05 03:53:50,821 - Epoch: [281][   55/   55]    Loss 2.275734    Top1 54.032258    Top5 71.486175    
2024-05-05 03:53:51,012 - ==> Top1: 54.032    Top5: 71.486    Loss: 2.276

2024-05-05 03:53:51,017 - ==> Best [Top1: 55.818   Top5: 71.774   Sparsity:0.00   Params: 384080 on epoch: 280]
2024-05-05 03:53:51,017 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:53:51,052 - 

2024-05-05 03:53:51,052 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:54:44,996 - Epoch: [282][  100/  217]    Overall Loss 0.138163    Objective Loss 0.138163                                        LR 0.000016    Time 0.539385    
2024-05-05 03:55:35,904 - Epoch: [282][  200/  217]    Overall Loss 0.125839    Objective Loss 0.125839                                        LR 0.000016    Time 0.524211    
2024-05-05 03:55:44,854 - Epoch: [282][  217/  217]    Overall Loss 0.125390    Objective Loss 0.125390    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.524382    
2024-05-05 03:55:44,984 - --- validate (epoch=282)-----------
2024-05-05 03:55:44,984 - 1736 samples (32 per mini-batch)
2024-05-05 03:56:15,466 - Epoch: [282][   55/   55]    Loss 2.200958    Top1 55.126728    Top5 70.794931    
2024-05-05 03:56:15,667 - ==> Top1: 55.127    Top5: 70.795    Loss: 2.201

2024-05-05 03:56:15,673 - ==> Best [Top1: 55.818   Top5: 71.774   Sparsity:0.00   Params: 384080 on epoch: 280]
2024-05-05 03:56:15,673 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:56:15,726 - 

2024-05-05 03:56:15,727 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:57:09,986 - Epoch: [283][  100/  217]    Overall Loss 0.122050    Objective Loss 0.122050                                        LR 0.000016    Time 0.542527    
2024-05-05 03:57:58,800 - Epoch: [283][  200/  217]    Overall Loss 0.134298    Objective Loss 0.134298                                        LR 0.000016    Time 0.515292    
2024-05-05 03:58:06,367 - Epoch: [283][  217/  217]    Overall Loss 0.135844    Objective Loss 0.135844    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.509785    
2024-05-05 03:58:06,494 - --- validate (epoch=283)-----------
2024-05-05 03:58:06,495 - 1736 samples (32 per mini-batch)
2024-05-05 03:58:36,312 - Epoch: [283][   55/   55]    Loss 2.153981    Top1 55.241935    Top5 71.601382    
2024-05-05 03:58:36,495 - ==> Top1: 55.242    Top5: 71.601    Loss: 2.154

2024-05-05 03:58:36,499 - ==> Best [Top1: 55.818   Top5: 71.774   Sparsity:0.00   Params: 384080 on epoch: 280]
2024-05-05 03:58:36,499 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 03:58:36,534 - 

2024-05-05 03:58:36,534 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 03:59:29,595 - Epoch: [284][  100/  217]    Overall Loss 0.125350    Objective Loss 0.125350                                        LR 0.000016    Time 0.530553    
2024-05-05 04:00:15,509 - Epoch: [284][  200/  217]    Overall Loss 0.120844    Objective Loss 0.120844                                        LR 0.000016    Time 0.494824    
2024-05-05 04:00:27,575 - Epoch: [284][  217/  217]    Overall Loss 0.120304    Objective Loss 0.120304    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.511656    
2024-05-05 04:00:27,772 - --- validate (epoch=284)-----------
2024-05-05 04:00:27,773 - 1736 samples (32 per mini-batch)
2024-05-05 04:00:59,924 - Epoch: [284][   55/   55]    Loss 2.230266    Top1 55.357143    Top5 70.967742    
2024-05-05 04:01:00,119 - ==> Top1: 55.357    Top5: 70.968    Loss: 2.230

2024-05-05 04:01:00,124 - ==> Best [Top1: 55.818   Top5: 71.774   Sparsity:0.00   Params: 384080 on epoch: 280]
2024-05-05 04:01:00,124 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:01:00,174 - 

2024-05-05 04:01:00,175 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:01:56,744 - Epoch: [285][  100/  217]    Overall Loss 0.134436    Objective Loss 0.134436                                        LR 0.000016    Time 0.565626    
2024-05-05 04:02:40,667 - Epoch: [285][  200/  217]    Overall Loss 0.132630    Objective Loss 0.132630                                        LR 0.000016    Time 0.502400    
2024-05-05 04:02:45,919 - Epoch: [285][  217/  217]    Overall Loss 0.131486    Objective Loss 0.131486    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.487242    
2024-05-05 04:02:46,077 - --- validate (epoch=285)-----------
2024-05-05 04:02:46,078 - 1736 samples (32 per mini-batch)
2024-05-05 04:03:17,729 - Epoch: [285][   55/   55]    Loss 2.149709    Top1 55.529954    Top5 72.292627    
2024-05-05 04:03:17,841 - ==> Top1: 55.530    Top5: 72.293    Loss: 2.150

2024-05-05 04:03:17,847 - ==> Best [Top1: 55.818   Top5: 71.774   Sparsity:0.00   Params: 384080 on epoch: 280]
2024-05-05 04:03:17,847 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:03:17,894 - 

2024-05-05 04:03:17,895 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:04:12,953 - Epoch: [286][  100/  217]    Overall Loss 0.100557    Objective Loss 0.100557                                        LR 0.000016    Time 0.550523    
2024-05-05 04:05:04,403 - Epoch: [286][  200/  217]    Overall Loss 0.112414    Objective Loss 0.112414                                        LR 0.000016    Time 0.532490    
2024-05-05 04:05:12,481 - Epoch: [286][  217/  217]    Overall Loss 0.114171    Objective Loss 0.114171    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.527991    
2024-05-05 04:05:12,616 - --- validate (epoch=286)-----------
2024-05-05 04:05:12,616 - 1736 samples (32 per mini-batch)
2024-05-05 04:05:45,093 - Epoch: [286][   55/   55]    Loss 2.175328    Top1 54.896313    Top5 70.910138    
2024-05-05 04:05:45,285 - ==> Top1: 54.896    Top5: 70.910    Loss: 2.175

2024-05-05 04:05:45,291 - ==> Best [Top1: 55.818   Top5: 71.774   Sparsity:0.00   Params: 384080 on epoch: 280]
2024-05-05 04:05:45,291 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:05:45,337 - 

2024-05-05 04:05:45,338 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:06:40,201 - Epoch: [287][  100/  217]    Overall Loss 0.112772    Objective Loss 0.112772                                        LR 0.000016    Time 0.548569    
2024-05-05 04:07:29,354 - Epoch: [287][  200/  217]    Overall Loss 0.118641    Objective Loss 0.118641                                        LR 0.000016    Time 0.520029    
2024-05-05 04:07:35,967 - Epoch: [287][  217/  217]    Overall Loss 0.119841    Objective Loss 0.119841    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.509759    
2024-05-05 04:07:36,086 - --- validate (epoch=287)-----------
2024-05-05 04:07:36,086 - 1736 samples (32 per mini-batch)
2024-05-05 04:08:06,372 - Epoch: [287][   55/   55]    Loss 2.182781    Top1 56.394009    Top5 71.025346    
2024-05-05 04:08:06,599 - ==> Top1: 56.394    Top5: 71.025    Loss: 2.183

2024-05-05 04:08:06,605 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:08:06,605 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:08:06,755 - 

2024-05-05 04:08:06,756 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:09:05,925 - Epoch: [288][  100/  217]    Overall Loss 0.111383    Objective Loss 0.111383                                        LR 0.000016    Time 0.591626    
2024-05-05 04:09:54,685 - Epoch: [288][  200/  217]    Overall Loss 0.116491    Objective Loss 0.116491                                        LR 0.000016    Time 0.539593    
2024-05-05 04:10:00,052 - Epoch: [288][  217/  217]    Overall Loss 0.115361    Objective Loss 0.115361    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.522045    
2024-05-05 04:10:00,218 - --- validate (epoch=288)-----------
2024-05-05 04:10:00,218 - 1736 samples (32 per mini-batch)
2024-05-05 04:10:30,216 - Epoch: [288][   55/   55]    Loss 2.209420    Top1 55.587558    Top5 72.004608    
2024-05-05 04:10:30,372 - ==> Top1: 55.588    Top5: 72.005    Loss: 2.209

2024-05-05 04:10:30,378 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:10:30,378 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:10:30,428 - 

2024-05-05 04:10:30,429 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:11:24,315 - Epoch: [289][  100/  217]    Overall Loss 0.098729    Objective Loss 0.098729                                        LR 0.000016    Time 0.538804    
2024-05-05 04:12:16,176 - Epoch: [289][  200/  217]    Overall Loss 0.108301    Objective Loss 0.108301                                        LR 0.000016    Time 0.528683    
2024-05-05 04:12:22,424 - Epoch: [289][  217/  217]    Overall Loss 0.110496    Objective Loss 0.110496    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.516053    
2024-05-05 04:12:22,591 - --- validate (epoch=289)-----------
2024-05-05 04:12:22,592 - 1736 samples (32 per mini-batch)
2024-05-05 04:12:53,973 - Epoch: [289][   55/   55]    Loss 2.212625    Top1 55.069124    Top5 71.313364    
2024-05-05 04:12:54,152 - ==> Top1: 55.069    Top5: 71.313    Loss: 2.213

2024-05-05 04:12:54,157 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:12:54,158 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:12:54,204 - 

2024-05-05 04:12:54,204 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:13:50,507 - Epoch: [290][  100/  217]    Overall Loss 0.106572    Objective Loss 0.106572                                        LR 0.000016    Time 0.562964    
2024-05-05 04:14:38,677 - Epoch: [290][  200/  217]    Overall Loss 0.112500    Objective Loss 0.112500                                        LR 0.000016    Time 0.522308    
2024-05-05 04:14:44,106 - Epoch: [290][  217/  217]    Overall Loss 0.114554    Objective Loss 0.114554    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.506405    
2024-05-05 04:14:44,335 - --- validate (epoch=290)-----------
2024-05-05 04:14:44,336 - 1736 samples (32 per mini-batch)
2024-05-05 04:15:13,599 - Epoch: [290][   55/   55]    Loss 2.196385    Top1 55.645161    Top5 71.198157    
2024-05-05 04:15:13,713 - ==> Top1: 55.645    Top5: 71.198    Loss: 2.196

2024-05-05 04:15:13,717 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:15:13,717 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:15:13,747 - 

2024-05-05 04:15:13,747 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:16:09,031 - Epoch: [291][  100/  217]    Overall Loss 0.117901    Objective Loss 0.117901                                        LR 0.000016    Time 0.552789    
2024-05-05 04:16:59,942 - Epoch: [291][  200/  217]    Overall Loss 0.118877    Objective Loss 0.118877                                        LR 0.000016    Time 0.530929    
2024-05-05 04:17:06,483 - Epoch: [291][  217/  217]    Overall Loss 0.116636    Objective Loss 0.116636    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.519475    
2024-05-05 04:17:06,614 - --- validate (epoch=291)-----------
2024-05-05 04:17:06,614 - 1736 samples (32 per mini-batch)
2024-05-05 04:17:36,866 - Epoch: [291][   55/   55]    Loss 2.171385    Top1 55.529954    Top5 71.658986    
2024-05-05 04:17:36,981 - ==> Top1: 55.530    Top5: 71.659    Loss: 2.171

2024-05-05 04:17:36,987 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:17:36,987 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:17:37,032 - 

2024-05-05 04:17:37,032 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:18:29,511 - Epoch: [292][  100/  217]    Overall Loss 0.098926    Objective Loss 0.098926                                        LR 0.000016    Time 0.524730    
2024-05-05 04:19:16,347 - Epoch: [292][  200/  217]    Overall Loss 0.106881    Objective Loss 0.106881                                        LR 0.000016    Time 0.496523    
2024-05-05 04:19:23,885 - Epoch: [292][  217/  217]    Overall Loss 0.108455    Objective Loss 0.108455    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.492356    
2024-05-05 04:19:24,005 - --- validate (epoch=292)-----------
2024-05-05 04:19:24,006 - 1736 samples (32 per mini-batch)
2024-05-05 04:19:52,972 - Epoch: [292][   55/   55]    Loss 2.233458    Top1 54.320276    Top5 70.276498    
2024-05-05 04:19:53,084 - ==> Top1: 54.320    Top5: 70.276    Loss: 2.233

2024-05-05 04:19:53,090 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:19:53,090 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:19:53,136 - 

2024-05-05 04:19:53,136 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:20:47,725 - Epoch: [293][  100/  217]    Overall Loss 0.106188    Objective Loss 0.106188                                        LR 0.000016    Time 0.545827    
2024-05-05 04:21:38,679 - Epoch: [293][  200/  217]    Overall Loss 0.111876    Objective Loss 0.111876                                        LR 0.000016    Time 0.527661    
2024-05-05 04:21:46,911 - Epoch: [293][  217/  217]    Overall Loss 0.112283    Objective Loss 0.112283    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.524255    
2024-05-05 04:21:47,071 - --- validate (epoch=293)-----------
2024-05-05 04:21:47,071 - 1736 samples (32 per mini-batch)
2024-05-05 04:22:14,794 - Epoch: [293][   55/   55]    Loss 2.219894    Top1 55.645161    Top5 71.889401    
2024-05-05 04:22:14,910 - ==> Top1: 55.645    Top5: 71.889    Loss: 2.220

2024-05-05 04:22:14,914 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:22:14,914 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:22:14,946 - 

2024-05-05 04:22:14,946 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:23:08,062 - Epoch: [294][  100/  217]    Overall Loss 0.102010    Objective Loss 0.102010                                        LR 0.000016    Time 0.531105    
2024-05-05 04:23:55,050 - Epoch: [294][  200/  217]    Overall Loss 0.107717    Objective Loss 0.107717                                        LR 0.000016    Time 0.500470    
2024-05-05 04:24:03,182 - Epoch: [294][  217/  217]    Overall Loss 0.112618    Objective Loss 0.112618    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.498734    
2024-05-05 04:24:03,307 - --- validate (epoch=294)-----------
2024-05-05 04:24:03,308 - 1736 samples (32 per mini-batch)
2024-05-05 04:24:32,940 - Epoch: [294][   55/   55]    Loss 2.256501    Top1 54.608295    Top5 70.103687    
2024-05-05 04:24:33,105 - ==> Top1: 54.608    Top5: 70.104    Loss: 2.257

2024-05-05 04:24:33,109 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:24:33,109 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:24:33,144 - 

2024-05-05 04:24:33,144 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:25:22,477 - Epoch: [295][  100/  217]    Overall Loss 0.112927    Objective Loss 0.112927                                        LR 0.000016    Time 0.493280    
2024-05-05 04:26:15,544 - Epoch: [295][  200/  217]    Overall Loss 0.103899    Objective Loss 0.103899                                        LR 0.000016    Time 0.511954    
2024-05-05 04:26:22,465 - Epoch: [295][  217/  217]    Overall Loss 0.104268    Objective Loss 0.104268    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.503736    
2024-05-05 04:26:22,637 - --- validate (epoch=295)-----------
2024-05-05 04:26:22,638 - 1736 samples (32 per mini-batch)
2024-05-05 04:26:53,067 - Epoch: [295][   55/   55]    Loss 2.178286    Top1 55.875576    Top5 71.601382    
2024-05-05 04:26:53,204 - ==> Top1: 55.876    Top5: 71.601    Loss: 2.178

2024-05-05 04:26:53,208 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:26:53,208 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:26:53,255 - 

2024-05-05 04:26:53,256 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:27:46,393 - Epoch: [296][  100/  217]    Overall Loss 0.096044    Objective Loss 0.096044                                        LR 0.000016    Time 0.531316    
2024-05-05 04:28:39,911 - Epoch: [296][  200/  217]    Overall Loss 0.105182    Objective Loss 0.105182                                        LR 0.000016    Time 0.533222    
2024-05-05 04:28:47,451 - Epoch: [296][  217/  217]    Overall Loss 0.106619    Objective Loss 0.106619    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.526190    
2024-05-05 04:28:47,647 - --- validate (epoch=296)-----------
2024-05-05 04:28:47,648 - 1736 samples (32 per mini-batch)
2024-05-05 04:29:19,488 - Epoch: [296][   55/   55]    Loss 2.180862    Top1 55.760369    Top5 72.177419    
2024-05-05 04:29:19,658 - ==> Top1: 55.760    Top5: 72.177    Loss: 2.181

2024-05-05 04:29:19,664 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:29:19,665 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:29:19,715 - 

2024-05-05 04:29:19,716 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:30:15,381 - Epoch: [297][  100/  217]    Overall Loss 0.102272    Objective Loss 0.102272                                        LR 0.000016    Time 0.556592    
2024-05-05 04:31:02,349 - Epoch: [297][  200/  217]    Overall Loss 0.120803    Objective Loss 0.120803                                        LR 0.000016    Time 0.513116    
2024-05-05 04:31:07,644 - Epoch: [297][  217/  217]    Overall Loss 0.121364    Objective Loss 0.121364    Top1 98.360656    Top5 100.000000    LR 0.000016    Time 0.497316    
2024-05-05 04:31:07,815 - --- validate (epoch=297)-----------
2024-05-05 04:31:07,815 - 1736 samples (32 per mini-batch)
2024-05-05 04:31:37,823 - Epoch: [297][   55/   55]    Loss 2.200188    Top1 55.126728    Top5 71.198157    
2024-05-05 04:31:37,932 - ==> Top1: 55.127    Top5: 71.198    Loss: 2.200

2024-05-05 04:31:37,936 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:31:37,936 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:31:37,967 - 

2024-05-05 04:31:37,967 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:32:33,440 - Epoch: [298][  100/  217]    Overall Loss 0.098298    Objective Loss 0.098298                                        LR 0.000016    Time 0.554674    
2024-05-05 04:33:24,788 - Epoch: [298][  200/  217]    Overall Loss 0.104120    Objective Loss 0.104120                                        LR 0.000016    Time 0.534048    
2024-05-05 04:33:31,344 - Epoch: [298][  217/  217]    Overall Loss 0.103692    Objective Loss 0.103692    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.522416    
2024-05-05 04:33:31,490 - --- validate (epoch=298)-----------
2024-05-05 04:33:31,490 - 1736 samples (32 per mini-batch)
2024-05-05 04:34:01,270 - Epoch: [298][   55/   55]    Loss 2.197072    Top1 55.472350    Top5 71.716590    
2024-05-05 04:34:01,397 - ==> Top1: 55.472    Top5: 71.717    Loss: 2.197

2024-05-05 04:34:01,402 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:34:01,402 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:34:01,432 - 

2024-05-05 04:34:01,433 - Training epoch: 6941 samples (32 per mini-batch)
2024-05-05 04:34:50,161 - Epoch: [299][  100/  217]    Overall Loss 0.103684    Objective Loss 0.103684                                        LR 0.000016    Time 0.487227    
2024-05-05 04:35:42,380 - Epoch: [299][  200/  217]    Overall Loss 0.105983    Objective Loss 0.105983                                        LR 0.000016    Time 0.504680    
2024-05-05 04:35:52,584 - Epoch: [299][  217/  217]    Overall Loss 0.105828    Objective Loss 0.105828    Top1 100.000000    Top5 100.000000    LR 0.000016    Time 0.512163    
2024-05-05 04:35:52,719 - --- validate (epoch=299)-----------
2024-05-05 04:35:52,719 - 1736 samples (32 per mini-batch)
2024-05-05 04:36:23,427 - Epoch: [299][   55/   55]    Loss 2.174403    Top1 56.048387    Top5 72.004608    
2024-05-05 04:36:23,565 - ==> Top1: 56.048    Top5: 72.005    Loss: 2.174

2024-05-05 04:36:23,571 - ==> Best [Top1: 56.394   Top5: 71.025   Sparsity:0.00   Params: 384080 on epoch: 287]
2024-05-05 04:36:23,571 - Saving checkpoint to: logs/2024.05.04-165410/qat_checkpoint.pth.tar
2024-05-05 04:36:23,616 - --- test ---------------------
2024-05-05 04:36:23,616 - 1736 samples (32 per mini-batch)
2024-05-05 04:36:54,391 - Test: [   55/   55]    Loss 2.174190    Top1 56.048387    Top5 72.004608    
2024-05-05 04:36:54,543 - ==> Top1: 56.048    Top5: 72.005    Loss: 2.174

2024-05-05 04:36:54,549 - 
2024-05-05 04:36:54,549 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.05.04-165410/2024.05.04-165410.log
