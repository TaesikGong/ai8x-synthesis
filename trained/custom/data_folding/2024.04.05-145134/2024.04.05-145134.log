2024-04-05 14:51:35,002 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.05-145134/2024.04.05-145134.log
2024-04-05 14:51:38,386 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-04-05 14:51:38,387 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-04-05 14:51:40,019 - Dataset sizes:
	training=50000
	validation=10000
	test=10000
2024-04-05 14:51:40,019 - Reading compression schedule from: policies/schedule-cifar-nas.yaml
2024-04-05 14:51:40,025 - 

2024-04-05 14:51:40,026 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:51:44,683 - Epoch: [0][  100/  500]    Overall Loss 4.282317    Objective Loss 4.282317                                        LR 0.001000    Time 0.046527    
2024-04-05 14:51:48,473 - Epoch: [0][  200/  500]    Overall Loss 4.070736    Objective Loss 4.070736                                        LR 0.001000    Time 0.042194    
2024-04-05 14:51:52,514 - Epoch: [0][  300/  500]    Overall Loss 3.940074    Objective Loss 3.940074                                        LR 0.001000    Time 0.041582    
2024-04-05 14:51:56,651 - Epoch: [0][  400/  500]    Overall Loss 3.829627    Objective Loss 3.829627                                        LR 0.001000    Time 0.041516    
2024-04-05 14:52:00,772 - Epoch: [0][  500/  500]    Overall Loss 3.732750    Objective Loss 3.732750    Top1 26.000000    Top5 54.000000    LR 0.001000    Time 0.041445    
2024-04-05 14:52:00,982 - --- validate (epoch=0)-----------
2024-04-05 14:52:00,983 - 10000 samples (100 per mini-batch)
2024-04-05 14:52:02,449 - Epoch: [0][  100/  100]    Loss 3.307890    Top1 18.120000    Top5 47.690000    
2024-04-05 14:52:02,614 - ==> Top1: 18.120    Top5: 47.690    Loss: 3.308

2024-04-05 14:52:02,620 - ==> Best [Top1: 18.120   Top5: 47.690   Sparsity:0.00   Params: 347840 on epoch: 0]
2024-04-05 14:52:02,620 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:52:02,653 - 

2024-04-05 14:52:02,653 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:52:07,617 - Epoch: [1][  100/  500]    Overall Loss 3.165591    Objective Loss 3.165591                                        LR 0.001000    Time 0.049585    
2024-04-05 14:52:11,809 - Epoch: [1][  200/  500]    Overall Loss 3.104851    Objective Loss 3.104851                                        LR 0.001000    Time 0.045719    
2024-04-05 14:52:15,960 - Epoch: [1][  300/  500]    Overall Loss 3.046830    Objective Loss 3.046830                                        LR 0.001000    Time 0.044300    
2024-04-05 14:52:20,160 - Epoch: [1][  400/  500]    Overall Loss 2.996514    Objective Loss 2.996514                                        LR 0.001000    Time 0.043712    
2024-04-05 14:52:24,177 - Epoch: [1][  500/  500]    Overall Loss 2.952022    Objective Loss 2.952022    Top1 29.000000    Top5 61.500000    LR 0.001000    Time 0.042994    
2024-04-05 14:52:24,358 - --- validate (epoch=1)-----------
2024-04-05 14:52:24,359 - 10000 samples (100 per mini-batch)
2024-04-05 14:52:25,854 - Epoch: [1][  100/  100]    Loss 2.749054    Top1 28.180000    Top5 61.510000    
2024-04-05 14:52:26,009 - ==> Top1: 28.180    Top5: 61.510    Loss: 2.749

2024-04-05 14:52:26,012 - ==> Best [Top1: 28.180   Top5: 61.510   Sparsity:0.00   Params: 347840 on epoch: 1]
2024-04-05 14:52:26,012 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:52:26,040 - 

2024-04-05 14:52:26,041 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:52:30,698 - Epoch: [2][  100/  500]    Overall Loss 2.638223    Objective Loss 2.638223                                        LR 0.001000    Time 0.046514    
2024-04-05 14:52:34,848 - Epoch: [2][  200/  500]    Overall Loss 2.614665    Objective Loss 2.614665                                        LR 0.001000    Time 0.043983    
2024-04-05 14:52:39,030 - Epoch: [2][  300/  500]    Overall Loss 2.591141    Objective Loss 2.591141                                        LR 0.001000    Time 0.043245    
2024-04-05 14:52:43,298 - Epoch: [2][  400/  500]    Overall Loss 2.565284    Objective Loss 2.565284                                        LR 0.001000    Time 0.043088    
2024-04-05 14:52:47,139 - Epoch: [2][  500/  500]    Overall Loss 2.542338    Objective Loss 2.542338    Top1 32.000000    Top5 68.500000    LR 0.001000    Time 0.042142    
2024-04-05 14:52:47,362 - --- validate (epoch=2)-----------
2024-04-05 14:52:47,363 - 10000 samples (100 per mini-batch)
2024-04-05 14:52:48,837 - Epoch: [2][  100/  100]    Loss 2.394170    Top1 36.520000    Top5 69.860000    
2024-04-05 14:52:49,034 - ==> Top1: 36.520    Top5: 69.860    Loss: 2.394

2024-04-05 14:52:49,042 - ==> Best [Top1: 36.520   Top5: 69.860   Sparsity:0.00   Params: 347840 on epoch: 2]
2024-04-05 14:52:49,042 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:52:49,080 - 

2024-04-05 14:52:49,081 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:52:53,957 - Epoch: [3][  100/  500]    Overall Loss 2.341623    Objective Loss 2.341623                                        LR 0.001000    Time 0.048709    
2024-04-05 14:52:58,150 - Epoch: [3][  200/  500]    Overall Loss 2.331637    Objective Loss 2.331637                                        LR 0.001000    Time 0.045292    
2024-04-05 14:53:02,394 - Epoch: [3][  300/  500]    Overall Loss 2.314202    Objective Loss 2.314202                                        LR 0.001000    Time 0.044324    
2024-04-05 14:53:06,614 - Epoch: [3][  400/  500]    Overall Loss 2.302163    Objective Loss 2.302163                                        LR 0.001000    Time 0.043779    
2024-04-05 14:53:10,286 - Epoch: [3][  500/  500]    Overall Loss 2.282836    Objective Loss 2.282836    Top1 41.000000    Top5 75.000000    LR 0.001000    Time 0.042358    
2024-04-05 14:53:10,477 - --- validate (epoch=3)-----------
2024-04-05 14:53:10,477 - 10000 samples (100 per mini-batch)
2024-04-05 14:53:11,886 - Epoch: [3][  100/  100]    Loss 2.507006    Top1 35.040000    Top5 66.420000    
2024-04-05 14:53:12,075 - ==> Top1: 35.040    Top5: 66.420    Loss: 2.507

2024-04-05 14:53:12,080 - ==> Best [Top1: 36.520   Top5: 69.860   Sparsity:0.00   Params: 347840 on epoch: 2]
2024-04-05 14:53:12,080 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:53:12,111 - 

2024-04-05 14:53:12,111 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:53:16,574 - Epoch: [4][  100/  500]    Overall Loss 2.143752    Objective Loss 2.143752                                        LR 0.001000    Time 0.044575    
2024-04-05 14:53:20,218 - Epoch: [4][  200/  500]    Overall Loss 2.145383    Objective Loss 2.145383                                        LR 0.001000    Time 0.040482    
2024-04-05 14:53:23,946 - Epoch: [4][  300/  500]    Overall Loss 2.135624    Objective Loss 2.135624                                        LR 0.001000    Time 0.039398    
2024-04-05 14:53:27,583 - Epoch: [4][  400/  500]    Overall Loss 2.116478    Objective Loss 2.116478                                        LR 0.001000    Time 0.038628    
2024-04-05 14:53:31,296 - Epoch: [4][  500/  500]    Overall Loss 2.105661    Objective Loss 2.105661    Top1 40.000000    Top5 76.500000    LR 0.001000    Time 0.038320    
2024-04-05 14:53:31,518 - --- validate (epoch=4)-----------
2024-04-05 14:53:31,518 - 10000 samples (100 per mini-batch)
2024-04-05 14:53:32,973 - Epoch: [4][  100/  100]    Loss 2.371167    Top1 37.290000    Top5 70.300000    
2024-04-05 14:53:33,136 - ==> Top1: 37.290    Top5: 70.300    Loss: 2.371

2024-04-05 14:53:33,142 - ==> Best [Top1: 37.290   Top5: 70.300   Sparsity:0.00   Params: 347840 on epoch: 4]
2024-04-05 14:53:33,142 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:53:33,180 - 

2024-04-05 14:53:33,180 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:53:37,869 - Epoch: [5][  100/  500]    Overall Loss 1.999727    Objective Loss 1.999727                                        LR 0.001000    Time 0.046832    
2024-04-05 14:53:42,071 - Epoch: [5][  200/  500]    Overall Loss 1.987956    Objective Loss 1.987956                                        LR 0.001000    Time 0.044395    
2024-04-05 14:53:46,254 - Epoch: [5][  300/  500]    Overall Loss 1.979046    Objective Loss 1.979046                                        LR 0.001000    Time 0.043524    
2024-04-05 14:53:50,413 - Epoch: [5][  400/  500]    Overall Loss 1.976009    Objective Loss 1.976009                                        LR 0.001000    Time 0.043026    
2024-04-05 14:53:54,539 - Epoch: [5][  500/  500]    Overall Loss 1.966472    Objective Loss 1.966472    Top1 44.500000    Top5 82.000000    LR 0.001000    Time 0.042661    
2024-04-05 14:53:54,741 - --- validate (epoch=5)-----------
2024-04-05 14:53:54,742 - 10000 samples (100 per mini-batch)
2024-04-05 14:53:56,163 - Epoch: [5][  100/  100]    Loss 2.275090    Top1 39.650000    Top5 71.410000    
2024-04-05 14:53:56,319 - ==> Top1: 39.650    Top5: 71.410    Loss: 2.275

2024-04-05 14:53:56,327 - ==> Best [Top1: 39.650   Top5: 71.410   Sparsity:0.00   Params: 347840 on epoch: 5]
2024-04-05 14:53:56,327 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:53:56,365 - 

2024-04-05 14:53:56,365 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:54:01,043 - Epoch: [6][  100/  500]    Overall Loss 1.856403    Objective Loss 1.856403                                        LR 0.001000    Time 0.046721    
2024-04-05 14:54:05,205 - Epoch: [6][  200/  500]    Overall Loss 1.879974    Objective Loss 1.879974                                        LR 0.001000    Time 0.044141    
2024-04-05 14:54:09,358 - Epoch: [6][  300/  500]    Overall Loss 1.874350    Objective Loss 1.874350                                        LR 0.001000    Time 0.043254    
2024-04-05 14:54:13,530 - Epoch: [6][  400/  500]    Overall Loss 1.868833    Objective Loss 1.868833                                        LR 0.001000    Time 0.042857    
2024-04-05 14:54:17,668 - Epoch: [6][  500/  500]    Overall Loss 1.862127    Objective Loss 1.862127    Top1 48.500000    Top5 79.500000    LR 0.001000    Time 0.042548    
2024-04-05 14:54:17,848 - --- validate (epoch=6)-----------
2024-04-05 14:54:17,850 - 10000 samples (100 per mini-batch)
2024-04-05 14:54:19,238 - Epoch: [6][  100/  100]    Loss 1.919826    Top1 47.130000    Top5 78.900000    
2024-04-05 14:54:19,393 - ==> Top1: 47.130    Top5: 78.900    Loss: 1.920

2024-04-05 14:54:19,399 - ==> Best [Top1: 47.130   Top5: 78.900   Sparsity:0.00   Params: 347840 on epoch: 6]
2024-04-05 14:54:19,400 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:54:19,627 - 

2024-04-05 14:54:19,627 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:54:24,244 - Epoch: [7][  100/  500]    Overall Loss 1.777828    Objective Loss 1.777828                                        LR 0.001000    Time 0.046112    
2024-04-05 14:54:28,383 - Epoch: [7][  200/  500]    Overall Loss 1.788003    Objective Loss 1.788003                                        LR 0.001000    Time 0.043724    
2024-04-05 14:54:32,377 - Epoch: [7][  300/  500]    Overall Loss 1.779549    Objective Loss 1.779549                                        LR 0.001000    Time 0.042447    
2024-04-05 14:54:36,454 - Epoch: [7][  400/  500]    Overall Loss 1.782049    Objective Loss 1.782049                                        LR 0.001000    Time 0.042015    
2024-04-05 14:54:40,507 - Epoch: [7][  500/  500]    Overall Loss 1.774478    Objective Loss 1.774478    Top1 43.000000    Top5 77.500000    LR 0.001000    Time 0.041709    
2024-04-05 14:54:40,658 - --- validate (epoch=7)-----------
2024-04-05 14:54:40,659 - 10000 samples (100 per mini-batch)
2024-04-05 14:54:41,807 - Epoch: [7][  100/  100]    Loss 1.862362    Top1 48.730000    Top5 79.710000    
2024-04-05 14:54:41,947 - ==> Top1: 48.730    Top5: 79.710    Loss: 1.862

2024-04-05 14:54:41,953 - ==> Best [Top1: 48.730   Top5: 79.710   Sparsity:0.00   Params: 347840 on epoch: 7]
2024-04-05 14:54:41,954 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:54:41,992 - 

2024-04-05 14:54:41,992 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:54:46,791 - Epoch: [8][  100/  500]    Overall Loss 1.674435    Objective Loss 1.674435                                        LR 0.001000    Time 0.047934    
2024-04-05 14:54:50,846 - Epoch: [8][  200/  500]    Overall Loss 1.692628    Objective Loss 1.692628                                        LR 0.001000    Time 0.044220    
2024-04-05 14:54:54,774 - Epoch: [8][  300/  500]    Overall Loss 1.695361    Objective Loss 1.695361                                        LR 0.001000    Time 0.042558    
2024-04-05 14:54:59,087 - Epoch: [8][  400/  500]    Overall Loss 1.705862    Objective Loss 1.705862                                        LR 0.001000    Time 0.042688    
2024-04-05 14:55:03,367 - Epoch: [8][  500/  500]    Overall Loss 1.703873    Objective Loss 1.703873    Top1 55.000000    Top5 87.000000    LR 0.001000    Time 0.042697    
2024-04-05 14:55:03,617 - --- validate (epoch=8)-----------
2024-04-05 14:55:03,618 - 10000 samples (100 per mini-batch)
2024-04-05 14:55:05,020 - Epoch: [8][  100/  100]    Loss 1.874889    Top1 47.470000    Top5 79.660000    
2024-04-05 14:55:05,181 - ==> Top1: 47.470    Top5: 79.660    Loss: 1.875

2024-04-05 14:55:05,186 - ==> Best [Top1: 48.730   Top5: 79.710   Sparsity:0.00   Params: 347840 on epoch: 7]
2024-04-05 14:55:05,187 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:55:05,219 - 

2024-04-05 14:55:05,219 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:55:09,928 - Epoch: [9][  100/  500]    Overall Loss 1.618435    Objective Loss 1.618435                                        LR 0.001000    Time 0.047028    
2024-04-05 14:55:14,100 - Epoch: [9][  200/  500]    Overall Loss 1.637148    Objective Loss 1.637148                                        LR 0.001000    Time 0.044344    
2024-04-05 14:55:18,267 - Epoch: [9][  300/  500]    Overall Loss 1.639659    Objective Loss 1.639659                                        LR 0.001000    Time 0.043434    
2024-04-05 14:55:22,380 - Epoch: [9][  400/  500]    Overall Loss 1.634165    Objective Loss 1.634165                                        LR 0.001000    Time 0.042843    
2024-04-05 14:55:26,521 - Epoch: [9][  500/  500]    Overall Loss 1.636965    Objective Loss 1.636965    Top1 60.500000    Top5 84.500000    LR 0.001000    Time 0.042546    
2024-04-05 14:55:26,733 - --- validate (epoch=9)-----------
2024-04-05 14:55:26,733 - 10000 samples (100 per mini-batch)
2024-04-05 14:55:28,093 - Epoch: [9][  100/  100]    Loss 1.831412    Top1 49.690000    Top5 80.530000    
2024-04-05 14:55:28,368 - ==> Top1: 49.690    Top5: 80.530    Loss: 1.831

2024-04-05 14:55:28,374 - ==> Best [Top1: 49.690   Top5: 80.530   Sparsity:0.00   Params: 347840 on epoch: 9]
2024-04-05 14:55:28,375 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:55:28,414 - 

2024-04-05 14:55:28,414 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:55:33,397 - Epoch: [10][  100/  500]    Overall Loss 1.589778    Objective Loss 1.589778                                        LR 0.001000    Time 0.049773    
2024-04-05 14:55:37,510 - Epoch: [10][  200/  500]    Overall Loss 1.591600    Objective Loss 1.591600                                        LR 0.001000    Time 0.045427    
2024-04-05 14:55:41,637 - Epoch: [10][  300/  500]    Overall Loss 1.597985    Objective Loss 1.597985                                        LR 0.001000    Time 0.044022    
2024-04-05 14:55:45,813 - Epoch: [10][  400/  500]    Overall Loss 1.591914    Objective Loss 1.591914                                        LR 0.001000    Time 0.043442    
2024-04-05 14:55:49,897 - Epoch: [10][  500/  500]    Overall Loss 1.596492    Objective Loss 1.596492    Top1 55.000000    Top5 79.500000    LR 0.001000    Time 0.042912    
2024-04-05 14:55:50,123 - --- validate (epoch=10)-----------
2024-04-05 14:55:50,124 - 10000 samples (100 per mini-batch)
2024-04-05 14:55:51,566 - Epoch: [10][  100/  100]    Loss 1.769446    Top1 51.660000    Top5 81.480000    
2024-04-05 14:55:51,803 - ==> Top1: 51.660    Top5: 81.480    Loss: 1.769

2024-04-05 14:55:51,807 - ==> Best [Top1: 51.660   Top5: 81.480   Sparsity:0.00   Params: 347840 on epoch: 10]
2024-04-05 14:55:51,807 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:55:51,837 - 

2024-04-05 14:55:51,838 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:55:56,643 - Epoch: [11][  100/  500]    Overall Loss 1.547614    Objective Loss 1.547614                                        LR 0.001000    Time 0.047991    
2024-04-05 14:56:00,852 - Epoch: [11][  200/  500]    Overall Loss 1.548109    Objective Loss 1.548109                                        LR 0.001000    Time 0.045010    
2024-04-05 14:56:05,062 - Epoch: [11][  300/  500]    Overall Loss 1.544288    Objective Loss 1.544288                                        LR 0.001000    Time 0.044020    
2024-04-05 14:56:09,225 - Epoch: [11][  400/  500]    Overall Loss 1.547971    Objective Loss 1.547971                                        LR 0.001000    Time 0.043409    
2024-04-05 14:56:13,221 - Epoch: [11][  500/  500]    Overall Loss 1.550556    Objective Loss 1.550556    Top1 51.000000    Top5 84.500000    LR 0.001000    Time 0.042710    
2024-04-05 14:56:13,431 - --- validate (epoch=11)-----------
2024-04-05 14:56:13,432 - 10000 samples (100 per mini-batch)
2024-04-05 14:56:14,495 - Epoch: [11][  100/  100]    Loss 1.706417    Top1 52.580000    Top5 82.550000    
2024-04-05 14:56:14,630 - ==> Top1: 52.580    Top5: 82.550    Loss: 1.706

2024-04-05 14:56:14,633 - ==> Best [Top1: 52.580   Top5: 82.550   Sparsity:0.00   Params: 347840 on epoch: 11]
2024-04-05 14:56:14,633 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:56:14,657 - 

2024-04-05 14:56:14,658 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:56:19,101 - Epoch: [12][  100/  500]    Overall Loss 1.497165    Objective Loss 1.497165                                        LR 0.001000    Time 0.044382    
2024-04-05 14:56:23,213 - Epoch: [12][  200/  500]    Overall Loss 1.516347    Objective Loss 1.516347                                        LR 0.001000    Time 0.042718    
2024-04-05 14:56:27,171 - Epoch: [12][  300/  500]    Overall Loss 1.510188    Objective Loss 1.510188                                        LR 0.001000    Time 0.041655    
2024-04-05 14:56:31,269 - Epoch: [12][  400/  500]    Overall Loss 1.504307    Objective Loss 1.504307                                        LR 0.001000    Time 0.041472    
2024-04-05 14:56:35,372 - Epoch: [12][  500/  500]    Overall Loss 1.506412    Objective Loss 1.506412    Top1 57.000000    Top5 89.000000    LR 0.001000    Time 0.041375    
2024-04-05 14:56:35,661 - --- validate (epoch=12)-----------
2024-04-05 14:56:35,662 - 10000 samples (100 per mini-batch)
2024-04-05 14:56:37,340 - Epoch: [12][  100/  100]    Loss 1.640093    Top1 54.280000    Top5 83.320000    
2024-04-05 14:56:37,590 - ==> Top1: 54.280    Top5: 83.320    Loss: 1.640

2024-04-05 14:56:37,596 - ==> Best [Top1: 54.280   Top5: 83.320   Sparsity:0.00   Params: 347840 on epoch: 12]
2024-04-05 14:56:37,597 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:56:37,634 - 

2024-04-05 14:56:37,634 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:56:41,453 - Epoch: [13][  100/  500]    Overall Loss 1.429090    Objective Loss 1.429090                                        LR 0.001000    Time 0.038138    
2024-04-05 14:56:44,590 - Epoch: [13][  200/  500]    Overall Loss 1.445998    Objective Loss 1.445998                                        LR 0.001000    Time 0.034731    
2024-04-05 14:56:47,803 - Epoch: [13][  300/  500]    Overall Loss 1.460564    Objective Loss 1.460564                                        LR 0.001000    Time 0.033853    
2024-04-05 14:56:50,869 - Epoch: [13][  400/  500]    Overall Loss 1.459803    Objective Loss 1.459803                                        LR 0.001000    Time 0.033043    
2024-04-05 14:56:54,275 - Epoch: [13][  500/  500]    Overall Loss 1.464874    Objective Loss 1.464874    Top1 57.500000    Top5 87.000000    LR 0.001000    Time 0.033237    
2024-04-05 14:56:54,503 - --- validate (epoch=13)-----------
2024-04-05 14:56:54,503 - 10000 samples (100 per mini-batch)
2024-04-05 14:56:55,928 - Epoch: [13][  100/  100]    Loss 1.718723    Top1 52.470000    Top5 82.510000    
2024-04-05 14:56:56,109 - ==> Top1: 52.470    Top5: 82.510    Loss: 1.719

2024-04-05 14:56:56,114 - ==> Best [Top1: 54.280   Top5: 83.320   Sparsity:0.00   Params: 347840 on epoch: 12]
2024-04-05 14:56:56,114 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:56:56,146 - 

2024-04-05 14:56:56,147 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:57:01,228 - Epoch: [14][  100/  500]    Overall Loss 1.394509    Objective Loss 1.394509                                        LR 0.001000    Time 0.050750    
2024-04-05 14:57:05,528 - Epoch: [14][  200/  500]    Overall Loss 1.408955    Objective Loss 1.408955                                        LR 0.001000    Time 0.046839    
2024-04-05 14:57:09,741 - Epoch: [14][  300/  500]    Overall Loss 1.420690    Objective Loss 1.420690                                        LR 0.001000    Time 0.045252    
2024-04-05 14:57:13,850 - Epoch: [14][  400/  500]    Overall Loss 1.426078    Objective Loss 1.426078                                        LR 0.001000    Time 0.044198    
2024-04-05 14:57:18,014 - Epoch: [14][  500/  500]    Overall Loss 1.429847    Objective Loss 1.429847    Top1 56.500000    Top5 87.000000    LR 0.001000    Time 0.043674    
2024-04-05 14:57:18,270 - --- validate (epoch=14)-----------
2024-04-05 14:57:18,271 - 10000 samples (100 per mini-batch)
2024-04-05 14:57:19,721 - Epoch: [14][  100/  100]    Loss 1.629250    Top1 54.730000    Top5 84.100000    
2024-04-05 14:57:19,915 - ==> Top1: 54.730    Top5: 84.100    Loss: 1.629

2024-04-05 14:57:19,921 - ==> Best [Top1: 54.730   Top5: 84.100   Sparsity:0.00   Params: 347840 on epoch: 14]
2024-04-05 14:57:19,921 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:57:19,961 - 

2024-04-05 14:57:19,961 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:57:23,593 - Epoch: [15][  100/  500]    Overall Loss 1.364868    Objective Loss 1.364868                                        LR 0.001000    Time 0.036266    
2024-04-05 14:57:26,758 - Epoch: [15][  200/  500]    Overall Loss 1.384562    Objective Loss 1.384562                                        LR 0.001000    Time 0.033937    
2024-04-05 14:57:30,671 - Epoch: [15][  300/  500]    Overall Loss 1.384315    Objective Loss 1.384315                                        LR 0.001000    Time 0.035652    
2024-04-05 14:57:34,822 - Epoch: [15][  400/  500]    Overall Loss 1.387023    Objective Loss 1.387023                                        LR 0.001000    Time 0.037103    
2024-04-05 14:57:38,943 - Epoch: [15][  500/  500]    Overall Loss 1.394856    Objective Loss 1.394856    Top1 63.000000    Top5 88.000000    LR 0.001000    Time 0.037914    
2024-04-05 14:57:39,185 - --- validate (epoch=15)-----------
2024-04-05 14:57:39,186 - 10000 samples (100 per mini-batch)
2024-04-05 14:57:40,617 - Epoch: [15][  100/  100]    Loss 1.590045    Top1 55.680000    Top5 84.190000    
2024-04-05 14:57:40,840 - ==> Top1: 55.680    Top5: 84.190    Loss: 1.590

2024-04-05 14:57:40,846 - ==> Best [Top1: 55.680   Top5: 84.190   Sparsity:0.00   Params: 347840 on epoch: 15]
2024-04-05 14:57:40,846 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:57:40,885 - 

2024-04-05 14:57:40,885 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:57:45,548 - Epoch: [16][  100/  500]    Overall Loss 1.343103    Objective Loss 1.343103                                        LR 0.001000    Time 0.046569    
2024-04-05 14:57:49,673 - Epoch: [16][  200/  500]    Overall Loss 1.360266    Objective Loss 1.360266                                        LR 0.001000    Time 0.043871    
2024-04-05 14:57:53,801 - Epoch: [16][  300/  500]    Overall Loss 1.363441    Objective Loss 1.363441                                        LR 0.001000    Time 0.042991    
2024-04-05 14:57:57,942 - Epoch: [16][  400/  500]    Overall Loss 1.365089    Objective Loss 1.365089                                        LR 0.001000    Time 0.042581    
2024-04-05 14:58:02,053 - Epoch: [16][  500/  500]    Overall Loss 1.369806    Objective Loss 1.369806    Top1 63.500000    Top5 91.500000    LR 0.001000    Time 0.042277    
2024-04-05 14:58:02,282 - --- validate (epoch=16)-----------
2024-04-05 14:58:02,282 - 10000 samples (100 per mini-batch)
2024-04-05 14:58:03,742 - Epoch: [16][  100/  100]    Loss 1.688670    Top1 53.470000    Top5 82.790000    
2024-04-05 14:58:03,951 - ==> Top1: 53.470    Top5: 82.790    Loss: 1.689

2024-04-05 14:58:03,957 - ==> Best [Top1: 55.680   Top5: 84.190   Sparsity:0.00   Params: 347840 on epoch: 15]
2024-04-05 14:58:03,957 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:58:03,991 - 

2024-04-05 14:58:03,991 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:58:08,812 - Epoch: [17][  100/  500]    Overall Loss 1.315448    Objective Loss 1.315448                                        LR 0.001000    Time 0.048156    
2024-04-05 14:58:12,925 - Epoch: [17][  200/  500]    Overall Loss 1.325319    Objective Loss 1.325319                                        LR 0.001000    Time 0.044613    
2024-04-05 14:58:17,046 - Epoch: [17][  300/  500]    Overall Loss 1.328273    Objective Loss 1.328273                                        LR 0.001000    Time 0.043461    
2024-04-05 14:58:21,150 - Epoch: [17][  400/  500]    Overall Loss 1.332059    Objective Loss 1.332059                                        LR 0.001000    Time 0.042844    
2024-04-05 14:58:25,303 - Epoch: [17][  500/  500]    Overall Loss 1.340286    Objective Loss 1.340286    Top1 60.000000    Top5 88.000000    LR 0.001000    Time 0.042569    
2024-04-05 14:58:25,480 - --- validate (epoch=17)-----------
2024-04-05 14:58:25,481 - 10000 samples (100 per mini-batch)
2024-04-05 14:58:26,855 - Epoch: [17][  100/  100]    Loss 1.593673    Top1 55.520000    Top5 84.130000    
2024-04-05 14:58:27,021 - ==> Top1: 55.520    Top5: 84.130    Loss: 1.594

2024-04-05 14:58:27,027 - ==> Best [Top1: 55.680   Top5: 84.190   Sparsity:0.00   Params: 347840 on epoch: 15]
2024-04-05 14:58:27,027 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:58:27,059 - 

2024-04-05 14:58:27,060 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:58:31,224 - Epoch: [18][  100/  500]    Overall Loss 1.287213    Objective Loss 1.287213                                        LR 0.001000    Time 0.041592    
2024-04-05 14:58:34,286 - Epoch: [18][  200/  500]    Overall Loss 1.278658    Objective Loss 1.278658                                        LR 0.001000    Time 0.036084    
2024-04-05 14:58:37,401 - Epoch: [18][  300/  500]    Overall Loss 1.293043    Objective Loss 1.293043                                        LR 0.001000    Time 0.034424    
2024-04-05 14:58:40,560 - Epoch: [18][  400/  500]    Overall Loss 1.297291    Objective Loss 1.297291                                        LR 0.001000    Time 0.033704    
2024-04-05 14:58:43,790 - Epoch: [18][  500/  500]    Overall Loss 1.303085    Objective Loss 1.303085    Top1 59.500000    Top5 87.500000    LR 0.001000    Time 0.033415    
2024-04-05 14:58:44,006 - --- validate (epoch=18)-----------
2024-04-05 14:58:44,006 - 10000 samples (100 per mini-batch)
2024-04-05 14:58:45,432 - Epoch: [18][  100/  100]    Loss 1.672603    Top1 54.100000    Top5 83.380000    
2024-04-05 14:58:45,640 - ==> Top1: 54.100    Top5: 83.380    Loss: 1.673

2024-04-05 14:58:45,645 - ==> Best [Top1: 55.680   Top5: 84.190   Sparsity:0.00   Params: 347840 on epoch: 15]
2024-04-05 14:58:45,646 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:58:45,678 - 

2024-04-05 14:58:45,678 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:58:50,352 - Epoch: [19][  100/  500]    Overall Loss 1.279560    Objective Loss 1.279560                                        LR 0.001000    Time 0.046679    
2024-04-05 14:58:54,475 - Epoch: [19][  200/  500]    Overall Loss 1.262440    Objective Loss 1.262440                                        LR 0.001000    Time 0.043928    
2024-04-05 14:58:58,570 - Epoch: [19][  300/  500]    Overall Loss 1.275163    Objective Loss 1.275163                                        LR 0.001000    Time 0.042919    
2024-04-05 14:59:02,673 - Epoch: [19][  400/  500]    Overall Loss 1.277193    Objective Loss 1.277193                                        LR 0.001000    Time 0.042432    
2024-04-05 14:59:06,781 - Epoch: [19][  500/  500]    Overall Loss 1.284177    Objective Loss 1.284177    Top1 61.000000    Top5 88.000000    LR 0.001000    Time 0.042152    
2024-04-05 14:59:07,005 - --- validate (epoch=19)-----------
2024-04-05 14:59:07,007 - 10000 samples (100 per mini-batch)
2024-04-05 14:59:08,422 - Epoch: [19][  100/  100]    Loss 1.625277    Top1 55.220000    Top5 83.450000    
2024-04-05 14:59:08,611 - ==> Top1: 55.220    Top5: 83.450    Loss: 1.625

2024-04-05 14:59:08,616 - ==> Best [Top1: 55.680   Top5: 84.190   Sparsity:0.00   Params: 347840 on epoch: 15]
2024-04-05 14:59:08,616 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:59:08,648 - 

2024-04-05 14:59:08,649 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:59:13,270 - Epoch: [20][  100/  500]    Overall Loss 1.244865    Objective Loss 1.244865                                        LR 0.001000    Time 0.046154    
2024-04-05 14:59:17,369 - Epoch: [20][  200/  500]    Overall Loss 1.249643    Objective Loss 1.249643                                        LR 0.001000    Time 0.043549    
2024-04-05 14:59:21,483 - Epoch: [20][  300/  500]    Overall Loss 1.256791    Objective Loss 1.256791                                        LR 0.001000    Time 0.042727    
2024-04-05 14:59:25,601 - Epoch: [20][  400/  500]    Overall Loss 1.266784    Objective Loss 1.266784                                        LR 0.001000    Time 0.042327    
2024-04-05 14:59:29,704 - Epoch: [20][  500/  500]    Overall Loss 1.265241    Objective Loss 1.265241    Top1 69.000000    Top5 90.000000    LR 0.001000    Time 0.042058    
2024-04-05 14:59:29,891 - --- validate (epoch=20)-----------
2024-04-05 14:59:29,891 - 10000 samples (100 per mini-batch)
2024-04-05 14:59:31,392 - Epoch: [20][  100/  100]    Loss 1.549190    Top1 56.750000    Top5 85.180000    
2024-04-05 14:59:31,559 - ==> Top1: 56.750    Top5: 85.180    Loss: 1.549

2024-04-05 14:59:31,565 - ==> Best [Top1: 56.750   Top5: 85.180   Sparsity:0.00   Params: 347840 on epoch: 20]
2024-04-05 14:59:31,565 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:59:31,604 - 

2024-04-05 14:59:31,605 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:59:36,515 - Epoch: [21][  100/  500]    Overall Loss 1.232832    Objective Loss 1.232832                                        LR 0.001000    Time 0.049045    
2024-04-05 14:59:40,639 - Epoch: [21][  200/  500]    Overall Loss 1.239196    Objective Loss 1.239196                                        LR 0.001000    Time 0.045119    
2024-04-05 14:59:44,760 - Epoch: [21][  300/  500]    Overall Loss 1.239178    Objective Loss 1.239178                                        LR 0.001000    Time 0.043795    
2024-04-05 14:59:48,143 - Epoch: [21][  400/  500]    Overall Loss 1.238954    Objective Loss 1.238954                                        LR 0.001000    Time 0.041293    
2024-04-05 14:59:51,192 - Epoch: [21][  500/  500]    Overall Loss 1.239786    Objective Loss 1.239786    Top1 60.500000    Top5 90.000000    LR 0.001000    Time 0.039126    
2024-04-05 14:59:51,316 - --- validate (epoch=21)-----------
2024-04-05 14:59:51,316 - 10000 samples (100 per mini-batch)
2024-04-05 14:59:52,375 - Epoch: [21][  100/  100]    Loss 1.613331    Top1 54.880000    Top5 84.130000    
2024-04-05 14:59:52,524 - ==> Top1: 54.880    Top5: 84.130    Loss: 1.613

2024-04-05 14:59:52,529 - ==> Best [Top1: 56.750   Top5: 85.180   Sparsity:0.00   Params: 347840 on epoch: 20]
2024-04-05 14:59:52,529 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 14:59:52,559 - 

2024-04-05 14:59:52,559 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 14:59:56,090 - Epoch: [22][  100/  500]    Overall Loss 1.224566    Objective Loss 1.224566                                        LR 0.001000    Time 0.035263    
2024-04-05 14:59:59,669 - Epoch: [22][  200/  500]    Overall Loss 1.217433    Objective Loss 1.217433                                        LR 0.001000    Time 0.035508    
2024-04-05 15:00:03,610 - Epoch: [22][  300/  500]    Overall Loss 1.215680    Objective Loss 1.215680                                        LR 0.001000    Time 0.036792    
2024-04-05 15:00:07,489 - Epoch: [22][  400/  500]    Overall Loss 1.222095    Objective Loss 1.222095                                        LR 0.001000    Time 0.037279    
2024-04-05 15:00:11,558 - Epoch: [22][  500/  500]    Overall Loss 1.225409    Objective Loss 1.225409    Top1 63.500000    Top5 91.500000    LR 0.001000    Time 0.037950    
2024-04-05 15:00:11,702 - --- validate (epoch=22)-----------
2024-04-05 15:00:11,702 - 10000 samples (100 per mini-batch)
2024-04-05 15:00:12,960 - Epoch: [22][  100/  100]    Loss 1.544143    Top1 57.400000    Top5 85.180000    
2024-04-05 15:00:13,078 - ==> Top1: 57.400    Top5: 85.180    Loss: 1.544

2024-04-05 15:00:13,082 - ==> Best [Top1: 57.400   Top5: 85.180   Sparsity:0.00   Params: 347840 on epoch: 22]
2024-04-05 15:00:13,083 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:00:13,122 - 

2024-04-05 15:00:13,122 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:00:17,469 - Epoch: [23][  100/  500]    Overall Loss 1.183941    Objective Loss 1.183941                                        LR 0.001000    Time 0.043410    
2024-04-05 15:00:21,645 - Epoch: [23][  200/  500]    Overall Loss 1.188623    Objective Loss 1.188623                                        LR 0.001000    Time 0.042555    
2024-04-05 15:00:25,705 - Epoch: [23][  300/  500]    Overall Loss 1.199293    Objective Loss 1.199293                                        LR 0.001000    Time 0.041888    
2024-04-05 15:00:29,716 - Epoch: [23][  400/  500]    Overall Loss 1.198759    Objective Loss 1.198759                                        LR 0.001000    Time 0.041430    
2024-04-05 15:00:33,653 - Epoch: [23][  500/  500]    Overall Loss 1.202069    Objective Loss 1.202069    Top1 62.000000    Top5 88.000000    LR 0.001000    Time 0.041009    
2024-04-05 15:00:33,865 - --- validate (epoch=23)-----------
2024-04-05 15:00:33,866 - 10000 samples (100 per mini-batch)
2024-04-05 15:00:35,083 - Epoch: [23][  100/  100]    Loss 1.691522    Top1 54.910000    Top5 82.400000    
2024-04-05 15:00:35,304 - ==> Top1: 54.910    Top5: 82.400    Loss: 1.692

2024-04-05 15:00:35,310 - ==> Best [Top1: 57.400   Top5: 85.180   Sparsity:0.00   Params: 347840 on epoch: 22]
2024-04-05 15:00:35,310 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:00:35,342 - 

2024-04-05 15:00:35,342 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:00:40,355 - Epoch: [24][  100/  500]    Overall Loss 1.152880    Objective Loss 1.152880                                        LR 0.001000    Time 0.050068    
2024-04-05 15:00:44,496 - Epoch: [24][  200/  500]    Overall Loss 1.160879    Objective Loss 1.160879                                        LR 0.001000    Time 0.045715    
2024-04-05 15:00:48,649 - Epoch: [24][  300/  500]    Overall Loss 1.168942    Objective Loss 1.168942                                        LR 0.001000    Time 0.044300    
2024-04-05 15:00:52,561 - Epoch: [24][  400/  500]    Overall Loss 1.175860    Objective Loss 1.175860                                        LR 0.001000    Time 0.042993    
2024-04-05 15:00:56,757 - Epoch: [24][  500/  500]    Overall Loss 1.182784    Objective Loss 1.182784    Top1 64.500000    Top5 89.000000    LR 0.001000    Time 0.042775    
2024-04-05 15:00:56,957 - --- validate (epoch=24)-----------
2024-04-05 15:00:56,958 - 10000 samples (100 per mini-batch)
2024-04-05 15:00:58,331 - Epoch: [24][  100/  100]    Loss 1.559046    Top1 57.160000    Top5 84.880000    
2024-04-05 15:00:58,521 - ==> Top1: 57.160    Top5: 84.880    Loss: 1.559

2024-04-05 15:00:58,527 - ==> Best [Top1: 57.400   Top5: 85.180   Sparsity:0.00   Params: 347840 on epoch: 22]
2024-04-05 15:00:58,528 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:00:58,559 - 

2024-04-05 15:00:58,559 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:01:02,919 - Epoch: [25][  100/  500]    Overall Loss 1.171007    Objective Loss 1.171007                                        LR 0.001000    Time 0.043544    
2024-04-05 15:01:07,007 - Epoch: [25][  200/  500]    Overall Loss 1.159858    Objective Loss 1.159858                                        LR 0.001000    Time 0.042183    
2024-04-05 15:01:11,089 - Epoch: [25][  300/  500]    Overall Loss 1.161093    Objective Loss 1.161093                                        LR 0.001000    Time 0.041711    
2024-04-05 15:01:15,201 - Epoch: [25][  400/  500]    Overall Loss 1.167637    Objective Loss 1.167637                                        LR 0.001000    Time 0.041551    
2024-04-05 15:01:19,357 - Epoch: [25][  500/  500]    Overall Loss 1.173380    Objective Loss 1.173380    Top1 66.500000    Top5 91.000000    LR 0.001000    Time 0.041541    
2024-04-05 15:01:19,634 - --- validate (epoch=25)-----------
2024-04-05 15:01:19,635 - 10000 samples (100 per mini-batch)
2024-04-05 15:01:21,112 - Epoch: [25][  100/  100]    Loss 1.528936    Top1 57.920000    Top5 85.580000    
2024-04-05 15:01:21,359 - ==> Top1: 57.920    Top5: 85.580    Loss: 1.529

2024-04-05 15:01:21,365 - ==> Best [Top1: 57.920   Top5: 85.580   Sparsity:0.00   Params: 347840 on epoch: 25]
2024-04-05 15:01:21,365 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:01:21,405 - 

2024-04-05 15:01:21,405 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:01:25,895 - Epoch: [26][  100/  500]    Overall Loss 1.105738    Objective Loss 1.105738                                        LR 0.001000    Time 0.044846    
2024-04-05 15:01:30,049 - Epoch: [26][  200/  500]    Overall Loss 1.118076    Objective Loss 1.118076                                        LR 0.001000    Time 0.043164    
2024-04-05 15:01:34,167 - Epoch: [26][  300/  500]    Overall Loss 1.136442    Objective Loss 1.136442                                        LR 0.001000    Time 0.042486    
2024-04-05 15:01:38,288 - Epoch: [26][  400/  500]    Overall Loss 1.151359    Objective Loss 1.151359                                        LR 0.001000    Time 0.042153    
2024-04-05 15:01:42,407 - Epoch: [26][  500/  500]    Overall Loss 1.154775    Objective Loss 1.154775    Top1 66.000000    Top5 92.000000    LR 0.001000    Time 0.041951    
2024-04-05 15:01:42,638 - --- validate (epoch=26)-----------
2024-04-05 15:01:42,638 - 10000 samples (100 per mini-batch)
2024-04-05 15:01:44,317 - Epoch: [26][  100/  100]    Loss 1.503510    Top1 58.060000    Top5 85.650000    
2024-04-05 15:01:44,541 - ==> Top1: 58.060    Top5: 85.650    Loss: 1.504

2024-04-05 15:01:44,545 - ==> Best [Top1: 58.060   Top5: 85.650   Sparsity:0.00   Params: 347840 on epoch: 26]
2024-04-05 15:01:44,546 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:01:44,584 - 

2024-04-05 15:01:44,584 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:01:49,321 - Epoch: [27][  100/  500]    Overall Loss 1.087594    Objective Loss 1.087594                                        LR 0.001000    Time 0.047310    
2024-04-05 15:01:53,481 - Epoch: [27][  200/  500]    Overall Loss 1.103750    Objective Loss 1.103750                                        LR 0.001000    Time 0.044427    
2024-04-05 15:01:57,599 - Epoch: [27][  300/  500]    Overall Loss 1.109416    Objective Loss 1.109416                                        LR 0.001000    Time 0.043327    
2024-04-05 15:02:01,720 - Epoch: [27][  400/  500]    Overall Loss 1.114389    Objective Loss 1.114389                                        LR 0.001000    Time 0.042786    
2024-04-05 15:02:05,840 - Epoch: [27][  500/  500]    Overall Loss 1.125249    Objective Loss 1.125249    Top1 67.000000    Top5 92.500000    LR 0.001000    Time 0.042458    
2024-04-05 15:02:06,058 - --- validate (epoch=27)-----------
2024-04-05 15:02:06,059 - 10000 samples (100 per mini-batch)
2024-04-05 15:02:07,523 - Epoch: [27][  100/  100]    Loss 1.497595    Top1 58.120000    Top5 86.130000    
2024-04-05 15:02:07,681 - ==> Top1: 58.120    Top5: 86.130    Loss: 1.498

2024-04-05 15:02:07,687 - ==> Best [Top1: 58.120   Top5: 86.130   Sparsity:0.00   Params: 347840 on epoch: 27]
2024-04-05 15:02:07,688 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:02:07,726 - 

2024-04-05 15:02:07,726 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:02:12,673 - Epoch: [28][  100/  500]    Overall Loss 1.100087    Objective Loss 1.100087                                        LR 0.001000    Time 0.049411    
2024-04-05 15:02:16,797 - Epoch: [28][  200/  500]    Overall Loss 1.102764    Objective Loss 1.102764                                        LR 0.001000    Time 0.045300    
2024-04-05 15:02:20,938 - Epoch: [28][  300/  500]    Overall Loss 1.108295    Objective Loss 1.108295                                        LR 0.001000    Time 0.043985    
2024-04-05 15:02:25,097 - Epoch: [28][  400/  500]    Overall Loss 1.110080    Objective Loss 1.110080                                        LR 0.001000    Time 0.043371    
2024-04-05 15:02:29,245 - Epoch: [28][  500/  500]    Overall Loss 1.113737    Objective Loss 1.113737    Top1 69.000000    Top5 91.500000    LR 0.001000    Time 0.042983    
2024-04-05 15:02:29,457 - --- validate (epoch=28)-----------
2024-04-05 15:02:29,458 - 10000 samples (100 per mini-batch)
2024-04-05 15:02:30,794 - Epoch: [28][  100/  100]    Loss 1.493123    Top1 58.680000    Top5 85.830000    
2024-04-05 15:02:31,014 - ==> Top1: 58.680    Top5: 85.830    Loss: 1.493

2024-04-05 15:02:31,021 - ==> Best [Top1: 58.680   Top5: 85.830   Sparsity:0.00   Params: 347840 on epoch: 28]
2024-04-05 15:02:31,022 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:02:31,059 - 

2024-04-05 15:02:31,060 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:02:35,722 - Epoch: [29][  100/  500]    Overall Loss 1.081867    Objective Loss 1.081867                                        LR 0.001000    Time 0.046573    
2024-04-05 15:02:39,826 - Epoch: [29][  200/  500]    Overall Loss 1.087506    Objective Loss 1.087506                                        LR 0.001000    Time 0.043776    
2024-04-05 15:02:43,931 - Epoch: [29][  300/  500]    Overall Loss 1.100826    Objective Loss 1.100826                                        LR 0.001000    Time 0.042850    
2024-04-05 15:02:48,040 - Epoch: [29][  400/  500]    Overall Loss 1.101860    Objective Loss 1.101860                                        LR 0.001000    Time 0.042398    
2024-04-05 15:02:52,169 - Epoch: [29][  500/  500]    Overall Loss 1.105603    Objective Loss 1.105603    Top1 66.500000    Top5 92.000000    LR 0.001000    Time 0.042165    
2024-04-05 15:02:52,387 - --- validate (epoch=29)-----------
2024-04-05 15:02:52,388 - 10000 samples (100 per mini-batch)
2024-04-05 15:02:53,816 - Epoch: [29][  100/  100]    Loss 1.500467    Top1 58.650000    Top5 86.020000    
2024-04-05 15:02:53,988 - ==> Top1: 58.650    Top5: 86.020    Loss: 1.500

2024-04-05 15:02:53,994 - ==> Best [Top1: 58.680   Top5: 85.830   Sparsity:0.00   Params: 347840 on epoch: 28]
2024-04-05 15:02:53,995 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:02:54,026 - 

2024-04-05 15:02:54,026 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:02:58,801 - Epoch: [30][  100/  500]    Overall Loss 1.056115    Objective Loss 1.056115                                        LR 0.001000    Time 0.047690    
2024-04-05 15:03:02,883 - Epoch: [30][  200/  500]    Overall Loss 1.058454    Objective Loss 1.058454                                        LR 0.001000    Time 0.044227    
2024-04-05 15:03:07,029 - Epoch: [30][  300/  500]    Overall Loss 1.069312    Objective Loss 1.069312                                        LR 0.001000    Time 0.043288    
2024-04-05 15:03:11,149 - Epoch: [30][  400/  500]    Overall Loss 1.080106    Objective Loss 1.080106                                        LR 0.001000    Time 0.042753    
2024-04-05 15:03:15,310 - Epoch: [30][  500/  500]    Overall Loss 1.088762    Objective Loss 1.088762    Top1 65.500000    Top5 91.000000    LR 0.001000    Time 0.042514    
2024-04-05 15:03:15,556 - --- validate (epoch=30)-----------
2024-04-05 15:03:15,557 - 10000 samples (100 per mini-batch)
2024-04-05 15:03:16,917 - Epoch: [30][  100/  100]    Loss 1.500633    Top1 58.790000    Top5 86.070000    
2024-04-05 15:03:17,100 - ==> Top1: 58.790    Top5: 86.070    Loss: 1.501

2024-04-05 15:03:17,106 - ==> Best [Top1: 58.790   Top5: 86.070   Sparsity:0.00   Params: 347840 on epoch: 30]
2024-04-05 15:03:17,106 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:03:17,142 - 

2024-04-05 15:03:17,142 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:03:21,814 - Epoch: [31][  100/  500]    Overall Loss 1.051155    Objective Loss 1.051155                                        LR 0.001000    Time 0.046660    
2024-04-05 15:03:25,916 - Epoch: [31][  200/  500]    Overall Loss 1.055480    Objective Loss 1.055480                                        LR 0.001000    Time 0.043811    
2024-04-05 15:03:30,050 - Epoch: [31][  300/  500]    Overall Loss 1.060630    Objective Loss 1.060630                                        LR 0.001000    Time 0.042971    
2024-04-05 15:03:34,167 - Epoch: [31][  400/  500]    Overall Loss 1.067061    Objective Loss 1.067061                                        LR 0.001000    Time 0.042508    
2024-04-05 15:03:38,285 - Epoch: [31][  500/  500]    Overall Loss 1.075134    Objective Loss 1.075134    Top1 69.000000    Top5 91.500000    LR 0.001000    Time 0.042230    
2024-04-05 15:03:38,616 - --- validate (epoch=31)-----------
2024-04-05 15:03:38,617 - 10000 samples (100 per mini-batch)
2024-04-05 15:03:40,087 - Epoch: [31][  100/  100]    Loss 1.490793    Top1 58.660000    Top5 86.130000    
2024-04-05 15:03:40,342 - ==> Top1: 58.660    Top5: 86.130    Loss: 1.491

2024-04-05 15:03:40,347 - ==> Best [Top1: 58.790   Top5: 86.070   Sparsity:0.00   Params: 347840 on epoch: 30]
2024-04-05 15:03:40,347 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:03:40,378 - 

2024-04-05 15:03:40,379 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:03:45,294 - Epoch: [32][  100/  500]    Overall Loss 1.035516    Objective Loss 1.035516                                        LR 0.001000    Time 0.049094    
2024-04-05 15:03:49,475 - Epoch: [32][  200/  500]    Overall Loss 1.045613    Objective Loss 1.045613                                        LR 0.001000    Time 0.045425    
2024-04-05 15:03:53,712 - Epoch: [32][  300/  500]    Overall Loss 1.059284    Objective Loss 1.059284                                        LR 0.001000    Time 0.044385    
2024-04-05 15:03:57,922 - Epoch: [32][  400/  500]    Overall Loss 1.059240    Objective Loss 1.059240                                        LR 0.001000    Time 0.043799    
2024-04-05 15:04:02,098 - Epoch: [32][  500/  500]    Overall Loss 1.060712    Objective Loss 1.060712    Top1 77.500000    Top5 94.500000    LR 0.001000    Time 0.043381    
2024-04-05 15:04:02,295 - --- validate (epoch=32)-----------
2024-04-05 15:04:02,296 - 10000 samples (100 per mini-batch)
2024-04-05 15:04:03,618 - Epoch: [32][  100/  100]    Loss 1.475446    Top1 59.340000    Top5 86.370000    
2024-04-05 15:04:03,772 - ==> Top1: 59.340    Top5: 86.370    Loss: 1.475

2024-04-05 15:04:03,778 - ==> Best [Top1: 59.340   Top5: 86.370   Sparsity:0.00   Params: 347840 on epoch: 32]
2024-04-05 15:04:03,778 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:04:03,818 - 

2024-04-05 15:04:03,818 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:04:08,547 - Epoch: [33][  100/  500]    Overall Loss 1.018522    Objective Loss 1.018522                                        LR 0.001000    Time 0.047213    
2024-04-05 15:04:12,670 - Epoch: [33][  200/  500]    Overall Loss 1.031006    Objective Loss 1.031006                                        LR 0.001000    Time 0.044196    
2024-04-05 15:04:16,783 - Epoch: [33][  300/  500]    Overall Loss 1.030795    Objective Loss 1.030795                                        LR 0.001000    Time 0.043154    
2024-04-05 15:04:20,888 - Epoch: [33][  400/  500]    Overall Loss 1.034790    Objective Loss 1.034790                                        LR 0.001000    Time 0.042617    
2024-04-05 15:04:25,067 - Epoch: [33][  500/  500]    Overall Loss 1.041375    Objective Loss 1.041375    Top1 68.000000    Top5 89.000000    LR 0.001000    Time 0.042440    
2024-04-05 15:04:25,239 - --- validate (epoch=33)-----------
2024-04-05 15:04:25,240 - 10000 samples (100 per mini-batch)
2024-04-05 15:04:26,446 - Epoch: [33][  100/  100]    Loss 1.441056    Top1 60.380000    Top5 86.700000    
2024-04-05 15:04:26,644 - ==> Top1: 60.380    Top5: 86.700    Loss: 1.441

2024-04-05 15:04:26,649 - ==> Best [Top1: 60.380   Top5: 86.700   Sparsity:0.00   Params: 347840 on epoch: 33]
2024-04-05 15:04:26,650 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:04:26,689 - 

2024-04-05 15:04:26,689 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:04:31,337 - Epoch: [34][  100/  500]    Overall Loss 1.008024    Objective Loss 1.008024                                        LR 0.001000    Time 0.046423    
2024-04-05 15:04:35,330 - Epoch: [34][  200/  500]    Overall Loss 1.015838    Objective Loss 1.015838                                        LR 0.001000    Time 0.043146    
2024-04-05 15:04:39,502 - Epoch: [34][  300/  500]    Overall Loss 1.023432    Objective Loss 1.023432                                        LR 0.001000    Time 0.042652    
2024-04-05 15:04:43,563 - Epoch: [34][  400/  500]    Overall Loss 1.029203    Objective Loss 1.029203                                        LR 0.001000    Time 0.042130    
2024-04-05 15:04:47,582 - Epoch: [34][  500/  500]    Overall Loss 1.034562    Objective Loss 1.034562    Top1 70.500000    Top5 92.000000    LR 0.001000    Time 0.041732    
2024-04-05 15:04:47,900 - --- validate (epoch=34)-----------
2024-04-05 15:04:47,901 - 10000 samples (100 per mini-batch)
2024-04-05 15:04:49,242 - Epoch: [34][  100/  100]    Loss 1.494246    Top1 59.030000    Top5 85.890000    
2024-04-05 15:04:49,382 - ==> Top1: 59.030    Top5: 85.890    Loss: 1.494

2024-04-05 15:04:49,385 - ==> Best [Top1: 60.380   Top5: 86.700   Sparsity:0.00   Params: 347840 on epoch: 33]
2024-04-05 15:04:49,385 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:04:49,405 - 

2024-04-05 15:04:49,405 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:04:54,112 - Epoch: [35][  100/  500]    Overall Loss 0.983671    Objective Loss 0.983671                                        LR 0.001000    Time 0.047006    
2024-04-05 15:04:58,339 - Epoch: [35][  200/  500]    Overall Loss 0.991676    Objective Loss 0.991676                                        LR 0.001000    Time 0.044613    
2024-04-05 15:05:02,592 - Epoch: [35][  300/  500]    Overall Loss 1.009547    Objective Loss 1.009547                                        LR 0.001000    Time 0.043901    
2024-04-05 15:05:06,786 - Epoch: [35][  400/  500]    Overall Loss 1.020782    Objective Loss 1.020782                                        LR 0.001000    Time 0.043397    
2024-04-05 15:05:11,042 - Epoch: [35][  500/  500]    Overall Loss 1.025621    Objective Loss 1.025621    Top1 70.000000    Top5 95.000000    LR 0.001000    Time 0.043218    
2024-04-05 15:05:11,221 - --- validate (epoch=35)-----------
2024-04-05 15:05:11,223 - 10000 samples (100 per mini-batch)
2024-04-05 15:05:12,601 - Epoch: [35][  100/  100]    Loss 1.448416    Top1 59.640000    Top5 86.830000    
2024-04-05 15:05:12,830 - ==> Top1: 59.640    Top5: 86.830    Loss: 1.448

2024-04-05 15:05:12,835 - ==> Best [Top1: 60.380   Top5: 86.700   Sparsity:0.00   Params: 347840 on epoch: 33]
2024-04-05 15:05:12,835 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:05:12,868 - 

2024-04-05 15:05:12,868 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:05:17,190 - Epoch: [36][  100/  500]    Overall Loss 0.978773    Objective Loss 0.978773                                        LR 0.001000    Time 0.043171    
2024-04-05 15:05:21,243 - Epoch: [36][  200/  500]    Overall Loss 0.997858    Objective Loss 0.997858                                        LR 0.001000    Time 0.041822    
2024-04-05 15:05:25,336 - Epoch: [36][  300/  500]    Overall Loss 1.013555    Objective Loss 1.013555                                        LR 0.001000    Time 0.041507    
2024-04-05 15:05:29,419 - Epoch: [36][  400/  500]    Overall Loss 1.012489    Objective Loss 1.012489                                        LR 0.001000    Time 0.041325    
2024-04-05 15:05:33,492 - Epoch: [36][  500/  500]    Overall Loss 1.015690    Objective Loss 1.015690    Top1 68.500000    Top5 94.000000    LR 0.001000    Time 0.041195    
2024-04-05 15:05:33,808 - --- validate (epoch=36)-----------
2024-04-05 15:05:33,809 - 10000 samples (100 per mini-batch)
2024-04-05 15:05:35,444 - Epoch: [36][  100/  100]    Loss 1.432496    Top1 60.420000    Top5 86.920000    
2024-04-05 15:05:35,624 - ==> Top1: 60.420    Top5: 86.920    Loss: 1.432

2024-04-05 15:05:35,629 - ==> Best [Top1: 60.420   Top5: 86.920   Sparsity:0.00   Params: 347840 on epoch: 36]
2024-04-05 15:05:35,630 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:05:35,673 - 

2024-04-05 15:05:35,673 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:05:40,130 - Epoch: [37][  100/  500]    Overall Loss 0.981247    Objective Loss 0.981247                                        LR 0.001000    Time 0.044516    
2024-04-05 15:05:44,200 - Epoch: [37][  200/  500]    Overall Loss 1.004299    Objective Loss 1.004299                                        LR 0.001000    Time 0.042580    
2024-04-05 15:05:48,321 - Epoch: [37][  300/  500]    Overall Loss 0.998219    Objective Loss 0.998219                                        LR 0.001000    Time 0.042106    
2024-04-05 15:05:52,414 - Epoch: [37][  400/  500]    Overall Loss 0.995163    Objective Loss 0.995163                                        LR 0.001000    Time 0.041799    
2024-04-05 15:05:56,459 - Epoch: [37][  500/  500]    Overall Loss 1.000384    Objective Loss 1.000384    Top1 67.500000    Top5 89.000000    LR 0.001000    Time 0.041519    
2024-04-05 15:05:56,634 - --- validate (epoch=37)-----------
2024-04-05 15:05:56,635 - 10000 samples (100 per mini-batch)
2024-04-05 15:05:58,151 - Epoch: [37][  100/  100]    Loss 1.455001    Top1 59.990000    Top5 86.520000    
2024-04-05 15:05:58,412 - ==> Top1: 59.990    Top5: 86.520    Loss: 1.455

2024-04-05 15:05:58,415 - ==> Best [Top1: 60.420   Top5: 86.920   Sparsity:0.00   Params: 347840 on epoch: 36]
2024-04-05 15:05:58,416 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:05:58,437 - 

2024-04-05 15:05:58,438 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:06:03,348 - Epoch: [38][  100/  500]    Overall Loss 0.962464    Objective Loss 0.962464                                        LR 0.001000    Time 0.049044    
2024-04-05 15:06:07,488 - Epoch: [38][  200/  500]    Overall Loss 0.974607    Objective Loss 0.974607                                        LR 0.001000    Time 0.045197    
2024-04-05 15:06:11,587 - Epoch: [38][  300/  500]    Overall Loss 0.981130    Objective Loss 0.981130                                        LR 0.001000    Time 0.043776    
2024-04-05 15:06:15,686 - Epoch: [38][  400/  500]    Overall Loss 0.987692    Objective Loss 0.987692                                        LR 0.001000    Time 0.043067    
2024-04-05 15:06:19,859 - Epoch: [38][  500/  500]    Overall Loss 0.990676    Objective Loss 0.990676    Top1 74.000000    Top5 94.000000    LR 0.001000    Time 0.042788    
2024-04-05 15:06:20,031 - --- validate (epoch=38)-----------
2024-04-05 15:06:20,031 - 10000 samples (100 per mini-batch)
2024-04-05 15:06:21,420 - Epoch: [38][  100/  100]    Loss 1.447727    Top1 60.300000    Top5 86.590000    
2024-04-05 15:06:21,581 - ==> Top1: 60.300    Top5: 86.590    Loss: 1.448

2024-04-05 15:06:21,588 - ==> Best [Top1: 60.420   Top5: 86.920   Sparsity:0.00   Params: 347840 on epoch: 36]
2024-04-05 15:06:21,588 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:06:21,621 - 

2024-04-05 15:06:21,621 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:06:26,370 - Epoch: [39][  100/  500]    Overall Loss 0.952075    Objective Loss 0.952075                                        LR 0.001000    Time 0.047428    
2024-04-05 15:06:30,496 - Epoch: [39][  200/  500]    Overall Loss 0.969809    Objective Loss 0.969809                                        LR 0.001000    Time 0.044314    
2024-04-05 15:06:34,741 - Epoch: [39][  300/  500]    Overall Loss 0.977744    Objective Loss 0.977744                                        LR 0.001000    Time 0.043674    
2024-04-05 15:06:38,914 - Epoch: [39][  400/  500]    Overall Loss 0.978725    Objective Loss 0.978725                                        LR 0.001000    Time 0.043174    
2024-04-05 15:06:43,062 - Epoch: [39][  500/  500]    Overall Loss 0.979013    Objective Loss 0.979013    Top1 71.500000    Top5 92.500000    LR 0.001000    Time 0.042825    
2024-04-05 15:06:43,262 - --- validate (epoch=39)-----------
2024-04-05 15:06:43,263 - 10000 samples (100 per mini-batch)
2024-04-05 15:06:44,626 - Epoch: [39][  100/  100]    Loss 1.496113    Top1 59.180000    Top5 86.170000    
2024-04-05 15:06:44,797 - ==> Top1: 59.180    Top5: 86.170    Loss: 1.496

2024-04-05 15:06:44,803 - ==> Best [Top1: 60.420   Top5: 86.920   Sparsity:0.00   Params: 347840 on epoch: 36]
2024-04-05 15:06:44,803 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:06:44,835 - 

2024-04-05 15:06:44,835 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:06:49,317 - Epoch: [40][  100/  500]    Overall Loss 0.937353    Objective Loss 0.937353                                        LR 0.001000    Time 0.044762    
2024-04-05 15:06:52,338 - Epoch: [40][  200/  500]    Overall Loss 0.949201    Objective Loss 0.949201                                        LR 0.001000    Time 0.037471    
2024-04-05 15:06:55,468 - Epoch: [40][  300/  500]    Overall Loss 0.963174    Objective Loss 0.963174                                        LR 0.001000    Time 0.035397    
2024-04-05 15:06:58,607 - Epoch: [40][  400/  500]    Overall Loss 0.968806    Objective Loss 0.968806                                        LR 0.001000    Time 0.034386    
2024-04-05 15:07:01,683 - Epoch: [40][  500/  500]    Overall Loss 0.970966    Objective Loss 0.970966    Top1 72.500000    Top5 96.000000    LR 0.001000    Time 0.033652    
2024-04-05 15:07:01,805 - --- validate (epoch=40)-----------
2024-04-05 15:07:01,806 - 10000 samples (100 per mini-batch)
2024-04-05 15:07:02,902 - Epoch: [40][  100/  100]    Loss 1.424007    Top1 60.450000    Top5 87.220000    
2024-04-05 15:07:03,047 - ==> Top1: 60.450    Top5: 87.220    Loss: 1.424

2024-04-05 15:07:03,052 - ==> Best [Top1: 60.450   Top5: 87.220   Sparsity:0.00   Params: 347840 on epoch: 40]
2024-04-05 15:07:03,052 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:07:03,089 - 

2024-04-05 15:07:03,089 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:07:07,723 - Epoch: [41][  100/  500]    Overall Loss 0.940018    Objective Loss 0.940018                                        LR 0.001000    Time 0.046289    
2024-04-05 15:07:11,938 - Epoch: [41][  200/  500]    Overall Loss 0.926177    Objective Loss 0.926177                                        LR 0.001000    Time 0.044190    
2024-04-05 15:07:16,151 - Epoch: [41][  300/  500]    Overall Loss 0.935742    Objective Loss 0.935742                                        LR 0.001000    Time 0.043484    
2024-04-05 15:07:20,367 - Epoch: [41][  400/  500]    Overall Loss 0.945420    Objective Loss 0.945420                                        LR 0.001000    Time 0.043140    
2024-04-05 15:07:24,582 - Epoch: [41][  500/  500]    Overall Loss 0.953093    Objective Loss 0.953093    Top1 70.000000    Top5 92.500000    LR 0.001000    Time 0.042931    
2024-04-05 15:07:24,887 - --- validate (epoch=41)-----------
2024-04-05 15:07:24,887 - 10000 samples (100 per mini-batch)
2024-04-05 15:07:26,288 - Epoch: [41][  100/  100]    Loss 1.412765    Top1 61.190000    Top5 87.210000    
2024-04-05 15:07:26,502 - ==> Top1: 61.190    Top5: 87.210    Loss: 1.413

2024-04-05 15:07:26,508 - ==> Best [Top1: 61.190   Top5: 87.210   Sparsity:0.00   Params: 347840 on epoch: 41]
2024-04-05 15:07:26,508 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:07:26,548 - 

2024-04-05 15:07:26,548 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:07:31,579 - Epoch: [42][  100/  500]    Overall Loss 0.928057    Objective Loss 0.928057                                        LR 0.001000    Time 0.050252    
2024-04-05 15:07:35,676 - Epoch: [42][  200/  500]    Overall Loss 0.922808    Objective Loss 0.922808                                        LR 0.001000    Time 0.045585    
2024-04-05 15:07:39,862 - Epoch: [42][  300/  500]    Overall Loss 0.922432    Objective Loss 0.922432                                        LR 0.001000    Time 0.044324    
2024-04-05 15:07:43,980 - Epoch: [42][  400/  500]    Overall Loss 0.938124    Objective Loss 0.938124                                        LR 0.001000    Time 0.043524    
2024-04-05 15:07:48,120 - Epoch: [42][  500/  500]    Overall Loss 0.946113    Objective Loss 0.946113    Top1 75.500000    Top5 93.500000    LR 0.001000    Time 0.043088    
2024-04-05 15:07:48,419 - --- validate (epoch=42)-----------
2024-04-05 15:07:48,420 - 10000 samples (100 per mini-batch)
2024-04-05 15:07:49,907 - Epoch: [42][  100/  100]    Loss 1.450596    Top1 60.070000    Top5 86.950000    
2024-04-05 15:07:50,096 - ==> Top1: 60.070    Top5: 86.950    Loss: 1.451

2024-04-05 15:07:50,101 - ==> Best [Top1: 61.190   Top5: 87.210   Sparsity:0.00   Params: 347840 on epoch: 41]
2024-04-05 15:07:50,102 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:07:50,134 - 

2024-04-05 15:07:50,134 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:07:54,866 - Epoch: [43][  100/  500]    Overall Loss 0.891154    Objective Loss 0.891154                                        LR 0.001000    Time 0.047258    
2024-04-05 15:07:59,085 - Epoch: [43][  200/  500]    Overall Loss 0.914806    Objective Loss 0.914806                                        LR 0.001000    Time 0.044695    
2024-04-05 15:08:03,245 - Epoch: [43][  300/  500]    Overall Loss 0.923391    Objective Loss 0.923391                                        LR 0.001000    Time 0.043645    
2024-04-05 15:08:07,381 - Epoch: [43][  400/  500]    Overall Loss 0.933242    Objective Loss 0.933242                                        LR 0.001000    Time 0.043061    
2024-04-05 15:08:11,316 - Epoch: [43][  500/  500]    Overall Loss 0.940476    Objective Loss 0.940476    Top1 73.000000    Top5 90.500000    LR 0.001000    Time 0.042309    
2024-04-05 15:08:11,487 - --- validate (epoch=43)-----------
2024-04-05 15:08:11,487 - 10000 samples (100 per mini-batch)
2024-04-05 15:08:12,575 - Epoch: [43][  100/  100]    Loss 1.456901    Top1 60.140000    Top5 86.910000    
2024-04-05 15:08:12,708 - ==> Top1: 60.140    Top5: 86.910    Loss: 1.457

2024-04-05 15:08:12,713 - ==> Best [Top1: 61.190   Top5: 87.210   Sparsity:0.00   Params: 347840 on epoch: 41]
2024-04-05 15:08:12,714 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:08:12,746 - 

2024-04-05 15:08:12,746 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:08:17,502 - Epoch: [44][  100/  500]    Overall Loss 0.922691    Objective Loss 0.922691                                        LR 0.001000    Time 0.047499    
2024-04-05 15:08:21,697 - Epoch: [44][  200/  500]    Overall Loss 0.926111    Objective Loss 0.926111                                        LR 0.001000    Time 0.044695    
2024-04-05 15:08:25,619 - Epoch: [44][  300/  500]    Overall Loss 0.920982    Objective Loss 0.920982                                        LR 0.001000    Time 0.042854    
2024-04-05 15:08:29,800 - Epoch: [44][  400/  500]    Overall Loss 0.920194    Objective Loss 0.920194                                        LR 0.001000    Time 0.042578    
2024-04-05 15:08:34,028 - Epoch: [44][  500/  500]    Overall Loss 0.925338    Objective Loss 0.925338    Top1 73.000000    Top5 91.000000    LR 0.001000    Time 0.042509    
2024-04-05 15:08:34,252 - --- validate (epoch=44)-----------
2024-04-05 15:08:34,253 - 10000 samples (100 per mini-batch)
2024-04-05 15:08:35,665 - Epoch: [44][  100/  100]    Loss 1.420606    Top1 61.290000    Top5 87.190000    
2024-04-05 15:08:35,821 - ==> Top1: 61.290    Top5: 87.190    Loss: 1.421

2024-04-05 15:08:35,826 - ==> Best [Top1: 61.290   Top5: 87.190   Sparsity:0.00   Params: 347840 on epoch: 44]
2024-04-05 15:08:35,827 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:08:36,068 - 

2024-04-05 15:08:36,068 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:08:40,851 - Epoch: [45][  100/  500]    Overall Loss 0.867736    Objective Loss 0.867736                                        LR 0.001000    Time 0.047767    
2024-04-05 15:08:45,049 - Epoch: [45][  200/  500]    Overall Loss 0.885291    Objective Loss 0.885291                                        LR 0.001000    Time 0.044850    
2024-04-05 15:08:49,234 - Epoch: [45][  300/  500]    Overall Loss 0.896395    Objective Loss 0.896395                                        LR 0.001000    Time 0.043831    
2024-04-05 15:08:53,472 - Epoch: [45][  400/  500]    Overall Loss 0.905435    Objective Loss 0.905435                                        LR 0.001000    Time 0.043456    
2024-04-05 15:08:57,715 - Epoch: [45][  500/  500]    Overall Loss 0.914792    Objective Loss 0.914792    Top1 70.500000    Top5 93.000000    LR 0.001000    Time 0.043240    
2024-04-05 15:08:57,894 - --- validate (epoch=45)-----------
2024-04-05 15:08:57,895 - 10000 samples (100 per mini-batch)
2024-04-05 15:08:59,293 - Epoch: [45][  100/  100]    Loss 1.396236    Top1 61.300000    Top5 87.790000    
2024-04-05 15:08:59,521 - ==> Top1: 61.300    Top5: 87.790    Loss: 1.396

2024-04-05 15:08:59,526 - ==> Best [Top1: 61.300   Top5: 87.790   Sparsity:0.00   Params: 347840 on epoch: 45]
2024-04-05 15:08:59,526 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:08:59,563 - 

2024-04-05 15:08:59,564 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:09:04,566 - Epoch: [46][  100/  500]    Overall Loss 0.879272    Objective Loss 0.879272                                        LR 0.001000    Time 0.049966    
2024-04-05 15:09:08,559 - Epoch: [46][  200/  500]    Overall Loss 0.891877    Objective Loss 0.891877                                        LR 0.001000    Time 0.044925    
2024-04-05 15:09:12,724 - Epoch: [46][  300/  500]    Overall Loss 0.899544    Objective Loss 0.899544                                        LR 0.001000    Time 0.043813    
2024-04-05 15:09:16,925 - Epoch: [46][  400/  500]    Overall Loss 0.902282    Objective Loss 0.902282                                        LR 0.001000    Time 0.043351    
2024-04-05 15:09:21,120 - Epoch: [46][  500/  500]    Overall Loss 0.911218    Objective Loss 0.911218    Top1 73.000000    Top5 93.000000    LR 0.001000    Time 0.043060    
2024-04-05 15:09:21,419 - --- validate (epoch=46)-----------
2024-04-05 15:09:21,420 - 10000 samples (100 per mini-batch)
2024-04-05 15:09:22,909 - Epoch: [46][  100/  100]    Loss 1.466004    Top1 60.490000    Top5 87.070000    
2024-04-05 15:09:23,125 - ==> Top1: 60.490    Top5: 87.070    Loss: 1.466

2024-04-05 15:09:23,131 - ==> Best [Top1: 61.300   Top5: 87.790   Sparsity:0.00   Params: 347840 on epoch: 45]
2024-04-05 15:09:23,132 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:09:23,163 - 

2024-04-05 15:09:23,164 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:09:27,917 - Epoch: [47][  100/  500]    Overall Loss 0.866830    Objective Loss 0.866830                                        LR 0.001000    Time 0.047480    
2024-04-05 15:09:31,926 - Epoch: [47][  200/  500]    Overall Loss 0.880952    Objective Loss 0.880952                                        LR 0.001000    Time 0.043758    
2024-04-05 15:09:36,111 - Epoch: [47][  300/  500]    Overall Loss 0.890029    Objective Loss 0.890029                                        LR 0.001000    Time 0.043103    
2024-04-05 15:09:40,296 - Epoch: [47][  400/  500]    Overall Loss 0.896444    Objective Loss 0.896444                                        LR 0.001000    Time 0.042775    
2024-04-05 15:09:44,449 - Epoch: [47][  500/  500]    Overall Loss 0.903455    Objective Loss 0.903455    Top1 72.500000    Top5 95.500000    LR 0.001000    Time 0.042515    
2024-04-05 15:09:44,684 - --- validate (epoch=47)-----------
2024-04-05 15:09:44,685 - 10000 samples (100 per mini-batch)
2024-04-05 15:09:46,161 - Epoch: [47][  100/  100]    Loss 1.447892    Top1 60.490000    Top5 87.060000    
2024-04-05 15:09:46,394 - ==> Top1: 60.490    Top5: 87.060    Loss: 1.448

2024-04-05 15:09:46,400 - ==> Best [Top1: 61.300   Top5: 87.790   Sparsity:0.00   Params: 347840 on epoch: 45]
2024-04-05 15:09:46,400 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:09:46,431 - 

2024-04-05 15:09:46,431 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:09:51,437 - Epoch: [48][  100/  500]    Overall Loss 0.879760    Objective Loss 0.879760                                        LR 0.001000    Time 0.049993    
2024-04-05 15:09:55,610 - Epoch: [48][  200/  500]    Overall Loss 0.880317    Objective Loss 0.880317                                        LR 0.001000    Time 0.045837    
2024-04-05 15:09:59,813 - Epoch: [48][  300/  500]    Overall Loss 0.885500    Objective Loss 0.885500                                        LR 0.001000    Time 0.044549    
2024-04-05 15:10:03,981 - Epoch: [48][  400/  500]    Overall Loss 0.886369    Objective Loss 0.886369                                        LR 0.001000    Time 0.043819    
2024-04-05 15:10:08,165 - Epoch: [48][  500/  500]    Overall Loss 0.893733    Objective Loss 0.893733    Top1 67.500000    Top5 94.000000    LR 0.001000    Time 0.043413    
2024-04-05 15:10:08,363 - --- validate (epoch=48)-----------
2024-04-05 15:10:08,363 - 10000 samples (100 per mini-batch)
2024-04-05 15:10:09,830 - Epoch: [48][  100/  100]    Loss 1.393389    Top1 62.200000    Top5 87.520000    
2024-04-05 15:10:10,076 - ==> Top1: 62.200    Top5: 87.520    Loss: 1.393

2024-04-05 15:10:10,082 - ==> Best [Top1: 62.200   Top5: 87.520   Sparsity:0.00   Params: 347840 on epoch: 48]
2024-04-05 15:10:10,082 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:10:10,121 - 

2024-04-05 15:10:10,121 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:10:14,912 - Epoch: [49][  100/  500]    Overall Loss 0.868318    Objective Loss 0.868318                                        LR 0.001000    Time 0.047850    
2024-04-05 15:10:18,975 - Epoch: [49][  200/  500]    Overall Loss 0.866097    Objective Loss 0.866097                                        LR 0.001000    Time 0.044212    
2024-04-05 15:10:23,197 - Epoch: [49][  300/  500]    Overall Loss 0.870845    Objective Loss 0.870845                                        LR 0.001000    Time 0.043530    
2024-04-05 15:10:27,401 - Epoch: [49][  400/  500]    Overall Loss 0.880703    Objective Loss 0.880703                                        LR 0.001000    Time 0.043144    
2024-04-05 15:10:31,574 - Epoch: [49][  500/  500]    Overall Loss 0.884704    Objective Loss 0.884704    Top1 71.500000    Top5 94.500000    LR 0.001000    Time 0.042851    
2024-04-05 15:10:31,783 - --- validate (epoch=49)-----------
2024-04-05 15:10:31,784 - 10000 samples (100 per mini-batch)
2024-04-05 15:10:33,294 - Epoch: [49][  100/  100]    Loss 1.405945    Top1 61.400000    Top5 87.130000    
2024-04-05 15:10:33,549 - ==> Top1: 61.400    Top5: 87.130    Loss: 1.406

2024-04-05 15:10:33,555 - ==> Best [Top1: 62.200   Top5: 87.520   Sparsity:0.00   Params: 347840 on epoch: 48]
2024-04-05 15:10:33,555 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:10:33,587 - 

2024-04-05 15:10:33,587 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:10:38,534 - Epoch: [50][  100/  500]    Overall Loss 0.859604    Objective Loss 0.859604                                        LR 0.001000    Time 0.049408    
2024-04-05 15:10:42,490 - Epoch: [50][  200/  500]    Overall Loss 0.856090    Objective Loss 0.856090                                        LR 0.001000    Time 0.044457    
2024-04-05 15:10:46,709 - Epoch: [50][  300/  500]    Overall Loss 0.866532    Objective Loss 0.866532                                        LR 0.001000    Time 0.043683    
2024-04-05 15:10:50,927 - Epoch: [50][  400/  500]    Overall Loss 0.868407    Objective Loss 0.868407                                        LR 0.001000    Time 0.043294    
2024-04-05 15:10:55,213 - Epoch: [50][  500/  500]    Overall Loss 0.874479    Objective Loss 0.874479    Top1 74.000000    Top5 94.500000    LR 0.001000    Time 0.043195    
2024-04-05 15:10:55,427 - --- validate (epoch=50)-----------
2024-04-05 15:10:55,428 - 10000 samples (100 per mini-batch)
2024-04-05 15:10:56,845 - Epoch: [50][  100/  100]    Loss 1.434939    Top1 61.220000    Top5 87.270000    
2024-04-05 15:10:56,993 - ==> Top1: 61.220    Top5: 87.270    Loss: 1.435

2024-04-05 15:10:56,999 - ==> Best [Top1: 62.200   Top5: 87.520   Sparsity:0.00   Params: 347840 on epoch: 48]
2024-04-05 15:10:57,000 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:10:57,031 - 

2024-04-05 15:10:57,032 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:11:01,808 - Epoch: [51][  100/  500]    Overall Loss 0.827965    Objective Loss 0.827965                                        LR 0.001000    Time 0.047708    
2024-04-05 15:11:06,019 - Epoch: [51][  200/  500]    Overall Loss 0.849910    Objective Loss 0.849910                                        LR 0.001000    Time 0.044882    
2024-04-05 15:11:10,222 - Epoch: [51][  300/  500]    Overall Loss 0.858772    Objective Loss 0.858772                                        LR 0.001000    Time 0.043913    
2024-04-05 15:11:14,438 - Epoch: [51][  400/  500]    Overall Loss 0.869309    Objective Loss 0.869309                                        LR 0.001000    Time 0.043461    
2024-04-05 15:11:18,565 - Epoch: [51][  500/  500]    Overall Loss 0.874451    Objective Loss 0.874451    Top1 70.000000    Top5 90.500000    LR 0.001000    Time 0.043013    
2024-04-05 15:11:18,781 - --- validate (epoch=51)-----------
2024-04-05 15:11:18,782 - 10000 samples (100 per mini-batch)
2024-04-05 15:11:20,083 - Epoch: [51][  100/  100]    Loss 1.418277    Top1 61.290000    Top5 87.500000    
2024-04-05 15:11:20,205 - ==> Top1: 61.290    Top5: 87.500    Loss: 1.418

2024-04-05 15:11:20,210 - ==> Best [Top1: 62.200   Top5: 87.520   Sparsity:0.00   Params: 347840 on epoch: 48]
2024-04-05 15:11:20,211 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:11:20,241 - 

2024-04-05 15:11:20,242 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:11:25,032 - Epoch: [52][  100/  500]    Overall Loss 0.828397    Objective Loss 0.828397                                        LR 0.001000    Time 0.047848    
2024-04-05 15:11:28,962 - Epoch: [52][  200/  500]    Overall Loss 0.837296    Objective Loss 0.837296                                        LR 0.001000    Time 0.043545    
2024-04-05 15:11:32,793 - Epoch: [52][  300/  500]    Overall Loss 0.843791    Objective Loss 0.843791                                        LR 0.001000    Time 0.041784    
2024-04-05 15:11:36,837 - Epoch: [52][  400/  500]    Overall Loss 0.858010    Objective Loss 0.858010                                        LR 0.001000    Time 0.041431    
2024-04-05 15:11:40,641 - Epoch: [52][  500/  500]    Overall Loss 0.864162    Objective Loss 0.864162    Top1 77.000000    Top5 93.000000    LR 0.001000    Time 0.040744    
2024-04-05 15:11:40,858 - --- validate (epoch=52)-----------
2024-04-05 15:11:40,858 - 10000 samples (100 per mini-batch)
2024-04-05 15:11:42,205 - Epoch: [52][  100/  100]    Loss 1.432749    Top1 60.870000    Top5 87.200000    
2024-04-05 15:11:42,363 - ==> Top1: 60.870    Top5: 87.200    Loss: 1.433

2024-04-05 15:11:42,369 - ==> Best [Top1: 62.200   Top5: 87.520   Sparsity:0.00   Params: 347840 on epoch: 48]
2024-04-05 15:11:42,369 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:11:42,402 - 

2024-04-05 15:11:42,403 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:11:46,915 - Epoch: [53][  100/  500]    Overall Loss 0.825698    Objective Loss 0.825698                                        LR 0.001000    Time 0.045067    
2024-04-05 15:11:50,556 - Epoch: [53][  200/  500]    Overall Loss 0.837718    Objective Loss 0.837718                                        LR 0.001000    Time 0.040711    
2024-04-05 15:11:54,684 - Epoch: [53][  300/  500]    Overall Loss 0.846840    Objective Loss 0.846840                                        LR 0.001000    Time 0.040884    
2024-04-05 15:11:58,835 - Epoch: [53][  400/  500]    Overall Loss 0.847202    Objective Loss 0.847202                                        LR 0.001000    Time 0.041025    
2024-04-05 15:12:02,986 - Epoch: [53][  500/  500]    Overall Loss 0.855312    Objective Loss 0.855312    Top1 72.500000    Top5 95.500000    LR 0.001000    Time 0.041113    
2024-04-05 15:12:03,308 - --- validate (epoch=53)-----------
2024-04-05 15:12:03,309 - 10000 samples (100 per mini-batch)
2024-04-05 15:12:04,803 - Epoch: [53][  100/  100]    Loss 1.421819    Top1 61.020000    Top5 87.530000    
2024-04-05 15:12:04,956 - ==> Top1: 61.020    Top5: 87.530    Loss: 1.422

2024-04-05 15:12:04,963 - ==> Best [Top1: 62.200   Top5: 87.520   Sparsity:0.00   Params: 347840 on epoch: 48]
2024-04-05 15:12:04,963 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:12:04,995 - 

2024-04-05 15:12:04,996 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:12:09,715 - Epoch: [54][  100/  500]    Overall Loss 0.810927    Objective Loss 0.810927                                        LR 0.001000    Time 0.047136    
2024-04-05 15:12:13,527 - Epoch: [54][  200/  500]    Overall Loss 0.821809    Objective Loss 0.821809                                        LR 0.001000    Time 0.042600    
2024-04-05 15:12:17,614 - Epoch: [54][  300/  500]    Overall Loss 0.830125    Objective Loss 0.830125                                        LR 0.001000    Time 0.042005    
2024-04-05 15:12:21,790 - Epoch: [54][  400/  500]    Overall Loss 0.839985    Objective Loss 0.839985                                        LR 0.001000    Time 0.041931    
2024-04-05 15:12:25,937 - Epoch: [54][  500/  500]    Overall Loss 0.846912    Objective Loss 0.846912    Top1 77.500000    Top5 93.000000    LR 0.001000    Time 0.041827    
2024-04-05 15:12:26,140 - --- validate (epoch=54)-----------
2024-04-05 15:12:26,141 - 10000 samples (100 per mini-batch)
2024-04-05 15:12:27,538 - Epoch: [54][  100/  100]    Loss 1.419821    Top1 61.650000    Top5 87.760000    
2024-04-05 15:12:27,754 - ==> Top1: 61.650    Top5: 87.760    Loss: 1.420

2024-04-05 15:12:27,758 - ==> Best [Top1: 62.200   Top5: 87.520   Sparsity:0.00   Params: 347840 on epoch: 48]
2024-04-05 15:12:27,758 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:12:27,781 - 

2024-04-05 15:12:27,781 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:12:32,734 - Epoch: [55][  100/  500]    Overall Loss 0.814729    Objective Loss 0.814729                                        LR 0.001000    Time 0.049463    
2024-04-05 15:12:36,329 - Epoch: [55][  200/  500]    Overall Loss 0.824494    Objective Loss 0.824494                                        LR 0.001000    Time 0.042685    
2024-04-05 15:12:40,502 - Epoch: [55][  300/  500]    Overall Loss 0.837865    Objective Loss 0.837865                                        LR 0.001000    Time 0.042344    
2024-04-05 15:12:44,626 - Epoch: [55][  400/  500]    Overall Loss 0.840971    Objective Loss 0.840971                                        LR 0.001000    Time 0.042056    
2024-04-05 15:12:48,762 - Epoch: [55][  500/  500]    Overall Loss 0.840213    Objective Loss 0.840213    Top1 76.000000    Top5 96.500000    LR 0.001000    Time 0.041907    
2024-04-05 15:12:49,042 - --- validate (epoch=55)-----------
2024-04-05 15:12:49,043 - 10000 samples (100 per mini-batch)
2024-04-05 15:12:50,444 - Epoch: [55][  100/  100]    Loss 1.441477    Top1 61.260000    Top5 87.160000    
2024-04-05 15:12:50,675 - ==> Top1: 61.260    Top5: 87.160    Loss: 1.441

2024-04-05 15:12:50,681 - ==> Best [Top1: 62.200   Top5: 87.520   Sparsity:0.00   Params: 347840 on epoch: 48]
2024-04-05 15:12:50,681 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:12:50,714 - 

2024-04-05 15:12:50,715 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:12:55,485 - Epoch: [56][  100/  500]    Overall Loss 0.792546    Objective Loss 0.792546                                        LR 0.001000    Time 0.047648    
2024-04-05 15:12:59,321 - Epoch: [56][  200/  500]    Overall Loss 0.806870    Objective Loss 0.806870                                        LR 0.001000    Time 0.042977    
2024-04-05 15:13:03,459 - Epoch: [56][  300/  500]    Overall Loss 0.814153    Objective Loss 0.814153                                        LR 0.001000    Time 0.042426    
2024-04-05 15:13:07,567 - Epoch: [56][  400/  500]    Overall Loss 0.825332    Objective Loss 0.825332                                        LR 0.001000    Time 0.042076    
2024-04-05 15:13:11,726 - Epoch: [56][  500/  500]    Overall Loss 0.831566    Objective Loss 0.831566    Top1 74.000000    Top5 93.500000    LR 0.001000    Time 0.041968    
2024-04-05 15:13:11,997 - --- validate (epoch=56)-----------
2024-04-05 15:13:11,997 - 10000 samples (100 per mini-batch)
2024-04-05 15:13:13,589 - Epoch: [56][  100/  100]    Loss 1.409388    Top1 62.100000    Top5 87.650000    
2024-04-05 15:13:13,748 - ==> Top1: 62.100    Top5: 87.650    Loss: 1.409

2024-04-05 15:13:13,753 - ==> Best [Top1: 62.200   Top5: 87.520   Sparsity:0.00   Params: 347840 on epoch: 48]
2024-04-05 15:13:13,753 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:13:13,785 - 

2024-04-05 15:13:13,785 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:13:18,482 - Epoch: [57][  100/  500]    Overall Loss 0.797200    Objective Loss 0.797200                                        LR 0.001000    Time 0.046910    
2024-04-05 15:13:22,355 - Epoch: [57][  200/  500]    Overall Loss 0.810352    Objective Loss 0.810352                                        LR 0.001000    Time 0.042794    
2024-04-05 15:13:26,379 - Epoch: [57][  300/  500]    Overall Loss 0.821899    Objective Loss 0.821899                                        LR 0.001000    Time 0.041926    
2024-04-05 15:13:30,512 - Epoch: [57][  400/  500]    Overall Loss 0.823765    Objective Loss 0.823765                                        LR 0.001000    Time 0.041761    
2024-04-05 15:13:34,639 - Epoch: [57][  500/  500]    Overall Loss 0.828594    Objective Loss 0.828594    Top1 81.500000    Top5 97.000000    LR 0.001000    Time 0.041653    
2024-04-05 15:13:34,858 - --- validate (epoch=57)-----------
2024-04-05 15:13:34,859 - 10000 samples (100 per mini-batch)
2024-04-05 15:13:36,299 - Epoch: [57][  100/  100]    Loss 1.420507    Top1 61.410000    Top5 87.420000    
2024-04-05 15:13:36,460 - ==> Top1: 61.410    Top5: 87.420    Loss: 1.421

2024-04-05 15:13:36,466 - ==> Best [Top1: 62.200   Top5: 87.520   Sparsity:0.00   Params: 347840 on epoch: 48]
2024-04-05 15:13:36,466 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:13:36,498 - 

2024-04-05 15:13:36,499 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:13:41,176 - Epoch: [58][  100/  500]    Overall Loss 0.807288    Objective Loss 0.807288                                        LR 0.001000    Time 0.046712    
2024-04-05 15:13:45,302 - Epoch: [58][  200/  500]    Overall Loss 0.806398    Objective Loss 0.806398                                        LR 0.001000    Time 0.043961    
2024-04-05 15:13:49,237 - Epoch: [58][  300/  500]    Overall Loss 0.802082    Objective Loss 0.802082                                        LR 0.001000    Time 0.042406    
2024-04-05 15:13:53,346 - Epoch: [58][  400/  500]    Overall Loss 0.811295    Objective Loss 0.811295                                        LR 0.001000    Time 0.042064    
2024-04-05 15:13:57,458 - Epoch: [58][  500/  500]    Overall Loss 0.818332    Objective Loss 0.818332    Top1 72.000000    Top5 95.000000    LR 0.001000    Time 0.041866    
2024-04-05 15:13:57,710 - --- validate (epoch=58)-----------
2024-04-05 15:13:57,710 - 10000 samples (100 per mini-batch)
2024-04-05 15:13:59,069 - Epoch: [58][  100/  100]    Loss 1.397580    Top1 62.340000    Top5 87.850000    
2024-04-05 15:13:59,249 - ==> Top1: 62.340    Top5: 87.850    Loss: 1.398

2024-04-05 15:13:59,254 - ==> Best [Top1: 62.340   Top5: 87.850   Sparsity:0.00   Params: 347840 on epoch: 58]
2024-04-05 15:13:59,255 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:13:59,459 - 

2024-04-05 15:13:59,460 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:14:03,663 - Epoch: [59][  100/  500]    Overall Loss 0.787712    Objective Loss 0.787712                                        LR 0.001000    Time 0.041981    
2024-04-05 15:14:07,778 - Epoch: [59][  200/  500]    Overall Loss 0.790006    Objective Loss 0.790006                                        LR 0.001000    Time 0.041540    
2024-04-05 15:14:11,874 - Epoch: [59][  300/  500]    Overall Loss 0.798048    Objective Loss 0.798048                                        LR 0.001000    Time 0.041331    
2024-04-05 15:14:15,968 - Epoch: [59][  400/  500]    Overall Loss 0.805622    Objective Loss 0.805622                                        LR 0.001000    Time 0.041219    
2024-04-05 15:14:20,088 - Epoch: [59][  500/  500]    Overall Loss 0.810546    Objective Loss 0.810546    Top1 74.500000    Top5 97.000000    LR 0.001000    Time 0.041204    
2024-04-05 15:14:20,290 - --- validate (epoch=59)-----------
2024-04-05 15:14:20,291 - 10000 samples (100 per mini-batch)
2024-04-05 15:14:21,740 - Epoch: [59][  100/  100]    Loss 1.424360    Top1 61.790000    Top5 87.420000    
2024-04-05 15:14:21,923 - ==> Top1: 61.790    Top5: 87.420    Loss: 1.424

2024-04-05 15:14:21,929 - ==> Best [Top1: 62.340   Top5: 87.850   Sparsity:0.00   Params: 347840 on epoch: 58]
2024-04-05 15:14:21,929 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:14:21,961 - 

2024-04-05 15:14:21,961 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:14:26,906 - Epoch: [60][  100/  500]    Overall Loss 0.778564    Objective Loss 0.778564                                        LR 0.001000    Time 0.049385    
2024-04-05 15:14:31,038 - Epoch: [60][  200/  500]    Overall Loss 0.778954    Objective Loss 0.778954                                        LR 0.001000    Time 0.045330    
2024-04-05 15:14:35,109 - Epoch: [60][  300/  500]    Overall Loss 0.790789    Objective Loss 0.790789                                        LR 0.001000    Time 0.043772    
2024-04-05 15:14:39,199 - Epoch: [60][  400/  500]    Overall Loss 0.797059    Objective Loss 0.797059                                        LR 0.001000    Time 0.043041    
2024-04-05 15:14:43,324 - Epoch: [60][  500/  500]    Overall Loss 0.807504    Objective Loss 0.807504    Top1 74.500000    Top5 96.500000    LR 0.001000    Time 0.042674    
2024-04-05 15:14:43,623 - --- validate (epoch=60)-----------
2024-04-05 15:14:43,624 - 10000 samples (100 per mini-batch)
2024-04-05 15:14:45,050 - Epoch: [60][  100/  100]    Loss 1.418286    Top1 61.710000    Top5 87.700000    
2024-04-05 15:14:45,217 - ==> Top1: 61.710    Top5: 87.700    Loss: 1.418

2024-04-05 15:14:45,222 - ==> Best [Top1: 62.340   Top5: 87.850   Sparsity:0.00   Params: 347840 on epoch: 58]
2024-04-05 15:14:45,223 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:14:45,255 - 

2024-04-05 15:14:45,255 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:14:49,955 - Epoch: [61][  100/  500]    Overall Loss 0.762522    Objective Loss 0.762522                                        LR 0.001000    Time 0.046947    
2024-04-05 15:14:54,074 - Epoch: [61][  200/  500]    Overall Loss 0.776451    Objective Loss 0.776451                                        LR 0.001000    Time 0.044040    
2024-04-05 15:14:58,163 - Epoch: [61][  300/  500]    Overall Loss 0.784527    Objective Loss 0.784527                                        LR 0.001000    Time 0.042973    
2024-04-05 15:15:02,221 - Epoch: [61][  400/  500]    Overall Loss 0.790749    Objective Loss 0.790749                                        LR 0.001000    Time 0.042362    
2024-04-05 15:15:06,266 - Epoch: [61][  500/  500]    Overall Loss 0.796509    Objective Loss 0.796509    Top1 74.000000    Top5 95.500000    LR 0.001000    Time 0.041970    
2024-04-05 15:15:06,466 - --- validate (epoch=61)-----------
2024-04-05 15:15:06,467 - 10000 samples (100 per mini-batch)
2024-04-05 15:15:07,877 - Epoch: [61][  100/  100]    Loss 1.445700    Top1 61.070000    Top5 87.440000    
2024-04-05 15:15:08,066 - ==> Top1: 61.070    Top5: 87.440    Loss: 1.446

2024-04-05 15:15:08,071 - ==> Best [Top1: 62.340   Top5: 87.850   Sparsity:0.00   Params: 347840 on epoch: 58]
2024-04-05 15:15:08,071 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:15:08,105 - 

2024-04-05 15:15:08,105 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:15:12,994 - Epoch: [62][  100/  500]    Overall Loss 0.763002    Objective Loss 0.763002                                        LR 0.001000    Time 0.048831    
2024-04-05 15:15:17,112 - Epoch: [62][  200/  500]    Overall Loss 0.772749    Objective Loss 0.772749                                        LR 0.001000    Time 0.044976    
2024-04-05 15:15:21,071 - Epoch: [62][  300/  500]    Overall Loss 0.780885    Objective Loss 0.780885                                        LR 0.001000    Time 0.043165    
2024-04-05 15:15:25,162 - Epoch: [62][  400/  500]    Overall Loss 0.789160    Objective Loss 0.789160                                        LR 0.001000    Time 0.042589    
2024-04-05 15:15:29,271 - Epoch: [62][  500/  500]    Overall Loss 0.795578    Objective Loss 0.795578    Top1 74.000000    Top5 95.000000    LR 0.001000    Time 0.042280    
2024-04-05 15:15:29,461 - --- validate (epoch=62)-----------
2024-04-05 15:15:29,463 - 10000 samples (100 per mini-batch)
2024-04-05 15:15:30,958 - Epoch: [62][  100/  100]    Loss 1.439474    Top1 61.900000    Top5 87.290000    
2024-04-05 15:15:31,170 - ==> Top1: 61.900    Top5: 87.290    Loss: 1.439

2024-04-05 15:15:31,176 - ==> Best [Top1: 62.340   Top5: 87.850   Sparsity:0.00   Params: 347840 on epoch: 58]
2024-04-05 15:15:31,177 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:15:31,208 - 

2024-04-05 15:15:31,208 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:15:35,900 - Epoch: [63][  100/  500]    Overall Loss 0.762064    Objective Loss 0.762064                                        LR 0.001000    Time 0.046864    
2024-04-05 15:15:40,059 - Epoch: [63][  200/  500]    Overall Loss 0.761421    Objective Loss 0.761421                                        LR 0.001000    Time 0.044200    
2024-04-05 15:15:44,223 - Epoch: [63][  300/  500]    Overall Loss 0.776700    Objective Loss 0.776700                                        LR 0.001000    Time 0.043328    
2024-04-05 15:15:47,717 - Epoch: [63][  400/  500]    Overall Loss 0.784328    Objective Loss 0.784328                                        LR 0.001000    Time 0.041220    
2024-04-05 15:15:51,845 - Epoch: [63][  500/  500]    Overall Loss 0.786586    Objective Loss 0.786586    Top1 74.500000    Top5 92.500000    LR 0.001000    Time 0.041223    
2024-04-05 15:15:52,067 - --- validate (epoch=63)-----------
2024-04-05 15:15:52,068 - 10000 samples (100 per mini-batch)
2024-04-05 15:15:53,518 - Epoch: [63][  100/  100]    Loss 1.406978    Top1 61.880000    Top5 87.870000    
2024-04-05 15:15:53,697 - ==> Top1: 61.880    Top5: 87.870    Loss: 1.407

2024-04-05 15:15:53,700 - ==> Best [Top1: 62.340   Top5: 87.850   Sparsity:0.00   Params: 347840 on epoch: 58]
2024-04-05 15:15:53,700 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:15:53,722 - 

2024-04-05 15:15:53,723 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:15:58,036 - Epoch: [64][  100/  500]    Overall Loss 0.731974    Objective Loss 0.731974                                        LR 0.001000    Time 0.043080    
2024-04-05 15:16:01,934 - Epoch: [64][  200/  500]    Overall Loss 0.760650    Objective Loss 0.760650                                        LR 0.001000    Time 0.041004    
2024-04-05 15:16:06,012 - Epoch: [64][  300/  500]    Overall Loss 0.764145    Objective Loss 0.764145                                        LR 0.001000    Time 0.040912    
2024-04-05 15:16:10,036 - Epoch: [64][  400/  500]    Overall Loss 0.771678    Objective Loss 0.771678                                        LR 0.001000    Time 0.040731    
2024-04-05 15:16:14,160 - Epoch: [64][  500/  500]    Overall Loss 0.775975    Objective Loss 0.775975    Top1 82.500000    Top5 97.500000    LR 0.001000    Time 0.040823    
2024-04-05 15:16:14,384 - --- validate (epoch=64)-----------
2024-04-05 15:16:14,385 - 10000 samples (100 per mini-batch)
2024-04-05 15:16:16,055 - Epoch: [64][  100/  100]    Loss 1.413483    Top1 61.750000    Top5 87.910000    
2024-04-05 15:16:16,211 - ==> Top1: 61.750    Top5: 87.910    Loss: 1.413

2024-04-05 15:16:16,215 - ==> Best [Top1: 62.340   Top5: 87.850   Sparsity:0.00   Params: 347840 on epoch: 58]
2024-04-05 15:16:16,215 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:16:16,236 - 

2024-04-05 15:16:16,236 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:16:20,901 - Epoch: [65][  100/  500]    Overall Loss 0.742638    Objective Loss 0.742638                                        LR 0.001000    Time 0.046592    
2024-04-05 15:16:25,010 - Epoch: [65][  200/  500]    Overall Loss 0.742838    Objective Loss 0.742838                                        LR 0.001000    Time 0.043817    
2024-04-05 15:16:29,134 - Epoch: [65][  300/  500]    Overall Loss 0.758294    Objective Loss 0.758294                                        LR 0.001000    Time 0.042938    
2024-04-05 15:16:33,223 - Epoch: [65][  400/  500]    Overall Loss 0.770304    Objective Loss 0.770304                                        LR 0.001000    Time 0.042413    
2024-04-05 15:16:37,357 - Epoch: [65][  500/  500]    Overall Loss 0.773436    Objective Loss 0.773436    Top1 75.500000    Top5 96.000000    LR 0.001000    Time 0.042190    
2024-04-05 15:16:37,616 - --- validate (epoch=65)-----------
2024-04-05 15:16:37,618 - 10000 samples (100 per mini-batch)
2024-04-05 15:16:39,050 - Epoch: [65][  100/  100]    Loss 1.438316    Top1 61.660000    Top5 87.810000    
2024-04-05 15:16:39,218 - ==> Top1: 61.660    Top5: 87.810    Loss: 1.438

2024-04-05 15:16:39,223 - ==> Best [Top1: 62.340   Top5: 87.850   Sparsity:0.00   Params: 347840 on epoch: 58]
2024-04-05 15:16:39,224 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:16:39,255 - 

2024-04-05 15:16:39,255 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:16:44,130 - Epoch: [66][  100/  500]    Overall Loss 0.752470    Objective Loss 0.752470                                        LR 0.001000    Time 0.048698    
2024-04-05 15:16:48,264 - Epoch: [66][  200/  500]    Overall Loss 0.759781    Objective Loss 0.759781                                        LR 0.001000    Time 0.044993    
2024-04-05 15:16:51,924 - Epoch: [66][  300/  500]    Overall Loss 0.759882    Objective Loss 0.759882                                        LR 0.001000    Time 0.042182    
2024-04-05 15:16:55,779 - Epoch: [66][  400/  500]    Overall Loss 0.766010    Objective Loss 0.766010                                        LR 0.001000    Time 0.041260    
2024-04-05 15:16:59,627 - Epoch: [66][  500/  500]    Overall Loss 0.768595    Objective Loss 0.768595    Top1 68.500000    Top5 93.000000    LR 0.001000    Time 0.040695    
2024-04-05 15:16:59,842 - --- validate (epoch=66)-----------
2024-04-05 15:16:59,842 - 10000 samples (100 per mini-batch)
2024-04-05 15:17:01,240 - Epoch: [66][  100/  100]    Loss 1.451124    Top1 61.700000    Top5 86.850000    
2024-04-05 15:17:01,418 - ==> Top1: 61.700    Top5: 86.850    Loss: 1.451

2024-04-05 15:17:01,423 - ==> Best [Top1: 62.340   Top5: 87.850   Sparsity:0.00   Params: 347840 on epoch: 58]
2024-04-05 15:17:01,423 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:17:01,455 - 

2024-04-05 15:17:01,455 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:17:06,140 - Epoch: [67][  100/  500]    Overall Loss 0.742626    Objective Loss 0.742626                                        LR 0.001000    Time 0.046791    
2024-04-05 15:17:10,299 - Epoch: [67][  200/  500]    Overall Loss 0.737167    Objective Loss 0.737167                                        LR 0.001000    Time 0.044162    
2024-04-05 15:17:14,440 - Epoch: [67][  300/  500]    Overall Loss 0.742335    Objective Loss 0.742335                                        LR 0.001000    Time 0.043228    
2024-04-05 15:17:18,571 - Epoch: [67][  400/  500]    Overall Loss 0.752361    Objective Loss 0.752361                                        LR 0.001000    Time 0.042735    
2024-04-05 15:17:22,333 - Epoch: [67][  500/  500]    Overall Loss 0.760403    Objective Loss 0.760403    Top1 80.500000    Top5 97.500000    LR 0.001000    Time 0.041701    
2024-04-05 15:17:22,570 - --- validate (epoch=67)-----------
2024-04-05 15:17:22,571 - 10000 samples (100 per mini-batch)
2024-04-05 15:17:24,041 - Epoch: [67][  100/  100]    Loss 1.434768    Top1 61.700000    Top5 87.380000    
2024-04-05 15:17:24,281 - ==> Top1: 61.700    Top5: 87.380    Loss: 1.435

2024-04-05 15:17:24,287 - ==> Best [Top1: 62.340   Top5: 87.850   Sparsity:0.00   Params: 347840 on epoch: 58]
2024-04-05 15:17:24,288 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:17:24,319 - 

2024-04-05 15:17:24,319 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:17:29,213 - Epoch: [68][  100/  500]    Overall Loss 0.744005    Objective Loss 0.744005                                        LR 0.001000    Time 0.048880    
2024-04-05 15:17:33,350 - Epoch: [68][  200/  500]    Overall Loss 0.750633    Objective Loss 0.750633                                        LR 0.001000    Time 0.045099    
2024-04-05 15:17:37,499 - Epoch: [68][  300/  500]    Overall Loss 0.754010    Objective Loss 0.754010                                        LR 0.001000    Time 0.043878    
2024-04-05 15:17:41,637 - Epoch: [68][  400/  500]    Overall Loss 0.755689    Objective Loss 0.755689                                        LR 0.001000    Time 0.043238    
2024-04-05 15:17:45,621 - Epoch: [68][  500/  500]    Overall Loss 0.758407    Objective Loss 0.758407    Top1 78.500000    Top5 96.000000    LR 0.001000    Time 0.042550    
2024-04-05 15:17:45,802 - --- validate (epoch=68)-----------
2024-04-05 15:17:45,802 - 10000 samples (100 per mini-batch)
2024-04-05 15:17:47,211 - Epoch: [68][  100/  100]    Loss 1.417361    Top1 61.720000    Top5 87.860000    
2024-04-05 15:17:47,435 - ==> Top1: 61.720    Top5: 87.860    Loss: 1.417

2024-04-05 15:17:47,440 - ==> Best [Top1: 62.340   Top5: 87.850   Sparsity:0.00   Params: 347840 on epoch: 58]
2024-04-05 15:17:47,440 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:17:47,471 - 

2024-04-05 15:17:47,472 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:17:52,189 - Epoch: [69][  100/  500]    Overall Loss 0.721700    Objective Loss 0.721700                                        LR 0.001000    Time 0.047120    
2024-04-05 15:17:56,307 - Epoch: [69][  200/  500]    Overall Loss 0.725635    Objective Loss 0.725635                                        LR 0.001000    Time 0.044119    
2024-04-05 15:18:00,442 - Epoch: [69][  300/  500]    Overall Loss 0.741326    Objective Loss 0.741326                                        LR 0.001000    Time 0.043180    
2024-04-05 15:18:04,594 - Epoch: [69][  400/  500]    Overall Loss 0.747732    Objective Loss 0.747732                                        LR 0.001000    Time 0.042750    
2024-04-05 15:18:08,550 - Epoch: [69][  500/  500]    Overall Loss 0.753916    Objective Loss 0.753916    Top1 73.500000    Top5 96.000000    LR 0.001000    Time 0.042102    
2024-04-05 15:18:08,776 - --- validate (epoch=69)-----------
2024-04-05 15:18:08,777 - 10000 samples (100 per mini-batch)
2024-04-05 15:18:10,229 - Epoch: [69][  100/  100]    Loss 1.378750    Top1 62.850000    Top5 88.280000    
2024-04-05 15:18:10,418 - ==> Top1: 62.850    Top5: 88.280    Loss: 1.379

2024-04-05 15:18:10,421 - ==> Best [Top1: 62.850   Top5: 88.280   Sparsity:0.00   Params: 347840 on epoch: 69]
2024-04-05 15:18:10,421 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:18:10,454 - 

2024-04-05 15:18:10,454 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:18:15,600 - Epoch: [70][  100/  500]    Overall Loss 0.726166    Objective Loss 0.726166                                        LR 0.001000    Time 0.051390    
2024-04-05 15:18:19,917 - Epoch: [70][  200/  500]    Overall Loss 0.727652    Objective Loss 0.727652                                        LR 0.001000    Time 0.047246    
2024-04-05 15:18:24,231 - Epoch: [70][  300/  500]    Overall Loss 0.736788    Objective Loss 0.736788                                        LR 0.001000    Time 0.045859    
2024-04-05 15:18:28,496 - Epoch: [70][  400/  500]    Overall Loss 0.742677    Objective Loss 0.742677                                        LR 0.001000    Time 0.045043    
2024-04-05 15:18:32,624 - Epoch: [70][  500/  500]    Overall Loss 0.746962    Objective Loss 0.746962    Top1 78.000000    Top5 95.000000    LR 0.001000    Time 0.044279    
2024-04-05 15:18:32,815 - --- validate (epoch=70)-----------
2024-04-05 15:18:32,815 - 10000 samples (100 per mini-batch)
2024-04-05 15:18:34,338 - Epoch: [70][  100/  100]    Loss 1.428419    Top1 62.110000    Top5 87.770000    
2024-04-05 15:18:34,494 - ==> Top1: 62.110    Top5: 87.770    Loss: 1.428

2024-04-05 15:18:34,500 - ==> Best [Top1: 62.850   Top5: 88.280   Sparsity:0.00   Params: 347840 on epoch: 69]
2024-04-05 15:18:34,500 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:18:34,533 - 

2024-04-05 15:18:34,533 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:18:39,187 - Epoch: [71][  100/  500]    Overall Loss 0.699762    Objective Loss 0.699762                                        LR 0.001000    Time 0.046488    
2024-04-05 15:18:43,348 - Epoch: [71][  200/  500]    Overall Loss 0.716112    Objective Loss 0.716112                                        LR 0.001000    Time 0.044017    
2024-04-05 15:18:47,521 - Epoch: [71][  300/  500]    Overall Loss 0.727844    Objective Loss 0.727844                                        LR 0.001000    Time 0.043236    
2024-04-05 15:18:51,659 - Epoch: [71][  400/  500]    Overall Loss 0.735251    Objective Loss 0.735251                                        LR 0.001000    Time 0.042758    
2024-04-05 15:18:55,813 - Epoch: [71][  500/  500]    Overall Loss 0.739890    Objective Loss 0.739890    Top1 84.500000    Top5 98.000000    LR 0.001000    Time 0.042504    
2024-04-05 15:18:55,995 - --- validate (epoch=71)-----------
2024-04-05 15:18:55,997 - 10000 samples (100 per mini-batch)
2024-04-05 15:18:57,857 - Epoch: [71][  100/  100]    Loss 1.407327    Top1 62.530000    Top5 87.870000    
2024-04-05 15:18:57,986 - ==> Top1: 62.530    Top5: 87.870    Loss: 1.407

2024-04-05 15:18:57,991 - ==> Best [Top1: 62.850   Top5: 88.280   Sparsity:0.00   Params: 347840 on epoch: 69]
2024-04-05 15:18:57,992 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:18:58,022 - 

2024-04-05 15:18:58,023 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:19:03,104 - Epoch: [72][  100/  500]    Overall Loss 0.708326    Objective Loss 0.708326                                        LR 0.001000    Time 0.050759    
2024-04-05 15:19:07,254 - Epoch: [72][  200/  500]    Overall Loss 0.719720    Objective Loss 0.719720                                        LR 0.001000    Time 0.046098    
2024-04-05 15:19:11,308 - Epoch: [72][  300/  500]    Overall Loss 0.725317    Objective Loss 0.725317                                        LR 0.001000    Time 0.044230    
2024-04-05 15:19:15,352 - Epoch: [72][  400/  500]    Overall Loss 0.734424    Objective Loss 0.734424                                        LR 0.001000    Time 0.043268    
2024-04-05 15:19:19,487 - Epoch: [72][  500/  500]    Overall Loss 0.739481    Objective Loss 0.739481    Top1 73.500000    Top5 98.000000    LR 0.001000    Time 0.042874    
2024-04-05 15:19:19,661 - --- validate (epoch=72)-----------
2024-04-05 15:19:19,661 - 10000 samples (100 per mini-batch)
2024-04-05 15:19:21,031 - Epoch: [72][  100/  100]    Loss 1.433278    Top1 62.140000    Top5 87.890000    
2024-04-05 15:19:21,271 - ==> Top1: 62.140    Top5: 87.890    Loss: 1.433

2024-04-05 15:19:21,278 - ==> Best [Top1: 62.850   Top5: 88.280   Sparsity:0.00   Params: 347840 on epoch: 69]
2024-04-05 15:19:21,278 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:19:21,311 - 

2024-04-05 15:19:21,312 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:19:25,614 - Epoch: [73][  100/  500]    Overall Loss 0.707234    Objective Loss 0.707234                                        LR 0.001000    Time 0.042971    
2024-04-05 15:19:29,828 - Epoch: [73][  200/  500]    Overall Loss 0.708474    Objective Loss 0.708474                                        LR 0.001000    Time 0.042524    
2024-04-05 15:19:33,945 - Epoch: [73][  300/  500]    Overall Loss 0.714280    Objective Loss 0.714280                                        LR 0.001000    Time 0.042054    
2024-04-05 15:19:38,083 - Epoch: [73][  400/  500]    Overall Loss 0.722571    Objective Loss 0.722571                                        LR 0.001000    Time 0.041873    
2024-04-05 15:19:42,228 - Epoch: [73][  500/  500]    Overall Loss 0.732075    Objective Loss 0.732075    Top1 78.500000    Top5 98.000000    LR 0.001000    Time 0.041778    
2024-04-05 15:19:42,494 - --- validate (epoch=73)-----------
2024-04-05 15:19:42,495 - 10000 samples (100 per mini-batch)
2024-04-05 15:19:43,969 - Epoch: [73][  100/  100]    Loss 1.427077    Top1 61.890000    Top5 87.730000    
2024-04-05 15:19:44,124 - ==> Top1: 61.890    Top5: 87.730    Loss: 1.427

2024-04-05 15:19:44,130 - ==> Best [Top1: 62.850   Top5: 88.280   Sparsity:0.00   Params: 347840 on epoch: 69]
2024-04-05 15:19:44,131 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:19:44,162 - 

2024-04-05 15:19:44,163 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:19:48,681 - Epoch: [74][  100/  500]    Overall Loss 0.701114    Objective Loss 0.701114                                        LR 0.001000    Time 0.045133    
2024-04-05 15:19:52,776 - Epoch: [74][  200/  500]    Overall Loss 0.706627    Objective Loss 0.706627                                        LR 0.001000    Time 0.043012    
2024-04-05 15:19:56,859 - Epoch: [74][  300/  500]    Overall Loss 0.712178    Objective Loss 0.712178                                        LR 0.001000    Time 0.042266    
2024-04-05 15:20:00,974 - Epoch: [74][  400/  500]    Overall Loss 0.719529    Objective Loss 0.719529                                        LR 0.001000    Time 0.041974    
2024-04-05 15:20:05,010 - Epoch: [74][  500/  500]    Overall Loss 0.723818    Objective Loss 0.723818    Top1 77.500000    Top5 94.500000    LR 0.001000    Time 0.041641    
2024-04-05 15:20:05,240 - --- validate (epoch=74)-----------
2024-04-05 15:20:05,241 - 10000 samples (100 per mini-batch)
2024-04-05 15:20:06,705 - Epoch: [74][  100/  100]    Loss 1.420302    Top1 61.940000    Top5 87.900000    
2024-04-05 15:20:06,848 - ==> Top1: 61.940    Top5: 87.900    Loss: 1.420

2024-04-05 15:20:06,858 - ==> Best [Top1: 62.850   Top5: 88.280   Sparsity:0.00   Params: 347840 on epoch: 69]
2024-04-05 15:20:06,859 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:20:06,890 - 

2024-04-05 15:20:06,891 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:20:11,393 - Epoch: [75][  100/  500]    Overall Loss 0.710091    Objective Loss 0.710091                                        LR 0.001000    Time 0.044963    
2024-04-05 15:20:15,499 - Epoch: [75][  200/  500]    Overall Loss 0.717703    Objective Loss 0.717703                                        LR 0.001000    Time 0.042987    
2024-04-05 15:20:19,586 - Epoch: [75][  300/  500]    Overall Loss 0.715782    Objective Loss 0.715782                                        LR 0.001000    Time 0.042264    
2024-04-05 15:20:23,697 - Epoch: [75][  400/  500]    Overall Loss 0.721206    Objective Loss 0.721206                                        LR 0.001000    Time 0.041963    
2024-04-05 15:20:27,756 - Epoch: [75][  500/  500]    Overall Loss 0.724585    Objective Loss 0.724585    Top1 75.500000    Top5 98.000000    LR 0.001000    Time 0.041678    
2024-04-05 15:20:27,947 - --- validate (epoch=75)-----------
2024-04-05 15:20:27,947 - 10000 samples (100 per mini-batch)
2024-04-05 15:20:29,362 - Epoch: [75][  100/  100]    Loss 1.432107    Top1 62.290000    Top5 87.780000    
2024-04-05 15:20:29,589 - ==> Top1: 62.290    Top5: 87.780    Loss: 1.432

2024-04-05 15:20:29,592 - ==> Best [Top1: 62.850   Top5: 88.280   Sparsity:0.00   Params: 347840 on epoch: 69]
2024-04-05 15:20:29,593 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:20:29,616 - 

2024-04-05 15:20:29,616 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:20:34,272 - Epoch: [76][  100/  500]    Overall Loss 0.681772    Objective Loss 0.681772                                        LR 0.001000    Time 0.046511    
2024-04-05 15:20:38,111 - Epoch: [76][  200/  500]    Overall Loss 0.700770    Objective Loss 0.700770                                        LR 0.001000    Time 0.042426    
2024-04-05 15:20:42,250 - Epoch: [76][  300/  500]    Overall Loss 0.703928    Objective Loss 0.703928                                        LR 0.001000    Time 0.042062    
2024-04-05 15:20:46,371 - Epoch: [76][  400/  500]    Overall Loss 0.711971    Objective Loss 0.711971                                        LR 0.001000    Time 0.041835    
2024-04-05 15:20:50,495 - Epoch: [76][  500/  500]    Overall Loss 0.718980    Objective Loss 0.718980    Top1 72.500000    Top5 97.000000    LR 0.001000    Time 0.041706    
2024-04-05 15:20:50,752 - --- validate (epoch=76)-----------
2024-04-05 15:20:50,752 - 10000 samples (100 per mini-batch)
2024-04-05 15:20:52,182 - Epoch: [76][  100/  100]    Loss 1.452133    Top1 61.430000    Top5 87.490000    
2024-04-05 15:20:52,412 - ==> Top1: 61.430    Top5: 87.490    Loss: 1.452

2024-04-05 15:20:52,417 - ==> Best [Top1: 62.850   Top5: 88.280   Sparsity:0.00   Params: 347840 on epoch: 69]
2024-04-05 15:20:52,418 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:20:52,449 - 

2024-04-05 15:20:52,449 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:20:57,212 - Epoch: [77][  100/  500]    Overall Loss 0.672590    Objective Loss 0.672590                                        LR 0.001000    Time 0.047577    
2024-04-05 15:21:01,259 - Epoch: [77][  200/  500]    Overall Loss 0.687662    Objective Loss 0.687662                                        LR 0.001000    Time 0.043995    
2024-04-05 15:21:05,440 - Epoch: [77][  300/  500]    Overall Loss 0.692061    Objective Loss 0.692061                                        LR 0.001000    Time 0.043251    
2024-04-05 15:21:09,629 - Epoch: [77][  400/  500]    Overall Loss 0.703181    Objective Loss 0.703181                                        LR 0.001000    Time 0.042897    
2024-04-05 15:21:13,741 - Epoch: [77][  500/  500]    Overall Loss 0.709002    Objective Loss 0.709002    Top1 76.500000    Top5 98.500000    LR 0.001000    Time 0.042533    
2024-04-05 15:21:13,906 - --- validate (epoch=77)-----------
2024-04-05 15:21:13,906 - 10000 samples (100 per mini-batch)
2024-04-05 15:21:15,301 - Epoch: [77][  100/  100]    Loss 1.402082    Top1 62.950000    Top5 87.980000    
2024-04-05 15:21:15,487 - ==> Top1: 62.950    Top5: 87.980    Loss: 1.402

2024-04-05 15:21:15,492 - ==> Best [Top1: 62.950   Top5: 87.980   Sparsity:0.00   Params: 347840 on epoch: 77]
2024-04-05 15:21:15,493 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:21:15,531 - 

2024-04-05 15:21:15,531 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:21:20,508 - Epoch: [78][  100/  500]    Overall Loss 0.669042    Objective Loss 0.669042                                        LR 0.001000    Time 0.049708    
2024-04-05 15:21:24,349 - Epoch: [78][  200/  500]    Overall Loss 0.697156    Objective Loss 0.697156                                        LR 0.001000    Time 0.044033    
2024-04-05 15:21:28,494 - Epoch: [78][  300/  500]    Overall Loss 0.693171    Objective Loss 0.693171                                        LR 0.001000    Time 0.043154    
2024-04-05 15:21:32,614 - Epoch: [78][  400/  500]    Overall Loss 0.696733    Objective Loss 0.696733                                        LR 0.001000    Time 0.042654    
2024-04-05 15:21:36,782 - Epoch: [78][  500/  500]    Overall Loss 0.702803    Objective Loss 0.702803    Top1 75.500000    Top5 97.000000    LR 0.001000    Time 0.042448    
2024-04-05 15:21:36,974 - --- validate (epoch=78)-----------
2024-04-05 15:21:36,975 - 10000 samples (100 per mini-batch)
2024-04-05 15:21:38,381 - Epoch: [78][  100/  100]    Loss 1.439206    Top1 61.420000    Top5 87.770000    
2024-04-05 15:21:38,541 - ==> Top1: 61.420    Top5: 87.770    Loss: 1.439

2024-04-05 15:21:38,547 - ==> Best [Top1: 62.950   Top5: 87.980   Sparsity:0.00   Params: 347840 on epoch: 77]
2024-04-05 15:21:38,548 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:21:38,580 - 

2024-04-05 15:21:38,580 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:21:43,315 - Epoch: [79][  100/  500]    Overall Loss 0.690162    Objective Loss 0.690162                                        LR 0.001000    Time 0.047290    
2024-04-05 15:21:47,150 - Epoch: [79][  200/  500]    Overall Loss 0.693952    Objective Loss 0.693952                                        LR 0.001000    Time 0.042796    
2024-04-05 15:21:50,941 - Epoch: [79][  300/  500]    Overall Loss 0.696074    Objective Loss 0.696074                                        LR 0.001000    Time 0.041152    
2024-04-05 15:21:55,024 - Epoch: [79][  400/  500]    Overall Loss 0.699758    Objective Loss 0.699758                                        LR 0.001000    Time 0.041056    
2024-04-05 15:21:59,135 - Epoch: [79][  500/  500]    Overall Loss 0.705380    Objective Loss 0.705380    Top1 78.500000    Top5 97.000000    LR 0.001000    Time 0.041056    
2024-04-05 15:21:59,307 - --- validate (epoch=79)-----------
2024-04-05 15:21:59,307 - 10000 samples (100 per mini-batch)
2024-04-05 15:22:00,675 - Epoch: [79][  100/  100]    Loss 1.428934    Top1 62.240000    Top5 87.820000    
2024-04-05 15:22:00,882 - ==> Top1: 62.240    Top5: 87.820    Loss: 1.429

2024-04-05 15:22:00,888 - ==> Best [Top1: 62.950   Top5: 87.980   Sparsity:0.00   Params: 347840 on epoch: 77]
2024-04-05 15:22:00,888 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:22:00,920 - 

2024-04-05 15:22:00,920 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:22:05,906 - Epoch: [80][  100/  500]    Overall Loss 0.674435    Objective Loss 0.674435                                        LR 0.001000    Time 0.049806    
2024-04-05 15:22:10,072 - Epoch: [80][  200/  500]    Overall Loss 0.671560    Objective Loss 0.671560                                        LR 0.001000    Time 0.045700    
2024-04-05 15:22:13,806 - Epoch: [80][  300/  500]    Overall Loss 0.680807    Objective Loss 0.680807                                        LR 0.001000    Time 0.042899    
2024-04-05 15:22:17,937 - Epoch: [80][  400/  500]    Overall Loss 0.689825    Objective Loss 0.689825                                        LR 0.001000    Time 0.042489    
2024-04-05 15:22:22,084 - Epoch: [80][  500/  500]    Overall Loss 0.696420    Objective Loss 0.696420    Top1 80.000000    Top5 95.000000    LR 0.001000    Time 0.042275    
2024-04-05 15:22:22,302 - --- validate (epoch=80)-----------
2024-04-05 15:22:22,303 - 10000 samples (100 per mini-batch)
2024-04-05 15:22:23,737 - Epoch: [80][  100/  100]    Loss 1.394966    Top1 63.140000    Top5 88.250000    
2024-04-05 15:22:23,893 - ==> Top1: 63.140    Top5: 88.250    Loss: 1.395

2024-04-05 15:22:23,898 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:22:23,899 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:22:23,937 - 

2024-04-05 15:22:23,937 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:22:28,333 - Epoch: [81][  100/  500]    Overall Loss 0.657311    Objective Loss 0.657311                                        LR 0.001000    Time 0.043902    
2024-04-05 15:22:32,451 - Epoch: [81][  200/  500]    Overall Loss 0.665026    Objective Loss 0.665026                                        LR 0.001000    Time 0.042513    
2024-04-05 15:22:36,359 - Epoch: [81][  300/  500]    Overall Loss 0.675868    Objective Loss 0.675868                                        LR 0.001000    Time 0.041349    
2024-04-05 15:22:40,519 - Epoch: [81][  400/  500]    Overall Loss 0.685313    Objective Loss 0.685313                                        LR 0.001000    Time 0.041401    
2024-04-05 15:22:44,693 - Epoch: [81][  500/  500]    Overall Loss 0.689887    Objective Loss 0.689887    Top1 80.500000    Top5 95.500000    LR 0.001000    Time 0.041457    
2024-04-05 15:22:44,922 - --- validate (epoch=81)-----------
2024-04-05 15:22:44,922 - 10000 samples (100 per mini-batch)
2024-04-05 15:22:46,347 - Epoch: [81][  100/  100]    Loss 1.433855    Top1 62.230000    Top5 87.880000    
2024-04-05 15:22:46,520 - ==> Top1: 62.230    Top5: 87.880    Loss: 1.434

2024-04-05 15:22:46,526 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:22:46,526 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:22:46,557 - 

2024-04-05 15:22:46,557 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:22:51,291 - Epoch: [82][  100/  500]    Overall Loss 0.684736    Objective Loss 0.684736                                        LR 0.001000    Time 0.047280    
2024-04-05 15:22:55,424 - Epoch: [82][  200/  500]    Overall Loss 0.682247    Objective Loss 0.682247                                        LR 0.001000    Time 0.044278    
2024-04-05 15:22:59,273 - Epoch: [82][  300/  500]    Overall Loss 0.684921    Objective Loss 0.684921                                        LR 0.001000    Time 0.042333    
2024-04-05 15:23:03,218 - Epoch: [82][  400/  500]    Overall Loss 0.686876    Objective Loss 0.686876                                        LR 0.001000    Time 0.041601    
2024-04-05 15:23:07,405 - Epoch: [82][  500/  500]    Overall Loss 0.689971    Objective Loss 0.689971    Top1 79.000000    Top5 98.000000    LR 0.001000    Time 0.041644    
2024-04-05 15:23:07,674 - --- validate (epoch=82)-----------
2024-04-05 15:23:07,675 - 10000 samples (100 per mini-batch)
2024-04-05 15:23:09,097 - Epoch: [82][  100/  100]    Loss 1.399294    Top1 62.960000    Top5 88.070000    
2024-04-05 15:23:09,353 - ==> Top1: 62.960    Top5: 88.070    Loss: 1.399

2024-04-05 15:23:09,359 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:23:09,359 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:23:09,391 - 

2024-04-05 15:23:09,392 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:23:14,150 - Epoch: [83][  100/  500]    Overall Loss 0.669294    Objective Loss 0.669294                                        LR 0.001000    Time 0.047530    
2024-04-05 15:23:18,345 - Epoch: [83][  200/  500]    Overall Loss 0.666642    Objective Loss 0.666642                                        LR 0.001000    Time 0.044712    
2024-04-05 15:23:22,484 - Epoch: [83][  300/  500]    Overall Loss 0.676312    Objective Loss 0.676312                                        LR 0.001000    Time 0.043586    
2024-04-05 15:23:26,464 - Epoch: [83][  400/  500]    Overall Loss 0.684589    Objective Loss 0.684589                                        LR 0.001000    Time 0.042627    
2024-04-05 15:23:30,579 - Epoch: [83][  500/  500]    Overall Loss 0.685731    Objective Loss 0.685731    Top1 82.000000    Top5 98.000000    LR 0.001000    Time 0.042322    
2024-04-05 15:23:30,841 - --- validate (epoch=83)-----------
2024-04-05 15:23:30,841 - 10000 samples (100 per mini-batch)
2024-04-05 15:23:32,237 - Epoch: [83][  100/  100]    Loss 1.443818    Top1 61.970000    Top5 87.780000    
2024-04-05 15:23:32,468 - ==> Top1: 61.970    Top5: 87.780    Loss: 1.444

2024-04-05 15:23:32,474 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:23:32,474 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:23:32,506 - 

2024-04-05 15:23:32,506 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:23:37,209 - Epoch: [84][  100/  500]    Overall Loss 0.652782    Objective Loss 0.652782                                        LR 0.001000    Time 0.046974    
2024-04-05 15:23:41,354 - Epoch: [84][  200/  500]    Overall Loss 0.657853    Objective Loss 0.657853                                        LR 0.001000    Time 0.044181    
2024-04-05 15:23:45,478 - Epoch: [84][  300/  500]    Overall Loss 0.666111    Objective Loss 0.666111                                        LR 0.001000    Time 0.043186    
2024-04-05 15:23:49,619 - Epoch: [84][  400/  500]    Overall Loss 0.668965    Objective Loss 0.668965                                        LR 0.001000    Time 0.042727    
2024-04-05 15:23:53,750 - Epoch: [84][  500/  500]    Overall Loss 0.678291    Objective Loss 0.678291    Top1 78.000000    Top5 96.500000    LR 0.001000    Time 0.042434    
2024-04-05 15:23:53,970 - --- validate (epoch=84)-----------
2024-04-05 15:23:53,970 - 10000 samples (100 per mini-batch)
2024-04-05 15:23:55,620 - Epoch: [84][  100/  100]    Loss 1.448661    Top1 61.990000    Top5 87.890000    
2024-04-05 15:23:55,806 - ==> Top1: 61.990    Top5: 87.890    Loss: 1.449

2024-04-05 15:23:55,811 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:23:55,811 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:23:55,843 - 

2024-04-05 15:23:55,843 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:24:00,574 - Epoch: [85][  100/  500]    Overall Loss 0.634337    Objective Loss 0.634337                                        LR 0.001000    Time 0.047254    
2024-04-05 15:24:04,762 - Epoch: [85][  200/  500]    Overall Loss 0.658462    Objective Loss 0.658462                                        LR 0.001000    Time 0.044535    
2024-04-05 15:24:08,965 - Epoch: [85][  300/  500]    Overall Loss 0.665742    Objective Loss 0.665742                                        LR 0.001000    Time 0.043682    
2024-04-05 15:24:12,990 - Epoch: [85][  400/  500]    Overall Loss 0.668672    Objective Loss 0.668672                                        LR 0.001000    Time 0.042813    
2024-04-05 15:24:17,166 - Epoch: [85][  500/  500]    Overall Loss 0.670196    Objective Loss 0.670196    Top1 79.500000    Top5 97.000000    LR 0.001000    Time 0.042590    
2024-04-05 15:24:17,443 - --- validate (epoch=85)-----------
2024-04-05 15:24:17,445 - 10000 samples (100 per mini-batch)
2024-04-05 15:24:18,894 - Epoch: [85][  100/  100]    Loss 1.458622    Top1 61.990000    Top5 87.970000    
2024-04-05 15:24:19,032 - ==> Top1: 61.990    Top5: 87.970    Loss: 1.459

2024-04-05 15:24:19,038 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:24:19,038 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:24:19,069 - 

2024-04-05 15:24:19,069 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:24:23,598 - Epoch: [86][  100/  500]    Overall Loss 0.649896    Objective Loss 0.649896                                        LR 0.001000    Time 0.045239    
2024-04-05 15:24:27,762 - Epoch: [86][  200/  500]    Overall Loss 0.645431    Objective Loss 0.645431                                        LR 0.001000    Time 0.043411    
2024-04-05 15:24:31,879 - Epoch: [86][  300/  500]    Overall Loss 0.656513    Objective Loss 0.656513                                        LR 0.001000    Time 0.042645    
2024-04-05 15:24:35,905 - Epoch: [86][  400/  500]    Overall Loss 0.665009    Objective Loss 0.665009                                        LR 0.001000    Time 0.042037    
2024-04-05 15:24:40,050 - Epoch: [86][  500/  500]    Overall Loss 0.670477    Objective Loss 0.670477    Top1 78.500000    Top5 96.000000    LR 0.001000    Time 0.041908    
2024-04-05 15:24:40,277 - --- validate (epoch=86)-----------
2024-04-05 15:24:40,278 - 10000 samples (100 per mini-batch)
2024-04-05 15:24:41,737 - Epoch: [86][  100/  100]    Loss 1.425108    Top1 63.020000    Top5 88.060000    
2024-04-05 15:24:41,894 - ==> Top1: 63.020    Top5: 88.060    Loss: 1.425

2024-04-05 15:24:41,899 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:24:41,900 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:24:41,930 - 

2024-04-05 15:24:41,931 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:24:46,645 - Epoch: [87][  100/  500]    Overall Loss 0.656199    Objective Loss 0.656199                                        LR 0.001000    Time 0.047083    
2024-04-05 15:24:50,787 - Epoch: [87][  200/  500]    Overall Loss 0.643985    Objective Loss 0.643985                                        LR 0.001000    Time 0.044223    
2024-04-05 15:24:54,958 - Epoch: [87][  300/  500]    Overall Loss 0.660211    Objective Loss 0.660211                                        LR 0.001000    Time 0.043370    
2024-04-05 15:24:58,836 - Epoch: [87][  400/  500]    Overall Loss 0.668103    Objective Loss 0.668103                                        LR 0.001000    Time 0.042208    
2024-04-05 15:25:02,993 - Epoch: [87][  500/  500]    Overall Loss 0.673650    Objective Loss 0.673650    Top1 76.000000    Top5 96.500000    LR 0.001000    Time 0.042070    
2024-04-05 15:25:03,242 - --- validate (epoch=87)-----------
2024-04-05 15:25:03,243 - 10000 samples (100 per mini-batch)
2024-04-05 15:25:04,586 - Epoch: [87][  100/  100]    Loss 1.432211    Top1 62.730000    Top5 87.640000    
2024-04-05 15:25:04,753 - ==> Top1: 62.730    Top5: 87.640    Loss: 1.432

2024-04-05 15:25:04,760 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:25:04,760 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:25:04,790 - 

2024-04-05 15:25:04,791 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:25:09,502 - Epoch: [88][  100/  500]    Overall Loss 0.641303    Objective Loss 0.641303                                        LR 0.001000    Time 0.047059    
2024-04-05 15:25:13,610 - Epoch: [88][  200/  500]    Overall Loss 0.654214    Objective Loss 0.654214                                        LR 0.001000    Time 0.044039    
2024-04-05 15:25:17,690 - Epoch: [88][  300/  500]    Overall Loss 0.651163    Objective Loss 0.651163                                        LR 0.001000    Time 0.042944    
2024-04-05 15:25:21,521 - Epoch: [88][  400/  500]    Overall Loss 0.653106    Objective Loss 0.653106                                        LR 0.001000    Time 0.041773    
2024-04-05 15:25:25,640 - Epoch: [88][  500/  500]    Overall Loss 0.656815    Objective Loss 0.656815    Top1 86.000000    Top5 99.500000    LR 0.001000    Time 0.041646    
2024-04-05 15:25:25,921 - --- validate (epoch=88)-----------
2024-04-05 15:25:25,922 - 10000 samples (100 per mini-batch)
2024-04-05 15:25:27,333 - Epoch: [88][  100/  100]    Loss 1.429622    Top1 62.370000    Top5 87.830000    
2024-04-05 15:25:27,486 - ==> Top1: 62.370    Top5: 87.830    Loss: 1.430

2024-04-05 15:25:27,492 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:25:27,492 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:25:27,524 - 

2024-04-05 15:25:27,524 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:25:32,101 - Epoch: [89][  100/  500]    Overall Loss 0.643397    Objective Loss 0.643397                                        LR 0.001000    Time 0.045713    
2024-04-05 15:25:36,217 - Epoch: [89][  200/  500]    Overall Loss 0.642777    Objective Loss 0.642777                                        LR 0.001000    Time 0.043407    
2024-04-05 15:25:40,290 - Epoch: [89][  300/  500]    Overall Loss 0.649344    Objective Loss 0.649344                                        LR 0.001000    Time 0.042496    
2024-04-05 15:25:44,309 - Epoch: [89][  400/  500]    Overall Loss 0.652374    Objective Loss 0.652374                                        LR 0.001000    Time 0.041908    
2024-04-05 15:25:48,449 - Epoch: [89][  500/  500]    Overall Loss 0.655719    Objective Loss 0.655719    Top1 79.500000    Top5 97.500000    LR 0.001000    Time 0.041795    
2024-04-05 15:25:48,673 - --- validate (epoch=89)-----------
2024-04-05 15:25:48,673 - 10000 samples (100 per mini-batch)
2024-04-05 15:25:50,096 - Epoch: [89][  100/  100]    Loss 1.441107    Top1 62.540000    Top5 88.240000    
2024-04-05 15:25:50,349 - ==> Top1: 62.540    Top5: 88.240    Loss: 1.441

2024-04-05 15:25:50,356 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:25:50,356 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:25:50,387 - 

2024-04-05 15:25:50,387 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:25:54,897 - Epoch: [90][  100/  500]    Overall Loss 0.625648    Objective Loss 0.625648                                        LR 0.001000    Time 0.045043    
2024-04-05 15:25:59,033 - Epoch: [90][  200/  500]    Overall Loss 0.635636    Objective Loss 0.635636                                        LR 0.001000    Time 0.043174    
2024-04-05 15:26:03,140 - Epoch: [90][  300/  500]    Overall Loss 0.644619    Objective Loss 0.644619                                        LR 0.001000    Time 0.042455    
2024-04-05 15:26:07,262 - Epoch: [90][  400/  500]    Overall Loss 0.648160    Objective Loss 0.648160                                        LR 0.001000    Time 0.042134    
2024-04-05 15:26:11,268 - Epoch: [90][  500/  500]    Overall Loss 0.654485    Objective Loss 0.654485    Top1 77.000000    Top5 97.000000    LR 0.001000    Time 0.041710    
2024-04-05 15:26:11,500 - --- validate (epoch=90)-----------
2024-04-05 15:26:11,501 - 10000 samples (100 per mini-batch)
2024-04-05 15:26:12,888 - Epoch: [90][  100/  100]    Loss 1.439905    Top1 62.490000    Top5 87.940000    
2024-04-05 15:26:13,069 - ==> Top1: 62.490    Top5: 87.940    Loss: 1.440

2024-04-05 15:26:13,075 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:26:13,075 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:26:13,105 - 

2024-04-05 15:26:13,106 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:26:17,763 - Epoch: [91][  100/  500]    Overall Loss 0.619821    Objective Loss 0.619821                                        LR 0.001000    Time 0.046515    
2024-04-05 15:26:21,880 - Epoch: [91][  200/  500]    Overall Loss 0.635105    Objective Loss 0.635105                                        LR 0.001000    Time 0.043817    
2024-04-05 15:26:26,006 - Epoch: [91][  300/  500]    Overall Loss 0.639547    Objective Loss 0.639547                                        LR 0.001000    Time 0.042948    
2024-04-05 15:26:30,134 - Epoch: [91][  400/  500]    Overall Loss 0.642874    Objective Loss 0.642874                                        LR 0.001000    Time 0.042517    
2024-04-05 15:26:33,919 - Epoch: [91][  500/  500]    Overall Loss 0.650488    Objective Loss 0.650488    Top1 80.000000    Top5 96.500000    LR 0.001000    Time 0.041576    
2024-04-05 15:26:34,094 - --- validate (epoch=91)-----------
2024-04-05 15:26:34,094 - 10000 samples (100 per mini-batch)
2024-04-05 15:26:35,464 - Epoch: [91][  100/  100]    Loss 1.435801    Top1 62.640000    Top5 87.950000    
2024-04-05 15:26:35,628 - ==> Top1: 62.640    Top5: 87.950    Loss: 1.436

2024-04-05 15:26:35,633 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:26:35,633 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:26:35,664 - 

2024-04-05 15:26:35,664 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:26:40,310 - Epoch: [92][  100/  500]    Overall Loss 0.618683    Objective Loss 0.618683                                        LR 0.001000    Time 0.046397    
2024-04-05 15:26:44,459 - Epoch: [92][  200/  500]    Overall Loss 0.634069    Objective Loss 0.634069                                        LR 0.001000    Time 0.043915    
2024-04-05 15:26:48,551 - Epoch: [92][  300/  500]    Overall Loss 0.643752    Objective Loss 0.643752                                        LR 0.001000    Time 0.042902    
2024-04-05 15:26:52,676 - Epoch: [92][  400/  500]    Overall Loss 0.646140    Objective Loss 0.646140                                        LR 0.001000    Time 0.042474    
2024-04-05 15:26:56,826 - Epoch: [92][  500/  500]    Overall Loss 0.650915    Objective Loss 0.650915    Top1 77.500000    Top5 97.000000    LR 0.001000    Time 0.042269    
2024-04-05 15:26:56,975 - --- validate (epoch=92)-----------
2024-04-05 15:26:56,976 - 10000 samples (100 per mini-batch)
2024-04-05 15:26:58,633 - Epoch: [92][  100/  100]    Loss 1.444599    Top1 62.750000    Top5 87.990000    
2024-04-05 15:26:58,794 - ==> Top1: 62.750    Top5: 87.990    Loss: 1.445

2024-04-05 15:26:58,799 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:26:58,800 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:26:59,018 - 

2024-04-05 15:26:59,019 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:27:03,735 - Epoch: [93][  100/  500]    Overall Loss 0.611259    Objective Loss 0.611259                                        LR 0.001000    Time 0.047102    
2024-04-05 15:27:07,938 - Epoch: [93][  200/  500]    Overall Loss 0.620314    Objective Loss 0.620314                                        LR 0.001000    Time 0.044531    
2024-04-05 15:27:12,079 - Epoch: [93][  300/  500]    Overall Loss 0.629582    Objective Loss 0.629582                                        LR 0.001000    Time 0.043472    
2024-04-05 15:27:16,272 - Epoch: [93][  400/  500]    Overall Loss 0.632266    Objective Loss 0.632266                                        LR 0.001000    Time 0.043073    
2024-04-05 15:27:20,401 - Epoch: [93][  500/  500]    Overall Loss 0.639024    Objective Loss 0.639024    Top1 80.000000    Top5 97.000000    LR 0.001000    Time 0.042706    
2024-04-05 15:27:20,656 - --- validate (epoch=93)-----------
2024-04-05 15:27:20,657 - 10000 samples (100 per mini-batch)
2024-04-05 15:27:22,260 - Epoch: [93][  100/  100]    Loss 1.476861    Top1 62.130000    Top5 87.740000    
2024-04-05 15:27:22,384 - ==> Top1: 62.130    Top5: 87.740    Loss: 1.477

2024-04-05 15:27:22,388 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:27:22,388 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:27:22,409 - 

2024-04-05 15:27:22,409 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:27:27,355 - Epoch: [94][  100/  500]    Overall Loss 0.613472    Objective Loss 0.613472                                        LR 0.001000    Time 0.049395    
2024-04-05 15:27:31,529 - Epoch: [94][  200/  500]    Overall Loss 0.620164    Objective Loss 0.620164                                        LR 0.001000    Time 0.045542    
2024-04-05 15:27:35,673 - Epoch: [94][  300/  500]    Overall Loss 0.624656    Objective Loss 0.624656                                        LR 0.001000    Time 0.044158    
2024-04-05 15:27:39,830 - Epoch: [94][  400/  500]    Overall Loss 0.634261    Objective Loss 0.634261                                        LR 0.001000    Time 0.043496    
2024-04-05 15:27:43,955 - Epoch: [94][  500/  500]    Overall Loss 0.641633    Objective Loss 0.641633    Top1 79.000000    Top5 97.500000    LR 0.001000    Time 0.043034    
2024-04-05 15:27:44,144 - --- validate (epoch=94)-----------
2024-04-05 15:27:44,145 - 10000 samples (100 per mini-batch)
2024-04-05 15:27:45,650 - Epoch: [94][  100/  100]    Loss 1.440139    Top1 62.750000    Top5 87.790000    
2024-04-05 15:27:45,816 - ==> Top1: 62.750    Top5: 87.790    Loss: 1.440

2024-04-05 15:27:45,823 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:27:45,823 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:27:45,855 - 

2024-04-05 15:27:45,855 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:27:50,516 - Epoch: [95][  100/  500]    Overall Loss 0.615933    Objective Loss 0.615933                                        LR 0.001000    Time 0.046553    
2024-04-05 15:27:54,662 - Epoch: [95][  200/  500]    Overall Loss 0.615808    Objective Loss 0.615808                                        LR 0.001000    Time 0.043981    
2024-04-05 15:27:58,773 - Epoch: [95][  300/  500]    Overall Loss 0.619272    Objective Loss 0.619272                                        LR 0.001000    Time 0.043000    
2024-04-05 15:28:02,964 - Epoch: [95][  400/  500]    Overall Loss 0.628551    Objective Loss 0.628551                                        LR 0.001000    Time 0.042715    
2024-04-05 15:28:07,105 - Epoch: [95][  500/  500]    Overall Loss 0.636329    Objective Loss 0.636329    Top1 77.000000    Top5 97.500000    LR 0.001000    Time 0.042442    
2024-04-05 15:28:07,295 - --- validate (epoch=95)-----------
2024-04-05 15:28:07,295 - 10000 samples (100 per mini-batch)
2024-04-05 15:28:08,728 - Epoch: [95][  100/  100]    Loss 1.466015    Top1 61.950000    Top5 87.940000    
2024-04-05 15:28:08,873 - ==> Top1: 61.950    Top5: 87.940    Loss: 1.466

2024-04-05 15:28:08,878 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:28:08,879 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:28:08,911 - 

2024-04-05 15:28:08,911 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:28:13,419 - Epoch: [96][  100/  500]    Overall Loss 0.623184    Objective Loss 0.623184                                        LR 0.001000    Time 0.045027    
2024-04-05 15:28:17,551 - Epoch: [96][  200/  500]    Overall Loss 0.612187    Objective Loss 0.612187                                        LR 0.001000    Time 0.043149    
2024-04-05 15:28:21,660 - Epoch: [96][  300/  500]    Overall Loss 0.615635    Objective Loss 0.615635                                        LR 0.001000    Time 0.042445    
2024-04-05 15:28:25,786 - Epoch: [96][  400/  500]    Overall Loss 0.623614    Objective Loss 0.623614                                        LR 0.001000    Time 0.042133    
2024-04-05 15:28:29,896 - Epoch: [96][  500/  500]    Overall Loss 0.624702    Objective Loss 0.624702    Top1 79.500000    Top5 98.500000    LR 0.001000    Time 0.041917    
2024-04-05 15:28:30,097 - --- validate (epoch=96)-----------
2024-04-05 15:28:30,098 - 10000 samples (100 per mini-batch)
2024-04-05 15:28:31,478 - Epoch: [96][  100/  100]    Loss 1.453607    Top1 62.600000    Top5 87.860000    
2024-04-05 15:28:31,661 - ==> Top1: 62.600    Top5: 87.860    Loss: 1.454

2024-04-05 15:28:31,667 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:28:31,667 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:28:31,699 - 

2024-04-05 15:28:31,700 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:28:35,889 - Epoch: [97][  100/  500]    Overall Loss 0.620504    Objective Loss 0.620504                                        LR 0.001000    Time 0.041846    
2024-04-05 15:28:39,627 - Epoch: [97][  200/  500]    Overall Loss 0.625599    Objective Loss 0.625599                                        LR 0.001000    Time 0.039585    
2024-04-05 15:28:43,652 - Epoch: [97][  300/  500]    Overall Loss 0.619981    Objective Loss 0.619981                                        LR 0.001000    Time 0.039790    
2024-04-05 15:28:47,761 - Epoch: [97][  400/  500]    Overall Loss 0.627172    Objective Loss 0.627172                                        LR 0.001000    Time 0.040103    
2024-04-05 15:28:51,812 - Epoch: [97][  500/  500]    Overall Loss 0.633677    Objective Loss 0.633677    Top1 74.000000    Top5 94.500000    LR 0.001000    Time 0.040174    
2024-04-05 15:28:52,037 - --- validate (epoch=97)-----------
2024-04-05 15:28:52,037 - 10000 samples (100 per mini-batch)
2024-04-05 15:28:53,444 - Epoch: [97][  100/  100]    Loss 1.481552    Top1 62.060000    Top5 87.310000    
2024-04-05 15:28:53,665 - ==> Top1: 62.060    Top5: 87.310    Loss: 1.482

2024-04-05 15:28:53,671 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:28:53,672 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:28:53,703 - 

2024-04-05 15:28:53,703 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:28:58,203 - Epoch: [98][  100/  500]    Overall Loss 0.609537    Objective Loss 0.609537                                        LR 0.001000    Time 0.044953    
2024-04-05 15:29:02,049 - Epoch: [98][  200/  500]    Overall Loss 0.612415    Objective Loss 0.612415                                        LR 0.001000    Time 0.041679    
2024-04-05 15:29:06,224 - Epoch: [98][  300/  500]    Overall Loss 0.616941    Objective Loss 0.616941                                        LR 0.001000    Time 0.041683    
2024-04-05 15:29:10,337 - Epoch: [98][  400/  500]    Overall Loss 0.621995    Objective Loss 0.621995                                        LR 0.001000    Time 0.041533    
2024-04-05 15:29:14,518 - Epoch: [98][  500/  500]    Overall Loss 0.626786    Objective Loss 0.626786    Top1 81.000000    Top5 96.000000    LR 0.001000    Time 0.041577    
2024-04-05 15:29:14,711 - --- validate (epoch=98)-----------
2024-04-05 15:29:14,712 - 10000 samples (100 per mini-batch)
2024-04-05 15:29:16,069 - Epoch: [98][  100/  100]    Loss 1.468170    Top1 62.540000    Top5 87.630000    
2024-04-05 15:29:16,241 - ==> Top1: 62.540    Top5: 87.630    Loss: 1.468

2024-04-05 15:29:16,246 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:29:16,247 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:29:16,280 - 

2024-04-05 15:29:16,280 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:29:21,077 - Epoch: [99][  100/  500]    Overall Loss 0.610686    Objective Loss 0.610686                                        LR 0.001000    Time 0.047909    
2024-04-05 15:29:24,727 - Epoch: [99][  200/  500]    Overall Loss 0.622076    Objective Loss 0.622076                                        LR 0.001000    Time 0.042176    
2024-04-05 15:29:28,905 - Epoch: [99][  300/  500]    Overall Loss 0.623046    Objective Loss 0.623046                                        LR 0.001000    Time 0.042026    
2024-04-05 15:29:33,040 - Epoch: [99][  400/  500]    Overall Loss 0.620298    Objective Loss 0.620298                                        LR 0.001000    Time 0.041844    
2024-04-05 15:29:37,198 - Epoch: [99][  500/  500]    Overall Loss 0.623630    Objective Loss 0.623630    Top1 78.500000    Top5 97.000000    LR 0.001000    Time 0.041780    
2024-04-05 15:29:37,404 - --- validate (epoch=99)-----------
2024-04-05 15:29:37,405 - 10000 samples (100 per mini-batch)
2024-04-05 15:29:38,776 - Epoch: [99][  100/  100]    Loss 1.448160    Top1 62.260000    Top5 87.840000    
2024-04-05 15:29:38,906 - ==> Top1: 62.260    Top5: 87.840    Loss: 1.448

2024-04-05 15:29:38,912 - ==> Best [Top1: 63.140   Top5: 88.250   Sparsity:0.00   Params: 347840 on epoch: 80]
2024-04-05 15:29:38,912 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:29:38,944 - 

2024-04-05 15:29:38,944 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:29:43,890 - Epoch: [100][  100/  500]    Overall Loss 0.565292    Objective Loss 0.565292                                        LR 0.000500    Time 0.049409    
2024-04-05 15:29:47,714 - Epoch: [100][  200/  500]    Overall Loss 0.560095    Objective Loss 0.560095                                        LR 0.000500    Time 0.043798    
2024-04-05 15:29:51,852 - Epoch: [100][  300/  500]    Overall Loss 0.551381    Objective Loss 0.551381                                        LR 0.000500    Time 0.042974    
2024-04-05 15:29:55,994 - Epoch: [100][  400/  500]    Overall Loss 0.550373    Objective Loss 0.550373                                        LR 0.000500    Time 0.042570    
2024-04-05 15:30:00,127 - Epoch: [100][  500/  500]    Overall Loss 0.550047    Objective Loss 0.550047    Top1 83.000000    Top5 98.500000    LR 0.000500    Time 0.042313    
2024-04-05 15:30:00,356 - --- validate (epoch=100)-----------
2024-04-05 15:30:00,356 - 10000 samples (100 per mini-batch)
2024-04-05 15:30:01,708 - Epoch: [100][  100/  100]    Loss 1.375588    Top1 64.010000    Top5 88.720000    
2024-04-05 15:30:01,865 - ==> Top1: 64.010    Top5: 88.720    Loss: 1.376

2024-04-05 15:30:01,872 - ==> Best [Top1: 64.010   Top5: 88.720   Sparsity:0.00   Params: 347840 on epoch: 100]
2024-04-05 15:30:01,872 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:30:01,911 - 

2024-04-05 15:30:01,912 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:30:06,532 - Epoch: [101][  100/  500]    Overall Loss 0.529414    Objective Loss 0.529414                                        LR 0.000500    Time 0.046146    
2024-04-05 15:30:10,030 - Epoch: [101][  200/  500]    Overall Loss 0.528767    Objective Loss 0.528767                                        LR 0.000500    Time 0.040542    
2024-04-05 15:30:14,210 - Epoch: [101][  300/  500]    Overall Loss 0.533077    Objective Loss 0.533077                                        LR 0.000500    Time 0.040942    
2024-04-05 15:30:18,345 - Epoch: [101][  400/  500]    Overall Loss 0.531900    Objective Loss 0.531900                                        LR 0.000500    Time 0.041030    
2024-04-05 15:30:22,499 - Epoch: [101][  500/  500]    Overall Loss 0.533506    Objective Loss 0.533506    Top1 82.500000    Top5 99.000000    LR 0.000500    Time 0.041121    
2024-04-05 15:30:22,697 - --- validate (epoch=101)-----------
2024-04-05 15:30:22,698 - 10000 samples (100 per mini-batch)
2024-04-05 15:30:24,077 - Epoch: [101][  100/  100]    Loss 1.376814    Top1 63.850000    Top5 88.870000    
2024-04-05 15:30:24,252 - ==> Top1: 63.850    Top5: 88.870    Loss: 1.377

2024-04-05 15:30:24,255 - ==> Best [Top1: 64.010   Top5: 88.720   Sparsity:0.00   Params: 347840 on epoch: 100]
2024-04-05 15:30:24,255 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:30:24,278 - 

2024-04-05 15:30:24,279 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:30:29,018 - Epoch: [102][  100/  500]    Overall Loss 0.534931    Objective Loss 0.534931                                        LR 0.000500    Time 0.047337    
2024-04-05 15:30:32,803 - Epoch: [102][  200/  500]    Overall Loss 0.531054    Objective Loss 0.531054                                        LR 0.000500    Time 0.042566    
2024-04-05 15:30:36,929 - Epoch: [102][  300/  500]    Overall Loss 0.530034    Objective Loss 0.530034                                        LR 0.000500    Time 0.042115    
2024-04-05 15:30:41,091 - Epoch: [102][  400/  500]    Overall Loss 0.528483    Objective Loss 0.528483                                        LR 0.000500    Time 0.041976    
2024-04-05 15:30:45,237 - Epoch: [102][  500/  500]    Overall Loss 0.530447    Objective Loss 0.530447    Top1 87.500000    Top5 97.500000    LR 0.000500    Time 0.041863    
2024-04-05 15:30:45,504 - --- validate (epoch=102)-----------
2024-04-05 15:30:45,505 - 10000 samples (100 per mini-batch)
2024-04-05 15:30:46,922 - Epoch: [102][  100/  100]    Loss 1.392851    Top1 63.920000    Top5 88.710000    
2024-04-05 15:30:47,087 - ==> Top1: 63.920    Top5: 88.710    Loss: 1.393

2024-04-05 15:30:47,092 - ==> Best [Top1: 64.010   Top5: 88.720   Sparsity:0.00   Params: 347840 on epoch: 100]
2024-04-05 15:30:47,093 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:30:47,123 - 

2024-04-05 15:30:47,123 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:30:52,038 - Epoch: [103][  100/  500]    Overall Loss 0.506151    Objective Loss 0.506151                                        LR 0.000500    Time 0.049091    
2024-04-05 15:30:56,075 - Epoch: [103][  200/  500]    Overall Loss 0.509586    Objective Loss 0.509586                                        LR 0.000500    Time 0.044706    
2024-04-05 15:30:59,744 - Epoch: [103][  300/  500]    Overall Loss 0.513328    Objective Loss 0.513328                                        LR 0.000500    Time 0.042017    
2024-04-05 15:31:03,866 - Epoch: [103][  400/  500]    Overall Loss 0.518916    Objective Loss 0.518916                                        LR 0.000500    Time 0.041805    
2024-04-05 15:31:08,000 - Epoch: [103][  500/  500]    Overall Loss 0.521530    Objective Loss 0.521530    Top1 87.500000    Top5 98.500000    LR 0.000500    Time 0.041701    
2024-04-05 15:31:08,222 - --- validate (epoch=103)-----------
2024-04-05 15:31:08,223 - 10000 samples (100 per mini-batch)
2024-04-05 15:31:09,624 - Epoch: [103][  100/  100]    Loss 1.391430    Top1 63.940000    Top5 88.950000    
2024-04-05 15:31:09,794 - ==> Top1: 63.940    Top5: 88.950    Loss: 1.391

2024-04-05 15:31:09,800 - ==> Best [Top1: 64.010   Top5: 88.720   Sparsity:0.00   Params: 347840 on epoch: 100]
2024-04-05 15:31:09,801 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:31:09,833 - 

2024-04-05 15:31:09,833 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:31:14,559 - Epoch: [104][  100/  500]    Overall Loss 0.500657    Objective Loss 0.500657                                        LR 0.000500    Time 0.047196    
2024-04-05 15:31:18,665 - Epoch: [104][  200/  500]    Overall Loss 0.504616    Objective Loss 0.504616                                        LR 0.000500    Time 0.044103    
2024-04-05 15:31:22,196 - Epoch: [104][  300/  500]    Overall Loss 0.513640    Objective Loss 0.513640                                        LR 0.000500    Time 0.041156    
2024-04-05 15:31:26,327 - Epoch: [104][  400/  500]    Overall Loss 0.518643    Objective Loss 0.518643                                        LR 0.000500    Time 0.041183    
2024-04-05 15:31:30,450 - Epoch: [104][  500/  500]    Overall Loss 0.523493    Objective Loss 0.523493    Top1 83.500000    Top5 99.000000    LR 0.000500    Time 0.041181    
2024-04-05 15:31:30,727 - --- validate (epoch=104)-----------
2024-04-05 15:31:30,728 - 10000 samples (100 per mini-batch)
2024-04-05 15:31:32,144 - Epoch: [104][  100/  100]    Loss 1.379547    Top1 63.950000    Top5 88.930000    
2024-04-05 15:31:32,308 - ==> Top1: 63.950    Top5: 88.930    Loss: 1.380

2024-04-05 15:31:32,313 - ==> Best [Top1: 64.010   Top5: 88.720   Sparsity:0.00   Params: 347840 on epoch: 100]
2024-04-05 15:31:32,314 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:31:32,345 - 

2024-04-05 15:31:32,346 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:31:36,723 - Epoch: [105][  100/  500]    Overall Loss 0.502943    Objective Loss 0.502943                                        LR 0.000500    Time 0.043721    
2024-04-05 15:31:40,847 - Epoch: [105][  200/  500]    Overall Loss 0.511182    Objective Loss 0.511182                                        LR 0.000500    Time 0.042451    
2024-04-05 15:31:44,520 - Epoch: [105][  300/  500]    Overall Loss 0.515363    Objective Loss 0.515363                                        LR 0.000500    Time 0.040529    
2024-04-05 15:31:48,536 - Epoch: [105][  400/  500]    Overall Loss 0.520867    Objective Loss 0.520867                                        LR 0.000500    Time 0.040425    
2024-04-05 15:31:52,657 - Epoch: [105][  500/  500]    Overall Loss 0.520010    Objective Loss 0.520010    Top1 86.000000    Top5 100.000000    LR 0.000500    Time 0.040572    
2024-04-05 15:31:52,877 - --- validate (epoch=105)-----------
2024-04-05 15:31:52,878 - 10000 samples (100 per mini-batch)
2024-04-05 15:31:54,249 - Epoch: [105][  100/  100]    Loss 1.389153    Top1 63.750000    Top5 88.610000    
2024-04-05 15:31:54,418 - ==> Top1: 63.750    Top5: 88.610    Loss: 1.389

2024-04-05 15:31:54,423 - ==> Best [Top1: 64.010   Top5: 88.720   Sparsity:0.00   Params: 347840 on epoch: 100]
2024-04-05 15:31:54,424 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:31:54,456 - 

2024-04-05 15:31:54,456 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:31:59,111 - Epoch: [106][  100/  500]    Overall Loss 0.511994    Objective Loss 0.511994                                        LR 0.000500    Time 0.046495    
2024-04-05 15:32:03,226 - Epoch: [106][  200/  500]    Overall Loss 0.513390    Objective Loss 0.513390                                        LR 0.000500    Time 0.043794    
2024-04-05 15:32:07,355 - Epoch: [106][  300/  500]    Overall Loss 0.513660    Objective Loss 0.513660                                        LR 0.000500    Time 0.042944    
2024-04-05 15:32:11,236 - Epoch: [106][  400/  500]    Overall Loss 0.513892    Objective Loss 0.513892                                        LR 0.000500    Time 0.041899    
2024-04-05 15:32:15,353 - Epoch: [106][  500/  500]    Overall Loss 0.512106    Objective Loss 0.512106    Top1 84.000000    Top5 96.500000    LR 0.000500    Time 0.041741    
2024-04-05 15:32:15,547 - --- validate (epoch=106)-----------
2024-04-05 15:32:15,548 - 10000 samples (100 per mini-batch)
2024-04-05 15:32:16,933 - Epoch: [106][  100/  100]    Loss 1.397944    Top1 63.900000    Top5 88.630000    
2024-04-05 15:32:17,093 - ==> Top1: 63.900    Top5: 88.630    Loss: 1.398

2024-04-05 15:32:17,100 - ==> Best [Top1: 64.010   Top5: 88.720   Sparsity:0.00   Params: 347840 on epoch: 100]
2024-04-05 15:32:17,100 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:32:17,318 - 

2024-04-05 15:32:17,318 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:32:21,974 - Epoch: [107][  100/  500]    Overall Loss 0.498998    Objective Loss 0.498998                                        LR 0.000500    Time 0.046505    
2024-04-05 15:32:26,041 - Epoch: [107][  200/  500]    Overall Loss 0.500784    Objective Loss 0.500784                                        LR 0.000500    Time 0.043563    
2024-04-05 15:32:30,152 - Epoch: [107][  300/  500]    Overall Loss 0.504820    Objective Loss 0.504820                                        LR 0.000500    Time 0.042726    
2024-04-05 15:32:33,906 - Epoch: [107][  400/  500]    Overall Loss 0.505884    Objective Loss 0.505884                                        LR 0.000500    Time 0.041419    
2024-04-05 15:32:38,031 - Epoch: [107][  500/  500]    Overall Loss 0.511133    Objective Loss 0.511133    Top1 84.000000    Top5 97.000000    LR 0.000500    Time 0.041375    
2024-04-05 15:32:38,316 - --- validate (epoch=107)-----------
2024-04-05 15:32:38,316 - 10000 samples (100 per mini-batch)
2024-04-05 15:32:39,731 - Epoch: [107][  100/  100]    Loss 1.386432    Top1 64.250000    Top5 88.830000    
2024-04-05 15:32:39,879 - ==> Top1: 64.250    Top5: 88.830    Loss: 1.386

2024-04-05 15:32:39,884 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:32:39,885 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:32:39,924 - 

2024-04-05 15:32:39,924 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:32:44,838 - Epoch: [108][  100/  500]    Overall Loss 0.505070    Objective Loss 0.505070                                        LR 0.000500    Time 0.049086    
2024-04-05 15:32:48,994 - Epoch: [108][  200/  500]    Overall Loss 0.500330    Objective Loss 0.500330                                        LR 0.000500    Time 0.045296    
2024-04-05 15:32:53,122 - Epoch: [108][  300/  500]    Overall Loss 0.498959    Objective Loss 0.498959                                        LR 0.000500    Time 0.043939    
2024-04-05 15:32:56,769 - Epoch: [108][  400/  500]    Overall Loss 0.502735    Objective Loss 0.502735                                        LR 0.000500    Time 0.042061    
2024-04-05 15:33:00,916 - Epoch: [108][  500/  500]    Overall Loss 0.505519    Objective Loss 0.505519    Top1 83.500000    Top5 99.500000    LR 0.000500    Time 0.041931    
2024-04-05 15:33:01,143 - --- validate (epoch=108)-----------
2024-04-05 15:33:01,144 - 10000 samples (100 per mini-batch)
2024-04-05 15:33:02,555 - Epoch: [108][  100/  100]    Loss 1.396911    Top1 63.830000    Top5 88.860000    
2024-04-05 15:33:02,707 - ==> Top1: 63.830    Top5: 88.860    Loss: 1.397

2024-04-05 15:33:02,714 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:33:02,714 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:33:02,746 - 

2024-04-05 15:33:02,747 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:33:07,498 - Epoch: [109][  100/  500]    Overall Loss 0.494960    Objective Loss 0.494960                                        LR 0.000500    Time 0.047458    
2024-04-05 15:33:11,640 - Epoch: [109][  200/  500]    Overall Loss 0.495831    Objective Loss 0.495831                                        LR 0.000500    Time 0.044410    
2024-04-05 15:33:15,789 - Epoch: [109][  300/  500]    Overall Loss 0.495559    Objective Loss 0.495559                                        LR 0.000500    Time 0.043417    
2024-04-05 15:33:19,908 - Epoch: [109][  400/  500]    Overall Loss 0.500350    Objective Loss 0.500350                                        LR 0.000500    Time 0.042848    
2024-04-05 15:33:23,232 - Epoch: [109][  500/  500]    Overall Loss 0.502347    Objective Loss 0.502347    Top1 86.000000    Top5 98.500000    LR 0.000500    Time 0.040917    
2024-04-05 15:33:23,463 - --- validate (epoch=109)-----------
2024-04-05 15:33:23,464 - 10000 samples (100 per mini-batch)
2024-04-05 15:33:24,854 - Epoch: [109][  100/  100]    Loss 1.405602    Top1 63.950000    Top5 88.600000    
2024-04-05 15:33:25,001 - ==> Top1: 63.950    Top5: 88.600    Loss: 1.406

2024-04-05 15:33:25,006 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:33:25,006 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:33:25,038 - 

2024-04-05 15:33:25,038 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:33:30,010 - Epoch: [110][  100/  500]    Overall Loss 0.490610    Objective Loss 0.490610                                        LR 0.000500    Time 0.049666    
2024-04-05 15:33:34,185 - Epoch: [110][  200/  500]    Overall Loss 0.492868    Objective Loss 0.492868                                        LR 0.000500    Time 0.045677    
2024-04-05 15:33:38,333 - Epoch: [110][  300/  500]    Overall Loss 0.497416    Objective Loss 0.497416                                        LR 0.000500    Time 0.044261    
2024-04-05 15:33:42,453 - Epoch: [110][  400/  500]    Overall Loss 0.500911    Objective Loss 0.500911                                        LR 0.000500    Time 0.043481    
2024-04-05 15:33:45,827 - Epoch: [110][  500/  500]    Overall Loss 0.503285    Objective Loss 0.503285    Top1 85.000000    Top5 97.000000    LR 0.000500    Time 0.041524    
2024-04-05 15:33:46,094 - --- validate (epoch=110)-----------
2024-04-05 15:33:46,094 - 10000 samples (100 per mini-batch)
2024-04-05 15:33:47,533 - Epoch: [110][  100/  100]    Loss 1.392045    Top1 63.940000    Top5 88.770000    
2024-04-05 15:33:47,679 - ==> Top1: 63.940    Top5: 88.770    Loss: 1.392

2024-04-05 15:33:47,685 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:33:47,686 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:33:47,719 - 

2024-04-05 15:33:47,719 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:33:52,600 - Epoch: [111][  100/  500]    Overall Loss 0.474981    Objective Loss 0.474981                                        LR 0.000500    Time 0.048750    
2024-04-05 15:33:56,812 - Epoch: [111][  200/  500]    Overall Loss 0.477609    Objective Loss 0.477609                                        LR 0.000500    Time 0.045407    
2024-04-05 15:34:00,546 - Epoch: [111][  300/  500]    Overall Loss 0.486732    Objective Loss 0.486732                                        LR 0.000500    Time 0.042703    
2024-04-05 15:34:04,572 - Epoch: [111][  400/  500]    Overall Loss 0.492925    Objective Loss 0.492925                                        LR 0.000500    Time 0.042079    
2024-04-05 15:34:08,797 - Epoch: [111][  500/  500]    Overall Loss 0.499518    Objective Loss 0.499518    Top1 86.000000    Top5 98.000000    LR 0.000500    Time 0.042099    
2024-04-05 15:34:09,083 - --- validate (epoch=111)-----------
2024-04-05 15:34:09,084 - 10000 samples (100 per mini-batch)
2024-04-05 15:34:10,514 - Epoch: [111][  100/  100]    Loss 1.395242    Top1 64.110000    Top5 89.020000    
2024-04-05 15:34:10,686 - ==> Top1: 64.110    Top5: 89.020    Loss: 1.395

2024-04-05 15:34:10,692 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:34:10,692 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:34:10,726 - 

2024-04-05 15:34:10,726 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:34:15,420 - Epoch: [112][  100/  500]    Overall Loss 0.466267    Objective Loss 0.466267                                        LR 0.000500    Time 0.046884    
2024-04-05 15:34:18,978 - Epoch: [112][  200/  500]    Overall Loss 0.485615    Objective Loss 0.485615                                        LR 0.000500    Time 0.041208    
2024-04-05 15:34:22,873 - Epoch: [112][  300/  500]    Overall Loss 0.486479    Objective Loss 0.486479                                        LR 0.000500    Time 0.040438    
2024-04-05 15:34:27,002 - Epoch: [112][  400/  500]    Overall Loss 0.490167    Objective Loss 0.490167                                        LR 0.000500    Time 0.040638    
2024-04-05 15:34:31,170 - Epoch: [112][  500/  500]    Overall Loss 0.495948    Objective Loss 0.495948    Top1 86.000000    Top5 99.500000    LR 0.000500    Time 0.040836    
2024-04-05 15:34:31,440 - --- validate (epoch=112)-----------
2024-04-05 15:34:31,441 - 10000 samples (100 per mini-batch)
2024-04-05 15:34:33,088 - Epoch: [112][  100/  100]    Loss 1.393756    Top1 64.000000    Top5 88.840000    
2024-04-05 15:34:33,262 - ==> Top1: 64.000    Top5: 88.840    Loss: 1.394

2024-04-05 15:34:33,267 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:34:33,267 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:34:33,300 - 

2024-04-05 15:34:33,300 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:34:38,001 - Epoch: [113][  100/  500]    Overall Loss 0.486792    Objective Loss 0.486792                                        LR 0.000500    Time 0.046951    
2024-04-05 15:34:42,207 - Epoch: [113][  200/  500]    Overall Loss 0.482787    Objective Loss 0.482787                                        LR 0.000500    Time 0.044477    
2024-04-05 15:34:45,729 - Epoch: [113][  300/  500]    Overall Loss 0.485574    Objective Loss 0.485574                                        LR 0.000500    Time 0.041375    
2024-04-05 15:34:49,844 - Epoch: [113][  400/  500]    Overall Loss 0.490184    Objective Loss 0.490184                                        LR 0.000500    Time 0.041306    
2024-04-05 15:34:53,983 - Epoch: [113][  500/  500]    Overall Loss 0.494534    Objective Loss 0.494534    Top1 82.500000    Top5 98.000000    LR 0.000500    Time 0.041311    
2024-04-05 15:34:54,179 - --- validate (epoch=113)-----------
2024-04-05 15:34:54,180 - 10000 samples (100 per mini-batch)
2024-04-05 15:34:55,524 - Epoch: [113][  100/  100]    Loss 1.406033    Top1 64.200000    Top5 88.400000    
2024-04-05 15:34:55,673 - ==> Top1: 64.200    Top5: 88.400    Loss: 1.406

2024-04-05 15:34:55,679 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:34:55,679 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:34:55,709 - 

2024-04-05 15:34:55,709 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:35:00,600 - Epoch: [114][  100/  500]    Overall Loss 0.480100    Objective Loss 0.480100                                        LR 0.000500    Time 0.048854    
2024-04-05 15:35:04,718 - Epoch: [114][  200/  500]    Overall Loss 0.479143    Objective Loss 0.479143                                        LR 0.000500    Time 0.044989    
2024-04-05 15:35:08,380 - Epoch: [114][  300/  500]    Overall Loss 0.485433    Objective Loss 0.485433                                        LR 0.000500    Time 0.042182    
2024-04-05 15:35:12,537 - Epoch: [114][  400/  500]    Overall Loss 0.486224    Objective Loss 0.486224                                        LR 0.000500    Time 0.042017    
2024-04-05 15:35:16,664 - Epoch: [114][  500/  500]    Overall Loss 0.491239    Objective Loss 0.491239    Top1 86.000000    Top5 98.500000    LR 0.000500    Time 0.041857    
2024-04-05 15:35:16,918 - --- validate (epoch=114)-----------
2024-04-05 15:35:16,919 - 10000 samples (100 per mini-batch)
2024-04-05 15:35:18,347 - Epoch: [114][  100/  100]    Loss 1.428300    Top1 63.340000    Top5 88.610000    
2024-04-05 15:35:18,509 - ==> Top1: 63.340    Top5: 88.610    Loss: 1.428

2024-04-05 15:35:18,516 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:35:18,516 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:35:18,548 - 

2024-04-05 15:35:18,549 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:35:23,211 - Epoch: [115][  100/  500]    Overall Loss 0.479375    Objective Loss 0.479375                                        LR 0.000500    Time 0.046565    
2024-04-05 15:35:27,340 - Epoch: [115][  200/  500]    Overall Loss 0.482868    Objective Loss 0.482868                                        LR 0.000500    Time 0.043900    
2024-04-05 15:35:31,164 - Epoch: [115][  300/  500]    Overall Loss 0.483071    Objective Loss 0.483071                                        LR 0.000500    Time 0.041999    
2024-04-05 15:35:34,828 - Epoch: [115][  400/  500]    Overall Loss 0.486263    Objective Loss 0.486263                                        LR 0.000500    Time 0.040648    
2024-04-05 15:35:38,954 - Epoch: [115][  500/  500]    Overall Loss 0.489317    Objective Loss 0.489317    Top1 85.000000    Top5 98.000000    LR 0.000500    Time 0.040760    
2024-04-05 15:35:39,192 - --- validate (epoch=115)-----------
2024-04-05 15:35:39,193 - 10000 samples (100 per mini-batch)
2024-04-05 15:35:40,588 - Epoch: [115][  100/  100]    Loss 1.417876    Top1 63.560000    Top5 88.740000    
2024-04-05 15:35:40,742 - ==> Top1: 63.560    Top5: 88.740    Loss: 1.418

2024-04-05 15:35:40,748 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:35:40,748 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:35:40,779 - 

2024-04-05 15:35:40,779 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:35:45,548 - Epoch: [116][  100/  500]    Overall Loss 0.479672    Objective Loss 0.479672                                        LR 0.000500    Time 0.047623    
2024-04-05 15:35:49,759 - Epoch: [116][  200/  500]    Overall Loss 0.481182    Objective Loss 0.481182                                        LR 0.000500    Time 0.044837    
2024-04-05 15:35:53,872 - Epoch: [116][  300/  500]    Overall Loss 0.481445    Objective Loss 0.481445                                        LR 0.000500    Time 0.043584    
2024-04-05 15:35:57,882 - Epoch: [116][  400/  500]    Overall Loss 0.484707    Objective Loss 0.484707                                        LR 0.000500    Time 0.042699    
2024-04-05 15:36:02,011 - Epoch: [116][  500/  500]    Overall Loss 0.488009    Objective Loss 0.488009    Top1 84.500000    Top5 98.500000    LR 0.000500    Time 0.042408    
2024-04-05 15:36:02,233 - --- validate (epoch=116)-----------
2024-04-05 15:36:02,234 - 10000 samples (100 per mini-batch)
2024-04-05 15:36:03,845 - Epoch: [116][  100/  100]    Loss 1.421283    Top1 63.820000    Top5 88.710000    
2024-04-05 15:36:03,982 - ==> Top1: 63.820    Top5: 88.710    Loss: 1.421

2024-04-05 15:36:03,985 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:36:03,985 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:36:04,008 - 

2024-04-05 15:36:04,008 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:36:08,748 - Epoch: [117][  100/  500]    Overall Loss 0.474025    Objective Loss 0.474025                                        LR 0.000500    Time 0.047341    
2024-04-05 15:36:12,861 - Epoch: [117][  200/  500]    Overall Loss 0.476395    Objective Loss 0.476395                                        LR 0.000500    Time 0.044206    
2024-04-05 15:36:16,973 - Epoch: [117][  300/  500]    Overall Loss 0.483605    Objective Loss 0.483605                                        LR 0.000500    Time 0.043159    
2024-04-05 15:36:20,615 - Epoch: [117][  400/  500]    Overall Loss 0.487047    Objective Loss 0.487047                                        LR 0.000500    Time 0.041461    
2024-04-05 15:36:24,732 - Epoch: [117][  500/  500]    Overall Loss 0.487470    Objective Loss 0.487470    Top1 81.000000    Top5 97.000000    LR 0.000500    Time 0.041392    
2024-04-05 15:36:25,015 - --- validate (epoch=117)-----------
2024-04-05 15:36:25,015 - 10000 samples (100 per mini-batch)
2024-04-05 15:36:26,419 - Epoch: [117][  100/  100]    Loss 1.401721    Top1 64.020000    Top5 88.970000    
2024-04-05 15:36:26,577 - ==> Top1: 64.020    Top5: 88.970    Loss: 1.402

2024-04-05 15:36:26,582 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:36:26,583 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:36:26,613 - 

2024-04-05 15:36:26,614 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:36:31,695 - Epoch: [118][  100/  500]    Overall Loss 0.464786    Objective Loss 0.464786                                        LR 0.000500    Time 0.050757    
2024-04-05 15:36:35,971 - Epoch: [118][  200/  500]    Overall Loss 0.466816    Objective Loss 0.466816                                        LR 0.000500    Time 0.046723    
2024-04-05 15:36:40,201 - Epoch: [118][  300/  500]    Overall Loss 0.472396    Objective Loss 0.472396                                        LR 0.000500    Time 0.045230    
2024-04-05 15:36:43,802 - Epoch: [118][  400/  500]    Overall Loss 0.475152    Objective Loss 0.475152                                        LR 0.000500    Time 0.042912    
2024-04-05 15:36:48,079 - Epoch: [118][  500/  500]    Overall Loss 0.481551    Objective Loss 0.481551    Top1 82.000000    Top5 99.000000    LR 0.000500    Time 0.042872    
2024-04-05 15:36:48,370 - --- validate (epoch=118)-----------
2024-04-05 15:36:48,371 - 10000 samples (100 per mini-batch)
2024-04-05 15:36:49,786 - Epoch: [118][  100/  100]    Loss 1.436684    Top1 63.730000    Top5 88.670000    
2024-04-05 15:36:49,936 - ==> Top1: 63.730    Top5: 88.670    Loss: 1.437

2024-04-05 15:36:49,943 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:36:49,943 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:36:49,975 - 

2024-04-05 15:36:49,975 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:36:54,749 - Epoch: [119][  100/  500]    Overall Loss 0.451039    Objective Loss 0.451039                                        LR 0.000500    Time 0.047688    
2024-04-05 15:36:58,900 - Epoch: [119][  200/  500]    Overall Loss 0.467135    Objective Loss 0.467135                                        LR 0.000500    Time 0.044569    
2024-04-05 15:37:03,064 - Epoch: [119][  300/  500]    Overall Loss 0.468234    Objective Loss 0.468234                                        LR 0.000500    Time 0.043573    
2024-04-05 15:37:06,944 - Epoch: [119][  400/  500]    Overall Loss 0.476239    Objective Loss 0.476239                                        LR 0.000500    Time 0.042367    
2024-04-05 15:37:10,732 - Epoch: [119][  500/  500]    Overall Loss 0.479041    Objective Loss 0.479041    Top1 83.000000    Top5 98.000000    LR 0.000500    Time 0.041461    
2024-04-05 15:37:11,000 - --- validate (epoch=119)-----------
2024-04-05 15:37:11,001 - 10000 samples (100 per mini-batch)
2024-04-05 15:37:12,475 - Epoch: [119][  100/  100]    Loss 1.411828    Top1 63.900000    Top5 88.940000    
2024-04-05 15:37:12,635 - ==> Top1: 63.900    Top5: 88.940    Loss: 1.412

2024-04-05 15:37:12,641 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:37:12,641 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:37:12,672 - 

2024-04-05 15:37:12,672 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:37:17,398 - Epoch: [120][  100/  500]    Overall Loss 0.457140    Objective Loss 0.457140                                        LR 0.000500    Time 0.047205    
2024-04-05 15:37:21,565 - Epoch: [120][  200/  500]    Overall Loss 0.459937    Objective Loss 0.459937                                        LR 0.000500    Time 0.044406    
2024-04-05 15:37:25,713 - Epoch: [120][  300/  500]    Overall Loss 0.473546    Objective Loss 0.473546                                        LR 0.000500    Time 0.043415    
2024-04-05 15:37:29,818 - Epoch: [120][  400/  500]    Overall Loss 0.476886    Objective Loss 0.476886                                        LR 0.000500    Time 0.042810    
2024-04-05 15:37:33,752 - Epoch: [120][  500/  500]    Overall Loss 0.481756    Objective Loss 0.481756    Top1 83.500000    Top5 99.000000    LR 0.000500    Time 0.042105    
2024-04-05 15:37:34,047 - --- validate (epoch=120)-----------
2024-04-05 15:37:34,048 - 10000 samples (100 per mini-batch)
2024-04-05 15:37:35,722 - Epoch: [120][  100/  100]    Loss 1.409797    Top1 64.020000    Top5 88.930000    
2024-04-05 15:37:35,872 - ==> Top1: 64.020    Top5: 88.930    Loss: 1.410

2024-04-05 15:37:35,878 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:37:35,878 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:37:35,910 - 

2024-04-05 15:37:35,910 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:37:40,608 - Epoch: [121][  100/  500]    Overall Loss 0.459392    Objective Loss 0.459392                                        LR 0.000500    Time 0.046926    
2024-04-05 15:37:44,717 - Epoch: [121][  200/  500]    Overall Loss 0.464278    Objective Loss 0.464278                                        LR 0.000500    Time 0.043979    
2024-04-05 15:37:48,839 - Epoch: [121][  300/  500]    Overall Loss 0.471392    Objective Loss 0.471392                                        LR 0.000500    Time 0.043043    
2024-04-05 15:37:52,949 - Epoch: [121][  400/  500]    Overall Loss 0.476627    Objective Loss 0.476627                                        LR 0.000500    Time 0.042545    
2024-04-05 15:37:56,733 - Epoch: [121][  500/  500]    Overall Loss 0.480073    Objective Loss 0.480073    Top1 85.500000    Top5 98.500000    LR 0.000500    Time 0.041594    
2024-04-05 15:37:57,046 - --- validate (epoch=121)-----------
2024-04-05 15:37:57,046 - 10000 samples (100 per mini-batch)
2024-04-05 15:37:58,487 - Epoch: [121][  100/  100]    Loss 1.408237    Top1 64.170000    Top5 88.940000    
2024-04-05 15:37:58,635 - ==> Top1: 64.170    Top5: 88.940    Loss: 1.408

2024-04-05 15:37:58,640 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:37:58,641 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:37:58,671 - 

2024-04-05 15:37:58,671 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:38:03,357 - Epoch: [122][  100/  500]    Overall Loss 0.455194    Objective Loss 0.455194                                        LR 0.000500    Time 0.046800    
2024-04-05 15:38:07,493 - Epoch: [122][  200/  500]    Overall Loss 0.459413    Objective Loss 0.459413                                        LR 0.000500    Time 0.044053    
2024-04-05 15:38:11,655 - Epoch: [122][  300/  500]    Overall Loss 0.464324    Objective Loss 0.464324                                        LR 0.000500    Time 0.043226    
2024-04-05 15:38:15,804 - Epoch: [122][  400/  500]    Overall Loss 0.468802    Objective Loss 0.468802                                        LR 0.000500    Time 0.042778    
2024-04-05 15:38:19,890 - Epoch: [122][  500/  500]    Overall Loss 0.473305    Objective Loss 0.473305    Top1 84.000000    Top5 99.000000    LR 0.000500    Time 0.042383    
2024-04-05 15:38:20,070 - --- validate (epoch=122)-----------
2024-04-05 15:38:20,071 - 10000 samples (100 per mini-batch)
2024-04-05 15:38:21,591 - Epoch: [122][  100/  100]    Loss 1.425498    Top1 63.790000    Top5 88.650000    
2024-04-05 15:38:21,747 - ==> Top1: 63.790    Top5: 88.650    Loss: 1.425

2024-04-05 15:38:21,750 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:38:21,750 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:38:21,771 - 

2024-04-05 15:38:21,772 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:38:26,401 - Epoch: [123][  100/  500]    Overall Loss 0.451592    Objective Loss 0.451592                                        LR 0.000500    Time 0.046232    
2024-04-05 15:38:30,508 - Epoch: [123][  200/  500]    Overall Loss 0.459478    Objective Loss 0.459478                                        LR 0.000500    Time 0.043626    
2024-04-05 15:38:34,619 - Epoch: [123][  300/  500]    Overall Loss 0.465434    Objective Loss 0.465434                                        LR 0.000500    Time 0.042771    
2024-04-05 15:38:38,733 - Epoch: [123][  400/  500]    Overall Loss 0.466567    Objective Loss 0.466567                                        LR 0.000500    Time 0.042350    
2024-04-05 15:38:42,777 - Epoch: [123][  500/  500]    Overall Loss 0.471145    Objective Loss 0.471145    Top1 84.000000    Top5 98.500000    LR 0.000500    Time 0.041957    
2024-04-05 15:38:42,928 - --- validate (epoch=123)-----------
2024-04-05 15:38:42,928 - 10000 samples (100 per mini-batch)
2024-04-05 15:38:44,464 - Epoch: [123][  100/  100]    Loss 1.432735    Top1 63.670000    Top5 88.640000    
2024-04-05 15:38:44,629 - ==> Top1: 63.670    Top5: 88.640    Loss: 1.433

2024-04-05 15:38:44,633 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:38:44,633 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:38:44,654 - 

2024-04-05 15:38:44,654 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:38:49,198 - Epoch: [124][  100/  500]    Overall Loss 0.450294    Objective Loss 0.450294                                        LR 0.000500    Time 0.045381    
2024-04-05 15:38:53,167 - Epoch: [124][  200/  500]    Overall Loss 0.459502    Objective Loss 0.459502                                        LR 0.000500    Time 0.042508    
2024-04-05 15:38:57,242 - Epoch: [124][  300/  500]    Overall Loss 0.463516    Objective Loss 0.463516                                        LR 0.000500    Time 0.041906    
2024-04-05 15:39:01,380 - Epoch: [124][  400/  500]    Overall Loss 0.463747    Objective Loss 0.463747                                        LR 0.000500    Time 0.041757    
2024-04-05 15:39:05,518 - Epoch: [124][  500/  500]    Overall Loss 0.466265    Objective Loss 0.466265    Top1 90.000000    Top5 99.000000    LR 0.000500    Time 0.041671    
2024-04-05 15:39:05,712 - --- validate (epoch=124)-----------
2024-04-05 15:39:05,713 - 10000 samples (100 per mini-batch)
2024-04-05 15:39:07,252 - Epoch: [124][  100/  100]    Loss 1.423004    Top1 64.170000    Top5 88.830000    
2024-04-05 15:39:07,379 - ==> Top1: 64.170    Top5: 88.830    Loss: 1.423

2024-04-05 15:39:07,386 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:39:07,386 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:39:07,417 - 

2024-04-05 15:39:07,418 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:39:12,129 - Epoch: [125][  100/  500]    Overall Loss 0.465331    Objective Loss 0.465331                                        LR 0.000500    Time 0.047056    
2024-04-05 15:39:16,281 - Epoch: [125][  200/  500]    Overall Loss 0.465979    Objective Loss 0.465979                                        LR 0.000500    Time 0.044259    
2024-04-05 15:39:20,385 - Epoch: [125][  300/  500]    Overall Loss 0.466181    Objective Loss 0.466181                                        LR 0.000500    Time 0.043169    
2024-04-05 15:39:24,505 - Epoch: [125][  400/  500]    Overall Loss 0.469577    Objective Loss 0.469577                                        LR 0.000500    Time 0.042663    
2024-04-05 15:39:28,626 - Epoch: [125][  500/  500]    Overall Loss 0.471750    Objective Loss 0.471750    Top1 79.500000    Top5 98.500000    LR 0.000500    Time 0.042362    
2024-04-05 15:39:28,896 - --- validate (epoch=125)-----------
2024-04-05 15:39:28,896 - 10000 samples (100 per mini-batch)
2024-04-05 15:39:30,394 - Epoch: [125][  100/  100]    Loss 1.438638    Top1 63.790000    Top5 88.510000    
2024-04-05 15:39:30,551 - ==> Top1: 63.790    Top5: 88.510    Loss: 1.439

2024-04-05 15:39:30,558 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:39:30,558 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:39:30,589 - 

2024-04-05 15:39:30,589 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:39:34,969 - Epoch: [126][  100/  500]    Overall Loss 0.443706    Objective Loss 0.443706                                        LR 0.000500    Time 0.043749    
2024-04-05 15:39:39,107 - Epoch: [126][  200/  500]    Overall Loss 0.458957    Objective Loss 0.458957                                        LR 0.000500    Time 0.042535    
2024-04-05 15:39:43,223 - Epoch: [126][  300/  500]    Overall Loss 0.464129    Objective Loss 0.464129                                        LR 0.000500    Time 0.042062    
2024-04-05 15:39:47,332 - Epoch: [126][  400/  500]    Overall Loss 0.464455    Objective Loss 0.464455                                        LR 0.000500    Time 0.041804    
2024-04-05 15:39:51,444 - Epoch: [126][  500/  500]    Overall Loss 0.465897    Objective Loss 0.465897    Top1 87.000000    Top5 97.000000    LR 0.000500    Time 0.041656    
2024-04-05 15:39:51,634 - --- validate (epoch=126)-----------
2024-04-05 15:39:51,635 - 10000 samples (100 per mini-batch)
2024-04-05 15:39:53,082 - Epoch: [126][  100/  100]    Loss 1.442807    Top1 63.710000    Top5 88.660000    
2024-04-05 15:39:53,235 - ==> Top1: 63.710    Top5: 88.660    Loss: 1.443

2024-04-05 15:39:53,241 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:39:53,241 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:39:53,274 - 

2024-04-05 15:39:53,275 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:39:57,484 - Epoch: [127][  100/  500]    Overall Loss 0.451626    Objective Loss 0.451626                                        LR 0.000500    Time 0.042045    
2024-04-05 15:40:01,620 - Epoch: [127][  200/  500]    Overall Loss 0.460878    Objective Loss 0.460878                                        LR 0.000500    Time 0.041672    
2024-04-05 15:40:05,733 - Epoch: [127][  300/  500]    Overall Loss 0.460454    Objective Loss 0.460454                                        LR 0.000500    Time 0.041475    
2024-04-05 15:40:09,847 - Epoch: [127][  400/  500]    Overall Loss 0.462899    Objective Loss 0.462899                                        LR 0.000500    Time 0.041377    
2024-04-05 15:40:13,971 - Epoch: [127][  500/  500]    Overall Loss 0.464901    Objective Loss 0.464901    Top1 89.500000    Top5 98.500000    LR 0.000500    Time 0.041341    
2024-04-05 15:40:14,209 - --- validate (epoch=127)-----------
2024-04-05 15:40:14,210 - 10000 samples (100 per mini-batch)
2024-04-05 15:40:15,677 - Epoch: [127][  100/  100]    Loss 1.427133    Top1 64.010000    Top5 88.880000    
2024-04-05 15:40:15,846 - ==> Top1: 64.010    Top5: 88.880    Loss: 1.427

2024-04-05 15:40:15,851 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:40:15,852 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:40:15,883 - 

2024-04-05 15:40:15,883 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:40:20,241 - Epoch: [128][  100/  500]    Overall Loss 0.430165    Objective Loss 0.430165                                        LR 0.000500    Time 0.043523    
2024-04-05 15:40:24,226 - Epoch: [128][  200/  500]    Overall Loss 0.438299    Objective Loss 0.438299                                        LR 0.000500    Time 0.041664    
2024-04-05 15:40:28,337 - Epoch: [128][  300/  500]    Overall Loss 0.451756    Objective Loss 0.451756                                        LR 0.000500    Time 0.041461    
2024-04-05 15:40:32,446 - Epoch: [128][  400/  500]    Overall Loss 0.457498    Objective Loss 0.457498                                        LR 0.000500    Time 0.041356    
2024-04-05 15:40:36,568 - Epoch: [128][  500/  500]    Overall Loss 0.457996    Objective Loss 0.457996    Top1 86.000000    Top5 99.000000    LR 0.000500    Time 0.041318    
2024-04-05 15:40:36,733 - --- validate (epoch=128)-----------
2024-04-05 15:40:36,734 - 10000 samples (100 per mini-batch)
2024-04-05 15:40:38,367 - Epoch: [128][  100/  100]    Loss 1.435402    Top1 63.850000    Top5 88.780000    
2024-04-05 15:40:38,622 - ==> Top1: 63.850    Top5: 88.780    Loss: 1.435

2024-04-05 15:40:38,627 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:40:38,628 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:40:38,660 - 

2024-04-05 15:40:38,660 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:40:43,401 - Epoch: [129][  100/  500]    Overall Loss 0.447964    Objective Loss 0.447964                                        LR 0.000500    Time 0.047349    
2024-04-05 15:40:46,574 - Epoch: [129][  200/  500]    Overall Loss 0.452193    Objective Loss 0.452193                                        LR 0.000500    Time 0.039516    
2024-04-05 15:40:49,611 - Epoch: [129][  300/  500]    Overall Loss 0.453761    Objective Loss 0.453761                                        LR 0.000500    Time 0.036454    
2024-04-05 15:40:52,670 - Epoch: [129][  400/  500]    Overall Loss 0.462419    Objective Loss 0.462419                                        LR 0.000500    Time 0.034978    
2024-04-05 15:40:56,665 - Epoch: [129][  500/  500]    Overall Loss 0.463450    Objective Loss 0.463450    Top1 86.000000    Top5 99.500000    LR 0.000500    Time 0.035962    
2024-04-05 15:40:56,952 - --- validate (epoch=129)-----------
2024-04-05 15:40:56,952 - 10000 samples (100 per mini-batch)
2024-04-05 15:40:58,418 - Epoch: [129][  100/  100]    Loss 1.445431    Top1 63.910000    Top5 88.810000    
2024-04-05 15:40:58,568 - ==> Top1: 63.910    Top5: 88.810    Loss: 1.445

2024-04-05 15:40:58,574 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:40:58,574 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:40:58,606 - 

2024-04-05 15:40:58,606 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:41:03,228 - Epoch: [130][  100/  500]    Overall Loss 0.450004    Objective Loss 0.450004                                        LR 0.000500    Time 0.046166    
2024-04-05 15:41:07,330 - Epoch: [130][  200/  500]    Overall Loss 0.444570    Objective Loss 0.444570                                        LR 0.000500    Time 0.043567    
2024-04-05 15:41:11,323 - Epoch: [130][  300/  500]    Overall Loss 0.449334    Objective Loss 0.449334                                        LR 0.000500    Time 0.042337    
2024-04-05 15:41:15,359 - Epoch: [130][  400/  500]    Overall Loss 0.451046    Objective Loss 0.451046                                        LR 0.000500    Time 0.041830    
2024-04-05 15:41:19,482 - Epoch: [130][  500/  500]    Overall Loss 0.458921    Objective Loss 0.458921    Top1 84.500000    Top5 98.000000    LR 0.000500    Time 0.041699    
2024-04-05 15:41:19,708 - --- validate (epoch=130)-----------
2024-04-05 15:41:19,708 - 10000 samples (100 per mini-batch)
2024-04-05 15:41:21,405 - Epoch: [130][  100/  100]    Loss 1.438201    Top1 63.880000    Top5 88.930000    
2024-04-05 15:41:21,552 - ==> Top1: 63.880    Top5: 88.930    Loss: 1.438

2024-04-05 15:41:21,558 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:41:21,558 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:41:21,591 - 

2024-04-05 15:41:21,591 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:41:26,366 - Epoch: [131][  100/  500]    Overall Loss 0.450470    Objective Loss 0.450470                                        LR 0.000500    Time 0.047690    
2024-04-05 15:41:30,502 - Epoch: [131][  200/  500]    Overall Loss 0.444610    Objective Loss 0.444610                                        LR 0.000500    Time 0.044501    
2024-04-05 15:41:34,155 - Epoch: [131][  300/  500]    Overall Loss 0.455940    Objective Loss 0.455940                                        LR 0.000500    Time 0.041828    
2024-04-05 15:41:38,198 - Epoch: [131][  400/  500]    Overall Loss 0.457287    Objective Loss 0.457287                                        LR 0.000500    Time 0.041466    
2024-04-05 15:41:42,325 - Epoch: [131][  500/  500]    Overall Loss 0.461923    Objective Loss 0.461923    Top1 85.000000    Top5 98.000000    LR 0.000500    Time 0.041415    
2024-04-05 15:41:42,530 - --- validate (epoch=131)-----------
2024-04-05 15:41:42,530 - 10000 samples (100 per mini-batch)
2024-04-05 15:41:44,032 - Epoch: [131][  100/  100]    Loss 1.447113    Top1 63.950000    Top5 88.650000    
2024-04-05 15:41:44,209 - ==> Top1: 63.950    Top5: 88.650    Loss: 1.447

2024-04-05 15:41:44,216 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:41:44,216 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:41:44,248 - 

2024-04-05 15:41:44,249 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:41:49,157 - Epoch: [132][  100/  500]    Overall Loss 0.448867    Objective Loss 0.448867                                        LR 0.000500    Time 0.049017    
2024-04-05 15:41:53,301 - Epoch: [132][  200/  500]    Overall Loss 0.451991    Objective Loss 0.451991                                        LR 0.000500    Time 0.045201    
2024-04-05 15:41:57,242 - Epoch: [132][  300/  500]    Overall Loss 0.453354    Objective Loss 0.453354                                        LR 0.000500    Time 0.043255    
2024-04-05 15:42:01,327 - Epoch: [132][  400/  500]    Overall Loss 0.458819    Objective Loss 0.458819                                        LR 0.000500    Time 0.042643    
2024-04-05 15:42:05,454 - Epoch: [132][  500/  500]    Overall Loss 0.461318    Objective Loss 0.461318    Top1 85.000000    Top5 98.500000    LR 0.000500    Time 0.042357    
2024-04-05 15:42:05,657 - --- validate (epoch=132)-----------
2024-04-05 15:42:05,657 - 10000 samples (100 per mini-batch)
2024-04-05 15:42:07,088 - Epoch: [132][  100/  100]    Loss 1.443172    Top1 63.500000    Top5 88.780000    
2024-04-05 15:42:07,234 - ==> Top1: 63.500    Top5: 88.780    Loss: 1.443

2024-04-05 15:42:07,241 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:42:07,241 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:42:07,272 - 

2024-04-05 15:42:07,272 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:42:11,975 - Epoch: [133][  100/  500]    Overall Loss 0.440831    Objective Loss 0.440831                                        LR 0.000500    Time 0.046973    
2024-04-05 15:42:16,100 - Epoch: [133][  200/  500]    Overall Loss 0.437371    Objective Loss 0.437371                                        LR 0.000500    Time 0.044086    
2024-04-05 15:42:20,204 - Epoch: [133][  300/  500]    Overall Loss 0.446986    Objective Loss 0.446986                                        LR 0.000500    Time 0.043051    
2024-04-05 15:42:23,757 - Epoch: [133][  400/  500]    Overall Loss 0.453284    Objective Loss 0.453284                                        LR 0.000500    Time 0.041161    
2024-04-05 15:42:27,971 - Epoch: [133][  500/  500]    Overall Loss 0.455810    Objective Loss 0.455810    Top1 87.500000    Top5 98.000000    LR 0.000500    Time 0.041345    
2024-04-05 15:42:28,279 - --- validate (epoch=133)-----------
2024-04-05 15:42:28,280 - 10000 samples (100 per mini-batch)
2024-04-05 15:42:29,713 - Epoch: [133][  100/  100]    Loss 1.455622    Top1 63.570000    Top5 88.610000    
2024-04-05 15:42:29,874 - ==> Top1: 63.570    Top5: 88.610    Loss: 1.456

2024-04-05 15:42:29,877 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:42:29,877 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:42:29,898 - 

2024-04-05 15:42:29,899 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:42:33,709 - Epoch: [134][  100/  500]    Overall Loss 0.439127    Objective Loss 0.439127                                        LR 0.000500    Time 0.038062    
2024-04-05 15:42:36,754 - Epoch: [134][  200/  500]    Overall Loss 0.442428    Objective Loss 0.442428                                        LR 0.000500    Time 0.034233    
2024-04-05 15:42:39,882 - Epoch: [134][  300/  500]    Overall Loss 0.448660    Objective Loss 0.448660                                        LR 0.000500    Time 0.033233    
2024-04-05 15:42:43,182 - Epoch: [134][  400/  500]    Overall Loss 0.449075    Objective Loss 0.449075                                        LR 0.000500    Time 0.033163    
2024-04-05 15:42:46,721 - Epoch: [134][  500/  500]    Overall Loss 0.453600    Objective Loss 0.453600    Top1 83.000000    Top5 98.000000    LR 0.000500    Time 0.033600    
2024-04-05 15:42:46,920 - --- validate (epoch=134)-----------
2024-04-05 15:42:46,921 - 10000 samples (100 per mini-batch)
2024-04-05 15:42:48,255 - Epoch: [134][  100/  100]    Loss 1.445068    Top1 64.080000    Top5 89.000000    
2024-04-05 15:42:48,439 - ==> Top1: 64.080    Top5: 89.000    Loss: 1.445

2024-04-05 15:42:48,446 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:42:48,446 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:42:48,478 - 

2024-04-05 15:42:48,479 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:42:53,235 - Epoch: [135][  100/  500]    Overall Loss 0.441290    Objective Loss 0.441290                                        LR 0.000500    Time 0.047507    
2024-04-05 15:42:57,409 - Epoch: [135][  200/  500]    Overall Loss 0.443497    Objective Loss 0.443497                                        LR 0.000500    Time 0.044596    
2024-04-05 15:43:01,503 - Epoch: [135][  300/  500]    Overall Loss 0.444102    Objective Loss 0.444102                                        LR 0.000500    Time 0.043361    
2024-04-05 15:43:04,854 - Epoch: [135][  400/  500]    Overall Loss 0.452778    Objective Loss 0.452778                                        LR 0.000500    Time 0.040886    
2024-04-05 15:43:08,984 - Epoch: [135][  500/  500]    Overall Loss 0.452979    Objective Loss 0.452979    Top1 86.500000    Top5 100.000000    LR 0.000500    Time 0.040959    
2024-04-05 15:43:09,198 - --- validate (epoch=135)-----------
2024-04-05 15:43:09,199 - 10000 samples (100 per mini-batch)
2024-04-05 15:43:10,638 - Epoch: [135][  100/  100]    Loss 1.447723    Top1 64.040000    Top5 88.790000    
2024-04-05 15:43:10,816 - ==> Top1: 64.040    Top5: 88.790    Loss: 1.448

2024-04-05 15:43:10,822 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:43:10,822 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:43:10,855 - 

2024-04-05 15:43:10,855 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:43:15,423 - Epoch: [136][  100/  500]    Overall Loss 0.431496    Objective Loss 0.431496                                        LR 0.000500    Time 0.045625    
2024-04-05 15:43:19,570 - Epoch: [136][  200/  500]    Overall Loss 0.435037    Objective Loss 0.435037                                        LR 0.000500    Time 0.043519    
2024-04-05 15:43:23,769 - Epoch: [136][  300/  500]    Overall Loss 0.441306    Objective Loss 0.441306                                        LR 0.000500    Time 0.042992    
2024-04-05 15:43:27,566 - Epoch: [136][  400/  500]    Overall Loss 0.448525    Objective Loss 0.448525                                        LR 0.000500    Time 0.041724    
2024-04-05 15:43:30,728 - Epoch: [136][  500/  500]    Overall Loss 0.451124    Objective Loss 0.451124    Top1 86.500000    Top5 99.500000    LR 0.000500    Time 0.039694    
2024-04-05 15:43:31,013 - --- validate (epoch=136)-----------
2024-04-05 15:43:31,013 - 10000 samples (100 per mini-batch)
2024-04-05 15:43:32,712 - Epoch: [136][  100/  100]    Loss 1.448428    Top1 63.930000    Top5 88.830000    
2024-04-05 15:43:32,892 - ==> Top1: 63.930    Top5: 88.830    Loss: 1.448

2024-04-05 15:43:32,897 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:43:32,898 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:43:32,931 - 

2024-04-05 15:43:32,931 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:43:37,701 - Epoch: [137][  100/  500]    Overall Loss 0.446291    Objective Loss 0.446291                                        LR 0.000500    Time 0.047642    
2024-04-05 15:43:41,813 - Epoch: [137][  200/  500]    Overall Loss 0.443556    Objective Loss 0.443556                                        LR 0.000500    Time 0.044352    
2024-04-05 15:43:45,336 - Epoch: [137][  300/  500]    Overall Loss 0.444483    Objective Loss 0.444483                                        LR 0.000500    Time 0.041296    
2024-04-05 15:43:49,493 - Epoch: [137][  400/  500]    Overall Loss 0.449359    Objective Loss 0.449359                                        LR 0.000500    Time 0.041350    
2024-04-05 15:43:53,608 - Epoch: [137][  500/  500]    Overall Loss 0.447850    Objective Loss 0.447850    Top1 85.500000    Top5 99.500000    LR 0.000500    Time 0.041300    
2024-04-05 15:43:53,833 - --- validate (epoch=137)-----------
2024-04-05 15:43:53,833 - 10000 samples (100 per mini-batch)
2024-04-05 15:43:55,270 - Epoch: [137][  100/  100]    Loss 1.433063    Top1 64.070000    Top5 88.790000    
2024-04-05 15:43:55,441 - ==> Top1: 64.070    Top5: 88.790    Loss: 1.433

2024-04-05 15:43:55,447 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:43:55,447 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:43:55,479 - 

2024-04-05 15:43:55,479 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:43:59,800 - Epoch: [138][  100/  500]    Overall Loss 0.427848    Objective Loss 0.427848                                        LR 0.000500    Time 0.043151    
2024-04-05 15:44:03,913 - Epoch: [138][  200/  500]    Overall Loss 0.433343    Objective Loss 0.433343                                        LR 0.000500    Time 0.042112    
2024-04-05 15:44:07,747 - Epoch: [138][  300/  500]    Overall Loss 0.435018    Objective Loss 0.435018                                        LR 0.000500    Time 0.040841    
2024-04-05 15:44:11,861 - Epoch: [138][  400/  500]    Overall Loss 0.439223    Objective Loss 0.439223                                        LR 0.000500    Time 0.040902    
2024-04-05 15:44:16,013 - Epoch: [138][  500/  500]    Overall Loss 0.443499    Objective Loss 0.443499    Top1 83.000000    Top5 97.500000    LR 0.000500    Time 0.041012    
2024-04-05 15:44:16,246 - --- validate (epoch=138)-----------
2024-04-05 15:44:16,247 - 10000 samples (100 per mini-batch)
2024-04-05 15:44:17,866 - Epoch: [138][  100/  100]    Loss 1.451341    Top1 63.720000    Top5 88.800000    
2024-04-05 15:44:18,000 - ==> Top1: 63.720    Top5: 88.800    Loss: 1.451

2024-04-05 15:44:18,007 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:44:18,007 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:44:18,038 - 

2024-04-05 15:44:18,039 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:44:22,726 - Epoch: [139][  100/  500]    Overall Loss 0.443494    Objective Loss 0.443494                                        LR 0.000500    Time 0.046816    
2024-04-05 15:44:26,877 - Epoch: [139][  200/  500]    Overall Loss 0.443551    Objective Loss 0.443551                                        LR 0.000500    Time 0.044137    
2024-04-05 15:44:30,674 - Epoch: [139][  300/  500]    Overall Loss 0.447069    Objective Loss 0.447069                                        LR 0.000500    Time 0.042063    
2024-04-05 15:44:34,608 - Epoch: [139][  400/  500]    Overall Loss 0.443453    Objective Loss 0.443453                                        LR 0.000500    Time 0.041372    
2024-04-05 15:44:38,722 - Epoch: [139][  500/  500]    Overall Loss 0.447932    Objective Loss 0.447932    Top1 88.500000    Top5 98.500000    LR 0.000500    Time 0.041315    
2024-04-05 15:44:38,950 - --- validate (epoch=139)-----------
2024-04-05 15:44:38,950 - 10000 samples (100 per mini-batch)
2024-04-05 15:44:40,377 - Epoch: [139][  100/  100]    Loss 1.442637    Top1 63.980000    Top5 88.930000    
2024-04-05 15:44:40,579 - ==> Top1: 63.980    Top5: 88.930    Loss: 1.443

2024-04-05 15:44:40,585 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:44:40,585 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:44:40,618 - 

2024-04-05 15:44:40,618 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:44:45,506 - Epoch: [140][  100/  500]    Overall Loss 0.436204    Objective Loss 0.436204                                        LR 0.000500    Time 0.048815    
2024-04-05 15:44:49,714 - Epoch: [140][  200/  500]    Overall Loss 0.443653    Objective Loss 0.443653                                        LR 0.000500    Time 0.045423    
2024-04-05 15:44:53,485 - Epoch: [140][  300/  500]    Overall Loss 0.442233    Objective Loss 0.442233                                        LR 0.000500    Time 0.042835    
2024-04-05 15:44:57,635 - Epoch: [140][  400/  500]    Overall Loss 0.445609    Objective Loss 0.445609                                        LR 0.000500    Time 0.042490    
2024-04-05 15:45:01,784 - Epoch: [140][  500/  500]    Overall Loss 0.448329    Objective Loss 0.448329    Top1 89.500000    Top5 99.000000    LR 0.000500    Time 0.042278    
2024-04-05 15:45:02,066 - --- validate (epoch=140)-----------
2024-04-05 15:45:02,066 - 10000 samples (100 per mini-batch)
2024-04-05 15:45:03,470 - Epoch: [140][  100/  100]    Loss 1.452038    Top1 63.960000    Top5 88.700000    
2024-04-05 15:45:03,629 - ==> Top1: 63.960    Top5: 88.700    Loss: 1.452

2024-04-05 15:45:03,635 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:45:03,635 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:45:03,666 - 

2024-04-05 15:45:03,666 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:45:08,354 - Epoch: [141][  100/  500]    Overall Loss 0.422513    Objective Loss 0.422513                                        LR 0.000500    Time 0.046819    
2024-04-05 15:45:12,491 - Epoch: [141][  200/  500]    Overall Loss 0.424347    Objective Loss 0.424347                                        LR 0.000500    Time 0.044070    
2024-04-05 15:45:15,906 - Epoch: [141][  300/  500]    Overall Loss 0.433561    Objective Loss 0.433561                                        LR 0.000500    Time 0.040749    
2024-04-05 15:45:20,052 - Epoch: [141][  400/  500]    Overall Loss 0.436249    Objective Loss 0.436249                                        LR 0.000500    Time 0.040913    
2024-04-05 15:45:24,165 - Epoch: [141][  500/  500]    Overall Loss 0.439059    Objective Loss 0.439059    Top1 85.500000    Top5 98.000000    LR 0.000500    Time 0.040946    
2024-04-05 15:45:24,446 - --- validate (epoch=141)-----------
2024-04-05 15:45:24,447 - 10000 samples (100 per mini-batch)
2024-04-05 15:45:25,864 - Epoch: [141][  100/  100]    Loss 1.446009    Top1 64.230000    Top5 88.920000    
2024-04-05 15:45:26,022 - ==> Top1: 64.230    Top5: 88.920    Loss: 1.446

2024-04-05 15:45:26,026 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:45:26,026 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:45:26,049 - 

2024-04-05 15:45:26,050 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:45:31,035 - Epoch: [142][  100/  500]    Overall Loss 0.422310    Objective Loss 0.422310                                        LR 0.000500    Time 0.049797    
2024-04-05 15:45:35,122 - Epoch: [142][  200/  500]    Overall Loss 0.433389    Objective Loss 0.433389                                        LR 0.000500    Time 0.045307    
2024-04-05 15:45:38,998 - Epoch: [142][  300/  500]    Overall Loss 0.432873    Objective Loss 0.432873                                        LR 0.000500    Time 0.043110    
2024-04-05 15:45:42,830 - Epoch: [142][  400/  500]    Overall Loss 0.435917    Objective Loss 0.435917                                        LR 0.000500    Time 0.041899    
2024-04-05 15:45:46,957 - Epoch: [142][  500/  500]    Overall Loss 0.437404    Objective Loss 0.437404    Top1 88.000000    Top5 99.500000    LR 0.000500    Time 0.041762    
2024-04-05 15:45:47,154 - --- validate (epoch=142)-----------
2024-04-05 15:45:47,154 - 10000 samples (100 per mini-batch)
2024-04-05 15:45:48,635 - Epoch: [142][  100/  100]    Loss 1.464619    Top1 63.820000    Top5 88.620000    
2024-04-05 15:45:48,803 - ==> Top1: 63.820    Top5: 88.620    Loss: 1.465

2024-04-05 15:45:48,809 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:45:48,809 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:45:48,840 - 

2024-04-05 15:45:48,840 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:45:53,579 - Epoch: [143][  100/  500]    Overall Loss 0.418838    Objective Loss 0.418838                                        LR 0.000500    Time 0.047334    
2024-04-05 15:45:57,712 - Epoch: [143][  200/  500]    Overall Loss 0.430323    Objective Loss 0.430323                                        LR 0.000500    Time 0.044300    
2024-04-05 15:46:01,139 - Epoch: [143][  300/  500]    Overall Loss 0.429918    Objective Loss 0.429918                                        LR 0.000500    Time 0.040944    
2024-04-05 15:46:05,277 - Epoch: [143][  400/  500]    Overall Loss 0.434885    Objective Loss 0.434885                                        LR 0.000500    Time 0.041040    
2024-04-05 15:46:09,426 - Epoch: [143][  500/  500]    Overall Loss 0.436048    Objective Loss 0.436048    Top1 87.500000    Top5 99.500000    LR 0.000500    Time 0.041118    
2024-04-05 15:46:09,656 - --- validate (epoch=143)-----------
2024-04-05 15:46:09,656 - 10000 samples (100 per mini-batch)
2024-04-05 15:46:11,112 - Epoch: [143][  100/  100]    Loss 1.466624    Top1 63.760000    Top5 88.510000    
2024-04-05 15:46:11,266 - ==> Top1: 63.760    Top5: 88.510    Loss: 1.467

2024-04-05 15:46:11,272 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:46:11,272 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:46:11,304 - 

2024-04-05 15:46:11,305 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:46:16,030 - Epoch: [144][  100/  500]    Overall Loss 0.434803    Objective Loss 0.434803                                        LR 0.000500    Time 0.047193    
2024-04-05 15:46:20,239 - Epoch: [144][  200/  500]    Overall Loss 0.437903    Objective Loss 0.437903                                        LR 0.000500    Time 0.044615    
2024-04-05 15:46:24,301 - Epoch: [144][  300/  500]    Overall Loss 0.435166    Objective Loss 0.435166                                        LR 0.000500    Time 0.043266    
2024-04-05 15:46:27,956 - Epoch: [144][  400/  500]    Overall Loss 0.433170    Objective Loss 0.433170                                        LR 0.000500    Time 0.041577    
2024-04-05 15:46:32,111 - Epoch: [144][  500/  500]    Overall Loss 0.439347    Objective Loss 0.439347    Top1 85.000000    Top5 98.500000    LR 0.000500    Time 0.041560    
2024-04-05 15:46:32,341 - --- validate (epoch=144)-----------
2024-04-05 15:46:32,342 - 10000 samples (100 per mini-batch)
2024-04-05 15:46:34,087 - Epoch: [144][  100/  100]    Loss 1.468661    Top1 63.670000    Top5 88.840000    
2024-04-05 15:46:34,274 - ==> Top1: 63.670    Top5: 88.840    Loss: 1.469

2024-04-05 15:46:34,280 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:46:34,281 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:46:34,312 - 

2024-04-05 15:46:34,313 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:46:39,090 - Epoch: [145][  100/  500]    Overall Loss 0.424121    Objective Loss 0.424121                                        LR 0.000500    Time 0.047717    
2024-04-05 15:46:43,244 - Epoch: [145][  200/  500]    Overall Loss 0.431256    Objective Loss 0.431256                                        LR 0.000500    Time 0.044601    
2024-04-05 15:46:47,369 - Epoch: [145][  300/  500]    Overall Loss 0.431903    Objective Loss 0.431903                                        LR 0.000500    Time 0.043466    
2024-04-05 15:46:50,848 - Epoch: [145][  400/  500]    Overall Loss 0.435755    Objective Loss 0.435755                                        LR 0.000500    Time 0.041285    
2024-04-05 15:46:55,026 - Epoch: [145][  500/  500]    Overall Loss 0.438586    Objective Loss 0.438586    Top1 85.500000    Top5 98.500000    LR 0.000500    Time 0.041374    
2024-04-05 15:46:55,196 - --- validate (epoch=145)-----------
2024-04-05 15:46:55,197 - 10000 samples (100 per mini-batch)
2024-04-05 15:46:56,623 - Epoch: [145][  100/  100]    Loss 1.474364    Top1 63.720000    Top5 88.570000    
2024-04-05 15:46:56,779 - ==> Top1: 63.720    Top5: 88.570    Loss: 1.474

2024-04-05 15:46:56,785 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:46:56,785 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:46:56,818 - 

2024-04-05 15:46:56,819 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:47:01,748 - Epoch: [146][  100/  500]    Overall Loss 0.414289    Objective Loss 0.414289                                        LR 0.000500    Time 0.049234    
2024-04-05 15:47:05,934 - Epoch: [146][  200/  500]    Overall Loss 0.426955    Objective Loss 0.426955                                        LR 0.000500    Time 0.045518    
2024-04-05 15:47:10,084 - Epoch: [146][  300/  500]    Overall Loss 0.425341    Objective Loss 0.425341                                        LR 0.000500    Time 0.044162    
2024-04-05 15:47:13,585 - Epoch: [146][  400/  500]    Overall Loss 0.427455    Objective Loss 0.427455                                        LR 0.000500    Time 0.041861    
2024-04-05 15:47:17,691 - Epoch: [146][  500/  500]    Overall Loss 0.431772    Objective Loss 0.431772    Top1 85.000000    Top5 99.000000    LR 0.000500    Time 0.041690    
2024-04-05 15:47:17,986 - --- validate (epoch=146)-----------
2024-04-05 15:47:17,987 - 10000 samples (100 per mini-batch)
2024-04-05 15:47:19,510 - Epoch: [146][  100/  100]    Loss 1.463528    Top1 63.880000    Top5 88.700000    
2024-04-05 15:47:19,705 - ==> Top1: 63.880    Top5: 88.700    Loss: 1.464

2024-04-05 15:47:19,711 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:47:19,711 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:47:19,744 - 

2024-04-05 15:47:19,744 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:47:24,469 - Epoch: [147][  100/  500]    Overall Loss 0.439732    Objective Loss 0.439732                                        LR 0.000500    Time 0.047187    
2024-04-05 15:47:28,658 - Epoch: [147][  200/  500]    Overall Loss 0.434190    Objective Loss 0.434190                                        LR 0.000500    Time 0.044513    
2024-04-05 15:47:32,356 - Epoch: [147][  300/  500]    Overall Loss 0.439842    Objective Loss 0.439842                                        LR 0.000500    Time 0.041985    
2024-04-05 15:47:36,280 - Epoch: [147][  400/  500]    Overall Loss 0.439679    Objective Loss 0.439679                                        LR 0.000500    Time 0.041288    
2024-04-05 15:47:40,375 - Epoch: [147][  500/  500]    Overall Loss 0.439582    Objective Loss 0.439582    Top1 86.000000    Top5 99.000000    LR 0.000500    Time 0.041209    
2024-04-05 15:47:40,544 - --- validate (epoch=147)-----------
2024-04-05 15:47:40,545 - 10000 samples (100 per mini-batch)
2024-04-05 15:47:41,990 - Epoch: [147][  100/  100]    Loss 1.462086    Top1 64.230000    Top5 88.670000    
2024-04-05 15:47:42,142 - ==> Top1: 64.230    Top5: 88.670    Loss: 1.462

2024-04-05 15:47:42,148 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:47:42,148 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:47:42,179 - 

2024-04-05 15:47:42,180 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:47:46,867 - Epoch: [148][  100/  500]    Overall Loss 0.419628    Objective Loss 0.419628                                        LR 0.000500    Time 0.046817    
2024-04-05 15:47:50,986 - Epoch: [148][  200/  500]    Overall Loss 0.421199    Objective Loss 0.421199                                        LR 0.000500    Time 0.043978    
2024-04-05 15:47:55,101 - Epoch: [148][  300/  500]    Overall Loss 0.426382    Objective Loss 0.426382                                        LR 0.000500    Time 0.043017    
2024-04-05 15:47:58,427 - Epoch: [148][  400/  500]    Overall Loss 0.428158    Objective Loss 0.428158                                        LR 0.000500    Time 0.040566    
2024-04-05 15:48:02,560 - Epoch: [148][  500/  500]    Overall Loss 0.433210    Objective Loss 0.433210    Top1 83.500000    Top5 99.500000    LR 0.000500    Time 0.040709    
2024-04-05 15:48:02,837 - --- validate (epoch=148)-----------
2024-04-05 15:48:02,838 - 10000 samples (100 per mini-batch)
2024-04-05 15:48:04,490 - Epoch: [148][  100/  100]    Loss 1.463296    Top1 63.950000    Top5 88.520000    
2024-04-05 15:48:04,636 - ==> Top1: 63.950    Top5: 88.520    Loss: 1.463

2024-04-05 15:48:04,642 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:48:04,642 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:48:04,673 - 

2024-04-05 15:48:04,674 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:48:09,361 - Epoch: [149][  100/  500]    Overall Loss 0.436748    Objective Loss 0.436748                                        LR 0.000500    Time 0.046814    
2024-04-05 15:48:13,478 - Epoch: [149][  200/  500]    Overall Loss 0.432200    Objective Loss 0.432200                                        LR 0.000500    Time 0.043964    
2024-04-05 15:48:17,625 - Epoch: [149][  300/  500]    Overall Loss 0.433517    Objective Loss 0.433517                                        LR 0.000500    Time 0.043116    
2024-04-05 15:48:21,143 - Epoch: [149][  400/  500]    Overall Loss 0.435249    Objective Loss 0.435249                                        LR 0.000500    Time 0.041121    
2024-04-05 15:48:24,233 - Epoch: [149][  500/  500]    Overall Loss 0.437811    Objective Loss 0.437811    Top1 81.000000    Top5 98.000000    LR 0.000500    Time 0.039068    
2024-04-05 15:48:24,459 - --- validate (epoch=149)-----------
2024-04-05 15:48:24,460 - 10000 samples (100 per mini-batch)
2024-04-05 15:48:25,920 - Epoch: [149][  100/  100]    Loss 1.479515    Top1 63.980000    Top5 88.610000    
2024-04-05 15:48:26,064 - ==> Top1: 63.980    Top5: 88.610    Loss: 1.480

2024-04-05 15:48:26,068 - ==> Best [Top1: 64.250   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 107]
2024-04-05 15:48:26,068 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:48:26,090 - 

2024-04-05 15:48:26,090 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:48:29,985 - Epoch: [150][  100/  500]    Overall Loss 0.402593    Objective Loss 0.402593                                        LR 0.000250    Time 0.038901    
2024-04-05 15:48:33,167 - Epoch: [150][  200/  500]    Overall Loss 0.404587    Objective Loss 0.404587                                        LR 0.000250    Time 0.035337    
2024-04-05 15:48:37,121 - Epoch: [150][  300/  500]    Overall Loss 0.407143    Objective Loss 0.407143                                        LR 0.000250    Time 0.036721    
2024-04-05 15:48:41,109 - Epoch: [150][  400/  500]    Overall Loss 0.404961    Objective Loss 0.404961                                        LR 0.000250    Time 0.037500    
2024-04-05 15:48:45,240 - Epoch: [150][  500/  500]    Overall Loss 0.406033    Objective Loss 0.406033    Top1 93.000000    Top5 100.000000    LR 0.000250    Time 0.038251    
2024-04-05 15:48:45,540 - --- validate (epoch=150)-----------
2024-04-05 15:48:45,540 - 10000 samples (100 per mini-batch)
2024-04-05 15:48:47,017 - Epoch: [150][  100/  100]    Loss 1.443666    Top1 64.620000    Top5 88.830000    
2024-04-05 15:48:47,176 - ==> Top1: 64.620    Top5: 88.830    Loss: 1.444

2024-04-05 15:48:47,182 - ==> Best [Top1: 64.620   Top5: 88.830   Sparsity:0.00   Params: 347840 on epoch: 150]
2024-04-05 15:48:47,182 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:48:47,221 - 

2024-04-05 15:48:47,221 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:48:51,881 - Epoch: [151][  100/  500]    Overall Loss 0.395105    Objective Loss 0.395105                                        LR 0.000250    Time 0.046522    
2024-04-05 15:48:56,005 - Epoch: [151][  200/  500]    Overall Loss 0.387718    Objective Loss 0.387718                                        LR 0.000250    Time 0.043855    
2024-04-05 15:49:00,143 - Epoch: [151][  300/  500]    Overall Loss 0.385662    Objective Loss 0.385662                                        LR 0.000250    Time 0.043014    
2024-04-05 15:49:04,177 - Epoch: [151][  400/  500]    Overall Loss 0.388257    Objective Loss 0.388257                                        LR 0.000250    Time 0.042332    
2024-04-05 15:49:07,684 - Epoch: [151][  500/  500]    Overall Loss 0.390008    Objective Loss 0.390008    Top1 92.000000    Top5 100.000000    LR 0.000250    Time 0.040872    
2024-04-05 15:49:07,887 - --- validate (epoch=151)-----------
2024-04-05 15:49:07,888 - 10000 samples (100 per mini-batch)
2024-04-05 15:49:09,320 - Epoch: [151][  100/  100]    Loss 1.428976    Top1 64.690000    Top5 88.860000    
2024-04-05 15:49:09,489 - ==> Top1: 64.690    Top5: 88.860    Loss: 1.429

2024-04-05 15:49:09,494 - ==> Best [Top1: 64.690   Top5: 88.860   Sparsity:0.00   Params: 347840 on epoch: 151]
2024-04-05 15:49:09,495 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:49:09,533 - 

2024-04-05 15:49:09,534 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:49:14,297 - Epoch: [152][  100/  500]    Overall Loss 0.369711    Objective Loss 0.369711                                        LR 0.000250    Time 0.047574    
2024-04-05 15:49:18,454 - Epoch: [152][  200/  500]    Overall Loss 0.373915    Objective Loss 0.373915                                        LR 0.000250    Time 0.044540    
2024-04-05 15:49:22,620 - Epoch: [152][  300/  500]    Overall Loss 0.381393    Objective Loss 0.381393                                        LR 0.000250    Time 0.043560    
2024-04-05 15:49:26,761 - Epoch: [152][  400/  500]    Overall Loss 0.386804    Objective Loss 0.386804                                        LR 0.000250    Time 0.043008    
2024-04-05 15:49:30,333 - Epoch: [152][  500/  500]    Overall Loss 0.390706    Objective Loss 0.390706    Top1 85.000000    Top5 99.500000    LR 0.000250    Time 0.041541    
2024-04-05 15:49:30,594 - --- validate (epoch=152)-----------
2024-04-05 15:49:30,595 - 10000 samples (100 per mini-batch)
2024-04-05 15:49:32,222 - Epoch: [152][  100/  100]    Loss 1.433518    Top1 64.500000    Top5 88.940000    
2024-04-05 15:49:32,378 - ==> Top1: 64.500    Top5: 88.940    Loss: 1.434

2024-04-05 15:49:32,384 - ==> Best [Top1: 64.690   Top5: 88.860   Sparsity:0.00   Params: 347840 on epoch: 151]
2024-04-05 15:49:32,384 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:49:32,415 - 

2024-04-05 15:49:32,416 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:49:37,082 - Epoch: [153][  100/  500]    Overall Loss 0.373322    Objective Loss 0.373322                                        LR 0.000250    Time 0.046610    
2024-04-05 15:49:41,215 - Epoch: [153][  200/  500]    Overall Loss 0.380259    Objective Loss 0.380259                                        LR 0.000250    Time 0.043944    
2024-04-05 15:49:45,353 - Epoch: [153][  300/  500]    Overall Loss 0.383332    Objective Loss 0.383332                                        LR 0.000250    Time 0.043070    
2024-04-05 15:49:49,482 - Epoch: [153][  400/  500]    Overall Loss 0.385831    Objective Loss 0.385831                                        LR 0.000250    Time 0.042612    
2024-04-05 15:49:53,120 - Epoch: [153][  500/  500]    Overall Loss 0.387768    Objective Loss 0.387768    Top1 88.000000    Top5 99.000000    LR 0.000250    Time 0.041356    
2024-04-05 15:49:53,325 - --- validate (epoch=153)-----------
2024-04-05 15:49:53,326 - 10000 samples (100 per mini-batch)
2024-04-05 15:49:54,723 - Epoch: [153][  100/  100]    Loss 1.433360    Top1 64.570000    Top5 89.070000    
2024-04-05 15:49:54,871 - ==> Top1: 64.570    Top5: 89.070    Loss: 1.433

2024-04-05 15:49:54,877 - ==> Best [Top1: 64.690   Top5: 88.860   Sparsity:0.00   Params: 347840 on epoch: 151]
2024-04-05 15:49:54,877 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:49:54,908 - 

2024-04-05 15:49:54,908 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:49:59,535 - Epoch: [154][  100/  500]    Overall Loss 0.368111    Objective Loss 0.368111                                        LR 0.000250    Time 0.046214    
2024-04-05 15:50:03,633 - Epoch: [154][  200/  500]    Overall Loss 0.377434    Objective Loss 0.377434                                        LR 0.000250    Time 0.043570    
2024-04-05 15:50:07,780 - Epoch: [154][  300/  500]    Overall Loss 0.380491    Objective Loss 0.380491                                        LR 0.000250    Time 0.042851    
2024-04-05 15:50:11,861 - Epoch: [154][  400/  500]    Overall Loss 0.380497    Objective Loss 0.380497                                        LR 0.000250    Time 0.042327    
2024-04-05 15:50:15,816 - Epoch: [154][  500/  500]    Overall Loss 0.381910    Objective Loss 0.381910    Top1 88.000000    Top5 100.000000    LR 0.000250    Time 0.041761    
2024-04-05 15:50:16,025 - --- validate (epoch=154)-----------
2024-04-05 15:50:16,025 - 10000 samples (100 per mini-batch)
2024-04-05 15:50:17,457 - Epoch: [154][  100/  100]    Loss 1.444001    Top1 64.320000    Top5 88.820000    
2024-04-05 15:50:17,611 - ==> Top1: 64.320    Top5: 88.820    Loss: 1.444

2024-04-05 15:50:17,618 - ==> Best [Top1: 64.690   Top5: 88.860   Sparsity:0.00   Params: 347840 on epoch: 151]
2024-04-05 15:50:17,618 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:50:17,651 - 

2024-04-05 15:50:17,651 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:50:22,318 - Epoch: [155][  100/  500]    Overall Loss 0.371824    Objective Loss 0.371824                                        LR 0.000250    Time 0.046612    
2024-04-05 15:50:26,434 - Epoch: [155][  200/  500]    Overall Loss 0.377566    Objective Loss 0.377566                                        LR 0.000250    Time 0.043861    
2024-04-05 15:50:30,543 - Epoch: [155][  300/  500]    Overall Loss 0.377358    Objective Loss 0.377358                                        LR 0.000250    Time 0.042920    
2024-04-05 15:50:34,658 - Epoch: [155][  400/  500]    Overall Loss 0.381892    Objective Loss 0.381892                                        LR 0.000250    Time 0.042463    
2024-04-05 15:50:38,769 - Epoch: [155][  500/  500]    Overall Loss 0.383487    Objective Loss 0.383487    Top1 89.000000    Top5 100.000000    LR 0.000250    Time 0.042182    
2024-04-05 15:50:38,976 - --- validate (epoch=155)-----------
2024-04-05 15:50:38,977 - 10000 samples (100 per mini-batch)
2024-04-05 15:50:40,742 - Epoch: [155][  100/  100]    Loss 1.449248    Top1 64.320000    Top5 88.990000    
2024-04-05 15:50:40,930 - ==> Top1: 64.320    Top5: 88.990    Loss: 1.449

2024-04-05 15:50:40,934 - ==> Best [Top1: 64.690   Top5: 88.860   Sparsity:0.00   Params: 347840 on epoch: 151]
2024-04-05 15:50:40,934 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:50:40,955 - 

2024-04-05 15:50:40,955 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:50:45,686 - Epoch: [156][  100/  500]    Overall Loss 0.367442    Objective Loss 0.367442                                        LR 0.000250    Time 0.047250    
2024-04-05 15:50:49,841 - Epoch: [156][  200/  500]    Overall Loss 0.372460    Objective Loss 0.372460                                        LR 0.000250    Time 0.044369    
2024-04-05 15:50:53,958 - Epoch: [156][  300/  500]    Overall Loss 0.373576    Objective Loss 0.373576                                        LR 0.000250    Time 0.043286    
2024-04-05 15:50:58,074 - Epoch: [156][  400/  500]    Overall Loss 0.376357    Objective Loss 0.376357                                        LR 0.000250    Time 0.042743    
2024-04-05 15:51:02,197 - Epoch: [156][  500/  500]    Overall Loss 0.378429    Objective Loss 0.378429    Top1 86.500000    Top5 98.500000    LR 0.000250    Time 0.042430    
2024-04-05 15:51:02,409 - --- validate (epoch=156)-----------
2024-04-05 15:51:02,410 - 10000 samples (100 per mini-batch)
2024-04-05 15:51:04,511 - Epoch: [156][  100/  100]    Loss 1.455238    Top1 64.210000    Top5 88.890000    
2024-04-05 15:51:04,762 - ==> Top1: 64.210    Top5: 88.890    Loss: 1.455

2024-04-05 15:51:04,769 - ==> Best [Top1: 64.690   Top5: 88.860   Sparsity:0.00   Params: 347840 on epoch: 151]
2024-04-05 15:51:04,769 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:51:04,801 - 

2024-04-05 15:51:04,801 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:51:09,598 - Epoch: [157][  100/  500]    Overall Loss 0.373323    Objective Loss 0.373323                                        LR 0.000250    Time 0.047907    
2024-04-05 15:51:13,793 - Epoch: [157][  200/  500]    Overall Loss 0.379325    Objective Loss 0.379325                                        LR 0.000250    Time 0.044899    
2024-04-05 15:51:17,942 - Epoch: [157][  300/  500]    Overall Loss 0.376071    Objective Loss 0.376071                                        LR 0.000250    Time 0.043742    
2024-04-05 15:51:22,112 - Epoch: [157][  400/  500]    Overall Loss 0.377818    Objective Loss 0.377818                                        LR 0.000250    Time 0.043219    
2024-04-05 15:51:26,296 - Epoch: [157][  500/  500]    Overall Loss 0.380720    Objective Loss 0.380720    Top1 89.000000    Top5 99.500000    LR 0.000250    Time 0.042932    
2024-04-05 15:51:26,529 - --- validate (epoch=157)-----------
2024-04-05 15:51:26,530 - 10000 samples (100 per mini-batch)
2024-04-05 15:51:28,299 - Epoch: [157][  100/  100]    Loss 1.447618    Top1 64.430000    Top5 88.990000    
2024-04-05 15:51:28,464 - ==> Top1: 64.430    Top5: 88.990    Loss: 1.448

2024-04-05 15:51:28,470 - ==> Best [Top1: 64.690   Top5: 88.860   Sparsity:0.00   Params: 347840 on epoch: 151]
2024-04-05 15:51:28,470 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:51:28,504 - 

2024-04-05 15:51:28,504 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:51:33,461 - Epoch: [158][  100/  500]    Overall Loss 0.380918    Objective Loss 0.380918                                        LR 0.000250    Time 0.049515    
2024-04-05 15:51:37,563 - Epoch: [158][  200/  500]    Overall Loss 0.380327    Objective Loss 0.380327                                        LR 0.000250    Time 0.045239    
2024-04-05 15:51:41,647 - Epoch: [158][  300/  500]    Overall Loss 0.382341    Objective Loss 0.382341                                        LR 0.000250    Time 0.043756    
2024-04-05 15:51:45,757 - Epoch: [158][  400/  500]    Overall Loss 0.379164    Objective Loss 0.379164                                        LR 0.000250    Time 0.043080    
2024-04-05 15:51:49,855 - Epoch: [158][  500/  500]    Overall Loss 0.380924    Objective Loss 0.380924    Top1 90.000000    Top5 99.500000    LR 0.000250    Time 0.042648    
2024-04-05 15:51:50,121 - --- validate (epoch=158)-----------
2024-04-05 15:51:50,121 - 10000 samples (100 per mini-batch)
2024-04-05 15:51:51,625 - Epoch: [158][  100/  100]    Loss 1.444536    Top1 64.640000    Top5 88.870000    
2024-04-05 15:51:51,778 - ==> Top1: 64.640    Top5: 88.870    Loss: 1.445

2024-04-05 15:51:51,784 - ==> Best [Top1: 64.690   Top5: 88.860   Sparsity:0.00   Params: 347840 on epoch: 151]
2024-04-05 15:51:51,784 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:51:51,816 - 

2024-04-05 15:51:51,816 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:51:55,552 - Epoch: [159][  100/  500]    Overall Loss 0.368721    Objective Loss 0.368721                                        LR 0.000250    Time 0.037306    
2024-04-05 15:51:59,298 - Epoch: [159][  200/  500]    Overall Loss 0.373622    Objective Loss 0.373622                                        LR 0.000250    Time 0.037359    
2024-04-05 15:52:03,354 - Epoch: [159][  300/  500]    Overall Loss 0.376577    Objective Loss 0.376577                                        LR 0.000250    Time 0.038408    
2024-04-05 15:52:07,400 - Epoch: [159][  400/  500]    Overall Loss 0.378851    Objective Loss 0.378851                                        LR 0.000250    Time 0.038909    
2024-04-05 15:52:11,461 - Epoch: [159][  500/  500]    Overall Loss 0.379106    Objective Loss 0.379106    Top1 86.500000    Top5 96.500000    LR 0.000250    Time 0.039240    
2024-04-05 15:52:11,670 - --- validate (epoch=159)-----------
2024-04-05 15:52:11,671 - 10000 samples (100 per mini-batch)
2024-04-05 15:52:13,164 - Epoch: [159][  100/  100]    Loss 1.439954    Top1 64.340000    Top5 89.100000    
2024-04-05 15:52:13,396 - ==> Top1: 64.340    Top5: 89.100    Loss: 1.440

2024-04-05 15:52:13,402 - ==> Best [Top1: 64.690   Top5: 88.860   Sparsity:0.00   Params: 347840 on epoch: 151]
2024-04-05 15:52:13,402 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:52:13,433 - 

2024-04-05 15:52:13,434 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:52:17,525 - Epoch: [160][  100/  500]    Overall Loss 0.370920    Objective Loss 0.370920                                        LR 0.000250    Time 0.040867    
2024-04-05 15:52:21,637 - Epoch: [160][  200/  500]    Overall Loss 0.377567    Objective Loss 0.377567                                        LR 0.000250    Time 0.040963    
2024-04-05 15:52:25,747 - Epoch: [160][  300/  500]    Overall Loss 0.379310    Objective Loss 0.379310                                        LR 0.000250    Time 0.040992    
2024-04-05 15:52:29,900 - Epoch: [160][  400/  500]    Overall Loss 0.376416    Objective Loss 0.376416                                        LR 0.000250    Time 0.041113    
2024-04-05 15:52:34,017 - Epoch: [160][  500/  500]    Overall Loss 0.378825    Objective Loss 0.378825    Top1 91.500000    Top5 100.000000    LR 0.000250    Time 0.041114    
2024-04-05 15:52:34,227 - --- validate (epoch=160)-----------
2024-04-05 15:52:34,227 - 10000 samples (100 per mini-batch)
2024-04-05 15:52:36,347 - Epoch: [160][  100/  100]    Loss 1.448145    Top1 64.830000    Top5 89.040000    
2024-04-05 15:52:36,561 - ==> Top1: 64.830    Top5: 89.040    Loss: 1.448

2024-04-05 15:52:36,566 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:52:36,567 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:52:36,604 - 

2024-04-05 15:52:36,605 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:52:41,301 - Epoch: [161][  100/  500]    Overall Loss 0.370115    Objective Loss 0.370115                                        LR 0.000250    Time 0.046901    
2024-04-05 15:52:45,433 - Epoch: [161][  200/  500]    Overall Loss 0.367832    Objective Loss 0.367832                                        LR 0.000250    Time 0.044083    
2024-04-05 15:52:49,559 - Epoch: [161][  300/  500]    Overall Loss 0.370252    Objective Loss 0.370252                                        LR 0.000250    Time 0.043126    
2024-04-05 15:52:53,727 - Epoch: [161][  400/  500]    Overall Loss 0.370245    Objective Loss 0.370245                                        LR 0.000250    Time 0.042750    
2024-04-05 15:52:57,863 - Epoch: [161][  500/  500]    Overall Loss 0.371751    Objective Loss 0.371751    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.042462    
2024-04-05 15:52:58,054 - --- validate (epoch=161)-----------
2024-04-05 15:52:58,055 - 10000 samples (100 per mini-batch)
2024-04-05 15:52:59,814 - Epoch: [161][  100/  100]    Loss 1.446058    Top1 64.770000    Top5 88.950000    
2024-04-05 15:52:59,960 - ==> Top1: 64.770    Top5: 88.950    Loss: 1.446

2024-04-05 15:52:59,967 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:52:59,967 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:53:00,002 - 

2024-04-05 15:53:00,002 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:53:04,748 - Epoch: [162][  100/  500]    Overall Loss 0.365876    Objective Loss 0.365876                                        LR 0.000250    Time 0.047392    
2024-04-05 15:53:08,898 - Epoch: [162][  200/  500]    Overall Loss 0.371778    Objective Loss 0.371778                                        LR 0.000250    Time 0.044421    
2024-04-05 15:53:13,020 - Epoch: [162][  300/  500]    Overall Loss 0.371328    Objective Loss 0.371328                                        LR 0.000250    Time 0.043337    
2024-04-05 15:53:17,147 - Epoch: [162][  400/  500]    Overall Loss 0.371870    Objective Loss 0.371870                                        LR 0.000250    Time 0.042806    
2024-04-05 15:53:21,286 - Epoch: [162][  500/  500]    Overall Loss 0.370616    Objective Loss 0.370616    Top1 92.000000    Top5 99.500000    LR 0.000250    Time 0.042512    
2024-04-05 15:53:21,563 - --- validate (epoch=162)-----------
2024-04-05 15:53:21,564 - 10000 samples (100 per mini-batch)
2024-04-05 15:53:23,186 - Epoch: [162][  100/  100]    Loss 1.454754    Top1 64.570000    Top5 89.010000    
2024-04-05 15:53:23,384 - ==> Top1: 64.570    Top5: 89.010    Loss: 1.455

2024-04-05 15:53:23,388 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:53:23,389 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:53:23,411 - 

2024-04-05 15:53:23,411 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:53:28,026 - Epoch: [163][  100/  500]    Overall Loss 0.361500    Objective Loss 0.361500                                        LR 0.000250    Time 0.046087    
2024-04-05 15:53:32,188 - Epoch: [163][  200/  500]    Overall Loss 0.372667    Objective Loss 0.372667                                        LR 0.000250    Time 0.043825    
2024-04-05 15:53:36,339 - Epoch: [163][  300/  500]    Overall Loss 0.374747    Objective Loss 0.374747                                        LR 0.000250    Time 0.043036    
2024-04-05 15:53:40,460 - Epoch: [163][  400/  500]    Overall Loss 0.372746    Objective Loss 0.372746                                        LR 0.000250    Time 0.042568    
2024-04-05 15:53:44,584 - Epoch: [163][  500/  500]    Overall Loss 0.372585    Objective Loss 0.372585    Top1 93.000000    Top5 99.500000    LR 0.000250    Time 0.042292    
2024-04-05 15:53:44,754 - --- validate (epoch=163)-----------
2024-04-05 15:53:44,754 - 10000 samples (100 per mini-batch)
2024-04-05 15:53:46,146 - Epoch: [163][  100/  100]    Loss 1.445846    Top1 64.630000    Top5 88.870000    
2024-04-05 15:53:46,311 - ==> Top1: 64.630    Top5: 88.870    Loss: 1.446

2024-04-05 15:53:46,316 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:53:46,316 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:53:46,337 - 

2024-04-05 15:53:46,337 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:53:50,889 - Epoch: [164][  100/  500]    Overall Loss 0.369602    Objective Loss 0.369602                                        LR 0.000250    Time 0.045459    
2024-04-05 15:53:55,007 - Epoch: [164][  200/  500]    Overall Loss 0.363428    Objective Loss 0.363428                                        LR 0.000250    Time 0.043292    
2024-04-05 15:53:59,117 - Epoch: [164][  300/  500]    Overall Loss 0.370069    Objective Loss 0.370069                                        LR 0.000250    Time 0.042548    
2024-04-05 15:54:03,223 - Epoch: [164][  400/  500]    Overall Loss 0.374984    Objective Loss 0.374984                                        LR 0.000250    Time 0.042163    
2024-04-05 15:54:07,349 - Epoch: [164][  500/  500]    Overall Loss 0.376266    Objective Loss 0.376266    Top1 85.500000    Top5 99.000000    LR 0.000250    Time 0.041970    
2024-04-05 15:54:07,549 - --- validate (epoch=164)-----------
2024-04-05 15:54:07,550 - 10000 samples (100 per mini-batch)
2024-04-05 15:54:08,994 - Epoch: [164][  100/  100]    Loss 1.455020    Top1 64.570000    Top5 88.950000    
2024-04-05 15:54:09,146 - ==> Top1: 64.570    Top5: 88.950    Loss: 1.455

2024-04-05 15:54:09,152 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:54:09,152 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:54:09,175 - 

2024-04-05 15:54:09,175 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:54:13,826 - Epoch: [165][  100/  500]    Overall Loss 0.366231    Objective Loss 0.366231                                        LR 0.000250    Time 0.046454    
2024-04-05 15:54:17,971 - Epoch: [165][  200/  500]    Overall Loss 0.361888    Objective Loss 0.361888                                        LR 0.000250    Time 0.043927    
2024-04-05 15:54:22,115 - Epoch: [165][  300/  500]    Overall Loss 0.365721    Objective Loss 0.365721                                        LR 0.000250    Time 0.043080    
2024-04-05 15:54:26,247 - Epoch: [165][  400/  500]    Overall Loss 0.371508    Objective Loss 0.371508                                        LR 0.000250    Time 0.042625    
2024-04-05 15:54:30,388 - Epoch: [165][  500/  500]    Overall Loss 0.372737    Objective Loss 0.372737    Top1 86.000000    Top5 99.500000    LR 0.000250    Time 0.042373    
2024-04-05 15:54:30,581 - --- validate (epoch=165)-----------
2024-04-05 15:54:30,581 - 10000 samples (100 per mini-batch)
2024-04-05 15:54:32,029 - Epoch: [165][  100/  100]    Loss 1.450169    Top1 64.430000    Top5 89.140000    
2024-04-05 15:54:32,199 - ==> Top1: 64.430    Top5: 89.140    Loss: 1.450

2024-04-05 15:54:32,206 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:54:32,206 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:54:32,239 - 

2024-04-05 15:54:32,240 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:54:36,822 - Epoch: [166][  100/  500]    Overall Loss 0.358255    Objective Loss 0.358255                                        LR 0.000250    Time 0.045777    
2024-04-05 15:54:40,938 - Epoch: [166][  200/  500]    Overall Loss 0.360772    Objective Loss 0.360772                                        LR 0.000250    Time 0.043436    
2024-04-05 15:54:45,064 - Epoch: [166][  300/  500]    Overall Loss 0.369304    Objective Loss 0.369304                                        LR 0.000250    Time 0.042694    
2024-04-05 15:54:49,126 - Epoch: [166][  400/  500]    Overall Loss 0.370129    Objective Loss 0.370129                                        LR 0.000250    Time 0.042164    
2024-04-05 15:54:53,248 - Epoch: [166][  500/  500]    Overall Loss 0.371160    Objective Loss 0.371160    Top1 91.000000    Top5 99.000000    LR 0.000250    Time 0.041964    
2024-04-05 15:54:53,471 - --- validate (epoch=166)-----------
2024-04-05 15:54:53,471 - 10000 samples (100 per mini-batch)
2024-04-05 15:54:54,592 - Epoch: [166][  100/  100]    Loss 1.449926    Top1 64.280000    Top5 88.970000    
2024-04-05 15:54:54,703 - ==> Top1: 64.280    Top5: 88.970    Loss: 1.450

2024-04-05 15:54:54,710 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:54:54,710 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:54:54,743 - 

2024-04-05 15:54:54,743 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:54:59,255 - Epoch: [167][  100/  500]    Overall Loss 0.351756    Objective Loss 0.351756                                        LR 0.000250    Time 0.045060    
2024-04-05 15:55:03,109 - Epoch: [167][  200/  500]    Overall Loss 0.364871    Objective Loss 0.364871                                        LR 0.000250    Time 0.041776    
2024-04-05 15:55:07,198 - Epoch: [167][  300/  500]    Overall Loss 0.364945    Objective Loss 0.364945                                        LR 0.000250    Time 0.041464    
2024-04-05 15:55:11,330 - Epoch: [167][  400/  500]    Overall Loss 0.365952    Objective Loss 0.365952                                        LR 0.000250    Time 0.041417    
2024-04-05 15:55:15,477 - Epoch: [167][  500/  500]    Overall Loss 0.369360    Objective Loss 0.369360    Top1 89.000000    Top5 99.500000    LR 0.000250    Time 0.041415    
2024-04-05 15:55:15,708 - --- validate (epoch=167)-----------
2024-04-05 15:55:15,708 - 10000 samples (100 per mini-batch)
2024-04-05 15:55:17,204 - Epoch: [167][  100/  100]    Loss 1.457288    Top1 64.230000    Top5 88.850000    
2024-04-05 15:55:17,404 - ==> Top1: 64.230    Top5: 88.850    Loss: 1.457

2024-04-05 15:55:17,411 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:55:17,411 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:55:17,444 - 

2024-04-05 15:55:17,444 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:55:22,125 - Epoch: [168][  100/  500]    Overall Loss 0.356734    Objective Loss 0.356734                                        LR 0.000250    Time 0.046748    
2024-04-05 15:55:25,801 - Epoch: [168][  200/  500]    Overall Loss 0.358493    Objective Loss 0.358493                                        LR 0.000250    Time 0.041727    
2024-04-05 15:55:29,972 - Epoch: [168][  300/  500]    Overall Loss 0.364844    Objective Loss 0.364844                                        LR 0.000250    Time 0.041705    
2024-04-05 15:55:34,108 - Epoch: [168][  400/  500]    Overall Loss 0.368630    Objective Loss 0.368630                                        LR 0.000250    Time 0.041608    
2024-04-05 15:55:38,273 - Epoch: [168][  500/  500]    Overall Loss 0.367812    Objective Loss 0.367812    Top1 92.000000    Top5 98.500000    LR 0.000250    Time 0.041605    
2024-04-05 15:55:38,468 - --- validate (epoch=168)-----------
2024-04-05 15:55:38,469 - 10000 samples (100 per mini-batch)
2024-04-05 15:55:40,104 - Epoch: [168][  100/  100]    Loss 1.456321    Top1 64.210000    Top5 88.680000    
2024-04-05 15:55:40,250 - ==> Top1: 64.210    Top5: 88.680    Loss: 1.456

2024-04-05 15:55:40,256 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:55:40,256 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:55:40,290 - 

2024-04-05 15:55:40,290 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:55:44,967 - Epoch: [169][  100/  500]    Overall Loss 0.361366    Objective Loss 0.361366                                        LR 0.000250    Time 0.046712    
2024-04-05 15:55:48,941 - Epoch: [169][  200/  500]    Overall Loss 0.363053    Objective Loss 0.363053                                        LR 0.000250    Time 0.043197    
2024-04-05 15:55:53,095 - Epoch: [169][  300/  500]    Overall Loss 0.364831    Objective Loss 0.364831                                        LR 0.000250    Time 0.042628    
2024-04-05 15:55:57,237 - Epoch: [169][  400/  500]    Overall Loss 0.366990    Objective Loss 0.366990                                        LR 0.000250    Time 0.042312    
2024-04-05 15:56:01,381 - Epoch: [169][  500/  500]    Overall Loss 0.369144    Objective Loss 0.369144    Top1 83.000000    Top5 98.000000    LR 0.000250    Time 0.042128    
2024-04-05 15:56:01,592 - --- validate (epoch=169)-----------
2024-04-05 15:56:01,592 - 10000 samples (100 per mini-batch)
2024-04-05 15:56:03,077 - Epoch: [169][  100/  100]    Loss 1.458950    Top1 64.290000    Top5 88.860000    
2024-04-05 15:56:03,236 - ==> Top1: 64.290    Top5: 88.860    Loss: 1.459

2024-04-05 15:56:03,242 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:56:03,243 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:56:03,275 - 

2024-04-05 15:56:03,275 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:56:08,205 - Epoch: [170][  100/  500]    Overall Loss 0.352514    Objective Loss 0.352514                                        LR 0.000250    Time 0.049246    
2024-04-05 15:56:12,005 - Epoch: [170][  200/  500]    Overall Loss 0.365518    Objective Loss 0.365518                                        LR 0.000250    Time 0.043593    
2024-04-05 15:56:16,126 - Epoch: [170][  300/  500]    Overall Loss 0.363963    Objective Loss 0.363963                                        LR 0.000250    Time 0.042783    
2024-04-05 15:56:20,272 - Epoch: [170][  400/  500]    Overall Loss 0.366533    Objective Loss 0.366533                                        LR 0.000250    Time 0.042440    
2024-04-05 15:56:24,404 - Epoch: [170][  500/  500]    Overall Loss 0.368949    Objective Loss 0.368949    Top1 88.000000    Top5 100.000000    LR 0.000250    Time 0.042204    
2024-04-05 15:56:24,622 - --- validate (epoch=170)-----------
2024-04-05 15:56:24,623 - 10000 samples (100 per mini-batch)
2024-04-05 15:56:26,078 - Epoch: [170][  100/  100]    Loss 1.461601    Top1 64.340000    Top5 89.000000    
2024-04-05 15:56:26,228 - ==> Top1: 64.340    Top5: 89.000    Loss: 1.462

2024-04-05 15:56:26,234 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:56:26,234 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:56:26,264 - 

2024-04-05 15:56:26,265 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:56:30,962 - Epoch: [171][  100/  500]    Overall Loss 0.356903    Objective Loss 0.356903                                        LR 0.000250    Time 0.046917    
2024-04-05 15:56:34,955 - Epoch: [171][  200/  500]    Overall Loss 0.356417    Objective Loss 0.356417                                        LR 0.000250    Time 0.043397    
2024-04-05 15:56:38,944 - Epoch: [171][  300/  500]    Overall Loss 0.361108    Objective Loss 0.361108                                        LR 0.000250    Time 0.042211    
2024-04-05 15:56:43,031 - Epoch: [171][  400/  500]    Overall Loss 0.361177    Objective Loss 0.361177                                        LR 0.000250    Time 0.041863    
2024-04-05 15:56:47,157 - Epoch: [171][  500/  500]    Overall Loss 0.363482    Objective Loss 0.363482    Top1 90.500000    Top5 99.500000    LR 0.000250    Time 0.041733    
2024-04-05 15:56:47,436 - --- validate (epoch=171)-----------
2024-04-05 15:56:47,437 - 10000 samples (100 per mini-batch)
2024-04-05 15:56:48,908 - Epoch: [171][  100/  100]    Loss 1.461457    Top1 64.380000    Top5 88.750000    
2024-04-05 15:56:49,128 - ==> Top1: 64.380    Top5: 88.750    Loss: 1.461

2024-04-05 15:56:49,134 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:56:49,135 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:56:49,165 - 

2024-04-05 15:56:49,165 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:56:53,548 - Epoch: [172][  100/  500]    Overall Loss 0.361458    Objective Loss 0.361458                                        LR 0.000250    Time 0.043775    
2024-04-05 15:56:57,627 - Epoch: [172][  200/  500]    Overall Loss 0.359812    Objective Loss 0.359812                                        LR 0.000250    Time 0.042258    
2024-04-05 15:57:01,068 - Epoch: [172][  300/  500]    Overall Loss 0.361425    Objective Loss 0.361425                                        LR 0.000250    Time 0.039625    
2024-04-05 15:57:05,189 - Epoch: [172][  400/  500]    Overall Loss 0.364482    Objective Loss 0.364482                                        LR 0.000250    Time 0.040006    
2024-04-05 15:57:09,241 - Epoch: [172][  500/  500]    Overall Loss 0.365819    Objective Loss 0.365819    Top1 93.000000    Top5 99.500000    LR 0.000250    Time 0.040100    
2024-04-05 15:57:09,444 - --- validate (epoch=172)-----------
2024-04-05 15:57:09,445 - 10000 samples (100 per mini-batch)
2024-04-05 15:57:11,099 - Epoch: [172][  100/  100]    Loss 1.457005    Top1 64.730000    Top5 88.730000    
2024-04-05 15:57:11,293 - ==> Top1: 64.730    Top5: 88.730    Loss: 1.457

2024-04-05 15:57:11,298 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:57:11,298 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:57:11,324 - 

2024-04-05 15:57:11,324 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:57:15,986 - Epoch: [173][  100/  500]    Overall Loss 0.361193    Objective Loss 0.361193                                        LR 0.000250    Time 0.046567    
2024-04-05 15:57:20,081 - Epoch: [173][  200/  500]    Overall Loss 0.353368    Objective Loss 0.353368                                        LR 0.000250    Time 0.043730    
2024-04-05 15:57:24,041 - Epoch: [173][  300/  500]    Overall Loss 0.360588    Objective Loss 0.360588                                        LR 0.000250    Time 0.042335    
2024-04-05 15:57:28,152 - Epoch: [173][  400/  500]    Overall Loss 0.367162    Objective Loss 0.367162                                        LR 0.000250    Time 0.042016    
2024-04-05 15:57:32,258 - Epoch: [173][  500/  500]    Overall Loss 0.368500    Objective Loss 0.368500    Top1 88.500000    Top5 99.000000    LR 0.000250    Time 0.041814    
2024-04-05 15:57:32,530 - --- validate (epoch=173)-----------
2024-04-05 15:57:32,530 - 10000 samples (100 per mini-batch)
2024-04-05 15:57:33,896 - Epoch: [173][  100/  100]    Loss 1.464583    Top1 64.340000    Top5 89.000000    
2024-04-05 15:57:34,046 - ==> Top1: 64.340    Top5: 89.000    Loss: 1.465

2024-04-05 15:57:34,052 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:57:34,052 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:57:34,083 - 

2024-04-05 15:57:34,083 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:57:38,937 - Epoch: [174][  100/  500]    Overall Loss 0.365359    Objective Loss 0.365359                                        LR 0.000250    Time 0.048484    
2024-04-05 15:57:43,049 - Epoch: [174][  200/  500]    Overall Loss 0.366270    Objective Loss 0.366270                                        LR 0.000250    Time 0.044780    
2024-04-05 15:57:47,082 - Epoch: [174][  300/  500]    Overall Loss 0.363939    Objective Loss 0.363939                                        LR 0.000250    Time 0.043280    
2024-04-05 15:57:50,937 - Epoch: [174][  400/  500]    Overall Loss 0.365003    Objective Loss 0.365003                                        LR 0.000250    Time 0.042086    
2024-04-05 15:57:55,048 - Epoch: [174][  500/  500]    Overall Loss 0.365721    Objective Loss 0.365721    Top1 90.000000    Top5 100.000000    LR 0.000250    Time 0.041880    
2024-04-05 15:57:55,245 - --- validate (epoch=174)-----------
2024-04-05 15:57:55,246 - 10000 samples (100 per mini-batch)
2024-04-05 15:57:56,667 - Epoch: [174][  100/  100]    Loss 1.459797    Top1 64.570000    Top5 88.830000    
2024-04-05 15:57:56,825 - ==> Top1: 64.570    Top5: 88.830    Loss: 1.460

2024-04-05 15:57:56,831 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:57:56,832 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:57:56,863 - 

2024-04-05 15:57:56,863 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:58:01,532 - Epoch: [175][  100/  500]    Overall Loss 0.356474    Objective Loss 0.356474                                        LR 0.000250    Time 0.046631    
2024-04-05 15:58:05,653 - Epoch: [175][  200/  500]    Overall Loss 0.359166    Objective Loss 0.359166                                        LR 0.000250    Time 0.043894    
2024-04-05 15:58:09,762 - Epoch: [175][  300/  500]    Overall Loss 0.365721    Objective Loss 0.365721                                        LR 0.000250    Time 0.042942    
2024-04-05 15:58:13,300 - Epoch: [175][  400/  500]    Overall Loss 0.367531    Objective Loss 0.367531                                        LR 0.000250    Time 0.041041    
2024-04-05 15:58:17,412 - Epoch: [175][  500/  500]    Overall Loss 0.368567    Objective Loss 0.368567    Top1 87.000000    Top5 100.000000    LR 0.000250    Time 0.041047    
2024-04-05 15:58:17,676 - --- validate (epoch=175)-----------
2024-04-05 15:58:17,676 - 10000 samples (100 per mini-batch)
2024-04-05 15:58:19,180 - Epoch: [175][  100/  100]    Loss 1.455163    Top1 64.150000    Top5 89.080000    
2024-04-05 15:58:19,347 - ==> Top1: 64.150    Top5: 89.080    Loss: 1.455

2024-04-05 15:58:19,353 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:58:19,353 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:58:19,386 - 

2024-04-05 15:58:19,386 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:58:24,084 - Epoch: [176][  100/  500]    Overall Loss 0.346019    Objective Loss 0.346019                                        LR 0.000250    Time 0.046926    
2024-04-05 15:58:28,197 - Epoch: [176][  200/  500]    Overall Loss 0.354420    Objective Loss 0.354420                                        LR 0.000250    Time 0.043999    
2024-04-05 15:58:32,305 - Epoch: [176][  300/  500]    Overall Loss 0.354767    Objective Loss 0.354767                                        LR 0.000250    Time 0.043009    
2024-04-05 15:58:35,787 - Epoch: [176][  400/  500]    Overall Loss 0.357134    Objective Loss 0.357134                                        LR 0.000250    Time 0.040952    
2024-04-05 15:58:39,929 - Epoch: [176][  500/  500]    Overall Loss 0.361402    Objective Loss 0.361402    Top1 87.000000    Top5 99.000000    LR 0.000250    Time 0.041035    
2024-04-05 15:58:40,125 - --- validate (epoch=176)-----------
2024-04-05 15:58:40,125 - 10000 samples (100 per mini-batch)
2024-04-05 15:58:41,775 - Epoch: [176][  100/  100]    Loss 1.465773    Top1 64.530000    Top5 88.730000    
2024-04-05 15:58:41,999 - ==> Top1: 64.530    Top5: 88.730    Loss: 1.466

2024-04-05 15:58:42,002 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:58:42,003 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:58:42,025 - 

2024-04-05 15:58:42,025 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:58:45,509 - Epoch: [177][  100/  500]    Overall Loss 0.348659    Objective Loss 0.348659                                        LR 0.000250    Time 0.034794    
2024-04-05 15:58:48,709 - Epoch: [177][  200/  500]    Overall Loss 0.356034    Objective Loss 0.356034                                        LR 0.000250    Time 0.033374    
2024-04-05 15:58:52,859 - Epoch: [177][  300/  500]    Overall Loss 0.361769    Objective Loss 0.361769                                        LR 0.000250    Time 0.036065    
2024-04-05 15:58:56,962 - Epoch: [177][  400/  500]    Overall Loss 0.363117    Objective Loss 0.363117                                        LR 0.000250    Time 0.037292    
2024-04-05 15:59:00,282 - Epoch: [177][  500/  500]    Overall Loss 0.363864    Objective Loss 0.363864    Top1 88.500000    Top5 99.500000    LR 0.000250    Time 0.036466    
2024-04-05 15:59:00,550 - --- validate (epoch=177)-----------
2024-04-05 15:59:00,551 - 10000 samples (100 per mini-batch)
2024-04-05 15:59:01,984 - Epoch: [177][  100/  100]    Loss 1.464508    Top1 64.410000    Top5 88.740000    
2024-04-05 15:59:02,149 - ==> Top1: 64.410    Top5: 88.740    Loss: 1.465

2024-04-05 15:59:02,155 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:59:02,155 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:59:02,186 - 

2024-04-05 15:59:02,186 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:59:07,067 - Epoch: [178][  100/  500]    Overall Loss 0.353120    Objective Loss 0.353120                                        LR 0.000250    Time 0.048753    
2024-04-05 15:59:11,187 - Epoch: [178][  200/  500]    Overall Loss 0.355906    Objective Loss 0.355906                                        LR 0.000250    Time 0.044946    
2024-04-05 15:59:15,181 - Epoch: [178][  300/  500]    Overall Loss 0.360098    Objective Loss 0.360098                                        LR 0.000250    Time 0.043262    
2024-04-05 15:59:18,988 - Epoch: [178][  400/  500]    Overall Loss 0.361547    Objective Loss 0.361547                                        LR 0.000250    Time 0.041952    
2024-04-05 15:59:23,134 - Epoch: [178][  500/  500]    Overall Loss 0.361028    Objective Loss 0.361028    Top1 89.000000    Top5 99.500000    LR 0.000250    Time 0.041843    
2024-04-05 15:59:23,416 - --- validate (epoch=178)-----------
2024-04-05 15:59:23,417 - 10000 samples (100 per mini-batch)
2024-04-05 15:59:24,871 - Epoch: [178][  100/  100]    Loss 1.479095    Top1 64.170000    Top5 88.660000    
2024-04-05 15:59:25,018 - ==> Top1: 64.170    Top5: 88.660    Loss: 1.479

2024-04-05 15:59:25,024 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:59:25,025 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:59:25,062 - 

2024-04-05 15:59:25,062 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:59:29,416 - Epoch: [179][  100/  500]    Overall Loss 0.363216    Objective Loss 0.363216                                        LR 0.000250    Time 0.043481    
2024-04-05 15:59:33,539 - Epoch: [179][  200/  500]    Overall Loss 0.359764    Objective Loss 0.359764                                        LR 0.000250    Time 0.042325    
2024-04-05 15:59:37,456 - Epoch: [179][  300/  500]    Overall Loss 0.356646    Objective Loss 0.356646                                        LR 0.000250    Time 0.041255    
2024-04-05 15:59:40,753 - Epoch: [179][  400/  500]    Overall Loss 0.356935    Objective Loss 0.356935                                        LR 0.000250    Time 0.039175    
2024-04-05 15:59:44,882 - Epoch: [179][  500/  500]    Overall Loss 0.357900    Objective Loss 0.357900    Top1 90.000000    Top5 100.000000    LR 0.000250    Time 0.039586    
2024-04-05 15:59:45,065 - --- validate (epoch=179)-----------
2024-04-05 15:59:45,066 - 10000 samples (100 per mini-batch)
2024-04-05 15:59:46,463 - Epoch: [179][  100/  100]    Loss 1.474933    Top1 63.880000    Top5 88.840000    
2024-04-05 15:59:46,640 - ==> Top1: 63.880    Top5: 88.840    Loss: 1.475

2024-04-05 15:59:46,643 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 15:59:46,643 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 15:59:46,669 - 

2024-04-05 15:59:46,670 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:59:50,979 - Epoch: [180][  100/  500]    Overall Loss 0.347823    Objective Loss 0.347823                                        LR 0.000250    Time 0.043033    
2024-04-05 15:59:55,090 - Epoch: [180][  200/  500]    Overall Loss 0.345694    Objective Loss 0.345694                                        LR 0.000250    Time 0.042043    
2024-04-05 15:59:58,651 - Epoch: [180][  300/  500]    Overall Loss 0.353308    Objective Loss 0.353308                                        LR 0.000250    Time 0.039883    
2024-04-05 16:00:02,763 - Epoch: [180][  400/  500]    Overall Loss 0.354469    Objective Loss 0.354469                                        LR 0.000250    Time 0.040173    
2024-04-05 16:00:06,885 - Epoch: [180][  500/  500]    Overall Loss 0.359465    Objective Loss 0.359465    Top1 88.000000    Top5 99.500000    LR 0.000250    Time 0.040373    
2024-04-05 16:00:07,154 - --- validate (epoch=180)-----------
2024-04-05 16:00:07,155 - 10000 samples (100 per mini-batch)
2024-04-05 16:00:08,538 - Epoch: [180][  100/  100]    Loss 1.483694    Top1 64.370000    Top5 88.690000    
2024-04-05 16:00:08,724 - ==> Top1: 64.370    Top5: 88.690    Loss: 1.484

2024-04-05 16:00:08,730 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:00:08,730 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:00:08,762 - 

2024-04-05 16:00:08,762 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:00:13,473 - Epoch: [181][  100/  500]    Overall Loss 0.352602    Objective Loss 0.352602                                        LR 0.000250    Time 0.047052    
2024-04-05 16:00:17,605 - Epoch: [181][  200/  500]    Overall Loss 0.351839    Objective Loss 0.351839                                        LR 0.000250    Time 0.044157    
2024-04-05 16:00:21,402 - Epoch: [181][  300/  500]    Overall Loss 0.358406    Objective Loss 0.358406                                        LR 0.000250    Time 0.042079    
2024-04-05 16:00:25,128 - Epoch: [181][  400/  500]    Overall Loss 0.360884    Objective Loss 0.360884                                        LR 0.000250    Time 0.040865    
2024-04-05 16:00:29,273 - Epoch: [181][  500/  500]    Overall Loss 0.359544    Objective Loss 0.359544    Top1 89.500000    Top5 99.000000    LR 0.000250    Time 0.040969    
2024-04-05 16:00:29,496 - --- validate (epoch=181)-----------
2024-04-05 16:00:29,496 - 10000 samples (100 per mini-batch)
2024-04-05 16:00:30,934 - Epoch: [181][  100/  100]    Loss 1.475214    Top1 64.600000    Top5 88.790000    
2024-04-05 16:00:31,110 - ==> Top1: 64.600    Top5: 88.790    Loss: 1.475

2024-04-05 16:00:31,116 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:00:31,116 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:00:31,147 - 

2024-04-05 16:00:31,148 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:00:36,062 - Epoch: [182][  100/  500]    Overall Loss 0.350488    Objective Loss 0.350488                                        LR 0.000250    Time 0.049089    
2024-04-05 16:00:40,211 - Epoch: [182][  200/  500]    Overall Loss 0.346611    Objective Loss 0.346611                                        LR 0.000250    Time 0.045253    
2024-04-05 16:00:44,367 - Epoch: [182][  300/  500]    Overall Loss 0.350127    Objective Loss 0.350127                                        LR 0.000250    Time 0.044003    
2024-04-05 16:00:47,947 - Epoch: [182][  400/  500]    Overall Loss 0.354320    Objective Loss 0.354320                                        LR 0.000250    Time 0.041941    
2024-04-05 16:00:52,082 - Epoch: [182][  500/  500]    Overall Loss 0.358904    Objective Loss 0.358904    Top1 84.500000    Top5 99.500000    LR 0.000250    Time 0.041812    
2024-04-05 16:00:52,246 - --- validate (epoch=182)-----------
2024-04-05 16:00:52,246 - 10000 samples (100 per mini-batch)
2024-04-05 16:00:53,641 - Epoch: [182][  100/  100]    Loss 1.472162    Top1 64.510000    Top5 88.900000    
2024-04-05 16:00:53,797 - ==> Top1: 64.510    Top5: 88.900    Loss: 1.472

2024-04-05 16:00:53,803 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:00:53,804 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:00:53,836 - 

2024-04-05 16:00:53,836 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:00:58,495 - Epoch: [183][  100/  500]    Overall Loss 0.350292    Objective Loss 0.350292                                        LR 0.000250    Time 0.046532    
2024-04-05 16:01:02,610 - Epoch: [183][  200/  500]    Overall Loss 0.351176    Objective Loss 0.351176                                        LR 0.000250    Time 0.043814    
2024-04-05 16:01:06,721 - Epoch: [183][  300/  500]    Overall Loss 0.353273    Objective Loss 0.353273                                        LR 0.000250    Time 0.042897    
2024-04-05 16:01:10,333 - Epoch: [183][  400/  500]    Overall Loss 0.353598    Objective Loss 0.353598                                        LR 0.000250    Time 0.041189    
2024-04-05 16:01:14,472 - Epoch: [183][  500/  500]    Overall Loss 0.356480    Objective Loss 0.356480    Top1 90.500000    Top5 99.000000    LR 0.000250    Time 0.041218    
2024-04-05 16:01:14,746 - --- validate (epoch=183)-----------
2024-04-05 16:01:14,747 - 10000 samples (100 per mini-batch)
2024-04-05 16:01:16,180 - Epoch: [183][  100/  100]    Loss 1.482238    Top1 64.300000    Top5 89.000000    
2024-04-05 16:01:16,387 - ==> Top1: 64.300    Top5: 89.000    Loss: 1.482

2024-04-05 16:01:16,393 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:01:16,393 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:01:16,424 - 

2024-04-05 16:01:16,424 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:01:21,148 - Epoch: [184][  100/  500]    Overall Loss 0.334882    Objective Loss 0.334882                                        LR 0.000250    Time 0.047181    
2024-04-05 16:01:25,270 - Epoch: [184][  200/  500]    Overall Loss 0.348038    Objective Loss 0.348038                                        LR 0.000250    Time 0.044174    
2024-04-05 16:01:29,418 - Epoch: [184][  300/  500]    Overall Loss 0.349657    Objective Loss 0.349657                                        LR 0.000250    Time 0.043257    
2024-04-05 16:01:33,336 - Epoch: [184][  400/  500]    Overall Loss 0.352626    Objective Loss 0.352626                                        LR 0.000250    Time 0.042226    
2024-04-05 16:01:37,204 - Epoch: [184][  500/  500]    Overall Loss 0.354330    Objective Loss 0.354330    Top1 89.500000    Top5 99.000000    LR 0.000250    Time 0.041507    
2024-04-05 16:01:37,428 - --- validate (epoch=184)-----------
2024-04-05 16:01:37,429 - 10000 samples (100 per mini-batch)
2024-04-05 16:01:39,035 - Epoch: [184][  100/  100]    Loss 1.470377    Top1 64.260000    Top5 88.830000    
2024-04-05 16:01:39,196 - ==> Top1: 64.260    Top5: 88.830    Loss: 1.470

2024-04-05 16:01:39,202 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:01:39,202 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:01:39,233 - 

2024-04-05 16:01:39,233 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:01:43,950 - Epoch: [185][  100/  500]    Overall Loss 0.349737    Objective Loss 0.349737                                        LR 0.000250    Time 0.047117    
2024-04-05 16:01:48,100 - Epoch: [185][  200/  500]    Overall Loss 0.347964    Objective Loss 0.347964                                        LR 0.000250    Time 0.044280    
2024-04-05 16:01:52,219 - Epoch: [185][  300/  500]    Overall Loss 0.349825    Objective Loss 0.349825                                        LR 0.000250    Time 0.043233    
2024-04-05 16:01:56,208 - Epoch: [185][  400/  500]    Overall Loss 0.352164    Objective Loss 0.352164                                        LR 0.000250    Time 0.042385    
2024-04-05 16:02:00,153 - Epoch: [185][  500/  500]    Overall Loss 0.354602    Objective Loss 0.354602    Top1 89.500000    Top5 100.000000    LR 0.000250    Time 0.041787    
2024-04-05 16:02:00,452 - --- validate (epoch=185)-----------
2024-04-05 16:02:00,453 - 10000 samples (100 per mini-batch)
2024-04-05 16:02:01,830 - Epoch: [185][  100/  100]    Loss 1.473315    Top1 64.260000    Top5 88.590000    
2024-04-05 16:02:01,990 - ==> Top1: 64.260    Top5: 88.590    Loss: 1.473

2024-04-05 16:02:01,996 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:02:01,996 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:02:02,029 - 

2024-04-05 16:02:02,030 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:02:06,933 - Epoch: [186][  100/  500]    Overall Loss 0.346546    Objective Loss 0.346546                                        LR 0.000250    Time 0.048973    
2024-04-05 16:02:11,059 - Epoch: [186][  200/  500]    Overall Loss 0.348110    Objective Loss 0.348110                                        LR 0.000250    Time 0.045090    
2024-04-05 16:02:15,131 - Epoch: [186][  300/  500]    Overall Loss 0.347189    Objective Loss 0.347189                                        LR 0.000250    Time 0.043616    
2024-04-05 16:02:19,237 - Epoch: [186][  400/  500]    Overall Loss 0.349071    Objective Loss 0.349071                                        LR 0.000250    Time 0.042963    
2024-04-05 16:02:22,560 - Epoch: [186][  500/  500]    Overall Loss 0.352377    Objective Loss 0.352377    Top1 89.000000    Top5 99.000000    LR 0.000250    Time 0.041007    
2024-04-05 16:02:22,798 - --- validate (epoch=186)-----------
2024-04-05 16:02:22,798 - 10000 samples (100 per mini-batch)
2024-04-05 16:02:24,210 - Epoch: [186][  100/  100]    Loss 1.474584    Top1 64.380000    Top5 88.880000    
2024-04-05 16:02:24,360 - ==> Top1: 64.380    Top5: 88.880    Loss: 1.475

2024-04-05 16:02:24,366 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:02:24,367 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:02:24,398 - 

2024-04-05 16:02:24,398 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:02:29,088 - Epoch: [187][  100/  500]    Overall Loss 0.348310    Objective Loss 0.348310                                        LR 0.000250    Time 0.046825    
2024-04-05 16:02:33,194 - Epoch: [187][  200/  500]    Overall Loss 0.347215    Objective Loss 0.347215                                        LR 0.000250    Time 0.043918    
2024-04-05 16:02:37,338 - Epoch: [187][  300/  500]    Overall Loss 0.346604    Objective Loss 0.346604                                        LR 0.000250    Time 0.043074    
2024-04-05 16:02:41,456 - Epoch: [187][  400/  500]    Overall Loss 0.350600    Objective Loss 0.350600                                        LR 0.000250    Time 0.042585    
2024-04-05 16:02:45,024 - Epoch: [187][  500/  500]    Overall Loss 0.351200    Objective Loss 0.351200    Top1 89.500000    Top5 99.500000    LR 0.000250    Time 0.041196    
2024-04-05 16:02:45,261 - --- validate (epoch=187)-----------
2024-04-05 16:02:45,261 - 10000 samples (100 per mini-batch)
2024-04-05 16:02:46,696 - Epoch: [187][  100/  100]    Loss 1.481829    Top1 64.340000    Top5 88.870000    
2024-04-05 16:02:46,850 - ==> Top1: 64.340    Top5: 88.870    Loss: 1.482

2024-04-05 16:02:46,856 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:02:46,856 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:02:46,886 - 

2024-04-05 16:02:46,887 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:02:51,567 - Epoch: [188][  100/  500]    Overall Loss 0.339965    Objective Loss 0.339965                                        LR 0.000250    Time 0.046746    
2024-04-05 16:02:55,697 - Epoch: [188][  200/  500]    Overall Loss 0.343308    Objective Loss 0.343308                                        LR 0.000250    Time 0.043998    
2024-04-05 16:02:59,843 - Epoch: [188][  300/  500]    Overall Loss 0.344215    Objective Loss 0.344215                                        LR 0.000250    Time 0.043133    
2024-04-05 16:03:03,991 - Epoch: [188][  400/  500]    Overall Loss 0.346464    Objective Loss 0.346464                                        LR 0.000250    Time 0.042707    
2024-04-05 16:03:07,777 - Epoch: [188][  500/  500]    Overall Loss 0.349322    Objective Loss 0.349322    Top1 86.000000    Top5 100.000000    LR 0.000250    Time 0.041728    
2024-04-05 16:03:08,018 - --- validate (epoch=188)-----------
2024-04-05 16:03:08,018 - 10000 samples (100 per mini-batch)
2024-04-05 16:03:09,649 - Epoch: [188][  100/  100]    Loss 1.477910    Top1 64.090000    Top5 88.820000    
2024-04-05 16:03:09,800 - ==> Top1: 64.090    Top5: 88.820    Loss: 1.478

2024-04-05 16:03:09,807 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:03:09,808 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:03:09,839 - 

2024-04-05 16:03:09,839 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:03:14,506 - Epoch: [189][  100/  500]    Overall Loss 0.355466    Objective Loss 0.355466                                        LR 0.000250    Time 0.046617    
2024-04-05 16:03:18,632 - Epoch: [189][  200/  500]    Overall Loss 0.348188    Objective Loss 0.348188                                        LR 0.000250    Time 0.043911    
2024-04-05 16:03:22,745 - Epoch: [189][  300/  500]    Overall Loss 0.351959    Objective Loss 0.351959                                        LR 0.000250    Time 0.042965    
2024-04-05 16:03:26,880 - Epoch: [189][  400/  500]    Overall Loss 0.353104    Objective Loss 0.353104                                        LR 0.000250    Time 0.042548    
2024-04-05 16:03:30,969 - Epoch: [189][  500/  500]    Overall Loss 0.353756    Objective Loss 0.353756    Top1 88.500000    Top5 98.500000    LR 0.000250    Time 0.042206    
2024-04-05 16:03:31,130 - --- validate (epoch=189)-----------
2024-04-05 16:03:31,131 - 10000 samples (100 per mini-batch)
2024-04-05 16:03:32,649 - Epoch: [189][  100/  100]    Loss 1.478538    Top1 64.340000    Top5 88.840000    
2024-04-05 16:03:32,816 - ==> Top1: 64.340    Top5: 88.840    Loss: 1.479

2024-04-05 16:03:32,823 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:03:32,823 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:03:32,855 - 

2024-04-05 16:03:32,856 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:03:37,733 - Epoch: [190][  100/  500]    Overall Loss 0.344799    Objective Loss 0.344799                                        LR 0.000250    Time 0.048718    
2024-04-05 16:03:41,831 - Epoch: [190][  200/  500]    Overall Loss 0.344040    Objective Loss 0.344040                                        LR 0.000250    Time 0.044823    
2024-04-05 16:03:45,980 - Epoch: [190][  300/  500]    Overall Loss 0.343993    Objective Loss 0.343993                                        LR 0.000250    Time 0.043694    
2024-04-05 16:03:50,116 - Epoch: [190][  400/  500]    Overall Loss 0.346648    Objective Loss 0.346648                                        LR 0.000250    Time 0.043095    
2024-04-05 16:03:54,261 - Epoch: [190][  500/  500]    Overall Loss 0.349508    Objective Loss 0.349508    Top1 90.000000    Top5 100.000000    LR 0.000250    Time 0.042756    
2024-04-05 16:03:54,425 - --- validate (epoch=190)-----------
2024-04-05 16:03:54,427 - 10000 samples (100 per mini-batch)
2024-04-05 16:03:56,207 - Epoch: [190][  100/  100]    Loss 1.477412    Top1 64.370000    Top5 89.070000    
2024-04-05 16:03:56,423 - ==> Top1: 64.370    Top5: 89.070    Loss: 1.477

2024-04-05 16:03:56,429 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:03:56,429 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:03:56,460 - 

2024-04-05 16:03:56,461 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:04:01,223 - Epoch: [191][  100/  500]    Overall Loss 0.352617    Objective Loss 0.352617                                        LR 0.000250    Time 0.047565    
2024-04-05 16:04:05,386 - Epoch: [191][  200/  500]    Overall Loss 0.346833    Objective Loss 0.346833                                        LR 0.000250    Time 0.044567    
2024-04-05 16:04:09,511 - Epoch: [191][  300/  500]    Overall Loss 0.347033    Objective Loss 0.347033                                        LR 0.000250    Time 0.043445    
2024-04-05 16:04:13,658 - Epoch: [191][  400/  500]    Overall Loss 0.351952    Objective Loss 0.351952                                        LR 0.000250    Time 0.042938    
2024-04-05 16:04:17,782 - Epoch: [191][  500/  500]    Overall Loss 0.352677    Objective Loss 0.352677    Top1 88.000000    Top5 99.500000    LR 0.000250    Time 0.042587    
2024-04-05 16:04:17,973 - --- validate (epoch=191)-----------
2024-04-05 16:04:17,974 - 10000 samples (100 per mini-batch)
2024-04-05 16:04:19,446 - Epoch: [191][  100/  100]    Loss 1.475947    Top1 64.470000    Top5 89.130000    
2024-04-05 16:04:19,659 - ==> Top1: 64.470    Top5: 89.130    Loss: 1.476

2024-04-05 16:04:19,665 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:04:19,666 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:04:19,697 - 

2024-04-05 16:04:19,698 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:04:23,984 - Epoch: [192][  100/  500]    Overall Loss 0.344100    Objective Loss 0.344100                                        LR 0.000250    Time 0.042813    
2024-04-05 16:04:28,097 - Epoch: [192][  200/  500]    Overall Loss 0.342354    Objective Loss 0.342354                                        LR 0.000250    Time 0.041942    
2024-04-05 16:04:32,214 - Epoch: [192][  300/  500]    Overall Loss 0.342585    Objective Loss 0.342585                                        LR 0.000250    Time 0.041670    
2024-04-05 16:04:36,233 - Epoch: [192][  400/  500]    Overall Loss 0.345951    Objective Loss 0.345951                                        LR 0.000250    Time 0.041286    
2024-04-05 16:04:40,355 - Epoch: [192][  500/  500]    Overall Loss 0.348750    Objective Loss 0.348750    Top1 88.500000    Top5 99.000000    LR 0.000250    Time 0.041262    
2024-04-05 16:04:40,577 - --- validate (epoch=192)-----------
2024-04-05 16:04:40,577 - 10000 samples (100 per mini-batch)
2024-04-05 16:04:42,005 - Epoch: [192][  100/  100]    Loss 1.487313    Top1 64.170000    Top5 88.710000    
2024-04-05 16:04:42,230 - ==> Top1: 64.170    Top5: 88.710    Loss: 1.487

2024-04-05 16:04:42,237 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:04:42,237 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:04:42,267 - 

2024-04-05 16:04:42,267 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:04:46,675 - Epoch: [193][  100/  500]    Overall Loss 0.343184    Objective Loss 0.343184                                        LR 0.000250    Time 0.044034    
2024-04-05 16:04:50,711 - Epoch: [193][  200/  500]    Overall Loss 0.345227    Objective Loss 0.345227                                        LR 0.000250    Time 0.042169    
2024-04-05 16:04:54,825 - Epoch: [193][  300/  500]    Overall Loss 0.348135    Objective Loss 0.348135                                        LR 0.000250    Time 0.041811    
2024-04-05 16:04:58,943 - Epoch: [193][  400/  500]    Overall Loss 0.350803    Objective Loss 0.350803                                        LR 0.000250    Time 0.041639    
2024-04-05 16:05:03,069 - Epoch: [193][  500/  500]    Overall Loss 0.354282    Objective Loss 0.354282    Top1 93.500000    Top5 99.500000    LR 0.000250    Time 0.041553    
2024-04-05 16:05:03,270 - --- validate (epoch=193)-----------
2024-04-05 16:05:03,271 - 10000 samples (100 per mini-batch)
2024-04-05 16:05:04,720 - Epoch: [193][  100/  100]    Loss 1.481691    Top1 64.270000    Top5 88.840000    
2024-04-05 16:05:04,874 - ==> Top1: 64.270    Top5: 88.840    Loss: 1.482

2024-04-05 16:05:04,881 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:05:04,881 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:05:04,913 - 

2024-04-05 16:05:04,913 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:05:09,347 - Epoch: [194][  100/  500]    Overall Loss 0.345459    Objective Loss 0.345459                                        LR 0.000250    Time 0.044281    
2024-04-05 16:05:13,469 - Epoch: [194][  200/  500]    Overall Loss 0.348290    Objective Loss 0.348290                                        LR 0.000250    Time 0.042725    
2024-04-05 16:05:17,615 - Epoch: [194][  300/  500]    Overall Loss 0.352669    Objective Loss 0.352669                                        LR 0.000250    Time 0.042283    
2024-04-05 16:05:21,747 - Epoch: [194][  400/  500]    Overall Loss 0.349703    Objective Loss 0.349703                                        LR 0.000250    Time 0.042029    
2024-04-05 16:05:25,905 - Epoch: [194][  500/  500]    Overall Loss 0.352013    Objective Loss 0.352013    Top1 92.000000    Top5 99.500000    LR 0.000250    Time 0.041929    
2024-04-05 16:05:26,076 - --- validate (epoch=194)-----------
2024-04-05 16:05:26,077 - 10000 samples (100 per mini-batch)
2024-04-05 16:05:27,773 - Epoch: [194][  100/  100]    Loss 1.478306    Top1 64.280000    Top5 88.840000    
2024-04-05 16:05:27,929 - ==> Top1: 64.280    Top5: 88.840    Loss: 1.478

2024-04-05 16:05:27,935 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:05:27,936 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:05:27,967 - 

2024-04-05 16:05:27,967 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:05:32,167 - Epoch: [195][  100/  500]    Overall Loss 0.338076    Objective Loss 0.338076                                        LR 0.000250    Time 0.041944    
2024-04-05 16:05:36,317 - Epoch: [195][  200/  500]    Overall Loss 0.341943    Objective Loss 0.341943                                        LR 0.000250    Time 0.041695    
2024-04-05 16:05:40,483 - Epoch: [195][  300/  500]    Overall Loss 0.342447    Objective Loss 0.342447                                        LR 0.000250    Time 0.041666    
2024-04-05 16:05:44,665 - Epoch: [195][  400/  500]    Overall Loss 0.345361    Objective Loss 0.345361                                        LR 0.000250    Time 0.041686    
2024-04-05 16:05:48,824 - Epoch: [195][  500/  500]    Overall Loss 0.346837    Objective Loss 0.346837    Top1 90.500000    Top5 99.500000    LR 0.000250    Time 0.041656    
2024-04-05 16:05:49,038 - --- validate (epoch=195)-----------
2024-04-05 16:05:49,039 - 10000 samples (100 per mini-batch)
2024-04-05 16:05:50,512 - Epoch: [195][  100/  100]    Loss 1.491416    Top1 63.910000    Top5 88.900000    
2024-04-05 16:05:50,739 - ==> Top1: 63.910    Top5: 88.900    Loss: 1.491

2024-04-05 16:05:50,746 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:05:50,746 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:05:50,777 - 

2024-04-05 16:05:50,777 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:05:55,172 - Epoch: [196][  100/  500]    Overall Loss 0.353863    Objective Loss 0.353863                                        LR 0.000250    Time 0.043893    
2024-04-05 16:05:59,285 - Epoch: [196][  200/  500]    Overall Loss 0.347427    Objective Loss 0.347427                                        LR 0.000250    Time 0.042482    
2024-04-05 16:06:03,446 - Epoch: [196][  300/  500]    Overall Loss 0.346087    Objective Loss 0.346087                                        LR 0.000250    Time 0.042174    
2024-04-05 16:06:07,566 - Epoch: [196][  400/  500]    Overall Loss 0.348288    Objective Loss 0.348288                                        LR 0.000250    Time 0.041919    
2024-04-05 16:06:11,713 - Epoch: [196][  500/  500]    Overall Loss 0.350659    Objective Loss 0.350659    Top1 91.000000    Top5 100.000000    LR 0.000250    Time 0.041818    
2024-04-05 16:06:11,950 - --- validate (epoch=196)-----------
2024-04-05 16:06:11,951 - 10000 samples (100 per mini-batch)
2024-04-05 16:06:13,549 - Epoch: [196][  100/  100]    Loss 1.486141    Top1 64.370000    Top5 88.930000    
2024-04-05 16:06:13,720 - ==> Top1: 64.370    Top5: 88.930    Loss: 1.486

2024-04-05 16:06:13,726 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:06:13,726 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:06:13,756 - 

2024-04-05 16:06:13,757 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:06:18,445 - Epoch: [197][  100/  500]    Overall Loss 0.329440    Objective Loss 0.329440                                        LR 0.000250    Time 0.046828    
2024-04-05 16:06:22,507 - Epoch: [197][  200/  500]    Overall Loss 0.334786    Objective Loss 0.334786                                        LR 0.000250    Time 0.043695    
2024-04-05 16:06:26,563 - Epoch: [197][  300/  500]    Overall Loss 0.339267    Objective Loss 0.339267                                        LR 0.000250    Time 0.042634    
2024-04-05 16:06:30,631 - Epoch: [197][  400/  500]    Overall Loss 0.343327    Objective Loss 0.343327                                        LR 0.000250    Time 0.042132    
2024-04-05 16:06:34,658 - Epoch: [197][  500/  500]    Overall Loss 0.344470    Objective Loss 0.344470    Top1 91.000000    Top5 100.000000    LR 0.000250    Time 0.041750    
2024-04-05 16:06:34,860 - --- validate (epoch=197)-----------
2024-04-05 16:06:34,860 - 10000 samples (100 per mini-batch)
2024-04-05 16:06:36,331 - Epoch: [197][  100/  100]    Loss 1.490491    Top1 63.990000    Top5 88.880000    
2024-04-05 16:06:36,503 - ==> Top1: 63.990    Top5: 88.880    Loss: 1.490

2024-04-05 16:06:36,509 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:06:36,510 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:06:36,540 - 

2024-04-05 16:06:36,540 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:06:41,417 - Epoch: [198][  100/  500]    Overall Loss 0.330737    Objective Loss 0.330737                                        LR 0.000250    Time 0.048705    
2024-04-05 16:06:45,543 - Epoch: [198][  200/  500]    Overall Loss 0.336295    Objective Loss 0.336295                                        LR 0.000250    Time 0.044960    
2024-04-05 16:06:49,642 - Epoch: [198][  300/  500]    Overall Loss 0.333613    Objective Loss 0.333613                                        LR 0.000250    Time 0.043616    
2024-04-05 16:06:53,775 - Epoch: [198][  400/  500]    Overall Loss 0.337323    Objective Loss 0.337323                                        LR 0.000250    Time 0.043032    
2024-04-05 16:06:57,885 - Epoch: [198][  500/  500]    Overall Loss 0.342499    Objective Loss 0.342499    Top1 88.000000    Top5 99.000000    LR 0.000250    Time 0.042635    
2024-04-05 16:06:58,083 - --- validate (epoch=198)-----------
2024-04-05 16:06:58,084 - 10000 samples (100 per mini-batch)
2024-04-05 16:06:59,560 - Epoch: [198][  100/  100]    Loss 1.486727    Top1 64.210000    Top5 88.900000    
2024-04-05 16:06:59,710 - ==> Top1: 64.210    Top5: 88.900    Loss: 1.487

2024-04-05 16:06:59,716 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:06:59,716 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:06:59,748 - 

2024-04-05 16:06:59,748 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:07:04,163 - Epoch: [199][  100/  500]    Overall Loss 0.332027    Objective Loss 0.332027                                        LR 0.000250    Time 0.044102    
2024-04-05 16:07:08,148 - Epoch: [199][  200/  500]    Overall Loss 0.337540    Objective Loss 0.337540                                        LR 0.000250    Time 0.041950    
2024-04-05 16:07:12,260 - Epoch: [199][  300/  500]    Overall Loss 0.339614    Objective Loss 0.339614                                        LR 0.000250    Time 0.041658    
2024-04-05 16:07:16,380 - Epoch: [199][  400/  500]    Overall Loss 0.341592    Objective Loss 0.341592                                        LR 0.000250    Time 0.041530    
2024-04-05 16:07:20,484 - Epoch: [199][  500/  500]    Overall Loss 0.346248    Objective Loss 0.346248    Top1 87.500000    Top5 99.500000    LR 0.000250    Time 0.041422    
2024-04-05 16:07:20,675 - --- validate (epoch=199)-----------
2024-04-05 16:07:20,676 - 10000 samples (100 per mini-batch)
2024-04-05 16:07:22,108 - Epoch: [199][  100/  100]    Loss 1.500121    Top1 64.150000    Top5 88.760000    
2024-04-05 16:07:22,263 - ==> Top1: 64.150    Top5: 88.760    Loss: 1.500

2024-04-05 16:07:22,270 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:07:22,270 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:07:22,303 - 

2024-04-05 16:07:22,304 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:07:27,006 - Epoch: [200][  100/  500]    Overall Loss 0.333777    Objective Loss 0.333777                                        LR 0.000125    Time 0.046962    
2024-04-05 16:07:30,742 - Epoch: [200][  200/  500]    Overall Loss 0.332065    Objective Loss 0.332065                                        LR 0.000125    Time 0.042138    
2024-04-05 16:07:34,847 - Epoch: [200][  300/  500]    Overall Loss 0.328957    Objective Loss 0.328957                                        LR 0.000125    Time 0.041758    
2024-04-05 16:07:38,960 - Epoch: [200][  400/  500]    Overall Loss 0.329511    Objective Loss 0.329511                                        LR 0.000125    Time 0.041588    
2024-04-05 16:07:43,053 - Epoch: [200][  500/  500]    Overall Loss 0.330164    Objective Loss 0.330164    Top1 90.500000    Top5 99.000000    LR 0.000125    Time 0.041447    
2024-04-05 16:07:43,248 - --- validate (epoch=200)-----------
2024-04-05 16:07:43,248 - 10000 samples (100 per mini-batch)
2024-04-05 16:07:44,932 - Epoch: [200][  100/  100]    Loss 1.476985    Top1 64.590000    Top5 89.100000    
2024-04-05 16:07:45,091 - ==> Top1: 64.590    Top5: 89.100    Loss: 1.477

2024-04-05 16:07:45,097 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:07:45,097 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:07:45,129 - 

2024-04-05 16:07:45,130 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:07:49,848 - Epoch: [201][  100/  500]    Overall Loss 0.323646    Objective Loss 0.323646                                        LR 0.000125    Time 0.047124    
2024-04-05 16:07:53,904 - Epoch: [201][  200/  500]    Overall Loss 0.326185    Objective Loss 0.326185                                        LR 0.000125    Time 0.043817    
2024-04-05 16:07:57,998 - Epoch: [201][  300/  500]    Overall Loss 0.324284    Objective Loss 0.324284                                        LR 0.000125    Time 0.042840    
2024-04-05 16:08:02,100 - Epoch: [201][  400/  500]    Overall Loss 0.327789    Objective Loss 0.327789                                        LR 0.000125    Time 0.042372    
2024-04-05 16:08:06,259 - Epoch: [201][  500/  500]    Overall Loss 0.327394    Objective Loss 0.327394    Top1 87.500000    Top5 100.000000    LR 0.000125    Time 0.042205    
2024-04-05 16:08:06,484 - --- validate (epoch=201)-----------
2024-04-05 16:08:06,484 - 10000 samples (100 per mini-batch)
2024-04-05 16:08:07,950 - Epoch: [201][  100/  100]    Loss 1.469901    Top1 64.750000    Top5 89.070000    
2024-04-05 16:08:08,124 - ==> Top1: 64.750    Top5: 89.070    Loss: 1.470

2024-04-05 16:08:08,130 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:08:08,131 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:08:08,162 - 

2024-04-05 16:08:08,162 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:08:13,130 - Epoch: [202][  100/  500]    Overall Loss 0.326634    Objective Loss 0.326634                                        LR 0.000125    Time 0.049623    
2024-04-05 16:08:16,844 - Epoch: [202][  200/  500]    Overall Loss 0.324023    Objective Loss 0.324023                                        LR 0.000125    Time 0.043357    
2024-04-05 16:08:20,973 - Epoch: [202][  300/  500]    Overall Loss 0.323344    Objective Loss 0.323344                                        LR 0.000125    Time 0.042651    
2024-04-05 16:08:25,111 - Epoch: [202][  400/  500]    Overall Loss 0.323693    Objective Loss 0.323693                                        LR 0.000125    Time 0.042319    
2024-04-05 16:08:29,247 - Epoch: [202][  500/  500]    Overall Loss 0.328485    Objective Loss 0.328485    Top1 85.000000    Top5 99.000000    LR 0.000125    Time 0.042116    
2024-04-05 16:08:29,457 - --- validate (epoch=202)-----------
2024-04-05 16:08:29,458 - 10000 samples (100 per mini-batch)
2024-04-05 16:08:30,924 - Epoch: [202][  100/  100]    Loss 1.480918    Top1 64.600000    Top5 88.930000    
2024-04-05 16:08:31,141 - ==> Top1: 64.600    Top5: 88.930    Loss: 1.481

2024-04-05 16:08:31,148 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:08:31,148 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:08:31,179 - 

2024-04-05 16:08:31,179 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:08:35,872 - Epoch: [203][  100/  500]    Overall Loss 0.326556    Objective Loss 0.326556                                        LR 0.000125    Time 0.046870    
2024-04-05 16:08:39,699 - Epoch: [203][  200/  500]    Overall Loss 0.327665    Objective Loss 0.327665                                        LR 0.000125    Time 0.042546    
2024-04-05 16:08:43,785 - Epoch: [203][  300/  500]    Overall Loss 0.324344    Objective Loss 0.324344                                        LR 0.000125    Time 0.041967    
2024-04-05 16:08:47,905 - Epoch: [203][  400/  500]    Overall Loss 0.326594    Objective Loss 0.326594                                        LR 0.000125    Time 0.041761    
2024-04-05 16:08:52,041 - Epoch: [203][  500/  500]    Overall Loss 0.325909    Objective Loss 0.325909    Top1 90.000000    Top5 99.000000    LR 0.000125    Time 0.041671    
2024-04-05 16:08:52,257 - --- validate (epoch=203)-----------
2024-04-05 16:08:52,258 - 10000 samples (100 per mini-batch)
2024-04-05 16:08:53,763 - Epoch: [203][  100/  100]    Loss 1.472135    Top1 64.650000    Top5 89.080000    
2024-04-05 16:08:53,938 - ==> Top1: 64.650    Top5: 89.080    Loss: 1.472

2024-04-05 16:08:53,946 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:08:53,946 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:08:53,977 - 

2024-04-05 16:08:53,977 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:08:58,831 - Epoch: [204][  100/  500]    Overall Loss 0.320277    Objective Loss 0.320277                                        LR 0.000125    Time 0.048485    
2024-04-05 16:09:02,801 - Epoch: [204][  200/  500]    Overall Loss 0.320926    Objective Loss 0.320926                                        LR 0.000125    Time 0.044067    
2024-04-05 16:09:05,879 - Epoch: [204][  300/  500]    Overall Loss 0.322589    Objective Loss 0.322589                                        LR 0.000125    Time 0.039623    
2024-04-05 16:09:09,054 - Epoch: [204][  400/  500]    Overall Loss 0.323788    Objective Loss 0.323788                                        LR 0.000125    Time 0.037646    
2024-04-05 16:09:12,117 - Epoch: [204][  500/  500]    Overall Loss 0.322184    Objective Loss 0.322184    Top1 90.000000    Top5 99.500000    LR 0.000125    Time 0.036235    
2024-04-05 16:09:12,320 - --- validate (epoch=204)-----------
2024-04-05 16:09:12,321 - 10000 samples (100 per mini-batch)
2024-04-05 16:09:13,728 - Epoch: [204][  100/  100]    Loss 1.479918    Top1 64.520000    Top5 89.020000    
2024-04-05 16:09:13,901 - ==> Top1: 64.520    Top5: 89.020    Loss: 1.480

2024-04-05 16:09:13,907 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:09:13,907 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:09:13,938 - 

2024-04-05 16:09:13,939 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:09:18,623 - Epoch: [205][  100/  500]    Overall Loss 0.322726    Objective Loss 0.322726                                        LR 0.000125    Time 0.046785    
2024-04-05 16:09:22,735 - Epoch: [205][  200/  500]    Overall Loss 0.325689    Objective Loss 0.325689                                        LR 0.000125    Time 0.043926    
2024-04-05 16:09:26,744 - Epoch: [205][  300/  500]    Overall Loss 0.325286    Objective Loss 0.325286                                        LR 0.000125    Time 0.042631    
2024-04-05 16:09:30,454 - Epoch: [205][  400/  500]    Overall Loss 0.322139    Objective Loss 0.322139                                        LR 0.000125    Time 0.041236    
2024-04-05 16:09:34,562 - Epoch: [205][  500/  500]    Overall Loss 0.319943    Objective Loss 0.319943    Top1 86.500000    Top5 100.000000    LR 0.000125    Time 0.041195    
2024-04-05 16:09:34,806 - --- validate (epoch=205)-----------
2024-04-05 16:09:34,807 - 10000 samples (100 per mini-batch)
2024-04-05 16:09:36,277 - Epoch: [205][  100/  100]    Loss 1.473417    Top1 64.510000    Top5 88.930000    
2024-04-05 16:09:36,434 - ==> Top1: 64.510    Top5: 88.930    Loss: 1.473

2024-04-05 16:09:36,443 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:09:36,444 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:09:36,475 - 

2024-04-05 16:09:36,476 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:09:41,033 - Epoch: [206][  100/  500]    Overall Loss 0.310930    Objective Loss 0.310930                                        LR 0.000125    Time 0.045523    
2024-04-05 16:09:45,155 - Epoch: [206][  200/  500]    Overall Loss 0.312636    Objective Loss 0.312636                                        LR 0.000125    Time 0.043345    
2024-04-05 16:09:49,241 - Epoch: [206][  300/  500]    Overall Loss 0.317580    Objective Loss 0.317580                                        LR 0.000125    Time 0.042501    
2024-04-05 16:09:52,643 - Epoch: [206][  400/  500]    Overall Loss 0.319864    Objective Loss 0.319864                                        LR 0.000125    Time 0.040369    
2024-04-05 16:09:56,772 - Epoch: [206][  500/  500]    Overall Loss 0.319324    Objective Loss 0.319324    Top1 93.500000    Top5 100.000000    LR 0.000125    Time 0.040543    
2024-04-05 16:09:56,982 - --- validate (epoch=206)-----------
2024-04-05 16:09:56,984 - 10000 samples (100 per mini-batch)
2024-04-05 16:09:58,453 - Epoch: [206][  100/  100]    Loss 1.471773    Top1 64.670000    Top5 88.960000    
2024-04-05 16:09:58,620 - ==> Top1: 64.670    Top5: 88.960    Loss: 1.472

2024-04-05 16:09:58,628 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:09:58,628 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:09:58,659 - 

2024-04-05 16:09:58,659 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:10:03,297 - Epoch: [207][  100/  500]    Overall Loss 0.322207    Objective Loss 0.322207                                        LR 0.000125    Time 0.046317    
2024-04-05 16:10:07,404 - Epoch: [207][  200/  500]    Overall Loss 0.323772    Objective Loss 0.323772                                        LR 0.000125    Time 0.043665    
2024-04-05 16:10:11,537 - Epoch: [207][  300/  500]    Overall Loss 0.318765    Objective Loss 0.318765                                        LR 0.000125    Time 0.042869    
2024-04-05 16:10:15,264 - Epoch: [207][  400/  500]    Overall Loss 0.320843    Objective Loss 0.320843                                        LR 0.000125    Time 0.041457    
2024-04-05 16:10:19,283 - Epoch: [207][  500/  500]    Overall Loss 0.321156    Objective Loss 0.321156    Top1 88.000000    Top5 98.500000    LR 0.000125    Time 0.041193    
2024-04-05 16:10:19,438 - --- validate (epoch=207)-----------
2024-04-05 16:10:19,439 - 10000 samples (100 per mini-batch)
2024-04-05 16:10:20,851 - Epoch: [207][  100/  100]    Loss 1.472978    Top1 64.480000    Top5 88.930000    
2024-04-05 16:10:20,994 - ==> Top1: 64.480    Top5: 88.930    Loss: 1.473

2024-04-05 16:10:21,000 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:10:21,000 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:10:21,031 - 

2024-04-05 16:10:21,031 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:10:25,717 - Epoch: [208][  100/  500]    Overall Loss 0.320645    Objective Loss 0.320645                                        LR 0.000125    Time 0.046802    
2024-04-05 16:10:29,862 - Epoch: [208][  200/  500]    Overall Loss 0.319425    Objective Loss 0.319425                                        LR 0.000125    Time 0.044099    
2024-04-05 16:10:34,032 - Epoch: [208][  300/  500]    Overall Loss 0.316868    Objective Loss 0.316868                                        LR 0.000125    Time 0.043284    
2024-04-05 16:10:38,167 - Epoch: [208][  400/  500]    Overall Loss 0.318329    Objective Loss 0.318329                                        LR 0.000125    Time 0.042787    
2024-04-05 16:10:41,781 - Epoch: [208][  500/  500]    Overall Loss 0.320109    Objective Loss 0.320109    Top1 92.500000    Top5 99.500000    LR 0.000125    Time 0.041449    
2024-04-05 16:10:42,095 - --- validate (epoch=208)-----------
2024-04-05 16:10:42,096 - 10000 samples (100 per mini-batch)
2024-04-05 16:10:43,538 - Epoch: [208][  100/  100]    Loss 1.475737    Top1 64.670000    Top5 89.080000    
2024-04-05 16:10:43,674 - ==> Top1: 64.670    Top5: 89.080    Loss: 1.476

2024-04-05 16:10:43,680 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:10:43,680 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:10:43,711 - 

2024-04-05 16:10:43,711 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:10:48,512 - Epoch: [209][  100/  500]    Overall Loss 0.309952    Objective Loss 0.309952                                        LR 0.000125    Time 0.047952    
2024-04-05 16:10:52,636 - Epoch: [209][  200/  500]    Overall Loss 0.309432    Objective Loss 0.309432                                        LR 0.000125    Time 0.044567    
2024-04-05 16:10:56,744 - Epoch: [209][  300/  500]    Overall Loss 0.316557    Objective Loss 0.316557                                        LR 0.000125    Time 0.043387    
2024-04-05 16:11:00,874 - Epoch: [209][  400/  500]    Overall Loss 0.317127    Objective Loss 0.317127                                        LR 0.000125    Time 0.042853    
2024-04-05 16:11:04,181 - Epoch: [209][  500/  500]    Overall Loss 0.319114    Objective Loss 0.319114    Top1 86.500000    Top5 99.500000    LR 0.000125    Time 0.040886    
2024-04-05 16:11:04,377 - --- validate (epoch=209)-----------
2024-04-05 16:11:04,378 - 10000 samples (100 per mini-batch)
2024-04-05 16:11:05,840 - Epoch: [209][  100/  100]    Loss 1.484423    Top1 64.490000    Top5 89.010000    
2024-04-05 16:11:05,993 - ==> Top1: 64.490    Top5: 89.010    Loss: 1.484

2024-04-05 16:11:06,000 - ==> Best [Top1: 64.830   Top5: 89.040   Sparsity:0.00   Params: 347840 on epoch: 160]
2024-04-05 16:11:06,000 - Saving checkpoint to: logs/2024.04.05-145134/checkpoint.pth.tar
2024-04-05 16:11:06,035 - 

2024-04-05 16:11:06,035 - Initiating quantization aware training (QAT)...
2024-04-05 16:11:06,074 - 

2024-04-05 16:11:06,074 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:11:11,231 - Epoch: [210][  100/  500]    Overall Loss 1.556064    Objective Loss 1.556064                                        LR 0.000125    Time 0.051528    
2024-04-05 16:11:15,510 - Epoch: [210][  200/  500]    Overall Loss 1.260836    Objective Loss 1.260836                                        LR 0.000125    Time 0.047141    
2024-04-05 16:11:19,847 - Epoch: [210][  300/  500]    Overall Loss 1.142969    Objective Loss 1.142969                                        LR 0.000125    Time 0.045871    
2024-04-05 16:11:24,125 - Epoch: [210][  400/  500]    Overall Loss 1.076578    Objective Loss 1.076578                                        LR 0.000125    Time 0.045090    
2024-04-05 16:11:28,173 - Epoch: [210][  500/  500]    Overall Loss 1.032594    Objective Loss 1.032594    Top1 79.500000    Top5 99.000000    LR 0.000125    Time 0.044162    
2024-04-05 16:11:28,385 - --- validate (epoch=210)-----------
2024-04-05 16:11:28,386 - 10000 samples (100 per mini-batch)
2024-04-05 16:11:30,848 - Epoch: [210][  100/  100]    Loss 1.336685    Top1 62.870000    Top5 88.010000    
2024-04-05 16:11:31,004 - ==> Top1: 62.870    Top5: 88.010    Loss: 1.337

2024-04-05 16:11:31,009 - ==> Best [Top1: 62.870   Top5: 88.010   Sparsity:0.00   Params: 347840 on epoch: 210]
2024-04-05 16:11:31,009 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:11:31,042 - 

2024-04-05 16:11:31,042 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:11:36,013 - Epoch: [211][  100/  500]    Overall Loss 0.811012    Objective Loss 0.811012                                        LR 0.000125    Time 0.049666    
2024-04-05 16:11:40,179 - Epoch: [211][  200/  500]    Overall Loss 0.803852    Objective Loss 0.803852                                        LR 0.000125    Time 0.045646    
2024-04-05 16:11:44,551 - Epoch: [211][  300/  500]    Overall Loss 0.798252    Objective Loss 0.798252                                        LR 0.000125    Time 0.044993    
2024-04-05 16:11:48,710 - Epoch: [211][  400/  500]    Overall Loss 0.796877    Objective Loss 0.796877                                        LR 0.000125    Time 0.044133    
2024-04-05 16:11:52,823 - Epoch: [211][  500/  500]    Overall Loss 0.793240    Objective Loss 0.793240    Top1 81.500000    Top5 98.500000    LR 0.000125    Time 0.043525    
2024-04-05 16:11:53,082 - --- validate (epoch=211)-----------
2024-04-05 16:11:53,082 - 10000 samples (100 per mini-batch)
2024-04-05 16:11:55,562 - Epoch: [211][  100/  100]    Loss 1.316671    Top1 62.870000    Top5 88.140000    
2024-04-05 16:11:55,767 - ==> Top1: 62.870    Top5: 88.140    Loss: 1.317

2024-04-05 16:11:55,773 - ==> Best [Top1: 62.870   Top5: 88.140   Sparsity:0.00   Params: 347840 on epoch: 211]
2024-04-05 16:11:55,774 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:11:55,813 - 

2024-04-05 16:11:55,813 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:12:00,763 - Epoch: [212][  100/  500]    Overall Loss 0.754264    Objective Loss 0.754264                                        LR 0.000125    Time 0.049453    
2024-04-05 16:12:05,158 - Epoch: [212][  200/  500]    Overall Loss 0.751473    Objective Loss 0.751473                                        LR 0.000125    Time 0.046684    
2024-04-05 16:12:09,463 - Epoch: [212][  300/  500]    Overall Loss 0.751219    Objective Loss 0.751219                                        LR 0.000125    Time 0.045463    
2024-04-05 16:12:13,595 - Epoch: [212][  400/  500]    Overall Loss 0.751211    Objective Loss 0.751211                                        LR 0.000125    Time 0.044418    
2024-04-05 16:12:17,699 - Epoch: [212][  500/  500]    Overall Loss 0.750411    Objective Loss 0.750411    Top1 83.500000    Top5 97.000000    LR 0.000125    Time 0.043736    
2024-04-05 16:12:17,891 - --- validate (epoch=212)-----------
2024-04-05 16:12:17,892 - 10000 samples (100 per mini-batch)
2024-04-05 16:12:20,279 - Epoch: [212][  100/  100]    Loss 1.288690    Top1 63.510000    Top5 88.670000    
2024-04-05 16:12:20,418 - ==> Top1: 63.510    Top5: 88.670    Loss: 1.289

2024-04-05 16:12:20,423 - ==> Best [Top1: 63.510   Top5: 88.670   Sparsity:0.00   Params: 347840 on epoch: 212]
2024-04-05 16:12:20,424 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:12:20,461 - 

2024-04-05 16:12:20,461 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:12:25,549 - Epoch: [213][  100/  500]    Overall Loss 0.721201    Objective Loss 0.721201                                        LR 0.000125    Time 0.050845    
2024-04-05 16:12:29,747 - Epoch: [213][  200/  500]    Overall Loss 0.730319    Objective Loss 0.730319                                        LR 0.000125    Time 0.046393    
2024-04-05 16:12:34,018 - Epoch: [213][  300/  500]    Overall Loss 0.727495    Objective Loss 0.727495                                        LR 0.000125    Time 0.045156    
2024-04-05 16:12:37,939 - Epoch: [213][  400/  500]    Overall Loss 0.726450    Objective Loss 0.726450                                        LR 0.000125    Time 0.043659    
2024-04-05 16:12:42,179 - Epoch: [213][  500/  500]    Overall Loss 0.727073    Objective Loss 0.727073    Top1 80.000000    Top5 99.500000    LR 0.000125    Time 0.043402    
2024-04-05 16:12:42,372 - --- validate (epoch=213)-----------
2024-04-05 16:12:42,373 - 10000 samples (100 per mini-batch)
2024-04-05 16:12:44,716 - Epoch: [213][  100/  100]    Loss 1.308521    Top1 62.930000    Top5 88.480000    
2024-04-05 16:12:44,904 - ==> Top1: 62.930    Top5: 88.480    Loss: 1.309

2024-04-05 16:12:44,910 - ==> Best [Top1: 63.510   Top5: 88.670   Sparsity:0.00   Params: 347840 on epoch: 212]
2024-04-05 16:12:44,910 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:12:44,942 - 

2024-04-05 16:12:44,942 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:12:49,950 - Epoch: [214][  100/  500]    Overall Loss 0.704054    Objective Loss 0.704054                                        LR 0.000125    Time 0.050035    
2024-04-05 16:12:54,268 - Epoch: [214][  200/  500]    Overall Loss 0.711370    Objective Loss 0.711370                                        LR 0.000125    Time 0.046589    
2024-04-05 16:12:58,478 - Epoch: [214][  300/  500]    Overall Loss 0.705814    Objective Loss 0.705814                                        LR 0.000125    Time 0.045084    
2024-04-05 16:13:02,453 - Epoch: [214][  400/  500]    Overall Loss 0.704764    Objective Loss 0.704764                                        LR 0.000125    Time 0.043743    
2024-04-05 16:13:06,708 - Epoch: [214][  500/  500]    Overall Loss 0.705093    Objective Loss 0.705093    Top1 82.500000    Top5 96.500000    LR 0.000125    Time 0.043497    
2024-04-05 16:13:06,951 - --- validate (epoch=214)-----------
2024-04-05 16:13:06,952 - 10000 samples (100 per mini-batch)
2024-04-05 16:13:09,518 - Epoch: [214][  100/  100]    Loss 1.274875    Top1 63.830000    Top5 88.810000    
2024-04-05 16:13:09,698 - ==> Top1: 63.830    Top5: 88.810    Loss: 1.275

2024-04-05 16:13:09,703 - ==> Best [Top1: 63.830   Top5: 88.810   Sparsity:0.00   Params: 347840 on epoch: 214]
2024-04-05 16:13:09,703 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:13:09,739 - 

2024-04-05 16:13:09,739 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:13:14,789 - Epoch: [215][  100/  500]    Overall Loss 0.686614    Objective Loss 0.686614                                        LR 0.000125    Time 0.050457    
2024-04-05 16:13:18,964 - Epoch: [215][  200/  500]    Overall Loss 0.685162    Objective Loss 0.685162                                        LR 0.000125    Time 0.046086    
2024-04-05 16:13:23,185 - Epoch: [215][  300/  500]    Overall Loss 0.692155    Objective Loss 0.692155                                        LR 0.000125    Time 0.044786    
2024-04-05 16:13:27,033 - Epoch: [215][  400/  500]    Overall Loss 0.692056    Objective Loss 0.692056                                        LR 0.000125    Time 0.043201    
2024-04-05 16:13:31,189 - Epoch: [215][  500/  500]    Overall Loss 0.694151    Objective Loss 0.694151    Top1 81.000000    Top5 98.000000    LR 0.000125    Time 0.042866    
2024-04-05 16:13:31,474 - --- validate (epoch=215)-----------
2024-04-05 16:13:31,475 - 10000 samples (100 per mini-batch)
2024-04-05 16:13:33,833 - Epoch: [215][  100/  100]    Loss 1.285511    Top1 63.730000    Top5 88.990000    
2024-04-05 16:13:33,963 - ==> Top1: 63.730    Top5: 88.990    Loss: 1.286

2024-04-05 16:13:33,968 - ==> Best [Top1: 63.830   Top5: 88.810   Sparsity:0.00   Params: 347840 on epoch: 214]
2024-04-05 16:13:33,968 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:13:33,999 - 

2024-04-05 16:13:33,999 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:13:39,208 - Epoch: [216][  100/  500]    Overall Loss 0.706332    Objective Loss 0.706332                                        LR 0.000125    Time 0.052052    
2024-04-05 16:13:43,485 - Epoch: [216][  200/  500]    Overall Loss 0.692436    Objective Loss 0.692436                                        LR 0.000125    Time 0.047394    
2024-04-05 16:13:47,669 - Epoch: [216][  300/  500]    Overall Loss 0.687063    Objective Loss 0.687063                                        LR 0.000125    Time 0.045531    
2024-04-05 16:13:51,537 - Epoch: [216][  400/  500]    Overall Loss 0.684911    Objective Loss 0.684911                                        LR 0.000125    Time 0.043810    
2024-04-05 16:13:55,766 - Epoch: [216][  500/  500]    Overall Loss 0.684300    Objective Loss 0.684300    Top1 85.500000    Top5 98.500000    LR 0.000125    Time 0.043499    
2024-04-05 16:13:55,973 - --- validate (epoch=216)-----------
2024-04-05 16:13:55,974 - 10000 samples (100 per mini-batch)
2024-04-05 16:13:58,313 - Epoch: [216][  100/  100]    Loss 1.332092    Top1 62.890000    Top5 87.950000    
2024-04-05 16:13:58,462 - ==> Top1: 62.890    Top5: 87.950    Loss: 1.332

2024-04-05 16:13:58,468 - ==> Best [Top1: 63.830   Top5: 88.810   Sparsity:0.00   Params: 347840 on epoch: 214]
2024-04-05 16:13:58,468 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:13:58,500 - 

2024-04-05 16:13:58,500 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:14:03,532 - Epoch: [217][  100/  500]    Overall Loss 0.670455    Objective Loss 0.670455                                        LR 0.000125    Time 0.050274    
2024-04-05 16:14:07,870 - Epoch: [217][  200/  500]    Overall Loss 0.666432    Objective Loss 0.666432                                        LR 0.000125    Time 0.046813    
2024-04-05 16:14:12,127 - Epoch: [217][  300/  500]    Overall Loss 0.667229    Objective Loss 0.667229                                        LR 0.000125    Time 0.045388    
2024-04-05 16:14:15,751 - Epoch: [217][  400/  500]    Overall Loss 0.674051    Objective Loss 0.674051                                        LR 0.000125    Time 0.043092    
2024-04-05 16:14:18,880 - Epoch: [217][  500/  500]    Overall Loss 0.674369    Objective Loss 0.674369    Top1 84.000000    Top5 97.500000    LR 0.000125    Time 0.040725    
2024-04-05 16:14:19,090 - --- validate (epoch=217)-----------
2024-04-05 16:14:19,091 - 10000 samples (100 per mini-batch)
2024-04-05 16:14:21,482 - Epoch: [217][  100/  100]    Loss 1.318947    Top1 63.280000    Top5 88.320000    
2024-04-05 16:14:21,654 - ==> Top1: 63.280    Top5: 88.320    Loss: 1.319

2024-04-05 16:14:21,660 - ==> Best [Top1: 63.830   Top5: 88.810   Sparsity:0.00   Params: 347840 on epoch: 214]
2024-04-05 16:14:21,660 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:14:21,690 - 

2024-04-05 16:14:21,691 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:14:26,620 - Epoch: [218][  100/  500]    Overall Loss 0.664478    Objective Loss 0.664478                                        LR 0.000125    Time 0.049247    
2024-04-05 16:14:30,828 - Epoch: [218][  200/  500]    Overall Loss 0.661494    Objective Loss 0.661494                                        LR 0.000125    Time 0.045648    
2024-04-05 16:14:35,120 - Epoch: [218][  300/  500]    Overall Loss 0.658715    Objective Loss 0.658715                                        LR 0.000125    Time 0.044727    
2024-04-05 16:14:39,002 - Epoch: [218][  400/  500]    Overall Loss 0.662563    Objective Loss 0.662563                                        LR 0.000125    Time 0.043243    
2024-04-05 16:14:43,098 - Epoch: [218][  500/  500]    Overall Loss 0.664228    Objective Loss 0.664228    Top1 78.500000    Top5 98.500000    LR 0.000125    Time 0.042781    
2024-04-05 16:14:43,261 - --- validate (epoch=218)-----------
2024-04-05 16:14:43,262 - 10000 samples (100 per mini-batch)
2024-04-05 16:14:45,211 - Epoch: [218][  100/  100]    Loss 1.282559    Top1 64.060000    Top5 89.000000    
2024-04-05 16:14:45,340 - ==> Top1: 64.060    Top5: 89.000    Loss: 1.283

2024-04-05 16:14:45,344 - ==> Best [Top1: 64.060   Top5: 89.000   Sparsity:0.00   Params: 347840 on epoch: 218]
2024-04-05 16:14:45,345 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:14:45,379 - 

2024-04-05 16:14:45,379 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:14:50,379 - Epoch: [219][  100/  500]    Overall Loss 0.640581    Objective Loss 0.640581                                        LR 0.000125    Time 0.049963    
2024-04-05 16:14:54,576 - Epoch: [219][  200/  500]    Overall Loss 0.656219    Objective Loss 0.656219                                        LR 0.000125    Time 0.045949    
2024-04-05 16:14:58,883 - Epoch: [219][  300/  500]    Overall Loss 0.651509    Objective Loss 0.651509                                        LR 0.000125    Time 0.044976    
2024-04-05 16:15:02,773 - Epoch: [219][  400/  500]    Overall Loss 0.653218    Objective Loss 0.653218                                        LR 0.000125    Time 0.043451    
2024-04-05 16:15:06,970 - Epoch: [219][  500/  500]    Overall Loss 0.651938    Objective Loss 0.651938    Top1 80.500000    Top5 97.500000    LR 0.000125    Time 0.043148    
2024-04-05 16:15:07,214 - --- validate (epoch=219)-----------
2024-04-05 16:15:07,215 - 10000 samples (100 per mini-batch)
2024-04-05 16:15:09,672 - Epoch: [219][  100/  100]    Loss 1.276135    Top1 64.260000    Top5 88.710000    
2024-04-05 16:15:09,912 - ==> Top1: 64.260    Top5: 88.710    Loss: 1.276

2024-04-05 16:15:09,919 - ==> Best [Top1: 64.260   Top5: 88.710   Sparsity:0.00   Params: 347840 on epoch: 219]
2024-04-05 16:15:09,919 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:15:09,959 - 

2024-04-05 16:15:09,959 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:15:14,940 - Epoch: [220][  100/  500]    Overall Loss 0.649990    Objective Loss 0.649990                                        LR 0.000125    Time 0.049758    
2024-04-05 16:15:19,164 - Epoch: [220][  200/  500]    Overall Loss 0.655288    Objective Loss 0.655288                                        LR 0.000125    Time 0.045984    
2024-04-05 16:15:23,292 - Epoch: [220][  300/  500]    Overall Loss 0.653008    Objective Loss 0.653008                                        LR 0.000125    Time 0.044403    
2024-04-05 16:15:27,484 - Epoch: [220][  400/  500]    Overall Loss 0.653280    Objective Loss 0.653280                                        LR 0.000125    Time 0.043774    
2024-04-05 16:15:31,710 - Epoch: [220][  500/  500]    Overall Loss 0.654377    Objective Loss 0.654377    Top1 78.000000    Top5 98.500000    LR 0.000125    Time 0.043466    
2024-04-05 16:15:31,941 - --- validate (epoch=220)-----------
2024-04-05 16:15:31,942 - 10000 samples (100 per mini-batch)
2024-04-05 16:15:34,554 - Epoch: [220][  100/  100]    Loss 1.302527    Top1 63.390000    Top5 88.460000    
2024-04-05 16:15:34,814 - ==> Top1: 63.390    Top5: 88.460    Loss: 1.303

2024-04-05 16:15:34,819 - ==> Best [Top1: 64.260   Top5: 88.710   Sparsity:0.00   Params: 347840 on epoch: 219]
2024-04-05 16:15:34,819 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:15:34,851 - 

2024-04-05 16:15:34,851 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:15:39,874 - Epoch: [221][  100/  500]    Overall Loss 0.633067    Objective Loss 0.633067                                        LR 0.000125    Time 0.050188    
2024-04-05 16:15:44,075 - Epoch: [221][  200/  500]    Overall Loss 0.630665    Objective Loss 0.630665                                        LR 0.000125    Time 0.046082    
2024-04-05 16:15:47,951 - Epoch: [221][  300/  500]    Overall Loss 0.636481    Objective Loss 0.636481                                        LR 0.000125    Time 0.043631    
2024-04-05 16:15:52,207 - Epoch: [221][  400/  500]    Overall Loss 0.641676    Objective Loss 0.641676                                        LR 0.000125    Time 0.043353    
2024-04-05 16:15:56,370 - Epoch: [221][  500/  500]    Overall Loss 0.644176    Objective Loss 0.644176    Top1 79.500000    Top5 99.000000    LR 0.000125    Time 0.043003    
2024-04-05 16:15:56,589 - --- validate (epoch=221)-----------
2024-04-05 16:15:56,589 - 10000 samples (100 per mini-batch)
2024-04-05 16:15:58,911 - Epoch: [221][  100/  100]    Loss 1.286103    Top1 64.020000    Top5 88.960000    
2024-04-05 16:15:59,097 - ==> Top1: 64.020    Top5: 88.960    Loss: 1.286

2024-04-05 16:15:59,101 - ==> Best [Top1: 64.260   Top5: 88.710   Sparsity:0.00   Params: 347840 on epoch: 219]
2024-04-05 16:15:59,102 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:15:59,132 - 

2024-04-05 16:15:59,133 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:16:04,059 - Epoch: [222][  100/  500]    Overall Loss 0.615537    Objective Loss 0.615537                                        LR 0.000125    Time 0.049225    
2024-04-05 16:16:08,376 - Epoch: [222][  200/  500]    Overall Loss 0.622752    Objective Loss 0.622752                                        LR 0.000125    Time 0.046178    
2024-04-05 16:16:12,273 - Epoch: [222][  300/  500]    Overall Loss 0.630180    Objective Loss 0.630180                                        LR 0.000125    Time 0.043763    
2024-04-05 16:16:16,437 - Epoch: [222][  400/  500]    Overall Loss 0.630476    Objective Loss 0.630476                                        LR 0.000125    Time 0.043224    
2024-04-05 16:16:20,708 - Epoch: [222][  500/  500]    Overall Loss 0.633611    Objective Loss 0.633611    Top1 82.500000    Top5 97.000000    LR 0.000125    Time 0.043115    
2024-04-05 16:16:20,935 - --- validate (epoch=222)-----------
2024-04-05 16:16:20,936 - 10000 samples (100 per mini-batch)
2024-04-05 16:16:23,319 - Epoch: [222][  100/  100]    Loss 1.306833    Top1 63.250000    Top5 88.660000    
2024-04-05 16:16:23,476 - ==> Top1: 63.250    Top5: 88.660    Loss: 1.307

2024-04-05 16:16:23,483 - ==> Best [Top1: 64.260   Top5: 88.710   Sparsity:0.00   Params: 347840 on epoch: 219]
2024-04-05 16:16:23,483 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:16:23,513 - 

2024-04-05 16:16:23,513 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:16:28,438 - Epoch: [223][  100/  500]    Overall Loss 0.604929    Objective Loss 0.604929                                        LR 0.000125    Time 0.049207    
2024-04-05 16:16:32,623 - Epoch: [223][  200/  500]    Overall Loss 0.611372    Objective Loss 0.611372                                        LR 0.000125    Time 0.045512    
2024-04-05 16:16:36,602 - Epoch: [223][  300/  500]    Overall Loss 0.614183    Objective Loss 0.614183                                        LR 0.000125    Time 0.043593    
2024-04-05 16:16:40,910 - Epoch: [223][  400/  500]    Overall Loss 0.619641    Objective Loss 0.619641                                        LR 0.000125    Time 0.043454    
2024-04-05 16:16:45,173 - Epoch: [223][  500/  500]    Overall Loss 0.621998    Objective Loss 0.621998    Top1 78.500000    Top5 98.000000    LR 0.000125    Time 0.043284    
2024-04-05 16:16:45,442 - --- validate (epoch=223)-----------
2024-04-05 16:16:45,443 - 10000 samples (100 per mini-batch)
2024-04-05 16:16:47,850 - Epoch: [223][  100/  100]    Loss 1.296458    Top1 63.790000    Top5 88.720000    
2024-04-05 16:16:48,081 - ==> Top1: 63.790    Top5: 88.720    Loss: 1.296

2024-04-05 16:16:48,086 - ==> Best [Top1: 64.260   Top5: 88.710   Sparsity:0.00   Params: 347840 on epoch: 219]
2024-04-05 16:16:48,086 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:16:48,117 - 

2024-04-05 16:16:48,117 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:16:53,139 - Epoch: [224][  100/  500]    Overall Loss 0.607391    Objective Loss 0.607391                                        LR 0.000125    Time 0.050175    
2024-04-05 16:16:57,375 - Epoch: [224][  200/  500]    Overall Loss 0.605459    Objective Loss 0.605459                                        LR 0.000125    Time 0.046249    
2024-04-05 16:17:01,583 - Epoch: [224][  300/  500]    Overall Loss 0.611977    Objective Loss 0.611977                                        LR 0.000125    Time 0.044846    
2024-04-05 16:17:05,808 - Epoch: [224][  400/  500]    Overall Loss 0.613794    Objective Loss 0.613794                                        LR 0.000125    Time 0.044190    
2024-04-05 16:17:09,996 - Epoch: [224][  500/  500]    Overall Loss 0.619847    Objective Loss 0.619847    Top1 79.500000    Top5 99.000000    LR 0.000125    Time 0.043722    
2024-04-05 16:17:10,175 - --- validate (epoch=224)-----------
2024-04-05 16:17:10,175 - 10000 samples (100 per mini-batch)
2024-04-05 16:17:12,615 - Epoch: [224][  100/  100]    Loss 1.304695    Top1 63.930000    Top5 88.600000    
2024-04-05 16:17:12,810 - ==> Top1: 63.930    Top5: 88.600    Loss: 1.305

2024-04-05 16:17:12,816 - ==> Best [Top1: 64.260   Top5: 88.710   Sparsity:0.00   Params: 347840 on epoch: 219]
2024-04-05 16:17:12,816 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:17:12,846 - 

2024-04-05 16:17:12,847 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:17:18,109 - Epoch: [225][  100/  500]    Overall Loss 0.619815    Objective Loss 0.619815                                        LR 0.000125    Time 0.052584    
2024-04-05 16:17:22,355 - Epoch: [225][  200/  500]    Overall Loss 0.609113    Objective Loss 0.609113                                        LR 0.000125    Time 0.047504    
2024-04-05 16:17:26,499 - Epoch: [225][  300/  500]    Overall Loss 0.613734    Objective Loss 0.613734                                        LR 0.000125    Time 0.045471    
2024-04-05 16:17:30,651 - Epoch: [225][  400/  500]    Overall Loss 0.616616    Objective Loss 0.616616                                        LR 0.000125    Time 0.044475    
2024-04-05 16:17:34,966 - Epoch: [225][  500/  500]    Overall Loss 0.623080    Objective Loss 0.623080    Top1 81.000000    Top5 97.000000    LR 0.000125    Time 0.044203    
2024-04-05 16:17:35,116 - --- validate (epoch=225)-----------
2024-04-05 16:17:35,116 - 10000 samples (100 per mini-batch)
2024-04-05 16:17:37,452 - Epoch: [225][  100/  100]    Loss 1.299484    Top1 63.780000    Top5 88.780000    
2024-04-05 16:17:37,614 - ==> Top1: 63.780    Top5: 88.780    Loss: 1.299

2024-04-05 16:17:37,621 - ==> Best [Top1: 64.260   Top5: 88.710   Sparsity:0.00   Params: 347840 on epoch: 219]
2024-04-05 16:17:37,621 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:17:37,652 - 

2024-04-05 16:17:37,652 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:17:42,613 - Epoch: [226][  100/  500]    Overall Loss 0.598481    Objective Loss 0.598481                                        LR 0.000125    Time 0.049566    
2024-04-05 16:17:46,806 - Epoch: [226][  200/  500]    Overall Loss 0.614421    Objective Loss 0.614421                                        LR 0.000125    Time 0.045728    
2024-04-05 16:17:50,785 - Epoch: [226][  300/  500]    Overall Loss 0.617850    Objective Loss 0.617850                                        LR 0.000125    Time 0.043738    
2024-04-05 16:17:55,047 - Epoch: [226][  400/  500]    Overall Loss 0.618273    Objective Loss 0.618273                                        LR 0.000125    Time 0.043451    
2024-04-05 16:17:59,217 - Epoch: [226][  500/  500]    Overall Loss 0.616207    Objective Loss 0.616207    Top1 81.500000    Top5 99.000000    LR 0.000125    Time 0.043095    
2024-04-05 16:17:59,433 - --- validate (epoch=226)-----------
2024-04-05 16:17:59,434 - 10000 samples (100 per mini-batch)
2024-04-05 16:18:02,009 - Epoch: [226][  100/  100]    Loss 1.276755    Top1 64.310000    Top5 88.980000    
2024-04-05 16:18:02,267 - ==> Top1: 64.310    Top5: 88.980    Loss: 1.277

2024-04-05 16:18:02,271 - ==> Best [Top1: 64.310   Top5: 88.980   Sparsity:0.00   Params: 347840 on epoch: 226]
2024-04-05 16:18:02,272 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:18:02,309 - 

2024-04-05 16:18:02,309 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:18:07,316 - Epoch: [227][  100/  500]    Overall Loss 0.595792    Objective Loss 0.595792                                        LR 0.000125    Time 0.050032    
2024-04-05 16:18:11,669 - Epoch: [227][  200/  500]    Overall Loss 0.597009    Objective Loss 0.597009                                        LR 0.000125    Time 0.046761    
2024-04-05 16:18:15,974 - Epoch: [227][  300/  500]    Overall Loss 0.605518    Objective Loss 0.605518                                        LR 0.000125    Time 0.045512    
2024-04-05 16:18:20,120 - Epoch: [227][  400/  500]    Overall Loss 0.608909    Objective Loss 0.608909                                        LR 0.000125    Time 0.044492    
2024-04-05 16:18:24,294 - Epoch: [227][  500/  500]    Overall Loss 0.611877    Objective Loss 0.611877    Top1 82.500000    Top5 99.500000    LR 0.000125    Time 0.043934    
2024-04-05 16:18:24,498 - --- validate (epoch=227)-----------
2024-04-05 16:18:24,500 - 10000 samples (100 per mini-batch)
2024-04-05 16:18:26,910 - Epoch: [227][  100/  100]    Loss 1.297247    Top1 63.970000    Top5 88.870000    
2024-04-05 16:18:27,123 - ==> Top1: 63.970    Top5: 88.870    Loss: 1.297

2024-04-05 16:18:27,129 - ==> Best [Top1: 64.310   Top5: 88.980   Sparsity:0.00   Params: 347840 on epoch: 226]
2024-04-05 16:18:27,129 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:18:27,159 - 

2024-04-05 16:18:27,160 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:18:32,282 - Epoch: [228][  100/  500]    Overall Loss 0.592299    Objective Loss 0.592299                                        LR 0.000125    Time 0.051178    
2024-04-05 16:18:36,351 - Epoch: [228][  200/  500]    Overall Loss 0.594138    Objective Loss 0.594138                                        LR 0.000125    Time 0.045921    
2024-04-05 16:18:40,496 - Epoch: [228][  300/  500]    Overall Loss 0.598881    Objective Loss 0.598881                                        LR 0.000125    Time 0.044418    
2024-04-05 16:18:44,653 - Epoch: [228][  400/  500]    Overall Loss 0.600860    Objective Loss 0.600860                                        LR 0.000125    Time 0.043697    
2024-04-05 16:18:48,854 - Epoch: [228][  500/  500]    Overall Loss 0.601252    Objective Loss 0.601252    Top1 79.500000    Top5 97.000000    LR 0.000125    Time 0.043353    
2024-04-05 16:18:49,087 - --- validate (epoch=228)-----------
2024-04-05 16:18:49,088 - 10000 samples (100 per mini-batch)
2024-04-05 16:18:51,430 - Epoch: [228][  100/  100]    Loss 1.291856    Top1 63.930000    Top5 88.900000    
2024-04-05 16:18:51,581 - ==> Top1: 63.930    Top5: 88.900    Loss: 1.292

2024-04-05 16:18:51,587 - ==> Best [Top1: 64.310   Top5: 88.980   Sparsity:0.00   Params: 347840 on epoch: 226]
2024-04-05 16:18:51,587 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:18:51,617 - 

2024-04-05 16:18:51,618 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:18:56,137 - Epoch: [229][  100/  500]    Overall Loss 0.593598    Objective Loss 0.593598                                        LR 0.000125    Time 0.045158    
2024-04-05 16:19:00,047 - Epoch: [229][  200/  500]    Overall Loss 0.594629    Objective Loss 0.594629                                        LR 0.000125    Time 0.042109    
2024-04-05 16:19:03,631 - Epoch: [229][  300/  500]    Overall Loss 0.596841    Objective Loss 0.596841                                        LR 0.000125    Time 0.040009    
2024-04-05 16:19:06,830 - Epoch: [229][  400/  500]    Overall Loss 0.599289    Objective Loss 0.599289                                        LR 0.000125    Time 0.037996    
2024-04-05 16:19:10,162 - Epoch: [229][  500/  500]    Overall Loss 0.600796    Objective Loss 0.600796    Top1 83.000000    Top5 98.000000    LR 0.000125    Time 0.037055    
2024-04-05 16:19:10,294 - --- validate (epoch=229)-----------
2024-04-05 16:19:10,294 - 10000 samples (100 per mini-batch)
2024-04-05 16:19:12,206 - Epoch: [229][  100/  100]    Loss 1.278991    Top1 64.550000    Top5 89.110000    
2024-04-05 16:19:12,320 - ==> Top1: 64.550    Top5: 89.110    Loss: 1.279

2024-04-05 16:19:12,326 - ==> Best [Top1: 64.550   Top5: 89.110   Sparsity:0.00   Params: 347840 on epoch: 229]
2024-04-05 16:19:12,326 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:19:12,363 - 

2024-04-05 16:19:12,363 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:19:17,375 - Epoch: [230][  100/  500]    Overall Loss 0.593697    Objective Loss 0.593697                                        LR 0.000125    Time 0.050072    
2024-04-05 16:19:21,570 - Epoch: [230][  200/  500]    Overall Loss 0.595578    Objective Loss 0.595578                                        LR 0.000125    Time 0.045991    
2024-04-05 16:19:25,843 - Epoch: [230][  300/  500]    Overall Loss 0.592506    Objective Loss 0.592506                                        LR 0.000125    Time 0.044893    
2024-04-05 16:19:30,086 - Epoch: [230][  400/  500]    Overall Loss 0.598325    Objective Loss 0.598325                                        LR 0.000125    Time 0.044265    
2024-04-05 16:19:34,387 - Epoch: [230][  500/  500]    Overall Loss 0.602216    Objective Loss 0.602216    Top1 83.000000    Top5 97.500000    LR 0.000125    Time 0.044007    
2024-04-05 16:19:34,603 - --- validate (epoch=230)-----------
2024-04-05 16:19:34,604 - 10000 samples (100 per mini-batch)
2024-04-05 16:19:36,986 - Epoch: [230][  100/  100]    Loss 1.285395    Top1 63.900000    Top5 89.150000    
2024-04-05 16:19:37,154 - ==> Top1: 63.900    Top5: 89.150    Loss: 1.285

2024-04-05 16:19:37,159 - ==> Best [Top1: 64.550   Top5: 89.110   Sparsity:0.00   Params: 347840 on epoch: 229]
2024-04-05 16:19:37,159 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:19:37,189 - 

2024-04-05 16:19:37,189 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:19:42,471 - Epoch: [231][  100/  500]    Overall Loss 0.583397    Objective Loss 0.583397                                        LR 0.000125    Time 0.052781    
2024-04-05 16:19:46,658 - Epoch: [231][  200/  500]    Overall Loss 0.587585    Objective Loss 0.587585                                        LR 0.000125    Time 0.047308    
2024-04-05 16:19:50,587 - Epoch: [231][  300/  500]    Overall Loss 0.590416    Objective Loss 0.590416                                        LR 0.000125    Time 0.044620    
2024-04-05 16:19:54,727 - Epoch: [231][  400/  500]    Overall Loss 0.588859    Objective Loss 0.588859                                        LR 0.000125    Time 0.043806    
2024-04-05 16:19:58,902 - Epoch: [231][  500/  500]    Overall Loss 0.590686    Objective Loss 0.590686    Top1 86.500000    Top5 98.500000    LR 0.000125    Time 0.043387    
2024-04-05 16:19:59,191 - --- validate (epoch=231)-----------
2024-04-05 16:19:59,192 - 10000 samples (100 per mini-batch)
2024-04-05 16:20:01,576 - Epoch: [231][  100/  100]    Loss 1.290816    Top1 63.940000    Top5 89.050000    
2024-04-05 16:20:01,755 - ==> Top1: 63.940    Top5: 89.050    Loss: 1.291

2024-04-05 16:20:01,760 - ==> Best [Top1: 64.550   Top5: 89.110   Sparsity:0.00   Params: 347840 on epoch: 229]
2024-04-05 16:20:01,761 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:20:01,793 - 

2024-04-05 16:20:01,793 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:20:06,823 - Epoch: [232][  100/  500]    Overall Loss 0.588064    Objective Loss 0.588064                                        LR 0.000125    Time 0.050262    
2024-04-05 16:20:11,122 - Epoch: [232][  200/  500]    Overall Loss 0.588011    Objective Loss 0.588011                                        LR 0.000125    Time 0.046607    
2024-04-05 16:20:15,113 - Epoch: [232][  300/  500]    Overall Loss 0.592417    Objective Loss 0.592417                                        LR 0.000125    Time 0.044363    
2024-04-05 16:20:19,299 - Epoch: [232][  400/  500]    Overall Loss 0.594977    Objective Loss 0.594977                                        LR 0.000125    Time 0.043731    
2024-04-05 16:20:23,521 - Epoch: [232][  500/  500]    Overall Loss 0.593978    Objective Loss 0.593978    Top1 86.500000    Top5 98.500000    LR 0.000125    Time 0.043421    
2024-04-05 16:20:23,801 - --- validate (epoch=232)-----------
2024-04-05 16:20:23,802 - 10000 samples (100 per mini-batch)
2024-04-05 16:20:26,259 - Epoch: [232][  100/  100]    Loss 1.274699    Top1 64.530000    Top5 89.060000    
2024-04-05 16:20:26,416 - ==> Top1: 64.530    Top5: 89.060    Loss: 1.275

2024-04-05 16:20:26,421 - ==> Best [Top1: 64.550   Top5: 89.110   Sparsity:0.00   Params: 347840 on epoch: 229]
2024-04-05 16:20:26,421 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:20:26,452 - 

2024-04-05 16:20:26,452 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:20:31,358 - Epoch: [233][  100/  500]    Overall Loss 0.570624    Objective Loss 0.570624                                        LR 0.000125    Time 0.049025    
2024-04-05 16:20:35,440 - Epoch: [233][  200/  500]    Overall Loss 0.574327    Objective Loss 0.574327                                        LR 0.000125    Time 0.044901    
2024-04-05 16:20:39,523 - Epoch: [233][  300/  500]    Overall Loss 0.580160    Objective Loss 0.580160                                        LR 0.000125    Time 0.043536    
2024-04-05 16:20:43,790 - Epoch: [233][  400/  500]    Overall Loss 0.582687    Objective Loss 0.582687                                        LR 0.000125    Time 0.043309    
2024-04-05 16:20:48,019 - Epoch: [233][  500/  500]    Overall Loss 0.584336    Objective Loss 0.584336    Top1 77.500000    Top5 99.500000    LR 0.000125    Time 0.043098    
2024-04-05 16:20:48,195 - --- validate (epoch=233)-----------
2024-04-05 16:20:48,196 - 10000 samples (100 per mini-batch)
2024-04-05 16:20:50,561 - Epoch: [233][  100/  100]    Loss 1.293958    Top1 63.810000    Top5 88.770000    
2024-04-05 16:20:50,778 - ==> Top1: 63.810    Top5: 88.770    Loss: 1.294

2024-04-05 16:20:50,785 - ==> Best [Top1: 64.550   Top5: 89.110   Sparsity:0.00   Params: 347840 on epoch: 229]
2024-04-05 16:20:50,785 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:20:50,822 - 

2024-04-05 16:20:50,823 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:20:56,089 - Epoch: [234][  100/  500]    Overall Loss 0.573387    Objective Loss 0.573387                                        LR 0.000125    Time 0.052618    
2024-04-05 16:21:00,001 - Epoch: [234][  200/  500]    Overall Loss 0.579915    Objective Loss 0.579915                                        LR 0.000125    Time 0.045853    
2024-04-05 16:21:04,168 - Epoch: [234][  300/  500]    Overall Loss 0.584941    Objective Loss 0.584941                                        LR 0.000125    Time 0.044448    
2024-04-05 16:21:08,342 - Epoch: [234][  400/  500]    Overall Loss 0.587243    Objective Loss 0.587243                                        LR 0.000125    Time 0.043763    
2024-04-05 16:21:12,512 - Epoch: [234][  500/  500]    Overall Loss 0.589762    Objective Loss 0.589762    Top1 83.000000    Top5 97.500000    LR 0.000125    Time 0.043344    
2024-04-05 16:21:12,783 - --- validate (epoch=234)-----------
2024-04-05 16:21:12,783 - 10000 samples (100 per mini-batch)
2024-04-05 16:21:15,179 - Epoch: [234][  100/  100]    Loss 1.304381    Top1 63.860000    Top5 88.710000    
2024-04-05 16:21:15,346 - ==> Top1: 63.860    Top5: 88.710    Loss: 1.304

2024-04-05 16:21:15,353 - ==> Best [Top1: 64.550   Top5: 89.110   Sparsity:0.00   Params: 347840 on epoch: 229]
2024-04-05 16:21:15,353 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:21:15,380 - 

2024-04-05 16:21:15,380 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:21:20,292 - Epoch: [235][  100/  500]    Overall Loss 0.554602    Objective Loss 0.554602                                        LR 0.000125    Time 0.049073    
2024-04-05 16:21:24,180 - Epoch: [235][  200/  500]    Overall Loss 0.567297    Objective Loss 0.567297                                        LR 0.000125    Time 0.043961    
2024-04-05 16:21:26,953 - Epoch: [235][  300/  500]    Overall Loss 0.569958    Objective Loss 0.569958                                        LR 0.000125    Time 0.038544    
2024-04-05 16:21:29,125 - Epoch: [235][  400/  500]    Overall Loss 0.574725    Objective Loss 0.574725                                        LR 0.000125    Time 0.034334    
2024-04-05 16:21:31,290 - Epoch: [235][  500/  500]    Overall Loss 0.575294    Objective Loss 0.575294    Top1 81.500000    Top5 96.500000    LR 0.000125    Time 0.031795    
2024-04-05 16:21:31,400 - --- validate (epoch=235)-----------
2024-04-05 16:21:31,401 - 10000 samples (100 per mini-batch)
2024-04-05 16:21:33,105 - Epoch: [235][  100/  100]    Loss 1.277648    Top1 64.230000    Top5 88.930000    
2024-04-05 16:21:33,221 - ==> Top1: 64.230    Top5: 88.930    Loss: 1.278

2024-04-05 16:21:33,228 - ==> Best [Top1: 64.550   Top5: 89.110   Sparsity:0.00   Params: 347840 on epoch: 229]
2024-04-05 16:21:33,228 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:21:33,257 - 

2024-04-05 16:21:33,258 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:21:37,889 - Epoch: [236][  100/  500]    Overall Loss 0.561455    Objective Loss 0.561455                                        LR 0.000125    Time 0.046279    
2024-04-05 16:21:41,943 - Epoch: [236][  200/  500]    Overall Loss 0.575951    Objective Loss 0.575951                                        LR 0.000125    Time 0.043393    
2024-04-05 16:21:44,947 - Epoch: [236][  300/  500]    Overall Loss 0.577978    Objective Loss 0.577978                                        LR 0.000125    Time 0.038935    
2024-04-05 16:21:47,953 - Epoch: [236][  400/  500]    Overall Loss 0.581388    Objective Loss 0.581388                                        LR 0.000125    Time 0.036709    
2024-04-05 16:21:50,308 - Epoch: [236][  500/  500]    Overall Loss 0.579504    Objective Loss 0.579504    Top1 87.500000    Top5 98.500000    LR 0.000125    Time 0.034073    
2024-04-05 16:21:50,535 - --- validate (epoch=236)-----------
2024-04-05 16:21:50,536 - 10000 samples (100 per mini-batch)
2024-04-05 16:21:52,199 - Epoch: [236][  100/  100]    Loss 1.288682    Top1 63.840000    Top5 89.020000    
2024-04-05 16:21:52,369 - ==> Top1: 63.840    Top5: 89.020    Loss: 1.289

2024-04-05 16:21:52,373 - ==> Best [Top1: 64.550   Top5: 89.110   Sparsity:0.00   Params: 347840 on epoch: 229]
2024-04-05 16:21:52,374 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:21:52,403 - 

2024-04-05 16:21:52,404 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:21:57,262 - Epoch: [237][  100/  500]    Overall Loss 0.558422    Objective Loss 0.558422                                        LR 0.000125    Time 0.048544    
2024-04-05 16:22:01,551 - Epoch: [237][  200/  500]    Overall Loss 0.564926    Objective Loss 0.564926                                        LR 0.000125    Time 0.045696    
2024-04-05 16:22:05,777 - Epoch: [237][  300/  500]    Overall Loss 0.570062    Objective Loss 0.570062                                        LR 0.000125    Time 0.044538    
2024-04-05 16:22:10,108 - Epoch: [237][  400/  500]    Overall Loss 0.575872    Objective Loss 0.575872                                        LR 0.000125    Time 0.044224    
2024-04-05 16:22:13,180 - Epoch: [237][  500/  500]    Overall Loss 0.578264    Objective Loss 0.578264    Top1 79.000000    Top5 96.500000    LR 0.000125    Time 0.041516    
2024-04-05 16:22:13,408 - --- validate (epoch=237)-----------
2024-04-05 16:22:13,409 - 10000 samples (100 per mini-batch)
2024-04-05 16:22:15,820 - Epoch: [237][  100/  100]    Loss 1.305992    Top1 63.660000    Top5 88.900000    
2024-04-05 16:22:15,976 - ==> Top1: 63.660    Top5: 88.900    Loss: 1.306

2024-04-05 16:22:15,982 - ==> Best [Top1: 64.550   Top5: 89.110   Sparsity:0.00   Params: 347840 on epoch: 229]
2024-04-05 16:22:15,982 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:22:16,014 - 

2024-04-05 16:22:16,015 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:22:21,161 - Epoch: [238][  100/  500]    Overall Loss 0.558573    Objective Loss 0.558573                                        LR 0.000125    Time 0.051425    
2024-04-05 16:22:25,512 - Epoch: [238][  200/  500]    Overall Loss 0.563432    Objective Loss 0.563432                                        LR 0.000125    Time 0.047449    
2024-04-05 16:22:29,725 - Epoch: [238][  300/  500]    Overall Loss 0.568993    Objective Loss 0.568993                                        LR 0.000125    Time 0.045664    
2024-04-05 16:22:33,876 - Epoch: [238][  400/  500]    Overall Loss 0.573667    Objective Loss 0.573667                                        LR 0.000125    Time 0.044618    
2024-04-05 16:22:38,058 - Epoch: [238][  500/  500]    Overall Loss 0.577348    Objective Loss 0.577348    Top1 84.500000    Top5 99.000000    LR 0.000125    Time 0.044050    
2024-04-05 16:22:38,279 - --- validate (epoch=238)-----------
2024-04-05 16:22:38,280 - 10000 samples (100 per mini-batch)
2024-04-05 16:22:40,733 - Epoch: [238][  100/  100]    Loss 1.308496    Top1 63.530000    Top5 88.550000    
2024-04-05 16:22:40,948 - ==> Top1: 63.530    Top5: 88.550    Loss: 1.308

2024-04-05 16:22:40,954 - ==> Best [Top1: 64.550   Top5: 89.110   Sparsity:0.00   Params: 347840 on epoch: 229]
2024-04-05 16:22:40,954 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:22:40,985 - 

2024-04-05 16:22:40,985 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:22:45,926 - Epoch: [239][  100/  500]    Overall Loss 0.568190    Objective Loss 0.568190                                        LR 0.000125    Time 0.049372    
2024-04-05 16:22:50,142 - Epoch: [239][  200/  500]    Overall Loss 0.565883    Objective Loss 0.565883                                        LR 0.000125    Time 0.045746    
2024-04-05 16:22:54,426 - Epoch: [239][  300/  500]    Overall Loss 0.566394    Objective Loss 0.566394                                        LR 0.000125    Time 0.044766    
2024-04-05 16:22:58,587 - Epoch: [239][  400/  500]    Overall Loss 0.569279    Objective Loss 0.569279                                        LR 0.000125    Time 0.043970    
2024-04-05 16:23:02,764 - Epoch: [239][  500/  500]    Overall Loss 0.572010    Objective Loss 0.572010    Top1 80.000000    Top5 98.500000    LR 0.000125    Time 0.043522    
2024-04-05 16:23:02,975 - --- validate (epoch=239)-----------
2024-04-05 16:23:02,976 - 10000 samples (100 per mini-batch)
2024-04-05 16:23:05,381 - Epoch: [239][  100/  100]    Loss 1.294350    Top1 63.960000    Top5 89.080000    
2024-04-05 16:23:05,534 - ==> Top1: 63.960    Top5: 89.080    Loss: 1.294

2024-04-05 16:23:05,541 - ==> Best [Top1: 64.550   Top5: 89.110   Sparsity:0.00   Params: 347840 on epoch: 229]
2024-04-05 16:23:05,542 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:23:05,572 - 

2024-04-05 16:23:05,572 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:23:10,477 - Epoch: [240][  100/  500]    Overall Loss 0.545600    Objective Loss 0.545600                                        LR 0.000125    Time 0.049004    
2024-04-05 16:23:14,878 - Epoch: [240][  200/  500]    Overall Loss 0.556391    Objective Loss 0.556391                                        LR 0.000125    Time 0.046490    
2024-04-05 16:23:19,118 - Epoch: [240][  300/  500]    Overall Loss 0.561764    Objective Loss 0.561764                                        LR 0.000125    Time 0.045114    
2024-04-05 16:23:23,279 - Epoch: [240][  400/  500]    Overall Loss 0.565182    Objective Loss 0.565182                                        LR 0.000125    Time 0.044230    
2024-04-05 16:23:27,463 - Epoch: [240][  500/  500]    Overall Loss 0.564511    Objective Loss 0.564511    Top1 87.000000    Top5 99.000000    LR 0.000125    Time 0.043746    
2024-04-05 16:23:27,696 - --- validate (epoch=240)-----------
2024-04-05 16:23:27,696 - 10000 samples (100 per mini-batch)
2024-04-05 16:23:30,308 - Epoch: [240][  100/  100]    Loss 1.297493    Top1 63.990000    Top5 89.090000    
2024-04-05 16:23:30,558 - ==> Top1: 63.990    Top5: 89.090    Loss: 1.297

2024-04-05 16:23:30,564 - ==> Best [Top1: 64.550   Top5: 89.110   Sparsity:0.00   Params: 347840 on epoch: 229]
2024-04-05 16:23:30,564 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:23:30,592 - 

2024-04-05 16:23:30,593 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:23:35,630 - Epoch: [241][  100/  500]    Overall Loss 0.563361    Objective Loss 0.563361                                        LR 0.000125    Time 0.050335    
2024-04-05 16:23:39,768 - Epoch: [241][  200/  500]    Overall Loss 0.564749    Objective Loss 0.564749                                        LR 0.000125    Time 0.045839    
2024-04-05 16:23:44,043 - Epoch: [241][  300/  500]    Overall Loss 0.569193    Objective Loss 0.569193                                        LR 0.000125    Time 0.044798    
2024-04-05 16:23:48,206 - Epoch: [241][  400/  500]    Overall Loss 0.569570    Objective Loss 0.569570                                        LR 0.000125    Time 0.043996    
2024-04-05 16:23:52,585 - Epoch: [241][  500/  500]    Overall Loss 0.567394    Objective Loss 0.567394    Top1 80.500000    Top5 98.000000    LR 0.000125    Time 0.043948    
2024-04-05 16:23:52,887 - --- validate (epoch=241)-----------
2024-04-05 16:23:52,887 - 10000 samples (100 per mini-batch)
2024-04-05 16:23:55,379 - Epoch: [241][  100/  100]    Loss 1.279479    Top1 64.690000    Top5 89.180000    
2024-04-05 16:23:55,645 - ==> Top1: 64.690    Top5: 89.180    Loss: 1.279

2024-04-05 16:23:55,649 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:23:55,649 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:23:55,678 - 

2024-04-05 16:23:55,678 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:24:01,036 - Epoch: [242][  100/  500]    Overall Loss 0.557034    Objective Loss 0.557034                                        LR 0.000125    Time 0.053539    
2024-04-05 16:24:05,540 - Epoch: [242][  200/  500]    Overall Loss 0.562466    Objective Loss 0.562466                                        LR 0.000125    Time 0.049267    
2024-04-05 16:24:10,057 - Epoch: [242][  300/  500]    Overall Loss 0.556713    Objective Loss 0.556713                                        LR 0.000125    Time 0.047888    
2024-04-05 16:24:13,910 - Epoch: [242][  400/  500]    Overall Loss 0.562266    Objective Loss 0.562266                                        LR 0.000125    Time 0.045538    
2024-04-05 16:24:18,350 - Epoch: [242][  500/  500]    Overall Loss 0.564342    Objective Loss 0.564342    Top1 85.000000    Top5 98.000000    LR 0.000125    Time 0.045304    
2024-04-05 16:24:18,611 - --- validate (epoch=242)-----------
2024-04-05 16:24:18,612 - 10000 samples (100 per mini-batch)
2024-04-05 16:24:21,074 - Epoch: [242][  100/  100]    Loss 1.303700    Top1 63.980000    Top5 88.740000    
2024-04-05 16:24:21,241 - ==> Top1: 63.980    Top5: 88.740    Loss: 1.304

2024-04-05 16:24:21,246 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:24:21,247 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:24:21,279 - 

2024-04-05 16:24:21,280 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:24:26,272 - Epoch: [243][  100/  500]    Overall Loss 0.553848    Objective Loss 0.553848                                        LR 0.000125    Time 0.049876    
2024-04-05 16:24:30,496 - Epoch: [243][  200/  500]    Overall Loss 0.554504    Objective Loss 0.554504                                        LR 0.000125    Time 0.046037    
2024-04-05 16:24:34,820 - Epoch: [243][  300/  500]    Overall Loss 0.559483    Objective Loss 0.559483                                        LR 0.000125    Time 0.045093    
2024-04-05 16:24:39,043 - Epoch: [243][  400/  500]    Overall Loss 0.563797    Objective Loss 0.563797                                        LR 0.000125    Time 0.044369    
2024-04-05 16:24:43,236 - Epoch: [243][  500/  500]    Overall Loss 0.565544    Objective Loss 0.565544    Top1 82.000000    Top5 98.000000    LR 0.000125    Time 0.043874    
2024-04-05 16:24:43,407 - --- validate (epoch=243)-----------
2024-04-05 16:24:43,408 - 10000 samples (100 per mini-batch)
2024-04-05 16:24:45,765 - Epoch: [243][  100/  100]    Loss 1.309128    Top1 63.820000    Top5 88.740000    
2024-04-05 16:24:45,912 - ==> Top1: 63.820    Top5: 88.740    Loss: 1.309

2024-04-05 16:24:45,915 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:24:45,916 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:24:45,934 - 

2024-04-05 16:24:45,935 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:24:51,234 - Epoch: [244][  100/  500]    Overall Loss 0.547003    Objective Loss 0.547003                                        LR 0.000125    Time 0.052949    
2024-04-05 16:24:55,453 - Epoch: [244][  200/  500]    Overall Loss 0.549410    Objective Loss 0.549410                                        LR 0.000125    Time 0.047554    
2024-04-05 16:24:59,477 - Epoch: [244][  300/  500]    Overall Loss 0.552651    Objective Loss 0.552651                                        LR 0.000125    Time 0.045105    
2024-04-05 16:25:03,712 - Epoch: [244][  400/  500]    Overall Loss 0.554723    Objective Loss 0.554723                                        LR 0.000125    Time 0.044407    
2024-04-05 16:25:07,980 - Epoch: [244][  500/  500]    Overall Loss 0.557198    Objective Loss 0.557198    Top1 83.500000    Top5 99.500000    LR 0.000125    Time 0.044055    
2024-04-05 16:25:08,205 - --- validate (epoch=244)-----------
2024-04-05 16:25:08,206 - 10000 samples (100 per mini-batch)
2024-04-05 16:25:10,588 - Epoch: [244][  100/  100]    Loss 1.311241    Top1 63.850000    Top5 88.760000    
2024-04-05 16:25:10,772 - ==> Top1: 63.850    Top5: 88.760    Loss: 1.311

2024-04-05 16:25:10,782 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:25:10,782 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:25:10,811 - 

2024-04-05 16:25:10,811 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:25:15,435 - Epoch: [245][  100/  500]    Overall Loss 0.535769    Objective Loss 0.535769                                        LR 0.000125    Time 0.046199    
2024-04-05 16:25:19,466 - Epoch: [245][  200/  500]    Overall Loss 0.547447    Objective Loss 0.547447                                        LR 0.000125    Time 0.043238    
2024-04-05 16:25:23,421 - Epoch: [245][  300/  500]    Overall Loss 0.548659    Objective Loss 0.548659                                        LR 0.000125    Time 0.041998    
2024-04-05 16:25:27,604 - Epoch: [245][  400/  500]    Overall Loss 0.553223    Objective Loss 0.553223                                        LR 0.000125    Time 0.041949    
2024-04-05 16:25:31,855 - Epoch: [245][  500/  500]    Overall Loss 0.554386    Objective Loss 0.554386    Top1 86.500000    Top5 99.500000    LR 0.000125    Time 0.042053    
2024-04-05 16:25:32,118 - --- validate (epoch=245)-----------
2024-04-05 16:25:32,118 - 10000 samples (100 per mini-batch)
2024-04-05 16:25:34,498 - Epoch: [245][  100/  100]    Loss 1.331475    Top1 63.070000    Top5 88.350000    
2024-04-05 16:25:34,742 - ==> Top1: 63.070    Top5: 88.350    Loss: 1.331

2024-04-05 16:25:34,747 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:25:34,747 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:25:34,778 - 

2024-04-05 16:25:34,778 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:25:39,476 - Epoch: [246][  100/  500]    Overall Loss 0.549542    Objective Loss 0.549542                                        LR 0.000125    Time 0.046943    
2024-04-05 16:25:43,592 - Epoch: [246][  200/  500]    Overall Loss 0.555247    Objective Loss 0.555247                                        LR 0.000125    Time 0.044035    
2024-04-05 16:25:47,621 - Epoch: [246][  300/  500]    Overall Loss 0.552121    Objective Loss 0.552121                                        LR 0.000125    Time 0.042773    
2024-04-05 16:25:51,868 - Epoch: [246][  400/  500]    Overall Loss 0.551868    Objective Loss 0.551868                                        LR 0.000125    Time 0.042688    
2024-04-05 16:25:55,928 - Epoch: [246][  500/  500]    Overall Loss 0.554834    Objective Loss 0.554834    Top1 81.000000    Top5 98.500000    LR 0.000125    Time 0.042266    
2024-04-05 16:25:56,162 - --- validate (epoch=246)-----------
2024-04-05 16:25:56,162 - 10000 samples (100 per mini-batch)
2024-04-05 16:25:58,677 - Epoch: [246][  100/  100]    Loss 1.328788    Top1 63.600000    Top5 88.390000    
2024-04-05 16:25:58,873 - ==> Top1: 63.600    Top5: 88.390    Loss: 1.329

2024-04-05 16:25:58,877 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:25:58,878 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:25:58,907 - 

2024-04-05 16:25:58,908 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:26:03,861 - Epoch: [247][  100/  500]    Overall Loss 0.529094    Objective Loss 0.529094                                        LR 0.000125    Time 0.049491    
2024-04-05 16:26:08,116 - Epoch: [247][  200/  500]    Overall Loss 0.536572    Objective Loss 0.536572                                        LR 0.000125    Time 0.046002    
2024-04-05 16:26:12,020 - Epoch: [247][  300/  500]    Overall Loss 0.541760    Objective Loss 0.541760                                        LR 0.000125    Time 0.043672    
2024-04-05 16:26:16,225 - Epoch: [247][  400/  500]    Overall Loss 0.546638    Objective Loss 0.546638                                        LR 0.000125    Time 0.043259    
2024-04-05 16:26:20,388 - Epoch: [247][  500/  500]    Overall Loss 0.553037    Objective Loss 0.553037    Top1 82.500000    Top5 98.500000    LR 0.000125    Time 0.042927    
2024-04-05 16:26:20,696 - --- validate (epoch=247)-----------
2024-04-05 16:26:20,696 - 10000 samples (100 per mini-batch)
2024-04-05 16:26:23,108 - Epoch: [247][  100/  100]    Loss 1.334205    Top1 63.760000    Top5 88.250000    
2024-04-05 16:26:23,298 - ==> Top1: 63.760    Top5: 88.250    Loss: 1.334

2024-04-05 16:26:23,303 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:26:23,303 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:26:23,335 - 

2024-04-05 16:26:23,335 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:26:28,538 - Epoch: [248][  100/  500]    Overall Loss 0.524612    Objective Loss 0.524612                                        LR 0.000125    Time 0.051992    
2024-04-05 16:26:32,828 - Epoch: [248][  200/  500]    Overall Loss 0.535239    Objective Loss 0.535239                                        LR 0.000125    Time 0.047428    
2024-04-05 16:26:36,957 - Epoch: [248][  300/  500]    Overall Loss 0.542093    Objective Loss 0.542093                                        LR 0.000125    Time 0.045368    
2024-04-05 16:26:41,098 - Epoch: [248][  400/  500]    Overall Loss 0.546374    Objective Loss 0.546374                                        LR 0.000125    Time 0.044371    
2024-04-05 16:26:45,278 - Epoch: [248][  500/  500]    Overall Loss 0.549449    Objective Loss 0.549449    Top1 86.000000    Top5 99.000000    LR 0.000125    Time 0.043852    
2024-04-05 16:26:45,465 - --- validate (epoch=248)-----------
2024-04-05 16:26:45,466 - 10000 samples (100 per mini-batch)
2024-04-05 16:26:47,886 - Epoch: [248][  100/  100]    Loss 1.315490    Top1 63.630000    Top5 88.510000    
2024-04-05 16:26:48,056 - ==> Top1: 63.630    Top5: 88.510    Loss: 1.315

2024-04-05 16:26:48,061 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:26:48,062 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:26:48,092 - 

2024-04-05 16:26:48,092 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:26:52,990 - Epoch: [249][  100/  500]    Overall Loss 0.533360    Objective Loss 0.533360                                        LR 0.000125    Time 0.048927    
2024-04-05 16:26:57,311 - Epoch: [249][  200/  500]    Overall Loss 0.539375    Objective Loss 0.539375                                        LR 0.000125    Time 0.046052    
2024-04-05 16:27:01,223 - Epoch: [249][  300/  500]    Overall Loss 0.546678    Objective Loss 0.546678                                        LR 0.000125    Time 0.043728    
2024-04-05 16:27:05,416 - Epoch: [249][  400/  500]    Overall Loss 0.548607    Objective Loss 0.548607                                        LR 0.000125    Time 0.043271    
2024-04-05 16:27:09,677 - Epoch: [249][  500/  500]    Overall Loss 0.549114    Objective Loss 0.549114    Top1 87.000000    Top5 97.500000    LR 0.000125    Time 0.043133    
2024-04-05 16:27:09,909 - --- validate (epoch=249)-----------
2024-04-05 16:27:09,909 - 10000 samples (100 per mini-batch)
2024-04-05 16:27:12,285 - Epoch: [249][  100/  100]    Loss 1.317451    Top1 63.610000    Top5 88.870000    
2024-04-05 16:27:12,473 - ==> Top1: 63.610    Top5: 88.870    Loss: 1.317

2024-04-05 16:27:12,479 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:27:12,480 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:27:12,510 - 

2024-04-05 16:27:12,510 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:27:17,383 - Epoch: [250][  100/  500]    Overall Loss 0.525883    Objective Loss 0.525883                                        LR 0.000125    Time 0.048687    
2024-04-05 16:27:21,616 - Epoch: [250][  200/  500]    Overall Loss 0.532019    Objective Loss 0.532019                                        LR 0.000125    Time 0.045496    
2024-04-05 16:27:25,776 - Epoch: [250][  300/  500]    Overall Loss 0.533435    Objective Loss 0.533435                                        LR 0.000125    Time 0.044186    
2024-04-05 16:27:29,957 - Epoch: [250][  400/  500]    Overall Loss 0.538422    Objective Loss 0.538422                                        LR 0.000125    Time 0.043582    
2024-04-05 16:27:34,206 - Epoch: [250][  500/  500]    Overall Loss 0.539100    Objective Loss 0.539100    Top1 79.000000    Top5 97.500000    LR 0.000125    Time 0.043356    
2024-04-05 16:27:34,403 - --- validate (epoch=250)-----------
2024-04-05 16:27:34,404 - 10000 samples (100 per mini-batch)
2024-04-05 16:27:36,762 - Epoch: [250][  100/  100]    Loss 1.310481    Top1 63.940000    Top5 89.030000    
2024-04-05 16:27:36,904 - ==> Top1: 63.940    Top5: 89.030    Loss: 1.310

2024-04-05 16:27:36,911 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:27:36,911 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:27:36,941 - 

2024-04-05 16:27:36,942 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:27:41,800 - Epoch: [251][  100/  500]    Overall Loss 0.535510    Objective Loss 0.535510                                        LR 0.000125    Time 0.048542    
2024-04-05 16:27:46,038 - Epoch: [251][  200/  500]    Overall Loss 0.538132    Objective Loss 0.538132                                        LR 0.000125    Time 0.045447    
2024-04-05 16:27:50,141 - Epoch: [251][  300/  500]    Overall Loss 0.540526    Objective Loss 0.540526                                        LR 0.000125    Time 0.043964    
2024-04-05 16:27:54,355 - Epoch: [251][  400/  500]    Overall Loss 0.541423    Objective Loss 0.541423                                        LR 0.000125    Time 0.043499    
2024-04-05 16:27:58,610 - Epoch: [251][  500/  500]    Overall Loss 0.542738    Objective Loss 0.542738    Top1 86.500000    Top5 100.000000    LR 0.000125    Time 0.043302    
2024-04-05 16:27:58,833 - --- validate (epoch=251)-----------
2024-04-05 16:27:58,834 - 10000 samples (100 per mini-batch)
2024-04-05 16:28:01,273 - Epoch: [251][  100/  100]    Loss 1.305321    Top1 64.120000    Top5 89.020000    
2024-04-05 16:28:01,546 - ==> Top1: 64.120    Top5: 89.020    Loss: 1.305

2024-04-05 16:28:01,552 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:28:01,552 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:28:01,583 - 

2024-04-05 16:28:01,584 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:28:06,484 - Epoch: [252][  100/  500]    Overall Loss 0.525982    Objective Loss 0.525982                                        LR 0.000125    Time 0.048960    
2024-04-05 16:28:10,779 - Epoch: [252][  200/  500]    Overall Loss 0.526278    Objective Loss 0.526278                                        LR 0.000125    Time 0.045939    
2024-04-05 16:28:14,716 - Epoch: [252][  300/  500]    Overall Loss 0.533497    Objective Loss 0.533497                                        LR 0.000125    Time 0.043739    
2024-04-05 16:28:18,955 - Epoch: [252][  400/  500]    Overall Loss 0.537170    Objective Loss 0.537170                                        LR 0.000125    Time 0.043392    
2024-04-05 16:28:23,287 - Epoch: [252][  500/  500]    Overall Loss 0.538279    Objective Loss 0.538279    Top1 84.500000    Top5 99.000000    LR 0.000125    Time 0.043372    
2024-04-05 16:28:23,461 - --- validate (epoch=252)-----------
2024-04-05 16:28:23,461 - 10000 samples (100 per mini-batch)
2024-04-05 16:28:25,806 - Epoch: [252][  100/  100]    Loss 1.326508    Top1 63.920000    Top5 88.690000    
2024-04-05 16:28:25,969 - ==> Top1: 63.920    Top5: 88.690    Loss: 1.327

2024-04-05 16:28:25,975 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:28:25,976 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:28:26,007 - 

2024-04-05 16:28:26,007 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:28:31,152 - Epoch: [253][  100/  500]    Overall Loss 0.525517    Objective Loss 0.525517                                        LR 0.000125    Time 0.051407    
2024-04-05 16:28:35,288 - Epoch: [253][  200/  500]    Overall Loss 0.529145    Objective Loss 0.529145                                        LR 0.000125    Time 0.046367    
2024-04-05 16:28:39,461 - Epoch: [253][  300/  500]    Overall Loss 0.529474    Objective Loss 0.529474                                        LR 0.000125    Time 0.044810    
2024-04-05 16:28:43,664 - Epoch: [253][  400/  500]    Overall Loss 0.530955    Objective Loss 0.530955                                        LR 0.000125    Time 0.044106    
2024-04-05 16:28:47,876 - Epoch: [253][  500/  500]    Overall Loss 0.532098    Objective Loss 0.532098    Top1 83.500000    Top5 99.000000    LR 0.000125    Time 0.043703    
2024-04-05 16:28:48,150 - --- validate (epoch=253)-----------
2024-04-05 16:28:48,151 - 10000 samples (100 per mini-batch)
2024-04-05 16:28:50,570 - Epoch: [253][  100/  100]    Loss 1.329391    Top1 63.780000    Top5 88.270000    
2024-04-05 16:28:50,725 - ==> Top1: 63.780    Top5: 88.270    Loss: 1.329

2024-04-05 16:28:50,730 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:28:50,731 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:28:50,761 - 

2024-04-05 16:28:50,761 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:28:55,657 - Epoch: [254][  100/  500]    Overall Loss 0.540658    Objective Loss 0.540658                                        LR 0.000125    Time 0.048920    
2024-04-05 16:28:59,676 - Epoch: [254][  200/  500]    Overall Loss 0.546818    Objective Loss 0.546818                                        LR 0.000125    Time 0.044538    
2024-04-05 16:29:03,766 - Epoch: [254][  300/  500]    Overall Loss 0.543531    Objective Loss 0.543531                                        LR 0.000125    Time 0.043315    
2024-04-05 16:29:07,912 - Epoch: [254][  400/  500]    Overall Loss 0.543339    Objective Loss 0.543339                                        LR 0.000125    Time 0.042843    
2024-04-05 16:29:12,137 - Epoch: [254][  500/  500]    Overall Loss 0.543000    Objective Loss 0.543000    Top1 87.000000    Top5 99.000000    LR 0.000125    Time 0.042718    
2024-04-05 16:29:12,311 - --- validate (epoch=254)-----------
2024-04-05 16:29:12,312 - 10000 samples (100 per mini-batch)
2024-04-05 16:29:14,792 - Epoch: [254][  100/  100]    Loss 1.316946    Top1 63.940000    Top5 88.960000    
2024-04-05 16:29:14,931 - ==> Top1: 63.940    Top5: 88.960    Loss: 1.317

2024-04-05 16:29:14,937 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:29:14,938 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:29:14,968 - 

2024-04-05 16:29:14,969 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:29:19,933 - Epoch: [255][  100/  500]    Overall Loss 0.538470    Objective Loss 0.538470                                        LR 0.000125    Time 0.049604    
2024-04-05 16:29:23,927 - Epoch: [255][  200/  500]    Overall Loss 0.538126    Objective Loss 0.538126                                        LR 0.000125    Time 0.044756    
2024-04-05 16:29:28,023 - Epoch: [255][  300/  500]    Overall Loss 0.540685    Objective Loss 0.540685                                        LR 0.000125    Time 0.043480    
2024-04-05 16:29:32,283 - Epoch: [255][  400/  500]    Overall Loss 0.539753    Objective Loss 0.539753                                        LR 0.000125    Time 0.043252    
2024-04-05 16:29:36,472 - Epoch: [255][  500/  500]    Overall Loss 0.539929    Objective Loss 0.539929    Top1 86.000000    Top5 98.000000    LR 0.000125    Time 0.042973    
2024-04-05 16:29:36,781 - --- validate (epoch=255)-----------
2024-04-05 16:29:36,782 - 10000 samples (100 per mini-batch)
2024-04-05 16:29:39,101 - Epoch: [255][  100/  100]    Loss 1.306249    Top1 64.150000    Top5 88.990000    
2024-04-05 16:29:39,241 - ==> Top1: 64.150    Top5: 88.990    Loss: 1.306

2024-04-05 16:29:39,247 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:29:39,248 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:29:39,277 - 

2024-04-05 16:29:39,277 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:29:44,088 - Epoch: [256][  100/  500]    Overall Loss 0.509907    Objective Loss 0.509907                                        LR 0.000125    Time 0.048073    
2024-04-05 16:29:48,127 - Epoch: [256][  200/  500]    Overall Loss 0.522842    Objective Loss 0.522842                                        LR 0.000125    Time 0.044217    
2024-04-05 16:29:52,319 - Epoch: [256][  300/  500]    Overall Loss 0.528782    Objective Loss 0.528782                                        LR 0.000125    Time 0.043438    
2024-04-05 16:29:56,561 - Epoch: [256][  400/  500]    Overall Loss 0.532282    Objective Loss 0.532282                                        LR 0.000125    Time 0.043176    
2024-04-05 16:30:00,748 - Epoch: [256][  500/  500]    Overall Loss 0.534741    Objective Loss 0.534741    Top1 83.000000    Top5 97.500000    LR 0.000125    Time 0.042908    
2024-04-05 16:30:00,927 - --- validate (epoch=256)-----------
2024-04-05 16:30:00,928 - 10000 samples (100 per mini-batch)
2024-04-05 16:30:03,277 - Epoch: [256][  100/  100]    Loss 1.310275    Top1 64.370000    Top5 88.640000    
2024-04-05 16:30:03,441 - ==> Top1: 64.370    Top5: 88.640    Loss: 1.310

2024-04-05 16:30:03,446 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:30:03,446 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:30:03,476 - 

2024-04-05 16:30:03,476 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:30:08,523 - Epoch: [257][  100/  500]    Overall Loss 0.516342    Objective Loss 0.516342                                        LR 0.000125    Time 0.050429    
2024-04-05 16:30:12,641 - Epoch: [257][  200/  500]    Overall Loss 0.518505    Objective Loss 0.518505                                        LR 0.000125    Time 0.045782    
2024-04-05 16:30:16,808 - Epoch: [257][  300/  500]    Overall Loss 0.524420    Objective Loss 0.524420                                        LR 0.000125    Time 0.044403    
2024-04-05 16:30:21,032 - Epoch: [257][  400/  500]    Overall Loss 0.528294    Objective Loss 0.528294                                        LR 0.000125    Time 0.043852    
2024-04-05 16:30:25,292 - Epoch: [257][  500/  500]    Overall Loss 0.533429    Objective Loss 0.533429    Top1 89.500000    Top5 98.000000    LR 0.000125    Time 0.043596    
2024-04-05 16:30:25,479 - --- validate (epoch=257)-----------
2024-04-05 16:30:25,480 - 10000 samples (100 per mini-batch)
2024-04-05 16:30:27,790 - Epoch: [257][  100/  100]    Loss 1.310268    Top1 64.120000    Top5 88.710000    
2024-04-05 16:30:27,955 - ==> Top1: 64.120    Top5: 88.710    Loss: 1.310

2024-04-05 16:30:27,962 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:30:27,962 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:30:27,991 - 

2024-04-05 16:30:27,991 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:30:32,820 - Epoch: [258][  100/  500]    Overall Loss 0.507812    Objective Loss 0.507812                                        LR 0.000125    Time 0.048251    
2024-04-05 16:30:36,922 - Epoch: [258][  200/  500]    Overall Loss 0.515423    Objective Loss 0.515423                                        LR 0.000125    Time 0.044616    
2024-04-05 16:30:41,117 - Epoch: [258][  300/  500]    Overall Loss 0.519410    Objective Loss 0.519410                                        LR 0.000125    Time 0.043718    
2024-04-05 16:30:45,322 - Epoch: [258][  400/  500]    Overall Loss 0.522198    Objective Loss 0.522198                                        LR 0.000125    Time 0.043291    
2024-04-05 16:30:49,529 - Epoch: [258][  500/  500]    Overall Loss 0.525858    Objective Loss 0.525858    Top1 83.500000    Top5 100.000000    LR 0.000125    Time 0.043039    
2024-04-05 16:30:49,735 - --- validate (epoch=258)-----------
2024-04-05 16:30:49,736 - 10000 samples (100 per mini-batch)
2024-04-05 16:30:52,174 - Epoch: [258][  100/  100]    Loss 1.318343    Top1 64.210000    Top5 88.420000    
2024-04-05 16:30:52,373 - ==> Top1: 64.210    Top5: 88.420    Loss: 1.318

2024-04-05 16:30:52,379 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:30:52,379 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:30:52,409 - 

2024-04-05 16:30:52,409 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:30:57,351 - Epoch: [259][  100/  500]    Overall Loss 0.517071    Objective Loss 0.517071                                        LR 0.000125    Time 0.049384    
2024-04-05 16:31:01,602 - Epoch: [259][  200/  500]    Overall Loss 0.529114    Objective Loss 0.529114                                        LR 0.000125    Time 0.045929    
2024-04-05 16:31:05,842 - Epoch: [259][  300/  500]    Overall Loss 0.528251    Objective Loss 0.528251                                        LR 0.000125    Time 0.044741    
2024-04-05 16:31:10,078 - Epoch: [259][  400/  500]    Overall Loss 0.527665    Objective Loss 0.527665                                        LR 0.000125    Time 0.044137    
2024-04-05 16:31:14,329 - Epoch: [259][  500/  500]    Overall Loss 0.530285    Objective Loss 0.530285    Top1 83.000000    Top5 98.500000    LR 0.000125    Time 0.043805    
2024-04-05 16:31:14,586 - --- validate (epoch=259)-----------
2024-04-05 16:31:14,587 - 10000 samples (100 per mini-batch)
2024-04-05 16:31:16,970 - Epoch: [259][  100/  100]    Loss 1.339846    Top1 63.260000    Top5 88.590000    
2024-04-05 16:31:17,141 - ==> Top1: 63.260    Top5: 88.590    Loss: 1.340

2024-04-05 16:31:17,146 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:31:17,147 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:31:17,177 - 

2024-04-05 16:31:17,178 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:31:22,164 - Epoch: [260][  100/  500]    Overall Loss 0.525177    Objective Loss 0.525177                                        LR 0.000125    Time 0.049825    
2024-04-05 16:31:26,335 - Epoch: [260][  200/  500]    Overall Loss 0.529900    Objective Loss 0.529900                                        LR 0.000125    Time 0.045747    
2024-04-05 16:31:30,470 - Epoch: [260][  300/  500]    Overall Loss 0.528712    Objective Loss 0.528712                                        LR 0.000125    Time 0.044271    
2024-04-05 16:31:34,692 - Epoch: [260][  400/  500]    Overall Loss 0.532818    Objective Loss 0.532818                                        LR 0.000125    Time 0.043749    
2024-04-05 16:31:38,769 - Epoch: [260][  500/  500]    Overall Loss 0.532287    Objective Loss 0.532287    Top1 85.500000    Top5 99.000000    LR 0.000125    Time 0.043146    
2024-04-05 16:31:38,939 - --- validate (epoch=260)-----------
2024-04-05 16:31:38,940 - 10000 samples (100 per mini-batch)
2024-04-05 16:31:41,465 - Epoch: [260][  100/  100]    Loss 1.328554    Top1 64.040000    Top5 88.420000    
2024-04-05 16:31:41,697 - ==> Top1: 64.040    Top5: 88.420    Loss: 1.329

2024-04-05 16:31:41,702 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:31:41,702 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:31:41,734 - 

2024-04-05 16:31:41,735 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:31:46,597 - Epoch: [261][  100/  500]    Overall Loss 0.531332    Objective Loss 0.531332                                        LR 0.000125    Time 0.048582    
2024-04-05 16:31:50,757 - Epoch: [261][  200/  500]    Overall Loss 0.520639    Objective Loss 0.520639                                        LR 0.000125    Time 0.045077    
2024-04-05 16:31:54,929 - Epoch: [261][  300/  500]    Overall Loss 0.521435    Objective Loss 0.521435                                        LR 0.000125    Time 0.043946    
2024-04-05 16:31:59,139 - Epoch: [261][  400/  500]    Overall Loss 0.522222    Objective Loss 0.522222                                        LR 0.000125    Time 0.043475    
2024-04-05 16:32:03,349 - Epoch: [261][  500/  500]    Overall Loss 0.523410    Objective Loss 0.523410    Top1 80.500000    Top5 98.000000    LR 0.000125    Time 0.043194    
2024-04-05 16:32:03,536 - --- validate (epoch=261)-----------
2024-04-05 16:32:03,536 - 10000 samples (100 per mini-batch)
2024-04-05 16:32:05,934 - Epoch: [261][  100/  100]    Loss 1.327845    Top1 63.790000    Top5 88.560000    
2024-04-05 16:32:06,121 - ==> Top1: 63.790    Top5: 88.560    Loss: 1.328

2024-04-05 16:32:06,131 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:32:06,131 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:32:06,161 - 

2024-04-05 16:32:06,161 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:32:11,292 - Epoch: [262][  100/  500]    Overall Loss 0.515948    Objective Loss 0.515948                                        LR 0.000125    Time 0.051268    
2024-04-05 16:32:15,577 - Epoch: [262][  200/  500]    Overall Loss 0.515940    Objective Loss 0.515940                                        LR 0.000125    Time 0.047039    
2024-04-05 16:32:19,469 - Epoch: [262][  300/  500]    Overall Loss 0.518757    Objective Loss 0.518757                                        LR 0.000125    Time 0.044322    
2024-04-05 16:32:23,830 - Epoch: [262][  400/  500]    Overall Loss 0.520357    Objective Loss 0.520357                                        LR 0.000125    Time 0.044136    
2024-04-05 16:32:28,122 - Epoch: [262][  500/  500]    Overall Loss 0.522426    Objective Loss 0.522426    Top1 80.500000    Top5 98.500000    LR 0.000125    Time 0.043886    
2024-04-05 16:32:28,312 - --- validate (epoch=262)-----------
2024-04-05 16:32:28,313 - 10000 samples (100 per mini-batch)
2024-04-05 16:32:30,684 - Epoch: [262][  100/  100]    Loss 1.327873    Top1 64.120000    Top5 88.680000    
2024-04-05 16:32:30,823 - ==> Top1: 64.120    Top5: 88.680    Loss: 1.328

2024-04-05 16:32:30,829 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:32:30,829 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:32:30,859 - 

2024-04-05 16:32:30,860 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:32:35,864 - Epoch: [263][  100/  500]    Overall Loss 0.511486    Objective Loss 0.511486                                        LR 0.000125    Time 0.049994    
2024-04-05 16:32:40,043 - Epoch: [263][  200/  500]    Overall Loss 0.513881    Objective Loss 0.513881                                        LR 0.000125    Time 0.045871    
2024-04-05 16:32:44,307 - Epoch: [263][  300/  500]    Overall Loss 0.519648    Objective Loss 0.519648                                        LR 0.000125    Time 0.044784    
2024-04-05 16:32:48,440 - Epoch: [263][  400/  500]    Overall Loss 0.519551    Objective Loss 0.519551                                        LR 0.000125    Time 0.043912    
2024-04-05 16:32:52,637 - Epoch: [263][  500/  500]    Overall Loss 0.521216    Objective Loss 0.521216    Top1 84.000000    Top5 97.000000    LR 0.000125    Time 0.043517    
2024-04-05 16:32:52,919 - --- validate (epoch=263)-----------
2024-04-05 16:32:52,919 - 10000 samples (100 per mini-batch)
2024-04-05 16:32:55,288 - Epoch: [263][  100/  100]    Loss 1.311940    Top1 64.220000    Top5 88.790000    
2024-04-05 16:32:55,514 - ==> Top1: 64.220    Top5: 88.790    Loss: 1.312

2024-04-05 16:32:55,519 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:32:55,519 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:32:55,548 - 

2024-04-05 16:32:55,549 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:33:00,540 - Epoch: [264][  100/  500]    Overall Loss 0.518949    Objective Loss 0.518949                                        LR 0.000125    Time 0.049873    
2024-04-05 16:33:04,678 - Epoch: [264][  200/  500]    Overall Loss 0.514658    Objective Loss 0.514658                                        LR 0.000125    Time 0.045610    
2024-04-05 16:33:08,843 - Epoch: [264][  300/  500]    Overall Loss 0.518101    Objective Loss 0.518101                                        LR 0.000125    Time 0.044278    
2024-04-05 16:33:12,941 - Epoch: [264][  400/  500]    Overall Loss 0.521521    Objective Loss 0.521521                                        LR 0.000125    Time 0.043446    
2024-04-05 16:33:17,105 - Epoch: [264][  500/  500]    Overall Loss 0.523339    Objective Loss 0.523339    Top1 83.500000    Top5 98.500000    LR 0.000125    Time 0.043078    
2024-04-05 16:33:17,382 - --- validate (epoch=264)-----------
2024-04-05 16:33:17,383 - 10000 samples (100 per mini-batch)
2024-04-05 16:33:19,696 - Epoch: [264][  100/  100]    Loss 1.322717    Top1 64.050000    Top5 88.660000    
2024-04-05 16:33:19,850 - ==> Top1: 64.050    Top5: 88.660    Loss: 1.323

2024-04-05 16:33:19,858 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:33:19,858 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:33:19,888 - 

2024-04-05 16:33:19,888 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:33:25,114 - Epoch: [265][  100/  500]    Overall Loss 0.505916    Objective Loss 0.505916                                        LR 0.000125    Time 0.052215    
2024-04-05 16:33:29,296 - Epoch: [265][  200/  500]    Overall Loss 0.513411    Objective Loss 0.513411                                        LR 0.000125    Time 0.047004    
2024-04-05 16:33:33,443 - Epoch: [265][  300/  500]    Overall Loss 0.513150    Objective Loss 0.513150                                        LR 0.000125    Time 0.045146    
2024-04-05 16:33:37,597 - Epoch: [265][  400/  500]    Overall Loss 0.514727    Objective Loss 0.514727                                        LR 0.000125    Time 0.044236    
2024-04-05 16:33:41,826 - Epoch: [265][  500/  500]    Overall Loss 0.517447    Objective Loss 0.517447    Top1 84.000000    Top5 99.000000    LR 0.000125    Time 0.043841    
2024-04-05 16:33:42,079 - --- validate (epoch=265)-----------
2024-04-05 16:33:42,080 - 10000 samples (100 per mini-batch)
2024-04-05 16:33:44,479 - Epoch: [265][  100/  100]    Loss 1.316981    Top1 64.100000    Top5 88.670000    
2024-04-05 16:33:44,704 - ==> Top1: 64.100    Top5: 88.670    Loss: 1.317

2024-04-05 16:33:44,709 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:33:44,710 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:33:44,740 - 

2024-04-05 16:33:44,740 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:33:49,478 - Epoch: [266][  100/  500]    Overall Loss 0.498564    Objective Loss 0.498564                                        LR 0.000125    Time 0.047338    
2024-04-05 16:33:53,637 - Epoch: [266][  200/  500]    Overall Loss 0.497360    Objective Loss 0.497360                                        LR 0.000125    Time 0.044445    
2024-04-05 16:33:57,720 - Epoch: [266][  300/  500]    Overall Loss 0.503093    Objective Loss 0.503093                                        LR 0.000125    Time 0.043229    
2024-04-05 16:34:01,808 - Epoch: [266][  400/  500]    Overall Loss 0.513306    Objective Loss 0.513306                                        LR 0.000125    Time 0.042633    
2024-04-05 16:34:05,998 - Epoch: [266][  500/  500]    Overall Loss 0.518364    Objective Loss 0.518364    Top1 81.000000    Top5 97.000000    LR 0.000125    Time 0.042479    
2024-04-05 16:34:06,192 - --- validate (epoch=266)-----------
2024-04-05 16:34:06,193 - 10000 samples (100 per mini-batch)
2024-04-05 16:34:08,568 - Epoch: [266][  100/  100]    Loss 1.326167    Top1 64.420000    Top5 88.910000    
2024-04-05 16:34:08,777 - ==> Top1: 64.420    Top5: 88.910    Loss: 1.326

2024-04-05 16:34:08,782 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:34:08,783 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:34:08,813 - 

2024-04-05 16:34:08,814 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:34:13,970 - Epoch: [267][  100/  500]    Overall Loss 0.502516    Objective Loss 0.502516                                        LR 0.000125    Time 0.051511    
2024-04-05 16:34:18,097 - Epoch: [267][  200/  500]    Overall Loss 0.506605    Objective Loss 0.506605                                        LR 0.000125    Time 0.046377    
2024-04-05 16:34:22,334 - Epoch: [267][  300/  500]    Overall Loss 0.512071    Objective Loss 0.512071                                        LR 0.000125    Time 0.045031    
2024-04-05 16:34:26,461 - Epoch: [267][  400/  500]    Overall Loss 0.514568    Objective Loss 0.514568                                        LR 0.000125    Time 0.044080    
2024-04-05 16:34:30,683 - Epoch: [267][  500/  500]    Overall Loss 0.516604    Objective Loss 0.516604    Top1 81.500000    Top5 99.500000    LR 0.000125    Time 0.043703    
2024-04-05 16:34:30,943 - --- validate (epoch=267)-----------
2024-04-05 16:34:30,944 - 10000 samples (100 per mini-batch)
2024-04-05 16:34:33,283 - Epoch: [267][  100/  100]    Loss 1.330015    Top1 63.580000    Top5 88.800000    
2024-04-05 16:34:33,443 - ==> Top1: 63.580    Top5: 88.800    Loss: 1.330

2024-04-05 16:34:33,449 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:34:33,449 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:34:33,480 - 

2024-04-05 16:34:33,480 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:34:38,502 - Epoch: [268][  100/  500]    Overall Loss 0.507960    Objective Loss 0.507960                                        LR 0.000125    Time 0.050178    
2024-04-05 16:34:42,652 - Epoch: [268][  200/  500]    Overall Loss 0.506972    Objective Loss 0.506972                                        LR 0.000125    Time 0.045822    
2024-04-05 16:34:46,868 - Epoch: [268][  300/  500]    Overall Loss 0.510099    Objective Loss 0.510099                                        LR 0.000125    Time 0.044591    
2024-04-05 16:34:50,818 - Epoch: [268][  400/  500]    Overall Loss 0.509230    Objective Loss 0.509230                                        LR 0.000125    Time 0.043312    
2024-04-05 16:34:55,038 - Epoch: [268][  500/  500]    Overall Loss 0.509786    Objective Loss 0.509786    Top1 87.000000    Top5 99.000000    LR 0.000125    Time 0.043083    
2024-04-05 16:34:55,326 - --- validate (epoch=268)-----------
2024-04-05 16:34:55,327 - 10000 samples (100 per mini-batch)
2024-04-05 16:34:57,694 - Epoch: [268][  100/  100]    Loss 1.329850    Top1 64.000000    Top5 88.730000    
2024-04-05 16:34:57,814 - ==> Top1: 64.000    Top5: 88.730    Loss: 1.330

2024-04-05 16:34:57,819 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:34:57,819 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:34:57,838 - 

2024-04-05 16:34:57,838 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:35:02,626 - Epoch: [269][  100/  500]    Overall Loss 0.508736    Objective Loss 0.508736                                        LR 0.000125    Time 0.047843    
2024-04-05 16:35:06,828 - Epoch: [269][  200/  500]    Overall Loss 0.510007    Objective Loss 0.510007                                        LR 0.000125    Time 0.044912    
2024-04-05 16:35:10,980 - Epoch: [269][  300/  500]    Overall Loss 0.514198    Objective Loss 0.514198                                        LR 0.000125    Time 0.043769    
2024-04-05 16:35:15,028 - Epoch: [269][  400/  500]    Overall Loss 0.513831    Objective Loss 0.513831                                        LR 0.000125    Time 0.042939    
2024-04-05 16:35:18,431 - Epoch: [269][  500/  500]    Overall Loss 0.516981    Objective Loss 0.516981    Top1 81.500000    Top5 98.000000    LR 0.000125    Time 0.041151    
2024-04-05 16:35:18,673 - --- validate (epoch=269)-----------
2024-04-05 16:35:18,674 - 10000 samples (100 per mini-batch)
2024-04-05 16:35:21,057 - Epoch: [269][  100/  100]    Loss 1.353800    Top1 63.530000    Top5 88.480000    
2024-04-05 16:35:21,216 - ==> Top1: 63.530    Top5: 88.480    Loss: 1.354

2024-04-05 16:35:21,222 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:35:21,222 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:35:21,251 - 

2024-04-05 16:35:21,252 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:35:26,170 - Epoch: [270][  100/  500]    Overall Loss 0.508539    Objective Loss 0.508539                                        LR 0.000125    Time 0.049141    
2024-04-05 16:35:30,349 - Epoch: [270][  200/  500]    Overall Loss 0.510999    Objective Loss 0.510999                                        LR 0.000125    Time 0.045449    
2024-04-05 16:35:34,647 - Epoch: [270][  300/  500]    Overall Loss 0.505794    Objective Loss 0.505794                                        LR 0.000125    Time 0.044612    
2024-04-05 16:35:38,829 - Epoch: [270][  400/  500]    Overall Loss 0.510040    Objective Loss 0.510040                                        LR 0.000125    Time 0.043906    
2024-04-05 16:35:42,913 - Epoch: [270][  500/  500]    Overall Loss 0.510954    Objective Loss 0.510954    Top1 88.000000    Top5 100.000000    LR 0.000125    Time 0.043286    
2024-04-05 16:35:43,115 - --- validate (epoch=270)-----------
2024-04-05 16:35:43,115 - 10000 samples (100 per mini-batch)
2024-04-05 16:35:45,733 - Epoch: [270][  100/  100]    Loss 1.322427    Top1 63.700000    Top5 88.800000    
2024-04-05 16:35:45,922 - ==> Top1: 63.700    Top5: 88.800    Loss: 1.322

2024-04-05 16:35:45,928 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:35:45,928 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:35:45,958 - 

2024-04-05 16:35:45,958 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:35:50,985 - Epoch: [271][  100/  500]    Overall Loss 0.501300    Objective Loss 0.501300                                        LR 0.000125    Time 0.050230    
2024-04-05 16:35:55,304 - Epoch: [271][  200/  500]    Overall Loss 0.508176    Objective Loss 0.508176                                        LR 0.000125    Time 0.046689    
2024-04-05 16:35:59,536 - Epoch: [271][  300/  500]    Overall Loss 0.513553    Objective Loss 0.513553                                        LR 0.000125    Time 0.045220    
2024-04-05 16:36:03,721 - Epoch: [271][  400/  500]    Overall Loss 0.516748    Objective Loss 0.516748                                        LR 0.000125    Time 0.044370    
2024-04-05 16:36:07,733 - Epoch: [271][  500/  500]    Overall Loss 0.517030    Objective Loss 0.517030    Top1 85.500000    Top5 98.000000    LR 0.000125    Time 0.043512    
2024-04-05 16:36:07,932 - --- validate (epoch=271)-----------
2024-04-05 16:36:07,933 - 10000 samples (100 per mini-batch)
2024-04-05 16:36:10,396 - Epoch: [271][  100/  100]    Loss 1.337109    Top1 63.990000    Top5 88.850000    
2024-04-05 16:36:10,571 - ==> Top1: 63.990    Top5: 88.850    Loss: 1.337

2024-04-05 16:36:10,574 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:36:10,574 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:36:10,595 - 

2024-04-05 16:36:10,595 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:36:15,482 - Epoch: [272][  100/  500]    Overall Loss 0.506610    Objective Loss 0.506610                                        LR 0.000125    Time 0.048828    
2024-04-05 16:36:19,869 - Epoch: [272][  200/  500]    Overall Loss 0.500198    Objective Loss 0.500198                                        LR 0.000125    Time 0.046328    
2024-04-05 16:36:24,133 - Epoch: [272][  300/  500]    Overall Loss 0.500911    Objective Loss 0.500911                                        LR 0.000125    Time 0.045085    
2024-04-05 16:36:28,322 - Epoch: [272][  400/  500]    Overall Loss 0.503668    Objective Loss 0.503668                                        LR 0.000125    Time 0.044278    
2024-04-05 16:36:32,351 - Epoch: [272][  500/  500]    Overall Loss 0.507080    Objective Loss 0.507080    Top1 86.500000    Top5 99.500000    LR 0.000125    Time 0.043474    
2024-04-05 16:36:32,591 - --- validate (epoch=272)-----------
2024-04-05 16:36:32,591 - 10000 samples (100 per mini-batch)
2024-04-05 16:36:34,955 - Epoch: [272][  100/  100]    Loss 1.346622    Top1 63.700000    Top5 88.320000    
2024-04-05 16:36:35,154 - ==> Top1: 63.700    Top5: 88.320    Loss: 1.347

2024-04-05 16:36:35,159 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:36:35,159 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:36:35,190 - 

2024-04-05 16:36:35,190 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:36:40,424 - Epoch: [273][  100/  500]    Overall Loss 0.506524    Objective Loss 0.506524                                        LR 0.000125    Time 0.052301    
2024-04-05 16:36:44,613 - Epoch: [273][  200/  500]    Overall Loss 0.511501    Objective Loss 0.511501                                        LR 0.000125    Time 0.047078    
2024-04-05 16:36:48,801 - Epoch: [273][  300/  500]    Overall Loss 0.510010    Objective Loss 0.510010                                        LR 0.000125    Time 0.045333    
2024-04-05 16:36:52,949 - Epoch: [273][  400/  500]    Overall Loss 0.514681    Objective Loss 0.514681                                        LR 0.000125    Time 0.044362    
2024-04-05 16:36:57,220 - Epoch: [273][  500/  500]    Overall Loss 0.513430    Objective Loss 0.513430    Top1 86.000000    Top5 99.500000    LR 0.000125    Time 0.044023    
2024-04-05 16:36:57,493 - --- validate (epoch=273)-----------
2024-04-05 16:36:57,494 - 10000 samples (100 per mini-batch)
2024-04-05 16:36:59,896 - Epoch: [273][  100/  100]    Loss 1.349730    Top1 63.460000    Top5 88.450000    
2024-04-05 16:37:00,068 - ==> Top1: 63.460    Top5: 88.450    Loss: 1.350

2024-04-05 16:37:00,073 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:37:00,074 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:37:00,102 - 

2024-04-05 16:37:00,102 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:37:05,243 - Epoch: [274][  100/  500]    Overall Loss 0.492553    Objective Loss 0.492553                                        LR 0.000125    Time 0.051368    
2024-04-05 16:37:09,467 - Epoch: [274][  200/  500]    Overall Loss 0.492079    Objective Loss 0.492079                                        LR 0.000125    Time 0.046786    
2024-04-05 16:37:13,706 - Epoch: [274][  300/  500]    Overall Loss 0.495904    Objective Loss 0.495904                                        LR 0.000125    Time 0.045309    
2024-04-05 16:37:17,956 - Epoch: [274][  400/  500]    Overall Loss 0.498447    Objective Loss 0.498447                                        LR 0.000125    Time 0.044597    
2024-04-05 16:37:22,098 - Epoch: [274][  500/  500]    Overall Loss 0.502554    Objective Loss 0.502554    Top1 86.500000    Top5 98.500000    LR 0.000125    Time 0.043955    
2024-04-05 16:37:22,402 - --- validate (epoch=274)-----------
2024-04-05 16:37:22,403 - 10000 samples (100 per mini-batch)
2024-04-05 16:37:24,778 - Epoch: [274][  100/  100]    Loss 1.325418    Top1 64.260000    Top5 88.710000    
2024-04-05 16:37:24,930 - ==> Top1: 64.260    Top5: 88.710    Loss: 1.325

2024-04-05 16:37:24,935 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:37:24,936 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:37:24,964 - 

2024-04-05 16:37:24,965 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:37:29,853 - Epoch: [275][  100/  500]    Overall Loss 0.501007    Objective Loss 0.501007                                        LR 0.000125    Time 0.048846    
2024-04-05 16:37:34,017 - Epoch: [275][  200/  500]    Overall Loss 0.497360    Objective Loss 0.497360                                        LR 0.000125    Time 0.045227    
2024-04-05 16:37:38,353 - Epoch: [275][  300/  500]    Overall Loss 0.497017    Objective Loss 0.497017                                        LR 0.000125    Time 0.044592    
2024-04-05 16:37:42,537 - Epoch: [275][  400/  500]    Overall Loss 0.503773    Objective Loss 0.503773                                        LR 0.000125    Time 0.043896    
2024-04-05 16:37:46,821 - Epoch: [275][  500/  500]    Overall Loss 0.505590    Objective Loss 0.505590    Top1 86.000000    Top5 99.000000    LR 0.000125    Time 0.043677    
2024-04-05 16:37:46,978 - --- validate (epoch=275)-----------
2024-04-05 16:37:46,979 - 10000 samples (100 per mini-batch)
2024-04-05 16:37:49,404 - Epoch: [275][  100/  100]    Loss 1.334485    Top1 64.330000    Top5 88.650000    
2024-04-05 16:37:49,595 - ==> Top1: 64.330    Top5: 88.650    Loss: 1.334

2024-04-05 16:37:49,603 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:37:49,603 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:37:49,633 - 

2024-04-05 16:37:49,633 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:37:54,569 - Epoch: [276][  100/  500]    Overall Loss 0.490844    Objective Loss 0.490844                                        LR 0.000125    Time 0.049319    
2024-04-05 16:37:58,837 - Epoch: [276][  200/  500]    Overall Loss 0.497056    Objective Loss 0.497056                                        LR 0.000125    Time 0.045981    
2024-04-05 16:38:03,041 - Epoch: [276][  300/  500]    Overall Loss 0.502682    Objective Loss 0.502682                                        LR 0.000125    Time 0.044657    
2024-04-05 16:38:07,319 - Epoch: [276][  400/  500]    Overall Loss 0.504552    Objective Loss 0.504552                                        LR 0.000125    Time 0.044179    
2024-04-05 16:38:11,488 - Epoch: [276][  500/  500]    Overall Loss 0.506278    Objective Loss 0.506278    Top1 87.000000    Top5 100.000000    LR 0.000125    Time 0.043674    
2024-04-05 16:38:11,674 - --- validate (epoch=276)-----------
2024-04-05 16:38:11,675 - 10000 samples (100 per mini-batch)
2024-04-05 16:38:14,355 - Epoch: [276][  100/  100]    Loss 1.332111    Top1 63.730000    Top5 88.770000    
2024-04-05 16:38:14,528 - ==> Top1: 63.730    Top5: 88.770    Loss: 1.332

2024-04-05 16:38:14,533 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:38:14,533 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:38:14,563 - 

2024-04-05 16:38:14,564 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:38:19,472 - Epoch: [277][  100/  500]    Overall Loss 0.492360    Objective Loss 0.492360                                        LR 0.000125    Time 0.049038    
2024-04-05 16:38:23,768 - Epoch: [277][  200/  500]    Overall Loss 0.498593    Objective Loss 0.498593                                        LR 0.000125    Time 0.045982    
2024-04-05 16:38:27,992 - Epoch: [277][  300/  500]    Overall Loss 0.499428    Objective Loss 0.499428                                        LR 0.000125    Time 0.044722    
2024-04-05 16:38:32,177 - Epoch: [277][  400/  500]    Overall Loss 0.500571    Objective Loss 0.500571                                        LR 0.000125    Time 0.043996    
2024-04-05 16:38:36,358 - Epoch: [277][  500/  500]    Overall Loss 0.501458    Objective Loss 0.501458    Top1 89.000000    Top5 98.500000    LR 0.000125    Time 0.043553    
2024-04-05 16:38:36,630 - --- validate (epoch=277)-----------
2024-04-05 16:38:36,630 - 10000 samples (100 per mini-batch)
2024-04-05 16:38:39,236 - Epoch: [277][  100/  100]    Loss 1.326153    Top1 64.070000    Top5 89.000000    
2024-04-05 16:38:39,473 - ==> Top1: 64.070    Top5: 89.000    Loss: 1.326

2024-04-05 16:38:39,477 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:38:39,477 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:38:39,507 - 

2024-04-05 16:38:39,508 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:38:44,630 - Epoch: [278][  100/  500]    Overall Loss 0.494271    Objective Loss 0.494271                                        LR 0.000125    Time 0.051166    
2024-04-05 16:38:48,946 - Epoch: [278][  200/  500]    Overall Loss 0.494421    Objective Loss 0.494421                                        LR 0.000125    Time 0.047144    
2024-04-05 16:38:53,312 - Epoch: [278][  300/  500]    Overall Loss 0.498200    Objective Loss 0.498200                                        LR 0.000125    Time 0.045959    
2024-04-05 16:38:57,536 - Epoch: [278][  400/  500]    Overall Loss 0.496903    Objective Loss 0.496903                                        LR 0.000125    Time 0.045021    
2024-04-05 16:39:01,790 - Epoch: [278][  500/  500]    Overall Loss 0.501611    Objective Loss 0.501611    Top1 83.000000    Top5 98.000000    LR 0.000125    Time 0.044517    
2024-04-05 16:39:02,001 - --- validate (epoch=278)-----------
2024-04-05 16:39:02,002 - 10000 samples (100 per mini-batch)
2024-04-05 16:39:04,733 - Epoch: [278][  100/  100]    Loss 1.353698    Top1 63.470000    Top5 88.300000    
2024-04-05 16:39:04,909 - ==> Top1: 63.470    Top5: 88.300    Loss: 1.354

2024-04-05 16:39:04,916 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:39:04,916 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:39:04,946 - 

2024-04-05 16:39:04,946 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:39:09,921 - Epoch: [279][  100/  500]    Overall Loss 0.616286    Objective Loss 0.616286                                        LR 0.000125    Time 0.049704    
2024-04-05 16:39:14,100 - Epoch: [279][  200/  500]    Overall Loss 0.583417    Objective Loss 0.583417                                        LR 0.000125    Time 0.045731    
2024-04-05 16:39:18,330 - Epoch: [279][  300/  500]    Overall Loss 0.598687    Objective Loss 0.598687                                        LR 0.000125    Time 0.044576    
2024-04-05 16:39:22,566 - Epoch: [279][  400/  500]    Overall Loss 0.580984    Objective Loss 0.580984                                        LR 0.000125    Time 0.044013    
2024-04-05 16:39:26,763 - Epoch: [279][  500/  500]    Overall Loss 0.569036    Objective Loss 0.569036    Top1 84.000000    Top5 99.500000    LR 0.000125    Time 0.043598    
2024-04-05 16:39:26,947 - --- validate (epoch=279)-----------
2024-04-05 16:39:26,948 - 10000 samples (100 per mini-batch)
2024-04-05 16:39:29,497 - Epoch: [279][  100/  100]    Loss 1.354435    Top1 63.420000    Top5 88.440000    
2024-04-05 16:39:29,662 - ==> Top1: 63.420    Top5: 88.440    Loss: 1.354

2024-04-05 16:39:29,667 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:39:29,667 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:39:29,698 - 

2024-04-05 16:39:29,698 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:39:34,789 - Epoch: [280][  100/  500]    Overall Loss 0.498099    Objective Loss 0.498099                                        LR 0.000125    Time 0.050870    
2024-04-05 16:39:38,977 - Epoch: [280][  200/  500]    Overall Loss 0.497470    Objective Loss 0.497470                                        LR 0.000125    Time 0.046355    
2024-04-05 16:39:43,262 - Epoch: [280][  300/  500]    Overall Loss 0.518456    Objective Loss 0.518456                                        LR 0.000125    Time 0.045175    
2024-04-05 16:39:47,446 - Epoch: [280][  400/  500]    Overall Loss 0.535261    Objective Loss 0.535261                                        LR 0.000125    Time 0.044334    
2024-04-05 16:39:51,639 - Epoch: [280][  500/  500]    Overall Loss 0.531862    Objective Loss 0.531862    Top1 81.500000    Top5 100.000000    LR 0.000125    Time 0.043847    
2024-04-05 16:39:51,838 - --- validate (epoch=280)-----------
2024-04-05 16:39:51,839 - 10000 samples (100 per mini-batch)
2024-04-05 16:39:54,216 - Epoch: [280][  100/  100]    Loss 1.343135    Top1 63.460000    Top5 88.830000    
2024-04-05 16:39:54,351 - ==> Top1: 63.460    Top5: 88.830    Loss: 1.343

2024-04-05 16:39:54,356 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:39:54,356 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:39:54,386 - 

2024-04-05 16:39:54,387 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:39:59,047 - Epoch: [281][  100/  500]    Overall Loss 0.483319    Objective Loss 0.483319                                        LR 0.000125    Time 0.046560    
2024-04-05 16:40:03,360 - Epoch: [281][  200/  500]    Overall Loss 0.531034    Objective Loss 0.531034                                        LR 0.000125    Time 0.044818    
2024-04-05 16:40:07,598 - Epoch: [281][  300/  500]    Overall Loss 0.532686    Objective Loss 0.532686                                        LR 0.000125    Time 0.043996    
2024-04-05 16:40:11,801 - Epoch: [281][  400/  500]    Overall Loss 0.526252    Objective Loss 0.526252                                        LR 0.000125    Time 0.043495    
2024-04-05 16:40:16,086 - Epoch: [281][  500/  500]    Overall Loss 0.525321    Objective Loss 0.525321    Top1 78.500000    Top5 98.000000    LR 0.000125    Time 0.043359    
2024-04-05 16:40:16,306 - --- validate (epoch=281)-----------
2024-04-05 16:40:16,306 - 10000 samples (100 per mini-batch)
2024-04-05 16:40:18,667 - Epoch: [281][  100/  100]    Loss 1.333893    Top1 63.970000    Top5 88.630000    
2024-04-05 16:40:18,842 - ==> Top1: 63.970    Top5: 88.630    Loss: 1.334

2024-04-05 16:40:18,847 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:40:18,848 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:40:18,878 - 

2024-04-05 16:40:18,878 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:40:23,916 - Epoch: [282][  100/  500]    Overall Loss 0.532807    Objective Loss 0.532807                                        LR 0.000125    Time 0.050339    
2024-04-05 16:40:28,401 - Epoch: [282][  200/  500]    Overall Loss 0.544082    Objective Loss 0.544082                                        LR 0.000125    Time 0.047575    
2024-04-05 16:40:32,720 - Epoch: [282][  300/  500]    Overall Loss 0.530164    Objective Loss 0.530164                                        LR 0.000125    Time 0.046099    
2024-04-05 16:40:36,950 - Epoch: [282][  400/  500]    Overall Loss 0.529094    Objective Loss 0.529094                                        LR 0.000125    Time 0.045141    
2024-04-05 16:40:41,219 - Epoch: [282][  500/  500]    Overall Loss 0.529034    Objective Loss 0.529034    Top1 84.500000    Top5 99.500000    LR 0.000125    Time 0.044643    
2024-04-05 16:40:41,511 - --- validate (epoch=282)-----------
2024-04-05 16:40:41,512 - 10000 samples (100 per mini-batch)
2024-04-05 16:40:43,901 - Epoch: [282][  100/  100]    Loss 1.349350    Top1 63.590000    Top5 88.540000    
2024-04-05 16:40:44,058 - ==> Top1: 63.590    Top5: 88.540    Loss: 1.349

2024-04-05 16:40:44,064 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:40:44,064 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:40:44,095 - 

2024-04-05 16:40:44,095 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:40:48,872 - Epoch: [283][  100/  500]    Overall Loss 0.498996    Objective Loss 0.498996                                        LR 0.000125    Time 0.047723    
2024-04-05 16:40:53,134 - Epoch: [283][  200/  500]    Overall Loss 0.499448    Objective Loss 0.499448                                        LR 0.000125    Time 0.045154    
2024-04-05 16:40:57,355 - Epoch: [283][  300/  500]    Overall Loss 0.501870    Objective Loss 0.501870                                        LR 0.000125    Time 0.044162    
2024-04-05 16:41:01,501 - Epoch: [283][  400/  500]    Overall Loss 0.498986    Objective Loss 0.498986                                        LR 0.000125    Time 0.043477    
2024-04-05 16:41:05,748 - Epoch: [283][  500/  500]    Overall Loss 0.499064    Objective Loss 0.499064    Top1 89.000000    Top5 99.500000    LR 0.000125    Time 0.043269    
2024-04-05 16:41:06,025 - --- validate (epoch=283)-----------
2024-04-05 16:41:06,026 - 10000 samples (100 per mini-batch)
2024-04-05 16:41:08,376 - Epoch: [283][  100/  100]    Loss 1.347045    Top1 63.690000    Top5 88.410000    
2024-04-05 16:41:08,563 - ==> Top1: 63.690    Top5: 88.410    Loss: 1.347

2024-04-05 16:41:08,568 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:41:08,569 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:41:08,598 - 

2024-04-05 16:41:08,598 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:41:13,229 - Epoch: [284][  100/  500]    Overall Loss 0.481286    Objective Loss 0.481286                                        LR 0.000125    Time 0.046271    
2024-04-05 16:41:17,467 - Epoch: [284][  200/  500]    Overall Loss 0.488719    Objective Loss 0.488719                                        LR 0.000125    Time 0.044305    
2024-04-05 16:41:21,646 - Epoch: [284][  300/  500]    Overall Loss 0.493548    Objective Loss 0.493548                                        LR 0.000125    Time 0.043458    
2024-04-05 16:41:25,871 - Epoch: [284][  400/  500]    Overall Loss 0.495544    Objective Loss 0.495544                                        LR 0.000125    Time 0.043146    
2024-04-05 16:41:30,072 - Epoch: [284][  500/  500]    Overall Loss 0.499455    Objective Loss 0.499455    Top1 81.500000    Top5 100.000000    LR 0.000125    Time 0.042912    
2024-04-05 16:41:30,334 - --- validate (epoch=284)-----------
2024-04-05 16:41:30,335 - 10000 samples (100 per mini-batch)
2024-04-05 16:41:32,959 - Epoch: [284][  100/  100]    Loss 1.370256    Top1 63.060000    Top5 88.800000    
2024-04-05 16:41:33,121 - ==> Top1: 63.060    Top5: 88.800    Loss: 1.370

2024-04-05 16:41:33,128 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:41:33,128 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:41:33,158 - 

2024-04-05 16:41:33,159 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:41:37,679 - Epoch: [285][  100/  500]    Overall Loss 0.487677    Objective Loss 0.487677                                        LR 0.000125    Time 0.045159    
2024-04-05 16:41:42,024 - Epoch: [285][  200/  500]    Overall Loss 0.491509    Objective Loss 0.491509                                        LR 0.000125    Time 0.044289    
2024-04-05 16:41:46,181 - Epoch: [285][  300/  500]    Overall Loss 0.490738    Objective Loss 0.490738                                        LR 0.000125    Time 0.043373    
2024-04-05 16:41:50,356 - Epoch: [285][  400/  500]    Overall Loss 0.492718    Objective Loss 0.492718                                        LR 0.000125    Time 0.042959    
2024-04-05 16:41:54,525 - Epoch: [285][  500/  500]    Overall Loss 0.498314    Objective Loss 0.498314    Top1 87.500000    Top5 98.000000    LR 0.000125    Time 0.042698    
2024-04-05 16:41:54,786 - --- validate (epoch=285)-----------
2024-04-05 16:41:54,786 - 10000 samples (100 per mini-batch)
2024-04-05 16:41:57,152 - Epoch: [285][  100/  100]    Loss 1.373936    Top1 63.860000    Top5 88.500000    
2024-04-05 16:41:57,366 - ==> Top1: 63.860    Top5: 88.500    Loss: 1.374

2024-04-05 16:41:57,371 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:41:57,371 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:41:57,401 - 

2024-04-05 16:41:57,401 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:42:02,490 - Epoch: [286][  100/  500]    Overall Loss 0.486341    Objective Loss 0.486341                                        LR 0.000125    Time 0.050851    
2024-04-05 16:42:06,660 - Epoch: [286][  200/  500]    Overall Loss 0.486603    Objective Loss 0.486603                                        LR 0.000125    Time 0.046258    
2024-04-05 16:42:10,904 - Epoch: [286][  300/  500]    Overall Loss 0.493265    Objective Loss 0.493265                                        LR 0.000125    Time 0.044975    
2024-04-05 16:42:15,039 - Epoch: [286][  400/  500]    Overall Loss 0.497605    Objective Loss 0.497605                                        LR 0.000125    Time 0.044061    
2024-04-05 16:42:19,260 - Epoch: [286][  500/  500]    Overall Loss 0.496855    Objective Loss 0.496855    Top1 81.500000    Top5 98.500000    LR 0.000125    Time 0.043684    
2024-04-05 16:42:19,464 - --- validate (epoch=286)-----------
2024-04-05 16:42:19,465 - 10000 samples (100 per mini-batch)
2024-04-05 16:42:21,805 - Epoch: [286][  100/  100]    Loss 1.348645    Top1 63.480000    Top5 88.610000    
2024-04-05 16:42:21,944 - ==> Top1: 63.480    Top5: 88.610    Loss: 1.349

2024-04-05 16:42:21,950 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:42:21,950 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:42:21,978 - 

2024-04-05 16:42:21,979 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:42:26,816 - Epoch: [287][  100/  500]    Overall Loss 0.499266    Objective Loss 0.499266                                        LR 0.000125    Time 0.048339    
2024-04-05 16:42:30,042 - Epoch: [287][  200/  500]    Overall Loss 0.498813    Objective Loss 0.498813                                        LR 0.000125    Time 0.040284    
2024-04-05 16:42:32,956 - Epoch: [287][  300/  500]    Overall Loss 0.499901    Objective Loss 0.499901                                        LR 0.000125    Time 0.036561    
2024-04-05 16:42:35,138 - Epoch: [287][  400/  500]    Overall Loss 0.499935    Objective Loss 0.499935                                        LR 0.000125    Time 0.032871    
2024-04-05 16:42:37,324 - Epoch: [287][  500/  500]    Overall Loss 0.497833    Objective Loss 0.497833    Top1 83.500000    Top5 99.500000    LR 0.000125    Time 0.030667    
2024-04-05 16:42:37,472 - --- validate (epoch=287)-----------
2024-04-05 16:42:37,473 - 10000 samples (100 per mini-batch)
2024-04-05 16:42:39,239 - Epoch: [287][  100/  100]    Loss 1.353046    Top1 64.020000    Top5 88.630000    
2024-04-05 16:42:39,429 - ==> Top1: 64.020    Top5: 88.630    Loss: 1.353

2024-04-05 16:42:39,435 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:42:39,435 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:42:39,465 - 

2024-04-05 16:42:39,465 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:42:44,640 - Epoch: [288][  100/  500]    Overall Loss 0.473280    Objective Loss 0.473280                                        LR 0.000125    Time 0.051706    
2024-04-05 16:42:48,911 - Epoch: [288][  200/  500]    Overall Loss 0.484682    Objective Loss 0.484682                                        LR 0.000125    Time 0.047194    
2024-04-05 16:42:53,119 - Epoch: [288][  300/  500]    Overall Loss 0.491133    Objective Loss 0.491133                                        LR 0.000125    Time 0.045471    
2024-04-05 16:42:57,342 - Epoch: [288][  400/  500]    Overall Loss 0.494360    Objective Loss 0.494360                                        LR 0.000125    Time 0.044650    
2024-04-05 16:43:01,525 - Epoch: [288][  500/  500]    Overall Loss 0.494446    Objective Loss 0.494446    Top1 84.000000    Top5 99.000000    LR 0.000125    Time 0.044080    
2024-04-05 16:43:01,796 - --- validate (epoch=288)-----------
2024-04-05 16:43:01,797 - 10000 samples (100 per mini-batch)
2024-04-05 16:43:04,231 - Epoch: [288][  100/  100]    Loss 1.352679    Top1 64.000000    Top5 88.520000    
2024-04-05 16:43:04,471 - ==> Top1: 64.000    Top5: 88.520    Loss: 1.353

2024-04-05 16:43:04,476 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:43:04,476 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:43:04,505 - 

2024-04-05 16:43:04,505 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:43:09,489 - Epoch: [289][  100/  500]    Overall Loss 0.463926    Objective Loss 0.463926                                        LR 0.000125    Time 0.049802    
2024-04-05 16:43:13,715 - Epoch: [289][  200/  500]    Overall Loss 0.474932    Objective Loss 0.474932                                        LR 0.000125    Time 0.046009    
2024-04-05 16:43:17,825 - Epoch: [289][  300/  500]    Overall Loss 0.480316    Objective Loss 0.480316                                        LR 0.000125    Time 0.044362    
2024-04-05 16:43:22,035 - Epoch: [289][  400/  500]    Overall Loss 0.483764    Objective Loss 0.483764                                        LR 0.000125    Time 0.043789    
2024-04-05 16:43:26,192 - Epoch: [289][  500/  500]    Overall Loss 0.488932    Objective Loss 0.488932    Top1 82.500000    Top5 98.000000    LR 0.000125    Time 0.043339    
2024-04-05 16:43:26,387 - --- validate (epoch=289)-----------
2024-04-05 16:43:26,388 - 10000 samples (100 per mini-batch)
2024-04-05 16:43:28,817 - Epoch: [289][  100/  100]    Loss 1.336207    Top1 64.320000    Top5 88.570000    
2024-04-05 16:43:28,987 - ==> Top1: 64.320    Top5: 88.570    Loss: 1.336

2024-04-05 16:43:28,993 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:43:28,994 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:43:29,023 - 

2024-04-05 16:43:29,024 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:43:34,228 - Epoch: [290][  100/  500]    Overall Loss 0.472511    Objective Loss 0.472511                                        LR 0.000125    Time 0.051998    
2024-04-05 16:43:38,404 - Epoch: [290][  200/  500]    Overall Loss 0.484407    Objective Loss 0.484407                                        LR 0.000125    Time 0.046862    
2024-04-05 16:43:42,616 - Epoch: [290][  300/  500]    Overall Loss 0.485644    Objective Loss 0.485644                                        LR 0.000125    Time 0.045270    
2024-04-05 16:43:46,870 - Epoch: [290][  400/  500]    Overall Loss 0.489208    Objective Loss 0.489208                                        LR 0.000125    Time 0.044580    
2024-04-05 16:43:51,059 - Epoch: [290][  500/  500]    Overall Loss 0.489047    Objective Loss 0.489047    Top1 87.500000    Top5 98.500000    LR 0.000125    Time 0.044036    
2024-04-05 16:43:51,253 - --- validate (epoch=290)-----------
2024-04-05 16:43:51,254 - 10000 samples (100 per mini-batch)
2024-04-05 16:43:53,636 - Epoch: [290][  100/  100]    Loss 1.356665    Top1 63.800000    Top5 88.630000    
2024-04-05 16:43:53,870 - ==> Top1: 63.800    Top5: 88.630    Loss: 1.357

2024-04-05 16:43:53,876 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:43:53,876 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:43:53,905 - 

2024-04-05 16:43:53,906 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:43:58,825 - Epoch: [291][  100/  500]    Overall Loss 0.464560    Objective Loss 0.464560                                        LR 0.000125    Time 0.049152    
2024-04-05 16:44:03,203 - Epoch: [291][  200/  500]    Overall Loss 0.472166    Objective Loss 0.472166                                        LR 0.000125    Time 0.046449    
2024-04-05 16:44:07,308 - Epoch: [291][  300/  500]    Overall Loss 0.474868    Objective Loss 0.474868                                        LR 0.000125    Time 0.044637    
2024-04-05 16:44:11,498 - Epoch: [291][  400/  500]    Overall Loss 0.479766    Objective Loss 0.479766                                        LR 0.000125    Time 0.043944    
2024-04-05 16:44:15,765 - Epoch: [291][  500/  500]    Overall Loss 0.482484    Objective Loss 0.482484    Top1 79.500000    Top5 97.000000    LR 0.000125    Time 0.043682    
2024-04-05 16:44:16,030 - --- validate (epoch=291)-----------
2024-04-05 16:44:16,030 - 10000 samples (100 per mini-batch)
2024-04-05 16:44:18,478 - Epoch: [291][  100/  100]    Loss 1.348319    Top1 64.120000    Top5 88.760000    
2024-04-05 16:44:18,675 - ==> Top1: 64.120    Top5: 88.760    Loss: 1.348

2024-04-05 16:44:18,681 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:44:18,681 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:44:18,713 - 

2024-04-05 16:44:18,713 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:44:23,921 - Epoch: [292][  100/  500]    Overall Loss 0.480861    Objective Loss 0.480861                                        LR 0.000125    Time 0.052032    
2024-04-05 16:44:28,147 - Epoch: [292][  200/  500]    Overall Loss 0.489009    Objective Loss 0.489009                                        LR 0.000125    Time 0.047131    
2024-04-05 16:44:32,279 - Epoch: [292][  300/  500]    Overall Loss 0.485689    Objective Loss 0.485689                                        LR 0.000125    Time 0.045181    
2024-04-05 16:44:36,497 - Epoch: [292][  400/  500]    Overall Loss 0.485419    Objective Loss 0.485419                                        LR 0.000125    Time 0.044422    
2024-04-05 16:44:40,719 - Epoch: [292][  500/  500]    Overall Loss 0.485868    Objective Loss 0.485868    Top1 88.500000    Top5 98.500000    LR 0.000125    Time 0.043975    
2024-04-05 16:44:40,900 - --- validate (epoch=292)-----------
2024-04-05 16:44:40,900 - 10000 samples (100 per mini-batch)
2024-04-05 16:44:43,329 - Epoch: [292][  100/  100]    Loss 1.384175    Top1 64.200000    Top5 88.380000    
2024-04-05 16:44:43,504 - ==> Top1: 64.200    Top5: 88.380    Loss: 1.384

2024-04-05 16:44:43,511 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:44:43,511 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:44:43,541 - 

2024-04-05 16:44:43,541 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:44:48,496 - Epoch: [293][  100/  500]    Overall Loss 0.464809    Objective Loss 0.464809                                        LR 0.000125    Time 0.049506    
2024-04-05 16:44:52,808 - Epoch: [293][  200/  500]    Overall Loss 0.466961    Objective Loss 0.466961                                        LR 0.000125    Time 0.046293    
2024-04-05 16:44:57,062 - Epoch: [293][  300/  500]    Overall Loss 0.471577    Objective Loss 0.471577                                        LR 0.000125    Time 0.045031    
2024-04-05 16:45:01,303 - Epoch: [293][  400/  500]    Overall Loss 0.477114    Objective Loss 0.477114                                        LR 0.000125    Time 0.044366    
2024-04-05 16:45:05,463 - Epoch: [293][  500/  500]    Overall Loss 0.479763    Objective Loss 0.479763    Top1 88.000000    Top5 98.000000    LR 0.000125    Time 0.043806    
2024-04-05 16:45:05,710 - --- validate (epoch=293)-----------
2024-04-05 16:45:05,710 - 10000 samples (100 per mini-batch)
2024-04-05 16:45:08,118 - Epoch: [293][  100/  100]    Loss 1.344721    Top1 64.390000    Top5 88.830000    
2024-04-05 16:45:08,293 - ==> Top1: 64.390    Top5: 88.830    Loss: 1.345

2024-04-05 16:45:08,298 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:45:08,299 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:45:08,327 - 

2024-04-05 16:45:08,328 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:45:13,369 - Epoch: [294][  100/  500]    Overall Loss 0.472984    Objective Loss 0.472984                                        LR 0.000125    Time 0.050381    
2024-04-05 16:45:17,512 - Epoch: [294][  200/  500]    Overall Loss 0.481378    Objective Loss 0.481378                                        LR 0.000125    Time 0.045889    
2024-04-05 16:45:21,744 - Epoch: [294][  300/  500]    Overall Loss 0.477038    Objective Loss 0.477038                                        LR 0.000125    Time 0.044685    
2024-04-05 16:45:25,965 - Epoch: [294][  400/  500]    Overall Loss 0.480145    Objective Loss 0.480145                                        LR 0.000125    Time 0.044057    
2024-04-05 16:45:30,186 - Epoch: [294][  500/  500]    Overall Loss 0.480891    Objective Loss 0.480891    Top1 88.000000    Top5 98.000000    LR 0.000125    Time 0.043683    
2024-04-05 16:45:30,404 - --- validate (epoch=294)-----------
2024-04-05 16:45:30,405 - 10000 samples (100 per mini-batch)
2024-04-05 16:45:32,781 - Epoch: [294][  100/  100]    Loss 1.350843    Top1 63.990000    Top5 88.500000    
2024-04-05 16:45:32,966 - ==> Top1: 63.990    Top5: 88.500    Loss: 1.351

2024-04-05 16:45:32,971 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:45:32,972 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:45:33,001 - 

2024-04-05 16:45:33,001 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:45:37,909 - Epoch: [295][  100/  500]    Overall Loss 0.450329    Objective Loss 0.450329                                        LR 0.000125    Time 0.049035    
2024-04-05 16:45:42,080 - Epoch: [295][  200/  500]    Overall Loss 0.459836    Objective Loss 0.459836                                        LR 0.000125    Time 0.045357    
2024-04-05 16:45:46,298 - Epoch: [295][  300/  500]    Overall Loss 0.469851    Objective Loss 0.469851                                        LR 0.000125    Time 0.044287    
2024-04-05 16:45:50,397 - Epoch: [295][  400/  500]    Overall Loss 0.473159    Objective Loss 0.473159                                        LR 0.000125    Time 0.043456    
2024-04-05 16:45:54,613 - Epoch: [295][  500/  500]    Overall Loss 0.475853    Objective Loss 0.475853    Top1 87.000000    Top5 99.500000    LR 0.000125    Time 0.043190    
2024-04-05 16:45:54,837 - --- validate (epoch=295)-----------
2024-04-05 16:45:54,838 - 10000 samples (100 per mini-batch)
2024-04-05 16:45:57,114 - Epoch: [295][  100/  100]    Loss 1.362144    Top1 63.750000    Top5 88.770000    
2024-04-05 16:45:57,274 - ==> Top1: 63.750    Top5: 88.770    Loss: 1.362

2024-04-05 16:45:57,279 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:45:57,279 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:45:57,309 - 

2024-04-05 16:45:57,309 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:46:02,450 - Epoch: [296][  100/  500]    Overall Loss 0.463050    Objective Loss 0.463050                                        LR 0.000125    Time 0.051363    
2024-04-05 16:46:06,783 - Epoch: [296][  200/  500]    Overall Loss 0.467354    Objective Loss 0.467354                                        LR 0.000125    Time 0.047328    
2024-04-05 16:46:11,008 - Epoch: [296][  300/  500]    Overall Loss 0.468566    Objective Loss 0.468566                                        LR 0.000125    Time 0.045627    
2024-04-05 16:46:15,252 - Epoch: [296][  400/  500]    Overall Loss 0.472894    Objective Loss 0.472894                                        LR 0.000125    Time 0.044821    
2024-04-05 16:46:19,549 - Epoch: [296][  500/  500]    Overall Loss 0.476282    Objective Loss 0.476282    Top1 88.500000    Top5 99.000000    LR 0.000125    Time 0.044444    
2024-04-05 16:46:19,709 - --- validate (epoch=296)-----------
2024-04-05 16:46:19,710 - 10000 samples (100 per mini-batch)
2024-04-05 16:46:22,044 - Epoch: [296][  100/  100]    Loss 1.357953    Top1 63.320000    Top5 88.660000    
2024-04-05 16:46:22,219 - ==> Top1: 63.320    Top5: 88.660    Loss: 1.358

2024-04-05 16:46:22,225 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:46:22,226 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:46:22,255 - 

2024-04-05 16:46:22,256 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:46:27,156 - Epoch: [297][  100/  500]    Overall Loss 0.487581    Objective Loss 0.487581                                        LR 0.000125    Time 0.048959    
2024-04-05 16:46:31,379 - Epoch: [297][  200/  500]    Overall Loss 0.477556    Objective Loss 0.477556                                        LR 0.000125    Time 0.045580    
2024-04-05 16:46:35,623 - Epoch: [297][  300/  500]    Overall Loss 0.476557    Objective Loss 0.476557                                        LR 0.000125    Time 0.044519    
2024-04-05 16:46:39,734 - Epoch: [297][  400/  500]    Overall Loss 0.476220    Objective Loss 0.476220                                        LR 0.000125    Time 0.043660    
2024-04-05 16:46:44,015 - Epoch: [297][  500/  500]    Overall Loss 0.478322    Objective Loss 0.478322    Top1 90.000000    Top5 99.500000    LR 0.000125    Time 0.043484    
2024-04-05 16:46:44,294 - --- validate (epoch=297)-----------
2024-04-05 16:46:44,295 - 10000 samples (100 per mini-batch)
2024-04-05 16:46:46,670 - Epoch: [297][  100/  100]    Loss 1.396730    Top1 63.150000    Top5 88.280000    
2024-04-05 16:46:46,825 - ==> Top1: 63.150    Top5: 88.280    Loss: 1.397

2024-04-05 16:46:46,831 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:46:46,831 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:46:46,861 - 

2024-04-05 16:46:46,861 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:46:51,683 - Epoch: [298][  100/  500]    Overall Loss 0.464511    Objective Loss 0.464511                                        LR 0.000125    Time 0.048183    
2024-04-05 16:46:55,861 - Epoch: [298][  200/  500]    Overall Loss 0.466558    Objective Loss 0.466558                                        LR 0.000125    Time 0.044963    
2024-04-05 16:47:00,070 - Epoch: [298][  300/  500]    Overall Loss 0.469511    Objective Loss 0.469511                                        LR 0.000125    Time 0.043989    
2024-04-05 16:47:04,137 - Epoch: [298][  400/  500]    Overall Loss 0.469105    Objective Loss 0.469105                                        LR 0.000125    Time 0.043151    
2024-04-05 16:47:08,433 - Epoch: [298][  500/  500]    Overall Loss 0.472935    Objective Loss 0.472935    Top1 86.000000    Top5 99.000000    LR 0.000125    Time 0.043106    
2024-04-05 16:47:08,613 - --- validate (epoch=298)-----------
2024-04-05 16:47:08,615 - 10000 samples (100 per mini-batch)
2024-04-05 16:47:11,001 - Epoch: [298][  100/  100]    Loss 1.356545    Top1 63.990000    Top5 88.560000    
2024-04-05 16:47:11,168 - ==> Top1: 63.990    Top5: 88.560    Loss: 1.357

2024-04-05 16:47:11,174 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:47:11,175 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:47:11,205 - 

2024-04-05 16:47:11,205 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:47:16,048 - Epoch: [299][  100/  500]    Overall Loss 0.458542    Objective Loss 0.458542                                        LR 0.000125    Time 0.048394    
2024-04-05 16:47:20,330 - Epoch: [299][  200/  500]    Overall Loss 0.463294    Objective Loss 0.463294                                        LR 0.000125    Time 0.045589    
2024-04-05 16:47:24,552 - Epoch: [299][  300/  500]    Overall Loss 0.468880    Objective Loss 0.468880                                        LR 0.000125    Time 0.044454    
2024-04-05 16:47:28,725 - Epoch: [299][  400/  500]    Overall Loss 0.472917    Objective Loss 0.472917                                        LR 0.000125    Time 0.043764    
2024-04-05 16:47:32,881 - Epoch: [299][  500/  500]    Overall Loss 0.472241    Objective Loss 0.472241    Top1 84.500000    Top5 99.000000    LR 0.000125    Time 0.043315    
2024-04-05 16:47:33,089 - --- validate (epoch=299)-----------
2024-04-05 16:47:33,090 - 10000 samples (100 per mini-batch)
2024-04-05 16:47:35,545 - Epoch: [299][  100/  100]    Loss 1.369613    Top1 63.690000    Top5 88.470000    
2024-04-05 16:47:35,721 - ==> Top1: 63.690    Top5: 88.470    Loss: 1.370

2024-04-05 16:47:35,727 - ==> Best [Top1: 64.690   Top5: 89.180   Sparsity:0.00   Params: 347840 on epoch: 241]
2024-04-05 16:47:35,727 - Saving checkpoint to: logs/2024.04.05-145134/qat_checkpoint.pth.tar
2024-04-05 16:47:35,759 - --- test ---------------------
2024-04-05 16:47:35,759 - 10000 samples (100 per mini-batch)
2024-04-05 16:47:38,128 - Test: [  100/  100]    Loss 1.369613    Top1 63.690000    Top5 88.470000    
2024-04-05 16:47:38,365 - ==> Top1: 63.690    Top5: 88.470    Loss: 1.370

2024-04-05 16:47:38,374 - 
2024-04-05 16:47:38,374 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.05-145134/2024.04.05-145134.log
