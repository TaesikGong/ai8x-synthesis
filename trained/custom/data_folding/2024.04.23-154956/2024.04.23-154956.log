2024-04-23 15:49:56,197 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.23-154956/2024.04.23-154956.log
2024-04-23 15:49:56,542 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.23-154956/2024.04.23-154956.log
2024-04-23 15:50:01,610 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-04-23 15:50:01,611 - Optimizer Args: {'lr': 0.00032, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-04-23 15:50:01,706 - Dataset sizes:
	training=9469
	validation=3925
	test=3925
2024-04-23 15:50:01,707 - Reading compression schedule from: policies/schedule-cifar100.yaml
2024-04-23 15:50:01,717 - 

2024-04-23 15:50:01,718 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:50:02,991 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-04-23 15:50:02,993 - Optimizer Args: {'lr': 0.1, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}
2024-04-23 15:50:03,367 - Dataset sizes:
	training=8523
	validation=946
	test=3925
2024-04-23 15:50:03,368 - Reading compression schedule from: policies/schedule.yaml
2024-04-23 15:50:03,379 - 

2024-04-23 15:50:03,380 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 15:50:08,472 - Epoch: [0][   10/  267]    Overall Loss 7.349388    Objective Loss 7.349388                                        LR 0.100000    Time 0.508870    
2024-04-23 15:50:10,924 - Epoch: [0][   20/  267]    Overall Loss 6.054841    Objective Loss 6.054841                                        LR 0.100000    Time 0.376851    
2024-04-23 15:50:13,228 - Epoch: [0][   30/  267]    Overall Loss 5.262652    Objective Loss 5.262652                                        LR 0.100000    Time 0.327915    
2024-04-23 15:50:16,469 - Epoch: [0][   40/  267]    Overall Loss 4.785155    Objective Loss 4.785155                                        LR 0.100000    Time 0.326882    
2024-04-23 15:50:18,739 - Epoch: [0][   50/  267]    Overall Loss 4.449232    Objective Loss 4.449232                                        LR 0.100000    Time 0.306821    
2024-04-23 15:50:21,860 - Epoch: [0][   60/  267]    Overall Loss 4.201260    Objective Loss 4.201260                                        LR 0.100000    Time 0.307646    
2024-04-23 15:50:24,506 - Epoch: [0][   70/  267]    Overall Loss 3.987753    Objective Loss 3.987753                                        LR 0.100000    Time 0.301449    
2024-04-23 15:50:27,104 - Epoch: [0][   80/  267]    Overall Loss 3.923907    Objective Loss 3.923907                                        LR 0.100000    Time 0.296200    
2024-04-23 15:50:29,337 - Epoch: [0][   90/  267]    Overall Loss 3.918359    Objective Loss 3.918359                                        LR 0.100000    Time 0.288070    
2024-04-23 15:50:30,505 - Epoch: [0][  100/  296]    Overall Loss 2.200953    Objective Loss 2.200953                                        LR 0.000320    Time 0.287670    
2024-04-23 15:50:32,124 - Epoch: [0][  100/  267]    Overall Loss 3.951410    Objective Loss 3.951410                                        LR 0.100000    Time 0.287107    
2024-04-23 15:50:34,328 - Epoch: [0][  110/  267]    Overall Loss 3.895773    Objective Loss 3.895773                                        LR 0.100000    Time 0.281020    
2024-04-23 15:50:38,320 - Epoch: [0][  120/  267]    Overall Loss 3.836915    Objective Loss 3.836915                                        LR 0.100000    Time 0.290838    
2024-04-23 15:50:40,842 - Epoch: [0][  130/  267]    Overall Loss 3.781638    Objective Loss 3.781638                                        LR 0.100000    Time 0.287840    
2024-04-23 15:50:44,205 - Epoch: [0][  140/  267]    Overall Loss 3.715284    Objective Loss 3.715284                                        LR 0.100000    Time 0.291282    
2024-04-23 15:50:46,883 - Epoch: [0][  150/  267]    Overall Loss 3.664654    Objective Loss 3.664654                                        LR 0.100000    Time 0.289699    
2024-04-23 15:50:50,126 - Epoch: [0][  160/  267]    Overall Loss 3.647513    Objective Loss 3.647513                                        LR 0.100000    Time 0.291840    
2024-04-23 15:50:52,375 - Epoch: [0][  170/  267]    Overall Loss 3.655645    Objective Loss 3.655645                                        LR 0.100000    Time 0.287872    
2024-04-23 15:50:55,447 - Epoch: [0][  180/  267]    Overall Loss 3.659054    Objective Loss 3.659054                                        LR 0.100000    Time 0.288931    
2024-04-23 15:50:56,985 - Epoch: [0][  200/  296]    Overall Loss 2.130468    Objective Loss 2.130468                                        LR 0.000320    Time 0.276145    
2024-04-23 15:50:57,189 - Epoch: [0][  190/  267]    Overall Loss 3.647291    Objective Loss 3.647291                                        LR 0.100000    Time 0.282878    
2024-04-23 15:51:00,626 - Epoch: [0][  200/  267]    Overall Loss 3.642194    Objective Loss 3.642194                                        LR 0.100000    Time 0.285901    
2024-04-23 15:51:02,910 - Epoch: [0][  210/  267]    Overall Loss 3.610030    Objective Loss 3.610030                                        LR 0.100000    Time 0.283143    
2024-04-23 15:51:07,175 - Epoch: [0][  220/  267]    Overall Loss 3.571399    Objective Loss 3.571399                                        LR 0.100000    Time 0.289645    
2024-04-23 15:51:09,478 - Epoch: [0][  230/  267]    Overall Loss 3.547338    Objective Loss 3.547338                                        LR 0.100000    Time 0.287051    
2024-04-23 15:51:12,713 - Epoch: [0][  240/  267]    Overall Loss 3.524152    Objective Loss 3.524152                                        LR 0.100000    Time 0.288538    
2024-04-23 15:51:14,793 - Epoch: [0][  250/  267]    Overall Loss 3.502770    Objective Loss 3.502770                                        LR 0.100000    Time 0.285300    
2024-04-23 15:51:17,588 - Epoch: [0][  260/  267]    Overall Loss 3.485828    Objective Loss 3.485828                                        LR 0.100000    Time 0.285065    
2024-04-23 15:51:18,733 - Epoch: [0][  267/  267]    Overall Loss 3.480910    Objective Loss 3.480910    Top1 9.302326    Top5 53.488372    LR 0.100000    Time 0.281871    
2024-04-23 15:51:18,965 - --- validate (epoch=0)-----------
2024-04-23 15:51:18,967 - 946 samples (32 per mini-batch)
2024-04-23 15:51:22,995 - Epoch: [0][  296/  296]    Overall Loss 2.076998    Objective Loss 2.076998    Top1 37.704918    Top5 86.885246    LR 0.000320    Time 0.274399    
2024-04-23 15:51:23,306 - --- validate (epoch=0)-----------
2024-04-23 15:51:23,307 - 3925 samples (32 per mini-batch)
2024-04-23 15:51:23,305 - Epoch: [0][   10/   30]    Loss 2.868780    Top1 11.562500    Top5 50.312500    
2024-04-23 15:51:25,660 - Epoch: [0][   20/   30]    Loss 2.809534    Top1 11.875000    Top5 52.812500    
2024-04-23 15:51:28,204 - Epoch: [0][   30/   30]    Loss 2.836633    Top1 10.570825    Top5 52.431290    
2024-04-23 15:51:28,423 - ==> Top1: 10.571    Top5: 52.431    Loss: 2.837

2024-04-23 15:51:28,426 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 15:51:28,431 - ==> Best [Top1: 10.571   Top5: 52.431   Sparsity:0.00   Params: 96528 on epoch: 0]
2024-04-23 15:51:28,432 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 15:51:28,453 - 

2024-04-23 15:51:28,454 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 15:51:32,806 - Epoch: [1][   10/  267]    Overall Loss 2.950195    Objective Loss 2.950195                                        LR 0.100000    Time 0.434751    
2024-04-23 15:51:36,125 - Epoch: [1][   20/  267]    Overall Loss 3.110533    Objective Loss 3.110533                                        LR 0.100000    Time 0.383019    
2024-04-23 15:51:38,829 - Epoch: [0][  100/  123]    Loss 1.879097    Top1 37.156250    Top5 84.343750    
2024-04-23 15:51:40,215 - Epoch: [1][   30/  267]    Overall Loss 3.256479    Objective Loss 3.256479                                        LR 0.100000    Time 0.391525    
2024-04-23 15:51:42,700 - Epoch: [0][  123/  123]    Loss 1.880537    Top1 37.375796    Top5 84.535032    
2024-04-23 15:51:42,893 - Epoch: [1][   40/  267]    Overall Loss 3.196098    Objective Loss 3.196098                                        LR 0.100000    Time 0.360478    
2024-04-23 15:51:42,978 - ==> Top1: 37.376    Top5: 84.535    Loss: 1.881

2024-04-23 15:51:42,984 - ==> Best [Top1: 37.376   Top5: 84.535   Sparsity:0.00   Params: 376752 on epoch: 0]
2024-04-23 15:51:42,985 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 15:51:43,032 - 

2024-04-23 15:51:43,032 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:51:46,130 - Epoch: [1][   50/  267]    Overall Loss 3.193182    Objective Loss 3.193182                                        LR 0.100000    Time 0.353044    
2024-04-23 15:51:48,710 - Epoch: [1][   60/  267]    Overall Loss 3.194942    Objective Loss 3.194942                                        LR 0.100000    Time 0.337134    
2024-04-23 15:51:52,543 - Epoch: [1][   70/  267]    Overall Loss 3.193262    Objective Loss 3.193262                                        LR 0.100000    Time 0.343616    
2024-04-23 15:51:54,916 - Epoch: [1][   80/  267]    Overall Loss 3.186883    Objective Loss 3.186883                                        LR 0.100000    Time 0.330263    
2024-04-23 15:51:57,683 - Epoch: [1][   90/  267]    Overall Loss 3.204020    Objective Loss 3.204020                                        LR 0.100000    Time 0.324285    
2024-04-23 15:51:59,752 - Epoch: [1][  100/  267]    Overall Loss 3.181526    Objective Loss 3.181526                                        LR 0.100000    Time 0.312513    
2024-04-23 15:52:02,163 - Epoch: [1][  100/  296]    Overall Loss 1.878940    Objective Loss 1.878940                                        LR 0.000320    Time 0.191098    
2024-04-23 15:52:03,399 - Epoch: [1][  110/  267]    Overall Loss 3.309331    Objective Loss 3.309331                                        LR 0.100000    Time 0.317224    
2024-04-23 15:52:05,721 - Epoch: [1][  120/  267]    Overall Loss 3.668343    Objective Loss 3.668343                                        LR 0.100000    Time 0.310117    
2024-04-23 15:52:09,071 - Epoch: [1][  130/  267]    Overall Loss 4.078298    Objective Loss 4.078298                                        LR 0.100000    Time 0.312003    
2024-04-23 15:52:11,201 - Epoch: [1][  140/  267]    Overall Loss 4.491076    Objective Loss 4.491076                                        LR 0.100000    Time 0.304906    
2024-04-23 15:52:14,369 - Epoch: [1][  150/  267]    Overall Loss 4.665061    Objective Loss 4.665061                                        LR 0.100000    Time 0.305672    
2024-04-23 15:52:16,839 - Epoch: [1][  160/  267]    Overall Loss 4.716716    Objective Loss 4.716716                                        LR 0.100000    Time 0.301984    
2024-04-23 15:52:19,625 - Epoch: [1][  170/  267]    Overall Loss 4.734360    Objective Loss 4.734360                                        LR 0.100000    Time 0.300592    
2024-04-23 15:52:21,810 - Epoch: [1][  200/  296]    Overall Loss 1.854387    Objective Loss 1.854387                                        LR 0.000320    Time 0.193678    
2024-04-23 15:52:22,946 - Epoch: [1][  180/  267]    Overall Loss 4.696785    Objective Loss 4.696785                                        LR 0.100000    Time 0.302321    
2024-04-23 15:52:26,258 - Epoch: [1][  190/  267]    Overall Loss 4.639518    Objective Loss 4.639518                                        LR 0.100000    Time 0.303816    
2024-04-23 15:52:29,399 - Epoch: [1][  200/  267]    Overall Loss 4.595429    Objective Loss 4.595429                                        LR 0.100000    Time 0.304309    
2024-04-23 15:52:32,270 - Epoch: [1][  210/  267]    Overall Loss 4.529907    Objective Loss 4.529907                                        LR 0.100000    Time 0.303472    
2024-04-23 15:52:35,272 - Epoch: [1][  220/  267]    Overall Loss 4.464546    Objective Loss 4.464546                                        LR 0.100000    Time 0.303306    
2024-04-23 15:52:37,253 - Epoch: [1][  230/  267]    Overall Loss 4.396845    Objective Loss 4.396845                                        LR 0.100000    Time 0.298723    
2024-04-23 15:52:39,574 - Epoch: [1][  240/  267]    Overall Loss 4.353533    Objective Loss 4.353533                                        LR 0.100000    Time 0.295932    
2024-04-23 15:52:39,998 - Epoch: [1][  296/  296]    Overall Loss 1.828915    Objective Loss 1.828915    Top1 45.901639    Top5 83.606557    LR 0.000320    Time 0.192246    
2024-04-23 15:52:40,270 - --- validate (epoch=1)-----------
2024-04-23 15:52:40,271 - 3925 samples (32 per mini-batch)
2024-04-23 15:52:41,492 - Epoch: [1][  250/  267]    Overall Loss 4.315302    Objective Loss 4.315302                                        LR 0.100000    Time 0.291759    
2024-04-23 15:52:44,232 - Epoch: [1][  260/  267]    Overall Loss 4.294162    Objective Loss 4.294162                                        LR 0.100000    Time 0.291069    
2024-04-23 15:52:46,457 - Epoch: [1][  267/  267]    Overall Loss 4.387903    Objective Loss 4.387903    Top1 18.604651    Top5 58.139535    LR 0.100000    Time 0.291767    
2024-04-23 15:52:46,616 - --- validate (epoch=1)-----------
2024-04-23 15:52:46,617 - 946 samples (32 per mini-batch)
2024-04-23 15:52:50,396 - Epoch: [1][   10/   30]    Loss 11.803951    Top1 11.562500    Top5 54.062500    
2024-04-23 15:52:52,764 - Epoch: [1][   20/   30]    Loss 12.410698    Top1 9.843750    Top5 49.531250    
2024-04-23 15:52:56,016 - Epoch: [1][   30/   30]    Loss 12.234695    Top1 10.359408    Top5 49.682875    
2024-04-23 15:52:56,214 - ==> Top1: 10.359    Top5: 49.683    Loss: 12.235

2024-04-23 15:52:56,216 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 15:52:56,219 - ==> Best [Top1: 10.571   Top5: 52.431   Sparsity:0.00   Params: 96528 on epoch: 0]
2024-04-23 15:52:56,219 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 15:52:56,242 - 

2024-04-23 15:52:56,242 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 15:52:59,330 - Epoch: [2][   10/  267]    Overall Loss 10.275883    Objective Loss 10.275883                                        LR 0.100000    Time 0.308411    
2024-04-23 15:53:01,306 - Epoch: [2][   20/  267]    Overall Loss 8.361982    Objective Loss 8.361982                                        LR 0.100000    Time 0.252825    
2024-04-23 15:53:04,100 - Epoch: [2][   30/  267]    Overall Loss 7.168169    Objective Loss 7.168169                                        LR 0.100000    Time 0.261561    
2024-04-23 15:53:06,190 - Epoch: [2][   40/  267]    Overall Loss 6.273445    Objective Loss 6.273445                                        LR 0.100000    Time 0.248333    
2024-04-23 15:53:08,484 - Epoch: [2][   50/  267]    Overall Loss 5.742023    Objective Loss 5.742023                                        LR 0.100000    Time 0.244472    
2024-04-23 15:53:10,089 - Epoch: [1][  100/  123]    Loss 1.690486    Top1 42.125000    Top5 88.250000    
2024-04-23 15:53:10,975 - Epoch: [2][   60/  267]    Overall Loss 5.365223    Objective Loss 5.365223                                        LR 0.100000    Time 0.245194    
2024-04-23 15:53:13,138 - Epoch: [2][   70/  267]    Overall Loss 5.144022    Objective Loss 5.144022                                        LR 0.100000    Time 0.241033    
2024-04-23 15:53:15,820 - Epoch: [1][  123/  123]    Loss 1.698057    Top1 41.732484    Top5 88.076433    
2024-04-23 15:53:16,048 - ==> Top1: 41.732    Top5: 88.076    Loss: 1.698

2024-04-23 15:53:16,056 - ==> Best [Top1: 41.732   Top5: 88.076   Sparsity:0.00   Params: 376752 on epoch: 1]
2024-04-23 15:53:16,057 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 15:53:16,124 - 

2024-04-23 15:53:16,125 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:53:16,179 - Epoch: [2][   80/  267]    Overall Loss 4.881358    Objective Loss 4.881358                                        LR 0.100000    Time 0.248870    
2024-04-23 15:53:18,304 - Epoch: [2][   90/  267]    Overall Loss 4.713151    Objective Loss 4.713151                                        LR 0.100000    Time 0.244800    
2024-04-23 15:53:21,073 - Epoch: [2][  100/  267]    Overall Loss 4.586389    Objective Loss 4.586389                                        LR 0.100000    Time 0.247975    
2024-04-23 15:53:23,092 - Epoch: [2][  110/  267]    Overall Loss 4.520905    Objective Loss 4.520905                                        LR 0.100000    Time 0.243759    
2024-04-23 15:53:25,675 - Epoch: [2][  120/  267]    Overall Loss 4.406267    Objective Loss 4.406267                                        LR 0.100000    Time 0.244951    
2024-04-23 15:53:28,497 - Epoch: [2][  130/  267]    Overall Loss 4.302228    Objective Loss 4.302228                                        LR 0.100000    Time 0.247791    
2024-04-23 15:53:30,993 - Epoch: [2][  140/  267]    Overall Loss 4.216164    Objective Loss 4.216164                                        LR 0.100000    Time 0.247891    
2024-04-23 15:53:33,708 - Epoch: [2][  150/  267]    Overall Loss 4.126016    Objective Loss 4.126016                                        LR 0.100000    Time 0.249447    
2024-04-23 15:53:35,238 - Epoch: [2][  160/  267]    Overall Loss 4.070332    Objective Loss 4.070332                                        LR 0.100000    Time 0.243393    
2024-04-23 15:53:37,634 - Epoch: [2][  170/  267]    Overall Loss 4.070170    Objective Loss 4.070170                                        LR 0.100000    Time 0.243151    
2024-04-23 15:53:39,635 - Epoch: [2][  180/  267]    Overall Loss 4.125757    Objective Loss 4.125757                                        LR 0.100000    Time 0.240742    
2024-04-23 15:53:40,586 - Epoch: [2][  100/  296]    Overall Loss 1.711505    Objective Loss 1.711505                                        LR 0.000320    Time 0.244396    
2024-04-23 15:53:42,707 - Epoch: [2][  190/  267]    Overall Loss 4.144097    Objective Loss 4.144097                                        LR 0.100000    Time 0.244221    
2024-04-23 15:53:44,643 - Epoch: [2][  200/  267]    Overall Loss 4.331526    Objective Loss 4.331526                                        LR 0.100000    Time 0.241673    
2024-04-23 15:53:47,209 - Epoch: [2][  210/  267]    Overall Loss 4.756257    Objective Loss 4.756257                                        LR 0.100000    Time 0.242367    
2024-04-23 15:53:49,409 - Epoch: [2][  220/  267]    Overall Loss 5.120649    Objective Loss 5.120649                                        LR 0.100000    Time 0.241330    
2024-04-23 15:53:52,291 - Epoch: [2][  230/  267]    Overall Loss 5.507799    Objective Loss 5.507799                                        LR 0.100000    Time 0.243357    
2024-04-23 15:53:54,262 - Epoch: [2][  240/  267]    Overall Loss 5.668618    Objective Loss 5.668618                                        LR 0.100000    Time 0.241418    
2024-04-23 15:53:57,333 - Epoch: [2][  250/  267]    Overall Loss 5.758692    Objective Loss 5.758692                                        LR 0.100000    Time 0.244031    
2024-04-23 15:53:59,186 - Epoch: [2][  260/  267]    Overall Loss 5.777305    Objective Loss 5.777305                                        LR 0.100000    Time 0.241758    
2024-04-23 15:54:00,668 - Epoch: [2][  267/  267]    Overall Loss 5.829231    Objective Loss 5.829231    Top1 16.279070    Top5 53.488372    LR 0.100000    Time 0.240958    
2024-04-23 15:54:00,955 - --- validate (epoch=2)-----------
2024-04-23 15:54:00,957 - 946 samples (32 per mini-batch)
2024-04-23 15:54:04,712 - Epoch: [2][  200/  296]    Overall Loss 1.689443    Objective Loss 1.689443                                        LR 0.000320    Time 0.242726    
2024-04-23 15:54:04,966 - Epoch: [2][   10/   30]    Loss 12.220268    Top1 8.437500    Top5 45.937500    
2024-04-23 15:54:06,953 - Epoch: [2][   20/   30]    Loss 11.986575    Top1 9.687500    Top5 47.656250    
2024-04-23 15:54:09,692 - Epoch: [2][   30/   30]    Loss 11.901935    Top1 10.253700    Top5 48.731501    
2024-04-23 15:54:09,868 - ==> Top1: 10.254    Top5: 48.732    Loss: 11.902

2024-04-23 15:54:09,870 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 15:54:09,874 - ==> Best [Top1: 10.571   Top5: 52.431   Sparsity:0.00   Params: 96528 on epoch: 0]
2024-04-23 15:54:09,874 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 15:54:09,894 - 

2024-04-23 15:54:09,896 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 15:54:14,444 - Epoch: [3][   10/  267]    Overall Loss 8.442426    Objective Loss 8.442426                                        LR 0.100000    Time 0.454497    
2024-04-23 15:54:16,550 - Epoch: [3][   20/  267]    Overall Loss 6.459379    Objective Loss 6.459379                                        LR 0.100000    Time 0.332388    
2024-04-23 15:54:19,573 - Epoch: [3][   30/  267]    Overall Loss 5.711184    Objective Loss 5.711184                                        LR 0.100000    Time 0.322232    
2024-04-23 15:54:22,028 - Epoch: [3][   40/  267]    Overall Loss 5.377367    Objective Loss 5.377367                                        LR 0.100000    Time 0.302989    
2024-04-23 15:54:25,240 - Epoch: [3][   50/  267]    Overall Loss 5.192012    Objective Loss 5.192012                                        LR 0.100000    Time 0.306563    
2024-04-23 15:54:25,484 - Epoch: [2][  296/  296]    Overall Loss 1.686387    Objective Loss 1.686387    Top1 40.983607    Top5 90.163934    LR 0.000320    Time 0.234115    
2024-04-23 15:54:25,700 - --- validate (epoch=2)-----------
2024-04-23 15:54:25,702 - 3925 samples (32 per mini-batch)
2024-04-23 15:54:27,280 - Epoch: [3][   60/  267]    Overall Loss 5.072653    Objective Loss 5.072653                                        LR 0.100000    Time 0.289363    
2024-04-23 15:54:30,348 - Epoch: [3][   70/  267]    Overall Loss 4.946686    Objective Loss 4.946686                                        LR 0.100000    Time 0.291771    
2024-04-23 15:54:32,724 - Epoch: [3][   80/  267]    Overall Loss 4.831984    Objective Loss 4.831984                                        LR 0.100000    Time 0.284944    
2024-04-23 15:54:36,090 - Epoch: [3][   90/  267]    Overall Loss 4.667257    Objective Loss 4.667257                                        LR 0.100000    Time 0.290647    
2024-04-23 15:54:38,415 - Epoch: [3][  100/  267]    Overall Loss 4.564794    Objective Loss 4.564794                                        LR 0.100000    Time 0.284798    
2024-04-23 15:54:41,893 - Epoch: [3][  110/  267]    Overall Loss 4.425146    Objective Loss 4.425146                                        LR 0.100000    Time 0.290492    
2024-04-23 15:54:43,946 - Epoch: [3][  120/  267]    Overall Loss 4.302861    Objective Loss 4.302861                                        LR 0.100000    Time 0.283362    
2024-04-23 15:54:47,060 - Epoch: [3][  130/  267]    Overall Loss 4.209286    Objective Loss 4.209286                                        LR 0.100000    Time 0.285490    
2024-04-23 15:54:47,358 - Epoch: [2][  100/  123]    Loss 2.063895    Top1 34.718750    Top5 75.375000    
2024-04-23 15:54:49,020 - Epoch: [3][  140/  267]    Overall Loss 4.120116    Objective Loss 4.120116                                        LR 0.100000    Time 0.279074    
2024-04-23 15:54:52,101 - Epoch: [3][  150/  267]    Overall Loss 4.053647    Objective Loss 4.053647                                        LR 0.100000    Time 0.280982    
2024-04-23 15:54:52,956 - Epoch: [2][  123/  123]    Loss 2.070431    Top1 34.165605    Top5 75.261146    
2024-04-23 15:54:53,111 - ==> Top1: 34.166    Top5: 75.261    Loss: 2.070

2024-04-23 15:54:53,119 - ==> Best [Top1: 41.732   Top5: 88.076   Sparsity:0.00   Params: 376752 on epoch: 1]
2024-04-23 15:54:53,120 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 15:54:53,164 - 

2024-04-23 15:54:53,165 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:54:54,239 - Epoch: [3][  160/  267]    Overall Loss 3.975479    Objective Loss 3.975479                                        LR 0.100000    Time 0.276764    
2024-04-23 15:54:57,142 - Epoch: [3][  170/  267]    Overall Loss 3.915409    Objective Loss 3.915409                                        LR 0.100000    Time 0.277541    
2024-04-23 15:54:58,928 - Epoch: [3][  180/  267]    Overall Loss 3.862185    Objective Loss 3.862185                                        LR 0.100000    Time 0.272031    
2024-04-23 15:55:01,807 - Epoch: [3][  190/  267]    Overall Loss 3.826675    Objective Loss 3.826675                                        LR 0.100000    Time 0.272852    
2024-04-23 15:55:04,366 - Epoch: [3][  200/  267]    Overall Loss 3.791741    Objective Loss 3.791741                                        LR 0.100000    Time 0.271989    
2024-04-23 15:55:07,271 - Epoch: [3][  210/  267]    Overall Loss 3.764324    Objective Loss 3.764324                                        LR 0.100000    Time 0.272851    
2024-04-23 15:55:08,659 - Epoch: [3][  220/  267]    Overall Loss 3.740910    Objective Loss 3.740910                                        LR 0.100000    Time 0.266745    
2024-04-23 15:55:11,621 - Epoch: [3][  230/  267]    Overall Loss 3.722066    Objective Loss 3.722066                                        LR 0.100000    Time 0.268015    
2024-04-23 15:55:13,706 - Epoch: [3][  240/  267]    Overall Loss 3.700640    Objective Loss 3.700640                                        LR 0.100000    Time 0.265519    
2024-04-23 15:55:15,577 - Epoch: [3][  100/  296]    Overall Loss 1.605135    Objective Loss 1.605135                                        LR 0.000320    Time 0.223902    
2024-04-23 15:55:16,211 - Epoch: [3][  250/  267]    Overall Loss 3.732737    Objective Loss 3.732737                                        LR 0.100000    Time 0.264906    
2024-04-23 15:55:18,208 - Epoch: [3][  260/  267]    Overall Loss 3.745959    Objective Loss 3.745959                                        LR 0.100000    Time 0.262381    
2024-04-23 15:55:20,190 - Epoch: [3][  267/  267]    Overall Loss 3.735509    Objective Loss 3.735509    Top1 11.627907    Top5 51.162791    LR 0.100000    Time 0.262915    
2024-04-23 15:55:20,444 - --- validate (epoch=3)-----------
2024-04-23 15:55:20,445 - 946 samples (32 per mini-batch)
2024-04-23 15:55:23,626 - Epoch: [3][   10/   30]    Loss 2.901986    Top1 9.375000    Top5 51.250000    
2024-04-23 15:55:25,577 - Epoch: [3][   20/   30]    Loss 2.934562    Top1 9.531250    Top5 48.750000    
2024-04-23 15:55:27,831 - Epoch: [3][   30/   30]    Loss 2.919040    Top1 9.830867    Top5 49.365751    
2024-04-23 15:55:28,027 - ==> Top1: 9.831    Top5: 49.366    Loss: 2.919

2024-04-23 15:55:28,028 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 15:55:28,032 - ==> Best [Top1: 10.571   Top5: 52.431   Sparsity:0.00   Params: 96528 on epoch: 0]
2024-04-23 15:55:28,033 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 15:55:28,044 - 

2024-04-23 15:55:28,045 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 15:55:31,943 - Epoch: [4][   10/  267]    Overall Loss 2.858631    Objective Loss 2.858631                                        LR 0.100000    Time 0.389327    
2024-04-23 15:55:34,233 - Epoch: [4][   20/  267]    Overall Loss 2.858893    Objective Loss 2.858893                                        LR 0.100000    Time 0.308982    
2024-04-23 15:55:36,900 - Epoch: [3][  200/  296]    Overall Loss 1.597916    Objective Loss 1.597916                                        LR 0.000320    Time 0.218444    
2024-04-23 15:55:37,718 - Epoch: [4][   30/  267]    Overall Loss 2.828869    Objective Loss 2.828869                                        LR 0.100000    Time 0.322025    
2024-04-23 15:55:39,813 - Epoch: [4][   40/  267]    Overall Loss 2.837317    Objective Loss 2.837317                                        LR 0.100000    Time 0.293817    
2024-04-23 15:55:42,883 - Epoch: [4][   50/  267]    Overall Loss 2.841237    Objective Loss 2.841237                                        LR 0.100000    Time 0.296393    
2024-04-23 15:55:45,046 - Epoch: [4][   60/  267]    Overall Loss 2.830533    Objective Loss 2.830533                                        LR 0.100000    Time 0.282995    
2024-04-23 15:55:48,188 - Epoch: [4][   70/  267]    Overall Loss 2.853207    Objective Loss 2.853207                                        LR 0.100000    Time 0.287412    
2024-04-23 15:55:50,243 - Epoch: [4][   80/  267]    Overall Loss 2.906022    Objective Loss 2.906022                                        LR 0.100000    Time 0.277125    
2024-04-23 15:55:53,367 - Epoch: [4][   90/  267]    Overall Loss 2.893167    Objective Loss 2.893167                                        LR 0.100000    Time 0.281015    
2024-04-23 15:55:55,428 - Epoch: [4][  100/  267]    Overall Loss 2.889021    Objective Loss 2.889021                                        LR 0.100000    Time 0.273493    
2024-04-23 15:55:58,491 - Epoch: [4][  110/  267]    Overall Loss 2.898613    Objective Loss 2.898613                                        LR 0.100000    Time 0.276450    
2024-04-23 15:56:00,560 - Epoch: [4][  120/  267]    Overall Loss 2.895488    Objective Loss 2.895488                                        LR 0.100000    Time 0.270633    
2024-04-23 15:56:01,536 - Epoch: [3][  296/  296]    Overall Loss 1.592214    Objective Loss 1.592214    Top1 44.262295    Top5 83.606557    LR 0.000320    Time 0.230759    
2024-04-23 15:56:01,806 - --- validate (epoch=3)-----------
2024-04-23 15:56:01,808 - 3925 samples (32 per mini-batch)
2024-04-23 15:56:03,160 - Epoch: [4][  130/  267]    Overall Loss 2.904735    Objective Loss 2.904735                                        LR 0.100000    Time 0.269787    
2024-04-23 15:56:05,547 - Epoch: [4][  140/  267]    Overall Loss 2.905638    Objective Loss 2.905638                                        LR 0.100000    Time 0.267545    
2024-04-23 15:56:08,684 - Epoch: [4][  150/  267]    Overall Loss 2.895237    Objective Loss 2.895237                                        LR 0.100000    Time 0.270600    
2024-04-23 15:56:10,404 - Epoch: [4][  160/  267]    Overall Loss 2.890420    Objective Loss 2.890420                                        LR 0.100000    Time 0.264416    
2024-04-23 15:56:13,082 - Epoch: [4][  170/  267]    Overall Loss 2.898216    Objective Loss 2.898216                                        LR 0.100000    Time 0.264597    
2024-04-23 15:56:15,697 - Epoch: [4][  180/  267]    Overall Loss 2.924222    Objective Loss 2.924222                                        LR 0.100000    Time 0.264407    
2024-04-23 15:56:18,364 - Epoch: [4][  190/  267]    Overall Loss 2.954864    Objective Loss 2.954864                                        LR 0.100000    Time 0.264506    
2024-04-23 15:56:20,430 - Epoch: [4][  200/  267]    Overall Loss 2.975562    Objective Loss 2.975562                                        LR 0.100000    Time 0.261596    
2024-04-23 15:56:22,977 - Epoch: [4][  210/  267]    Overall Loss 2.991478    Objective Loss 2.991478                                        LR 0.100000    Time 0.261252    
2024-04-23 15:56:25,970 - Epoch: [4][  220/  267]    Overall Loss 3.001278    Objective Loss 3.001278                                        LR 0.100000    Time 0.262968    
2024-04-23 15:56:27,686 - Epoch: [4][  230/  267]    Overall Loss 3.004076    Objective Loss 3.004076                                        LR 0.100000    Time 0.258981    
2024-04-23 15:56:29,785 - Epoch: [3][  100/  123]    Loss 1.965199    Top1 34.218750    Top5 85.218750    
2024-04-23 15:56:30,516 - Epoch: [4][  240/  267]    Overall Loss 3.000271    Objective Loss 3.000271                                        LR 0.100000    Time 0.259970    
2024-04-23 15:56:32,271 - Epoch: [4][  250/  267]    Overall Loss 2.997999    Objective Loss 2.997999                                        LR 0.100000    Time 0.256579    
2024-04-23 15:56:34,953 - Epoch: [4][  260/  267]    Overall Loss 2.990046    Objective Loss 2.990046                                        LR 0.100000    Time 0.257005    
2024-04-23 15:56:35,338 - Epoch: [3][  123/  123]    Loss 1.968493    Top1 34.012739    Top5 85.324841    
2024-04-23 15:56:35,501 - ==> Top1: 34.013    Top5: 85.325    Loss: 1.968

2024-04-23 15:56:35,507 - ==> Best [Top1: 41.732   Top5: 88.076   Sparsity:0.00   Params: 376752 on epoch: 1]
2024-04-23 15:56:35,507 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 15:56:35,547 - 

2024-04-23 15:56:35,547 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:56:35,556 - Epoch: [4][  267/  267]    Overall Loss 2.989717    Objective Loss 2.989717    Top1 2.325581    Top5 51.162791    LR 0.100000    Time 0.252521    
2024-04-23 15:56:35,734 - --- validate (epoch=4)-----------
2024-04-23 15:56:35,735 - 946 samples (32 per mini-batch)
2024-04-23 15:56:39,184 - Epoch: [4][   10/   30]    Loss 2.598970    Top1 10.625000    Top5 50.625000    
2024-04-23 15:56:41,229 - Epoch: [4][   20/   30]    Loss 2.569802    Top1 11.250000    Top5 50.937500    
2024-04-23 15:56:43,759 - Epoch: [4][   30/   30]    Loss 2.592073    Top1 10.042283    Top5 49.577167    
2024-04-23 15:56:43,951 - ==> Top1: 10.042    Top5: 49.577    Loss: 2.592

2024-04-23 15:56:43,953 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 15:56:43,958 - ==> Best [Top1: 10.571   Top5: 52.431   Sparsity:0.00   Params: 96528 on epoch: 0]
2024-04-23 15:56:43,959 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 15:56:43,976 - 

2024-04-23 15:56:43,977 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 15:56:47,695 - Epoch: [5][   10/  267]    Overall Loss 3.254997    Objective Loss 3.254997                                        LR 0.100000    Time 0.371381    
2024-04-23 15:56:49,999 - Epoch: [5][   20/  267]    Overall Loss 3.020662    Objective Loss 3.020662                                        LR 0.100000    Time 0.300703    
2024-04-23 15:56:52,220 - Epoch: [5][   30/  267]    Overall Loss 3.041450    Objective Loss 3.041450                                        LR 0.100000    Time 0.274401    
2024-04-23 15:56:55,133 - Epoch: [5][   40/  267]    Overall Loss 3.190315    Objective Loss 3.190315                                        LR 0.100000    Time 0.278567    
2024-04-23 15:56:57,544 - Epoch: [5][   50/  267]    Overall Loss 3.182321    Objective Loss 3.182321                                        LR 0.100000    Time 0.271012    
2024-04-23 15:57:00,206 - Epoch: [5][   60/  267]    Overall Loss 3.191922    Objective Loss 3.191922                                        LR 0.100000    Time 0.270149    
2024-04-23 15:57:01,147 - Epoch: [4][  100/  296]    Overall Loss 1.560222    Objective Loss 1.560222                                        LR 0.000320    Time 0.255780    
2024-04-23 15:57:02,272 - Epoch: [5][   70/  267]    Overall Loss 3.185739    Objective Loss 3.185739                                        LR 0.100000    Time 0.261029    
2024-04-23 15:57:05,247 - Epoch: [5][   80/  267]    Overall Loss 3.217342    Objective Loss 3.217342                                        LR 0.100000    Time 0.265559    
2024-04-23 15:57:07,405 - Epoch: [5][   90/  267]    Overall Loss 3.235832    Objective Loss 3.235832                                        LR 0.100000    Time 0.259994    
2024-04-23 15:57:10,634 - Epoch: [5][  100/  267]    Overall Loss 3.237468    Objective Loss 3.237468                                        LR 0.100000    Time 0.266256    
2024-04-23 15:57:12,582 - Epoch: [5][  110/  267]    Overall Loss 3.235565    Objective Loss 3.235565                                        LR 0.100000    Time 0.259731    
2024-04-23 15:57:15,246 - Epoch: [5][  120/  267]    Overall Loss 3.229556    Objective Loss 3.229556                                        LR 0.100000    Time 0.260264    
2024-04-23 15:57:16,981 - Epoch: [5][  130/  267]    Overall Loss 3.199763    Objective Loss 3.199763                                        LR 0.100000    Time 0.253566    
2024-04-23 15:57:20,337 - Epoch: [5][  140/  267]    Overall Loss 3.176091    Objective Loss 3.176091                                        LR 0.100000    Time 0.259403    
2024-04-23 15:57:22,463 - Epoch: [5][  150/  267]    Overall Loss 3.167974    Objective Loss 3.167974                                        LR 0.100000    Time 0.256259    
2024-04-23 15:57:25,036 - Epoch: [4][  200/  296]    Overall Loss 1.548872    Objective Loss 1.548872                                        LR 0.000320    Time 0.247226    
2024-04-23 15:57:25,136 - Epoch: [5][  160/  267]    Overall Loss 3.185044    Objective Loss 3.185044                                        LR 0.100000    Time 0.256920    
2024-04-23 15:57:27,201 - Epoch: [5][  170/  267]    Overall Loss 3.191653    Objective Loss 3.191653                                        LR 0.100000    Time 0.253933    
2024-04-23 15:57:30,488 - Epoch: [5][  180/  267]    Overall Loss 3.204401    Objective Loss 3.204401                                        LR 0.100000    Time 0.258066    
2024-04-23 15:57:32,736 - Epoch: [5][  190/  267]    Overall Loss 3.207269    Objective Loss 3.207269                                        LR 0.100000    Time 0.256297    
2024-04-23 15:57:35,318 - Epoch: [5][  200/  267]    Overall Loss 3.212759    Objective Loss 3.212759                                        LR 0.100000    Time 0.256376    
2024-04-23 15:57:37,593 - Epoch: [5][  210/  267]    Overall Loss 3.207066    Objective Loss 3.207066                                        LR 0.100000    Time 0.254987    
2024-04-23 15:57:39,634 - Epoch: [5][  220/  267]    Overall Loss 3.179647    Objective Loss 3.179647                                        LR 0.100000    Time 0.252658    
2024-04-23 15:57:41,678 - Epoch: [5][  230/  267]    Overall Loss 3.160149    Objective Loss 3.160149                                        LR 0.100000    Time 0.250547    
2024-04-23 15:57:44,540 - Epoch: [5][  240/  267]    Overall Loss 3.149453    Objective Loss 3.149453                                        LR 0.100000    Time 0.252019    
2024-04-23 15:57:46,633 - Epoch: [5][  250/  267]    Overall Loss 3.148071    Objective Loss 3.148071                                        LR 0.100000    Time 0.250294    
2024-04-23 15:57:47,601 - Epoch: [4][  296/  296]    Overall Loss 1.541677    Objective Loss 1.541677    Top1 63.934426    Top5 88.524590    LR 0.000320    Time 0.243209    
2024-04-23 15:57:48,060 - --- validate (epoch=4)-----------
2024-04-23 15:57:48,061 - 3925 samples (32 per mini-batch)
2024-04-23 15:57:49,306 - Epoch: [5][  260/  267]    Overall Loss 3.134822    Objective Loss 3.134822                                        LR 0.100000    Time 0.250939    
2024-04-23 15:57:50,615 - Epoch: [5][  267/  267]    Overall Loss 3.132860    Objective Loss 3.132860    Top1 9.302326    Top5 44.186047    LR 0.100000    Time 0.249254    
2024-04-23 15:57:50,885 - --- validate (epoch=5)-----------
2024-04-23 15:57:50,887 - 946 samples (32 per mini-batch)
2024-04-23 15:57:54,762 - Epoch: [5][   10/   30]    Loss 3.185258    Top1 7.812500    Top5 48.437500    
2024-04-23 15:57:56,956 - Epoch: [5][   20/   30]    Loss 3.215859    Top1 8.281250    Top5 47.656250    
2024-04-23 15:57:59,509 - Epoch: [5][   30/   30]    Loss 3.178537    Top1 8.456660    Top5 48.837209    
2024-04-23 15:57:59,712 - ==> Top1: 8.457    Top5: 48.837    Loss: 3.179

2024-04-23 15:57:59,714 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 15:57:59,719 - ==> Best [Top1: 10.571   Top5: 52.431   Sparsity:0.00   Params: 96528 on epoch: 0]
2024-04-23 15:57:59,719 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 15:57:59,735 - 

2024-04-23 15:57:59,736 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 15:58:04,323 - Epoch: [6][   10/  267]    Overall Loss 3.376797    Objective Loss 3.376797                                        LR 0.100000    Time 0.458218    
2024-04-23 15:58:07,239 - Epoch: [6][   20/  267]    Overall Loss 3.489753    Objective Loss 3.489753                                        LR 0.100000    Time 0.374753    
2024-04-23 15:58:10,480 - Epoch: [6][   30/  267]    Overall Loss 3.473508    Objective Loss 3.473508                                        LR 0.100000    Time 0.357601    
2024-04-23 15:58:12,618 - Epoch: [6][   40/  267]    Overall Loss 3.674439    Objective Loss 3.674439                                        LR 0.100000    Time 0.321588    
2024-04-23 15:58:15,620 - Epoch: [6][   50/  267]    Overall Loss 3.681555    Objective Loss 3.681555                                        LR 0.100000    Time 0.317240    
2024-04-23 15:58:16,265 - Epoch: [4][  100/  123]    Loss 1.326204    Top1 56.750000    Top5 91.593750    
2024-04-23 15:58:17,830 - Epoch: [6][   60/  267]    Overall Loss 3.579240    Objective Loss 3.579240                                        LR 0.100000    Time 0.301139    
2024-04-23 15:58:20,900 - Epoch: [6][   70/  267]    Overall Loss 3.516834    Objective Loss 3.516834                                        LR 0.100000    Time 0.301920    
2024-04-23 15:58:21,931 - Epoch: [4][  123/  123]    Loss 1.325583    Top1 56.815287    Top5 91.745223    
2024-04-23 15:58:22,177 - ==> Top1: 56.815    Top5: 91.745    Loss: 1.326

2024-04-23 15:58:22,182 - ==> Best [Top1: 56.815   Top5: 91.745   Sparsity:0.00   Params: 376752 on epoch: 4]
2024-04-23 15:58:22,183 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 15:58:22,250 - 

2024-04-23 15:58:22,251 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 15:58:22,393 - Epoch: [6][   80/  267]    Overall Loss 3.457443    Objective Loss 3.457443                                        LR 0.100000    Time 0.282771    
2024-04-23 15:58:25,234 - Epoch: [6][   90/  267]    Overall Loss 3.406019    Objective Loss 3.406019                                        LR 0.100000    Time 0.282887    
2024-04-23 15:58:27,033 - Epoch: [6][  100/  267]    Overall Loss 3.351602    Objective Loss 3.351602                                        LR 0.100000    Time 0.272544    
2024-04-23 15:58:30,037 - Epoch: [6][  110/  267]    Overall Loss 3.335956    Objective Loss 3.335956                                        LR 0.100000    Time 0.275046    
2024-04-23 15:58:32,199 - Epoch: [6][  120/  267]    Overall Loss 3.324489    Objective Loss 3.324489                                        LR 0.100000    Time 0.270116    
2024-04-23 15:58:35,356 - Epoch: [6][  130/  267]    Overall Loss 3.312208    Objective Loss 3.312208                                        LR 0.100000    Time 0.273599    
2024-04-23 15:58:37,393 - Epoch: [6][  140/  267]    Overall Loss 3.300454    Objective Loss 3.300454                                        LR 0.100000    Time 0.268582    
2024-04-23 15:58:40,149 - Epoch: [6][  150/  267]    Overall Loss 3.267609    Objective Loss 3.267609                                        LR 0.100000    Time 0.269028    
2024-04-23 15:58:42,227 - Epoch: [6][  160/  267]    Overall Loss 3.248503    Objective Loss 3.248503                                        LR 0.100000    Time 0.265176    
2024-04-23 15:58:45,334 - Epoch: [6][  170/  267]    Overall Loss 3.244517    Objective Loss 3.244517                                        LR 0.100000    Time 0.267817    
2024-04-23 15:58:47,251 - Epoch: [6][  180/  267]    Overall Loss 3.227367    Objective Loss 3.227367                                        LR 0.100000    Time 0.263568    
2024-04-23 15:58:49,213 - Epoch: [5][  100/  296]    Overall Loss 1.507592    Objective Loss 1.507592                                        LR 0.000320    Time 0.269389    
2024-04-23 15:58:49,674 - Epoch: [6][  190/  267]    Overall Loss 3.220587    Objective Loss 3.220587                                        LR 0.100000    Time 0.262436    
2024-04-23 15:58:52,808 - Epoch: [6][  200/  267]    Overall Loss 3.196167    Objective Loss 3.196167                                        LR 0.100000    Time 0.264962    
2024-04-23 15:58:55,247 - Epoch: [6][  210/  267]    Overall Loss 3.181380    Objective Loss 3.181380                                        LR 0.100000    Time 0.263942    
2024-04-23 15:58:58,539 - Epoch: [6][  220/  267]    Overall Loss 3.164303    Objective Loss 3.164303                                        LR 0.100000    Time 0.266891    
2024-04-23 15:59:00,295 - Epoch: [6][  230/  267]    Overall Loss 3.161181    Objective Loss 3.161181                                        LR 0.100000    Time 0.262909    
2024-04-23 15:59:02,686 - Epoch: [6][  240/  267]    Overall Loss 3.154061    Objective Loss 3.154061                                        LR 0.100000    Time 0.261903    
2024-04-23 15:59:04,819 - Epoch: [6][  250/  267]    Overall Loss 3.140208    Objective Loss 3.140208                                        LR 0.100000    Time 0.259950    
2024-04-23 15:59:07,031 - Epoch: [6][  260/  267]    Overall Loss 3.137870    Objective Loss 3.137870                                        LR 0.100000    Time 0.258443    
2024-04-23 15:59:08,993 - Epoch: [6][  267/  267]    Overall Loss 3.136498    Objective Loss 3.136498    Top1 13.953488    Top5 46.511628    LR 0.100000    Time 0.259006    
2024-04-23 15:59:09,267 - --- validate (epoch=6)-----------
2024-04-23 15:59:09,268 - 946 samples (32 per mini-batch)
2024-04-23 15:59:10,663 - Epoch: [5][  200/  296]    Overall Loss 1.488959    Objective Loss 1.488959                                        LR 0.000320    Time 0.241844    
2024-04-23 15:59:12,560 - Epoch: [6][   10/   30]    Loss 3.597469    Top1 9.687500    Top5 53.750000    
2024-04-23 15:59:14,366 - Epoch: [6][   20/   30]    Loss 3.579342    Top1 10.937500    Top5 53.437500    
2024-04-23 15:59:16,725 - Epoch: [6][   30/   30]    Loss 3.650953    Top1 10.253700    Top5 51.057082    
2024-04-23 15:59:16,947 - ==> Top1: 10.254    Top5: 51.057    Loss: 3.651

2024-04-23 15:59:16,950 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 15:59:16,954 - ==> Best [Top1: 10.571   Top5: 52.431   Sparsity:0.00   Params: 96528 on epoch: 0]
2024-04-23 15:59:16,955 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 15:59:16,976 - 

2024-04-23 15:59:16,977 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 15:59:20,595 - Epoch: [7][   10/  267]    Overall Loss 3.250047    Objective Loss 3.250047                                        LR 0.100000    Time 0.361380    
2024-04-23 15:59:23,319 - Epoch: [7][   20/  267]    Overall Loss 3.047441    Objective Loss 3.047441                                        LR 0.100000    Time 0.316708    
2024-04-23 15:59:25,627 - Epoch: [7][   30/  267]    Overall Loss 3.017227    Objective Loss 3.017227                                        LR 0.100000    Time 0.287942    
2024-04-23 15:59:28,855 - Epoch: [7][   40/  267]    Overall Loss 3.011114    Objective Loss 3.011114                                        LR 0.100000    Time 0.296599    
2024-04-23 15:59:30,769 - Epoch: [7][   50/  267]    Overall Loss 2.964820    Objective Loss 2.964820                                        LR 0.100000    Time 0.275499    
2024-04-23 15:59:32,436 - Epoch: [5][  296/  296]    Overall Loss 1.483286    Objective Loss 1.483286    Top1 40.983607    Top5 86.885246    LR 0.000320    Time 0.236899    
2024-04-23 15:59:32,669 - --- validate (epoch=5)-----------
2024-04-23 15:59:32,670 - 3925 samples (32 per mini-batch)
2024-04-23 15:59:32,761 - Epoch: [7][   60/  267]    Overall Loss 2.949442    Objective Loss 2.949442                                        LR 0.100000    Time 0.262732    
2024-04-23 15:59:34,674 - Epoch: [7][   70/  267]    Overall Loss 2.991338    Objective Loss 2.991338                                        LR 0.100000    Time 0.252486    
2024-04-23 15:59:37,840 - Epoch: [7][   80/  267]    Overall Loss 2.992542    Objective Loss 2.992542                                        LR 0.100000    Time 0.260452    
2024-04-23 15:59:39,855 - Epoch: [7][   90/  267]    Overall Loss 3.266277    Objective Loss 3.266277                                        LR 0.100000    Time 0.253869    
2024-04-23 15:59:42,892 - Epoch: [7][  100/  267]    Overall Loss 3.399206    Objective Loss 3.399206                                        LR 0.100000    Time 0.258813    
2024-04-23 15:59:44,945 - Epoch: [7][  110/  267]    Overall Loss 3.404260    Objective Loss 3.404260                                        LR 0.100000    Time 0.253928    
2024-04-23 15:59:47,731 - Epoch: [7][  120/  267]    Overall Loss 3.354560    Objective Loss 3.354560                                        LR 0.100000    Time 0.255954    
2024-04-23 15:59:50,008 - Epoch: [7][  130/  267]    Overall Loss 3.292198    Objective Loss 3.292198                                        LR 0.100000    Time 0.253757    
2024-04-23 15:59:52,779 - Epoch: [7][  140/  267]    Overall Loss 3.241040    Objective Loss 3.241040                                        LR 0.100000    Time 0.255398    
2024-04-23 15:59:55,131 - Epoch: [7][  150/  267]    Overall Loss 3.197700    Objective Loss 3.197700                                        LR 0.100000    Time 0.254033    
2024-04-23 15:59:57,494 - Epoch: [7][  160/  267]    Overall Loss 3.157473    Objective Loss 3.157473                                        LR 0.100000    Time 0.252904    
2024-04-23 15:59:59,455 - Epoch: [7][  170/  267]    Overall Loss 3.127200    Objective Loss 3.127200                                        LR 0.100000    Time 0.249543    
2024-04-23 15:59:59,951 - Epoch: [5][  100/  123]    Loss 1.655944    Top1 43.093750    Top5 86.781250    
2024-04-23 16:00:02,085 - Epoch: [7][  180/  267]    Overall Loss 3.097098    Objective Loss 3.097098                                        LR 0.100000    Time 0.250270    
2024-04-23 16:00:04,050 - Epoch: [7][  190/  267]    Overall Loss 3.072935    Objective Loss 3.072935                                        LR 0.100000    Time 0.247419    
2024-04-23 16:00:05,489 - Epoch: [5][  123/  123]    Loss 1.644707    Top1 43.821656    Top5 86.980892    
2024-04-23 16:00:05,812 - ==> Top1: 43.822    Top5: 86.981    Loss: 1.645

2024-04-23 16:00:05,823 - ==> Best [Top1: 56.815   Top5: 91.745   Sparsity:0.00   Params: 376752 on epoch: 4]
2024-04-23 16:00:05,824 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:00:05,879 - 

2024-04-23 16:00:05,881 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:00:06,988 - Epoch: [7][  200/  267]    Overall Loss 3.051184    Objective Loss 3.051184                                        LR 0.100000    Time 0.249721    
2024-04-23 16:00:09,194 - Epoch: [7][  210/  267]    Overall Loss 3.028084    Objective Loss 3.028084                                        LR 0.100000    Time 0.248316    
2024-04-23 16:00:12,011 - Epoch: [7][  220/  267]    Overall Loss 3.011147    Objective Loss 3.011147                                        LR 0.100000    Time 0.249820    
2024-04-23 16:00:14,296 - Epoch: [7][  230/  267]    Overall Loss 2.997335    Objective Loss 2.997335                                        LR 0.100000    Time 0.248882    
2024-04-23 16:00:17,500 - Epoch: [7][  240/  267]    Overall Loss 2.979371    Objective Loss 2.979371                                        LR 0.100000    Time 0.251849    
2024-04-23 16:00:19,281 - Epoch: [7][  250/  267]    Overall Loss 2.962047    Objective Loss 2.962047                                        LR 0.100000    Time 0.248889    
2024-04-23 16:00:22,766 - Epoch: [7][  260/  267]    Overall Loss 2.954407    Objective Loss 2.954407                                        LR 0.100000    Time 0.252708    
2024-04-23 16:00:24,326 - Epoch: [7][  267/  267]    Overall Loss 2.950780    Objective Loss 2.950780    Top1 4.651163    Top5 46.511628    LR 0.100000    Time 0.251913    
2024-04-23 16:00:24,614 - --- validate (epoch=7)-----------
2024-04-23 16:00:24,616 - 946 samples (32 per mini-batch)
2024-04-23 16:00:29,830 - Epoch: [7][   10/   30]    Loss 2.640666    Top1 9.062500    Top5 52.500000    
2024-04-23 16:00:32,085 - Epoch: [7][   20/   30]    Loss 2.640300    Top1 8.906250    Top5 50.312500    
2024-04-23 16:00:34,768 - Epoch: [6][  100/  296]    Overall Loss 1.481199    Objective Loss 1.481199                                        LR 0.000320    Time 0.288633    
2024-04-23 16:00:35,340 - Epoch: [7][   30/   30]    Loss 2.637690    Top1 8.456660    Top5 50.105708    
2024-04-23 16:00:35,574 - ==> Top1: 8.457    Top5: 50.106    Loss: 2.638

2024-04-23 16:00:35,576 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 16:00:35,581 - ==> Best [Top1: 10.571   Top5: 52.431   Sparsity:0.00   Params: 96528 on epoch: 0]
2024-04-23 16:00:35,582 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:00:35,601 - 

2024-04-23 16:00:35,602 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:00:39,961 - Epoch: [8][   10/  267]    Overall Loss 2.734369    Objective Loss 2.734369                                        LR 0.100000    Time 0.435504    
2024-04-23 16:00:42,270 - Epoch: [8][   20/  267]    Overall Loss 2.713817    Objective Loss 2.713817                                        LR 0.100000    Time 0.333040    
2024-04-23 16:00:45,253 - Epoch: [8][   30/  267]    Overall Loss 2.673414    Objective Loss 2.673414                                        LR 0.100000    Time 0.321341    
2024-04-23 16:00:47,067 - Epoch: [8][   40/  267]    Overall Loss 2.667462    Objective Loss 2.667462                                        LR 0.100000    Time 0.286271    
2024-04-23 16:00:49,727 - Epoch: [8][   50/  267]    Overall Loss 2.679298    Objective Loss 2.679298                                        LR 0.100000    Time 0.282136    
2024-04-23 16:00:52,045 - Epoch: [8][   60/  267]    Overall Loss 2.673230    Objective Loss 2.673230                                        LR 0.100000    Time 0.273684    
2024-04-23 16:00:54,234 - Epoch: [8][   70/  267]    Overall Loss 2.662714    Objective Loss 2.662714                                        LR 0.100000    Time 0.265805    
2024-04-23 16:00:57,226 - Epoch: [8][   80/  267]    Overall Loss 2.645634    Objective Loss 2.645634                                        LR 0.100000    Time 0.269937    
2024-04-23 16:00:58,409 - Epoch: [6][  200/  296]    Overall Loss 1.469285    Objective Loss 1.469285                                        LR 0.000320    Time 0.262414    
2024-04-23 16:00:59,374 - Epoch: [8][   90/  267]    Overall Loss 2.630238    Objective Loss 2.630238                                        LR 0.100000    Time 0.263779    
2024-04-23 16:01:02,589 - Epoch: [8][  100/  267]    Overall Loss 2.627358    Objective Loss 2.627358                                        LR 0.100000    Time 0.269516    
2024-04-23 16:01:04,849 - Epoch: [8][  110/  267]    Overall Loss 2.626774    Objective Loss 2.626774                                        LR 0.100000    Time 0.265536    
2024-04-23 16:01:07,791 - Epoch: [8][  120/  267]    Overall Loss 2.638422    Objective Loss 2.638422                                        LR 0.100000    Time 0.267893    
2024-04-23 16:01:09,624 - Epoch: [8][  130/  267]    Overall Loss 2.641737    Objective Loss 2.641737                                        LR 0.100000    Time 0.261345    
2024-04-23 16:01:12,475 - Epoch: [8][  140/  267]    Overall Loss 2.640734    Objective Loss 2.640734                                        LR 0.100000    Time 0.263021    
2024-04-23 16:01:14,081 - Epoch: [8][  150/  267]    Overall Loss 2.639106    Objective Loss 2.639106                                        LR 0.100000    Time 0.256178    
2024-04-23 16:01:16,321 - Epoch: [8][  160/  267]    Overall Loss 2.642909    Objective Loss 2.642909                                        LR 0.100000    Time 0.254143    
2024-04-23 16:01:19,232 - Epoch: [8][  170/  267]    Overall Loss 2.647342    Objective Loss 2.647342                                        LR 0.100000    Time 0.256299    
2024-04-23 16:01:21,612 - Epoch: [8][  180/  267]    Overall Loss 2.638965    Objective Loss 2.638965                                        LR 0.100000    Time 0.255262    
2024-04-23 16:01:22,459 - Epoch: [6][  296/  296]    Overall Loss 1.467268    Objective Loss 1.467268    Top1 45.901639    Top5 80.327869    LR 0.000320    Time 0.258476    
2024-04-23 16:01:22,775 - --- validate (epoch=6)-----------
2024-04-23 16:01:22,776 - 3925 samples (32 per mini-batch)
2024-04-23 16:01:24,395 - Epoch: [8][  190/  267]    Overall Loss 2.639155    Objective Loss 2.639155                                        LR 0.100000    Time 0.256458    
2024-04-23 16:01:26,581 - Epoch: [8][  200/  267]    Overall Loss 2.647538    Objective Loss 2.647538                                        LR 0.100000    Time 0.254544    
2024-04-23 16:01:29,850 - Epoch: [8][  210/  267]    Overall Loss 2.649242    Objective Loss 2.649242                                        LR 0.100000    Time 0.257974    
2024-04-23 16:01:31,919 - Epoch: [8][  220/  267]    Overall Loss 2.643465    Objective Loss 2.643465                                        LR 0.100000    Time 0.255637    
2024-04-23 16:01:34,828 - Epoch: [8][  230/  267]    Overall Loss 2.637055    Objective Loss 2.637055                                        LR 0.100000    Time 0.257156    
2024-04-23 16:01:36,847 - Epoch: [8][  240/  267]    Overall Loss 2.634001    Objective Loss 2.634001                                        LR 0.100000    Time 0.254836    
2024-04-23 16:01:40,102 - Epoch: [8][  250/  267]    Overall Loss 2.629717    Objective Loss 2.629717                                        LR 0.100000    Time 0.257649    
2024-04-23 16:01:41,769 - Epoch: [8][  260/  267]    Overall Loss 2.629797    Objective Loss 2.629797                                        LR 0.100000    Time 0.254138    
2024-04-23 16:01:43,196 - Epoch: [8][  267/  267]    Overall Loss 2.628108    Objective Loss 2.628108    Top1 16.279070    Top5 58.139535    LR 0.100000    Time 0.252808    
2024-04-23 16:01:43,458 - --- validate (epoch=8)-----------
2024-04-23 16:01:43,459 - 946 samples (32 per mini-batch)
2024-04-23 16:01:47,339 - Epoch: [8][   10/   30]    Loss 2.711483    Top1 7.187500    Top5 53.437500    
2024-04-23 16:01:49,769 - Epoch: [8][   20/   30]    Loss 2.716899    Top1 9.531250    Top5 52.656250    
2024-04-23 16:01:51,181 - Epoch: [6][  100/  123]    Loss 1.313068    Top1 56.687500    Top5 92.281250    
2024-04-23 16:01:52,572 - Epoch: [8][   30/   30]    Loss 2.789119    Top1 9.196617    Top5 50.422833    
2024-04-23 16:01:52,791 - ==> Top1: 9.197    Top5: 50.423    Loss: 2.789

2024-04-23 16:01:52,793 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 16:01:52,798 - ==> Best [Top1: 10.571   Top5: 52.431   Sparsity:0.00   Params: 96528 on epoch: 0]
2024-04-23 16:01:52,799 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:01:52,818 - 

2024-04-23 16:01:52,819 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:01:57,102 - Epoch: [9][   10/  267]    Overall Loss 2.657512    Objective Loss 2.657512                                        LR 0.100000    Time 0.427869    
2024-04-23 16:01:57,366 - Epoch: [6][  123/  123]    Loss 1.306327    Top1 56.815287    Top5 92.229299    
2024-04-23 16:01:57,672 - ==> Top1: 56.815    Top5: 92.229    Loss: 1.306

2024-04-23 16:01:57,683 - ==> Best [Top1: 56.815   Top5: 92.229   Sparsity:0.00   Params: 376752 on epoch: 6]
2024-04-23 16:01:57,684 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:01:57,779 - 

2024-04-23 16:01:57,780 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:01:59,287 - Epoch: [9][   20/  267]    Overall Loss 2.724408    Objective Loss 2.724408                                        LR 0.100000    Time 0.322966    
2024-04-23 16:02:02,250 - Epoch: [9][   30/  267]    Overall Loss 2.698590    Objective Loss 2.698590                                        LR 0.100000    Time 0.313967    
2024-04-23 16:02:04,756 - Epoch: [9][   40/  267]    Overall Loss 2.704048    Objective Loss 2.704048                                        LR 0.100000    Time 0.298034    
2024-04-23 16:02:08,963 - Epoch: [9][   50/  267]    Overall Loss 2.690696    Objective Loss 2.690696                                        LR 0.100000    Time 0.322506    
2024-04-23 16:02:11,797 - Epoch: [9][   60/  267]    Overall Loss 2.741138    Objective Loss 2.741138                                        LR 0.100000    Time 0.315930    
2024-04-23 16:02:15,128 - Epoch: [9][   70/  267]    Overall Loss 2.750775    Objective Loss 2.750775                                        LR 0.100000    Time 0.318327    
2024-04-23 16:02:17,557 - Epoch: [9][   80/  267]    Overall Loss 2.725950    Objective Loss 2.725950                                        LR 0.100000    Time 0.308860    
2024-04-23 16:02:21,072 - Epoch: [9][   90/  267]    Overall Loss 2.713798    Objective Loss 2.713798                                        LR 0.100000    Time 0.313572    
2024-04-23 16:02:23,160 - Epoch: [9][  100/  267]    Overall Loss 2.701585    Objective Loss 2.701585                                        LR 0.100000    Time 0.303064    
2024-04-23 16:02:26,157 - Epoch: [9][  110/  267]    Overall Loss 2.704843    Objective Loss 2.704843                                        LR 0.100000    Time 0.302727    
2024-04-23 16:02:28,481 - Epoch: [9][  120/  267]    Overall Loss 2.709159    Objective Loss 2.709159                                        LR 0.100000    Time 0.296843    
2024-04-23 16:02:30,443 - Epoch: [7][  100/  296]    Overall Loss 1.415945    Objective Loss 1.415945                                        LR 0.000320    Time 0.326386    
2024-04-23 16:02:32,055 - Epoch: [9][  130/  267]    Overall Loss 2.739942    Objective Loss 2.739942                                        LR 0.100000    Time 0.301484    
2024-04-23 16:02:34,458 - Epoch: [9][  140/  267]    Overall Loss 2.748959    Objective Loss 2.748959                                        LR 0.100000    Time 0.297086    
2024-04-23 16:02:37,939 - Epoch: [9][  150/  267]    Overall Loss 2.747330    Objective Loss 2.747330                                        LR 0.100000    Time 0.300470    
2024-04-23 16:02:40,220 - Epoch: [9][  160/  267]    Overall Loss 2.748429    Objective Loss 2.748429                                        LR 0.100000    Time 0.295927    
2024-04-23 16:02:43,411 - Epoch: [9][  170/  267]    Overall Loss 2.744211    Objective Loss 2.744211                                        LR 0.100000    Time 0.297261    
2024-04-23 16:02:45,375 - Epoch: [9][  180/  267]    Overall Loss 2.731721    Objective Loss 2.731721                                        LR 0.100000    Time 0.291641    
2024-04-23 16:02:47,454 - Epoch: [9][  190/  267]    Overall Loss 2.727795    Objective Loss 2.727795                                        LR 0.100000    Time 0.287216    
2024-04-23 16:02:50,996 - Epoch: [9][  200/  267]    Overall Loss 2.713638    Objective Loss 2.713638                                        LR 0.100000    Time 0.290546    
2024-04-23 16:02:53,280 - Epoch: [9][  210/  267]    Overall Loss 2.703978    Objective Loss 2.703978                                        LR 0.100000    Time 0.287575    
2024-04-23 16:02:56,314 - Epoch: [9][  220/  267]    Overall Loss 2.694552    Objective Loss 2.694552                                        LR 0.100000    Time 0.288276    
2024-04-23 16:02:57,902 - Epoch: [7][  200/  296]    Overall Loss 1.408384    Objective Loss 1.408384                                        LR 0.000320    Time 0.300381    
2024-04-23 16:02:58,034 - Epoch: [9][  230/  267]    Overall Loss 2.690098    Objective Loss 2.690098                                        LR 0.100000    Time 0.283209    
2024-04-23 16:03:01,115 - Epoch: [9][  240/  267]    Overall Loss 2.833190    Objective Loss 2.833190                                        LR 0.100000    Time 0.284233    
2024-04-23 16:03:03,908 - Epoch: [9][  250/  267]    Overall Loss 2.955387    Objective Loss 2.955387                                        LR 0.100000    Time 0.284019    
2024-04-23 16:03:07,070 - Epoch: [9][  260/  267]    Overall Loss 3.181700    Objective Loss 3.181700                                        LR 0.100000    Time 0.285247    
2024-04-23 16:03:08,861 - Epoch: [9][  267/  267]    Overall Loss 3.269179    Objective Loss 3.269179    Top1 9.302326    Top5 55.813953    LR 0.100000    Time 0.284470    
2024-04-23 16:03:09,044 - --- validate (epoch=9)-----------
2024-04-23 16:03:09,045 - 946 samples (32 per mini-batch)
2024-04-23 16:03:13,171 - Epoch: [9][   10/   30]    Loss 7.694398    Top1 9.062500    Top5 47.187500    
2024-04-23 16:03:15,411 - Epoch: [9][   20/   30]    Loss 7.552337    Top1 10.312500    Top5 49.062500    
2024-04-23 16:03:17,764 - Epoch: [9][   30/   30]    Loss 7.506470    Top1 10.570825    Top5 49.260042    
2024-04-23 16:03:18,027 - ==> Top1: 10.571    Top5: 49.260    Loss: 7.506

2024-04-23 16:03:18,030 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 16:03:18,035 - ==> Best [Top1: 10.571   Top5: 52.431   Sparsity:0.00   Params: 96528 on epoch: 0]
2024-04-23 16:03:18,036 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:03:18,056 - 

2024-04-23 16:03:18,057 - Initiating quantization aware training (QAT)...
2024-04-23 16:03:18,076 - 

2024-04-23 16:03:18,078 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:03:22,166 - Epoch: [7][  296/  296]    Overall Loss 1.409637    Objective Loss 1.409637    Top1 72.131148    Top5 98.360656    LR 0.000320    Time 0.284852    
2024-04-23 16:03:22,379 - --- validate (epoch=7)-----------
2024-04-23 16:03:22,380 - 3925 samples (32 per mini-batch)
2024-04-23 16:03:22,399 - Epoch: [10][   10/  267]    Overall Loss 2.813065    Objective Loss 2.813065                                        LR 0.100000    Time 0.431835    
2024-04-23 16:03:23,862 - Epoch: [10][   20/  267]    Overall Loss 2.738770    Objective Loss 2.738770                                        LR 0.100000    Time 0.288890    
2024-04-23 16:03:27,730 - Epoch: [10][   30/  267]    Overall Loss 2.684716    Objective Loss 2.684716                                        LR 0.100000    Time 0.321450    
2024-04-23 16:03:30,262 - Epoch: [10][   40/  267]    Overall Loss 2.641124    Objective Loss 2.641124                                        LR 0.100000    Time 0.304334    
2024-04-23 16:03:33,896 - Epoch: [10][   50/  267]    Overall Loss 2.596440    Objective Loss 2.596440                                        LR 0.100000    Time 0.316101    
2024-04-23 16:03:36,462 - Epoch: [10][   60/  267]    Overall Loss 2.578884    Objective Loss 2.578884                                        LR 0.100000    Time 0.306132    
2024-04-23 16:03:40,146 - Epoch: [10][   70/  267]    Overall Loss 2.572729    Objective Loss 2.572729                                        LR 0.100000    Time 0.314990    
2024-04-23 16:03:42,634 - Epoch: [10][   80/  267]    Overall Loss 2.561143    Objective Loss 2.561143                                        LR 0.100000    Time 0.306709    
2024-04-23 16:03:46,079 - Epoch: [10][   90/  267]    Overall Loss 2.546350    Objective Loss 2.546350                                        LR 0.100000    Time 0.310876    
2024-04-23 16:03:48,785 - Epoch: [10][  100/  267]    Overall Loss 2.534726    Objective Loss 2.534726                                        LR 0.100000    Time 0.306830    
2024-04-23 16:03:52,415 - Epoch: [10][  110/  267]    Overall Loss 2.521415    Objective Loss 2.521415                                        LR 0.100000    Time 0.311912    
2024-04-23 16:03:54,569 - Epoch: [10][  120/  267]    Overall Loss 2.530809    Objective Loss 2.530809                                        LR 0.100000    Time 0.303843    
2024-04-23 16:03:55,677 - Epoch: [7][  100/  123]    Loss 1.426044    Top1 53.156250    Top5 90.500000    
2024-04-23 16:03:57,971 - Epoch: [10][  130/  267]    Overall Loss 2.520631    Objective Loss 2.520631                                        LR 0.100000    Time 0.306620    
2024-04-23 16:04:00,042 - Epoch: [10][  140/  267]    Overall Loss 2.511710    Objective Loss 2.511710                                        LR 0.100000    Time 0.299485    
2024-04-23 16:04:01,286 - Epoch: [7][  123/  123]    Loss 1.426535    Top1 53.477707    Top5 90.624204    
2024-04-23 16:04:01,569 - ==> Top1: 53.478    Top5: 90.624    Loss: 1.427

2024-04-23 16:04:01,578 - ==> Best [Top1: 56.815   Top5: 92.229   Sparsity:0.00   Params: 376752 on epoch: 6]
2024-04-23 16:04:01,579 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:04:01,666 - 

2024-04-23 16:04:01,668 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:04:02,685 - Epoch: [10][  150/  267]    Overall Loss 2.500775    Objective Loss 2.500775                                        LR 0.100000    Time 0.297122    
2024-04-23 16:04:04,616 - Epoch: [10][  160/  267]    Overall Loss 2.495299    Objective Loss 2.495299                                        LR 0.100000    Time 0.290599    
2024-04-23 16:04:07,647 - Epoch: [10][  170/  267]    Overall Loss 2.493755    Objective Loss 2.493755                                        LR 0.100000    Time 0.291318    
2024-04-23 16:04:09,836 - Epoch: [10][  180/  267]    Overall Loss 2.492161    Objective Loss 2.492161                                        LR 0.100000    Time 0.287282    
2024-04-23 16:04:13,039 - Epoch: [10][  190/  267]    Overall Loss 2.489257    Objective Loss 2.489257                                        LR 0.100000    Time 0.289005    
2024-04-23 16:04:15,011 - Epoch: [10][  200/  267]    Overall Loss 2.490529    Objective Loss 2.490529                                        LR 0.100000    Time 0.284400    
2024-04-23 16:04:17,510 - Epoch: [10][  210/  267]    Overall Loss 2.490676    Objective Loss 2.490676                                        LR 0.100000    Time 0.282749    
2024-04-23 16:04:19,486 - Epoch: [10][  220/  267]    Overall Loss 2.490710    Objective Loss 2.490710                                        LR 0.100000    Time 0.278865    
2024-04-23 16:04:22,330 - Epoch: [10][  230/  267]    Overall Loss 2.485909    Objective Loss 2.485909                                        LR 0.100000    Time 0.279095    
2024-04-23 16:04:24,782 - Epoch: [10][  240/  267]    Overall Loss 2.486064    Objective Loss 2.486064                                        LR 0.100000    Time 0.277667    
2024-04-23 16:04:26,996 - Epoch: [10][  250/  267]    Overall Loss 2.482596    Objective Loss 2.482596                                        LR 0.100000    Time 0.275409    
2024-04-23 16:04:29,372 - Epoch: [10][  260/  267]    Overall Loss 2.484471    Objective Loss 2.484471                                        LR 0.100000    Time 0.273945    
2024-04-23 16:04:31,101 - Epoch: [10][  267/  267]    Overall Loss 2.483767    Objective Loss 2.483767    Top1 13.953488    Top5 51.162791    LR 0.100000    Time 0.273228    
2024-04-23 16:04:31,378 - --- validate (epoch=10)-----------
2024-04-23 16:04:31,380 - 946 samples (32 per mini-batch)
2024-04-23 16:04:31,390 - Epoch: [8][  100/  296]    Overall Loss 1.395149    Objective Loss 1.395149                                        LR 0.000320    Time 0.296985    
2024-04-23 16:04:35,320 - Epoch: [10][   10/   30]    Loss 2.353948    Top1 13.437500    Top5 46.875000    
2024-04-23 16:04:37,425 - Epoch: [10][   20/   30]    Loss 2.356215    Top1 11.562500    Top5 49.062500    
2024-04-23 16:04:39,790 - Epoch: [10][   30/   30]    Loss 2.371897    Top1 10.465116    Top5 47.780127    
2024-04-23 16:04:39,983 - ==> Top1: 10.465    Top5: 47.780    Loss: 2.372

2024-04-23 16:04:39,985 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 16:04:39,990 - ==> Best [Top1: 10.465   Top5: 47.780   Sparsity:0.00   Params: 96528 on epoch: 10]
2024-04-23 16:04:39,992 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:04:40,015 - 

2024-04-23 16:04:40,016 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:04:44,656 - Epoch: [11][   10/  267]    Overall Loss 2.442011    Objective Loss 2.442011                                        LR 0.100000    Time 0.463548    
2024-04-23 16:04:46,741 - Epoch: [11][   20/  267]    Overall Loss 2.425963    Objective Loss 2.425963                                        LR 0.100000    Time 0.335854    
2024-04-23 16:04:49,474 - Epoch: [11][   30/  267]    Overall Loss 2.422482    Objective Loss 2.422482                                        LR 0.100000    Time 0.314899    
2024-04-23 16:04:51,334 - Epoch: [11][   40/  267]    Overall Loss 2.424214    Objective Loss 2.424214                                        LR 0.100000    Time 0.282592    
2024-04-23 16:04:53,601 - Epoch: [8][  200/  296]    Overall Loss 1.399641    Objective Loss 1.399641                                        LR 0.000320    Time 0.259444    
2024-04-23 16:04:54,210 - Epoch: [11][   50/  267]    Overall Loss 2.437824    Objective Loss 2.437824                                        LR 0.100000    Time 0.283517    
2024-04-23 16:04:56,349 - Epoch: [11][   60/  267]    Overall Loss 2.440986    Objective Loss 2.440986                                        LR 0.100000    Time 0.271869    
2024-04-23 16:04:59,363 - Epoch: [11][   70/  267]    Overall Loss 2.444192    Objective Loss 2.444192                                        LR 0.100000    Time 0.276052    
2024-04-23 16:05:01,446 - Epoch: [11][   80/  267]    Overall Loss 2.468029    Objective Loss 2.468029                                        LR 0.100000    Time 0.267542    
2024-04-23 16:05:04,558 - Epoch: [11][   90/  267]    Overall Loss 2.469347    Objective Loss 2.469347                                        LR 0.100000    Time 0.272361    
2024-04-23 16:05:06,403 - Epoch: [11][  100/  267]    Overall Loss 2.475369    Objective Loss 2.475369                                        LR 0.100000    Time 0.263546    
2024-04-23 16:05:08,917 - Epoch: [11][  110/  267]    Overall Loss 2.473904    Objective Loss 2.473904                                        LR 0.100000    Time 0.262408    
2024-04-23 16:05:11,208 - Epoch: [11][  120/  267]    Overall Loss 2.468593    Objective Loss 2.468593                                        LR 0.100000    Time 0.259608    
2024-04-23 16:05:13,503 - Epoch: [11][  130/  267]    Overall Loss 2.466063    Objective Loss 2.466063                                        LR 0.100000    Time 0.257263    
2024-04-23 16:05:14,788 - Epoch: [8][  296/  296]    Overall Loss 1.396920    Objective Loss 1.396920    Top1 52.459016    Top5 90.163934    LR 0.000320    Time 0.246813    
2024-04-23 16:05:15,008 - --- validate (epoch=8)-----------
2024-04-23 16:05:15,010 - 3925 samples (32 per mini-batch)
2024-04-23 16:05:15,308 - Epoch: [11][  140/  267]    Overall Loss 2.462436    Objective Loss 2.462436                                        LR 0.100000    Time 0.251755    
2024-04-23 16:05:18,215 - Epoch: [11][  150/  267]    Overall Loss 2.460190    Objective Loss 2.460190                                        LR 0.100000    Time 0.254332    
2024-04-23 16:05:20,241 - Epoch: [11][  160/  267]    Overall Loss 2.457464    Objective Loss 2.457464                                        LR 0.100000    Time 0.251077    
2024-04-23 16:05:23,020 - Epoch: [11][  170/  267]    Overall Loss 2.453341    Objective Loss 2.453341                                        LR 0.100000    Time 0.252637    
2024-04-23 16:05:25,031 - Epoch: [11][  180/  267]    Overall Loss 2.447638    Objective Loss 2.447638                                        LR 0.100000    Time 0.249755    
2024-04-23 16:05:27,808 - Epoch: [11][  190/  267]    Overall Loss 2.442249    Objective Loss 2.442249                                        LR 0.100000    Time 0.251211    
2024-04-23 16:05:29,631 - Epoch: [11][  200/  267]    Overall Loss 2.438107    Objective Loss 2.438107                                        LR 0.100000    Time 0.247753    
2024-04-23 16:05:32,458 - Epoch: [11][  210/  267]    Overall Loss 2.434945    Objective Loss 2.434945                                        LR 0.100000    Time 0.249403    
2024-04-23 16:05:34,027 - Epoch: [11][  220/  267]    Overall Loss 2.432422    Objective Loss 2.432422                                        LR 0.100000    Time 0.245183    
2024-04-23 16:05:36,978 - Epoch: [11][  230/  267]    Overall Loss 2.430859    Objective Loss 2.430859                                        LR 0.100000    Time 0.247338    
2024-04-23 16:05:39,247 - Epoch: [11][  240/  267]    Overall Loss 2.432175    Objective Loss 2.432175                                        LR 0.100000    Time 0.246476    
2024-04-23 16:05:39,533 - Epoch: [8][  100/  123]    Loss 1.248509    Top1 58.656250    Top5 93.375000    
2024-04-23 16:05:42,595 - Epoch: [11][  250/  267]    Overall Loss 2.430698    Objective Loss 2.430698                                        LR 0.100000    Time 0.249997    
2024-04-23 16:05:43,311 - Epoch: [8][  123/  123]    Loss 1.247278    Top1 58.751592    Top5 93.375796    
2024-04-23 16:05:43,556 - ==> Top1: 58.752    Top5: 93.376    Loss: 1.247

2024-04-23 16:05:43,564 - ==> Best [Top1: 58.752   Top5: 93.376   Sparsity:0.00   Params: 376752 on epoch: 8]
2024-04-23 16:05:43,565 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:05:43,630 - 

2024-04-23 16:05:43,631 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:05:44,870 - Epoch: [11][  260/  267]    Overall Loss 2.431229    Objective Loss 2.431229                                        LR 0.100000    Time 0.249119    
2024-04-23 16:05:46,199 - Epoch: [11][  267/  267]    Overall Loss 2.431734    Objective Loss 2.431734    Top1 2.325581    Top5 39.534884    LR 0.100000    Time 0.247558    
2024-04-23 16:05:46,348 - --- validate (epoch=11)-----------
2024-04-23 16:05:46,349 - 946 samples (32 per mini-batch)
2024-04-23 16:05:50,025 - Epoch: [11][   10/   30]    Loss 2.439379    Top1 10.312500    Top5 53.750000    
2024-04-23 16:05:52,177 - Epoch: [11][   20/   30]    Loss 2.467688    Top1 9.531250    Top5 51.718750    
2024-04-23 16:05:54,750 - Epoch: [11][   30/   30]    Loss 2.488664    Top1 9.196617    Top5 49.788584    
2024-04-23 16:05:54,886 - ==> Top1: 9.197    Top5: 49.789    Loss: 2.489

2024-04-23 16:05:54,888 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 16:05:54,892 - ==> Best [Top1: 10.465   Top5: 47.780   Sparsity:0.00   Params: 96528 on epoch: 10]
2024-04-23 16:05:54,892 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:05:54,908 - 

2024-04-23 16:05:54,909 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:05:58,147 - Epoch: [12][   10/  267]    Overall Loss 2.447646    Objective Loss 2.447646                                        LR 0.100000    Time 0.323507    
2024-04-23 16:06:00,142 - Epoch: [12][   20/  267]    Overall Loss 2.417249    Objective Loss 2.417249                                        LR 0.100000    Time 0.261339    
2024-04-23 16:06:02,431 - Epoch: [12][   30/  267]    Overall Loss 2.414696    Objective Loss 2.414696                                        LR 0.100000    Time 0.250441    
2024-04-23 16:06:04,675 - Epoch: [12][   40/  267]    Overall Loss 2.399708    Objective Loss 2.399708                                        LR 0.100000    Time 0.243834    
2024-04-23 16:06:07,566 - Epoch: [9][  100/  296]    Overall Loss 1.375948    Objective Loss 1.375948                                        LR 0.000320    Time 0.239123    
2024-04-23 16:06:07,624 - Epoch: [12][   50/  267]    Overall Loss 2.416389    Objective Loss 2.416389                                        LR 0.100000    Time 0.253985    
2024-04-23 16:06:09,846 - Epoch: [12][   60/  267]    Overall Loss 2.412243    Objective Loss 2.412243                                        LR 0.100000    Time 0.248626    
2024-04-23 16:06:12,566 - Epoch: [12][   70/  267]    Overall Loss 2.411308    Objective Loss 2.411308                                        LR 0.100000    Time 0.251912    
2024-04-23 16:06:14,683 - Epoch: [12][   80/  267]    Overall Loss 2.419430    Objective Loss 2.419430                                        LR 0.100000    Time 0.246855    
2024-04-23 16:06:17,634 - Epoch: [12][   90/  267]    Overall Loss 2.424061    Objective Loss 2.424061                                        LR 0.100000    Time 0.252135    
2024-04-23 16:06:19,818 - Epoch: [12][  100/  267]    Overall Loss 2.423989    Objective Loss 2.423989                                        LR 0.100000    Time 0.248727    
2024-04-23 16:06:22,885 - Epoch: [12][  110/  267]    Overall Loss 2.426977    Objective Loss 2.426977                                        LR 0.100000    Time 0.253978    
2024-04-23 16:06:25,191 - Epoch: [12][  120/  267]    Overall Loss 2.424554    Objective Loss 2.424554                                        LR 0.100000    Time 0.252000    
2024-04-23 16:06:28,382 - Epoch: [12][  130/  267]    Overall Loss 2.422821    Objective Loss 2.422821                                        LR 0.100000    Time 0.257132    
2024-04-23 16:06:28,969 - Epoch: [9][  200/  296]    Overall Loss 1.355590    Objective Loss 1.355590                                        LR 0.000320    Time 0.226474    
2024-04-23 16:06:30,500 - Epoch: [12][  140/  267]    Overall Loss 2.426296    Objective Loss 2.426296                                        LR 0.100000    Time 0.253871    
2024-04-23 16:06:33,376 - Epoch: [12][  150/  267]    Overall Loss 2.422052    Objective Loss 2.422052                                        LR 0.100000    Time 0.256092    
2024-04-23 16:06:35,604 - Epoch: [12][  160/  267]    Overall Loss 2.420336    Objective Loss 2.420336                                        LR 0.100000    Time 0.253981    
2024-04-23 16:06:38,499 - Epoch: [12][  170/  267]    Overall Loss 2.418483    Objective Loss 2.418483                                        LR 0.100000    Time 0.256056    
2024-04-23 16:06:40,683 - Epoch: [12][  180/  267]    Overall Loss 2.416276    Objective Loss 2.416276                                        LR 0.100000    Time 0.253925    
2024-04-23 16:06:43,949 - Epoch: [12][  190/  267]    Overall Loss 2.417205    Objective Loss 2.417205                                        LR 0.100000    Time 0.257730    
2024-04-23 16:06:45,635 - Epoch: [12][  200/  267]    Overall Loss 2.416876    Objective Loss 2.416876                                        LR 0.100000    Time 0.253261    
2024-04-23 16:06:48,290 - Epoch: [12][  210/  267]    Overall Loss 2.417754    Objective Loss 2.417754                                        LR 0.100000    Time 0.253829    
2024-04-23 16:06:48,956 - Epoch: [9][  296/  296]    Overall Loss 1.357164    Objective Loss 1.357164    Top1 52.459016    Top5 88.524590    LR 0.000320    Time 0.220480    
2024-04-23 16:06:49,179 - --- validate (epoch=9)-----------
2024-04-23 16:06:49,180 - 3925 samples (32 per mini-batch)
2024-04-23 16:06:50,397 - Epoch: [12][  220/  267]    Overall Loss 2.418233    Objective Loss 2.418233                                        LR 0.100000    Time 0.251852    
2024-04-23 16:06:53,069 - Epoch: [12][  230/  267]    Overall Loss 2.421382    Objective Loss 2.421382                                        LR 0.100000    Time 0.252503    
2024-04-23 16:06:54,666 - Epoch: [12][  240/  267]    Overall Loss 2.430157    Objective Loss 2.430157                                        LR 0.100000    Time 0.248625    
2024-04-23 16:06:57,804 - Epoch: [12][  250/  267]    Overall Loss 2.433600    Objective Loss 2.433600                                        LR 0.100000    Time 0.251218    
2024-04-23 16:06:59,998 - Epoch: [12][  260/  267]    Overall Loss 2.434343    Objective Loss 2.434343                                        LR 0.100000    Time 0.249986    
2024-04-23 16:07:01,528 - Epoch: [12][  267/  267]    Overall Loss 2.434189    Objective Loss 2.434189    Top1 9.302326    Top5 48.837209    LR 0.100000    Time 0.249151    
2024-04-23 16:07:01,742 - --- validate (epoch=12)-----------
2024-04-23 16:07:01,743 - 946 samples (32 per mini-batch)
2024-04-23 16:07:05,764 - Epoch: [12][   10/   30]    Loss 2.419028    Top1 6.875000    Top5 47.187500    
2024-04-23 16:07:07,526 - Epoch: [12][   20/   30]    Loss 2.384034    Top1 9.062500    Top5 49.687500    
2024-04-23 16:07:09,334 - Epoch: [12][   30/   30]    Loss 2.402373    Top1 8.456660    Top5 48.837209    
2024-04-23 16:07:09,470 - ==> Top1: 8.457    Top5: 48.837    Loss: 2.402

2024-04-23 16:07:09,471 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 16:07:09,474 - ==> Best [Top1: 10.465   Top5: 47.780   Sparsity:0.00   Params: 96528 on epoch: 10]
2024-04-23 16:07:09,475 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:07:09,492 - 

2024-04-23 16:07:09,492 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:07:12,513 - Epoch: [13][   10/  267]    Overall Loss 2.576797    Objective Loss 2.576797                                        LR 0.100000    Time 0.301747    
2024-04-23 16:07:13,305 - Epoch: [9][  100/  123]    Loss 1.334680    Top1 55.156250    Top5 91.937500    
2024-04-23 16:07:15,221 - Epoch: [13][   20/  267]    Overall Loss 2.557760    Objective Loss 2.557760                                        LR 0.100000    Time 0.286097    
2024-04-23 16:07:17,544 - Epoch: [13][   30/  267]    Overall Loss 2.558680    Objective Loss 2.558680                                        LR 0.100000    Time 0.268058    
2024-04-23 16:07:19,334 - Epoch: [9][  123/  123]    Loss 1.339256    Top1 54.802548    Top5 91.796178    
2024-04-23 16:07:19,552 - ==> Top1: 54.803    Top5: 91.796    Loss: 1.339

2024-04-23 16:07:19,562 - ==> Best [Top1: 58.752   Top5: 93.376   Sparsity:0.00   Params: 376752 on epoch: 8]
2024-04-23 16:07:19,563 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:07:19,618 - 

2024-04-23 16:07:19,619 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:07:20,086 - Epoch: [13][   40/  267]    Overall Loss 2.581869    Objective Loss 2.581869                                        LR 0.100000    Time 0.264533    
2024-04-23 16:07:21,946 - Epoch: [13][   50/  267]    Overall Loss 2.570602    Objective Loss 2.570602                                        LR 0.100000    Time 0.248764    
2024-04-23 16:07:24,657 - Epoch: [13][   60/  267]    Overall Loss 2.571972    Objective Loss 2.571972                                        LR 0.100000    Time 0.252430    
2024-04-23 16:07:26,699 - Epoch: [13][   70/  267]    Overall Loss 2.579431    Objective Loss 2.579431                                        LR 0.100000    Time 0.245497    
2024-04-23 16:07:29,779 - Epoch: [13][   80/  267]    Overall Loss 2.584043    Objective Loss 2.584043                                        LR 0.100000    Time 0.253279    
2024-04-23 16:07:31,788 - Epoch: [13][   90/  267]    Overall Loss 2.577245    Objective Loss 2.577245                                        LR 0.100000    Time 0.247422    
2024-04-23 16:07:33,971 - Epoch: [13][  100/  267]    Overall Loss 2.569658    Objective Loss 2.569658                                        LR 0.100000    Time 0.244479    
2024-04-23 16:07:35,854 - Epoch: [13][  110/  267]    Overall Loss 2.559305    Objective Loss 2.559305                                        LR 0.100000    Time 0.239343    
2024-04-23 16:07:38,423 - Epoch: [13][  120/  267]    Overall Loss 2.573580    Objective Loss 2.573580                                        LR 0.100000    Time 0.240786    
2024-04-23 16:07:40,238 - Epoch: [13][  130/  267]    Overall Loss 2.584906    Objective Loss 2.584906                                        LR 0.100000    Time 0.236202    
2024-04-23 16:07:43,045 - Epoch: [13][  140/  267]    Overall Loss 2.588539    Objective Loss 2.588539                                        LR 0.100000    Time 0.239349    
2024-04-23 16:07:43,330 - Epoch: [10][  100/  296]    Overall Loss 1.375415    Objective Loss 1.375415                                        LR 0.000320    Time 0.236890    
2024-04-23 16:07:44,978 - Epoch: [13][  150/  267]    Overall Loss 2.574961    Objective Loss 2.574961                                        LR 0.100000    Time 0.236257    
2024-04-23 16:07:47,766 - Epoch: [13][  160/  267]    Overall Loss 2.563745    Objective Loss 2.563745                                        LR 0.100000    Time 0.238895    
2024-04-23 16:07:50,008 - Epoch: [13][  170/  267]    Overall Loss 2.552103    Objective Loss 2.552103                                        LR 0.100000    Time 0.238014    
2024-04-23 16:07:52,717 - Epoch: [13][  180/  267]    Overall Loss 2.544161    Objective Loss 2.544161                                        LR 0.100000    Time 0.239823    
2024-04-23 16:07:55,081 - Epoch: [13][  190/  267]    Overall Loss 2.538951    Objective Loss 2.538951                                        LR 0.100000    Time 0.239628    
2024-04-23 16:07:57,514 - Epoch: [13][  200/  267]    Overall Loss 2.540628    Objective Loss 2.540628                                        LR 0.100000    Time 0.239793    
2024-04-23 16:08:00,025 - Epoch: [13][  210/  267]    Overall Loss 2.537802    Objective Loss 2.537802                                        LR 0.100000    Time 0.240319    
2024-04-23 16:08:02,507 - Epoch: [13][  220/  267]    Overall Loss 2.545019    Objective Loss 2.545019                                        LR 0.100000    Time 0.240666    
2024-04-23 16:08:03,863 - Epoch: [10][  200/  296]    Overall Loss 1.362351    Objective Loss 1.362351                                        LR 0.000320    Time 0.221003    
2024-04-23 16:08:04,971 - Epoch: [13][  230/  267]    Overall Loss 2.548377    Objective Loss 2.548377                                        LR 0.100000    Time 0.240904    
2024-04-23 16:08:07,393 - Epoch: [13][  240/  267]    Overall Loss 2.543867    Objective Loss 2.543867                                        LR 0.100000    Time 0.240944    
2024-04-23 16:08:09,892 - Epoch: [13][  250/  267]    Overall Loss 2.541989    Objective Loss 2.541989                                        LR 0.100000    Time 0.241292    
2024-04-23 16:08:12,404 - Epoch: [13][  260/  267]    Overall Loss 2.547077    Objective Loss 2.547077                                        LR 0.100000    Time 0.241657    
2024-04-23 16:08:13,623 - Epoch: [13][  267/  267]    Overall Loss 2.546699    Objective Loss 2.546699    Top1 13.953488    Top5 55.813953    LR 0.100000    Time 0.239880    
2024-04-23 16:08:13,845 - --- validate (epoch=13)-----------
2024-04-23 16:08:13,846 - 946 samples (32 per mini-batch)
2024-04-23 16:08:17,421 - Epoch: [13][   10/   30]    Loss 2.524700    Top1 12.187500    Top5 49.687500    
2024-04-23 16:08:19,396 - Epoch: [13][   20/   30]    Loss 2.518500    Top1 11.250000    Top5 51.562500    
2024-04-23 16:08:21,411 - Epoch: [13][   30/   30]    Loss 2.545164    Top1 9.830867    Top5 50.739958    
2024-04-23 16:08:21,566 - ==> Top1: 9.831    Top5: 50.740    Loss: 2.545

2024-04-23 16:08:21,568 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 16:08:21,571 - ==> Best [Top1: 10.465   Top5: 47.780   Sparsity:0.00   Params: 96528 on epoch: 10]
2024-04-23 16:08:21,572 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:08:21,587 - 

2024-04-23 16:08:21,588 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:08:25,263 - Epoch: [10][  296/  296]    Overall Loss 1.348758    Objective Loss 1.348758    Top1 59.016393    Top5 85.245902    LR 0.000320    Time 0.221554    
2024-04-23 16:08:25,504 - --- validate (epoch=10)-----------
2024-04-23 16:08:25,505 - 3925 samples (32 per mini-batch)
2024-04-23 16:08:26,001 - Epoch: [14][   10/  267]    Overall Loss 2.530275    Objective Loss 2.530275                                        LR 0.100000    Time 0.440994    
2024-04-23 16:08:27,633 - Epoch: [14][   20/  267]    Overall Loss 2.584470    Objective Loss 2.584470                                        LR 0.100000    Time 0.301927    
2024-04-23 16:08:30,133 - Epoch: [14][   30/  267]    Overall Loss 2.551187    Objective Loss 2.551187                                        LR 0.100000    Time 0.284515    
2024-04-23 16:08:32,528 - Epoch: [14][   40/  267]    Overall Loss 2.535094    Objective Loss 2.535094                                        LR 0.100000    Time 0.273195    
2024-04-23 16:08:35,596 - Epoch: [14][   50/  267]    Overall Loss 2.523727    Objective Loss 2.523727                                        LR 0.100000    Time 0.279872    
2024-04-23 16:08:37,711 - Epoch: [14][   60/  267]    Overall Loss 2.526454    Objective Loss 2.526454                                        LR 0.100000    Time 0.268411    
2024-04-23 16:08:40,661 - Epoch: [14][   70/  267]    Overall Loss 2.524024    Objective Loss 2.524024                                        LR 0.100000    Time 0.272170    
2024-04-23 16:08:42,297 - Epoch: [14][   80/  267]    Overall Loss 2.521790    Objective Loss 2.521790                                        LR 0.100000    Time 0.258564    
2024-04-23 16:08:44,924 - Epoch: [14][   90/  267]    Overall Loss 2.524759    Objective Loss 2.524759                                        LR 0.100000    Time 0.259003    
2024-04-23 16:08:47,245 - Epoch: [14][  100/  267]    Overall Loss 2.535623    Objective Loss 2.535623                                        LR 0.100000    Time 0.256285    
2024-04-23 16:08:49,828 - Epoch: [14][  110/  267]    Overall Loss 2.538930    Objective Loss 2.538930                                        LR 0.100000    Time 0.256439    
2024-04-23 16:08:50,610 - Epoch: [10][  100/  123]    Loss 1.200928    Top1 60.750000    Top5 92.875000    
2024-04-23 16:08:52,361 - Epoch: [14][  120/  267]    Overall Loss 2.535226    Objective Loss 2.535226                                        LR 0.100000    Time 0.256152    
2024-04-23 16:08:54,470 - Epoch: [10][  123/  123]    Loss 1.178350    Top1 61.859873    Top5 93.146497    
2024-04-23 16:08:54,582 - ==> Top1: 61.860    Top5: 93.146    Loss: 1.178

2024-04-23 16:08:54,589 - ==> Best [Top1: 61.860   Top5: 93.146   Sparsity:0.00   Params: 376752 on epoch: 10]
2024-04-23 16:08:54,589 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:08:54,631 - 

2024-04-23 16:08:54,632 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:08:54,949 - Epoch: [14][  130/  267]    Overall Loss 2.538159    Objective Loss 2.538159                                        LR 0.100000    Time 0.256331    
2024-04-23 16:08:56,902 - Epoch: [14][  140/  267]    Overall Loss 2.533565    Objective Loss 2.533565                                        LR 0.100000    Time 0.251947    
2024-04-23 16:08:59,214 - Epoch: [14][  150/  267]    Overall Loss 2.529825    Objective Loss 2.529825                                        LR 0.100000    Time 0.250544    
2024-04-23 16:09:02,160 - Epoch: [14][  160/  267]    Overall Loss 2.522572    Objective Loss 2.522572                                        LR 0.100000    Time 0.253264    
2024-04-23 16:09:04,036 - Epoch: [14][  170/  267]    Overall Loss 2.515082    Objective Loss 2.515082                                        LR 0.100000    Time 0.249387    
2024-04-23 16:09:06,742 - Epoch: [14][  180/  267]    Overall Loss 2.511619    Objective Loss 2.511619                                        LR 0.100000    Time 0.250544    
2024-04-23 16:09:08,969 - Epoch: [14][  190/  267]    Overall Loss 2.510024    Objective Loss 2.510024                                        LR 0.100000    Time 0.249052    
2024-04-23 16:09:11,463 - Epoch: [14][  200/  267]    Overall Loss 2.508891    Objective Loss 2.508891                                        LR 0.100000    Time 0.249054    
2024-04-23 16:09:13,308 - Epoch: [14][  210/  267]    Overall Loss 2.505270    Objective Loss 2.505270                                        LR 0.100000    Time 0.245965    
2024-04-23 16:09:16,077 - Epoch: [14][  220/  267]    Overall Loss 2.505810    Objective Loss 2.505810                                        LR 0.100000    Time 0.247360    
2024-04-23 16:09:17,682 - Epoch: [14][  230/  267]    Overall Loss 2.504906    Objective Loss 2.504906                                        LR 0.100000    Time 0.243569    
2024-04-23 16:09:18,320 - Epoch: [11][  100/  296]    Overall Loss 1.329013    Objective Loss 1.329013                                        LR 0.000320    Time 0.236638    
2024-04-23 16:09:20,038 - Epoch: [14][  240/  267]    Overall Loss 2.502180    Objective Loss 2.502180                                        LR 0.100000    Time 0.243222    
2024-04-23 16:09:22,184 - Epoch: [14][  250/  267]    Overall Loss 2.500610    Objective Loss 2.500610                                        LR 0.100000    Time 0.242065    
2024-04-23 16:09:25,027 - Epoch: [14][  260/  267]    Overall Loss 2.501037    Objective Loss 2.501037                                        LR 0.100000    Time 0.243675    
2024-04-23 16:09:26,104 - Epoch: [14][  267/  267]    Overall Loss 2.500699    Objective Loss 2.500699    Top1 16.279070    Top5 51.162791    LR 0.100000    Time 0.241312    
2024-04-23 16:09:26,316 - --- validate (epoch=14)-----------
2024-04-23 16:09:26,318 - 946 samples (32 per mini-batch)
2024-04-23 16:09:30,280 - Epoch: [14][   10/   30]    Loss 2.556174    Top1 9.687500    Top5 50.000000    
2024-04-23 16:09:32,320 - Epoch: [14][   20/   30]    Loss 2.527402    Top1 9.843750    Top5 50.156250    
2024-04-23 16:09:34,761 - Epoch: [14][   30/   30]    Loss 2.520565    Top1 10.359408    Top5 51.902748    
2024-04-23 16:09:35,055 - ==> Top1: 10.359    Top5: 51.903    Loss: 2.521

2024-04-23 16:09:35,058 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 16:09:35,062 - ==> Best [Top1: 10.465   Top5: 47.780   Sparsity:0.00   Params: 96528 on epoch: 10]
2024-04-23 16:09:35,063 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:09:35,081 - 

2024-04-23 16:09:35,082 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:09:38,997 - Epoch: [15][   10/  267]    Overall Loss 2.492813    Objective Loss 2.492813                                        LR 0.100000    Time 0.391007    
2024-04-23 16:09:41,062 - Epoch: [15][   20/  267]    Overall Loss 2.532205    Objective Loss 2.532205                                        LR 0.100000    Time 0.298564    
2024-04-23 16:09:42,282 - Epoch: [11][  200/  296]    Overall Loss 1.338038    Objective Loss 1.338038                                        LR 0.000320    Time 0.238025    
2024-04-23 16:09:44,146 - Epoch: [15][   30/  267]    Overall Loss 2.546602    Objective Loss 2.546602                                        LR 0.100000    Time 0.301756    
2024-04-23 16:09:46,327 - Epoch: [15][   40/  267]    Overall Loss 2.534172    Objective Loss 2.534172                                        LR 0.100000    Time 0.280762    
2024-04-23 16:09:49,305 - Epoch: [15][   50/  267]    Overall Loss 2.524481    Objective Loss 2.524481                                        LR 0.100000    Time 0.284103    
2024-04-23 16:09:51,094 - Epoch: [15][   60/  267]    Overall Loss 2.517034    Objective Loss 2.517034                                        LR 0.100000    Time 0.266515    
2024-04-23 16:09:54,039 - Epoch: [15][   70/  267]    Overall Loss 2.520513    Objective Loss 2.520513                                        LR 0.100000    Time 0.270471    
2024-04-23 16:09:56,295 - Epoch: [15][   80/  267]    Overall Loss 2.528743    Objective Loss 2.528743                                        LR 0.100000    Time 0.264820    
2024-04-23 16:09:59,364 - Epoch: [15][   90/  267]    Overall Loss 2.524666    Objective Loss 2.524666                                        LR 0.100000    Time 0.269464    
2024-04-23 16:10:00,973 - Epoch: [11][  296/  296]    Overall Loss 1.329009    Objective Loss 1.329009    Top1 49.180328    Top5 86.885246    LR 0.000320    Time 0.223908    
2024-04-23 16:10:00,975 - Epoch: [15][  100/  267]    Overall Loss 2.525165    Objective Loss 2.525165                                        LR 0.100000    Time 0.258591    
2024-04-23 16:10:01,145 - --- validate (epoch=11)-----------
2024-04-23 16:10:01,146 - 3925 samples (32 per mini-batch)
2024-04-23 16:10:04,087 - Epoch: [15][  110/  267]    Overall Loss 2.526007    Objective Loss 2.526007                                        LR 0.100000    Time 0.263343    
2024-04-23 16:10:05,814 - Epoch: [15][  120/  267]    Overall Loss 2.527846    Objective Loss 2.527846                                        LR 0.100000    Time 0.255765    
2024-04-23 16:10:07,597 - Epoch: [15][  130/  267]    Overall Loss 2.526398    Objective Loss 2.526398                                        LR 0.100000    Time 0.249776    
2024-04-23 16:10:10,119 - Epoch: [15][  140/  267]    Overall Loss 2.540465    Objective Loss 2.540465                                        LR 0.100000    Time 0.249932    
2024-04-23 16:10:12,678 - Epoch: [15][  150/  267]    Overall Loss 2.544237    Objective Loss 2.544237                                        LR 0.100000    Time 0.250306    
2024-04-23 16:10:15,025 - Epoch: [15][  160/  267]    Overall Loss 2.554884    Objective Loss 2.554884                                        LR 0.100000    Time 0.249315    
2024-04-23 16:10:17,487 - Epoch: [15][  170/  267]    Overall Loss 2.560157    Objective Loss 2.560157                                        LR 0.100000    Time 0.249112    
2024-04-23 16:10:19,953 - Epoch: [15][  180/  267]    Overall Loss 2.557058    Objective Loss 2.557058                                        LR 0.100000    Time 0.248957    
2024-04-23 16:10:22,534 - Epoch: [15][  190/  267]    Overall Loss 2.558608    Objective Loss 2.558608                                        LR 0.100000    Time 0.249421    
2024-04-23 16:10:25,384 - Epoch: [15][  200/  267]    Overall Loss 2.557873    Objective Loss 2.557873                                        LR 0.100000    Time 0.251183    
2024-04-23 16:10:26,022 - Epoch: [11][  100/  123]    Loss 1.153384    Top1 61.375000    Top5 93.281250    
2024-04-23 16:10:27,539 - Epoch: [15][  210/  267]    Overall Loss 2.556228    Objective Loss 2.556228                                        LR 0.100000    Time 0.249472    
2024-04-23 16:10:30,399 - Epoch: [15][  220/  267]    Overall Loss 2.554267    Objective Loss 2.554267                                        LR 0.100000    Time 0.251117    
2024-04-23 16:10:31,864 - Epoch: [11][  123/  123]    Loss 1.173194    Top1 60.789809    Top5 93.095541    
2024-04-23 16:10:32,086 - ==> Top1: 60.790    Top5: 93.096    Loss: 1.173

2024-04-23 16:10:32,095 - ==> Best [Top1: 61.860   Top5: 93.146   Sparsity:0.00   Params: 376752 on epoch: 10]
2024-04-23 16:10:32,096 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:10:32,154 - 

2024-04-23 16:10:32,155 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:10:32,997 - Epoch: [15][  230/  267]    Overall Loss 2.555730    Objective Loss 2.555730                                        LR 0.100000    Time 0.251485    
2024-04-23 16:10:36,365 - Epoch: [15][  240/  267]    Overall Loss 2.558730    Objective Loss 2.558730                                        LR 0.100000    Time 0.255024    
2024-04-23 16:10:38,444 - Epoch: [15][  250/  267]    Overall Loss 2.566120    Objective Loss 2.566120                                        LR 0.100000    Time 0.253131    
2024-04-23 16:10:41,557 - Epoch: [15][  260/  267]    Overall Loss 2.567753    Objective Loss 2.567753                                        LR 0.100000    Time 0.255357    
2024-04-23 16:10:42,720 - Epoch: [15][  267/  267]    Overall Loss 2.564822    Objective Loss 2.564822    Top1 13.953488    Top5 48.837209    LR 0.100000    Time 0.253009    
2024-04-23 16:10:42,958 - --- validate (epoch=15)-----------
2024-04-23 16:10:42,959 - 946 samples (32 per mini-batch)
2024-04-23 16:10:46,934 - Epoch: [15][   10/   30]    Loss 2.546692    Top1 10.312500    Top5 46.562500    
2024-04-23 16:10:49,114 - Epoch: [15][   20/   30]    Loss 2.548484    Top1 10.468750    Top5 48.125000    
2024-04-23 16:10:51,341 - Epoch: [15][   30/   30]    Loss 2.541741    Top1 10.570825    Top5 48.837209    
2024-04-23 16:10:51,537 - ==> Top1: 10.571    Top5: 48.837    Loss: 2.542

2024-04-23 16:10:51,539 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 16:10:51,544 - ==> Best [Top1: 10.571   Top5: 48.837   Sparsity:0.00   Params: 96527 on epoch: 15]
2024-04-23 16:10:51,545 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:10:51,568 - 

2024-04-23 16:10:51,569 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:10:55,286 - Epoch: [12][  100/  296]    Overall Loss 1.290607    Objective Loss 1.290607                                        LR 0.000320    Time 0.231099    
2024-04-23 16:10:55,422 - Epoch: [16][   10/  267]    Overall Loss 2.537311    Objective Loss 2.537311                                        LR 0.100000    Time 0.384836    
2024-04-23 16:10:57,653 - Epoch: [16][   20/  267]    Overall Loss 2.565600    Objective Loss 2.565600                                        LR 0.100000    Time 0.303800    
2024-04-23 16:11:00,451 - Epoch: [16][   30/  267]    Overall Loss 2.560521    Objective Loss 2.560521                                        LR 0.100000    Time 0.295695    
2024-04-23 16:11:02,286 - Epoch: [16][   40/  267]    Overall Loss 2.547704    Objective Loss 2.547704                                        LR 0.100000    Time 0.267586    
2024-04-23 16:11:05,000 - Epoch: [16][   50/  267]    Overall Loss 2.541640    Objective Loss 2.541640                                        LR 0.100000    Time 0.268279    
2024-04-23 16:11:07,786 - Epoch: [16][   60/  267]    Overall Loss 2.529060    Objective Loss 2.529060                                        LR 0.100000    Time 0.269959    
2024-04-23 16:11:10,343 - Epoch: [16][   70/  267]    Overall Loss 2.545779    Objective Loss 2.545779                                        LR 0.100000    Time 0.267868    
2024-04-23 16:11:12,520 - Epoch: [16][   80/  267]    Overall Loss 2.566656    Objective Loss 2.566656                                        LR 0.100000    Time 0.261561    
2024-04-23 16:11:14,984 - Epoch: [16][   90/  267]    Overall Loss 2.569676    Objective Loss 2.569676                                        LR 0.100000    Time 0.259846    
2024-04-23 16:11:17,154 - Epoch: [16][  100/  267]    Overall Loss 2.564210    Objective Loss 2.564210                                        LR 0.100000    Time 0.255532    
2024-04-23 16:11:17,329 - Epoch: [12][  200/  296]    Overall Loss 1.284050    Objective Loss 1.284050                                        LR 0.000320    Time 0.225650    
2024-04-23 16:11:19,982 - Epoch: [16][  110/  267]    Overall Loss 2.570255    Objective Loss 2.570255                                        LR 0.100000    Time 0.257983    
2024-04-23 16:11:22,277 - Epoch: [16][  120/  267]    Overall Loss 2.565999    Objective Loss 2.565999                                        LR 0.100000    Time 0.255543    
2024-04-23 16:11:25,128 - Epoch: [16][  130/  267]    Overall Loss 2.564196    Objective Loss 2.564196                                        LR 0.100000    Time 0.257793    
2024-04-23 16:11:27,471 - Epoch: [16][  140/  267]    Overall Loss 2.552930    Objective Loss 2.552930                                        LR 0.100000    Time 0.256093    
2024-04-23 16:11:30,132 - Epoch: [16][  150/  267]    Overall Loss 2.543459    Objective Loss 2.543459                                        LR 0.100000    Time 0.256743    
2024-04-23 16:11:32,054 - Epoch: [16][  160/  267]    Overall Loss 2.543736    Objective Loss 2.543736                                        LR 0.100000    Time 0.252693    
2024-04-23 16:11:34,968 - Epoch: [16][  170/  267]    Overall Loss 2.539739    Objective Loss 2.539739                                        LR 0.100000    Time 0.254949    
2024-04-23 16:11:36,891 - Epoch: [16][  180/  267]    Overall Loss 2.537957    Objective Loss 2.537957                                        LR 0.100000    Time 0.251452    
2024-04-23 16:11:38,615 - Epoch: [12][  296/  296]    Overall Loss 1.287255    Objective Loss 1.287255    Top1 57.377049    Top5 88.524590    LR 0.000320    Time 0.224316    
2024-04-23 16:11:38,836 - Epoch: [16][  190/  267]    Overall Loss 2.536892    Objective Loss 2.536892                                        LR 0.100000    Time 0.248438    
2024-04-23 16:11:38,861 - --- validate (epoch=12)-----------
2024-04-23 16:11:38,862 - 3925 samples (32 per mini-batch)
2024-04-23 16:11:41,275 - Epoch: [16][  200/  267]    Overall Loss 2.530980    Objective Loss 2.530980                                        LR 0.100000    Time 0.248194    
2024-04-23 16:11:44,220 - Epoch: [16][  210/  267]    Overall Loss 2.528373    Objective Loss 2.528373                                        LR 0.100000    Time 0.250388    
2024-04-23 16:11:45,950 - Epoch: [16][  220/  267]    Overall Loss 2.527814    Objective Loss 2.527814                                        LR 0.100000    Time 0.246859    
2024-04-23 16:11:48,686 - Epoch: [16][  230/  267]    Overall Loss 2.525998    Objective Loss 2.525998                                        LR 0.100000    Time 0.248009    
2024-04-23 16:11:50,651 - Epoch: [16][  240/  267]    Overall Loss 2.523731    Objective Loss 2.523731                                        LR 0.100000    Time 0.245848    
2024-04-23 16:11:53,451 - Epoch: [16][  250/  267]    Overall Loss 2.523383    Objective Loss 2.523383                                        LR 0.100000    Time 0.247201    
2024-04-23 16:11:55,626 - Epoch: [16][  260/  267]    Overall Loss 2.526191    Objective Loss 2.526191                                        LR 0.100000    Time 0.246050    
2024-04-23 16:11:57,325 - Epoch: [16][  267/  267]    Overall Loss 2.526312    Objective Loss 2.526312    Top1 13.953488    Top5 41.860465    LR 0.100000    Time 0.245952    
2024-04-23 16:11:57,555 - --- validate (epoch=16)-----------
2024-04-23 16:11:57,557 - 946 samples (32 per mini-batch)
2024-04-23 16:12:01,526 - Epoch: [16][   10/   30]    Loss 2.472741    Top1 10.625000    Top5 50.312500    
2024-04-23 16:12:03,163 - Epoch: [12][  100/  123]    Loss 1.287067    Top1 57.500000    Top5 91.062500    
2024-04-23 16:12:03,677 - Epoch: [16][   20/   30]    Loss 2.498388    Top1 9.843750    Top5 48.437500    
2024-04-23 16:12:06,257 - Epoch: [16][   30/   30]    Loss 2.512145    Top1 9.196617    Top5 48.097252    
2024-04-23 16:12:06,447 - ==> Top1: 9.197    Top5: 48.097    Loss: 2.512

2024-04-23 16:12:06,448 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 16:12:06,452 - ==> Best [Top1: 10.571   Top5: 48.837   Sparsity:0.00   Params: 96527 on epoch: 15]
2024-04-23 16:12:06,452 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:12:06,465 - 

2024-04-23 16:12:06,466 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:12:07,674 - Epoch: [12][  123/  123]    Loss 1.295938    Top1 56.968153    Top5 91.082803    
2024-04-23 16:12:07,961 - ==> Top1: 56.968    Top5: 91.083    Loss: 1.296

2024-04-23 16:12:07,970 - ==> Best [Top1: 61.860   Top5: 93.146   Sparsity:0.00   Params: 376752 on epoch: 10]
2024-04-23 16:12:07,971 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:12:08,022 - 

2024-04-23 16:12:08,023 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:12:10,322 - Epoch: [17][   10/  267]    Overall Loss 2.464569    Objective Loss 2.464569                                        LR 0.100000    Time 0.385250    
2024-04-23 16:12:12,550 - Epoch: [17][   20/  267]    Overall Loss 2.494929    Objective Loss 2.494929                                        LR 0.100000    Time 0.303850    
2024-04-23 16:12:15,432 - Epoch: [17][   30/  267]    Overall Loss 2.466559    Objective Loss 2.466559                                        LR 0.100000    Time 0.298520    
2024-04-23 16:12:17,742 - Epoch: [17][   40/  267]    Overall Loss 2.459155    Objective Loss 2.459155                                        LR 0.100000    Time 0.281554    
2024-04-23 16:12:20,487 - Epoch: [17][   50/  267]    Overall Loss 2.448514    Objective Loss 2.448514                                        LR 0.100000    Time 0.280092    
2024-04-23 16:12:23,266 - Epoch: [17][   60/  267]    Overall Loss 2.451863    Objective Loss 2.451863                                        LR 0.100000    Time 0.279664    
2024-04-23 16:12:25,099 - Epoch: [17][   70/  267]    Overall Loss 2.451997    Objective Loss 2.451997                                        LR 0.100000    Time 0.265864    
2024-04-23 16:12:27,769 - Epoch: [17][   80/  267]    Overall Loss 2.454552    Objective Loss 2.454552                                        LR 0.100000    Time 0.265962    
2024-04-23 16:12:30,183 - Epoch: [17][   90/  267]    Overall Loss 2.464316    Objective Loss 2.464316                                        LR 0.100000    Time 0.263200    
2024-04-23 16:12:32,049 - Epoch: [17][  100/  267]    Overall Loss 2.474483    Objective Loss 2.474483                                        LR 0.100000    Time 0.255518    
2024-04-23 16:12:32,301 - Epoch: [13][  100/  296]    Overall Loss 1.260902    Objective Loss 1.260902                                        LR 0.000320    Time 0.242562    
2024-04-23 16:12:34,454 - Epoch: [17][  110/  267]    Overall Loss 2.478358    Objective Loss 2.478358                                        LR 0.100000    Time 0.254126    
2024-04-23 16:12:36,970 - Epoch: [17][  120/  267]    Overall Loss 2.477550    Objective Loss 2.477550                                        LR 0.100000    Time 0.253884    
2024-04-23 16:12:39,042 - Epoch: [17][  130/  267]    Overall Loss 2.478819    Objective Loss 2.478819                                        LR 0.100000    Time 0.250274    
2024-04-23 16:12:42,039 - Epoch: [17][  140/  267]    Overall Loss 2.482515    Objective Loss 2.482515                                        LR 0.100000    Time 0.253759    
2024-04-23 16:12:44,371 - Epoch: [17][  150/  267]    Overall Loss 2.482815    Objective Loss 2.482815                                        LR 0.100000    Time 0.252365    
2024-04-23 16:12:47,472 - Epoch: [17][  160/  267]    Overall Loss 2.485500    Objective Loss 2.485500                                        LR 0.100000    Time 0.255955    
2024-04-23 16:12:49,698 - Epoch: [17][  170/  267]    Overall Loss 2.485583    Objective Loss 2.485583                                        LR 0.100000    Time 0.253961    
2024-04-23 16:12:52,080 - Epoch: [17][  180/  267]    Overall Loss 2.487731    Objective Loss 2.487731                                        LR 0.100000    Time 0.253072    
2024-04-23 16:12:54,363 - Epoch: [13][  200/  296]    Overall Loss 1.285156    Objective Loss 1.285156                                        LR 0.000320    Time 0.231482    
2024-04-23 16:12:54,521 - Epoch: [17][  190/  267]    Overall Loss 2.490549    Objective Loss 2.490549                                        LR 0.100000    Time 0.252584    
2024-04-23 16:12:57,035 - Epoch: [17][  200/  267]    Overall Loss 2.493747    Objective Loss 2.493747                                        LR 0.100000    Time 0.252507    
2024-04-23 16:12:58,799 - Epoch: [17][  210/  267]    Overall Loss 2.495165    Objective Loss 2.495165                                        LR 0.100000    Time 0.248867    
2024-04-23 16:13:01,891 - Epoch: [17][  220/  267]    Overall Loss 2.492851    Objective Loss 2.492851                                        LR 0.100000    Time 0.251594    
2024-04-23 16:13:04,214 - Epoch: [17][  230/  267]    Overall Loss 2.491772    Objective Loss 2.491772                                        LR 0.100000    Time 0.250747    
2024-04-23 16:13:07,610 - Epoch: [17][  240/  267]    Overall Loss 2.492581    Objective Loss 2.492581                                        LR 0.100000    Time 0.254437    
2024-04-23 16:13:09,834 - Epoch: [17][  250/  267]    Overall Loss 2.493403    Objective Loss 2.493403                                        LR 0.100000    Time 0.253143    
2024-04-23 16:13:13,158 - Epoch: [17][  260/  267]    Overall Loss 2.496297    Objective Loss 2.496297                                        LR 0.100000    Time 0.256181    
2024-04-23 16:13:14,250 - Epoch: [17][  267/  267]    Overall Loss 2.499464    Objective Loss 2.499464    Top1 9.302326    Top5 39.534884    LR 0.100000    Time 0.253545    
2024-04-23 16:13:14,440 - --- validate (epoch=17)-----------
2024-04-23 16:13:14,441 - 946 samples (32 per mini-batch)
2024-04-23 16:13:15,125 - Epoch: [13][  296/  296]    Overall Loss 1.289446    Objective Loss 1.289446    Top1 65.573770    Top5 93.442623    LR 0.000320    Time 0.226482    
2024-04-23 16:13:15,322 - --- validate (epoch=13)-----------
2024-04-23 16:13:15,323 - 3925 samples (32 per mini-batch)
2024-04-23 16:13:18,166 - Epoch: [17][   10/   30]    Loss 2.488754    Top1 11.250000    Top5 47.187500    
2024-04-23 16:13:20,214 - Epoch: [17][   20/   30]    Loss 2.478832    Top1 10.312500    Top5 48.437500    
2024-04-23 16:13:22,763 - Epoch: [17][   30/   30]    Loss 2.474980    Top1 10.042283    Top5 49.154334    
2024-04-23 16:13:22,951 - ==> Top1: 10.042    Top5: 49.154    Loss: 2.475

2024-04-23 16:13:22,954 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 16:13:22,957 - ==> Best [Top1: 10.571   Top5: 48.837   Sparsity:0.00   Params: 96527 on epoch: 15]
2024-04-23 16:13:22,958 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:13:22,977 - 

2024-04-23 16:13:22,979 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:13:26,433 - Epoch: [18][   10/  267]    Overall Loss 2.469361    Objective Loss 2.469361                                        LR 0.100000    Time 0.344930    
2024-04-23 16:13:28,623 - Epoch: [18][   20/  267]    Overall Loss 2.467149    Objective Loss 2.467149                                        LR 0.100000    Time 0.281828    
2024-04-23 16:13:31,513 - Epoch: [18][   30/  267]    Overall Loss 2.503312    Objective Loss 2.503312                                        LR 0.100000    Time 0.284100    
2024-04-23 16:13:33,657 - Epoch: [18][   40/  267]    Overall Loss 2.525320    Objective Loss 2.525320                                        LR 0.100000    Time 0.266610    
2024-04-23 16:13:36,400 - Epoch: [18][   50/  267]    Overall Loss 2.517962    Objective Loss 2.517962                                        LR 0.100000    Time 0.268096    
2024-04-23 16:13:38,947 - Epoch: [18][   60/  267]    Overall Loss 2.508903    Objective Loss 2.508903                                        LR 0.100000    Time 0.265803    
2024-04-23 16:13:39,700 - Epoch: [13][  100/  123]    Loss 1.277352    Top1 57.718750    Top5 93.687500    
2024-04-23 16:13:41,820 - Epoch: [18][   70/  267]    Overall Loss 2.491692    Objective Loss 2.491692                                        LR 0.100000    Time 0.268825    
2024-04-23 16:13:43,986 - Epoch: [18][   80/  267]    Overall Loss 2.483087    Objective Loss 2.483087                                        LR 0.100000    Time 0.262256    
2024-04-23 16:13:45,192 - Epoch: [13][  123/  123]    Loss 1.276146    Top1 58.063694    Top5 93.656051    
2024-04-23 16:13:45,498 - ==> Top1: 58.064    Top5: 93.656    Loss: 1.276

2024-04-23 16:13:45,504 - ==> Best [Top1: 61.860   Top5: 93.146   Sparsity:0.00   Params: 376752 on epoch: 10]
2024-04-23 16:13:45,505 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:13:45,551 - 

2024-04-23 16:13:45,552 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:13:46,511 - Epoch: [18][   90/  267]    Overall Loss 2.480970    Objective Loss 2.480970                                        LR 0.100000    Time 0.261146    
2024-04-23 16:13:48,796 - Epoch: [18][  100/  267]    Overall Loss 2.479810    Objective Loss 2.479810                                        LR 0.100000    Time 0.257842    
2024-04-23 16:13:51,274 - Epoch: [18][  110/  267]    Overall Loss 2.480349    Objective Loss 2.480349                                        LR 0.100000    Time 0.256898    
2024-04-23 16:13:53,495 - Epoch: [18][  120/  267]    Overall Loss 2.487434    Objective Loss 2.487434                                        LR 0.100000    Time 0.253972    
2024-04-23 16:13:56,562 - Epoch: [18][  130/  267]    Overall Loss 2.486765    Objective Loss 2.486765                                        LR 0.100000    Time 0.257999    
2024-04-23 16:13:58,707 - Epoch: [18][  140/  267]    Overall Loss 2.494266    Objective Loss 2.494266                                        LR 0.100000    Time 0.254870    
2024-04-23 16:14:01,524 - Epoch: [18][  150/  267]    Overall Loss 2.488392    Objective Loss 2.488392                                        LR 0.100000    Time 0.256605    
2024-04-23 16:14:03,703 - Epoch: [18][  160/  267]    Overall Loss 2.485609    Objective Loss 2.485609                                        LR 0.100000    Time 0.254166    
2024-04-23 16:14:06,368 - Epoch: [18][  170/  267]    Overall Loss 2.481873    Objective Loss 2.481873                                        LR 0.100000    Time 0.254874    
2024-04-23 16:14:08,629 - Epoch: [18][  180/  267]    Overall Loss 2.476867    Objective Loss 2.476867                                        LR 0.100000    Time 0.253257    
2024-04-23 16:14:09,389 - Epoch: [14][  100/  296]    Overall Loss 1.263066    Objective Loss 1.263066                                        LR 0.000320    Time 0.238138    
2024-04-23 16:14:10,813 - Epoch: [18][  190/  267]    Overall Loss 2.472893    Objective Loss 2.472893                                        LR 0.100000    Time 0.251400    
2024-04-23 16:14:12,600 - Epoch: [18][  200/  267]    Overall Loss 2.470172    Objective Loss 2.470172                                        LR 0.100000    Time 0.247750    
2024-04-23 16:14:15,596 - Epoch: [18][  210/  267]    Overall Loss 2.469080    Objective Loss 2.469080                                        LR 0.100000    Time 0.250206    
2024-04-23 16:14:17,128 - Epoch: [18][  220/  267]    Overall Loss 2.471975    Objective Loss 2.471975                                        LR 0.100000    Time 0.245783    
2024-04-23 16:14:19,461 - Epoch: [18][  230/  267]    Overall Loss 2.471832    Objective Loss 2.471832                                        LR 0.100000    Time 0.245232    
2024-04-23 16:14:21,502 - Epoch: [18][  240/  267]    Overall Loss 2.469923    Objective Loss 2.469923                                        LR 0.100000    Time 0.243508    
2024-04-23 16:14:24,405 - Epoch: [18][  250/  267]    Overall Loss 2.467320    Objective Loss 2.467320                                        LR 0.100000    Time 0.245367    
2024-04-23 16:14:26,466 - Epoch: [18][  260/  267]    Overall Loss 2.467445    Objective Loss 2.467445                                        LR 0.100000    Time 0.243844    
2024-04-23 16:14:28,141 - Epoch: [18][  267/  267]    Overall Loss 2.467959    Objective Loss 2.467959    Top1 13.953488    Top5 55.813953    LR 0.100000    Time 0.243716    
2024-04-23 16:14:28,336 - --- validate (epoch=18)-----------
2024-04-23 16:14:28,337 - 946 samples (32 per mini-batch)
2024-04-23 16:14:29,800 - Epoch: [14][  200/  296]    Overall Loss 1.253976    Objective Loss 1.253976                                        LR 0.000320    Time 0.221022    
2024-04-23 16:14:32,003 - Epoch: [18][   10/   30]    Loss 2.436986    Top1 10.937500    Top5 54.687500    
2024-04-23 16:14:34,114 - Epoch: [18][   20/   30]    Loss 2.450852    Top1 10.937500    Top5 51.406250    
2024-04-23 16:14:36,747 - Epoch: [18][   30/   30]    Loss 2.459490    Top1 10.253700    Top5 50.211416    
2024-04-23 16:14:36,987 - ==> Top1: 10.254    Top5: 50.211    Loss: 2.459

2024-04-23 16:14:36,990 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 16:14:36,994 - ==> Best [Top1: 10.571   Top5: 48.837   Sparsity:0.00   Params: 96527 on epoch: 15]
2024-04-23 16:14:36,995 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:14:37,018 - 

2024-04-23 16:14:37,019 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:14:41,283 - Epoch: [19][   10/  267]    Overall Loss 2.512973    Objective Loss 2.512973                                        LR 0.100000    Time 0.426038    
2024-04-23 16:14:43,342 - Epoch: [19][   20/  267]    Overall Loss 2.548978    Objective Loss 2.548978                                        LR 0.100000    Time 0.315804    
2024-04-23 16:14:46,266 - Epoch: [19][   30/  267]    Overall Loss 2.544756    Objective Loss 2.544756                                        LR 0.100000    Time 0.307912    
2024-04-23 16:14:48,296 - Epoch: [19][   40/  267]    Overall Loss 2.550074    Objective Loss 2.550074                                        LR 0.100000    Time 0.281596    
2024-04-23 16:14:51,178 - Epoch: [19][   50/  267]    Overall Loss 2.544890    Objective Loss 2.544890                                        LR 0.100000    Time 0.282846    
2024-04-23 16:14:51,995 - Epoch: [14][  296/  296]    Overall Loss 1.263356    Objective Loss 1.263356    Top1 52.459016    Top5 90.163934    LR 0.000320    Time 0.224258    
2024-04-23 16:14:52,243 - --- validate (epoch=14)-----------
2024-04-23 16:14:52,245 - 3925 samples (32 per mini-batch)
2024-04-23 16:14:53,302 - Epoch: [19][   60/  267]    Overall Loss 2.549228    Objective Loss 2.549228                                        LR 0.100000    Time 0.271049    
2024-04-23 16:14:56,522 - Epoch: [19][   70/  267]    Overall Loss 2.546844    Objective Loss 2.546844                                        LR 0.100000    Time 0.278289    
2024-04-23 16:14:58,197 - Epoch: [19][   80/  267]    Overall Loss 2.545174    Objective Loss 2.545174                                        LR 0.100000    Time 0.264398    
2024-04-23 16:15:00,812 - Epoch: [19][   90/  267]    Overall Loss 2.539777    Objective Loss 2.539777                                        LR 0.100000    Time 0.264036    
2024-04-23 16:15:02,913 - Epoch: [19][  100/  267]    Overall Loss 2.527512    Objective Loss 2.527512                                        LR 0.100000    Time 0.258617    
2024-04-23 16:15:05,341 - Epoch: [19][  110/  267]    Overall Loss 2.523651    Objective Loss 2.523651                                        LR 0.100000    Time 0.257148    
2024-04-23 16:15:07,323 - Epoch: [19][  120/  267]    Overall Loss 2.519612    Objective Loss 2.519612                                        LR 0.100000    Time 0.252212    
2024-04-23 16:15:09,886 - Epoch: [19][  130/  267]    Overall Loss 2.514414    Objective Loss 2.514414                                        LR 0.100000    Time 0.252505    
2024-04-23 16:15:12,098 - Epoch: [19][  140/  267]    Overall Loss 2.511042    Objective Loss 2.511042                                        LR 0.100000    Time 0.250245    
2024-04-23 16:15:14,168 - Epoch: [19][  150/  267]    Overall Loss 2.509695    Objective Loss 2.509695                                        LR 0.100000    Time 0.247346    
2024-04-23 16:15:16,465 - Epoch: [19][  160/  267]    Overall Loss 2.504591    Objective Loss 2.504591                                        LR 0.100000    Time 0.246220    
2024-04-23 16:15:16,606 - Epoch: [14][  100/  123]    Loss 1.245410    Top1 58.843750    Top5 92.906250    
2024-04-23 16:15:19,344 - Epoch: [19][  170/  267]    Overall Loss 2.499702    Objective Loss 2.499702                                        LR 0.100000    Time 0.248660    
2024-04-23 16:15:21,556 - Epoch: [14][  123/  123]    Loss 1.241396    Top1 58.649682    Top5 93.197452    
2024-04-23 16:15:21,568 - Epoch: [19][  180/  267]    Overall Loss 2.492550    Objective Loss 2.492550                                        LR 0.100000    Time 0.247181    
2024-04-23 16:15:21,855 - ==> Top1: 58.650    Top5: 93.197    Loss: 1.241

2024-04-23 16:15:21,867 - ==> Best [Top1: 61.860   Top5: 93.146   Sparsity:0.00   Params: 376752 on epoch: 10]
2024-04-23 16:15:21,868 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:15:21,954 - 

2024-04-23 16:15:21,955 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:15:25,027 - Epoch: [19][  190/  267]    Overall Loss 2.491648    Objective Loss 2.491648                                        LR 0.100000    Time 0.252362    
2024-04-23 16:15:27,911 - Epoch: [19][  200/  267]    Overall Loss 2.487393    Objective Loss 2.487393                                        LR 0.100000    Time 0.254145    
2024-04-23 16:15:30,861 - Epoch: [19][  210/  267]    Overall Loss 2.489105    Objective Loss 2.489105                                        LR 0.100000    Time 0.256071    
2024-04-23 16:15:32,973 - Epoch: [19][  220/  267]    Overall Loss 2.493653    Objective Loss 2.493653                                        LR 0.100000    Time 0.254021    
2024-04-23 16:15:35,464 - Epoch: [19][  230/  267]    Overall Loss 2.501049    Objective Loss 2.501049                                        LR 0.100000    Time 0.253793    
2024-04-23 16:15:37,460 - Epoch: [19][  240/  267]    Overall Loss 2.502893    Objective Loss 2.502893                                        LR 0.100000    Time 0.251521    
2024-04-23 16:15:40,244 - Epoch: [19][  250/  267]    Overall Loss 2.498552    Objective Loss 2.498552                                        LR 0.100000    Time 0.252583    
2024-04-23 16:15:41,863 - Epoch: [19][  260/  267]    Overall Loss 2.499736    Objective Loss 2.499736                                        LR 0.100000    Time 0.249084    
2024-04-23 16:15:43,394 - Epoch: [19][  267/  267]    Overall Loss 2.498341    Objective Loss 2.498341    Top1 9.302326    Top5 44.186047    LR 0.100000    Time 0.248280    
2024-04-23 16:15:43,634 - --- validate (epoch=19)-----------
2024-04-23 16:15:43,635 - 946 samples (32 per mini-batch)
2024-04-23 16:15:47,451 - Epoch: [19][   10/   30]    Loss 2.431975    Top1 14.375000    Top5 52.812500    
2024-04-23 16:15:48,500 - Epoch: [15][  100/  296]    Overall Loss 1.267634    Objective Loss 1.267634                                        LR 0.000320    Time 0.265181    
2024-04-23 16:15:49,552 - Epoch: [19][   20/   30]    Loss 2.444693    Top1 10.468750    Top5 50.781250    
2024-04-23 16:15:51,393 - Epoch: [19][   30/   30]    Loss 2.442888    Top1 10.359408    Top5 50.211416    
2024-04-23 16:15:51,591 - ==> Top1: 10.359    Top5: 50.211    Loss: 2.443

2024-04-23 16:15:51,593 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 16:15:51,597 - ==> Best [Top1: 10.571   Top5: 48.837   Sparsity:0.00   Params: 96527 on epoch: 15]
2024-04-23 16:15:51,598 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:15:51,615 - 

2024-04-23 16:15:51,615 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:15:55,271 - Epoch: [20][   10/  267]    Overall Loss 2.598669    Objective Loss 2.598669                                        LR 0.100000    Time 0.365200    
2024-04-23 16:15:57,119 - Epoch: [20][   20/  267]    Overall Loss 2.544896    Objective Loss 2.544896                                        LR 0.100000    Time 0.274832    
2024-04-23 16:16:00,107 - Epoch: [20][   30/  267]    Overall Loss 2.488141    Objective Loss 2.488141                                        LR 0.100000    Time 0.282711    
2024-04-23 16:16:02,230 - Epoch: [20][   40/  267]    Overall Loss 2.454031    Objective Loss 2.454031                                        LR 0.100000    Time 0.265015    
2024-04-23 16:16:05,317 - Epoch: [20][   50/  267]    Overall Loss 2.440629    Objective Loss 2.440629                                        LR 0.100000    Time 0.273698    
2024-04-23 16:16:07,431 - Epoch: [20][   60/  267]    Overall Loss 2.447164    Objective Loss 2.447164                                        LR 0.100000    Time 0.263261    
2024-04-23 16:16:09,196 - Epoch: [15][  200/  296]    Overall Loss 1.250869    Objective Loss 1.250869                                        LR 0.000320    Time 0.235960    
2024-04-23 16:16:10,482 - Epoch: [20][   70/  267]    Overall Loss 2.439540    Objective Loss 2.439540                                        LR 0.100000    Time 0.269193    
2024-04-23 16:16:12,895 - Epoch: [20][   80/  267]    Overall Loss 2.444517    Objective Loss 2.444517                                        LR 0.100000    Time 0.265658    
2024-04-23 16:16:15,936 - Epoch: [20][   90/  267]    Overall Loss 2.448087    Objective Loss 2.448087                                        LR 0.100000    Time 0.269892    
2024-04-23 16:16:18,132 - Epoch: [20][  100/  267]    Overall Loss 2.451427    Objective Loss 2.451427                                        LR 0.100000    Time 0.264836    
2024-04-23 16:16:21,050 - Epoch: [20][  110/  267]    Overall Loss 2.463921    Objective Loss 2.463921                                        LR 0.100000    Time 0.267253    
2024-04-23 16:16:23,046 - Epoch: [20][  120/  267]    Overall Loss 2.471767    Objective Loss 2.471767                                        LR 0.100000    Time 0.261584    
2024-04-23 16:16:25,898 - Epoch: [20][  130/  267]    Overall Loss 2.479420    Objective Loss 2.479420                                        LR 0.100000    Time 0.263378    
2024-04-23 16:16:28,094 - Epoch: [20][  140/  267]    Overall Loss 2.485239    Objective Loss 2.485239                                        LR 0.100000    Time 0.260223    
2024-04-23 16:16:30,543 - Epoch: [15][  296/  296]    Overall Loss 1.255365    Objective Loss 1.255365    Top1 67.213115    Top5 100.000000    LR 0.000320    Time 0.231480    
2024-04-23 16:16:30,657 - Epoch: [20][  150/  267]    Overall Loss 2.486632    Objective Loss 2.486632                                        LR 0.100000    Time 0.259938    
2024-04-23 16:16:30,672 - --- validate (epoch=15)-----------
2024-04-23 16:16:30,673 - 3925 samples (32 per mini-batch)
2024-04-23 16:16:32,849 - Epoch: [20][  160/  267]    Overall Loss 2.483625    Objective Loss 2.483625                                        LR 0.100000    Time 0.257375    
2024-04-23 16:16:35,970 - Epoch: [20][  170/  267]    Overall Loss 2.485020    Objective Loss 2.485020                                        LR 0.100000    Time 0.260573    
2024-04-23 16:16:38,081 - Epoch: [20][  180/  267]    Overall Loss 2.487069    Objective Loss 2.487069                                        LR 0.100000    Time 0.257805    
2024-04-23 16:16:40,196 - Epoch: [20][  190/  267]    Overall Loss 2.488873    Objective Loss 2.488873                                        LR 0.100000    Time 0.255354    
2024-04-23 16:16:41,793 - Epoch: [20][  200/  267]    Overall Loss 2.494031    Objective Loss 2.494031                                        LR 0.100000    Time 0.250555    
2024-04-23 16:16:44,611 - Epoch: [20][  210/  267]    Overall Loss 2.494061    Objective Loss 2.494061                                        LR 0.100000    Time 0.252030    
2024-04-23 16:16:46,430 - Epoch: [20][  220/  267]    Overall Loss 2.492064    Objective Loss 2.492064                                        LR 0.100000    Time 0.248830    
2024-04-23 16:16:48,800 - Epoch: [20][  230/  267]    Overall Loss 2.487653    Objective Loss 2.487653                                        LR 0.100000    Time 0.248301    
2024-04-23 16:16:50,904 - Epoch: [20][  240/  267]    Overall Loss 2.486758    Objective Loss 2.486758                                        LR 0.100000    Time 0.246709    
2024-04-23 16:16:53,974 - Epoch: [20][  250/  267]    Overall Loss 2.485782    Objective Loss 2.485782                                        LR 0.100000    Time 0.249109    
2024-04-23 16:16:54,495 - Epoch: [15][  100/  123]    Loss 1.043781    Top1 65.093750    Top5 95.250000    
2024-04-23 16:16:55,846 - Epoch: [20][  260/  267]    Overall Loss 2.485652    Objective Loss 2.485652                                        LR 0.100000    Time 0.246716    
2024-04-23 16:16:57,187 - Epoch: [20][  267/  267]    Overall Loss 2.483913    Objective Loss 2.483913    Top1 6.976744    Top5 72.093023    LR 0.100000    Time 0.245262    
2024-04-23 16:16:57,396 - --- validate (epoch=20)-----------
2024-04-23 16:16:57,398 - 946 samples (32 per mini-batch)
2024-04-23 16:16:58,641 - Epoch: [15][  123/  123]    Loss 1.061303    Top1 64.611465    Top5 95.133758    
2024-04-23 16:16:58,843 - ==> Top1: 64.611    Top5: 95.134    Loss: 1.061

2024-04-23 16:16:58,848 - ==> Best [Top1: 64.611   Top5: 95.134   Sparsity:0.00   Params: 376752 on epoch: 15]
2024-04-23 16:16:58,849 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:16:58,912 - 

2024-04-23 16:16:58,912 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:17:02,425 - Epoch: [20][   10/   30]    Loss 2.733694    Top1 8.750000    Top5 45.625000    
2024-04-23 16:17:04,979 - Epoch: [20][   20/   30]    Loss 2.682982    Top1 10.312500    Top5 49.062500    
2024-04-23 16:17:07,588 - Epoch: [20][   30/   30]    Loss 2.690929    Top1 9.830867    Top5 48.942918    
2024-04-23 16:17:07,814 - ==> Top1: 9.831    Top5: 48.943    Loss: 2.691

2024-04-23 16:17:07,816 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 16:17:07,821 - ==> Best [Top1: 10.571   Top5: 48.837   Sparsity:0.00   Params: 96527 on epoch: 15]
2024-04-23 16:17:07,821 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:17:07,841 - 

2024-04-23 16:17:07,842 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:17:11,852 - Epoch: [21][   10/  267]    Overall Loss 2.637806    Objective Loss 2.637806                                        LR 0.100000    Time 0.400653    
2024-04-23 16:17:14,063 - Epoch: [21][   20/  267]    Overall Loss 2.552084    Objective Loss 2.552084                                        LR 0.100000    Time 0.310663    
2024-04-23 16:17:17,717 - Epoch: [21][   30/  267]    Overall Loss 2.498734    Objective Loss 2.498734                                        LR 0.100000    Time 0.328650    
2024-04-23 16:17:18,913 - Epoch: [16][  100/  296]    Overall Loss 1.212805    Objective Loss 1.212805                                        LR 0.000320    Time 0.199777    
2024-04-23 16:17:19,851 - Epoch: [21][   40/  267]    Overall Loss 2.469076    Objective Loss 2.469076                                        LR 0.100000    Time 0.299769    
2024-04-23 16:17:23,118 - Epoch: [21][   50/  267]    Overall Loss 2.468904    Objective Loss 2.468904                                        LR 0.100000    Time 0.305094    
2024-04-23 16:17:25,434 - Epoch: [21][   60/  267]    Overall Loss 2.470328    Objective Loss 2.470328                                        LR 0.100000    Time 0.292803    
2024-04-23 16:17:28,991 - Epoch: [21][   70/  267]    Overall Loss 2.461649    Objective Loss 2.461649                                        LR 0.100000    Time 0.301736    
2024-04-23 16:17:31,197 - Epoch: [21][   80/  267]    Overall Loss 2.456807    Objective Loss 2.456807                                        LR 0.100000    Time 0.291552    
2024-04-23 16:17:34,414 - Epoch: [21][   90/  267]    Overall Loss 2.452268    Objective Loss 2.452268                                        LR 0.100000    Time 0.294862    
2024-04-23 16:17:37,142 - Epoch: [21][  100/  267]    Overall Loss 2.442374    Objective Loss 2.442374                                        LR 0.100000    Time 0.292620    
2024-04-23 16:17:37,515 - Epoch: [16][  200/  296]    Overall Loss 1.207749    Objective Loss 1.207749                                        LR 0.000320    Time 0.192796    
2024-04-23 16:17:40,539 - Epoch: [21][  110/  267]    Overall Loss 2.438137    Objective Loss 2.438137                                        LR 0.100000    Time 0.296873    
2024-04-23 16:17:42,927 - Epoch: [21][  120/  267]    Overall Loss 2.433468    Objective Loss 2.433468                                        LR 0.100000    Time 0.292010    
2024-04-23 16:17:45,955 - Epoch: [21][  130/  267]    Overall Loss 2.428975    Objective Loss 2.428975                                        LR 0.100000    Time 0.292811    
2024-04-23 16:17:48,033 - Epoch: [21][  140/  267]    Overall Loss 2.430829    Objective Loss 2.430829                                        LR 0.100000    Time 0.286723    
2024-04-23 16:17:50,432 - Epoch: [21][  150/  267]    Overall Loss 2.431557    Objective Loss 2.431557                                        LR 0.100000    Time 0.283585    
2024-04-23 16:17:52,146 - Epoch: [21][  160/  267]    Overall Loss 2.430824    Objective Loss 2.430824                                        LR 0.100000    Time 0.276553    
2024-04-23 16:17:55,080 - Epoch: [21][  170/  267]    Overall Loss 2.434507    Objective Loss 2.434507                                        LR 0.100000    Time 0.277528    
2024-04-23 16:17:57,228 - Epoch: [21][  180/  267]    Overall Loss 2.435117    Objective Loss 2.435117                                        LR 0.100000    Time 0.274031    
2024-04-23 16:17:58,900 - Epoch: [16][  296/  296]    Overall Loss 1.227712    Objective Loss 1.227712    Top1 47.540984    Top5 88.524590    LR 0.000320    Time 0.202446    
2024-04-23 16:17:59,084 - --- validate (epoch=16)-----------
2024-04-23 16:17:59,085 - 3925 samples (32 per mini-batch)
2024-04-23 16:17:59,581 - Epoch: [21][  190/  267]    Overall Loss 2.432248    Objective Loss 2.432248                                        LR 0.100000    Time 0.271973    
2024-04-23 16:18:02,220 - Epoch: [21][  200/  267]    Overall Loss 2.430390    Objective Loss 2.430390                                        LR 0.100000    Time 0.271552    
2024-04-23 16:18:05,124 - Epoch: [21][  210/  267]    Overall Loss 2.429258    Objective Loss 2.429258                                        LR 0.100000    Time 0.272437    
2024-04-23 16:18:07,109 - Epoch: [21][  220/  267]    Overall Loss 2.438779    Objective Loss 2.438779                                        LR 0.100000    Time 0.269051    
2024-04-23 16:18:10,170 - Epoch: [21][  230/  267]    Overall Loss 2.442274    Objective Loss 2.442274                                        LR 0.100000    Time 0.270646    
2024-04-23 16:18:12,518 - Epoch: [21][  240/  267]    Overall Loss 2.446514    Objective Loss 2.446514                                        LR 0.100000    Time 0.269141    
2024-04-23 16:18:15,340 - Epoch: [21][  250/  267]    Overall Loss 2.447911    Objective Loss 2.447911                                        LR 0.100000    Time 0.269652    
2024-04-23 16:18:17,747 - Epoch: [21][  260/  267]    Overall Loss 2.446574    Objective Loss 2.446574                                        LR 0.100000    Time 0.268524    
2024-04-23 16:18:19,405 - Epoch: [21][  267/  267]    Overall Loss 2.445382    Objective Loss 2.445382    Top1 13.953488    Top5 51.162791    LR 0.100000    Time 0.267686    
2024-04-23 16:18:19,664 - --- validate (epoch=21)-----------
2024-04-23 16:18:19,666 - 946 samples (32 per mini-batch)
2024-04-23 16:18:22,229 - Epoch: [16][  100/  123]    Loss 1.088273    Top1 64.031250    Top5 93.750000    
2024-04-23 16:18:23,060 - Epoch: [21][   10/   30]    Loss 2.332715    Top1 11.875000    Top5 53.750000    
2024-04-23 16:18:25,413 - Epoch: [21][   20/   30]    Loss 2.343954    Top1 10.625000    Top5 52.656250    
2024-04-23 16:18:26,918 - Epoch: [16][  123/  123]    Loss 1.085838    Top1 64.382166    Top5 93.808917    
2024-04-23 16:18:27,163 - ==> Top1: 64.382    Top5: 93.809    Loss: 1.086

2024-04-23 16:18:27,169 - ==> Best [Top1: 64.611   Top5: 95.134   Sparsity:0.00   Params: 376752 on epoch: 15]
2024-04-23 16:18:27,170 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:18:27,220 - 

2024-04-23 16:18:27,221 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:18:27,654 - Epoch: [21][   30/   30]    Loss 2.374728    Top1 10.465116    Top5 49.788584    
2024-04-23 16:18:27,885 - ==> Top1: 10.465    Top5: 49.789    Loss: 2.375

2024-04-23 16:18:27,887 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 16:18:27,890 - ==> Best [Top1: 10.571   Top5: 48.837   Sparsity:0.00   Params: 96527 on epoch: 15]
2024-04-23 16:18:27,890 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:18:27,901 - 

2024-04-23 16:18:27,902 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:18:30,750 - Epoch: [22][   10/  267]    Overall Loss 2.482248    Objective Loss 2.482248                                        LR 0.100000    Time 0.284509    
2024-04-23 16:18:33,275 - Epoch: [22][   20/  267]    Overall Loss 2.468421    Objective Loss 2.468421                                        LR 0.100000    Time 0.268378    
2024-04-23 16:18:36,168 - Epoch: [22][   30/  267]    Overall Loss 2.483395    Objective Loss 2.483395                                        LR 0.100000    Time 0.275250    
2024-04-23 16:18:38,459 - Epoch: [22][   40/  267]    Overall Loss 2.499811    Objective Loss 2.499811                                        LR 0.100000    Time 0.263639    
2024-04-23 16:18:41,439 - Epoch: [22][   50/  267]    Overall Loss 2.483352    Objective Loss 2.483352                                        LR 0.100000    Time 0.270447    
2024-04-23 16:18:43,427 - Epoch: [22][   60/  267]    Overall Loss 2.481251    Objective Loss 2.481251                                        LR 0.100000    Time 0.258445    
2024-04-23 16:18:46,466 - Epoch: [22][   70/  267]    Overall Loss 2.467470    Objective Loss 2.467470                                        LR 0.100000    Time 0.264897    
2024-04-23 16:18:48,839 - Epoch: [22][   80/  267]    Overall Loss 2.456526    Objective Loss 2.456526                                        LR 0.100000    Time 0.261406    
2024-04-23 16:18:50,005 - Epoch: [17][  100/  296]    Overall Loss 1.254141    Objective Loss 1.254141                                        LR 0.000320    Time 0.227627    
2024-04-23 16:18:52,465 - Epoch: [22][   90/  267]    Overall Loss 2.451332    Objective Loss 2.451332                                        LR 0.100000    Time 0.272615    
2024-04-23 16:18:54,992 - Epoch: [22][  100/  267]    Overall Loss 2.448048    Objective Loss 2.448048                                        LR 0.100000    Time 0.270589    
2024-04-23 16:18:58,273 - Epoch: [22][  110/  267]    Overall Loss 2.463969    Objective Loss 2.463969                                        LR 0.100000    Time 0.275786    
2024-04-23 16:19:01,023 - Epoch: [22][  120/  267]    Overall Loss 2.467377    Objective Loss 2.467377                                        LR 0.100000    Time 0.275693    
2024-04-23 16:19:04,576 - Epoch: [22][  130/  267]    Overall Loss 2.471430    Objective Loss 2.471430                                        LR 0.100000    Time 0.281794    
2024-04-23 16:19:06,741 - Epoch: [17][  200/  296]    Overall Loss 1.233015    Objective Loss 1.233015                                        LR 0.000320    Time 0.197397    
2024-04-23 16:19:06,793 - Epoch: [22][  140/  267]    Overall Loss 2.471097    Objective Loss 2.471097                                        LR 0.100000    Time 0.277480    
2024-04-23 16:19:10,009 - Epoch: [22][  150/  267]    Overall Loss 2.473039    Objective Loss 2.473039                                        LR 0.100000    Time 0.280395    
2024-04-23 16:19:12,286 - Epoch: [22][  160/  267]    Overall Loss 2.476994    Objective Loss 2.476994                                        LR 0.100000    Time 0.277082    
2024-04-23 16:19:15,382 - Epoch: [22][  170/  267]    Overall Loss 2.477404    Objective Loss 2.477404                                        LR 0.100000    Time 0.278978    
2024-04-23 16:19:17,213 - Epoch: [22][  180/  267]    Overall Loss 2.477829    Objective Loss 2.477829                                        LR 0.100000    Time 0.273633    
2024-04-23 16:19:20,161 - Epoch: [22][  190/  267]    Overall Loss 2.477963    Objective Loss 2.477963                                        LR 0.100000    Time 0.274733    
2024-04-23 16:19:22,527 - Epoch: [22][  200/  267]    Overall Loss 2.475119    Objective Loss 2.475119                                        LR 0.100000    Time 0.272808    
2024-04-23 16:19:24,914 - Epoch: [22][  210/  267]    Overall Loss 2.476981    Objective Loss 2.476981                                        LR 0.100000    Time 0.271169    
2024-04-23 16:19:25,229 - Epoch: [17][  296/  296]    Overall Loss 1.226125    Objective Loss 1.226125    Top1 72.131148    Top5 95.081967    LR 0.000320    Time 0.195774    
2024-04-23 16:19:25,428 - --- validate (epoch=17)-----------
2024-04-23 16:19:25,429 - 3925 samples (32 per mini-batch)
2024-04-23 16:19:27,476 - Epoch: [22][  220/  267]    Overall Loss 2.472826    Objective Loss 2.472826                                        LR 0.100000    Time 0.270478    
2024-04-23 16:19:31,205 - Epoch: [22][  230/  267]    Overall Loss 2.473855    Objective Loss 2.473855                                        LR 0.100000    Time 0.274917    
2024-04-23 16:19:33,112 - Epoch: [22][  240/  267]    Overall Loss 2.475624    Objective Loss 2.475624                                        LR 0.100000    Time 0.271397    
2024-04-23 16:19:35,617 - Epoch: [22][  250/  267]    Overall Loss 2.477767    Objective Loss 2.477767                                        LR 0.100000    Time 0.270545    
2024-04-23 16:19:38,910 - Epoch: [22][  260/  267]    Overall Loss 2.484315    Objective Loss 2.484315                                        LR 0.100000    Time 0.272791    
2024-04-23 16:19:39,720 - Epoch: [22][  267/  267]    Overall Loss 2.487682    Objective Loss 2.487682    Top1 0.000000    Top5 25.581395    LR 0.100000    Time 0.268655    
2024-04-23 16:19:39,951 - --- validate (epoch=22)-----------
2024-04-23 16:19:39,953 - 946 samples (32 per mini-batch)
2024-04-23 16:19:44,389 - Epoch: [22][   10/   30]    Loss 2.339650    Top1 9.687500    Top5 50.937500    
2024-04-23 16:19:46,908 - Epoch: [22][   20/   30]    Loss 2.354965    Top1 9.062500    Top5 48.437500    
2024-04-23 16:19:49,448 - Epoch: [17][  100/  123]    Loss 1.072768    Top1 64.156250    Top5 95.031250    
2024-04-23 16:19:49,983 - Epoch: [22][   30/   30]    Loss 2.366711    Top1 9.196617    Top5 47.780127    
2024-04-23 16:19:50,247 - ==> Top1: 9.197    Top5: 47.780    Loss: 2.367

2024-04-23 16:19:50,250 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 16:19:50,257 - ==> Best [Top1: 10.571   Top5: 48.837   Sparsity:0.00   Params: 96527 on epoch: 15]
2024-04-23 16:19:50,258 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:19:50,279 - 

2024-04-23 16:19:50,280 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:19:52,768 - Epoch: [17][  123/  123]    Loss 1.079407    Top1 64.101911    Top5 94.751592    
2024-04-23 16:19:52,921 - ==> Top1: 64.102    Top5: 94.752    Loss: 1.079

2024-04-23 16:19:52,927 - ==> Best [Top1: 64.611   Top5: 95.134   Sparsity:0.00   Params: 376752 on epoch: 15]
2024-04-23 16:19:52,928 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:19:52,967 - 

2024-04-23 16:19:52,968 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:19:54,718 - Epoch: [23][   10/  267]    Overall Loss 2.582714    Objective Loss 2.582714                                        LR 0.100000    Time 0.443195    
2024-04-23 16:19:57,710 - Epoch: [23][   20/  267]    Overall Loss 2.518386    Objective Loss 2.518386                                        LR 0.100000    Time 0.370763    
2024-04-23 16:20:01,158 - Epoch: [23][   30/  267]    Overall Loss 2.500277    Objective Loss 2.500277                                        LR 0.100000    Time 0.362029    
2024-04-23 16:20:02,931 - Epoch: [23][   40/  267]    Overall Loss 2.498324    Objective Loss 2.498324                                        LR 0.100000    Time 0.315778    
2024-04-23 16:20:05,209 - Epoch: [23][   50/  267]    Overall Loss 2.499915    Objective Loss 2.499915                                        LR 0.100000    Time 0.298096    
2024-04-23 16:20:06,984 - Epoch: [23][   60/  267]    Overall Loss 2.482532    Objective Loss 2.482532                                        LR 0.100000    Time 0.277961    
2024-04-23 16:20:09,589 - Epoch: [23][   70/  267]    Overall Loss 2.481905    Objective Loss 2.481905                                        LR 0.100000    Time 0.275428    
2024-04-23 16:20:11,472 - Epoch: [23][   80/  267]    Overall Loss 2.474260    Objective Loss 2.474260                                        LR 0.100000    Time 0.264502    
2024-04-23 16:20:13,875 - Epoch: [23][   90/  267]    Overall Loss 2.475014    Objective Loss 2.475014                                        LR 0.100000    Time 0.261775    
2024-04-23 16:20:15,132 - Epoch: [18][  100/  296]    Overall Loss 1.197909    Objective Loss 1.197909                                        LR 0.000320    Time 0.221410    
2024-04-23 16:20:16,787 - Epoch: [23][  100/  267]    Overall Loss 2.469995    Objective Loss 2.469995                                        LR 0.100000    Time 0.264690    
2024-04-23 16:20:18,890 - Epoch: [23][  110/  267]    Overall Loss 2.469375    Objective Loss 2.469375                                        LR 0.100000    Time 0.259715    
2024-04-23 16:20:21,828 - Epoch: [23][  120/  267]    Overall Loss 2.465438    Objective Loss 2.465438                                        LR 0.100000    Time 0.262532    
2024-04-23 16:20:23,804 - Epoch: [23][  130/  267]    Overall Loss 2.463508    Objective Loss 2.463508                                        LR 0.100000    Time 0.257516    
2024-04-23 16:20:26,707 - Epoch: [23][  140/  267]    Overall Loss 2.462653    Objective Loss 2.462653                                        LR 0.100000    Time 0.259838    
2024-04-23 16:20:28,697 - Epoch: [23][  150/  267]    Overall Loss 2.456307    Objective Loss 2.456307                                        LR 0.100000    Time 0.255768    
2024-04-23 16:20:31,467 - Epoch: [23][  160/  267]    Overall Loss 2.447074    Objective Loss 2.447074                                        LR 0.100000    Time 0.257077    
2024-04-23 16:20:33,426 - Epoch: [23][  170/  267]    Overall Loss 2.441789    Objective Loss 2.441789                                        LR 0.100000    Time 0.253457    
2024-04-23 16:20:35,542 - Epoch: [23][  180/  267]    Overall Loss 2.434096    Objective Loss 2.434096                                        LR 0.100000    Time 0.251112    
2024-04-23 16:20:38,387 - Epoch: [23][  190/  267]    Overall Loss 2.427113    Objective Loss 2.427113                                        LR 0.100000    Time 0.252853    
2024-04-23 16:20:38,437 - Epoch: [18][  200/  296]    Overall Loss 1.221352    Objective Loss 1.221352                                        LR 0.000320    Time 0.227118    
2024-04-23 16:20:40,455 - Epoch: [23][  200/  267]    Overall Loss 2.420646    Objective Loss 2.420646                                        LR 0.100000    Time 0.250536    
2024-04-23 16:20:43,319 - Epoch: [23][  210/  267]    Overall Loss 2.415039    Objective Loss 2.415039                                        LR 0.100000    Time 0.252231    
2024-04-23 16:20:45,255 - Epoch: [23][  220/  267]    Overall Loss 2.410321    Objective Loss 2.410321                                        LR 0.100000    Time 0.249556    
2024-04-23 16:20:48,157 - Epoch: [23][  230/  267]    Overall Loss 2.405935    Objective Loss 2.405935                                        LR 0.100000    Time 0.251305    
2024-04-23 16:20:50,725 - Epoch: [23][  240/  267]    Overall Loss 2.401884    Objective Loss 2.401884                                        LR 0.100000    Time 0.251522    
2024-04-23 16:20:53,201 - Epoch: [23][  250/  267]    Overall Loss 2.397759    Objective Loss 2.397759                                        LR 0.100000    Time 0.251352    
2024-04-23 16:20:55,018 - Epoch: [23][  260/  267]    Overall Loss 2.394343    Objective Loss 2.394343                                        LR 0.100000    Time 0.248662    
2024-04-23 16:20:56,215 - Epoch: [23][  267/  267]    Overall Loss 2.392131    Objective Loss 2.392131    Top1 11.627907    Top5 53.488372    LR 0.100000    Time 0.246620    
2024-04-23 16:20:56,469 - --- validate (epoch=23)-----------
2024-04-23 16:20:56,471 - 946 samples (32 per mini-batch)
2024-04-23 16:20:58,946 - Epoch: [18][  296/  296]    Overall Loss 1.221065    Objective Loss 1.221065    Top1 49.180328    Top5 91.803279    LR 0.000320    Time 0.222679    
2024-04-23 16:20:59,123 - --- validate (epoch=18)-----------
2024-04-23 16:20:59,124 - 3925 samples (32 per mini-batch)
2024-04-23 16:21:00,150 - Epoch: [23][   10/   30]    Loss 2.304161    Top1 12.187500    Top5 47.812500    
2024-04-23 16:21:01,834 - Epoch: [23][   20/   30]    Loss 2.303514    Top1 10.937500    Top5 48.593750    
2024-04-23 16:21:04,268 - Epoch: [23][   30/   30]    Loss 2.303490    Top1 10.993658    Top5 49.154334    
2024-04-23 16:21:04,473 - ==> Top1: 10.994    Top5: 49.154    Loss: 2.303

2024-04-23 16:21:04,475 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 16:21:04,480 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:21:04,481 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:21:04,508 - 

2024-04-23 16:21:04,509 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:21:08,664 - Epoch: [24][   10/  267]    Overall Loss 2.301695    Objective Loss 2.301695                                        LR 0.100000    Time 0.415063    
2024-04-23 16:21:10,706 - Epoch: [24][   20/  267]    Overall Loss 2.304418    Objective Loss 2.304418                                        LR 0.100000    Time 0.309484    
2024-04-23 16:21:13,745 - Epoch: [24][   30/  267]    Overall Loss 2.304652    Objective Loss 2.304652                                        LR 0.100000    Time 0.307524    
2024-04-23 16:21:15,833 - Epoch: [24][   40/  267]    Overall Loss 2.302712    Objective Loss 2.302712                                        LR 0.100000    Time 0.282778    
2024-04-23 16:21:18,771 - Epoch: [24][   50/  267]    Overall Loss 2.301997    Objective Loss 2.301997                                        LR 0.100000    Time 0.284916    
2024-04-23 16:21:20,931 - Epoch: [24][   60/  267]    Overall Loss 2.301635    Objective Loss 2.301635                                        LR 0.100000    Time 0.273392    
2024-04-23 16:21:23,777 - Epoch: [24][   70/  267]    Overall Loss 2.301769    Objective Loss 2.301769                                        LR 0.100000    Time 0.274938    
2024-04-23 16:21:23,958 - Epoch: [18][  100/  123]    Loss 1.152451    Top1 62.156250    Top5 94.000000    
2024-04-23 16:21:25,853 - Epoch: [24][   80/  267]    Overall Loss 2.302744    Objective Loss 2.302744                                        LR 0.100000    Time 0.266480    
2024-04-23 16:21:28,612 - Epoch: [24][   90/  267]    Overall Loss 2.302324    Objective Loss 2.302324                                        LR 0.100000    Time 0.267491    
2024-04-23 16:21:28,785 - Epoch: [18][  123/  123]    Loss 1.155048    Top1 61.859873    Top5 94.140127    
2024-04-23 16:21:28,963 - ==> Top1: 61.860    Top5: 94.140    Loss: 1.155

2024-04-23 16:21:28,971 - ==> Best [Top1: 64.611   Top5: 95.134   Sparsity:0.00   Params: 376752 on epoch: 15]
2024-04-23 16:21:28,972 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:21:29,014 - 

2024-04-23 16:21:29,014 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:21:30,750 - Epoch: [24][  100/  267]    Overall Loss 2.302248    Objective Loss 2.302248                                        LR 0.100000    Time 0.262092    
2024-04-23 16:21:33,715 - Epoch: [24][  110/  267]    Overall Loss 2.302192    Objective Loss 2.302192                                        LR 0.100000    Time 0.265192    
2024-04-23 16:21:36,067 - Epoch: [24][  120/  267]    Overall Loss 2.302031    Objective Loss 2.302031                                        LR 0.100000    Time 0.262665    
2024-04-23 16:21:39,194 - Epoch: [24][  130/  267]    Overall Loss 2.302466    Objective Loss 2.302466                                        LR 0.100000    Time 0.266493    
2024-04-23 16:21:41,180 - Epoch: [24][  140/  267]    Overall Loss 2.302796    Objective Loss 2.302796                                        LR 0.100000    Time 0.261621    
2024-04-23 16:21:44,006 - Epoch: [24][  150/  267]    Overall Loss 2.303529    Objective Loss 2.303529                                        LR 0.100000    Time 0.262999    
2024-04-23 16:21:45,651 - Epoch: [24][  160/  267]    Overall Loss 2.303674    Objective Loss 2.303674                                        LR 0.100000    Time 0.256820    
2024-04-23 16:21:48,367 - Epoch: [24][  170/  267]    Overall Loss 2.303565    Objective Loss 2.303565                                        LR 0.100000    Time 0.257667    
2024-04-23 16:21:50,447 - Epoch: [24][  180/  267]    Overall Loss 2.303613    Objective Loss 2.303613                                        LR 0.100000    Time 0.254889    
2024-04-23 16:21:52,395 - Epoch: [24][  190/  267]    Overall Loss 2.303673    Objective Loss 2.303673                                        LR 0.100000    Time 0.251716    
2024-04-23 16:21:52,565 - Epoch: [19][  100/  296]    Overall Loss 1.227126    Objective Loss 1.227126                                        LR 0.000320    Time 0.235287    
2024-04-23 16:21:54,370 - Epoch: [24][  200/  267]    Overall Loss 2.303760    Objective Loss 2.303760                                        LR 0.100000    Time 0.248993    
2024-04-23 16:21:57,506 - Epoch: [24][  210/  267]    Overall Loss 2.303860    Objective Loss 2.303860                                        LR 0.100000    Time 0.252054    
2024-04-23 16:21:59,247 - Epoch: [24][  220/  267]    Overall Loss 2.303918    Objective Loss 2.303918                                        LR 0.100000    Time 0.248495    
2024-04-23 16:22:02,022 - Epoch: [24][  230/  267]    Overall Loss 2.304048    Objective Loss 2.304048                                        LR 0.100000    Time 0.249744    
2024-04-23 16:22:03,966 - Epoch: [24][  240/  267]    Overall Loss 2.304121    Objective Loss 2.304121                                        LR 0.100000    Time 0.247422    
2024-04-23 16:22:06,280 - Epoch: [24][  250/  267]    Overall Loss 2.304122    Objective Loss 2.304122                                        LR 0.100000    Time 0.246770    
2024-04-23 16:22:08,791 - Epoch: [24][  260/  267]    Overall Loss 2.304295    Objective Loss 2.304295                                        LR 0.100000    Time 0.246920    
2024-04-23 16:22:10,029 - Epoch: [24][  267/  267]    Overall Loss 2.304196    Objective Loss 2.304196    Top1 6.976744    Top5 67.441860    LR 0.100000    Time 0.245075    
2024-04-23 16:22:10,297 - --- validate (epoch=24)-----------
2024-04-23 16:22:10,298 - 946 samples (32 per mini-batch)
2024-04-23 16:22:14,172 - Epoch: [24][   10/   30]    Loss 2.298541    Top1 11.875000    Top5 53.125000    
2024-04-23 16:22:14,297 - Epoch: [19][  200/  296]    Overall Loss 1.217184    Objective Loss 1.217184                                        LR 0.000320    Time 0.226200    
2024-04-23 16:22:16,598 - Epoch: [24][   20/   30]    Loss 2.303949    Top1 9.843750    Top5 51.562500    
2024-04-23 16:22:19,146 - Epoch: [24][   30/   30]    Loss 2.303245    Top1 10.570825    Top5 51.691332    
2024-04-23 16:22:19,353 - ==> Top1: 10.571    Top5: 51.691    Loss: 2.303

2024-04-23 16:22:19,355 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 16:22:19,358 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:22:19,359 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:22:19,374 - 

2024-04-23 16:22:19,375 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:22:23,431 - Epoch: [25][   10/  267]    Overall Loss 2.308068    Objective Loss 2.308068                                        LR 0.100000    Time 0.405219    
2024-04-23 16:22:25,548 - Epoch: [25][   20/  267]    Overall Loss 2.305812    Objective Loss 2.305812                                        LR 0.100000    Time 0.308311    
2024-04-23 16:22:28,521 - Epoch: [25][   30/  267]    Overall Loss 2.303405    Objective Loss 2.303405                                        LR 0.100000    Time 0.304508    
2024-04-23 16:22:30,804 - Epoch: [25][   40/  267]    Overall Loss 2.304475    Objective Loss 2.304475                                        LR 0.100000    Time 0.285370    
2024-04-23 16:22:32,409 - Epoch: [25][   50/  267]    Overall Loss 2.303468    Objective Loss 2.303468                                        LR 0.100000    Time 0.260355    
2024-04-23 16:22:34,362 - Epoch: [25][   60/  267]    Overall Loss 2.303635    Objective Loss 2.303635                                        LR 0.100000    Time 0.249459    
2024-04-23 16:22:36,606 - Epoch: [19][  296/  296]    Overall Loss 1.219763    Objective Loss 1.219763    Top1 62.295082    Top5 93.442623    LR 0.000320    Time 0.228142    
2024-04-23 16:22:36,737 - --- validate (epoch=19)-----------
2024-04-23 16:22:36,737 - 3925 samples (32 per mini-batch)
2024-04-23 16:22:37,360 - Epoch: [25][   70/  267]    Overall Loss 2.304012    Objective Loss 2.304012                                        LR 0.100000    Time 0.256591    
2024-04-23 16:22:39,283 - Epoch: [25][   80/  267]    Overall Loss 2.304537    Objective Loss 2.304537                                        LR 0.100000    Time 0.248518    
2024-04-23 16:22:41,921 - Epoch: [25][   90/  267]    Overall Loss 2.304324    Objective Loss 2.304324                                        LR 0.100000    Time 0.250194    
2024-04-23 16:22:44,545 - Epoch: [25][  100/  267]    Overall Loss 2.304077    Objective Loss 2.304077                                        LR 0.100000    Time 0.251383    
2024-04-23 16:22:47,007 - Epoch: [25][  110/  267]    Overall Loss 2.304323    Objective Loss 2.304323                                        LR 0.100000    Time 0.250888    
2024-04-23 16:22:49,100 - Epoch: [25][  120/  267]    Overall Loss 2.304465    Objective Loss 2.304465                                        LR 0.100000    Time 0.247391    
2024-04-23 16:22:51,663 - Epoch: [25][  130/  267]    Overall Loss 2.304605    Objective Loss 2.304605                                        LR 0.100000    Time 0.248055    
2024-04-23 16:22:53,926 - Epoch: [25][  140/  267]    Overall Loss 2.304972    Objective Loss 2.304972                                        LR 0.100000    Time 0.246479    
2024-04-23 16:22:56,279 - Epoch: [25][  150/  267]    Overall Loss 2.304779    Objective Loss 2.304779                                        LR 0.100000    Time 0.245718    
2024-04-23 16:22:58,242 - Epoch: [25][  160/  267]    Overall Loss 2.304624    Objective Loss 2.304624                                        LR 0.100000    Time 0.242613    
2024-04-23 16:23:01,186 - Epoch: [19][  100/  123]    Loss 1.047846    Top1 65.718750    Top5 94.375000    
2024-04-23 16:23:01,309 - Epoch: [25][  170/  267]    Overall Loss 2.304776    Objective Loss 2.304776                                        LR 0.100000    Time 0.246360    
2024-04-23 16:23:03,188 - Epoch: [25][  180/  267]    Overall Loss 2.304867    Objective Loss 2.304867                                        LR 0.100000    Time 0.243095    
2024-04-23 16:23:05,942 - Epoch: [19][  123/  123]    Loss 1.050615    Top1 65.783439    Top5 94.242038    
2024-04-23 16:23:06,214 - ==> Top1: 65.783    Top5: 94.242    Loss: 1.051

2024-04-23 16:23:06,224 - ==> Best [Top1: 65.783   Top5: 94.242   Sparsity:0.00   Params: 376752 on epoch: 19]
2024-04-23 16:23:06,225 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:23:06,251 - Epoch: [25][  190/  267]    Overall Loss 2.304493    Objective Loss 2.304493                                        LR 0.100000    Time 0.246405    
2024-04-23 16:23:06,295 - 

2024-04-23 16:23:06,297 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:23:08,436 - Epoch: [25][  200/  267]    Overall Loss 2.304654    Objective Loss 2.304654                                        LR 0.100000    Time 0.244997    
2024-04-23 16:23:11,313 - Epoch: [25][  210/  267]    Overall Loss 2.304670    Objective Loss 2.304670                                        LR 0.100000    Time 0.247013    
2024-04-23 16:23:13,275 - Epoch: [25][  220/  267]    Overall Loss 2.304859    Objective Loss 2.304859                                        LR 0.100000    Time 0.244687    
2024-04-23 16:23:16,069 - Epoch: [25][  230/  267]    Overall Loss 2.304889    Objective Loss 2.304889                                        LR 0.100000    Time 0.246187    
2024-04-23 16:23:18,874 - Epoch: [25][  240/  267]    Overall Loss 2.304882    Objective Loss 2.304882                                        LR 0.100000    Time 0.247602    
2024-04-23 16:23:20,978 - Epoch: [25][  250/  267]    Overall Loss 2.304855    Objective Loss 2.304855                                        LR 0.100000    Time 0.246100    
2024-04-23 16:23:23,233 - Epoch: [25][  260/  267]    Overall Loss 2.304738    Objective Loss 2.304738                                        LR 0.100000    Time 0.245296    
2024-04-23 16:23:24,072 - Epoch: [25][  267/  267]    Overall Loss 2.304794    Objective Loss 2.304794    Top1 6.976744    Top5 53.488372    LR 0.100000    Time 0.241998    
2024-04-23 16:23:24,284 - --- validate (epoch=25)-----------
2024-04-23 16:23:24,285 - 946 samples (32 per mini-batch)
2024-04-23 16:23:27,636 - Epoch: [25][   10/   30]    Loss 2.307640    Top1 7.812500    Top5 49.062500    
2024-04-23 16:23:29,328 - Epoch: [25][   20/   30]    Loss 2.301890    Top1 10.937500    Top5 51.250000    
2024-04-23 16:23:30,553 - Epoch: [20][  100/  296]    Overall Loss 1.174253    Objective Loss 1.174253                                        LR 0.000320    Time 0.242352    
2024-04-23 16:23:31,642 - Epoch: [25][   30/   30]    Loss 2.303110    Top1 10.570825    Top5 50.845666    
2024-04-23 16:23:31,872 - ==> Top1: 10.571    Top5: 50.846    Loss: 2.303

2024-04-23 16:23:31,874 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 16:23:31,878 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:23:31,878 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:23:31,892 - 

2024-04-23 16:23:31,893 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:23:36,023 - Epoch: [26][   10/  267]    Overall Loss 2.303286    Objective Loss 2.303286                                        LR 0.100000    Time 0.412592    
2024-04-23 16:23:38,400 - Epoch: [26][   20/  267]    Overall Loss 2.305210    Objective Loss 2.305210                                        LR 0.100000    Time 0.324958    
2024-04-23 16:23:41,434 - Epoch: [26][   30/  267]    Overall Loss 2.306510    Objective Loss 2.306510                                        LR 0.100000    Time 0.317699    
2024-04-23 16:23:43,455 - Epoch: [26][   40/  267]    Overall Loss 2.306467    Objective Loss 2.306467                                        LR 0.100000    Time 0.288721    
2024-04-23 16:23:46,359 - Epoch: [26][   50/  267]    Overall Loss 2.306297    Objective Loss 2.306297                                        LR 0.100000    Time 0.289001    
2024-04-23 16:23:48,617 - Epoch: [26][   60/  267]    Overall Loss 2.305572    Objective Loss 2.305572                                        LR 0.100000    Time 0.278428    
2024-04-23 16:23:51,333 - Epoch: [26][   70/  267]    Overall Loss 2.305117    Objective Loss 2.305117                                        LR 0.100000    Time 0.277405    
2024-04-23 16:23:53,260 - Epoch: [20][  200/  296]    Overall Loss 1.179723    Objective Loss 1.179723                                        LR 0.000320    Time 0.234598    
2024-04-23 16:23:53,492 - Epoch: [26][   80/  267]    Overall Loss 2.305174    Objective Loss 2.305174                                        LR 0.100000    Time 0.269669    
2024-04-23 16:23:55,951 - Epoch: [26][   90/  267]    Overall Loss 2.305138    Objective Loss 2.305138                                        LR 0.100000    Time 0.266984    
2024-04-23 16:23:58,011 - Epoch: [26][  100/  267]    Overall Loss 2.305278    Objective Loss 2.305278                                        LR 0.100000    Time 0.260855    
2024-04-23 16:24:00,826 - Epoch: [26][  110/  267]    Overall Loss 2.305497    Objective Loss 2.305497                                        LR 0.100000    Time 0.262701    
2024-04-23 16:24:02,808 - Epoch: [26][  120/  267]    Overall Loss 2.305224    Objective Loss 2.305224                                        LR 0.100000    Time 0.257303    
2024-04-23 16:24:05,511 - Epoch: [26][  130/  267]    Overall Loss 2.304336    Objective Loss 2.304336                                        LR 0.100000    Time 0.258281    
2024-04-23 16:24:07,440 - Epoch: [26][  140/  267]    Overall Loss 2.303248    Objective Loss 2.303248                                        LR 0.100000    Time 0.253586    
2024-04-23 16:24:10,106 - Epoch: [26][  150/  267]    Overall Loss 2.303578    Objective Loss 2.303578                                        LR 0.100000    Time 0.254439    
2024-04-23 16:24:12,006 - Epoch: [26][  160/  267]    Overall Loss 2.303676    Objective Loss 2.303676                                        LR 0.100000    Time 0.250396    
2024-04-23 16:24:14,568 - Epoch: [26][  170/  267]    Overall Loss 2.304165    Objective Loss 2.304165                                        LR 0.100000    Time 0.250719    
2024-04-23 16:24:14,623 - Epoch: [20][  296/  296]    Overall Loss 1.183388    Objective Loss 1.183388    Top1 70.491803    Top5 98.360656    LR 0.000320    Time 0.230613    
2024-04-23 16:24:14,804 - --- validate (epoch=20)-----------
2024-04-23 16:24:14,805 - 3925 samples (32 per mini-batch)
2024-04-23 16:24:17,607 - Epoch: [26][  180/  267]    Overall Loss 2.304474    Objective Loss 2.304474                                        LR 0.100000    Time 0.253649    
2024-04-23 16:24:20,909 - Epoch: [26][  190/  267]    Overall Loss 2.304493    Objective Loss 2.304493                                        LR 0.100000    Time 0.257663    
2024-04-23 16:24:23,790 - Epoch: [26][  200/  267]    Overall Loss 2.305101    Objective Loss 2.305101                                        LR 0.100000    Time 0.259166    
2024-04-23 16:24:26,339 - Epoch: [26][  210/  267]    Overall Loss 2.305297    Objective Loss 2.305297                                        LR 0.100000    Time 0.258946    
2024-04-23 16:24:28,929 - Epoch: [26][  220/  267]    Overall Loss 2.305409    Objective Loss 2.305409                                        LR 0.100000    Time 0.258932    
2024-04-23 16:24:31,202 - Epoch: [26][  230/  267]    Overall Loss 2.305464    Objective Loss 2.305464                                        LR 0.100000    Time 0.257541    
2024-04-23 16:24:33,911 - Epoch: [26][  240/  267]    Overall Loss 2.305541    Objective Loss 2.305541                                        LR 0.100000    Time 0.258083    
2024-04-23 16:24:36,195 - Epoch: [26][  250/  267]    Overall Loss 2.305487    Objective Loss 2.305487                                        LR 0.100000    Time 0.256881    
2024-04-23 16:24:38,931 - Epoch: [26][  260/  267]    Overall Loss 2.305466    Objective Loss 2.305466                                        LR 0.100000    Time 0.257512    
2024-04-23 16:24:40,227 - Epoch: [26][  267/  267]    Overall Loss 2.305488    Objective Loss 2.305488    Top1 6.976744    Top5 46.511628    LR 0.100000    Time 0.255607    
2024-04-23 16:24:40,446 - --- validate (epoch=26)-----------
2024-04-23 16:24:40,448 - 946 samples (32 per mini-batch)
2024-04-23 16:24:41,304 - Epoch: [20][  100/  123]    Loss 1.022338    Top1 66.656250    Top5 95.125000    
2024-04-23 16:24:43,780 - Epoch: [26][   10/   30]    Loss 2.301040    Top1 8.437500    Top5 52.812500    
2024-04-23 16:24:46,016 - Epoch: [26][   20/   30]    Loss 2.302334    Top1 9.687500    Top5 52.656250    
2024-04-23 16:24:46,060 - Epoch: [20][  123/  123]    Loss 1.016573    Top1 66.649682    Top5 95.261146    
2024-04-23 16:24:46,276 - ==> Top1: 66.650    Top5: 95.261    Loss: 1.017

2024-04-23 16:24:46,290 - ==> Best [Top1: 66.650   Top5: 95.261   Sparsity:0.00   Params: 376752 on epoch: 20]
2024-04-23 16:24:46,291 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:24:46,377 - 

2024-04-23 16:24:46,378 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:24:48,976 - Epoch: [26][   30/   30]    Loss 2.302573    Top1 9.830867    Top5 51.902748    
2024-04-23 16:24:49,185 - ==> Top1: 9.831    Top5: 51.903    Loss: 2.303

2024-04-23 16:24:49,187 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 16:24:49,192 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:24:49,193 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:24:49,216 - 

2024-04-23 16:24:49,218 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:24:54,467 - Epoch: [27][   10/  267]    Overall Loss 2.303100    Objective Loss 2.303100                                        LR 0.100000    Time 0.524515    
2024-04-23 16:24:57,342 - Epoch: [27][   20/  267]    Overall Loss 2.302565    Objective Loss 2.302565                                        LR 0.100000    Time 0.405823    
2024-04-23 16:24:59,634 - Epoch: [27][   30/  267]    Overall Loss 2.301693    Objective Loss 2.301693                                        LR 0.100000    Time 0.346847    
2024-04-23 16:25:02,560 - Epoch: [27][   40/  267]    Overall Loss 2.303497    Objective Loss 2.303497                                        LR 0.100000    Time 0.333186    
2024-04-23 16:25:05,200 - Epoch: [27][   50/  267]    Overall Loss 2.305422    Objective Loss 2.305422                                        LR 0.100000    Time 0.319298    
2024-04-23 16:25:07,415 - Epoch: [27][   60/  267]    Overall Loss 2.303877    Objective Loss 2.303877                                        LR 0.100000    Time 0.302946    
2024-04-23 16:25:10,564 - Epoch: [27][   70/  267]    Overall Loss 2.304581    Objective Loss 2.304581                                        LR 0.100000    Time 0.304620    
2024-04-23 16:25:12,650 - Epoch: [27][   80/  267]    Overall Loss 2.303988    Objective Loss 2.303988                                        LR 0.100000    Time 0.292511    
2024-04-23 16:25:14,162 - Epoch: [21][  100/  296]    Overall Loss 1.193768    Objective Loss 1.193768                                        LR 0.000320    Time 0.277599    
2024-04-23 16:25:16,036 - Epoch: [27][   90/  267]    Overall Loss 2.304905    Objective Loss 2.304905                                        LR 0.100000    Time 0.297596    
2024-04-23 16:25:17,826 - Epoch: [27][  100/  267]    Overall Loss 2.304615    Objective Loss 2.304615                                        LR 0.100000    Time 0.285707    
2024-04-23 16:25:20,215 - Epoch: [27][  110/  267]    Overall Loss 2.304994    Objective Loss 2.304994                                        LR 0.100000    Time 0.281427    
2024-04-23 16:25:22,311 - Epoch: [27][  120/  267]    Overall Loss 2.304886    Objective Loss 2.304886                                        LR 0.100000    Time 0.275410    
2024-04-23 16:25:24,866 - Epoch: [27][  130/  267]    Overall Loss 2.314306    Objective Loss 2.314306                                        LR 0.100000    Time 0.273850    
2024-04-23 16:25:27,178 - Epoch: [27][  140/  267]    Overall Loss 2.317589    Objective Loss 2.317589                                        LR 0.100000    Time 0.270789    
2024-04-23 16:25:29,911 - Epoch: [27][  150/  267]    Overall Loss 2.316905    Objective Loss 2.316905                                        LR 0.100000    Time 0.270930    
2024-04-23 16:25:32,493 - Epoch: [27][  160/  267]    Overall Loss 2.316136    Objective Loss 2.316136                                        LR 0.100000    Time 0.270117    
2024-04-23 16:25:35,216 - Epoch: [27][  170/  267]    Overall Loss 2.315416    Objective Loss 2.315416                                        LR 0.100000    Time 0.270228    
2024-04-23 16:25:37,677 - Epoch: [27][  180/  267]    Overall Loss 2.315017    Objective Loss 2.315017                                        LR 0.100000    Time 0.268864    
2024-04-23 16:25:39,619 - Epoch: [21][  200/  296]    Overall Loss 1.179289    Objective Loss 1.179289                                        LR 0.000320    Time 0.265953    
2024-04-23 16:25:40,695 - Epoch: [27][  190/  267]    Overall Loss 2.314382    Objective Loss 2.314382                                        LR 0.100000    Time 0.270582    
2024-04-23 16:25:42,808 - Epoch: [27][  200/  267]    Overall Loss 2.314102    Objective Loss 2.314102                                        LR 0.100000    Time 0.267605    
2024-04-23 16:25:45,094 - Epoch: [27][  210/  267]    Overall Loss 2.314041    Objective Loss 2.314041                                        LR 0.100000    Time 0.265731    
2024-04-23 16:25:47,856 - Epoch: [27][  220/  267]    Overall Loss 2.313640    Objective Loss 2.313640                                        LR 0.100000    Time 0.266195    
2024-04-23 16:25:49,532 - Epoch: [27][  230/  267]    Overall Loss 2.313621    Objective Loss 2.313621                                        LR 0.100000    Time 0.261896    
2024-04-23 16:25:52,359 - Epoch: [27][  240/  267]    Overall Loss 2.313262    Objective Loss 2.313262                                        LR 0.100000    Time 0.262748    
2024-04-23 16:25:54,326 - Epoch: [27][  250/  267]    Overall Loss 2.313039    Objective Loss 2.313039                                        LR 0.100000    Time 0.260092    
2024-04-23 16:25:56,611 - Epoch: [27][  260/  267]    Overall Loss 2.312764    Objective Loss 2.312764                                        LR 0.100000    Time 0.258865    
2024-04-23 16:25:57,306 - Epoch: [27][  267/  267]    Overall Loss 2.312743    Objective Loss 2.312743    Top1 18.604651    Top5 53.488372    LR 0.100000    Time 0.254675    
2024-04-23 16:25:57,506 - --- validate (epoch=27)-----------
2024-04-23 16:25:57,508 - 946 samples (32 per mini-batch)
2024-04-23 16:26:00,406 - Epoch: [27][   10/   30]    Loss 2.307279    Top1 12.187500    Top5 52.500000    
2024-04-23 16:26:01,253 - Epoch: [21][  296/  296]    Overall Loss 1.182573    Objective Loss 1.182573    Top1 59.016393    Top5 96.721311    LR 0.000320    Time 0.252716    
2024-04-23 16:26:01,621 - --- validate (epoch=21)-----------
2024-04-23 16:26:01,623 - 3925 samples (32 per mini-batch)
2024-04-23 16:26:02,567 - Epoch: [27][   20/   30]    Loss 2.309464    Top1 10.312500    Top5 50.312500    
2024-04-23 16:26:05,081 - Epoch: [27][   30/   30]    Loss 2.310747    Top1 10.042283    Top5 49.682875    
2024-04-23 16:26:05,328 - ==> Top1: 10.042    Top5: 49.683    Loss: 2.311

2024-04-23 16:26:05,330 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 16:26:05,337 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:26:05,338 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:26:05,355 - 

2024-04-23 16:26:05,356 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:26:08,738 - Epoch: [28][   10/  267]    Overall Loss 2.313044    Objective Loss 2.313044                                        LR 0.100000    Time 0.337831    
2024-04-23 16:26:10,170 - Epoch: [28][   20/  267]    Overall Loss 2.308882    Objective Loss 2.308882                                        LR 0.100000    Time 0.240293    
2024-04-23 16:26:11,768 - Epoch: [28][   30/  267]    Overall Loss 2.308737    Objective Loss 2.308737                                        LR 0.100000    Time 0.213353    
2024-04-23 16:26:12,727 - Epoch: [28][   40/  267]    Overall Loss 2.308643    Objective Loss 2.308643                                        LR 0.100000    Time 0.183928    
2024-04-23 16:26:14,216 - Epoch: [28][   50/  267]    Overall Loss 2.309198    Objective Loss 2.309198                                        LR 0.100000    Time 0.176878    
2024-04-23 16:26:15,311 - Epoch: [28][   60/  267]    Overall Loss 2.308401    Objective Loss 2.308401                                        LR 0.100000    Time 0.165618    
2024-04-23 16:26:16,902 - Epoch: [28][   70/  267]    Overall Loss 2.308201    Objective Loss 2.308201                                        LR 0.100000    Time 0.164637    
2024-04-23 16:26:18,325 - Epoch: [28][   80/  267]    Overall Loss 2.307996    Objective Loss 2.307996                                        LR 0.100000    Time 0.161824    
2024-04-23 16:26:20,419 - Epoch: [28][   90/  267]    Overall Loss 2.307099    Objective Loss 2.307099                                        LR 0.100000    Time 0.167071    
2024-04-23 16:26:21,938 - Epoch: [28][  100/  267]    Overall Loss 2.306320    Objective Loss 2.306320                                        LR 0.100000    Time 0.165534    
2024-04-23 16:26:24,309 - Epoch: [28][  110/  267]    Overall Loss 2.306913    Objective Loss 2.306913                                        LR 0.100000    Time 0.172008    
2024-04-23 16:26:26,166 - Epoch: [28][  120/  267]    Overall Loss 2.307711    Objective Loss 2.307711                                        LR 0.100000    Time 0.173125    
2024-04-23 16:26:28,198 - Epoch: [28][  130/  267]    Overall Loss 2.307221    Objective Loss 2.307221                                        LR 0.100000    Time 0.175421    
2024-04-23 16:26:29,754 - Epoch: [28][  140/  267]    Overall Loss 2.307712    Objective Loss 2.307712                                        LR 0.100000    Time 0.173952    
2024-04-23 16:26:31,422 - Epoch: [21][  100/  123]    Loss 1.030228    Top1 66.187500    Top5 94.750000    
2024-04-23 16:26:31,635 - Epoch: [28][  150/  267]    Overall Loss 2.307203    Objective Loss 2.307203                                        LR 0.100000    Time 0.174877    
2024-04-23 16:26:32,953 - Epoch: [28][  160/  267]    Overall Loss 2.307504    Objective Loss 2.307504                                        LR 0.100000    Time 0.172176    
2024-04-23 16:26:35,433 - Epoch: [28][  170/  267]    Overall Loss 2.307389    Objective Loss 2.307389                                        LR 0.100000    Time 0.176620    
2024-04-23 16:26:36,890 - Epoch: [21][  123/  123]    Loss 1.030826    Top1 66.191083    Top5 94.726115    
2024-04-23 16:26:37,230 - ==> Top1: 66.191    Top5: 94.726    Loss: 1.031

2024-04-23 16:26:37,242 - ==> Best [Top1: 66.650   Top5: 95.261   Sparsity:0.00   Params: 376752 on epoch: 20]
2024-04-23 16:26:37,243 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:26:37,270 - Epoch: [28][  180/  267]    Overall Loss 2.307266    Objective Loss 2.307266                                        LR 0.100000    Time 0.176997    
2024-04-23 16:26:37,307 - 

2024-04-23 16:26:37,308 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:26:39,906 - Epoch: [28][  190/  267]    Overall Loss 2.307516    Objective Loss 2.307516                                        LR 0.100000    Time 0.181543    
2024-04-23 16:26:41,850 - Epoch: [28][  200/  267]    Overall Loss 2.307200    Objective Loss 2.307200                                        LR 0.100000    Time 0.182160    
2024-04-23 16:26:43,943 - Epoch: [28][  210/  267]    Overall Loss 2.307350    Objective Loss 2.307350                                        LR 0.100000    Time 0.183435    
2024-04-23 16:26:45,341 - Epoch: [28][  220/  267]    Overall Loss 2.307972    Objective Loss 2.307972                                        LR 0.100000    Time 0.181439    
2024-04-23 16:26:48,123 - Epoch: [28][  230/  267]    Overall Loss 2.308050    Objective Loss 2.308050                                        LR 0.100000    Time 0.185636    
2024-04-23 16:26:50,181 - Epoch: [28][  240/  267]    Overall Loss 2.308047    Objective Loss 2.308047                                        LR 0.100000    Time 0.186459    
2024-04-23 16:26:52,425 - Epoch: [28][  250/  267]    Overall Loss 2.308026    Objective Loss 2.308026                                        LR 0.100000    Time 0.187964    
2024-04-23 16:26:54,075 - Epoch: [28][  260/  267]    Overall Loss 2.307969    Objective Loss 2.307969                                        LR 0.100000    Time 0.187071    
2024-04-23 16:26:55,517 - Epoch: [28][  267/  267]    Overall Loss 2.307455    Objective Loss 2.307455    Top1 6.976744    Top5 41.860465    LR 0.100000    Time 0.187559    
2024-04-23 16:26:55,740 - --- validate (epoch=28)-----------
2024-04-23 16:26:55,741 - 946 samples (32 per mini-batch)
2024-04-23 16:26:59,623 - Epoch: [28][   10/   30]    Loss 2.309623    Top1 10.000000    Top5 49.062500    
2024-04-23 16:27:02,073 - Epoch: [28][   20/   30]    Loss 2.310905    Top1 10.000000    Top5 49.531250    
2024-04-23 16:27:04,325 - Epoch: [22][  100/  296]    Overall Loss 1.188559    Objective Loss 1.188559                                        LR 0.000320    Time 0.269944    
2024-04-23 16:27:04,949 - Epoch: [28][   30/   30]    Loss 2.306978    Top1 10.465116    Top5 50.105708    
2024-04-23 16:27:05,158 - ==> Top1: 10.465    Top5: 50.106    Loss: 2.307

2024-04-23 16:27:05,161 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 16:27:05,166 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:27:05,167 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:27:05,185 - 

2024-04-23 16:27:05,186 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:27:09,838 - Epoch: [29][   10/  267]    Overall Loss 2.317133    Objective Loss 2.317133                                        LR 0.100000    Time 0.464821    
2024-04-23 16:27:12,048 - Epoch: [29][   20/  267]    Overall Loss 2.311025    Objective Loss 2.311025                                        LR 0.100000    Time 0.342738    
2024-04-23 16:27:14,943 - Epoch: [29][   30/  267]    Overall Loss 2.309775    Objective Loss 2.309775                                        LR 0.100000    Time 0.324905    
2024-04-23 16:27:17,271 - Epoch: [29][   40/  267]    Overall Loss 2.308950    Objective Loss 2.308950                                        LR 0.100000    Time 0.301817    
2024-04-23 16:27:19,724 - Epoch: [29][   50/  267]    Overall Loss 2.309191    Objective Loss 2.309191                                        LR 0.100000    Time 0.290454    
2024-04-23 16:27:21,822 - Epoch: [29][   60/  267]    Overall Loss 2.308401    Objective Loss 2.308401                                        LR 0.100000    Time 0.276954    
2024-04-23 16:27:24,826 - Epoch: [29][   70/  267]    Overall Loss 2.308401    Objective Loss 2.308401                                        LR 0.100000    Time 0.280258    
2024-04-23 16:27:26,993 - Epoch: [29][   80/  267]    Overall Loss 2.307877    Objective Loss 2.307877                                        LR 0.100000    Time 0.272272    
2024-04-23 16:27:29,959 - Epoch: [29][   90/  267]    Overall Loss 2.307627    Objective Loss 2.307627                                        LR 0.100000    Time 0.274935    
2024-04-23 16:27:30,473 - Epoch: [22][  200/  296]    Overall Loss 1.165040    Objective Loss 1.165040                                        LR 0.000320    Time 0.265608    
2024-04-23 16:27:32,258 - Epoch: [29][  100/  267]    Overall Loss 2.308014    Objective Loss 2.308014                                        LR 0.100000    Time 0.270399    
2024-04-23 16:27:35,458 - Epoch: [29][  110/  267]    Overall Loss 2.308503    Objective Loss 2.308503                                        LR 0.100000    Time 0.274884    
2024-04-23 16:27:37,735 - Epoch: [29][  120/  267]    Overall Loss 2.308019    Objective Loss 2.308019                                        LR 0.100000    Time 0.270930    
2024-04-23 16:27:40,556 - Epoch: [29][  130/  267]    Overall Loss 2.308530    Objective Loss 2.308530                                        LR 0.100000    Time 0.271767    
2024-04-23 16:27:42,483 - Epoch: [29][  140/  267]    Overall Loss 2.307776    Objective Loss 2.307776                                        LR 0.100000    Time 0.266102    
2024-04-23 16:27:44,846 - Epoch: [29][  150/  267]    Overall Loss 2.307994    Objective Loss 2.307994                                        LR 0.100000    Time 0.264096    
2024-04-23 16:27:46,633 - Epoch: [29][  160/  267]    Overall Loss 2.308111    Objective Loss 2.308111                                        LR 0.100000    Time 0.258737    
2024-04-23 16:27:49,376 - Epoch: [29][  170/  267]    Overall Loss 2.307940    Objective Loss 2.307940                                        LR 0.100000    Time 0.259635    
2024-04-23 16:27:51,043 - Epoch: [29][  180/  267]    Overall Loss 2.307731    Objective Loss 2.307731                                        LR 0.100000    Time 0.254455    
2024-04-23 16:27:53,411 - Epoch: [29][  190/  267]    Overall Loss 2.307967    Objective Loss 2.307967                                        LR 0.100000    Time 0.253514    
2024-04-23 16:27:55,069 - Epoch: [29][  200/  267]    Overall Loss 2.307870    Objective Loss 2.307870                                        LR 0.100000    Time 0.249118    
2024-04-23 16:27:55,744 - Epoch: [22][  296/  296]    Overall Loss 1.160422    Objective Loss 1.160422    Top1 63.934426    Top5 93.442623    LR 0.000320    Time 0.264771    
2024-04-23 16:27:56,118 - --- validate (epoch=22)-----------
2024-04-23 16:27:56,119 - 3925 samples (32 per mini-batch)
2024-04-23 16:27:57,495 - Epoch: [29][  210/  267]    Overall Loss 2.308290    Objective Loss 2.308290                                        LR 0.100000    Time 0.248792    
2024-04-23 16:27:59,559 - Epoch: [29][  220/  267]    Overall Loss 2.308195    Objective Loss 2.308195                                        LR 0.100000    Time 0.246851    
2024-04-23 16:28:02,590 - Epoch: [29][  230/  267]    Overall Loss 2.308148    Objective Loss 2.308148                                        LR 0.100000    Time 0.249282    
2024-04-23 16:28:04,510 - Epoch: [29][  240/  267]    Overall Loss 2.308166    Objective Loss 2.308166                                        LR 0.100000    Time 0.246886    
2024-04-23 16:28:07,409 - Epoch: [29][  250/  267]    Overall Loss 2.307967    Objective Loss 2.307967                                        LR 0.100000    Time 0.248592    
2024-04-23 16:28:09,624 - Epoch: [29][  260/  267]    Overall Loss 2.307725    Objective Loss 2.307725                                        LR 0.100000    Time 0.247535    
2024-04-23 16:28:10,932 - Epoch: [29][  267/  267]    Overall Loss 2.307978    Objective Loss 2.307978    Top1 9.302326    Top5 39.534884    LR 0.100000    Time 0.245937    
2024-04-23 16:28:11,135 - --- validate (epoch=29)-----------
2024-04-23 16:28:11,136 - 946 samples (32 per mini-batch)
2024-04-23 16:28:14,969 - Epoch: [29][   10/   30]    Loss 2.316637    Top1 10.312500    Top5 47.500000    
2024-04-23 16:28:17,227 - Epoch: [29][   20/   30]    Loss 2.309752    Top1 10.000000    Top5 49.687500    
2024-04-23 16:28:19,929 - Epoch: [29][   30/   30]    Loss 2.307306    Top1 10.465116    Top5 49.788584    
2024-04-23 16:28:20,120 - ==> Top1: 10.465    Top5: 49.789    Loss: 2.307

2024-04-23 16:28:20,124 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 16:28:20,130 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:28:20,130 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:28:20,147 - 

2024-04-23 16:28:20,149 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:28:23,815 - Epoch: [22][  100/  123]    Loss 0.972209    Top1 67.906250    Top5 95.093750    
2024-04-23 16:28:24,417 - Epoch: [30][   10/  267]    Overall Loss 2.302856    Objective Loss 2.302856                                        LR 0.100000    Time 0.426373    
2024-04-23 16:28:26,611 - Epoch: [30][   20/  267]    Overall Loss 2.309833    Objective Loss 2.309833                                        LR 0.100000    Time 0.322716    
2024-04-23 16:28:28,982 - Epoch: [22][  123/  123]    Loss 0.972342    Top1 67.821656    Top5 95.108280    
2024-04-23 16:28:29,216 - ==> Top1: 67.822    Top5: 95.108    Loss: 0.972

2024-04-23 16:28:29,225 - ==> Best [Top1: 67.822   Top5: 95.108   Sparsity:0.00   Params: 376752 on epoch: 22]
2024-04-23 16:28:29,226 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:28:29,305 - 

2024-04-23 16:28:29,306 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:28:29,378 - Epoch: [30][   30/  267]    Overall Loss 2.308303    Objective Loss 2.308303                                        LR 0.100000    Time 0.307285    
2024-04-23 16:28:31,254 - Epoch: [30][   40/  267]    Overall Loss 2.308974    Objective Loss 2.308974                                        LR 0.100000    Time 0.277303    
2024-04-23 16:28:34,159 - Epoch: [30][   50/  267]    Overall Loss 2.309230    Objective Loss 2.309230                                        LR 0.100000    Time 0.279874    
2024-04-23 16:28:36,232 - Epoch: [30][   60/  267]    Overall Loss 2.308282    Objective Loss 2.308282                                        LR 0.100000    Time 0.267723    
2024-04-23 16:28:39,279 - Epoch: [30][   70/  267]    Overall Loss 2.307889    Objective Loss 2.307889                                        LR 0.100000    Time 0.272967    
2024-04-23 16:28:41,429 - Epoch: [30][   80/  267]    Overall Loss 2.307886    Objective Loss 2.307886                                        LR 0.100000    Time 0.265674    
2024-04-23 16:28:44,413 - Epoch: [30][   90/  267]    Overall Loss 2.309276    Objective Loss 2.309276                                        LR 0.100000    Time 0.269281    
2024-04-23 16:28:46,078 - Epoch: [30][  100/  267]    Overall Loss 2.308982    Objective Loss 2.308982                                        LR 0.100000    Time 0.258971    
2024-04-23 16:28:49,254 - Epoch: [30][  110/  267]    Overall Loss 2.309237    Objective Loss 2.309237                                        LR 0.100000    Time 0.264268    
2024-04-23 16:28:51,510 - Epoch: [30][  120/  267]    Overall Loss 2.309854    Objective Loss 2.309854                                        LR 0.100000    Time 0.261016    
2024-04-23 16:28:54,300 - Epoch: [30][  130/  267]    Overall Loss 2.309221    Objective Loss 2.309221                                        LR 0.100000    Time 0.262375    
2024-04-23 16:28:55,646 - Epoch: [23][  100/  296]    Overall Loss 1.188020    Objective Loss 1.188020                                        LR 0.000320    Time 0.263176    
2024-04-23 16:28:57,457 - Epoch: [30][  140/  267]    Overall Loss 2.308349    Objective Loss 2.308349                                        LR 0.100000    Time 0.266153    
2024-04-23 16:29:01,242 - Epoch: [30][  150/  267]    Overall Loss 2.308826    Objective Loss 2.308826                                        LR 0.100000    Time 0.273622    
2024-04-23 16:29:03,479 - Epoch: [30][  160/  267]    Overall Loss 2.308965    Objective Loss 2.308965                                        LR 0.100000    Time 0.270475    
2024-04-23 16:29:06,643 - Epoch: [30][  170/  267]    Overall Loss 2.308561    Objective Loss 2.308561                                        LR 0.100000    Time 0.273158    
2024-04-23 16:29:09,252 - Epoch: [30][  180/  267]    Overall Loss 2.309377    Objective Loss 2.309377                                        LR 0.100000    Time 0.272460    
2024-04-23 16:29:12,398 - Epoch: [30][  190/  267]    Overall Loss 2.309356    Objective Loss 2.309356                                        LR 0.100000    Time 0.274662    
2024-04-23 16:29:14,575 - Epoch: [30][  200/  267]    Overall Loss 2.308914    Objective Loss 2.308914                                        LR 0.100000    Time 0.271797    
2024-04-23 16:29:17,497 - Epoch: [30][  210/  267]    Overall Loss 2.309053    Objective Loss 2.309053                                        LR 0.100000    Time 0.272755    
2024-04-23 16:29:19,675 - Epoch: [30][  220/  267]    Overall Loss 2.308691    Objective Loss 2.308691                                        LR 0.100000    Time 0.270243    
2024-04-23 16:29:22,503 - Epoch: [30][  230/  267]    Overall Loss 2.308021    Objective Loss 2.308021                                        LR 0.100000    Time 0.270776    
2024-04-23 16:29:22,756 - Epoch: [23][  200/  296]    Overall Loss 1.173166    Objective Loss 1.173166                                        LR 0.000320    Time 0.267026    
2024-04-23 16:29:24,824 - Epoch: [30][  240/  267]    Overall Loss 2.308525    Objective Loss 2.308525                                        LR 0.100000    Time 0.269155    
2024-04-23 16:29:27,746 - Epoch: [30][  250/  267]    Overall Loss 2.308875    Objective Loss 2.308875                                        LR 0.100000    Time 0.270065    
2024-04-23 16:29:29,895 - Epoch: [30][  260/  267]    Overall Loss 2.308965    Objective Loss 2.308965                                        LR 0.100000    Time 0.267930    
2024-04-23 16:29:31,429 - Epoch: [30][  267/  267]    Overall Loss 2.309068    Objective Loss 2.309068    Top1 4.651163    Top5 46.511628    LR 0.100000    Time 0.266641    
2024-04-23 16:29:31,644 - --- validate (epoch=30)-----------
2024-04-23 16:29:31,645 - 946 samples (32 per mini-batch)
2024-04-23 16:29:35,400 - Epoch: [30][   10/   30]    Loss 2.307508    Top1 10.312500    Top5 51.250000    
2024-04-23 16:29:37,567 - Epoch: [30][   20/   30]    Loss 2.306580    Top1 9.687500    Top5 50.156250    
2024-04-23 16:29:39,622 - Epoch: [30][   30/   30]    Loss 2.306829    Top1 10.465116    Top5 49.048626    
2024-04-23 16:29:39,816 - ==> Top1: 10.465    Top5: 49.049    Loss: 2.307

2024-04-23 16:29:39,818 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 16:29:39,824 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:29:39,825 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:29:39,846 - 

2024-04-23 16:29:39,847 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:29:44,089 - Epoch: [31][   10/  267]    Overall Loss 2.301720    Objective Loss 2.301720                                        LR 0.100000    Time 0.423807    
2024-04-23 16:29:45,745 - Epoch: [31][   20/  267]    Overall Loss 2.304033    Objective Loss 2.304033                                        LR 0.100000    Time 0.294557    
2024-04-23 16:29:46,110 - Epoch: [23][  296/  296]    Overall Loss 1.157711    Objective Loss 1.157711    Top1 68.852459    Top5 98.360656    LR 0.000320    Time 0.259254    
2024-04-23 16:29:46,395 - --- validate (epoch=23)-----------
2024-04-23 16:29:46,396 - 3925 samples (32 per mini-batch)
2024-04-23 16:29:47,668 - Epoch: [31][   30/  267]    Overall Loss 2.301431    Objective Loss 2.301431                                        LR 0.100000    Time 0.260382    
2024-04-23 16:29:49,824 - Epoch: [31][   40/  267]    Overall Loss 2.305799    Objective Loss 2.305799                                        LR 0.100000    Time 0.249076    
2024-04-23 16:29:52,169 - Epoch: [31][   50/  267]    Overall Loss 2.308027    Objective Loss 2.308027                                        LR 0.100000    Time 0.246093    
2024-04-23 16:29:54,179 - Epoch: [31][   60/  267]    Overall Loss 2.305453    Objective Loss 2.305453                                        LR 0.100000    Time 0.238518    
2024-04-23 16:29:57,185 - Epoch: [31][   70/  267]    Overall Loss 2.306644    Objective Loss 2.306644                                        LR 0.100000    Time 0.247341    
2024-04-23 16:29:59,386 - Epoch: [31][   80/  267]    Overall Loss 2.306675    Objective Loss 2.306675                                        LR 0.100000    Time 0.243894    
2024-04-23 16:30:02,657 - Epoch: [31][   90/  267]    Overall Loss 2.306572    Objective Loss 2.306572                                        LR 0.100000    Time 0.253110    
2024-04-23 16:30:04,944 - Epoch: [31][  100/  267]    Overall Loss 2.306568    Objective Loss 2.306568                                        LR 0.100000    Time 0.250640    
2024-04-23 16:30:08,470 - Epoch: [31][  110/  267]    Overall Loss 2.306301    Objective Loss 2.306301                                        LR 0.100000    Time 0.259877    
2024-04-23 16:30:11,368 - Epoch: [31][  120/  267]    Overall Loss 2.306415    Objective Loss 2.306415                                        LR 0.100000    Time 0.262345    
2024-04-23 16:30:15,284 - Epoch: [31][  130/  267]    Overall Loss 2.307173    Objective Loss 2.307173                                        LR 0.100000    Time 0.272251    
2024-04-23 16:30:17,203 - Epoch: [23][  100/  123]    Loss 1.056683    Top1 65.218750    Top5 94.656250    
2024-04-23 16:30:17,424 - Epoch: [31][  140/  267]    Overall Loss 2.307666    Objective Loss 2.307666                                        LR 0.100000    Time 0.268072    
2024-04-23 16:30:20,531 - Epoch: [31][  150/  267]    Overall Loss 2.307028    Objective Loss 2.307028                                        LR 0.100000    Time 0.270865    
2024-04-23 16:30:22,649 - Epoch: [31][  160/  267]    Overall Loss 2.306445    Objective Loss 2.306445                                        LR 0.100000    Time 0.267150    
2024-04-23 16:30:23,371 - Epoch: [23][  123/  123]    Loss 1.049106    Top1 65.197452    Top5 94.853503    
2024-04-23 16:30:23,674 - ==> Top1: 65.197    Top5: 94.854    Loss: 1.049

2024-04-23 16:30:23,685 - ==> Best [Top1: 67.822   Top5: 95.108   Sparsity:0.00   Params: 376752 on epoch: 22]
2024-04-23 16:30:23,686 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:30:23,744 - 

2024-04-23 16:30:23,745 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:30:24,677 - Epoch: [31][  170/  267]    Overall Loss 2.306595    Objective Loss 2.306595                                        LR 0.100000    Time 0.263348    
2024-04-23 16:30:26,754 - Epoch: [31][  180/  267]    Overall Loss 2.307193    Objective Loss 2.307193                                        LR 0.100000    Time 0.260239    
2024-04-23 16:30:29,567 - Epoch: [31][  190/  267]    Overall Loss 2.307082    Objective Loss 2.307082                                        LR 0.100000    Time 0.261331    
2024-04-23 16:30:31,615 - Epoch: [31][  200/  267]    Overall Loss 2.307709    Objective Loss 2.307709                                        LR 0.100000    Time 0.258493    
2024-04-23 16:30:35,035 - Epoch: [31][  210/  267]    Overall Loss 2.307194    Objective Loss 2.307194                                        LR 0.100000    Time 0.262454    
2024-04-23 16:30:37,744 - Epoch: [31][  220/  267]    Overall Loss 2.307471    Objective Loss 2.307471                                        LR 0.100000    Time 0.262822    
2024-04-23 16:30:40,092 - Epoch: [31][  230/  267]    Overall Loss 2.307302    Objective Loss 2.307302                                        LR 0.100000    Time 0.261592    
2024-04-23 16:30:42,891 - Epoch: [31][  240/  267]    Overall Loss 2.307396    Objective Loss 2.307396                                        LR 0.100000    Time 0.262339    
2024-04-23 16:30:45,242 - Epoch: [31][  250/  267]    Overall Loss 2.307595    Objective Loss 2.307595                                        LR 0.100000    Time 0.261239    
2024-04-23 16:30:47,236 - Epoch: [31][  260/  267]    Overall Loss 2.307762    Objective Loss 2.307762                                        LR 0.100000    Time 0.258851    
2024-04-23 16:30:48,359 - Epoch: [31][  267/  267]    Overall Loss 2.307906    Objective Loss 2.307906    Top1 4.651163    Top5 51.162791    LR 0.100000    Time 0.256260    
2024-04-23 16:30:48,613 - --- validate (epoch=31)-----------
2024-04-23 16:30:48,616 - 946 samples (32 per mini-batch)
2024-04-23 16:30:51,129 - Epoch: [24][  100/  296]    Overall Loss 1.122983    Objective Loss 1.122983                                        LR 0.000320    Time 0.273604    
2024-04-23 16:30:53,138 - Epoch: [31][   10/   30]    Loss 2.298825    Top1 13.750000    Top5 54.687500    
2024-04-23 16:30:55,678 - Epoch: [31][   20/   30]    Loss 2.307797    Top1 11.875000    Top5 52.187500    
2024-04-23 16:30:58,900 - Epoch: [31][   30/   30]    Loss 2.313066    Top1 10.570825    Top5 50.528541    
2024-04-23 16:30:59,189 - ==> Top1: 10.571    Top5: 50.529    Loss: 2.313

2024-04-23 16:30:59,191 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 16:30:59,197 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:30:59,198 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:30:59,223 - 

2024-04-23 16:30:59,224 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:31:03,671 - Epoch: [32][   10/  267]    Overall Loss 2.317147    Objective Loss 2.317147                                        LR 0.100000    Time 0.444198    
2024-04-23 16:31:06,586 - Epoch: [32][   20/  267]    Overall Loss 2.312711    Objective Loss 2.312711                                        LR 0.100000    Time 0.367710    
2024-04-23 16:31:09,634 - Epoch: [32][   30/  267]    Overall Loss 2.310132    Objective Loss 2.310132                                        LR 0.100000    Time 0.346608    
2024-04-23 16:31:11,964 - Epoch: [32][   40/  267]    Overall Loss 2.309137    Objective Loss 2.309137                                        LR 0.100000    Time 0.318121    
2024-04-23 16:31:15,499 - Epoch: [32][   50/  267]    Overall Loss 2.309472    Objective Loss 2.309472                                        LR 0.100000    Time 0.325153    
2024-04-23 16:31:17,726 - Epoch: [32][   60/  267]    Overall Loss 2.309467    Objective Loss 2.309467                                        LR 0.100000    Time 0.308022    
2024-04-23 16:31:18,974 - Epoch: [24][  200/  296]    Overall Loss 1.148271    Objective Loss 1.148271                                        LR 0.000320    Time 0.275921    
2024-04-23 16:31:20,950 - Epoch: [32][   70/  267]    Overall Loss 2.309094    Objective Loss 2.309094                                        LR 0.100000    Time 0.310041    
2024-04-23 16:31:23,243 - Epoch: [32][   80/  267]    Overall Loss 2.308430    Objective Loss 2.308430                                        LR 0.100000    Time 0.299913    
2024-04-23 16:31:26,456 - Epoch: [32][   90/  267]    Overall Loss 2.305929    Objective Loss 2.305929                                        LR 0.100000    Time 0.302248    
2024-04-23 16:31:29,066 - Epoch: [32][  100/  267]    Overall Loss 2.308881    Objective Loss 2.308881                                        LR 0.100000    Time 0.298100    
2024-04-23 16:31:32,257 - Epoch: [32][  110/  267]    Overall Loss 2.307738    Objective Loss 2.307738                                        LR 0.100000    Time 0.299975    
2024-04-23 16:31:34,389 - Epoch: [32][  120/  267]    Overall Loss 2.308797    Objective Loss 2.308797                                        LR 0.100000    Time 0.292724    
2024-04-23 16:31:37,163 - Epoch: [32][  130/  267]    Overall Loss 2.309113    Objective Loss 2.309113                                        LR 0.100000    Time 0.291519    
2024-04-23 16:31:39,773 - Epoch: [32][  140/  267]    Overall Loss 2.309303    Objective Loss 2.309303                                        LR 0.100000    Time 0.289315    
2024-04-23 16:31:43,048 - Epoch: [32][  150/  267]    Overall Loss 2.308831    Objective Loss 2.308831                                        LR 0.100000    Time 0.291834    
2024-04-23 16:31:45,073 - Epoch: [32][  160/  267]    Overall Loss 2.309132    Objective Loss 2.309132                                        LR 0.100000    Time 0.286235    
2024-04-23 16:31:45,207 - Epoch: [24][  296/  296]    Overall Loss 1.149141    Objective Loss 1.149141    Top1 62.295082    Top5 91.803279    LR 0.000320    Time 0.274992    
2024-04-23 16:31:45,502 - --- validate (epoch=24)-----------
2024-04-23 16:31:45,504 - 3925 samples (32 per mini-batch)
2024-04-23 16:31:47,687 - Epoch: [32][  170/  267]    Overall Loss 2.308882    Objective Loss 2.308882                                        LR 0.100000    Time 0.284755    
2024-04-23 16:31:49,976 - Epoch: [32][  180/  267]    Overall Loss 2.308763    Objective Loss 2.308763                                        LR 0.100000    Time 0.281636    
2024-04-23 16:31:52,834 - Epoch: [32][  190/  267]    Overall Loss 2.308504    Objective Loss 2.308504                                        LR 0.100000    Time 0.281835    
2024-04-23 16:31:55,225 - Epoch: [32][  200/  267]    Overall Loss 2.307819    Objective Loss 2.307819                                        LR 0.100000    Time 0.279654    
2024-04-23 16:31:58,864 - Epoch: [32][  210/  267]    Overall Loss 2.308357    Objective Loss 2.308357                                        LR 0.100000    Time 0.283651    
2024-04-23 16:32:01,481 - Epoch: [32][  220/  267]    Overall Loss 2.308284    Objective Loss 2.308284                                        LR 0.100000    Time 0.282635    
2024-04-23 16:32:04,704 - Epoch: [32][  230/  267]    Overall Loss 2.308336    Objective Loss 2.308336                                        LR 0.100000    Time 0.284342    
2024-04-23 16:32:06,827 - Epoch: [32][  240/  267]    Overall Loss 2.308369    Objective Loss 2.308369                                        LR 0.100000    Time 0.281332    
2024-04-23 16:32:10,052 - Epoch: [32][  250/  267]    Overall Loss 2.308526    Objective Loss 2.308526                                        LR 0.100000    Time 0.282965    
2024-04-23 16:32:12,454 - Epoch: [32][  260/  267]    Overall Loss 2.308298    Objective Loss 2.308298                                        LR 0.100000    Time 0.281309    
2024-04-23 16:32:14,398 - Epoch: [32][  267/  267]    Overall Loss 2.308018    Objective Loss 2.308018    Top1 20.930233    Top5 58.139535    LR 0.100000    Time 0.281208    
2024-04-23 16:32:14,713 - --- validate (epoch=32)-----------
2024-04-23 16:32:14,714 - 946 samples (32 per mini-batch)
2024-04-23 16:32:16,532 - Epoch: [24][  100/  123]    Loss 0.980788    Top1 66.781250    Top5 94.937500    
2024-04-23 16:32:19,276 - Epoch: [32][   10/   30]    Loss 2.305641    Top1 10.000000    Top5 51.875000    
2024-04-23 16:32:21,869 - Epoch: [32][   20/   30]    Loss 2.303944    Top1 10.625000    Top5 50.468750    
2024-04-23 16:32:23,799 - Epoch: [24][  123/  123]    Loss 0.972555    Top1 67.133758    Top5 95.006369    
2024-04-23 16:32:24,109 - ==> Top1: 67.134    Top5: 95.006    Loss: 0.973

2024-04-23 16:32:24,120 - ==> Best [Top1: 67.822   Top5: 95.108   Sparsity:0.00   Params: 376752 on epoch: 22]
2024-04-23 16:32:24,121 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:32:24,178 - 

2024-04-23 16:32:24,179 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:32:24,367 - Epoch: [32][   30/   30]    Loss 2.304698    Top1 10.465116    Top5 49.577167    
2024-04-23 16:32:24,553 - ==> Top1: 10.465    Top5: 49.577    Loss: 2.305

2024-04-23 16:32:24,556 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 16:32:24,560 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:32:24,560 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:32:24,578 - 

2024-04-23 16:32:24,579 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:32:29,401 - Epoch: [33][   10/  267]    Overall Loss 2.294240    Objective Loss 2.294240                                        LR 0.100000    Time 0.481677    
2024-04-23 16:32:31,700 - Epoch: [33][   20/  267]    Overall Loss 2.306258    Objective Loss 2.306258                                        LR 0.100000    Time 0.355613    
2024-04-23 16:32:34,641 - Epoch: [33][   30/  267]    Overall Loss 2.311392    Objective Loss 2.311392                                        LR 0.100000    Time 0.334991    
2024-04-23 16:32:37,042 - Epoch: [33][   40/  267]    Overall Loss 2.310589    Objective Loss 2.310589                                        LR 0.100000    Time 0.311190    
2024-04-23 16:32:39,963 - Epoch: [33][   50/  267]    Overall Loss 2.310225    Objective Loss 2.310225                                        LR 0.100000    Time 0.307306    
2024-04-23 16:32:42,212 - Epoch: [33][   60/  267]    Overall Loss 2.308998    Objective Loss 2.308998                                        LR 0.100000    Time 0.293517    
2024-04-23 16:32:45,182 - Epoch: [33][   70/  267]    Overall Loss 2.309520    Objective Loss 2.309520                                        LR 0.100000    Time 0.293969    
2024-04-23 16:32:47,161 - Epoch: [33][   80/  267]    Overall Loss 2.309088    Objective Loss 2.309088                                        LR 0.100000    Time 0.281931    
2024-04-23 16:32:50,216 - Epoch: [33][   90/  267]    Overall Loss 2.309838    Objective Loss 2.309838                                        LR 0.100000    Time 0.284514    
2024-04-23 16:32:52,217 - Epoch: [25][  100/  296]    Overall Loss 1.113906    Objective Loss 1.113906                                        LR 0.000320    Time 0.280157    
2024-04-23 16:32:52,461 - Epoch: [33][  100/  267]    Overall Loss 2.309070    Objective Loss 2.309070                                        LR 0.100000    Time 0.278470    
2024-04-23 16:32:55,470 - Epoch: [33][  110/  267]    Overall Loss 2.308843    Objective Loss 2.308843                                        LR 0.100000    Time 0.280479    
2024-04-23 16:32:57,930 - Epoch: [33][  120/  267]    Overall Loss 2.309279    Objective Loss 2.309279                                        LR 0.100000    Time 0.277580    
2024-04-23 16:33:01,179 - Epoch: [33][  130/  267]    Overall Loss 2.309472    Objective Loss 2.309472                                        LR 0.100000    Time 0.281191    
2024-04-23 16:33:03,109 - Epoch: [33][  140/  267]    Overall Loss 2.309793    Objective Loss 2.309793                                        LR 0.100000    Time 0.274877    
2024-04-23 16:33:06,155 - Epoch: [33][  150/  267]    Overall Loss 2.309906    Objective Loss 2.309906                                        LR 0.100000    Time 0.276831    
2024-04-23 16:33:08,367 - Epoch: [33][  160/  267]    Overall Loss 2.310689    Objective Loss 2.310689                                        LR 0.100000    Time 0.273337    
2024-04-23 16:33:11,804 - Epoch: [33][  170/  267]    Overall Loss 2.310518    Objective Loss 2.310518                                        LR 0.100000    Time 0.277458    
2024-04-23 16:33:13,763 - Epoch: [33][  180/  267]    Overall Loss 2.310291    Objective Loss 2.310291                                        LR 0.100000    Time 0.272908    
2024-04-23 16:33:16,690 - Epoch: [33][  190/  267]    Overall Loss 2.310907    Objective Loss 2.310907                                        LR 0.100000    Time 0.273935    
2024-04-23 16:33:18,497 - Epoch: [33][  200/  267]    Overall Loss 2.311001    Objective Loss 2.311001                                        LR 0.100000    Time 0.269257    
2024-04-23 16:33:19,897 - Epoch: [25][  200/  296]    Overall Loss 1.142861    Objective Loss 1.142861                                        LR 0.000320    Time 0.278378    
2024-04-23 16:33:20,949 - Epoch: [33][  210/  267]    Overall Loss 2.311057    Objective Loss 2.311057                                        LR 0.100000    Time 0.268094    
2024-04-23 16:33:22,693 - Epoch: [33][  220/  267]    Overall Loss 2.311014    Objective Loss 2.311014                                        LR 0.100000    Time 0.263824    
2024-04-23 16:33:24,869 - Epoch: [33][  230/  267]    Overall Loss 2.311178    Objective Loss 2.311178                                        LR 0.100000    Time 0.261801    
2024-04-23 16:33:26,881 - Epoch: [33][  240/  267]    Overall Loss 2.310873    Objective Loss 2.310873                                        LR 0.100000    Time 0.259264    
2024-04-23 16:33:29,085 - Epoch: [33][  250/  267]    Overall Loss 2.311366    Objective Loss 2.311366                                        LR 0.100000    Time 0.257695    
2024-04-23 16:33:31,510 - Epoch: [33][  260/  267]    Overall Loss 2.310961    Objective Loss 2.310961                                        LR 0.100000    Time 0.257100    
2024-04-23 16:33:32,886 - Epoch: [33][  267/  267]    Overall Loss 2.311511    Objective Loss 2.311511    Top1 6.976744    Top5 44.186047    LR 0.100000    Time 0.255502    
2024-04-23 16:33:33,074 - --- validate (epoch=33)-----------
2024-04-23 16:33:33,075 - 946 samples (32 per mini-batch)
2024-04-23 16:33:37,470 - Epoch: [33][   10/   30]    Loss 2.321548    Top1 8.437500    Top5 50.312500    
2024-04-23 16:33:40,451 - Epoch: [33][   20/   30]    Loss 2.316336    Top1 10.625000    Top5 50.781250    
2024-04-23 16:33:41,335 - Epoch: [25][  296/  296]    Overall Loss 1.143278    Objective Loss 1.143278    Top1 68.852459    Top5 98.360656    LR 0.000320    Time 0.260449    
2024-04-23 16:33:41,661 - --- validate (epoch=25)-----------
2024-04-23 16:33:41,663 - 3925 samples (32 per mini-batch)
2024-04-23 16:33:42,422 - Epoch: [33][   30/   30]    Loss 2.311983    Top1 10.042283    Top5 51.268499    
2024-04-23 16:33:42,654 - ==> Top1: 10.042    Top5: 51.268    Loss: 2.312

2024-04-23 16:33:42,656 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 16:33:42,659 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:33:42,660 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:33:42,675 - 

2024-04-23 16:33:42,677 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:33:46,086 - Epoch: [34][   10/  267]    Overall Loss 2.308677    Objective Loss 2.308677                                        LR 0.100000    Time 0.340547    
2024-04-23 16:33:48,340 - Epoch: [34][   20/  267]    Overall Loss 2.319946    Objective Loss 2.319946                                        LR 0.100000    Time 0.282753    
2024-04-23 16:33:51,117 - Epoch: [34][   30/  267]    Overall Loss 2.319817    Objective Loss 2.319817                                        LR 0.100000    Time 0.280970    
2024-04-23 16:33:52,857 - Epoch: [34][   40/  267]    Overall Loss 2.318945    Objective Loss 2.318945                                        LR 0.100000    Time 0.254137    
2024-04-23 16:33:55,497 - Epoch: [34][   50/  267]    Overall Loss 2.316378    Objective Loss 2.316378                                        LR 0.100000    Time 0.256048    
2024-04-23 16:33:57,870 - Epoch: [34][   60/  267]    Overall Loss 2.318795    Objective Loss 2.318795                                        LR 0.100000    Time 0.252874    
2024-04-23 16:34:00,572 - Epoch: [34][   70/  267]    Overall Loss 2.316909    Objective Loss 2.316909                                        LR 0.100000    Time 0.255297    
2024-04-23 16:34:03,029 - Epoch: [34][   80/  267]    Overall Loss 2.315567    Objective Loss 2.315567                                        LR 0.100000    Time 0.254062    
2024-04-23 16:34:05,309 - Epoch: [34][   90/  267]    Overall Loss 2.316543    Objective Loss 2.316543                                        LR 0.100000    Time 0.251137    
2024-04-23 16:34:05,348 - Epoch: [25][  100/  123]    Loss 1.023923    Top1 65.968750    Top5 94.375000    
2024-04-23 16:34:07,370 - Epoch: [34][  100/  267]    Overall Loss 2.314923    Objective Loss 2.314923                                        LR 0.100000    Time 0.246557    
2024-04-23 16:34:09,883 - Epoch: [34][  110/  267]    Overall Loss 2.315442    Objective Loss 2.315442                                        LR 0.100000    Time 0.246960    
2024-04-23 16:34:11,120 - Epoch: [25][  123/  123]    Loss 1.004558    Top1 66.496815    Top5 94.675159    
2024-04-23 16:34:11,329 - ==> Top1: 66.497    Top5: 94.675    Loss: 1.005

2024-04-23 16:34:11,338 - ==> Best [Top1: 67.822   Top5: 95.108   Sparsity:0.00   Params: 376752 on epoch: 22]
2024-04-23 16:34:11,339 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:34:11,394 - 

2024-04-23 16:34:11,395 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:34:12,270 - Epoch: [34][  120/  267]    Overall Loss 2.314185    Objective Loss 2.314185                                        LR 0.100000    Time 0.246248    
2024-04-23 16:34:14,255 - Epoch: [34][  130/  267]    Overall Loss 2.315097    Objective Loss 2.315097                                        LR 0.100000    Time 0.242549    
2024-04-23 16:34:16,771 - Epoch: [34][  140/  267]    Overall Loss 2.315171    Objective Loss 2.315171                                        LR 0.100000    Time 0.243177    
2024-04-23 16:34:18,933 - Epoch: [34][  150/  267]    Overall Loss 2.315050    Objective Loss 2.315050                                        LR 0.100000    Time 0.241366    
2024-04-23 16:34:21,103 - Epoch: [34][  160/  267]    Overall Loss 2.316044    Objective Loss 2.316044                                        LR 0.100000    Time 0.239820    
2024-04-23 16:34:23,407 - Epoch: [34][  170/  267]    Overall Loss 2.315759    Objective Loss 2.315759                                        LR 0.100000    Time 0.239246    
2024-04-23 16:34:25,202 - Epoch: [34][  180/  267]    Overall Loss 2.316457    Objective Loss 2.316457                                        LR 0.100000    Time 0.235911    
2024-04-23 16:34:28,311 - Epoch: [34][  190/  267]    Overall Loss 2.316323    Objective Loss 2.316323                                        LR 0.100000    Time 0.239832    
2024-04-23 16:34:30,968 - Epoch: [34][  200/  267]    Overall Loss 2.316451    Objective Loss 2.316451                                        LR 0.100000    Time 0.241082    
2024-04-23 16:34:34,175 - Epoch: [34][  210/  267]    Overall Loss 2.315733    Objective Loss 2.315733                                        LR 0.100000    Time 0.244859    
2024-04-23 16:34:36,446 - Epoch: [34][  220/  267]    Overall Loss 2.316499    Objective Loss 2.316499                                        LR 0.100000    Time 0.244037    
2024-04-23 16:34:39,536 - Epoch: [26][  100/  296]    Overall Loss 1.105681    Objective Loss 1.105681                                        LR 0.000320    Time 0.281189    
2024-04-23 16:34:39,625 - Epoch: [34][  230/  267]    Overall Loss 2.316141    Objective Loss 2.316141                                        LR 0.100000    Time 0.247237    
2024-04-23 16:34:41,344 - Epoch: [34][  240/  267]    Overall Loss 2.316167    Objective Loss 2.316167                                        LR 0.100000    Time 0.244086    
2024-04-23 16:34:43,864 - Epoch: [34][  250/  267]    Overall Loss 2.316646    Objective Loss 2.316646                                        LR 0.100000    Time 0.244388    
2024-04-23 16:34:45,901 - Epoch: [34][  260/  267]    Overall Loss 2.316091    Objective Loss 2.316091                                        LR 0.100000    Time 0.242810    
2024-04-23 16:34:47,326 - Epoch: [34][  267/  267]    Overall Loss 2.316102    Objective Loss 2.316102    Top1 9.302326    Top5 51.162791    LR 0.100000    Time 0.241773    
2024-04-23 16:34:47,475 - --- validate (epoch=34)-----------
2024-04-23 16:34:47,476 - 946 samples (32 per mini-batch)
2024-04-23 16:34:51,173 - Epoch: [34][   10/   30]    Loss 2.319134    Top1 9.375000    Top5 48.750000    
2024-04-23 16:34:52,877 - Epoch: [34][   20/   30]    Loss 2.314178    Top1 10.625000    Top5 51.406250    
2024-04-23 16:34:55,778 - Epoch: [34][   30/   30]    Loss 2.314718    Top1 10.253700    Top5 50.951374    
2024-04-23 16:34:55,984 - ==> Top1: 10.254    Top5: 50.951    Loss: 2.315

2024-04-23 16:34:55,986 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 16:34:55,990 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:34:55,990 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:34:56,006 - 

2024-04-23 16:34:56,007 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:34:59,846 - Epoch: [35][   10/  267]    Overall Loss 2.329834    Objective Loss 2.329834                                        LR 0.100000    Time 0.383568    
2024-04-23 16:35:02,067 - Epoch: [35][   20/  267]    Overall Loss 2.317445    Objective Loss 2.317445                                        LR 0.100000    Time 0.302703    
2024-04-23 16:35:04,991 - Epoch: [35][   30/  267]    Overall Loss 2.318196    Objective Loss 2.318196                                        LR 0.100000    Time 0.299135    
2024-04-23 16:35:05,514 - Epoch: [26][  200/  296]    Overall Loss 1.123602    Objective Loss 1.123602                                        LR 0.000320    Time 0.270381    
2024-04-23 16:35:07,052 - Epoch: [35][   40/  267]    Overall Loss 2.317795    Objective Loss 2.317795                                        LR 0.100000    Time 0.275819    
2024-04-23 16:35:10,183 - Epoch: [35][   50/  267]    Overall Loss 2.316644    Objective Loss 2.316644                                        LR 0.100000    Time 0.283209    
2024-04-23 16:35:12,263 - Epoch: [35][   60/  267]    Overall Loss 2.315820    Objective Loss 2.315820                                        LR 0.100000    Time 0.270639    
2024-04-23 16:35:15,144 - Epoch: [35][   70/  267]    Overall Loss 2.315950    Objective Loss 2.315950                                        LR 0.100000    Time 0.273090    
2024-04-23 16:35:17,322 - Epoch: [35][   80/  267]    Overall Loss 2.314397    Objective Loss 2.314397                                        LR 0.100000    Time 0.266133    
2024-04-23 16:35:20,239 - Epoch: [35][   90/  267]    Overall Loss 2.314183    Objective Loss 2.314183                                        LR 0.100000    Time 0.268935    
2024-04-23 16:35:22,335 - Epoch: [35][  100/  267]    Overall Loss 2.314818    Objective Loss 2.314818                                        LR 0.100000    Time 0.262971    
2024-04-23 16:35:25,598 - Epoch: [35][  110/  267]    Overall Loss 2.315042    Objective Loss 2.315042                                        LR 0.100000    Time 0.268698    
2024-04-23 16:35:27,590 - Epoch: [35][  120/  267]    Overall Loss 2.314155    Objective Loss 2.314155                                        LR 0.100000    Time 0.262883    
2024-04-23 16:35:27,734 - Epoch: [26][  296/  296]    Overall Loss 1.139388    Objective Loss 1.139388    Top1 67.213115    Top5 93.442623    LR 0.000320    Time 0.257693    
2024-04-23 16:35:28,049 - --- validate (epoch=26)-----------
2024-04-23 16:35:28,050 - 3925 samples (32 per mini-batch)
2024-04-23 16:35:30,409 - Epoch: [35][  130/  267]    Overall Loss 2.314998    Objective Loss 2.314998                                        LR 0.100000    Time 0.264323    
2024-04-23 16:35:32,541 - Epoch: [35][  140/  267]    Overall Loss 2.314859    Objective Loss 2.314859                                        LR 0.100000    Time 0.260648    
2024-04-23 16:35:35,610 - Epoch: [35][  150/  267]    Overall Loss 2.314700    Objective Loss 2.314700                                        LR 0.100000    Time 0.263715    
2024-04-23 16:35:37,613 - Epoch: [35][  160/  267]    Overall Loss 2.314822    Objective Loss 2.314822                                        LR 0.100000    Time 0.259734    
2024-04-23 16:35:40,116 - Epoch: [35][  170/  267]    Overall Loss 2.314802    Objective Loss 2.314802                                        LR 0.100000    Time 0.259168    
2024-04-23 16:35:42,265 - Epoch: [35][  180/  267]    Overall Loss 2.314795    Objective Loss 2.314795                                        LR 0.100000    Time 0.256685    
2024-04-23 16:35:44,862 - Epoch: [35][  190/  267]    Overall Loss 2.314658    Objective Loss 2.314658                                        LR 0.100000    Time 0.256834    
2024-04-23 16:35:46,317 - Epoch: [35][  200/  267]    Overall Loss 2.315095    Objective Loss 2.315095                                        LR 0.100000    Time 0.251254    
2024-04-23 16:35:48,883 - Epoch: [35][  210/  267]    Overall Loss 2.314790    Objective Loss 2.314790                                        LR 0.100000    Time 0.251496    
2024-04-23 16:35:50,966 - Epoch: [35][  220/  267]    Overall Loss 2.314937    Objective Loss 2.314937                                        LR 0.100000    Time 0.249517    
2024-04-23 16:35:51,936 - Epoch: [26][  100/  123]    Loss 0.948588    Top1 69.125000    Top5 95.093750    
2024-04-23 16:35:53,937 - Epoch: [35][  230/  267]    Overall Loss 2.315361    Objective Loss 2.315361                                        LR 0.100000    Time 0.251576    
2024-04-23 16:35:55,581 - Epoch: [35][  240/  267]    Overall Loss 2.315168    Objective Loss 2.315168                                        LR 0.100000    Time 0.247933    
2024-04-23 16:35:57,022 - Epoch: [26][  123/  123]    Loss 0.942330    Top1 69.121019    Top5 95.235669    
2024-04-23 16:35:57,146 - ==> Top1: 69.121    Top5: 95.236    Loss: 0.942

2024-04-23 16:35:57,156 - ==> Best [Top1: 69.121   Top5: 95.236   Sparsity:0.00   Params: 376752 on epoch: 26]
2024-04-23 16:35:57,157 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:35:57,219 - 

2024-04-23 16:35:57,221 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:35:58,585 - Epoch: [35][  250/  267]    Overall Loss 2.315111    Objective Loss 2.315111                                        LR 0.100000    Time 0.250019    
2024-04-23 16:36:00,870 - Epoch: [35][  260/  267]    Overall Loss 2.315066    Objective Loss 2.315066                                        LR 0.100000    Time 0.249173    
2024-04-23 16:36:02,428 - Epoch: [35][  267/  267]    Overall Loss 2.315115    Objective Loss 2.315115    Top1 11.627907    Top5 37.209302    LR 0.100000    Time 0.248452    
2024-04-23 16:36:02,675 - --- validate (epoch=35)-----------
2024-04-23 16:36:02,677 - 946 samples (32 per mini-batch)
2024-04-23 16:36:07,019 - Epoch: [35][   10/   30]    Loss 2.323177    Top1 9.062500    Top5 45.625000    
2024-04-23 16:36:09,138 - Epoch: [35][   20/   30]    Loss 2.313399    Top1 10.312500    Top5 48.750000    
2024-04-23 16:36:10,892 - Epoch: [35][   30/   30]    Loss 2.310635    Top1 10.465116    Top5 48.942918    
2024-04-23 16:36:11,114 - ==> Top1: 10.465    Top5: 48.943    Loss: 2.311

2024-04-23 16:36:11,116 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 16:36:11,121 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:36:11,122 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:36:11,139 - 

2024-04-23 16:36:11,140 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:36:15,035 - Epoch: [36][   10/  267]    Overall Loss 2.316715    Objective Loss 2.316715                                        LR 0.100000    Time 0.389066    
2024-04-23 16:36:17,240 - Epoch: [36][   20/  267]    Overall Loss 2.320281    Objective Loss 2.320281                                        LR 0.100000    Time 0.304538    
2024-04-23 16:36:19,968 - Epoch: [36][   30/  267]    Overall Loss 2.319051    Objective Loss 2.319051                                        LR 0.100000    Time 0.293858    
2024-04-23 16:36:21,621 - Epoch: [27][  100/  296]    Overall Loss 1.137701    Objective Loss 1.137701                                        LR 0.000320    Time 0.243786    
2024-04-23 16:36:22,661 - Epoch: [36][   40/  267]    Overall Loss 2.316657    Objective Loss 2.316657                                        LR 0.100000    Time 0.287645    
2024-04-23 16:36:25,271 - Epoch: [36][   50/  267]    Overall Loss 2.319123    Objective Loss 2.319123                                        LR 0.100000    Time 0.282271    
2024-04-23 16:36:27,476 - Epoch: [36][   60/  267]    Overall Loss 2.319067    Objective Loss 2.319067                                        LR 0.100000    Time 0.271931    
2024-04-23 16:36:30,543 - Epoch: [36][   70/  267]    Overall Loss 2.317859    Objective Loss 2.317859                                        LR 0.100000    Time 0.276851    
2024-04-23 16:36:32,601 - Epoch: [36][   80/  267]    Overall Loss 2.315764    Objective Loss 2.315764                                        LR 0.100000    Time 0.267935    
2024-04-23 16:36:35,047 - Epoch: [36][   90/  267]    Overall Loss 2.314845    Objective Loss 2.314845                                        LR 0.100000    Time 0.265311    
2024-04-23 16:36:36,741 - Epoch: [36][  100/  267]    Overall Loss 2.312785    Objective Loss 2.312785                                        LR 0.100000    Time 0.255693    
2024-04-23 16:36:39,408 - Epoch: [36][  110/  267]    Overall Loss 2.314090    Objective Loss 2.314090                                        LR 0.100000    Time 0.256669    
2024-04-23 16:36:41,254 - Epoch: [36][  120/  267]    Overall Loss 2.314369    Objective Loss 2.314369                                        LR 0.100000    Time 0.250647    
2024-04-23 16:36:43,575 - Epoch: [36][  130/  267]    Overall Loss 2.314555    Objective Loss 2.314555                                        LR 0.100000    Time 0.249193    
2024-04-23 16:36:45,204 - Epoch: [27][  200/  296]    Overall Loss 1.126360    Objective Loss 1.126360                                        LR 0.000320    Time 0.239700    
2024-04-23 16:36:45,596 - Epoch: [36][  140/  267]    Overall Loss 2.314001    Objective Loss 2.314001                                        LR 0.100000    Time 0.245808    
2024-04-23 16:36:48,410 - Epoch: [36][  150/  267]    Overall Loss 2.314257    Objective Loss 2.314257                                        LR 0.100000    Time 0.248161    
2024-04-23 16:36:50,660 - Epoch: [36][  160/  267]    Overall Loss 2.313576    Objective Loss 2.313576                                        LR 0.100000    Time 0.246694    
2024-04-23 16:36:53,382 - Epoch: [36][  170/  267]    Overall Loss 2.313262    Objective Loss 2.313262                                        LR 0.100000    Time 0.248174    
2024-04-23 16:36:55,734 - Epoch: [36][  180/  267]    Overall Loss 2.313726    Objective Loss 2.313726                                        LR 0.100000    Time 0.247434    
2024-04-23 16:36:58,366 - Epoch: [36][  190/  267]    Overall Loss 2.314088    Objective Loss 2.314088                                        LR 0.100000    Time 0.248250    
2024-04-23 16:37:00,998 - Epoch: [36][  200/  267]    Overall Loss 2.313765    Objective Loss 2.313765                                        LR 0.100000    Time 0.248981    
2024-04-23 16:37:03,307 - Epoch: [36][  210/  267]    Overall Loss 2.314082    Objective Loss 2.314082                                        LR 0.100000    Time 0.248107    
2024-04-23 16:37:05,721 - Epoch: [36][  220/  267]    Overall Loss 2.314040    Objective Loss 2.314040                                        LR 0.100000    Time 0.247787    
2024-04-23 16:37:05,772 - Epoch: [27][  296/  296]    Overall Loss 1.119415    Objective Loss 1.119415    Top1 68.852459    Top5 95.081967    LR 0.000320    Time 0.231379    
2024-04-23 16:37:06,027 - --- validate (epoch=27)-----------
2024-04-23 16:37:06,028 - 3925 samples (32 per mini-batch)
2024-04-23 16:37:07,665 - Epoch: [36][  230/  267]    Overall Loss 2.313823    Objective Loss 2.313823                                        LR 0.100000    Time 0.245458    
2024-04-23 16:37:10,285 - Epoch: [36][  240/  267]    Overall Loss 2.313667    Objective Loss 2.313667                                        LR 0.100000    Time 0.246135    
2024-04-23 16:37:12,456 - Epoch: [36][  250/  267]    Overall Loss 2.312830    Objective Loss 2.312830                                        LR 0.100000    Time 0.244962    
2024-04-23 16:37:14,903 - Epoch: [36][  260/  267]    Overall Loss 2.313415    Objective Loss 2.313415                                        LR 0.100000    Time 0.244936    
2024-04-23 16:37:16,162 - Epoch: [36][  267/  267]    Overall Loss 2.313286    Objective Loss 2.313286    Top1 6.976744    Top5 44.186047    LR 0.100000    Time 0.243221    
2024-04-23 16:37:16,381 - --- validate (epoch=36)-----------
2024-04-23 16:37:16,383 - 946 samples (32 per mini-batch)
2024-04-23 16:37:20,023 - Epoch: [36][   10/   30]    Loss 2.294933    Top1 11.562500    Top5 54.375000    
2024-04-23 16:37:22,497 - Epoch: [36][   20/   30]    Loss 2.302379    Top1 11.250000    Top5 53.593750    
2024-04-23 16:37:24,164 - Epoch: [36][   30/   30]    Loss 2.307471    Top1 10.570825    Top5 52.219873    
2024-04-23 16:37:24,365 - ==> Top1: 10.571    Top5: 52.220    Loss: 2.307

2024-04-23 16:37:24,367 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 16:37:24,370 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:37:24,370 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:37:24,384 - 

2024-04-23 16:37:24,385 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:37:28,036 - Epoch: [37][   10/  267]    Overall Loss 2.313678    Objective Loss 2.313678                                        LR 0.100000    Time 0.364710    
2024-04-23 16:37:29,567 - Epoch: [37][   20/  267]    Overall Loss 2.318451    Objective Loss 2.318451                                        LR 0.100000    Time 0.258748    
2024-04-23 16:37:31,764 - Epoch: [37][   30/  267]    Overall Loss 2.322458    Objective Loss 2.322458                                        LR 0.100000    Time 0.245655    
2024-04-23 16:37:32,325 - Epoch: [27][  100/  123]    Loss 0.971055    Top1 68.468750    Top5 95.000000    
2024-04-23 16:37:33,797 - Epoch: [37][   40/  267]    Overall Loss 2.322606    Objective Loss 2.322606                                        LR 0.100000    Time 0.234989    
2024-04-23 16:37:36,869 - Epoch: [27][  123/  123]    Loss 0.964463    Top1 68.662420    Top5 95.006369    
2024-04-23 16:37:37,001 - Epoch: [37][   50/  267]    Overall Loss 2.318227    Objective Loss 2.318227                                        LR 0.100000    Time 0.252009    
2024-04-23 16:37:37,220 - ==> Top1: 68.662    Top5: 95.006    Loss: 0.964

2024-04-23 16:37:37,231 - ==> Best [Top1: 69.121   Top5: 95.236   Sparsity:0.00   Params: 376752 on epoch: 26]
2024-04-23 16:37:37,233 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:37:37,285 - 

2024-04-23 16:37:37,286 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:37:39,200 - Epoch: [37][   60/  267]    Overall Loss 2.317434    Objective Loss 2.317434                                        LR 0.100000    Time 0.246614    
2024-04-23 16:37:41,588 - Epoch: [37][   70/  267]    Overall Loss 2.316411    Objective Loss 2.316411                                        LR 0.100000    Time 0.245456    
2024-04-23 16:37:44,514 - Epoch: [37][   80/  267]    Overall Loss 2.318323    Objective Loss 2.318323                                        LR 0.100000    Time 0.251310    
2024-04-23 16:37:47,160 - Epoch: [37][   90/  267]    Overall Loss 2.316964    Objective Loss 2.316964                                        LR 0.100000    Time 0.252752    
2024-04-23 16:37:49,839 - Epoch: [37][  100/  267]    Overall Loss 2.315624    Objective Loss 2.315624                                        LR 0.100000    Time 0.254239    
2024-04-23 16:37:52,632 - Epoch: [37][  110/  267]    Overall Loss 2.316049    Objective Loss 2.316049                                        LR 0.100000    Time 0.256495    
2024-04-23 16:37:55,089 - Epoch: [37][  120/  267]    Overall Loss 2.316115    Objective Loss 2.316115                                        LR 0.100000    Time 0.255570    
2024-04-23 16:37:58,301 - Epoch: [37][  130/  267]    Overall Loss 2.316360    Objective Loss 2.316360                                        LR 0.100000    Time 0.260593    
2024-04-23 16:38:00,604 - Epoch: [37][  140/  267]    Overall Loss 2.317646    Objective Loss 2.317646                                        LR 0.100000    Time 0.258408    
2024-04-23 16:38:01,008 - Epoch: [28][  100/  296]    Overall Loss 1.120848    Objective Loss 1.120848                                        LR 0.000320    Time 0.236993    
2024-04-23 16:38:04,001 - Epoch: [37][  150/  267]    Overall Loss 2.318741    Objective Loss 2.318741                                        LR 0.100000    Time 0.263806    
2024-04-23 16:38:06,187 - Epoch: [37][  160/  267]    Overall Loss 2.319250    Objective Loss 2.319250                                        LR 0.100000    Time 0.260967    
2024-04-23 16:38:09,389 - Epoch: [37][  170/  267]    Overall Loss 2.319036    Objective Loss 2.319036                                        LR 0.100000    Time 0.264433    
2024-04-23 16:38:11,367 - Epoch: [37][  180/  267]    Overall Loss 2.318977    Objective Loss 2.318977                                        LR 0.100000    Time 0.260711    
2024-04-23 16:38:13,761 - Epoch: [37][  190/  267]    Overall Loss 2.319169    Objective Loss 2.319169                                        LR 0.100000    Time 0.259575    
2024-04-23 16:38:15,713 - Epoch: [37][  200/  267]    Overall Loss 2.320204    Objective Loss 2.320204                                        LR 0.100000    Time 0.256341    
2024-04-23 16:38:18,552 - Epoch: [37][  210/  267]    Overall Loss 2.320086    Objective Loss 2.320086                                        LR 0.100000    Time 0.257638    
2024-04-23 16:38:20,243 - Epoch: [37][  220/  267]    Overall Loss 2.319470    Objective Loss 2.319470                                        LR 0.100000    Time 0.253602    
2024-04-23 16:38:22,751 - Epoch: [37][  230/  267]    Overall Loss 2.320720    Objective Loss 2.320720                                        LR 0.100000    Time 0.253469    
2024-04-23 16:38:22,818 - Epoch: [28][  200/  296]    Overall Loss 1.100382    Objective Loss 1.100382                                        LR 0.000320    Time 0.227448    
2024-04-23 16:38:24,458 - Epoch: [37][  240/  267]    Overall Loss 2.320741    Objective Loss 2.320741                                        LR 0.100000    Time 0.250005    
2024-04-23 16:38:27,109 - Epoch: [37][  250/  267]    Overall Loss 2.320323    Objective Loss 2.320323                                        LR 0.100000    Time 0.250598    
2024-04-23 16:38:29,027 - Epoch: [37][  260/  267]    Overall Loss 2.319959    Objective Loss 2.319959                                        LR 0.100000    Time 0.248320    
2024-04-23 16:38:29,986 - Epoch: [37][  267/  267]    Overall Loss 2.320467    Objective Loss 2.320467    Top1 20.930233    Top5 48.837209    LR 0.100000    Time 0.245395    
2024-04-23 16:38:30,206 - --- validate (epoch=37)-----------
2024-04-23 16:38:30,207 - 946 samples (32 per mini-batch)
2024-04-23 16:38:33,976 - Epoch: [37][   10/   30]    Loss 2.327424    Top1 10.937500    Top5 52.187500    
2024-04-23 16:38:35,766 - Epoch: [37][   20/   30]    Loss 2.341620    Top1 10.156250    Top5 49.375000    
2024-04-23 16:38:38,072 - Epoch: [37][   30/   30]    Loss 2.342072    Top1 10.359408    Top5 50.105708    
2024-04-23 16:38:38,277 - ==> Top1: 10.359    Top5: 50.106    Loss: 2.342

2024-04-23 16:38:38,279 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 16:38:38,284 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:38:38,284 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:38:38,300 - 

2024-04-23 16:38:38,301 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:38:42,594 - Epoch: [38][   10/  267]    Overall Loss 2.307094    Objective Loss 2.307094                                        LR 0.100000    Time 0.428916    
2024-04-23 16:38:44,669 - Epoch: [28][  296/  296]    Overall Loss 1.111714    Objective Loss 1.111714    Top1 70.491803    Top5 98.360656    LR 0.000320    Time 0.227436    
2024-04-23 16:38:44,859 - Epoch: [38][   20/  267]    Overall Loss 2.312164    Objective Loss 2.312164                                        LR 0.100000    Time 0.327512    
2024-04-23 16:38:44,908 - --- validate (epoch=28)-----------
2024-04-23 16:38:44,909 - 3925 samples (32 per mini-batch)
2024-04-23 16:38:47,843 - Epoch: [38][   30/  267]    Overall Loss 2.319115    Objective Loss 2.319115                                        LR 0.100000    Time 0.317704    
2024-04-23 16:38:49,597 - Epoch: [38][   40/  267]    Overall Loss 2.325754    Objective Loss 2.325754                                        LR 0.100000    Time 0.282034    
2024-04-23 16:38:52,561 - Epoch: [38][   50/  267]    Overall Loss 2.328180    Objective Loss 2.328180                                        LR 0.100000    Time 0.284839    
2024-04-23 16:38:55,502 - Epoch: [38][   60/  267]    Overall Loss 2.325174    Objective Loss 2.325174                                        LR 0.100000    Time 0.286341    
2024-04-23 16:38:59,282 - Epoch: [38][   70/  267]    Overall Loss 2.327271    Objective Loss 2.327271                                        LR 0.100000    Time 0.299390    
2024-04-23 16:39:01,655 - Epoch: [38][   80/  267]    Overall Loss 2.327945    Objective Loss 2.327945                                        LR 0.100000    Time 0.291584    
2024-04-23 16:39:04,690 - Epoch: [38][   90/  267]    Overall Loss 2.326399    Objective Loss 2.326399                                        LR 0.100000    Time 0.292882    
2024-04-23 16:39:06,076 - Epoch: [28][  100/  123]    Loss 0.946246    Top1 68.687500    Top5 95.656250    
2024-04-23 16:39:07,307 - Epoch: [38][  100/  267]    Overall Loss 2.323915    Objective Loss 2.323915                                        LR 0.100000    Time 0.289726    
2024-04-23 16:39:10,282 - Epoch: [38][  110/  267]    Overall Loss 2.325107    Objective Loss 2.325107                                        LR 0.100000    Time 0.290407    
2024-04-23 16:39:10,797 - Epoch: [28][  123/  123]    Loss 0.939965    Top1 69.350318    Top5 95.668790    
2024-04-23 16:39:10,974 - ==> Top1: 69.350    Top5: 95.669    Loss: 0.940

2024-04-23 16:39:10,981 - ==> Best [Top1: 69.350   Top5: 95.669   Sparsity:0.00   Params: 376752 on epoch: 28]
2024-04-23 16:39:10,982 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:39:11,060 - 

2024-04-23 16:39:11,062 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:39:11,844 - Epoch: [38][  120/  267]    Overall Loss 2.324070    Objective Loss 2.324070                                        LR 0.100000    Time 0.279204    
2024-04-23 16:39:14,540 - Epoch: [38][  130/  267]    Overall Loss 2.323873    Objective Loss 2.323873                                        LR 0.100000    Time 0.278439    
2024-04-23 16:39:16,669 - Epoch: [38][  140/  267]    Overall Loss 2.322916    Objective Loss 2.322916                                        LR 0.100000    Time 0.273737    
2024-04-23 16:39:19,974 - Epoch: [38][  150/  267]    Overall Loss 2.323612    Objective Loss 2.323612                                        LR 0.100000    Time 0.277498    
2024-04-23 16:39:22,578 - Epoch: [38][  160/  267]    Overall Loss 2.324063    Objective Loss 2.324063                                        LR 0.100000    Time 0.276409    
2024-04-23 16:39:25,648 - Epoch: [38][  170/  267]    Overall Loss 2.324514    Objective Loss 2.324514                                        LR 0.100000    Time 0.278192    
2024-04-23 16:39:27,725 - Epoch: [38][  180/  267]    Overall Loss 2.325639    Objective Loss 2.325639                                        LR 0.100000    Time 0.274261    
2024-04-23 16:39:30,171 - Epoch: [38][  190/  267]    Overall Loss 2.325628    Objective Loss 2.325628                                        LR 0.100000    Time 0.272686    
2024-04-23 16:39:32,086 - Epoch: [38][  200/  267]    Overall Loss 2.325881    Objective Loss 2.325881                                        LR 0.100000    Time 0.268606    
2024-04-23 16:39:34,881 - Epoch: [38][  210/  267]    Overall Loss 2.325229    Objective Loss 2.325229                                        LR 0.100000    Time 0.269109    
2024-04-23 16:39:35,857 - Epoch: [29][  100/  296]    Overall Loss 1.072753    Objective Loss 1.072753                                        LR 0.000320    Time 0.247710    
2024-04-23 16:39:36,862 - Epoch: [38][  220/  267]    Overall Loss 2.325641    Objective Loss 2.325641                                        LR 0.100000    Time 0.265868    
2024-04-23 16:39:39,410 - Epoch: [38][  230/  267]    Overall Loss 2.326374    Objective Loss 2.326374                                        LR 0.100000    Time 0.265375    
2024-04-23 16:39:41,384 - Epoch: [38][  240/  267]    Overall Loss 2.325782    Objective Loss 2.325782                                        LR 0.100000    Time 0.262529    
2024-04-23 16:39:44,387 - Epoch: [38][  250/  267]    Overall Loss 2.325871    Objective Loss 2.325871                                        LR 0.100000    Time 0.264028    
2024-04-23 16:39:46,389 - Epoch: [38][  260/  267]    Overall Loss 2.326032    Objective Loss 2.326032                                        LR 0.100000    Time 0.261557    
2024-04-23 16:39:47,375 - Epoch: [38][  267/  267]    Overall Loss 2.325448    Objective Loss 2.325448    Top1 13.953488    Top5 55.813953    LR 0.100000    Time 0.258386    
2024-04-23 16:39:47,602 - --- validate (epoch=38)-----------
2024-04-23 16:39:47,603 - 946 samples (32 per mini-batch)
2024-04-23 16:39:51,155 - Epoch: [38][   10/   30]    Loss 2.355797    Top1 10.000000    Top5 48.125000    
2024-04-23 16:39:53,542 - Epoch: [38][   20/   30]    Loss 2.353588    Top1 10.000000    Top5 47.500000    
2024-04-23 16:39:55,497 - Epoch: [38][   30/   30]    Loss 2.355522    Top1 10.359408    Top5 48.520085    
2024-04-23 16:39:55,684 - ==> Top1: 10.359    Top5: 48.520    Loss: 2.356

2024-04-23 16:39:55,687 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 16:39:55,692 - ==> Best [Top1: 10.994   Top5: 49.154   Sparsity:0.00   Params: 96528 on epoch: 23]
2024-04-23 16:39:55,693 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:39:55,716 - 

2024-04-23 16:39:55,717 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:39:58,649 - Epoch: [29][  200/  296]    Overall Loss 1.090257    Objective Loss 1.090257                                        LR 0.000320    Time 0.237707    
2024-04-23 16:39:59,245 - Epoch: [39][   10/  267]    Overall Loss 2.335886    Objective Loss 2.335886                                        LR 0.100000    Time 0.352432    
2024-04-23 16:40:01,395 - Epoch: [39][   20/  267]    Overall Loss 2.333451    Objective Loss 2.333451                                        LR 0.100000    Time 0.283559    
2024-04-23 16:40:04,448 - Epoch: [39][   30/  267]    Overall Loss 2.334365    Objective Loss 2.334365                                        LR 0.100000    Time 0.290680    
2024-04-23 16:40:06,571 - Epoch: [39][   40/  267]    Overall Loss 2.331450    Objective Loss 2.331450                                        LR 0.100000    Time 0.271003    
2024-04-23 16:40:09,431 - Epoch: [39][   50/  267]    Overall Loss 2.328388    Objective Loss 2.328388                                        LR 0.100000    Time 0.273925    
2024-04-23 16:40:12,027 - Epoch: [39][   60/  267]    Overall Loss 2.325403    Objective Loss 2.325403                                        LR 0.100000    Time 0.271478    
2024-04-23 16:40:14,348 - Epoch: [39][   70/  267]    Overall Loss 2.325420    Objective Loss 2.325420                                        LR 0.100000    Time 0.265808    
2024-04-23 16:40:16,959 - Epoch: [39][   80/  267]    Overall Loss 2.322323    Objective Loss 2.322323                                        LR 0.100000    Time 0.265177    
2024-04-23 16:40:18,283 - Epoch: [29][  296/  296]    Overall Loss 1.093928    Objective Loss 1.093928    Top1 68.852459    Top5 95.081967    LR 0.000320    Time 0.226877    
2024-04-23 16:40:18,505 - --- validate (epoch=29)-----------
2024-04-23 16:40:18,506 - 3925 samples (32 per mini-batch)
2024-04-23 16:40:19,535 - Epoch: [39][   90/  267]    Overall Loss 2.324868    Objective Loss 2.324868                                        LR 0.100000    Time 0.264299    
2024-04-23 16:40:22,510 - Epoch: [39][  100/  267]    Overall Loss 2.324294    Objective Loss 2.324294                                        LR 0.100000    Time 0.267584    
2024-04-23 16:40:25,091 - Epoch: [39][  110/  267]    Overall Loss 2.323063    Objective Loss 2.323063                                        LR 0.100000    Time 0.266699    
2024-04-23 16:40:26,943 - Epoch: [39][  120/  267]    Overall Loss 2.322652    Objective Loss 2.322652                                        LR 0.100000    Time 0.259882    
2024-04-23 16:40:29,613 - Epoch: [39][  130/  267]    Overall Loss 2.322232    Objective Loss 2.322232                                        LR 0.100000    Time 0.260401    
2024-04-23 16:40:32,054 - Epoch: [39][  140/  267]    Overall Loss 2.323627    Objective Loss 2.323627                                        LR 0.100000    Time 0.259219    
2024-04-23 16:40:34,278 - Epoch: [39][  150/  267]    Overall Loss 2.322601    Objective Loss 2.322601                                        LR 0.100000    Time 0.256746    
2024-04-23 16:40:36,971 - Epoch: [39][  160/  267]    Overall Loss 2.321911    Objective Loss 2.321911                                        LR 0.100000    Time 0.257511    
2024-04-23 16:40:39,194 - Epoch: [39][  170/  267]    Overall Loss 2.322620    Objective Loss 2.322620                                        LR 0.100000    Time 0.255423    
2024-04-23 16:40:41,595 - Epoch: [39][  180/  267]    Overall Loss 2.322663    Objective Loss 2.322663                                        LR 0.100000    Time 0.254555    
2024-04-23 16:40:43,589 - Epoch: [29][  100/  123]    Loss 1.094940    Top1 64.062500    Top5 93.562500    
2024-04-23 16:40:43,874 - Epoch: [39][  190/  267]    Overall Loss 2.323179    Objective Loss 2.323179                                        LR 0.100000    Time 0.253134    
2024-04-23 16:40:46,672 - Epoch: [29][  123/  123]    Loss 1.101098    Top1 63.617834    Top5 93.834395    
2024-04-23 16:40:46,886 - ==> Top1: 63.618    Top5: 93.834    Loss: 1.101

2024-04-23 16:40:46,897 - ==> Best [Top1: 69.350   Top5: 95.669   Sparsity:0.00   Params: 376752 on epoch: 28]
2024-04-23 16:40:46,898 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:40:46,958 - 

2024-04-23 16:40:46,960 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:40:47,171 - Epoch: [39][  200/  267]    Overall Loss 2.323219    Objective Loss 2.323219                                        LR 0.100000    Time 0.256947    
2024-04-23 16:40:49,617 - Epoch: [39][  210/  267]    Overall Loss 2.323745    Objective Loss 2.323745                                        LR 0.100000    Time 0.256343    
2024-04-23 16:40:52,118 - Epoch: [39][  220/  267]    Overall Loss 2.324469    Objective Loss 2.324469                                        LR 0.100000    Time 0.256042    
2024-04-23 16:40:54,734 - Epoch: [39][  230/  267]    Overall Loss 2.325138    Objective Loss 2.325138                                        LR 0.100000    Time 0.256273    
2024-04-23 16:40:57,233 - Epoch: [39][  240/  267]    Overall Loss 2.325099    Objective Loss 2.325099                                        LR 0.100000    Time 0.255995    
2024-04-23 16:40:59,581 - Epoch: [39][  250/  267]    Overall Loss 2.324631    Objective Loss 2.324631                                        LR 0.100000    Time 0.255133    
2024-04-23 16:41:01,825 - Epoch: [39][  260/  267]    Overall Loss 2.323890    Objective Loss 2.323890                                        LR 0.100000    Time 0.253935    
2024-04-23 16:41:03,404 - Epoch: [39][  267/  267]    Overall Loss 2.323364    Objective Loss 2.323364    Top1 4.651163    Top5 58.139535    LR 0.100000    Time 0.253177    
2024-04-23 16:41:03,651 - --- validate (epoch=39)-----------
2024-04-23 16:41:03,652 - 946 samples (32 per mini-batch)
2024-04-23 16:41:07,837 - Epoch: [39][   10/   30]    Loss 2.350116    Top1 11.875000    Top5 50.625000    
2024-04-23 16:41:08,806 - Epoch: [30][  100/  296]    Overall Loss 1.082890    Objective Loss 1.082890                                        LR 0.000320    Time 0.218234    
2024-04-23 16:41:10,383 - Epoch: [39][   20/   30]    Loss 2.362104    Top1 11.093750    Top5 50.625000    
2024-04-23 16:41:13,558 - Epoch: [39][   30/   30]    Loss 2.349560    Top1 10.993658    Top5 51.268499    
2024-04-23 16:41:13,756 - ==> Top1: 10.994    Top5: 51.268    Loss: 2.350

2024-04-23 16:41:13,759 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 16:41:13,763 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:41:13,764 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:41:13,788 - 

2024-04-23 16:41:13,789 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:41:18,366 - Epoch: [40][   10/  267]    Overall Loss 2.366329    Objective Loss 2.366329                                        LR 0.100000    Time 0.457367    
2024-04-23 16:41:21,363 - Epoch: [40][   20/  267]    Overall Loss 2.359939    Objective Loss 2.359939                                        LR 0.100000    Time 0.378349    
2024-04-23 16:41:24,813 - Epoch: [40][   30/  267]    Overall Loss 2.351982    Objective Loss 2.351982                                        LR 0.100000    Time 0.367100    
2024-04-23 16:41:26,442 - Epoch: [30][  200/  296]    Overall Loss 1.076464    Objective Loss 1.076464                                        LR 0.000320    Time 0.197193    
2024-04-23 16:41:27,438 - Epoch: [40][   40/  267]    Overall Loss 2.356032    Objective Loss 2.356032                                        LR 0.100000    Time 0.340881    
2024-04-23 16:41:30,642 - Epoch: [40][   50/  267]    Overall Loss 2.353535    Objective Loss 2.353535                                        LR 0.100000    Time 0.336715    
2024-04-23 16:41:32,981 - Epoch: [40][   60/  267]    Overall Loss 2.350896    Objective Loss 2.350896                                        LR 0.100000    Time 0.319532    
2024-04-23 16:41:36,035 - Epoch: [40][   70/  267]    Overall Loss 2.353688    Objective Loss 2.353688                                        LR 0.100000    Time 0.317470    
2024-04-23 16:41:37,881 - Epoch: [40][   80/  267]    Overall Loss 2.353222    Objective Loss 2.353222                                        LR 0.100000    Time 0.300828    
2024-04-23 16:41:40,962 - Epoch: [40][   90/  267]    Overall Loss 2.355477    Objective Loss 2.355477                                        LR 0.100000    Time 0.301600    
2024-04-23 16:41:43,771 - Epoch: [40][  100/  267]    Overall Loss 2.353857    Objective Loss 2.353857                                        LR 0.100000    Time 0.299501    
2024-04-23 16:41:44,894 - Epoch: [30][  296/  296]    Overall Loss 1.088865    Objective Loss 1.088865    Top1 52.459016    Top5 90.163934    LR 0.000320    Time 0.195511    
2024-04-23 16:41:44,995 - --- validate (epoch=30)-----------
2024-04-23 16:41:44,996 - 3925 samples (32 per mini-batch)
2024-04-23 16:41:46,464 - Epoch: [40][  110/  267]    Overall Loss 2.354225    Objective Loss 2.354225                                        LR 0.100000    Time 0.296737    
2024-04-23 16:41:48,803 - Epoch: [40][  120/  267]    Overall Loss 2.352207    Objective Loss 2.352207                                        LR 0.100000    Time 0.291471    
2024-04-23 16:41:51,898 - Epoch: [40][  130/  267]    Overall Loss 2.354006    Objective Loss 2.354006                                        LR 0.100000    Time 0.292833    
2024-04-23 16:41:54,368 - Epoch: [40][  140/  267]    Overall Loss 2.352329    Objective Loss 2.352329                                        LR 0.100000    Time 0.289537    
2024-04-23 16:41:57,450 - Epoch: [40][  150/  267]    Overall Loss 2.355458    Objective Loss 2.355458                                        LR 0.100000    Time 0.290759    
2024-04-23 16:41:59,789 - Epoch: [40][  160/  267]    Overall Loss 2.354476    Objective Loss 2.354476                                        LR 0.100000    Time 0.287185    
2024-04-23 16:42:03,165 - Epoch: [40][  170/  267]    Overall Loss 2.353738    Objective Loss 2.353738                                        LR 0.100000    Time 0.290128    
2024-04-23 16:42:03,346 - Epoch: [30][  100/  123]    Loss 0.916501    Top1 69.625000    Top5 95.531250    
2024-04-23 16:42:05,394 - Epoch: [40][  180/  267]    Overall Loss 2.353541    Objective Loss 2.353541                                        LR 0.100000    Time 0.286376    
2024-04-23 16:42:07,369 - Epoch: [30][  123/  123]    Loss 0.904176    Top1 69.808917    Top5 95.745223    
2024-04-23 16:42:07,692 - ==> Top1: 69.809    Top5: 95.745    Loss: 0.904

2024-04-23 16:42:07,699 - ==> Best [Top1: 69.809   Top5: 95.745   Sparsity:0.00   Params: 376752 on epoch: 30]
2024-04-23 16:42:07,700 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:42:07,769 - 

2024-04-23 16:42:07,770 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:42:08,354 - Epoch: [40][  190/  267]    Overall Loss 2.353517    Objective Loss 2.353517                                        LR 0.100000    Time 0.286865    
2024-04-23 16:42:10,566 - Epoch: [40][  200/  267]    Overall Loss 2.352772    Objective Loss 2.352772                                        LR 0.100000    Time 0.283556    
2024-04-23 16:42:13,657 - Epoch: [40][  210/  267]    Overall Loss 2.351742    Objective Loss 2.351742                                        LR 0.100000    Time 0.284757    
2024-04-23 16:42:15,966 - Epoch: [40][  220/  267]    Overall Loss 2.353039    Objective Loss 2.353039                                        LR 0.100000    Time 0.282293    
2024-04-23 16:42:19,279 - Epoch: [40][  230/  267]    Overall Loss 2.353273    Objective Loss 2.353273                                        LR 0.100000    Time 0.284409    
2024-04-23 16:42:21,474 - Epoch: [40][  240/  267]    Overall Loss 2.354395    Objective Loss 2.354395                                        LR 0.100000    Time 0.281692    
2024-04-23 16:42:24,324 - Epoch: [40][  250/  267]    Overall Loss 2.354466    Objective Loss 2.354466                                        LR 0.100000    Time 0.281816    
2024-04-23 16:42:26,612 - Epoch: [40][  260/  267]    Overall Loss 2.354263    Objective Loss 2.354263                                        LR 0.100000    Time 0.279763    
2024-04-23 16:42:27,677 - Epoch: [31][  100/  296]    Overall Loss 1.076724    Objective Loss 1.076724                                        LR 0.000320    Time 0.198847    
2024-04-23 16:42:28,376 - Epoch: [40][  267/  267]    Overall Loss 2.353250    Objective Loss 2.353250    Top1 11.627907    Top5 55.813953    LR 0.100000    Time 0.279025    
2024-04-23 16:42:28,591 - --- validate (epoch=40)-----------
2024-04-23 16:42:28,593 - 946 samples (32 per mini-batch)
2024-04-23 16:42:32,890 - Epoch: [40][   10/   30]    Loss 2.349257    Top1 10.625000    Top5 51.250000    
2024-04-23 16:42:34,601 - Epoch: [40][   20/   30]    Loss 2.348634    Top1 10.468750    Top5 50.312500    
2024-04-23 16:42:37,688 - Epoch: [40][   30/   30]    Loss 2.350835    Top1 10.465116    Top5 50.317125    
2024-04-23 16:42:37,905 - ==> Top1: 10.465    Top5: 50.317    Loss: 2.351

2024-04-23 16:42:37,907 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 16:42:37,912 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:42:37,913 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:42:37,931 - 

2024-04-23 16:42:37,932 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:42:41,707 - Epoch: [41][   10/  267]    Overall Loss 2.377764    Objective Loss 2.377764                                        LR 0.100000    Time 0.377119    
2024-04-23 16:42:44,707 - Epoch: [31][  200/  296]    Overall Loss 1.103757    Objective Loss 1.103757                                        LR 0.000320    Time 0.184447    
2024-04-23 16:42:44,899 - Epoch: [41][   20/  267]    Overall Loss 2.363636    Objective Loss 2.363636                                        LR 0.100000    Time 0.348002    
2024-04-23 16:42:48,160 - Epoch: [41][   30/  267]    Overall Loss 2.362940    Objective Loss 2.362940                                        LR 0.100000    Time 0.340583    
2024-04-23 16:42:50,707 - Epoch: [41][   40/  267]    Overall Loss 2.356476    Objective Loss 2.356476                                        LR 0.100000    Time 0.319032    
2024-04-23 16:42:54,532 - Epoch: [41][   50/  267]    Overall Loss 2.362413    Objective Loss 2.362413                                        LR 0.100000    Time 0.331644    
2024-04-23 16:42:56,978 - Epoch: [41][   60/  267]    Overall Loss 2.364383    Objective Loss 2.364383                                        LR 0.100000    Time 0.317081    
2024-04-23 16:43:00,440 - Epoch: [41][   70/  267]    Overall Loss 2.360909    Objective Loss 2.360909                                        LR 0.100000    Time 0.321097    
2024-04-23 16:43:00,450 - Epoch: [31][  296/  296]    Overall Loss 1.091366    Objective Loss 1.091366    Top1 55.737705    Top5 95.081967    LR 0.000320    Time 0.177746    
2024-04-23 16:43:00,559 - --- validate (epoch=31)-----------
2024-04-23 16:43:00,561 - 3925 samples (32 per mini-batch)
2024-04-23 16:43:03,231 - Epoch: [41][   80/  267]    Overall Loss 2.359220    Objective Loss 2.359220                                        LR 0.100000    Time 0.315790    
2024-04-23 16:43:07,988 - Epoch: [41][   90/  267]    Overall Loss 2.362124    Objective Loss 2.362124                                        LR 0.100000    Time 0.333525    
2024-04-23 16:43:10,699 - Epoch: [41][  100/  267]    Overall Loss 2.363349    Objective Loss 2.363349                                        LR 0.100000    Time 0.327250    
2024-04-23 16:43:14,229 - Epoch: [41][  110/  267]    Overall Loss 2.363269    Objective Loss 2.363269                                        LR 0.100000    Time 0.329567    
2024-04-23 16:43:15,246 - Epoch: [31][  100/  123]    Loss 0.931574    Top1 69.125000    Top5 95.593750    
2024-04-23 16:43:17,019 - Epoch: [41][  120/  267]    Overall Loss 2.362903    Objective Loss 2.362903                                        LR 0.100000    Time 0.325325    
2024-04-23 16:43:19,412 - Epoch: [31][  123/  123]    Loss 0.939928    Top1 69.019108    Top5 95.515924    
2024-04-23 16:43:19,568 - ==> Top1: 69.019    Top5: 95.516    Loss: 0.940

2024-04-23 16:43:19,576 - ==> Best [Top1: 69.809   Top5: 95.745   Sparsity:0.00   Params: 376752 on epoch: 30]
2024-04-23 16:43:19,576 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:43:19,623 - 

2024-04-23 16:43:19,624 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:43:19,776 - Epoch: [41][  130/  267]    Overall Loss 2.362617    Objective Loss 2.362617                                        LR 0.100000    Time 0.321479    
2024-04-23 16:43:22,783 - Epoch: [41][  140/  267]    Overall Loss 2.361937    Objective Loss 2.361937                                        LR 0.100000    Time 0.319977    
2024-04-23 16:43:25,314 - Epoch: [41][  150/  267]    Overall Loss 2.359244    Objective Loss 2.359244                                        LR 0.100000    Time 0.315496    
2024-04-23 16:43:28,078 - Epoch: [41][  160/  267]    Overall Loss 2.361199    Objective Loss 2.361199                                        LR 0.100000    Time 0.313036    
2024-04-23 16:43:30,922 - Epoch: [41][  170/  267]    Overall Loss 2.361005    Objective Loss 2.361005                                        LR 0.100000    Time 0.311329    
2024-04-23 16:43:33,360 - Epoch: [41][  180/  267]    Overall Loss 2.361112    Objective Loss 2.361112                                        LR 0.100000    Time 0.307561    
2024-04-23 16:43:36,505 - Epoch: [41][  190/  267]    Overall Loss 2.361142    Objective Loss 2.361142                                        LR 0.100000    Time 0.307912    
2024-04-23 16:43:38,913 - Epoch: [41][  200/  267]    Overall Loss 2.359419    Objective Loss 2.359419                                        LR 0.100000    Time 0.304542    
2024-04-23 16:43:39,806 - Epoch: [32][  100/  296]    Overall Loss 1.073604    Objective Loss 1.073604                                        LR 0.000320    Time 0.201599    
2024-04-23 16:43:41,954 - Epoch: [41][  210/  267]    Overall Loss 2.358068    Objective Loss 2.358068                                        LR 0.100000    Time 0.304499    
2024-04-23 16:43:44,948 - Epoch: [41][  220/  267]    Overall Loss 2.357081    Objective Loss 2.357081                                        LR 0.100000    Time 0.304258    
2024-04-23 16:43:48,525 - Epoch: [41][  230/  267]    Overall Loss 2.356600    Objective Loss 2.356600                                        LR 0.100000    Time 0.306565    
2024-04-23 16:43:50,654 - Epoch: [32][  200/  296]    Overall Loss 1.074026    Objective Loss 1.074026                                        LR 0.000320    Time 0.154953    
2024-04-23 16:43:51,073 - Epoch: [41][  240/  267]    Overall Loss 2.354739    Objective Loss 2.354739                                        LR 0.100000    Time 0.304398    
2024-04-23 16:43:54,537 - Epoch: [41][  250/  267]    Overall Loss 2.353973    Objective Loss 2.353973                                        LR 0.100000    Time 0.306063    
2024-04-23 16:43:58,076 - Epoch: [41][  260/  267]    Overall Loss 2.352746    Objective Loss 2.352746                                        LR 0.100000    Time 0.307891    
2024-04-23 16:43:59,668 - Epoch: [32][  296/  296]    Overall Loss 1.081025    Objective Loss 1.081025    Top1 67.213115    Top5 98.360656    LR 0.000320    Time 0.135099    
2024-04-23 16:43:59,766 - --- validate (epoch=32)-----------
2024-04-23 16:43:59,767 - 3925 samples (32 per mini-batch)
2024-04-23 16:44:00,443 - Epoch: [41][  267/  267]    Overall Loss 2.351701    Objective Loss 2.351701    Top1 20.930233    Top5 53.488372    LR 0.100000    Time 0.308673    
2024-04-23 16:44:00,796 - --- validate (epoch=41)-----------
2024-04-23 16:44:00,798 - 946 samples (32 per mini-batch)
2024-04-23 16:44:04,491 - Epoch: [41][   10/   30]    Loss 2.348352    Top1 9.375000    Top5 47.812500    
2024-04-23 16:44:07,801 - Epoch: [41][   20/   30]    Loss 2.334607    Top1 10.468750    Top5 51.406250    
2024-04-23 16:44:10,880 - Epoch: [41][   30/   30]    Loss 2.340901    Top1 10.465116    Top5 49.682875    
2024-04-23 16:44:11,114 - ==> Top1: 10.465    Top5: 49.683    Loss: 2.341

2024-04-23 16:44:11,116 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 16:44:11,122 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:44:11,123 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:44:11,140 - 

2024-04-23 16:44:11,141 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:44:14,586 - Epoch: [42][   10/  267]    Overall Loss 2.344648    Objective Loss 2.344648                                        LR 0.100000    Time 0.344145    
2024-04-23 16:44:16,801 - Epoch: [42][   20/  267]    Overall Loss 2.344296    Objective Loss 2.344296                                        LR 0.100000    Time 0.282652    
2024-04-23 16:44:17,656 - Epoch: [32][  100/  123]    Loss 1.122369    Top1 62.093750    Top5 93.750000    
2024-04-23 16:44:19,845 - Epoch: [42][   30/  267]    Overall Loss 2.351827    Objective Loss 2.351827                                        LR 0.100000    Time 0.289824    
2024-04-23 16:44:22,280 - Epoch: [42][   40/  267]    Overall Loss 2.348469    Objective Loss 2.348469                                        LR 0.100000    Time 0.278165    
2024-04-23 16:44:23,849 - Epoch: [32][  123/  123]    Loss 1.117847    Top1 62.471338    Top5 94.089172    
2024-04-23 16:44:24,143 - ==> Top1: 62.471    Top5: 94.089    Loss: 1.118

2024-04-23 16:44:24,154 - ==> Best [Top1: 69.809   Top5: 95.745   Sparsity:0.00   Params: 376752 on epoch: 30]
2024-04-23 16:44:24,155 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:44:24,213 - 

2024-04-23 16:44:24,214 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:44:24,651 - Epoch: [42][   50/  267]    Overall Loss 2.345998    Objective Loss 2.345998                                        LR 0.100000    Time 0.269893    
2024-04-23 16:44:26,448 - Epoch: [42][   60/  267]    Overall Loss 2.343875    Objective Loss 2.343875                                        LR 0.100000    Time 0.254826    
2024-04-23 16:44:29,213 - Epoch: [42][   70/  267]    Overall Loss 2.345208    Objective Loss 2.345208                                        LR 0.100000    Time 0.257864    
2024-04-23 16:44:31,225 - Epoch: [42][   80/  267]    Overall Loss 2.345944    Objective Loss 2.345944                                        LR 0.100000    Time 0.250755    
2024-04-23 16:44:33,915 - Epoch: [42][   90/  267]    Overall Loss 2.346180    Objective Loss 2.346180                                        LR 0.100000    Time 0.252743    
2024-04-23 16:44:35,411 - Epoch: [42][  100/  267]    Overall Loss 2.345403    Objective Loss 2.345403                                        LR 0.100000    Time 0.242408    
2024-04-23 16:44:38,000 - Epoch: [42][  110/  267]    Overall Loss 2.347356    Objective Loss 2.347356                                        LR 0.100000    Time 0.243875    
2024-04-23 16:44:39,820 - Epoch: [42][  120/  267]    Overall Loss 2.345226    Objective Loss 2.345226                                        LR 0.100000    Time 0.238691    
2024-04-23 16:44:42,528 - Epoch: [42][  130/  267]    Overall Loss 2.346980    Objective Loss 2.346980                                        LR 0.100000    Time 0.241141    
2024-04-23 16:44:44,401 - Epoch: [42][  140/  267]    Overall Loss 2.346401    Objective Loss 2.346401                                        LR 0.100000    Time 0.237271    
2024-04-23 16:44:46,857 - Epoch: [42][  150/  267]    Overall Loss 2.349254    Objective Loss 2.349254                                        LR 0.100000    Time 0.237807    
2024-04-23 16:44:47,609 - Epoch: [33][  100/  296]    Overall Loss 1.055804    Objective Loss 1.055804                                        LR 0.000320    Time 0.233730    
2024-04-23 16:44:48,993 - Epoch: [42][  160/  267]    Overall Loss 2.348751    Objective Loss 2.348751                                        LR 0.100000    Time 0.236277    
2024-04-23 16:44:51,253 - Epoch: [42][  170/  267]    Overall Loss 2.349903    Objective Loss 2.349903                                        LR 0.100000    Time 0.235656    
2024-04-23 16:44:52,937 - Epoch: [42][  180/  267]    Overall Loss 2.349663    Objective Loss 2.349663                                        LR 0.100000    Time 0.231904    
2024-04-23 16:44:54,581 - Epoch: [42][  190/  267]    Overall Loss 2.349932    Objective Loss 2.349932                                        LR 0.100000    Time 0.228333    
2024-04-23 16:44:56,310 - Epoch: [42][  200/  267]    Overall Loss 2.350341    Objective Loss 2.350341                                        LR 0.100000    Time 0.225549    
2024-04-23 16:45:00,023 - Epoch: [42][  210/  267]    Overall Loss 2.352960    Objective Loss 2.352960                                        LR 0.100000    Time 0.232474    
2024-04-23 16:45:01,874 - Epoch: [42][  220/  267]    Overall Loss 2.353545    Objective Loss 2.353545                                        LR 0.100000    Time 0.230303    
2024-04-23 16:45:04,619 - Epoch: [42][  230/  267]    Overall Loss 2.353281    Objective Loss 2.353281                                        LR 0.100000    Time 0.232212    
2024-04-23 16:45:06,567 - Epoch: [42][  240/  267]    Overall Loss 2.353012    Objective Loss 2.353012                                        LR 0.100000    Time 0.230628    
2024-04-23 16:45:08,734 - Epoch: [33][  200/  296]    Overall Loss 1.068258    Objective Loss 1.068258                                        LR 0.000320    Time 0.222381    
2024-04-23 16:45:09,644 - Epoch: [42][  250/  267]    Overall Loss 2.352638    Objective Loss 2.352638                                        LR 0.100000    Time 0.233700    
2024-04-23 16:45:11,901 - Epoch: [42][  260/  267]    Overall Loss 2.352307    Objective Loss 2.352307                                        LR 0.100000    Time 0.233379    
2024-04-23 16:45:13,774 - Epoch: [42][  267/  267]    Overall Loss 2.352300    Objective Loss 2.352300    Top1 11.627907    Top5 46.511628    LR 0.100000    Time 0.234265    
2024-04-23 16:45:14,009 - --- validate (epoch=42)-----------
2024-04-23 16:45:14,011 - 946 samples (32 per mini-batch)
2024-04-23 16:45:18,387 - Epoch: [42][   10/   30]    Loss 2.326410    Top1 11.562500    Top5 51.562500    
2024-04-23 16:45:20,709 - Epoch: [42][   20/   30]    Loss 2.334406    Top1 10.156250    Top5 49.218750    
2024-04-23 16:45:23,641 - Epoch: [42][   30/   30]    Loss 2.328605    Top1 10.570825    Top5 50.422833    
2024-04-23 16:45:23,867 - ==> Top1: 10.571    Top5: 50.423    Loss: 2.329

2024-04-23 16:45:23,869 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 16:45:23,872 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:45:23,873 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:45:23,893 - 

2024-04-23 16:45:23,895 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:45:28,181 - Epoch: [43][   10/  267]    Overall Loss 2.319178    Objective Loss 2.319178                                        LR 0.100000    Time 0.428023    
2024-04-23 16:45:30,465 - Epoch: [43][   20/  267]    Overall Loss 2.353951    Objective Loss 2.353951                                        LR 0.100000    Time 0.328043    
2024-04-23 16:45:32,129 - Epoch: [33][  296/  296]    Overall Loss 1.070558    Objective Loss 1.070558    Top1 60.655738    Top5 98.360656    LR 0.000320    Time 0.229221    
2024-04-23 16:45:32,365 - --- validate (epoch=33)-----------
2024-04-23 16:45:32,367 - 3925 samples (32 per mini-batch)
2024-04-23 16:45:33,072 - Epoch: [43][   30/  267]    Overall Loss 2.371240    Objective Loss 2.371240                                        LR 0.100000    Time 0.305502    
2024-04-23 16:45:35,671 - Epoch: [43][   40/  267]    Overall Loss 2.367286    Objective Loss 2.367286                                        LR 0.100000    Time 0.294025    
2024-04-23 16:45:38,425 - Epoch: [43][   50/  267]    Overall Loss 2.373077    Objective Loss 2.373077                                        LR 0.100000    Time 0.290242    
2024-04-23 16:45:39,991 - Epoch: [43][   60/  267]    Overall Loss 2.369195    Objective Loss 2.369195                                        LR 0.100000    Time 0.267914    
2024-04-23 16:45:42,681 - Epoch: [43][   70/  267]    Overall Loss 2.366790    Objective Loss 2.366790                                        LR 0.100000    Time 0.267958    
2024-04-23 16:45:44,726 - Epoch: [43][   80/  267]    Overall Loss 2.366047    Objective Loss 2.366047                                        LR 0.100000    Time 0.259984    
2024-04-23 16:45:47,888 - Epoch: [43][   90/  267]    Overall Loss 2.364623    Objective Loss 2.364623                                        LR 0.100000    Time 0.266185    
2024-04-23 16:45:50,075 - Epoch: [43][  100/  267]    Overall Loss 2.359531    Objective Loss 2.359531                                        LR 0.100000    Time 0.261404    
2024-04-23 16:45:52,956 - Epoch: [43][  110/  267]    Overall Loss 2.356552    Objective Loss 2.356552                                        LR 0.100000    Time 0.263802    
2024-04-23 16:45:55,032 - Epoch: [43][  120/  267]    Overall Loss 2.358089    Objective Loss 2.358089                                        LR 0.100000    Time 0.259095    
2024-04-23 16:45:58,311 - Epoch: [43][  130/  267]    Overall Loss 2.357593    Objective Loss 2.357593                                        LR 0.100000    Time 0.264357    
2024-04-23 16:45:59,421 - Epoch: [33][  100/  123]    Loss 0.939507    Top1 68.875000    Top5 95.500000    
2024-04-23 16:46:00,566 - Epoch: [43][  140/  267]    Overall Loss 2.357129    Objective Loss 2.357129                                        LR 0.100000    Time 0.261557    
2024-04-23 16:46:03,223 - Epoch: [43][  150/  267]    Overall Loss 2.356256    Objective Loss 2.356256                                        LR 0.100000    Time 0.261807    
2024-04-23 16:46:05,129 - Epoch: [33][  123/  123]    Loss 0.945107    Top1 68.713376    Top5 95.414013    
2024-04-23 16:46:05,389 - ==> Top1: 68.713    Top5: 95.414    Loss: 0.945

2024-04-23 16:46:05,399 - ==> Best [Top1: 69.809   Top5: 95.745   Sparsity:0.00   Params: 376752 on epoch: 30]
2024-04-23 16:46:05,400 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:46:05,453 - 

2024-04-23 16:46:05,454 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:46:05,509 - Epoch: [43][  160/  267]    Overall Loss 2.356155    Objective Loss 2.356155                                        LR 0.100000    Time 0.259713    
2024-04-23 16:46:07,760 - Epoch: [43][  170/  267]    Overall Loss 2.354456    Objective Loss 2.354456                                        LR 0.100000    Time 0.257654    
2024-04-23 16:46:10,876 - Epoch: [43][  180/  267]    Overall Loss 2.354161    Objective Loss 2.354161                                        LR 0.100000    Time 0.260639    
2024-04-23 16:46:13,365 - Epoch: [43][  190/  267]    Overall Loss 2.355423    Objective Loss 2.355423                                        LR 0.100000    Time 0.260006    
2024-04-23 16:46:16,392 - Epoch: [43][  200/  267]    Overall Loss 2.354166    Objective Loss 2.354166                                        LR 0.100000    Time 0.262123    
2024-04-23 16:46:18,660 - Epoch: [43][  210/  267]    Overall Loss 2.354733    Objective Loss 2.354733                                        LR 0.100000    Time 0.260425    
2024-04-23 16:46:21,856 - Epoch: [43][  220/  267]    Overall Loss 2.356970    Objective Loss 2.356970                                        LR 0.100000    Time 0.263103    
2024-04-23 16:46:23,952 - Epoch: [43][  230/  267]    Overall Loss 2.358057    Objective Loss 2.358057                                        LR 0.100000    Time 0.260768    
2024-04-23 16:46:26,974 - Epoch: [43][  240/  267]    Overall Loss 2.356510    Objective Loss 2.356510                                        LR 0.100000    Time 0.262481    
2024-04-23 16:46:28,994 - Epoch: [43][  250/  267]    Overall Loss 2.356830    Objective Loss 2.356830                                        LR 0.100000    Time 0.260051    
2024-04-23 16:46:31,861 - Epoch: [43][  260/  267]    Overall Loss 2.356053    Objective Loss 2.356053                                        LR 0.100000    Time 0.261065    
2024-04-23 16:46:32,250 - Epoch: [34][  100/  296]    Overall Loss 1.076284    Objective Loss 1.076284                                        LR 0.000320    Time 0.267727    
2024-04-23 16:46:32,950 - Epoch: [43][  267/  267]    Overall Loss 2.354675    Objective Loss 2.354675    Top1 4.651163    Top5 65.116279    LR 0.100000    Time 0.258290    
2024-04-23 16:46:33,246 - --- validate (epoch=43)-----------
2024-04-23 16:46:33,246 - 946 samples (32 per mini-batch)
2024-04-23 16:46:37,087 - Epoch: [43][   10/   30]    Loss 2.342346    Top1 10.937500    Top5 52.187500    
2024-04-23 16:46:38,889 - Epoch: [43][   20/   30]    Loss 2.347387    Top1 11.093750    Top5 52.031250    
2024-04-23 16:46:41,180 - Epoch: [43][   30/   30]    Loss 2.346672    Top1 10.570825    Top5 50.845666    
2024-04-23 16:46:41,400 - ==> Top1: 10.571    Top5: 50.846    Loss: 2.347

2024-04-23 16:46:41,402 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 16:46:41,408 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:46:41,409 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:46:41,430 - 

2024-04-23 16:46:41,432 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:46:45,334 - Epoch: [44][   10/  267]    Overall Loss 2.366101    Objective Loss 2.366101                                        LR 0.100000    Time 0.389848    
2024-04-23 16:46:47,640 - Epoch: [44][   20/  267]    Overall Loss 2.373282    Objective Loss 2.373282                                        LR 0.100000    Time 0.310024    
2024-04-23 16:46:50,084 - Epoch: [44][   30/  267]    Overall Loss 2.373801    Objective Loss 2.373801                                        LR 0.100000    Time 0.288056    
2024-04-23 16:46:52,299 - Epoch: [44][   40/  267]    Overall Loss 2.375955    Objective Loss 2.375955                                        LR 0.100000    Time 0.271333    
2024-04-23 16:46:55,056 - Epoch: [44][   50/  267]    Overall Loss 2.367838    Objective Loss 2.367838                                        LR 0.100000    Time 0.272133    
2024-04-23 16:46:55,539 - Epoch: [34][  200/  296]    Overall Loss 1.081359    Objective Loss 1.081359                                        LR 0.000320    Time 0.250203    
2024-04-23 16:46:57,657 - Epoch: [44][   60/  267]    Overall Loss 2.364429    Objective Loss 2.364429                                        LR 0.100000    Time 0.270072    
2024-04-23 16:47:00,238 - Epoch: [44][   70/  267]    Overall Loss 2.358922    Objective Loss 2.358922                                        LR 0.100000    Time 0.268327    
2024-04-23 16:47:03,124 - Epoch: [44][   80/  267]    Overall Loss 2.360769    Objective Loss 2.360769                                        LR 0.100000    Time 0.270817    
2024-04-23 16:47:04,807 - Epoch: [44][   90/  267]    Overall Loss 2.361146    Objective Loss 2.361146                                        LR 0.100000    Time 0.259396    
2024-04-23 16:47:07,792 - Epoch: [44][  100/  267]    Overall Loss 2.359190    Objective Loss 2.359190                                        LR 0.100000    Time 0.263267    
2024-04-23 16:47:09,811 - Epoch: [44][  110/  267]    Overall Loss 2.358554    Objective Loss 2.358554                                        LR 0.100000    Time 0.257657    
2024-04-23 16:47:12,353 - Epoch: [44][  120/  267]    Overall Loss 2.358368    Objective Loss 2.358368                                        LR 0.100000    Time 0.257346    
2024-04-23 16:47:14,526 - Epoch: [44][  130/  267]    Overall Loss 2.356415    Objective Loss 2.356415                                        LR 0.100000    Time 0.254237    
2024-04-23 16:47:17,539 - Epoch: [34][  296/  296]    Overall Loss 1.071294    Objective Loss 1.071294    Top1 60.655738    Top5 93.442623    LR 0.000320    Time 0.243309    
2024-04-23 16:47:17,557 - Epoch: [44][  140/  267]    Overall Loss 2.356263    Objective Loss 2.356263                                        LR 0.100000    Time 0.257708    
2024-04-23 16:47:17,803 - --- validate (epoch=34)-----------
2024-04-23 16:47:17,804 - 3925 samples (32 per mini-batch)
2024-04-23 16:47:19,230 - Epoch: [44][  150/  267]    Overall Loss 2.358453    Objective Loss 2.358453                                        LR 0.100000    Time 0.251658    
2024-04-23 16:47:22,145 - Epoch: [44][  160/  267]    Overall Loss 2.356532    Objective Loss 2.356532                                        LR 0.100000    Time 0.254129    
2024-04-23 16:47:24,447 - Epoch: [44][  170/  267]    Overall Loss 2.358216    Objective Loss 2.358216                                        LR 0.100000    Time 0.252701    
2024-04-23 16:47:27,399 - Epoch: [44][  180/  267]    Overall Loss 2.359661    Objective Loss 2.359661                                        LR 0.100000    Time 0.255045    
2024-04-23 16:47:29,524 - Epoch: [44][  190/  267]    Overall Loss 2.359265    Objective Loss 2.359265                                        LR 0.100000    Time 0.252785    
2024-04-23 16:47:32,282 - Epoch: [44][  200/  267]    Overall Loss 2.358250    Objective Loss 2.358250                                        LR 0.100000    Time 0.253921    
2024-04-23 16:47:34,230 - Epoch: [44][  210/  267]    Overall Loss 2.356994    Objective Loss 2.356994                                        LR 0.100000    Time 0.251093    
2024-04-23 16:47:36,901 - Epoch: [44][  220/  267]    Overall Loss 2.359063    Objective Loss 2.359063                                        LR 0.100000    Time 0.251804    
2024-04-23 16:47:38,875 - Epoch: [44][  230/  267]    Overall Loss 2.358835    Objective Loss 2.358835                                        LR 0.100000    Time 0.249429    
2024-04-23 16:47:41,604 - Epoch: [44][  240/  267]    Overall Loss 2.360210    Objective Loss 2.360210                                        LR 0.100000    Time 0.250394    
2024-04-23 16:47:43,850 - Epoch: [44][  250/  267]    Overall Loss 2.359527    Objective Loss 2.359527                                        LR 0.100000    Time 0.249351    
2024-04-23 16:47:45,936 - Epoch: [34][  100/  123]    Loss 0.960490    Top1 68.531250    Top5 95.343750    
2024-04-23 16:47:46,338 - Epoch: [44][  260/  267]    Overall Loss 2.360139    Objective Loss 2.360139                                        LR 0.100000    Time 0.249313    
2024-04-23 16:47:47,851 - Epoch: [44][  267/  267]    Overall Loss 2.359576    Objective Loss 2.359576    Top1 4.651163    Top5 53.488372    LR 0.100000    Time 0.248432    
2024-04-23 16:47:48,065 - --- validate (epoch=44)-----------
2024-04-23 16:47:48,067 - 946 samples (32 per mini-batch)
2024-04-23 16:47:51,496 - Epoch: [34][  123/  123]    Loss 0.949027    Top1 68.815287    Top5 95.414013    
2024-04-23 16:47:51,587 - Epoch: [44][   10/   30]    Loss 2.348655    Top1 10.625000    Top5 53.125000    
2024-04-23 16:47:51,718 - ==> Top1: 68.815    Top5: 95.414    Loss: 0.949

2024-04-23 16:47:51,727 - ==> Best [Top1: 69.809   Top5: 95.745   Sparsity:0.00   Params: 376752 on epoch: 30]
2024-04-23 16:47:51,727 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:47:51,791 - 

2024-04-23 16:47:51,792 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:47:53,360 - Epoch: [44][   20/   30]    Loss 2.360850    Top1 11.250000    Top5 50.312500    
2024-04-23 16:47:55,718 - Epoch: [44][   30/   30]    Loss 2.362421    Top1 10.253700    Top5 50.845666    
2024-04-23 16:47:55,972 - ==> Top1: 10.254    Top5: 50.846    Loss: 2.362

2024-04-23 16:47:55,975 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 16:47:55,979 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:47:55,980 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:47:55,997 - 

2024-04-23 16:47:55,998 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:47:58,973 - Epoch: [45][   10/  267]    Overall Loss 2.366468    Objective Loss 2.366468                                        LR 0.100000    Time 0.297098    
2024-04-23 16:48:01,520 - Epoch: [45][   20/  267]    Overall Loss 2.353119    Objective Loss 2.353119                                        LR 0.100000    Time 0.275721    
2024-04-23 16:48:04,637 - Epoch: [45][   30/  267]    Overall Loss 2.355275    Objective Loss 2.355275                                        LR 0.100000    Time 0.287597    
2024-04-23 16:48:06,640 - Epoch: [45][   40/  267]    Overall Loss 2.356988    Objective Loss 2.356988                                        LR 0.100000    Time 0.265719    
2024-04-23 16:48:09,427 - Epoch: [45][   50/  267]    Overall Loss 2.359728    Objective Loss 2.359728                                        LR 0.100000    Time 0.268241    
2024-04-23 16:48:11,442 - Epoch: [45][   60/  267]    Overall Loss 2.359807    Objective Loss 2.359807                                        LR 0.100000    Time 0.257050    
2024-04-23 16:48:14,303 - Epoch: [45][   70/  267]    Overall Loss 2.359237    Objective Loss 2.359237                                        LR 0.100000    Time 0.261162    
2024-04-23 16:48:15,790 - Epoch: [35][  100/  296]    Overall Loss 1.058115    Objective Loss 1.058115                                        LR 0.000320    Time 0.239711    
2024-04-23 16:48:16,288 - Epoch: [45][   80/  267]    Overall Loss 2.360287    Objective Loss 2.360287                                        LR 0.100000    Time 0.253290    
2024-04-23 16:48:18,817 - Epoch: [45][   90/  267]    Overall Loss 2.358567    Objective Loss 2.358567                                        LR 0.100000    Time 0.253215    
2024-04-23 16:48:21,086 - Epoch: [45][  100/  267]    Overall Loss 2.358203    Objective Loss 2.358203                                        LR 0.100000    Time 0.250552    
2024-04-23 16:48:23,898 - Epoch: [45][  110/  267]    Overall Loss 2.355969    Objective Loss 2.355969                                        LR 0.100000    Time 0.253318    
2024-04-23 16:48:25,956 - Epoch: [45][  120/  267]    Overall Loss 2.358558    Objective Loss 2.358558                                        LR 0.100000    Time 0.249332    
2024-04-23 16:48:28,696 - Epoch: [45][  130/  267]    Overall Loss 2.358123    Objective Loss 2.358123                                        LR 0.100000    Time 0.251206    
2024-04-23 16:48:31,285 - Epoch: [45][  140/  267]    Overall Loss 2.360654    Objective Loss 2.360654                                        LR 0.100000    Time 0.251736    
2024-04-23 16:48:33,701 - Epoch: [45][  150/  267]    Overall Loss 2.358350    Objective Loss 2.358350                                        LR 0.100000    Time 0.251038    
2024-04-23 16:48:36,719 - Epoch: [45][  160/  267]    Overall Loss 2.355359    Objective Loss 2.355359                                        LR 0.100000    Time 0.254191    
2024-04-23 16:48:38,840 - Epoch: [45][  170/  267]    Overall Loss 2.356188    Objective Loss 2.356188                                        LR 0.100000    Time 0.251699    
2024-04-23 16:48:39,385 - Epoch: [35][  200/  296]    Overall Loss 1.065222    Objective Loss 1.065222                                        LR 0.000320    Time 0.237719    
2024-04-23 16:48:41,907 - Epoch: [45][  180/  267]    Overall Loss 2.356393    Objective Loss 2.356393                                        LR 0.100000    Time 0.254741    
2024-04-23 16:48:44,006 - Epoch: [45][  190/  267]    Overall Loss 2.357119    Objective Loss 2.357119                                        LR 0.100000    Time 0.252361    
2024-04-23 16:48:46,885 - Epoch: [45][  200/  267]    Overall Loss 2.357212    Objective Loss 2.357212                                        LR 0.100000    Time 0.254122    
2024-04-23 16:48:48,791 - Epoch: [45][  210/  267]    Overall Loss 2.359040    Objective Loss 2.359040                                        LR 0.100000    Time 0.251084    
2024-04-23 16:48:51,655 - Epoch: [45][  220/  267]    Overall Loss 2.359571    Objective Loss 2.359571                                        LR 0.100000    Time 0.252670    
2024-04-23 16:48:53,764 - Epoch: [45][  230/  267]    Overall Loss 2.358537    Objective Loss 2.358537                                        LR 0.100000    Time 0.250842    
2024-04-23 16:48:56,665 - Epoch: [45][  240/  267]    Overall Loss 2.358959    Objective Loss 2.358959                                        LR 0.100000    Time 0.252467    
2024-04-23 16:48:58,743 - Epoch: [45][  250/  267]    Overall Loss 2.358169    Objective Loss 2.358169                                        LR 0.100000    Time 0.250668    
2024-04-23 16:49:01,788 - Epoch: [45][  260/  267]    Overall Loss 2.357909    Objective Loss 2.357909                                        LR 0.100000    Time 0.252728    
2024-04-23 16:49:02,424 - Epoch: [35][  296/  296]    Overall Loss 1.053659    Objective Loss 1.053659    Top1 72.131148    Top5 91.803279    LR 0.000320    Time 0.238383    
2024-04-23 16:49:02,496 - Epoch: [45][  267/  267]    Overall Loss 2.357651    Objective Loss 2.357651    Top1 11.627907    Top5 53.488372    LR 0.100000    Time 0.248746    
2024-04-23 16:49:02,590 - --- validate (epoch=35)-----------
2024-04-23 16:49:02,591 - 3925 samples (32 per mini-batch)
2024-04-23 16:49:02,743 - --- validate (epoch=45)-----------
2024-04-23 16:49:02,743 - 946 samples (32 per mini-batch)
2024-04-23 16:49:05,396 - Epoch: [45][   10/   30]    Loss 2.346068    Top1 9.687500    Top5 49.375000    
2024-04-23 16:49:07,117 - Epoch: [45][   20/   30]    Loss 2.348412    Top1 10.000000    Top5 48.750000    
2024-04-23 16:49:09,453 - Epoch: [45][   30/   30]    Loss 2.342359    Top1 10.465116    Top5 49.154334    
2024-04-23 16:49:09,719 - ==> Top1: 10.465    Top5: 49.154    Loss: 2.342

2024-04-23 16:49:09,721 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 16:49:09,726 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:49:09,726 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:49:09,744 - 

2024-04-23 16:49:09,745 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:49:13,216 - Epoch: [46][   10/  267]    Overall Loss 2.312569    Objective Loss 2.312569                                        LR 0.100000    Time 0.346726    
2024-04-23 16:49:14,713 - Epoch: [46][   20/  267]    Overall Loss 2.344333    Objective Loss 2.344333                                        LR 0.100000    Time 0.248062    
2024-04-23 16:49:17,410 - Epoch: [46][   30/  267]    Overall Loss 2.345838    Objective Loss 2.345838                                        LR 0.100000    Time 0.255161    
2024-04-23 16:49:19,265 - Epoch: [46][   40/  267]    Overall Loss 2.340192    Objective Loss 2.340192                                        LR 0.100000    Time 0.237662    
2024-04-23 16:49:21,880 - Epoch: [46][   50/  267]    Overall Loss 2.348561    Objective Loss 2.348561                                        LR 0.100000    Time 0.242376    
2024-04-23 16:49:23,382 - Epoch: [46][   60/  267]    Overall Loss 2.352294    Objective Loss 2.352294                                        LR 0.100000    Time 0.226955    
2024-04-23 16:49:25,584 - Epoch: [46][   70/  267]    Overall Loss 2.348436    Objective Loss 2.348436                                        LR 0.100000    Time 0.225937    
2024-04-23 16:49:27,575 - Epoch: [46][   80/  267]    Overall Loss 2.346252    Objective Loss 2.346252                                        LR 0.100000    Time 0.222550    
2024-04-23 16:49:29,668 - Epoch: [35][  100/  123]    Loss 0.917625    Top1 69.000000    Top5 95.656250    
2024-04-23 16:49:30,232 - Epoch: [46][   90/  267]    Overall Loss 2.347909    Objective Loss 2.347909                                        LR 0.100000    Time 0.227305    
2024-04-23 16:49:32,436 - Epoch: [46][  100/  267]    Overall Loss 2.345061    Objective Loss 2.345061                                        LR 0.100000    Time 0.226589    
2024-04-23 16:49:34,549 - Epoch: [46][  110/  267]    Overall Loss 2.347160    Objective Loss 2.347160                                        LR 0.100000    Time 0.225164    
2024-04-23 16:49:34,894 - Epoch: [35][  123/  123]    Loss 0.916959    Top1 69.197452    Top5 95.617834    
2024-04-23 16:49:35,176 - ==> Top1: 69.197    Top5: 95.618    Loss: 0.917

2024-04-23 16:49:35,186 - ==> Best [Top1: 69.809   Top5: 95.745   Sparsity:0.00   Params: 376752 on epoch: 30]
2024-04-23 16:49:35,187 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:49:35,247 - 

2024-04-23 16:49:35,248 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:49:36,719 - Epoch: [46][  120/  267]    Overall Loss 2.348881    Objective Loss 2.348881                                        LR 0.100000    Time 0.224461    
2024-04-23 16:49:38,308 - Epoch: [46][  130/  267]    Overall Loss 2.350386    Objective Loss 2.350386                                        LR 0.100000    Time 0.219397    
2024-04-23 16:49:41,390 - Epoch: [46][  140/  267]    Overall Loss 2.351484    Objective Loss 2.351484                                        LR 0.100000    Time 0.225717    
2024-04-23 16:49:43,571 - Epoch: [46][  150/  267]    Overall Loss 2.351290    Objective Loss 2.351290                                        LR 0.100000    Time 0.225187    
2024-04-23 16:49:46,609 - Epoch: [46][  160/  267]    Overall Loss 2.352167    Objective Loss 2.352167                                        LR 0.100000    Time 0.230080    
2024-04-23 16:49:48,662 - Epoch: [46][  170/  267]    Overall Loss 2.352738    Objective Loss 2.352738                                        LR 0.100000    Time 0.228606    
2024-04-23 16:49:51,592 - Epoch: [46][  180/  267]    Overall Loss 2.353189    Objective Loss 2.353189                                        LR 0.100000    Time 0.232168    
2024-04-23 16:49:53,594 - Epoch: [46][  190/  267]    Overall Loss 2.353873    Objective Loss 2.353873                                        LR 0.100000    Time 0.230465    
2024-04-23 16:49:56,767 - Epoch: [46][  200/  267]    Overall Loss 2.354172    Objective Loss 2.354172                                        LR 0.100000    Time 0.234791    
2024-04-23 16:49:58,860 - Epoch: [46][  210/  267]    Overall Loss 2.352769    Objective Loss 2.352769                                        LR 0.100000    Time 0.233565    
2024-04-23 16:50:01,911 - Epoch: [36][  100/  296]    Overall Loss 1.048243    Objective Loss 1.048243                                        LR 0.000320    Time 0.266402    
2024-04-23 16:50:01,913 - Epoch: [46][  220/  267]    Overall Loss 2.352202    Objective Loss 2.352202                                        LR 0.100000    Time 0.236815    
2024-04-23 16:50:03,992 - Epoch: [46][  230/  267]    Overall Loss 2.353077    Objective Loss 2.353077                                        LR 0.100000    Time 0.235545    
2024-04-23 16:50:07,086 - Epoch: [46][  240/  267]    Overall Loss 2.354465    Objective Loss 2.354465                                        LR 0.100000    Time 0.238609    
2024-04-23 16:50:08,816 - Epoch: [46][  250/  267]    Overall Loss 2.355210    Objective Loss 2.355210                                        LR 0.100000    Time 0.235973    
2024-04-23 16:50:11,918 - Epoch: [46][  260/  267]    Overall Loss 2.355806    Objective Loss 2.355806                                        LR 0.100000    Time 0.238817    
2024-04-23 16:50:13,175 - Epoch: [46][  267/  267]    Overall Loss 2.355613    Objective Loss 2.355613    Top1 4.651163    Top5 51.162791    LR 0.100000    Time 0.237256    
2024-04-23 16:50:13,404 - --- validate (epoch=46)-----------
2024-04-23 16:50:13,406 - 946 samples (32 per mini-batch)
2024-04-23 16:50:17,076 - Epoch: [46][   10/   30]    Loss 2.381900    Top1 9.062500    Top5 50.312500    
2024-04-23 16:50:19,777 - Epoch: [46][   20/   30]    Loss 2.368570    Top1 9.687500    Top5 50.468750    
2024-04-23 16:50:21,933 - Epoch: [46][   30/   30]    Loss 2.374005    Top1 10.993658    Top5 50.422833    
2024-04-23 16:50:22,226 - ==> Top1: 10.994    Top5: 50.423    Loss: 2.374

2024-04-23 16:50:22,228 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 16:50:22,234 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:50:22,235 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:50:22,253 - 

2024-04-23 16:50:22,255 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:50:25,312 - Epoch: [36][  200/  296]    Overall Loss 1.058355    Objective Loss 1.058355                                        LR 0.000320    Time 0.250097    
2024-04-23 16:50:26,211 - Epoch: [47][   10/  267]    Overall Loss 2.341583    Objective Loss 2.341583                                        LR 0.100000    Time 0.395190    
2024-04-23 16:50:28,590 - Epoch: [47][   20/  267]    Overall Loss 2.341096    Objective Loss 2.341096                                        LR 0.100000    Time 0.316362    
2024-04-23 16:50:31,105 - Epoch: [47][   30/  267]    Overall Loss 2.337985    Objective Loss 2.337985                                        LR 0.100000    Time 0.294650    
2024-04-23 16:50:32,967 - Epoch: [47][   40/  267]    Overall Loss 2.337643    Objective Loss 2.337643                                        LR 0.100000    Time 0.267449    
2024-04-23 16:50:35,718 - Epoch: [47][   50/  267]    Overall Loss 2.346146    Objective Loss 2.346146                                        LR 0.100000    Time 0.268931    
2024-04-23 16:50:37,729 - Epoch: [47][   60/  267]    Overall Loss 2.349026    Objective Loss 2.349026                                        LR 0.100000    Time 0.257574    
2024-04-23 16:50:40,567 - Epoch: [47][   70/  267]    Overall Loss 2.353356    Objective Loss 2.353356                                        LR 0.100000    Time 0.261272    
2024-04-23 16:50:42,639 - Epoch: [47][   80/  267]    Overall Loss 2.353538    Objective Loss 2.353538                                        LR 0.100000    Time 0.254475    
2024-04-23 16:50:45,638 - Epoch: [47][   90/  267]    Overall Loss 2.356493    Objective Loss 2.356493                                        LR 0.100000    Time 0.259489    
2024-04-23 16:50:47,656 - Epoch: [47][  100/  267]    Overall Loss 2.356211    Objective Loss 2.356211                                        LR 0.100000    Time 0.253682    
2024-04-23 16:50:47,767 - Epoch: [36][  296/  296]    Overall Loss 1.053821    Objective Loss 1.053821    Top1 68.852459    Top5 98.360656    LR 0.000320    Time 0.244777    
2024-04-23 16:50:48,014 - --- validate (epoch=36)-----------
2024-04-23 16:50:48,015 - 3925 samples (32 per mini-batch)
2024-04-23 16:50:49,838 - Epoch: [47][  110/  267]    Overall Loss 2.354807    Objective Loss 2.354807                                        LR 0.100000    Time 0.250425    
2024-04-23 16:50:52,143 - Epoch: [47][  120/  267]    Overall Loss 2.356648    Objective Loss 2.356648                                        LR 0.100000    Time 0.248736    
2024-04-23 16:50:55,042 - Epoch: [47][  130/  267]    Overall Loss 2.356552    Objective Loss 2.356552                                        LR 0.100000    Time 0.251881    
2024-04-23 16:50:57,695 - Epoch: [47][  140/  267]    Overall Loss 2.356432    Objective Loss 2.356432                                        LR 0.100000    Time 0.252821    
2024-04-23 16:50:59,422 - Epoch: [47][  150/  267]    Overall Loss 2.356425    Objective Loss 2.356425                                        LR 0.100000    Time 0.247462    
2024-04-23 16:51:01,431 - Epoch: [47][  160/  267]    Overall Loss 2.354447    Objective Loss 2.354447                                        LR 0.100000    Time 0.244531    
2024-04-23 16:51:03,519 - Epoch: [47][  170/  267]    Overall Loss 2.353517    Objective Loss 2.353517                                        LR 0.100000    Time 0.242413    
2024-04-23 16:51:06,777 - Epoch: [47][  180/  267]    Overall Loss 2.353798    Objective Loss 2.353798                                        LR 0.100000    Time 0.247029    
2024-04-23 16:51:08,597 - Epoch: [47][  190/  267]    Overall Loss 2.354828    Objective Loss 2.354828                                        LR 0.100000    Time 0.243585    
2024-04-23 16:51:11,524 - Epoch: [47][  200/  267]    Overall Loss 2.355098    Objective Loss 2.355098                                        LR 0.100000    Time 0.246025    
2024-04-23 16:51:13,362 - Epoch: [47][  210/  267]    Overall Loss 2.354276    Objective Loss 2.354276                                        LR 0.100000    Time 0.243050    
2024-04-23 16:51:15,278 - Epoch: [47][  220/  267]    Overall Loss 2.354527    Objective Loss 2.354527                                        LR 0.100000    Time 0.240696    
2024-04-23 16:51:16,184 - Epoch: [36][  100/  123]    Loss 0.911701    Top1 69.906250    Top5 95.281250    
2024-04-23 16:51:17,343 - Epoch: [47][  230/  267]    Overall Loss 2.355373    Objective Loss 2.355373                                        LR 0.100000    Time 0.239193    
2024-04-23 16:51:20,213 - Epoch: [47][  240/  267]    Overall Loss 2.353950    Objective Loss 2.353950                                        LR 0.100000    Time 0.241171    
2024-04-23 16:51:22,242 - Epoch: [47][  250/  267]    Overall Loss 2.353832    Objective Loss 2.353832                                        LR 0.100000    Time 0.239630    
2024-04-23 16:51:22,278 - Epoch: [36][  123/  123]    Loss 0.908047    Top1 69.885350    Top5 95.592357    
2024-04-23 16:51:22,586 - ==> Top1: 69.885    Top5: 95.592    Loss: 0.908

2024-04-23 16:51:22,596 - ==> Best [Top1: 69.885   Top5: 95.592   Sparsity:0.00   Params: 376752 on epoch: 36]
2024-04-23 16:51:22,597 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:51:22,668 - 

2024-04-23 16:51:22,669 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:51:24,532 - Epoch: [47][  260/  267]    Overall Loss 2.354681    Objective Loss 2.354681                                        LR 0.100000    Time 0.239210    
2024-04-23 16:51:25,951 - Epoch: [47][  267/  267]    Overall Loss 2.355169    Objective Loss 2.355169    Top1 13.953488    Top5 58.139535    LR 0.100000    Time 0.238246    
2024-04-23 16:51:26,160 - --- validate (epoch=47)-----------
2024-04-23 16:51:26,162 - 946 samples (32 per mini-batch)
2024-04-23 16:51:30,299 - Epoch: [47][   10/   30]    Loss 2.342948    Top1 10.937500    Top5 50.625000    
2024-04-23 16:51:32,457 - Epoch: [47][   20/   30]    Loss 2.331217    Top1 12.031250    Top5 51.718750    
2024-04-23 16:51:35,482 - Epoch: [47][   30/   30]    Loss 2.346163    Top1 10.993658    Top5 48.837209    
2024-04-23 16:51:35,678 - ==> Top1: 10.994    Top5: 48.837    Loss: 2.346

2024-04-23 16:51:35,681 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 16:51:35,686 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:51:35,687 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:51:35,705 - 

2024-04-23 16:51:35,706 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:51:39,380 - Epoch: [48][   10/  267]    Overall Loss 2.366170    Objective Loss 2.366170                                        LR 0.100000    Time 0.366926    
2024-04-23 16:51:42,622 - Epoch: [48][   20/  267]    Overall Loss 2.359522    Objective Loss 2.359522                                        LR 0.100000    Time 0.345313    
2024-04-23 16:51:45,904 - Epoch: [48][   30/  267]    Overall Loss 2.356500    Objective Loss 2.356500                                        LR 0.100000    Time 0.339479    
2024-04-23 16:51:48,191 - Epoch: [48][   40/  267]    Overall Loss 2.349888    Objective Loss 2.349888                                        LR 0.100000    Time 0.311733    
2024-04-23 16:51:51,243 - Epoch: [37][  100/  296]    Overall Loss 1.018849    Objective Loss 1.018849                                        LR 0.000320    Time 0.285518    
2024-04-23 16:51:51,350 - Epoch: [48][   50/  267]    Overall Loss 2.353409    Objective Loss 2.353409                                        LR 0.100000    Time 0.312502    
2024-04-23 16:51:53,542 - Epoch: [48][   60/  267]    Overall Loss 2.354279    Objective Loss 2.354279                                        LR 0.100000    Time 0.296910    
2024-04-23 16:51:56,715 - Epoch: [48][   70/  267]    Overall Loss 2.356776    Objective Loss 2.356776                                        LR 0.100000    Time 0.299782    
2024-04-23 16:51:58,564 - Epoch: [48][   80/  267]    Overall Loss 2.350603    Objective Loss 2.350603                                        LR 0.100000    Time 0.285395    
2024-04-23 16:52:01,099 - Epoch: [48][   90/  267]    Overall Loss 2.351339    Objective Loss 2.351339                                        LR 0.100000    Time 0.281818    
2024-04-23 16:52:03,303 - Epoch: [48][  100/  267]    Overall Loss 2.353665    Objective Loss 2.353665                                        LR 0.100000    Time 0.275638    
2024-04-23 16:52:06,325 - Epoch: [48][  110/  267]    Overall Loss 2.352043    Objective Loss 2.352043                                        LR 0.100000    Time 0.278025    
2024-04-23 16:52:08,699 - Epoch: [48][  120/  267]    Overall Loss 2.354015    Objective Loss 2.354015                                        LR 0.100000    Time 0.274624    
2024-04-23 16:52:11,594 - Epoch: [48][  130/  267]    Overall Loss 2.356373    Objective Loss 2.356373                                        LR 0.100000    Time 0.275737    
2024-04-23 16:52:13,605 - Epoch: [48][  140/  267]    Overall Loss 2.356582    Objective Loss 2.356582                                        LR 0.100000    Time 0.270384    
2024-04-23 16:52:16,501 - Epoch: [48][  150/  267]    Overall Loss 2.353989    Objective Loss 2.353989                                        LR 0.100000    Time 0.271651    
2024-04-23 16:52:16,873 - Epoch: [37][  200/  296]    Overall Loss 1.052604    Objective Loss 1.052604                                        LR 0.000320    Time 0.270800    
2024-04-23 16:52:18,976 - Epoch: [48][  160/  267]    Overall Loss 2.353986    Objective Loss 2.353986                                        LR 0.100000    Time 0.270127    
2024-04-23 16:52:22,954 - Epoch: [48][  170/  267]    Overall Loss 2.354419    Objective Loss 2.354419                                        LR 0.100000    Time 0.277618    
2024-04-23 16:52:25,076 - Epoch: [48][  180/  267]    Overall Loss 2.352866    Objective Loss 2.352866                                        LR 0.100000    Time 0.273968    
2024-04-23 16:52:27,710 - Epoch: [48][  190/  267]    Overall Loss 2.351557    Objective Loss 2.351557                                        LR 0.100000    Time 0.273395    
2024-04-23 16:52:29,287 - Epoch: [48][  200/  267]    Overall Loss 2.351711    Objective Loss 2.351711                                        LR 0.100000    Time 0.267594    
2024-04-23 16:52:32,311 - Epoch: [48][  210/  267]    Overall Loss 2.351998    Objective Loss 2.351998                                        LR 0.100000    Time 0.269237    
2024-04-23 16:52:34,511 - Epoch: [48][  220/  267]    Overall Loss 2.351025    Objective Loss 2.351025                                        LR 0.100000    Time 0.266989    
2024-04-23 16:52:37,712 - Epoch: [48][  230/  267]    Overall Loss 2.350777    Objective Loss 2.350777                                        LR 0.100000    Time 0.269283    
2024-04-23 16:52:40,099 - Epoch: [48][  240/  267]    Overall Loss 2.350898    Objective Loss 2.350898                                        LR 0.100000    Time 0.267996    
2024-04-23 16:52:42,782 - Epoch: [48][  250/  267]    Overall Loss 2.349933    Objective Loss 2.349933                                        LR 0.100000    Time 0.267995    
2024-04-23 16:52:42,814 - Epoch: [37][  296/  296]    Overall Loss 1.061737    Objective Loss 1.061737    Top1 80.327869    Top5 98.360656    LR 0.000320    Time 0.270538    
2024-04-23 16:52:43,071 - --- validate (epoch=37)-----------
2024-04-23 16:52:43,073 - 3925 samples (32 per mini-batch)
2024-04-23 16:52:44,814 - Epoch: [48][  260/  267]    Overall Loss 2.349604    Objective Loss 2.349604                                        LR 0.100000    Time 0.265494    
2024-04-23 16:52:46,384 - Epoch: [48][  267/  267]    Overall Loss 2.349876    Objective Loss 2.349876    Top1 13.953488    Top5 55.813953    LR 0.100000    Time 0.264403    
2024-04-23 16:52:46,641 - --- validate (epoch=48)-----------
2024-04-23 16:52:46,643 - 946 samples (32 per mini-batch)
2024-04-23 16:52:51,603 - Epoch: [48][   10/   30]    Loss 2.326004    Top1 12.187500    Top5 53.125000    
2024-04-23 16:52:53,446 - Epoch: [48][   20/   30]    Loss 2.339663    Top1 10.781250    Top5 51.406250    
2024-04-23 16:52:56,178 - Epoch: [48][   30/   30]    Loss 2.357860    Top1 10.042283    Top5 50.000000    
2024-04-23 16:52:56,436 - ==> Top1: 10.042    Top5: 50.000    Loss: 2.358

2024-04-23 16:52:56,439 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 16:52:56,442 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:52:56,442 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:52:56,464 - 

2024-04-23 16:52:56,465 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:53:00,749 - Epoch: [49][   10/  267]    Overall Loss 2.361728    Objective Loss 2.361728                                        LR 0.100000    Time 0.427866    
2024-04-23 16:53:03,403 - Epoch: [49][   20/  267]    Overall Loss 2.348725    Objective Loss 2.348725                                        LR 0.100000    Time 0.346465    
2024-04-23 16:53:06,729 - Epoch: [37][  100/  123]    Loss 0.945967    Top1 69.593750    Top5 95.312500    
2024-04-23 16:53:07,089 - Epoch: [49][   30/  267]    Overall Loss 2.352441    Objective Loss 2.352441                                        LR 0.100000    Time 0.353732    
2024-04-23 16:53:09,387 - Epoch: [49][   40/  267]    Overall Loss 2.365113    Objective Loss 2.365113                                        LR 0.100000    Time 0.322671    
2024-04-23 16:53:10,756 - Epoch: [37][  123/  123]    Loss 0.950651    Top1 69.070064    Top5 95.235669    
2024-04-23 16:53:10,878 - ==> Top1: 69.070    Top5: 95.236    Loss: 0.951

2024-04-23 16:53:10,882 - ==> Best [Top1: 69.885   Top5: 95.592   Sparsity:0.00   Params: 376752 on epoch: 36]
2024-04-23 16:53:10,883 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:53:10,917 - 

2024-04-23 16:53:10,918 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:53:13,109 - Epoch: [49][   50/  267]    Overall Loss 2.359855    Objective Loss 2.359855                                        LR 0.100000    Time 0.332501    
2024-04-23 16:53:15,838 - Epoch: [49][   60/  267]    Overall Loss 2.357111    Objective Loss 2.357111                                        LR 0.100000    Time 0.322516    
2024-04-23 16:53:19,116 - Epoch: [49][   70/  267]    Overall Loss 2.361129    Objective Loss 2.361129                                        LR 0.100000    Time 0.323214    
2024-04-23 16:53:21,752 - Epoch: [49][   80/  267]    Overall Loss 2.361887    Objective Loss 2.361887                                        LR 0.100000    Time 0.315729    
2024-04-23 16:53:24,960 - Epoch: [49][   90/  267]    Overall Loss 2.363667    Objective Loss 2.363667                                        LR 0.100000    Time 0.316252    
2024-04-23 16:53:27,033 - Epoch: [49][  100/  267]    Overall Loss 2.360989    Objective Loss 2.360989                                        LR 0.100000    Time 0.305331    
2024-04-23 16:53:29,390 - Epoch: [38][  100/  296]    Overall Loss 1.024192    Objective Loss 1.024192                                        LR 0.000320    Time 0.184512    
2024-04-23 16:53:30,294 - Epoch: [49][  110/  267]    Overall Loss 2.361608    Objective Loss 2.361608                                        LR 0.100000    Time 0.307183    
2024-04-23 16:53:32,792 - Epoch: [49][  120/  267]    Overall Loss 2.362644    Objective Loss 2.362644                                        LR 0.100000    Time 0.302372    
2024-04-23 16:53:35,464 - Epoch: [49][  130/  267]    Overall Loss 2.361742    Objective Loss 2.361742                                        LR 0.100000    Time 0.299644    
2024-04-23 16:53:37,756 - Epoch: [49][  140/  267]    Overall Loss 2.358158    Objective Loss 2.358158                                        LR 0.100000    Time 0.294592    
2024-04-23 16:53:40,532 - Epoch: [49][  150/  267]    Overall Loss 2.357346    Objective Loss 2.357346                                        LR 0.100000    Time 0.293444    
2024-04-23 16:53:42,707 - Epoch: [49][  160/  267]    Overall Loss 2.358113    Objective Loss 2.358113                                        LR 0.100000    Time 0.288678    
2024-04-23 16:53:45,411 - Epoch: [49][  170/  267]    Overall Loss 2.357520    Objective Loss 2.357520                                        LR 0.100000    Time 0.287579    
2024-04-23 16:53:47,485 - Epoch: [49][  180/  267]    Overall Loss 2.357889    Objective Loss 2.357889                                        LR 0.100000    Time 0.283110    
2024-04-23 16:53:50,772 - Epoch: [49][  190/  267]    Overall Loss 2.357624    Objective Loss 2.357624                                        LR 0.100000    Time 0.285494    
2024-04-23 16:53:50,986 - Epoch: [38][  200/  296]    Overall Loss 1.047921    Objective Loss 1.047921                                        LR 0.000320    Time 0.200124    
2024-04-23 16:53:52,903 - Epoch: [49][  200/  267]    Overall Loss 2.358541    Objective Loss 2.358541                                        LR 0.100000    Time 0.281856    
2024-04-23 16:53:56,006 - Epoch: [49][  210/  267]    Overall Loss 2.356964    Objective Loss 2.356964                                        LR 0.100000    Time 0.283198    
2024-04-23 16:53:58,461 - Epoch: [49][  220/  267]    Overall Loss 2.358650    Objective Loss 2.358650                                        LR 0.100000    Time 0.281473    
2024-04-23 16:54:01,287 - Epoch: [49][  230/  267]    Overall Loss 2.357699    Objective Loss 2.357699                                        LR 0.100000    Time 0.281509    
2024-04-23 16:54:03,320 - Epoch: [49][  240/  267]    Overall Loss 2.356829    Objective Loss 2.356829                                        LR 0.100000    Time 0.278239    
2024-04-23 16:54:06,685 - Epoch: [49][  250/  267]    Overall Loss 2.356647    Objective Loss 2.356647                                        LR 0.100000    Time 0.280557    
2024-04-23 16:54:08,903 - Epoch: [49][  260/  267]    Overall Loss 2.356007    Objective Loss 2.356007                                        LR 0.100000    Time 0.278287    
2024-04-23 16:54:10,489 - Epoch: [49][  267/  267]    Overall Loss 2.356461    Objective Loss 2.356461    Top1 4.651163    Top5 46.511628    LR 0.100000    Time 0.276926    
2024-04-23 16:54:10,740 - --- validate (epoch=49)-----------
2024-04-23 16:54:10,742 - 946 samples (32 per mini-batch)
2024-04-23 16:54:11,484 - Epoch: [38][  296/  296]    Overall Loss 1.053884    Objective Loss 1.053884    Top1 57.377049    Top5 90.163934    LR 0.000320    Time 0.204400    
2024-04-23 16:54:11,630 - --- validate (epoch=38)-----------
2024-04-23 16:54:11,631 - 3925 samples (32 per mini-batch)
2024-04-23 16:54:15,707 - Epoch: [49][   10/   30]    Loss 2.340092    Top1 10.937500    Top5 51.562500    
2024-04-23 16:54:18,228 - Epoch: [49][   20/   30]    Loss 2.340630    Top1 10.937500    Top5 51.093750    
2024-04-23 16:54:21,804 - Epoch: [49][   30/   30]    Loss 2.341571    Top1 10.993658    Top5 50.211416    
2024-04-23 16:54:22,043 - ==> Top1: 10.994    Top5: 50.211    Loss: 2.342

2024-04-23 16:54:22,046 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 16:54:22,051 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:54:22,052 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:54:22,071 - 

2024-04-23 16:54:22,072 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:54:26,916 - Epoch: [50][   10/  267]    Overall Loss 2.398135    Objective Loss 2.398135                                        LR 0.100000    Time 0.483966    
2024-04-23 16:54:29,842 - Epoch: [50][   20/  267]    Overall Loss 2.392356    Objective Loss 2.392356                                        LR 0.100000    Time 0.388148    
2024-04-23 16:54:32,235 - Epoch: [50][   30/  267]    Overall Loss 2.382873    Objective Loss 2.382873                                        LR 0.100000    Time 0.338141    
2024-04-23 16:54:32,322 - Epoch: [38][  100/  123]    Loss 0.872208    Top1 71.062500    Top5 95.687500    
2024-04-23 16:54:35,813 - Epoch: [50][   40/  267]    Overall Loss 2.375821    Objective Loss 2.375821                                        LR 0.100000    Time 0.342989    
2024-04-23 16:54:36,903 - Epoch: [38][  123/  123]    Loss 0.879007    Top1 70.904459    Top5 95.694268    
2024-04-23 16:54:37,063 - ==> Top1: 70.904    Top5: 95.694    Loss: 0.879

2024-04-23 16:54:37,071 - ==> Best [Top1: 70.904   Top5: 95.694   Sparsity:0.00   Params: 376752 on epoch: 38]
2024-04-23 16:54:37,072 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:54:37,146 - 

2024-04-23 16:54:37,148 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:54:38,275 - Epoch: [50][   50/  267]    Overall Loss 2.368591    Objective Loss 2.368591                                        LR 0.100000    Time 0.323559    
2024-04-23 16:54:41,739 - Epoch: [50][   60/  267]    Overall Loss 2.367370    Objective Loss 2.367370                                        LR 0.100000    Time 0.327308    
2024-04-23 16:54:44,099 - Epoch: [50][   70/  267]    Overall Loss 2.369535    Objective Loss 2.369535                                        LR 0.100000    Time 0.314226    
2024-04-23 16:54:47,549 - Epoch: [50][   80/  267]    Overall Loss 2.367178    Objective Loss 2.367178                                        LR 0.100000    Time 0.318032    
2024-04-23 16:54:49,575 - Epoch: [50][   90/  267]    Overall Loss 2.363584    Objective Loss 2.363584                                        LR 0.100000    Time 0.305182    
2024-04-23 16:54:53,664 - Epoch: [50][  100/  267]    Overall Loss 2.361333    Objective Loss 2.361333                                        LR 0.100000    Time 0.315518    
2024-04-23 16:54:55,746 - Epoch: [39][  100/  296]    Overall Loss 1.039133    Objective Loss 1.039133                                        LR 0.000320    Time 0.185753    
2024-04-23 16:54:55,863 - Epoch: [50][  110/  267]    Overall Loss 2.366560    Objective Loss 2.366560                                        LR 0.100000    Time 0.306802    
2024-04-23 16:54:58,826 - Epoch: [50][  120/  267]    Overall Loss 2.366762    Objective Loss 2.366762                                        LR 0.100000    Time 0.305898    
2024-04-23 16:55:00,998 - Epoch: [50][  130/  267]    Overall Loss 2.366297    Objective Loss 2.366297                                        LR 0.100000    Time 0.299047    
2024-04-23 16:55:03,638 - Epoch: [50][  140/  267]    Overall Loss 2.366592    Objective Loss 2.366592                                        LR 0.100000    Time 0.296519    
2024-04-23 16:55:06,115 - Epoch: [50][  150/  267]    Overall Loss 2.365621    Objective Loss 2.365621                                        LR 0.100000    Time 0.293245    
2024-04-23 16:55:09,065 - Epoch: [50][  160/  267]    Overall Loss 2.364030    Objective Loss 2.364030                                        LR 0.100000    Time 0.293331    
2024-04-23 16:55:11,618 - Epoch: [50][  170/  267]    Overall Loss 2.361506    Objective Loss 2.361506                                        LR 0.100000    Time 0.291076    
2024-04-23 16:55:13,963 - Epoch: [39][  200/  296]    Overall Loss 1.020390    Objective Loss 1.020390                                        LR 0.000320    Time 0.183857    
2024-04-23 16:55:14,994 - Epoch: [50][  180/  267]    Overall Loss 2.361925    Objective Loss 2.361925                                        LR 0.100000    Time 0.293649    
2024-04-23 16:55:17,379 - Epoch: [50][  190/  267]    Overall Loss 2.359195    Objective Loss 2.359195                                        LR 0.100000    Time 0.290730    
2024-04-23 16:55:21,195 - Epoch: [50][  200/  267]    Overall Loss 2.360915    Objective Loss 2.360915                                        LR 0.100000    Time 0.295259    
2024-04-23 16:55:23,493 - Epoch: [50][  210/  267]    Overall Loss 2.360584    Objective Loss 2.360584                                        LR 0.100000    Time 0.292131    
2024-04-23 16:55:26,252 - Epoch: [50][  220/  267]    Overall Loss 2.361464    Objective Loss 2.361464                                        LR 0.100000    Time 0.291376    
2024-04-23 16:55:28,037 - Epoch: [50][  230/  267]    Overall Loss 2.361949    Objective Loss 2.361949                                        LR 0.100000    Time 0.286455    
2024-04-23 16:55:31,244 - Epoch: [50][  240/  267]    Overall Loss 2.361835    Objective Loss 2.361835                                        LR 0.100000    Time 0.287869    
2024-04-23 16:55:32,999 - Epoch: [50][  250/  267]    Overall Loss 2.361074    Objective Loss 2.361074                                        LR 0.100000    Time 0.283360    
2024-04-23 16:55:33,414 - Epoch: [39][  296/  296]    Overall Loss 1.019745    Objective Loss 1.019745    Top1 67.213115    Top5 98.360656    LR 0.000320    Time 0.189870    
2024-04-23 16:55:33,649 - --- validate (epoch=39)-----------
2024-04-23 16:55:33,651 - 3925 samples (32 per mini-batch)
2024-04-23 16:55:36,032 - Epoch: [50][  260/  267]    Overall Loss 2.362015    Objective Loss 2.362015                                        LR 0.100000    Time 0.284119    
2024-04-23 16:55:37,265 - Epoch: [50][  267/  267]    Overall Loss 2.361510    Objective Loss 2.361510    Top1 4.651163    Top5 39.534884    LR 0.100000    Time 0.281276    
2024-04-23 16:55:37,547 - --- validate (epoch=50)-----------
2024-04-23 16:55:37,549 - 946 samples (32 per mini-batch)
2024-04-23 16:55:42,197 - Epoch: [50][   10/   30]    Loss 2.343438    Top1 12.187500    Top5 54.375000    
2024-04-23 16:55:44,656 - Epoch: [50][   20/   30]    Loss 2.371490    Top1 9.531250    Top5 50.156250    
2024-04-23 16:55:47,797 - Epoch: [50][   30/   30]    Loss 2.375847    Top1 8.456660    Top5 49.365751    
2024-04-23 16:55:48,029 - ==> Top1: 8.457    Top5: 49.366    Loss: 2.376

2024-04-23 16:55:48,032 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 16:55:48,038 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:55:48,039 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:55:48,062 - 

2024-04-23 16:55:48,063 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:55:52,534 - Epoch: [39][  100/  123]    Loss 1.077228    Top1 64.875000    Top5 94.531250    
2024-04-23 16:55:52,973 - Epoch: [51][   10/  267]    Overall Loss 2.383913    Objective Loss 2.383913                                        LR 0.100000    Time 0.490649    
2024-04-23 16:55:55,138 - Epoch: [51][   20/  267]    Overall Loss 2.369859    Objective Loss 2.369859                                        LR 0.100000    Time 0.353363    
2024-04-23 16:55:55,867 - Epoch: [39][  123/  123]    Loss 1.066317    Top1 65.324841    Top5 94.649682    
2024-04-23 16:55:56,008 - ==> Top1: 65.325    Top5: 94.650    Loss: 1.066

2024-04-23 16:55:56,013 - ==> Best [Top1: 70.904   Top5: 95.694   Sparsity:0.00   Params: 376752 on epoch: 38]
2024-04-23 16:55:56,014 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:55:56,066 - 

2024-04-23 16:55:56,067 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:55:59,012 - Epoch: [51][   30/  267]    Overall Loss 2.375819    Objective Loss 2.375819                                        LR 0.100000    Time 0.364615    
2024-04-23 16:56:01,462 - Epoch: [51][   40/  267]    Overall Loss 2.375618    Objective Loss 2.375618                                        LR 0.100000    Time 0.334601    
2024-04-23 16:56:04,282 - Epoch: [51][   50/  267]    Overall Loss 2.368584    Objective Loss 2.368584                                        LR 0.100000    Time 0.324015    
2024-04-23 16:56:06,766 - Epoch: [51][   60/  267]    Overall Loss 2.368266    Objective Loss 2.368266                                        LR 0.100000    Time 0.311365    
2024-04-23 16:56:10,610 - Epoch: [51][   70/  267]    Overall Loss 2.372298    Objective Loss 2.372298                                        LR 0.100000    Time 0.321753    
2024-04-23 16:56:12,728 - Epoch: [51][   80/  267]    Overall Loss 2.369064    Objective Loss 2.369064                                        LR 0.100000    Time 0.307968    
2024-04-23 16:56:15,404 - Epoch: [51][   90/  267]    Overall Loss 2.369238    Objective Loss 2.369238                                        LR 0.100000    Time 0.303438    
2024-04-23 16:56:16,958 - Epoch: [40][  100/  296]    Overall Loss 1.043188    Objective Loss 1.043188                                        LR 0.000320    Time 0.208689    
2024-04-23 16:56:17,576 - Epoch: [51][  100/  267]    Overall Loss 2.369731    Objective Loss 2.369731                                        LR 0.100000    Time 0.294790    
2024-04-23 16:56:20,492 - Epoch: [51][  110/  267]    Overall Loss 2.368414    Objective Loss 2.368414                                        LR 0.100000    Time 0.294473    
2024-04-23 16:56:22,992 - Epoch: [51][  120/  267]    Overall Loss 2.369713    Objective Loss 2.369713                                        LR 0.100000    Time 0.290738    
2024-04-23 16:56:26,101 - Epoch: [51][  130/  267]    Overall Loss 2.367072    Objective Loss 2.367072                                        LR 0.100000    Time 0.292261    
2024-04-23 16:56:28,537 - Epoch: [51][  140/  267]    Overall Loss 2.366701    Objective Loss 2.366701                                        LR 0.100000    Time 0.288763    
2024-04-23 16:56:31,710 - Epoch: [51][  150/  267]    Overall Loss 2.366225    Objective Loss 2.366225                                        LR 0.100000    Time 0.290645    
2024-04-23 16:56:33,962 - Epoch: [51][  160/  267]    Overall Loss 2.366253    Objective Loss 2.366253                                        LR 0.100000    Time 0.286536    
2024-04-23 16:56:36,266 - Epoch: [51][  170/  267]    Overall Loss 2.366334    Objective Loss 2.366334                                        LR 0.100000    Time 0.283218    
2024-04-23 16:56:38,286 - Epoch: [51][  180/  267]    Overall Loss 2.366116    Objective Loss 2.366116                                        LR 0.100000    Time 0.278691    
2024-04-23 16:56:38,643 - Epoch: [40][  200/  296]    Overall Loss 1.041153    Objective Loss 1.041153                                        LR 0.000320    Time 0.212658    
2024-04-23 16:56:41,985 - Epoch: [51][  190/  267]    Overall Loss 2.365726    Objective Loss 2.365726                                        LR 0.100000    Time 0.283474    
2024-04-23 16:56:43,445 - Epoch: [51][  200/  267]    Overall Loss 2.364896    Objective Loss 2.364896                                        LR 0.100000    Time 0.276590    
2024-04-23 16:56:46,227 - Epoch: [51][  210/  267]    Overall Loss 2.364805    Objective Loss 2.364805                                        LR 0.100000    Time 0.276654    
2024-04-23 16:56:48,471 - Epoch: [51][  220/  267]    Overall Loss 2.364089    Objective Loss 2.364089                                        LR 0.100000    Time 0.274265    
2024-04-23 16:56:51,199 - Epoch: [51][  230/  267]    Overall Loss 2.363728    Objective Loss 2.363728                                        LR 0.100000    Time 0.274188    
2024-04-23 16:56:53,142 - Epoch: [51][  240/  267]    Overall Loss 2.361767    Objective Loss 2.361767                                        LR 0.100000    Time 0.270848    
2024-04-23 16:56:55,661 - Epoch: [51][  250/  267]    Overall Loss 2.361886    Objective Loss 2.361886                                        LR 0.100000    Time 0.270079    
2024-04-23 16:56:57,379 - Epoch: [51][  260/  267]    Overall Loss 2.361522    Objective Loss 2.361522                                        LR 0.100000    Time 0.266289    
2024-04-23 16:56:59,080 - Epoch: [51][  267/  267]    Overall Loss 2.360344    Objective Loss 2.360344    Top1 16.279070    Top5 55.813953    LR 0.100000    Time 0.265666    
2024-04-23 16:56:59,349 - --- validate (epoch=51)-----------
2024-04-23 16:56:59,350 - 946 samples (32 per mini-batch)
2024-04-23 16:57:00,496 - Epoch: [40][  296/  296]    Overall Loss 1.031466    Objective Loss 1.031466    Top1 60.655738    Top5 95.081967    LR 0.000320    Time 0.217446    
2024-04-23 16:57:00,974 - --- validate (epoch=40)-----------
2024-04-23 16:57:00,975 - 3925 samples (32 per mini-batch)
2024-04-23 16:57:03,683 - Epoch: [51][   10/   30]    Loss 2.347621    Top1 9.062500    Top5 47.500000    
2024-04-23 16:57:06,146 - Epoch: [51][   20/   30]    Loss 2.332692    Top1 10.312500    Top5 48.437500    
2024-04-23 16:57:09,101 - Epoch: [51][   30/   30]    Loss 2.336911    Top1 9.830867    Top5 47.780127    
2024-04-23 16:57:09,351 - ==> Top1: 9.831    Top5: 47.780    Loss: 2.337

2024-04-23 16:57:09,353 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 16:57:09,360 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:57:09,360 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:57:09,381 - 

2024-04-23 16:57:09,383 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:57:14,776 - Epoch: [52][   10/  267]    Overall Loss 2.355312    Objective Loss 2.355312                                        LR 0.100000    Time 0.538848    
2024-04-23 16:57:17,538 - Epoch: [52][   20/  267]    Overall Loss 2.368755    Objective Loss 2.368755                                        LR 0.100000    Time 0.407355    
2024-04-23 16:57:21,297 - Epoch: [52][   30/  267]    Overall Loss 2.356275    Objective Loss 2.356275                                        LR 0.100000    Time 0.396764    
2024-04-23 16:57:22,356 - Epoch: [40][  100/  123]    Loss 0.853322    Top1 72.437500    Top5 95.937500    
2024-04-23 16:57:25,084 - Epoch: [52][   40/  267]    Overall Loss 2.351473    Objective Loss 2.351473                                        LR 0.100000    Time 0.392162    
2024-04-23 16:57:27,151 - Epoch: [40][  123/  123]    Loss 0.842836    Top1 72.611465    Top5 95.898089    
2024-04-23 16:57:27,389 - ==> Top1: 72.611    Top5: 95.898    Loss: 0.843

2024-04-23 16:57:27,397 - ==> Best [Top1: 72.611   Top5: 95.898   Sparsity:0.00   Params: 376752 on epoch: 40]
2024-04-23 16:57:27,398 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:57:27,452 - 

2024-04-23 16:57:27,452 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:57:27,501 - Epoch: [52][   50/  267]    Overall Loss 2.364129    Objective Loss 2.364129                                        LR 0.100000    Time 0.362003    
2024-04-23 16:57:30,705 - Epoch: [52][   60/  267]    Overall Loss 2.363322    Objective Loss 2.363322                                        LR 0.100000    Time 0.355010    
2024-04-23 16:57:32,727 - Epoch: [52][   70/  267]    Overall Loss 2.363342    Objective Loss 2.363342                                        LR 0.100000    Time 0.333142    
2024-04-23 16:57:35,775 - Epoch: [52][   80/  267]    Overall Loss 2.362426    Objective Loss 2.362426                                        LR 0.100000    Time 0.329555    
2024-04-23 16:57:37,885 - Epoch: [52][   90/  267]    Overall Loss 2.360447    Objective Loss 2.360447                                        LR 0.100000    Time 0.316355    
2024-04-23 16:57:40,677 - Epoch: [52][  100/  267]    Overall Loss 2.358362    Objective Loss 2.358362                                        LR 0.100000    Time 0.312611    
2024-04-23 16:57:42,542 - Epoch: [52][  110/  267]    Overall Loss 2.357400    Objective Loss 2.357400                                        LR 0.100000    Time 0.301116    
2024-04-23 16:57:45,611 - Epoch: [52][  120/  267]    Overall Loss 2.357166    Objective Loss 2.357166                                        LR 0.100000    Time 0.301573    
2024-04-23 16:57:47,813 - Epoch: [52][  130/  267]    Overall Loss 2.356746    Objective Loss 2.356746                                        LR 0.100000    Time 0.295289    
2024-04-23 16:57:50,195 - Epoch: [52][  140/  267]    Overall Loss 2.357470    Objective Loss 2.357470                                        LR 0.100000    Time 0.291189    
2024-04-23 16:57:50,535 - Epoch: [41][  100/  296]    Overall Loss 1.024272    Objective Loss 1.024272                                        LR 0.000320    Time 0.230601    
2024-04-23 16:57:52,409 - Epoch: [52][  150/  267]    Overall Loss 2.356334    Objective Loss 2.356334                                        LR 0.100000    Time 0.286515    
2024-04-23 16:57:55,180 - Epoch: [52][  160/  267]    Overall Loss 2.355592    Objective Loss 2.355592                                        LR 0.100000    Time 0.285906    
2024-04-23 16:57:57,020 - Epoch: [52][  170/  267]    Overall Loss 2.356673    Objective Loss 2.356673                                        LR 0.100000    Time 0.279896    
2024-04-23 16:57:58,262 - Epoch: [52][  180/  267]    Overall Loss 2.354394    Objective Loss 2.354394                                        LR 0.100000    Time 0.271233    
2024-04-23 16:58:00,195 - Epoch: [52][  190/  267]    Overall Loss 2.352908    Objective Loss 2.352908                                        LR 0.100000    Time 0.267113    
2024-04-23 16:58:02,731 - Epoch: [52][  200/  267]    Overall Loss 2.351849    Objective Loss 2.351849                                        LR 0.100000    Time 0.266420    
2024-04-23 16:58:05,161 - Epoch: [52][  210/  267]    Overall Loss 2.351902    Objective Loss 2.351902                                        LR 0.100000    Time 0.265292    
2024-04-23 16:58:07,274 - Epoch: [52][  220/  267]    Overall Loss 2.351889    Objective Loss 2.351889                                        LR 0.100000    Time 0.262821    
2024-04-23 16:58:10,181 - Epoch: [52][  230/  267]    Overall Loss 2.351761    Objective Loss 2.351761                                        LR 0.100000    Time 0.264021    
2024-04-23 16:58:11,656 - Epoch: [41][  200/  296]    Overall Loss 1.026710    Objective Loss 1.026710                                        LR 0.000320    Time 0.220797    
2024-04-23 16:58:12,269 - Epoch: [52][  240/  267]    Overall Loss 2.353528    Objective Loss 2.353528                                        LR 0.100000    Time 0.261710    
2024-04-23 16:58:15,372 - Epoch: [52][  250/  267]    Overall Loss 2.352920    Objective Loss 2.352920                                        LR 0.100000    Time 0.263641    
2024-04-23 16:58:17,720 - Epoch: [52][  260/  267]    Overall Loss 2.353421    Objective Loss 2.353421                                        LR 0.100000    Time 0.262519    
2024-04-23 16:58:19,503 - Epoch: [52][  267/  267]    Overall Loss 2.354834    Objective Loss 2.354834    Top1 2.325581    Top5 41.860465    LR 0.100000    Time 0.262304    
2024-04-23 16:58:19,777 - --- validate (epoch=52)-----------
2024-04-23 16:58:19,778 - 946 samples (32 per mini-batch)
2024-04-23 16:58:23,454 - Epoch: [52][   10/   30]    Loss 2.347556    Top1 10.625000    Top5 50.625000    
2024-04-23 16:58:25,115 - Epoch: [52][   20/   30]    Loss 2.360581    Top1 9.843750    Top5 49.531250    
2024-04-23 16:58:27,509 - Epoch: [52][   30/   30]    Loss 2.358328    Top1 10.570825    Top5 48.625793    
2024-04-23 16:58:27,718 - ==> Top1: 10.571    Top5: 48.626    Loss: 2.358

2024-04-23 16:58:27,720 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 16:58:27,724 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:58:27,725 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:58:27,742 - 

2024-04-23 16:58:27,743 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:58:31,034 - Epoch: [53][   10/  267]    Overall Loss 2.393481    Objective Loss 2.393481                                        LR 0.100000    Time 0.328742    
2024-04-23 16:58:33,142 - Epoch: [53][   20/  267]    Overall Loss 2.378850    Objective Loss 2.378850                                        LR 0.100000    Time 0.269600    
2024-04-23 16:58:33,222 - Epoch: [41][  296/  296]    Overall Loss 1.024037    Objective Loss 1.024037    Top1 70.491803    Top5 95.081967    LR 0.000320    Time 0.221962    
2024-04-23 16:58:33,513 - --- validate (epoch=41)-----------
2024-04-23 16:58:33,514 - 3925 samples (32 per mini-batch)
2024-04-23 16:58:36,127 - Epoch: [53][   30/  267]    Overall Loss 2.387622    Objective Loss 2.387622                                        LR 0.100000    Time 0.279137    
2024-04-23 16:58:39,487 - Epoch: [53][   40/  267]    Overall Loss 2.380440    Objective Loss 2.380440                                        LR 0.100000    Time 0.293243    
2024-04-23 16:58:42,452 - Epoch: [53][   50/  267]    Overall Loss 2.384038    Objective Loss 2.384038                                        LR 0.100000    Time 0.293861    
2024-04-23 16:58:45,422 - Epoch: [53][   60/  267]    Overall Loss 2.379951    Objective Loss 2.379951                                        LR 0.100000    Time 0.294337    
2024-04-23 16:58:47,442 - Epoch: [53][   70/  267]    Overall Loss 2.381332    Objective Loss 2.381332                                        LR 0.100000    Time 0.281099    
2024-04-23 16:58:50,260 - Epoch: [53][   80/  267]    Overall Loss 2.382891    Objective Loss 2.382891                                        LR 0.100000    Time 0.281150    
2024-04-23 16:58:52,496 - Epoch: [53][   90/  267]    Overall Loss 2.382552    Objective Loss 2.382552                                        LR 0.100000    Time 0.274723    
2024-04-23 16:58:55,627 - Epoch: [53][  100/  267]    Overall Loss 2.379635    Objective Loss 2.379635                                        LR 0.100000    Time 0.278523    
2024-04-23 16:58:57,963 - Epoch: [53][  110/  267]    Overall Loss 2.374953    Objective Loss 2.374953                                        LR 0.100000    Time 0.274413    
2024-04-23 16:59:00,487 - Epoch: [53][  120/  267]    Overall Loss 2.374791    Objective Loss 2.374791                                        LR 0.100000    Time 0.272549    
2024-04-23 16:59:02,905 - Epoch: [41][  100/  123]    Loss 0.886191    Top1 70.750000    Top5 95.531250    
2024-04-23 16:59:03,003 - Epoch: [53][  130/  267]    Overall Loss 2.372163    Objective Loss 2.372163                                        LR 0.100000    Time 0.270918    
2024-04-23 16:59:06,678 - Epoch: [53][  140/  267]    Overall Loss 2.375003    Objective Loss 2.375003                                        LR 0.100000    Time 0.277794    
2024-04-23 16:59:08,233 - Epoch: [41][  123/  123]    Loss 0.893316    Top1 70.216561    Top5 95.541401    
2024-04-23 16:59:08,562 - ==> Top1: 70.217    Top5: 95.541    Loss: 0.893

2024-04-23 16:59:08,577 - ==> Best [Top1: 72.611   Top5: 95.898   Sparsity:0.00   Params: 376752 on epoch: 40]
2024-04-23 16:59:08,578 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 16:59:08,672 - 

2024-04-23 16:59:08,673 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 16:59:08,933 - Epoch: [53][  150/  267]    Overall Loss 2.373807    Objective Loss 2.373807                                        LR 0.100000    Time 0.274251    
2024-04-23 16:59:13,030 - Epoch: [53][  160/  267]    Overall Loss 2.374001    Objective Loss 2.374001                                        LR 0.100000    Time 0.282690    
2024-04-23 16:59:15,695 - Epoch: [53][  170/  267]    Overall Loss 2.373095    Objective Loss 2.373095                                        LR 0.100000    Time 0.281717    
2024-04-23 16:59:19,686 - Epoch: [53][  180/  267]    Overall Loss 2.373452    Objective Loss 2.373452                                        LR 0.100000    Time 0.288222    
2024-04-23 16:59:22,058 - Epoch: [53][  190/  267]    Overall Loss 2.372628    Objective Loss 2.372628                                        LR 0.100000    Time 0.285521    
2024-04-23 16:59:23,705 - Epoch: [53][  200/  267]    Overall Loss 2.372269    Objective Loss 2.372269                                        LR 0.100000    Time 0.279466    
2024-04-23 16:59:25,390 - Epoch: [53][  210/  267]    Overall Loss 2.371057    Objective Loss 2.371057                                        LR 0.100000    Time 0.274170    
2024-04-23 16:59:27,674 - Epoch: [53][  220/  267]    Overall Loss 2.371274    Objective Loss 2.371274                                        LR 0.100000    Time 0.272072    
2024-04-23 16:59:30,593 - Epoch: [53][  230/  267]    Overall Loss 2.370493    Objective Loss 2.370493                                        LR 0.100000    Time 0.272923    
2024-04-23 16:59:32,407 - Epoch: [53][  240/  267]    Overall Loss 2.369991    Objective Loss 2.369991                                        LR 0.100000    Time 0.269094    
2024-04-23 16:59:35,487 - Epoch: [53][  250/  267]    Overall Loss 2.369005    Objective Loss 2.369005                                        LR 0.100000    Time 0.270637    
2024-04-23 16:59:37,859 - Epoch: [53][  260/  267]    Overall Loss 2.368579    Objective Loss 2.368579                                        LR 0.100000    Time 0.269338    
2024-04-23 16:59:38,685 - Epoch: [42][  100/  296]    Overall Loss 1.023075    Objective Loss 1.023075                                        LR 0.000320    Time 0.299871    
2024-04-23 16:59:39,970 - Epoch: [53][  267/  267]    Overall Loss 2.368537    Objective Loss 2.368537    Top1 9.302326    Top5 44.186047    LR 0.100000    Time 0.270175    
2024-04-23 16:59:40,244 - --- validate (epoch=53)-----------
2024-04-23 16:59:40,246 - 946 samples (32 per mini-batch)
2024-04-23 16:59:44,703 - Epoch: [53][   10/   30]    Loss 2.359729    Top1 9.687500    Top5 48.125000    
2024-04-23 16:59:47,146 - Epoch: [53][   20/   30]    Loss 2.353760    Top1 9.843750    Top5 50.156250    
2024-04-23 16:59:50,237 - Epoch: [53][   30/   30]    Loss 2.345661    Top1 10.993658    Top5 50.845666    
2024-04-23 16:59:50,471 - ==> Top1: 10.994    Top5: 50.846    Loss: 2.346

2024-04-23 16:59:50,474 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 16:59:50,480 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 16:59:50,481 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 16:59:50,500 - 

2024-04-23 16:59:50,501 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 16:59:54,438 - Epoch: [54][   10/  267]    Overall Loss 2.393399    Objective Loss 2.393399                                        LR 0.100000    Time 0.393387    
2024-04-23 16:59:56,953 - Epoch: [54][   20/  267]    Overall Loss 2.357361    Objective Loss 2.357361                                        LR 0.100000    Time 0.322266    
2024-04-23 17:00:00,694 - Epoch: [54][   30/  267]    Overall Loss 2.359563    Objective Loss 2.359563                                        LR 0.100000    Time 0.339430    
2024-04-23 17:00:03,230 - Epoch: [54][   40/  267]    Overall Loss 2.356533    Objective Loss 2.356533                                        LR 0.100000    Time 0.317899    
2024-04-23 17:00:05,690 - Epoch: [54][   50/  267]    Overall Loss 2.354928    Objective Loss 2.354928                                        LR 0.100000    Time 0.303456    
2024-04-23 17:00:06,858 - Epoch: [42][  200/  296]    Overall Loss 1.020216    Objective Loss 1.020216                                        LR 0.000320    Time 0.290685    
2024-04-23 17:00:08,563 - Epoch: [54][   60/  267]    Overall Loss 2.355275    Objective Loss 2.355275                                        LR 0.100000    Time 0.300705    
2024-04-23 17:00:12,333 - Epoch: [54][   70/  267]    Overall Loss 2.356033    Objective Loss 2.356033                                        LR 0.100000    Time 0.311566    
2024-04-23 17:00:14,319 - Epoch: [54][   80/  267]    Overall Loss 2.361510    Objective Loss 2.361510                                        LR 0.100000    Time 0.297411    
2024-04-23 17:00:17,552 - Epoch: [54][   90/  267]    Overall Loss 2.361428    Objective Loss 2.361428                                        LR 0.100000    Time 0.300255    
2024-04-23 17:00:20,144 - Epoch: [54][  100/  267]    Overall Loss 2.364116    Objective Loss 2.364116                                        LR 0.100000    Time 0.296116    
2024-04-23 17:00:23,530 - Epoch: [54][  110/  267]    Overall Loss 2.361583    Objective Loss 2.361583                                        LR 0.100000    Time 0.299954    
2024-04-23 17:00:26,066 - Epoch: [54][  120/  267]    Overall Loss 2.359727    Objective Loss 2.359727                                        LR 0.100000    Time 0.296064    
2024-04-23 17:00:29,030 - Epoch: [54][  130/  267]    Overall Loss 2.364730    Objective Loss 2.364730                                        LR 0.100000    Time 0.296065    
2024-04-23 17:00:30,972 - Epoch: [54][  140/  267]    Overall Loss 2.363193    Objective Loss 2.363193                                        LR 0.100000    Time 0.288761    
2024-04-23 17:00:32,747 - Epoch: [42][  296/  296]    Overall Loss 1.008954    Objective Loss 1.008954    Top1 78.688525    Top5 98.360656    LR 0.000320    Time 0.283800    
2024-04-23 17:00:33,110 - --- validate (epoch=42)-----------
2024-04-23 17:00:33,111 - 3925 samples (32 per mini-batch)
2024-04-23 17:00:33,264 - Epoch: [54][  150/  267]    Overall Loss 2.364922    Objective Loss 2.364922                                        LR 0.100000    Time 0.284773    
2024-04-23 17:00:35,233 - Epoch: [54][  160/  267]    Overall Loss 2.363051    Objective Loss 2.363051                                        LR 0.100000    Time 0.279262    
2024-04-23 17:00:38,251 - Epoch: [54][  170/  267]    Overall Loss 2.363304    Objective Loss 2.363304                                        LR 0.100000    Time 0.280566    
2024-04-23 17:00:40,526 - Epoch: [54][  180/  267]    Overall Loss 2.362734    Objective Loss 2.362734                                        LR 0.100000    Time 0.277599    
2024-04-23 17:00:43,701 - Epoch: [54][  190/  267]    Overall Loss 2.362846    Objective Loss 2.362846                                        LR 0.100000    Time 0.279685    
2024-04-23 17:00:45,938 - Epoch: [54][  200/  267]    Overall Loss 2.362865    Objective Loss 2.362865                                        LR 0.100000    Time 0.276868    
2024-04-23 17:00:49,176 - Epoch: [54][  210/  267]    Overall Loss 2.363778    Objective Loss 2.363778                                        LR 0.100000    Time 0.279091    
2024-04-23 17:00:51,424 - Epoch: [54][  220/  267]    Overall Loss 2.362357    Objective Loss 2.362357                                        LR 0.100000    Time 0.276606    
2024-04-23 17:00:54,863 - Epoch: [54][  230/  267]    Overall Loss 2.361762    Objective Loss 2.361762                                        LR 0.100000    Time 0.279523    
2024-04-23 17:00:56,862 - Epoch: [54][  240/  267]    Overall Loss 2.362565    Objective Loss 2.362565                                        LR 0.100000    Time 0.276193    
2024-04-23 17:00:59,771 - Epoch: [54][  250/  267]    Overall Loss 2.362189    Objective Loss 2.362189                                        LR 0.100000    Time 0.276765    
2024-04-23 17:01:02,075 - Epoch: [54][  260/  267]    Overall Loss 2.362276    Objective Loss 2.362276                                        LR 0.100000    Time 0.274970    
2024-04-23 17:01:02,471 - Epoch: [42][  100/  123]    Loss 0.853071    Top1 72.500000    Top5 95.968750    
2024-04-23 17:01:04,254 - Epoch: [54][  267/  267]    Overall Loss 2.362329    Objective Loss 2.362329    Top1 16.279070    Top5 48.837209    LR 0.100000    Time 0.275915    
2024-04-23 17:01:04,542 - --- validate (epoch=54)-----------
2024-04-23 17:01:04,543 - 946 samples (32 per mini-batch)
2024-04-23 17:01:09,286 - Epoch: [54][   10/   30]    Loss 2.324013    Top1 9.687500    Top5 49.687500    
2024-04-23 17:01:09,471 - Epoch: [42][  123/  123]    Loss 0.858528    Top1 72.356688    Top5 96.127389    
2024-04-23 17:01:09,692 - ==> Top1: 72.357    Top5: 96.127    Loss: 0.859

2024-04-23 17:01:09,703 - ==> Best [Top1: 72.611   Top5: 95.898   Sparsity:0.00   Params: 376752 on epoch: 40]
2024-04-23 17:01:09,704 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:01:09,761 - 

2024-04-23 17:01:09,762 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:01:11,854 - Epoch: [54][   20/   30]    Loss 2.321132    Top1 10.156250    Top5 50.937500    
2024-04-23 17:01:14,742 - Epoch: [54][   30/   30]    Loss 2.321623    Top1 10.042283    Top5 50.634249    
2024-04-23 17:01:14,956 - ==> Top1: 10.042    Top5: 50.634    Loss: 2.322

2024-04-23 17:01:14,958 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 17:01:14,964 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:01:14,965 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:01:14,985 - 

2024-04-23 17:01:14,986 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:01:18,980 - Epoch: [55][   10/  267]    Overall Loss 2.342727    Objective Loss 2.342727                                        LR 0.100000    Time 0.398888    
2024-04-23 17:01:21,818 - Epoch: [55][   20/  267]    Overall Loss 2.338163    Objective Loss 2.338163                                        LR 0.100000    Time 0.341199    
2024-04-23 17:01:25,129 - Epoch: [55][   30/  267]    Overall Loss 2.350409    Objective Loss 2.350409                                        LR 0.100000    Time 0.337728    
2024-04-23 17:01:28,001 - Epoch: [55][   40/  267]    Overall Loss 2.345450    Objective Loss 2.345450                                        LR 0.100000    Time 0.324982    
2024-04-23 17:01:31,773 - Epoch: [55][   50/  267]    Overall Loss 2.351827    Objective Loss 2.351827                                        LR 0.100000    Time 0.335354    
2024-04-23 17:01:34,226 - Epoch: [55][   60/  267]    Overall Loss 2.355660    Objective Loss 2.355660                                        LR 0.100000    Time 0.320274    
2024-04-23 17:01:38,029 - Epoch: [55][   70/  267]    Overall Loss 2.354077    Objective Loss 2.354077                                        LR 0.100000    Time 0.328794    
2024-04-23 17:01:40,619 - Epoch: [43][  100/  296]    Overall Loss 1.008237    Objective Loss 1.008237                                        LR 0.000320    Time 0.308349    
2024-04-23 17:01:40,630 - Epoch: [55][   80/  267]    Overall Loss 2.356026    Objective Loss 2.356026                                        LR 0.100000    Time 0.320132    
2024-04-23 17:01:44,032 - Epoch: [55][   90/  267]    Overall Loss 2.356310    Objective Loss 2.356310                                        LR 0.100000    Time 0.322332    
2024-04-23 17:01:46,518 - Epoch: [55][  100/  267]    Overall Loss 2.359301    Objective Loss 2.359301                                        LR 0.100000    Time 0.314927    
2024-04-23 17:01:49,723 - Epoch: [55][  110/  267]    Overall Loss 2.359881    Objective Loss 2.359881                                        LR 0.100000    Time 0.315407    
2024-04-23 17:01:52,158 - Epoch: [55][  120/  267]    Overall Loss 2.360882    Objective Loss 2.360882                                        LR 0.100000    Time 0.309381    
2024-04-23 17:01:55,336 - Epoch: [55][  130/  267]    Overall Loss 2.361777    Objective Loss 2.361777                                        LR 0.100000    Time 0.310009    
2024-04-23 17:01:57,580 - Epoch: [55][  140/  267]    Overall Loss 2.360879    Objective Loss 2.360879                                        LR 0.100000    Time 0.303870    
2024-04-23 17:02:00,788 - Epoch: [55][  150/  267]    Overall Loss 2.361302    Objective Loss 2.361302                                        LR 0.100000    Time 0.304981    
2024-04-23 17:02:03,134 - Epoch: [55][  160/  267]    Overall Loss 2.360070    Objective Loss 2.360070                                        LR 0.100000    Time 0.300568    
2024-04-23 17:02:06,428 - Epoch: [55][  170/  267]    Overall Loss 2.361998    Objective Loss 2.361998                                        LR 0.100000    Time 0.302242    
2024-04-23 17:02:08,944 - Epoch: [55][  180/  267]    Overall Loss 2.362448    Objective Loss 2.362448                                        LR 0.100000    Time 0.299409    
2024-04-23 17:02:09,333 - Epoch: [43][  200/  296]    Overall Loss 1.016943    Objective Loss 1.016943                                        LR 0.000320    Time 0.297631    
2024-04-23 17:02:12,308 - Epoch: [55][  190/  267]    Overall Loss 2.363370    Objective Loss 2.363370                                        LR 0.100000    Time 0.301335    
2024-04-23 17:02:14,787 - Epoch: [55][  200/  267]    Overall Loss 2.362240    Objective Loss 2.362240                                        LR 0.100000    Time 0.298650    
2024-04-23 17:02:17,143 - Epoch: [55][  210/  267]    Overall Loss 2.362490    Objective Loss 2.362490                                        LR 0.100000    Time 0.295635    
2024-04-23 17:02:19,626 - Epoch: [55][  220/  267]    Overall Loss 2.362828    Objective Loss 2.362828                                        LR 0.100000    Time 0.293472    
2024-04-23 17:02:23,220 - Epoch: [55][  230/  267]    Overall Loss 2.362452    Objective Loss 2.362452                                        LR 0.100000    Time 0.296321    
2024-04-23 17:02:24,970 - Epoch: [55][  240/  267]    Overall Loss 2.361709    Objective Loss 2.361709                                        LR 0.100000    Time 0.291251    
2024-04-23 17:02:28,430 - Epoch: [55][  250/  267]    Overall Loss 2.361329    Objective Loss 2.361329                                        LR 0.100000    Time 0.293433    
2024-04-23 17:02:31,052 - Epoch: [55][  260/  267]    Overall Loss 2.361425    Objective Loss 2.361425                                        LR 0.100000    Time 0.292215    
2024-04-23 17:02:33,303 - Epoch: [55][  267/  267]    Overall Loss 2.361059    Objective Loss 2.361059    Top1 13.953488    Top5 48.837209    LR 0.100000    Time 0.292978    
2024-04-23 17:02:33,563 - --- validate (epoch=55)-----------
2024-04-23 17:02:33,564 - 946 samples (32 per mini-batch)
2024-04-23 17:02:37,309 - Epoch: [55][   10/   30]    Loss 2.389797    Top1 9.375000    Top5 47.812500    
2024-04-23 17:02:37,314 - Epoch: [43][  296/  296]    Overall Loss 1.012437    Objective Loss 1.012437    Top1 60.655738    Top5 88.524590    LR 0.000320    Time 0.295563    
2024-04-23 17:02:37,594 - --- validate (epoch=43)-----------
2024-04-23 17:02:37,595 - 3925 samples (32 per mini-batch)
2024-04-23 17:02:39,224 - Epoch: [55][   20/   30]    Loss 2.378139    Top1 9.843750    Top5 49.843750    
2024-04-23 17:02:42,345 - Epoch: [55][   30/   30]    Loss 2.377538    Top1 10.042283    Top5 50.317125    
2024-04-23 17:02:42,590 - ==> Top1: 10.042    Top5: 50.317    Loss: 2.378

2024-04-23 17:02:42,592 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 17:02:42,598 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:02:42,598 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:02:42,619 - 

2024-04-23 17:02:42,621 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:02:47,622 - Epoch: [56][   10/  267]    Overall Loss 2.349493    Objective Loss 2.349493                                        LR 0.100000    Time 0.499597    
2024-04-23 17:02:50,070 - Epoch: [56][   20/  267]    Overall Loss 2.362310    Objective Loss 2.362310                                        LR 0.100000    Time 0.372031    
2024-04-23 17:02:53,595 - Epoch: [56][   30/  267]    Overall Loss 2.363802    Objective Loss 2.363802                                        LR 0.100000    Time 0.365389    
2024-04-23 17:02:56,097 - Epoch: [56][   40/  267]    Overall Loss 2.363786    Objective Loss 2.363786                                        LR 0.100000    Time 0.336532    
2024-04-23 17:02:59,691 - Epoch: [56][   50/  267]    Overall Loss 2.363470    Objective Loss 2.363470                                        LR 0.100000    Time 0.341035    
2024-04-23 17:03:02,251 - Epoch: [56][   60/  267]    Overall Loss 2.364923    Objective Loss 2.364923                                        LR 0.100000    Time 0.326799    
2024-04-23 17:03:05,494 - Epoch: [56][   70/  267]    Overall Loss 2.363969    Objective Loss 2.363969                                        LR 0.100000    Time 0.326403    
2024-04-23 17:03:08,023 - Epoch: [56][   80/  267]    Overall Loss 2.365557    Objective Loss 2.365557                                        LR 0.100000    Time 0.317175    
2024-04-23 17:03:09,619 - Epoch: [43][  100/  123]    Loss 0.823082    Top1 73.343750    Top5 96.343750    
2024-04-23 17:03:10,840 - Epoch: [56][   90/  267]    Overall Loss 2.364186    Objective Loss 2.364186                                        LR 0.100000    Time 0.313194    
2024-04-23 17:03:13,121 - Epoch: [56][  100/  267]    Overall Loss 2.361475    Objective Loss 2.361475                                        LR 0.100000    Time 0.304656    
2024-04-23 17:03:15,600 - Epoch: [43][  123/  123]    Loss 0.835746    Top1 72.968153    Top5 96.127389    
2024-04-23 17:03:15,763 - Epoch: [56][  110/  267]    Overall Loss 2.362847    Objective Loss 2.362847                                        LR 0.100000    Time 0.300953    
2024-04-23 17:03:15,903 - ==> Top1: 72.968    Top5: 96.127    Loss: 0.836

2024-04-23 17:03:15,911 - ==> Best [Top1: 72.968   Top5: 96.127   Sparsity:0.00   Params: 376752 on epoch: 43]
2024-04-23 17:03:15,912 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:03:15,989 - 

2024-04-23 17:03:15,991 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:03:17,031 - Epoch: [56][  120/  267]    Overall Loss 2.361781    Objective Loss 2.361781                                        LR 0.100000    Time 0.286421    
2024-04-23 17:03:19,540 - Epoch: [56][  130/  267]    Overall Loss 2.362839    Objective Loss 2.362839                                        LR 0.100000    Time 0.283663    
2024-04-23 17:03:21,431 - Epoch: [56][  140/  267]    Overall Loss 2.363941    Objective Loss 2.363941                                        LR 0.100000    Time 0.276885    
2024-04-23 17:03:24,043 - Epoch: [56][  150/  267]    Overall Loss 2.361787    Objective Loss 2.361787                                        LR 0.100000    Time 0.275816    
2024-04-23 17:03:26,557 - Epoch: [56][  160/  267]    Overall Loss 2.361974    Objective Loss 2.361974                                        LR 0.100000    Time 0.274273    
2024-04-23 17:03:29,585 - Epoch: [56][  170/  267]    Overall Loss 2.360680    Objective Loss 2.360680                                        LR 0.100000    Time 0.275933    
2024-04-23 17:03:32,307 - Epoch: [56][  180/  267]    Overall Loss 2.362204    Objective Loss 2.362204                                        LR 0.100000    Time 0.275707    
2024-04-23 17:03:37,050 - Epoch: [56][  190/  267]    Overall Loss 2.362395    Objective Loss 2.362395                                        LR 0.100000    Time 0.286140    
2024-04-23 17:03:39,879 - Epoch: [56][  200/  267]    Overall Loss 2.362169    Objective Loss 2.362169                                        LR 0.100000    Time 0.285962    
2024-04-23 17:03:43,055 - Epoch: [56][  210/  267]    Overall Loss 2.363199    Objective Loss 2.363199                                        LR 0.100000    Time 0.287454    
2024-04-23 17:03:45,342 - Epoch: [56][  220/  267]    Overall Loss 2.362718    Objective Loss 2.362718                                        LR 0.100000    Time 0.284765    
2024-04-23 17:03:45,939 - Epoch: [44][  100/  296]    Overall Loss 1.003001    Objective Loss 1.003001                                        LR 0.000320    Time 0.299250    
2024-04-23 17:03:48,360 - Epoch: [56][  230/  267]    Overall Loss 2.362686    Objective Loss 2.362686                                        LR 0.100000    Time 0.285493    
2024-04-23 17:03:50,712 - Epoch: [56][  240/  267]    Overall Loss 2.363443    Objective Loss 2.363443                                        LR 0.100000    Time 0.283387    
2024-04-23 17:03:53,588 - Epoch: [56][  250/  267]    Overall Loss 2.363782    Objective Loss 2.363782                                        LR 0.100000    Time 0.283545    
2024-04-23 17:03:55,673 - Epoch: [56][  260/  267]    Overall Loss 2.363461    Objective Loss 2.363461                                        LR 0.100000    Time 0.280644    
2024-04-23 17:03:57,723 - Epoch: [56][  267/  267]    Overall Loss 2.365034    Objective Loss 2.365034    Top1 4.651163    Top5 55.813953    LR 0.100000    Time 0.280956    
2024-04-23 17:03:57,988 - --- validate (epoch=56)-----------
2024-04-23 17:03:57,989 - 946 samples (32 per mini-batch)
2024-04-23 17:04:02,092 - Epoch: [56][   10/   30]    Loss 2.317150    Top1 10.000000    Top5 48.437500    
2024-04-23 17:04:04,567 - Epoch: [56][   20/   30]    Loss 2.324303    Top1 9.843750    Top5 48.906250    
2024-04-23 17:04:07,770 - Epoch: [56][   30/   30]    Loss 2.321590    Top1 10.465116    Top5 49.365751    
2024-04-23 17:04:08,018 - ==> Top1: 10.465    Top5: 49.366    Loss: 2.322

2024-04-23 17:04:08,021 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 17:04:08,026 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:04:08,026 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:04:08,046 - 

2024-04-23 17:04:08,047 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:04:11,392 - Epoch: [44][  200/  296]    Overall Loss 0.996705    Objective Loss 0.996705                                        LR 0.000320    Time 0.276789    
2024-04-23 17:04:11,510 - Epoch: [57][   10/  267]    Overall Loss 2.373895    Objective Loss 2.373895                                        LR 0.100000    Time 0.345935    
2024-04-23 17:04:13,642 - Epoch: [57][   20/  267]    Overall Loss 2.395378    Objective Loss 2.395378                                        LR 0.100000    Time 0.279385    
2024-04-23 17:04:16,946 - Epoch: [57][   30/  267]    Overall Loss 2.380189    Objective Loss 2.380189                                        LR 0.100000    Time 0.296267    
2024-04-23 17:04:19,009 - Epoch: [57][   40/  267]    Overall Loss 2.379950    Objective Loss 2.379950                                        LR 0.100000    Time 0.273687    
2024-04-23 17:04:21,352 - Epoch: [57][   50/  267]    Overall Loss 2.381802    Objective Loss 2.381802                                        LR 0.100000    Time 0.265766    
2024-04-23 17:04:24,658 - Epoch: [57][   60/  267]    Overall Loss 2.377741    Objective Loss 2.377741                                        LR 0.100000    Time 0.276521    
2024-04-23 17:04:27,857 - Epoch: [57][   70/  267]    Overall Loss 2.377268    Objective Loss 2.377268                                        LR 0.100000    Time 0.282665    
2024-04-23 17:04:30,823 - Epoch: [57][   80/  267]    Overall Loss 2.374266    Objective Loss 2.374266                                        LR 0.100000    Time 0.284369    
2024-04-23 17:04:34,555 - Epoch: [57][   90/  267]    Overall Loss 2.370260    Objective Loss 2.370260                                        LR 0.100000    Time 0.294196    
2024-04-23 17:04:37,249 - Epoch: [57][  100/  267]    Overall Loss 2.371018    Objective Loss 2.371018                                        LR 0.100000    Time 0.291685    
2024-04-23 17:04:38,157 - Epoch: [44][  296/  296]    Overall Loss 1.001840    Objective Loss 1.001840    Top1 65.573770    Top5 95.081967    LR 0.000320    Time 0.277371    
2024-04-23 17:04:38,432 - --- validate (epoch=44)-----------
2024-04-23 17:04:38,434 - 3925 samples (32 per mini-batch)
2024-04-23 17:04:40,982 - Epoch: [57][  110/  267]    Overall Loss 2.369562    Objective Loss 2.369562                                        LR 0.100000    Time 0.299077    
2024-04-23 17:04:43,830 - Epoch: [57][  120/  267]    Overall Loss 2.369738    Objective Loss 2.369738                                        LR 0.100000    Time 0.297803    
2024-04-23 17:04:47,504 - Epoch: [57][  130/  267]    Overall Loss 2.371181    Objective Loss 2.371181                                        LR 0.100000    Time 0.303128    
2024-04-23 17:04:50,176 - Epoch: [57][  140/  267]    Overall Loss 2.368939    Objective Loss 2.368939                                        LR 0.100000    Time 0.300535    
2024-04-23 17:04:54,493 - Epoch: [57][  150/  267]    Overall Loss 2.365971    Objective Loss 2.365971                                        LR 0.100000    Time 0.309249    
2024-04-23 17:04:57,273 - Epoch: [57][  160/  267]    Overall Loss 2.367382    Objective Loss 2.367382                                        LR 0.100000    Time 0.307278    
2024-04-23 17:05:01,132 - Epoch: [57][  170/  267]    Overall Loss 2.365268    Objective Loss 2.365268                                        LR 0.100000    Time 0.311885    
2024-04-23 17:05:03,878 - Epoch: [57][  180/  267]    Overall Loss 2.364231    Objective Loss 2.364231                                        LR 0.100000    Time 0.309795    
2024-04-23 17:05:07,789 - Epoch: [57][  190/  267]    Overall Loss 2.364375    Objective Loss 2.364375                                        LR 0.100000    Time 0.314054    
2024-04-23 17:05:10,250 - Epoch: [57][  200/  267]    Overall Loss 2.365033    Objective Loss 2.365033                                        LR 0.100000    Time 0.310635    
2024-04-23 17:05:12,355 - Epoch: [44][  100/  123]    Loss 0.837026    Top1 72.468750    Top5 96.093750    
2024-04-23 17:05:13,336 - Epoch: [57][  210/  267]    Overall Loss 2.365023    Objective Loss 2.365023                                        LR 0.100000    Time 0.310528    
2024-04-23 17:05:15,575 - Epoch: [57][  220/  267]    Overall Loss 2.366336    Objective Loss 2.366336                                        LR 0.100000    Time 0.306579    
2024-04-23 17:05:18,764 - Epoch: [57][  230/  267]    Overall Loss 2.365484    Objective Loss 2.365484                                        LR 0.100000    Time 0.307101    
2024-04-23 17:05:18,911 - Epoch: [44][  123/  123]    Loss 0.827241    Top1 72.687898    Top5 96.254777    
2024-04-23 17:05:19,146 - ==> Top1: 72.688    Top5: 96.255    Loss: 0.827

2024-04-23 17:05:19,155 - ==> Best [Top1: 72.968   Top5: 96.127   Sparsity:0.00   Params: 376752 on epoch: 43]
2024-04-23 17:05:19,156 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:05:19,215 - 

2024-04-23 17:05:19,216 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:05:20,207 - Epoch: [57][  240/  267]    Overall Loss 2.364338    Objective Loss 2.364338                                        LR 0.100000    Time 0.300309    
2024-04-23 17:05:23,631 - Epoch: [57][  250/  267]    Overall Loss 2.363731    Objective Loss 2.363731                                        LR 0.100000    Time 0.301979    
2024-04-23 17:05:26,217 - Epoch: [57][  260/  267]    Overall Loss 2.363452    Objective Loss 2.363452                                        LR 0.100000    Time 0.300301    
2024-04-23 17:05:28,616 - Epoch: [57][  267/  267]    Overall Loss 2.363800    Objective Loss 2.363800    Top1 9.302326    Top5 37.209302    LR 0.100000    Time 0.301405    
2024-04-23 17:05:28,921 - --- validate (epoch=57)-----------
2024-04-23 17:05:28,923 - 946 samples (32 per mini-batch)
2024-04-23 17:05:34,075 - Epoch: [57][   10/   30]    Loss 2.390008    Top1 12.500000    Top5 48.125000    
2024-04-23 17:05:36,642 - Epoch: [57][   20/   30]    Loss 2.393927    Top1 11.093750    Top5 49.687500    
2024-04-23 17:05:39,751 - Epoch: [57][   30/   30]    Loss 2.389937    Top1 10.993658    Top5 50.422833    
2024-04-23 17:05:40,011 - ==> Top1: 10.994    Top5: 50.423    Loss: 2.390

2024-04-23 17:05:40,013 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 17:05:40,017 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:05:40,019 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:05:40,047 - 

2024-04-23 17:05:40,049 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:05:44,921 - Epoch: [58][   10/  267]    Overall Loss 2.376998    Objective Loss 2.376998                                        LR 0.100000    Time 0.486580    
2024-04-23 17:05:48,142 - Epoch: [58][   20/  267]    Overall Loss 2.372606    Objective Loss 2.372606                                        LR 0.100000    Time 0.404174    
2024-04-23 17:05:52,759 - Epoch: [58][   30/  267]    Overall Loss 2.378406    Objective Loss 2.378406                                        LR 0.100000    Time 0.423257    
2024-04-23 17:05:53,381 - Epoch: [45][  100/  296]    Overall Loss 1.037287    Objective Loss 1.037287                                        LR 0.000320    Time 0.341428    
2024-04-23 17:05:55,999 - Epoch: [58][   40/  267]    Overall Loss 2.371414    Objective Loss 2.371414                                        LR 0.100000    Time 0.398355    
2024-04-23 17:06:00,302 - Epoch: [58][   50/  267]    Overall Loss 2.368982    Objective Loss 2.368982                                        LR 0.100000    Time 0.404645    
2024-04-23 17:06:03,989 - Epoch: [58][   60/  267]    Overall Loss 2.371917    Objective Loss 2.371917                                        LR 0.100000    Time 0.398605    
2024-04-23 17:06:08,023 - Epoch: [58][   70/  267]    Overall Loss 2.372425    Objective Loss 2.372425                                        LR 0.100000    Time 0.399236    
2024-04-23 17:06:11,438 - Epoch: [58][   80/  267]    Overall Loss 2.363479    Objective Loss 2.363479                                        LR 0.100000    Time 0.391973    
2024-04-23 17:06:14,072 - Epoch: [58][   90/  267]    Overall Loss 2.362760    Objective Loss 2.362760                                        LR 0.100000    Time 0.377651    
2024-04-23 17:06:17,084 - Epoch: [58][  100/  267]    Overall Loss 2.365805    Objective Loss 2.365805                                        LR 0.100000    Time 0.369975    
2024-04-23 17:06:20,308 - Epoch: [58][  110/  267]    Overall Loss 2.365120    Objective Loss 2.365120                                        LR 0.100000    Time 0.365612    
2024-04-23 17:06:24,299 - Epoch: [58][  120/  267]    Overall Loss 2.364048    Objective Loss 2.364048                                        LR 0.100000    Time 0.368377    
2024-04-23 17:06:27,009 - Epoch: [58][  130/  267]    Overall Loss 2.366364    Objective Loss 2.366364                                        LR 0.100000    Time 0.360866    
2024-04-23 17:06:27,629 - Epoch: [45][  200/  296]    Overall Loss 1.008947    Objective Loss 1.008947                                        LR 0.000320    Time 0.341843    
2024-04-23 17:06:30,165 - Epoch: [58][  140/  267]    Overall Loss 2.368571    Objective Loss 2.368571                                        LR 0.100000    Time 0.357606    
2024-04-23 17:06:32,461 - Epoch: [58][  150/  267]    Overall Loss 2.366675    Objective Loss 2.366675                                        LR 0.100000    Time 0.349040    
2024-04-23 17:06:35,773 - Epoch: [58][  160/  267]    Overall Loss 2.366869    Objective Loss 2.366869                                        LR 0.100000    Time 0.347901    
2024-04-23 17:06:38,137 - Epoch: [58][  170/  267]    Overall Loss 2.366841    Objective Loss 2.366841                                        LR 0.100000    Time 0.341327    
2024-04-23 17:06:41,732 - Epoch: [58][  180/  267]    Overall Loss 2.365064    Objective Loss 2.365064                                        LR 0.100000    Time 0.342319    
2024-04-23 17:06:43,881 - Epoch: [58][  190/  267]    Overall Loss 2.364136    Objective Loss 2.364136                                        LR 0.100000    Time 0.335597    
2024-04-23 17:06:46,639 - Epoch: [58][  200/  267]    Overall Loss 2.365012    Objective Loss 2.365012                                        LR 0.100000    Time 0.332591    
2024-04-23 17:06:48,620 - Epoch: [58][  210/  267]    Overall Loss 2.364133    Objective Loss 2.364133                                        LR 0.100000    Time 0.326170    
2024-04-23 17:06:51,446 - Epoch: [58][  220/  267]    Overall Loss 2.364049    Objective Loss 2.364049                                        LR 0.100000    Time 0.324179    
2024-04-23 17:06:53,727 - Epoch: [58][  230/  267]    Overall Loss 2.363590    Objective Loss 2.363590                                        LR 0.100000    Time 0.319988    
2024-04-23 17:06:55,217 - Epoch: [45][  296/  296]    Overall Loss 1.009680    Objective Loss 1.009680    Top1 62.295082    Top5 96.721311    LR 0.000320    Time 0.324112    
2024-04-23 17:06:55,546 - --- validate (epoch=45)-----------
2024-04-23 17:06:55,548 - 3925 samples (32 per mini-batch)
2024-04-23 17:06:56,868 - Epoch: [58][  240/  267]    Overall Loss 2.362981    Objective Loss 2.362981                                        LR 0.100000    Time 0.319728    
2024-04-23 17:06:59,403 - Epoch: [58][  250/  267]    Overall Loss 2.361940    Objective Loss 2.361940                                        LR 0.100000    Time 0.317066    
2024-04-23 17:07:03,450 - Epoch: [58][  260/  267]    Overall Loss 2.362433    Objective Loss 2.362433                                        LR 0.100000    Time 0.320424    
2024-04-23 17:07:04,912 - Epoch: [58][  267/  267]    Overall Loss 2.362219    Objective Loss 2.362219    Top1 16.279070    Top5 65.116279    LR 0.100000    Time 0.317489    
2024-04-23 17:07:05,195 - --- validate (epoch=58)-----------
2024-04-23 17:07:05,196 - 946 samples (32 per mini-batch)
2024-04-23 17:07:09,487 - Epoch: [58][   10/   30]    Loss 2.342108    Top1 8.437500    Top5 50.312500    
2024-04-23 17:07:11,989 - Epoch: [58][   20/   30]    Loss 2.337726    Top1 9.687500    Top5 49.687500    
2024-04-23 17:07:15,430 - Epoch: [58][   30/   30]    Loss 2.333812    Top1 10.253700    Top5 50.000000    
2024-04-23 17:07:15,689 - ==> Top1: 10.254    Top5: 50.000    Loss: 2.334

2024-04-23 17:07:15,691 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 17:07:15,695 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:07:15,696 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:07:15,715 - 

2024-04-23 17:07:15,716 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:07:18,588 - Epoch: [59][   10/  267]    Overall Loss 2.343624    Objective Loss 2.343624                                        LR 0.100000    Time 0.286851    
2024-04-23 17:07:21,008 - Epoch: [59][   20/  267]    Overall Loss 2.368680    Objective Loss 2.368680                                        LR 0.100000    Time 0.264189    
2024-04-23 17:07:24,222 - Epoch: [59][   30/  267]    Overall Loss 2.361489    Objective Loss 2.361489                                        LR 0.100000    Time 0.283187    
2024-04-23 17:07:26,016 - Epoch: [59][   40/  267]    Overall Loss 2.363765    Objective Loss 2.363765                                        LR 0.100000    Time 0.257164    
2024-04-23 17:07:26,398 - Epoch: [45][  100/  123]    Loss 0.877581    Top1 71.562500    Top5 95.656250    
2024-04-23 17:07:28,811 - Epoch: [59][   50/  267]    Overall Loss 2.364087    Objective Loss 2.364087                                        LR 0.100000    Time 0.261571    
2024-04-23 17:07:30,896 - Epoch: [59][   60/  267]    Overall Loss 2.358495    Objective Loss 2.358495                                        LR 0.100000    Time 0.252666    
2024-04-23 17:07:32,249 - Epoch: [45][  123/  123]    Loss 0.866450    Top1 71.745223    Top5 95.745223    
2024-04-23 17:07:32,606 - ==> Top1: 71.745    Top5: 95.745    Loss: 0.866

2024-04-23 17:07:32,614 - ==> Best [Top1: 72.968   Top5: 96.127   Sparsity:0.00   Params: 376752 on epoch: 43]
2024-04-23 17:07:32,615 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:07:32,662 - 

2024-04-23 17:07:32,663 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:07:33,589 - Epoch: [59][   70/  267]    Overall Loss 2.355195    Objective Loss 2.355195                                        LR 0.100000    Time 0.255004    
2024-04-23 17:07:35,541 - Epoch: [59][   80/  267]    Overall Loss 2.352970    Objective Loss 2.352970                                        LR 0.100000    Time 0.247492    
2024-04-23 17:07:37,155 - Epoch: [59][   90/  267]    Overall Loss 2.353733    Objective Loss 2.353733                                        LR 0.100000    Time 0.237890    
2024-04-23 17:07:38,856 - Epoch: [59][  100/  267]    Overall Loss 2.357038    Objective Loss 2.357038                                        LR 0.100000    Time 0.231080    
2024-04-23 17:07:40,884 - Epoch: [59][  110/  267]    Overall Loss 2.357551    Objective Loss 2.357551                                        LR 0.100000    Time 0.228479    
2024-04-23 17:07:43,479 - Epoch: [59][  120/  267]    Overall Loss 2.357543    Objective Loss 2.357543                                        LR 0.100000    Time 0.231037    
2024-04-23 17:07:45,398 - Epoch: [59][  130/  267]    Overall Loss 2.353338    Objective Loss 2.353338                                        LR 0.100000    Time 0.228003    
2024-04-23 17:07:48,091 - Epoch: [59][  140/  267]    Overall Loss 2.353248    Objective Loss 2.353248                                        LR 0.100000    Time 0.230935    
2024-04-23 17:07:50,134 - Epoch: [59][  150/  267]    Overall Loss 2.351241    Objective Loss 2.351241                                        LR 0.100000    Time 0.229138    
2024-04-23 17:07:52,835 - Epoch: [59][  160/  267]    Overall Loss 2.352100    Objective Loss 2.352100                                        LR 0.100000    Time 0.231681    
2024-04-23 17:07:54,734 - Epoch: [59][  170/  267]    Overall Loss 2.351897    Objective Loss 2.351897                                        LR 0.100000    Time 0.229209    
2024-04-23 17:07:57,438 - Epoch: [59][  180/  267]    Overall Loss 2.352042    Objective Loss 2.352042                                        LR 0.100000    Time 0.231472    
2024-04-23 17:07:58,751 - Epoch: [46][  100/  296]    Overall Loss 0.989396    Objective Loss 0.989396                                        LR 0.000320    Time 0.260644    
2024-04-23 17:07:59,289 - Epoch: [59][  190/  267]    Overall Loss 2.353810    Objective Loss 2.353810                                        LR 0.100000    Time 0.229011    
2024-04-23 17:08:01,947 - Epoch: [59][  200/  267]    Overall Loss 2.353439    Objective Loss 2.353439                                        LR 0.100000    Time 0.230835    
2024-04-23 17:08:03,781 - Epoch: [59][  210/  267]    Overall Loss 2.353113    Objective Loss 2.353113                                        LR 0.100000    Time 0.228564    
2024-04-23 17:08:06,330 - Epoch: [59][  220/  267]    Overall Loss 2.353246    Objective Loss 2.353246                                        LR 0.100000    Time 0.229744    
2024-04-23 17:08:07,795 - Epoch: [59][  230/  267]    Overall Loss 2.354632    Objective Loss 2.354632                                        LR 0.100000    Time 0.226110    
2024-04-23 17:08:10,399 - Epoch: [59][  240/  267]    Overall Loss 2.354824    Objective Loss 2.354824                                        LR 0.100000    Time 0.227526    
2024-04-23 17:08:12,287 - Epoch: [59][  250/  267]    Overall Loss 2.356873    Objective Loss 2.356873                                        LR 0.100000    Time 0.225965    
2024-04-23 17:08:14,294 - Epoch: [59][  260/  267]    Overall Loss 2.356564    Objective Loss 2.356564                                        LR 0.100000    Time 0.224985    
2024-04-23 17:08:15,264 - Epoch: [59][  267/  267]    Overall Loss 2.358678    Objective Loss 2.358678    Top1 2.325581    Top5 34.883721    LR 0.100000    Time 0.222707    
2024-04-23 17:08:15,535 - --- validate (epoch=59)-----------
2024-04-23 17:08:15,536 - 946 samples (32 per mini-batch)
2024-04-23 17:08:20,422 - Epoch: [59][   10/   30]    Loss 2.360058    Top1 9.687500    Top5 54.375000    
2024-04-23 17:08:23,021 - Epoch: [59][   20/   30]    Loss 2.354101    Top1 10.937500    Top5 53.750000    
2024-04-23 17:08:26,662 - Epoch: [59][   30/   30]    Loss 2.366952    Top1 10.359408    Top5 52.642706    
2024-04-23 17:08:26,896 - ==> Top1: 10.359    Top5: 52.643    Loss: 2.367

2024-04-23 17:08:26,899 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 17:08:26,905 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:08:26,905 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:08:26,926 - 

2024-04-23 17:08:26,928 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:08:27,096 - Epoch: [46][  200/  296]    Overall Loss 0.981214    Objective Loss 0.981214                                        LR 0.000320    Time 0.271938    
2024-04-23 17:08:32,251 - Epoch: [60][   10/  267]    Overall Loss 2.402805    Objective Loss 2.402805                                        LR 0.100000    Time 0.531818    
2024-04-23 17:08:35,208 - Epoch: [60][   20/  267]    Overall Loss 2.372894    Objective Loss 2.372894                                        LR 0.100000    Time 0.413592    
2024-04-23 17:08:39,066 - Epoch: [60][   30/  267]    Overall Loss 2.363533    Objective Loss 2.363533                                        LR 0.100000    Time 0.404225    
2024-04-23 17:08:41,755 - Epoch: [60][   40/  267]    Overall Loss 2.361576    Objective Loss 2.361576                                        LR 0.100000    Time 0.370304    
2024-04-23 17:08:45,062 - Epoch: [60][   50/  267]    Overall Loss 2.362030    Objective Loss 2.362030                                        LR 0.100000    Time 0.362320    
2024-04-23 17:08:47,489 - Epoch: [60][   60/  267]    Overall Loss 2.367557    Objective Loss 2.367557                                        LR 0.100000    Time 0.342334    
2024-04-23 17:08:50,428 - Epoch: [60][   70/  267]    Overall Loss 2.365123    Objective Loss 2.365123                                        LR 0.100000    Time 0.335369    
2024-04-23 17:08:52,114 - Epoch: [60][   80/  267]    Overall Loss 2.366780    Objective Loss 2.366780                                        LR 0.100000    Time 0.314496    
2024-04-23 17:08:54,636 - Epoch: [60][   90/  267]    Overall Loss 2.359520    Objective Loss 2.359520                                        LR 0.100000    Time 0.307536    
2024-04-23 17:08:55,097 - Epoch: [46][  296/  296]    Overall Loss 0.986918    Objective Loss 0.986918    Top1 75.409836    Top5 98.360656    LR 0.000320    Time 0.278272    
2024-04-23 17:08:55,427 - --- validate (epoch=46)-----------
2024-04-23 17:08:55,428 - 3925 samples (32 per mini-batch)
2024-04-23 17:08:56,651 - Epoch: [60][  100/  267]    Overall Loss 2.364384    Objective Loss 2.364384                                        LR 0.100000    Time 0.296899    
2024-04-23 17:08:59,591 - Epoch: [60][  110/  267]    Overall Loss 2.362274    Objective Loss 2.362274                                        LR 0.100000    Time 0.296608    
2024-04-23 17:09:01,735 - Epoch: [60][  120/  267]    Overall Loss 2.360067    Objective Loss 2.360067                                        LR 0.100000    Time 0.289725    
2024-04-23 17:09:04,478 - Epoch: [60][  130/  267]    Overall Loss 2.360546    Objective Loss 2.360546                                        LR 0.100000    Time 0.288515    
2024-04-23 17:09:07,016 - Epoch: [60][  140/  267]    Overall Loss 2.362150    Objective Loss 2.362150                                        LR 0.100000    Time 0.286013    
2024-04-23 17:09:09,800 - Epoch: [60][  150/  267]    Overall Loss 2.360217    Objective Loss 2.360217                                        LR 0.100000    Time 0.285487    
2024-04-23 17:09:13,134 - Epoch: [60][  160/  267]    Overall Loss 2.360136    Objective Loss 2.360136                                        LR 0.100000    Time 0.288460    
2024-04-23 17:09:15,528 - Epoch: [60][  170/  267]    Overall Loss 2.360285    Objective Loss 2.360285                                        LR 0.100000    Time 0.285555    
2024-04-23 17:09:18,764 - Epoch: [60][  180/  267]    Overall Loss 2.360978    Objective Loss 2.360978                                        LR 0.100000    Time 0.287648    
2024-04-23 17:09:21,042 - Epoch: [60][  190/  267]    Overall Loss 2.361317    Objective Loss 2.361317                                        LR 0.100000    Time 0.284480    
2024-04-23 17:09:24,327 - Epoch: [60][  200/  267]    Overall Loss 2.361611    Objective Loss 2.361611                                        LR 0.100000    Time 0.286663    
2024-04-23 17:09:25,550 - Epoch: [46][  100/  123]    Loss 0.839193    Top1 72.562500    Top5 95.937500    
2024-04-23 17:09:26,717 - Epoch: [60][  210/  267]    Overall Loss 2.362723    Objective Loss 2.362723                                        LR 0.100000    Time 0.284383    
2024-04-23 17:09:29,998 - Epoch: [60][  220/  267]    Overall Loss 2.362318    Objective Loss 2.362318                                        LR 0.100000    Time 0.286351    
2024-04-23 17:09:31,649 - Epoch: [46][  123/  123]    Loss 0.829104    Top1 72.738854    Top5 95.898089    
2024-04-23 17:09:31,991 - ==> Top1: 72.739    Top5: 95.898    Loss: 0.829

2024-04-23 17:09:31,998 - ==> Best [Top1: 72.968   Top5: 96.127   Sparsity:0.00   Params: 376752 on epoch: 43]
2024-04-23 17:09:31,998 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:09:32,046 - 

2024-04-23 17:09:32,047 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:09:32,257 - Epoch: [60][  230/  267]    Overall Loss 2.362827    Objective Loss 2.362827                                        LR 0.100000    Time 0.283712    
2024-04-23 17:09:35,119 - Epoch: [60][  240/  267]    Overall Loss 2.363448    Objective Loss 2.363448                                        LR 0.100000    Time 0.283805    
2024-04-23 17:09:36,840 - Epoch: [60][  250/  267]    Overall Loss 2.362997    Objective Loss 2.362997                                        LR 0.100000    Time 0.279326    
2024-04-23 17:09:39,467 - Epoch: [60][  260/  267]    Overall Loss 2.365253    Objective Loss 2.365253                                        LR 0.100000    Time 0.278676    
2024-04-23 17:09:40,427 - Epoch: [60][  267/  267]    Overall Loss 2.365115    Objective Loss 2.365115    Top1 9.302326    Top5 60.465116    LR 0.100000    Time 0.274956    
2024-04-23 17:09:40,671 - --- validate (epoch=60)-----------
2024-04-23 17:09:40,672 - 946 samples (32 per mini-batch)
2024-04-23 17:09:45,012 - Epoch: [60][   10/   30]    Loss 2.440823    Top1 9.375000    Top5 49.375000    
2024-04-23 17:09:47,536 - Epoch: [60][   20/   30]    Loss 2.405386    Top1 9.375000    Top5 50.937500    
2024-04-23 17:09:50,364 - Epoch: [60][   30/   30]    Loss 2.405878    Top1 9.830867    Top5 50.317125    
2024-04-23 17:09:50,580 - ==> Top1: 9.831    Top5: 50.317    Loss: 2.406

2024-04-23 17:09:50,583 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 17:09:50,588 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:09:50,589 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:09:50,610 - 

2024-04-23 17:09:50,612 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:09:55,099 - Epoch: [61][   10/  267]    Overall Loss 2.367168    Objective Loss 2.367168                                        LR 0.100000    Time 0.448349    
2024-04-23 17:09:57,608 - Epoch: [61][   20/  267]    Overall Loss 2.363260    Objective Loss 2.363260                                        LR 0.100000    Time 0.349399    
2024-04-23 17:10:00,329 - Epoch: [61][   30/  267]    Overall Loss 2.352940    Objective Loss 2.352940                                        LR 0.100000    Time 0.323517    
2024-04-23 17:10:00,504 - Epoch: [47][  100/  296]    Overall Loss 0.990744    Objective Loss 0.990744                                        LR 0.000320    Time 0.284365    
2024-04-23 17:10:02,257 - Epoch: [61][   40/  267]    Overall Loss 2.357754    Objective Loss 2.357754                                        LR 0.100000    Time 0.290777    
2024-04-23 17:10:04,983 - Epoch: [61][   50/  267]    Overall Loss 2.358253    Objective Loss 2.358253                                        LR 0.100000    Time 0.287071    
2024-04-23 17:10:07,421 - Epoch: [61][   60/  267]    Overall Loss 2.365003    Objective Loss 2.365003                                        LR 0.100000    Time 0.279813    
2024-04-23 17:10:10,557 - Epoch: [61][   70/  267]    Overall Loss 2.365610    Objective Loss 2.365610                                        LR 0.100000    Time 0.284589    
2024-04-23 17:10:12,823 - Epoch: [61][   80/  267]    Overall Loss 2.364936    Objective Loss 2.364936                                        LR 0.100000    Time 0.277309    
2024-04-23 17:10:16,134 - Epoch: [61][   90/  267]    Overall Loss 2.363802    Objective Loss 2.363802                                        LR 0.100000    Time 0.283243    
2024-04-23 17:10:18,393 - Epoch: [61][  100/  267]    Overall Loss 2.362183    Objective Loss 2.362183                                        LR 0.100000    Time 0.277479    
2024-04-23 17:10:21,225 - Epoch: [61][  110/  267]    Overall Loss 2.358872    Objective Loss 2.358872                                        LR 0.100000    Time 0.277977    
2024-04-23 17:10:23,679 - Epoch: [61][  120/  267]    Overall Loss 2.358170    Objective Loss 2.358170                                        LR 0.100000    Time 0.275232    
2024-04-23 17:10:26,582 - Epoch: [47][  200/  296]    Overall Loss 1.001811    Objective Loss 1.001811                                        LR 0.000320    Time 0.272477    
2024-04-23 17:10:27,110 - Epoch: [61][  130/  267]    Overall Loss 2.357497    Objective Loss 2.357497                                        LR 0.100000    Time 0.280432    
2024-04-23 17:10:29,207 - Epoch: [61][  140/  267]    Overall Loss 2.358401    Objective Loss 2.358401                                        LR 0.100000    Time 0.275357    
2024-04-23 17:10:32,172 - Epoch: [61][  150/  267]    Overall Loss 2.360569    Objective Loss 2.360569                                        LR 0.100000    Time 0.276718    
2024-04-23 17:10:34,356 - Epoch: [61][  160/  267]    Overall Loss 2.358965    Objective Loss 2.358965                                        LR 0.100000    Time 0.273055    
2024-04-23 17:10:37,274 - Epoch: [61][  170/  267]    Overall Loss 2.359692    Objective Loss 2.359692                                        LR 0.100000    Time 0.274140    
2024-04-23 17:10:39,408 - Epoch: [61][  180/  267]    Overall Loss 2.360327    Objective Loss 2.360327                                        LR 0.100000    Time 0.270751    
2024-04-23 17:10:42,308 - Epoch: [61][  190/  267]    Overall Loss 2.362278    Objective Loss 2.362278                                        LR 0.100000    Time 0.271744    
2024-04-23 17:10:44,447 - Epoch: [61][  200/  267]    Overall Loss 2.361169    Objective Loss 2.361169                                        LR 0.100000    Time 0.268839    
2024-04-23 17:10:47,343 - Epoch: [61][  210/  267]    Overall Loss 2.362369    Objective Loss 2.362369                                        LR 0.100000    Time 0.269814    
2024-04-23 17:10:48,828 - Epoch: [61][  220/  267]    Overall Loss 2.362879    Objective Loss 2.362879                                        LR 0.100000    Time 0.264288    
2024-04-23 17:10:51,054 - Epoch: [61][  230/  267]    Overall Loss 2.365561    Objective Loss 2.365561                                        LR 0.100000    Time 0.262459    
2024-04-23 17:10:52,560 - Epoch: [47][  296/  296]    Overall Loss 1.005685    Objective Loss 1.005685    Top1 72.131148    Top5 100.000000    LR 0.000320    Time 0.271800    
2024-04-23 17:10:52,940 - --- validate (epoch=47)-----------
2024-04-23 17:10:52,941 - 3925 samples (32 per mini-batch)
2024-04-23 17:10:53,035 - Epoch: [61][  240/  267]    Overall Loss 2.364064    Objective Loss 2.364064                                        LR 0.100000    Time 0.259766    
2024-04-23 17:10:55,419 - Epoch: [61][  250/  267]    Overall Loss 2.363403    Objective Loss 2.363403                                        LR 0.100000    Time 0.258900    
2024-04-23 17:10:57,056 - Epoch: [61][  260/  267]    Overall Loss 2.364836    Objective Loss 2.364836                                        LR 0.100000    Time 0.255230    
2024-04-23 17:10:58,583 - Epoch: [61][  267/  267]    Overall Loss 2.364121    Objective Loss 2.364121    Top1 2.325581    Top5 41.860465    LR 0.100000    Time 0.254249    
2024-04-23 17:10:58,782 - --- validate (epoch=61)-----------
2024-04-23 17:10:58,783 - 946 samples (32 per mini-batch)
2024-04-23 17:11:01,913 - Epoch: [61][   10/   30]    Loss 2.300846    Top1 10.937500    Top5 56.250000    
2024-04-23 17:11:04,059 - Epoch: [61][   20/   30]    Loss 2.323625    Top1 10.937500    Top5 52.968750    
2024-04-23 17:11:06,453 - Epoch: [61][   30/   30]    Loss 2.332753    Top1 10.570825    Top5 50.951374    
2024-04-23 17:11:06,636 - ==> Top1: 10.571    Top5: 50.951    Loss: 2.333

2024-04-23 17:11:06,638 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 17:11:06,642 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:11:06,642 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:11:06,658 - 

2024-04-23 17:11:06,659 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:11:10,073 - Epoch: [62][   10/  267]    Overall Loss 2.377985    Objective Loss 2.377985                                        LR 0.100000    Time 0.340927    
2024-04-23 17:11:11,779 - Epoch: [62][   20/  267]    Overall Loss 2.365956    Objective Loss 2.365956                                        LR 0.100000    Time 0.255617    
2024-04-23 17:11:14,423 - Epoch: [62][   30/  267]    Overall Loss 2.364910    Objective Loss 2.364910                                        LR 0.100000    Time 0.258440    
2024-04-23 17:11:16,111 - Epoch: [62][   40/  267]    Overall Loss 2.362271    Objective Loss 2.362271                                        LR 0.100000    Time 0.235947    
2024-04-23 17:11:18,892 - Epoch: [62][   50/  267]    Overall Loss 2.359599    Objective Loss 2.359599                                        LR 0.100000    Time 0.244293    
2024-04-23 17:11:19,923 - Epoch: [47][  100/  123]    Loss 0.837585    Top1 72.312500    Top5 96.468750    
2024-04-23 17:11:20,497 - Epoch: [62][   60/  267]    Overall Loss 2.360466    Objective Loss 2.360466                                        LR 0.100000    Time 0.230282    
2024-04-23 17:11:22,790 - Epoch: [62][   70/  267]    Overall Loss 2.357213    Objective Loss 2.357213                                        LR 0.100000    Time 0.230095    
2024-04-23 17:11:24,542 - Epoch: [62][   80/  267]    Overall Loss 2.355714    Objective Loss 2.355714                                        LR 0.100000    Time 0.223204    
2024-04-23 17:11:26,028 - Epoch: [47][  123/  123]    Loss 0.842308    Top1 72.203822    Top5 96.433121    
2024-04-23 17:11:26,268 - ==> Top1: 72.204    Top5: 96.433    Loss: 0.842

2024-04-23 17:11:26,275 - ==> Best [Top1: 72.968   Top5: 96.127   Sparsity:0.00   Params: 376752 on epoch: 43]
2024-04-23 17:11:26,276 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:11:26,343 - 

2024-04-23 17:11:26,344 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:11:26,914 - Epoch: [62][   90/  267]    Overall Loss 2.357438    Objective Loss 2.357438                                        LR 0.100000    Time 0.224728    
2024-04-23 17:11:28,675 - Epoch: [62][  100/  267]    Overall Loss 2.357304    Objective Loss 2.357304                                        LR 0.100000    Time 0.219839    
2024-04-23 17:11:31,369 - Epoch: [62][  110/  267]    Overall Loss 2.361827    Objective Loss 2.361827                                        LR 0.100000    Time 0.224316    
2024-04-23 17:11:33,506 - Epoch: [62][  120/  267]    Overall Loss 2.360897    Objective Loss 2.360897                                        LR 0.100000    Time 0.223406    
2024-04-23 17:11:36,552 - Epoch: [62][  130/  267]    Overall Loss 2.362231    Objective Loss 2.362231                                        LR 0.100000    Time 0.229632    
2024-04-23 17:11:38,049 - Epoch: [62][  140/  267]    Overall Loss 2.364288    Objective Loss 2.364288                                        LR 0.100000    Time 0.223903    
2024-04-23 17:11:40,704 - Epoch: [62][  150/  267]    Overall Loss 2.364081    Objective Loss 2.364081                                        LR 0.100000    Time 0.226654    
2024-04-23 17:11:42,699 - Epoch: [62][  160/  267]    Overall Loss 2.360512    Objective Loss 2.360512                                        LR 0.100000    Time 0.224935    
2024-04-23 17:11:45,181 - Epoch: [62][  170/  267]    Overall Loss 2.360137    Objective Loss 2.360137                                        LR 0.100000    Time 0.226287    
2024-04-23 17:11:46,555 - Epoch: [62][  180/  267]    Overall Loss 2.360414    Objective Loss 2.360414                                        LR 0.100000    Time 0.221336    
2024-04-23 17:11:49,209 - Epoch: [62][  190/  267]    Overall Loss 2.362831    Objective Loss 2.362831                                        LR 0.100000    Time 0.223642    
2024-04-23 17:11:51,546 - Epoch: [62][  200/  267]    Overall Loss 2.362128    Objective Loss 2.362128                                        LR 0.100000    Time 0.224128    
2024-04-23 17:11:51,630 - Epoch: [48][  100/  296]    Overall Loss 0.982886    Objective Loss 0.982886                                        LR 0.000320    Time 0.252640    
2024-04-23 17:11:53,328 - Epoch: [62][  210/  267]    Overall Loss 2.362679    Objective Loss 2.362679                                        LR 0.100000    Time 0.221926    
2024-04-23 17:11:55,779 - Epoch: [62][  220/  267]    Overall Loss 2.363988    Objective Loss 2.363988                                        LR 0.100000    Time 0.222965    
2024-04-23 17:11:58,089 - Epoch: [62][  230/  267]    Overall Loss 2.365463    Objective Loss 2.365463                                        LR 0.100000    Time 0.223297    
2024-04-23 17:12:00,671 - Epoch: [62][  240/  267]    Overall Loss 2.364447    Objective Loss 2.364447                                        LR 0.100000    Time 0.224739    
2024-04-23 17:12:02,493 - Epoch: [62][  250/  267]    Overall Loss 2.363478    Objective Loss 2.363478                                        LR 0.100000    Time 0.223028    
2024-04-23 17:12:05,648 - Epoch: [62][  260/  267]    Overall Loss 2.362917    Objective Loss 2.362917                                        LR 0.100000    Time 0.226570    
2024-04-23 17:12:06,685 - Epoch: [62][  267/  267]    Overall Loss 2.363026    Objective Loss 2.363026    Top1 6.976744    Top5 39.534884    LR 0.100000    Time 0.224504    
2024-04-23 17:12:06,896 - --- validate (epoch=62)-----------
2024-04-23 17:12:06,897 - 946 samples (32 per mini-batch)
2024-04-23 17:12:10,615 - Epoch: [62][   10/   30]    Loss 2.464452    Top1 7.812500    Top5 51.250000    
2024-04-23 17:12:13,112 - Epoch: [62][   20/   30]    Loss 2.456126    Top1 8.906250    Top5 51.718750    
2024-04-23 17:12:14,918 - Epoch: [48][  200/  296]    Overall Loss 0.983306    Objective Loss 0.983306                                        LR 0.000320    Time 0.242660    
2024-04-23 17:12:15,458 - Epoch: [62][   30/   30]    Loss 2.437870    Top1 9.196617    Top5 51.585624    
2024-04-23 17:12:15,669 - ==> Top1: 9.197    Top5: 51.586    Loss: 2.438

2024-04-23 17:12:15,671 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 17:12:15,676 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:12:15,677 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:12:15,693 - 

2024-04-23 17:12:15,695 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:12:19,626 - Epoch: [63][   10/  267]    Overall Loss 2.340066    Objective Loss 2.340066                                        LR 0.100000    Time 0.392699    
2024-04-23 17:12:21,967 - Epoch: [63][   20/  267]    Overall Loss 2.360884    Objective Loss 2.360884                                        LR 0.100000    Time 0.313209    
2024-04-23 17:12:24,615 - Epoch: [63][   30/  267]    Overall Loss 2.368492    Objective Loss 2.368492                                        LR 0.100000    Time 0.296985    
2024-04-23 17:12:27,297 - Epoch: [63][   40/  267]    Overall Loss 2.364288    Objective Loss 2.364288                                        LR 0.100000    Time 0.289683    
2024-04-23 17:12:29,759 - Epoch: [63][   50/  267]    Overall Loss 2.363932    Objective Loss 2.363932                                        LR 0.100000    Time 0.280931    
2024-04-23 17:12:32,536 - Epoch: [63][   60/  267]    Overall Loss 2.361922    Objective Loss 2.361922                                        LR 0.100000    Time 0.280335    
2024-04-23 17:12:35,192 - Epoch: [63][   70/  267]    Overall Loss 2.366716    Objective Loss 2.366716                                        LR 0.100000    Time 0.278178    
2024-04-23 17:12:38,058 - Epoch: [63][   80/  267]    Overall Loss 2.364914    Objective Loss 2.364914                                        LR 0.100000    Time 0.279177    
2024-04-23 17:12:39,414 - Epoch: [48][  296/  296]    Overall Loss 0.987091    Objective Loss 0.987091    Top1 60.655738    Top5 93.442623    LR 0.000320    Time 0.246647    
2024-04-23 17:12:39,725 - --- validate (epoch=48)-----------
2024-04-23 17:12:39,726 - 3925 samples (32 per mini-batch)
2024-04-23 17:12:40,470 - Epoch: [63][   90/  267]    Overall Loss 2.364669    Objective Loss 2.364669                                        LR 0.100000    Time 0.274920    
2024-04-23 17:12:43,774 - Epoch: [63][  100/  267]    Overall Loss 2.362972    Objective Loss 2.362972                                        LR 0.100000    Time 0.280432    
2024-04-23 17:12:46,079 - Epoch: [63][  110/  267]    Overall Loss 2.361072    Objective Loss 2.361072                                        LR 0.100000    Time 0.275857    
2024-04-23 17:12:49,039 - Epoch: [63][  120/  267]    Overall Loss 2.366457    Objective Loss 2.366457                                        LR 0.100000    Time 0.277511    
2024-04-23 17:12:51,000 - Epoch: [63][  130/  267]    Overall Loss 2.364863    Objective Loss 2.364863                                        LR 0.100000    Time 0.271224    
2024-04-23 17:12:54,021 - Epoch: [63][  140/  267]    Overall Loss 2.363653    Objective Loss 2.363653                                        LR 0.100000    Time 0.273407    
2024-04-23 17:12:56,006 - Epoch: [63][  150/  267]    Overall Loss 2.365109    Objective Loss 2.365109                                        LR 0.100000    Time 0.268394    
2024-04-23 17:12:58,757 - Epoch: [63][  160/  267]    Overall Loss 2.364594    Objective Loss 2.364594                                        LR 0.100000    Time 0.268794    
2024-04-23 17:13:00,300 - Epoch: [63][  170/  267]    Overall Loss 2.363045    Objective Loss 2.363045                                        LR 0.100000    Time 0.262044    
2024-04-23 17:13:03,336 - Epoch: [63][  180/  267]    Overall Loss 2.363483    Objective Loss 2.363483                                        LR 0.100000    Time 0.264333    
2024-04-23 17:13:05,374 - Epoch: [63][  190/  267]    Overall Loss 2.362608    Objective Loss 2.362608                                        LR 0.100000    Time 0.261129    
2024-04-23 17:13:07,835 - Epoch: [48][  100/  123]    Loss 0.809214    Top1 73.437500    Top5 96.156250    
2024-04-23 17:13:08,433 - Epoch: [63][  200/  267]    Overall Loss 2.362926    Objective Loss 2.362926                                        LR 0.100000    Time 0.263356    
2024-04-23 17:13:10,431 - Epoch: [63][  210/  267]    Overall Loss 2.361134    Objective Loss 2.361134                                        LR 0.100000    Time 0.260311    
2024-04-23 17:13:12,899 - Epoch: [48][  123/  123]    Loss 0.804424    Top1 73.528662    Top5 96.229299    
2024-04-23 17:13:13,052 - Epoch: [63][  220/  267]    Overall Loss 2.359410    Objective Loss 2.359410                                        LR 0.100000    Time 0.260381    
2024-04-23 17:13:13,084 - ==> Top1: 73.529    Top5: 96.229    Loss: 0.804

2024-04-23 17:13:13,099 - ==> Best [Top1: 73.529   Top5: 96.229   Sparsity:0.00   Params: 376752 on epoch: 48]
2024-04-23 17:13:13,100 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:13:13,209 - 

2024-04-23 17:13:13,210 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:13:15,116 - Epoch: [63][  230/  267]    Overall Loss 2.357908    Objective Loss 2.357908                                        LR 0.100000    Time 0.258020    
2024-04-23 17:13:18,215 - Epoch: [63][  240/  267]    Overall Loss 2.358154    Objective Loss 2.358154                                        LR 0.100000    Time 0.260164    
2024-04-23 17:13:20,926 - Epoch: [63][  250/  267]    Overall Loss 2.358991    Objective Loss 2.358991                                        LR 0.100000    Time 0.260591    
2024-04-23 17:13:25,208 - Epoch: [63][  260/  267]    Overall Loss 2.360071    Objective Loss 2.360071                                        LR 0.100000    Time 0.267028    
2024-04-23 17:13:26,738 - Epoch: [63][  267/  267]    Overall Loss 2.359435    Objective Loss 2.359435    Top1 13.953488    Top5 51.162791    LR 0.100000    Time 0.265747    
2024-04-23 17:13:27,039 - --- validate (epoch=63)-----------
2024-04-23 17:13:27,040 - 946 samples (32 per mini-batch)
2024-04-23 17:13:31,434 - Epoch: [63][   10/   30]    Loss 2.339426    Top1 13.750000    Top5 51.562500    
2024-04-23 17:13:34,152 - Epoch: [63][   20/   30]    Loss 2.349863    Top1 11.875000    Top5 50.937500    
2024-04-23 17:13:37,342 - Epoch: [63][   30/   30]    Loss 2.360041    Top1 10.993658    Top5 49.788584    
2024-04-23 17:13:37,570 - ==> Top1: 10.994    Top5: 49.789    Loss: 2.360

2024-04-23 17:13:37,572 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 17:13:37,577 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:13:37,578 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:13:37,597 - 

2024-04-23 17:13:37,598 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:13:42,551 - Epoch: [64][   10/  267]    Overall Loss 2.422258    Objective Loss 2.422258                                        LR 0.100000    Time 0.494931    
2024-04-23 17:13:45,296 - Epoch: [64][   20/  267]    Overall Loss 2.386328    Objective Loss 2.386328                                        LR 0.100000    Time 0.384523    
2024-04-23 17:13:45,589 - Epoch: [49][  100/  296]    Overall Loss 0.971740    Objective Loss 0.971740                                        LR 0.000320    Time 0.323577    
2024-04-23 17:13:48,743 - Epoch: [64][   30/  267]    Overall Loss 2.373296    Objective Loss 2.373296                                        LR 0.100000    Time 0.371155    
2024-04-23 17:13:51,176 - Epoch: [64][   40/  267]    Overall Loss 2.367968    Objective Loss 2.367968                                        LR 0.100000    Time 0.339097    
2024-04-23 17:13:54,441 - Epoch: [64][   50/  267]    Overall Loss 2.360482    Objective Loss 2.360482                                        LR 0.100000    Time 0.336520    
2024-04-23 17:13:56,508 - Epoch: [64][   60/  267]    Overall Loss 2.363516    Objective Loss 2.363516                                        LR 0.100000    Time 0.314829    
2024-04-23 17:13:59,718 - Epoch: [64][   70/  267]    Overall Loss 2.366938    Objective Loss 2.366938                                        LR 0.100000    Time 0.315677    
2024-04-23 17:14:02,102 - Epoch: [64][   80/  267]    Overall Loss 2.365654    Objective Loss 2.365654                                        LR 0.100000    Time 0.305969    
2024-04-23 17:14:04,998 - Epoch: [64][   90/  267]    Overall Loss 2.367879    Objective Loss 2.367879                                        LR 0.100000    Time 0.304113    
2024-04-23 17:14:07,571 - Epoch: [64][  100/  267]    Overall Loss 2.366522    Objective Loss 2.366522                                        LR 0.100000    Time 0.299405    
2024-04-23 17:14:11,009 - Epoch: [64][  110/  267]    Overall Loss 2.362549    Objective Loss 2.362549                                        LR 0.100000    Time 0.303401    
2024-04-23 17:14:13,433 - Epoch: [49][  200/  296]    Overall Loss 0.977853    Objective Loss 0.977853                                        LR 0.000320    Time 0.300895    
2024-04-23 17:14:13,646 - Epoch: [64][  120/  267]    Overall Loss 2.361643    Objective Loss 2.361643                                        LR 0.100000    Time 0.300046    
2024-04-23 17:14:16,828 - Epoch: [64][  130/  267]    Overall Loss 2.364605    Objective Loss 2.364605                                        LR 0.100000    Time 0.301419    
2024-04-23 17:14:19,095 - Epoch: [64][  140/  267]    Overall Loss 2.363527    Objective Loss 2.363527                                        LR 0.100000    Time 0.296056    
2024-04-23 17:14:22,386 - Epoch: [64][  150/  267]    Overall Loss 2.363910    Objective Loss 2.363910                                        LR 0.100000    Time 0.298241    
2024-04-23 17:14:24,598 - Epoch: [64][  160/  267]    Overall Loss 2.362010    Objective Loss 2.362010                                        LR 0.100000    Time 0.293402    
2024-04-23 17:14:27,931 - Epoch: [64][  170/  267]    Overall Loss 2.362465    Objective Loss 2.362465                                        LR 0.100000    Time 0.295737    
2024-04-23 17:14:30,096 - Epoch: [64][  180/  267]    Overall Loss 2.361867    Objective Loss 2.361867                                        LR 0.100000    Time 0.291321    
2024-04-23 17:14:33,063 - Epoch: [64][  190/  267]    Overall Loss 2.361376    Objective Loss 2.361376                                        LR 0.100000    Time 0.291589    
2024-04-23 17:14:35,550 - Epoch: [64][  200/  267]    Overall Loss 2.359359    Objective Loss 2.359359                                        LR 0.100000    Time 0.289426    
2024-04-23 17:14:38,793 - Epoch: [64][  210/  267]    Overall Loss 2.358551    Objective Loss 2.358551                                        LR 0.100000    Time 0.291073    
2024-04-23 17:14:39,850 - Epoch: [49][  296/  296]    Overall Loss 0.997200    Objective Loss 0.997200    Top1 73.770492    Top5 91.803279    LR 0.000320    Time 0.292481    
2024-04-23 17:14:40,175 - --- validate (epoch=49)-----------
2024-04-23 17:14:40,177 - 3925 samples (32 per mini-batch)
2024-04-23 17:14:40,755 - Epoch: [64][  220/  267]    Overall Loss 2.358414    Objective Loss 2.358414                                        LR 0.100000    Time 0.286746    
2024-04-23 17:14:44,322 - Epoch: [64][  230/  267]    Overall Loss 2.358302    Objective Loss 2.358302                                        LR 0.100000    Time 0.289774    
2024-04-23 17:14:46,927 - Epoch: [64][  240/  267]    Overall Loss 2.358668    Objective Loss 2.358668                                        LR 0.100000    Time 0.288537    
2024-04-23 17:14:50,359 - Epoch: [64][  250/  267]    Overall Loss 2.358826    Objective Loss 2.358826                                        LR 0.100000    Time 0.290714    
2024-04-23 17:14:52,922 - Epoch: [64][  260/  267]    Overall Loss 2.359102    Objective Loss 2.359102                                        LR 0.100000    Time 0.289375    
2024-04-23 17:14:54,919 - Epoch: [64][  267/  267]    Overall Loss 2.359432    Objective Loss 2.359432    Top1 11.627907    Top5 48.837209    LR 0.100000    Time 0.289259    
2024-04-23 17:14:55,163 - --- validate (epoch=64)-----------
2024-04-23 17:14:55,164 - 946 samples (32 per mini-batch)
2024-04-23 17:14:59,671 - Epoch: [64][   10/   30]    Loss 2.324060    Top1 9.062500    Top5 49.375000    
2024-04-23 17:15:02,375 - Epoch: [64][   20/   30]    Loss 2.327869    Top1 10.156250    Top5 50.468750    
2024-04-23 17:15:05,174 - Epoch: [64][   30/   30]    Loss 2.327889    Top1 10.042283    Top5 49.894292    
2024-04-23 17:15:05,386 - ==> Top1: 10.042    Top5: 49.894    Loss: 2.328

2024-04-23 17:15:05,388 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 17:15:05,393 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:15:05,394 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:15:05,417 - 

2024-04-23 17:15:05,418 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:15:09,848 - Epoch: [65][   10/  267]    Overall Loss 2.373136    Objective Loss 2.373136                                        LR 0.100000    Time 0.442609    
2024-04-23 17:15:11,560 - Epoch: [49][  100/  123]    Loss 0.850324    Top1 72.093750    Top5 96.062500    
2024-04-23 17:15:12,098 - Epoch: [65][   20/  267]    Overall Loss 2.385688    Objective Loss 2.385688                                        LR 0.100000    Time 0.333650    
2024-04-23 17:15:15,229 - Epoch: [65][   30/  267]    Overall Loss 2.374649    Objective Loss 2.374649                                        LR 0.100000    Time 0.326707    
2024-04-23 17:15:17,538 - Epoch: [65][   40/  267]    Overall Loss 2.373217    Objective Loss 2.373217                                        LR 0.100000    Time 0.302671    
2024-04-23 17:15:17,969 - Epoch: [49][  123/  123]    Loss 0.830482    Top1 72.738854    Top5 96.407643    
2024-04-23 17:15:18,237 - ==> Top1: 72.739    Top5: 96.408    Loss: 0.830

2024-04-23 17:15:18,248 - ==> Best [Top1: 73.529   Top5: 96.229   Sparsity:0.00   Params: 376752 on epoch: 48]
2024-04-23 17:15:18,249 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:15:18,329 - 

2024-04-23 17:15:18,332 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:15:19,755 - Epoch: [65][   50/  267]    Overall Loss 2.367198    Objective Loss 2.367198                                        LR 0.100000    Time 0.286425    
2024-04-23 17:15:22,383 - Epoch: [65][   60/  267]    Overall Loss 2.362566    Objective Loss 2.362566                                        LR 0.100000    Time 0.282445    
2024-04-23 17:15:25,395 - Epoch: [65][   70/  267]    Overall Loss 2.363686    Objective Loss 2.363686                                        LR 0.100000    Time 0.285073    
2024-04-23 17:15:27,398 - Epoch: [65][   80/  267]    Overall Loss 2.369848    Objective Loss 2.369848                                        LR 0.100000    Time 0.274451    
2024-04-23 17:15:30,843 - Epoch: [65][   90/  267]    Overall Loss 2.366252    Objective Loss 2.366252                                        LR 0.100000    Time 0.282195    
2024-04-23 17:15:32,919 - Epoch: [65][  100/  267]    Overall Loss 2.361343    Objective Loss 2.361343                                        LR 0.100000    Time 0.274713    
2024-04-23 17:15:36,104 - Epoch: [65][  110/  267]    Overall Loss 2.359605    Objective Loss 2.359605                                        LR 0.100000    Time 0.278671    
2024-04-23 17:15:38,155 - Epoch: [65][  120/  267]    Overall Loss 2.362068    Objective Loss 2.362068                                        LR 0.100000    Time 0.272509    
2024-04-23 17:15:41,075 - Epoch: [65][  130/  267]    Overall Loss 2.360451    Objective Loss 2.360451                                        LR 0.100000    Time 0.273985    
2024-04-23 17:15:43,247 - Epoch: [65][  140/  267]    Overall Loss 2.360014    Objective Loss 2.360014                                        LR 0.100000    Time 0.269905    
2024-04-23 17:15:45,370 - Epoch: [50][  100/  296]    Overall Loss 0.986481    Objective Loss 0.986481                                        LR 0.000320    Time 0.270124    
2024-04-23 17:15:46,003 - Epoch: [65][  150/  267]    Overall Loss 2.359089    Objective Loss 2.359089                                        LR 0.100000    Time 0.270267    
2024-04-23 17:15:48,159 - Epoch: [65][  160/  267]    Overall Loss 2.361214    Objective Loss 2.361214                                        LR 0.100000    Time 0.266838    
2024-04-23 17:15:51,204 - Epoch: [65][  170/  267]    Overall Loss 2.360466    Objective Loss 2.360466                                        LR 0.100000    Time 0.269037    
2024-04-23 17:15:53,310 - Epoch: [65][  180/  267]    Overall Loss 2.361709    Objective Loss 2.361709                                        LR 0.100000    Time 0.265771    
2024-04-23 17:15:56,634 - Epoch: [65][  190/  267]    Overall Loss 2.361715    Objective Loss 2.361715                                        LR 0.100000    Time 0.269260    
2024-04-23 17:15:59,028 - Epoch: [65][  200/  267]    Overall Loss 2.360776    Objective Loss 2.360776                                        LR 0.100000    Time 0.267753    
2024-04-23 17:16:02,360 - Epoch: [65][  210/  267]    Overall Loss 2.361561    Objective Loss 2.361561                                        LR 0.100000    Time 0.270853    
2024-04-23 17:16:04,709 - Epoch: [65][  220/  267]    Overall Loss 2.361141    Objective Loss 2.361141                                        LR 0.100000    Time 0.269208    
2024-04-23 17:16:08,034 - Epoch: [65][  230/  267]    Overall Loss 2.360941    Objective Loss 2.360941                                        LR 0.100000    Time 0.271948    
2024-04-23 17:16:09,846 - Epoch: [65][  240/  267]    Overall Loss 2.362296    Objective Loss 2.362296                                        LR 0.100000    Time 0.268154    
2024-04-23 17:16:11,086 - Epoch: [50][  200/  296]    Overall Loss 0.993805    Objective Loss 0.993805                                        LR 0.000320    Time 0.263530    
2024-04-23 17:16:11,932 - Epoch: [65][  250/  267]    Overall Loss 2.362647    Objective Loss 2.362647                                        LR 0.100000    Time 0.265760    
2024-04-23 17:16:15,323 - Epoch: [65][  260/  267]    Overall Loss 2.363177    Objective Loss 2.363177                                        LR 0.100000    Time 0.268567    
2024-04-23 17:16:16,410 - Epoch: [65][  267/  267]    Overall Loss 2.362572    Objective Loss 2.362572    Top1 2.325581    Top5 55.813953    LR 0.100000    Time 0.265591    
2024-04-23 17:16:16,625 - --- validate (epoch=65)-----------
2024-04-23 17:16:16,626 - 946 samples (32 per mini-batch)
2024-04-23 17:16:20,785 - Epoch: [65][   10/   30]    Loss 2.351885    Top1 12.500000    Top5 48.125000    
2024-04-23 17:16:22,984 - Epoch: [65][   20/   30]    Loss 2.351251    Top1 11.093750    Top5 49.062500    
2024-04-23 17:16:25,796 - Epoch: [65][   30/   30]    Loss 2.357655    Top1 10.570825    Top5 48.520085    
2024-04-23 17:16:26,021 - ==> Top1: 10.571    Top5: 48.520    Loss: 2.358

2024-04-23 17:16:26,023 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 17:16:26,028 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:16:26,028 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:16:26,049 - 

2024-04-23 17:16:26,050 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:16:30,026 - Epoch: [66][   10/  267]    Overall Loss 2.351565    Objective Loss 2.351565                                        LR 0.100000    Time 0.397116    
2024-04-23 17:16:32,327 - Epoch: [66][   20/  267]    Overall Loss 2.356376    Objective Loss 2.356376                                        LR 0.100000    Time 0.313413    
2024-04-23 17:16:34,412 - Epoch: [50][  296/  296]    Overall Loss 0.979977    Objective Loss 0.979977    Top1 68.852459    Top5 95.081967    LR 0.000320    Time 0.256799    
2024-04-23 17:16:34,669 - --- validate (epoch=50)-----------
2024-04-23 17:16:34,670 - 3925 samples (32 per mini-batch)
2024-04-23 17:16:34,694 - Epoch: [66][   30/  267]    Overall Loss 2.354267    Objective Loss 2.354267                                        LR 0.100000    Time 0.287741    
2024-04-23 17:16:36,271 - Epoch: [66][   40/  267]    Overall Loss 2.355070    Objective Loss 2.355070                                        LR 0.100000    Time 0.255148    
2024-04-23 17:16:39,590 - Epoch: [66][   50/  267]    Overall Loss 2.355659    Objective Loss 2.355659                                        LR 0.100000    Time 0.270434    
2024-04-23 17:16:41,918 - Epoch: [66][   60/  267]    Overall Loss 2.367044    Objective Loss 2.367044                                        LR 0.100000    Time 0.264101    
2024-04-23 17:16:45,108 - Epoch: [66][   70/  267]    Overall Loss 2.369812    Objective Loss 2.369812                                        LR 0.100000    Time 0.271896    
2024-04-23 17:16:47,250 - Epoch: [66][   80/  267]    Overall Loss 2.367620    Objective Loss 2.367620                                        LR 0.100000    Time 0.264650    
2024-04-23 17:16:50,361 - Epoch: [66][   90/  267]    Overall Loss 2.374212    Objective Loss 2.374212                                        LR 0.100000    Time 0.269775    
2024-04-23 17:16:52,428 - Epoch: [66][  100/  267]    Overall Loss 2.372195    Objective Loss 2.372195                                        LR 0.100000    Time 0.263435    
2024-04-23 17:16:55,460 - Epoch: [66][  110/  267]    Overall Loss 2.370616    Objective Loss 2.370616                                        LR 0.100000    Time 0.267023    
2024-04-23 17:16:57,726 - Epoch: [66][  120/  267]    Overall Loss 2.369509    Objective Loss 2.369509                                        LR 0.100000    Time 0.263629    
2024-04-23 17:17:00,085 - Epoch: [66][  130/  267]    Overall Loss 2.366352    Objective Loss 2.366352                                        LR 0.100000    Time 0.261467    
2024-04-23 17:17:01,690 - Epoch: [66][  140/  267]    Overall Loss 2.368873    Objective Loss 2.368873                                        LR 0.100000    Time 0.254232    
2024-04-23 17:17:02,681 - Epoch: [50][  100/  123]    Loss 0.917292    Top1 69.312500    Top5 95.531250    
2024-04-23 17:17:04,239 - Epoch: [66][  150/  267]    Overall Loss 2.369595    Objective Loss 2.369595                                        LR 0.100000    Time 0.254254    
2024-04-23 17:17:06,120 - Epoch: [66][  160/  267]    Overall Loss 2.368073    Objective Loss 2.368073                                        LR 0.100000    Time 0.250096    
2024-04-23 17:17:08,121 - Epoch: [50][  123/  123]    Loss 0.913730    Top1 69.222930    Top5 95.796178    
2024-04-23 17:17:08,417 - Epoch: [66][  170/  267]    Overall Loss 2.367672    Objective Loss 2.367672                                        LR 0.100000    Time 0.248867    
2024-04-23 17:17:08,417 - ==> Top1: 69.223    Top5: 95.796    Loss: 0.914

2024-04-23 17:17:08,427 - ==> Best [Top1: 73.529   Top5: 96.229   Sparsity:0.00   Params: 376752 on epoch: 48]
2024-04-23 17:17:08,428 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:17:08,483 - 

2024-04-23 17:17:08,484 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:17:09,954 - Epoch: [66][  180/  267]    Overall Loss 2.367432    Objective Loss 2.367432                                        LR 0.100000    Time 0.243568    
2024-04-23 17:17:12,931 - Epoch: [66][  190/  267]    Overall Loss 2.366100    Objective Loss 2.366100                                        LR 0.100000    Time 0.246400    
2024-04-23 17:17:14,758 - Epoch: [66][  200/  267]    Overall Loss 2.367610    Objective Loss 2.367610                                        LR 0.100000    Time 0.243197    
2024-04-23 17:17:17,511 - Epoch: [66][  210/  267]    Overall Loss 2.369000    Objective Loss 2.369000                                        LR 0.100000    Time 0.244713    
2024-04-23 17:17:19,549 - Epoch: [66][  220/  267]    Overall Loss 2.369525    Objective Loss 2.369525                                        LR 0.100000    Time 0.242839    
2024-04-23 17:17:21,865 - Epoch: [66][  230/  267]    Overall Loss 2.369707    Objective Loss 2.369707                                        LR 0.100000    Time 0.242339    
2024-04-23 17:17:23,973 - Epoch: [66][  240/  267]    Overall Loss 2.369107    Objective Loss 2.369107                                        LR 0.100000    Time 0.241013    
2024-04-23 17:17:26,039 - Epoch: [66][  250/  267]    Overall Loss 2.367730    Objective Loss 2.367730                                        LR 0.100000    Time 0.239625    
2024-04-23 17:17:28,464 - Epoch: [66][  260/  267]    Overall Loss 2.366864    Objective Loss 2.366864                                        LR 0.100000    Time 0.239723    
2024-04-23 17:17:29,242 - Epoch: [66][  267/  267]    Overall Loss 2.366432    Objective Loss 2.366432    Top1 9.302326    Top5 53.488372    LR 0.100000    Time 0.236345    
2024-04-23 17:17:29,398 - --- validate (epoch=66)-----------
2024-04-23 17:17:29,399 - 946 samples (32 per mini-batch)
2024-04-23 17:17:32,981 - Epoch: [66][   10/   30]    Loss 2.399075    Top1 10.000000    Top5 49.687500    
2024-04-23 17:17:33,175 - Epoch: [51][  100/  296]    Overall Loss 0.987114    Objective Loss 0.987114                                        LR 0.000320    Time 0.246682    
2024-04-23 17:17:34,971 - Epoch: [66][   20/   30]    Loss 2.387783    Top1 10.000000    Top5 48.437500    
2024-04-23 17:17:37,716 - Epoch: [66][   30/   30]    Loss 2.369030    Top1 10.993658    Top5 50.211416    
2024-04-23 17:17:37,923 - ==> Top1: 10.994    Top5: 50.211    Loss: 2.369

2024-04-23 17:17:37,925 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 17:17:37,930 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:17:37,931 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:17:37,949 - 

2024-04-23 17:17:37,950 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:17:41,772 - Epoch: [67][   10/  267]    Overall Loss 2.384873    Objective Loss 2.384873                                        LR 0.100000    Time 0.381758    
2024-04-23 17:17:44,064 - Epoch: [67][   20/  267]    Overall Loss 2.361528    Objective Loss 2.361528                                        LR 0.100000    Time 0.305360    
2024-04-23 17:17:47,440 - Epoch: [67][   30/  267]    Overall Loss 2.369859    Objective Loss 2.369859                                        LR 0.100000    Time 0.315972    
2024-04-23 17:17:49,969 - Epoch: [67][   40/  267]    Overall Loss 2.372724    Objective Loss 2.372724                                        LR 0.100000    Time 0.300101    
2024-04-23 17:17:53,061 - Epoch: [67][   50/  267]    Overall Loss 2.374455    Objective Loss 2.374455                                        LR 0.100000    Time 0.301851    
2024-04-23 17:17:54,946 - Epoch: [67][   60/  267]    Overall Loss 2.373357    Objective Loss 2.373357                                        LR 0.100000    Time 0.282918    
2024-04-23 17:17:57,662 - Epoch: [51][  200/  296]    Overall Loss 0.994783    Objective Loss 0.994783                                        LR 0.000320    Time 0.245667    
2024-04-23 17:17:58,712 - Epoch: [67][   70/  267]    Overall Loss 2.372133    Objective Loss 2.372133                                        LR 0.100000    Time 0.296245    
2024-04-23 17:18:01,289 - Epoch: [67][   80/  267]    Overall Loss 2.368616    Objective Loss 2.368616                                        LR 0.100000    Time 0.291391    
2024-04-23 17:18:04,548 - Epoch: [67][   90/  267]    Overall Loss 2.370310    Objective Loss 2.370310                                        LR 0.100000    Time 0.295189    
2024-04-23 17:18:06,501 - Epoch: [67][  100/  267]    Overall Loss 2.366193    Objective Loss 2.366193                                        LR 0.100000    Time 0.285165    
2024-04-23 17:18:09,203 - Epoch: [67][  110/  267]    Overall Loss 2.363480    Objective Loss 2.363480                                        LR 0.100000    Time 0.283788    
2024-04-23 17:18:11,127 - Epoch: [67][  120/  267]    Overall Loss 2.361419    Objective Loss 2.361419                                        LR 0.100000    Time 0.276144    
2024-04-23 17:18:13,862 - Epoch: [67][  130/  267]    Overall Loss 2.358450    Objective Loss 2.358450                                        LR 0.100000    Time 0.275912    
2024-04-23 17:18:15,761 - Epoch: [67][  140/  267]    Overall Loss 2.361817    Objective Loss 2.361817                                        LR 0.100000    Time 0.269746    
2024-04-23 17:18:18,390 - Epoch: [67][  150/  267]    Overall Loss 2.360547    Objective Loss 2.360547                                        LR 0.100000    Time 0.269266    
2024-04-23 17:18:20,561 - Epoch: [67][  160/  267]    Overall Loss 2.360287    Objective Loss 2.360287                                        LR 0.100000    Time 0.265992    
2024-04-23 17:18:21,395 - Epoch: [51][  296/  296]    Overall Loss 0.983205    Objective Loss 0.983205    Top1 67.213115    Top5 93.442623    LR 0.000320    Time 0.246098    
2024-04-23 17:18:21,712 - --- validate (epoch=51)-----------
2024-04-23 17:18:21,713 - 3925 samples (32 per mini-batch)
2024-04-23 17:18:23,034 - Epoch: [67][  170/  267]    Overall Loss 2.360240    Objective Loss 2.360240                                        LR 0.100000    Time 0.264872    
2024-04-23 17:18:25,443 - Epoch: [67][  180/  267]    Overall Loss 2.362630    Objective Loss 2.362630                                        LR 0.100000    Time 0.263523    
2024-04-23 17:18:28,546 - Epoch: [67][  190/  267]    Overall Loss 2.364681    Objective Loss 2.364681                                        LR 0.100000    Time 0.265965    
2024-04-23 17:18:30,876 - Epoch: [67][  200/  267]    Overall Loss 2.367468    Objective Loss 2.367468                                        LR 0.100000    Time 0.264304    
2024-04-23 17:18:34,797 - Epoch: [67][  210/  267]    Overall Loss 2.366568    Objective Loss 2.366568                                        LR 0.100000    Time 0.270372    
2024-04-23 17:18:37,848 - Epoch: [67][  220/  267]    Overall Loss 2.366021    Objective Loss 2.366021                                        LR 0.100000    Time 0.271933    
2024-04-23 17:18:41,267 - Epoch: [67][  230/  267]    Overall Loss 2.364866    Objective Loss 2.364866                                        LR 0.100000    Time 0.274960    
2024-04-23 17:18:44,149 - Epoch: [67][  240/  267]    Overall Loss 2.364212    Objective Loss 2.364212                                        LR 0.100000    Time 0.275495    
2024-04-23 17:18:48,263 - Epoch: [67][  250/  267]    Overall Loss 2.362980    Objective Loss 2.362980                                        LR 0.100000    Time 0.280916    
2024-04-23 17:18:50,279 - Epoch: [67][  260/  267]    Overall Loss 2.363371    Objective Loss 2.363371                                        LR 0.100000    Time 0.277857    
2024-04-23 17:18:51,871 - Epoch: [67][  267/  267]    Overall Loss 2.363575    Objective Loss 2.363575    Top1 11.627907    Top5 55.813953    LR 0.100000    Time 0.276525    
2024-04-23 17:18:52,108 - --- validate (epoch=67)-----------
2024-04-23 17:18:52,109 - 946 samples (32 per mini-batch)
2024-04-23 17:18:53,966 - Epoch: [51][  100/  123]    Loss 0.860570    Top1 71.031250    Top5 96.062500    
2024-04-23 17:18:55,906 - Epoch: [67][   10/   30]    Loss 2.337607    Top1 8.125000    Top5 50.000000    
2024-04-23 17:18:57,517 - Epoch: [67][   20/   30]    Loss 2.328146    Top1 10.312500    Top5 51.250000    
2024-04-23 17:18:59,488 - Epoch: [51][  123/  123]    Loss 0.852291    Top1 71.363057    Top5 96.229299    
2024-04-23 17:18:59,618 - Epoch: [67][   30/   30]    Loss 2.329959    Top1 10.359408    Top5 50.634249    
2024-04-23 17:18:59,759 - ==> Top1: 71.363    Top5: 96.229    Loss: 0.852

2024-04-23 17:18:59,766 - ==> Best [Top1: 73.529   Top5: 96.229   Sparsity:0.00   Params: 376752 on epoch: 48]
2024-04-23 17:18:59,767 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:18:59,775 - ==> Top1: 10.359    Top5: 50.634    Loss: 2.330

2024-04-23 17:18:59,777 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 17:18:59,781 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:18:59,781 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:18:59,796 - 

2024-04-23 17:18:59,797 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:18:59,805 - 

2024-04-23 17:18:59,806 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:19:03,369 - Epoch: [68][   10/  267]    Overall Loss 2.367875    Objective Loss 2.367875                                        LR 0.100000    Time 0.356830    
2024-04-23 17:19:06,047 - Epoch: [68][   20/  267]    Overall Loss 2.356244    Objective Loss 2.356244                                        LR 0.100000    Time 0.312132    
2024-04-23 17:19:08,699 - Epoch: [68][   30/  267]    Overall Loss 2.349294    Objective Loss 2.349294                                        LR 0.100000    Time 0.296390    
2024-04-23 17:19:11,082 - Epoch: [68][   40/  267]    Overall Loss 2.348750    Objective Loss 2.348750                                        LR 0.100000    Time 0.281786    
2024-04-23 17:19:14,009 - Epoch: [68][   50/  267]    Overall Loss 2.352633    Objective Loss 2.352633                                        LR 0.100000    Time 0.283901    
2024-04-23 17:19:16,251 - Epoch: [68][   60/  267]    Overall Loss 2.358477    Objective Loss 2.358477                                        LR 0.100000    Time 0.273902    
2024-04-23 17:19:19,465 - Epoch: [68][   70/  267]    Overall Loss 2.355699    Objective Loss 2.355699                                        LR 0.100000    Time 0.280646    
2024-04-23 17:19:21,569 - Epoch: [68][   80/  267]    Overall Loss 2.361556    Objective Loss 2.361556                                        LR 0.100000    Time 0.271806    
2024-04-23 17:19:24,147 - Epoch: [68][   90/  267]    Overall Loss 2.361813    Objective Loss 2.361813                                        LR 0.100000    Time 0.270229    
2024-04-23 17:19:25,854 - Epoch: [52][  100/  296]    Overall Loss 0.966116    Objective Loss 0.966116                                        LR 0.000320    Time 0.260239    
2024-04-23 17:19:26,719 - Epoch: [68][  100/  267]    Overall Loss 2.362548    Objective Loss 2.362548                                        LR 0.100000    Time 0.268890    
2024-04-23 17:19:30,099 - Epoch: [68][  110/  267]    Overall Loss 2.361617    Objective Loss 2.361617                                        LR 0.100000    Time 0.275143    
2024-04-23 17:19:32,266 - Epoch: [68][  120/  267]    Overall Loss 2.364744    Objective Loss 2.364744                                        LR 0.100000    Time 0.270248    
2024-04-23 17:19:34,525 - Epoch: [68][  130/  267]    Overall Loss 2.364825    Objective Loss 2.364825                                        LR 0.100000    Time 0.266800    
2024-04-23 17:19:36,094 - Epoch: [68][  140/  267]    Overall Loss 2.366965    Objective Loss 2.366965                                        LR 0.100000    Time 0.258928    
2024-04-23 17:19:38,556 - Epoch: [68][  150/  267]    Overall Loss 2.365675    Objective Loss 2.365675                                        LR 0.100000    Time 0.258057    
2024-04-23 17:19:40,569 - Epoch: [68][  160/  267]    Overall Loss 2.367508    Objective Loss 2.367508                                        LR 0.100000    Time 0.254493    
2024-04-23 17:19:43,175 - Epoch: [68][  170/  267]    Overall Loss 2.367010    Objective Loss 2.367010                                        LR 0.100000    Time 0.254837    
2024-04-23 17:19:45,242 - Epoch: [68][  180/  267]    Overall Loss 2.367333    Objective Loss 2.367333                                        LR 0.100000    Time 0.252139    
2024-04-23 17:19:47,927 - Epoch: [68][  190/  267]    Overall Loss 2.369438    Objective Loss 2.369438                                        LR 0.100000    Time 0.252985    
2024-04-23 17:19:50,029 - Epoch: [68][  200/  267]    Overall Loss 2.370111    Objective Loss 2.370111                                        LR 0.100000    Time 0.250829    
2024-04-23 17:19:50,212 - Epoch: [52][  200/  296]    Overall Loss 0.968081    Objective Loss 0.968081                                        LR 0.000320    Time 0.251768    
2024-04-23 17:19:53,008 - Epoch: [68][  210/  267]    Overall Loss 2.369858    Objective Loss 2.369858                                        LR 0.100000    Time 0.253054    
2024-04-23 17:19:55,060 - Epoch: [68][  220/  267]    Overall Loss 2.368785    Objective Loss 2.368785                                        LR 0.100000    Time 0.250865    
2024-04-23 17:19:57,704 - Epoch: [68][  230/  267]    Overall Loss 2.369259    Objective Loss 2.369259                                        LR 0.100000    Time 0.251439    
2024-04-23 17:19:59,440 - Epoch: [68][  240/  267]    Overall Loss 2.368844    Objective Loss 2.368844                                        LR 0.100000    Time 0.248182    
2024-04-23 17:20:02,100 - Epoch: [68][  250/  267]    Overall Loss 2.369018    Objective Loss 2.369018                                        LR 0.100000    Time 0.248882    
2024-04-23 17:20:04,139 - Epoch: [68][  260/  267]    Overall Loss 2.368067    Objective Loss 2.368067                                        LR 0.100000    Time 0.247135    
2024-04-23 17:20:05,527 - Epoch: [68][  267/  267]    Overall Loss 2.368880    Objective Loss 2.368880    Top1 4.651163    Top5 51.162791    LR 0.100000    Time 0.245846    
2024-04-23 17:20:05,732 - --- validate (epoch=68)-----------
2024-04-23 17:20:05,734 - 946 samples (32 per mini-batch)
2024-04-23 17:20:09,535 - Epoch: [68][   10/   30]    Loss 2.344251    Top1 10.000000    Top5 50.000000    
2024-04-23 17:20:11,804 - Epoch: [68][   20/   30]    Loss 2.348694    Top1 9.218750    Top5 50.000000    
2024-04-23 17:20:12,581 - Epoch: [52][  296/  296]    Overall Loss 0.979460    Objective Loss 0.979460    Top1 62.295082    Top5 96.721311    LR 0.000320    Time 0.245614    
2024-04-23 17:20:12,937 - --- validate (epoch=52)-----------
2024-04-23 17:20:12,938 - 3925 samples (32 per mini-batch)
2024-04-23 17:20:13,343 - Epoch: [68][   30/   30]    Loss 2.345429    Top1 9.830867    Top5 50.211416    
2024-04-23 17:20:13,439 - ==> Top1: 9.831    Top5: 50.211    Loss: 2.345

2024-04-23 17:20:13,441 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 17:20:13,444 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:20:13,445 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:20:13,458 - 

2024-04-23 17:20:13,458 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:20:16,743 - Epoch: [69][   10/  267]    Overall Loss 2.368554    Objective Loss 2.368554                                        LR 0.100000    Time 0.328244    
2024-04-23 17:20:18,431 - Epoch: [69][   20/  267]    Overall Loss 2.359157    Objective Loss 2.359157                                        LR 0.100000    Time 0.248372    
2024-04-23 17:20:20,761 - Epoch: [69][   30/  267]    Overall Loss 2.355947    Objective Loss 2.355947                                        LR 0.100000    Time 0.243140    
2024-04-23 17:20:22,555 - Epoch: [69][   40/  267]    Overall Loss 2.370017    Objective Loss 2.370017                                        LR 0.100000    Time 0.227162    
2024-04-23 17:20:24,712 - Epoch: [69][   50/  267]    Overall Loss 2.368898    Objective Loss 2.368898                                        LR 0.100000    Time 0.224780    
2024-04-23 17:20:26,294 - Epoch: [69][   60/  267]    Overall Loss 2.372483    Objective Loss 2.372483                                        LR 0.100000    Time 0.213650    
2024-04-23 17:20:28,460 - Epoch: [69][   70/  267]    Overall Loss 2.371844    Objective Loss 2.371844                                        LR 0.100000    Time 0.214036    
2024-04-23 17:20:30,092 - Epoch: [69][   80/  267]    Overall Loss 2.368197    Objective Loss 2.368197                                        LR 0.100000    Time 0.207653    
2024-04-23 17:20:32,345 - Epoch: [69][   90/  267]    Overall Loss 2.368713    Objective Loss 2.368713                                        LR 0.100000    Time 0.209577    
2024-04-23 17:20:33,946 - Epoch: [69][  100/  267]    Overall Loss 2.373167    Objective Loss 2.373167                                        LR 0.100000    Time 0.204600    
2024-04-23 17:20:36,743 - Epoch: [69][  110/  267]    Overall Loss 2.370456    Objective Loss 2.370456                                        LR 0.100000    Time 0.211394    
2024-04-23 17:20:36,891 - Epoch: [52][  100/  123]    Loss 0.834794    Top1 71.687500    Top5 96.375000    
2024-04-23 17:20:38,177 - Epoch: [69][  120/  267]    Overall Loss 2.369081    Objective Loss 2.369081                                        LR 0.100000    Time 0.205699    
2024-04-23 17:20:40,607 - Epoch: [69][  130/  267]    Overall Loss 2.368160    Objective Loss 2.368160                                        LR 0.100000    Time 0.208541    
2024-04-23 17:20:41,998 - Epoch: [69][  140/  267]    Overall Loss 2.368761    Objective Loss 2.368761                                        LR 0.100000    Time 0.203557    
2024-04-23 17:20:42,238 - Epoch: [52][  123/  123]    Loss 0.830140    Top1 72.203822    Top5 96.433121    
2024-04-23 17:20:42,470 - ==> Top1: 72.204    Top5: 96.433    Loss: 0.830

2024-04-23 17:20:42,479 - ==> Best [Top1: 73.529   Top5: 96.229   Sparsity:0.00   Params: 376752 on epoch: 48]
2024-04-23 17:20:42,480 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:20:42,527 - 

2024-04-23 17:20:42,528 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:20:43,629 - Epoch: [69][  150/  267]    Overall Loss 2.366569    Objective Loss 2.366569                                        LR 0.100000    Time 0.200845    
2024-04-23 17:20:46,125 - Epoch: [69][  160/  267]    Overall Loss 2.367270    Objective Loss 2.367270                                        LR 0.100000    Time 0.203875    
2024-04-23 17:20:48,558 - Epoch: [69][  170/  267]    Overall Loss 2.366673    Objective Loss 2.366673                                        LR 0.100000    Time 0.206173    
2024-04-23 17:20:50,946 - Epoch: [69][  180/  267]    Overall Loss 2.366302    Objective Loss 2.366302                                        LR 0.100000    Time 0.207966    
2024-04-23 17:20:52,999 - Epoch: [69][  190/  267]    Overall Loss 2.365871    Objective Loss 2.365871                                        LR 0.100000    Time 0.207813    
2024-04-23 17:20:55,317 - Epoch: [69][  200/  267]    Overall Loss 2.366102    Objective Loss 2.366102                                        LR 0.100000    Time 0.209002    
2024-04-23 17:20:57,634 - Epoch: [69][  210/  267]    Overall Loss 2.368279    Objective Loss 2.368279                                        LR 0.100000    Time 0.210065    
2024-04-23 17:20:59,713 - Epoch: [69][  220/  267]    Overall Loss 2.369058    Objective Loss 2.369058                                        LR 0.100000    Time 0.209948    
2024-04-23 17:21:02,050 - Epoch: [69][  230/  267]    Overall Loss 2.368265    Objective Loss 2.368265                                        LR 0.100000    Time 0.210964    
2024-04-23 17:21:04,485 - Epoch: [69][  240/  267]    Overall Loss 2.367888    Objective Loss 2.367888                                        LR 0.100000    Time 0.212307    
2024-04-23 17:21:07,362 - Epoch: [69][  250/  267]    Overall Loss 2.368387    Objective Loss 2.368387                                        LR 0.100000    Time 0.215308    
2024-04-23 17:21:07,744 - Epoch: [53][  100/  296]    Overall Loss 0.977425    Objective Loss 0.977425                                        LR 0.000320    Time 0.251940    
2024-04-23 17:21:09,428 - Epoch: [69][  260/  267]    Overall Loss 2.368425    Objective Loss 2.368425                                        LR 0.100000    Time 0.214965    
2024-04-23 17:21:11,167 - Epoch: [69][  267/  267]    Overall Loss 2.368866    Objective Loss 2.368866    Top1 6.976744    Top5 46.511628    LR 0.100000    Time 0.215835    
2024-04-23 17:21:11,376 - --- validate (epoch=69)-----------
2024-04-23 17:21:11,377 - 946 samples (32 per mini-batch)
2024-04-23 17:21:15,020 - Epoch: [69][   10/   30]    Loss 2.369373    Top1 6.875000    Top5 53.125000    
2024-04-23 17:21:17,330 - Epoch: [69][   20/   30]    Loss 2.358826    Top1 9.062500    Top5 51.718750    
2024-04-23 17:21:19,746 - Epoch: [69][   30/   30]    Loss 2.361228    Top1 9.196617    Top5 50.634249    
2024-04-23 17:21:19,984 - ==> Top1: 9.197    Top5: 50.634    Loss: 2.361

2024-04-23 17:21:19,986 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 17:21:19,991 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:21:19,992 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:21:20,011 - 

2024-04-23 17:21:20,012 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:21:23,919 - Epoch: [70][   10/  267]    Overall Loss 2.367248    Objective Loss 2.367248                                        LR 0.100000    Time 0.390299    
2024-04-23 17:21:26,184 - Epoch: [70][   20/  267]    Overall Loss 2.372784    Objective Loss 2.372784                                        LR 0.100000    Time 0.308241    
2024-04-23 17:21:28,903 - Epoch: [70][   30/  267]    Overall Loss 2.370022    Objective Loss 2.370022                                        LR 0.100000    Time 0.296016    
2024-04-23 17:21:29,559 - Epoch: [53][  200/  296]    Overall Loss 0.950921    Objective Loss 0.950921                                        LR 0.000320    Time 0.234940    
2024-04-23 17:21:30,549 - Epoch: [70][   40/  267]    Overall Loss 2.377483    Objective Loss 2.377483                                        LR 0.100000    Time 0.263097    
2024-04-23 17:21:33,823 - Epoch: [70][   50/  267]    Overall Loss 2.368737    Objective Loss 2.368737                                        LR 0.100000    Time 0.275785    
2024-04-23 17:21:36,214 - Epoch: [70][   60/  267]    Overall Loss 2.377533    Objective Loss 2.377533                                        LR 0.100000    Time 0.269611    
2024-04-23 17:21:39,047 - Epoch: [70][   70/  267]    Overall Loss 2.372300    Objective Loss 2.372300                                        LR 0.100000    Time 0.271535    
2024-04-23 17:21:41,101 - Epoch: [70][   80/  267]    Overall Loss 2.374820    Objective Loss 2.374820                                        LR 0.100000    Time 0.263225    
2024-04-23 17:21:44,120 - Epoch: [70][   90/  267]    Overall Loss 2.373811    Objective Loss 2.373811                                        LR 0.100000    Time 0.267487    
2024-04-23 17:21:46,387 - Epoch: [70][  100/  267]    Overall Loss 2.371344    Objective Loss 2.371344                                        LR 0.100000    Time 0.263378    
2024-04-23 17:21:49,391 - Epoch: [70][  110/  267]    Overall Loss 2.369748    Objective Loss 2.369748                                        LR 0.100000    Time 0.266709    
2024-04-23 17:21:52,250 - Epoch: [70][  120/  267]    Overall Loss 2.370036    Objective Loss 2.370036                                        LR 0.100000    Time 0.268267    
2024-04-23 17:21:54,897 - Epoch: [70][  130/  267]    Overall Loss 2.370320    Objective Loss 2.370320                                        LR 0.100000    Time 0.267964    
2024-04-23 17:21:55,020 - Epoch: [53][  296/  296]    Overall Loss 0.962419    Objective Loss 0.962419    Top1 75.409836    Top5 95.081967    LR 0.000320    Time 0.244691    
2024-04-23 17:21:55,301 - --- validate (epoch=53)-----------
2024-04-23 17:21:55,303 - 3925 samples (32 per mini-batch)
2024-04-23 17:21:55,903 - Epoch: [70][  140/  267]    Overall Loss 2.371133    Objective Loss 2.371133                                        LR 0.100000    Time 0.256000    
2024-04-23 17:21:57,538 - Epoch: [70][  150/  267]    Overall Loss 2.370516    Objective Loss 2.370516                                        LR 0.100000    Time 0.249820    
2024-04-23 17:21:59,812 - Epoch: [70][  160/  267]    Overall Loss 2.371104    Objective Loss 2.371104                                        LR 0.100000    Time 0.248392    
2024-04-23 17:22:02,485 - Epoch: [70][  170/  267]    Overall Loss 2.368924    Objective Loss 2.368924                                        LR 0.100000    Time 0.249489    
2024-04-23 17:22:05,719 - Epoch: [70][  180/  267]    Overall Loss 2.366925    Objective Loss 2.366925                                        LR 0.100000    Time 0.253574    
2024-04-23 17:22:07,810 - Epoch: [70][  190/  267]    Overall Loss 2.366865    Objective Loss 2.366865                                        LR 0.100000    Time 0.251221    
2024-04-23 17:22:10,268 - Epoch: [70][  200/  267]    Overall Loss 2.364539    Objective Loss 2.364539                                        LR 0.100000    Time 0.250932    
2024-04-23 17:22:12,292 - Epoch: [70][  210/  267]    Overall Loss 2.363518    Objective Loss 2.363518                                        LR 0.100000    Time 0.248609    
2024-04-23 17:22:15,104 - Epoch: [70][  220/  267]    Overall Loss 2.362795    Objective Loss 2.362795                                        LR 0.100000    Time 0.250076    
2024-04-23 17:22:17,177 - Epoch: [70][  230/  267]    Overall Loss 2.363115    Objective Loss 2.363115                                        LR 0.100000    Time 0.248198    
2024-04-23 17:22:19,552 - Epoch: [70][  240/  267]    Overall Loss 2.361763    Objective Loss 2.361763                                        LR 0.100000    Time 0.247737    
2024-04-23 17:22:21,166 - Epoch: [70][  250/  267]    Overall Loss 2.360077    Objective Loss 2.360077                                        LR 0.100000    Time 0.244272    
2024-04-23 17:22:21,276 - Epoch: [53][  100/  123]    Loss 0.835624    Top1 72.125000    Top5 96.406250    
2024-04-23 17:22:23,657 - Epoch: [70][  260/  267]    Overall Loss 2.360319    Objective Loss 2.360319                                        LR 0.100000    Time 0.244445    
2024-04-23 17:22:24,793 - Epoch: [70][  267/  267]    Overall Loss 2.360461    Objective Loss 2.360461    Top1 23.255814    Top5 48.837209    LR 0.100000    Time 0.242286    
2024-04-23 17:22:24,997 - --- validate (epoch=70)-----------
2024-04-23 17:22:24,998 - 946 samples (32 per mini-batch)
2024-04-23 17:22:25,952 - Epoch: [53][  123/  123]    Loss 0.821725    Top1 72.815287    Top5 96.433121    
2024-04-23 17:22:26,223 - ==> Top1: 72.815    Top5: 96.433    Loss: 0.822

2024-04-23 17:22:26,233 - ==> Best [Top1: 73.529   Top5: 96.229   Sparsity:0.00   Params: 376752 on epoch: 48]
2024-04-23 17:22:26,234 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:22:26,286 - 

2024-04-23 17:22:26,287 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:22:27,240 - Epoch: [70][   10/   30]    Loss 2.331976    Top1 9.687500    Top5 52.187500    
2024-04-23 17:22:29,142 - Epoch: [70][   20/   30]    Loss 2.316217    Top1 10.156250    Top5 53.750000    
2024-04-23 17:22:31,545 - Epoch: [70][   30/   30]    Loss 2.323007    Top1 10.570825    Top5 51.797040    
2024-04-23 17:22:31,714 - ==> Top1: 10.571    Top5: 51.797    Loss: 2.323

2024-04-23 17:22:31,717 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 17:22:31,721 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:22:31,721 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:22:31,735 - 

2024-04-23 17:22:31,736 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:22:35,935 - Epoch: [71][   10/  267]    Overall Loss 2.324719    Objective Loss 2.324719                                        LR 0.100000    Time 0.419562    
2024-04-23 17:22:38,179 - Epoch: [71][   20/  267]    Overall Loss 2.319624    Objective Loss 2.319624                                        LR 0.100000    Time 0.321831    
2024-04-23 17:22:40,982 - Epoch: [71][   30/  267]    Overall Loss 2.353655    Objective Loss 2.353655                                        LR 0.100000    Time 0.307854    
2024-04-23 17:22:43,059 - Epoch: [71][   40/  267]    Overall Loss 2.357065    Objective Loss 2.357065                                        LR 0.100000    Time 0.282732    
2024-04-23 17:22:45,949 - Epoch: [71][   50/  267]    Overall Loss 2.356991    Objective Loss 2.356991                                        LR 0.100000    Time 0.283853    
2024-04-23 17:22:48,582 - Epoch: [71][   60/  267]    Overall Loss 2.357088    Objective Loss 2.357088                                        LR 0.100000    Time 0.280380    
2024-04-23 17:22:51,387 - Epoch: [71][   70/  267]    Overall Loss 2.355287    Objective Loss 2.355287                                        LR 0.100000    Time 0.280305    
2024-04-23 17:22:51,750 - Epoch: [54][  100/  296]    Overall Loss 0.963685    Objective Loss 0.963685                                        LR 0.000320    Time 0.254404    
2024-04-23 17:22:55,517 - Epoch: [71][   80/  267]    Overall Loss 2.354314    Objective Loss 2.354314                                        LR 0.100000    Time 0.296843    
2024-04-23 17:22:58,007 - Epoch: [71][   90/  267]    Overall Loss 2.355265    Objective Loss 2.355265                                        LR 0.100000    Time 0.291500    
2024-04-23 17:23:01,344 - Epoch: [71][  100/  267]    Overall Loss 2.358609    Objective Loss 2.358609                                        LR 0.100000    Time 0.295685    
2024-04-23 17:23:03,575 - Epoch: [71][  110/  267]    Overall Loss 2.359693    Objective Loss 2.359693                                        LR 0.100000    Time 0.289055    
2024-04-23 17:23:06,410 - Epoch: [71][  120/  267]    Overall Loss 2.357597    Objective Loss 2.357597                                        LR 0.100000    Time 0.288567    
2024-04-23 17:23:08,473 - Epoch: [71][  130/  267]    Overall Loss 2.358711    Objective Loss 2.358711                                        LR 0.100000    Time 0.282205    
2024-04-23 17:23:11,651 - Epoch: [71][  140/  267]    Overall Loss 2.361518    Objective Loss 2.361518                                        LR 0.100000    Time 0.284724    
2024-04-23 17:23:13,973 - Epoch: [71][  150/  267]    Overall Loss 2.362114    Objective Loss 2.362114                                        LR 0.100000    Time 0.281200    
2024-04-23 17:23:16,667 - Epoch: [71][  160/  267]    Overall Loss 2.363523    Objective Loss 2.363523                                        LR 0.100000    Time 0.280445    
2024-04-23 17:23:18,206 - Epoch: [54][  200/  296]    Overall Loss 0.956540    Objective Loss 0.956540                                        LR 0.000320    Time 0.259372    
2024-04-23 17:23:18,669 - Epoch: [71][  170/  267]    Overall Loss 2.362688    Objective Loss 2.362688                                        LR 0.100000    Time 0.275705    
2024-04-23 17:23:21,666 - Epoch: [71][  180/  267]    Overall Loss 2.364996    Objective Loss 2.364996                                        LR 0.100000    Time 0.277020    
2024-04-23 17:23:23,842 - Epoch: [71][  190/  267]    Overall Loss 2.364621    Objective Loss 2.364621                                        LR 0.100000    Time 0.273874    
2024-04-23 17:23:26,828 - Epoch: [71][  200/  267]    Overall Loss 2.364910    Objective Loss 2.364910                                        LR 0.100000    Time 0.275095    
2024-04-23 17:23:28,806 - Epoch: [71][  210/  267]    Overall Loss 2.363461    Objective Loss 2.363461                                        LR 0.100000    Time 0.271406    
2024-04-23 17:23:31,623 - Epoch: [71][  220/  267]    Overall Loss 2.363452    Objective Loss 2.363452                                        LR 0.100000    Time 0.271859    
2024-04-23 17:23:34,064 - Epoch: [71][  230/  267]    Overall Loss 2.363438    Objective Loss 2.363438                                        LR 0.100000    Time 0.270635    
2024-04-23 17:23:37,890 - Epoch: [71][  240/  267]    Overall Loss 2.364545    Objective Loss 2.364545                                        LR 0.100000    Time 0.275286    
2024-04-23 17:23:39,939 - Epoch: [71][  250/  267]    Overall Loss 2.363908    Objective Loss 2.363908                                        LR 0.100000    Time 0.272456    
2024-04-23 17:23:42,329 - Epoch: [71][  260/  267]    Overall Loss 2.364783    Objective Loss 2.364783                                        LR 0.100000    Time 0.271156    
2024-04-23 17:23:42,708 - Epoch: [54][  296/  296]    Overall Loss 0.960302    Objective Loss 0.960302    Top1 65.573770    Top5 95.081967    LR 0.000320    Time 0.257959    
2024-04-23 17:23:42,777 - Epoch: [71][  267/  267]    Overall Loss 2.364671    Objective Loss 2.364671    Top1 6.976744    Top5 46.511628    LR 0.100000    Time 0.265718    
2024-04-23 17:23:42,927 - --- validate (epoch=71)-----------
2024-04-23 17:23:42,928 - 946 samples (32 per mini-batch)
2024-04-23 17:23:43,010 - --- validate (epoch=54)-----------
2024-04-23 17:23:43,011 - 3925 samples (32 per mini-batch)
2024-04-23 17:23:45,951 - Epoch: [71][   10/   30]    Loss 2.357062    Top1 12.500000    Top5 46.562500    
2024-04-23 17:23:47,717 - Epoch: [71][   20/   30]    Loss 2.348236    Top1 12.343750    Top5 48.750000    
2024-04-23 17:23:49,811 - Epoch: [71][   30/   30]    Loss 2.350093    Top1 10.993658    Top5 49.048626    
2024-04-23 17:23:49,940 - ==> Top1: 10.994    Top5: 49.049    Loss: 2.350

2024-04-23 17:23:49,941 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 17:23:49,945 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:23:49,946 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:23:49,962 - 

2024-04-23 17:23:49,963 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:23:52,907 - Epoch: [72][   10/  267]    Overall Loss 2.437913    Objective Loss 2.437913                                        LR 0.100000    Time 0.294102    
2024-04-23 17:23:54,725 - Epoch: [72][   20/  267]    Overall Loss 2.410836    Objective Loss 2.410836                                        LR 0.100000    Time 0.237736    
2024-04-23 17:23:56,713 - Epoch: [72][   30/  267]    Overall Loss 2.405602    Objective Loss 2.405602                                        LR 0.100000    Time 0.224673    
2024-04-23 17:23:58,590 - Epoch: [72][   40/  267]    Overall Loss 2.393028    Objective Loss 2.393028                                        LR 0.100000    Time 0.215353    
2024-04-23 17:24:01,243 - Epoch: [72][   50/  267]    Overall Loss 2.395878    Objective Loss 2.395878                                        LR 0.100000    Time 0.225288    
2024-04-23 17:24:03,095 - Epoch: [72][   60/  267]    Overall Loss 2.390629    Objective Loss 2.390629                                        LR 0.100000    Time 0.218557    
2024-04-23 17:24:06,161 - Epoch: [72][   70/  267]    Overall Loss 2.387294    Objective Loss 2.387294                                        LR 0.100000    Time 0.231095    
2024-04-23 17:24:06,712 - Epoch: [54][  100/  123]    Loss 0.784515    Top1 74.531250    Top5 96.812500    
2024-04-23 17:24:08,384 - Epoch: [72][   80/  267]    Overall Loss 2.385111    Objective Loss 2.385111                                        LR 0.100000    Time 0.229951    
2024-04-23 17:24:11,167 - Epoch: [72][   90/  267]    Overall Loss 2.378811    Objective Loss 2.378811                                        LR 0.100000    Time 0.235286    
2024-04-23 17:24:12,387 - Epoch: [54][  123/  123]    Loss 0.800056    Top1 74.267516    Top5 96.662420    
2024-04-23 17:24:12,679 - Epoch: [72][  100/  267]    Overall Loss 2.376250    Objective Loss 2.376250                                        LR 0.100000    Time 0.226845    
2024-04-23 17:24:12,679 - ==> Top1: 74.268    Top5: 96.662    Loss: 0.800

2024-04-23 17:24:12,687 - ==> Best [Top1: 74.268   Top5: 96.662   Sparsity:0.00   Params: 376752 on epoch: 54]
2024-04-23 17:24:12,687 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:24:12,750 - 

2024-04-23 17:24:12,751 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:24:14,367 - Epoch: [72][  110/  267]    Overall Loss 2.377258    Objective Loss 2.377258                                        LR 0.100000    Time 0.221553    
2024-04-23 17:24:16,206 - Epoch: [72][  120/  267]    Overall Loss 2.373563    Objective Loss 2.373563                                        LR 0.100000    Time 0.218389    
2024-04-23 17:24:19,080 - Epoch: [72][  130/  267]    Overall Loss 2.372936    Objective Loss 2.372936                                        LR 0.100000    Time 0.223671    
2024-04-23 17:24:20,980 - Epoch: [72][  140/  267]    Overall Loss 2.373653    Objective Loss 2.373653                                        LR 0.100000    Time 0.221240    
2024-04-23 17:24:23,916 - Epoch: [72][  150/  267]    Overall Loss 2.372061    Objective Loss 2.372061                                        LR 0.100000    Time 0.226047    
2024-04-23 17:24:26,222 - Epoch: [72][  160/  267]    Overall Loss 2.371762    Objective Loss 2.371762                                        LR 0.100000    Time 0.226310    
2024-04-23 17:24:29,011 - Epoch: [72][  170/  267]    Overall Loss 2.371489    Objective Loss 2.371489                                        LR 0.100000    Time 0.229380    
2024-04-23 17:24:30,966 - Epoch: [72][  180/  267]    Overall Loss 2.372797    Objective Loss 2.372797                                        LR 0.100000    Time 0.227485    
2024-04-23 17:24:33,847 - Epoch: [72][  190/  267]    Overall Loss 2.371434    Objective Loss 2.371434                                        LR 0.100000    Time 0.230653    
2024-04-23 17:24:35,898 - Epoch: [72][  200/  267]    Overall Loss 2.370859    Objective Loss 2.370859                                        LR 0.100000    Time 0.229362    
2024-04-23 17:24:38,763 - Epoch: [55][  100/  296]    Overall Loss 0.941603    Objective Loss 0.941603                                        LR 0.000320    Time 0.259896    
2024-04-23 17:24:39,093 - Epoch: [72][  210/  267]    Overall Loss 2.370062    Objective Loss 2.370062                                        LR 0.100000    Time 0.233640    
2024-04-23 17:24:41,131 - Epoch: [72][  220/  267]    Overall Loss 2.369001    Objective Loss 2.369001                                        LR 0.100000    Time 0.232273    
2024-04-23 17:24:43,898 - Epoch: [72][  230/  267]    Overall Loss 2.368847    Objective Loss 2.368847                                        LR 0.100000    Time 0.234191    
2024-04-23 17:24:45,430 - Epoch: [72][  240/  267]    Overall Loss 2.367984    Objective Loss 2.367984                                        LR 0.100000    Time 0.230807    
2024-04-23 17:24:48,095 - Epoch: [72][  250/  267]    Overall Loss 2.369872    Objective Loss 2.369872                                        LR 0.100000    Time 0.232226    
2024-04-23 17:24:49,977 - Epoch: [72][  260/  267]    Overall Loss 2.370517    Objective Loss 2.370517                                        LR 0.100000    Time 0.230518    
2024-04-23 17:24:51,295 - Epoch: [72][  267/  267]    Overall Loss 2.372021    Objective Loss 2.372021    Top1 13.953488    Top5 48.837209    LR 0.100000    Time 0.229402    
2024-04-23 17:24:51,488 - --- validate (epoch=72)-----------
2024-04-23 17:24:51,489 - 946 samples (32 per mini-batch)
2024-04-23 17:24:55,235 - Epoch: [72][   10/   30]    Loss 2.411603    Top1 8.437500    Top5 45.625000    
2024-04-23 17:24:57,585 - Epoch: [72][   20/   30]    Loss 2.415509    Top1 8.593750    Top5 47.187500    
2024-04-23 17:25:00,926 - Epoch: [72][   30/   30]    Loss 2.390287    Top1 8.456660    Top5 49.471459    
2024-04-23 17:25:01,128 - ==> Top1: 8.457    Top5: 49.471    Loss: 2.390

2024-04-23 17:25:01,131 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 17:25:01,137 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:25:01,138 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:25:01,161 - 

2024-04-23 17:25:01,162 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:25:01,661 - Epoch: [55][  200/  296]    Overall Loss 0.939748    Objective Loss 0.939748                                        LR 0.000320    Time 0.244335    
2024-04-23 17:25:05,380 - Epoch: [73][   10/  267]    Overall Loss 2.381297    Objective Loss 2.381297                                        LR 0.100000    Time 0.421363    
2024-04-23 17:25:07,814 - Epoch: [73][   20/  267]    Overall Loss 2.375942    Objective Loss 2.375942                                        LR 0.100000    Time 0.332237    
2024-04-23 17:25:11,139 - Epoch: [73][   30/  267]    Overall Loss 2.369335    Objective Loss 2.369335                                        LR 0.100000    Time 0.332229    
2024-04-23 17:25:13,282 - Epoch: [73][   40/  267]    Overall Loss 2.368152    Objective Loss 2.368152                                        LR 0.100000    Time 0.302673    
2024-04-23 17:25:16,337 - Epoch: [73][   50/  267]    Overall Loss 2.370308    Objective Loss 2.370308                                        LR 0.100000    Time 0.303168    
2024-04-23 17:25:18,438 - Epoch: [73][   60/  267]    Overall Loss 2.362398    Objective Loss 2.362398                                        LR 0.100000    Time 0.287609    
2024-04-23 17:25:21,480 - Epoch: [73][   70/  267]    Overall Loss 2.368305    Objective Loss 2.368305                                        LR 0.100000    Time 0.289922    
2024-04-23 17:25:23,916 - Epoch: [73][   80/  267]    Overall Loss 2.370416    Objective Loss 2.370416                                        LR 0.100000    Time 0.284091    
2024-04-23 17:25:26,089 - Epoch: [55][  296/  296]    Overall Loss 0.936101    Objective Loss 0.936101    Top1 73.770492    Top5 96.721311    LR 0.000320    Time 0.247548    
2024-04-23 17:25:26,307 - Epoch: [73][   90/  267]    Overall Loss 2.374701    Objective Loss 2.374701                                        LR 0.100000    Time 0.279065    
2024-04-23 17:25:26,445 - --- validate (epoch=55)-----------
2024-04-23 17:25:26,446 - 3925 samples (32 per mini-batch)
2024-04-23 17:25:27,585 - Epoch: [73][  100/  267]    Overall Loss 2.376106    Objective Loss 2.376106                                        LR 0.100000    Time 0.263907    
2024-04-23 17:25:29,760 - Epoch: [73][  110/  267]    Overall Loss 2.373873    Objective Loss 2.373873                                        LR 0.100000    Time 0.259658    
2024-04-23 17:25:31,541 - Epoch: [73][  120/  267]    Overall Loss 2.374445    Objective Loss 2.374445                                        LR 0.100000    Time 0.252837    
2024-04-23 17:25:33,835 - Epoch: [73][  130/  267]    Overall Loss 2.373570    Objective Loss 2.373570                                        LR 0.100000    Time 0.251009    
2024-04-23 17:25:36,089 - Epoch: [73][  140/  267]    Overall Loss 2.372594    Objective Loss 2.372594                                        LR 0.100000    Time 0.249165    
2024-04-23 17:25:38,485 - Epoch: [73][  150/  267]    Overall Loss 2.373530    Objective Loss 2.373530                                        LR 0.100000    Time 0.248501    
2024-04-23 17:25:40,007 - Epoch: [73][  160/  267]    Overall Loss 2.372948    Objective Loss 2.372948                                        LR 0.100000    Time 0.242466    
2024-04-23 17:25:42,596 - Epoch: [73][  170/  267]    Overall Loss 2.375955    Objective Loss 2.375955                                        LR 0.100000    Time 0.243413    
2024-04-23 17:25:44,777 - Epoch: [73][  180/  267]    Overall Loss 2.375870    Objective Loss 2.375870                                        LR 0.100000    Time 0.241989    
2024-04-23 17:25:47,827 - Epoch: [73][  190/  267]    Overall Loss 2.375025    Objective Loss 2.375025                                        LR 0.100000    Time 0.245286    
2024-04-23 17:25:49,982 - Epoch: [73][  200/  267]    Overall Loss 2.372873    Objective Loss 2.372873                                        LR 0.100000    Time 0.243780    
2024-04-23 17:25:52,030 - Epoch: [55][  100/  123]    Loss 0.838162    Top1 72.218750    Top5 96.187500    
2024-04-23 17:25:53,215 - Epoch: [73][  210/  267]    Overall Loss 2.373201    Objective Loss 2.373201                                        LR 0.100000    Time 0.247552    
2024-04-23 17:25:55,685 - Epoch: [73][  220/  267]    Overall Loss 2.372209    Objective Loss 2.372209                                        LR 0.100000    Time 0.247511    
2024-04-23 17:25:57,873 - Epoch: [73][  230/  267]    Overall Loss 2.371400    Objective Loss 2.371400                                        LR 0.100000    Time 0.246255    
2024-04-23 17:25:58,202 - Epoch: [55][  123/  123]    Loss 0.830438    Top1 72.433121    Top5 96.356688    
2024-04-23 17:25:58,489 - ==> Top1: 72.433    Top5: 96.357    Loss: 0.830

2024-04-23 17:25:58,501 - ==> Best [Top1: 74.268   Top5: 96.662   Sparsity:0.00   Params: 376752 on epoch: 54]
2024-04-23 17:25:58,502 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:25:58,562 - 

2024-04-23 17:25:58,563 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:25:59,540 - Epoch: [73][  240/  267]    Overall Loss 2.371216    Objective Loss 2.371216                                        LR 0.100000    Time 0.242925    
2024-04-23 17:26:03,112 - Epoch: [73][  250/  267]    Overall Loss 2.370992    Objective Loss 2.370992                                        LR 0.100000    Time 0.247485    
2024-04-23 17:26:05,270 - Epoch: [73][  260/  267]    Overall Loss 2.370430    Objective Loss 2.370430                                        LR 0.100000    Time 0.246255    
2024-04-23 17:26:06,390 - Epoch: [73][  267/  267]    Overall Loss 2.369701    Objective Loss 2.369701    Top1 11.627907    Top5 48.837209    LR 0.100000    Time 0.243987    
2024-04-23 17:26:06,583 - --- validate (epoch=73)-----------
2024-04-23 17:26:06,584 - 946 samples (32 per mini-batch)
2024-04-23 17:26:11,312 - Epoch: [73][   10/   30]    Loss 2.334701    Top1 8.750000    Top5 52.187500    
2024-04-23 17:26:14,202 - Epoch: [73][   20/   30]    Loss 2.342514    Top1 8.281250    Top5 50.312500    
2024-04-23 17:26:17,442 - Epoch: [73][   30/   30]    Loss 2.344360    Top1 8.456660    Top5 49.365751    
2024-04-23 17:26:17,672 - ==> Top1: 8.457    Top5: 49.366    Loss: 2.344

2024-04-23 17:26:17,674 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 17:26:17,680 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:26:17,681 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:26:17,704 - 

2024-04-23 17:26:17,706 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:26:22,036 - Epoch: [74][   10/  267]    Overall Loss 2.335967    Objective Loss 2.335967                                        LR 0.100000    Time 0.432436    
2024-04-23 17:26:24,304 - Epoch: [74][   20/  267]    Overall Loss 2.350349    Objective Loss 2.350349                                        LR 0.100000    Time 0.329455    
2024-04-23 17:26:27,754 - Epoch: [56][  100/  296]    Overall Loss 1.004464    Objective Loss 1.004464                                        LR 0.000320    Time 0.291681    
2024-04-23 17:26:27,964 - Epoch: [74][   30/  267]    Overall Loss 2.358026    Objective Loss 2.358026                                        LR 0.100000    Time 0.341538    
2024-04-23 17:26:30,299 - Epoch: [74][   40/  267]    Overall Loss 2.363662    Objective Loss 2.363662                                        LR 0.100000    Time 0.314455    
2024-04-23 17:26:33,682 - Epoch: [74][   50/  267]    Overall Loss 2.367852    Objective Loss 2.367852                                        LR 0.100000    Time 0.319158    
2024-04-23 17:26:36,328 - Epoch: [74][   60/  267]    Overall Loss 2.368490    Objective Loss 2.368490                                        LR 0.100000    Time 0.310008    
2024-04-23 17:26:39,475 - Epoch: [74][   70/  267]    Overall Loss 2.366056    Objective Loss 2.366056                                        LR 0.100000    Time 0.310646    
2024-04-23 17:26:41,772 - Epoch: [74][   80/  267]    Overall Loss 2.371076    Objective Loss 2.371076                                        LR 0.100000    Time 0.300488    
2024-04-23 17:26:44,693 - Epoch: [74][   90/  267]    Overall Loss 2.373913    Objective Loss 2.373913                                        LR 0.100000    Time 0.299530    
2024-04-23 17:26:47,670 - Epoch: [74][  100/  267]    Overall Loss 2.369861    Objective Loss 2.369861                                        LR 0.100000    Time 0.299319    
2024-04-23 17:26:49,724 - Epoch: [74][  110/  267]    Overall Loss 2.366648    Objective Loss 2.366648                                        LR 0.100000    Time 0.290752    
2024-04-23 17:26:53,080 - Epoch: [74][  120/  267]    Overall Loss 2.365948    Objective Loss 2.365948                                        LR 0.100000    Time 0.294466    
2024-04-23 17:26:54,727 - Epoch: [56][  200/  296]    Overall Loss 0.962035    Objective Loss 0.962035                                        LR 0.000320    Time 0.280595    
2024-04-23 17:26:55,319 - Epoch: [74][  130/  267]    Overall Loss 2.364165    Objective Loss 2.364165                                        LR 0.100000    Time 0.289012    
2024-04-23 17:26:58,101 - Epoch: [74][  140/  267]    Overall Loss 2.364506    Objective Loss 2.364506                                        LR 0.100000    Time 0.288214    
2024-04-23 17:27:00,560 - Epoch: [74][  150/  267]    Overall Loss 2.365816    Objective Loss 2.365816                                        LR 0.100000    Time 0.285369    
2024-04-23 17:27:03,909 - Epoch: [74][  160/  267]    Overall Loss 2.365873    Objective Loss 2.365873                                        LR 0.100000    Time 0.288444    
2024-04-23 17:27:05,771 - Epoch: [74][  170/  267]    Overall Loss 2.367566    Objective Loss 2.367566                                        LR 0.100000    Time 0.282408    
2024-04-23 17:27:08,954 - Epoch: [74][  180/  267]    Overall Loss 2.367226    Objective Loss 2.367226                                        LR 0.100000    Time 0.284386    
2024-04-23 17:27:11,567 - Epoch: [74][  190/  267]    Overall Loss 2.369834    Objective Loss 2.369834                                        LR 0.100000    Time 0.283158    
2024-04-23 17:27:14,877 - Epoch: [74][  200/  267]    Overall Loss 2.368502    Objective Loss 2.368502                                        LR 0.100000    Time 0.285532    
2024-04-23 17:27:17,354 - Epoch: [74][  210/  267]    Overall Loss 2.368553    Objective Loss 2.368553                                        LR 0.100000    Time 0.283713    
2024-04-23 17:27:20,362 - Epoch: [74][  220/  267]    Overall Loss 2.368066    Objective Loss 2.368066                                        LR 0.100000    Time 0.284480    
2024-04-23 17:27:20,480 - Epoch: [56][  296/  296]    Overall Loss 0.941859    Objective Loss 0.941859    Top1 72.131148    Top5 96.721311    LR 0.000320    Time 0.276522    
2024-04-23 17:27:20,787 - --- validate (epoch=56)-----------
2024-04-23 17:27:20,788 - 3925 samples (32 per mini-batch)
2024-04-23 17:27:22,852 - Epoch: [74][  230/  267]    Overall Loss 2.368182    Objective Loss 2.368182                                        LR 0.100000    Time 0.282923    
2024-04-23 17:27:26,475 - Epoch: [74][  240/  267]    Overall Loss 2.369540    Objective Loss 2.369540                                        LR 0.100000    Time 0.286215    
2024-04-23 17:27:28,971 - Epoch: [74][  250/  267]    Overall Loss 2.369769    Objective Loss 2.369769                                        LR 0.100000    Time 0.284735    
2024-04-23 17:27:32,269 - Epoch: [74][  260/  267]    Overall Loss 2.369028    Objective Loss 2.369028                                        LR 0.100000    Time 0.286457    
2024-04-23 17:27:33,312 - Epoch: [74][  267/  267]    Overall Loss 2.369859    Objective Loss 2.369859    Top1 4.651163    Top5 37.209302    LR 0.100000    Time 0.282845    
2024-04-23 17:27:33,532 - --- validate (epoch=74)-----------
2024-04-23 17:27:33,533 - 946 samples (32 per mini-batch)
2024-04-23 17:27:37,033 - Epoch: [74][   10/   30]    Loss 2.357730    Top1 9.375000    Top5 50.000000    
2024-04-23 17:27:39,347 - Epoch: [74][   20/   30]    Loss 2.350857    Top1 9.843750    Top5 51.093750    
2024-04-23 17:27:42,051 - Epoch: [74][   30/   30]    Loss 2.360723    Top1 9.830867    Top5 49.788584    
2024-04-23 17:27:42,223 - ==> Top1: 9.831    Top5: 49.789    Loss: 2.361

2024-04-23 17:27:42,224 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 17:27:42,226 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:27:42,226 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:27:42,235 - 

2024-04-23 17:27:42,235 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:27:46,088 - Epoch: [75][   10/  267]    Overall Loss 2.373916    Objective Loss 2.373916                                        LR 0.100000    Time 0.385000    
2024-04-23 17:27:48,634 - Epoch: [56][  100/  123]    Loss 0.783872    Top1 74.187500    Top5 96.625000    
2024-04-23 17:27:48,790 - Epoch: [75][   20/  267]    Overall Loss 2.384816    Objective Loss 2.384816                                        LR 0.100000    Time 0.327425    
2024-04-23 17:27:51,642 - Epoch: [75][   30/  267]    Overall Loss 2.365105    Objective Loss 2.365105                                        LR 0.100000    Time 0.313236    
2024-04-23 17:27:54,117 - Epoch: [75][   40/  267]    Overall Loss 2.368753    Objective Loss 2.368753                                        LR 0.100000    Time 0.296728    
2024-04-23 17:27:54,530 - Epoch: [56][  123/  123]    Loss 0.802360    Top1 73.248408    Top5 96.560510    
2024-04-23 17:27:54,864 - ==> Top1: 73.248    Top5: 96.561    Loss: 0.802

2024-04-23 17:27:54,875 - ==> Best [Top1: 74.268   Top5: 96.662   Sparsity:0.00   Params: 376752 on epoch: 54]
2024-04-23 17:27:54,875 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:27:54,941 - 

2024-04-23 17:27:54,943 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:27:56,787 - Epoch: [75][   50/  267]    Overall Loss 2.368032    Objective Loss 2.368032                                        LR 0.100000    Time 0.290706    
2024-04-23 17:27:59,112 - Epoch: [75][   60/  267]    Overall Loss 2.367527    Objective Loss 2.367527                                        LR 0.100000    Time 0.280955    
2024-04-23 17:28:02,508 - Epoch: [75][   70/  267]    Overall Loss 2.364735    Objective Loss 2.364735                                        LR 0.100000    Time 0.289281    
2024-04-23 17:28:05,103 - Epoch: [75][   80/  267]    Overall Loss 2.367208    Objective Loss 2.367208                                        LR 0.100000    Time 0.285513    
2024-04-23 17:28:08,405 - Epoch: [75][   90/  267]    Overall Loss 2.364165    Objective Loss 2.364165                                        LR 0.100000    Time 0.290447    
2024-04-23 17:28:10,728 - Epoch: [75][  100/  267]    Overall Loss 2.369141    Objective Loss 2.369141                                        LR 0.100000    Time 0.284599    
2024-04-23 17:28:13,919 - Epoch: [75][  110/  267]    Overall Loss 2.372349    Objective Loss 2.372349                                        LR 0.100000    Time 0.287708    
2024-04-23 17:28:16,060 - Epoch: [75][  120/  267]    Overall Loss 2.375017    Objective Loss 2.375017                                        LR 0.100000    Time 0.281552    
2024-04-23 17:28:19,423 - Epoch: [75][  130/  267]    Overall Loss 2.379138    Objective Loss 2.379138                                        LR 0.100000    Time 0.285742    
2024-04-23 17:28:21,648 - Epoch: [75][  140/  267]    Overall Loss 2.376710    Objective Loss 2.376710                                        LR 0.100000    Time 0.281205    
2024-04-23 17:28:24,521 - Epoch: [57][  100/  296]    Overall Loss 0.942893    Objective Loss 0.942893                                        LR 0.000320    Time 0.295547    
2024-04-23 17:28:24,827 - Epoch: [75][  150/  267]    Overall Loss 2.373583    Objective Loss 2.373583                                        LR 0.100000    Time 0.283632    
2024-04-23 17:28:27,014 - Epoch: [75][  160/  267]    Overall Loss 2.374444    Objective Loss 2.374444                                        LR 0.100000    Time 0.279558    
2024-04-23 17:28:30,086 - Epoch: [75][  170/  267]    Overall Loss 2.370825    Objective Loss 2.370825                                        LR 0.100000    Time 0.281165    
2024-04-23 17:28:32,272 - Epoch: [75][  180/  267]    Overall Loss 2.370617    Objective Loss 2.370617                                        LR 0.100000    Time 0.277671    
2024-04-23 17:28:35,097 - Epoch: [75][  190/  267]    Overall Loss 2.369063    Objective Loss 2.369063                                        LR 0.100000    Time 0.277904    
2024-04-23 17:28:36,421 - Epoch: [75][  200/  267]    Overall Loss 2.369378    Objective Loss 2.369378                                        LR 0.100000    Time 0.270620    
2024-04-23 17:28:39,613 - Epoch: [75][  210/  267]    Overall Loss 2.369022    Objective Loss 2.369022                                        LR 0.100000    Time 0.272912    
2024-04-23 17:28:42,124 - Epoch: [75][  220/  267]    Overall Loss 2.368438    Objective Loss 2.368438                                        LR 0.100000    Time 0.271906    
2024-04-23 17:28:44,772 - Epoch: [75][  230/  267]    Overall Loss 2.367416    Objective Loss 2.367416                                        LR 0.100000    Time 0.271584    
2024-04-23 17:28:47,136 - Epoch: [75][  240/  267]    Overall Loss 2.366605    Objective Loss 2.366605                                        LR 0.100000    Time 0.270105    
2024-04-23 17:28:50,042 - Epoch: [75][  250/  267]    Overall Loss 2.365414    Objective Loss 2.365414                                        LR 0.100000    Time 0.270912    
2024-04-23 17:28:50,714 - Epoch: [57][  200/  296]    Overall Loss 0.946424    Objective Loss 0.946424                                        LR 0.000320    Time 0.278637    
2024-04-23 17:28:52,115 - Epoch: [75][  260/  267]    Overall Loss 2.362966    Objective Loss 2.362966                                        LR 0.100000    Time 0.268450    
2024-04-23 17:28:53,938 - Epoch: [75][  267/  267]    Overall Loss 2.362914    Objective Loss 2.362914    Top1 9.302326    Top5 55.813953    LR 0.100000    Time 0.268231    
2024-04-23 17:28:54,171 - --- validate (epoch=75)-----------
2024-04-23 17:28:54,172 - 946 samples (32 per mini-batch)
2024-04-23 17:28:58,330 - Epoch: [75][   10/   30]    Loss 2.406528    Top1 9.375000    Top5 50.625000    
2024-04-23 17:29:00,604 - Epoch: [75][   20/   30]    Loss 2.413181    Top1 9.531250    Top5 49.062500    
2024-04-23 17:29:03,304 - Epoch: [75][   30/   30]    Loss 2.399988    Top1 10.465116    Top5 49.577167    
2024-04-23 17:29:03,476 - ==> Top1: 10.465    Top5: 49.577    Loss: 2.400

2024-04-23 17:29:03,478 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 17:29:03,483 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:29:03,483 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:29:03,505 - 

2024-04-23 17:29:03,506 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:29:07,236 - Epoch: [76][   10/  267]    Overall Loss 2.362621    Objective Loss 2.362621                                        LR 0.100000    Time 0.372606    
2024-04-23 17:29:09,511 - Epoch: [76][   20/  267]    Overall Loss 2.357265    Objective Loss 2.357265                                        LR 0.100000    Time 0.299891    
2024-04-23 17:29:12,711 - Epoch: [76][   30/  267]    Overall Loss 2.355450    Objective Loss 2.355450                                        LR 0.100000    Time 0.306488    
2024-04-23 17:29:13,896 - Epoch: [57][  296/  296]    Overall Loss 0.959302    Objective Loss 0.959302    Top1 72.131148    Top5 95.081967    LR 0.000320    Time 0.266514    
2024-04-23 17:29:14,234 - --- validate (epoch=57)-----------
2024-04-23 17:29:14,235 - 3925 samples (32 per mini-batch)
2024-04-23 17:29:14,367 - Epoch: [76][   40/  267]    Overall Loss 2.353784    Objective Loss 2.353784                                        LR 0.100000    Time 0.271177    
2024-04-23 17:29:16,927 - Epoch: [76][   50/  267]    Overall Loss 2.353309    Objective Loss 2.353309                                        LR 0.100000    Time 0.268096    
2024-04-23 17:29:19,228 - Epoch: [76][   60/  267]    Overall Loss 2.351287    Objective Loss 2.351287                                        LR 0.100000    Time 0.261713    
2024-04-23 17:29:22,423 - Epoch: [76][   70/  267]    Overall Loss 2.356202    Objective Loss 2.356202                                        LR 0.100000    Time 0.269935    
2024-04-23 17:29:24,607 - Epoch: [76][   80/  267]    Overall Loss 2.354528    Objective Loss 2.354528                                        LR 0.100000    Time 0.263452    
2024-04-23 17:29:27,483 - Epoch: [76][   90/  267]    Overall Loss 2.351585    Objective Loss 2.351585                                        LR 0.100000    Time 0.266103    
2024-04-23 17:29:29,385 - Epoch: [76][  100/  267]    Overall Loss 2.354282    Objective Loss 2.354282                                        LR 0.100000    Time 0.258484    
2024-04-23 17:29:32,220 - Epoch: [76][  110/  267]    Overall Loss 2.353399    Objective Loss 2.353399                                        LR 0.100000    Time 0.260727    
2024-04-23 17:29:34,141 - Epoch: [76][  120/  267]    Overall Loss 2.357319    Objective Loss 2.357319                                        LR 0.100000    Time 0.254981    
2024-04-23 17:29:37,292 - Epoch: [76][  130/  267]    Overall Loss 2.358711    Objective Loss 2.358711                                        LR 0.100000    Time 0.259582    
2024-04-23 17:29:39,654 - Epoch: [76][  140/  267]    Overall Loss 2.359715    Objective Loss 2.359715                                        LR 0.100000    Time 0.257883    
2024-04-23 17:29:42,896 - Epoch: [76][  150/  267]    Overall Loss 2.360914    Objective Loss 2.360914                                        LR 0.100000    Time 0.262289    
2024-04-23 17:29:43,041 - Epoch: [57][  100/  123]    Loss 0.884016    Top1 70.500000    Top5 95.750000    
2024-04-23 17:29:45,033 - Epoch: [76][  160/  267]    Overall Loss 2.362429    Objective Loss 2.362429                                        LR 0.100000    Time 0.259230    
2024-04-23 17:29:48,150 - Epoch: [76][  170/  267]    Overall Loss 2.362265    Objective Loss 2.362265                                        LR 0.100000    Time 0.262296    
2024-04-23 17:29:49,627 - Epoch: [57][  123/  123]    Loss 0.865361    Top1 71.133758    Top5 95.923567    
2024-04-23 17:29:49,903 - ==> Top1: 71.134    Top5: 95.924    Loss: 0.865

2024-04-23 17:29:49,910 - ==> Best [Top1: 74.268   Top5: 96.662   Sparsity:0.00   Params: 376752 on epoch: 54]
2024-04-23 17:29:49,910 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:29:49,957 - 

2024-04-23 17:29:49,959 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:29:50,018 - Epoch: [76][  180/  267]    Overall Loss 2.363390    Objective Loss 2.363390                                        LR 0.100000    Time 0.258089    
2024-04-23 17:29:52,429 - Epoch: [76][  190/  267]    Overall Loss 2.363229    Objective Loss 2.363229                                        LR 0.100000    Time 0.257180    
2024-04-23 17:29:54,441 - Epoch: [76][  200/  267]    Overall Loss 2.364329    Objective Loss 2.364329                                        LR 0.100000    Time 0.254347    
2024-04-23 17:29:57,334 - Epoch: [76][  210/  267]    Overall Loss 2.363069    Objective Loss 2.363069                                        LR 0.100000    Time 0.255999    
2024-04-23 17:29:59,406 - Epoch: [76][  220/  267]    Overall Loss 2.363625    Objective Loss 2.363625                                        LR 0.100000    Time 0.253767    
2024-04-23 17:30:02,003 - Epoch: [76][  230/  267]    Overall Loss 2.362929    Objective Loss 2.362929                                        LR 0.100000    Time 0.254013    
2024-04-23 17:30:03,881 - Epoch: [76][  240/  267]    Overall Loss 2.362962    Objective Loss 2.362962                                        LR 0.100000    Time 0.251241    
2024-04-23 17:30:06,906 - Epoch: [76][  250/  267]    Overall Loss 2.363106    Objective Loss 2.363106                                        LR 0.100000    Time 0.253278    
2024-04-23 17:30:09,022 - Epoch: [76][  260/  267]    Overall Loss 2.364557    Objective Loss 2.364557                                        LR 0.100000    Time 0.251664    
2024-04-23 17:30:10,947 - Epoch: [76][  267/  267]    Overall Loss 2.365220    Objective Loss 2.365220    Top1 4.651163    Top5 58.139535    LR 0.100000    Time 0.252265    
2024-04-23 17:30:11,161 - --- validate (epoch=76)-----------
2024-04-23 17:30:11,163 - 946 samples (32 per mini-batch)
2024-04-23 17:30:15,182 - Epoch: [76][   10/   30]    Loss 2.328383    Top1 9.375000    Top5 52.187500    
2024-04-23 17:30:17,445 - Epoch: [76][   20/   30]    Loss 2.321816    Top1 9.687500    Top5 52.031250    
2024-04-23 17:30:17,788 - Epoch: [58][  100/  296]    Overall Loss 0.915285    Objective Loss 0.915285                                        LR 0.000320    Time 0.278049    
2024-04-23 17:30:19,676 - Epoch: [76][   30/   30]    Loss 2.325788    Top1 10.465116    Top5 51.057082    
2024-04-23 17:30:19,939 - ==> Top1: 10.465    Top5: 51.057    Loss: 2.326

2024-04-23 17:30:19,941 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 17:30:19,946 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:30:19,946 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:30:19,969 - 

2024-04-23 17:30:19,969 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:30:23,848 - Epoch: [77][   10/  267]    Overall Loss 2.350959    Objective Loss 2.350959                                        LR 0.100000    Time 0.387461    
2024-04-23 17:30:26,021 - Epoch: [77][   20/  267]    Overall Loss 2.359904    Objective Loss 2.359904                                        LR 0.100000    Time 0.302232    
2024-04-23 17:30:28,323 - Epoch: [77][   30/  267]    Overall Loss 2.368107    Objective Loss 2.368107                                        LR 0.100000    Time 0.278115    
2024-04-23 17:30:31,019 - Epoch: [77][   40/  267]    Overall Loss 2.365553    Objective Loss 2.365553                                        LR 0.100000    Time 0.275923    
2024-04-23 17:30:33,244 - Epoch: [77][   50/  267]    Overall Loss 2.371902    Objective Loss 2.371902                                        LR 0.100000    Time 0.265173    
2024-04-23 17:30:36,091 - Epoch: [77][   60/  267]    Overall Loss 2.386297    Objective Loss 2.386297                                        LR 0.100000    Time 0.268393    
2024-04-23 17:30:38,325 - Epoch: [77][   70/  267]    Overall Loss 2.383536    Objective Loss 2.383536                                        LR 0.100000    Time 0.261925    
2024-04-23 17:30:41,088 - Epoch: [58][  200/  296]    Overall Loss 0.949989    Objective Loss 0.949989                                        LR 0.000320    Time 0.255421    
2024-04-23 17:30:41,634 - Epoch: [77][   80/  267]    Overall Loss 2.382450    Objective Loss 2.382450                                        LR 0.100000    Time 0.270499    
2024-04-23 17:30:43,723 - Epoch: [77][   90/  267]    Overall Loss 2.379592    Objective Loss 2.379592                                        LR 0.100000    Time 0.263622    
2024-04-23 17:30:46,659 - Epoch: [77][  100/  267]    Overall Loss 2.375770    Objective Loss 2.375770                                        LR 0.100000    Time 0.266588    
2024-04-23 17:30:48,703 - Epoch: [77][  110/  267]    Overall Loss 2.374370    Objective Loss 2.374370                                        LR 0.100000    Time 0.260913    
2024-04-23 17:30:51,772 - Epoch: [77][  120/  267]    Overall Loss 2.375030    Objective Loss 2.375030                                        LR 0.100000    Time 0.264722    
2024-04-23 17:30:53,853 - Epoch: [77][  130/  267]    Overall Loss 2.375042    Objective Loss 2.375042                                        LR 0.100000    Time 0.260335    
2024-04-23 17:30:56,844 - Epoch: [77][  140/  267]    Overall Loss 2.374983    Objective Loss 2.374983                                        LR 0.100000    Time 0.263082    
2024-04-23 17:30:59,152 - Epoch: [77][  150/  267]    Overall Loss 2.372087    Objective Loss 2.372087                                        LR 0.100000    Time 0.260912    
2024-04-23 17:31:02,036 - Epoch: [77][  160/  267]    Overall Loss 2.370751    Objective Loss 2.370751                                        LR 0.100000    Time 0.262606    
2024-04-23 17:31:04,692 - Epoch: [77][  170/  267]    Overall Loss 2.372151    Objective Loss 2.372151                                        LR 0.100000    Time 0.262765    
2024-04-23 17:31:05,857 - Epoch: [58][  296/  296]    Overall Loss 0.948273    Objective Loss 0.948273    Top1 65.573770    Top5 96.721311    LR 0.000320    Time 0.256190    
2024-04-23 17:31:06,185 - --- validate (epoch=58)-----------
2024-04-23 17:31:06,187 - 3925 samples (32 per mini-batch)
2024-04-23 17:31:06,674 - Epoch: [77][  180/  267]    Overall Loss 2.374783    Objective Loss 2.374783                                        LR 0.100000    Time 0.259165    
2024-04-23 17:31:09,179 - Epoch: [77][  190/  267]    Overall Loss 2.373975    Objective Loss 2.373975                                        LR 0.100000    Time 0.258698    
2024-04-23 17:31:11,324 - Epoch: [77][  200/  267]    Overall Loss 2.372765    Objective Loss 2.372765                                        LR 0.100000    Time 0.256470    
2024-04-23 17:31:14,191 - Epoch: [77][  210/  267]    Overall Loss 2.370435    Objective Loss 2.370435                                        LR 0.100000    Time 0.257899    
2024-04-23 17:31:15,885 - Epoch: [77][  220/  267]    Overall Loss 2.371963    Objective Loss 2.371963                                        LR 0.100000    Time 0.253860    
2024-04-23 17:31:18,629 - Epoch: [77][  230/  267]    Overall Loss 2.371112    Objective Loss 2.371112                                        LR 0.100000    Time 0.254739    
2024-04-23 17:31:20,693 - Epoch: [77][  240/  267]    Overall Loss 2.371895    Objective Loss 2.371895                                        LR 0.100000    Time 0.252714    
2024-04-23 17:31:24,084 - Epoch: [77][  250/  267]    Overall Loss 2.371383    Objective Loss 2.371383                                        LR 0.100000    Time 0.256155    
2024-04-23 17:31:25,920 - Epoch: [77][  260/  267]    Overall Loss 2.370513    Objective Loss 2.370513                                        LR 0.100000    Time 0.253354    
2024-04-23 17:31:27,441 - Epoch: [77][  267/  267]    Overall Loss 2.370305    Objective Loss 2.370305    Top1 9.302326    Top5 55.813953    LR 0.100000    Time 0.252401    
2024-04-23 17:31:27,638 - --- validate (epoch=77)-----------
2024-04-23 17:31:27,640 - 946 samples (32 per mini-batch)
2024-04-23 17:31:31,605 - Epoch: [77][   10/   30]    Loss 2.407048    Top1 11.250000    Top5 55.000000    
2024-04-23 17:31:32,635 - Epoch: [58][  100/  123]    Loss 0.842899    Top1 72.562500    Top5 96.187500    
2024-04-23 17:31:33,831 - Epoch: [77][   20/   30]    Loss 2.446977    Top1 10.937500    Top5 51.562500    
2024-04-23 17:31:36,349 - Epoch: [77][   30/   30]    Loss 2.454732    Top1 10.570825    Top5 50.845666    
2024-04-23 17:31:36,611 - ==> Top1: 10.571    Top5: 50.846    Loss: 2.455

2024-04-23 17:31:36,614 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 17:31:36,619 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:31:36,620 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:31:36,640 - 

2024-04-23 17:31:36,641 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:31:39,562 - Epoch: [78][   10/  267]    Overall Loss 2.343387    Objective Loss 2.343387                                        LR 0.100000    Time 0.291642    
2024-04-23 17:31:39,781 - Epoch: [58][  123/  123]    Loss 0.831355    Top1 72.866242    Top5 96.254777    
2024-04-23 17:31:40,046 - ==> Top1: 72.866    Top5: 96.255    Loss: 0.831

2024-04-23 17:31:40,057 - ==> Best [Top1: 74.268   Top5: 96.662   Sparsity:0.00   Params: 376752 on epoch: 54]
2024-04-23 17:31:40,058 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:31:40,113 - 

2024-04-23 17:31:40,115 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:31:41,455 - Epoch: [78][   20/  267]    Overall Loss 2.356473    Objective Loss 2.356473                                        LR 0.100000    Time 0.240349    
2024-04-23 17:31:44,467 - Epoch: [78][   30/  267]    Overall Loss 2.379714    Objective Loss 2.379714                                        LR 0.100000    Time 0.260524    
2024-04-23 17:31:47,146 - Epoch: [78][   40/  267]    Overall Loss 2.373158    Objective Loss 2.373158                                        LR 0.100000    Time 0.262302    
2024-04-23 17:31:49,676 - Epoch: [78][   50/  267]    Overall Loss 2.369551    Objective Loss 2.369551                                        LR 0.100000    Time 0.260368    
2024-04-23 17:31:51,873 - Epoch: [78][   60/  267]    Overall Loss 2.364361    Objective Loss 2.364361                                        LR 0.100000    Time 0.253536    
2024-04-23 17:31:54,394 - Epoch: [78][   70/  267]    Overall Loss 2.360629    Objective Loss 2.360629                                        LR 0.100000    Time 0.253281    
2024-04-23 17:31:57,073 - Epoch: [78][   80/  267]    Overall Loss 2.362380    Objective Loss 2.362380                                        LR 0.100000    Time 0.255076    
2024-04-23 17:31:59,896 - Epoch: [78][   90/  267]    Overall Loss 2.366057    Objective Loss 2.366057                                        LR 0.100000    Time 0.258074    
2024-04-23 17:32:02,146 - Epoch: [78][  100/  267]    Overall Loss 2.365920    Objective Loss 2.365920                                        LR 0.100000    Time 0.254725    
2024-04-23 17:32:05,187 - Epoch: [78][  110/  267]    Overall Loss 2.367243    Objective Loss 2.367243                                        LR 0.100000    Time 0.259190    
2024-04-23 17:32:06,302 - Epoch: [59][  100/  296]    Overall Loss 0.916549    Objective Loss 0.916549                                        LR 0.000320    Time 0.261647    
2024-04-23 17:32:06,839 - Epoch: [78][  120/  267]    Overall Loss 2.365666    Objective Loss 2.365666                                        LR 0.100000    Time 0.251331    
2024-04-23 17:32:09,742 - Epoch: [78][  130/  267]    Overall Loss 2.370269    Objective Loss 2.370269                                        LR 0.100000    Time 0.254295    
2024-04-23 17:32:11,981 - Epoch: [78][  140/  267]    Overall Loss 2.370195    Objective Loss 2.370195                                        LR 0.100000    Time 0.252098    
2024-04-23 17:32:15,027 - Epoch: [78][  150/  267]    Overall Loss 2.369841    Objective Loss 2.369841                                        LR 0.100000    Time 0.255580    
2024-04-23 17:32:17,045 - Epoch: [78][  160/  267]    Overall Loss 2.369272    Objective Loss 2.369272                                        LR 0.100000    Time 0.252184    
2024-04-23 17:32:19,990 - Epoch: [78][  170/  267]    Overall Loss 2.368256    Objective Loss 2.368256                                        LR 0.100000    Time 0.254655    
2024-04-23 17:32:22,201 - Epoch: [78][  180/  267]    Overall Loss 2.372301    Objective Loss 2.372301                                        LR 0.100000    Time 0.252767    
2024-04-23 17:32:25,602 - Epoch: [78][  190/  267]    Overall Loss 2.372998    Objective Loss 2.372998                                        LR 0.100000    Time 0.257348    
2024-04-23 17:32:27,611 - Epoch: [78][  200/  267]    Overall Loss 2.373787    Objective Loss 2.373787                                        LR 0.100000    Time 0.254509    
2024-04-23 17:32:30,486 - Epoch: [78][  210/  267]    Overall Loss 2.373552    Objective Loss 2.373552                                        LR 0.100000    Time 0.256068    
2024-04-23 17:32:32,686 - Epoch: [78][  220/  267]    Overall Loss 2.374505    Objective Loss 2.374505                                        LR 0.100000    Time 0.254415    
2024-04-23 17:32:33,117 - Epoch: [59][  200/  296]    Overall Loss 0.940931    Objective Loss 0.940931                                        LR 0.000320    Time 0.264790    
2024-04-23 17:32:35,424 - Epoch: [78][  230/  267]    Overall Loss 2.373389    Objective Loss 2.373389                                        LR 0.100000    Time 0.255243    
2024-04-23 17:32:37,665 - Epoch: [78][  240/  267]    Overall Loss 2.372384    Objective Loss 2.372384                                        LR 0.100000    Time 0.253930    
2024-04-23 17:32:40,963 - Epoch: [78][  250/  267]    Overall Loss 2.373940    Objective Loss 2.373940                                        LR 0.100000    Time 0.256951    
2024-04-23 17:32:42,932 - Epoch: [78][  260/  267]    Overall Loss 2.374882    Objective Loss 2.374882                                        LR 0.100000    Time 0.254630    
2024-04-23 17:32:44,590 - Epoch: [78][  267/  267]    Overall Loss 2.374702    Objective Loss 2.374702    Top1 9.302326    Top5 55.813953    LR 0.100000    Time 0.254156    
2024-04-23 17:32:44,835 - --- validate (epoch=78)-----------
2024-04-23 17:32:44,837 - 946 samples (32 per mini-batch)
2024-04-23 17:32:48,312 - Epoch: [78][   10/   30]    Loss 2.416611    Top1 10.937500    Top5 52.812500    
2024-04-23 17:32:50,460 - Epoch: [78][   20/   30]    Loss 2.447910    Top1 8.750000    Top5 50.156250    
2024-04-23 17:32:52,836 - Epoch: [78][   30/   30]    Loss 2.441950    Top1 9.196617    Top5 51.057082    
2024-04-23 17:32:53,049 - ==> Top1: 9.197    Top5: 51.057    Loss: 2.442

2024-04-23 17:32:53,052 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 17:32:53,060 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:32:53,061 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:32:53,075 - 

2024-04-23 17:32:53,076 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:32:55,456 - Epoch: [59][  296/  296]    Overall Loss 0.942201    Objective Loss 0.942201    Top1 75.409836    Top5 98.360656    LR 0.000320    Time 0.254311    
2024-04-23 17:32:55,763 - --- validate (epoch=59)-----------
2024-04-23 17:32:55,765 - 3925 samples (32 per mini-batch)
2024-04-23 17:32:56,367 - Epoch: [79][   10/  267]    Overall Loss 2.385115    Objective Loss 2.385115                                        LR 0.100000    Time 0.328734    
2024-04-23 17:32:58,247 - Epoch: [79][   20/  267]    Overall Loss 2.372884    Objective Loss 2.372884                                        LR 0.100000    Time 0.258172    
2024-04-23 17:33:01,510 - Epoch: [79][   30/  267]    Overall Loss 2.374819    Objective Loss 2.374819                                        LR 0.100000    Time 0.280775    
2024-04-23 17:33:04,304 - Epoch: [79][   40/  267]    Overall Loss 2.363555    Objective Loss 2.363555                                        LR 0.100000    Time 0.280346    
2024-04-23 17:33:07,982 - Epoch: [79][   50/  267]    Overall Loss 2.366950    Objective Loss 2.366950                                        LR 0.100000    Time 0.297764    
2024-04-23 17:33:10,439 - Epoch: [79][   60/  267]    Overall Loss 2.365444    Objective Loss 2.365444                                        LR 0.100000    Time 0.289044    
2024-04-23 17:33:13,679 - Epoch: [79][   70/  267]    Overall Loss 2.362218    Objective Loss 2.362218                                        LR 0.100000    Time 0.293977    
2024-04-23 17:33:15,863 - Epoch: [79][   80/  267]    Overall Loss 2.362872    Objective Loss 2.362872                                        LR 0.100000    Time 0.284491    
2024-04-23 17:33:18,785 - Epoch: [79][   90/  267]    Overall Loss 2.363338    Objective Loss 2.363338                                        LR 0.100000    Time 0.285312    
2024-04-23 17:33:21,781 - Epoch: [79][  100/  267]    Overall Loss 2.365660    Objective Loss 2.365660                                        LR 0.100000    Time 0.286708    
2024-04-23 17:33:24,356 - Epoch: [79][  110/  267]    Overall Loss 2.362305    Objective Loss 2.362305                                        LR 0.100000    Time 0.284019    
2024-04-23 17:33:26,411 - Epoch: [59][  100/  123]    Loss 0.829654    Top1 73.781250    Top5 96.218750    
2024-04-23 17:33:27,101 - Epoch: [79][  120/  267]    Overall Loss 2.364597    Objective Loss 2.364597                                        LR 0.100000    Time 0.283201    
2024-04-23 17:33:29,434 - Epoch: [79][  130/  267]    Overall Loss 2.363885    Objective Loss 2.363885                                        LR 0.100000    Time 0.279337    
2024-04-23 17:33:31,748 - Epoch: [79][  140/  267]    Overall Loss 2.366184    Objective Loss 2.366184                                        LR 0.100000    Time 0.275887    
2024-04-23 17:33:32,484 - Epoch: [59][  123/  123]    Loss 0.831942    Top1 73.987261    Top5 96.254777    
2024-04-23 17:33:32,762 - ==> Top1: 73.987    Top5: 96.255    Loss: 0.832

2024-04-23 17:33:32,773 - ==> Best [Top1: 74.268   Top5: 96.662   Sparsity:0.00   Params: 376752 on epoch: 54]
2024-04-23 17:33:32,775 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:33:32,834 - 

2024-04-23 17:33:32,835 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:33:33,522 - Epoch: [79][  150/  267]    Overall Loss 2.365410    Objective Loss 2.365410                                        LR 0.100000    Time 0.269301    
2024-04-23 17:33:35,982 - Epoch: [79][  160/  267]    Overall Loss 2.364730    Objective Loss 2.364730                                        LR 0.100000    Time 0.267820    
2024-04-23 17:33:38,299 - Epoch: [79][  170/  267]    Overall Loss 2.364412    Objective Loss 2.364412                                        LR 0.100000    Time 0.265676    
2024-04-23 17:33:41,006 - Epoch: [79][  180/  267]    Overall Loss 2.361527    Objective Loss 2.361527                                        LR 0.100000    Time 0.265935    
2024-04-23 17:33:42,604 - Epoch: [79][  190/  267]    Overall Loss 2.360208    Objective Loss 2.360208                                        LR 0.100000    Time 0.260337    
2024-04-23 17:33:45,426 - Epoch: [79][  200/  267]    Overall Loss 2.363087    Objective Loss 2.363087                                        LR 0.100000    Time 0.261412    
2024-04-23 17:33:47,411 - Epoch: [79][  210/  267]    Overall Loss 2.364394    Objective Loss 2.364394                                        LR 0.100000    Time 0.258401    
2024-04-23 17:33:50,379 - Epoch: [79][  220/  267]    Overall Loss 2.363253    Objective Loss 2.363253                                        LR 0.100000    Time 0.260125    
2024-04-23 17:33:51,916 - Epoch: [79][  230/  267]    Overall Loss 2.364041    Objective Loss 2.364041                                        LR 0.100000    Time 0.255487    
2024-04-23 17:33:54,313 - Epoch: [79][  240/  267]    Overall Loss 2.365049    Objective Loss 2.365049                                        LR 0.100000    Time 0.254811    
2024-04-23 17:33:56,658 - Epoch: [79][  250/  267]    Overall Loss 2.365936    Objective Loss 2.365936                                        LR 0.100000    Time 0.253989    
2024-04-23 17:33:58,725 - Epoch: [60][  100/  296]    Overall Loss 0.953116    Objective Loss 0.953116                                        LR 0.000320    Time 0.258673    
2024-04-23 17:33:58,898 - Epoch: [79][  260/  267]    Overall Loss 2.366223    Objective Loss 2.366223                                        LR 0.100000    Time 0.252820    
2024-04-23 17:34:00,434 - Epoch: [79][  267/  267]    Overall Loss 2.365730    Objective Loss 2.365730    Top1 11.627907    Top5 48.837209    LR 0.100000    Time 0.251932    
2024-04-23 17:34:00,726 - --- validate (epoch=79)-----------
2024-04-23 17:34:00,728 - 946 samples (32 per mini-batch)
2024-04-23 17:34:04,719 - Epoch: [79][   10/   30]    Loss 2.358580    Top1 7.500000    Top5 48.750000    
2024-04-23 17:34:07,068 - Epoch: [79][   20/   30]    Loss 2.359703    Top1 8.125000    Top5 49.375000    
2024-04-23 17:34:09,052 - Epoch: [79][   30/   30]    Loss 2.355147    Top1 9.196617    Top5 50.845666    
2024-04-23 17:34:09,208 - ==> Top1: 9.197    Top5: 50.846    Loss: 2.355

2024-04-23 17:34:09,210 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 17:34:09,214 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:34:09,215 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:34:09,233 - 

2024-04-23 17:34:09,234 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:34:13,457 - Epoch: [80][   10/  267]    Overall Loss 2.348207    Objective Loss 2.348207                                        LR 0.100000    Time 0.421917    
2024-04-23 17:34:15,807 - Epoch: [80][   20/  267]    Overall Loss 2.344085    Objective Loss 2.344085                                        LR 0.100000    Time 0.328268    
2024-04-23 17:34:18,948 - Epoch: [80][   30/  267]    Overall Loss 2.338794    Objective Loss 2.338794                                        LR 0.100000    Time 0.323438    
2024-04-23 17:34:21,330 - Epoch: [80][   40/  267]    Overall Loss 2.340993    Objective Loss 2.340993                                        LR 0.100000    Time 0.302042    
2024-04-23 17:34:21,705 - Epoch: [60][  200/  296]    Overall Loss 0.946614    Objective Loss 0.946614                                        LR 0.000320    Time 0.244131    
2024-04-23 17:34:24,033 - Epoch: [80][   50/  267]    Overall Loss 2.349875    Objective Loss 2.349875                                        LR 0.100000    Time 0.295622    
2024-04-23 17:34:26,804 - Epoch: [80][   60/  267]    Overall Loss 2.355108    Objective Loss 2.355108                                        LR 0.100000    Time 0.292478    
2024-04-23 17:34:29,310 - Epoch: [80][   70/  267]    Overall Loss 2.354121    Objective Loss 2.354121                                        LR 0.100000    Time 0.286442    
2024-04-23 17:34:31,562 - Epoch: [80][   80/  267]    Overall Loss 2.357116    Objective Loss 2.357116                                        LR 0.100000    Time 0.278750    
2024-04-23 17:34:34,499 - Epoch: [80][   90/  267]    Overall Loss 2.363730    Objective Loss 2.363730                                        LR 0.100000    Time 0.280363    
2024-04-23 17:34:36,288 - Epoch: [80][  100/  267]    Overall Loss 2.364103    Objective Loss 2.364103                                        LR 0.100000    Time 0.270188    
2024-04-23 17:34:38,558 - Epoch: [80][  110/  267]    Overall Loss 2.366113    Objective Loss 2.366113                                        LR 0.100000    Time 0.266230    
2024-04-23 17:34:40,676 - Epoch: [80][  120/  267]    Overall Loss 2.365603    Objective Loss 2.365603                                        LR 0.100000    Time 0.261667    
2024-04-23 17:34:43,132 - Epoch: [60][  296/  296]    Overall Loss 0.948342    Objective Loss 0.948342    Top1 65.573770    Top5 95.081967    LR 0.000320    Time 0.237269    
2024-04-23 17:34:43,220 - Epoch: [80][  130/  267]    Overall Loss 2.363026    Objective Loss 2.363026                                        LR 0.100000    Time 0.261085    
2024-04-23 17:34:43,432 - --- validate (epoch=60)-----------
2024-04-23 17:34:43,433 - 3925 samples (32 per mini-batch)
2024-04-23 17:34:44,592 - Epoch: [80][  140/  267]    Overall Loss 2.363323    Objective Loss 2.363323                                        LR 0.100000    Time 0.252219    
2024-04-23 17:34:47,448 - Epoch: [80][  150/  267]    Overall Loss 2.364686    Objective Loss 2.364686                                        LR 0.100000    Time 0.254417    
2024-04-23 17:34:49,539 - Epoch: [80][  160/  267]    Overall Loss 2.364108    Objective Loss 2.364108                                        LR 0.100000    Time 0.251574    
2024-04-23 17:34:52,176 - Epoch: [80][  170/  267]    Overall Loss 2.364191    Objective Loss 2.364191                                        LR 0.100000    Time 0.252271    
2024-04-23 17:34:54,247 - Epoch: [80][  180/  267]    Overall Loss 2.365301    Objective Loss 2.365301                                        LR 0.100000    Time 0.249707    
2024-04-23 17:34:57,312 - Epoch: [80][  190/  267]    Overall Loss 2.366290    Objective Loss 2.366290                                        LR 0.100000    Time 0.252683    
2024-04-23 17:34:59,108 - Epoch: [80][  200/  267]    Overall Loss 2.364412    Objective Loss 2.364412                                        LR 0.100000    Time 0.249010    
2024-04-23 17:35:01,328 - Epoch: [80][  210/  267]    Overall Loss 2.365065    Objective Loss 2.365065                                        LR 0.100000    Time 0.247684    
2024-04-23 17:35:02,981 - Epoch: [80][  220/  267]    Overall Loss 2.366107    Objective Loss 2.366107                                        LR 0.100000    Time 0.243923    
2024-04-23 17:35:05,453 - Epoch: [80][  230/  267]    Overall Loss 2.366068    Objective Loss 2.366068                                        LR 0.100000    Time 0.244054    
2024-04-23 17:35:07,551 - Epoch: [80][  240/  267]    Overall Loss 2.368193    Objective Loss 2.368193                                        LR 0.100000    Time 0.242612    
2024-04-23 17:35:09,821 - Epoch: [80][  250/  267]    Overall Loss 2.366404    Objective Loss 2.366404                                        LR 0.100000    Time 0.241976    
2024-04-23 17:35:10,031 - Epoch: [60][  100/  123]    Loss 0.818621    Top1 73.250000    Top5 96.250000    
2024-04-23 17:35:11,702 - Epoch: [80][  260/  267]    Overall Loss 2.366666    Objective Loss 2.366666                                        LR 0.100000    Time 0.239893    
2024-04-23 17:35:12,958 - Epoch: [80][  267/  267]    Overall Loss 2.368115    Objective Loss 2.368115    Top1 9.302326    Top5 44.186047    LR 0.100000    Time 0.238298    
2024-04-23 17:35:13,184 - --- validate (epoch=80)-----------
2024-04-23 17:35:13,185 - 946 samples (32 per mini-batch)
2024-04-23 17:35:14,099 - Epoch: [60][  123/  123]    Loss 0.807821    Top1 73.681529    Top5 96.356688    
2024-04-23 17:35:14,371 - ==> Top1: 73.682    Top5: 96.357    Loss: 0.808

2024-04-23 17:35:14,379 - ==> Best [Top1: 74.268   Top5: 96.662   Sparsity:0.00   Params: 376752 on epoch: 54]
2024-04-23 17:35:14,379 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:35:14,418 - 

2024-04-23 17:35:14,418 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:35:17,690 - Epoch: [80][   10/   30]    Loss 2.382991    Top1 8.437500    Top5 49.687500    
2024-04-23 17:35:19,369 - Epoch: [80][   20/   30]    Loss 2.376277    Top1 9.062500    Top5 50.000000    
2024-04-23 17:35:21,516 - Epoch: [80][   30/   30]    Loss 2.363625    Top1 9.830867    Top5 50.739958    
2024-04-23 17:35:21,740 - ==> Top1: 9.831    Top5: 50.740    Loss: 2.364

2024-04-23 17:35:21,742 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 17:35:21,746 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:35:21,747 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:35:21,768 - 

2024-04-23 17:35:21,769 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:35:26,746 - Epoch: [81][   10/  267]    Overall Loss 2.370831    Objective Loss 2.370831                                        LR 0.100000    Time 0.497293    
2024-04-23 17:35:29,166 - Epoch: [81][   20/  267]    Overall Loss 2.362074    Objective Loss 2.362074                                        LR 0.100000    Time 0.369425    
2024-04-23 17:35:31,692 - Epoch: [81][   30/  267]    Overall Loss 2.363414    Objective Loss 2.363414                                        LR 0.100000    Time 0.330386    
2024-04-23 17:35:34,036 - Epoch: [81][   40/  267]    Overall Loss 2.371463    Objective Loss 2.371463                                        LR 0.100000    Time 0.306321    
2024-04-23 17:35:35,113 - Epoch: [61][  100/  296]    Overall Loss 0.936812    Objective Loss 0.936812                                        LR 0.000320    Time 0.206725    
2024-04-23 17:35:36,680 - Epoch: [81][   50/  267]    Overall Loss 2.366355    Objective Loss 2.366355                                        LR 0.100000    Time 0.297887    
2024-04-23 17:35:38,762 - Epoch: [81][   60/  267]    Overall Loss 2.366015    Objective Loss 2.366015                                        LR 0.100000    Time 0.282875    
2024-04-23 17:35:41,940 - Epoch: [81][   70/  267]    Overall Loss 2.368235    Objective Loss 2.368235                                        LR 0.100000    Time 0.287820    
2024-04-23 17:35:44,530 - Epoch: [81][   80/  267]    Overall Loss 2.372634    Objective Loss 2.372634                                        LR 0.100000    Time 0.284191    
2024-04-23 17:35:48,125 - Epoch: [81][   90/  267]    Overall Loss 2.369569    Objective Loss 2.369569                                        LR 0.100000    Time 0.292524    
2024-04-23 17:35:50,394 - Epoch: [81][  100/  267]    Overall Loss 2.368812    Objective Loss 2.368812                                        LR 0.100000    Time 0.285937    
2024-04-23 17:35:54,208 - Epoch: [81][  110/  267]    Overall Loss 2.367956    Objective Loss 2.367956                                        LR 0.100000    Time 0.294586    
2024-04-23 17:35:56,509 - Epoch: [81][  120/  267]    Overall Loss 2.370714    Objective Loss 2.370714                                        LR 0.100000    Time 0.289165    
2024-04-23 17:35:58,600 - Epoch: [61][  200/  296]    Overall Loss 0.939002    Objective Loss 0.939002                                        LR 0.000320    Time 0.220690    
2024-04-23 17:35:59,178 - Epoch: [81][  130/  267]    Overall Loss 2.373612    Objective Loss 2.373612                                        LR 0.100000    Time 0.287445    
2024-04-23 17:36:01,687 - Epoch: [81][  140/  267]    Overall Loss 2.374143    Objective Loss 2.374143                                        LR 0.100000    Time 0.284805    
2024-04-23 17:36:05,420 - Epoch: [81][  150/  267]    Overall Loss 2.373929    Objective Loss 2.373929                                        LR 0.100000    Time 0.290691    
2024-04-23 17:36:07,530 - Epoch: [81][  160/  267]    Overall Loss 2.374334    Objective Loss 2.374334                                        LR 0.100000    Time 0.285689    
2024-04-23 17:36:11,183 - Epoch: [81][  170/  267]    Overall Loss 2.372621    Objective Loss 2.372621                                        LR 0.100000    Time 0.290355    
2024-04-23 17:36:13,255 - Epoch: [81][  180/  267]    Overall Loss 2.373228    Objective Loss 2.373228                                        LR 0.100000    Time 0.285719    
2024-04-23 17:36:15,992 - Epoch: [81][  190/  267]    Overall Loss 2.373134    Objective Loss 2.373134                                        LR 0.100000    Time 0.285069    
2024-04-23 17:36:17,920 - Epoch: [81][  200/  267]    Overall Loss 2.372882    Objective Loss 2.372882                                        LR 0.100000    Time 0.280439    
2024-04-23 17:36:19,092 - Epoch: [61][  296/  296]    Overall Loss 0.936552    Objective Loss 0.936552    Top1 70.491803    Top5 91.803279    LR 0.000320    Time 0.218273    
2024-04-23 17:36:19,402 - --- validate (epoch=61)-----------
2024-04-23 17:36:19,403 - 3925 samples (32 per mini-batch)
2024-04-23 17:36:19,783 - Epoch: [81][  210/  267]    Overall Loss 2.370868    Objective Loss 2.370868                                        LR 0.100000    Time 0.275944    
2024-04-23 17:36:21,184 - Epoch: [81][  220/  267]    Overall Loss 2.369793    Objective Loss 2.369793                                        LR 0.100000    Time 0.269756    
2024-04-23 17:36:24,103 - Epoch: [81][  230/  267]    Overall Loss 2.369846    Objective Loss 2.369846                                        LR 0.100000    Time 0.270687    
2024-04-23 17:36:26,022 - Epoch: [81][  240/  267]    Overall Loss 2.369904    Objective Loss 2.369904                                        LR 0.100000    Time 0.267394    
2024-04-23 17:36:28,945 - Epoch: [81][  250/  267]    Overall Loss 2.369735    Objective Loss 2.369735                                        LR 0.100000    Time 0.268379    
2024-04-23 17:36:30,803 - Epoch: [81][  260/  267]    Overall Loss 2.368712    Objective Loss 2.368712                                        LR 0.100000    Time 0.265189    
2024-04-23 17:36:32,324 - Epoch: [81][  267/  267]    Overall Loss 2.368881    Objective Loss 2.368881    Top1 6.976744    Top5 48.837209    LR 0.100000    Time 0.263926    
2024-04-23 17:36:32,534 - --- validate (epoch=81)-----------
2024-04-23 17:36:32,535 - 946 samples (32 per mini-batch)
2024-04-23 17:36:37,099 - Epoch: [81][   10/   30]    Loss 2.388029    Top1 9.375000    Top5 50.000000    
2024-04-23 17:36:39,838 - Epoch: [81][   20/   30]    Loss 2.400297    Top1 9.687500    Top5 49.531250    
2024-04-23 17:36:41,053 - Epoch: [61][  100/  123]    Loss 0.884275    Top1 70.406250    Top5 95.812500    
2024-04-23 17:36:42,118 - Epoch: [81][   30/   30]    Loss 2.393215    Top1 10.359408    Top5 50.528541    
2024-04-23 17:36:42,373 - ==> Top1: 10.359    Top5: 50.529    Loss: 2.393

2024-04-23 17:36:42,375 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 17:36:42,381 - ==> Best [Top1: 10.994   Top5: 51.268   Sparsity:0.00   Params: 96528 on epoch: 39]
2024-04-23 17:36:42,382 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:36:42,402 - 

2024-04-23 17:36:42,403 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:36:44,545 - Epoch: [61][  123/  123]    Loss 0.885314    Top1 70.420382    Top5 95.847134    
2024-04-23 17:36:44,812 - ==> Top1: 70.420    Top5: 95.847    Loss: 0.885

2024-04-23 17:36:44,822 - ==> Best [Top1: 74.268   Top5: 96.662   Sparsity:0.00   Params: 376752 on epoch: 54]
2024-04-23 17:36:44,823 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:36:44,869 - 

2024-04-23 17:36:44,870 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:36:46,896 - Epoch: [82][   10/  267]    Overall Loss 2.360860    Objective Loss 2.360860                                        LR 0.100000    Time 0.448944    
2024-04-23 17:36:49,121 - Epoch: [82][   20/  267]    Overall Loss 2.358893    Objective Loss 2.358893                                        LR 0.100000    Time 0.335591    
2024-04-23 17:36:52,465 - Epoch: [82][   30/  267]    Overall Loss 2.365546    Objective Loss 2.365546                                        LR 0.100000    Time 0.335055    
2024-04-23 17:36:55,125 - Epoch: [82][   40/  267]    Overall Loss 2.371881    Objective Loss 2.371881                                        LR 0.100000    Time 0.317728    
2024-04-23 17:36:58,192 - Epoch: [82][   50/  267]    Overall Loss 2.368988    Objective Loss 2.368988                                        LR 0.100000    Time 0.315462    
2024-04-23 17:37:00,686 - Epoch: [82][   60/  267]    Overall Loss 2.371619    Objective Loss 2.371619                                        LR 0.100000    Time 0.304413    
2024-04-23 17:37:03,819 - Epoch: [82][   70/  267]    Overall Loss 2.374877    Objective Loss 2.374877                                        LR 0.100000    Time 0.305638    
2024-04-23 17:37:05,740 - Epoch: [62][  100/  296]    Overall Loss 0.939543    Objective Loss 0.939543                                        LR 0.000320    Time 0.208505    
2024-04-23 17:37:06,160 - Epoch: [82][   80/  267]    Overall Loss 2.379453    Objective Loss 2.379453                                        LR 0.100000    Time 0.296662    
2024-04-23 17:37:09,336 - Epoch: [82][   90/  267]    Overall Loss 2.377951    Objective Loss 2.377951                                        LR 0.100000    Time 0.298948    
2024-04-23 17:37:11,418 - Epoch: [82][  100/  267]    Overall Loss 2.380503    Objective Loss 2.380503                                        LR 0.100000    Time 0.289840    
2024-04-23 17:37:14,333 - Epoch: [82][  110/  267]    Overall Loss 2.377324    Objective Loss 2.377324                                        LR 0.100000    Time 0.289966    
2024-04-23 17:37:16,284 - Epoch: [82][  120/  267]    Overall Loss 2.374613    Objective Loss 2.374613                                        LR 0.100000    Time 0.282035    
2024-04-23 17:37:18,606 - Epoch: [82][  130/  267]    Overall Loss 2.376690    Objective Loss 2.376690                                        LR 0.100000    Time 0.278178    
2024-04-23 17:37:20,600 - Epoch: [82][  140/  267]    Overall Loss 2.378013    Objective Loss 2.378013                                        LR 0.100000    Time 0.272527    
2024-04-23 17:37:22,606 - Epoch: [82][  150/  267]    Overall Loss 2.376434    Objective Loss 2.376434                                        LR 0.100000    Time 0.267715    
2024-04-23 17:37:25,212 - Epoch: [82][  160/  267]    Overall Loss 2.374888    Objective Loss 2.374888                                        LR 0.100000    Time 0.267255    
2024-04-23 17:37:27,292 - Epoch: [82][  170/  267]    Overall Loss 2.376288    Objective Loss 2.376288                                        LR 0.100000    Time 0.263747    
2024-04-23 17:37:27,831 - Epoch: [62][  200/  296]    Overall Loss 0.939433    Objective Loss 0.939433                                        LR 0.000320    Time 0.214603    
2024-04-23 17:37:30,084 - Epoch: [82][  180/  267]    Overall Loss 2.377005    Objective Loss 2.377005                                        LR 0.100000    Time 0.264588    
2024-04-23 17:37:31,996 - Epoch: [82][  190/  267]    Overall Loss 2.377228    Objective Loss 2.377228                                        LR 0.100000    Time 0.260710    
2024-04-23 17:37:34,874 - Epoch: [82][  200/  267]    Overall Loss 2.378026    Objective Loss 2.378026                                        LR 0.100000    Time 0.262046    
2024-04-23 17:37:36,987 - Epoch: [82][  210/  267]    Overall Loss 2.376698    Objective Loss 2.376698                                        LR 0.100000    Time 0.259616    
2024-04-23 17:37:39,779 - Epoch: [82][  220/  267]    Overall Loss 2.374724    Objective Loss 2.374724                                        LR 0.100000    Time 0.260494    
2024-04-23 17:37:41,508 - Epoch: [82][  230/  267]    Overall Loss 2.372814    Objective Loss 2.372814                                        LR 0.100000    Time 0.256674    
2024-04-23 17:37:44,186 - Epoch: [82][  240/  267]    Overall Loss 2.375080    Objective Loss 2.375080                                        LR 0.100000    Time 0.257122    
2024-04-23 17:37:46,211 - Epoch: [82][  250/  267]    Overall Loss 2.376038    Objective Loss 2.376038                                        LR 0.100000    Time 0.254925    
2024-04-23 17:37:48,680 - Epoch: [82][  260/  267]    Overall Loss 2.375866    Objective Loss 2.375866                                        LR 0.100000    Time 0.254606    
2024-04-23 17:37:49,682 - Epoch: [82][  267/  267]    Overall Loss 2.375596    Objective Loss 2.375596    Top1 6.976744    Top5 46.511628    LR 0.100000    Time 0.251674    
2024-04-23 17:37:49,885 - --- validate (epoch=82)-----------
2024-04-23 17:37:49,886 - 946 samples (32 per mini-batch)
2024-04-23 17:37:50,083 - Epoch: [62][  296/  296]    Overall Loss 0.944409    Objective Loss 0.944409    Top1 68.852459    Top5 98.360656    LR 0.000320    Time 0.220110    
2024-04-23 17:37:50,383 - --- validate (epoch=62)-----------
2024-04-23 17:37:50,385 - 3925 samples (32 per mini-batch)
2024-04-23 17:37:52,815 - Epoch: [82][   10/   30]    Loss 2.323553    Top1 9.375000    Top5 51.250000    
2024-04-23 17:37:55,694 - Epoch: [82][   20/   30]    Loss 2.325115    Top1 9.687500    Top5 50.781250    
2024-04-23 17:37:58,423 - Epoch: [82][   30/   30]    Loss 2.315206    Top1 10.993658    Top5 51.479915    
2024-04-23 17:37:58,611 - ==> Top1: 10.994    Top5: 51.480    Loss: 2.315

2024-04-23 17:37:58,613 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 17:37:58,617 - ==> Best [Top1: 10.994   Top5: 51.480   Sparsity:0.00   Params: 96528 on epoch: 82]
2024-04-23 17:37:58,617 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:37:58,640 - 

2024-04-23 17:37:58,641 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:38:02,393 - Epoch: [83][   10/  267]    Overall Loss 2.410801    Objective Loss 2.410801                                        LR 0.100000    Time 0.374874    
2024-04-23 17:38:04,589 - Epoch: [83][   20/  267]    Overall Loss 2.385429    Objective Loss 2.385429                                        LR 0.100000    Time 0.297079    
2024-04-23 17:38:07,364 - Epoch: [83][   30/  267]    Overall Loss 2.382373    Objective Loss 2.382373                                        LR 0.100000    Time 0.290437    
2024-04-23 17:38:09,451 - Epoch: [83][   40/  267]    Overall Loss 2.376881    Objective Loss 2.376881                                        LR 0.100000    Time 0.269934    
2024-04-23 17:38:12,512 - Epoch: [83][   50/  267]    Overall Loss 2.371794    Objective Loss 2.371794                                        LR 0.100000    Time 0.277119    
2024-04-23 17:38:14,911 - Epoch: [83][   60/  267]    Overall Loss 2.374835    Objective Loss 2.374835                                        LR 0.100000    Time 0.270867    
2024-04-23 17:38:17,898 - Epoch: [83][   70/  267]    Overall Loss 2.376143    Objective Loss 2.376143                                        LR 0.100000    Time 0.274794    
2024-04-23 17:38:19,727 - Epoch: [83][   80/  267]    Overall Loss 2.373155    Objective Loss 2.373155                                        LR 0.100000    Time 0.263271    
2024-04-23 17:38:20,083 - Epoch: [62][  100/  123]    Loss 0.779405    Top1 74.000000    Top5 96.625000    
2024-04-23 17:38:22,306 - Epoch: [83][   90/  267]    Overall Loss 2.372564    Objective Loss 2.372564                                        LR 0.100000    Time 0.262648    
2024-04-23 17:38:24,361 - Epoch: [83][  100/  267]    Overall Loss 2.370697    Objective Loss 2.370697                                        LR 0.100000    Time 0.256903    
2024-04-23 17:38:25,888 - Epoch: [62][  123/  123]    Loss 0.780846    Top1 74.242038    Top5 96.509554    
2024-04-23 17:38:26,223 - ==> Top1: 74.242    Top5: 96.510    Loss: 0.781

2024-04-23 17:38:26,238 - ==> Best [Top1: 74.268   Top5: 96.662   Sparsity:0.00   Params: 376752 on epoch: 54]
2024-04-23 17:38:26,239 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:38:26,299 - 

2024-04-23 17:38:26,300 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:38:26,703 - Epoch: [83][  110/  267]    Overall Loss 2.370726    Objective Loss 2.370726                                        LR 0.100000    Time 0.254811    
2024-04-23 17:38:28,484 - Epoch: [83][  120/  267]    Overall Loss 2.369601    Objective Loss 2.369601                                        LR 0.100000    Time 0.248394    
2024-04-23 17:38:31,743 - Epoch: [83][  130/  267]    Overall Loss 2.367692    Objective Loss 2.367692                                        LR 0.100000    Time 0.254326    
2024-04-23 17:38:33,844 - Epoch: [83][  140/  267]    Overall Loss 2.369439    Objective Loss 2.369439                                        LR 0.100000    Time 0.251146    
2024-04-23 17:38:36,904 - Epoch: [83][  150/  267]    Overall Loss 2.368127    Objective Loss 2.368127                                        LR 0.100000    Time 0.254782    
2024-04-23 17:38:38,854 - Epoch: [83][  160/  267]    Overall Loss 2.367975    Objective Loss 2.367975                                        LR 0.100000    Time 0.251028    
2024-04-23 17:38:41,805 - Epoch: [83][  170/  267]    Overall Loss 2.369234    Objective Loss 2.369234                                        LR 0.100000    Time 0.253596    
2024-04-23 17:38:44,151 - Epoch: [83][  180/  267]    Overall Loss 2.368361    Objective Loss 2.368361                                        LR 0.100000    Time 0.252523    
2024-04-23 17:38:46,677 - Epoch: [83][  190/  267]    Overall Loss 2.366924    Objective Loss 2.366924                                        LR 0.100000    Time 0.252514    
2024-04-23 17:38:48,642 - Epoch: [83][  200/  267]    Overall Loss 2.366529    Objective Loss 2.366529                                        LR 0.100000    Time 0.249697    
2024-04-23 17:38:50,982 - Epoch: [83][  210/  267]    Overall Loss 2.366110    Objective Loss 2.366110                                        LR 0.100000    Time 0.248932    
2024-04-23 17:38:52,188 - Epoch: [63][  100/  296]    Overall Loss 0.951467    Objective Loss 0.951467                                        LR 0.000320    Time 0.258661    
2024-04-23 17:38:52,890 - Epoch: [83][  220/  267]    Overall Loss 2.366094    Objective Loss 2.366094                                        LR 0.100000    Time 0.246277    
2024-04-23 17:38:55,273 - Epoch: [83][  230/  267]    Overall Loss 2.365296    Objective Loss 2.365296                                        LR 0.100000    Time 0.245916    
2024-04-23 17:38:56,799 - Epoch: [83][  240/  267]    Overall Loss 2.365489    Objective Loss 2.365489                                        LR 0.100000    Time 0.242014    
2024-04-23 17:38:59,606 - Epoch: [83][  250/  267]    Overall Loss 2.367389    Objective Loss 2.367389                                        LR 0.100000    Time 0.243550    
2024-04-23 17:39:01,784 - Epoch: [83][  260/  267]    Overall Loss 2.368257    Objective Loss 2.368257                                        LR 0.100000    Time 0.242549    
2024-04-23 17:39:03,226 - Epoch: [83][  267/  267]    Overall Loss 2.369551    Objective Loss 2.369551    Top1 6.976744    Top5 34.883721    LR 0.100000    Time 0.241579    
2024-04-23 17:39:03,469 - --- validate (epoch=83)-----------
2024-04-23 17:39:03,470 - 946 samples (32 per mini-batch)
2024-04-23 17:39:07,270 - Epoch: [83][   10/   30]    Loss 2.345692    Top1 8.750000    Top5 50.000000    
2024-04-23 17:39:09,266 - Epoch: [83][   20/   30]    Loss 2.366725    Top1 9.062500    Top5 48.125000    
2024-04-23 17:39:11,610 - Epoch: [83][   30/   30]    Loss 2.368839    Top1 8.456660    Top5 48.202960    
2024-04-23 17:39:11,805 - ==> Top1: 8.457    Top5: 48.203    Loss: 2.369

2024-04-23 17:39:11,807 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 17:39:11,812 - ==> Best [Top1: 10.994   Top5: 51.480   Sparsity:0.00   Params: 96528 on epoch: 82]
2024-04-23 17:39:11,813 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:39:11,830 - 

2024-04-23 17:39:11,832 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:39:15,408 - Epoch: [63][  200/  296]    Overall Loss 0.922416    Objective Loss 0.922416                                        LR 0.000320    Time 0.245330    
2024-04-23 17:39:16,097 - Epoch: [84][   10/  267]    Overall Loss 2.362197    Objective Loss 2.362197                                        LR 0.100000    Time 0.426106    
2024-04-23 17:39:18,203 - Epoch: [84][   20/  267]    Overall Loss 2.374354    Objective Loss 2.374354                                        LR 0.100000    Time 0.318203    
2024-04-23 17:39:21,557 - Epoch: [84][   30/  267]    Overall Loss 2.366790    Objective Loss 2.366790                                        LR 0.100000    Time 0.323822    
2024-04-23 17:39:24,367 - Epoch: [84][   40/  267]    Overall Loss 2.366870    Objective Loss 2.366870                                        LR 0.100000    Time 0.313034    
2024-04-23 17:39:27,783 - Epoch: [84][   50/  267]    Overall Loss 2.367745    Objective Loss 2.367745                                        LR 0.100000    Time 0.318679    
2024-04-23 17:39:30,488 - Epoch: [84][   60/  267]    Overall Loss 2.369588    Objective Loss 2.369588                                        LR 0.100000    Time 0.310604    
2024-04-23 17:39:34,021 - Epoch: [84][   70/  267]    Overall Loss 2.368890    Objective Loss 2.368890                                        LR 0.100000    Time 0.316663    
2024-04-23 17:39:36,557 - Epoch: [84][   80/  267]    Overall Loss 2.363308    Objective Loss 2.363308                                        LR 0.100000    Time 0.308736    
2024-04-23 17:39:39,573 - Epoch: [84][   90/  267]    Overall Loss 2.368203    Objective Loss 2.368203                                        LR 0.100000    Time 0.307911    
2024-04-23 17:39:41,506 - Epoch: [63][  296/  296]    Overall Loss 0.918421    Objective Loss 0.918421    Top1 70.491803    Top5 96.721311    LR 0.000320    Time 0.253866    
2024-04-23 17:39:41,639 - Epoch: [84][  100/  267]    Overall Loss 2.368882    Objective Loss 2.368882                                        LR 0.100000    Time 0.297756    
2024-04-23 17:39:41,894 - --- validate (epoch=63)-----------
2024-04-23 17:39:41,896 - 3925 samples (32 per mini-batch)
2024-04-23 17:39:44,948 - Epoch: [84][  110/  267]    Overall Loss 2.366715    Objective Loss 2.366715                                        LR 0.100000    Time 0.300738    
2024-04-23 17:39:46,804 - Epoch: [84][  120/  267]    Overall Loss 2.367224    Objective Loss 2.367224                                        LR 0.100000    Time 0.291129    
2024-04-23 17:39:50,270 - Epoch: [84][  130/  267]    Overall Loss 2.365421    Objective Loss 2.365421                                        LR 0.100000    Time 0.295364    
2024-04-23 17:39:52,603 - Epoch: [84][  140/  267]    Overall Loss 2.366014    Objective Loss 2.366014                                        LR 0.100000    Time 0.290901    
2024-04-23 17:39:55,697 - Epoch: [84][  150/  267]    Overall Loss 2.366740    Objective Loss 2.366740                                        LR 0.100000    Time 0.292120    
2024-04-23 17:39:57,979 - Epoch: [84][  160/  267]    Overall Loss 2.365467    Objective Loss 2.365467                                        LR 0.100000    Time 0.288104    
2024-04-23 17:40:01,129 - Epoch: [84][  170/  267]    Overall Loss 2.363248    Objective Loss 2.363248                                        LR 0.100000    Time 0.289655    
2024-04-23 17:40:03,307 - Epoch: [84][  180/  267]    Overall Loss 2.364830    Objective Loss 2.364830                                        LR 0.100000    Time 0.285645    
2024-04-23 17:40:06,259 - Epoch: [84][  190/  267]    Overall Loss 2.365129    Objective Loss 2.365129                                        LR 0.100000    Time 0.286129    
2024-04-23 17:40:08,063 - Epoch: [84][  200/  267]    Overall Loss 2.365148    Objective Loss 2.365148                                        LR 0.100000    Time 0.280822    
2024-04-23 17:40:09,679 - Epoch: [63][  100/  123]    Loss 0.800982    Top1 73.937500    Top5 96.343750    
2024-04-23 17:40:10,416 - Epoch: [84][  210/  267]    Overall Loss 2.364578    Objective Loss 2.364578                                        LR 0.100000    Time 0.278637    
2024-04-23 17:40:12,385 - Epoch: [84][  220/  267]    Overall Loss 2.366760    Objective Loss 2.366760                                        LR 0.100000    Time 0.274901    
2024-04-23 17:40:14,792 - Epoch: [84][  230/  267]    Overall Loss 2.369052    Objective Loss 2.369052                                        LR 0.100000    Time 0.273400    
2024-04-23 17:40:15,148 - Epoch: [63][  123/  123]    Loss 0.791093    Top1 74.369427    Top5 96.535032    
2024-04-23 17:40:15,471 - ==> Top1: 74.369    Top5: 96.535    Loss: 0.791

2024-04-23 17:40:15,483 - ==> Best [Top1: 74.369   Top5: 96.535   Sparsity:0.00   Params: 376752 on epoch: 63]
2024-04-23 17:40:15,484 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:40:15,561 - 

2024-04-23 17:40:15,562 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:40:16,654 - Epoch: [84][  240/  267]    Overall Loss 2.369276    Objective Loss 2.369276                                        LR 0.100000    Time 0.269754    
2024-04-23 17:40:18,953 - Epoch: [84][  250/  267]    Overall Loss 2.367811    Objective Loss 2.367811                                        LR 0.100000    Time 0.268147    
2024-04-23 17:40:21,603 - Epoch: [84][  260/  267]    Overall Loss 2.367738    Objective Loss 2.367738                                        LR 0.100000    Time 0.268011    
2024-04-23 17:40:22,877 - Epoch: [84][  267/  267]    Overall Loss 2.368957    Objective Loss 2.368957    Top1 6.976744    Top5 41.860465    LR 0.100000    Time 0.265743    
2024-04-23 17:40:23,104 - --- validate (epoch=84)-----------
2024-04-23 17:40:23,105 - 946 samples (32 per mini-batch)
2024-04-23 17:40:27,104 - Epoch: [84][   10/   30]    Loss 2.324000    Top1 14.062500    Top5 51.250000    
2024-04-23 17:40:29,537 - Epoch: [84][   20/   30]    Loss 2.336256    Top1 11.406250    Top5 50.156250    
2024-04-23 17:40:32,086 - Epoch: [84][   30/   30]    Loss 2.340600    Top1 9.830867    Top5 49.471459    
2024-04-23 17:40:32,345 - ==> Top1: 9.831    Top5: 49.471    Loss: 2.341

2024-04-23 17:40:32,348 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 17:40:32,354 - ==> Best [Top1: 10.994   Top5: 51.480   Sparsity:0.00   Params: 96528 on epoch: 82]
2024-04-23 17:40:32,355 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:40:32,377 - 

2024-04-23 17:40:32,378 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:40:36,491 - Epoch: [85][   10/  267]    Overall Loss 2.332680    Objective Loss 2.332680                                        LR 0.100000    Time 0.410929    
2024-04-23 17:40:38,373 - Epoch: [85][   20/  267]    Overall Loss 2.334460    Objective Loss 2.334460                                        LR 0.100000    Time 0.299397    
2024-04-23 17:40:41,767 - Epoch: [85][   30/  267]    Overall Loss 2.350142    Objective Loss 2.350142                                        LR 0.100000    Time 0.312609    
2024-04-23 17:40:42,423 - Epoch: [64][  100/  296]    Overall Loss 0.923174    Objective Loss 0.923174                                        LR 0.000320    Time 0.268383    
2024-04-23 17:40:44,220 - Epoch: [85][   40/  267]    Overall Loss 2.344469    Objective Loss 2.344469                                        LR 0.100000    Time 0.295695    
2024-04-23 17:40:47,738 - Epoch: [85][   50/  267]    Overall Loss 2.346198    Objective Loss 2.346198                                        LR 0.100000    Time 0.306873    
2024-04-23 17:40:49,831 - Epoch: [85][   60/  267]    Overall Loss 2.344706    Objective Loss 2.344706                                        LR 0.100000    Time 0.290547    
2024-04-23 17:40:52,633 - Epoch: [85][   70/  267]    Overall Loss 2.341838    Objective Loss 2.341838                                        LR 0.100000    Time 0.289029    
2024-04-23 17:40:54,608 - Epoch: [85][   80/  267]    Overall Loss 2.344149    Objective Loss 2.344149                                        LR 0.100000    Time 0.277547    
2024-04-23 17:40:57,437 - Epoch: [85][   90/  267]    Overall Loss 2.347188    Objective Loss 2.347188                                        LR 0.100000    Time 0.278105    
2024-04-23 17:40:59,491 - Epoch: [85][  100/  267]    Overall Loss 2.352647    Objective Loss 2.352647                                        LR 0.100000    Time 0.270809    
2024-04-23 17:41:02,541 - Epoch: [85][  110/  267]    Overall Loss 2.352996    Objective Loss 2.352996                                        LR 0.100000    Time 0.273882    
2024-04-23 17:41:04,570 - Epoch: [85][  120/  267]    Overall Loss 2.356798    Objective Loss 2.356798                                        LR 0.100000    Time 0.267940    
2024-04-23 17:41:07,299 - Epoch: [85][  130/  267]    Overall Loss 2.357897    Objective Loss 2.357897                                        LR 0.100000    Time 0.268294    
2024-04-23 17:41:07,370 - Epoch: [64][  200/  296]    Overall Loss 0.905983    Objective Loss 0.905983                                        LR 0.000320    Time 0.258821    
2024-04-23 17:41:09,056 - Epoch: [85][  140/  267]    Overall Loss 2.354957    Objective Loss 2.354957                                        LR 0.100000    Time 0.261661    
2024-04-23 17:41:12,015 - Epoch: [85][  150/  267]    Overall Loss 2.355891    Objective Loss 2.355891                                        LR 0.100000    Time 0.263922    
2024-04-23 17:41:14,047 - Epoch: [85][  160/  267]    Overall Loss 2.355436    Objective Loss 2.355436                                        LR 0.100000    Time 0.260098    
2024-04-23 17:41:17,050 - Epoch: [85][  170/  267]    Overall Loss 2.355691    Objective Loss 2.355691                                        LR 0.100000    Time 0.262444    
2024-04-23 17:41:19,500 - Epoch: [85][  180/  267]    Overall Loss 2.356328    Objective Loss 2.356328                                        LR 0.100000    Time 0.261456    
2024-04-23 17:41:22,029 - Epoch: [85][  190/  267]    Overall Loss 2.358543    Objective Loss 2.358543                                        LR 0.100000    Time 0.260993    
2024-04-23 17:41:24,311 - Epoch: [85][  200/  267]    Overall Loss 2.360322    Objective Loss 2.360322                                        LR 0.100000    Time 0.259337    
2024-04-23 17:41:27,048 - Epoch: [85][  210/  267]    Overall Loss 2.360642    Objective Loss 2.360642                                        LR 0.100000    Time 0.260003    
2024-04-23 17:41:29,008 - Epoch: [85][  220/  267]    Overall Loss 2.361567    Objective Loss 2.361567                                        LR 0.100000    Time 0.257079    
2024-04-23 17:41:31,178 - Epoch: [64][  296/  296]    Overall Loss 0.910201    Objective Loss 0.910201    Top1 62.295082    Top5 91.803279    LR 0.000320    Time 0.255229    
2024-04-23 17:41:31,330 - Epoch: [85][  230/  267]    Overall Loss 2.360686    Objective Loss 2.360686                                        LR 0.100000    Time 0.255985    
2024-04-23 17:41:31,425 - --- validate (epoch=64)-----------
2024-04-23 17:41:31,426 - 3925 samples (32 per mini-batch)
2024-04-23 17:41:33,823 - Epoch: [85][  240/  267]    Overall Loss 2.361371    Objective Loss 2.361371                                        LR 0.100000    Time 0.255695    
2024-04-23 17:41:35,680 - Epoch: [85][  250/  267]    Overall Loss 2.361508    Objective Loss 2.361508                                        LR 0.100000    Time 0.252879    
2024-04-23 17:41:37,875 - Epoch: [85][  260/  267]    Overall Loss 2.360808    Objective Loss 2.360808                                        LR 0.100000    Time 0.251585    
2024-04-23 17:41:39,219 - Epoch: [85][  267/  267]    Overall Loss 2.360457    Objective Loss 2.360457    Top1 2.325581    Top5 37.209302    LR 0.100000    Time 0.250015    
2024-04-23 17:41:39,497 - --- validate (epoch=85)-----------
2024-04-23 17:41:39,498 - 946 samples (32 per mini-batch)
2024-04-23 17:41:43,476 - Epoch: [85][   10/   30]    Loss 2.344954    Top1 9.375000    Top5 51.875000    
2024-04-23 17:41:45,522 - Epoch: [85][   20/   30]    Loss 2.333858    Top1 8.437500    Top5 52.656250    
2024-04-23 17:41:47,965 - Epoch: [85][   30/   30]    Loss 2.340545    Top1 9.196617    Top5 51.268499    
2024-04-23 17:41:48,155 - ==> Top1: 9.197    Top5: 51.268    Loss: 2.341

2024-04-23 17:41:48,156 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 17:41:48,160 - ==> Best [Top1: 10.994   Top5: 51.480   Sparsity:0.00   Params: 96528 on epoch: 82]
2024-04-23 17:41:48,160 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:41:48,179 - 

2024-04-23 17:41:48,180 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:41:52,023 - Epoch: [86][   10/  267]    Overall Loss 2.363413    Objective Loss 2.363413                                        LR 0.100000    Time 0.383977    
2024-04-23 17:41:54,463 - Epoch: [86][   20/  267]    Overall Loss 2.368568    Objective Loss 2.368568                                        LR 0.100000    Time 0.313821    
2024-04-23 17:41:56,309 - Epoch: [64][  100/  123]    Loss 0.818329    Top1 72.500000    Top5 96.375000    
2024-04-23 17:41:57,335 - Epoch: [86][   30/  267]    Overall Loss 2.368647    Objective Loss 2.368647                                        LR 0.100000    Time 0.304828    
2024-04-23 17:41:59,481 - Epoch: [86][   40/  267]    Overall Loss 2.371555    Objective Loss 2.371555                                        LR 0.100000    Time 0.282196    
2024-04-23 17:42:02,341 - Epoch: [86][   50/  267]    Overall Loss 2.368664    Objective Loss 2.368664                                        LR 0.100000    Time 0.282903    
2024-04-23 17:42:02,709 - Epoch: [64][  123/  123]    Loss 0.822091    Top1 72.611465    Top5 96.356688    
2024-04-23 17:42:02,966 - ==> Top1: 72.611    Top5: 96.357    Loss: 0.822

2024-04-23 17:42:02,977 - ==> Best [Top1: 74.369   Top5: 96.535   Sparsity:0.00   Params: 376752 on epoch: 63]
2024-04-23 17:42:02,978 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:42:03,033 - 

2024-04-23 17:42:03,034 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:42:03,945 - Epoch: [86][   60/  267]    Overall Loss 2.368566    Objective Loss 2.368566                                        LR 0.100000    Time 0.262436    
2024-04-23 17:42:06,734 - Epoch: [86][   70/  267]    Overall Loss 2.374698    Objective Loss 2.374698                                        LR 0.100000    Time 0.264732    
2024-04-23 17:42:08,572 - Epoch: [86][   80/  267]    Overall Loss 2.377564    Objective Loss 2.377564                                        LR 0.100000    Time 0.254584    
2024-04-23 17:42:10,936 - Epoch: [86][   90/  267]    Overall Loss 2.372679    Objective Loss 2.372679                                        LR 0.100000    Time 0.252534    
2024-04-23 17:42:13,002 - Epoch: [86][  100/  267]    Overall Loss 2.369794    Objective Loss 2.369794                                        LR 0.100000    Time 0.247909    
2024-04-23 17:42:15,410 - Epoch: [86][  110/  267]    Overall Loss 2.369500    Objective Loss 2.369500                                        LR 0.100000    Time 0.247230    
2024-04-23 17:42:16,991 - Epoch: [86][  120/  267]    Overall Loss 2.367084    Objective Loss 2.367084                                        LR 0.100000    Time 0.239786    
2024-04-23 17:42:19,795 - Epoch: [86][  130/  267]    Overall Loss 2.368841    Objective Loss 2.368841                                        LR 0.100000    Time 0.242882    
2024-04-23 17:42:21,611 - Epoch: [86][  140/  267]    Overall Loss 2.367553    Objective Loss 2.367553                                        LR 0.100000    Time 0.238485    
2024-04-23 17:42:24,280 - Epoch: [86][  150/  267]    Overall Loss 2.367509    Objective Loss 2.367509                                        LR 0.100000    Time 0.240356    
2024-04-23 17:42:26,260 - Epoch: [86][  160/  267]    Overall Loss 2.367058    Objective Loss 2.367058                                        LR 0.100000    Time 0.237689    
2024-04-23 17:42:27,870 - Epoch: [65][  100/  296]    Overall Loss 0.933975    Objective Loss 0.933975                                        LR 0.000320    Time 0.248103    
2024-04-23 17:42:28,733 - Epoch: [86][  170/  267]    Overall Loss 2.367170    Objective Loss 2.367170                                        LR 0.100000    Time 0.238234    
2024-04-23 17:42:30,639 - Epoch: [86][  180/  267]    Overall Loss 2.366756    Objective Loss 2.366756                                        LR 0.100000    Time 0.235567    
2024-04-23 17:42:33,537 - Epoch: [86][  190/  267]    Overall Loss 2.367702    Objective Loss 2.367702                                        LR 0.100000    Time 0.238409    
2024-04-23 17:42:35,738 - Epoch: [86][  200/  267]    Overall Loss 2.368475    Objective Loss 2.368475                                        LR 0.100000    Time 0.237479    
2024-04-23 17:42:38,803 - Epoch: [86][  210/  267]    Overall Loss 2.367567    Objective Loss 2.367567                                        LR 0.100000    Time 0.240752    
2024-04-23 17:42:41,105 - Epoch: [86][  220/  267]    Overall Loss 2.366099    Objective Loss 2.366099                                        LR 0.100000    Time 0.240260    
2024-04-23 17:42:44,033 - Epoch: [86][  230/  267]    Overall Loss 2.366117    Objective Loss 2.366117                                        LR 0.100000    Time 0.242525    
2024-04-23 17:42:46,076 - Epoch: [86][  240/  267]    Overall Loss 2.365788    Objective Loss 2.365788                                        LR 0.100000    Time 0.240918    
2024-04-23 17:42:49,069 - Epoch: [86][  250/  267]    Overall Loss 2.366087    Objective Loss 2.366087                                        LR 0.100000    Time 0.243244    
2024-04-23 17:42:51,148 - Epoch: [86][  260/  267]    Overall Loss 2.368255    Objective Loss 2.368255                                        LR 0.100000    Time 0.241875    
2024-04-23 17:42:51,456 - Epoch: [65][  200/  296]    Overall Loss 0.932240    Objective Loss 0.932240                                        LR 0.000320    Time 0.241877    
2024-04-23 17:42:52,657 - Epoch: [86][  267/  267]    Overall Loss 2.368271    Objective Loss 2.368271    Top1 9.302326    Top5 44.186047    LR 0.100000    Time 0.241178    
2024-04-23 17:42:52,852 - --- validate (epoch=86)-----------
2024-04-23 17:42:52,854 - 946 samples (32 per mini-batch)
2024-04-23 17:42:56,647 - Epoch: [86][   10/   30]    Loss 2.371241    Top1 10.625000    Top5 49.687500    
2024-04-23 17:42:58,449 - Epoch: [86][   20/   30]    Loss 2.372315    Top1 9.531250    Top5 51.250000    
2024-04-23 17:43:01,254 - Epoch: [86][   30/   30]    Loss 2.368615    Top1 9.830867    Top5 51.057082    
2024-04-23 17:43:01,460 - ==> Top1: 9.831    Top5: 51.057    Loss: 2.369

2024-04-23 17:43:01,461 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 17:43:01,467 - ==> Best [Top1: 10.994   Top5: 51.480   Sparsity:0.00   Params: 96528 on epoch: 82]
2024-04-23 17:43:01,468 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:43:01,484 - 

2024-04-23 17:43:01,485 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:43:05,289 - Epoch: [87][   10/  267]    Overall Loss 2.354609    Objective Loss 2.354609                                        LR 0.100000    Time 0.379934    
2024-04-23 17:43:07,610 - Epoch: [87][   20/  267]    Overall Loss 2.356070    Objective Loss 2.356070                                        LR 0.100000    Time 0.305794    
2024-04-23 17:43:10,764 - Epoch: [87][   30/  267]    Overall Loss 2.349782    Objective Loss 2.349782                                        LR 0.100000    Time 0.308872    
2024-04-23 17:43:12,834 - Epoch: [87][   40/  267]    Overall Loss 2.358555    Objective Loss 2.358555                                        LR 0.100000    Time 0.283303    
2024-04-23 17:43:13,764 - Epoch: [65][  296/  296]    Overall Loss 0.924729    Objective Loss 0.924729    Top1 68.852459    Top5 96.721311    LR 0.000320    Time 0.238719    
2024-04-23 17:43:14,076 - --- validate (epoch=65)-----------
2024-04-23 17:43:14,077 - 3925 samples (32 per mini-batch)
2024-04-23 17:43:14,999 - Epoch: [87][   50/  267]    Overall Loss 2.364240    Objective Loss 2.364240                                        LR 0.100000    Time 0.269880    
2024-04-23 17:43:16,979 - Epoch: [87][   60/  267]    Overall Loss 2.359986    Objective Loss 2.359986                                        LR 0.100000    Time 0.257843    
2024-04-23 17:43:19,947 - Epoch: [87][   70/  267]    Overall Loss 2.354799    Objective Loss 2.354799                                        LR 0.100000    Time 0.263346    
2024-04-23 17:43:22,137 - Epoch: [87][   80/  267]    Overall Loss 2.354002    Objective Loss 2.354002                                        LR 0.100000    Time 0.257761    
2024-04-23 17:43:25,032 - Epoch: [87][   90/  267]    Overall Loss 2.357450    Objective Loss 2.357450                                        LR 0.100000    Time 0.261227    
2024-04-23 17:43:27,110 - Epoch: [87][  100/  267]    Overall Loss 2.359825    Objective Loss 2.359825                                        LR 0.100000    Time 0.255851    
2024-04-23 17:43:29,949 - Epoch: [87][  110/  267]    Overall Loss 2.362752    Objective Loss 2.362752                                        LR 0.100000    Time 0.258370    
2024-04-23 17:43:32,127 - Epoch: [87][  120/  267]    Overall Loss 2.361032    Objective Loss 2.361032                                        LR 0.100000    Time 0.254963    
2024-04-23 17:43:34,849 - Epoch: [87][  130/  267]    Overall Loss 2.360224    Objective Loss 2.360224                                        LR 0.100000    Time 0.256266    
2024-04-23 17:43:37,513 - Epoch: [87][  140/  267]    Overall Loss 2.362149    Objective Loss 2.362149                                        LR 0.100000    Time 0.256966    
2024-04-23 17:43:40,012 - Epoch: [87][  150/  267]    Overall Loss 2.359825    Objective Loss 2.359825                                        LR 0.100000    Time 0.256474    
2024-04-23 17:43:42,631 - Epoch: [87][  160/  267]    Overall Loss 2.360634    Objective Loss 2.360634                                        LR 0.100000    Time 0.256792    
2024-04-23 17:43:43,606 - Epoch: [65][  100/  123]    Loss 0.764438    Top1 74.437500    Top5 96.937500    
2024-04-23 17:43:45,166 - Epoch: [87][  170/  267]    Overall Loss 2.359138    Objective Loss 2.359138                                        LR 0.100000    Time 0.256578    
2024-04-23 17:43:47,722 - Epoch: [87][  180/  267]    Overall Loss 2.358598    Objective Loss 2.358598                                        LR 0.100000    Time 0.256507    
2024-04-23 17:43:49,411 - Epoch: [65][  123/  123]    Loss 0.775808    Top1 74.038217    Top5 96.764331    
2024-04-23 17:43:49,697 - ==> Top1: 74.038    Top5: 96.764    Loss: 0.776

2024-04-23 17:43:49,706 - ==> Best [Top1: 74.369   Top5: 96.535   Sparsity:0.00   Params: 376752 on epoch: 63]
2024-04-23 17:43:49,707 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:43:49,756 - 

2024-04-23 17:43:49,758 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:43:49,919 - Epoch: [87][  190/  267]    Overall Loss 2.358150    Objective Loss 2.358150                                        LR 0.100000    Time 0.254556    
2024-04-23 17:43:51,868 - Epoch: [87][  200/  267]    Overall Loss 2.357572    Objective Loss 2.357572                                        LR 0.100000    Time 0.251558    
2024-04-23 17:43:53,926 - Epoch: [87][  210/  267]    Overall Loss 2.359032    Objective Loss 2.359032                                        LR 0.100000    Time 0.249363    
2024-04-23 17:43:56,015 - Epoch: [87][  220/  267]    Overall Loss 2.359251    Objective Loss 2.359251                                        LR 0.100000    Time 0.247508    
2024-04-23 17:43:59,313 - Epoch: [87][  230/  267]    Overall Loss 2.359571    Objective Loss 2.359571                                        LR 0.100000    Time 0.251073    
2024-04-23 17:44:01,600 - Epoch: [87][  240/  267]    Overall Loss 2.360049    Objective Loss 2.360049                                        LR 0.100000    Time 0.250129    
2024-04-23 17:44:05,116 - Epoch: [87][  250/  267]    Overall Loss 2.360669    Objective Loss 2.360669                                        LR 0.100000    Time 0.254170    
2024-04-23 17:44:07,228 - Epoch: [87][  260/  267]    Overall Loss 2.361651    Objective Loss 2.361651                                        LR 0.100000    Time 0.252504    
2024-04-23 17:44:08,914 - Epoch: [87][  267/  267]    Overall Loss 2.361388    Objective Loss 2.361388    Top1 11.627907    Top5 55.813953    LR 0.100000    Time 0.252191    
2024-04-23 17:44:09,134 - --- validate (epoch=87)-----------
2024-04-23 17:44:09,136 - 946 samples (32 per mini-batch)
2024-04-23 17:44:13,966 - Epoch: [87][   10/   30]    Loss 2.364577    Top1 8.750000    Top5 50.312500    
2024-04-23 17:44:17,675 - Epoch: [87][   20/   30]    Loss 2.358266    Top1 10.000000    Top5 49.531250    
2024-04-23 17:44:17,733 - Epoch: [66][  100/  296]    Overall Loss 0.894586    Objective Loss 0.894586                                        LR 0.000320    Time 0.279502    
2024-04-23 17:44:20,585 - Epoch: [87][   30/   30]    Loss 2.347254    Top1 10.993658    Top5 51.902748    
2024-04-23 17:44:20,757 - ==> Top1: 10.994    Top5: 51.903    Loss: 2.347

2024-04-23 17:44:20,758 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 17:44:20,762 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:44:20,763 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:44:20,781 - 

2024-04-23 17:44:20,782 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:44:24,372 - Epoch: [88][   10/  267]    Overall Loss 2.333600    Objective Loss 2.333600                                        LR 0.100000    Time 0.358631    
2024-04-23 17:44:26,725 - Epoch: [88][   20/  267]    Overall Loss 2.341281    Objective Loss 2.341281                                        LR 0.100000    Time 0.296806    
2024-04-23 17:44:29,698 - Epoch: [88][   30/  267]    Overall Loss 2.350546    Objective Loss 2.350546                                        LR 0.100000    Time 0.296835    
2024-04-23 17:44:31,969 - Epoch: [88][   40/  267]    Overall Loss 2.356515    Objective Loss 2.356515                                        LR 0.100000    Time 0.279341    
2024-04-23 17:44:34,891 - Epoch: [88][   50/  267]    Overall Loss 2.360616    Objective Loss 2.360616                                        LR 0.100000    Time 0.281843    
2024-04-23 17:44:37,182 - Epoch: [88][   60/  267]    Overall Loss 2.363772    Objective Loss 2.363772                                        LR 0.100000    Time 0.272988    
2024-04-23 17:44:39,864 - Epoch: [88][   70/  267]    Overall Loss 2.370273    Objective Loss 2.370273                                        LR 0.100000    Time 0.272257    
2024-04-23 17:44:40,497 - Epoch: [66][  200/  296]    Overall Loss 0.899669    Objective Loss 0.899669                                        LR 0.000320    Time 0.253460    
2024-04-23 17:44:42,130 - Epoch: [88][   80/  267]    Overall Loss 2.370762    Objective Loss 2.370762                                        LR 0.100000    Time 0.266512    
2024-04-23 17:44:45,028 - Epoch: [88][   90/  267]    Overall Loss 2.369052    Objective Loss 2.369052                                        LR 0.100000    Time 0.269067    
2024-04-23 17:44:47,229 - Epoch: [88][  100/  267]    Overall Loss 2.365781    Objective Loss 2.365781                                        LR 0.100000    Time 0.264134    
2024-04-23 17:44:50,041 - Epoch: [88][  110/  267]    Overall Loss 2.363489    Objective Loss 2.363489                                        LR 0.100000    Time 0.265660    
2024-04-23 17:44:52,250 - Epoch: [88][  120/  267]    Overall Loss 2.362387    Objective Loss 2.362387                                        LR 0.100000    Time 0.261903    
2024-04-23 17:44:55,045 - Epoch: [88][  130/  267]    Overall Loss 2.362266    Objective Loss 2.362266                                        LR 0.100000    Time 0.263234    
2024-04-23 17:44:57,761 - Epoch: [88][  140/  267]    Overall Loss 2.363404    Objective Loss 2.363404                                        LR 0.100000    Time 0.263806    
2024-04-23 17:45:00,217 - Epoch: [88][  150/  267]    Overall Loss 2.363384    Objective Loss 2.363384                                        LR 0.100000    Time 0.262573    
2024-04-23 17:45:02,925 - Epoch: [88][  160/  267]    Overall Loss 2.362929    Objective Loss 2.362929                                        LR 0.100000    Time 0.263066    
2024-04-23 17:45:04,654 - Epoch: [66][  296/  296]    Overall Loss 0.909452    Objective Loss 0.909452    Top1 67.213115    Top5 96.721311    LR 0.000320    Time 0.252800    
2024-04-23 17:45:04,974 - --- validate (epoch=66)-----------
2024-04-23 17:45:04,975 - 3925 samples (32 per mini-batch)
2024-04-23 17:45:05,306 - Epoch: [88][  170/  267]    Overall Loss 2.363374    Objective Loss 2.363374                                        LR 0.100000    Time 0.261585    
2024-04-23 17:45:07,468 - Epoch: [88][  180/  267]    Overall Loss 2.362534    Objective Loss 2.362534                                        LR 0.100000    Time 0.259045    
2024-04-23 17:45:10,084 - Epoch: [88][  190/  267]    Overall Loss 2.364960    Objective Loss 2.364960                                        LR 0.100000    Time 0.259161    
2024-04-23 17:45:13,265 - Epoch: [88][  200/  267]    Overall Loss 2.365537    Objective Loss 2.365537                                        LR 0.100000    Time 0.262092    
2024-04-23 17:45:15,345 - Epoch: [88][  210/  267]    Overall Loss 2.365613    Objective Loss 2.365613                                        LR 0.100000    Time 0.259501    
2024-04-23 17:45:18,157 - Epoch: [88][  220/  267]    Overall Loss 2.365259    Objective Loss 2.365259                                        LR 0.100000    Time 0.260469    
2024-04-23 17:45:20,013 - Epoch: [88][  230/  267]    Overall Loss 2.364438    Objective Loss 2.364438                                        LR 0.100000    Time 0.257200    
2024-04-23 17:45:22,415 - Epoch: [88][  240/  267]    Overall Loss 2.364718    Objective Loss 2.364718                                        LR 0.100000    Time 0.256481    
2024-04-23 17:45:24,998 - Epoch: [88][  250/  267]    Overall Loss 2.364435    Objective Loss 2.364435                                        LR 0.100000    Time 0.256544    
2024-04-23 17:45:27,590 - Epoch: [88][  260/  267]    Overall Loss 2.363776    Objective Loss 2.363776                                        LR 0.100000    Time 0.256633    
2024-04-23 17:45:28,895 - Epoch: [88][  267/  267]    Overall Loss 2.364022    Objective Loss 2.364022    Top1 4.651163    Top5 39.534884    LR 0.100000    Time 0.254785    
2024-04-23 17:45:29,109 - --- validate (epoch=88)-----------
2024-04-23 17:45:29,110 - 946 samples (32 per mini-batch)
2024-04-23 17:45:33,344 - Epoch: [88][   10/   30]    Loss 2.349876    Top1 12.187500    Top5 54.375000    
2024-04-23 17:45:33,787 - Epoch: [66][  100/  123]    Loss 0.898835    Top1 70.656250    Top5 96.000000    
2024-04-23 17:45:35,699 - Epoch: [88][   20/   30]    Loss 2.372178    Top1 11.562500    Top5 52.656250    
2024-04-23 17:45:38,543 - Epoch: [88][   30/   30]    Loss 2.378906    Top1 10.993658    Top5 51.691332    
2024-04-23 17:45:38,699 - ==> Top1: 10.994    Top5: 51.691    Loss: 2.379

2024-04-23 17:45:38,701 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 17:45:38,706 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:45:38,706 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:45:38,724 - 

2024-04-23 17:45:38,725 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:45:39,842 - Epoch: [66][  123/  123]    Loss 0.898799    Top1 70.624204    Top5 96.101911    
2024-04-23 17:45:40,121 - ==> Top1: 70.624    Top5: 96.102    Loss: 0.899

2024-04-23 17:45:40,133 - ==> Best [Top1: 74.369   Top5: 96.535   Sparsity:0.00   Params: 376752 on epoch: 63]
2024-04-23 17:45:40,134 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:45:40,195 - 

2024-04-23 17:45:40,196 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:45:41,689 - Epoch: [89][   10/  267]    Overall Loss 2.359682    Objective Loss 2.359682                                        LR 0.100000    Time 0.295848    
2024-04-23 17:45:44,526 - Epoch: [89][   20/  267]    Overall Loss 2.368715    Objective Loss 2.368715                                        LR 0.100000    Time 0.289544    
2024-04-23 17:45:47,042 - Epoch: [89][   30/  267]    Overall Loss 2.374003    Objective Loss 2.374003                                        LR 0.100000    Time 0.276817    
2024-04-23 17:45:49,511 - Epoch: [89][   40/  267]    Overall Loss 2.365635    Objective Loss 2.365635                                        LR 0.100000    Time 0.269235    
2024-04-23 17:45:52,849 - Epoch: [89][   50/  267]    Overall Loss 2.356906    Objective Loss 2.356906                                        LR 0.100000    Time 0.282078    
2024-04-23 17:45:55,738 - Epoch: [89][   60/  267]    Overall Loss 2.359018    Objective Loss 2.359018                                        LR 0.100000    Time 0.283161    
2024-04-23 17:45:58,138 - Epoch: [89][   70/  267]    Overall Loss 2.359042    Objective Loss 2.359042                                        LR 0.100000    Time 0.276952    
2024-04-23 17:46:01,321 - Epoch: [89][   80/  267]    Overall Loss 2.360082    Objective Loss 2.360082                                        LR 0.100000    Time 0.282074    
2024-04-23 17:46:03,734 - Epoch: [89][   90/  267]    Overall Loss 2.355279    Objective Loss 2.355279                                        LR 0.100000    Time 0.277510    
2024-04-23 17:46:06,595 - Epoch: [89][  100/  267]    Overall Loss 2.358960    Objective Loss 2.358960                                        LR 0.100000    Time 0.278338    
2024-04-23 17:46:07,818 - Epoch: [67][  100/  296]    Overall Loss 0.928473    Objective Loss 0.928473                                        LR 0.000320    Time 0.275992    
2024-04-23 17:46:08,655 - Epoch: [89][  110/  267]    Overall Loss 2.357628    Objective Loss 2.357628                                        LR 0.100000    Time 0.271736    
2024-04-23 17:46:11,675 - Epoch: [89][  120/  267]    Overall Loss 2.356718    Objective Loss 2.356718                                        LR 0.100000    Time 0.274223    
2024-04-23 17:46:13,772 - Epoch: [89][  130/  267]    Overall Loss 2.355294    Objective Loss 2.355294                                        LR 0.100000    Time 0.269241    
2024-04-23 17:46:16,786 - Epoch: [89][  140/  267]    Overall Loss 2.353932    Objective Loss 2.353932                                        LR 0.100000    Time 0.271517    
2024-04-23 17:46:18,968 - Epoch: [89][  150/  267]    Overall Loss 2.354469    Objective Loss 2.354469                                        LR 0.100000    Time 0.267942    
2024-04-23 17:46:21,924 - Epoch: [89][  160/  267]    Overall Loss 2.356154    Objective Loss 2.356154                                        LR 0.100000    Time 0.269650    
2024-04-23 17:46:24,039 - Epoch: [89][  170/  267]    Overall Loss 2.357623    Objective Loss 2.357623                                        LR 0.100000    Time 0.266212    
2024-04-23 17:46:27,265 - Epoch: [89][  180/  267]    Overall Loss 2.360130    Objective Loss 2.360130                                        LR 0.100000    Time 0.269331    
2024-04-23 17:46:29,671 - Epoch: [89][  190/  267]    Overall Loss 2.361091    Objective Loss 2.361091                                        LR 0.100000    Time 0.267802    
2024-04-23 17:46:32,860 - Epoch: [89][  200/  267]    Overall Loss 2.361806    Objective Loss 2.361806                                        LR 0.100000    Time 0.270341    
2024-04-23 17:46:33,425 - Epoch: [67][  200/  296]    Overall Loss 0.913832    Objective Loss 0.913832                                        LR 0.000320    Time 0.265929    
2024-04-23 17:46:35,839 - Epoch: [89][  210/  267]    Overall Loss 2.364012    Objective Loss 2.364012                                        LR 0.100000    Time 0.271640    
2024-04-23 17:46:39,547 - Epoch: [89][  220/  267]    Overall Loss 2.362584    Objective Loss 2.362584                                        LR 0.100000    Time 0.276130    
2024-04-23 17:46:42,117 - Epoch: [89][  230/  267]    Overall Loss 2.362719    Objective Loss 2.362719                                        LR 0.100000    Time 0.275289    
2024-04-23 17:46:45,618 - Epoch: [89][  240/  267]    Overall Loss 2.363786    Objective Loss 2.363786                                        LR 0.100000    Time 0.278391    
2024-04-23 17:46:48,011 - Epoch: [89][  250/  267]    Overall Loss 2.363228    Objective Loss 2.363228                                        LR 0.100000    Time 0.276812    
2024-04-23 17:46:51,044 - Epoch: [89][  260/  267]    Overall Loss 2.363204    Objective Loss 2.363204                                        LR 0.100000    Time 0.277818    
2024-04-23 17:46:52,262 - Epoch: [89][  267/  267]    Overall Loss 2.363508    Objective Loss 2.363508    Top1 9.302326    Top5 37.209302    LR 0.100000    Time 0.275088    
2024-04-23 17:46:52,505 - --- validate (epoch=89)-----------
2024-04-23 17:46:52,507 - 946 samples (32 per mini-batch)
2024-04-23 17:46:56,658 - Epoch: [89][   10/   30]    Loss 2.385363    Top1 10.937500    Top5 50.937500    
2024-04-23 17:46:58,941 - Epoch: [67][  296/  296]    Overall Loss 0.911850    Objective Loss 0.911850    Top1 80.327869    Top5 98.360656    LR 0.000320    Time 0.265810    
2024-04-23 17:46:58,972 - Epoch: [89][   20/   30]    Loss 2.363159    Top1 11.250000    Top5 51.562500    
2024-04-23 17:46:59,252 - --- validate (epoch=67)-----------
2024-04-23 17:46:59,253 - 3925 samples (32 per mini-batch)
2024-04-23 17:47:02,055 - Epoch: [89][   30/   30]    Loss 2.375674    Top1 9.830867    Top5 50.105708    
2024-04-23 17:47:02,322 - ==> Top1: 9.831    Top5: 50.106    Loss: 2.376

2024-04-23 17:47:02,325 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 17:47:02,330 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:47:02,331 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:47:02,353 - 

2024-04-23 17:47:02,354 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:47:07,268 - Epoch: [90][   10/  267]    Overall Loss 2.397051    Objective Loss 2.397051                                        LR 0.100000    Time 0.490795    
2024-04-23 17:47:09,886 - Epoch: [90][   20/  267]    Overall Loss 2.382740    Objective Loss 2.382740                                        LR 0.100000    Time 0.376125    
2024-04-23 17:47:13,321 - Epoch: [90][   30/  267]    Overall Loss 2.382826    Objective Loss 2.382826                                        LR 0.100000    Time 0.365109    
2024-04-23 17:47:16,168 - Epoch: [90][   40/  267]    Overall Loss 2.380101    Objective Loss 2.380101                                        LR 0.100000    Time 0.344932    
2024-04-23 17:47:18,681 - Epoch: [90][   50/  267]    Overall Loss 2.374374    Objective Loss 2.374374                                        LR 0.100000    Time 0.326116    
2024-04-23 17:47:20,890 - Epoch: [90][   60/  267]    Overall Loss 2.368737    Objective Loss 2.368737                                        LR 0.100000    Time 0.308538    
2024-04-23 17:47:23,771 - Epoch: [90][   70/  267]    Overall Loss 2.364960    Objective Loss 2.364960                                        LR 0.100000    Time 0.305566    
2024-04-23 17:47:26,002 - Epoch: [90][   80/  267]    Overall Loss 2.359052    Objective Loss 2.359052                                        LR 0.100000    Time 0.295224    
2024-04-23 17:47:28,841 - Epoch: [90][   90/  267]    Overall Loss 2.357039    Objective Loss 2.357039                                        LR 0.100000    Time 0.293928    
2024-04-23 17:47:29,713 - Epoch: [67][  100/  123]    Loss 0.825721    Top1 73.031250    Top5 96.375000    
2024-04-23 17:47:30,944 - Epoch: [90][  100/  267]    Overall Loss 2.357318    Objective Loss 2.357318                                        LR 0.100000    Time 0.285534    
2024-04-23 17:47:34,438 - Epoch: [90][  110/  267]    Overall Loss 2.355290    Objective Loss 2.355290                                        LR 0.100000    Time 0.291305    
2024-04-23 17:47:35,697 - Epoch: [67][  123/  123]    Loss 0.837430    Top1 72.611465    Top5 96.229299    
2024-04-23 17:47:36,005 - ==> Top1: 72.611    Top5: 96.229    Loss: 0.837

2024-04-23 17:47:36,020 - ==> Best [Top1: 74.369   Top5: 96.535   Sparsity:0.00   Params: 376752 on epoch: 63]
2024-04-23 17:47:36,021 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:47:36,103 - 

2024-04-23 17:47:36,105 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:47:36,582 - Epoch: [90][  120/  267]    Overall Loss 2.355871    Objective Loss 2.355871                                        LR 0.100000    Time 0.284869    
2024-04-23 17:47:40,271 - Epoch: [90][  130/  267]    Overall Loss 2.353746    Objective Loss 2.353746                                        LR 0.100000    Time 0.291312    
2024-04-23 17:47:43,180 - Epoch: [90][  140/  267]    Overall Loss 2.350962    Objective Loss 2.350962                                        LR 0.100000    Time 0.291257    
2024-04-23 17:47:46,831 - Epoch: [90][  150/  267]    Overall Loss 2.352713    Objective Loss 2.352713                                        LR 0.100000    Time 0.296167    
2024-04-23 17:47:49,314 - Epoch: [90][  160/  267]    Overall Loss 2.354660    Objective Loss 2.354660                                        LR 0.100000    Time 0.293159    
2024-04-23 17:47:53,130 - Epoch: [90][  170/  267]    Overall Loss 2.355840    Objective Loss 2.355840                                        LR 0.100000    Time 0.298342    
2024-04-23 17:47:55,444 - Epoch: [90][  180/  267]    Overall Loss 2.355239    Objective Loss 2.355239                                        LR 0.100000    Time 0.294591    
2024-04-23 17:47:59,077 - Epoch: [90][  190/  267]    Overall Loss 2.355363    Objective Loss 2.355363                                        LR 0.100000    Time 0.298192    
2024-04-23 17:48:01,370 - Epoch: [90][  200/  267]    Overall Loss 2.355680    Objective Loss 2.355680                                        LR 0.100000    Time 0.294730    
2024-04-23 17:48:03,937 - Epoch: [90][  210/  267]    Overall Loss 2.356047    Objective Loss 2.356047                                        LR 0.100000    Time 0.292903    
2024-04-23 17:48:06,160 - Epoch: [90][  220/  267]    Overall Loss 2.354914    Objective Loss 2.354914                                        LR 0.100000    Time 0.289677    
2024-04-23 17:48:07,831 - Epoch: [68][  100/  296]    Overall Loss 0.933004    Objective Loss 0.933004                                        LR 0.000320    Time 0.317043    
2024-04-23 17:48:09,203 - Epoch: [90][  230/  267]    Overall Loss 2.356235    Objective Loss 2.356235                                        LR 0.100000    Time 0.290296    
2024-04-23 17:48:11,495 - Epoch: [90][  240/  267]    Overall Loss 2.357434    Objective Loss 2.357434                                        LR 0.100000    Time 0.287740    
2024-04-23 17:48:14,676 - Epoch: [90][  250/  267]    Overall Loss 2.357745    Objective Loss 2.357745                                        LR 0.100000    Time 0.288942    
2024-04-23 17:48:17,024 - Epoch: [90][  260/  267]    Overall Loss 2.356959    Objective Loss 2.356959                                        LR 0.100000    Time 0.286841    
2024-04-23 17:48:18,643 - Epoch: [90][  267/  267]    Overall Loss 2.359141    Objective Loss 2.359141    Top1 4.651163    Top5 37.209302    LR 0.100000    Time 0.285377    
2024-04-23 17:48:18,868 - --- validate (epoch=90)-----------
2024-04-23 17:48:18,870 - 946 samples (32 per mini-batch)
2024-04-23 17:48:23,148 - Epoch: [90][   10/   30]    Loss 2.414815    Top1 10.312500    Top5 50.312500    
2024-04-23 17:48:25,778 - Epoch: [90][   20/   30]    Loss 2.403048    Top1 10.000000    Top5 51.718750    
2024-04-23 17:48:29,067 - Epoch: [90][   30/   30]    Loss 2.407120    Top1 9.196617    Top5 50.528541    
2024-04-23 17:48:29,288 - ==> Top1: 9.197    Top5: 50.529    Loss: 2.407

2024-04-23 17:48:29,291 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 17:48:29,296 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:48:29,297 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:48:29,318 - 

2024-04-23 17:48:29,320 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:48:31,614 - Epoch: [68][  200/  296]    Overall Loss 0.922068    Objective Loss 0.922068                                        LR 0.000320    Time 0.277328    
2024-04-23 17:48:34,036 - Epoch: [91][   10/  267]    Overall Loss 2.409142    Objective Loss 2.409142                                        LR 0.100000    Time 0.471166    
2024-04-23 17:48:36,364 - Epoch: [91][   20/  267]    Overall Loss 2.375323    Objective Loss 2.375323                                        LR 0.100000    Time 0.351825    
2024-04-23 17:48:39,696 - Epoch: [91][   30/  267]    Overall Loss 2.371515    Objective Loss 2.371515                                        LR 0.100000    Time 0.345516    
2024-04-23 17:48:41,906 - Epoch: [91][   40/  267]    Overall Loss 2.355724    Objective Loss 2.355724                                        LR 0.100000    Time 0.314308    
2024-04-23 17:48:44,552 - Epoch: [91][   50/  267]    Overall Loss 2.365915    Objective Loss 2.365915                                        LR 0.100000    Time 0.304295    
2024-04-23 17:48:46,483 - Epoch: [91][   60/  267]    Overall Loss 2.367154    Objective Loss 2.367154                                        LR 0.100000    Time 0.285713    
2024-04-23 17:48:48,594 - Epoch: [91][   70/  267]    Overall Loss 2.364215    Objective Loss 2.364215                                        LR 0.100000    Time 0.275016    
2024-04-23 17:48:50,718 - Epoch: [91][   80/  267]    Overall Loss 2.366048    Objective Loss 2.366048                                        LR 0.100000    Time 0.267165    
2024-04-23 17:48:53,589 - Epoch: [91][   90/  267]    Overall Loss 2.364176    Objective Loss 2.364176                                        LR 0.100000    Time 0.269348    
2024-04-23 17:48:54,526 - Epoch: [68][  296/  296]    Overall Loss 0.916345    Objective Loss 0.916345    Top1 78.688525    Top5 90.163934    LR 0.000320    Time 0.264716    
2024-04-23 17:48:54,896 - --- validate (epoch=68)-----------
2024-04-23 17:48:54,898 - 3925 samples (32 per mini-batch)
2024-04-23 17:48:55,780 - Epoch: [91][  100/  267]    Overall Loss 2.368854    Objective Loss 2.368854                                        LR 0.100000    Time 0.264288    
2024-04-23 17:48:58,706 - Epoch: [91][  110/  267]    Overall Loss 2.369042    Objective Loss 2.369042                                        LR 0.100000    Time 0.266831    
2024-04-23 17:49:00,642 - Epoch: [91][  120/  267]    Overall Loss 2.367301    Objective Loss 2.367301                                        LR 0.100000    Time 0.260700    
2024-04-23 17:49:03,390 - Epoch: [91][  130/  267]    Overall Loss 2.365640    Objective Loss 2.365640                                        LR 0.100000    Time 0.261767    
2024-04-23 17:49:05,427 - Epoch: [91][  140/  267]    Overall Loss 2.364769    Objective Loss 2.364769                                        LR 0.100000    Time 0.257597    
2024-04-23 17:49:08,104 - Epoch: [91][  150/  267]    Overall Loss 2.364342    Objective Loss 2.364342                                        LR 0.100000    Time 0.258248    
2024-04-23 17:49:10,106 - Epoch: [91][  160/  267]    Overall Loss 2.367161    Objective Loss 2.367161                                        LR 0.100000    Time 0.254598    
2024-04-23 17:49:12,917 - Epoch: [91][  170/  267]    Overall Loss 2.369193    Objective Loss 2.369193                                        LR 0.100000    Time 0.256143    
2024-04-23 17:49:14,847 - Epoch: [91][  180/  267]    Overall Loss 2.366262    Objective Loss 2.366262                                        LR 0.100000    Time 0.252618    
2024-04-23 17:49:17,246 - Epoch: [91][  190/  267]    Overall Loss 2.367402    Objective Loss 2.367402                                        LR 0.100000    Time 0.251934    
2024-04-23 17:49:18,814 - Epoch: [91][  200/  267]    Overall Loss 2.371357    Objective Loss 2.371357                                        LR 0.100000    Time 0.247163    
2024-04-23 17:49:21,844 - Epoch: [91][  210/  267]    Overall Loss 2.371945    Objective Loss 2.371945                                        LR 0.100000    Time 0.249805    
2024-04-23 17:49:22,413 - Epoch: [68][  100/  123]    Loss 0.826033    Top1 72.218750    Top5 96.250000    
2024-04-23 17:49:23,828 - Epoch: [91][  220/  267]    Overall Loss 2.371431    Objective Loss 2.371431                                        LR 0.100000    Time 0.247459    
2024-04-23 17:49:26,365 - Epoch: [91][  230/  267]    Overall Loss 2.370463    Objective Loss 2.370463                                        LR 0.100000    Time 0.247714    
2024-04-23 17:49:27,655 - Epoch: [91][  240/  267]    Overall Loss 2.370018    Objective Loss 2.370018                                        LR 0.100000    Time 0.242760    
2024-04-23 17:49:28,177 - Epoch: [68][  123/  123]    Loss 0.818522    Top1 72.738854    Top5 96.305732    
2024-04-23 17:49:28,463 - ==> Top1: 72.739    Top5: 96.306    Loss: 0.819

2024-04-23 17:49:28,474 - ==> Best [Top1: 74.369   Top5: 96.535   Sparsity:0.00   Params: 376752 on epoch: 63]
2024-04-23 17:49:28,474 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:49:28,532 - 

2024-04-23 17:49:28,533 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:49:30,226 - Epoch: [91][  250/  267]    Overall Loss 2.368453    Objective Loss 2.368453                                        LR 0.100000    Time 0.243321    
2024-04-23 17:49:32,005 - Epoch: [91][  260/  267]    Overall Loss 2.368247    Objective Loss 2.368247                                        LR 0.100000    Time 0.240792    
2024-04-23 17:49:32,785 - Epoch: [91][  267/  267]    Overall Loss 2.369114    Objective Loss 2.369114    Top1 6.976744    Top5 48.837209    LR 0.100000    Time 0.237390    
2024-04-23 17:49:33,006 - --- validate (epoch=91)-----------
2024-04-23 17:49:33,008 - 946 samples (32 per mini-batch)
2024-04-23 17:49:36,786 - Epoch: [91][   10/   30]    Loss 2.353853    Top1 11.250000    Top5 50.625000    
2024-04-23 17:49:38,638 - Epoch: [91][   20/   30]    Loss 2.344149    Top1 10.625000    Top5 49.843750    
2024-04-23 17:49:40,931 - Epoch: [91][   30/   30]    Loss 2.343943    Top1 10.465116    Top5 50.317125    
2024-04-23 17:49:41,136 - ==> Top1: 10.465    Top5: 50.317    Loss: 2.344

2024-04-23 17:49:41,137 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 17:49:41,141 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:49:41,141 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:49:41,151 - 

2024-04-23 17:49:41,152 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:49:44,854 - Epoch: [92][   10/  267]    Overall Loss 2.352720    Objective Loss 2.352720                                        LR 0.100000    Time 0.369861    
2024-04-23 17:49:46,686 - Epoch: [92][   20/  267]    Overall Loss 2.358414    Objective Loss 2.358414                                        LR 0.100000    Time 0.276353    
2024-04-23 17:49:48,728 - Epoch: [92][   30/  267]    Overall Loss 2.362809    Objective Loss 2.362809                                        LR 0.100000    Time 0.252182    
2024-04-23 17:49:50,684 - Epoch: [92][   40/  267]    Overall Loss 2.363707    Objective Loss 2.363707                                        LR 0.100000    Time 0.237972    
2024-04-23 17:49:53,042 - Epoch: [92][   50/  267]    Overall Loss 2.364054    Objective Loss 2.364054                                        LR 0.100000    Time 0.237468    
2024-04-23 17:49:54,169 - Epoch: [69][  100/  296]    Overall Loss 0.903933    Objective Loss 0.903933                                        LR 0.000320    Time 0.256128    
2024-04-23 17:49:54,949 - Epoch: [92][   60/  267]    Overall Loss 2.370571    Objective Loss 2.370571                                        LR 0.100000    Time 0.229623    
2024-04-23 17:49:57,619 - Epoch: [92][   70/  267]    Overall Loss 2.371419    Objective Loss 2.371419                                        LR 0.100000    Time 0.234927    
2024-04-23 17:49:59,560 - Epoch: [92][   80/  267]    Overall Loss 2.371598    Objective Loss 2.371598                                        LR 0.100000    Time 0.229789    
2024-04-23 17:50:02,306 - Epoch: [92][   90/  267]    Overall Loss 2.371898    Objective Loss 2.371898                                        LR 0.100000    Time 0.234728    
2024-04-23 17:50:04,571 - Epoch: [92][  100/  267]    Overall Loss 2.372876    Objective Loss 2.372876                                        LR 0.100000    Time 0.233873    
2024-04-23 17:50:07,333 - Epoch: [92][  110/  267]    Overall Loss 2.375646    Objective Loss 2.375646                                        LR 0.100000    Time 0.237698    
2024-04-23 17:50:09,368 - Epoch: [92][  120/  267]    Overall Loss 2.375327    Objective Loss 2.375327                                        LR 0.100000    Time 0.234826    
2024-04-23 17:50:11,339 - Epoch: [92][  130/  267]    Overall Loss 2.376656    Objective Loss 2.376656                                        LR 0.100000    Time 0.231895    
2024-04-23 17:50:14,127 - Epoch: [92][  140/  267]    Overall Loss 2.375558    Objective Loss 2.375558                                        LR 0.100000    Time 0.235224    
2024-04-23 17:50:15,805 - Epoch: [92][  150/  267]    Overall Loss 2.374641    Objective Loss 2.374641                                        LR 0.100000    Time 0.230710    
2024-04-23 17:50:17,490 - Epoch: [69][  200/  296]    Overall Loss 0.911239    Objective Loss 0.911239                                        LR 0.000320    Time 0.244561    
2024-04-23 17:50:18,509 - Epoch: [92][  160/  267]    Overall Loss 2.372715    Objective Loss 2.372715                                        LR 0.100000    Time 0.233174    
2024-04-23 17:50:20,414 - Epoch: [92][  170/  267]    Overall Loss 2.373690    Objective Loss 2.373690                                        LR 0.100000    Time 0.230649    
2024-04-23 17:50:22,964 - Epoch: [92][  180/  267]    Overall Loss 2.372515    Objective Loss 2.372515                                        LR 0.100000    Time 0.231983    
2024-04-23 17:50:24,944 - Epoch: [92][  190/  267]    Overall Loss 2.370542    Objective Loss 2.370542                                        LR 0.100000    Time 0.230178    
2024-04-23 17:50:27,846 - Epoch: [92][  200/  267]    Overall Loss 2.371888    Objective Loss 2.371888                                        LR 0.100000    Time 0.233163    
2024-04-23 17:50:29,807 - Epoch: [92][  210/  267]    Overall Loss 2.373107    Objective Loss 2.373107                                        LR 0.100000    Time 0.231375    
2024-04-23 17:50:31,807 - Epoch: [92][  220/  267]    Overall Loss 2.371241    Objective Loss 2.371241                                        LR 0.100000    Time 0.229933    
2024-04-23 17:50:33,759 - Epoch: [92][  230/  267]    Overall Loss 2.369896    Objective Loss 2.369896                                        LR 0.100000    Time 0.228410    
2024-04-23 17:50:35,852 - Epoch: [92][  240/  267]    Overall Loss 2.370528    Objective Loss 2.370528                                        LR 0.100000    Time 0.227600    
2024-04-23 17:50:37,670 - Epoch: [92][  250/  267]    Overall Loss 2.371493    Objective Loss 2.371493                                        LR 0.100000    Time 0.225757    
2024-04-23 17:50:39,729 - Epoch: [69][  296/  296]    Overall Loss 0.914916    Objective Loss 0.914916    Top1 67.213115    Top5 96.721311    LR 0.000320    Time 0.240302    
2024-04-23 17:50:40,017 - --- validate (epoch=69)-----------
2024-04-23 17:50:40,018 - 3925 samples (32 per mini-batch)
2024-04-23 17:50:40,664 - Epoch: [92][  260/  267]    Overall Loss 2.371089    Objective Loss 2.371089                                        LR 0.100000    Time 0.228578    
2024-04-23 17:50:41,454 - Epoch: [92][  267/  267]    Overall Loss 2.371813    Objective Loss 2.371813    Top1 4.651163    Top5 44.186047    LR 0.100000    Time 0.225536    
2024-04-23 17:50:41,678 - --- validate (epoch=92)-----------
2024-04-23 17:50:41,680 - 946 samples (32 per mini-batch)
2024-04-23 17:50:45,395 - Epoch: [92][   10/   30]    Loss 2.389433    Top1 8.125000    Top5 49.062500    
2024-04-23 17:50:47,191 - Epoch: [92][   20/   30]    Loss 2.378410    Top1 9.062500    Top5 50.156250    
2024-04-23 17:50:49,828 - Epoch: [92][   30/   30]    Loss 2.385817    Top1 9.830867    Top5 49.577167    
2024-04-23 17:50:49,994 - ==> Top1: 9.831    Top5: 49.577    Loss: 2.386

2024-04-23 17:50:49,996 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 17:50:50,000 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:50:50,000 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:50:50,015 - 

2024-04-23 17:50:50,016 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:50:53,299 - Epoch: [93][   10/  267]    Overall Loss 2.351522    Objective Loss 2.351522                                        LR 0.100000    Time 0.327983    
2024-04-23 17:50:55,199 - Epoch: [93][   20/  267]    Overall Loss 2.344578    Objective Loss 2.344578                                        LR 0.100000    Time 0.258784    
2024-04-23 17:50:57,402 - Epoch: [93][   30/  267]    Overall Loss 2.359692    Objective Loss 2.359692                                        LR 0.100000    Time 0.245888    
2024-04-23 17:50:59,274 - Epoch: [93][   40/  267]    Overall Loss 2.362289    Objective Loss 2.362289                                        LR 0.100000    Time 0.231134    
2024-04-23 17:51:01,280 - Epoch: [93][   50/  267]    Overall Loss 2.368545    Objective Loss 2.368545                                        LR 0.100000    Time 0.224955    
2024-04-23 17:51:03,315 - Epoch: [93][   60/  267]    Overall Loss 2.367171    Objective Loss 2.367171                                        LR 0.100000    Time 0.221335    
2024-04-23 17:51:05,799 - Epoch: [93][   70/  267]    Overall Loss 2.366580    Objective Loss 2.366580                                        LR 0.100000    Time 0.225145    
2024-04-23 17:51:07,587 - Epoch: [93][   80/  267]    Overall Loss 2.364628    Objective Loss 2.364628                                        LR 0.100000    Time 0.219317    
2024-04-23 17:51:08,064 - Epoch: [69][  100/  123]    Loss 0.775713    Top1 74.281250    Top5 96.406250    
2024-04-23 17:51:10,371 - Epoch: [93][   90/  267]    Overall Loss 2.366118    Objective Loss 2.366118                                        LR 0.100000    Time 0.225840    
2024-04-23 17:51:12,184 - Epoch: [93][  100/  267]    Overall Loss 2.364763    Objective Loss 2.364763                                        LR 0.100000    Time 0.221361    
2024-04-23 17:51:14,241 - Epoch: [69][  123/  123]    Loss 0.771235    Top1 74.471338    Top5 96.636943    
2024-04-23 17:51:14,497 - ==> Top1: 74.471    Top5: 96.637    Loss: 0.771

2024-04-23 17:51:14,508 - ==> Best [Top1: 74.471   Top5: 96.637   Sparsity:0.00   Params: 376752 on epoch: 69]
2024-04-23 17:51:14,509 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:51:14,568 - 

2024-04-23 17:51:14,569 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:51:14,963 - Epoch: [93][  110/  267]    Overall Loss 2.361706    Objective Loss 2.361706                                        LR 0.100000    Time 0.226476    
2024-04-23 17:51:16,948 - Epoch: [93][  120/  267]    Overall Loss 2.358383    Objective Loss 2.358383                                        LR 0.100000    Time 0.224111    
2024-04-23 17:51:19,468 - Epoch: [93][  130/  267]    Overall Loss 2.358331    Objective Loss 2.358331                                        LR 0.100000    Time 0.226233    
2024-04-23 17:51:21,431 - Epoch: [93][  140/  267]    Overall Loss 2.359689    Objective Loss 2.359689                                        LR 0.100000    Time 0.224083    
2024-04-23 17:51:24,276 - Epoch: [93][  150/  267]    Overall Loss 2.360278    Objective Loss 2.360278                                        LR 0.100000    Time 0.228089    
2024-04-23 17:51:26,222 - Epoch: [93][  160/  267]    Overall Loss 2.360124    Objective Loss 2.360124                                        LR 0.100000    Time 0.225970    
2024-04-23 17:51:28,797 - Epoch: [93][  170/  267]    Overall Loss 2.359637    Objective Loss 2.359637                                        LR 0.100000    Time 0.227786    
2024-04-23 17:51:30,718 - Epoch: [93][  180/  267]    Overall Loss 2.360787    Objective Loss 2.360787                                        LR 0.100000    Time 0.225787    
2024-04-23 17:51:33,226 - Epoch: [93][  190/  267]    Overall Loss 2.361075    Objective Loss 2.361075                                        LR 0.100000    Time 0.227090    
2024-04-23 17:51:34,711 - Epoch: [93][  200/  267]    Overall Loss 2.361157    Objective Loss 2.361157                                        LR 0.100000    Time 0.223148    
2024-04-23 17:51:37,427 - Epoch: [93][  210/  267]    Overall Loss 2.360818    Objective Loss 2.360818                                        LR 0.100000    Time 0.225440    
2024-04-23 17:51:39,085 - Epoch: [93][  220/  267]    Overall Loss 2.361669    Objective Loss 2.361669                                        LR 0.100000    Time 0.222717    
2024-04-23 17:51:40,281 - Epoch: [70][  100/  296]    Overall Loss 0.909260    Objective Loss 0.909260                                        LR 0.000320    Time 0.256897    
2024-04-23 17:51:41,561 - Epoch: [93][  230/  267]    Overall Loss 2.359868    Objective Loss 2.359868                                        LR 0.100000    Time 0.223787    
2024-04-23 17:51:43,492 - Epoch: [93][  240/  267]    Overall Loss 2.361828    Objective Loss 2.361828                                        LR 0.100000    Time 0.222492    
2024-04-23 17:51:46,123 - Epoch: [93][  250/  267]    Overall Loss 2.361834    Objective Loss 2.361834                                        LR 0.100000    Time 0.224102    
2024-04-23 17:51:48,471 - Epoch: [93][  260/  267]    Overall Loss 2.362020    Objective Loss 2.362020                                        LR 0.100000    Time 0.224500    
2024-04-23 17:51:49,751 - Epoch: [93][  267/  267]    Overall Loss 2.362008    Objective Loss 2.362008    Top1 6.976744    Top5 44.186047    LR 0.100000    Time 0.223394    
2024-04-23 17:51:50,012 - --- validate (epoch=93)-----------
2024-04-23 17:51:50,013 - 946 samples (32 per mini-batch)
2024-04-23 17:51:53,703 - Epoch: [93][   10/   30]    Loss 2.376689    Top1 7.187500    Top5 44.687500    
2024-04-23 17:51:54,699 - Epoch: [93][   20/   30]    Loss 2.353960    Top1 8.750000    Top5 48.125000    
2024-04-23 17:51:56,776 - Epoch: [93][   30/   30]    Loss 2.353663    Top1 9.196617    Top5 48.520085    
2024-04-23 17:51:57,029 - ==> Top1: 9.197    Top5: 48.520    Loss: 2.354

2024-04-23 17:51:57,032 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 17:51:57,037 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:51:57,038 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:51:57,056 - 

2024-04-23 17:51:57,057 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:51:59,799 - Epoch: [94][   10/  267]    Overall Loss 2.409634    Objective Loss 2.409634                                        LR 0.100000    Time 0.273933    
2024-04-23 17:52:01,570 - Epoch: [94][   20/  267]    Overall Loss 2.392057    Objective Loss 2.392057                                        LR 0.100000    Time 0.225291    
2024-04-23 17:52:04,459 - Epoch: [94][   30/  267]    Overall Loss 2.392493    Objective Loss 2.392493                                        LR 0.100000    Time 0.246416    
2024-04-23 17:52:05,015 - Epoch: [70][  200/  296]    Overall Loss 0.916791    Objective Loss 0.916791                                        LR 0.000320    Time 0.252002    
2024-04-23 17:52:06,562 - Epoch: [94][   40/  267]    Overall Loss 2.381385    Objective Loss 2.381385                                        LR 0.100000    Time 0.237309    
2024-04-23 17:52:09,249 - Epoch: [94][   50/  267]    Overall Loss 2.370256    Objective Loss 2.370256                                        LR 0.100000    Time 0.243533    
2024-04-23 17:52:11,081 - Epoch: [94][   60/  267]    Overall Loss 2.371311    Objective Loss 2.371311                                        LR 0.100000    Time 0.233431    
2024-04-23 17:52:13,896 - Epoch: [94][   70/  267]    Overall Loss 2.372059    Objective Loss 2.372059                                        LR 0.100000    Time 0.240263    
2024-04-23 17:52:15,920 - Epoch: [94][   80/  267]    Overall Loss 2.367027    Objective Loss 2.367027                                        LR 0.100000    Time 0.235482    
2024-04-23 17:52:18,609 - Epoch: [94][   90/  267]    Overall Loss 2.363912    Objective Loss 2.363912                                        LR 0.100000    Time 0.239166    
2024-04-23 17:52:20,673 - Epoch: [94][  100/  267]    Overall Loss 2.367065    Objective Loss 2.367065                                        LR 0.100000    Time 0.235854    
2024-04-23 17:52:23,537 - Epoch: [94][  110/  267]    Overall Loss 2.365758    Objective Loss 2.365758                                        LR 0.100000    Time 0.240422    
2024-04-23 17:52:25,448 - Epoch: [94][  120/  267]    Overall Loss 2.370196    Objective Loss 2.370196                                        LR 0.100000    Time 0.236281    
2024-04-23 17:52:27,490 - Epoch: [70][  296/  296]    Overall Loss 0.911211    Objective Loss 0.911211    Top1 67.213115    Top5 95.081967    LR 0.000320    Time 0.246132    
2024-04-23 17:52:27,796 - --- validate (epoch=70)-----------
2024-04-23 17:52:27,797 - 3925 samples (32 per mini-batch)
2024-04-23 17:52:28,141 - Epoch: [94][  130/  267]    Overall Loss 2.370127    Objective Loss 2.370127                                        LR 0.100000    Time 0.238802    
2024-04-23 17:52:30,099 - Epoch: [94][  140/  267]    Overall Loss 2.368838    Objective Loss 2.368838                                        LR 0.100000    Time 0.235715    
2024-04-23 17:52:32,929 - Epoch: [94][  150/  267]    Overall Loss 2.368551    Objective Loss 2.368551                                        LR 0.100000    Time 0.238840    
2024-04-23 17:52:34,800 - Epoch: [94][  160/  267]    Overall Loss 2.369725    Objective Loss 2.369725                                        LR 0.100000    Time 0.235594    
2024-04-23 17:52:37,460 - Epoch: [94][  170/  267]    Overall Loss 2.370850    Objective Loss 2.370850                                        LR 0.100000    Time 0.237363    
2024-04-23 17:52:38,850 - Epoch: [94][  180/  267]    Overall Loss 2.369962    Objective Loss 2.369962                                        LR 0.100000    Time 0.231882    
2024-04-23 17:52:41,362 - Epoch: [94][  190/  267]    Overall Loss 2.370830    Objective Loss 2.370830                                        LR 0.100000    Time 0.232859    
2024-04-23 17:52:43,386 - Epoch: [94][  200/  267]    Overall Loss 2.371270    Objective Loss 2.371270                                        LR 0.100000    Time 0.231318    
2024-04-23 17:52:45,664 - Epoch: [94][  210/  267]    Overall Loss 2.372180    Objective Loss 2.372180                                        LR 0.100000    Time 0.231132    
2024-04-23 17:52:47,202 - Epoch: [94][  220/  267]    Overall Loss 2.371911    Objective Loss 2.371911                                        LR 0.100000    Time 0.227609    
2024-04-23 17:52:49,239 - Epoch: [94][  230/  267]    Overall Loss 2.371376    Objective Loss 2.371376                                        LR 0.100000    Time 0.226558    
2024-04-23 17:52:51,650 - Epoch: [94][  240/  267]    Overall Loss 2.370488    Objective Loss 2.370488                                        LR 0.100000    Time 0.227150    
2024-04-23 17:52:53,414 - Epoch: [70][  100/  123]    Loss 0.823392    Top1 73.062500    Top5 96.843750    
2024-04-23 17:52:53,680 - Epoch: [94][  250/  267]    Overall Loss 2.371378    Objective Loss 2.371378                                        LR 0.100000    Time 0.226174    
2024-04-23 17:52:55,880 - Epoch: [94][  260/  267]    Overall Loss 2.370381    Objective Loss 2.370381                                        LR 0.100000    Time 0.225924    
2024-04-23 17:52:57,159 - Epoch: [94][  267/  267]    Overall Loss 2.369905    Objective Loss 2.369905    Top1 9.302326    Top5 53.488372    LR 0.100000    Time 0.224786    
2024-04-23 17:52:57,395 - --- validate (epoch=94)-----------
2024-04-23 17:52:57,396 - 946 samples (32 per mini-batch)
2024-04-23 17:52:59,391 - Epoch: [70][  123/  123]    Loss 0.822055    Top1 73.350318    Top5 96.789809    
2024-04-23 17:52:59,628 - ==> Top1: 73.350    Top5: 96.790    Loss: 0.822

2024-04-23 17:52:59,639 - ==> Best [Top1: 74.471   Top5: 96.637   Sparsity:0.00   Params: 376752 on epoch: 69]
2024-04-23 17:52:59,640 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:52:59,700 - 

2024-04-23 17:52:59,701 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:53:00,316 - Epoch: [94][   10/   30]    Loss 2.336250    Top1 11.250000    Top5 53.437500    
2024-04-23 17:53:02,643 - Epoch: [94][   20/   30]    Loss 2.324971    Top1 11.406250    Top5 54.062500    
2024-04-23 17:53:05,913 - Epoch: [94][   30/   30]    Loss 2.344375    Top1 10.465116    Top5 50.845666    
2024-04-23 17:53:06,139 - ==> Top1: 10.465    Top5: 50.846    Loss: 2.344

2024-04-23 17:53:06,142 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 17:53:06,148 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:53:06,148 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:53:06,164 - 

2024-04-23 17:53:06,166 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:53:10,524 - Epoch: [95][   10/  267]    Overall Loss 2.322972    Objective Loss 2.322972                                        LR 0.100000    Time 0.435360    
2024-04-23 17:53:12,700 - Epoch: [95][   20/  267]    Overall Loss 2.364731    Objective Loss 2.364731                                        LR 0.100000    Time 0.326341    
2024-04-23 17:53:15,879 - Epoch: [95][   30/  267]    Overall Loss 2.359588    Objective Loss 2.359588                                        LR 0.100000    Time 0.323427    
2024-04-23 17:53:17,901 - Epoch: [95][   40/  267]    Overall Loss 2.354286    Objective Loss 2.354286                                        LR 0.100000    Time 0.293051    
2024-04-23 17:53:20,923 - Epoch: [95][   50/  267]    Overall Loss 2.368230    Objective Loss 2.368230                                        LR 0.100000    Time 0.294808    
2024-04-23 17:53:23,001 - Epoch: [95][   60/  267]    Overall Loss 2.372356    Objective Loss 2.372356                                        LR 0.100000    Time 0.280256    
2024-04-23 17:53:25,880 - Epoch: [95][   70/  267]    Overall Loss 2.372074    Objective Loss 2.372074                                        LR 0.100000    Time 0.281300    
2024-04-23 17:53:27,082 - Epoch: [71][  100/  296]    Overall Loss 0.893784    Objective Loss 0.893784                                        LR 0.000320    Time 0.273580    
2024-04-23 17:53:27,955 - Epoch: [95][   80/  267]    Overall Loss 2.368038    Objective Loss 2.368038                                        LR 0.100000    Time 0.272044    
2024-04-23 17:53:30,860 - Epoch: [95][   90/  267]    Overall Loss 2.367596    Objective Loss 2.367596                                        LR 0.100000    Time 0.274055    
2024-04-23 17:53:33,090 - Epoch: [95][  100/  267]    Overall Loss 2.365822    Objective Loss 2.365822                                        LR 0.100000    Time 0.268923    
2024-04-23 17:53:36,287 - Epoch: [95][  110/  267]    Overall Loss 2.365912    Objective Loss 2.365912                                        LR 0.100000    Time 0.273507    
2024-04-23 17:53:38,519 - Epoch: [95][  120/  267]    Overall Loss 2.367060    Objective Loss 2.367060                                        LR 0.100000    Time 0.269296    
2024-04-23 17:53:41,487 - Epoch: [95][  130/  267]    Overall Loss 2.366830    Objective Loss 2.366830                                        LR 0.100000    Time 0.271380    
2024-04-23 17:53:43,556 - Epoch: [95][  140/  267]    Overall Loss 2.362494    Objective Loss 2.362494                                        LR 0.100000    Time 0.266748    
2024-04-23 17:53:46,375 - Epoch: [95][  150/  267]    Overall Loss 2.363292    Objective Loss 2.363292                                        LR 0.100000    Time 0.267744    
2024-04-23 17:53:48,032 - Epoch: [95][  160/  267]    Overall Loss 2.366500    Objective Loss 2.366500                                        LR 0.100000    Time 0.261347    
2024-04-23 17:53:51,033 - Epoch: [95][  170/  267]    Overall Loss 2.365382    Objective Loss 2.365382                                        LR 0.100000    Time 0.263611    
2024-04-23 17:53:51,111 - Epoch: [71][  200/  296]    Overall Loss 0.907192    Objective Loss 0.907192                                        LR 0.000320    Time 0.256831    
2024-04-23 17:53:52,667 - Epoch: [95][  180/  267]    Overall Loss 2.365184    Objective Loss 2.365184                                        LR 0.100000    Time 0.258029    
2024-04-23 17:53:55,351 - Epoch: [95][  190/  267]    Overall Loss 2.366200    Objective Loss 2.366200                                        LR 0.100000    Time 0.258553    
2024-04-23 17:53:57,237 - Epoch: [95][  200/  267]    Overall Loss 2.366207    Objective Loss 2.366207                                        LR 0.100000    Time 0.255039    
2024-04-23 17:54:00,696 - Epoch: [95][  210/  267]    Overall Loss 2.365644    Objective Loss 2.365644                                        LR 0.100000    Time 0.259350    
2024-04-23 17:54:02,901 - Epoch: [95][  220/  267]    Overall Loss 2.365633    Objective Loss 2.365633                                        LR 0.100000    Time 0.257568    
2024-04-23 17:54:05,851 - Epoch: [95][  230/  267]    Overall Loss 2.364620    Objective Loss 2.364620                                        LR 0.100000    Time 0.259185    
2024-04-23 17:54:07,897 - Epoch: [95][  240/  267]    Overall Loss 2.365632    Objective Loss 2.365632                                        LR 0.100000    Time 0.256891    
2024-04-23 17:54:09,906 - Epoch: [95][  250/  267]    Overall Loss 2.368043    Objective Loss 2.368043                                        LR 0.100000    Time 0.254640    
2024-04-23 17:54:11,806 - Epoch: [95][  260/  267]    Overall Loss 2.366275    Objective Loss 2.366275                                        LR 0.100000    Time 0.252136    
2024-04-23 17:54:12,708 - Epoch: [71][  296/  296]    Overall Loss 0.911827    Objective Loss 0.911827    Top1 63.934426    Top5 98.360656    LR 0.000320    Time 0.246429    
2024-04-23 17:54:12,875 - Epoch: [95][  267/  267]    Overall Loss 2.366292    Objective Loss 2.366292    Top1 2.325581    Top5 39.534884    LR 0.100000    Time 0.249519    
2024-04-23 17:54:13,022 - --- validate (epoch=71)-----------
2024-04-23 17:54:13,024 - 3925 samples (32 per mini-batch)
2024-04-23 17:54:13,073 - --- validate (epoch=95)-----------
2024-04-23 17:54:13,074 - 946 samples (32 per mini-batch)
2024-04-23 17:54:17,084 - Epoch: [95][   10/   30]    Loss 2.367216    Top1 9.375000    Top5 52.187500    
2024-04-23 17:54:19,210 - Epoch: [95][   20/   30]    Loss 2.365128    Top1 10.000000    Top5 52.812500    
2024-04-23 17:54:21,985 - Epoch: [95][   30/   30]    Loss 2.370474    Top1 9.830867    Top5 51.057082    
2024-04-23 17:54:22,213 - ==> Top1: 9.831    Top5: 51.057    Loss: 2.370

2024-04-23 17:54:22,216 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 17:54:22,222 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:54:22,223 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:54:22,241 - 

2024-04-23 17:54:22,242 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:54:26,786 - Epoch: [96][   10/  267]    Overall Loss 2.377932    Objective Loss 2.377932                                        LR 0.100000    Time 0.453931    
2024-04-23 17:54:29,144 - Epoch: [96][   20/  267]    Overall Loss 2.370921    Objective Loss 2.370921                                        LR 0.100000    Time 0.344667    
2024-04-23 17:54:32,172 - Epoch: [96][   30/  267]    Overall Loss 2.364872    Objective Loss 2.364872                                        LR 0.100000    Time 0.330634    
2024-04-23 17:54:34,461 - Epoch: [96][   40/  267]    Overall Loss 2.363467    Objective Loss 2.363467                                        LR 0.100000    Time 0.305116    
2024-04-23 17:54:37,384 - Epoch: [96][   50/  267]    Overall Loss 2.363567    Objective Loss 2.363567                                        LR 0.100000    Time 0.302485    
2024-04-23 17:54:39,423 - Epoch: [96][   60/  267]    Overall Loss 2.361367    Objective Loss 2.361367                                        LR 0.100000    Time 0.286008    
2024-04-23 17:54:41,126 - Epoch: [71][  100/  123]    Loss 0.781990    Top1 73.531250    Top5 96.750000    
2024-04-23 17:54:41,616 - Epoch: [96][   70/  267]    Overall Loss 2.360102    Objective Loss 2.360102                                        LR 0.100000    Time 0.276431    
2024-04-23 17:54:43,662 - Epoch: [96][   80/  267]    Overall Loss 2.358982    Objective Loss 2.358982                                        LR 0.100000    Time 0.267421    
2024-04-23 17:54:47,006 - Epoch: [96][   90/  267]    Overall Loss 2.358674    Objective Loss 2.358674                                        LR 0.100000    Time 0.274832    
2024-04-23 17:54:47,008 - Epoch: [71][  123/  123]    Loss 0.781756    Top1 73.681529    Top5 96.713376    
2024-04-23 17:54:47,240 - ==> Top1: 73.682    Top5: 96.713    Loss: 0.782

2024-04-23 17:54:47,244 - ==> Best [Top1: 74.471   Top5: 96.637   Sparsity:0.00   Params: 376752 on epoch: 69]
2024-04-23 17:54:47,245 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:54:47,286 - 

2024-04-23 17:54:47,287 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:54:49,186 - Epoch: [96][  100/  267]    Overall Loss 2.359845    Objective Loss 2.359845                                        LR 0.100000    Time 0.269120    
2024-04-23 17:54:52,332 - Epoch: [96][  110/  267]    Overall Loss 2.358549    Objective Loss 2.358549                                        LR 0.100000    Time 0.273207    
2024-04-23 17:54:54,370 - Epoch: [96][  120/  267]    Overall Loss 2.359291    Objective Loss 2.359291                                        LR 0.100000    Time 0.267394    
2024-04-23 17:54:57,313 - Epoch: [96][  130/  267]    Overall Loss 2.360040    Objective Loss 2.360040                                        LR 0.100000    Time 0.269452    
2024-04-23 17:54:59,155 - Epoch: [96][  140/  267]    Overall Loss 2.358893    Objective Loss 2.358893                                        LR 0.100000    Time 0.263335    
2024-04-23 17:55:01,503 - Epoch: [96][  150/  267]    Overall Loss 2.358353    Objective Loss 2.358353                                        LR 0.100000    Time 0.261413    
2024-04-23 17:55:03,616 - Epoch: [96][  160/  267]    Overall Loss 2.357267    Objective Loss 2.357267                                        LR 0.100000    Time 0.258261    
2024-04-23 17:55:06,311 - Epoch: [96][  170/  267]    Overall Loss 2.360064    Objective Loss 2.360064                                        LR 0.100000    Time 0.258906    
2024-04-23 17:55:07,807 - Epoch: [96][  180/  267]    Overall Loss 2.361076    Objective Loss 2.361076                                        LR 0.100000    Time 0.252819    
2024-04-23 17:55:10,695 - Epoch: [96][  190/  267]    Overall Loss 2.361013    Objective Loss 2.361013                                        LR 0.100000    Time 0.254691    
2024-04-23 17:55:11,361 - Epoch: [72][  100/  296]    Overall Loss 0.891062    Objective Loss 0.891062                                        LR 0.000320    Time 0.240526    
2024-04-23 17:55:12,874 - Epoch: [96][  200/  267]    Overall Loss 2.361852    Objective Loss 2.361852                                        LR 0.100000    Time 0.252834    
2024-04-23 17:55:15,738 - Epoch: [96][  210/  267]    Overall Loss 2.362037    Objective Loss 2.362037                                        LR 0.100000    Time 0.254415    
2024-04-23 17:55:17,775 - Epoch: [96][  220/  267]    Overall Loss 2.363563    Objective Loss 2.363563                                        LR 0.100000    Time 0.252095    
2024-04-23 17:55:20,723 - Epoch: [96][  230/  267]    Overall Loss 2.364347    Objective Loss 2.364347                                        LR 0.100000    Time 0.253943    
2024-04-23 17:55:22,776 - Epoch: [96][  240/  267]    Overall Loss 2.365179    Objective Loss 2.365179                                        LR 0.100000    Time 0.251897    
2024-04-23 17:55:24,954 - Epoch: [96][  250/  267]    Overall Loss 2.364347    Objective Loss 2.364347                                        LR 0.100000    Time 0.250520    
2024-04-23 17:55:26,780 - Epoch: [96][  260/  267]    Overall Loss 2.363930    Objective Loss 2.363930                                        LR 0.100000    Time 0.247896    
2024-04-23 17:55:28,280 - Epoch: [96][  267/  267]    Overall Loss 2.363604    Objective Loss 2.363604    Top1 6.976744    Top5 55.813953    LR 0.100000    Time 0.247007    
2024-04-23 17:55:28,536 - --- validate (epoch=96)-----------
2024-04-23 17:55:28,538 - 946 samples (32 per mini-batch)
2024-04-23 17:55:32,839 - Epoch: [96][   10/   30]    Loss 2.336888    Top1 11.250000    Top5 49.375000    
2024-04-23 17:55:35,224 - Epoch: [96][   20/   30]    Loss 2.329747    Top1 11.406250    Top5 51.093750    
2024-04-23 17:55:35,643 - Epoch: [72][  200/  296]    Overall Loss 0.892445    Objective Loss 0.892445                                        LR 0.000320    Time 0.241567    
2024-04-23 17:55:37,881 - Epoch: [96][   30/   30]    Loss 2.338595    Top1 10.465116    Top5 50.105708    
2024-04-23 17:55:38,149 - ==> Top1: 10.465    Top5: 50.106    Loss: 2.339

2024-04-23 17:55:38,152 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 17:55:38,159 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:55:38,160 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:55:38,186 - 

2024-04-23 17:55:38,187 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:55:42,943 - Epoch: [97][   10/  267]    Overall Loss 2.456197    Objective Loss 2.456197                                        LR 0.100000    Time 0.475129    
2024-04-23 17:55:45,592 - Epoch: [97][   20/  267]    Overall Loss 2.439088    Objective Loss 2.439088                                        LR 0.100000    Time 0.369870    
2024-04-23 17:55:48,447 - Epoch: [97][   30/  267]    Overall Loss 2.419621    Objective Loss 2.419621                                        LR 0.100000    Time 0.341601    
2024-04-23 17:55:50,907 - Epoch: [97][   40/  267]    Overall Loss 2.404339    Objective Loss 2.404339                                        LR 0.100000    Time 0.317626    
2024-04-23 17:55:53,429 - Epoch: [97][   50/  267]    Overall Loss 2.400713    Objective Loss 2.400713                                        LR 0.100000    Time 0.304468    
2024-04-23 17:55:55,894 - Epoch: [97][   60/  267]    Overall Loss 2.397398    Objective Loss 2.397398                                        LR 0.100000    Time 0.294765    
2024-04-23 17:55:57,994 - Epoch: [97][   70/  267]    Overall Loss 2.393830    Objective Loss 2.393830                                        LR 0.100000    Time 0.282607    
2024-04-23 17:55:59,778 - Epoch: [72][  296/  296]    Overall Loss 0.894639    Objective Loss 0.894639    Top1 72.131148    Top5 90.163934    LR 0.000320    Time 0.244689    
2024-04-23 17:56:00,077 - --- validate (epoch=72)-----------
2024-04-23 17:56:00,079 - 3925 samples (32 per mini-batch)
2024-04-23 17:56:00,412 - Epoch: [97][   80/  267]    Overall Loss 2.393699    Objective Loss 2.393699                                        LR 0.100000    Time 0.277472    
2024-04-23 17:56:02,744 - Epoch: [97][   90/  267]    Overall Loss 2.387720    Objective Loss 2.387720                                        LR 0.100000    Time 0.272516    
2024-04-23 17:56:05,392 - Epoch: [97][  100/  267]    Overall Loss 2.386446    Objective Loss 2.386446                                        LR 0.100000    Time 0.271719    
2024-04-23 17:56:08,308 - Epoch: [97][  110/  267]    Overall Loss 2.380059    Objective Loss 2.380059                                        LR 0.100000    Time 0.273501    
2024-04-23 17:56:12,026 - Epoch: [97][  120/  267]    Overall Loss 2.379443    Objective Loss 2.379443                                        LR 0.100000    Time 0.281672    
2024-04-23 17:56:14,251 - Epoch: [97][  130/  267]    Overall Loss 2.378688    Objective Loss 2.378688                                        LR 0.100000    Time 0.277093    
2024-04-23 17:56:16,700 - Epoch: [97][  140/  267]    Overall Loss 2.375943    Objective Loss 2.375943                                        LR 0.100000    Time 0.274766    
2024-04-23 17:56:18,672 - Epoch: [97][  150/  267]    Overall Loss 2.373856    Objective Loss 2.373856                                        LR 0.100000    Time 0.269575    
2024-04-23 17:56:21,189 - Epoch: [97][  160/  267]    Overall Loss 2.373022    Objective Loss 2.373022                                        LR 0.100000    Time 0.268439    
2024-04-23 17:56:21,649 - Epoch: [72][  100/  123]    Loss 0.760819    Top1 74.968750    Top5 96.875000    
2024-04-23 17:56:23,605 - Epoch: [97][  170/  267]    Overall Loss 2.372214    Objective Loss 2.372214                                        LR 0.100000    Time 0.266844    
2024-04-23 17:56:25,620 - Epoch: [97][  180/  267]    Overall Loss 2.371684    Objective Loss 2.371684                                        LR 0.100000    Time 0.263197    
2024-04-23 17:56:26,756 - Epoch: [72][  123/  123]    Loss 0.769068    Top1 74.726115    Top5 96.942675    
2024-04-23 17:56:26,858 - ==> Top1: 74.726    Top5: 96.943    Loss: 0.769

2024-04-23 17:56:26,865 - ==> Best [Top1: 74.726   Top5: 96.943   Sparsity:0.00   Params: 376752 on epoch: 72]
2024-04-23 17:56:26,865 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:56:26,915 - 

2024-04-23 17:56:26,916 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:56:28,822 - Epoch: [97][  190/  267]    Overall Loss 2.371345    Objective Loss 2.371345                                        LR 0.100000    Time 0.266181    
2024-04-23 17:56:31,202 - Epoch: [97][  200/  267]    Overall Loss 2.371541    Objective Loss 2.371541                                        LR 0.100000    Time 0.264758    
2024-04-23 17:56:34,414 - Epoch: [97][  210/  267]    Overall Loss 2.371095    Objective Loss 2.371095                                        LR 0.100000    Time 0.267433    
2024-04-23 17:56:36,522 - Epoch: [97][  220/  267]    Overall Loss 2.372032    Objective Loss 2.372032                                        LR 0.100000    Time 0.264850    
2024-04-23 17:56:39,339 - Epoch: [97][  230/  267]    Overall Loss 2.370384    Objective Loss 2.370384                                        LR 0.100000    Time 0.265567    
2024-04-23 17:56:41,483 - Epoch: [97][  240/  267]    Overall Loss 2.369382    Objective Loss 2.369382                                        LR 0.100000    Time 0.263426    
2024-04-23 17:56:44,265 - Epoch: [97][  250/  267]    Overall Loss 2.371518    Objective Loss 2.371518                                        LR 0.100000    Time 0.264005    
2024-04-23 17:56:46,267 - Epoch: [97][  260/  267]    Overall Loss 2.371200    Objective Loss 2.371200                                        LR 0.100000    Time 0.261542    
2024-04-23 17:56:47,703 - Epoch: [97][  267/  267]    Overall Loss 2.373070    Objective Loss 2.373070    Top1 4.651163    Top5 44.186047    LR 0.100000    Time 0.260055    
2024-04-23 17:56:47,905 - --- validate (epoch=97)-----------
2024-04-23 17:56:47,906 - 946 samples (32 per mini-batch)
2024-04-23 17:56:49,358 - Epoch: [73][  100/  296]    Overall Loss 0.872625    Objective Loss 0.872625                                        LR 0.000320    Time 0.224200    
2024-04-23 17:56:52,609 - Epoch: [97][   10/   30]    Loss 2.357625    Top1 8.750000    Top5 45.625000    
2024-04-23 17:56:55,090 - Epoch: [97][   20/   30]    Loss 2.343075    Top1 9.375000    Top5 50.000000    
2024-04-23 17:56:57,144 - Epoch: [97][   30/   30]    Loss 2.340989    Top1 10.042283    Top5 50.951374    
2024-04-23 17:56:57,418 - ==> Top1: 10.042    Top5: 50.951    Loss: 2.341

2024-04-23 17:56:57,421 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 17:56:57,427 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:56:57,427 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:56:57,451 - 

2024-04-23 17:56:57,452 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:57:02,330 - Epoch: [98][   10/  267]    Overall Loss 2.346208    Objective Loss 2.346208                                        LR 0.100000    Time 0.487303    
2024-04-23 17:57:04,846 - Epoch: [98][   20/  267]    Overall Loss 2.354770    Objective Loss 2.354770                                        LR 0.100000    Time 0.369276    
2024-04-23 17:57:07,981 - Epoch: [98][   30/  267]    Overall Loss 2.344982    Objective Loss 2.344982                                        LR 0.100000    Time 0.350603    
2024-04-23 17:57:10,280 - Epoch: [98][   40/  267]    Overall Loss 2.356059    Objective Loss 2.356059                                        LR 0.100000    Time 0.320345    
2024-04-23 17:57:13,452 - Epoch: [98][   50/  267]    Overall Loss 2.362976    Objective Loss 2.362976                                        LR 0.100000    Time 0.319662    
2024-04-23 17:57:15,950 - Epoch: [98][   60/  267]    Overall Loss 2.360293    Objective Loss 2.360293                                        LR 0.100000    Time 0.307961    
2024-04-23 17:57:17,545 - Epoch: [73][  200/  296]    Overall Loss 0.918226    Objective Loss 0.918226                                        LR 0.000320    Time 0.252928    
2024-04-23 17:57:18,663 - Epoch: [98][   70/  267]    Overall Loss 2.356747    Objective Loss 2.356747                                        LR 0.100000    Time 0.302679    
2024-04-23 17:57:20,717 - Epoch: [98][   80/  267]    Overall Loss 2.360066    Objective Loss 2.360066                                        LR 0.100000    Time 0.290485    
2024-04-23 17:57:23,730 - Epoch: [98][   90/  267]    Overall Loss 2.358774    Objective Loss 2.358774                                        LR 0.100000    Time 0.291643    
2024-04-23 17:57:25,371 - Epoch: [98][  100/  267]    Overall Loss 2.357505    Objective Loss 2.357505                                        LR 0.100000    Time 0.278859    
2024-04-23 17:57:28,343 - Epoch: [98][  110/  267]    Overall Loss 2.357475    Objective Loss 2.357475                                        LR 0.100000    Time 0.280495    
2024-04-23 17:57:30,354 - Epoch: [98][  120/  267]    Overall Loss 2.360649    Objective Loss 2.360649                                        LR 0.100000    Time 0.273854    
2024-04-23 17:57:32,760 - Epoch: [98][  130/  267]    Overall Loss 2.360114    Objective Loss 2.360114                                        LR 0.100000    Time 0.271277    
2024-04-23 17:57:35,083 - Epoch: [98][  140/  267]    Overall Loss 2.360160    Objective Loss 2.360160                                        LR 0.100000    Time 0.268465    
2024-04-23 17:57:38,068 - Epoch: [98][  150/  267]    Overall Loss 2.358892    Objective Loss 2.358892                                        LR 0.100000    Time 0.270444    
2024-04-23 17:57:40,278 - Epoch: [98][  160/  267]    Overall Loss 2.360707    Objective Loss 2.360707                                        LR 0.100000    Time 0.267340    
2024-04-23 17:57:41,173 - Epoch: [73][  296/  296]    Overall Loss 0.915888    Objective Loss 0.915888    Top1 68.852459    Top5 90.163934    LR 0.000320    Time 0.250656    
2024-04-23 17:57:41,545 - --- validate (epoch=73)-----------
2024-04-23 17:57:41,546 - 3925 samples (32 per mini-batch)
2024-04-23 17:57:42,428 - Epoch: [98][  170/  267]    Overall Loss 2.362533    Objective Loss 2.362533                                        LR 0.100000    Time 0.264241    
2024-04-23 17:57:44,516 - Epoch: [98][  180/  267]    Overall Loss 2.365233    Objective Loss 2.365233                                        LR 0.100000    Time 0.261149    
2024-04-23 17:57:46,960 - Epoch: [98][  190/  267]    Overall Loss 2.366048    Objective Loss 2.366048                                        LR 0.100000    Time 0.260254    
2024-04-23 17:57:49,543 - Epoch: [98][  200/  267]    Overall Loss 2.368131    Objective Loss 2.368131                                        LR 0.100000    Time 0.260140    
2024-04-23 17:57:51,756 - Epoch: [98][  210/  267]    Overall Loss 2.366460    Objective Loss 2.366460                                        LR 0.100000    Time 0.258275    
2024-04-23 17:57:55,136 - Epoch: [98][  220/  267]    Overall Loss 2.367811    Objective Loss 2.367811                                        LR 0.100000    Time 0.261890    
2024-04-23 17:57:57,051 - Epoch: [98][  230/  267]    Overall Loss 2.367478    Objective Loss 2.367478                                        LR 0.100000    Time 0.258817    
2024-04-23 17:57:59,642 - Epoch: [98][  240/  267]    Overall Loss 2.368025    Objective Loss 2.368025                                        LR 0.100000    Time 0.258815    
2024-04-23 17:58:01,802 - Epoch: [98][  250/  267]    Overall Loss 2.367605    Objective Loss 2.367605                                        LR 0.100000    Time 0.257090    
2024-04-23 17:58:04,964 - Epoch: [98][  260/  267]    Overall Loss 2.368083    Objective Loss 2.368083                                        LR 0.100000    Time 0.259353    
2024-04-23 17:58:06,149 - Epoch: [98][  267/  267]    Overall Loss 2.368993    Objective Loss 2.368993    Top1 13.953488    Top5 46.511628    LR 0.100000    Time 0.256986    
2024-04-23 17:58:06,412 - --- validate (epoch=98)-----------
2024-04-23 17:58:06,413 - 946 samples (32 per mini-batch)
2024-04-23 17:58:09,538 - Epoch: [73][  100/  123]    Loss 0.821600    Top1 73.156250    Top5 96.812500    
2024-04-23 17:58:10,750 - Epoch: [98][   10/   30]    Loss 2.408839    Top1 7.187500    Top5 46.875000    
2024-04-23 17:58:13,054 - Epoch: [98][   20/   30]    Loss 2.378053    Top1 9.843750    Top5 50.000000    
2024-04-23 17:58:15,878 - Epoch: [73][  123/  123]    Loss 0.827228    Top1 73.095541    Top5 96.840764    
2024-04-23 17:58:15,930 - Epoch: [98][   30/   30]    Loss 2.381165    Top1 9.830867    Top5 50.211416    
2024-04-23 17:58:16,147 - ==> Top1: 9.831    Top5: 50.211    Loss: 2.381

2024-04-23 17:58:16,150 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 17:58:16,155 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:58:16,156 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:58:16,164 - ==> Top1: 73.096    Top5: 96.841    Loss: 0.827

2024-04-23 17:58:16,174 - 

2024-04-23 17:58:16,175 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:58:16,177 - ==> Best [Top1: 74.726   Top5: 96.943   Sparsity:0.00   Params: 376752 on epoch: 72]
2024-04-23 17:58:16,178 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 17:58:16,244 - 

2024-04-23 17:58:16,246 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 17:58:20,035 - Epoch: [99][   10/  267]    Overall Loss 2.378444    Objective Loss 2.378444                                        LR 0.100000    Time 0.385627    
2024-04-23 17:58:21,673 - Epoch: [99][   20/  267]    Overall Loss 2.358939    Objective Loss 2.358939                                        LR 0.100000    Time 0.274587    
2024-04-23 17:58:23,558 - Epoch: [99][   30/  267]    Overall Loss 2.361986    Objective Loss 2.361986                                        LR 0.100000    Time 0.245812    
2024-04-23 17:58:25,032 - Epoch: [99][   40/  267]    Overall Loss 2.373897    Objective Loss 2.373897                                        LR 0.100000    Time 0.221140    
2024-04-23 17:58:27,239 - Epoch: [99][   50/  267]    Overall Loss 2.371346    Objective Loss 2.371346                                        LR 0.100000    Time 0.220986    
2024-04-23 17:58:28,986 - Epoch: [99][   60/  267]    Overall Loss 2.364978    Objective Loss 2.364978                                        LR 0.100000    Time 0.213230    
2024-04-23 17:58:31,681 - Epoch: [99][   70/  267]    Overall Loss 2.366888    Objective Loss 2.366888                                        LR 0.100000    Time 0.221205    
2024-04-23 17:58:33,649 - Epoch: [99][   80/  267]    Overall Loss 2.364287    Objective Loss 2.364287                                        LR 0.100000    Time 0.218116    
2024-04-23 17:58:36,456 - Epoch: [99][   90/  267]    Overall Loss 2.366206    Objective Loss 2.366206                                        LR 0.100000    Time 0.225032    
2024-04-23 17:58:38,355 - Epoch: [99][  100/  267]    Overall Loss 2.368757    Objective Loss 2.368757                                        LR 0.100000    Time 0.221484    
2024-04-23 17:58:41,488 - Epoch: [99][  110/  267]    Overall Loss 2.367378    Objective Loss 2.367378                                        LR 0.100000    Time 0.229808    
2024-04-23 17:58:42,286 - Epoch: [74][  100/  296]    Overall Loss 0.892714    Objective Loss 0.892714                                        LR 0.000320    Time 0.260161    
2024-04-23 17:58:43,039 - Epoch: [99][  120/  267]    Overall Loss 2.367436    Objective Loss 2.367436                                        LR 0.100000    Time 0.223562    
2024-04-23 17:58:45,385 - Epoch: [99][  130/  267]    Overall Loss 2.367407    Objective Loss 2.367407                                        LR 0.100000    Time 0.224386    
2024-04-23 17:58:47,305 - Epoch: [99][  140/  267]    Overall Loss 2.366922    Objective Loss 2.366922                                        LR 0.100000    Time 0.222050    
2024-04-23 17:58:49,876 - Epoch: [99][  150/  267]    Overall Loss 2.368822    Objective Loss 2.368822                                        LR 0.100000    Time 0.224362    
2024-04-23 17:58:51,796 - Epoch: [99][  160/  267]    Overall Loss 2.368472    Objective Loss 2.368472                                        LR 0.100000    Time 0.222326    
2024-04-23 17:58:54,372 - Epoch: [99][  170/  267]    Overall Loss 2.368112    Objective Loss 2.368112                                        LR 0.100000    Time 0.224384    
2024-04-23 17:58:56,222 - Epoch: [99][  180/  267]    Overall Loss 2.366174    Objective Loss 2.366174                                        LR 0.100000    Time 0.222180    
2024-04-23 17:58:58,731 - Epoch: [99][  190/  267]    Overall Loss 2.364980    Objective Loss 2.364980                                        LR 0.100000    Time 0.223677    
2024-04-23 17:59:00,547 - Epoch: [99][  200/  267]    Overall Loss 2.365302    Objective Loss 2.365302                                        LR 0.100000    Time 0.221554    
2024-04-23 17:59:03,425 - Epoch: [99][  210/  267]    Overall Loss 2.364731    Objective Loss 2.364731                                        LR 0.100000    Time 0.224696    
2024-04-23 17:59:05,232 - Epoch: [99][  220/  267]    Overall Loss 2.366040    Objective Loss 2.366040                                        LR 0.100000    Time 0.222682    
2024-04-23 17:59:06,601 - Epoch: [74][  200/  296]    Overall Loss 0.891117    Objective Loss 0.891117                                        LR 0.000320    Time 0.251554    
2024-04-23 17:59:07,798 - Epoch: [99][  230/  267]    Overall Loss 2.367078    Objective Loss 2.367078                                        LR 0.100000    Time 0.224147    
2024-04-23 17:59:09,663 - Epoch: [99][  240/  267]    Overall Loss 2.366830    Objective Loss 2.366830                                        LR 0.100000    Time 0.222564    
2024-04-23 17:59:12,320 - Epoch: [99][  250/  267]    Overall Loss 2.367119    Objective Loss 2.367119                                        LR 0.100000    Time 0.224276    
2024-04-23 17:59:13,875 - Epoch: [99][  260/  267]    Overall Loss 2.365487    Objective Loss 2.365487                                        LR 0.100000    Time 0.221621    
2024-04-23 17:59:15,219 - Epoch: [99][  267/  267]    Overall Loss 2.365584    Objective Loss 2.365584    Top1 16.279070    Top5 53.488372    LR 0.100000    Time 0.220838    
2024-04-23 17:59:15,473 - --- validate (epoch=99)-----------
2024-04-23 17:59:15,474 - 946 samples (32 per mini-batch)
2024-04-23 17:59:19,072 - Epoch: [99][   10/   30]    Loss 2.335956    Top1 11.562500    Top5 54.687500    
2024-04-23 17:59:20,864 - Epoch: [99][   20/   30]    Loss 2.347223    Top1 10.312500    Top5 51.406250    
2024-04-23 17:59:23,315 - Epoch: [99][   30/   30]    Loss 2.355939    Top1 10.253700    Top5 50.000000    
2024-04-23 17:59:23,511 - ==> Top1: 10.254    Top5: 50.000    Loss: 2.356

2024-04-23 17:59:23,513 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 17:59:23,517 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 17:59:23,518 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 17:59:23,534 - 

2024-04-23 17:59:23,535 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 17:59:26,859 - Epoch: [100][   10/  267]    Overall Loss 2.361098    Objective Loss 2.361098                                        LR 0.100000    Time 0.332039    
2024-04-23 17:59:28,805 - Epoch: [100][   20/  267]    Overall Loss 2.363598    Objective Loss 2.363598                                        LR 0.100000    Time 0.262986    
2024-04-23 17:59:29,191 - Epoch: [74][  296/  296]    Overall Loss 0.903011    Objective Loss 0.903011    Top1 63.934426    Top5 95.081967    LR 0.000320    Time 0.246216    
2024-04-23 17:59:29,426 - --- validate (epoch=74)-----------
2024-04-23 17:59:29,427 - 3925 samples (32 per mini-batch)
2024-04-23 17:59:31,405 - Epoch: [100][   30/  267]    Overall Loss 2.350791    Objective Loss 2.350791                                        LR 0.100000    Time 0.261888    
2024-04-23 17:59:33,461 - Epoch: [100][   40/  267]    Overall Loss 2.354830    Objective Loss 2.354830                                        LR 0.100000    Time 0.247744    
2024-04-23 17:59:36,189 - Epoch: [100][   50/  267]    Overall Loss 2.355439    Objective Loss 2.355439                                        LR 0.100000    Time 0.252692    
2024-04-23 17:59:38,427 - Epoch: [100][   60/  267]    Overall Loss 2.359512    Objective Loss 2.359512                                        LR 0.100000    Time 0.247829    
2024-04-23 17:59:40,847 - Epoch: [100][   70/  267]    Overall Loss 2.361649    Objective Loss 2.361649                                        LR 0.100000    Time 0.246940    
2024-04-23 17:59:43,379 - Epoch: [100][   80/  267]    Overall Loss 2.363025    Objective Loss 2.363025                                        LR 0.100000    Time 0.247690    
2024-04-23 17:59:45,258 - Epoch: [100][   90/  267]    Overall Loss 2.365062    Objective Loss 2.365062                                        LR 0.100000    Time 0.241019    
2024-04-23 17:59:47,802 - Epoch: [100][  100/  267]    Overall Loss 2.366770    Objective Loss 2.366770                                        LR 0.100000    Time 0.242321    
2024-04-23 17:59:49,736 - Epoch: [100][  110/  267]    Overall Loss 2.366462    Objective Loss 2.366462                                        LR 0.100000    Time 0.237846    
2024-04-23 17:59:51,800 - Epoch: [100][  120/  267]    Overall Loss 2.365871    Objective Loss 2.365871                                        LR 0.100000    Time 0.235204    
2024-04-23 17:59:53,684 - Epoch: [100][  130/  267]    Overall Loss 2.365107    Objective Loss 2.365107                                        LR 0.100000    Time 0.231588    
2024-04-23 17:59:56,266 - Epoch: [100][  140/  267]    Overall Loss 2.366231    Objective Loss 2.366231                                        LR 0.100000    Time 0.233465    
2024-04-23 17:59:57,095 - Epoch: [74][  100/  123]    Loss 0.764800    Top1 74.843750    Top5 96.937500    
2024-04-23 17:59:58,233 - Epoch: [100][  150/  267]    Overall Loss 2.367139    Objective Loss 2.367139                                        LR 0.100000    Time 0.230999    
2024-04-23 18:00:00,987 - Epoch: [100][  160/  267]    Overall Loss 2.363738    Objective Loss 2.363738                                        LR 0.100000    Time 0.233751    
2024-04-23 18:00:02,794 - Epoch: [74][  123/  123]    Loss 0.779755    Top1 74.573248    Top5 96.687898    
2024-04-23 18:00:02,928 - Epoch: [100][  170/  267]    Overall Loss 2.365732    Objective Loss 2.365732                                        LR 0.100000    Time 0.231395    
2024-04-23 18:00:03,115 - ==> Top1: 74.573    Top5: 96.688    Loss: 0.780

2024-04-23 18:00:03,128 - ==> Best [Top1: 74.726   Top5: 96.943   Sparsity:0.00   Params: 376752 on epoch: 72]
2024-04-23 18:00:03,129 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:00:03,192 - 

2024-04-23 18:00:03,194 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:00:05,430 - Epoch: [100][  180/  267]    Overall Loss 2.364991    Objective Loss 2.364991                                        LR 0.100000    Time 0.232423    
2024-04-23 18:00:07,348 - Epoch: [100][  190/  267]    Overall Loss 2.364325    Objective Loss 2.364325                                        LR 0.100000    Time 0.230262    
2024-04-23 18:00:10,059 - Epoch: [100][  200/  267]    Overall Loss 2.364229    Objective Loss 2.364229                                        LR 0.100000    Time 0.232286    
2024-04-23 18:00:11,664 - Epoch: [100][  210/  267]    Overall Loss 2.365581    Objective Loss 2.365581                                        LR 0.100000    Time 0.228856    
2024-04-23 18:00:14,313 - Epoch: [100][  220/  267]    Overall Loss 2.364650    Objective Loss 2.364650                                        LR 0.100000    Time 0.230485    
2024-04-23 18:00:16,242 - Epoch: [100][  230/  267]    Overall Loss 2.365148    Objective Loss 2.365148                                        LR 0.100000    Time 0.228839    
2024-04-23 18:00:18,847 - Epoch: [100][  240/  267]    Overall Loss 2.365277    Objective Loss 2.365277                                        LR 0.100000    Time 0.230143    
2024-04-23 18:00:20,831 - Epoch: [100][  250/  267]    Overall Loss 2.365677    Objective Loss 2.365677                                        LR 0.100000    Time 0.228862    
2024-04-23 18:00:23,312 - Epoch: [100][  260/  267]    Overall Loss 2.365785    Objective Loss 2.365785                                        LR 0.100000    Time 0.229591    
2024-04-23 18:00:24,700 - Epoch: [100][  267/  267]    Overall Loss 2.368068    Objective Loss 2.368068    Top1 9.302326    Top5 46.511628    LR 0.100000    Time 0.228762    
2024-04-23 18:00:24,948 - --- validate (epoch=100)-----------
2024-04-23 18:00:24,949 - 946 samples (32 per mini-batch)
2024-04-23 18:00:27,972 - Epoch: [75][  100/  296]    Overall Loss 0.877545    Objective Loss 0.877545                                        LR 0.000320    Time 0.247544    
2024-04-23 18:00:28,659 - Epoch: [100][   10/   30]    Loss 2.370179    Top1 11.250000    Top5 52.812500    
2024-04-23 18:00:30,319 - Epoch: [100][   20/   30]    Loss 2.388966    Top1 10.156250    Top5 51.718750    
2024-04-23 18:00:32,495 - Epoch: [100][   30/   30]    Loss 2.397688    Top1 9.830867    Top5 51.691332    
2024-04-23 18:00:32,743 - ==> Top1: 9.831    Top5: 51.691    Loss: 2.398

2024-04-23 18:00:32,745 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 18:00:32,750 - ==> Best [Top1: 10.994   Top5: 51.903   Sparsity:0.00   Params: 96527 on epoch: 87]
2024-04-23 18:00:32,751 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:00:32,766 - 

2024-04-23 18:00:32,767 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:00:36,215 - Epoch: [101][   10/  267]    Overall Loss 2.414865    Objective Loss 2.414865                                        LR 0.100000    Time 0.344390    
2024-04-23 18:00:38,231 - Epoch: [101][   20/  267]    Overall Loss 2.377694    Objective Loss 2.377694                                        LR 0.100000    Time 0.272835    
2024-04-23 18:00:41,039 - Epoch: [101][   30/  267]    Overall Loss 2.367560    Objective Loss 2.367560                                        LR 0.100000    Time 0.275375    
2024-04-23 18:00:43,040 - Epoch: [101][   40/  267]    Overall Loss 2.368446    Objective Loss 2.368446                                        LR 0.100000    Time 0.256475    
2024-04-23 18:00:45,880 - Epoch: [101][   50/  267]    Overall Loss 2.373082    Objective Loss 2.373082                                        LR 0.100000    Time 0.261939    
2024-04-23 18:00:47,820 - Epoch: [101][   60/  267]    Overall Loss 2.377070    Objective Loss 2.377070                                        LR 0.100000    Time 0.250554    
2024-04-23 18:00:50,428 - Epoch: [101][   70/  267]    Overall Loss 2.382830    Objective Loss 2.382830                                        LR 0.100000    Time 0.251970    
2024-04-23 18:00:51,814 - Epoch: [101][   80/  267]    Overall Loss 2.385751    Objective Loss 2.385751                                        LR 0.100000    Time 0.237774    
2024-04-23 18:00:53,331 - Epoch: [75][  200/  296]    Overall Loss 0.883154    Objective Loss 0.883154                                        LR 0.000320    Time 0.250460    
2024-04-23 18:00:54,120 - Epoch: [101][   90/  267]    Overall Loss 2.382432    Objective Loss 2.382432                                        LR 0.100000    Time 0.236941    
2024-04-23 18:00:55,042 - Epoch: [101][  100/  267]    Overall Loss 2.381306    Objective Loss 2.381306                                        LR 0.100000    Time 0.222443    
2024-04-23 18:00:57,590 - Epoch: [101][  110/  267]    Overall Loss 2.380476    Objective Loss 2.380476                                        LR 0.100000    Time 0.225359    
2024-04-23 18:00:59,479 - Epoch: [101][  120/  267]    Overall Loss 2.380980    Objective Loss 2.380980                                        LR 0.100000    Time 0.222295    
2024-04-23 18:01:01,708 - Epoch: [101][  130/  267]    Overall Loss 2.380479    Objective Loss 2.380479                                        LR 0.100000    Time 0.222318    
2024-04-23 18:01:03,367 - Epoch: [101][  140/  267]    Overall Loss 2.382049    Objective Loss 2.382049                                        LR 0.100000    Time 0.218265    
2024-04-23 18:01:05,828 - Epoch: [101][  150/  267]    Overall Loss 2.382223    Objective Loss 2.382223                                        LR 0.100000    Time 0.220101    
2024-04-23 18:01:08,409 - Epoch: [101][  160/  267]    Overall Loss 2.382409    Objective Loss 2.382409                                        LR 0.100000    Time 0.222460    
2024-04-23 18:01:10,424 - Epoch: [101][  170/  267]    Overall Loss 2.383552    Objective Loss 2.383552                                        LR 0.100000    Time 0.221214    
2024-04-23 18:01:13,131 - Epoch: [101][  180/  267]    Overall Loss 2.382384    Objective Loss 2.382384                                        LR 0.100000    Time 0.223947    
2024-04-23 18:01:15,080 - Epoch: [101][  190/  267]    Overall Loss 2.382120    Objective Loss 2.382120                                        LR 0.100000    Time 0.222403    
2024-04-23 18:01:16,151 - Epoch: [75][  296/  296]    Overall Loss 0.891305    Objective Loss 0.891305    Top1 65.573770    Top5 96.721311    LR 0.000320    Time 0.246257    
2024-04-23 18:01:16,463 - --- validate (epoch=75)-----------
2024-04-23 18:01:16,464 - 3925 samples (32 per mini-batch)
2024-04-23 18:01:17,852 - Epoch: [101][  200/  267]    Overall Loss 2.382852    Objective Loss 2.382852                                        LR 0.100000    Time 0.225130    
2024-04-23 18:01:19,808 - Epoch: [101][  210/  267]    Overall Loss 2.381077    Objective Loss 2.381077                                        LR 0.100000    Time 0.223705    
2024-04-23 18:01:22,433 - Epoch: [101][  220/  267]    Overall Loss 2.381513    Objective Loss 2.381513                                        LR 0.100000    Time 0.225455    
2024-04-23 18:01:24,586 - Epoch: [101][  230/  267]    Overall Loss 2.381941    Objective Loss 2.381941                                        LR 0.100000    Time 0.225000    
2024-04-23 18:01:27,039 - Epoch: [101][  240/  267]    Overall Loss 2.380715    Objective Loss 2.380715                                        LR 0.100000    Time 0.225834    
2024-04-23 18:01:29,190 - Epoch: [101][  250/  267]    Overall Loss 2.378272    Objective Loss 2.378272                                        LR 0.100000    Time 0.225395    
2024-04-23 18:01:31,952 - Epoch: [101][  260/  267]    Overall Loss 2.376674    Objective Loss 2.376674                                        LR 0.100000    Time 0.227336    
2024-04-23 18:01:33,204 - Epoch: [101][  267/  267]    Overall Loss 2.377138    Objective Loss 2.377138    Top1 4.651163    Top5 41.860465    LR 0.100000    Time 0.226058    
2024-04-23 18:01:33,411 - --- validate (epoch=101)-----------
2024-04-23 18:01:33,412 - 946 samples (32 per mini-batch)
2024-04-23 18:01:36,803 - Epoch: [101][   10/   30]    Loss 2.359455    Top1 10.625000    Top5 51.250000    
2024-04-23 18:01:38,439 - Epoch: [101][   20/   30]    Loss 2.367401    Top1 9.375000    Top5 51.562500    
2024-04-23 18:01:40,830 - Epoch: [101][   30/   30]    Loss 2.359122    Top1 10.993658    Top5 52.114165    
2024-04-23 18:01:41,027 - ==> Top1: 10.994    Top5: 52.114    Loss: 2.359

2024-04-23 18:01:41,029 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 18:01:41,032 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:01:41,033 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:01:41,047 - 

2024-04-23 18:01:41,048 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:01:43,937 - Epoch: [75][  100/  123]    Loss 0.753906    Top1 75.093750    Top5 96.593750    
2024-04-23 18:01:44,803 - Epoch: [102][   10/  267]    Overall Loss 2.355835    Objective Loss 2.355835                                        LR 0.100000    Time 0.375204    
2024-04-23 18:01:46,446 - Epoch: [102][   20/  267]    Overall Loss 2.360465    Objective Loss 2.360465                                        LR 0.100000    Time 0.269565    
2024-04-23 18:01:49,019 - Epoch: [102][   30/  267]    Overall Loss 2.375735    Objective Loss 2.375735                                        LR 0.100000    Time 0.265378    
2024-04-23 18:01:49,750 - Epoch: [75][  123/  123]    Loss 0.754773    Top1 75.159236    Top5 96.636943    
2024-04-23 18:01:50,023 - ==> Top1: 75.159    Top5: 96.637    Loss: 0.755

2024-04-23 18:01:50,030 - ==> Best [Top1: 75.159   Top5: 96.637   Sparsity:0.00   Params: 376752 on epoch: 75]
2024-04-23 18:01:50,031 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:01:50,097 - 

2024-04-23 18:01:50,098 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:01:50,986 - Epoch: [102][   40/  267]    Overall Loss 2.372333    Objective Loss 2.372333                                        LR 0.100000    Time 0.248162    
2024-04-23 18:01:53,206 - Epoch: [102][   50/  267]    Overall Loss 2.375887    Objective Loss 2.375887                                        LR 0.100000    Time 0.242878    
2024-04-23 18:01:54,426 - Epoch: [102][   60/  267]    Overall Loss 2.379829    Objective Loss 2.379829                                        LR 0.100000    Time 0.222687    
2024-04-23 18:01:56,423 - Epoch: [102][   70/  267]    Overall Loss 2.385350    Objective Loss 2.385350                                        LR 0.100000    Time 0.219379    
2024-04-23 18:01:58,158 - Epoch: [102][   80/  267]    Overall Loss 2.383789    Objective Loss 2.383789                                        LR 0.100000    Time 0.213607    
2024-04-23 18:01:59,588 - Epoch: [102][   90/  267]    Overall Loss 2.380065    Objective Loss 2.380065                                        LR 0.100000    Time 0.205723    
2024-04-23 18:02:02,098 - Epoch: [102][  100/  267]    Overall Loss 2.379089    Objective Loss 2.379089                                        LR 0.100000    Time 0.210227    
2024-04-23 18:02:04,036 - Epoch: [102][  110/  267]    Overall Loss 2.376855    Objective Loss 2.376855                                        LR 0.100000    Time 0.208705    
2024-04-23 18:02:06,693 - Epoch: [102][  120/  267]    Overall Loss 2.375596    Objective Loss 2.375596                                        LR 0.100000    Time 0.213433    
2024-04-23 18:02:08,791 - Epoch: [102][  130/  267]    Overall Loss 2.373394    Objective Loss 2.373394                                        LR 0.100000    Time 0.213128    
2024-04-23 18:02:11,230 - Epoch: [102][  140/  267]    Overall Loss 2.372969    Objective Loss 2.372969                                        LR 0.100000    Time 0.215307    
2024-04-23 18:02:13,419 - Epoch: [102][  150/  267]    Overall Loss 2.372026    Objective Loss 2.372026                                        LR 0.100000    Time 0.215525    
2024-04-23 18:02:15,863 - Epoch: [102][  160/  267]    Overall Loss 2.372218    Objective Loss 2.372218                                        LR 0.100000    Time 0.217308    
2024-04-23 18:02:16,051 - Epoch: [76][  100/  296]    Overall Loss 0.896046    Objective Loss 0.896046                                        LR 0.000320    Time 0.259306    
2024-04-23 18:02:18,073 - Epoch: [102][  170/  267]    Overall Loss 2.373330    Objective Loss 2.373330                                        LR 0.100000    Time 0.217508    
2024-04-23 18:02:20,550 - Epoch: [102][  180/  267]    Overall Loss 2.372153    Objective Loss 2.372153                                        LR 0.100000    Time 0.219172    
2024-04-23 18:02:22,680 - Epoch: [102][  190/  267]    Overall Loss 2.370441    Objective Loss 2.370441                                        LR 0.100000    Time 0.218828    
2024-04-23 18:02:25,154 - Epoch: [102][  200/  267]    Overall Loss 2.369716    Objective Loss 2.369716                                        LR 0.100000    Time 0.220240    
2024-04-23 18:02:27,218 - Epoch: [102][  210/  267]    Overall Loss 2.369576    Objective Loss 2.369576                                        LR 0.100000    Time 0.219569    
2024-04-23 18:02:29,831 - Epoch: [102][  220/  267]    Overall Loss 2.371217    Objective Loss 2.371217                                        LR 0.100000    Time 0.221453    
2024-04-23 18:02:31,770 - Epoch: [102][  230/  267]    Overall Loss 2.371325    Objective Loss 2.371325                                        LR 0.100000    Time 0.220242    
2024-04-23 18:02:34,540 - Epoch: [102][  240/  267]    Overall Loss 2.372823    Objective Loss 2.372823                                        LR 0.100000    Time 0.222594    
2024-04-23 18:02:37,135 - Epoch: [102][  250/  267]    Overall Loss 2.371589    Objective Loss 2.371589                                        LR 0.100000    Time 0.224058    
2024-04-23 18:02:39,438 - Epoch: [102][  260/  267]    Overall Loss 2.370243    Objective Loss 2.370243                                        LR 0.100000    Time 0.224287    
2024-04-23 18:02:39,838 - Epoch: [102][  267/  267]    Overall Loss 2.369064    Objective Loss 2.369064    Top1 9.302326    Top5 58.139535    LR 0.100000    Time 0.219901    
2024-04-23 18:02:40,034 - --- validate (epoch=102)-----------
2024-04-23 18:02:40,034 - 946 samples (32 per mini-batch)
2024-04-23 18:02:41,414 - Epoch: [76][  200/  296]    Overall Loss 0.889372    Objective Loss 0.889372                                        LR 0.000320    Time 0.256360    
2024-04-23 18:02:43,050 - Epoch: [102][   10/   30]    Loss 2.387759    Top1 12.500000    Top5 53.125000    
2024-04-23 18:02:44,847 - Epoch: [102][   20/   30]    Loss 2.398428    Top1 11.093750    Top5 51.406250    
2024-04-23 18:02:46,651 - Epoch: [102][   30/   30]    Loss 2.401614    Top1 9.830867    Top5 51.268499    
2024-04-23 18:02:46,864 - ==> Top1: 9.831    Top5: 51.268    Loss: 2.402

2024-04-23 18:02:46,866 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 18:02:46,871 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:02:46,872 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:02:46,889 - 

2024-04-23 18:02:46,890 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:02:50,399 - Epoch: [103][   10/  267]    Overall Loss 2.364198    Objective Loss 2.364198                                        LR 0.100000    Time 0.350482    
2024-04-23 18:02:52,626 - Epoch: [103][   20/  267]    Overall Loss 2.379900    Objective Loss 2.379900                                        LR 0.100000    Time 0.286423    
2024-04-23 18:02:55,714 - Epoch: [103][   30/  267]    Overall Loss 2.379670    Objective Loss 2.379670                                        LR 0.100000    Time 0.293773    
2024-04-23 18:02:58,130 - Epoch: [103][   40/  267]    Overall Loss 2.376151    Objective Loss 2.376151                                        LR 0.100000    Time 0.280635    
2024-04-23 18:03:00,256 - Epoch: [103][   50/  267]    Overall Loss 2.380279    Objective Loss 2.380279                                        LR 0.100000    Time 0.266975    
2024-04-23 18:03:01,841 - Epoch: [103][   60/  267]    Overall Loss 2.379051    Objective Loss 2.379051                                        LR 0.100000    Time 0.248856    
2024-04-23 18:03:03,918 - Epoch: [76][  296/  296]    Overall Loss 0.889209    Objective Loss 0.889209    Top1 80.327869    Top5 96.721311    LR 0.000320    Time 0.249171    
2024-04-23 18:03:04,232 - --- validate (epoch=76)-----------
2024-04-23 18:03:04,233 - 3925 samples (32 per mini-batch)
2024-04-23 18:03:04,326 - Epoch: [103][   70/  267]    Overall Loss 2.384889    Objective Loss 2.384889                                        LR 0.100000    Time 0.248763    
2024-04-23 18:03:06,189 - Epoch: [103][   80/  267]    Overall Loss 2.383370    Objective Loss 2.383370                                        LR 0.100000    Time 0.240912    
2024-04-23 18:03:08,901 - Epoch: [103][   90/  267]    Overall Loss 2.386110    Objective Loss 2.386110                                        LR 0.100000    Time 0.244251    
2024-04-23 18:03:10,661 - Epoch: [103][  100/  267]    Overall Loss 2.385083    Objective Loss 2.385083                                        LR 0.100000    Time 0.237393    
2024-04-23 18:03:13,290 - Epoch: [103][  110/  267]    Overall Loss 2.384767    Objective Loss 2.384767                                        LR 0.100000    Time 0.239681    
2024-04-23 18:03:15,140 - Epoch: [103][  120/  267]    Overall Loss 2.383674    Objective Loss 2.383674                                        LR 0.100000    Time 0.235092    
2024-04-23 18:03:17,886 - Epoch: [103][  130/  267]    Overall Loss 2.383408    Objective Loss 2.383408                                        LR 0.100000    Time 0.238108    
2024-04-23 18:03:19,784 - Epoch: [103][  140/  267]    Overall Loss 2.378942    Objective Loss 2.378942                                        LR 0.100000    Time 0.234642    
2024-04-23 18:03:22,447 - Epoch: [103][  150/  267]    Overall Loss 2.376756    Objective Loss 2.376756                                        LR 0.100000    Time 0.236719    
2024-04-23 18:03:24,478 - Epoch: [103][  160/  267]    Overall Loss 2.376124    Objective Loss 2.376124                                        LR 0.100000    Time 0.234597    
2024-04-23 18:03:26,879 - Epoch: [103][  170/  267]    Overall Loss 2.375932    Objective Loss 2.375932                                        LR 0.100000    Time 0.234906    
2024-04-23 18:03:29,144 - Epoch: [103][  180/  267]    Overall Loss 2.375768    Objective Loss 2.375768                                        LR 0.100000    Time 0.234422    
2024-04-23 18:03:31,146 - Epoch: [103][  190/  267]    Overall Loss 2.375256    Objective Loss 2.375256                                        LR 0.100000    Time 0.232605    
2024-04-23 18:03:31,198 - Epoch: [76][  100/  123]    Loss 0.756680    Top1 75.718750    Top5 96.687500    
2024-04-23 18:03:32,962 - Epoch: [103][  200/  267]    Overall Loss 2.374424    Objective Loss 2.374424                                        LR 0.100000    Time 0.230042    
2024-04-23 18:03:35,487 - Epoch: [103][  210/  267]    Overall Loss 2.374210    Objective Loss 2.374210                                        LR 0.100000    Time 0.231100    
2024-04-23 18:03:36,813 - Epoch: [76][  123/  123]    Loss 0.764744    Top1 75.592357    Top5 96.611465    
2024-04-23 18:03:37,099 - ==> Top1: 75.592    Top5: 96.611    Loss: 0.765

2024-04-23 18:03:37,110 - ==> Best [Top1: 75.592   Top5: 96.611   Sparsity:0.00   Params: 376752 on epoch: 76]
2024-04-23 18:03:37,111 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:03:37,205 - 

2024-04-23 18:03:37,206 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:03:37,673 - Epoch: [103][  220/  267]    Overall Loss 2.373030    Objective Loss 2.373030                                        LR 0.100000    Time 0.230520    
2024-04-23 18:03:39,994 - Epoch: [103][  230/  267]    Overall Loss 2.373683    Objective Loss 2.373683                                        LR 0.100000    Time 0.230577    
2024-04-23 18:03:41,787 - Epoch: [103][  240/  267]    Overall Loss 2.373494    Objective Loss 2.373494                                        LR 0.100000    Time 0.228428    
2024-04-23 18:03:43,885 - Epoch: [103][  250/  267]    Overall Loss 2.372772    Objective Loss 2.372772                                        LR 0.100000    Time 0.227670    
2024-04-23 18:03:45,751 - Epoch: [103][  260/  267]    Overall Loss 2.370945    Objective Loss 2.370945                                        LR 0.100000    Time 0.226083    
2024-04-23 18:03:46,815 - Epoch: [103][  267/  267]    Overall Loss 2.371114    Objective Loss 2.371114    Top1 2.325581    Top5 39.534884    LR 0.100000    Time 0.224130    
2024-04-23 18:03:46,996 - --- validate (epoch=103)-----------
2024-04-23 18:03:46,997 - 946 samples (32 per mini-batch)
2024-04-23 18:03:49,964 - Epoch: [103][   10/   30]    Loss 2.331870    Top1 9.687500    Top5 48.125000    
2024-04-23 18:03:51,501 - Epoch: [103][   20/   30]    Loss 2.324424    Top1 10.312500    Top5 50.781250    
2024-04-23 18:03:53,475 - Epoch: [103][   30/   30]    Loss 2.325414    Top1 10.253700    Top5 51.057082    
2024-04-23 18:03:53,686 - ==> Top1: 10.254    Top5: 51.057    Loss: 2.325

2024-04-23 18:03:53,688 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 18:03:53,693 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:03:53,693 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:03:53,711 - 

2024-04-23 18:03:53,712 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:03:56,868 - Epoch: [104][   10/  267]    Overall Loss 2.330427    Objective Loss 2.330427                                        LR 0.100000    Time 0.315292    
2024-04-23 18:03:58,571 - Epoch: [104][   20/  267]    Overall Loss 2.333774    Objective Loss 2.333774                                        LR 0.100000    Time 0.242632    
2024-04-23 18:04:00,933 - Epoch: [104][   30/  267]    Overall Loss 2.358108    Objective Loss 2.358108                                        LR 0.100000    Time 0.240412    
2024-04-23 18:04:02,094 - Epoch: [104][   40/  267]    Overall Loss 2.361530    Objective Loss 2.361530                                        LR 0.100000    Time 0.209285    
2024-04-23 18:04:04,408 - Epoch: [104][   50/  267]    Overall Loss 2.366005    Objective Loss 2.366005                                        LR 0.100000    Time 0.213646    
2024-04-23 18:04:06,105 - Epoch: [104][   60/  267]    Overall Loss 2.367127    Objective Loss 2.367127                                        LR 0.100000    Time 0.206262    
2024-04-23 18:04:06,439 - Epoch: [77][  100/  296]    Overall Loss 0.880171    Objective Loss 0.880171                                        LR 0.000320    Time 0.292065    
2024-04-23 18:04:08,417 - Epoch: [104][   70/  267]    Overall Loss 2.370241    Objective Loss 2.370241                                        LR 0.100000    Time 0.209781    
2024-04-23 18:04:10,186 - Epoch: [104][   80/  267]    Overall Loss 2.371350    Objective Loss 2.371350                                        LR 0.100000    Time 0.205637    
2024-04-23 18:04:12,455 - Epoch: [104][   90/  267]    Overall Loss 2.373156    Objective Loss 2.373156                                        LR 0.100000    Time 0.207962    
2024-04-23 18:04:14,010 - Epoch: [104][  100/  267]    Overall Loss 2.373902    Objective Loss 2.373902                                        LR 0.100000    Time 0.202689    
2024-04-23 18:04:16,703 - Epoch: [104][  110/  267]    Overall Loss 2.371538    Objective Loss 2.371538                                        LR 0.100000    Time 0.208720    
2024-04-23 18:04:18,507 - Epoch: [104][  120/  267]    Overall Loss 2.370531    Objective Loss 2.370531                                        LR 0.100000    Time 0.206332    
2024-04-23 18:04:21,095 - Epoch: [104][  130/  267]    Overall Loss 2.373258    Objective Loss 2.373258                                        LR 0.100000    Time 0.210346    
2024-04-23 18:04:22,795 - Epoch: [104][  140/  267]    Overall Loss 2.372632    Objective Loss 2.372632                                        LR 0.100000    Time 0.207447    
2024-04-23 18:04:24,892 - Epoch: [104][  150/  267]    Overall Loss 2.370997    Objective Loss 2.370997                                        LR 0.100000    Time 0.207584    
2024-04-23 18:04:26,853 - Epoch: [104][  160/  267]    Overall Loss 2.370345    Objective Loss 2.370345                                        LR 0.100000    Time 0.206848    
2024-04-23 18:04:30,412 - Epoch: [77][  200/  296]    Overall Loss 0.887041    Objective Loss 0.887041                                        LR 0.000320    Time 0.265788    
2024-04-23 18:04:30,505 - Epoch: [104][  170/  267]    Overall Loss 2.369400    Objective Loss 2.369400                                        LR 0.100000    Time 0.216137    
2024-04-23 18:04:32,968 - Epoch: [104][  180/  267]    Overall Loss 2.368515    Objective Loss 2.368515                                        LR 0.100000    Time 0.217796    
2024-04-23 18:04:35,743 - Epoch: [104][  190/  267]    Overall Loss 2.368256    Objective Loss 2.368256                                        LR 0.100000    Time 0.220921    
2024-04-23 18:04:37,936 - Epoch: [104][  200/  267]    Overall Loss 2.366880    Objective Loss 2.366880                                        LR 0.100000    Time 0.220827    
2024-04-23 18:04:41,351 - Epoch: [104][  210/  267]    Overall Loss 2.366082    Objective Loss 2.366082                                        LR 0.100000    Time 0.226560    
2024-04-23 18:04:43,548 - Epoch: [104][  220/  267]    Overall Loss 2.367250    Objective Loss 2.367250                                        LR 0.100000    Time 0.226230    
2024-04-23 18:04:46,464 - Epoch: [104][  230/  267]    Overall Loss 2.366458    Objective Loss 2.366458                                        LR 0.100000    Time 0.229060    
2024-04-23 18:04:49,644 - Epoch: [104][  240/  267]    Overall Loss 2.366613    Objective Loss 2.366613                                        LR 0.100000    Time 0.232745    
2024-04-23 18:04:50,306 - Epoch: [77][  296/  296]    Overall Loss 0.888178    Objective Loss 0.888178    Top1 72.131148    Top5 96.721311    LR 0.000320    Time 0.246728    
2024-04-23 18:04:50,641 - --- validate (epoch=77)-----------
2024-04-23 18:04:50,642 - 3925 samples (32 per mini-batch)
2024-04-23 18:04:52,136 - Epoch: [104][  250/  267]    Overall Loss 2.367063    Objective Loss 2.367063                                        LR 0.100000    Time 0.233392    
2024-04-23 18:04:55,460 - Epoch: [104][  260/  267]    Overall Loss 2.366572    Objective Loss 2.366572                                        LR 0.100000    Time 0.237186    
2024-04-23 18:04:57,160 - Epoch: [104][  267/  267]    Overall Loss 2.366908    Objective Loss 2.366908    Top1 9.302326    Top5 46.511628    LR 0.100000    Time 0.237329    
2024-04-23 18:04:57,429 - --- validate (epoch=104)-----------
2024-04-23 18:04:57,431 - 946 samples (32 per mini-batch)
2024-04-23 18:05:00,912 - Epoch: [104][   10/   30]    Loss 2.346582    Top1 9.687500    Top5 49.687500    
2024-04-23 18:05:02,715 - Epoch: [104][   20/   30]    Loss 2.357911    Top1 9.218750    Top5 48.750000    
2024-04-23 18:05:05,567 - Epoch: [104][   30/   30]    Loss 2.363959    Top1 8.456660    Top5 48.308668    
2024-04-23 18:05:05,774 - ==> Top1: 8.457    Top5: 48.309    Loss: 2.364

2024-04-23 18:05:05,777 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 18:05:05,783 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:05:05,784 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:05:05,803 - 

2024-04-23 18:05:05,804 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:05:09,307 - Epoch: [105][   10/  267]    Overall Loss 2.378026    Objective Loss 2.378026                                        LR 0.100000    Time 0.349864    
2024-04-23 18:05:11,833 - Epoch: [105][   20/  267]    Overall Loss 2.373691    Objective Loss 2.373691                                        LR 0.100000    Time 0.301085    
2024-04-23 18:05:14,431 - Epoch: [105][   30/  267]    Overall Loss 2.365986    Objective Loss 2.365986                                        LR 0.100000    Time 0.287236    
2024-04-23 18:05:15,689 - Epoch: [77][  100/  123]    Loss 0.797126    Top1 73.718750    Top5 96.687500    
2024-04-23 18:05:15,930 - Epoch: [105][   40/  267]    Overall Loss 2.357826    Objective Loss 2.357826                                        LR 0.100000    Time 0.252820    
2024-04-23 18:05:18,579 - Epoch: [105][   50/  267]    Overall Loss 2.361427    Objective Loss 2.361427                                        LR 0.100000    Time 0.255166    
2024-04-23 18:05:20,597 - Epoch: [77][  123/  123]    Loss 0.795944    Top1 73.656051    Top5 96.636943    
2024-04-23 18:05:20,654 - Epoch: [105][   60/  267]    Overall Loss 2.357515    Objective Loss 2.357515                                        LR 0.100000    Time 0.247182    
2024-04-23 18:05:20,819 - ==> Top1: 73.656    Top5: 96.637    Loss: 0.796

2024-04-23 18:05:20,829 - ==> Best [Top1: 75.592   Top5: 96.611   Sparsity:0.00   Params: 376752 on epoch: 76]
2024-04-23 18:05:20,830 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:05:20,888 - 

2024-04-23 18:05:20,889 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:05:22,711 - Epoch: [105][   70/  267]    Overall Loss 2.363579    Objective Loss 2.363579                                        LR 0.100000    Time 0.241217    
2024-04-23 18:05:24,335 - Epoch: [105][   80/  267]    Overall Loss 2.365449    Objective Loss 2.365449                                        LR 0.100000    Time 0.231328    
2024-04-23 18:05:27,338 - Epoch: [105][   90/  267]    Overall Loss 2.365992    Objective Loss 2.365992                                        LR 0.100000    Time 0.238953    
2024-04-23 18:05:29,460 - Epoch: [105][  100/  267]    Overall Loss 2.364502    Objective Loss 2.364502                                        LR 0.100000    Time 0.236248    
2024-04-23 18:05:32,281 - Epoch: [105][  110/  267]    Overall Loss 2.364795    Objective Loss 2.364795                                        LR 0.100000    Time 0.240394    
2024-04-23 18:05:34,897 - Epoch: [105][  120/  267]    Overall Loss 2.370013    Objective Loss 2.370013                                        LR 0.100000    Time 0.242132    
2024-04-23 18:05:37,266 - Epoch: [105][  130/  267]    Overall Loss 2.367174    Objective Loss 2.367174                                        LR 0.100000    Time 0.241711    
2024-04-23 18:05:40,358 - Epoch: [105][  140/  267]    Overall Loss 2.365344    Objective Loss 2.365344                                        LR 0.100000    Time 0.246513    
2024-04-23 18:05:41,973 - Epoch: [105][  150/  267]    Overall Loss 2.364710    Objective Loss 2.364710                                        LR 0.100000    Time 0.240829    
2024-04-23 18:05:44,896 - Epoch: [105][  160/  267]    Overall Loss 2.367048    Objective Loss 2.367048                                        LR 0.100000    Time 0.244031    
2024-04-23 18:05:47,246 - Epoch: [105][  170/  267]    Overall Loss 2.366938    Objective Loss 2.366938                                        LR 0.100000    Time 0.243483    
2024-04-23 18:05:47,281 - Epoch: [78][  100/  296]    Overall Loss 0.847492    Objective Loss 0.847492                                        LR 0.000320    Time 0.263675    
2024-04-23 18:05:50,923 - Epoch: [105][  180/  267]    Overall Loss 2.367372    Objective Loss 2.367372                                        LR 0.100000    Time 0.250375    
2024-04-23 18:05:53,222 - Epoch: [105][  190/  267]    Overall Loss 2.366680    Objective Loss 2.366680                                        LR 0.100000    Time 0.249282    
2024-04-23 18:05:56,251 - Epoch: [105][  200/  267]    Overall Loss 2.366955    Objective Loss 2.366955                                        LR 0.100000    Time 0.251948    
2024-04-23 18:05:58,562 - Epoch: [105][  210/  267]    Overall Loss 2.367972    Objective Loss 2.367972                                        LR 0.100000    Time 0.250948    
2024-04-23 18:06:02,054 - Epoch: [105][  220/  267]    Overall Loss 2.367517    Objective Loss 2.367517                                        LR 0.100000    Time 0.255404    
2024-04-23 18:06:04,447 - Epoch: [105][  230/  267]    Overall Loss 2.368880    Objective Loss 2.368880                                        LR 0.100000    Time 0.254697    
2024-04-23 18:06:06,932 - Epoch: [105][  240/  267]    Overall Loss 2.367800    Objective Loss 2.367800                                        LR 0.100000    Time 0.254429    
2024-04-23 18:06:08,506 - Epoch: [105][  250/  267]    Overall Loss 2.368446    Objective Loss 2.368446                                        LR 0.100000    Time 0.250542    
2024-04-23 18:06:11,591 - Epoch: [105][  260/  267]    Overall Loss 2.368939    Objective Loss 2.368939                                        LR 0.100000    Time 0.252757    
2024-04-23 18:06:12,153 - Epoch: [105][  267/  267]    Overall Loss 2.369307    Objective Loss 2.369307    Top1 16.279070    Top5 48.837209    LR 0.100000    Time 0.248231    
2024-04-23 18:06:12,358 - --- validate (epoch=105)-----------
2024-04-23 18:06:12,359 - 946 samples (32 per mini-batch)
2024-04-23 18:06:12,836 - Epoch: [78][  200/  296]    Overall Loss 0.884599    Objective Loss 0.884599                                        LR 0.000320    Time 0.259509    
2024-04-23 18:06:16,808 - Epoch: [105][   10/   30]    Loss 2.348420    Top1 14.687500    Top5 57.500000    
2024-04-23 18:06:19,387 - Epoch: [105][   20/   30]    Loss 2.380208    Top1 11.250000    Top5 51.718750    
2024-04-23 18:06:22,265 - Epoch: [105][   30/   30]    Loss 2.410748    Top1 10.042283    Top5 49.788584    
2024-04-23 18:06:22,477 - ==> Top1: 10.042    Top5: 49.789    Loss: 2.411

2024-04-23 18:06:22,478 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 18:06:22,483 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:06:22,484 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:06:22,501 - 

2024-04-23 18:06:22,502 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:06:27,467 - Epoch: [106][   10/  267]    Overall Loss 2.381728    Objective Loss 2.381728                                        LR 0.100000    Time 0.496082    
2024-04-23 18:06:28,721 - Epoch: [78][  296/  296]    Overall Loss 0.890600    Objective Loss 0.890600    Top1 65.573770    Top5 96.721311    LR 0.000320    Time 0.228946    
2024-04-23 18:06:29,002 - --- validate (epoch=78)-----------
2024-04-23 18:06:29,002 - 3925 samples (32 per mini-batch)
2024-04-23 18:06:29,958 - Epoch: [106][   20/  267]    Overall Loss 2.389830    Objective Loss 2.389830                                        LR 0.100000    Time 0.372460    
2024-04-23 18:06:33,646 - Epoch: [106][   30/  267]    Overall Loss 2.375047    Objective Loss 2.375047                                        LR 0.100000    Time 0.371134    
2024-04-23 18:06:36,169 - Epoch: [106][   40/  267]    Overall Loss 2.375165    Objective Loss 2.375165                                        LR 0.100000    Time 0.341366    
2024-04-23 18:06:39,014 - Epoch: [106][   50/  267]    Overall Loss 2.382613    Objective Loss 2.382613                                        LR 0.100000    Time 0.329925    
2024-04-23 18:06:40,868 - Epoch: [106][   60/  267]    Overall Loss 2.381714    Objective Loss 2.381714                                        LR 0.100000    Time 0.305783    
2024-04-23 18:06:43,645 - Epoch: [106][   70/  267]    Overall Loss 2.381381    Objective Loss 2.381381                                        LR 0.100000    Time 0.301734    
2024-04-23 18:06:45,391 - Epoch: [106][   80/  267]    Overall Loss 2.376098    Objective Loss 2.376098                                        LR 0.100000    Time 0.285797    
2024-04-23 18:06:48,009 - Epoch: [106][   90/  267]    Overall Loss 2.374882    Objective Loss 2.374882                                        LR 0.100000    Time 0.283097    
2024-04-23 18:06:50,213 - Epoch: [106][  100/  267]    Overall Loss 2.374278    Objective Loss 2.374278                                        LR 0.100000    Time 0.276795    
2024-04-23 18:06:51,867 - Epoch: [78][  100/  123]    Loss 0.772150    Top1 74.812500    Top5 96.468750    
2024-04-23 18:06:52,929 - Epoch: [106][  110/  267]    Overall Loss 2.374172    Objective Loss 2.374172                                        LR 0.100000    Time 0.276284    
2024-04-23 18:06:55,091 - Epoch: [106][  120/  267]    Overall Loss 2.375024    Objective Loss 2.375024                                        LR 0.100000    Time 0.271256    
2024-04-23 18:06:56,826 - Epoch: [78][  123/  123]    Loss 0.761653    Top1 75.388535    Top5 96.356688    
2024-04-23 18:06:57,119 - ==> Top1: 75.389    Top5: 96.357    Loss: 0.762

2024-04-23 18:06:57,129 - ==> Best [Top1: 75.592   Top5: 96.611   Sparsity:0.00   Params: 376752 on epoch: 76]
2024-04-23 18:06:57,129 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:06:57,187 - 

2024-04-23 18:06:57,189 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:06:57,544 - Epoch: [106][  130/  267]    Overall Loss 2.373834    Objective Loss 2.373834                                        LR 0.100000    Time 0.269241    
2024-04-23 18:06:59,989 - Epoch: [106][  140/  267]    Overall Loss 2.370431    Objective Loss 2.370431                                        LR 0.100000    Time 0.267452    
2024-04-23 18:07:03,011 - Epoch: [106][  150/  267]    Overall Loss 2.369333    Objective Loss 2.369333                                        LR 0.100000    Time 0.269749    
2024-04-23 18:07:05,284 - Epoch: [106][  160/  267]    Overall Loss 2.368299    Objective Loss 2.368299                                        LR 0.100000    Time 0.267073    
2024-04-23 18:07:08,294 - Epoch: [106][  170/  267]    Overall Loss 2.366927    Objective Loss 2.366927                                        LR 0.100000    Time 0.269050    
2024-04-23 18:07:10,695 - Epoch: [106][  180/  267]    Overall Loss 2.367948    Objective Loss 2.367948                                        LR 0.100000    Time 0.267424    
2024-04-23 18:07:13,614 - Epoch: [106][  190/  267]    Overall Loss 2.367760    Objective Loss 2.367760                                        LR 0.100000    Time 0.268698    
2024-04-23 18:07:15,390 - Epoch: [106][  200/  267]    Overall Loss 2.369744    Objective Loss 2.369744                                        LR 0.100000    Time 0.264121    
2024-04-23 18:07:17,980 - Epoch: [106][  210/  267]    Overall Loss 2.370363    Objective Loss 2.370363                                        LR 0.100000    Time 0.263863    
2024-04-23 18:07:18,619 - Epoch: [79][  100/  296]    Overall Loss 0.881999    Objective Loss 0.881999                                        LR 0.000320    Time 0.214082    
2024-04-23 18:07:19,795 - Epoch: [106][  220/  267]    Overall Loss 2.371237    Objective Loss 2.371237                                        LR 0.100000    Time 0.260102    
2024-04-23 18:07:22,269 - Epoch: [106][  230/  267]    Overall Loss 2.371316    Objective Loss 2.371316                                        LR 0.100000    Time 0.259533    
2024-04-23 18:07:24,202 - Epoch: [106][  240/  267]    Overall Loss 2.369989    Objective Loss 2.369989                                        LR 0.100000    Time 0.256761    
2024-04-23 18:07:26,346 - Epoch: [106][  250/  267]    Overall Loss 2.369774    Objective Loss 2.369774                                        LR 0.100000    Time 0.255054    
2024-04-23 18:07:27,910 - Epoch: [106][  260/  267]    Overall Loss 2.370361    Objective Loss 2.370361                                        LR 0.100000    Time 0.251248    
2024-04-23 18:07:29,129 - Epoch: [106][  267/  267]    Overall Loss 2.370363    Objective Loss 2.370363    Top1 9.302326    Top5 53.488372    LR 0.100000    Time 0.249217    
2024-04-23 18:07:29,389 - --- validate (epoch=106)-----------
2024-04-23 18:07:29,390 - 946 samples (32 per mini-batch)
2024-04-23 18:07:34,430 - Epoch: [106][   10/   30]    Loss 2.338581    Top1 10.312500    Top5 45.625000    
2024-04-23 18:07:37,081 - Epoch: [106][   20/   30]    Loss 2.331904    Top1 10.781250    Top5 48.437500    
2024-04-23 18:07:39,306 - Epoch: [106][   30/   30]    Loss 2.325252    Top1 10.993658    Top5 50.528541    
2024-04-23 18:07:39,550 - ==> Top1: 10.994    Top5: 50.529    Loss: 2.325

2024-04-23 18:07:39,553 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 18:07:39,560 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:07:39,561 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:07:39,581 - 

2024-04-23 18:07:39,582 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:07:43,965 - Epoch: [107][   10/  267]    Overall Loss 2.345661    Objective Loss 2.345661                                        LR 0.100000    Time 0.437932    
2024-04-23 18:07:46,769 - Epoch: [79][  200/  296]    Overall Loss 0.882433    Objective Loss 0.882433                                        LR 0.000320    Time 0.247686    
2024-04-23 18:07:47,088 - Epoch: [107][   20/  267]    Overall Loss 2.362270    Objective Loss 2.362270                                        LR 0.100000    Time 0.374908    
2024-04-23 18:07:50,804 - Epoch: [107][   30/  267]    Overall Loss 2.355145    Objective Loss 2.355145                                        LR 0.100000    Time 0.373673    
2024-04-23 18:07:54,092 - Epoch: [107][   40/  267]    Overall Loss 2.354420    Objective Loss 2.354420                                        LR 0.100000    Time 0.362397    
2024-04-23 18:07:57,237 - Epoch: [107][   50/  267]    Overall Loss 2.358316    Objective Loss 2.358316                                        LR 0.100000    Time 0.352747    
2024-04-23 18:08:00,574 - Epoch: [107][   60/  267]    Overall Loss 2.354358    Objective Loss 2.354358                                        LR 0.100000    Time 0.349498    
2024-04-23 18:08:03,600 - Epoch: [107][   70/  267]    Overall Loss 2.360827    Objective Loss 2.360827                                        LR 0.100000    Time 0.342753    
2024-04-23 18:08:07,069 - Epoch: [107][   80/  267]    Overall Loss 2.363104    Objective Loss 2.363104                                        LR 0.100000    Time 0.343243    
2024-04-23 18:08:09,888 - Epoch: [107][   90/  267]    Overall Loss 2.360740    Objective Loss 2.360740                                        LR 0.100000    Time 0.336386    
2024-04-23 18:08:12,903 - Epoch: [107][  100/  267]    Overall Loss 2.356894    Objective Loss 2.356894                                        LR 0.100000    Time 0.332868    
2024-04-23 18:08:16,200 - Epoch: [107][  110/  267]    Overall Loss 2.359863    Objective Loss 2.359863                                        LR 0.100000    Time 0.332548    
2024-04-23 18:08:16,294 - Epoch: [79][  296/  296]    Overall Loss 0.888368    Objective Loss 0.888368    Top1 77.049180    Top5 96.721311    LR 0.000320    Time 0.267033    
2024-04-23 18:08:16,604 - --- validate (epoch=79)-----------
2024-04-23 18:08:16,606 - 3925 samples (32 per mini-batch)
2024-04-23 18:08:18,438 - Epoch: [107][  120/  267]    Overall Loss 2.356209    Objective Loss 2.356209                                        LR 0.100000    Time 0.323460    
2024-04-23 18:08:21,824 - Epoch: [107][  130/  267]    Overall Loss 2.356473    Objective Loss 2.356473                                        LR 0.100000    Time 0.324605    
2024-04-23 18:08:23,865 - Epoch: [107][  140/  267]    Overall Loss 2.357287    Objective Loss 2.357287                                        LR 0.100000    Time 0.315974    
2024-04-23 18:08:26,915 - Epoch: [107][  150/  267]    Overall Loss 2.357621    Objective Loss 2.357621                                        LR 0.100000    Time 0.315201    
2024-04-23 18:08:29,314 - Epoch: [107][  160/  267]    Overall Loss 2.360926    Objective Loss 2.360926                                        LR 0.100000    Time 0.310476    
2024-04-23 18:08:31,926 - Epoch: [107][  170/  267]    Overall Loss 2.361495    Objective Loss 2.361495                                        LR 0.100000    Time 0.307557    
2024-04-23 18:08:34,186 - Epoch: [107][  180/  267]    Overall Loss 2.361931    Objective Loss 2.361931                                        LR 0.100000    Time 0.303008    
2024-04-23 18:08:37,071 - Epoch: [107][  190/  267]    Overall Loss 2.362056    Objective Loss 2.362056                                        LR 0.100000    Time 0.302230    
2024-04-23 18:08:39,155 - Epoch: [107][  200/  267]    Overall Loss 2.363887    Objective Loss 2.363887                                        LR 0.100000    Time 0.297521    
2024-04-23 18:08:42,424 - Epoch: [107][  210/  267]    Overall Loss 2.365172    Objective Loss 2.365172                                        LR 0.100000    Time 0.298911    
2024-04-23 18:08:44,764 - Epoch: [107][  220/  267]    Overall Loss 2.365710    Objective Loss 2.365710                                        LR 0.100000    Time 0.295943    
2024-04-23 18:08:45,903 - Epoch: [79][  100/  123]    Loss 0.745670    Top1 75.687500    Top5 96.781250    
2024-04-23 18:08:47,680 - Epoch: [107][  230/  267]    Overall Loss 2.364456    Objective Loss 2.364456                                        LR 0.100000    Time 0.295741    
2024-04-23 18:08:49,857 - Epoch: [107][  240/  267]    Overall Loss 2.364220    Objective Loss 2.364220                                        LR 0.100000    Time 0.292480    
2024-04-23 18:08:52,298 - Epoch: [79][  123/  123]    Loss 0.751570    Top1 75.694268    Top5 96.585987    
2024-04-23 18:08:52,583 - ==> Top1: 75.694    Top5: 96.586    Loss: 0.752

2024-04-23 18:08:52,591 - ==> Best [Top1: 75.694   Top5: 96.586   Sparsity:0.00   Params: 376752 on epoch: 79]
2024-04-23 18:08:52,592 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:08:52,616 - Epoch: [107][  250/  267]    Overall Loss 2.362956    Objective Loss 2.362956                                        LR 0.100000    Time 0.291807    
2024-04-23 18:08:52,661 - 

2024-04-23 18:08:52,661 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:08:55,010 - Epoch: [107][  260/  267]    Overall Loss 2.362277    Objective Loss 2.362277                                        LR 0.100000    Time 0.289778    
2024-04-23 18:08:57,111 - Epoch: [107][  267/  267]    Overall Loss 2.362554    Objective Loss 2.362554    Top1 6.976744    Top5 48.837209    LR 0.100000    Time 0.290044    
2024-04-23 18:08:57,357 - --- validate (epoch=107)-----------
2024-04-23 18:08:57,358 - 946 samples (32 per mini-batch)
2024-04-23 18:09:01,336 - Epoch: [107][   10/   30]    Loss 2.314477    Top1 11.250000    Top5 50.625000    
2024-04-23 18:09:03,736 - Epoch: [107][   20/   30]    Loss 2.322180    Top1 10.937500    Top5 48.906250    
2024-04-23 18:09:06,720 - Epoch: [107][   30/   30]    Loss 2.325892    Top1 10.359408    Top5 48.097252    
2024-04-23 18:09:06,956 - ==> Top1: 10.359    Top5: 48.097    Loss: 2.326

2024-04-23 18:09:06,958 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 18:09:06,965 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:09:06,966 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:09:06,987 - 

2024-04-23 18:09:06,988 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:09:11,556 - Epoch: [108][   10/  267]    Overall Loss 2.369200    Objective Loss 2.369200                                        LR 0.100000    Time 0.456409    
2024-04-23 18:09:13,994 - Epoch: [108][   20/  267]    Overall Loss 2.367306    Objective Loss 2.367306                                        LR 0.100000    Time 0.349848    
2024-04-23 18:09:17,174 - Epoch: [108][   30/  267]    Overall Loss 2.371254    Objective Loss 2.371254                                        LR 0.100000    Time 0.339137    
2024-04-23 18:09:19,162 - Epoch: [108][   40/  267]    Overall Loss 2.365490    Objective Loss 2.365490                                        LR 0.100000    Time 0.303996    
2024-04-23 18:09:21,652 - Epoch: [108][   50/  267]    Overall Loss 2.366015    Objective Loss 2.366015                                        LR 0.100000    Time 0.292949    
2024-04-23 18:09:22,072 - Epoch: [80][  100/  296]    Overall Loss 0.864083    Objective Loss 0.864083                                        LR 0.000320    Time 0.293884    
2024-04-23 18:09:23,405 - Epoch: [108][   60/  267]    Overall Loss 2.364322    Objective Loss 2.364322                                        LR 0.100000    Time 0.273280    
2024-04-23 18:09:25,903 - Epoch: [108][   70/  267]    Overall Loss 2.363093    Objective Loss 2.363093                                        LR 0.100000    Time 0.269859    
2024-04-23 18:09:28,148 - Epoch: [108][   80/  267]    Overall Loss 2.361576    Objective Loss 2.361576                                        LR 0.100000    Time 0.264150    
2024-04-23 18:09:30,406 - Epoch: [108][   90/  267]    Overall Loss 2.362527    Objective Loss 2.362527                                        LR 0.100000    Time 0.259858    
2024-04-23 18:09:33,414 - Epoch: [108][  100/  267]    Overall Loss 2.370339    Objective Loss 2.370339                                        LR 0.100000    Time 0.263930    
2024-04-23 18:09:35,597 - Epoch: [108][  110/  267]    Overall Loss 2.371142    Objective Loss 2.371142                                        LR 0.100000    Time 0.259760    
2024-04-23 18:09:38,699 - Epoch: [108][  120/  267]    Overall Loss 2.374226    Objective Loss 2.374226                                        LR 0.100000    Time 0.263944    
2024-04-23 18:09:40,691 - Epoch: [108][  130/  267]    Overall Loss 2.371698    Objective Loss 2.371698                                        LR 0.100000    Time 0.258941    
2024-04-23 18:09:43,756 - Epoch: [108][  140/  267]    Overall Loss 2.372281    Objective Loss 2.372281                                        LR 0.100000    Time 0.262315    
2024-04-23 18:09:46,041 - Epoch: [108][  150/  267]    Overall Loss 2.370644    Objective Loss 2.370644                                        LR 0.100000    Time 0.260036    
2024-04-23 18:09:46,066 - Epoch: [80][  200/  296]    Overall Loss 0.867721    Objective Loss 0.867721                                        LR 0.000320    Time 0.266809    
2024-04-23 18:09:49,101 - Epoch: [108][  160/  267]    Overall Loss 2.369134    Objective Loss 2.369134                                        LR 0.100000    Time 0.262889    
2024-04-23 18:09:51,211 - Epoch: [108][  170/  267]    Overall Loss 2.371863    Objective Loss 2.371863                                        LR 0.100000    Time 0.259813    
2024-04-23 18:09:54,009 - Epoch: [108][  180/  267]    Overall Loss 2.372330    Objective Loss 2.372330                                        LR 0.100000    Time 0.260903    
2024-04-23 18:09:55,967 - Epoch: [108][  190/  267]    Overall Loss 2.374928    Objective Loss 2.374928                                        LR 0.100000    Time 0.257457    
2024-04-23 18:09:58,898 - Epoch: [108][  200/  267]    Overall Loss 2.373344    Objective Loss 2.373344                                        LR 0.100000    Time 0.259223    
2024-04-23 18:10:01,470 - Epoch: [108][  210/  267]    Overall Loss 2.372102    Objective Loss 2.372102                                        LR 0.100000    Time 0.259111    
2024-04-23 18:10:03,658 - Epoch: [108][  220/  267]    Overall Loss 2.371642    Objective Loss 2.371642                                        LR 0.100000    Time 0.257262    
2024-04-23 18:10:05,786 - Epoch: [108][  230/  267]    Overall Loss 2.373435    Objective Loss 2.373435                                        LR 0.100000    Time 0.255313    
2024-04-23 18:10:08,409 - Epoch: [108][  240/  267]    Overall Loss 2.373919    Objective Loss 2.373919                                        LR 0.100000    Time 0.255593    
2024-04-23 18:10:08,877 - Epoch: [80][  296/  296]    Overall Loss 0.872698    Objective Loss 0.872698    Top1 73.770492    Top5 98.360656    LR 0.000320    Time 0.257265    
2024-04-23 18:10:09,278 - --- validate (epoch=80)-----------
2024-04-23 18:10:09,279 - 3925 samples (32 per mini-batch)
2024-04-23 18:10:10,870 - Epoch: [108][  250/  267]    Overall Loss 2.373764    Objective Loss 2.373764                                        LR 0.100000    Time 0.255203    
2024-04-23 18:10:12,852 - Epoch: [108][  260/  267]    Overall Loss 2.374441    Objective Loss 2.374441                                        LR 0.100000    Time 0.252996    
2024-04-23 18:10:14,388 - Epoch: [108][  267/  267]    Overall Loss 2.374667    Objective Loss 2.374667    Top1 16.279070    Top5 46.511628    LR 0.100000    Time 0.252107    
2024-04-23 18:10:14,681 - --- validate (epoch=108)-----------
2024-04-23 18:10:14,682 - 946 samples (32 per mini-batch)
2024-04-23 18:10:19,223 - Epoch: [108][   10/   30]    Loss 2.343813    Top1 9.375000    Top5 49.062500    
2024-04-23 18:10:21,352 - Epoch: [108][   20/   30]    Loss 2.346218    Top1 8.906250    Top5 49.687500    
2024-04-23 18:10:23,275 - Epoch: [108][   30/   30]    Loss 2.344601    Top1 9.830867    Top5 49.894292    
2024-04-23 18:10:23,487 - ==> Top1: 9.831    Top5: 49.894    Loss: 2.345

2024-04-23 18:10:23,489 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 18:10:23,493 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:10:23,494 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:10:23,509 - 

2024-04-23 18:10:23,509 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:10:27,574 - Epoch: [109][   10/  267]    Overall Loss 2.389578    Objective Loss 2.389578                                        LR 0.100000    Time 0.406093    
2024-04-23 18:10:29,800 - Epoch: [109][   20/  267]    Overall Loss 2.376667    Objective Loss 2.376667                                        LR 0.100000    Time 0.314152    
2024-04-23 18:10:32,262 - Epoch: [109][   30/  267]    Overall Loss 2.367513    Objective Loss 2.367513                                        LR 0.100000    Time 0.291402    
2024-04-23 18:10:34,928 - Epoch: [109][   40/  267]    Overall Loss 2.360502    Objective Loss 2.360502                                        LR 0.100000    Time 0.285143    
2024-04-23 18:10:37,283 - Epoch: [80][  100/  123]    Loss 0.816032    Top1 72.968750    Top5 96.406250    
2024-04-23 18:10:38,722 - Epoch: [109][   50/  267]    Overall Loss 2.357861    Objective Loss 2.357861                                        LR 0.100000    Time 0.303922    
2024-04-23 18:10:41,221 - Epoch: [109][   60/  267]    Overall Loss 2.366399    Objective Loss 2.366399                                        LR 0.100000    Time 0.294866    
2024-04-23 18:10:44,420 - Epoch: [80][  123/  123]    Loss 0.809052    Top1 72.917197    Top5 96.560510    
2024-04-23 18:10:44,647 - Epoch: [109][   70/  267]    Overall Loss 2.362474    Objective Loss 2.362474                                        LR 0.100000    Time 0.301639    
2024-04-23 18:10:44,757 - ==> Top1: 72.917    Top5: 96.561    Loss: 0.809

2024-04-23 18:10:44,768 - ==> Best [Top1: 75.694   Top5: 96.586   Sparsity:0.00   Params: 376752 on epoch: 79]
2024-04-23 18:10:44,769 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:10:44,826 - 

2024-04-23 18:10:44,827 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:10:46,719 - Epoch: [109][   80/  267]    Overall Loss 2.361339    Objective Loss 2.361339                                        LR 0.100000    Time 0.289802    
2024-04-23 18:10:48,744 - Epoch: [109][   90/  267]    Overall Loss 2.363782    Objective Loss 2.363782                                        LR 0.100000    Time 0.280069    
2024-04-23 18:10:49,825 - Epoch: [109][  100/  267]    Overall Loss 2.362640    Objective Loss 2.362640                                        LR 0.100000    Time 0.262840    
2024-04-23 18:10:50,900 - Epoch: [109][  110/  267]    Overall Loss 2.362690    Objective Loss 2.362690                                        LR 0.100000    Time 0.248695    
2024-04-23 18:10:51,875 - Epoch: [109][  120/  267]    Overall Loss 2.361019    Objective Loss 2.361019                                        LR 0.100000    Time 0.236077    
2024-04-23 18:10:53,622 - Epoch: [109][  130/  267]    Overall Loss 2.361525    Objective Loss 2.361525                                        LR 0.100000    Time 0.231333    
2024-04-23 18:10:55,179 - Epoch: [109][  140/  267]    Overall Loss 2.361838    Objective Loss 2.361838                                        LR 0.100000    Time 0.225902    
2024-04-23 18:10:57,234 - Epoch: [109][  150/  267]    Overall Loss 2.363000    Objective Loss 2.363000                                        LR 0.100000    Time 0.224521    
2024-04-23 18:10:59,114 - Epoch: [109][  160/  267]    Overall Loss 2.362764    Objective Loss 2.362764                                        LR 0.100000    Time 0.222214    
2024-04-23 18:11:01,916 - Epoch: [109][  170/  267]    Overall Loss 2.362654    Objective Loss 2.362654                                        LR 0.100000    Time 0.225608    
2024-04-23 18:11:04,047 - Epoch: [109][  180/  267]    Overall Loss 2.362535    Objective Loss 2.362535                                        LR 0.100000    Time 0.224898    
2024-04-23 18:11:07,484 - Epoch: [109][  190/  267]    Overall Loss 2.362619    Objective Loss 2.362619                                        LR 0.100000    Time 0.231135    
2024-04-23 18:11:09,954 - Epoch: [109][  200/  267]    Overall Loss 2.362486    Objective Loss 2.362486                                        LR 0.100000    Time 0.231911    
2024-04-23 18:11:10,221 - Epoch: [81][  100/  296]    Overall Loss 0.888526    Objective Loss 0.888526                                        LR 0.000320    Time 0.253714    
2024-04-23 18:11:13,296 - Epoch: [109][  210/  267]    Overall Loss 2.363494    Objective Loss 2.363494                                        LR 0.100000    Time 0.236764    
2024-04-23 18:11:15,520 - Epoch: [109][  220/  267]    Overall Loss 2.363447    Objective Loss 2.363447                                        LR 0.100000    Time 0.236095    
2024-04-23 18:11:17,886 - Epoch: [109][  230/  267]    Overall Loss 2.363774    Objective Loss 2.363774                                        LR 0.100000    Time 0.236101    
2024-04-23 18:11:19,781 - Epoch: [109][  240/  267]    Overall Loss 2.364918    Objective Loss 2.364918                                        LR 0.100000    Time 0.234145    
2024-04-23 18:11:22,747 - Epoch: [109][  250/  267]    Overall Loss 2.366040    Objective Loss 2.366040                                        LR 0.100000    Time 0.236631    
2024-04-23 18:11:24,655 - Epoch: [109][  260/  267]    Overall Loss 2.367353    Objective Loss 2.367353                                        LR 0.100000    Time 0.234857    
2024-04-23 18:11:25,780 - Epoch: [109][  267/  267]    Overall Loss 2.367945    Objective Loss 2.367945    Top1 6.976744    Top5 48.837209    LR 0.100000    Time 0.232907    
2024-04-23 18:11:26,014 - --- validate (epoch=109)-----------
2024-04-23 18:11:26,015 - 946 samples (32 per mini-batch)
2024-04-23 18:11:30,049 - Epoch: [109][   10/   30]    Loss 2.346523    Top1 9.687500    Top5 49.062500    
2024-04-23 18:11:31,185 - Epoch: [81][  200/  296]    Overall Loss 0.877890    Objective Loss 0.877890                                        LR 0.000320    Time 0.231573    
2024-04-23 18:11:32,281 - Epoch: [109][   20/   30]    Loss 2.340761    Top1 9.531250    Top5 51.406250    
2024-04-23 18:11:34,888 - Epoch: [109][   30/   30]    Loss 2.346130    Top1 9.196617    Top5 50.634249    
2024-04-23 18:11:35,143 - ==> Top1: 9.197    Top5: 50.634    Loss: 2.346

2024-04-23 18:11:35,145 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 18:11:35,149 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:11:35,150 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:11:35,173 - 

2024-04-23 18:11:35,174 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:11:38,569 - Epoch: [110][   10/  267]    Overall Loss 2.340419    Objective Loss 2.340419                                        LR 0.100000    Time 0.339113    
2024-04-23 18:11:40,502 - Epoch: [110][   20/  267]    Overall Loss 2.356238    Objective Loss 2.356238                                        LR 0.100000    Time 0.266063    
2024-04-23 18:11:43,000 - Epoch: [110][   30/  267]    Overall Loss 2.353669    Objective Loss 2.353669                                        LR 0.100000    Time 0.260514    
2024-04-23 18:11:45,781 - Epoch: [110][   40/  267]    Overall Loss 2.356079    Objective Loss 2.356079                                        LR 0.100000    Time 0.264841    
2024-04-23 18:11:49,060 - Epoch: [110][   50/  267]    Overall Loss 2.376135    Objective Loss 2.376135                                        LR 0.100000    Time 0.277387    
2024-04-23 18:11:51,125 - Epoch: [110][   60/  267]    Overall Loss 2.373108    Objective Loss 2.373108                                        LR 0.100000    Time 0.265514    
2024-04-23 18:11:52,568 - Epoch: [81][  296/  296]    Overall Loss 0.882838    Objective Loss 0.882838    Top1 67.213115    Top5 95.081967    LR 0.000320    Time 0.228638    
2024-04-23 18:11:52,893 - --- validate (epoch=81)-----------
2024-04-23 18:11:52,895 - 3925 samples (32 per mini-batch)
2024-04-23 18:11:54,158 - Epoch: [110][   70/  267]    Overall Loss 2.374055    Objective Loss 2.374055                                        LR 0.100000    Time 0.270869    
2024-04-23 18:11:56,112 - Epoch: [110][   80/  267]    Overall Loss 2.375042    Objective Loss 2.375042                                        LR 0.100000    Time 0.261401    
2024-04-23 18:11:58,606 - Epoch: [110][   90/  267]    Overall Loss 2.376522    Objective Loss 2.376522                                        LR 0.100000    Time 0.260028    
2024-04-23 18:12:00,756 - Epoch: [110][  100/  267]    Overall Loss 2.375423    Objective Loss 2.375423                                        LR 0.100000    Time 0.255498    
2024-04-23 18:12:03,290 - Epoch: [110][  110/  267]    Overall Loss 2.374375    Objective Loss 2.374375                                        LR 0.100000    Time 0.255276    
2024-04-23 18:12:05,387 - Epoch: [110][  120/  267]    Overall Loss 2.372919    Objective Loss 2.372919                                        LR 0.100000    Time 0.251453    
2024-04-23 18:12:07,722 - Epoch: [110][  130/  267]    Overall Loss 2.376020    Objective Loss 2.376020                                        LR 0.100000    Time 0.250049    
2024-04-23 18:12:09,816 - Epoch: [110][  140/  267]    Overall Loss 2.372769    Objective Loss 2.372769                                        LR 0.100000    Time 0.247132    
2024-04-23 18:12:12,591 - Epoch: [110][  150/  267]    Overall Loss 2.370854    Objective Loss 2.370854                                        LR 0.100000    Time 0.249129    
2024-04-23 18:12:14,153 - Epoch: [110][  160/  267]    Overall Loss 2.370499    Objective Loss 2.370499                                        LR 0.100000    Time 0.243304    
2024-04-23 18:12:16,543 - Epoch: [110][  170/  267]    Overall Loss 2.370423    Objective Loss 2.370423                                        LR 0.100000    Time 0.243032    
2024-04-23 18:12:18,351 - Epoch: [81][  100/  123]    Loss 0.750115    Top1 74.750000    Top5 97.062500    
2024-04-23 18:12:18,387 - Epoch: [110][  180/  267]    Overall Loss 2.369543    Objective Loss 2.369543                                        LR 0.100000    Time 0.239753    
2024-04-23 18:12:20,571 - Epoch: [110][  190/  267]    Overall Loss 2.369833    Objective Loss 2.369833                                        LR 0.100000    Time 0.238614    
2024-04-23 18:12:22,825 - Epoch: [110][  200/  267]    Overall Loss 2.369676    Objective Loss 2.369676                                        LR 0.100000    Time 0.237939    
2024-04-23 18:12:23,775 - Epoch: [81][  123/  123]    Loss 0.763399    Top1 74.165605    Top5 97.121019    
2024-04-23 18:12:24,034 - ==> Top1: 74.166    Top5: 97.121    Loss: 0.763

2024-04-23 18:12:24,045 - ==> Best [Top1: 75.694   Top5: 96.586   Sparsity:0.00   Params: 376752 on epoch: 79]
2024-04-23 18:12:24,046 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:12:24,097 - 

2024-04-23 18:12:24,098 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:12:25,321 - Epoch: [110][  210/  267]    Overall Loss 2.369405    Objective Loss 2.369405                                        LR 0.100000    Time 0.238476    
2024-04-23 18:12:27,430 - Epoch: [110][  220/  267]    Overall Loss 2.371008    Objective Loss 2.371008                                        LR 0.100000    Time 0.237209    
2024-04-23 18:12:29,057 - Epoch: [110][  230/  267]    Overall Loss 2.370546    Objective Loss 2.370546                                        LR 0.100000    Time 0.233956    
2024-04-23 18:12:31,383 - Epoch: [110][  240/  267]    Overall Loss 2.369970    Objective Loss 2.369970                                        LR 0.100000    Time 0.233890    
2024-04-23 18:12:33,169 - Epoch: [110][  250/  267]    Overall Loss 2.369504    Objective Loss 2.369504                                        LR 0.100000    Time 0.231666    
2024-04-23 18:12:35,467 - Epoch: [110][  260/  267]    Overall Loss 2.369321    Objective Loss 2.369321                                        LR 0.100000    Time 0.231582    
2024-04-23 18:12:36,401 - Epoch: [110][  267/  267]    Overall Loss 2.368803    Objective Loss 2.368803    Top1 11.627907    Top5 55.813953    LR 0.100000    Time 0.229001    
2024-04-23 18:12:36,660 - --- validate (epoch=110)-----------
2024-04-23 18:12:36,661 - 946 samples (32 per mini-batch)
2024-04-23 18:12:40,566 - Epoch: [110][   10/   30]    Loss 2.365500    Top1 10.000000    Top5 47.187500    
2024-04-23 18:12:42,814 - Epoch: [110][   20/   30]    Loss 2.369675    Top1 8.906250    Top5 49.687500    
2024-04-23 18:12:45,045 - Epoch: [110][   30/   30]    Loss 2.347830    Top1 10.993658    Top5 51.691332    
2024-04-23 18:12:45,308 - ==> Top1: 10.994    Top5: 51.691    Loss: 2.348

2024-04-23 18:12:45,310 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 18:12:45,317 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:12:45,318 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:12:45,340 - 

2024-04-23 18:12:45,342 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:12:49,861 - Epoch: [111][   10/  267]    Overall Loss 2.391525    Objective Loss 2.391525                                        LR 0.100000    Time 0.451532    
2024-04-23 18:12:50,297 - Epoch: [82][  100/  296]    Overall Loss 0.916257    Objective Loss 0.916257                                        LR 0.000320    Time 0.261747    
2024-04-23 18:12:51,822 - Epoch: [111][   20/  267]    Overall Loss 2.380700    Objective Loss 2.380700                                        LR 0.100000    Time 0.323647    
2024-04-23 18:12:54,040 - Epoch: [111][   30/  267]    Overall Loss 2.373065    Objective Loss 2.373065                                        LR 0.100000    Time 0.289615    
2024-04-23 18:12:55,425 - Epoch: [111][   40/  267]    Overall Loss 2.375866    Objective Loss 2.375866                                        LR 0.100000    Time 0.251758    
2024-04-23 18:12:57,933 - Epoch: [111][   50/  267]    Overall Loss 2.375234    Objective Loss 2.375234                                        LR 0.100000    Time 0.251525    
2024-04-23 18:12:59,356 - Epoch: [111][   60/  267]    Overall Loss 2.376036    Objective Loss 2.376036                                        LR 0.100000    Time 0.233282    
2024-04-23 18:13:00,833 - Epoch: [111][   70/  267]    Overall Loss 2.376778    Objective Loss 2.376778                                        LR 0.100000    Time 0.221026    
2024-04-23 18:13:02,281 - Epoch: [111][   80/  267]    Overall Loss 2.376954    Objective Loss 2.376954                                        LR 0.100000    Time 0.211463    
2024-04-23 18:13:04,909 - Epoch: [111][   90/  267]    Overall Loss 2.375993    Objective Loss 2.375993                                        LR 0.100000    Time 0.217143    
2024-04-23 18:13:06,048 - Epoch: [111][  100/  267]    Overall Loss 2.372983    Objective Loss 2.372983                                        LR 0.100000    Time 0.206794    
2024-04-23 18:13:08,419 - Epoch: [111][  110/  267]    Overall Loss 2.372191    Objective Loss 2.372191                                        LR 0.100000    Time 0.209516    
2024-04-23 18:13:10,292 - Epoch: [111][  120/  267]    Overall Loss 2.373789    Objective Loss 2.373789                                        LR 0.100000    Time 0.207637    
2024-04-23 18:13:12,805 - Epoch: [111][  130/  267]    Overall Loss 2.374366    Objective Loss 2.374366                                        LR 0.100000    Time 0.210975    
2024-04-23 18:13:13,490 - Epoch: [82][  200/  296]    Overall Loss 0.890017    Objective Loss 0.890017                                        LR 0.000320    Time 0.246735    
2024-04-23 18:13:14,755 - Epoch: [111][  140/  267]    Overall Loss 2.375245    Objective Loss 2.375245                                        LR 0.100000    Time 0.209810    
2024-04-23 18:13:17,411 - Epoch: [111][  150/  267]    Overall Loss 2.375062    Objective Loss 2.375062                                        LR 0.100000    Time 0.213515    
2024-04-23 18:13:20,023 - Epoch: [111][  160/  267]    Overall Loss 2.375141    Objective Loss 2.375141                                        LR 0.100000    Time 0.216474    
2024-04-23 18:13:22,499 - Epoch: [111][  170/  267]    Overall Loss 2.374704    Objective Loss 2.374704                                        LR 0.100000    Time 0.218284    
2024-04-23 18:13:24,571 - Epoch: [111][  180/  267]    Overall Loss 2.373014    Objective Loss 2.373014                                        LR 0.100000    Time 0.217648    
2024-04-23 18:13:26,610 - Epoch: [111][  190/  267]    Overall Loss 2.370809    Objective Loss 2.370809                                        LR 0.100000    Time 0.216911    
2024-04-23 18:13:28,789 - Epoch: [111][  200/  267]    Overall Loss 2.370142    Objective Loss 2.370142                                        LR 0.100000    Time 0.216944    
2024-04-23 18:13:30,839 - Epoch: [111][  210/  267]    Overall Loss 2.369617    Objective Loss 2.369617                                        LR 0.100000    Time 0.216364    
2024-04-23 18:13:33,681 - Epoch: [111][  220/  267]    Overall Loss 2.369497    Objective Loss 2.369497                                        LR 0.100000    Time 0.219434    
2024-04-23 18:13:35,742 - Epoch: [111][  230/  267]    Overall Loss 2.368240    Objective Loss 2.368240                                        LR 0.100000    Time 0.218838    
2024-04-23 18:13:36,573 - Epoch: [82][  296/  296]    Overall Loss 0.884443    Objective Loss 0.884443    Top1 73.770492    Top5 95.081967    LR 0.000320    Time 0.244618    
2024-04-23 18:13:36,939 - --- validate (epoch=82)-----------
2024-04-23 18:13:36,941 - 3925 samples (32 per mini-batch)
2024-04-23 18:13:38,527 - Epoch: [111][  240/  267]    Overall Loss 2.368331    Objective Loss 2.368331                                        LR 0.100000    Time 0.221312    
2024-04-23 18:13:40,363 - Epoch: [111][  250/  267]    Overall Loss 2.367061    Objective Loss 2.367061                                        LR 0.100000    Time 0.219791    
2024-04-23 18:13:42,642 - Epoch: [111][  260/  267]    Overall Loss 2.368679    Objective Loss 2.368679                                        LR 0.100000    Time 0.220095    
2024-04-23 18:13:43,472 - Epoch: [111][  267/  267]    Overall Loss 2.368670    Objective Loss 2.368670    Top1 16.279070    Top5 58.139535    LR 0.100000    Time 0.217426    
2024-04-23 18:13:43,746 - --- validate (epoch=111)-----------
2024-04-23 18:13:43,747 - 946 samples (32 per mini-batch)
2024-04-23 18:13:47,041 - Epoch: [111][   10/   30]    Loss 2.360097    Top1 13.437500    Top5 51.875000    
2024-04-23 18:13:48,091 - Epoch: [111][   20/   30]    Loss 2.373268    Top1 10.937500    Top5 50.781250    
2024-04-23 18:13:50,090 - Epoch: [111][   30/   30]    Loss 2.375564    Top1 10.359408    Top5 50.951374    
2024-04-23 18:13:50,293 - ==> Top1: 10.359    Top5: 50.951    Loss: 2.376

2024-04-23 18:13:50,296 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 18:13:50,302 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:13:50,303 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:13:50,323 - 

2024-04-23 18:13:50,324 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:13:54,008 - Epoch: [112][   10/  267]    Overall Loss 2.418056    Objective Loss 2.418056                                        LR 0.100000    Time 0.368103    
2024-04-23 18:13:56,185 - Epoch: [112][   20/  267]    Overall Loss 2.386313    Objective Loss 2.386313                                        LR 0.100000    Time 0.292736    
2024-04-23 18:13:59,064 - Epoch: [112][   30/  267]    Overall Loss 2.386881    Objective Loss 2.386881                                        LR 0.100000    Time 0.291008    
2024-04-23 18:14:01,098 - Epoch: [112][   40/  267]    Overall Loss 2.381437    Objective Loss 2.381437                                        LR 0.100000    Time 0.269026    
2024-04-23 18:14:03,738 - Epoch: [112][   50/  267]    Overall Loss 2.375765    Objective Loss 2.375765                                        LR 0.100000    Time 0.267952    
2024-04-23 18:14:04,011 - Epoch: [82][  100/  123]    Loss 0.789196    Top1 74.250000    Top5 96.937500    
2024-04-23 18:14:05,666 - Epoch: [112][   60/  267]    Overall Loss 2.370409    Objective Loss 2.370409                                        LR 0.100000    Time 0.255368    
2024-04-23 18:14:08,610 - Epoch: [112][   70/  267]    Overall Loss 2.372445    Objective Loss 2.372445                                        LR 0.100000    Time 0.260915    
2024-04-23 18:14:10,098 - Epoch: [82][  123/  123]    Loss 0.786083    Top1 74.216561    Top5 97.019108    
2024-04-23 18:14:10,404 - ==> Top1: 74.217    Top5: 97.019    Loss: 0.786

2024-04-23 18:14:10,414 - ==> Best [Top1: 75.694   Top5: 96.586   Sparsity:0.00   Params: 376752 on epoch: 79]
2024-04-23 18:14:10,415 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:14:10,446 - Epoch: [112][   80/  267]    Overall Loss 2.372368    Objective Loss 2.372368                                        LR 0.100000    Time 0.251214    
2024-04-23 18:14:10,497 - 

2024-04-23 18:14:10,498 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:14:13,812 - Epoch: [112][   90/  267]    Overall Loss 2.372031    Objective Loss 2.372031                                        LR 0.100000    Time 0.260672    
2024-04-23 18:14:16,612 - Epoch: [112][  100/  267]    Overall Loss 2.372479    Objective Loss 2.372479                                        LR 0.100000    Time 0.262567    
2024-04-23 18:14:20,376 - Epoch: [112][  110/  267]    Overall Loss 2.370739    Objective Loss 2.370739                                        LR 0.100000    Time 0.272880    
2024-04-23 18:14:22,709 - Epoch: [112][  120/  267]    Overall Loss 2.370067    Objective Loss 2.370067                                        LR 0.100000    Time 0.269558    
2024-04-23 18:14:25,655 - Epoch: [112][  130/  267]    Overall Loss 2.371421    Objective Loss 2.371421                                        LR 0.100000    Time 0.271462    
2024-04-23 18:14:27,923 - Epoch: [112][  140/  267]    Overall Loss 2.371524    Objective Loss 2.371524                                        LR 0.100000    Time 0.268253    
2024-04-23 18:14:30,509 - Epoch: [112][  150/  267]    Overall Loss 2.371525    Objective Loss 2.371525                                        LR 0.100000    Time 0.267589    
2024-04-23 18:14:32,138 - Epoch: [112][  160/  267]    Overall Loss 2.371571    Objective Loss 2.371571                                        LR 0.100000    Time 0.261031    
2024-04-23 18:14:34,903 - Epoch: [112][  170/  267]    Overall Loss 2.371476    Objective Loss 2.371476                                        LR 0.100000    Time 0.261920    
2024-04-23 18:14:36,286 - Epoch: [112][  180/  267]    Overall Loss 2.374088    Objective Loss 2.374088                                        LR 0.100000    Time 0.255039    
2024-04-23 18:14:38,495 - Epoch: [112][  190/  267]    Overall Loss 2.372102    Objective Loss 2.372102                                        LR 0.100000    Time 0.253228    
2024-04-23 18:14:38,567 - Epoch: [83][  100/  296]    Overall Loss 0.865295    Objective Loss 0.865295                                        LR 0.000320    Time 0.280452    
2024-04-23 18:14:40,570 - Epoch: [112][  200/  267]    Overall Loss 2.372119    Objective Loss 2.372119                                        LR 0.100000    Time 0.250927    
2024-04-23 18:14:42,896 - Epoch: [112][  210/  267]    Overall Loss 2.371589    Objective Loss 2.371589                                        LR 0.100000    Time 0.250038    
2024-04-23 18:14:45,084 - Epoch: [112][  220/  267]    Overall Loss 2.372347    Objective Loss 2.372347                                        LR 0.100000    Time 0.248605    
2024-04-23 18:14:47,952 - Epoch: [112][  230/  267]    Overall Loss 2.370754    Objective Loss 2.370754                                        LR 0.100000    Time 0.250253    
2024-04-23 18:14:50,180 - Epoch: [112][  240/  267]    Overall Loss 2.370682    Objective Loss 2.370682                                        LR 0.100000    Time 0.249096    
2024-04-23 18:14:53,124 - Epoch: [112][  250/  267]    Overall Loss 2.370374    Objective Loss 2.370374                                        LR 0.100000    Time 0.250896    
2024-04-23 18:14:55,155 - Epoch: [112][  260/  267]    Overall Loss 2.369626    Objective Loss 2.369626                                        LR 0.100000    Time 0.249045    
2024-04-23 18:14:56,928 - Epoch: [112][  267/  267]    Overall Loss 2.368709    Objective Loss 2.368709    Top1 13.953488    Top5 55.813953    LR 0.100000    Time 0.249148    
2024-04-23 18:14:57,159 - --- validate (epoch=112)-----------
2024-04-23 18:14:57,161 - 946 samples (32 per mini-batch)
2024-04-23 18:15:01,638 - Epoch: [112][   10/   30]    Loss 2.347505    Top1 9.375000    Top5 49.062500    
2024-04-23 18:15:04,077 - Epoch: [83][  200/  296]    Overall Loss 0.875580    Objective Loss 0.875580                                        LR 0.000320    Time 0.267672    
2024-04-23 18:15:04,388 - Epoch: [112][   20/   30]    Loss 2.345418    Top1 9.375000    Top5 50.156250    
2024-04-23 18:15:07,269 - Epoch: [112][   30/   30]    Loss 2.343351    Top1 9.196617    Top5 50.951374    
2024-04-23 18:15:07,526 - ==> Top1: 9.197    Top5: 50.951    Loss: 2.343

2024-04-23 18:15:07,528 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 18:15:07,537 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:15:07,538 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:15:07,559 - 

2024-04-23 18:15:07,560 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:15:10,936 - Epoch: [113][   10/  267]    Overall Loss 2.358268    Objective Loss 2.358268                                        LR 0.100000    Time 0.336993    
2024-04-23 18:15:13,443 - Epoch: [113][   20/  267]    Overall Loss 2.377575    Objective Loss 2.377575                                        LR 0.100000    Time 0.293683    
2024-04-23 18:15:16,016 - Epoch: [113][   30/  267]    Overall Loss 2.374347    Objective Loss 2.374347                                        LR 0.100000    Time 0.281433    
2024-04-23 18:15:18,165 - Epoch: [113][   40/  267]    Overall Loss 2.373498    Objective Loss 2.373498                                        LR 0.100000    Time 0.264737    
2024-04-23 18:15:20,713 - Epoch: [113][   50/  267]    Overall Loss 2.377573    Objective Loss 2.377573                                        LR 0.100000    Time 0.262678    
2024-04-23 18:15:22,184 - Epoch: [113][   60/  267]    Overall Loss 2.376513    Objective Loss 2.376513                                        LR 0.100000    Time 0.243372    
2024-04-23 18:15:24,530 - Epoch: [113][   70/  267]    Overall Loss 2.373131    Objective Loss 2.373131                                        LR 0.100000    Time 0.242082    
2024-04-23 18:15:26,361 - Epoch: [83][  296/  296]    Overall Loss 0.865554    Objective Loss 0.865554    Top1 80.327869    Top5 96.721311    LR 0.000320    Time 0.256070    
2024-04-23 18:15:26,776 - --- validate (epoch=83)-----------
2024-04-23 18:15:26,778 - 3925 samples (32 per mini-batch)
2024-04-23 18:15:26,888 - Epoch: [113][   80/  267]    Overall Loss 2.368255    Objective Loss 2.368255                                        LR 0.100000    Time 0.241251    
2024-04-23 18:15:30,295 - Epoch: [113][   90/  267]    Overall Loss 2.369640    Objective Loss 2.369640                                        LR 0.100000    Time 0.252265    
2024-04-23 18:15:33,307 - Epoch: [113][  100/  267]    Overall Loss 2.369741    Objective Loss 2.369741                                        LR 0.100000    Time 0.257131    
2024-04-23 18:15:37,217 - Epoch: [113][  110/  267]    Overall Loss 2.369626    Objective Loss 2.369626                                        LR 0.100000    Time 0.269265    
2024-04-23 18:15:39,876 - Epoch: [113][  120/  267]    Overall Loss 2.366333    Objective Loss 2.366333                                        LR 0.100000    Time 0.268950    
2024-04-23 18:15:44,083 - Epoch: [113][  130/  267]    Overall Loss 2.364214    Objective Loss 2.364214                                        LR 0.100000    Time 0.280595    
2024-04-23 18:15:46,886 - Epoch: [113][  140/  267]    Overall Loss 2.364643    Objective Loss 2.364643                                        LR 0.100000    Time 0.280548    
2024-04-23 18:15:50,324 - Epoch: [113][  150/  267]    Overall Loss 2.362519    Objective Loss 2.362519                                        LR 0.100000    Time 0.284746    
2024-04-23 18:15:52,491 - Epoch: [113][  160/  267]    Overall Loss 2.361863    Objective Loss 2.361863                                        LR 0.100000    Time 0.280471    
2024-04-23 18:15:55,511 - Epoch: [113][  170/  267]    Overall Loss 2.362836    Objective Loss 2.362836                                        LR 0.100000    Time 0.281721    
2024-04-23 18:15:57,819 - Epoch: [113][  180/  267]    Overall Loss 2.362525    Objective Loss 2.362525                                        LR 0.100000    Time 0.278872    
2024-04-23 18:15:59,711 - Epoch: [83][  100/  123]    Loss 0.743946    Top1 75.062500    Top5 97.062500    
2024-04-23 18:16:00,864 - Epoch: [113][  190/  267]    Overall Loss 2.361802    Objective Loss 2.361802                                        LR 0.100000    Time 0.280204    
2024-04-23 18:16:03,251 - Epoch: [113][  200/  267]    Overall Loss 2.362837    Objective Loss 2.362837                                        LR 0.100000    Time 0.278114    
2024-04-23 18:16:05,699 - Epoch: [83][  123/  123]    Loss 0.759213    Top1 74.573248    Top5 96.917197    
2024-04-23 18:16:05,933 - Epoch: [113][  210/  267]    Overall Loss 2.363930    Objective Loss 2.363930                                        LR 0.100000    Time 0.277625    
2024-04-23 18:16:06,006 - ==> Top1: 74.573    Top5: 96.917    Loss: 0.759

2024-04-23 18:16:06,014 - ==> Best [Top1: 75.694   Top5: 96.586   Sparsity:0.00   Params: 376752 on epoch: 79]
2024-04-23 18:16:06,015 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:16:06,079 - 

2024-04-23 18:16:06,081 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:16:07,598 - Epoch: [113][  220/  267]    Overall Loss 2.364095    Objective Loss 2.364095                                        LR 0.100000    Time 0.272563    
2024-04-23 18:16:10,376 - Epoch: [113][  230/  267]    Overall Loss 2.364082    Objective Loss 2.364082                                        LR 0.100000    Time 0.272779    
2024-04-23 18:16:12,668 - Epoch: [113][  240/  267]    Overall Loss 2.366281    Objective Loss 2.366281                                        LR 0.100000    Time 0.270952    
2024-04-23 18:16:15,872 - Epoch: [113][  250/  267]    Overall Loss 2.367411    Objective Loss 2.367411                                        LR 0.100000    Time 0.272915    
2024-04-23 18:16:17,782 - Epoch: [113][  260/  267]    Overall Loss 2.366601    Objective Loss 2.366601                                        LR 0.100000    Time 0.269753    
2024-04-23 18:16:18,718 - Epoch: [113][  267/  267]    Overall Loss 2.365633    Objective Loss 2.365633    Top1 16.279070    Top5 62.790698    LR 0.100000    Time 0.266180    
2024-04-23 18:16:18,914 - --- validate (epoch=113)-----------
2024-04-23 18:16:18,915 - 946 samples (32 per mini-batch)
2024-04-23 18:16:22,297 - Epoch: [113][   10/   30]    Loss 2.414835    Top1 9.687500    Top5 46.250000    
2024-04-23 18:16:24,027 - Epoch: [113][   20/   30]    Loss 2.382645    Top1 9.062500    Top5 51.875000    
2024-04-23 18:16:25,511 - Epoch: [113][   30/   30]    Loss 2.397650    Top1 8.456660    Top5 50.211416    
2024-04-23 18:16:25,764 - ==> Top1: 8.457    Top5: 50.211    Loss: 2.398

2024-04-23 18:16:25,766 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 18:16:25,771 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:16:25,772 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:16:25,787 - 

2024-04-23 18:16:25,788 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:16:25,976 - Epoch: [84][  100/  296]    Overall Loss 0.886213    Objective Loss 0.886213                                        LR 0.000320    Time 0.198742    
2024-04-23 18:16:28,681 - Epoch: [114][   10/  267]    Overall Loss 2.335155    Objective Loss 2.335155                                        LR 0.100000    Time 0.288910    
2024-04-23 18:16:30,552 - Epoch: [114][   20/  267]    Overall Loss 2.348149    Objective Loss 2.348149                                        LR 0.100000    Time 0.237871    
2024-04-23 18:16:32,617 - Epoch: [114][   30/  267]    Overall Loss 2.347565    Objective Loss 2.347565                                        LR 0.100000    Time 0.227288    
2024-04-23 18:16:34,939 - Epoch: [114][   40/  267]    Overall Loss 2.354922    Objective Loss 2.354922                                        LR 0.100000    Time 0.228465    
2024-04-23 18:16:36,170 - Epoch: [114][   50/  267]    Overall Loss 2.355454    Objective Loss 2.355454                                        LR 0.100000    Time 0.207330    
2024-04-23 18:16:38,674 - Epoch: [114][   60/  267]    Overall Loss 2.366176    Objective Loss 2.366176                                        LR 0.100000    Time 0.214461    
2024-04-23 18:16:40,415 - Epoch: [114][   70/  267]    Overall Loss 2.363998    Objective Loss 2.363998                                        LR 0.100000    Time 0.208646    
2024-04-23 18:16:42,968 - Epoch: [114][   80/  267]    Overall Loss 2.364984    Objective Loss 2.364984                                        LR 0.100000    Time 0.214447    
2024-04-23 18:16:45,037 - Epoch: [114][   90/  267]    Overall Loss 2.364152    Objective Loss 2.364152                                        LR 0.100000    Time 0.213576    
2024-04-23 18:16:45,971 - Epoch: [84][  200/  296]    Overall Loss 0.866558    Objective Loss 0.866558                                        LR 0.000320    Time 0.199242    
2024-04-23 18:16:47,375 - Epoch: [114][  100/  267]    Overall Loss 2.365698    Objective Loss 2.365698                                        LR 0.100000    Time 0.215564    
2024-04-23 18:16:49,349 - Epoch: [114][  110/  267]    Overall Loss 2.366590    Objective Loss 2.366590                                        LR 0.100000    Time 0.213863    
2024-04-23 18:16:51,665 - Epoch: [114][  120/  267]    Overall Loss 2.367165    Objective Loss 2.367165                                        LR 0.100000    Time 0.215317    
2024-04-23 18:16:53,359 - Epoch: [114][  130/  267]    Overall Loss 2.364753    Objective Loss 2.364753                                        LR 0.100000    Time 0.211768    
2024-04-23 18:16:55,743 - Epoch: [114][  140/  267]    Overall Loss 2.365135    Objective Loss 2.365135                                        LR 0.100000    Time 0.213650    
2024-04-23 18:16:57,483 - Epoch: [114][  150/  267]    Overall Loss 2.367159    Objective Loss 2.367159                                        LR 0.100000    Time 0.210989    
2024-04-23 18:17:00,054 - Epoch: [114][  160/  267]    Overall Loss 2.368531    Objective Loss 2.368531                                        LR 0.100000    Time 0.213848    
2024-04-23 18:17:02,008 - Epoch: [114][  170/  267]    Overall Loss 2.369271    Objective Loss 2.369271                                        LR 0.100000    Time 0.212749    
2024-04-23 18:17:05,652 - Epoch: [114][  180/  267]    Overall Loss 2.367447    Objective Loss 2.367447                                        LR 0.100000    Time 0.221154    
2024-04-23 18:17:07,194 - Epoch: [84][  296/  296]    Overall Loss 0.866793    Objective Loss 0.866793    Top1 78.688525    Top5 98.360656    LR 0.000320    Time 0.206250    
2024-04-23 18:17:07,472 - --- validate (epoch=84)-----------
2024-04-23 18:17:07,473 - 3925 samples (32 per mini-batch)
2024-04-23 18:17:07,530 - Epoch: [114][  190/  267]    Overall Loss 2.370256    Objective Loss 2.370256                                        LR 0.100000    Time 0.219380    
2024-04-23 18:17:10,234 - Epoch: [114][  200/  267]    Overall Loss 2.370005    Objective Loss 2.370005                                        LR 0.100000    Time 0.221920    
2024-04-23 18:17:12,087 - Epoch: [114][  210/  267]    Overall Loss 2.371171    Objective Loss 2.371171                                        LR 0.100000    Time 0.220158    
2024-04-23 18:17:14,853 - Epoch: [114][  220/  267]    Overall Loss 2.370927    Objective Loss 2.370927                                        LR 0.100000    Time 0.222710    
2024-04-23 18:17:16,624 - Epoch: [114][  230/  267]    Overall Loss 2.371460    Objective Loss 2.371460                                        LR 0.100000    Time 0.220719    
2024-04-23 18:17:19,955 - Epoch: [114][  240/  267]    Overall Loss 2.371409    Objective Loss 2.371409                                        LR 0.100000    Time 0.225389    
2024-04-23 18:17:22,112 - Epoch: [114][  250/  267]    Overall Loss 2.370289    Objective Loss 2.370289                                        LR 0.100000    Time 0.224991    
2024-04-23 18:17:24,668 - Epoch: [114][  260/  267]    Overall Loss 2.371790    Objective Loss 2.371790                                        LR 0.100000    Time 0.226154    
2024-04-23 18:17:25,856 - Epoch: [114][  267/  267]    Overall Loss 2.371237    Objective Loss 2.371237    Top1 11.627907    Top5 48.837209    LR 0.100000    Time 0.224663    
2024-04-23 18:17:26,064 - --- validate (epoch=114)-----------
2024-04-23 18:17:26,065 - 946 samples (32 per mini-batch)
2024-04-23 18:17:30,644 - Epoch: [114][   10/   30]    Loss 2.359131    Top1 8.437500    Top5 51.250000    
2024-04-23 18:17:33,351 - Epoch: [114][   20/   30]    Loss 2.381140    Top1 8.750000    Top5 47.968750    
2024-04-23 18:17:33,785 - Epoch: [84][  100/  123]    Loss 0.761982    Top1 74.656250    Top5 96.656250    
2024-04-23 18:17:36,461 - Epoch: [114][   30/   30]    Loss 2.359398    Top1 10.570825    Top5 49.682875    
2024-04-23 18:17:36,716 - ==> Top1: 10.571    Top5: 49.683    Loss: 2.359

2024-04-23 18:17:36,719 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 18:17:36,725 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:17:36,727 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:17:36,750 - 

2024-04-23 18:17:36,751 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:17:40,878 - Epoch: [84][  123/  123]    Loss 0.764805    Top1 74.853503    Top5 96.509554    
2024-04-23 18:17:41,200 - ==> Top1: 74.854    Top5: 96.510    Loss: 0.765

2024-04-23 18:17:41,215 - ==> Best [Top1: 75.694   Top5: 96.586   Sparsity:0.00   Params: 376752 on epoch: 79]
2024-04-23 18:17:41,216 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:17:41,313 - 

2024-04-23 18:17:41,315 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:17:41,422 - Epoch: [115][   10/  267]    Overall Loss 2.385322    Objective Loss 2.385322                                        LR 0.100000    Time 0.466569    
2024-04-23 18:17:43,759 - Epoch: [115][   20/  267]    Overall Loss 2.389623    Objective Loss 2.389623                                        LR 0.100000    Time 0.349974    
2024-04-23 18:17:47,170 - Epoch: [115][   30/  267]    Overall Loss 2.385504    Objective Loss 2.385504                                        LR 0.100000    Time 0.346903    
2024-04-23 18:17:50,067 - Epoch: [115][   40/  267]    Overall Loss 2.392511    Objective Loss 2.392511                                        LR 0.100000    Time 0.332543    
2024-04-23 18:17:52,857 - Epoch: [115][   50/  267]    Overall Loss 2.391190    Objective Loss 2.391190                                        LR 0.100000    Time 0.321774    
2024-04-23 18:17:55,217 - Epoch: [115][   60/  267]    Overall Loss 2.391118    Objective Loss 2.391118                                        LR 0.100000    Time 0.307434    
2024-04-23 18:17:57,455 - Epoch: [115][   70/  267]    Overall Loss 2.386642    Objective Loss 2.386642                                        LR 0.100000    Time 0.295439    
2024-04-23 18:18:00,159 - Epoch: [115][   80/  267]    Overall Loss 2.386297    Objective Loss 2.386297                                        LR 0.100000    Time 0.292264    
2024-04-23 18:18:03,209 - Epoch: [115][   90/  267]    Overall Loss 2.390398    Objective Loss 2.390398                                        LR 0.100000    Time 0.293638    
2024-04-23 18:18:05,621 - Epoch: [115][  100/  267]    Overall Loss 2.388262    Objective Loss 2.388262                                        LR 0.100000    Time 0.288363    
2024-04-23 18:18:08,941 - Epoch: [115][  110/  267]    Overall Loss 2.386686    Objective Loss 2.386686                                        LR 0.100000    Time 0.292295    
2024-04-23 18:18:09,732 - Epoch: [85][  100/  296]    Overall Loss 0.850547    Objective Loss 0.850547                                        LR 0.000320    Time 0.283918    
2024-04-23 18:18:10,970 - Epoch: [115][  120/  267]    Overall Loss 2.383025    Objective Loss 2.383025                                        LR 0.100000    Time 0.284829    
2024-04-23 18:18:13,636 - Epoch: [115][  130/  267]    Overall Loss 2.384364    Objective Loss 2.384364                                        LR 0.100000    Time 0.283399    
2024-04-23 18:18:16,038 - Epoch: [115][  140/  267]    Overall Loss 2.382234    Objective Loss 2.382234                                        LR 0.100000    Time 0.280284    
2024-04-23 18:18:19,470 - Epoch: [115][  150/  267]    Overall Loss 2.380138    Objective Loss 2.380138                                        LR 0.100000    Time 0.284453    
2024-04-23 18:18:21,634 - Epoch: [115][  160/  267]    Overall Loss 2.378645    Objective Loss 2.378645                                        LR 0.100000    Time 0.280180    
2024-04-23 18:18:24,658 - Epoch: [115][  170/  267]    Overall Loss 2.377419    Objective Loss 2.377419                                        LR 0.100000    Time 0.281467    
2024-04-23 18:18:26,612 - Epoch: [115][  180/  267]    Overall Loss 2.375298    Objective Loss 2.375298                                        LR 0.100000    Time 0.276671    
2024-04-23 18:18:29,586 - Epoch: [115][  190/  267]    Overall Loss 2.376069    Objective Loss 2.376069                                        LR 0.100000    Time 0.277742    
2024-04-23 18:18:31,880 - Epoch: [115][  200/  267]    Overall Loss 2.373720    Objective Loss 2.373720                                        LR 0.100000    Time 0.275311    
2024-04-23 18:18:35,015 - Epoch: [115][  210/  267]    Overall Loss 2.372759    Objective Loss 2.372759                                        LR 0.100000    Time 0.277115    
2024-04-23 18:18:35,549 - Epoch: [85][  200/  296]    Overall Loss 0.858014    Objective Loss 0.858014                                        LR 0.000320    Time 0.270939    
2024-04-23 18:18:37,397 - Epoch: [115][  220/  267]    Overall Loss 2.372998    Objective Loss 2.372998                                        LR 0.100000    Time 0.275335    
2024-04-23 18:18:40,069 - Epoch: [115][  230/  267]    Overall Loss 2.372588    Objective Loss 2.372588                                        LR 0.100000    Time 0.274968    
2024-04-23 18:18:42,530 - Epoch: [115][  240/  267]    Overall Loss 2.372117    Objective Loss 2.372117                                        LR 0.100000    Time 0.273749    
2024-04-23 18:18:45,682 - Epoch: [115][  250/  267]    Overall Loss 2.372271    Objective Loss 2.372271                                        LR 0.100000    Time 0.275398    
2024-04-23 18:18:47,831 - Epoch: [115][  260/  267]    Overall Loss 2.371636    Objective Loss 2.371636                                        LR 0.100000    Time 0.273058    
2024-04-23 18:18:49,559 - Epoch: [115][  267/  267]    Overall Loss 2.371251    Objective Loss 2.371251    Top1 9.302326    Top5 46.511628    LR 0.100000    Time 0.272360    
2024-04-23 18:18:49,831 - --- validate (epoch=115)-----------
2024-04-23 18:18:49,832 - 946 samples (32 per mini-batch)
2024-04-23 18:18:53,926 - Epoch: [115][   10/   30]    Loss 2.320682    Top1 8.125000    Top5 52.500000    
2024-04-23 18:18:56,194 - Epoch: [115][   20/   30]    Loss 2.322806    Top1 9.687500    Top5 50.781250    
2024-04-23 18:18:59,080 - Epoch: [115][   30/   30]    Loss 2.318464    Top1 9.830867    Top5 51.902748    
2024-04-23 18:18:59,280 - ==> Top1: 9.831    Top5: 51.903    Loss: 2.318

2024-04-23 18:18:59,281 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 18:18:59,284 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:18:59,285 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:18:59,294 - Epoch: [85][  296/  296]    Overall Loss 0.866567    Objective Loss 0.866567    Top1 75.409836    Top5 95.081967    LR 0.000320    Time 0.263202    
2024-04-23 18:18:59,298 - 

2024-04-23 18:18:59,298 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:18:59,511 - --- validate (epoch=85)-----------
2024-04-23 18:18:59,512 - 3925 samples (32 per mini-batch)
2024-04-23 18:19:02,841 - Epoch: [116][   10/  267]    Overall Loss 2.367614    Objective Loss 2.367614                                        LR 0.100000    Time 0.353954    
2024-04-23 18:19:05,201 - Epoch: [116][   20/  267]    Overall Loss 2.376270    Objective Loss 2.376270                                        LR 0.100000    Time 0.294804    
2024-04-23 18:19:07,793 - Epoch: [116][   30/  267]    Overall Loss 2.371313    Objective Loss 2.371313                                        LR 0.100000    Time 0.282813    
2024-04-23 18:19:10,397 - Epoch: [116][   40/  267]    Overall Loss 2.370638    Objective Loss 2.370638                                        LR 0.100000    Time 0.277102    
2024-04-23 18:19:13,015 - Epoch: [116][   50/  267]    Overall Loss 2.368274    Objective Loss 2.368274                                        LR 0.100000    Time 0.273958    
2024-04-23 18:19:15,310 - Epoch: [116][   60/  267]    Overall Loss 2.366486    Objective Loss 2.366486                                        LR 0.100000    Time 0.266492    
2024-04-23 18:19:18,419 - Epoch: [116][   70/  267]    Overall Loss 2.364511    Objective Loss 2.364511                                        LR 0.100000    Time 0.272788    
2024-04-23 18:19:20,255 - Epoch: [116][   80/  267]    Overall Loss 2.363685    Objective Loss 2.363685                                        LR 0.100000    Time 0.261596    
2024-04-23 18:19:22,890 - Epoch: [116][   90/  267]    Overall Loss 2.369562    Objective Loss 2.369562                                        LR 0.100000    Time 0.261768    
2024-04-23 18:19:25,095 - Epoch: [116][  100/  267]    Overall Loss 2.368943    Objective Loss 2.368943                                        LR 0.100000    Time 0.257617    
2024-04-23 18:19:26,132 - Epoch: [85][  100/  123]    Loss 0.785401    Top1 73.968750    Top5 96.906250    
2024-04-23 18:19:28,264 - Epoch: [116][  110/  267]    Overall Loss 2.369529    Objective Loss 2.369529                                        LR 0.100000    Time 0.262976    
2024-04-23 18:19:30,240 - Epoch: [116][  120/  267]    Overall Loss 2.369837    Objective Loss 2.369837                                        LR 0.100000    Time 0.257504    
2024-04-23 18:19:31,782 - Epoch: [85][  123/  123]    Loss 0.782967    Top1 74.089172    Top5 96.815287    
2024-04-23 18:19:32,010 - ==> Top1: 74.089    Top5: 96.815    Loss: 0.783

2024-04-23 18:19:32,020 - ==> Best [Top1: 75.694   Top5: 96.586   Sparsity:0.00   Params: 376752 on epoch: 79]
2024-04-23 18:19:32,021 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:19:32,073 - 

2024-04-23 18:19:32,074 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:19:32,669 - Epoch: [116][  130/  267]    Overall Loss 2.370034    Objective Loss 2.370034                                        LR 0.100000    Time 0.256353    
2024-04-23 18:19:34,392 - Epoch: [116][  140/  267]    Overall Loss 2.370560    Objective Loss 2.370560                                        LR 0.100000    Time 0.250328    
2024-04-23 18:19:37,296 - Epoch: [116][  150/  267]    Overall Loss 2.368175    Objective Loss 2.368175                                        LR 0.100000    Time 0.252976    
2024-04-23 18:19:39,262 - Epoch: [116][  160/  267]    Overall Loss 2.365908    Objective Loss 2.365908                                        LR 0.100000    Time 0.249438    
2024-04-23 18:19:42,129 - Epoch: [116][  170/  267]    Overall Loss 2.366761    Objective Loss 2.366761                                        LR 0.100000    Time 0.251610    
2024-04-23 18:19:44,220 - Epoch: [116][  180/  267]    Overall Loss 2.367946    Objective Loss 2.367946                                        LR 0.100000    Time 0.249229    
2024-04-23 18:19:46,925 - Epoch: [116][  190/  267]    Overall Loss 2.364586    Objective Loss 2.364586                                        LR 0.100000    Time 0.250335    
2024-04-23 18:19:48,900 - Epoch: [116][  200/  267]    Overall Loss 2.364424    Objective Loss 2.364424                                        LR 0.100000    Time 0.247680    
2024-04-23 18:19:51,164 - Epoch: [116][  210/  267]    Overall Loss 2.365761    Objective Loss 2.365761                                        LR 0.100000    Time 0.246651    
2024-04-23 18:19:53,266 - Epoch: [116][  220/  267]    Overall Loss 2.366135    Objective Loss 2.366135                                        LR 0.100000    Time 0.244980    
2024-04-23 18:19:55,840 - Epoch: [116][  230/  267]    Overall Loss 2.365519    Objective Loss 2.365519                                        LR 0.100000    Time 0.245508    
2024-04-23 18:19:57,907 - Epoch: [86][  100/  296]    Overall Loss 0.865952    Objective Loss 0.865952                                        LR 0.000320    Time 0.258122    
2024-04-23 18:19:58,415 - Epoch: [116][  240/  267]    Overall Loss 2.365007    Objective Loss 2.365007                                        LR 0.100000    Time 0.245992    
2024-04-23 18:20:00,714 - Epoch: [116][  250/  267]    Overall Loss 2.365306    Objective Loss 2.365306                                        LR 0.100000    Time 0.245335    
2024-04-23 18:20:03,522 - Epoch: [116][  260/  267]    Overall Loss 2.366275    Objective Loss 2.366275                                        LR 0.100000    Time 0.246687    
2024-04-23 18:20:04,549 - Epoch: [116][  267/  267]    Overall Loss 2.366638    Objective Loss 2.366638    Top1 9.302326    Top5 53.488372    LR 0.100000    Time 0.244058    
2024-04-23 18:20:04,818 - --- validate (epoch=116)-----------
2024-04-23 18:20:04,820 - 946 samples (32 per mini-batch)
2024-04-23 18:20:08,904 - Epoch: [116][   10/   30]    Loss 2.416480    Top1 10.000000    Top5 45.937500    
2024-04-23 18:20:11,565 - Epoch: [116][   20/   30]    Loss 2.381909    Top1 10.156250    Top5 48.125000    
2024-04-23 18:20:13,766 - Epoch: [116][   30/   30]    Loss 2.372541    Top1 9.830867    Top5 49.365751    
2024-04-23 18:20:13,998 - ==> Top1: 9.831    Top5: 49.366    Loss: 2.373

2024-04-23 18:20:14,000 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 18:20:14,004 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:20:14,005 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:20:14,016 - 

2024-04-23 18:20:14,017 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:20:17,463 - Epoch: [117][   10/  267]    Overall Loss 2.334268    Objective Loss 2.334268                                        LR 0.100000    Time 0.344148    
2024-04-23 18:20:20,430 - Epoch: [117][   20/  267]    Overall Loss 2.357044    Objective Loss 2.357044                                        LR 0.100000    Time 0.320254    
2024-04-23 18:20:21,660 - Epoch: [86][  200/  296]    Overall Loss 0.858938    Objective Loss 0.858938                                        LR 0.000320    Time 0.247722    
2024-04-23 18:20:23,201 - Epoch: [117][   30/  267]    Overall Loss 2.355521    Objective Loss 2.355521                                        LR 0.100000    Time 0.305730    
2024-04-23 18:20:25,967 - Epoch: [117][   40/  267]    Overall Loss 2.355583    Objective Loss 2.355583                                        LR 0.100000    Time 0.298379    
2024-04-23 18:20:29,227 - Epoch: [117][   50/  267]    Overall Loss 2.363259    Objective Loss 2.363259                                        LR 0.100000    Time 0.303843    
2024-04-23 18:20:31,999 - Epoch: [117][   60/  267]    Overall Loss 2.365372    Objective Loss 2.365372                                        LR 0.100000    Time 0.299350    
2024-04-23 18:20:35,208 - Epoch: [117][   70/  267]    Overall Loss 2.364267    Objective Loss 2.364267                                        LR 0.100000    Time 0.302385    
2024-04-23 18:20:38,029 - Epoch: [117][   80/  267]    Overall Loss 2.365264    Objective Loss 2.365264                                        LR 0.100000    Time 0.299810    
2024-04-23 18:20:40,741 - Epoch: [117][   90/  267]    Overall Loss 2.364712    Objective Loss 2.364712                                        LR 0.100000    Time 0.296603    
2024-04-23 18:20:43,401 - Epoch: [117][  100/  267]    Overall Loss 2.363232    Objective Loss 2.363232                                        LR 0.100000    Time 0.293508    
2024-04-23 18:20:45,935 - Epoch: [117][  110/  267]    Overall Loss 2.360712    Objective Loss 2.360712                                        LR 0.100000    Time 0.289837    
2024-04-23 18:20:46,783 - Epoch: [86][  296/  296]    Overall Loss 0.853379    Objective Loss 0.853379    Top1 73.770492    Top5 93.442623    LR 0.000320    Time 0.252186    
2024-04-23 18:20:47,091 - --- validate (epoch=86)-----------
2024-04-23 18:20:47,093 - 3925 samples (32 per mini-batch)
2024-04-23 18:20:47,563 - Epoch: [117][  120/  267]    Overall Loss 2.362424    Objective Loss 2.362424                                        LR 0.100000    Time 0.279227    
2024-04-23 18:20:50,373 - Epoch: [117][  130/  267]    Overall Loss 2.361078    Objective Loss 2.361078                                        LR 0.100000    Time 0.279327    
2024-04-23 18:20:52,723 - Epoch: [117][  140/  267]    Overall Loss 2.360364    Objective Loss 2.360364                                        LR 0.100000    Time 0.276135    
2024-04-23 18:20:55,618 - Epoch: [117][  150/  267]    Overall Loss 2.361736    Objective Loss 2.361736                                        LR 0.100000    Time 0.277009    
2024-04-23 18:20:58,080 - Epoch: [117][  160/  267]    Overall Loss 2.360375    Objective Loss 2.360375                                        LR 0.100000    Time 0.275058    
2024-04-23 18:21:00,680 - Epoch: [117][  170/  267]    Overall Loss 2.358318    Objective Loss 2.358318                                        LR 0.100000    Time 0.274158    
2024-04-23 18:21:02,912 - Epoch: [117][  180/  267]    Overall Loss 2.360896    Objective Loss 2.360896                                        LR 0.100000    Time 0.271311    
2024-04-23 18:21:06,067 - Epoch: [117][  190/  267]    Overall Loss 2.360325    Objective Loss 2.360325                                        LR 0.100000    Time 0.273622    
2024-04-23 18:21:08,634 - Epoch: [117][  200/  267]    Overall Loss 2.361204    Objective Loss 2.361204                                        LR 0.100000    Time 0.272757    
2024-04-23 18:21:11,894 - Epoch: [117][  210/  267]    Overall Loss 2.360406    Objective Loss 2.360406                                        LR 0.100000    Time 0.275272    
2024-04-23 18:21:13,920 - Epoch: [117][  220/  267]    Overall Loss 2.362593    Objective Loss 2.362593                                        LR 0.100000    Time 0.271958    
2024-04-23 18:21:17,264 - Epoch: [117][  230/  267]    Overall Loss 2.362714    Objective Loss 2.362714                                        LR 0.100000    Time 0.274657    
2024-04-23 18:21:17,488 - Epoch: [86][  100/  123]    Loss 0.774098    Top1 74.875000    Top5 96.656250    
2024-04-23 18:21:19,344 - Epoch: [117][  240/  267]    Overall Loss 2.361774    Objective Loss 2.361774                                        LR 0.100000    Time 0.271870    
2024-04-23 18:21:21,837 - Epoch: [117][  250/  267]    Overall Loss 2.361452    Objective Loss 2.361452                                        LR 0.100000    Time 0.270953    
2024-04-23 18:21:22,512 - Epoch: [86][  123/  123]    Loss 0.774488    Top1 74.980892    Top5 96.560510    
2024-04-23 18:21:22,653 - ==> Top1: 74.981    Top5: 96.561    Loss: 0.774

2024-04-23 18:21:22,661 - ==> Best [Top1: 75.694   Top5: 96.586   Sparsity:0.00   Params: 376752 on epoch: 79]
2024-04-23 18:21:22,662 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:21:22,705 - 

2024-04-23 18:21:22,706 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:21:23,011 - Epoch: [117][  260/  267]    Overall Loss 2.360843    Objective Loss 2.360843                                        LR 0.100000    Time 0.265042    
2024-04-23 18:21:25,428 - Epoch: [117][  267/  267]    Overall Loss 2.360780    Objective Loss 2.360780    Top1 6.976744    Top5 46.511628    LR 0.100000    Time 0.267138    
2024-04-23 18:21:25,677 - --- validate (epoch=117)-----------
2024-04-23 18:21:25,678 - 946 samples (32 per mini-batch)
2024-04-23 18:21:29,471 - Epoch: [117][   10/   30]    Loss 2.345387    Top1 8.437500    Top5 50.000000    
2024-04-23 18:21:31,713 - Epoch: [117][   20/   30]    Loss 2.332484    Top1 9.687500    Top5 52.031250    
2024-04-23 18:21:34,386 - Epoch: [117][   30/   30]    Loss 2.339737    Top1 9.830867    Top5 51.162791    
2024-04-23 18:21:34,616 - ==> Top1: 9.831    Top5: 51.163    Loss: 2.340

2024-04-23 18:21:34,619 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 18:21:34,624 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:21:34,625 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:21:34,643 - 

2024-04-23 18:21:34,645 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:21:38,596 - Epoch: [118][   10/  267]    Overall Loss 2.346554    Objective Loss 2.346554                                        LR 0.100000    Time 0.394788    
2024-04-23 18:21:40,531 - Epoch: [118][   20/  267]    Overall Loss 2.357876    Objective Loss 2.357876                                        LR 0.100000    Time 0.293977    
2024-04-23 18:21:43,025 - Epoch: [118][   30/  267]    Overall Loss 2.386897    Objective Loss 2.386897                                        LR 0.100000    Time 0.278999    
2024-04-23 18:21:45,248 - Epoch: [118][   40/  267]    Overall Loss 2.385308    Objective Loss 2.385308                                        LR 0.100000    Time 0.264740    
2024-04-23 18:21:45,685 - Epoch: [87][  100/  296]    Overall Loss 0.860471    Objective Loss 0.860471                                        LR 0.000320    Time 0.229569    
2024-04-23 18:21:48,016 - Epoch: [118][   50/  267]    Overall Loss 2.386106    Objective Loss 2.386106                                        LR 0.100000    Time 0.267075    
2024-04-23 18:21:50,451 - Epoch: [118][   60/  267]    Overall Loss 2.387591    Objective Loss 2.387591                                        LR 0.100000    Time 0.263089    
2024-04-23 18:21:52,971 - Epoch: [118][   70/  267]    Overall Loss 2.382160    Objective Loss 2.382160                                        LR 0.100000    Time 0.261379    
2024-04-23 18:21:55,831 - Epoch: [118][   80/  267]    Overall Loss 2.382742    Objective Loss 2.382742                                        LR 0.100000    Time 0.264420    
2024-04-23 18:21:57,942 - Epoch: [118][   90/  267]    Overall Loss 2.381383    Objective Loss 2.381383                                        LR 0.100000    Time 0.258457    
2024-04-23 18:22:00,807 - Epoch: [118][  100/  267]    Overall Loss 2.384597    Objective Loss 2.384597                                        LR 0.100000    Time 0.261237    
2024-04-23 18:22:02,925 - Epoch: [118][  110/  267]    Overall Loss 2.383753    Objective Loss 2.383753                                        LR 0.100000    Time 0.256715    
2024-04-23 18:22:05,761 - Epoch: [118][  120/  267]    Overall Loss 2.379471    Objective Loss 2.379471                                        LR 0.100000    Time 0.258926    
2024-04-23 18:22:07,026 - Epoch: [118][  130/  267]    Overall Loss 2.378935    Objective Loss 2.378935                                        LR 0.100000    Time 0.248728    
2024-04-23 18:22:08,741 - Epoch: [87][  200/  296]    Overall Loss 0.855871    Objective Loss 0.855871                                        LR 0.000320    Time 0.229957    
2024-04-23 18:22:08,985 - Epoch: [118][  140/  267]    Overall Loss 2.381112    Objective Loss 2.381112                                        LR 0.100000    Time 0.244933    
2024-04-23 18:22:10,987 - Epoch: [118][  150/  267]    Overall Loss 2.379053    Objective Loss 2.379053                                        LR 0.100000    Time 0.241933    
2024-04-23 18:22:13,527 - Epoch: [118][  160/  267]    Overall Loss 2.376560    Objective Loss 2.376560                                        LR 0.100000    Time 0.242662    
2024-04-23 18:22:16,337 - Epoch: [118][  170/  267]    Overall Loss 2.377333    Objective Loss 2.377333                                        LR 0.100000    Time 0.244891    
2024-04-23 18:22:18,513 - Epoch: [118][  180/  267]    Overall Loss 2.377524    Objective Loss 2.377524                                        LR 0.100000    Time 0.243359    
2024-04-23 18:22:21,421 - Epoch: [118][  190/  267]    Overall Loss 2.378060    Objective Loss 2.378060                                        LR 0.100000    Time 0.245837    
2024-04-23 18:22:23,625 - Epoch: [118][  200/  267]    Overall Loss 2.375932    Objective Loss 2.375932                                        LR 0.100000    Time 0.244546    
2024-04-23 18:22:26,520 - Epoch: [118][  210/  267]    Overall Loss 2.375180    Objective Loss 2.375180                                        LR 0.100000    Time 0.246669    
2024-04-23 18:22:28,562 - Epoch: [118][  220/  267]    Overall Loss 2.374764    Objective Loss 2.374764                                        LR 0.100000    Time 0.244706    
2024-04-23 18:22:30,835 - Epoch: [87][  296/  296]    Overall Loss 0.860135    Objective Loss 0.860135    Top1 60.655738    Top5 93.442623    LR 0.000320    Time 0.229948    
2024-04-23 18:22:31,088 - --- validate (epoch=87)-----------
2024-04-23 18:22:31,090 - 3925 samples (32 per mini-batch)
2024-04-23 18:22:31,216 - Epoch: [118][  230/  267]    Overall Loss 2.374221    Objective Loss 2.374221                                        LR 0.100000    Time 0.245591    
2024-04-23 18:22:32,939 - Epoch: [118][  240/  267]    Overall Loss 2.372955    Objective Loss 2.372955                                        LR 0.100000    Time 0.242527    
2024-04-23 18:22:35,615 - Epoch: [118][  250/  267]    Overall Loss 2.371644    Objective Loss 2.371644                                        LR 0.100000    Time 0.243518    
2024-04-23 18:22:37,714 - Epoch: [118][  260/  267]    Overall Loss 2.371553    Objective Loss 2.371553                                        LR 0.100000    Time 0.242215    
2024-04-23 18:22:39,497 - Epoch: [118][  267/  267]    Overall Loss 2.371050    Objective Loss 2.371050    Top1 6.976744    Top5 51.162791    LR 0.100000    Time 0.242521    
2024-04-23 18:22:39,724 - --- validate (epoch=118)-----------
2024-04-23 18:22:39,725 - 946 samples (32 per mini-batch)
2024-04-23 18:22:43,578 - Epoch: [118][   10/   30]    Loss 2.419118    Top1 6.562500    Top5 44.687500    
2024-04-23 18:22:45,558 - Epoch: [118][   20/   30]    Loss 2.391200    Top1 8.125000    Top5 48.125000    
2024-04-23 18:22:48,398 - Epoch: [118][   30/   30]    Loss 2.382977    Top1 9.196617    Top5 49.365751    
2024-04-23 18:22:48,620 - ==> Top1: 9.197    Top5: 49.366    Loss: 2.383

2024-04-23 18:22:48,623 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 18:22:48,629 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:22:48,630 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:22:48,645 - 

2024-04-23 18:22:48,646 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:22:52,876 - Epoch: [119][   10/  267]    Overall Loss 2.363118    Objective Loss 2.363118                                        LR 0.100000    Time 0.422519    
2024-04-23 18:22:55,010 - Epoch: [119][   20/  267]    Overall Loss 2.381982    Objective Loss 2.381982                                        LR 0.100000    Time 0.317760    
2024-04-23 18:22:56,970 - Epoch: [87][  100/  123]    Loss 0.809266    Top1 73.093750    Top5 96.250000    
2024-04-23 18:22:58,256 - Epoch: [119][   30/  267]    Overall Loss 2.379009    Objective Loss 2.379009                                        LR 0.100000    Time 0.319923    
2024-04-23 18:23:00,436 - Epoch: [119][   40/  267]    Overall Loss 2.376125    Objective Loss 2.376125                                        LR 0.100000    Time 0.294369    
2024-04-23 18:23:02,546 - Epoch: [87][  123/  123]    Loss 0.803953    Top1 73.503185    Top5 96.382166    
2024-04-23 18:23:02,694 - ==> Top1: 73.503    Top5: 96.382    Loss: 0.804

2024-04-23 18:23:02,702 - ==> Best [Top1: 75.694   Top5: 96.586   Sparsity:0.00   Params: 376752 on epoch: 79]
2024-04-23 18:23:02,703 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:23:02,751 - 

2024-04-23 18:23:02,751 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:23:02,757 - Epoch: [119][   50/  267]    Overall Loss 2.382746    Objective Loss 2.382746                                        LR 0.100000    Time 0.281869    
2024-04-23 18:23:04,349 - Epoch: [119][   60/  267]    Overall Loss 2.381723    Objective Loss 2.381723                                        LR 0.100000    Time 0.261391    
2024-04-23 18:23:07,332 - Epoch: [119][   70/  267]    Overall Loss 2.379604    Objective Loss 2.379604                                        LR 0.100000    Time 0.266616    
2024-04-23 18:23:09,618 - Epoch: [119][   80/  267]    Overall Loss 2.378543    Objective Loss 2.378543                                        LR 0.100000    Time 0.261828    
2024-04-23 18:23:12,520 - Epoch: [119][   90/  267]    Overall Loss 2.374895    Objective Loss 2.374895                                        LR 0.100000    Time 0.264944    
2024-04-23 18:23:14,075 - Epoch: [119][  100/  267]    Overall Loss 2.375561    Objective Loss 2.375561                                        LR 0.100000    Time 0.253972    
2024-04-23 18:23:17,031 - Epoch: [119][  110/  267]    Overall Loss 2.377447    Objective Loss 2.377447                                        LR 0.100000    Time 0.257734    
2024-04-23 18:23:19,107 - Epoch: [119][  120/  267]    Overall Loss 2.375620    Objective Loss 2.375620                                        LR 0.100000    Time 0.253529    
2024-04-23 18:23:21,866 - Epoch: [119][  130/  267]    Overall Loss 2.374243    Objective Loss 2.374243                                        LR 0.100000    Time 0.255223    
2024-04-23 18:23:23,946 - Epoch: [119][  140/  267]    Overall Loss 2.374311    Objective Loss 2.374311                                        LR 0.100000    Time 0.251828    
2024-04-23 18:23:26,879 - Epoch: [119][  150/  267]    Overall Loss 2.374242    Objective Loss 2.374242                                        LR 0.100000    Time 0.254571    
2024-04-23 18:23:27,569 - Epoch: [88][  100/  296]    Overall Loss 0.877279    Objective Loss 0.877279                                        LR 0.000320    Time 0.247952    
2024-04-23 18:23:28,784 - Epoch: [119][  160/  267]    Overall Loss 2.376488    Objective Loss 2.376488                                        LR 0.100000    Time 0.250549    
2024-04-23 18:23:30,993 - Epoch: [119][  170/  267]    Overall Loss 2.378058    Objective Loss 2.378058                                        LR 0.100000    Time 0.248790    
2024-04-23 18:23:33,008 - Epoch: [119][  180/  267]    Overall Loss 2.378838    Objective Loss 2.378838                                        LR 0.100000    Time 0.246143    
2024-04-23 18:23:35,372 - Epoch: [119][  190/  267]    Overall Loss 2.377114    Objective Loss 2.377114                                        LR 0.100000    Time 0.245617    
2024-04-23 18:23:37,442 - Epoch: [119][  200/  267]    Overall Loss 2.375994    Objective Loss 2.375994                                        LR 0.100000    Time 0.243674    
2024-04-23 18:23:40,123 - Epoch: [119][  210/  267]    Overall Loss 2.376033    Objective Loss 2.376033                                        LR 0.100000    Time 0.244820    
2024-04-23 18:23:42,554 - Epoch: [119][  220/  267]    Overall Loss 2.375406    Objective Loss 2.375406                                        LR 0.100000    Time 0.244724    
2024-04-23 18:23:45,661 - Epoch: [119][  230/  267]    Overall Loss 2.373530    Objective Loss 2.373530                                        LR 0.100000    Time 0.247581    
2024-04-23 18:23:47,837 - Epoch: [119][  240/  267]    Overall Loss 2.373232    Objective Loss 2.373232                                        LR 0.100000    Time 0.246300    
2024-04-23 18:23:50,812 - Epoch: [119][  250/  267]    Overall Loss 2.372884    Objective Loss 2.372884                                        LR 0.100000    Time 0.248335    
2024-04-23 18:23:51,881 - Epoch: [88][  200/  296]    Overall Loss 0.862946    Objective Loss 0.862946                                        LR 0.000320    Time 0.245428    
2024-04-23 18:23:52,864 - Epoch: [119][  260/  267]    Overall Loss 2.370640    Objective Loss 2.370640                                        LR 0.100000    Time 0.246664    
2024-04-23 18:23:54,524 - Epoch: [119][  267/  267]    Overall Loss 2.369264    Objective Loss 2.369264    Top1 20.930233    Top5 55.813953    LR 0.100000    Time 0.246410    
2024-04-23 18:23:54,789 - --- validate (epoch=119)-----------
2024-04-23 18:23:54,790 - 946 samples (32 per mini-batch)
2024-04-23 18:23:58,557 - Epoch: [119][   10/   30]    Loss 2.427777    Top1 10.937500    Top5 50.000000    
2024-04-23 18:24:00,895 - Epoch: [119][   20/   30]    Loss 2.418317    Top1 11.093750    Top5 50.937500    
2024-04-23 18:24:03,221 - Epoch: [119][   30/   30]    Loss 2.432676    Top1 10.570825    Top5 50.000000    
2024-04-23 18:24:03,443 - ==> Top1: 10.571    Top5: 50.000    Loss: 2.433

2024-04-23 18:24:03,447 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 18:24:03,454 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:24:03,455 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:24:03,479 - 

2024-04-23 18:24:03,480 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:24:07,602 - Epoch: [120][   10/  267]    Overall Loss 2.362053    Objective Loss 2.362053                                        LR 0.100000    Time 0.411790    
2024-04-23 18:24:09,789 - Epoch: [120][   20/  267]    Overall Loss 2.359508    Objective Loss 2.359508                                        LR 0.100000    Time 0.315032    
2024-04-23 18:24:12,556 - Epoch: [120][   30/  267]    Overall Loss 2.367571    Objective Loss 2.367571                                        LR 0.100000    Time 0.302160    
2024-04-23 18:24:14,592 - Epoch: [120][   40/  267]    Overall Loss 2.366965    Objective Loss 2.366965                                        LR 0.100000    Time 0.277439    
2024-04-23 18:24:14,984 - Epoch: [88][  296/  296]    Overall Loss 0.870230    Objective Loss 0.870230    Top1 75.409836    Top5 98.360656    LR 0.000320    Time 0.243810    
2024-04-23 18:24:15,239 - --- validate (epoch=88)-----------
2024-04-23 18:24:15,241 - 3925 samples (32 per mini-batch)
2024-04-23 18:24:16,888 - Epoch: [120][   50/  267]    Overall Loss 2.362795    Objective Loss 2.362795                                        LR 0.100000    Time 0.267826    
2024-04-23 18:24:18,903 - Epoch: [120][   60/  267]    Overall Loss 2.361297    Objective Loss 2.361297                                        LR 0.100000    Time 0.256727    
2024-04-23 18:24:21,359 - Epoch: [120][   70/  267]    Overall Loss 2.365523    Objective Loss 2.365523                                        LR 0.100000    Time 0.255093    
2024-04-23 18:24:23,475 - Epoch: [120][   80/  267]    Overall Loss 2.362080    Objective Loss 2.362080                                        LR 0.100000    Time 0.249609    
2024-04-23 18:24:26,298 - Epoch: [120][   90/  267]    Overall Loss 2.359451    Objective Loss 2.359451                                        LR 0.100000    Time 0.253210    
2024-04-23 18:24:27,646 - Epoch: [120][  100/  267]    Overall Loss 2.358212    Objective Loss 2.358212                                        LR 0.100000    Time 0.241339    
2024-04-23 18:24:30,442 - Epoch: [120][  110/  267]    Overall Loss 2.358559    Objective Loss 2.358559                                        LR 0.100000    Time 0.244794    
2024-04-23 18:24:32,397 - Epoch: [120][  120/  267]    Overall Loss 2.355670    Objective Loss 2.355670                                        LR 0.100000    Time 0.240662    
2024-04-23 18:24:35,358 - Epoch: [120][  130/  267]    Overall Loss 2.356541    Objective Loss 2.356541                                        LR 0.100000    Time 0.244901    
2024-04-23 18:24:37,560 - Epoch: [120][  140/  267]    Overall Loss 2.355412    Objective Loss 2.355412                                        LR 0.100000    Time 0.243115    
2024-04-23 18:24:40,801 - Epoch: [88][  100/  123]    Loss 0.792351    Top1 73.968750    Top5 96.812500    
2024-04-23 18:24:40,949 - Epoch: [120][  150/  267]    Overall Loss 2.356007    Objective Loss 2.356007                                        LR 0.100000    Time 0.249477    
2024-04-23 18:24:42,621 - Epoch: [120][  160/  267]    Overall Loss 2.355443    Objective Loss 2.355443                                        LR 0.100000    Time 0.244313    
2024-04-23 18:24:45,598 - Epoch: [120][  170/  267]    Overall Loss 2.355750    Objective Loss 2.355750                                        LR 0.100000    Time 0.247429    
2024-04-23 18:24:46,117 - Epoch: [88][  123/  123]    Loss 0.784270    Top1 74.191083    Top5 96.891720    
2024-04-23 18:24:46,327 - ==> Top1: 74.191    Top5: 96.892    Loss: 0.784

2024-04-23 18:24:46,338 - ==> Best [Top1: 75.694   Top5: 96.586   Sparsity:0.00   Params: 376752 on epoch: 79]
2024-04-23 18:24:46,339 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:24:46,394 - 

2024-04-23 18:24:46,395 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:24:47,210 - Epoch: [120][  180/  267]    Overall Loss 2.356536    Objective Loss 2.356536                                        LR 0.100000    Time 0.242626    
2024-04-23 18:24:50,005 - Epoch: [120][  190/  267]    Overall Loss 2.356588    Objective Loss 2.356588                                        LR 0.100000    Time 0.244545    
2024-04-23 18:24:52,138 - Epoch: [120][  200/  267]    Overall Loss 2.356230    Objective Loss 2.356230                                        LR 0.100000    Time 0.242966    
2024-04-23 18:24:54,442 - Epoch: [120][  210/  267]    Overall Loss 2.355736    Objective Loss 2.355736                                        LR 0.100000    Time 0.242353    
2024-04-23 18:24:56,801 - Epoch: [120][  220/  267]    Overall Loss 2.356285    Objective Loss 2.356285                                        LR 0.100000    Time 0.242044    
2024-04-23 18:24:59,632 - Epoch: [120][  230/  267]    Overall Loss 2.355904    Objective Loss 2.355904                                        LR 0.100000    Time 0.243818    
2024-04-23 18:25:01,738 - Epoch: [120][  240/  267]    Overall Loss 2.356279    Objective Loss 2.356279                                        LR 0.100000    Time 0.242420    
2024-04-23 18:25:04,436 - Epoch: [120][  250/  267]    Overall Loss 2.356063    Objective Loss 2.356063                                        LR 0.100000    Time 0.243502    
2024-04-23 18:25:06,494 - Epoch: [120][  260/  267]    Overall Loss 2.355672    Objective Loss 2.355672                                        LR 0.100000    Time 0.242040    
2024-04-23 18:25:08,083 - Epoch: [120][  267/  267]    Overall Loss 2.356149    Objective Loss 2.356149    Top1 16.279070    Top5 48.837209    LR 0.100000    Time 0.241641    
2024-04-23 18:25:08,340 - --- validate (epoch=120)-----------
2024-04-23 18:25:08,341 - 946 samples (32 per mini-batch)
2024-04-23 18:25:12,279 - Epoch: [120][   10/   30]    Loss 2.366062    Top1 10.000000    Top5 47.500000    
2024-04-23 18:25:12,297 - Epoch: [89][  100/  296]    Overall Loss 0.836021    Objective Loss 0.836021                                        LR 0.000320    Time 0.258793    
2024-04-23 18:25:14,367 - Epoch: [120][   20/   30]    Loss 2.353465    Top1 9.687500    Top5 50.312500    
2024-04-23 18:25:17,059 - Epoch: [120][   30/   30]    Loss 2.354856    Top1 9.830867    Top5 49.788584    
2024-04-23 18:25:17,279 - ==> Top1: 9.831    Top5: 49.789    Loss: 2.355

2024-04-23 18:25:17,282 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 18:25:17,288 - ==> Best [Top1: 10.994   Top5: 52.114   Sparsity:0.00   Params: 96528 on epoch: 101]
2024-04-23 18:25:17,289 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:25:17,308 - 

2024-04-23 18:25:17,309 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:25:21,578 - Epoch: [121][   10/  267]    Overall Loss 2.355932    Objective Loss 2.355932                                        LR 0.100000    Time 0.426469    
2024-04-23 18:25:23,771 - Epoch: [121][   20/  267]    Overall Loss 2.369865    Objective Loss 2.369865                                        LR 0.100000    Time 0.322759    
2024-04-23 18:25:26,733 - Epoch: [121][   30/  267]    Overall Loss 2.359819    Objective Loss 2.359819                                        LR 0.100000    Time 0.313811    
2024-04-23 18:25:28,597 - Epoch: [121][   40/  267]    Overall Loss 2.365071    Objective Loss 2.365071                                        LR 0.100000    Time 0.281869    
2024-04-23 18:25:30,842 - Epoch: [121][   50/  267]    Overall Loss 2.363629    Objective Loss 2.363629                                        LR 0.100000    Time 0.270331    
2024-04-23 18:25:33,757 - Epoch: [121][   60/  267]    Overall Loss 2.362908    Objective Loss 2.362908                                        LR 0.100000    Time 0.273791    
2024-04-23 18:25:36,161 - Epoch: [121][   70/  267]    Overall Loss 2.362887    Objective Loss 2.362887                                        LR 0.100000    Time 0.268976    
2024-04-23 18:25:36,837 - Epoch: [89][  200/  296]    Overall Loss 0.847874    Objective Loss 0.847874                                        LR 0.000320    Time 0.251986    
2024-04-23 18:25:39,898 - Epoch: [121][   80/  267]    Overall Loss 2.364664    Objective Loss 2.364664                                        LR 0.100000    Time 0.282020    
2024-04-23 18:25:42,125 - Epoch: [121][   90/  267]    Overall Loss 2.361286    Objective Loss 2.361286                                        LR 0.100000    Time 0.275390    
2024-04-23 18:25:44,965 - Epoch: [121][  100/  267]    Overall Loss 2.361423    Objective Loss 2.361423                                        LR 0.100000    Time 0.276222    
2024-04-23 18:25:46,922 - Epoch: [121][  110/  267]    Overall Loss 2.360738    Objective Loss 2.360738                                        LR 0.100000    Time 0.268868    
2024-04-23 18:25:49,226 - Epoch: [121][  120/  267]    Overall Loss 2.360204    Objective Loss 2.360204                                        LR 0.100000    Time 0.265648    
2024-04-23 18:25:50,575 - Epoch: [121][  130/  267]    Overall Loss 2.359284    Objective Loss 2.359284                                        LR 0.100000    Time 0.255566    
2024-04-23 18:25:53,482 - Epoch: [121][  140/  267]    Overall Loss 2.360238    Objective Loss 2.360238                                        LR 0.100000    Time 0.258054    
2024-04-23 18:25:55,643 - Epoch: [121][  150/  267]    Overall Loss 2.357792    Objective Loss 2.357792                                        LR 0.100000    Time 0.255231    
2024-04-23 18:25:58,557 - Epoch: [121][  160/  267]    Overall Loss 2.358722    Objective Loss 2.358722                                        LR 0.100000    Time 0.257435    
2024-04-23 18:25:58,846 - Epoch: [89][  296/  296]    Overall Loss 0.851983    Objective Loss 0.851983    Top1 67.213115    Top5 91.803279    LR 0.000320    Time 0.244549    
2024-04-23 18:25:59,164 - --- validate (epoch=89)-----------
2024-04-23 18:25:59,166 - 3925 samples (32 per mini-batch)
2024-04-23 18:26:00,144 - Epoch: [121][  170/  267]    Overall Loss 2.358926    Objective Loss 2.358926                                        LR 0.100000    Time 0.251607    
2024-04-23 18:26:02,925 - Epoch: [121][  180/  267]    Overall Loss 2.357565    Objective Loss 2.357565                                        LR 0.100000    Time 0.253058    
2024-04-23 18:26:04,871 - Epoch: [121][  190/  267]    Overall Loss 2.358971    Objective Loss 2.358971                                        LR 0.100000    Time 0.249970    
2024-04-23 18:26:07,638 - Epoch: [121][  200/  267]    Overall Loss 2.359508    Objective Loss 2.359508                                        LR 0.100000    Time 0.251290    
2024-04-23 18:26:09,634 - Epoch: [121][  210/  267]    Overall Loss 2.359831    Objective Loss 2.359831                                        LR 0.100000    Time 0.248815    
2024-04-23 18:26:12,364 - Epoch: [121][  220/  267]    Overall Loss 2.362085    Objective Loss 2.362085                                        LR 0.100000    Time 0.249900    
2024-04-23 18:26:14,439 - Epoch: [121][  230/  267]    Overall Loss 2.360650    Objective Loss 2.360650                                        LR 0.100000    Time 0.248046    
2024-04-23 18:26:17,013 - Epoch: [121][  240/  267]    Overall Loss 2.360764    Objective Loss 2.360764                                        LR 0.100000    Time 0.248412    
2024-04-23 18:26:19,025 - Epoch: [121][  250/  267]    Overall Loss 2.362194    Objective Loss 2.362194                                        LR 0.100000    Time 0.246506    
2024-04-23 18:26:21,837 - Epoch: [121][  260/  267]    Overall Loss 2.361128    Objective Loss 2.361128                                        LR 0.100000    Time 0.247829    
2024-04-23 18:26:22,893 - Epoch: [121][  267/  267]    Overall Loss 2.362297    Objective Loss 2.362297    Top1 6.976744    Top5 53.488372    LR 0.100000    Time 0.245278    
2024-04-23 18:26:23,146 - --- validate (epoch=121)-----------
2024-04-23 18:26:23,148 - 946 samples (32 per mini-batch)
2024-04-23 18:26:25,104 - Epoch: [89][  100/  123]    Loss 0.833402    Top1 73.250000    Top5 96.375000    
2024-04-23 18:26:27,255 - Epoch: [121][   10/   30]    Loss 2.397888    Top1 11.875000    Top5 50.312500    
2024-04-23 18:26:29,355 - Epoch: [121][   20/   30]    Loss 2.391613    Top1 10.312500    Top5 51.406250    
2024-04-23 18:26:31,098 - Epoch: [89][  123/  123]    Loss 0.820752    Top1 73.783439    Top5 96.560510    
2024-04-23 18:26:31,277 - ==> Top1: 73.783    Top5: 96.561    Loss: 0.821

2024-04-23 18:26:31,285 - ==> Best [Top1: 75.694   Top5: 96.586   Sparsity:0.00   Params: 376752 on epoch: 79]
2024-04-23 18:26:31,286 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:26:31,342 - 

2024-04-23 18:26:31,343 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:26:31,406 - Epoch: [121][   30/   30]    Loss 2.379790    Top1 10.993658    Top5 52.219873    
2024-04-23 18:26:31,676 - ==> Top1: 10.994    Top5: 52.220    Loss: 2.380

2024-04-23 18:26:31,678 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 18:26:31,684 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:26:31,685 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:26:31,708 - 

2024-04-23 18:26:31,710 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:26:37,184 - Epoch: [122][   10/  267]    Overall Loss 2.412993    Objective Loss 2.412993                                        LR 0.100000    Time 0.546968    
2024-04-23 18:26:39,972 - Epoch: [122][   20/  267]    Overall Loss 2.381380    Objective Loss 2.381380                                        LR 0.100000    Time 0.412661    
2024-04-23 18:26:42,620 - Epoch: [122][   30/  267]    Overall Loss 2.365180    Objective Loss 2.365180                                        LR 0.100000    Time 0.363278    
2024-04-23 18:26:45,315 - Epoch: [122][   40/  267]    Overall Loss 2.362170    Objective Loss 2.362170                                        LR 0.100000    Time 0.339767    
2024-04-23 18:26:49,012 - Epoch: [122][   50/  267]    Overall Loss 2.366658    Objective Loss 2.366658                                        LR 0.100000    Time 0.345689    
2024-04-23 18:26:52,213 - Epoch: [122][   60/  267]    Overall Loss 2.364381    Objective Loss 2.364381                                        LR 0.100000    Time 0.341366    
2024-04-23 18:26:54,614 - Epoch: [122][   70/  267]    Overall Loss 2.363555    Objective Loss 2.363555                                        LR 0.100000    Time 0.326850    
2024-04-23 18:26:56,401 - Epoch: [90][  100/  296]    Overall Loss 0.846951    Objective Loss 0.846951                                        LR 0.000320    Time 0.250321    
2024-04-23 18:26:57,256 - Epoch: [122][   80/  267]    Overall Loss 2.364375    Objective Loss 2.364375                                        LR 0.100000    Time 0.318984    
2024-04-23 18:26:58,931 - Epoch: [122][   90/  267]    Overall Loss 2.364268    Objective Loss 2.364268                                        LR 0.100000    Time 0.302120    
2024-04-23 18:27:01,745 - Epoch: [122][  100/  267]    Overall Loss 2.360654    Objective Loss 2.360654                                        LR 0.100000    Time 0.300011    
2024-04-23 18:27:04,106 - Epoch: [122][  110/  267]    Overall Loss 2.359316    Objective Loss 2.359316                                        LR 0.100000    Time 0.294172    
2024-04-23 18:27:07,051 - Epoch: [122][  120/  267]    Overall Loss 2.360604    Objective Loss 2.360604                                        LR 0.100000    Time 0.294173    
2024-04-23 18:27:09,264 - Epoch: [122][  130/  267]    Overall Loss 2.358321    Objective Loss 2.358321                                        LR 0.100000    Time 0.288552    
2024-04-23 18:27:12,521 - Epoch: [122][  140/  267]    Overall Loss 2.358917    Objective Loss 2.358917                                        LR 0.100000    Time 0.291181    
2024-04-23 18:27:14,928 - Epoch: [122][  150/  267]    Overall Loss 2.359587    Objective Loss 2.359587                                        LR 0.100000    Time 0.287807    
2024-04-23 18:27:18,794 - Epoch: [122][  160/  267]    Overall Loss 2.358255    Objective Loss 2.358255                                        LR 0.100000    Time 0.293959    
2024-04-23 18:27:21,290 - Epoch: [122][  170/  267]    Overall Loss 2.358968    Objective Loss 2.358968                                        LR 0.100000    Time 0.291332    
2024-04-23 18:27:23,328 - Epoch: [90][  200/  296]    Overall Loss 0.867928    Objective Loss 0.867928                                        LR 0.000320    Time 0.259687    
2024-04-23 18:27:24,665 - Epoch: [122][  180/  267]    Overall Loss 2.360534    Objective Loss 2.360534                                        LR 0.100000    Time 0.293881    
2024-04-23 18:27:26,833 - Epoch: [122][  190/  267]    Overall Loss 2.361962    Objective Loss 2.361962                                        LR 0.100000    Time 0.289809    
2024-04-23 18:27:29,718 - Epoch: [122][  200/  267]    Overall Loss 2.361581    Objective Loss 2.361581                                        LR 0.100000    Time 0.289730    
2024-04-23 18:27:31,662 - Epoch: [122][  210/  267]    Overall Loss 2.363174    Objective Loss 2.363174                                        LR 0.100000    Time 0.285180    
2024-04-23 18:27:34,697 - Epoch: [122][  220/  267]    Overall Loss 2.362577    Objective Loss 2.362577                                        LR 0.100000    Time 0.285998    
2024-04-23 18:27:36,967 - Epoch: [122][  230/  267]    Overall Loss 2.362906    Objective Loss 2.362906                                        LR 0.100000    Time 0.283422    
2024-04-23 18:27:40,179 - Epoch: [122][  240/  267]    Overall Loss 2.363687    Objective Loss 2.363687                                        LR 0.100000    Time 0.284983    
2024-04-23 18:27:41,951 - Epoch: [122][  250/  267]    Overall Loss 2.363439    Objective Loss 2.363439                                        LR 0.100000    Time 0.280659    
2024-04-23 18:27:44,647 - Epoch: [122][  260/  267]    Overall Loss 2.363378    Objective Loss 2.363378                                        LR 0.100000    Time 0.280223    
2024-04-23 18:27:46,002 - Epoch: [122][  267/  267]    Overall Loss 2.363192    Objective Loss 2.363192    Top1 16.279070    Top5 44.186047    LR 0.100000    Time 0.277942    
2024-04-23 18:27:46,244 - --- validate (epoch=122)-----------
2024-04-23 18:27:46,245 - 946 samples (32 per mini-batch)
2024-04-23 18:27:46,840 - Epoch: [90][  296/  296]    Overall Loss 0.869939    Objective Loss 0.869939    Top1 65.573770    Top5 100.000000    LR 0.000320    Time 0.254831    
2024-04-23 18:27:47,024 - --- validate (epoch=90)-----------
2024-04-23 18:27:47,025 - 3925 samples (32 per mini-batch)
2024-04-23 18:27:50,411 - Epoch: [122][   10/   30]    Loss 2.403134    Top1 8.437500    Top5 47.500000    
2024-04-23 18:27:52,686 - Epoch: [122][   20/   30]    Loss 2.392636    Top1 8.750000    Top5 49.687500    
2024-04-23 18:27:55,777 - Epoch: [122][   30/   30]    Loss 2.382559    Top1 9.196617    Top5 49.894292    
2024-04-23 18:27:56,008 - ==> Top1: 9.197    Top5: 49.894    Loss: 2.383

2024-04-23 18:27:56,011 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 18:27:56,016 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:27:56,017 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:27:56,033 - 

2024-04-23 18:27:56,034 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:28:00,533 - Epoch: [123][   10/  267]    Overall Loss 2.407063    Objective Loss 2.407063                                        LR 0.100000    Time 0.449578    
2024-04-23 18:28:02,983 - Epoch: [123][   20/  267]    Overall Loss 2.385425    Objective Loss 2.385425                                        LR 0.100000    Time 0.347126    
2024-04-23 18:28:06,943 - Epoch: [123][   30/  267]    Overall Loss 2.384621    Objective Loss 2.384621                                        LR 0.100000    Time 0.363310    
2024-04-23 18:28:09,611 - Epoch: [123][   40/  267]    Overall Loss 2.383521    Objective Loss 2.383521                                        LR 0.100000    Time 0.339094    
2024-04-23 18:28:09,674 - Epoch: [90][  100/  123]    Loss 0.765825    Top1 75.406250    Top5 96.937500    
2024-04-23 18:28:12,693 - Epoch: [123][   50/  267]    Overall Loss 2.378800    Objective Loss 2.378800                                        LR 0.100000    Time 0.332856    
2024-04-23 18:28:13,961 - Epoch: [90][  123/  123]    Loss 0.780892    Top1 75.108280    Top5 96.815287    
2024-04-23 18:28:14,287 - ==> Top1: 75.108    Top5: 96.815    Loss: 0.781

2024-04-23 18:28:14,294 - ==> Best [Top1: 75.694   Top5: 96.586   Sparsity:0.00   Params: 376752 on epoch: 79]
2024-04-23 18:28:14,295 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:28:14,334 - 

2024-04-23 18:28:14,335 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:28:15,352 - Epoch: [123][   60/  267]    Overall Loss 2.372014    Objective Loss 2.372014                                        LR 0.100000    Time 0.321652    
2024-04-23 18:28:19,129 - Epoch: [123][   70/  267]    Overall Loss 2.373692    Objective Loss 2.373692                                        LR 0.100000    Time 0.329604    
2024-04-23 18:28:21,919 - Epoch: [123][   80/  267]    Overall Loss 2.369624    Objective Loss 2.369624                                        LR 0.100000    Time 0.323237    
2024-04-23 18:28:25,301 - Epoch: [123][   90/  267]    Overall Loss 2.367509    Objective Loss 2.367509                                        LR 0.100000    Time 0.324871    
2024-04-23 18:28:28,008 - Epoch: [123][  100/  267]    Overall Loss 2.369072    Objective Loss 2.369072                                        LR 0.100000    Time 0.319411    
2024-04-23 18:28:30,851 - Epoch: [123][  110/  267]    Overall Loss 2.376186    Objective Loss 2.376186                                        LR 0.100000    Time 0.316185    
2024-04-23 18:28:33,174 - Epoch: [123][  120/  267]    Overall Loss 2.372847    Objective Loss 2.372847                                        LR 0.100000    Time 0.309138    
2024-04-23 18:28:35,077 - Epoch: [91][  100/  296]    Overall Loss 0.852256    Objective Loss 0.852256                                        LR 0.000320    Time 0.207211    
2024-04-23 18:28:36,350 - Epoch: [123][  130/  267]    Overall Loss 2.370207    Objective Loss 2.370207                                        LR 0.100000    Time 0.309733    
2024-04-23 18:28:38,698 - Epoch: [123][  140/  267]    Overall Loss 2.369322    Objective Loss 2.369322                                        LR 0.100000    Time 0.304350    
2024-04-23 18:28:41,774 - Epoch: [123][  150/  267]    Overall Loss 2.368771    Objective Loss 2.368771                                        LR 0.100000    Time 0.304541    
2024-04-23 18:28:44,054 - Epoch: [123][  160/  267]    Overall Loss 2.369057    Objective Loss 2.369057                                        LR 0.100000    Time 0.299738    
2024-04-23 18:28:47,490 - Epoch: [123][  170/  267]    Overall Loss 2.370555    Objective Loss 2.370555                                        LR 0.100000    Time 0.302302    
2024-04-23 18:28:49,463 - Epoch: [123][  180/  267]    Overall Loss 2.369422    Objective Loss 2.369422                                        LR 0.100000    Time 0.296448    
2024-04-23 18:28:52,089 - Epoch: [123][  190/  267]    Overall Loss 2.369223    Objective Loss 2.369223                                        LR 0.100000    Time 0.294649    
2024-04-23 18:28:53,845 - Epoch: [123][  200/  267]    Overall Loss 2.368891    Objective Loss 2.368891                                        LR 0.100000    Time 0.288680    
2024-04-23 18:28:54,345 - Epoch: [91][  200/  296]    Overall Loss 0.866008    Objective Loss 0.866008                                        LR 0.000320    Time 0.199840    
2024-04-23 18:28:56,795 - Epoch: [123][  210/  267]    Overall Loss 2.370532    Objective Loss 2.370532                                        LR 0.100000    Time 0.288965    
2024-04-23 18:28:58,933 - Epoch: [123][  220/  267]    Overall Loss 2.370808    Objective Loss 2.370808                                        LR 0.100000    Time 0.285525    
2024-04-23 18:29:01,659 - Epoch: [123][  230/  267]    Overall Loss 2.369999    Objective Loss 2.369999                                        LR 0.100000    Time 0.284950    
2024-04-23 18:29:03,776 - Epoch: [123][  240/  267]    Overall Loss 2.368944    Objective Loss 2.368944                                        LR 0.100000    Time 0.281879    
2024-04-23 18:29:06,776 - Epoch: [123][  250/  267]    Overall Loss 2.367717    Objective Loss 2.367717                                        LR 0.100000    Time 0.282591    
2024-04-23 18:29:09,465 - Epoch: [123][  260/  267]    Overall Loss 2.367806    Objective Loss 2.367806                                        LR 0.100000    Time 0.282053    
2024-04-23 18:29:11,453 - Epoch: [123][  267/  267]    Overall Loss 2.366651    Objective Loss 2.366651    Top1 23.255814    Top5 48.837209    LR 0.100000    Time 0.282097    
2024-04-23 18:29:11,747 - --- validate (epoch=123)-----------
2024-04-23 18:29:11,748 - 946 samples (32 per mini-batch)
2024-04-23 18:29:12,709 - Epoch: [91][  296/  296]    Overall Loss 0.855418    Objective Loss 0.855418    Top1 73.770492    Top5 90.163934    LR 0.000320    Time 0.197002    
2024-04-23 18:29:12,965 - --- validate (epoch=91)-----------
2024-04-23 18:29:12,967 - 3925 samples (32 per mini-batch)
2024-04-23 18:29:15,357 - Epoch: [123][   10/   30]    Loss 2.338121    Top1 9.062500    Top5 50.312500    
2024-04-23 18:29:17,901 - Epoch: [123][   20/   30]    Loss 2.351988    Top1 8.906250    Top5 49.218750    
2024-04-23 18:29:21,252 - Epoch: [123][   30/   30]    Loss 2.338618    Top1 10.465116    Top5 50.845666    
2024-04-23 18:29:21,514 - ==> Top1: 10.465    Top5: 50.846    Loss: 2.339

2024-04-23 18:29:21,516 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 18:29:21,522 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:29:21,523 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:29:21,546 - 

2024-04-23 18:29:21,548 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:29:25,896 - Epoch: [124][   10/  267]    Overall Loss 2.379603    Objective Loss 2.379603                                        LR 0.100000    Time 0.434455    
2024-04-23 18:29:28,097 - Epoch: [124][   20/  267]    Overall Loss 2.367470    Objective Loss 2.367470                                        LR 0.100000    Time 0.327067    
2024-04-23 18:29:31,005 - Epoch: [124][   30/  267]    Overall Loss 2.373399    Objective Loss 2.373399                                        LR 0.100000    Time 0.314883    
2024-04-23 18:29:33,296 - Epoch: [124][   40/  267]    Overall Loss 2.364521    Objective Loss 2.364521                                        LR 0.100000    Time 0.293363    
2024-04-23 18:29:36,342 - Epoch: [124][   50/  267]    Overall Loss 2.354949    Objective Loss 2.354949                                        LR 0.100000    Time 0.295551    
2024-04-23 18:29:38,607 - Epoch: [124][   60/  267]    Overall Loss 2.358970    Objective Loss 2.358970                                        LR 0.100000    Time 0.283987    
2024-04-23 18:29:41,819 - Epoch: [124][   70/  267]    Overall Loss 2.359247    Objective Loss 2.359247                                        LR 0.100000    Time 0.289256    
2024-04-23 18:29:42,146 - Epoch: [91][  100/  123]    Loss 0.747218    Top1 75.687500    Top5 96.718750    
2024-04-23 18:29:43,861 - Epoch: [124][   80/  267]    Overall Loss 2.364253    Objective Loss 2.364253                                        LR 0.100000    Time 0.278591    
2024-04-23 18:29:46,524 - Epoch: [124][   90/  267]    Overall Loss 2.364988    Objective Loss 2.364988                                        LR 0.100000    Time 0.277193    
2024-04-23 18:29:47,385 - Epoch: [91][  123/  123]    Loss 0.735265    Top1 75.847134    Top5 96.993631    
2024-04-23 18:29:47,773 - ==> Top1: 75.847    Top5: 96.994    Loss: 0.735

2024-04-23 18:29:47,784 - ==> Best [Top1: 75.847   Top5: 96.994   Sparsity:0.00   Params: 376752 on epoch: 91]
2024-04-23 18:29:47,785 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:29:47,861 - 

2024-04-23 18:29:47,862 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:29:48,218 - Epoch: [124][  100/  267]    Overall Loss 2.365278    Objective Loss 2.365278                                        LR 0.100000    Time 0.266385    
2024-04-23 18:29:50,320 - Epoch: [124][  110/  267]    Overall Loss 2.368287    Objective Loss 2.368287                                        LR 0.100000    Time 0.261253    
2024-04-23 18:29:51,434 - Epoch: [124][  120/  267]    Overall Loss 2.367160    Objective Loss 2.367160                                        LR 0.100000    Time 0.248747    
2024-04-23 18:29:53,325 - Epoch: [124][  130/  267]    Overall Loss 2.365114    Objective Loss 2.365114                                        LR 0.100000    Time 0.244140    
2024-04-23 18:29:55,093 - Epoch: [124][  140/  267]    Overall Loss 2.368447    Objective Loss 2.368447                                        LR 0.100000    Time 0.239311    
2024-04-23 18:29:57,684 - Epoch: [124][  150/  267]    Overall Loss 2.366014    Objective Loss 2.366014                                        LR 0.100000    Time 0.240608    
2024-04-23 18:29:59,546 - Epoch: [124][  160/  267]    Overall Loss 2.365837    Objective Loss 2.365837                                        LR 0.100000    Time 0.237191    
2024-04-23 18:30:02,661 - Epoch: [124][  170/  267]    Overall Loss 2.367049    Objective Loss 2.367049                                        LR 0.100000    Time 0.241541    
2024-04-23 18:30:05,221 - Epoch: [124][  180/  267]    Overall Loss 2.365950    Objective Loss 2.365950                                        LR 0.100000    Time 0.242324    
2024-04-23 18:30:08,358 - Epoch: [124][  190/  267]    Overall Loss 2.365828    Objective Loss 2.365828                                        LR 0.100000    Time 0.246059    
2024-04-23 18:30:10,498 - Epoch: [124][  200/  267]    Overall Loss 2.368792    Objective Loss 2.368792                                        LR 0.100000    Time 0.244443    
2024-04-23 18:30:14,340 - Epoch: [124][  210/  267]    Overall Loss 2.368781    Objective Loss 2.368781                                        LR 0.100000    Time 0.251085    
2024-04-23 18:30:15,805 - Epoch: [92][  100/  296]    Overall Loss 0.869229    Objective Loss 0.869229                                        LR 0.000320    Time 0.279207    
2024-04-23 18:30:16,323 - Epoch: [124][  220/  267]    Overall Loss 2.368486    Objective Loss 2.368486                                        LR 0.100000    Time 0.248672    
2024-04-23 18:30:19,177 - Epoch: [124][  230/  267]    Overall Loss 2.368278    Objective Loss 2.368278                                        LR 0.100000    Time 0.250254    
2024-04-23 18:30:21,157 - Epoch: [124][  240/  267]    Overall Loss 2.369083    Objective Loss 2.369083                                        LR 0.100000    Time 0.248066    
2024-04-23 18:30:24,127 - Epoch: [124][  250/  267]    Overall Loss 2.368276    Objective Loss 2.368276                                        LR 0.100000    Time 0.250012    
2024-04-23 18:30:26,182 - Epoch: [124][  260/  267]    Overall Loss 2.369008    Objective Loss 2.369008                                        LR 0.100000    Time 0.248287    
2024-04-23 18:30:27,828 - Epoch: [124][  267/  267]    Overall Loss 2.368924    Objective Loss 2.368924    Top1 11.627907    Top5 60.465116    LR 0.100000    Time 0.247936    
2024-04-23 18:30:28,087 - --- validate (epoch=124)-----------
2024-04-23 18:30:28,088 - 946 samples (32 per mini-batch)
2024-04-23 18:30:31,895 - Epoch: [124][   10/   30]    Loss 2.394160    Top1 8.437500    Top5 48.437500    
2024-04-23 18:30:34,154 - Epoch: [124][   20/   30]    Loss 2.401362    Top1 7.968750    Top5 48.906250    
2024-04-23 18:30:36,551 - Epoch: [124][   30/   30]    Loss 2.398668    Top1 8.456660    Top5 49.154334    
2024-04-23 18:30:36,861 - ==> Top1: 8.457    Top5: 49.154    Loss: 2.399

2024-04-23 18:30:36,863 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 18:30:36,870 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:30:36,871 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:30:36,889 - 

2024-04-23 18:30:36,890 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:30:40,986 - Epoch: [92][  200/  296]    Overall Loss 0.863588    Objective Loss 0.863588                                        LR 0.000320    Time 0.265398    
2024-04-23 18:30:41,250 - Epoch: [125][   10/  267]    Overall Loss 2.362544    Objective Loss 2.362544                                        LR 0.100000    Time 0.435632    
2024-04-23 18:30:43,488 - Epoch: [125][   20/  267]    Overall Loss 2.364774    Objective Loss 2.364774                                        LR 0.100000    Time 0.329531    
2024-04-23 18:30:46,677 - Epoch: [125][   30/  267]    Overall Loss 2.363162    Objective Loss 2.363162                                        LR 0.100000    Time 0.325848    
2024-04-23 18:30:49,342 - Epoch: [125][   40/  267]    Overall Loss 2.367571    Objective Loss 2.367571                                        LR 0.100000    Time 0.310938    
2024-04-23 18:30:52,593 - Epoch: [125][   50/  267]    Overall Loss 2.369860    Objective Loss 2.369860                                        LR 0.100000    Time 0.313700    
2024-04-23 18:30:54,847 - Epoch: [125][   60/  267]    Overall Loss 2.374200    Objective Loss 2.374200                                        LR 0.100000    Time 0.298947    
2024-04-23 18:30:57,917 - Epoch: [125][   70/  267]    Overall Loss 2.383613    Objective Loss 2.383613                                        LR 0.100000    Time 0.300045    
2024-04-23 18:31:00,321 - Epoch: [125][   80/  267]    Overall Loss 2.382840    Objective Loss 2.382840                                        LR 0.100000    Time 0.292552    
2024-04-23 18:31:02,119 - Epoch: [125][   90/  267]    Overall Loss 2.379051    Objective Loss 2.379051                                        LR 0.100000    Time 0.280001    
2024-04-23 18:31:03,896 - Epoch: [92][  296/  296]    Overall Loss 0.849820    Objective Loss 0.849820    Top1 75.409836    Top5 98.360656    LR 0.000320    Time 0.256654    
2024-04-23 18:31:04,225 - --- validate (epoch=92)-----------
2024-04-23 18:31:04,227 - 3925 samples (32 per mini-batch)
2024-04-23 18:31:04,382 - Epoch: [125][  100/  267]    Overall Loss 2.380199    Objective Loss 2.380199                                        LR 0.100000    Time 0.274606    
2024-04-23 18:31:06,395 - Epoch: [125][  110/  267]    Overall Loss 2.379498    Objective Loss 2.379498                                        LR 0.100000    Time 0.267924    
2024-04-23 18:31:09,591 - Epoch: [125][  120/  267]    Overall Loss 2.379395    Objective Loss 2.379395                                        LR 0.100000    Time 0.272204    
2024-04-23 18:31:11,128 - Epoch: [125][  130/  267]    Overall Loss 2.379335    Objective Loss 2.379335                                        LR 0.100000    Time 0.263065    
2024-04-23 18:31:13,503 - Epoch: [125][  140/  267]    Overall Loss 2.380452    Objective Loss 2.380452                                        LR 0.100000    Time 0.261224    
2024-04-23 18:31:15,383 - Epoch: [125][  150/  267]    Overall Loss 2.382164    Objective Loss 2.382164                                        LR 0.100000    Time 0.256319    
2024-04-23 18:31:17,620 - Epoch: [125][  160/  267]    Overall Loss 2.378762    Objective Loss 2.378762                                        LR 0.100000    Time 0.254262    
2024-04-23 18:31:19,218 - Epoch: [125][  170/  267]    Overall Loss 2.375485    Objective Loss 2.375485                                        LR 0.100000    Time 0.248691    
2024-04-23 18:31:21,605 - Epoch: [125][  180/  267]    Overall Loss 2.374536    Objective Loss 2.374536                                        LR 0.100000    Time 0.248120    
2024-04-23 18:31:23,439 - Epoch: [125][  190/  267]    Overall Loss 2.376347    Objective Loss 2.376347                                        LR 0.100000    Time 0.244698    
2024-04-23 18:31:25,037 - Epoch: [125][  200/  267]    Overall Loss 2.378243    Objective Loss 2.378243                                        LR 0.100000    Time 0.240437    
2024-04-23 18:31:27,082 - Epoch: [125][  210/  267]    Overall Loss 2.379352    Objective Loss 2.379352                                        LR 0.100000    Time 0.238713    
2024-04-23 18:31:30,241 - Epoch: [125][  220/  267]    Overall Loss 2.378844    Objective Loss 2.378844                                        LR 0.100000    Time 0.242206    
2024-04-23 18:31:32,324 - Epoch: [125][  230/  267]    Overall Loss 2.378003    Objective Loss 2.378003                                        LR 0.100000    Time 0.240713    
2024-04-23 18:31:33,796 - Epoch: [92][  100/  123]    Loss 0.731644    Top1 75.906250    Top5 96.812500    
2024-04-23 18:31:35,160 - Epoch: [125][  240/  267]    Overall Loss 2.375215    Objective Loss 2.375215                                        LR 0.100000    Time 0.242483    
2024-04-23 18:31:37,184 - Epoch: [125][  250/  267]    Overall Loss 2.376587    Objective Loss 2.376587                                        LR 0.100000    Time 0.240867    
2024-04-23 18:31:38,429 - Epoch: [92][  123/  123]    Loss 0.731508    Top1 76.127389    Top5 96.764331    
2024-04-23 18:31:38,780 - ==> Top1: 76.127    Top5: 96.764    Loss: 0.732

2024-04-23 18:31:38,793 - ==> Best [Top1: 76.127   Top5: 96.764   Sparsity:0.00   Params: 376752 on epoch: 92]
2024-04-23 18:31:38,794 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:31:38,889 - 

2024-04-23 18:31:38,890 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:31:40,259 - Epoch: [125][  260/  267]    Overall Loss 2.377513    Objective Loss 2.377513                                        LR 0.100000    Time 0.243415    
2024-04-23 18:31:41,097 - Epoch: [125][  267/  267]    Overall Loss 2.378373    Objective Loss 2.378373    Top1 9.302326    Top5 37.209302    LR 0.100000    Time 0.240160    
2024-04-23 18:31:41,334 - --- validate (epoch=125)-----------
2024-04-23 18:31:41,336 - 946 samples (32 per mini-batch)
2024-04-23 18:31:44,935 - Epoch: [125][   10/   30]    Loss 2.313457    Top1 11.562500    Top5 54.375000    
2024-04-23 18:31:47,047 - Epoch: [125][   20/   30]    Loss 2.321562    Top1 11.250000    Top5 52.500000    
2024-04-23 18:31:49,742 - Epoch: [125][   30/   30]    Loss 2.338239    Top1 10.359408    Top5 50.422833    
2024-04-23 18:31:49,971 - ==> Top1: 10.359    Top5: 50.423    Loss: 2.338

2024-04-23 18:31:49,973 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 18:31:49,979 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:31:49,980 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:31:50,004 - 

2024-04-23 18:31:50,006 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:31:53,874 - Epoch: [126][   10/  267]    Overall Loss 2.355720    Objective Loss 2.355720                                        LR 0.100000    Time 0.386336    
2024-04-23 18:31:56,369 - Epoch: [126][   20/  267]    Overall Loss 2.349605    Objective Loss 2.349605                                        LR 0.100000    Time 0.317793    
2024-04-23 18:31:59,203 - Epoch: [126][   30/  267]    Overall Loss 2.362077    Objective Loss 2.362077                                        LR 0.100000    Time 0.306199    
2024-04-23 18:32:01,379 - Epoch: [93][  100/  296]    Overall Loss 0.833132    Objective Loss 0.833132                                        LR 0.000320    Time 0.224648    
2024-04-23 18:32:01,682 - Epoch: [126][   40/  267]    Overall Loss 2.367474    Objective Loss 2.367474                                        LR 0.100000    Time 0.291538    
2024-04-23 18:32:05,481 - Epoch: [126][   50/  267]    Overall Loss 2.367970    Objective Loss 2.367970                                        LR 0.100000    Time 0.309149    
2024-04-23 18:32:07,839 - Epoch: [126][   60/  267]    Overall Loss 2.369839    Objective Loss 2.369839                                        LR 0.100000    Time 0.296878    
2024-04-23 18:32:10,557 - Epoch: [126][   70/  267]    Overall Loss 2.368997    Objective Loss 2.368997                                        LR 0.100000    Time 0.293257    
2024-04-23 18:32:12,322 - Epoch: [126][   80/  267]    Overall Loss 2.371273    Objective Loss 2.371273                                        LR 0.100000    Time 0.278628    
2024-04-23 18:32:14,887 - Epoch: [126][   90/  267]    Overall Loss 2.367084    Objective Loss 2.367084                                        LR 0.100000    Time 0.276134    
2024-04-23 18:32:16,586 - Epoch: [126][  100/  267]    Overall Loss 2.370029    Objective Loss 2.370029                                        LR 0.100000    Time 0.265484    
2024-04-23 18:32:18,207 - Epoch: [126][  110/  267]    Overall Loss 2.367078    Objective Loss 2.367078                                        LR 0.100000    Time 0.256057    
2024-04-23 18:32:20,929 - Epoch: [93][  200/  296]    Overall Loss 0.843294    Objective Loss 0.843294                                        LR 0.000320    Time 0.209974    
2024-04-23 18:32:21,056 - Epoch: [126][  120/  267]    Overall Loss 2.364430    Objective Loss 2.364430                                        LR 0.100000    Time 0.258436    
2024-04-23 18:32:22,918 - Epoch: [126][  130/  267]    Overall Loss 2.365767    Objective Loss 2.365767                                        LR 0.100000    Time 0.252853    
2024-04-23 18:32:25,292 - Epoch: [126][  140/  267]    Overall Loss 2.364577    Objective Loss 2.364577                                        LR 0.100000    Time 0.251728    
2024-04-23 18:32:27,159 - Epoch: [126][  150/  267]    Overall Loss 2.365526    Objective Loss 2.365526                                        LR 0.100000    Time 0.247371    
2024-04-23 18:32:29,343 - Epoch: [126][  160/  267]    Overall Loss 2.364769    Objective Loss 2.364769                                        LR 0.100000    Time 0.245544    
2024-04-23 18:32:31,659 - Epoch: [126][  170/  267]    Overall Loss 2.365015    Objective Loss 2.365015                                        LR 0.100000    Time 0.244704    
2024-04-23 18:32:33,559 - Epoch: [126][  180/  267]    Overall Loss 2.366770    Objective Loss 2.366770                                        LR 0.100000    Time 0.241651    
2024-04-23 18:32:35,704 - Epoch: [126][  190/  267]    Overall Loss 2.369597    Objective Loss 2.369597                                        LR 0.100000    Time 0.240209    
2024-04-23 18:32:38,143 - Epoch: [126][  200/  267]    Overall Loss 2.369836    Objective Loss 2.369836                                        LR 0.100000    Time 0.240381    
2024-04-23 18:32:39,723 - Epoch: [126][  210/  267]    Overall Loss 2.369352    Objective Loss 2.369352                                        LR 0.100000    Time 0.236446    
2024-04-23 18:32:40,792 - Epoch: [93][  296/  296]    Overall Loss 0.841186    Objective Loss 0.841186    Top1 62.295082    Top5 95.081967    LR 0.000320    Time 0.208909    
2024-04-23 18:32:41,116 - --- validate (epoch=93)-----------
2024-04-23 18:32:41,117 - 3925 samples (32 per mini-batch)
2024-04-23 18:32:41,480 - Epoch: [126][  220/  267]    Overall Loss 2.369658    Objective Loss 2.369658                                        LR 0.100000    Time 0.233674    
2024-04-23 18:32:43,865 - Epoch: [126][  230/  267]    Overall Loss 2.368857    Objective Loss 2.368857                                        LR 0.100000    Time 0.233872    
2024-04-23 18:32:46,085 - Epoch: [126][  240/  267]    Overall Loss 2.368059    Objective Loss 2.368059                                        LR 0.100000    Time 0.233354    
2024-04-23 18:32:49,370 - Epoch: [126][  250/  267]    Overall Loss 2.367728    Objective Loss 2.367728                                        LR 0.100000    Time 0.237150    
2024-04-23 18:32:51,465 - Epoch: [126][  260/  267]    Overall Loss 2.369230    Objective Loss 2.369230                                        LR 0.100000    Time 0.236072    
2024-04-23 18:32:53,340 - Epoch: [126][  267/  267]    Overall Loss 2.368206    Objective Loss 2.368206    Top1 9.302326    Top5 51.162791    LR 0.100000    Time 0.236895    
2024-04-23 18:32:53,662 - --- validate (epoch=126)-----------
2024-04-23 18:32:53,663 - 946 samples (32 per mini-batch)
2024-04-23 18:32:58,403 - Epoch: [126][   10/   30]    Loss 2.359625    Top1 10.312500    Top5 49.687500    
2024-04-23 18:33:00,856 - Epoch: [126][   20/   30]    Loss 2.364032    Top1 9.843750    Top5 48.437500    
2024-04-23 18:33:04,101 - Epoch: [126][   30/   30]    Loss 2.360735    Top1 9.830867    Top5 49.682875    
2024-04-23 18:33:04,335 - ==> Top1: 9.831    Top5: 49.683    Loss: 2.361

2024-04-23 18:33:04,337 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 18:33:04,340 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:33:04,340 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:33:04,352 - 

2024-04-23 18:33:04,353 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:33:08,423 - Epoch: [127][   10/  267]    Overall Loss 2.387616    Objective Loss 2.387616                                        LR 0.100000    Time 0.406609    
2024-04-23 18:33:08,504 - Epoch: [93][  100/  123]    Loss 0.742188    Top1 76.343750    Top5 96.812500    
2024-04-23 18:33:11,132 - Epoch: [127][   20/  267]    Overall Loss 2.388386    Objective Loss 2.388386                                        LR 0.100000    Time 0.338596    
2024-04-23 18:33:14,174 - Epoch: [93][  123/  123]    Loss 0.738664    Top1 76.254777    Top5 96.917197    
2024-04-23 18:33:14,294 - Epoch: [127][   30/  267]    Overall Loss 2.380515    Objective Loss 2.380515                                        LR 0.100000    Time 0.330995    
2024-04-23 18:33:14,568 - ==> Top1: 76.255    Top5: 96.917    Loss: 0.739

2024-04-23 18:33:14,581 - ==> Best [Top1: 76.255   Top5: 96.917   Sparsity:0.00   Params: 376752 on epoch: 93]
2024-04-23 18:33:14,582 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:33:14,671 - 

2024-04-23 18:33:14,672 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:33:16,269 - Epoch: [127][   40/  267]    Overall Loss 2.374937    Objective Loss 2.374937                                        LR 0.100000    Time 0.297545    
2024-04-23 18:33:19,037 - Epoch: [127][   50/  267]    Overall Loss 2.370132    Objective Loss 2.370132                                        LR 0.100000    Time 0.293325    
2024-04-23 18:33:21,032 - Epoch: [127][   60/  267]    Overall Loss 2.372350    Objective Loss 2.372350                                        LR 0.100000    Time 0.277649    
2024-04-23 18:33:23,875 - Epoch: [127][   70/  267]    Overall Loss 2.367400    Objective Loss 2.367400                                        LR 0.100000    Time 0.278548    
2024-04-23 18:33:25,859 - Epoch: [127][   80/  267]    Overall Loss 2.368037    Objective Loss 2.368037                                        LR 0.100000    Time 0.268487    
2024-04-23 18:33:28,198 - Epoch: [127][   90/  267]    Overall Loss 2.362772    Objective Loss 2.362772                                        LR 0.100000    Time 0.264611    
2024-04-23 18:33:29,926 - Epoch: [127][  100/  267]    Overall Loss 2.365788    Objective Loss 2.365788                                        LR 0.100000    Time 0.255401    
2024-04-23 18:33:32,754 - Epoch: [127][  110/  267]    Overall Loss 2.363847    Objective Loss 2.363847                                        LR 0.100000    Time 0.257860    
2024-04-23 18:33:34,892 - Epoch: [127][  120/  267]    Overall Loss 2.363125    Objective Loss 2.363125                                        LR 0.100000    Time 0.254158    
2024-04-23 18:33:38,072 - Epoch: [127][  130/  267]    Overall Loss 2.361876    Objective Loss 2.361876                                        LR 0.100000    Time 0.259040    
2024-04-23 18:33:40,228 - Epoch: [127][  140/  267]    Overall Loss 2.363403    Objective Loss 2.363403                                        LR 0.100000    Time 0.255909    
2024-04-23 18:33:42,301 - Epoch: [94][  100/  296]    Overall Loss 0.868594    Objective Loss 0.868594                                        LR 0.000320    Time 0.276034    
2024-04-23 18:33:43,440 - Epoch: [127][  150/  267]    Overall Loss 2.362299    Objective Loss 2.362299                                        LR 0.100000    Time 0.260240    
2024-04-23 18:33:45,488 - Epoch: [127][  160/  267]    Overall Loss 2.362152    Objective Loss 2.362152                                        LR 0.100000    Time 0.256757    
2024-04-23 18:33:48,631 - Epoch: [127][  170/  267]    Overall Loss 2.362493    Objective Loss 2.362493                                        LR 0.100000    Time 0.260118    
2024-04-23 18:33:50,682 - Epoch: [127][  180/  267]    Overall Loss 2.363647    Objective Loss 2.363647                                        LR 0.100000    Time 0.257030    
2024-04-23 18:33:53,157 - Epoch: [127][  190/  267]    Overall Loss 2.362680    Objective Loss 2.362680                                        LR 0.100000    Time 0.256516    
2024-04-23 18:33:54,669 - Epoch: [127][  200/  267]    Overall Loss 2.361260    Objective Loss 2.361260                                        LR 0.100000    Time 0.251232    
2024-04-23 18:33:57,059 - Epoch: [127][  210/  267]    Overall Loss 2.360349    Objective Loss 2.360349                                        LR 0.100000    Time 0.250637    
2024-04-23 18:33:58,731 - Epoch: [127][  220/  267]    Overall Loss 2.360404    Objective Loss 2.360404                                        LR 0.100000    Time 0.246831    
2024-04-23 18:34:00,783 - Epoch: [127][  230/  267]    Overall Loss 2.361085    Objective Loss 2.361085                                        LR 0.100000    Time 0.245011    
2024-04-23 18:34:02,682 - Epoch: [127][  240/  267]    Overall Loss 2.361837    Objective Loss 2.361837                                        LR 0.100000    Time 0.242700    
2024-04-23 18:34:05,655 - Epoch: [127][  250/  267]    Overall Loss 2.361939    Objective Loss 2.361939                                        LR 0.100000    Time 0.244871    
2024-04-23 18:34:06,023 - Epoch: [94][  200/  296]    Overall Loss 0.873612    Objective Loss 0.873612                                        LR 0.000320    Time 0.256519    
2024-04-23 18:34:07,902 - Epoch: [127][  260/  267]    Overall Loss 2.361258    Objective Loss 2.361258                                        LR 0.100000    Time 0.244083    
2024-04-23 18:34:09,742 - Epoch: [127][  267/  267]    Overall Loss 2.361651    Objective Loss 2.361651    Top1 13.953488    Top5 46.511628    LR 0.100000    Time 0.244566    
2024-04-23 18:34:09,960 - --- validate (epoch=127)-----------
2024-04-23 18:34:09,962 - 946 samples (32 per mini-batch)
2024-04-23 18:34:14,087 - Epoch: [127][   10/   30]    Loss 2.345189    Top1 10.312500    Top5 48.437500    
2024-04-23 18:34:16,600 - Epoch: [127][   20/   30]    Loss 2.353697    Top1 10.937500    Top5 47.343750    
2024-04-23 18:34:18,990 - Epoch: [127][   30/   30]    Loss 2.350445    Top1 10.465116    Top5 47.780127    
2024-04-23 18:34:19,197 - ==> Top1: 10.465    Top5: 47.780    Loss: 2.350

2024-04-23 18:34:19,199 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 18:34:19,204 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:34:19,205 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:34:19,221 - 

2024-04-23 18:34:19,222 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:34:23,321 - Epoch: [128][   10/  267]    Overall Loss 2.375115    Objective Loss 2.375115                                        LR 0.100000    Time 0.409380    
2024-04-23 18:34:25,894 - Epoch: [128][   20/  267]    Overall Loss 2.380508    Objective Loss 2.380508                                        LR 0.100000    Time 0.333166    
2024-04-23 18:34:29,088 - Epoch: [128][   30/  267]    Overall Loss 2.376811    Objective Loss 2.376811                                        LR 0.100000    Time 0.328480    
2024-04-23 18:34:31,146 - Epoch: [94][  296/  296]    Overall Loss 0.869623    Objective Loss 0.869623    Top1 73.770492    Top5 93.442623    LR 0.000320    Time 0.258123    
2024-04-23 18:34:31,227 - Epoch: [128][   40/  267]    Overall Loss 2.370894    Objective Loss 2.370894                                        LR 0.100000    Time 0.299779    
2024-04-23 18:34:31,518 - --- validate (epoch=94)-----------
2024-04-23 18:34:31,520 - 3925 samples (32 per mini-batch)
2024-04-23 18:34:33,019 - Epoch: [128][   50/  267]    Overall Loss 2.367377    Objective Loss 2.367377                                        LR 0.100000    Time 0.275589    
2024-04-23 18:34:34,170 - Epoch: [128][   60/  267]    Overall Loss 2.370761    Objective Loss 2.370761                                        LR 0.100000    Time 0.248796    
2024-04-23 18:34:36,797 - Epoch: [128][   70/  267]    Overall Loss 2.366078    Objective Loss 2.366078                                        LR 0.100000    Time 0.250736    
2024-04-23 18:34:39,051 - Epoch: [128][   80/  267]    Overall Loss 2.364319    Objective Loss 2.364319                                        LR 0.100000    Time 0.247516    
2024-04-23 18:34:41,801 - Epoch: [128][   90/  267]    Overall Loss 2.361731    Objective Loss 2.361731                                        LR 0.100000    Time 0.250533    
2024-04-23 18:34:44,179 - Epoch: [128][  100/  267]    Overall Loss 2.358993    Objective Loss 2.358993                                        LR 0.100000    Time 0.249220    
2024-04-23 18:34:46,730 - Epoch: [128][  110/  267]    Overall Loss 2.361348    Objective Loss 2.361348                                        LR 0.100000    Time 0.249722    
2024-04-23 18:34:48,869 - Epoch: [128][  120/  267]    Overall Loss 2.360684    Objective Loss 2.360684                                        LR 0.100000    Time 0.246715    
2024-04-23 18:34:51,460 - Epoch: [128][  130/  267]    Overall Loss 2.360722    Objective Loss 2.360722                                        LR 0.100000    Time 0.247644    
2024-04-23 18:34:53,500 - Epoch: [128][  140/  267]    Overall Loss 2.361909    Objective Loss 2.361909                                        LR 0.100000    Time 0.244503    
2024-04-23 18:34:56,818 - Epoch: [128][  150/  267]    Overall Loss 2.362082    Objective Loss 2.362082                                        LR 0.100000    Time 0.250300    
2024-04-23 18:34:58,500 - Epoch: [94][  100/  123]    Loss 0.745548    Top1 76.031250    Top5 96.843750    
2024-04-23 18:34:59,024 - Epoch: [128][  160/  267]    Overall Loss 2.361560    Objective Loss 2.361560                                        LR 0.100000    Time 0.248423    
2024-04-23 18:35:02,215 - Epoch: [128][  170/  267]    Overall Loss 2.360210    Objective Loss 2.360210                                        LR 0.100000    Time 0.252554    
2024-04-23 18:35:03,696 - Epoch: [94][  123/  123]    Loss 0.742398    Top1 76.025478    Top5 96.866242    
2024-04-23 18:35:03,947 - ==> Top1: 76.025    Top5: 96.866    Loss: 0.742

2024-04-23 18:35:03,958 - ==> Best [Top1: 76.255   Top5: 96.917   Sparsity:0.00   Params: 376752 on epoch: 93]
2024-04-23 18:35:03,959 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:35:04,022 - 

2024-04-23 18:35:04,023 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:35:04,239 - Epoch: [128][  180/  267]    Overall Loss 2.360513    Objective Loss 2.360513                                        LR 0.100000    Time 0.249755    
2024-04-23 18:35:08,164 - Epoch: [128][  190/  267]    Overall Loss 2.359920    Objective Loss 2.359920                                        LR 0.100000    Time 0.257248    
2024-04-23 18:35:10,700 - Epoch: [128][  200/  267]    Overall Loss 2.362226    Objective Loss 2.362226                                        LR 0.100000    Time 0.257052    
2024-04-23 18:35:14,184 - Epoch: [128][  210/  267]    Overall Loss 2.362266    Objective Loss 2.362266                                        LR 0.100000    Time 0.261388    
2024-04-23 18:35:16,779 - Epoch: [128][  220/  267]    Overall Loss 2.364091    Objective Loss 2.364091                                        LR 0.100000    Time 0.261287    
2024-04-23 18:35:19,877 - Epoch: [128][  230/  267]    Overall Loss 2.364340    Objective Loss 2.364340                                        LR 0.100000    Time 0.263380    
2024-04-23 18:35:21,899 - Epoch: [128][  240/  267]    Overall Loss 2.364437    Objective Loss 2.364437                                        LR 0.100000    Time 0.260817    
2024-04-23 18:35:24,969 - Epoch: [128][  250/  267]    Overall Loss 2.364702    Objective Loss 2.364702                                        LR 0.100000    Time 0.262651    
2024-04-23 18:35:27,031 - Epoch: [128][  260/  267]    Overall Loss 2.363194    Objective Loss 2.363194                                        LR 0.100000    Time 0.260468    
2024-04-23 18:35:28,591 - Epoch: [128][  267/  267]    Overall Loss 2.363450    Objective Loss 2.363450    Top1 9.302326    Top5 53.488372    LR 0.100000    Time 0.259472    
2024-04-23 18:35:28,837 - --- validate (epoch=128)-----------
2024-04-23 18:35:28,839 - 946 samples (32 per mini-batch)
2024-04-23 18:35:33,016 - Epoch: [95][  100/  296]    Overall Loss 0.864619    Objective Loss 0.864619                                        LR 0.000320    Time 0.289706    
2024-04-23 18:35:33,170 - Epoch: [128][   10/   30]    Loss 2.338646    Top1 10.312500    Top5 49.062500    
2024-04-23 18:35:35,522 - Epoch: [128][   20/   30]    Loss 2.332030    Top1 10.625000    Top5 51.250000    
2024-04-23 18:35:38,449 - Epoch: [128][   30/   30]    Loss 2.336873    Top1 10.042283    Top5 51.585624    
2024-04-23 18:35:38,638 - ==> Top1: 10.042    Top5: 51.586    Loss: 2.337

2024-04-23 18:35:38,640 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 18:35:38,645 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:35:38,646 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:35:38,673 - 

2024-04-23 18:35:38,673 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:35:43,335 - Epoch: [129][   10/  267]    Overall Loss 2.374007    Objective Loss 2.374007                                        LR 0.100000    Time 0.465756    
2024-04-23 18:35:45,713 - Epoch: [129][   20/  267]    Overall Loss 2.381458    Objective Loss 2.381458                                        LR 0.100000    Time 0.351588    
2024-04-23 18:35:47,876 - Epoch: [129][   30/  267]    Overall Loss 2.374768    Objective Loss 2.374768                                        LR 0.100000    Time 0.306399    
2024-04-23 18:35:50,172 - Epoch: [129][   40/  267]    Overall Loss 2.370361    Objective Loss 2.370361                                        LR 0.100000    Time 0.287124    
2024-04-23 18:35:52,247 - Epoch: [129][   50/  267]    Overall Loss 2.367386    Objective Loss 2.367386                                        LR 0.100000    Time 0.271118    
2024-04-23 18:35:53,889 - Epoch: [129][   60/  267]    Overall Loss 2.370040    Objective Loss 2.370040                                        LR 0.100000    Time 0.253258    
2024-04-23 18:35:55,849 - Epoch: [129][   70/  267]    Overall Loss 2.369480    Objective Loss 2.369480                                        LR 0.100000    Time 0.245032    
2024-04-23 18:35:56,625 - Epoch: [95][  200/  296]    Overall Loss 0.853370    Objective Loss 0.853370                                        LR 0.000320    Time 0.262783    
2024-04-23 18:35:58,498 - Epoch: [129][   80/  267]    Overall Loss 2.371353    Objective Loss 2.371353                                        LR 0.100000    Time 0.247472    
2024-04-23 18:36:00,913 - Epoch: [129][   90/  267]    Overall Loss 2.372372    Objective Loss 2.372372                                        LR 0.100000    Time 0.246778    
2024-04-23 18:36:03,476 - Epoch: [129][  100/  267]    Overall Loss 2.371460    Objective Loss 2.371460                                        LR 0.100000    Time 0.247696    
2024-04-23 18:36:05,759 - Epoch: [129][  110/  267]    Overall Loss 2.370621    Objective Loss 2.370621                                        LR 0.100000    Time 0.245904    
2024-04-23 18:36:08,850 - Epoch: [129][  120/  267]    Overall Loss 2.367786    Objective Loss 2.367786                                        LR 0.100000    Time 0.251139    
2024-04-23 18:36:10,909 - Epoch: [129][  130/  267]    Overall Loss 2.368042    Objective Loss 2.368042                                        LR 0.100000    Time 0.247638    
2024-04-23 18:36:14,112 - Epoch: [129][  140/  267]    Overall Loss 2.369729    Objective Loss 2.369729                                        LR 0.100000    Time 0.252800    
2024-04-23 18:36:16,132 - Epoch: [129][  150/  267]    Overall Loss 2.367637    Objective Loss 2.367637                                        LR 0.100000    Time 0.249399    
2024-04-23 18:36:18,764 - Epoch: [129][  160/  267]    Overall Loss 2.369202    Objective Loss 2.369202                                        LR 0.100000    Time 0.250242    
2024-04-23 18:36:20,044 - Epoch: [95][  296/  296]    Overall Loss 0.861283    Objective Loss 0.861283    Top1 75.409836    Top5 98.360656    LR 0.000320    Time 0.256600    
2024-04-23 18:36:20,398 - Epoch: [129][  170/  267]    Overall Loss 2.369140    Objective Loss 2.369140                                        LR 0.100000    Time 0.245117    
2024-04-23 18:36:20,405 - --- validate (epoch=95)-----------
2024-04-23 18:36:20,406 - 3925 samples (32 per mini-batch)
2024-04-23 18:36:23,006 - Epoch: [129][  180/  267]    Overall Loss 2.368805    Objective Loss 2.368805                                        LR 0.100000    Time 0.245969    
2024-04-23 18:36:25,233 - Epoch: [129][  190/  267]    Overall Loss 2.368868    Objective Loss 2.368868                                        LR 0.100000    Time 0.244729    
2024-04-23 18:36:27,915 - Epoch: [129][  200/  267]    Overall Loss 2.368524    Objective Loss 2.368524                                        LR 0.100000    Time 0.245888    
2024-04-23 18:36:29,855 - Epoch: [129][  210/  267]    Overall Loss 2.368027    Objective Loss 2.368027                                        LR 0.100000    Time 0.243400    
2024-04-23 18:36:32,756 - Epoch: [129][  220/  267]    Overall Loss 2.366986    Objective Loss 2.366986                                        LR 0.100000    Time 0.245510    
2024-04-23 18:36:34,809 - Epoch: [129][  230/  267]    Overall Loss 2.367215    Objective Loss 2.367215                                        LR 0.100000    Time 0.243748    
2024-04-23 18:36:37,699 - Epoch: [129][  240/  267]    Overall Loss 2.369362    Objective Loss 2.369362                                        LR 0.100000    Time 0.245616    
2024-04-23 18:36:39,967 - Epoch: [129][  250/  267]    Overall Loss 2.370928    Objective Loss 2.370928                                        LR 0.100000    Time 0.244851    
2024-04-23 18:36:42,885 - Epoch: [129][  260/  267]    Overall Loss 2.369674    Objective Loss 2.369674                                        LR 0.100000    Time 0.246642    
2024-04-23 18:36:43,695 - Epoch: [129][  267/  267]    Overall Loss 2.368988    Objective Loss 2.368988    Top1 13.953488    Top5 48.837209    LR 0.100000    Time 0.243205    
2024-04-23 18:36:43,931 - --- validate (epoch=129)-----------
2024-04-23 18:36:43,932 - 946 samples (32 per mini-batch)
2024-04-23 18:36:47,520 - Epoch: [95][  100/  123]    Loss 0.781072    Top1 74.687500    Top5 97.062500    
2024-04-23 18:36:47,560 - Epoch: [129][   10/   30]    Loss 2.384262    Top1 7.187500    Top5 45.937500    
2024-04-23 18:36:49,825 - Epoch: [129][   20/   30]    Loss 2.367941    Top1 8.437500    Top5 47.343750    
2024-04-23 18:36:52,505 - Epoch: [129][   30/   30]    Loss 2.352678    Top1 9.830867    Top5 48.731501    
2024-04-23 18:36:52,688 - ==> Top1: 9.831    Top5: 48.732    Loss: 2.353

2024-04-23 18:36:52,690 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 18:36:52,695 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:36:52,696 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:36:52,713 - 

2024-04-23 18:36:52,714 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:36:53,177 - Epoch: [95][  123/  123]    Loss 0.782690    Top1 74.598726    Top5 96.942675    
2024-04-23 18:36:53,426 - ==> Top1: 74.599    Top5: 96.943    Loss: 0.783

2024-04-23 18:36:53,436 - ==> Best [Top1: 76.255   Top5: 96.917   Sparsity:0.00   Params: 376752 on epoch: 93]
2024-04-23 18:36:53,437 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:36:53,497 - 

2024-04-23 18:36:53,498 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:36:56,434 - Epoch: [130][   10/  267]    Overall Loss 2.333870    Objective Loss 2.333870                                        LR 0.100000    Time 0.371640    
2024-04-23 18:36:58,634 - Epoch: [130][   20/  267]    Overall Loss 2.362541    Objective Loss 2.362541                                        LR 0.100000    Time 0.295597    
2024-04-23 18:37:02,115 - Epoch: [130][   30/  267]    Overall Loss 2.383864    Objective Loss 2.383864                                        LR 0.100000    Time 0.313012    
2024-04-23 18:37:04,434 - Epoch: [130][   40/  267]    Overall Loss 2.379077    Objective Loss 2.379077                                        LR 0.100000    Time 0.292643    
2024-04-23 18:37:07,576 - Epoch: [130][   50/  267]    Overall Loss 2.385067    Objective Loss 2.385067                                        LR 0.100000    Time 0.296887    
2024-04-23 18:37:09,719 - Epoch: [130][   60/  267]    Overall Loss 2.385415    Objective Loss 2.385415                                        LR 0.100000    Time 0.283078    
2024-04-23 18:37:13,065 - Epoch: [130][   70/  267]    Overall Loss 2.379568    Objective Loss 2.379568                                        LR 0.100000    Time 0.290393    
2024-04-23 18:37:15,249 - Epoch: [130][   80/  267]    Overall Loss 2.383971    Objective Loss 2.383971                                        LR 0.100000    Time 0.281350    
2024-04-23 18:37:18,429 - Epoch: [130][   90/  267]    Overall Loss 2.381406    Objective Loss 2.381406                                        LR 0.100000    Time 0.285395    
2024-04-23 18:37:20,722 - Epoch: [130][  100/  267]    Overall Loss 2.378712    Objective Loss 2.378712                                        LR 0.100000    Time 0.279747    
2024-04-23 18:37:22,382 - Epoch: [96][  100/  296]    Overall Loss 0.820981    Objective Loss 0.820981                                        LR 0.000320    Time 0.288606    
2024-04-23 18:37:24,058 - Epoch: [130][  110/  267]    Overall Loss 2.381470    Objective Loss 2.381470                                        LR 0.100000    Time 0.284619    
2024-04-23 18:37:26,541 - Epoch: [130][  120/  267]    Overall Loss 2.376667    Objective Loss 2.376667                                        LR 0.100000    Time 0.281556    
2024-04-23 18:37:30,101 - Epoch: [130][  130/  267]    Overall Loss 2.373029    Objective Loss 2.373029                                        LR 0.100000    Time 0.287262    
2024-04-23 18:37:32,425 - Epoch: [130][  140/  267]    Overall Loss 2.373214    Objective Loss 2.373214                                        LR 0.100000    Time 0.283321    
2024-04-23 18:37:35,961 - Epoch: [130][  150/  267]    Overall Loss 2.372215    Objective Loss 2.372215                                        LR 0.100000    Time 0.287981    
2024-04-23 18:37:38,130 - Epoch: [130][  160/  267]    Overall Loss 2.373076    Objective Loss 2.373076                                        LR 0.100000    Time 0.283516    
2024-04-23 18:37:41,190 - Epoch: [130][  170/  267]    Overall Loss 2.374702    Objective Loss 2.374702                                        LR 0.100000    Time 0.284820    
2024-04-23 18:37:43,298 - Epoch: [130][  180/  267]    Overall Loss 2.374217    Objective Loss 2.374217                                        LR 0.100000    Time 0.280692    
2024-04-23 18:37:46,084 - Epoch: [130][  190/  267]    Overall Loss 2.374330    Objective Loss 2.374330                                        LR 0.100000    Time 0.280565    
2024-04-23 18:37:47,876 - Epoch: [130][  200/  267]    Overall Loss 2.375408    Objective Loss 2.375408                                        LR 0.100000    Time 0.275479    
2024-04-23 18:37:48,946 - Epoch: [96][  200/  296]    Overall Loss 0.826529    Objective Loss 0.826529                                        LR 0.000320    Time 0.277015    
2024-04-23 18:37:50,431 - Epoch: [130][  210/  267]    Overall Loss 2.374070    Objective Loss 2.374070                                        LR 0.100000    Time 0.274513    
2024-04-23 18:37:52,482 - Epoch: [130][  220/  267]    Overall Loss 2.375287    Objective Loss 2.375287                                        LR 0.100000    Time 0.271340    
2024-04-23 18:37:55,706 - Epoch: [130][  230/  267]    Overall Loss 2.373578    Objective Loss 2.373578                                        LR 0.100000    Time 0.273547    
2024-04-23 18:37:58,119 - Epoch: [130][  240/  267]    Overall Loss 2.372224    Objective Loss 2.372224                                        LR 0.100000    Time 0.272187    
2024-04-23 18:38:01,038 - Epoch: [130][  250/  267]    Overall Loss 2.373068    Objective Loss 2.373068                                        LR 0.100000    Time 0.272961    
2024-04-23 18:38:03,295 - Epoch: [130][  260/  267]    Overall Loss 2.371743    Objective Loss 2.371743                                        LR 0.100000    Time 0.271129    
2024-04-23 18:38:05,000 - Epoch: [130][  267/  267]    Overall Loss 2.371545    Objective Loss 2.371545    Top1 9.302326    Top5 41.860465    LR 0.100000    Time 0.270400    
2024-04-23 18:38:05,229 - --- validate (epoch=130)-----------
2024-04-23 18:38:05,231 - 946 samples (32 per mini-batch)
2024-04-23 18:38:09,184 - Epoch: [130][   10/   30]    Loss 2.354665    Top1 10.625000    Top5 52.500000    
2024-04-23 18:38:11,343 - Epoch: [130][   20/   30]    Loss 2.365334    Top1 10.625000    Top5 51.718750    
2024-04-23 18:38:12,743 - Epoch: [96][  296/  296]    Overall Loss 0.833644    Objective Loss 0.833644    Top1 63.934426    Top5 100.000000    LR 0.000320    Time 0.267494    
2024-04-23 18:38:12,988 - Epoch: [130][   30/   30]    Loss 2.386166    Top1 9.830867    Top5 51.374207    
2024-04-23 18:38:12,988 - --- validate (epoch=96)-----------
2024-04-23 18:38:12,989 - 3925 samples (32 per mini-batch)
2024-04-23 18:38:13,110 - ==> Top1: 9.831    Top5: 51.374    Loss: 2.386

2024-04-23 18:38:13,112 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 18:38:13,116 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:38:13,116 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:38:13,130 - 

2024-04-23 18:38:13,131 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:38:15,700 - Epoch: [131][   10/  267]    Overall Loss 2.362677    Objective Loss 2.362677                                        LR 0.100000    Time 0.256634    
2024-04-23 18:38:17,872 - Epoch: [131][   20/  267]    Overall Loss 2.367108    Objective Loss 2.367108                                        LR 0.100000    Time 0.236735    
2024-04-23 18:38:20,880 - Epoch: [131][   30/  267]    Overall Loss 2.367678    Objective Loss 2.367678                                        LR 0.100000    Time 0.258000    
2024-04-23 18:38:22,830 - Epoch: [131][   40/  267]    Overall Loss 2.364566    Objective Loss 2.364566                                        LR 0.100000    Time 0.242177    
2024-04-23 18:38:25,925 - Epoch: [131][   50/  267]    Overall Loss 2.367566    Objective Loss 2.367566                                        LR 0.100000    Time 0.255564    
2024-04-23 18:38:28,188 - Epoch: [131][   60/  267]    Overall Loss 2.369624    Objective Loss 2.369624                                        LR 0.100000    Time 0.250636    
2024-04-23 18:38:31,525 - Epoch: [131][   70/  267]    Overall Loss 2.374291    Objective Loss 2.374291                                        LR 0.100000    Time 0.262457    
2024-04-23 18:38:33,874 - Epoch: [131][   80/  267]    Overall Loss 2.379647    Objective Loss 2.379647                                        LR 0.100000    Time 0.258971    
2024-04-23 18:38:36,844 - Epoch: [131][   90/  267]    Overall Loss 2.380358    Objective Loss 2.380358                                        LR 0.100000    Time 0.263165    
2024-04-23 18:38:39,001 - Epoch: [131][  100/  267]    Overall Loss 2.380006    Objective Loss 2.380006                                        LR 0.100000    Time 0.258391    
2024-04-23 18:38:41,533 - Epoch: [96][  100/  123]    Loss 0.769341    Top1 74.812500    Top5 96.750000    
2024-04-23 18:38:42,119 - Epoch: [131][  110/  267]    Overall Loss 2.378884    Objective Loss 2.378884                                        LR 0.100000    Time 0.263212    
2024-04-23 18:38:44,254 - Epoch: [131][  120/  267]    Overall Loss 2.376609    Objective Loss 2.376609                                        LR 0.100000    Time 0.259036    
2024-04-23 18:38:47,408 - Epoch: [131][  130/  267]    Overall Loss 2.375188    Objective Loss 2.375188                                        LR 0.100000    Time 0.263350    
2024-04-23 18:38:47,989 - Epoch: [96][  123/  123]    Loss 0.773369    Top1 74.394904    Top5 96.968153    
2024-04-23 18:38:48,389 - ==> Top1: 74.395    Top5: 96.968    Loss: 0.773

2024-04-23 18:38:48,402 - ==> Best [Top1: 76.255   Top5: 96.917   Sparsity:0.00   Params: 376752 on epoch: 93]
2024-04-23 18:38:48,403 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:38:48,466 - 

2024-04-23 18:38:48,467 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:38:49,099 - Epoch: [131][  140/  267]    Overall Loss 2.374386    Objective Loss 2.374386                                        LR 0.100000    Time 0.256587    
2024-04-23 18:38:51,442 - Epoch: [131][  150/  267]    Overall Loss 2.373844    Objective Loss 2.373844                                        LR 0.100000    Time 0.255083    
2024-04-23 18:38:53,661 - Epoch: [131][  160/  267]    Overall Loss 2.372674    Objective Loss 2.372674                                        LR 0.100000    Time 0.252984    
2024-04-23 18:38:55,710 - Epoch: [131][  170/  267]    Overall Loss 2.371215    Objective Loss 2.371215                                        LR 0.100000    Time 0.250134    
2024-04-23 18:38:57,859 - Epoch: [131][  180/  267]    Overall Loss 2.370417    Objective Loss 2.370417                                        LR 0.100000    Time 0.248163    
2024-04-23 18:38:59,657 - Epoch: [131][  190/  267]    Overall Loss 2.371674    Objective Loss 2.371674                                        LR 0.100000    Time 0.244549    
2024-04-23 18:39:02,144 - Epoch: [131][  200/  267]    Overall Loss 2.371328    Objective Loss 2.371328                                        LR 0.100000    Time 0.244740    
2024-04-23 18:39:03,824 - Epoch: [131][  210/  267]    Overall Loss 2.370007    Objective Loss 2.370007                                        LR 0.100000    Time 0.241073    
2024-04-23 18:39:06,276 - Epoch: [131][  220/  267]    Overall Loss 2.370498    Objective Loss 2.370498                                        LR 0.100000    Time 0.241248    
2024-04-23 18:39:08,381 - Epoch: [131][  230/  267]    Overall Loss 2.369949    Objective Loss 2.369949                                        LR 0.100000    Time 0.239895    
2024-04-23 18:39:11,170 - Epoch: [131][  240/  267]    Overall Loss 2.369282    Objective Loss 2.369282                                        LR 0.100000    Time 0.241510    
2024-04-23 18:39:13,838 - Epoch: [131][  250/  267]    Overall Loss 2.368354    Objective Loss 2.368354                                        LR 0.100000    Time 0.242508    
2024-04-23 18:39:16,632 - Epoch: [131][  260/  267]    Overall Loss 2.366531    Objective Loss 2.366531                                        LR 0.100000    Time 0.243914    
2024-04-23 18:39:17,276 - Epoch: [97][  100/  296]    Overall Loss 0.807088    Objective Loss 0.807088                                        LR 0.000320    Time 0.287831    
2024-04-23 18:39:17,424 - Epoch: [131][  267/  267]    Overall Loss 2.366291    Objective Loss 2.366291    Top1 6.976744    Top5 55.813953    LR 0.100000    Time 0.240460    
2024-04-23 18:39:17,636 - --- validate (epoch=131)-----------
2024-04-23 18:39:17,638 - 946 samples (32 per mini-batch)
2024-04-23 18:39:21,277 - Epoch: [131][   10/   30]    Loss 2.362936    Top1 12.500000    Top5 54.062500    
2024-04-23 18:39:23,448 - Epoch: [131][   20/   30]    Loss 2.388400    Top1 9.687500    Top5 51.562500    
2024-04-23 18:39:25,763 - Epoch: [131][   30/   30]    Loss 2.400613    Top1 9.196617    Top5 50.845666    
2024-04-23 18:39:25,934 - ==> Top1: 9.197    Top5: 50.846    Loss: 2.401

2024-04-23 18:39:25,935 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 18:39:25,937 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:39:25,937 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:39:25,948 - 

2024-04-23 18:39:25,949 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:39:29,766 - Epoch: [132][   10/  267]    Overall Loss 2.373536    Objective Loss 2.373536                                        LR 0.100000    Time 0.381305    
2024-04-23 18:39:31,347 - Epoch: [132][   20/  267]    Overall Loss 2.374009    Objective Loss 2.374009                                        LR 0.100000    Time 0.269539    
2024-04-23 18:39:33,170 - Epoch: [132][   30/  267]    Overall Loss 2.360785    Objective Loss 2.360785                                        LR 0.100000    Time 0.240357    
2024-04-23 18:39:35,118 - Epoch: [132][   40/  267]    Overall Loss 2.355486    Objective Loss 2.355486                                        LR 0.100000    Time 0.228876    
2024-04-23 18:39:38,153 - Epoch: [132][   50/  267]    Overall Loss 2.353146    Objective Loss 2.353146                                        LR 0.100000    Time 0.243730    
2024-04-23 18:39:40,168 - Epoch: [132][   60/  267]    Overall Loss 2.357953    Objective Loss 2.357953                                        LR 0.100000    Time 0.236642    
2024-04-23 18:39:43,058 - Epoch: [132][   70/  267]    Overall Loss 2.357696    Objective Loss 2.357696                                        LR 0.100000    Time 0.244082    
2024-04-23 18:39:43,562 - Epoch: [97][  200/  296]    Overall Loss 0.820432    Objective Loss 0.820432                                        LR 0.000320    Time 0.275243    
2024-04-23 18:39:44,963 - Epoch: [132][   80/  267]    Overall Loss 2.356157    Objective Loss 2.356157                                        LR 0.100000    Time 0.237348    
2024-04-23 18:39:47,985 - Epoch: [132][   90/  267]    Overall Loss 2.359126    Objective Loss 2.359126                                        LR 0.100000    Time 0.244520    
2024-04-23 18:39:50,527 - Epoch: [132][  100/  267]    Overall Loss 2.358118    Objective Loss 2.358118                                        LR 0.100000    Time 0.245447    
2024-04-23 18:39:53,348 - Epoch: [132][  110/  267]    Overall Loss 2.357001    Objective Loss 2.357001                                        LR 0.100000    Time 0.248751    
2024-04-23 18:39:55,855 - Epoch: [132][  120/  267]    Overall Loss 2.362958    Objective Loss 2.362958                                        LR 0.100000    Time 0.248891    
2024-04-23 18:39:58,907 - Epoch: [132][  130/  267]    Overall Loss 2.364868    Objective Loss 2.364868                                        LR 0.100000    Time 0.253196    
2024-04-23 18:40:01,290 - Epoch: [132][  140/  267]    Overall Loss 2.365566    Objective Loss 2.365566                                        LR 0.100000    Time 0.252114    
2024-04-23 18:40:04,309 - Epoch: [132][  150/  267]    Overall Loss 2.365826    Objective Loss 2.365826                                        LR 0.100000    Time 0.255409    
2024-04-23 18:40:06,503 - Epoch: [132][  160/  267]    Overall Loss 2.368190    Objective Loss 2.368190                                        LR 0.100000    Time 0.253135    
2024-04-23 18:40:07,571 - Epoch: [97][  296/  296]    Overall Loss 0.828345    Objective Loss 0.828345    Top1 60.655738    Top5 95.081967    LR 0.000320    Time 0.267015    
2024-04-23 18:40:07,902 - --- validate (epoch=97)-----------
2024-04-23 18:40:07,903 - 3925 samples (32 per mini-batch)
2024-04-23 18:40:08,494 - Epoch: [132][  170/  267]    Overall Loss 2.365494    Objective Loss 2.365494                                        LR 0.100000    Time 0.249942    
2024-04-23 18:40:10,529 - Epoch: [132][  180/  267]    Overall Loss 2.365227    Objective Loss 2.365227                                        LR 0.100000    Time 0.247350    
2024-04-23 18:40:13,826 - Epoch: [132][  190/  267]    Overall Loss 2.366509    Objective Loss 2.366509                                        LR 0.100000    Time 0.251665    
2024-04-23 18:40:16,239 - Epoch: [132][  200/  267]    Overall Loss 2.366695    Objective Loss 2.366695                                        LR 0.100000    Time 0.251122    
2024-04-23 18:40:19,581 - Epoch: [132][  210/  267]    Overall Loss 2.367691    Objective Loss 2.367691                                        LR 0.100000    Time 0.255064    
2024-04-23 18:40:22,153 - Epoch: [132][  220/  267]    Overall Loss 2.367957    Objective Loss 2.367957                                        LR 0.100000    Time 0.255147    
2024-04-23 18:40:25,469 - Epoch: [132][  230/  267]    Overall Loss 2.369493    Objective Loss 2.369493                                        LR 0.100000    Time 0.258458    
2024-04-23 18:40:27,843 - Epoch: [132][  240/  267]    Overall Loss 2.369722    Objective Loss 2.369722                                        LR 0.100000    Time 0.257559    
2024-04-23 18:40:30,535 - Epoch: [132][  250/  267]    Overall Loss 2.368728    Objective Loss 2.368728                                        LR 0.100000    Time 0.258006    
2024-04-23 18:40:32,894 - Epoch: [132][  260/  267]    Overall Loss 2.367444    Objective Loss 2.367444                                        LR 0.100000    Time 0.257146    
2024-04-23 18:40:34,839 - Epoch: [132][  267/  267]    Overall Loss 2.365644    Objective Loss 2.365644    Top1 23.255814    Top5 62.790698    LR 0.100000    Time 0.257679    
2024-04-23 18:40:35,102 - --- validate (epoch=132)-----------
2024-04-23 18:40:35,104 - 946 samples (32 per mini-batch)
2024-04-23 18:40:37,735 - Epoch: [97][  100/  123]    Loss 0.775821    Top1 74.656250    Top5 96.718750    
2024-04-23 18:40:39,404 - Epoch: [132][   10/   30]    Loss 2.381784    Top1 10.625000    Top5 49.687500    
2024-04-23 18:40:41,921 - Epoch: [132][   20/   30]    Loss 2.380331    Top1 11.250000    Top5 49.062500    
2024-04-23 18:40:43,613 - Epoch: [97][  123/  123]    Loss 0.780497    Top1 74.777070    Top5 96.585987    
2024-04-23 18:40:43,889 - ==> Top1: 74.777    Top5: 96.586    Loss: 0.780

2024-04-23 18:40:43,900 - ==> Best [Top1: 76.255   Top5: 96.917   Sparsity:0.00   Params: 376752 on epoch: 93]
2024-04-23 18:40:43,901 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:40:43,932 - Epoch: [132][   30/   30]    Loss 2.390900    Top1 10.570825    Top5 48.731501    
2024-04-23 18:40:43,954 - 

2024-04-23 18:40:43,955 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:40:44,099 - ==> Top1: 10.571    Top5: 48.732    Loss: 2.391

2024-04-23 18:40:44,101 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 18:40:44,105 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:40:44,105 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:40:44,119 - 

2024-04-23 18:40:44,120 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:40:47,921 - Epoch: [133][   10/  267]    Overall Loss 2.365092    Objective Loss 2.365092                                        LR 0.100000    Time 0.379719    
2024-04-23 18:40:50,231 - Epoch: [133][   20/  267]    Overall Loss 2.354487    Objective Loss 2.354487                                        LR 0.100000    Time 0.305185    
2024-04-23 18:40:53,451 - Epoch: [133][   30/  267]    Overall Loss 2.350556    Objective Loss 2.350556                                        LR 0.100000    Time 0.310671    
2024-04-23 18:40:56,171 - Epoch: [133][   40/  267]    Overall Loss 2.360715    Objective Loss 2.360715                                        LR 0.100000    Time 0.300941    
2024-04-23 18:40:59,287 - Epoch: [133][   50/  267]    Overall Loss 2.365691    Objective Loss 2.365691                                        LR 0.100000    Time 0.303003    
2024-04-23 18:41:01,502 - Epoch: [133][   60/  267]    Overall Loss 2.370421    Objective Loss 2.370421                                        LR 0.100000    Time 0.289365    
2024-04-23 18:41:04,518 - Epoch: [133][   70/  267]    Overall Loss 2.370232    Objective Loss 2.370232                                        LR 0.100000    Time 0.291075    
2024-04-23 18:41:06,816 - Epoch: [133][   80/  267]    Overall Loss 2.367150    Objective Loss 2.367150                                        LR 0.100000    Time 0.283382    
2024-04-23 18:41:09,876 - Epoch: [133][   90/  267]    Overall Loss 2.366429    Objective Loss 2.366429                                        LR 0.100000    Time 0.285845    
2024-04-23 18:41:12,078 - Epoch: [133][  100/  267]    Overall Loss 2.363056    Objective Loss 2.363056                                        LR 0.100000    Time 0.279252    
2024-04-23 18:41:13,395 - Epoch: [98][  100/  296]    Overall Loss 0.859173    Objective Loss 0.859173                                        LR 0.000320    Time 0.294160    
2024-04-23 18:41:15,235 - Epoch: [133][  110/  267]    Overall Loss 2.362309    Objective Loss 2.362309                                        LR 0.100000    Time 0.282543    
2024-04-23 18:41:17,485 - Epoch: [133][  120/  267]    Overall Loss 2.363356    Objective Loss 2.363356                                        LR 0.100000    Time 0.277715    
2024-04-23 18:41:20,644 - Epoch: [133][  130/  267]    Overall Loss 2.361730    Objective Loss 2.361730                                        LR 0.100000    Time 0.280628    
2024-04-23 18:41:22,967 - Epoch: [133][  140/  267]    Overall Loss 2.362779    Objective Loss 2.362779                                        LR 0.100000    Time 0.277147    
2024-04-23 18:41:26,551 - Epoch: [133][  150/  267]    Overall Loss 2.364160    Objective Loss 2.364160                                        LR 0.100000    Time 0.282544    
2024-04-23 18:41:28,856 - Epoch: [133][  160/  267]    Overall Loss 2.362500    Objective Loss 2.362500                                        LR 0.100000    Time 0.279275    
2024-04-23 18:41:31,614 - Epoch: [133][  170/  267]    Overall Loss 2.363197    Objective Loss 2.363197                                        LR 0.100000    Time 0.279054    
2024-04-23 18:41:33,746 - Epoch: [133][  180/  267]    Overall Loss 2.363284    Objective Loss 2.363284                                        LR 0.100000    Time 0.275378    
2024-04-23 18:41:37,119 - Epoch: [133][  190/  267]    Overall Loss 2.360794    Objective Loss 2.360794                                        LR 0.100000    Time 0.278621    
2024-04-23 18:41:38,676 - Epoch: [98][  200/  296]    Overall Loss 0.847484    Objective Loss 0.847484                                        LR 0.000320    Time 0.273371    
2024-04-23 18:41:39,898 - Epoch: [133][  200/  267]    Overall Loss 2.360788    Objective Loss 2.360788                                        LR 0.100000    Time 0.278568    
2024-04-23 18:41:43,222 - Epoch: [133][  210/  267]    Overall Loss 2.360602    Objective Loss 2.360602                                        LR 0.100000    Time 0.281119    
2024-04-23 18:41:45,528 - Epoch: [133][  220/  267]    Overall Loss 2.359165    Objective Loss 2.359165                                        LR 0.100000    Time 0.278806    
2024-04-23 18:41:48,666 - Epoch: [133][  230/  267]    Overall Loss 2.359493    Objective Loss 2.359493                                        LR 0.100000    Time 0.280314    
2024-04-23 18:41:50,911 - Epoch: [133][  240/  267]    Overall Loss 2.359801    Objective Loss 2.359801                                        LR 0.100000    Time 0.277971    
2024-04-23 18:41:54,150 - Epoch: [133][  250/  267]    Overall Loss 2.359537    Objective Loss 2.359537                                        LR 0.100000    Time 0.279794    
2024-04-23 18:41:56,343 - Epoch: [133][  260/  267]    Overall Loss 2.359379    Objective Loss 2.359379                                        LR 0.100000    Time 0.277455    
2024-04-23 18:41:58,244 - Epoch: [133][  267/  267]    Overall Loss 2.359292    Objective Loss 2.359292    Top1 11.627907    Top5 46.511628    LR 0.100000    Time 0.277286    
2024-04-23 18:41:58,456 - --- validate (epoch=133)-----------
2024-04-23 18:41:58,457 - 946 samples (32 per mini-batch)
2024-04-23 18:42:02,479 - Epoch: [133][   10/   30]    Loss 2.327730    Top1 9.687500    Top5 52.500000    
2024-04-23 18:42:04,393 - Epoch: [133][   20/   30]    Loss 2.324056    Top1 10.468750    Top5 54.218750    
2024-04-23 18:42:04,664 - Epoch: [98][  296/  296]    Overall Loss 0.850672    Objective Loss 0.850672    Top1 75.409836    Top5 98.360656    LR 0.000320    Time 0.272435    
2024-04-23 18:42:04,984 - --- validate (epoch=98)-----------
2024-04-23 18:42:04,985 - 3925 samples (32 per mini-batch)
2024-04-23 18:42:06,299 - Epoch: [133][   30/   30]    Loss 2.332850    Top1 10.253700    Top5 50.951374    
2024-04-23 18:42:06,469 - ==> Top1: 10.254    Top5: 50.951    Loss: 2.333

2024-04-23 18:42:06,470 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 18:42:06,475 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:42:06,475 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:42:06,490 - 

2024-04-23 18:42:06,491 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:42:10,054 - Epoch: [134][   10/  267]    Overall Loss 2.368774    Objective Loss 2.368774                                        LR 0.100000    Time 0.355861    
2024-04-23 18:42:12,828 - Epoch: [134][   20/  267]    Overall Loss 2.385187    Objective Loss 2.385187                                        LR 0.100000    Time 0.316425    
2024-04-23 18:42:15,958 - Epoch: [134][   30/  267]    Overall Loss 2.380495    Objective Loss 2.380495                                        LR 0.100000    Time 0.315156    
2024-04-23 18:42:18,326 - Epoch: [134][   40/  267]    Overall Loss 2.365932    Objective Loss 2.365932                                        LR 0.100000    Time 0.295467    
2024-04-23 18:42:21,596 - Epoch: [134][   50/  267]    Overall Loss 2.364558    Objective Loss 2.364558                                        LR 0.100000    Time 0.301686    
2024-04-23 18:42:24,223 - Epoch: [134][   60/  267]    Overall Loss 2.361973    Objective Loss 2.361973                                        LR 0.100000    Time 0.295137    
2024-04-23 18:42:26,885 - Epoch: [134][   70/  267]    Overall Loss 2.361854    Objective Loss 2.361854                                        LR 0.100000    Time 0.290951    
2024-04-23 18:42:29,656 - Epoch: [134][   80/  267]    Overall Loss 2.366360    Objective Loss 2.366360                                        LR 0.100000    Time 0.289180    
2024-04-23 18:42:33,100 - Epoch: [134][   90/  267]    Overall Loss 2.366843    Objective Loss 2.366843                                        LR 0.100000    Time 0.295282    
2024-04-23 18:42:33,607 - Epoch: [98][  100/  123]    Loss 0.740148    Top1 76.062500    Top5 97.000000    
2024-04-23 18:42:35,860 - Epoch: [134][  100/  267]    Overall Loss 2.361253    Objective Loss 2.361253                                        LR 0.100000    Time 0.293311    
2024-04-23 18:42:39,022 - Epoch: [134][  110/  267]    Overall Loss 2.362780    Objective Loss 2.362780                                        LR 0.100000    Time 0.295369    
2024-04-23 18:42:40,303 - Epoch: [98][  123/  123]    Loss 0.737807    Top1 76.101911    Top5 96.993631    
2024-04-23 18:42:40,593 - ==> Top1: 76.102    Top5: 96.994    Loss: 0.738

2024-04-23 18:42:40,605 - ==> Best [Top1: 76.255   Top5: 96.917   Sparsity:0.00   Params: 376752 on epoch: 93]
2024-04-23 18:42:40,606 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:42:40,674 - 

2024-04-23 18:42:40,675 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:42:41,001 - Epoch: [134][  120/  267]    Overall Loss 2.366886    Objective Loss 2.366886                                        LR 0.100000    Time 0.287216    
2024-04-23 18:42:43,660 - Epoch: [134][  130/  267]    Overall Loss 2.368847    Objective Loss 2.368847                                        LR 0.100000    Time 0.285553    
2024-04-23 18:42:46,074 - Epoch: [134][  140/  267]    Overall Loss 2.370838    Objective Loss 2.370838                                        LR 0.100000    Time 0.282374    
2024-04-23 18:42:49,337 - Epoch: [134][  150/  267]    Overall Loss 2.369274    Objective Loss 2.369274                                        LR 0.100000    Time 0.285277    
2024-04-23 18:42:51,481 - Epoch: [134][  160/  267]    Overall Loss 2.368823    Objective Loss 2.368823                                        LR 0.100000    Time 0.280826    
2024-04-23 18:42:54,674 - Epoch: [134][  170/  267]    Overall Loss 2.368584    Objective Loss 2.368584                                        LR 0.100000    Time 0.283070    
2024-04-23 18:42:57,020 - Epoch: [134][  180/  267]    Overall Loss 2.365751    Objective Loss 2.365751                                        LR 0.100000    Time 0.280356    
2024-04-23 18:43:00,128 - Epoch: [134][  190/  267]    Overall Loss 2.367804    Objective Loss 2.367804                                        LR 0.100000    Time 0.281943    
2024-04-23 18:43:02,328 - Epoch: [134][  200/  267]    Overall Loss 2.368366    Objective Loss 2.368366                                        LR 0.100000    Time 0.278831    
2024-04-23 18:43:05,379 - Epoch: [134][  210/  267]    Overall Loss 2.368558    Objective Loss 2.368558                                        LR 0.100000    Time 0.280067    
2024-04-23 18:43:07,639 - Epoch: [134][  220/  267]    Overall Loss 2.367487    Objective Loss 2.367487                                        LR 0.100000    Time 0.277594    
2024-04-23 18:43:10,636 - Epoch: [99][  100/  296]    Overall Loss 0.806941    Objective Loss 0.806941                                        LR 0.000320    Time 0.299378    
2024-04-23 18:43:10,718 - Epoch: [134][  230/  267]    Overall Loss 2.366084    Objective Loss 2.366084                                        LR 0.100000    Time 0.278898    
2024-04-23 18:43:12,890 - Epoch: [134][  240/  267]    Overall Loss 2.367151    Objective Loss 2.367151                                        LR 0.100000    Time 0.276315    
2024-04-23 18:43:16,073 - Epoch: [134][  250/  267]    Overall Loss 2.367509    Objective Loss 2.367509                                        LR 0.100000    Time 0.277979    
2024-04-23 18:43:18,360 - Epoch: [134][  260/  267]    Overall Loss 2.366771    Objective Loss 2.366771                                        LR 0.100000    Time 0.276071    
2024-04-23 18:43:20,243 - Epoch: [134][  267/  267]    Overall Loss 2.366688    Objective Loss 2.366688    Top1 4.651163    Top5 58.139535    LR 0.100000    Time 0.275875    
2024-04-23 18:43:20,476 - --- validate (epoch=134)-----------
2024-04-23 18:43:20,477 - 946 samples (32 per mini-batch)
2024-04-23 18:43:24,840 - Epoch: [134][   10/   30]    Loss 2.500711    Top1 8.750000    Top5 44.687500    
2024-04-23 18:43:27,057 - Epoch: [134][   20/   30]    Loss 2.464065    Top1 8.906250    Top5 47.968750    
2024-04-23 18:43:28,901 - Epoch: [134][   30/   30]    Loss 2.469328    Top1 9.830867    Top5 47.674419    
2024-04-23 18:43:29,021 - ==> Top1: 9.831    Top5: 47.674    Loss: 2.469

2024-04-23 18:43:29,023 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 18:43:29,027 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:43:29,027 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:43:29,041 - 

2024-04-23 18:43:29,042 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:43:32,605 - Epoch: [135][   10/  267]    Overall Loss 2.323423    Objective Loss 2.323423                                        LR 0.100000    Time 0.355878    
2024-04-23 18:43:34,971 - Epoch: [135][   20/  267]    Overall Loss 2.347242    Objective Loss 2.347242                                        LR 0.100000    Time 0.296081    
2024-04-23 18:43:35,798 - Epoch: [99][  200/  296]    Overall Loss 0.817410    Objective Loss 0.817410                                        LR 0.000320    Time 0.275387    
2024-04-23 18:43:38,135 - Epoch: [135][   30/  267]    Overall Loss 2.359596    Objective Loss 2.359596                                        LR 0.100000    Time 0.302715    
2024-04-23 18:43:40,554 - Epoch: [135][   40/  267]    Overall Loss 2.362785    Objective Loss 2.362785                                        LR 0.100000    Time 0.287427    
2024-04-23 18:43:43,735 - Epoch: [135][   50/  267]    Overall Loss 2.365276    Objective Loss 2.365276                                        LR 0.100000    Time 0.293496    
2024-04-23 18:43:46,067 - Epoch: [135][   60/  267]    Overall Loss 2.371154    Objective Loss 2.371154                                        LR 0.100000    Time 0.283398    
2024-04-23 18:43:48,968 - Epoch: [135][   70/  267]    Overall Loss 2.376293    Objective Loss 2.376293                                        LR 0.100000    Time 0.284306    
2024-04-23 18:43:51,788 - Epoch: [135][   80/  267]    Overall Loss 2.373326    Objective Loss 2.373326                                        LR 0.100000    Time 0.283980    
2024-04-23 18:43:54,304 - Epoch: [135][   90/  267]    Overall Loss 2.368706    Objective Loss 2.368706                                        LR 0.100000    Time 0.280335    
2024-04-23 18:43:56,842 - Epoch: [135][  100/  267]    Overall Loss 2.373168    Objective Loss 2.373168                                        LR 0.100000    Time 0.277648    
2024-04-23 18:43:59,238 - Epoch: [135][  110/  267]    Overall Loss 2.370941    Objective Loss 2.370941                                        LR 0.100000    Time 0.274158    
2024-04-23 18:44:01,356 - Epoch: [99][  296/  296]    Overall Loss 0.822812    Objective Loss 0.822812    Top1 68.852459    Top5 95.081967    LR 0.000320    Time 0.272347    
2024-04-23 18:44:01,684 - --- validate (epoch=99)-----------
2024-04-23 18:44:01,685 - 3925 samples (32 per mini-batch)
2024-04-23 18:44:01,771 - Epoch: [135][  120/  267]    Overall Loss 2.371314    Objective Loss 2.371314                                        LR 0.100000    Time 0.272389    
2024-04-23 18:44:04,101 - Epoch: [135][  130/  267]    Overall Loss 2.371152    Objective Loss 2.371152                                        LR 0.100000    Time 0.269338    
2024-04-23 18:44:06,239 - Epoch: [135][  140/  267]    Overall Loss 2.371822    Objective Loss 2.371822                                        LR 0.100000    Time 0.265348    
2024-04-23 18:44:09,977 - Epoch: [135][  150/  267]    Overall Loss 2.371213    Objective Loss 2.371213                                        LR 0.100000    Time 0.272558    
2024-04-23 18:44:12,562 - Epoch: [135][  160/  267]    Overall Loss 2.370889    Objective Loss 2.370889                                        LR 0.100000    Time 0.271652    
2024-04-23 18:44:16,382 - Epoch: [135][  170/  267]    Overall Loss 2.372215    Objective Loss 2.372215                                        LR 0.100000    Time 0.278125    
2024-04-23 18:44:19,022 - Epoch: [135][  180/  267]    Overall Loss 2.371727    Objective Loss 2.371727                                        LR 0.100000    Time 0.277324    
2024-04-23 18:44:23,209 - Epoch: [135][  190/  267]    Overall Loss 2.371000    Objective Loss 2.371000                                        LR 0.100000    Time 0.284743    
2024-04-23 18:44:26,150 - Epoch: [135][  200/  267]    Overall Loss 2.370341    Objective Loss 2.370341                                        LR 0.100000    Time 0.285198    
2024-04-23 18:44:29,903 - Epoch: [135][  210/  267]    Overall Loss 2.370825    Objective Loss 2.370825                                        LR 0.100000    Time 0.289471    
2024-04-23 18:44:32,532 - Epoch: [135][  220/  267]    Overall Loss 2.371804    Objective Loss 2.371804                                        LR 0.100000    Time 0.288250    
2024-04-23 18:44:36,061 - Epoch: [135][  230/  267]    Overall Loss 2.371598    Objective Loss 2.371598                                        LR 0.100000    Time 0.291044    
2024-04-23 18:44:36,836 - Epoch: [99][  100/  123]    Loss 0.778868    Top1 74.875000    Top5 96.468750    
2024-04-23 18:44:38,969 - Epoch: [135][  240/  267]    Overall Loss 2.369671    Objective Loss 2.369671                                        LR 0.100000    Time 0.291020    
2024-04-23 18:44:42,319 - Epoch: [135][  250/  267]    Overall Loss 2.370115    Objective Loss 2.370115                                        LR 0.100000    Time 0.292767    
2024-04-23 18:44:43,915 - Epoch: [99][  123/  123]    Loss 0.777403    Top1 74.929936    Top5 96.458599    
2024-04-23 18:44:44,215 - ==> Top1: 74.930    Top5: 96.459    Loss: 0.777

2024-04-23 18:44:44,223 - ==> Best [Top1: 76.255   Top5: 96.917   Sparsity:0.00   Params: 376752 on epoch: 93]
2024-04-23 18:44:44,224 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:44:44,287 - 

2024-04-23 18:44:44,289 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:44:44,399 - Epoch: [135][  260/  267]    Overall Loss 2.368515    Objective Loss 2.368515                                        LR 0.100000    Time 0.289493    
2024-04-23 18:44:46,187 - Epoch: [135][  267/  267]    Overall Loss 2.369056    Objective Loss 2.369056    Top1 4.651163    Top5 44.186047    LR 0.100000    Time 0.288589    
2024-04-23 18:44:46,462 - --- validate (epoch=135)-----------
2024-04-23 18:44:46,463 - 946 samples (32 per mini-batch)
2024-04-23 18:44:50,809 - Epoch: [135][   10/   30]    Loss 2.436557    Top1 10.000000    Top5 51.562500    
2024-04-23 18:44:53,256 - Epoch: [135][   20/   30]    Loss 2.448654    Top1 8.906250    Top5 50.625000    
2024-04-23 18:44:56,790 - Epoch: [135][   30/   30]    Loss 2.441125    Top1 9.196617    Top5 49.471459    
2024-04-23 18:44:57,017 - ==> Top1: 9.197    Top5: 49.471    Loss: 2.441

2024-04-23 18:44:57,020 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 18:44:57,027 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:44:57,028 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:44:57,053 - 

2024-04-23 18:44:57,055 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:45:01,651 - Epoch: [136][   10/  267]    Overall Loss 2.386208    Objective Loss 2.386208                                        LR 0.100000    Time 0.459230    
2024-04-23 18:45:04,368 - Epoch: [136][   20/  267]    Overall Loss 2.412739    Objective Loss 2.412739                                        LR 0.100000    Time 0.365315    
2024-04-23 18:45:07,749 - Epoch: [136][   30/  267]    Overall Loss 2.412721    Objective Loss 2.412721                                        LR 0.100000    Time 0.356133    
2024-04-23 18:45:10,559 - Epoch: [136][   40/  267]    Overall Loss 2.394078    Objective Loss 2.394078                                        LR 0.100000    Time 0.337247    
2024-04-23 18:45:14,222 - Epoch: [100][  100/  296]    Overall Loss 0.807473    Objective Loss 0.807473                                        LR 0.000080    Time 0.299082    
2024-04-23 18:45:14,240 - Epoch: [136][   50/  267]    Overall Loss 2.388056    Objective Loss 2.388056                                        LR 0.100000    Time 0.343362    
2024-04-23 18:45:16,598 - Epoch: [136][   60/  267]    Overall Loss 2.383250    Objective Loss 2.383250                                        LR 0.100000    Time 0.325403    
2024-04-23 18:45:19,655 - Epoch: [136][   70/  267]    Overall Loss 2.377715    Objective Loss 2.377715                                        LR 0.100000    Time 0.322549    
2024-04-23 18:45:21,974 - Epoch: [136][   80/  267]    Overall Loss 2.380929    Objective Loss 2.380929                                        LR 0.100000    Time 0.311173    
2024-04-23 18:45:25,024 - Epoch: [136][   90/  267]    Overall Loss 2.379001    Objective Loss 2.379001                                        LR 0.100000    Time 0.310450    
2024-04-23 18:45:27,513 - Epoch: [136][  100/  267]    Overall Loss 2.377685    Objective Loss 2.377685                                        LR 0.100000    Time 0.304265    
2024-04-23 18:45:30,562 - Epoch: [136][  110/  267]    Overall Loss 2.378558    Objective Loss 2.378558                                        LR 0.100000    Time 0.304294    
2024-04-23 18:45:32,821 - Epoch: [136][  120/  267]    Overall Loss 2.376493    Objective Loss 2.376493                                        LR 0.100000    Time 0.297736    
2024-04-23 18:45:34,795 - Epoch: [136][  130/  267]    Overall Loss 2.374372    Objective Loss 2.374372                                        LR 0.100000    Time 0.289997    
2024-04-23 18:45:36,994 - Epoch: [136][  140/  267]    Overall Loss 2.373414    Objective Loss 2.373414                                        LR 0.100000    Time 0.284971    
2024-04-23 18:45:39,568 - Epoch: [136][  150/  267]    Overall Loss 2.373486    Objective Loss 2.373486                                        LR 0.100000    Time 0.283102    
2024-04-23 18:45:41,629 - Epoch: [100][  200/  296]    Overall Loss 0.795296    Objective Loss 0.795296                                        LR 0.000080    Time 0.286454    
2024-04-23 18:45:42,543 - Epoch: [136][  160/  267]    Overall Loss 2.374019    Objective Loss 2.374019                                        LR 0.100000    Time 0.283981    
2024-04-23 18:45:45,221 - Epoch: [136][  170/  267]    Overall Loss 2.374670    Objective Loss 2.374670                                        LR 0.100000    Time 0.283012    
2024-04-23 18:45:47,835 - Epoch: [136][  180/  267]    Overall Loss 2.374370    Objective Loss 2.374370                                        LR 0.100000    Time 0.281795    
2024-04-23 18:45:51,092 - Epoch: [136][  190/  267]    Overall Loss 2.374632    Objective Loss 2.374632                                        LR 0.100000    Time 0.284088    
2024-04-23 18:45:53,664 - Epoch: [136][  200/  267]    Overall Loss 2.377269    Objective Loss 2.377269                                        LR 0.100000    Time 0.282725    
2024-04-23 18:45:56,748 - Epoch: [136][  210/  267]    Overall Loss 2.375449    Objective Loss 2.375449                                        LR 0.100000    Time 0.283926    
2024-04-23 18:45:59,210 - Epoch: [136][  220/  267]    Overall Loss 2.374026    Objective Loss 2.374026                                        LR 0.100000    Time 0.282197    
2024-04-23 18:46:02,103 - Epoch: [136][  230/  267]    Overall Loss 2.374007    Objective Loss 2.374007                                        LR 0.100000    Time 0.282492    
2024-04-23 18:46:05,011 - Epoch: [136][  240/  267]    Overall Loss 2.373890    Objective Loss 2.373890                                        LR 0.100000    Time 0.282818    
2024-04-23 18:46:07,245 - Epoch: [136][  250/  267]    Overall Loss 2.373545    Objective Loss 2.373545                                        LR 0.100000    Time 0.280419    
2024-04-23 18:46:08,618 - Epoch: [100][  296/  296]    Overall Loss 0.792820    Objective Loss 0.792820    Top1 77.049180    Top5 96.721311    LR 0.000080    Time 0.284657    
2024-04-23 18:46:08,937 - --- validate (epoch=100)-----------
2024-04-23 18:46:08,938 - 3925 samples (32 per mini-batch)
2024-04-23 18:46:09,447 - Epoch: [136][  260/  267]    Overall Loss 2.372768    Objective Loss 2.372768                                        LR 0.100000    Time 0.278090    
2024-04-23 18:46:10,453 - Epoch: [136][  267/  267]    Overall Loss 2.371151    Objective Loss 2.371151    Top1 9.302326    Top5 55.813953    LR 0.100000    Time 0.274556    
2024-04-23 18:46:10,713 - --- validate (epoch=136)-----------
2024-04-23 18:46:10,715 - 946 samples (32 per mini-batch)
2024-04-23 18:46:13,794 - Epoch: [136][   10/   30]    Loss 2.376691    Top1 10.000000    Top5 51.875000    
2024-04-23 18:46:16,042 - Epoch: [136][   20/   30]    Loss 2.369061    Top1 10.156250    Top5 51.250000    
2024-04-23 18:46:18,891 - Epoch: [136][   30/   30]    Loss 2.369344    Top1 9.830867    Top5 51.479915    
2024-04-23 18:46:19,177 - ==> Top1: 9.831    Top5: 51.480    Loss: 2.369

2024-04-23 18:46:19,179 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 18:46:19,188 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:46:19,189 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:46:19,212 - 

2024-04-23 18:46:19,214 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:46:23,913 - Epoch: [137][   10/  267]    Overall Loss 2.367943    Objective Loss 2.367943                                        LR 0.100000    Time 0.469234    
2024-04-23 18:46:26,596 - Epoch: [137][   20/  267]    Overall Loss 2.380816    Objective Loss 2.380816                                        LR 0.100000    Time 0.368588    
2024-04-23 18:46:29,257 - Epoch: [137][   30/  267]    Overall Loss 2.368950    Objective Loss 2.368950                                        LR 0.100000    Time 0.334336    
2024-04-23 18:46:32,212 - Epoch: [137][   40/  267]    Overall Loss 2.365887    Objective Loss 2.365887                                        LR 0.100000    Time 0.324521    
2024-04-23 18:46:34,138 - Epoch: [100][  100/  123]    Loss 0.679310    Top1 77.750000    Top5 97.281250    
2024-04-23 18:46:34,639 - Epoch: [137][   50/  267]    Overall Loss 2.361784    Objective Loss 2.361784                                        LR 0.100000    Time 0.308092    
2024-04-23 18:46:38,237 - Epoch: [137][   60/  267]    Overall Loss 2.372165    Objective Loss 2.372165                                        LR 0.100000    Time 0.316650    
2024-04-23 18:46:39,012 - Epoch: [100][  123/  123]    Loss 0.683883    Top1 77.605096    Top5 97.452229    
2024-04-23 18:46:39,282 - ==> Top1: 77.605    Top5: 97.452    Loss: 0.684

2024-04-23 18:46:39,293 - ==> Best [Top1: 77.605   Top5: 97.452   Sparsity:0.00   Params: 376752 on epoch: 100]
2024-04-23 18:46:39,294 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:46:39,361 - 

2024-04-23 18:46:39,362 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:46:40,115 - Epoch: [137][   70/  267]    Overall Loss 2.369187    Objective Loss 2.369187                                        LR 0.100000    Time 0.298198    
2024-04-23 18:46:43,735 - Epoch: [137][   80/  267]    Overall Loss 2.368712    Objective Loss 2.368712                                        LR 0.100000    Time 0.306138    
2024-04-23 18:46:45,977 - Epoch: [137][   90/  267]    Overall Loss 2.367091    Objective Loss 2.367091                                        LR 0.100000    Time 0.296987    
2024-04-23 18:46:49,690 - Epoch: [137][  100/  267]    Overall Loss 2.366710    Objective Loss 2.366710                                        LR 0.100000    Time 0.304390    
2024-04-23 18:46:52,474 - Epoch: [137][  110/  267]    Overall Loss 2.365680    Objective Loss 2.365680                                        LR 0.100000    Time 0.301993    
2024-04-23 18:46:56,121 - Epoch: [137][  120/  267]    Overall Loss 2.368560    Objective Loss 2.368560                                        LR 0.100000    Time 0.307192    
2024-04-23 18:46:58,644 - Epoch: [137][  130/  267]    Overall Loss 2.369465    Objective Loss 2.369465                                        LR 0.100000    Time 0.302937    
2024-04-23 18:47:02,054 - Epoch: [137][  140/  267]    Overall Loss 2.366206    Objective Loss 2.366206                                        LR 0.100000    Time 0.305636    
2024-04-23 18:47:03,801 - Epoch: [101][  100/  296]    Overall Loss 0.773570    Objective Loss 0.773570                                        LR 0.000080    Time 0.244166    
2024-04-23 18:47:04,240 - Epoch: [137][  150/  267]    Overall Loss 2.370367    Objective Loss 2.370367                                        LR 0.100000    Time 0.299814    
2024-04-23 18:47:07,444 - Epoch: [137][  160/  267]    Overall Loss 2.368416    Objective Loss 2.368416                                        LR 0.100000    Time 0.301081    
2024-04-23 18:47:09,720 - Epoch: [137][  170/  267]    Overall Loss 2.368773    Objective Loss 2.368773                                        LR 0.100000    Time 0.296743    
2024-04-23 18:47:12,623 - Epoch: [137][  180/  267]    Overall Loss 2.367901    Objective Loss 2.367901                                        LR 0.100000    Time 0.296367    
2024-04-23 18:47:14,549 - Epoch: [137][  190/  267]    Overall Loss 2.367130    Objective Loss 2.367130                                        LR 0.100000    Time 0.290891    
2024-04-23 18:47:17,269 - Epoch: [137][  200/  267]    Overall Loss 2.367292    Objective Loss 2.367292                                        LR 0.100000    Time 0.289930    
2024-04-23 18:47:19,314 - Epoch: [137][  210/  267]    Overall Loss 2.367681    Objective Loss 2.367681                                        LR 0.100000    Time 0.285848    
2024-04-23 18:47:21,960 - Epoch: [137][  220/  267]    Overall Loss 2.367012    Objective Loss 2.367012                                        LR 0.100000    Time 0.284869    
2024-04-23 18:47:24,063 - Epoch: [137][  230/  267]    Overall Loss 2.368941    Objective Loss 2.368941                                        LR 0.100000    Time 0.281612    
2024-04-23 18:47:26,551 - Epoch: [137][  240/  267]    Overall Loss 2.369553    Objective Loss 2.369553                                        LR 0.100000    Time 0.280232    
2024-04-23 18:47:28,486 - Epoch: [101][  200/  296]    Overall Loss 0.773212    Objective Loss 0.773212                                        LR 0.000080    Time 0.245396    
2024-04-23 18:47:28,554 - Epoch: [137][  250/  267]    Overall Loss 2.368980    Objective Loss 2.368980                                        LR 0.100000    Time 0.277022    
2024-04-23 18:47:31,110 - Epoch: [137][  260/  267]    Overall Loss 2.366963    Objective Loss 2.366963                                        LR 0.100000    Time 0.276186    
2024-04-23 18:47:32,241 - Epoch: [137][  267/  267]    Overall Loss 2.366422    Objective Loss 2.366422    Top1 6.976744    Top5 44.186047    LR 0.100000    Time 0.273173    
2024-04-23 18:47:32,498 - --- validate (epoch=137)-----------
2024-04-23 18:47:32,500 - 946 samples (32 per mini-batch)
2024-04-23 18:47:36,828 - Epoch: [137][   10/   30]    Loss 2.350783    Top1 12.187500    Top5 50.937500    
2024-04-23 18:47:39,355 - Epoch: [137][   20/   30]    Loss 2.355739    Top1 10.468750    Top5 50.468750    
2024-04-23 18:47:42,432 - Epoch: [137][   30/   30]    Loss 2.352658    Top1 10.465116    Top5 50.739958    
2024-04-23 18:47:42,668 - ==> Top1: 10.465    Top5: 50.740    Loss: 2.353

2024-04-23 18:47:42,672 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 18:47:42,679 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:47:42,680 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:47:42,700 - 

2024-04-23 18:47:42,702 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:47:46,686 - Epoch: [138][   10/  267]    Overall Loss 2.309874    Objective Loss 2.309874                                        LR 0.100000    Time 0.397977    
2024-04-23 18:47:48,811 - Epoch: [101][  296/  296]    Overall Loss 0.774156    Objective Loss 0.774156    Top1 60.655738    Top5 90.163934    LR 0.000080    Time 0.234401    
2024-04-23 18:47:49,167 - --- validate (epoch=101)-----------
2024-04-23 18:47:49,169 - 3925 samples (32 per mini-batch)
2024-04-23 18:47:49,280 - Epoch: [138][   20/  267]    Overall Loss 2.326803    Objective Loss 2.326803                                        LR 0.100000    Time 0.328536    
2024-04-23 18:47:53,778 - Epoch: [138][   30/  267]    Overall Loss 2.340535    Objective Loss 2.340535                                        LR 0.100000    Time 0.368854    
2024-04-23 18:47:56,752 - Epoch: [138][   40/  267]    Overall Loss 2.350621    Objective Loss 2.350621                                        LR 0.100000    Time 0.350903    
2024-04-23 18:48:00,420 - Epoch: [138][   50/  267]    Overall Loss 2.345237    Objective Loss 2.345237                                        LR 0.100000    Time 0.354035    
2024-04-23 18:48:03,221 - Epoch: [138][   60/  267]    Overall Loss 2.344041    Objective Loss 2.344041                                        LR 0.100000    Time 0.341660    
2024-04-23 18:48:06,659 - Epoch: [138][   70/  267]    Overall Loss 2.348429    Objective Loss 2.348429                                        LR 0.100000    Time 0.341923    
2024-04-23 18:48:09,327 - Epoch: [138][   80/  267]    Overall Loss 2.351348    Objective Loss 2.351348                                        LR 0.100000    Time 0.332479    
2024-04-23 18:48:12,352 - Epoch: [138][   90/  267]    Overall Loss 2.354592    Objective Loss 2.354592                                        LR 0.100000    Time 0.329113    
2024-04-23 18:48:14,603 - Epoch: [138][  100/  267]    Overall Loss 2.357988    Objective Loss 2.357988                                        LR 0.100000    Time 0.318674    
2024-04-23 18:48:17,469 - Epoch: [138][  110/  267]    Overall Loss 2.360501    Objective Loss 2.360501                                        LR 0.100000    Time 0.315727    
2024-04-23 18:48:19,735 - Epoch: [138][  120/  267]    Overall Loss 2.360731    Objective Loss 2.360731                                        LR 0.100000    Time 0.308272    
2024-04-23 18:48:21,209 - Epoch: [101][  100/  123]    Loss 0.650364    Top1 78.062500    Top5 97.250000    
2024-04-23 18:48:22,645 - Epoch: [138][  130/  267]    Overall Loss 2.358634    Objective Loss 2.358634                                        LR 0.100000    Time 0.306910    
2024-04-23 18:48:24,382 - Epoch: [138][  140/  267]    Overall Loss 2.358883    Objective Loss 2.358883                                        LR 0.100000    Time 0.297377    
2024-04-23 18:48:26,671 - Epoch: [101][  123/  123]    Loss 0.679201    Top1 77.197452    Top5 97.299363    
2024-04-23 18:48:26,927 - ==> Top1: 77.197    Top5: 97.299    Loss: 0.679

2024-04-23 18:48:26,938 - ==> Best [Top1: 77.605   Top5: 97.452   Sparsity:0.00   Params: 376752 on epoch: 100]
2024-04-23 18:48:26,939 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:48:27,005 - 

2024-04-23 18:48:27,007 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:48:27,062 - Epoch: [138][  150/  267]    Overall Loss 2.358966    Objective Loss 2.358966                                        LR 0.100000    Time 0.295394    
2024-04-23 18:48:28,745 - Epoch: [138][  160/  267]    Overall Loss 2.363860    Objective Loss 2.363860                                        LR 0.100000    Time 0.287428    
2024-04-23 18:48:31,159 - Epoch: [138][  170/  267]    Overall Loss 2.365967    Objective Loss 2.365967                                        LR 0.100000    Time 0.284699    
2024-04-23 18:48:34,130 - Epoch: [138][  180/  267]    Overall Loss 2.369457    Objective Loss 2.369457                                        LR 0.100000    Time 0.285374    
2024-04-23 18:48:36,283 - Epoch: [138][  190/  267]    Overall Loss 2.369647    Objective Loss 2.369647                                        LR 0.100000    Time 0.281669    
2024-04-23 18:48:39,268 - Epoch: [138][  200/  267]    Overall Loss 2.370079    Objective Loss 2.370079                                        LR 0.100000    Time 0.282494    
2024-04-23 18:48:41,478 - Epoch: [138][  210/  267]    Overall Loss 2.371730    Objective Loss 2.371730                                        LR 0.100000    Time 0.279552    
2024-04-23 18:48:44,426 - Epoch: [138][  220/  267]    Overall Loss 2.370591    Objective Loss 2.370591                                        LR 0.100000    Time 0.280218    
2024-04-23 18:48:46,670 - Epoch: [138][  230/  267]    Overall Loss 2.369223    Objective Loss 2.369223                                        LR 0.100000    Time 0.277779    
2024-04-23 18:48:50,108 - Epoch: [138][  240/  267]    Overall Loss 2.370898    Objective Loss 2.370898                                        LR 0.100000    Time 0.280518    
2024-04-23 18:48:52,314 - Epoch: [138][  250/  267]    Overall Loss 2.368948    Objective Loss 2.368948                                        LR 0.100000    Time 0.278109    
2024-04-23 18:48:55,348 - Epoch: [102][  100/  296]    Overall Loss 0.803600    Objective Loss 0.803600                                        LR 0.000080    Time 0.283160    
2024-04-23 18:48:55,360 - Epoch: [138][  260/  267]    Overall Loss 2.368905    Objective Loss 2.368905                                        LR 0.100000    Time 0.279118    
2024-04-23 18:48:56,119 - Epoch: [138][  267/  267]    Overall Loss 2.368775    Objective Loss 2.368775    Top1 9.302326    Top5 51.162791    LR 0.100000    Time 0.274632    
2024-04-23 18:48:56,342 - --- validate (epoch=138)-----------
2024-04-23 18:48:56,343 - 946 samples (32 per mini-batch)
2024-04-23 18:49:01,210 - Epoch: [138][   10/   30]    Loss 2.415681    Top1 7.500000    Top5 48.125000    
2024-04-23 18:49:03,751 - Epoch: [138][   20/   30]    Loss 2.405684    Top1 8.750000    Top5 50.156250    
2024-04-23 18:49:06,453 - Epoch: [138][   30/   30]    Loss 2.425995    Top1 8.456660    Top5 49.682875    
2024-04-23 18:49:06,779 - ==> Top1: 8.457    Top5: 49.683    Loss: 2.426

2024-04-23 18:49:06,782 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 18:49:06,789 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:49:06,790 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:49:06,816 - 

2024-04-23 18:49:06,818 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:49:11,952 - Epoch: [139][   10/  267]    Overall Loss 2.396387    Objective Loss 2.396387                                        LR 0.100000    Time 0.512914    
2024-04-23 18:49:14,786 - Epoch: [139][   20/  267]    Overall Loss 2.390819    Objective Loss 2.390819                                        LR 0.100000    Time 0.397931    
2024-04-23 18:49:17,540 - Epoch: [139][   30/  267]    Overall Loss 2.362847    Objective Loss 2.362847                                        LR 0.100000    Time 0.356983    
2024-04-23 18:49:20,009 - Epoch: [139][   40/  267]    Overall Loss 2.356140    Objective Loss 2.356140                                        LR 0.100000    Time 0.329348    
2024-04-23 18:49:22,680 - Epoch: [102][  200/  296]    Overall Loss 0.772116    Objective Loss 0.772116                                        LR 0.000080    Time 0.278125    
2024-04-23 18:49:23,421 - Epoch: [139][   50/  267]    Overall Loss 2.354882    Objective Loss 2.354882                                        LR 0.100000    Time 0.331597    
2024-04-23 18:49:25,620 - Epoch: [139][   60/  267]    Overall Loss 2.353528    Objective Loss 2.353528                                        LR 0.100000    Time 0.312907    
2024-04-23 18:49:29,304 - Epoch: [139][   70/  267]    Overall Loss 2.355197    Objective Loss 2.355197                                        LR 0.100000    Time 0.320781    
2024-04-23 18:49:31,593 - Epoch: [139][   80/  267]    Overall Loss 2.361195    Objective Loss 2.361195                                        LR 0.100000    Time 0.309265    
2024-04-23 18:49:34,033 - Epoch: [139][   90/  267]    Overall Loss 2.364106    Objective Loss 2.364106                                        LR 0.100000    Time 0.301969    
2024-04-23 18:49:36,100 - Epoch: [139][  100/  267]    Overall Loss 2.366186    Objective Loss 2.366186                                        LR 0.100000    Time 0.292420    
2024-04-23 18:49:39,271 - Epoch: [139][  110/  267]    Overall Loss 2.370510    Objective Loss 2.370510                                        LR 0.100000    Time 0.294634    
2024-04-23 18:49:41,343 - Epoch: [139][  120/  267]    Overall Loss 2.373905    Objective Loss 2.373905                                        LR 0.100000    Time 0.287318    
2024-04-23 18:49:44,303 - Epoch: [139][  130/  267]    Overall Loss 2.373250    Objective Loss 2.373250                                        LR 0.100000    Time 0.287962    
2024-04-23 18:49:46,409 - Epoch: [139][  140/  267]    Overall Loss 2.373536    Objective Loss 2.373536                                        LR 0.100000    Time 0.282410    
2024-04-23 18:49:47,576 - Epoch: [102][  296/  296]    Overall Loss 0.776093    Objective Loss 0.776093    Top1 80.327869    Top5 98.360656    LR 0.000080    Time 0.271960    
2024-04-23 18:49:47,975 - --- validate (epoch=102)-----------
2024-04-23 18:49:47,976 - 3925 samples (32 per mini-batch)
2024-04-23 18:49:49,184 - Epoch: [139][  150/  267]    Overall Loss 2.373080    Objective Loss 2.373080                                        LR 0.100000    Time 0.282059    
2024-04-23 18:49:51,987 - Epoch: [139][  160/  267]    Overall Loss 2.373635    Objective Loss 2.373635                                        LR 0.100000    Time 0.281927    
2024-04-23 18:49:55,374 - Epoch: [139][  170/  267]    Overall Loss 2.370694    Objective Loss 2.370694                                        LR 0.100000    Time 0.285246    
2024-04-23 18:49:57,734 - Epoch: [139][  180/  267]    Overall Loss 2.371378    Objective Loss 2.371378                                        LR 0.100000    Time 0.282489    
2024-04-23 18:50:01,148 - Epoch: [139][  190/  267]    Overall Loss 2.370899    Objective Loss 2.370899                                        LR 0.100000    Time 0.285573    
2024-04-23 18:50:03,461 - Epoch: [139][  200/  267]    Overall Loss 2.370308    Objective Loss 2.370308                                        LR 0.100000    Time 0.282847    
2024-04-23 18:50:06,719 - Epoch: [139][  210/  267]    Overall Loss 2.369797    Objective Loss 2.369797                                        LR 0.100000    Time 0.284875    
2024-04-23 18:50:09,103 - Epoch: [139][  220/  267]    Overall Loss 2.368541    Objective Loss 2.368541                                        LR 0.100000    Time 0.282749    
2024-04-23 18:50:12,437 - Epoch: [139][  230/  267]    Overall Loss 2.366538    Objective Loss 2.366538                                        LR 0.100000    Time 0.284935    
2024-04-23 18:50:14,868 - Epoch: [139][  240/  267]    Overall Loss 2.368048    Objective Loss 2.368048                                        LR 0.100000    Time 0.283179    
2024-04-23 18:50:18,393 - Epoch: [139][  250/  267]    Overall Loss 2.367340    Objective Loss 2.367340                                        LR 0.100000    Time 0.285938    
2024-04-23 18:50:19,947 - Epoch: [102][  100/  123]    Loss 0.681034    Top1 77.656250    Top5 97.312500    
2024-04-23 18:50:20,766 - Epoch: [139][  260/  267]    Overall Loss 2.366864    Objective Loss 2.366864                                        LR 0.100000    Time 0.284055    
2024-04-23 18:50:22,712 - Epoch: [139][  267/  267]    Overall Loss 2.367474    Objective Loss 2.367474    Top1 11.627907    Top5 53.488372    LR 0.100000    Time 0.283888    
2024-04-23 18:50:22,939 - --- validate (epoch=139)-----------
2024-04-23 18:50:22,941 - 946 samples (32 per mini-batch)
2024-04-23 18:50:26,125 - Epoch: [102][  123/  123]    Loss 0.670281    Top1 77.987261    Top5 97.375796    
2024-04-23 18:50:26,401 - ==> Top1: 77.987    Top5: 97.376    Loss: 0.670

2024-04-23 18:50:26,415 - ==> Best [Top1: 77.987   Top5: 97.376   Sparsity:0.00   Params: 376752 on epoch: 102]
2024-04-23 18:50:26,416 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:50:26,493 - 

2024-04-23 18:50:26,494 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:50:26,827 - Epoch: [139][   10/   30]    Loss 2.387421    Top1 10.625000    Top5 50.625000    
2024-04-23 18:50:29,016 - Epoch: [139][   20/   30]    Loss 2.368414    Top1 9.531250    Top5 49.843750    
2024-04-23 18:50:31,189 - Epoch: [139][   30/   30]    Loss 2.374423    Top1 8.456660    Top5 49.682875    
2024-04-23 18:50:31,424 - ==> Top1: 8.457    Top5: 49.683    Loss: 2.374

2024-04-23 18:50:31,426 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 18:50:31,432 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:50:31,433 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:50:31,449 - 

2024-04-23 18:50:31,450 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:50:35,308 - Epoch: [140][   10/  267]    Overall Loss 2.356915    Objective Loss 2.356915                                        LR 0.100000    Time 0.385491    
2024-04-23 18:50:38,065 - Epoch: [140][   20/  267]    Overall Loss 2.363418    Objective Loss 2.363418                                        LR 0.100000    Time 0.330417    
2024-04-23 18:50:41,441 - Epoch: [140][   30/  267]    Overall Loss 2.366159    Objective Loss 2.366159                                        LR 0.100000    Time 0.332695    
2024-04-23 18:50:44,185 - Epoch: [140][   40/  267]    Overall Loss 2.362939    Objective Loss 2.362939                                        LR 0.100000    Time 0.318043    
2024-04-23 18:50:48,102 - Epoch: [140][   50/  267]    Overall Loss 2.355550    Objective Loss 2.355550                                        LR 0.100000    Time 0.332728    
2024-04-23 18:50:50,979 - Epoch: [140][   60/  267]    Overall Loss 2.346134    Objective Loss 2.346134                                        LR 0.100000    Time 0.325110    
2024-04-23 18:50:55,475 - Epoch: [140][   70/  267]    Overall Loss 2.351784    Objective Loss 2.351784                                        LR 0.100000    Time 0.342846    
2024-04-23 18:50:58,560 - Epoch: [140][   80/  267]    Overall Loss 2.350900    Objective Loss 2.350900                                        LR 0.100000    Time 0.338515    
2024-04-23 18:50:58,873 - Epoch: [103][  100/  296]    Overall Loss 0.753487    Objective Loss 0.753487                                        LR 0.000080    Time 0.323558    
2024-04-23 18:51:02,427 - Epoch: [140][   90/  267]    Overall Loss 2.350019    Objective Loss 2.350019                                        LR 0.100000    Time 0.343833    
2024-04-23 18:51:05,106 - Epoch: [140][  100/  267]    Overall Loss 2.350395    Objective Loss 2.350395                                        LR 0.100000    Time 0.336208    
2024-04-23 18:51:07,909 - Epoch: [140][  110/  267]    Overall Loss 2.353315    Objective Loss 2.353315                                        LR 0.100000    Time 0.331095    
2024-04-23 18:51:09,922 - Epoch: [140][  120/  267]    Overall Loss 2.354400    Objective Loss 2.354400                                        LR 0.100000    Time 0.320251    
2024-04-23 18:51:13,098 - Epoch: [140][  130/  267]    Overall Loss 2.359416    Objective Loss 2.359416                                        LR 0.100000    Time 0.320029    
2024-04-23 18:51:15,258 - Epoch: [140][  140/  267]    Overall Loss 2.357442    Objective Loss 2.357442                                        LR 0.100000    Time 0.312577    
2024-04-23 18:51:18,277 - Epoch: [140][  150/  267]    Overall Loss 2.357057    Objective Loss 2.357057                                        LR 0.100000    Time 0.311843    
2024-04-23 18:51:20,459 - Epoch: [140][  160/  267]    Overall Loss 2.356306    Objective Loss 2.356306                                        LR 0.100000    Time 0.305973    
2024-04-23 18:51:23,539 - Epoch: [140][  170/  267]    Overall Loss 2.359767    Objective Loss 2.359767                                        LR 0.100000    Time 0.306077    
2024-04-23 18:51:25,813 - Epoch: [140][  180/  267]    Overall Loss 2.360641    Objective Loss 2.360641                                        LR 0.100000    Time 0.301688    
2024-04-23 18:51:25,926 - Epoch: [103][  200/  296]    Overall Loss 0.740970    Objective Loss 0.740970                                        LR 0.000080    Time 0.296934    
2024-04-23 18:51:28,761 - Epoch: [140][  190/  267]    Overall Loss 2.361705    Objective Loss 2.361705                                        LR 0.100000    Time 0.301306    
2024-04-23 18:51:30,988 - Epoch: [140][  200/  267]    Overall Loss 2.362468    Objective Loss 2.362468                                        LR 0.100000    Time 0.297363    
2024-04-23 18:51:34,243 - Epoch: [140][  210/  267]    Overall Loss 2.360631    Objective Loss 2.360631                                        LR 0.100000    Time 0.298688    
2024-04-23 18:51:36,112 - Epoch: [140][  220/  267]    Overall Loss 2.359876    Objective Loss 2.359876                                        LR 0.100000    Time 0.293587    
2024-04-23 18:51:38,271 - Epoch: [140][  230/  267]    Overall Loss 2.361946    Objective Loss 2.361946                                        LR 0.100000    Time 0.290195    
2024-04-23 18:51:40,339 - Epoch: [140][  240/  267]    Overall Loss 2.362483    Objective Loss 2.362483                                        LR 0.100000    Time 0.286708    
2024-04-23 18:51:43,394 - Epoch: [140][  250/  267]    Overall Loss 2.363063    Objective Loss 2.363063                                        LR 0.100000    Time 0.287446    
2024-04-23 18:51:45,388 - Epoch: [140][  260/  267]    Overall Loss 2.363004    Objective Loss 2.363004                                        LR 0.100000    Time 0.284048    
2024-04-23 18:51:47,037 - Epoch: [140][  267/  267]    Overall Loss 2.363764    Objective Loss 2.363764    Top1 9.302326    Top5 39.534884    LR 0.100000    Time 0.282768    
2024-04-23 18:51:47,266 - --- validate (epoch=140)-----------
2024-04-23 18:51:47,268 - 946 samples (32 per mini-batch)
2024-04-23 18:51:48,722 - Epoch: [103][  296/  296]    Overall Loss 0.756115    Objective Loss 0.756115    Top1 77.049180    Top5 96.721311    LR 0.000080    Time 0.277573    
2024-04-23 18:51:48,972 - --- validate (epoch=103)-----------
2024-04-23 18:51:48,973 - 3925 samples (32 per mini-batch)
2024-04-23 18:51:50,881 - Epoch: [140][   10/   30]    Loss 2.355961    Top1 11.250000    Top5 50.312500    
2024-04-23 18:51:52,734 - Epoch: [140][   20/   30]    Loss 2.361991    Top1 10.312500    Top5 50.156250    
2024-04-23 18:51:55,055 - Epoch: [140][   30/   30]    Loss 2.363293    Top1 10.465116    Top5 49.365751    
2024-04-23 18:51:55,240 - ==> Top1: 10.465    Top5: 49.366    Loss: 2.363

2024-04-23 18:51:55,242 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 18:51:55,247 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:51:55,248 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:51:55,266 - 

2024-04-23 18:51:55,267 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:51:58,548 - Epoch: [141][   10/  267]    Overall Loss 2.386635    Objective Loss 2.386635                                        LR 0.100000    Time 0.327757    
2024-04-23 18:52:00,692 - Epoch: [141][   20/  267]    Overall Loss 2.381334    Objective Loss 2.381334                                        LR 0.100000    Time 0.270876    
2024-04-23 18:52:02,848 - Epoch: [141][   30/  267]    Overall Loss 2.390395    Objective Loss 2.390395                                        LR 0.100000    Time 0.252357    
2024-04-23 18:52:04,589 - Epoch: [141][   40/  267]    Overall Loss 2.389577    Objective Loss 2.389577                                        LR 0.100000    Time 0.232727    
2024-04-23 18:52:06,889 - Epoch: [141][   50/  267]    Overall Loss 2.392605    Objective Loss 2.392605                                        LR 0.100000    Time 0.232118    
2024-04-23 18:52:09,167 - Epoch: [141][   60/  267]    Overall Loss 2.386788    Objective Loss 2.386788                                        LR 0.100000    Time 0.231345    
2024-04-23 18:52:11,821 - Epoch: [141][   70/  267]    Overall Loss 2.386295    Objective Loss 2.386295                                        LR 0.100000    Time 0.236161    
2024-04-23 18:52:14,625 - Epoch: [141][   80/  267]    Overall Loss 2.384987    Objective Loss 2.384987                                        LR 0.100000    Time 0.241650    
2024-04-23 18:52:17,198 - Epoch: [141][   90/  267]    Overall Loss 2.386907    Objective Loss 2.386907                                        LR 0.100000    Time 0.243356    
2024-04-23 18:52:18,661 - Epoch: [103][  100/  123]    Loss 0.668457    Top1 77.843750    Top5 97.625000    
2024-04-23 18:52:19,771 - Epoch: [141][  100/  267]    Overall Loss 2.384932    Objective Loss 2.384932                                        LR 0.100000    Time 0.244718    
2024-04-23 18:52:22,412 - Epoch: [141][  110/  267]    Overall Loss 2.381345    Objective Loss 2.381345                                        LR 0.100000    Time 0.246444    
2024-04-23 18:52:24,651 - Epoch: [103][  123/  123]    Loss 0.674409    Top1 77.757962    Top5 97.477707    
2024-04-23 18:52:24,679 - Epoch: [141][  120/  267]    Overall Loss 2.380556    Objective Loss 2.380556                                        LR 0.100000    Time 0.244773    
2024-04-23 18:52:25,019 - ==> Top1: 77.758    Top5: 97.478    Loss: 0.674

2024-04-23 18:52:25,032 - ==> Best [Top1: 77.987   Top5: 97.376   Sparsity:0.00   Params: 376752 on epoch: 102]
2024-04-23 18:52:25,033 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:52:25,126 - 

2024-04-23 18:52:25,127 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:52:26,840 - Epoch: [141][  130/  267]    Overall Loss 2.382643    Objective Loss 2.382643                                        LR 0.100000    Time 0.242543    
2024-04-23 18:52:29,802 - Epoch: [141][  140/  267]    Overall Loss 2.382670    Objective Loss 2.382670                                        LR 0.100000    Time 0.246355    
2024-04-23 18:52:31,294 - Epoch: [141][  150/  267]    Overall Loss 2.380146    Objective Loss 2.380146                                        LR 0.100000    Time 0.239863    
2024-04-23 18:52:33,986 - Epoch: [141][  160/  267]    Overall Loss 2.377176    Objective Loss 2.377176                                        LR 0.100000    Time 0.241676    
2024-04-23 18:52:35,808 - Epoch: [141][  170/  267]    Overall Loss 2.376676    Objective Loss 2.376676                                        LR 0.100000    Time 0.238163    
2024-04-23 18:52:38,561 - Epoch: [141][  180/  267]    Overall Loss 2.375250    Objective Loss 2.375250                                        LR 0.100000    Time 0.240209    
2024-04-23 18:52:40,534 - Epoch: [141][  190/  267]    Overall Loss 2.376126    Objective Loss 2.376126                                        LR 0.100000    Time 0.237932    
2024-04-23 18:52:43,094 - Epoch: [141][  200/  267]    Overall Loss 2.377091    Objective Loss 2.377091                                        LR 0.100000    Time 0.238825    
2024-04-23 18:52:45,040 - Epoch: [141][  210/  267]    Overall Loss 2.375131    Objective Loss 2.375131                                        LR 0.100000    Time 0.236703    
2024-04-23 18:52:47,349 - Epoch: [141][  220/  267]    Overall Loss 2.377157    Objective Loss 2.377157                                        LR 0.100000    Time 0.236425    
2024-04-23 18:52:48,932 - Epoch: [141][  230/  267]    Overall Loss 2.376579    Objective Loss 2.376579                                        LR 0.100000    Time 0.233011    
2024-04-23 18:52:51,047 - Epoch: [141][  240/  267]    Overall Loss 2.377008    Objective Loss 2.377008                                        LR 0.100000    Time 0.232099    
2024-04-23 18:52:52,573 - Epoch: [104][  100/  296]    Overall Loss 0.728559    Objective Loss 0.728559                                        LR 0.000080    Time 0.274180    
2024-04-23 18:52:52,755 - Epoch: [141][  250/  267]    Overall Loss 2.376596    Objective Loss 2.376596                                        LR 0.100000    Time 0.229640    
2024-04-23 18:52:55,145 - Epoch: [141][  260/  267]    Overall Loss 2.377071    Objective Loss 2.377071                                        LR 0.100000    Time 0.229987    
2024-04-23 18:52:56,740 - Epoch: [141][  267/  267]    Overall Loss 2.376503    Objective Loss 2.376503    Top1 0.000000    Top5 51.162791    LR 0.100000    Time 0.229920    
2024-04-23 18:52:56,992 - --- validate (epoch=141)-----------
2024-04-23 18:52:56,993 - 946 samples (32 per mini-batch)
2024-04-23 18:53:01,269 - Epoch: [141][   10/   30]    Loss 2.347729    Top1 11.562500    Top5 53.437500    
2024-04-23 18:53:03,694 - Epoch: [141][   20/   30]    Loss 2.383582    Top1 9.531250    Top5 49.687500    
2024-04-23 18:53:06,947 - Epoch: [141][   30/   30]    Loss 2.380809    Top1 9.830867    Top5 49.682875    
2024-04-23 18:53:07,238 - ==> Top1: 9.831    Top5: 49.683    Loss: 2.381

2024-04-23 18:53:07,239 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 18:53:07,247 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:53:07,248 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:53:07,271 - 

2024-04-23 18:53:07,272 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:53:11,672 - Epoch: [142][   10/  267]    Overall Loss 2.339236    Objective Loss 2.339236                                        LR 0.100000    Time 0.439562    
2024-04-23 18:53:13,365 - Epoch: [104][  200/  296]    Overall Loss 0.745323    Objective Loss 0.745323                                        LR 0.000080    Time 0.240936    
2024-04-23 18:53:14,291 - Epoch: [142][   20/  267]    Overall Loss 2.356240    Objective Loss 2.356240                                        LR 0.100000    Time 0.350567    
2024-04-23 18:53:17,356 - Epoch: [142][   30/  267]    Overall Loss 2.352069    Objective Loss 2.352069                                        LR 0.100000    Time 0.335782    
2024-04-23 18:53:19,637 - Epoch: [142][   40/  267]    Overall Loss 2.355041    Objective Loss 2.355041                                        LR 0.100000    Time 0.308772    
2024-04-23 18:53:22,522 - Epoch: [142][   50/  267]    Overall Loss 2.361557    Objective Loss 2.361557                                        LR 0.100000    Time 0.304658    
2024-04-23 18:53:24,443 - Epoch: [142][   60/  267]    Overall Loss 2.359821    Objective Loss 2.359821                                        LR 0.100000    Time 0.285850    
2024-04-23 18:53:27,353 - Epoch: [142][   70/  267]    Overall Loss 2.361226    Objective Loss 2.361226                                        LR 0.100000    Time 0.286556    
2024-04-23 18:53:29,331 - Epoch: [142][   80/  267]    Overall Loss 2.359554    Objective Loss 2.359554                                        LR 0.100000    Time 0.275415    
2024-04-23 18:53:32,462 - Epoch: [142][   90/  267]    Overall Loss 2.358278    Objective Loss 2.358278                                        LR 0.100000    Time 0.279569    
2024-04-23 18:53:34,743 - Epoch: [142][  100/  267]    Overall Loss 2.362953    Objective Loss 2.362953                                        LR 0.100000    Time 0.274394    
2024-04-23 18:53:35,135 - Epoch: [104][  296/  296]    Overall Loss 0.750311    Objective Loss 0.750311    Top1 65.573770    Top5 96.721311    LR 0.000080    Time 0.236272    
2024-04-23 18:53:35,488 - --- validate (epoch=104)-----------
2024-04-23 18:53:35,489 - 3925 samples (32 per mini-batch)
2024-04-23 18:53:38,067 - Epoch: [142][  110/  267]    Overall Loss 2.363297    Objective Loss 2.363297                                        LR 0.100000    Time 0.279646    
2024-04-23 18:53:40,131 - Epoch: [142][  120/  267]    Overall Loss 2.365155    Objective Loss 2.365155                                        LR 0.100000    Time 0.273511    
2024-04-23 18:53:43,305 - Epoch: [142][  130/  267]    Overall Loss 2.363582    Objective Loss 2.363582                                        LR 0.100000    Time 0.276866    
2024-04-23 18:53:45,359 - Epoch: [142][  140/  267]    Overall Loss 2.360962    Objective Loss 2.360962                                        LR 0.100000    Time 0.271710    
2024-04-23 18:53:48,287 - Epoch: [142][  150/  267]    Overall Loss 2.362463    Objective Loss 2.362463                                        LR 0.100000    Time 0.273092    
2024-04-23 18:53:50,458 - Epoch: [142][  160/  267]    Overall Loss 2.362213    Objective Loss 2.362213                                        LR 0.100000    Time 0.269577    
2024-04-23 18:53:53,293 - Epoch: [142][  170/  267]    Overall Loss 2.362911    Objective Loss 2.362911                                        LR 0.100000    Time 0.270373    
2024-04-23 18:53:55,091 - Epoch: [142][  180/  267]    Overall Loss 2.363856    Objective Loss 2.363856                                        LR 0.100000    Time 0.265305    
2024-04-23 18:53:58,105 - Epoch: [142][  190/  267]    Overall Loss 2.364625    Objective Loss 2.364625                                        LR 0.100000    Time 0.267187    
2024-04-23 18:54:00,412 - Epoch: [142][  200/  267]    Overall Loss 2.365339    Objective Loss 2.365339                                        LR 0.100000    Time 0.265346    
2024-04-23 18:54:01,581 - Epoch: [104][  100/  123]    Loss 0.683254    Top1 77.031250    Top5 97.531250    
2024-04-23 18:54:03,551 - Epoch: [142][  210/  267]    Overall Loss 2.365150    Objective Loss 2.365150                                        LR 0.100000    Time 0.267643    
2024-04-23 18:54:05,763 - Epoch: [142][  220/  267]    Overall Loss 2.364875    Objective Loss 2.364875                                        LR 0.100000    Time 0.265502    
2024-04-23 18:54:06,985 - Epoch: [104][  123/  123]    Loss 0.674636    Top1 77.528662    Top5 97.401274    
2024-04-23 18:54:07,285 - ==> Top1: 77.529    Top5: 97.401    Loss: 0.675

2024-04-23 18:54:07,292 - ==> Best [Top1: 77.987   Top5: 97.376   Sparsity:0.00   Params: 376752 on epoch: 102]
2024-04-23 18:54:07,293 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:54:07,347 - 

2024-04-23 18:54:07,347 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:54:08,914 - Epoch: [142][  230/  267]    Overall Loss 2.364259    Objective Loss 2.364259                                        LR 0.100000    Time 0.267643    
2024-04-23 18:54:11,578 - Epoch: [142][  240/  267]    Overall Loss 2.364830    Objective Loss 2.364830                                        LR 0.100000    Time 0.267576    
2024-04-23 18:54:15,346 - Epoch: [142][  250/  267]    Overall Loss 2.364390    Objective Loss 2.364390                                        LR 0.100000    Time 0.271934    
2024-04-23 18:54:18,070 - Epoch: [142][  260/  267]    Overall Loss 2.364468    Objective Loss 2.364468                                        LR 0.100000    Time 0.271942    
2024-04-23 18:54:20,096 - Epoch: [142][  267/  267]    Overall Loss 2.364358    Objective Loss 2.364358    Top1 16.279070    Top5 51.162791    LR 0.100000    Time 0.272393    
2024-04-23 18:54:20,341 - --- validate (epoch=142)-----------
2024-04-23 18:54:20,343 - 946 samples (32 per mini-batch)
2024-04-23 18:54:24,045 - Epoch: [142][   10/   30]    Loss 2.398833    Top1 10.937500    Top5 45.000000    
2024-04-23 18:54:26,105 - Epoch: [142][   20/   30]    Loss 2.373846    Top1 10.156250    Top5 49.843750    
2024-04-23 18:54:28,390 - Epoch: [142][   30/   30]    Loss 2.368046    Top1 10.253700    Top5 51.691332    
2024-04-23 18:54:28,553 - ==> Top1: 10.254    Top5: 51.691    Loss: 2.368

2024-04-23 18:54:28,554 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 18:54:28,556 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:54:28,556 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:54:28,565 - 

2024-04-23 18:54:28,565 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:54:32,254 - Epoch: [143][   10/  267]    Overall Loss 2.350412    Objective Loss 2.350412                                        LR 0.100000    Time 0.368539    
2024-04-23 18:54:32,879 - Epoch: [105][  100/  296]    Overall Loss 0.753408    Objective Loss 0.753408                                        LR 0.000080    Time 0.255111    
2024-04-23 18:54:34,065 - Epoch: [143][   20/  267]    Overall Loss 2.369275    Objective Loss 2.369275                                        LR 0.100000    Time 0.274666    
2024-04-23 18:54:36,900 - Epoch: [143][   30/  267]    Overall Loss 2.358250    Objective Loss 2.358250                                        LR 0.100000    Time 0.277512    
2024-04-23 18:54:38,543 - Epoch: [143][   40/  267]    Overall Loss 2.373310    Objective Loss 2.373310                                        LR 0.100000    Time 0.249140    
2024-04-23 18:54:40,168 - Epoch: [143][   50/  267]    Overall Loss 2.371269    Objective Loss 2.371269                                        LR 0.100000    Time 0.231772    
2024-04-23 18:54:41,805 - Epoch: [143][   60/  267]    Overall Loss 2.368759    Objective Loss 2.368759                                        LR 0.100000    Time 0.220381    
2024-04-23 18:54:44,490 - Epoch: [143][   70/  267]    Overall Loss 2.371470    Objective Loss 2.371470                                        LR 0.100000    Time 0.227217    
2024-04-23 18:54:46,638 - Epoch: [143][   80/  267]    Overall Loss 2.372432    Objective Loss 2.372432                                        LR 0.100000    Time 0.225620    
2024-04-23 18:54:50,324 - Epoch: [143][   90/  267]    Overall Loss 2.372011    Objective Loss 2.372011                                        LR 0.100000    Time 0.241478    
2024-04-23 18:54:52,235 - Epoch: [143][  100/  267]    Overall Loss 2.375159    Objective Loss 2.375159                                        LR 0.100000    Time 0.236410    
2024-04-23 18:54:54,219 - Epoch: [143][  110/  267]    Overall Loss 2.371957    Objective Loss 2.371957                                        LR 0.100000    Time 0.232925    
2024-04-23 18:54:54,444 - Epoch: [105][  200/  296]    Overall Loss 0.750255    Objective Loss 0.750255                                        LR 0.000080    Time 0.235260    
2024-04-23 18:54:55,999 - Epoch: [143][  120/  267]    Overall Loss 2.374494    Objective Loss 2.374494                                        LR 0.100000    Time 0.228328    
2024-04-23 18:54:58,231 - Epoch: [143][  130/  267]    Overall Loss 2.374405    Objective Loss 2.374405                                        LR 0.100000    Time 0.227908    
2024-04-23 18:54:59,903 - Epoch: [143][  140/  267]    Overall Loss 2.375297    Objective Loss 2.375297                                        LR 0.100000    Time 0.223557    
2024-04-23 18:55:02,354 - Epoch: [143][  150/  267]    Overall Loss 2.373843    Objective Loss 2.373843                                        LR 0.100000    Time 0.224974    
2024-04-23 18:55:04,129 - Epoch: [143][  160/  267]    Overall Loss 2.372367    Objective Loss 2.372367                                        LR 0.100000    Time 0.221991    
2024-04-23 18:55:06,557 - Epoch: [143][  170/  267]    Overall Loss 2.371958    Objective Loss 2.371958                                        LR 0.100000    Time 0.223199    
2024-04-23 18:55:08,564 - Epoch: [143][  180/  267]    Overall Loss 2.368716    Objective Loss 2.368716                                        LR 0.100000    Time 0.221930    
2024-04-23 18:55:11,016 - Epoch: [143][  190/  267]    Overall Loss 2.368893    Objective Loss 2.368893                                        LR 0.100000    Time 0.223136    
2024-04-23 18:55:12,530 - Epoch: [143][  200/  267]    Overall Loss 2.370085    Objective Loss 2.370085                                        LR 0.100000    Time 0.219542    
2024-04-23 18:55:14,334 - Epoch: [143][  210/  267]    Overall Loss 2.370451    Objective Loss 2.370451                                        LR 0.100000    Time 0.217664    
2024-04-23 18:55:14,352 - Epoch: [105][  296/  296]    Overall Loss 0.757635    Objective Loss 0.757635    Top1 70.491803    Top5 91.803279    LR 0.000080    Time 0.226153    
2024-04-23 18:55:14,621 - --- validate (epoch=105)-----------
2024-04-23 18:55:14,622 - 3925 samples (32 per mini-batch)
2024-04-23 18:55:15,468 - Epoch: [143][  220/  267]    Overall Loss 2.370284    Objective Loss 2.370284                                        LR 0.100000    Time 0.212916    
2024-04-23 18:55:18,489 - Epoch: [143][  230/  267]    Overall Loss 2.372502    Objective Loss 2.372502                                        LR 0.100000    Time 0.216780    
2024-04-23 18:55:20,494 - Epoch: [143][  240/  267]    Overall Loss 2.370548    Objective Loss 2.370548                                        LR 0.100000    Time 0.216087    
2024-04-23 18:55:23,210 - Epoch: [143][  250/  267]    Overall Loss 2.372361    Objective Loss 2.372361                                        LR 0.100000    Time 0.218298    
2024-04-23 18:55:24,805 - Epoch: [143][  260/  267]    Overall Loss 2.371881    Objective Loss 2.371881                                        LR 0.100000    Time 0.216026    
2024-04-23 18:55:25,849 - Epoch: [143][  267/  267]    Overall Loss 2.370586    Objective Loss 2.370586    Top1 13.953488    Top5 58.139535    LR 0.100000    Time 0.214264    
2024-04-23 18:55:26,012 - --- validate (epoch=143)-----------
2024-04-23 18:55:26,014 - 946 samples (32 per mini-batch)
2024-04-23 18:55:29,277 - Epoch: [143][   10/   30]    Loss 2.533154    Top1 7.812500    Top5 44.687500    
2024-04-23 18:55:31,418 - Epoch: [143][   20/   30]    Loss 2.507433    Top1 8.281250    Top5 46.718750    
2024-04-23 18:55:33,590 - Epoch: [143][   30/   30]    Loss 2.459087    Top1 10.253700    Top5 50.317125    
2024-04-23 18:55:33,771 - ==> Top1: 10.254    Top5: 50.317    Loss: 2.459

2024-04-23 18:55:33,774 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 18:55:33,779 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:55:33,780 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:55:33,799 - 

2024-04-23 18:55:33,800 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:55:37,310 - Epoch: [144][   10/  267]    Overall Loss 2.370984    Objective Loss 2.370984                                        LR 0.100000    Time 0.350504    
2024-04-23 18:55:39,149 - Epoch: [144][   20/  267]    Overall Loss 2.392775    Objective Loss 2.392775                                        LR 0.100000    Time 0.267005    
2024-04-23 18:55:41,670 - Epoch: [144][   30/  267]    Overall Loss 2.369489    Objective Loss 2.369489                                        LR 0.100000    Time 0.261937    
2024-04-23 18:55:41,773 - Epoch: [105][  100/  123]    Loss 0.675805    Top1 77.312500    Top5 97.312500    
2024-04-23 18:55:43,428 - Epoch: [144][   40/  267]    Overall Loss 2.369867    Objective Loss 2.369867                                        LR 0.100000    Time 0.240328    
2024-04-23 18:55:45,982 - Epoch: [144][   50/  267]    Overall Loss 2.364730    Objective Loss 2.364730                                        LR 0.100000    Time 0.243288    
2024-04-23 18:55:47,028 - Epoch: [105][  123/  123]    Loss 0.682155    Top1 77.375796    Top5 97.273885    
2024-04-23 18:55:47,350 - ==> Top1: 77.376    Top5: 97.274    Loss: 0.682

2024-04-23 18:55:47,358 - ==> Best [Top1: 77.987   Top5: 97.376   Sparsity:0.00   Params: 376752 on epoch: 102]
2024-04-23 18:55:47,359 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:55:47,407 - 

2024-04-23 18:55:47,408 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:55:47,870 - Epoch: [144][   60/  267]    Overall Loss 2.371012    Objective Loss 2.371012                                        LR 0.100000    Time 0.234170    
2024-04-23 18:55:50,386 - Epoch: [144][   70/  267]    Overall Loss 2.371219    Objective Loss 2.371219                                        LR 0.100000    Time 0.236613    
2024-04-23 18:55:52,379 - Epoch: [144][   80/  267]    Overall Loss 2.373071    Objective Loss 2.373071                                        LR 0.100000    Time 0.231919    
2024-04-23 18:55:55,138 - Epoch: [144][   90/  267]    Overall Loss 2.378562    Objective Loss 2.378562                                        LR 0.100000    Time 0.236770    
2024-04-23 18:55:56,942 - Epoch: [144][  100/  267]    Overall Loss 2.380179    Objective Loss 2.380179                                        LR 0.100000    Time 0.231107    
2024-04-23 18:55:59,509 - Epoch: [144][  110/  267]    Overall Loss 2.382941    Objective Loss 2.382941                                        LR 0.100000    Time 0.233411    
2024-04-23 18:56:01,367 - Epoch: [144][  120/  267]    Overall Loss 2.381927    Objective Loss 2.381927                                        LR 0.100000    Time 0.229423    
2024-04-23 18:56:04,064 - Epoch: [144][  130/  267]    Overall Loss 2.381985    Objective Loss 2.381985                                        LR 0.100000    Time 0.232498    
2024-04-23 18:56:05,933 - Epoch: [144][  140/  267]    Overall Loss 2.380859    Objective Loss 2.380859                                        LR 0.100000    Time 0.229224    
2024-04-23 18:56:09,513 - Epoch: [144][  150/  267]    Overall Loss 2.379173    Objective Loss 2.379173                                        LR 0.100000    Time 0.237786    
2024-04-23 18:56:11,226 - Epoch: [144][  160/  267]    Overall Loss 2.381169    Objective Loss 2.381169                                        LR 0.100000    Time 0.233611    
2024-04-23 18:56:12,732 - Epoch: [106][  100/  296]    Overall Loss 0.756487    Objective Loss 0.756487                                        LR 0.000080    Time 0.253039    
2024-04-23 18:56:13,437 - Epoch: [144][  170/  267]    Overall Loss 2.380009    Objective Loss 2.380009                                        LR 0.100000    Time 0.232856    
2024-04-23 18:56:14,993 - Epoch: [144][  180/  267]    Overall Loss 2.380868    Objective Loss 2.380868                                        LR 0.100000    Time 0.228546    
2024-04-23 18:56:17,067 - Epoch: [144][  190/  267]    Overall Loss 2.378464    Objective Loss 2.378464                                        LR 0.100000    Time 0.227421    
2024-04-23 18:56:18,376 - Epoch: [144][  200/  267]    Overall Loss 2.377073    Objective Loss 2.377073                                        LR 0.100000    Time 0.222583    
2024-04-23 18:56:20,722 - Epoch: [144][  210/  267]    Overall Loss 2.376507    Objective Loss 2.376507                                        LR 0.100000    Time 0.223141    
2024-04-23 18:56:22,692 - Epoch: [144][  220/  267]    Overall Loss 2.377664    Objective Loss 2.377664                                        LR 0.100000    Time 0.221941    
2024-04-23 18:56:25,391 - Epoch: [144][  230/  267]    Overall Loss 2.375572    Objective Loss 2.375572                                        LR 0.100000    Time 0.223993    
2024-04-23 18:56:27,477 - Epoch: [144][  240/  267]    Overall Loss 2.374697    Objective Loss 2.374697                                        LR 0.100000    Time 0.223341    
2024-04-23 18:56:29,742 - Epoch: [144][  250/  267]    Overall Loss 2.374236    Objective Loss 2.374236                                        LR 0.100000    Time 0.223458    
2024-04-23 18:56:31,718 - Epoch: [144][  260/  267]    Overall Loss 2.373820    Objective Loss 2.373820                                        LR 0.100000    Time 0.222449    
2024-04-23 18:56:33,365 - Epoch: [144][  267/  267]    Overall Loss 2.374580    Objective Loss 2.374580    Top1 13.953488    Top5 46.511628    LR 0.100000    Time 0.222780    
2024-04-23 18:56:33,569 - --- validate (epoch=144)-----------
2024-04-23 18:56:33,570 - 946 samples (32 per mini-batch)
2024-04-23 18:56:35,714 - Epoch: [106][  200/  296]    Overall Loss 0.749307    Objective Loss 0.749307                                        LR 0.000080    Time 0.241335    
2024-04-23 18:56:36,940 - Epoch: [144][   10/   30]    Loss 2.354172    Top1 10.000000    Top5 49.687500    
2024-04-23 18:56:38,882 - Epoch: [144][   20/   30]    Loss 2.356846    Top1 9.375000    Top5 51.093750    
2024-04-23 18:56:40,759 - Epoch: [144][   30/   30]    Loss 2.369367    Top1 9.830867    Top5 50.317125    
2024-04-23 18:56:40,967 - ==> Top1: 9.831    Top5: 50.317    Loss: 2.369

2024-04-23 18:56:40,969 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 18:56:40,972 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:56:40,972 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:56:40,987 - 

2024-04-23 18:56:40,988 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:56:44,414 - Epoch: [145][   10/  267]    Overall Loss 2.355068    Objective Loss 2.355068                                        LR 0.100000    Time 0.342194    
2024-04-23 18:56:46,252 - Epoch: [145][   20/  267]    Overall Loss 2.342075    Objective Loss 2.342075                                        LR 0.100000    Time 0.262872    
2024-04-23 18:56:48,153 - Epoch: [145][   30/  267]    Overall Loss 2.354862    Objective Loss 2.354862                                        LR 0.100000    Time 0.238534    
2024-04-23 18:56:50,038 - Epoch: [145][   40/  267]    Overall Loss 2.350095    Objective Loss 2.350095                                        LR 0.100000    Time 0.225941    
2024-04-23 18:56:52,507 - Epoch: [145][   50/  267]    Overall Loss 2.356319    Objective Loss 2.356319                                        LR 0.100000    Time 0.230072    
2024-04-23 18:56:54,418 - Epoch: [145][   60/  267]    Overall Loss 2.357435    Objective Loss 2.357435                                        LR 0.100000    Time 0.223533    
2024-04-23 18:56:56,033 - Epoch: [106][  296/  296]    Overall Loss 0.749058    Objective Loss 0.749058    Top1 80.327869    Top5 96.721311    LR 0.000080    Time 0.231645    
2024-04-23 18:56:56,322 - --- validate (epoch=106)-----------
2024-04-23 18:56:56,324 - 3925 samples (32 per mini-batch)
2024-04-23 18:56:56,649 - Epoch: [145][   70/  267]    Overall Loss 2.360385    Objective Loss 2.360385                                        LR 0.100000    Time 0.223431    
2024-04-23 18:56:58,872 - Epoch: [145][   80/  267]    Overall Loss 2.357302    Objective Loss 2.357302                                        LR 0.100000    Time 0.223251    
2024-04-23 18:57:02,293 - Epoch: [145][   90/  267]    Overall Loss 2.353127    Objective Loss 2.353127                                        LR 0.100000    Time 0.236426    
2024-04-23 18:57:04,376 - Epoch: [145][  100/  267]    Overall Loss 2.357337    Objective Loss 2.357337                                        LR 0.100000    Time 0.233580    
2024-04-23 18:57:07,243 - Epoch: [145][  110/  267]    Overall Loss 2.359986    Objective Loss 2.359986                                        LR 0.100000    Time 0.238380    
2024-04-23 18:57:09,433 - Epoch: [145][  120/  267]    Overall Loss 2.359073    Objective Loss 2.359073                                        LR 0.100000    Time 0.236742    
2024-04-23 18:57:11,998 - Epoch: [145][  130/  267]    Overall Loss 2.359430    Objective Loss 2.359430                                        LR 0.100000    Time 0.238235    
2024-04-23 18:57:14,058 - Epoch: [145][  140/  267]    Overall Loss 2.362766    Objective Loss 2.362766                                        LR 0.100000    Time 0.235913    
2024-04-23 18:57:16,624 - Epoch: [145][  150/  267]    Overall Loss 2.363434    Objective Loss 2.363434                                        LR 0.100000    Time 0.237271    
2024-04-23 18:57:18,726 - Epoch: [145][  160/  267]    Overall Loss 2.364517    Objective Loss 2.364517                                        LR 0.100000    Time 0.235566    
2024-04-23 18:57:21,010 - Epoch: [145][  170/  267]    Overall Loss 2.363146    Objective Loss 2.363146                                        LR 0.100000    Time 0.235129    
2024-04-23 18:57:23,581 - Epoch: [106][  100/  123]    Loss 0.669229    Top1 77.656250    Top5 97.250000    
2024-04-23 18:57:24,146 - Epoch: [145][  180/  267]    Overall Loss 2.365190    Objective Loss 2.365190                                        LR 0.100000    Time 0.239468    
2024-04-23 18:57:26,534 - Epoch: [145][  190/  267]    Overall Loss 2.363744    Objective Loss 2.363744                                        LR 0.100000    Time 0.239415    
2024-04-23 18:57:29,203 - Epoch: [145][  200/  267]    Overall Loss 2.362632    Objective Loss 2.362632                                        LR 0.100000    Time 0.240778    
2024-04-23 18:57:29,563 - Epoch: [106][  123/  123]    Loss 0.681269    Top1 77.299363    Top5 97.146497    
2024-04-23 18:57:29,878 - ==> Top1: 77.299    Top5: 97.146    Loss: 0.681

2024-04-23 18:57:29,888 - ==> Best [Top1: 77.987   Top5: 97.376   Sparsity:0.00   Params: 376752 on epoch: 102]
2024-04-23 18:57:29,889 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:57:29,942 - 

2024-04-23 18:57:29,943 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:57:31,317 - Epoch: [145][  210/  267]    Overall Loss 2.360434    Objective Loss 2.360434                                        LR 0.100000    Time 0.239364    
2024-04-23 18:57:33,286 - Epoch: [145][  220/  267]    Overall Loss 2.360203    Objective Loss 2.360203                                        LR 0.100000    Time 0.237421    
2024-04-23 18:57:36,339 - Epoch: [145][  230/  267]    Overall Loss 2.360110    Objective Loss 2.360110                                        LR 0.100000    Time 0.240359    
2024-04-23 18:57:38,559 - Epoch: [145][  240/  267]    Overall Loss 2.359299    Objective Loss 2.359299                                        LR 0.100000    Time 0.239577    
2024-04-23 18:57:41,883 - Epoch: [145][  250/  267]    Overall Loss 2.360204    Objective Loss 2.360204                                        LR 0.100000    Time 0.243279    
2024-04-23 18:57:44,166 - Epoch: [145][  260/  267]    Overall Loss 2.358494    Objective Loss 2.358494                                        LR 0.100000    Time 0.242692    
2024-04-23 18:57:45,912 - Epoch: [145][  267/  267]    Overall Loss 2.359019    Objective Loss 2.359019    Top1 9.302326    Top5 48.837209    LR 0.100000    Time 0.242863    
2024-04-23 18:57:46,166 - --- validate (epoch=145)-----------
2024-04-23 18:57:46,167 - 946 samples (32 per mini-batch)
2024-04-23 18:57:50,313 - Epoch: [145][   10/   30]    Loss 2.412696    Top1 7.812500    Top5 46.562500    
2024-04-23 18:57:52,519 - Epoch: [145][   20/   30]    Loss 2.379175    Top1 9.687500    Top5 49.218750    
2024-04-23 18:57:55,123 - Epoch: [145][   30/   30]    Loss 2.370481    Top1 10.993658    Top5 50.317125    
2024-04-23 18:57:55,311 - ==> Top1: 10.994    Top5: 50.317    Loss: 2.370

2024-04-23 18:57:55,313 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 18:57:55,320 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:57:55,321 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:57:55,338 - 

2024-04-23 18:57:55,339 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:57:55,884 - Epoch: [107][  100/  296]    Overall Loss 0.719948    Objective Loss 0.719948                                        LR 0.000080    Time 0.259199    
2024-04-23 18:57:58,963 - Epoch: [146][   10/  267]    Overall Loss 2.406083    Objective Loss 2.406083                                        LR 0.100000    Time 0.361964    
2024-04-23 18:58:01,041 - Epoch: [146][   20/  267]    Overall Loss 2.385390    Objective Loss 2.385390                                        LR 0.100000    Time 0.284742    
2024-04-23 18:58:03,897 - Epoch: [146][   30/  267]    Overall Loss 2.394528    Objective Loss 2.394528                                        LR 0.100000    Time 0.284952    
2024-04-23 18:58:05,983 - Epoch: [146][   40/  267]    Overall Loss 2.393930    Objective Loss 2.393930                                        LR 0.100000    Time 0.265801    
2024-04-23 18:58:09,027 - Epoch: [146][   50/  267]    Overall Loss 2.391021    Objective Loss 2.391021                                        LR 0.100000    Time 0.273441    
2024-04-23 18:58:11,132 - Epoch: [146][   60/  267]    Overall Loss 2.380846    Objective Loss 2.380846                                        LR 0.100000    Time 0.262895    
2024-04-23 18:58:13,978 - Epoch: [146][   70/  267]    Overall Loss 2.379467    Objective Loss 2.379467                                        LR 0.100000    Time 0.265962    
2024-04-23 18:58:16,206 - Epoch: [146][   80/  267]    Overall Loss 2.376243    Objective Loss 2.376243                                        LR 0.100000    Time 0.260530    
2024-04-23 18:58:18,960 - Epoch: [146][   90/  267]    Overall Loss 2.370449    Objective Loss 2.370449                                        LR 0.100000    Time 0.262135    
2024-04-23 18:58:19,769 - Epoch: [107][  200/  296]    Overall Loss 0.746881    Objective Loss 0.746881                                        LR 0.000080    Time 0.248930    
2024-04-23 18:58:21,325 - Epoch: [146][  100/  267]    Overall Loss 2.373444    Objective Loss 2.373444                                        LR 0.100000    Time 0.259541    
2024-04-23 18:58:24,136 - Epoch: [146][  110/  267]    Overall Loss 2.372268    Objective Loss 2.372268                                        LR 0.100000    Time 0.261483    
2024-04-23 18:58:26,717 - Epoch: [146][  120/  267]    Overall Loss 2.369794    Objective Loss 2.369794                                        LR 0.100000    Time 0.261172    
2024-04-23 18:58:29,465 - Epoch: [146][  130/  267]    Overall Loss 2.369401    Objective Loss 2.369401                                        LR 0.100000    Time 0.262193    
2024-04-23 18:58:31,882 - Epoch: [146][  140/  267]    Overall Loss 2.371940    Objective Loss 2.371940                                        LR 0.100000    Time 0.260715    
2024-04-23 18:58:34,442 - Epoch: [146][  150/  267]    Overall Loss 2.371509    Objective Loss 2.371509                                        LR 0.100000    Time 0.260378    
2024-04-23 18:58:36,386 - Epoch: [146][  160/  267]    Overall Loss 2.371475    Objective Loss 2.371475                                        LR 0.100000    Time 0.256239    
2024-04-23 18:58:39,243 - Epoch: [146][  170/  267]    Overall Loss 2.371528    Objective Loss 2.371528                                        LR 0.100000    Time 0.257954    
2024-04-23 18:58:41,392 - Epoch: [146][  180/  267]    Overall Loss 2.371291    Objective Loss 2.371291                                        LR 0.100000    Time 0.255550    
2024-04-23 18:58:43,401 - Epoch: [107][  296/  296]    Overall Loss 0.758990    Objective Loss 0.758990    Top1 80.327869    Top5 100.000000    LR 0.000080    Time 0.247971    
2024-04-23 18:58:43,615 - Epoch: [146][  190/  267]    Overall Loss 2.369644    Objective Loss 2.369644                                        LR 0.100000    Time 0.253781    
2024-04-23 18:58:43,726 - --- validate (epoch=107)-----------
2024-04-23 18:58:43,727 - 3925 samples (32 per mini-batch)
2024-04-23 18:58:45,418 - Epoch: [146][  200/  267]    Overall Loss 2.372490    Objective Loss 2.372490                                        LR 0.100000    Time 0.250094    
2024-04-23 18:58:48,458 - Epoch: [146][  210/  267]    Overall Loss 2.372206    Objective Loss 2.372206                                        LR 0.100000    Time 0.252647    
2024-04-23 18:58:50,612 - Epoch: [146][  220/  267]    Overall Loss 2.369830    Objective Loss 2.369830                                        LR 0.100000    Time 0.250945    
2024-04-23 18:58:53,900 - Epoch: [146][  230/  267]    Overall Loss 2.369911    Objective Loss 2.369911                                        LR 0.100000    Time 0.254318    
2024-04-23 18:58:56,049 - Epoch: [146][  240/  267]    Overall Loss 2.369292    Objective Loss 2.369292                                        LR 0.100000    Time 0.252660    
2024-04-23 18:58:58,906 - Epoch: [146][  250/  267]    Overall Loss 2.369178    Objective Loss 2.369178                                        LR 0.100000    Time 0.253971    
2024-04-23 18:59:01,376 - Epoch: [146][  260/  267]    Overall Loss 2.369198    Objective Loss 2.369198                                        LR 0.100000    Time 0.253693    
2024-04-23 18:59:02,830 - Epoch: [146][  267/  267]    Overall Loss 2.369366    Objective Loss 2.369366    Top1 6.976744    Top5 48.837209    LR 0.100000    Time 0.252480    
2024-04-23 18:59:03,094 - --- validate (epoch=146)-----------
2024-04-23 18:59:03,095 - 946 samples (32 per mini-batch)
2024-04-23 18:59:06,330 - Epoch: [146][   10/   30]    Loss 2.375209    Top1 13.437500    Top5 53.750000    
2024-04-23 18:59:08,804 - Epoch: [146][   20/   30]    Loss 2.390077    Top1 12.031250    Top5 53.125000    
2024-04-23 18:59:11,242 - Epoch: [146][   30/   30]    Loss 2.404321    Top1 10.570825    Top5 51.585624    
2024-04-23 18:59:11,438 - Epoch: [107][  100/  123]    Loss 0.653342    Top1 78.312500    Top5 97.312500    
2024-04-23 18:59:11,447 - ==> Top1: 10.571    Top5: 51.586    Loss: 2.404

2024-04-23 18:59:11,449 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 18:59:11,454 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 18:59:11,454 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 18:59:11,473 - 

2024-04-23 18:59:11,474 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 18:59:15,666 - Epoch: [147][   10/  267]    Overall Loss 2.356469    Objective Loss 2.356469                                        LR 0.100000    Time 0.418856    
2024-04-23 18:59:16,179 - Epoch: [107][  123/  123]    Loss 0.670548    Top1 77.885350    Top5 97.324841    
2024-04-23 18:59:16,454 - ==> Top1: 77.885    Top5: 97.325    Loss: 0.671

2024-04-23 18:59:16,464 - ==> Best [Top1: 77.987   Top5: 97.376   Sparsity:0.00   Params: 376752 on epoch: 102]
2024-04-23 18:59:16,464 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 18:59:16,511 - 

2024-04-23 18:59:16,512 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 18:59:17,804 - Epoch: [147][   20/  267]    Overall Loss 2.376747    Objective Loss 2.376747                                        LR 0.100000    Time 0.316195    
2024-04-23 18:59:20,672 - Epoch: [147][   30/  267]    Overall Loss 2.382885    Objective Loss 2.382885                                        LR 0.100000    Time 0.306267    
2024-04-23 18:59:22,122 - Epoch: [147][   40/  267]    Overall Loss 2.373787    Objective Loss 2.373787                                        LR 0.100000    Time 0.265899    
2024-04-23 18:59:24,618 - Epoch: [147][   50/  267]    Overall Loss 2.371917    Objective Loss 2.371917                                        LR 0.100000    Time 0.262575    
2024-04-23 18:59:26,691 - Epoch: [147][   60/  267]    Overall Loss 2.374083    Objective Loss 2.374083                                        LR 0.100000    Time 0.253319    
2024-04-23 18:59:29,353 - Epoch: [147][   70/  267]    Overall Loss 2.372481    Objective Loss 2.372481                                        LR 0.100000    Time 0.255131    
2024-04-23 18:59:31,195 - Epoch: [147][   80/  267]    Overall Loss 2.375906    Objective Loss 2.375906                                        LR 0.100000    Time 0.246226    
2024-04-23 18:59:34,067 - Epoch: [147][   90/  267]    Overall Loss 2.376455    Objective Loss 2.376455                                        LR 0.100000    Time 0.250696    
2024-04-23 18:59:36,251 - Epoch: [147][  100/  267]    Overall Loss 2.373084    Objective Loss 2.373084                                        LR 0.100000    Time 0.247450    
2024-04-23 18:59:38,414 - Epoch: [147][  110/  267]    Overall Loss 2.374632    Objective Loss 2.374632                                        LR 0.100000    Time 0.244592    
2024-04-23 18:59:40,087 - Epoch: [147][  120/  267]    Overall Loss 2.380216    Objective Loss 2.380216                                        LR 0.100000    Time 0.238132    
2024-04-23 18:59:40,438 - Epoch: [108][  100/  296]    Overall Loss 0.765570    Objective Loss 0.765570                                        LR 0.000080    Time 0.239049    
2024-04-23 18:59:42,360 - Epoch: [147][  130/  267]    Overall Loss 2.375531    Objective Loss 2.375531                                        LR 0.100000    Time 0.237280    
2024-04-23 18:59:43,409 - Epoch: [147][  140/  267]    Overall Loss 2.375021    Objective Loss 2.375021                                        LR 0.100000    Time 0.227803    
2024-04-23 18:59:45,837 - Epoch: [147][  150/  267]    Overall Loss 2.376226    Objective Loss 2.376226                                        LR 0.100000    Time 0.228790    
2024-04-23 18:59:47,599 - Epoch: [147][  160/  267]    Overall Loss 2.373980    Objective Loss 2.373980                                        LR 0.100000    Time 0.225483    
2024-04-23 18:59:49,739 - Epoch: [147][  170/  267]    Overall Loss 2.370712    Objective Loss 2.370712                                        LR 0.100000    Time 0.224787    
2024-04-23 18:59:51,340 - Epoch: [147][  180/  267]    Overall Loss 2.369604    Objective Loss 2.369604                                        LR 0.100000    Time 0.221178    
2024-04-23 18:59:53,498 - Epoch: [147][  190/  267]    Overall Loss 2.369297    Objective Loss 2.369297                                        LR 0.100000    Time 0.220880    
2024-04-23 18:59:55,081 - Epoch: [147][  200/  267]    Overall Loss 2.367845    Objective Loss 2.367845                                        LR 0.100000    Time 0.217736    
2024-04-23 18:59:57,260 - Epoch: [147][  210/  267]    Overall Loss 2.367862    Objective Loss 2.367862                                        LR 0.100000    Time 0.217729    
2024-04-23 18:59:59,133 - Epoch: [147][  220/  267]    Overall Loss 2.368087    Objective Loss 2.368087                                        LR 0.100000    Time 0.216333    
2024-04-23 19:00:01,274 - Epoch: [147][  230/  267]    Overall Loss 2.367830    Objective Loss 2.367830                                        LR 0.100000    Time 0.216222    
2024-04-23 19:00:02,339 - Epoch: [147][  240/  267]    Overall Loss 2.366808    Objective Loss 2.366808                                        LR 0.100000    Time 0.211642    
2024-04-23 19:00:02,782 - Epoch: [108][  200/  296]    Overall Loss 0.762036    Objective Loss 0.762036                                        LR 0.000080    Time 0.231147    
2024-04-23 19:00:04,269 - Epoch: [147][  250/  267]    Overall Loss 2.366974    Objective Loss 2.366974                                        LR 0.100000    Time 0.210883    
2024-04-23 19:00:06,200 - Epoch: [147][  260/  267]    Overall Loss 2.365662    Objective Loss 2.365662                                        LR 0.100000    Time 0.210189    
2024-04-23 19:00:07,732 - Epoch: [147][  267/  267]    Overall Loss 2.366010    Objective Loss 2.366010    Top1 11.627907    Top5 48.837209    LR 0.100000    Time 0.210408    
2024-04-23 19:00:07,991 - --- validate (epoch=147)-----------
2024-04-23 19:00:07,992 - 946 samples (32 per mini-batch)
2024-04-23 19:00:10,757 - Epoch: [147][   10/   30]    Loss 2.368825    Top1 9.687500    Top5 48.750000    
2024-04-23 19:00:11,935 - Epoch: [147][   20/   30]    Loss 2.381569    Top1 10.156250    Top5 48.125000    
2024-04-23 19:00:13,785 - Epoch: [147][   30/   30]    Loss 2.376820    Top1 10.042283    Top5 48.520085    
2024-04-23 19:00:13,990 - ==> Top1: 10.042    Top5: 48.520    Loss: 2.377

2024-04-23 19:00:13,991 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 19:00:13,994 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:00:13,995 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:00:14,006 - 

2024-04-23 19:00:14,007 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:00:17,373 - Epoch: [148][   10/  267]    Overall Loss 2.355282    Objective Loss 2.355282                                        LR 0.100000    Time 0.336326    
2024-04-23 19:00:18,949 - Epoch: [148][   20/  267]    Overall Loss 2.373956    Objective Loss 2.373956                                        LR 0.100000    Time 0.246818    
2024-04-23 19:00:21,086 - Epoch: [148][   30/  267]    Overall Loss 2.387130    Objective Loss 2.387130                                        LR 0.100000    Time 0.235677    
2024-04-23 19:00:22,868 - Epoch: [148][   40/  267]    Overall Loss 2.369022    Objective Loss 2.369022                                        LR 0.100000    Time 0.221234    
2024-04-23 19:00:23,081 - Epoch: [108][  296/  296]    Overall Loss 0.762773    Objective Loss 0.762773    Top1 63.934426    Top5 98.360656    LR 0.000080    Time 0.224696    
2024-04-23 19:00:23,373 - --- validate (epoch=108)-----------
2024-04-23 19:00:23,374 - 3925 samples (32 per mini-batch)
2024-04-23 19:00:25,850 - Epoch: [148][   50/  267]    Overall Loss 2.362580    Objective Loss 2.362580                                        LR 0.100000    Time 0.236557    
2024-04-23 19:00:28,291 - Epoch: [148][   60/  267]    Overall Loss 2.364423    Objective Loss 2.364423                                        LR 0.100000    Time 0.237769    
2024-04-23 19:00:30,827 - Epoch: [148][   70/  267]    Overall Loss 2.358382    Objective Loss 2.358382                                        LR 0.100000    Time 0.239985    
2024-04-23 19:00:32,405 - Epoch: [148][   80/  267]    Overall Loss 2.361127    Objective Loss 2.361127                                        LR 0.100000    Time 0.229667    
2024-04-23 19:00:34,715 - Epoch: [148][   90/  267]    Overall Loss 2.361910    Objective Loss 2.361910                                        LR 0.100000    Time 0.229781    
2024-04-23 19:00:36,580 - Epoch: [148][  100/  267]    Overall Loss 2.362940    Objective Loss 2.362940                                        LR 0.100000    Time 0.225420    
2024-04-23 19:00:39,227 - Epoch: [148][  110/  267]    Overall Loss 2.366528    Objective Loss 2.366528                                        LR 0.100000    Time 0.228970    
2024-04-23 19:00:40,522 - Epoch: [148][  120/  267]    Overall Loss 2.367908    Objective Loss 2.367908                                        LR 0.100000    Time 0.220658    
2024-04-23 19:00:41,981 - Epoch: [148][  130/  267]    Overall Loss 2.369917    Objective Loss 2.369917                                        LR 0.100000    Time 0.214891    
2024-04-23 19:00:43,792 - Epoch: [148][  140/  267]    Overall Loss 2.369981    Objective Loss 2.369981                                        LR 0.100000    Time 0.212456    
2024-04-23 19:00:46,725 - Epoch: [148][  150/  267]    Overall Loss 2.369783    Objective Loss 2.369783                                        LR 0.100000    Time 0.217825    
2024-04-23 19:00:48,507 - Epoch: [148][  160/  267]    Overall Loss 2.371994    Objective Loss 2.371994                                        LR 0.100000    Time 0.215328    
2024-04-23 19:00:49,379 - Epoch: [108][  100/  123]    Loss 0.664644    Top1 77.656250    Top5 97.375000    
2024-04-23 19:00:50,747 - Epoch: [148][  170/  267]    Overall Loss 2.369822    Objective Loss 2.369822                                        LR 0.100000    Time 0.215823    
2024-04-23 19:00:52,185 - Epoch: [148][  180/  267]    Overall Loss 2.372209    Objective Loss 2.372209                                        LR 0.100000    Time 0.211807    
2024-04-23 19:00:54,304 - Epoch: [148][  190/  267]    Overall Loss 2.371266    Objective Loss 2.371266                                        LR 0.100000    Time 0.211801    
2024-04-23 19:00:55,195 - Epoch: [108][  123/  123]    Loss 0.672066    Top1 77.757962    Top5 97.273885    
2024-04-23 19:00:55,472 - ==> Top1: 77.758    Top5: 97.274    Loss: 0.672

2024-04-23 19:00:55,481 - ==> Best [Top1: 77.987   Top5: 97.376   Sparsity:0.00   Params: 376752 on epoch: 102]
2024-04-23 19:00:55,482 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:00:55,538 - 

2024-04-23 19:00:55,539 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:00:55,780 - Epoch: [148][  200/  267]    Overall Loss 2.370730    Objective Loss 2.370730                                        LR 0.100000    Time 0.208578    
2024-04-23 19:00:58,744 - Epoch: [148][  210/  267]    Overall Loss 2.370877    Objective Loss 2.370877                                        LR 0.100000    Time 0.212726    
2024-04-23 19:01:00,241 - Epoch: [148][  220/  267]    Overall Loss 2.369966    Objective Loss 2.369966                                        LR 0.100000    Time 0.209849    
2024-04-23 19:01:02,969 - Epoch: [148][  230/  267]    Overall Loss 2.372744    Objective Loss 2.372744                                        LR 0.100000    Time 0.212575    
2024-04-23 19:01:05,031 - Epoch: [148][  240/  267]    Overall Loss 2.372521    Objective Loss 2.372521                                        LR 0.100000    Time 0.212295    
2024-04-23 19:01:07,801 - Epoch: [148][  250/  267]    Overall Loss 2.372751    Objective Loss 2.372751                                        LR 0.100000    Time 0.214872    
2024-04-23 19:01:09,815 - Epoch: [148][  260/  267]    Overall Loss 2.372142    Objective Loss 2.372142                                        LR 0.100000    Time 0.214343    
2024-04-23 19:01:11,412 - Epoch: [148][  267/  267]    Overall Loss 2.371005    Objective Loss 2.371005    Top1 13.953488    Top5 44.186047    LR 0.100000    Time 0.214699    
2024-04-23 19:01:11,571 - --- validate (epoch=148)-----------
2024-04-23 19:01:11,572 - 946 samples (32 per mini-batch)
2024-04-23 19:01:15,519 - Epoch: [148][   10/   30]    Loss 2.325130    Top1 10.312500    Top5 51.250000    
2024-04-23 19:01:16,089 - Epoch: [109][  100/  296]    Overall Loss 0.758886    Objective Loss 0.758886                                        LR 0.000080    Time 0.205292    
2024-04-23 19:01:17,349 - Epoch: [148][   20/   30]    Loss 2.323824    Top1 9.843750    Top5 52.500000    
2024-04-23 19:01:19,649 - Epoch: [148][   30/   30]    Loss 2.331982    Top1 10.042283    Top5 50.317125    
2024-04-23 19:01:19,856 - ==> Top1: 10.042    Top5: 50.317    Loss: 2.332

2024-04-23 19:01:19,858 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 19:01:19,865 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:01:19,866 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:01:19,884 - 

2024-04-23 19:01:19,885 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:01:23,961 - Epoch: [149][   10/  267]    Overall Loss 2.392838    Objective Loss 2.392838                                        LR 0.100000    Time 0.407145    
2024-04-23 19:01:26,114 - Epoch: [149][   20/  267]    Overall Loss 2.375929    Objective Loss 2.375929                                        LR 0.100000    Time 0.311054    
2024-04-23 19:01:28,769 - Epoch: [149][   30/  267]    Overall Loss 2.379098    Objective Loss 2.379098                                        LR 0.100000    Time 0.295768    
2024-04-23 19:01:30,431 - Epoch: [149][   40/  267]    Overall Loss 2.371366    Objective Loss 2.371366                                        LR 0.100000    Time 0.263304    
2024-04-23 19:01:33,488 - Epoch: [149][   50/  267]    Overall Loss 2.369443    Objective Loss 2.369443                                        LR 0.100000    Time 0.271739    
2024-04-23 19:01:35,580 - Epoch: [149][   60/  267]    Overall Loss 2.373150    Objective Loss 2.373150                                        LR 0.100000    Time 0.261259    
2024-04-23 19:01:38,201 - Epoch: [149][   70/  267]    Overall Loss 2.369868    Objective Loss 2.369868                                        LR 0.100000    Time 0.261336    
2024-04-23 19:01:38,728 - Epoch: [109][  200/  296]    Overall Loss 0.744253    Objective Loss 0.744253                                        LR 0.000080    Time 0.215747    
2024-04-23 19:01:40,104 - Epoch: [149][   80/  267]    Overall Loss 2.368146    Objective Loss 2.368146                                        LR 0.100000    Time 0.252426    
2024-04-23 19:01:42,689 - Epoch: [149][   90/  267]    Overall Loss 2.368523    Objective Loss 2.368523                                        LR 0.100000    Time 0.253074    
2024-04-23 19:01:44,213 - Epoch: [149][  100/  267]    Overall Loss 2.368695    Objective Loss 2.368695                                        LR 0.100000    Time 0.242978    
2024-04-23 19:01:46,190 - Epoch: [149][  110/  267]    Overall Loss 2.363776    Objective Loss 2.363776                                        LR 0.100000    Time 0.238839    
2024-04-23 19:01:47,469 - Epoch: [149][  120/  267]    Overall Loss 2.369070    Objective Loss 2.369070                                        LR 0.100000    Time 0.229565    
2024-04-23 19:01:49,381 - Epoch: [149][  130/  267]    Overall Loss 2.369594    Objective Loss 2.369594                                        LR 0.100000    Time 0.226592    
2024-04-23 19:01:50,881 - Epoch: [149][  140/  267]    Overall Loss 2.370104    Objective Loss 2.370104                                        LR 0.100000    Time 0.221098    
2024-04-23 19:01:53,046 - Epoch: [149][  150/  267]    Overall Loss 2.365861    Objective Loss 2.365861                                        LR 0.100000    Time 0.220778    
2024-04-23 19:01:54,926 - Epoch: [149][  160/  267]    Overall Loss 2.365256    Objective Loss 2.365256                                        LR 0.100000    Time 0.218708    
2024-04-23 19:01:56,081 - Epoch: [109][  296/  296]    Overall Loss 0.742714    Objective Loss 0.742714    Top1 85.245902    Top5 98.360656    LR 0.000080    Time 0.204335    
2024-04-23 19:01:56,204 - --- validate (epoch=109)-----------
2024-04-23 19:01:56,205 - 3925 samples (32 per mini-batch)
2024-04-23 19:01:56,381 - Epoch: [149][  170/  267]    Overall Loss 2.366091    Objective Loss 2.366091                                        LR 0.100000    Time 0.214390    
2024-04-23 19:01:57,414 - Epoch: [149][  180/  267]    Overall Loss 2.368462    Objective Loss 2.368462                                        LR 0.100000    Time 0.208203    
2024-04-23 19:01:59,384 - Epoch: [149][  190/  267]    Overall Loss 2.367334    Objective Loss 2.367334                                        LR 0.100000    Time 0.207601    
2024-04-23 19:02:01,313 - Epoch: [149][  200/  267]    Overall Loss 2.368048    Objective Loss 2.368048                                        LR 0.100000    Time 0.206850    
2024-04-23 19:02:03,715 - Epoch: [149][  210/  267]    Overall Loss 2.366225    Objective Loss 2.366225                                        LR 0.100000    Time 0.208420    
2024-04-23 19:02:05,263 - Epoch: [149][  220/  267]    Overall Loss 2.367835    Objective Loss 2.367835                                        LR 0.100000    Time 0.205967    
2024-04-23 19:02:08,108 - Epoch: [149][  230/  267]    Overall Loss 2.367436    Objective Loss 2.367436                                        LR 0.100000    Time 0.209372    
2024-04-23 19:02:10,179 - Epoch: [149][  240/  267]    Overall Loss 2.368571    Objective Loss 2.368571                                        LR 0.100000    Time 0.209262    
2024-04-23 19:02:12,647 - Epoch: [149][  250/  267]    Overall Loss 2.369259    Objective Loss 2.369259                                        LR 0.100000    Time 0.210753    
2024-04-23 19:02:14,683 - Epoch: [149][  260/  267]    Overall Loss 2.371815    Objective Loss 2.371815                                        LR 0.100000    Time 0.210465    
2024-04-23 19:02:16,007 - Epoch: [149][  267/  267]    Overall Loss 2.371332    Objective Loss 2.371332    Top1 11.627907    Top5 37.209302    LR 0.100000    Time 0.209898    
2024-04-23 19:02:16,226 - --- validate (epoch=149)-----------
2024-04-23 19:02:16,227 - 946 samples (32 per mini-batch)
2024-04-23 19:02:19,217 - Epoch: [109][  100/  123]    Loss 0.657877    Top1 78.718750    Top5 97.500000    
2024-04-23 19:02:19,815 - Epoch: [149][   10/   30]    Loss 2.360027    Top1 11.875000    Top5 51.875000    
2024-04-23 19:02:21,670 - Epoch: [149][   20/   30]    Loss 2.375847    Top1 12.031250    Top5 50.000000    
2024-04-23 19:02:24,000 - Epoch: [149][   30/   30]    Loss 2.398217    Top1 10.993658    Top5 48.942918    
2024-04-23 19:02:24,171 - ==> Top1: 10.994    Top5: 48.943    Loss: 2.398

2024-04-23 19:02:24,173 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 19:02:24,174 - Epoch: [109][  123/  123]    Loss 0.664355    Top1 78.216561    Top5 97.452229    
2024-04-23 19:02:24,177 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:02:24,178 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:02:24,192 - 

2024-04-23 19:02:24,192 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:02:24,301 - ==> Top1: 78.217    Top5: 97.452    Loss: 0.664

2024-04-23 19:02:24,309 - ==> Best [Top1: 78.217   Top5: 97.452   Sparsity:0.00   Params: 376752 on epoch: 109]
2024-04-23 19:02:24,310 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:02:24,392 - 

2024-04-23 19:02:24,393 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:02:26,538 - Epoch: [150][   10/  267]    Overall Loss 2.409127    Objective Loss 2.409127                                        LR 0.100000    Time 0.234334    
2024-04-23 19:02:27,376 - Epoch: [150][   20/  267]    Overall Loss 2.396190    Objective Loss 2.396190                                        LR 0.100000    Time 0.158924    
2024-04-23 19:02:29,106 - Epoch: [150][   30/  267]    Overall Loss 2.389626    Objective Loss 2.389626                                        LR 0.100000    Time 0.163518    
2024-04-23 19:02:30,973 - Epoch: [150][   40/  267]    Overall Loss 2.386973    Objective Loss 2.386973                                        LR 0.100000    Time 0.169248    
2024-04-23 19:02:33,254 - Epoch: [150][   50/  267]    Overall Loss 2.384335    Objective Loss 2.384335                                        LR 0.100000    Time 0.180969    
2024-04-23 19:02:35,034 - Epoch: [150][   60/  267]    Overall Loss 2.380586    Objective Loss 2.380586                                        LR 0.100000    Time 0.180433    
2024-04-23 19:02:37,445 - Epoch: [150][   70/  267]    Overall Loss 2.379405    Objective Loss 2.379405                                        LR 0.100000    Time 0.189056    
2024-04-23 19:02:39,271 - Epoch: [150][   80/  267]    Overall Loss 2.382843    Objective Loss 2.382843                                        LR 0.100000    Time 0.188219    
2024-04-23 19:02:41,826 - Epoch: [150][   90/  267]    Overall Loss 2.377943    Objective Loss 2.377943                                        LR 0.100000    Time 0.195659    
2024-04-23 19:02:43,540 - Epoch: [150][  100/  267]    Overall Loss 2.382239    Objective Loss 2.382239                                        LR 0.100000    Time 0.193203    
2024-04-23 19:02:46,110 - Epoch: [150][  110/  267]    Overall Loss 2.379997    Objective Loss 2.379997                                        LR 0.100000    Time 0.198979    
2024-04-23 19:02:47,653 - Epoch: [110][  100/  296]    Overall Loss 0.759820    Objective Loss 0.759820                                        LR 0.000080    Time 0.232390    
2024-04-23 19:02:47,690 - Epoch: [150][  120/  267]    Overall Loss 2.380208    Objective Loss 2.380208                                        LR 0.100000    Time 0.195539    
2024-04-23 19:02:49,558 - Epoch: [150][  130/  267]    Overall Loss 2.378811    Objective Loss 2.378811                                        LR 0.100000    Time 0.194851    
2024-04-23 19:02:50,944 - Epoch: [150][  140/  267]    Overall Loss 2.377788    Objective Loss 2.377788                                        LR 0.100000    Time 0.190808    
2024-04-23 19:02:53,015 - Epoch: [150][  150/  267]    Overall Loss 2.377297    Objective Loss 2.377297                                        LR 0.100000    Time 0.191880    
2024-04-23 19:02:54,586 - Epoch: [150][  160/  267]    Overall Loss 2.378323    Objective Loss 2.378323                                        LR 0.100000    Time 0.189687    
2024-04-23 19:02:56,467 - Epoch: [150][  170/  267]    Overall Loss 2.377103    Objective Loss 2.377103                                        LR 0.100000    Time 0.189574    
2024-04-23 19:02:58,272 - Epoch: [150][  180/  267]    Overall Loss 2.377087    Objective Loss 2.377087                                        LR 0.100000    Time 0.189052    
2024-04-23 19:03:00,621 - Epoch: [150][  190/  267]    Overall Loss 2.375833    Objective Loss 2.375833                                        LR 0.100000    Time 0.191451    
2024-04-23 19:03:02,267 - Epoch: [150][  200/  267]    Overall Loss 2.377516    Objective Loss 2.377516                                        LR 0.100000    Time 0.190094    
2024-04-23 19:03:04,606 - Epoch: [150][  210/  267]    Overall Loss 2.377917    Objective Loss 2.377917                                        LR 0.100000    Time 0.192164    
2024-04-23 19:03:05,792 - Epoch: [150][  220/  267]    Overall Loss 2.378079    Objective Loss 2.378079                                        LR 0.100000    Time 0.188808    
2024-04-23 19:03:05,838 - Epoch: [110][  200/  296]    Overall Loss 0.756540    Objective Loss 0.756540                                        LR 0.000080    Time 0.207018    
2024-04-23 19:03:07,478 - Epoch: [150][  230/  267]    Overall Loss 2.378860    Objective Loss 2.378860                                        LR 0.100000    Time 0.187922    
2024-04-23 19:03:09,327 - Epoch: [150][  240/  267]    Overall Loss 2.379107    Objective Loss 2.379107                                        LR 0.100000    Time 0.187780    
2024-04-23 19:03:11,592 - Epoch: [150][  250/  267]    Overall Loss 2.380299    Objective Loss 2.380299                                        LR 0.100000    Time 0.189317    
2024-04-23 19:03:13,273 - Epoch: [150][  260/  267]    Overall Loss 2.379339    Objective Loss 2.379339                                        LR 0.100000    Time 0.188491    
2024-04-23 19:03:14,400 - Epoch: [150][  267/  267]    Overall Loss 2.378435    Objective Loss 2.378435    Top1 4.651163    Top5 62.790698    LR 0.100000    Time 0.187764    
2024-04-23 19:03:14,602 - --- validate (epoch=150)-----------
2024-04-23 19:03:14,602 - 946 samples (32 per mini-batch)
2024-04-23 19:03:17,562 - Epoch: [150][   10/   30]    Loss 2.354640    Top1 8.437500    Top5 47.500000    
2024-04-23 19:03:19,821 - Epoch: [150][   20/   30]    Loss 2.336574    Top1 10.312500    Top5 49.375000    
2024-04-23 19:03:22,318 - Epoch: [150][   30/   30]    Loss 2.333709    Top1 10.993658    Top5 49.260042    
2024-04-23 19:03:22,510 - ==> Top1: 10.994    Top5: 49.260    Loss: 2.334

2024-04-23 19:03:22,512 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 19:03:22,516 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:03:22,516 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:03:22,527 - 

2024-04-23 19:03:22,528 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:03:22,707 - Epoch: [110][  296/  296]    Overall Loss 0.761358    Objective Loss 0.761358    Top1 75.409836    Top5 100.000000    LR 0.000080    Time 0.196796    
2024-04-23 19:03:22,875 - --- validate (epoch=110)-----------
2024-04-23 19:03:22,876 - 3925 samples (32 per mini-batch)
2024-04-23 19:03:25,451 - Epoch: [151][   10/  267]    Overall Loss 2.354674    Objective Loss 2.354674                                        LR 0.100000    Time 0.291948    
2024-04-23 19:03:27,287 - Epoch: [151][   20/  267]    Overall Loss 2.357925    Objective Loss 2.357925                                        LR 0.100000    Time 0.237643    
2024-04-23 19:03:29,917 - Epoch: [151][   30/  267]    Overall Loss 2.358020    Objective Loss 2.358020                                        LR 0.100000    Time 0.246006    
2024-04-23 19:03:31,841 - Epoch: [151][   40/  267]    Overall Loss 2.359428    Objective Loss 2.359428                                        LR 0.100000    Time 0.232534    
2024-04-23 19:03:34,400 - Epoch: [151][   50/  267]    Overall Loss 2.359367    Objective Loss 2.359367                                        LR 0.100000    Time 0.237137    
2024-04-23 19:03:36,184 - Epoch: [151][   60/  267]    Overall Loss 2.364473    Objective Loss 2.364473                                        LR 0.100000    Time 0.227309    
2024-04-23 19:03:38,550 - Epoch: [151][   70/  267]    Overall Loss 2.363507    Objective Loss 2.363507                                        LR 0.100000    Time 0.228602    
2024-04-23 19:03:40,571 - Epoch: [151][   80/  267]    Overall Loss 2.366681    Objective Loss 2.366681                                        LR 0.100000    Time 0.225250    
2024-04-23 19:03:43,593 - Epoch: [151][   90/  267]    Overall Loss 2.369346    Objective Loss 2.369346                                        LR 0.100000    Time 0.233771    
2024-04-23 19:03:45,170 - Epoch: [151][  100/  267]    Overall Loss 2.367350    Objective Loss 2.367350                                        LR 0.100000    Time 0.226135    
2024-04-23 19:03:45,673 - Epoch: [110][  100/  123]    Loss 0.677511    Top1 78.406250    Top5 97.156250    
2024-04-23 19:03:46,993 - Epoch: [151][  110/  267]    Overall Loss 2.369584    Objective Loss 2.369584                                        LR 0.100000    Time 0.222129    
2024-04-23 19:03:48,481 - Epoch: [151][  120/  267]    Overall Loss 2.368674    Objective Loss 2.368674                                        LR 0.100000    Time 0.215998    
2024-04-23 19:03:49,567 - Epoch: [110][  123/  123]    Loss 0.673896    Top1 78.522293    Top5 97.121019    
2024-04-23 19:03:49,714 - ==> Top1: 78.522    Top5: 97.121    Loss: 0.674

2024-04-23 19:03:49,722 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:03:49,723 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:03:49,776 - 

2024-04-23 19:03:49,777 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:03:49,817 - Epoch: [151][  130/  267]    Overall Loss 2.366294    Objective Loss 2.366294                                        LR 0.100000    Time 0.209641    
2024-04-23 19:03:50,755 - Epoch: [151][  140/  267]    Overall Loss 2.368080    Objective Loss 2.368080                                        LR 0.100000    Time 0.201350    
2024-04-23 19:03:52,499 - Epoch: [151][  150/  267]    Overall Loss 2.368562    Objective Loss 2.368562                                        LR 0.100000    Time 0.199539    
2024-04-23 19:03:53,829 - Epoch: [151][  160/  267]    Overall Loss 2.366904    Objective Loss 2.366904                                        LR 0.100000    Time 0.195366    
2024-04-23 19:03:55,806 - Epoch: [151][  170/  267]    Overall Loss 2.369305    Objective Loss 2.369305                                        LR 0.100000    Time 0.195489    
2024-04-23 19:03:57,182 - Epoch: [151][  180/  267]    Overall Loss 2.372265    Objective Loss 2.372265                                        LR 0.100000    Time 0.192257    
2024-04-23 19:03:59,187 - Epoch: [151][  190/  267]    Overall Loss 2.371559    Objective Loss 2.371559                                        LR 0.100000    Time 0.192678    
2024-04-23 19:04:00,694 - Epoch: [151][  200/  267]    Overall Loss 2.373364    Objective Loss 2.373364                                        LR 0.100000    Time 0.190563    
2024-04-23 19:04:02,808 - Epoch: [151][  210/  267]    Overall Loss 2.372849    Objective Loss 2.372849                                        LR 0.100000    Time 0.191545    
2024-04-23 19:04:04,547 - Epoch: [151][  220/  267]    Overall Loss 2.372567    Objective Loss 2.372567                                        LR 0.100000    Time 0.190730    
2024-04-23 19:04:06,685 - Epoch: [151][  230/  267]    Overall Loss 2.373681    Objective Loss 2.373681                                        LR 0.100000    Time 0.191720    
2024-04-23 19:04:07,956 - Epoch: [111][  100/  296]    Overall Loss 0.763895    Objective Loss 0.763895                                        LR 0.000080    Time 0.181587    
2024-04-23 19:04:08,833 - Epoch: [151][  240/  267]    Overall Loss 2.374433    Objective Loss 2.374433                                        LR 0.100000    Time 0.192670    
2024-04-23 19:04:11,683 - Epoch: [151][  250/  267]    Overall Loss 2.373629    Objective Loss 2.373629                                        LR 0.100000    Time 0.196347    
2024-04-23 19:04:13,597 - Epoch: [151][  260/  267]    Overall Loss 2.372141    Objective Loss 2.372141                                        LR 0.100000    Time 0.196146    
2024-04-23 19:04:15,057 - Epoch: [151][  267/  267]    Overall Loss 2.371873    Objective Loss 2.371873    Top1 13.953488    Top5 53.488372    LR 0.100000    Time 0.196463    
2024-04-23 19:04:15,246 - --- validate (epoch=151)-----------
2024-04-23 19:04:15,247 - 946 samples (32 per mini-batch)
2024-04-23 19:04:18,948 - Epoch: [151][   10/   30]    Loss 2.338973    Top1 10.625000    Top5 52.500000    
2024-04-23 19:04:20,827 - Epoch: [151][   20/   30]    Loss 2.342477    Top1 10.312500    Top5 52.812500    
2024-04-23 19:04:22,404 - Epoch: [151][   30/   30]    Loss 2.358816    Top1 9.196617    Top5 50.634249    
2024-04-23 19:04:22,585 - ==> Top1: 9.197    Top5: 50.634    Loss: 2.359

2024-04-23 19:04:22,587 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 19:04:22,591 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:04:22,592 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:04:22,609 - 

2024-04-23 19:04:22,610 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:04:26,173 - Epoch: [152][   10/  267]    Overall Loss 2.343508    Objective Loss 2.343508                                        LR 0.100000    Time 0.355948    
2024-04-23 19:04:27,309 - Epoch: [111][  200/  296]    Overall Loss 0.746509    Objective Loss 0.746509                                        LR 0.000080    Time 0.187461    
2024-04-23 19:04:28,252 - Epoch: [152][   20/  267]    Overall Loss 2.356445    Objective Loss 2.356445                                        LR 0.100000    Time 0.281739    
2024-04-23 19:04:30,915 - Epoch: [152][   30/  267]    Overall Loss 2.367254    Objective Loss 2.367254                                        LR 0.100000    Time 0.276499    
2024-04-23 19:04:32,964 - Epoch: [152][   40/  267]    Overall Loss 2.366145    Objective Loss 2.366145                                        LR 0.100000    Time 0.258494    
2024-04-23 19:04:35,634 - Epoch: [152][   50/  267]    Overall Loss 2.357737    Objective Loss 2.357737                                        LR 0.100000    Time 0.260137    
2024-04-23 19:04:37,614 - Epoch: [152][   60/  267]    Overall Loss 2.361774    Objective Loss 2.361774                                        LR 0.100000    Time 0.249733    
2024-04-23 19:04:40,206 - Epoch: [152][   70/  267]    Overall Loss 2.361544    Objective Loss 2.361544                                        LR 0.100000    Time 0.251019    
2024-04-23 19:04:41,809 - Epoch: [152][   80/  267]    Overall Loss 2.357557    Objective Loss 2.357557                                        LR 0.100000    Time 0.239636    
2024-04-23 19:04:43,582 - Epoch: [152][   90/  267]    Overall Loss 2.359152    Objective Loss 2.359152                                        LR 0.100000    Time 0.232691    
2024-04-23 19:04:45,208 - Epoch: [152][  100/  267]    Overall Loss 2.361352    Objective Loss 2.361352                                        LR 0.100000    Time 0.225645    
2024-04-23 19:04:46,846 - Epoch: [152][  110/  267]    Overall Loss 2.360024    Objective Loss 2.360024                                        LR 0.100000    Time 0.220001    
2024-04-23 19:04:48,556 - Epoch: [111][  296/  296]    Overall Loss 0.739544    Objective Loss 0.739544    Top1 81.967213    Top5 98.360656    LR 0.000080    Time 0.198379    
2024-04-23 19:04:48,870 - --- validate (epoch=111)-----------
2024-04-23 19:04:48,871 - 3925 samples (32 per mini-batch)
2024-04-23 19:04:49,115 - Epoch: [152][  120/  267]    Overall Loss 2.357410    Objective Loss 2.357410                                        LR 0.100000    Time 0.220558    
2024-04-23 19:04:50,433 - Epoch: [152][  130/  267]    Overall Loss 2.355558    Objective Loss 2.355558                                        LR 0.100000    Time 0.213705    
2024-04-23 19:04:52,900 - Epoch: [152][  140/  267]    Overall Loss 2.354671    Objective Loss 2.354671                                        LR 0.100000    Time 0.216045    
2024-04-23 19:04:54,952 - Epoch: [152][  150/  267]    Overall Loss 2.356130    Objective Loss 2.356130                                        LR 0.100000    Time 0.215296    
2024-04-23 19:04:57,652 - Epoch: [152][  160/  267]    Overall Loss 2.358824    Objective Loss 2.358824                                        LR 0.100000    Time 0.218696    
2024-04-23 19:04:59,469 - Epoch: [152][  170/  267]    Overall Loss 2.358576    Objective Loss 2.358576                                        LR 0.100000    Time 0.216499    
2024-04-23 19:05:02,197 - Epoch: [152][  180/  267]    Overall Loss 2.358241    Objective Loss 2.358241                                        LR 0.100000    Time 0.219609    
2024-04-23 19:05:04,074 - Epoch: [152][  190/  267]    Overall Loss 2.357295    Objective Loss 2.357295                                        LR 0.100000    Time 0.217918    
2024-04-23 19:05:06,191 - Epoch: [152][  200/  267]    Overall Loss 2.358740    Objective Loss 2.358740                                        LR 0.100000    Time 0.217579    
2024-04-23 19:05:08,182 - Epoch: [152][  210/  267]    Overall Loss 2.359367    Objective Loss 2.359367                                        LR 0.100000    Time 0.216685    
2024-04-23 19:05:10,646 - Epoch: [152][  220/  267]    Overall Loss 2.359491    Objective Loss 2.359491                                        LR 0.100000    Time 0.218023    
2024-04-23 19:05:12,360 - Epoch: [152][  230/  267]    Overall Loss 2.360547    Objective Loss 2.360547                                        LR 0.100000    Time 0.215981    
2024-04-23 19:05:14,459 - Epoch: [152][  240/  267]    Overall Loss 2.361082    Objective Loss 2.361082                                        LR 0.100000    Time 0.215715    
2024-04-23 19:05:14,620 - Epoch: [111][  100/  123]    Loss 0.672093    Top1 77.531250    Top5 97.656250    
2024-04-23 19:05:16,356 - Epoch: [152][  250/  267]    Overall Loss 2.361284    Objective Loss 2.361284                                        LR 0.100000    Time 0.214663    
2024-04-23 19:05:18,453 - Epoch: [152][  260/  267]    Overall Loss 2.362239    Objective Loss 2.362239                                        LR 0.100000    Time 0.214459    
2024-04-23 19:05:18,965 - Epoch: [111][  123/  123]    Loss 0.670597    Top1 77.910828    Top5 97.477707    
2024-04-23 19:05:19,166 - ==> Top1: 77.911    Top5: 97.478    Loss: 0.671

2024-04-23 19:05:19,177 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:05:19,177 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:05:19,230 - 

2024-04-23 19:05:19,231 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:05:20,027 - Epoch: [152][  267/  267]    Overall Loss 2.363657    Objective Loss 2.363657    Top1 0.000000    Top5 37.209302    LR 0.100000    Time 0.214725    
2024-04-23 19:05:20,306 - --- validate (epoch=152)-----------
2024-04-23 19:05:20,307 - 946 samples (32 per mini-batch)
2024-04-23 19:05:24,868 - Epoch: [152][   10/   30]    Loss 2.349359    Top1 9.687500    Top5 51.875000    
2024-04-23 19:05:26,855 - Epoch: [152][   20/   30]    Loss 2.348480    Top1 9.531250    Top5 51.093750    
2024-04-23 19:05:29,321 - Epoch: [152][   30/   30]    Loss 2.340340    Top1 10.359408    Top5 52.431290    
2024-04-23 19:05:29,577 - ==> Top1: 10.359    Top5: 52.431    Loss: 2.340

2024-04-23 19:05:29,579 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 19:05:29,586 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:05:29,587 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:05:29,606 - 

2024-04-23 19:05:29,607 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:05:33,323 - Epoch: [153][   10/  267]    Overall Loss 2.366216    Objective Loss 2.366216                                        LR 0.100000    Time 0.371178    
2024-04-23 19:05:35,538 - Epoch: [153][   20/  267]    Overall Loss 2.355842    Objective Loss 2.355842                                        LR 0.100000    Time 0.296160    
2024-04-23 19:05:36,376 - Epoch: [112][  100/  296]    Overall Loss 0.770871    Objective Loss 0.770871                                        LR 0.000080    Time 0.171233    
2024-04-23 19:05:38,858 - Epoch: [153][   30/  267]    Overall Loss 2.361031    Objective Loss 2.361031                                        LR 0.100000    Time 0.307998    
2024-04-23 19:05:41,311 - Epoch: [153][   40/  267]    Overall Loss 2.360353    Objective Loss 2.360353                                        LR 0.100000    Time 0.292257    
2024-04-23 19:05:44,629 - Epoch: [153][   50/  267]    Overall Loss 2.364253    Objective Loss 2.364253                                        LR 0.100000    Time 0.300110    
2024-04-23 19:05:46,718 - Epoch: [153][   60/  267]    Overall Loss 2.362989    Objective Loss 2.362989                                        LR 0.100000    Time 0.284868    
2024-04-23 19:05:49,614 - Epoch: [153][   70/  267]    Overall Loss 2.366766    Objective Loss 2.366766                                        LR 0.100000    Time 0.285506    
2024-04-23 19:05:50,856 - Epoch: [112][  200/  296]    Overall Loss 0.766044    Objective Loss 0.766044                                        LR 0.000080    Time 0.157910    
2024-04-23 19:05:51,640 - Epoch: [153][   80/  267]    Overall Loss 2.369238    Objective Loss 2.369238                                        LR 0.100000    Time 0.275107    
2024-04-23 19:05:53,961 - Epoch: [153][   90/  267]    Overall Loss 2.365229    Objective Loss 2.365229                                        LR 0.100000    Time 0.270295    
2024-04-23 19:05:55,545 - Epoch: [153][  100/  267]    Overall Loss 2.365099    Objective Loss 2.365099                                        LR 0.100000    Time 0.259072    
2024-04-23 19:05:58,876 - Epoch: [153][  110/  267]    Overall Loss 2.361906    Objective Loss 2.361906                                        LR 0.100000    Time 0.265781    
2024-04-23 19:06:01,031 - Epoch: [153][  120/  267]    Overall Loss 2.360590    Objective Loss 2.360590                                        LR 0.100000    Time 0.261564    
2024-04-23 19:06:04,059 - Epoch: [153][  130/  267]    Overall Loss 2.363767    Objective Loss 2.363767                                        LR 0.100000    Time 0.264718    
2024-04-23 19:06:05,411 - Epoch: [112][  296/  296]    Overall Loss 0.757386    Objective Loss 0.757386    Top1 80.327869    Top5 96.721311    LR 0.000080    Time 0.155784    
2024-04-23 19:06:05,559 - --- validate (epoch=112)-----------
2024-04-23 19:06:05,560 - 3925 samples (32 per mini-batch)
2024-04-23 19:06:06,312 - Epoch: [153][  140/  267]    Overall Loss 2.363384    Objective Loss 2.363384                                        LR 0.100000    Time 0.261877    
2024-04-23 19:06:09,817 - Epoch: [153][  150/  267]    Overall Loss 2.363976    Objective Loss 2.363976                                        LR 0.100000    Time 0.267770    
2024-04-23 19:06:12,217 - Epoch: [153][  160/  267]    Overall Loss 2.364292    Objective Loss 2.364292                                        LR 0.100000    Time 0.266015    
2024-04-23 19:06:15,470 - Epoch: [153][  170/  267]    Overall Loss 2.364654    Objective Loss 2.364654                                        LR 0.100000    Time 0.269488    
2024-04-23 19:06:17,592 - Epoch: [153][  180/  267]    Overall Loss 2.363828    Objective Loss 2.363828                                        LR 0.100000    Time 0.266289    
2024-04-23 19:06:20,623 - Epoch: [153][  190/  267]    Overall Loss 2.362569    Objective Loss 2.362569                                        LR 0.100000    Time 0.268208    
2024-04-23 19:06:22,599 - Epoch: [153][  200/  267]    Overall Loss 2.363477    Objective Loss 2.363477                                        LR 0.100000    Time 0.264664    
2024-04-23 19:06:23,539 - Epoch: [112][  100/  123]    Loss 0.700410    Top1 77.062500    Top5 96.875000    
2024-04-23 19:06:24,832 - Epoch: [153][  210/  267]    Overall Loss 2.361812    Objective Loss 2.361812                                        LR 0.100000    Time 0.262682    
2024-04-23 19:06:26,828 - Epoch: [153][  220/  267]    Overall Loss 2.364466    Objective Loss 2.364466                                        LR 0.100000    Time 0.259805    
2024-04-23 19:06:27,416 - Epoch: [112][  123/  123]    Loss 0.686633    Top1 77.426752    Top5 97.121019    
2024-04-23 19:06:27,550 - ==> Top1: 77.427    Top5: 97.121    Loss: 0.687

2024-04-23 19:06:27,557 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:06:27,558 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:06:27,598 - 

2024-04-23 19:06:27,599 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:06:28,283 - Epoch: [153][  230/  267]    Overall Loss 2.365480    Objective Loss 2.365480                                        LR 0.100000    Time 0.254827    
2024-04-23 19:06:30,110 - Epoch: [153][  240/  267]    Overall Loss 2.366396    Objective Loss 2.366396                                        LR 0.100000    Time 0.251810    
2024-04-23 19:06:32,424 - Epoch: [153][  250/  267]    Overall Loss 2.367565    Objective Loss 2.367565                                        LR 0.100000    Time 0.250982    
2024-04-23 19:06:35,736 - Epoch: [153][  260/  267]    Overall Loss 2.368360    Objective Loss 2.368360                                        LR 0.100000    Time 0.254056    
2024-04-23 19:06:36,520 - Epoch: [153][  267/  267]    Overall Loss 2.368408    Objective Loss 2.368408    Top1 13.953488    Top5 46.511628    LR 0.100000    Time 0.250322    
2024-04-23 19:06:36,806 - --- validate (epoch=153)-----------
2024-04-23 19:06:36,807 - 946 samples (32 per mini-batch)
2024-04-23 19:06:40,594 - Epoch: [153][   10/   30]    Loss 2.334437    Top1 9.375000    Top5 50.937500    
2024-04-23 19:06:42,721 - Epoch: [153][   20/   30]    Loss 2.318360    Top1 11.250000    Top5 51.250000    
2024-04-23 19:06:44,806 - Epoch: [153][   30/   30]    Loss 2.325904    Top1 10.465116    Top5 49.048626    
2024-04-23 19:06:45,048 - ==> Top1: 10.465    Top5: 49.049    Loss: 2.326

2024-04-23 19:06:45,049 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 19:06:45,052 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:06:45,052 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:06:45,065 - 

2024-04-23 19:06:45,066 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:06:49,170 - Epoch: [154][   10/  267]    Overall Loss 2.342385    Objective Loss 2.342385                                        LR 0.100000    Time 0.410041    
2024-04-23 19:06:50,814 - Epoch: [154][   20/  267]    Overall Loss 2.338463    Objective Loss 2.338463                                        LR 0.100000    Time 0.287061    
2024-04-23 19:06:51,993 - Epoch: [113][  100/  296]    Overall Loss 0.757080    Objective Loss 0.757080                                        LR 0.000080    Time 0.243731    
2024-04-23 19:06:53,868 - Epoch: [154][   30/  267]    Overall Loss 2.330934    Objective Loss 2.330934                                        LR 0.100000    Time 0.293051    
2024-04-23 19:06:55,973 - Epoch: [154][   40/  267]    Overall Loss 2.340672    Objective Loss 2.340672                                        LR 0.100000    Time 0.272351    
2024-04-23 19:06:58,338 - Epoch: [154][   50/  267]    Overall Loss 2.347118    Objective Loss 2.347118                                        LR 0.100000    Time 0.265097    
2024-04-23 19:07:00,196 - Epoch: [154][   60/  267]    Overall Loss 2.345641    Objective Loss 2.345641                                        LR 0.100000    Time 0.251836    
2024-04-23 19:07:02,694 - Epoch: [154][   70/  267]    Overall Loss 2.348628    Objective Loss 2.348628                                        LR 0.100000    Time 0.251507    
2024-04-23 19:07:04,357 - Epoch: [154][   80/  267]    Overall Loss 2.350265    Objective Loss 2.350265                                        LR 0.100000    Time 0.240816    
2024-04-23 19:07:07,108 - Epoch: [154][   90/  267]    Overall Loss 2.354904    Objective Loss 2.354904                                        LR 0.100000    Time 0.244596    
2024-04-23 19:07:08,845 - Epoch: [154][  100/  267]    Overall Loss 2.356050    Objective Loss 2.356050                                        LR 0.100000    Time 0.237468    
2024-04-23 19:07:11,481 - Epoch: [154][  110/  267]    Overall Loss 2.359266    Objective Loss 2.359266                                        LR 0.100000    Time 0.239815    
2024-04-23 19:07:13,273 - Epoch: [154][  120/  267]    Overall Loss 2.358974    Objective Loss 2.358974                                        LR 0.100000    Time 0.234742    
2024-04-23 19:07:14,968 - Epoch: [113][  200/  296]    Overall Loss 0.754495    Objective Loss 0.754495                                        LR 0.000080    Time 0.236645    
2024-04-23 19:07:15,285 - Epoch: [154][  130/  267]    Overall Loss 2.365984    Objective Loss 2.365984                                        LR 0.100000    Time 0.232141    
2024-04-23 19:07:17,302 - Epoch: [154][  140/  267]    Overall Loss 2.362834    Objective Loss 2.362834                                        LR 0.100000    Time 0.229946    
2024-04-23 19:07:19,881 - Epoch: [154][  150/  267]    Overall Loss 2.363217    Objective Loss 2.363217                                        LR 0.100000    Time 0.231788    
2024-04-23 19:07:21,595 - Epoch: [154][  160/  267]    Overall Loss 2.362821    Objective Loss 2.362821                                        LR 0.100000    Time 0.227994    
2024-04-23 19:07:23,852 - Epoch: [154][  170/  267]    Overall Loss 2.364166    Objective Loss 2.364166                                        LR 0.100000    Time 0.227842    
2024-04-23 19:07:26,086 - Epoch: [154][  180/  267]    Overall Loss 2.363815    Objective Loss 2.363815                                        LR 0.100000    Time 0.227580    
2024-04-23 19:07:28,171 - Epoch: [154][  190/  267]    Overall Loss 2.363494    Objective Loss 2.363494                                        LR 0.100000    Time 0.226561    
2024-04-23 19:07:30,378 - Epoch: [154][  200/  267]    Overall Loss 2.364584    Objective Loss 2.364584                                        LR 0.100000    Time 0.226254    
2024-04-23 19:07:32,534 - Epoch: [154][  210/  267]    Overall Loss 2.366011    Objective Loss 2.366011                                        LR 0.100000    Time 0.225731    
2024-04-23 19:07:34,418 - Epoch: [154][  220/  267]    Overall Loss 2.365899    Objective Loss 2.365899                                        LR 0.100000    Time 0.224025    
2024-04-23 19:07:35,288 - Epoch: [113][  296/  296]    Overall Loss 0.748155    Objective Loss 0.748155    Top1 68.852459    Top5 93.442623    LR 0.000080    Time 0.228482    
2024-04-23 19:07:35,536 - --- validate (epoch=113)-----------
2024-04-23 19:07:35,536 - 3925 samples (32 per mini-batch)
2024-04-23 19:07:35,954 - Epoch: [154][  230/  267]    Overall Loss 2.366867    Objective Loss 2.366867                                        LR 0.100000    Time 0.220957    
2024-04-23 19:07:37,548 - Epoch: [154][  240/  267]    Overall Loss 2.367016    Objective Loss 2.367016                                        LR 0.100000    Time 0.218379    
2024-04-23 19:07:40,474 - Epoch: [154][  250/  267]    Overall Loss 2.367329    Objective Loss 2.367329                                        LR 0.100000    Time 0.221343    
2024-04-23 19:07:42,524 - Epoch: [154][  260/  267]    Overall Loss 2.368248    Objective Loss 2.368248                                        LR 0.100000    Time 0.220703    
2024-04-23 19:07:44,400 - Epoch: [154][  267/  267]    Overall Loss 2.368320    Objective Loss 2.368320    Top1 18.604651    Top5 41.860465    LR 0.100000    Time 0.221939    
2024-04-23 19:07:44,626 - --- validate (epoch=154)-----------
2024-04-23 19:07:44,627 - 946 samples (32 per mini-batch)
2024-04-23 19:07:48,689 - Epoch: [154][   10/   30]    Loss 2.362201    Top1 10.000000    Top5 49.687500    
2024-04-23 19:07:51,060 - Epoch: [154][   20/   30]    Loss 2.355499    Top1 10.781250    Top5 49.687500    
2024-04-23 19:07:53,789 - Epoch: [154][   30/   30]    Loss 2.347452    Top1 10.465116    Top5 51.691332    
2024-04-23 19:07:53,983 - ==> Top1: 10.465    Top5: 51.691    Loss: 2.347

2024-04-23 19:07:53,985 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 19:07:53,991 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:07:53,992 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:07:54,010 - 

2024-04-23 19:07:54,011 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:07:57,380 - Epoch: [155][   10/  267]    Overall Loss 2.413411    Objective Loss 2.413411                                        LR 0.100000    Time 0.336358    
2024-04-23 19:07:59,184 - Epoch: [155][   20/  267]    Overall Loss 2.379648    Objective Loss 2.379648                                        LR 0.100000    Time 0.258263    
2024-04-23 19:08:00,557 - Epoch: [113][  100/  123]    Loss 0.675002    Top1 77.781250    Top5 97.375000    
2024-04-23 19:08:01,390 - Epoch: [155][   30/  267]    Overall Loss 2.386615    Objective Loss 2.386615                                        LR 0.100000    Time 0.245610    
2024-04-23 19:08:03,720 - Epoch: [113][  123/  123]    Loss 0.677634    Top1 77.605096    Top5 97.375796    
2024-04-23 19:08:04,069 - Epoch: [155][   40/  267]    Overall Loss 2.386578    Objective Loss 2.386578                                        LR 0.100000    Time 0.251121    
2024-04-23 19:08:04,071 - ==> Top1: 77.605    Top5: 97.376    Loss: 0.678

2024-04-23 19:08:04,081 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:08:04,082 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:08:04,132 - 

2024-04-23 19:08:04,133 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:08:07,014 - Epoch: [155][   50/  267]    Overall Loss 2.385556    Objective Loss 2.385556                                        LR 0.100000    Time 0.259728    
2024-04-23 19:08:09,083 - Epoch: [155][   60/  267]    Overall Loss 2.382954    Objective Loss 2.382954                                        LR 0.100000    Time 0.250883    
2024-04-23 19:08:11,700 - Epoch: [155][   70/  267]    Overall Loss 2.380431    Objective Loss 2.380431                                        LR 0.100000    Time 0.252365    
2024-04-23 19:08:13,790 - Epoch: [155][   80/  267]    Overall Loss 2.378512    Objective Loss 2.378512                                        LR 0.100000    Time 0.246911    
2024-04-23 19:08:16,634 - Epoch: [155][   90/  267]    Overall Loss 2.378227    Objective Loss 2.378227                                        LR 0.100000    Time 0.251044    
2024-04-23 19:08:18,614 - Epoch: [155][  100/  267]    Overall Loss 2.381347    Objective Loss 2.381347                                        LR 0.100000    Time 0.245713    
2024-04-23 19:08:21,535 - Epoch: [155][  110/  267]    Overall Loss 2.376408    Objective Loss 2.376408                                        LR 0.100000    Time 0.249901    
2024-04-23 19:08:21,783 - Epoch: [114][  100/  296]    Overall Loss 0.753332    Objective Loss 0.753332                                        LR 0.000080    Time 0.176305    
2024-04-23 19:08:23,587 - Epoch: [155][  120/  267]    Overall Loss 2.378884    Objective Loss 2.378884                                        LR 0.100000    Time 0.246151    
2024-04-23 19:08:26,580 - Epoch: [155][  130/  267]    Overall Loss 2.383554    Objective Loss 2.383554                                        LR 0.100000    Time 0.250219    
2024-04-23 19:08:28,907 - Epoch: [155][  140/  267]    Overall Loss 2.381830    Objective Loss 2.381830                                        LR 0.100000    Time 0.248944    
2024-04-23 19:08:31,718 - Epoch: [155][  150/  267]    Overall Loss 2.381628    Objective Loss 2.381628                                        LR 0.100000    Time 0.251074    
2024-04-23 19:08:33,425 - Epoch: [155][  160/  267]    Overall Loss 2.381098    Objective Loss 2.381098                                        LR 0.100000    Time 0.246030    
2024-04-23 19:08:36,393 - Epoch: [155][  170/  267]    Overall Loss 2.379261    Objective Loss 2.379261                                        LR 0.100000    Time 0.249000    
2024-04-23 19:08:38,084 - Epoch: [114][  200/  296]    Overall Loss 0.754076    Objective Loss 0.754076                                        LR 0.000080    Time 0.169565    
2024-04-23 19:08:38,409 - Epoch: [155][  180/  267]    Overall Loss 2.376082    Objective Loss 2.376082                                        LR 0.100000    Time 0.246350    
2024-04-23 19:08:41,104 - Epoch: [155][  190/  267]    Overall Loss 2.376665    Objective Loss 2.376665                                        LR 0.100000    Time 0.247553    
2024-04-23 19:08:43,539 - Epoch: [155][  200/  267]    Overall Loss 2.378892    Objective Loss 2.378892                                        LR 0.100000    Time 0.247332    
2024-04-23 19:08:46,718 - Epoch: [155][  210/  267]    Overall Loss 2.379467    Objective Loss 2.379467                                        LR 0.100000    Time 0.250678    
2024-04-23 19:08:48,848 - Epoch: [155][  220/  267]    Overall Loss 2.377168    Objective Loss 2.377168                                        LR 0.100000    Time 0.248946    
2024-04-23 19:08:51,816 - Epoch: [155][  230/  267]    Overall Loss 2.378757    Objective Loss 2.378757                                        LR 0.100000    Time 0.251011    
2024-04-23 19:08:53,647 - Epoch: [155][  240/  267]    Overall Loss 2.381143    Objective Loss 2.381143                                        LR 0.100000    Time 0.248169    
2024-04-23 19:08:54,192 - Epoch: [114][  296/  296]    Overall Loss 0.750307    Objective Loss 0.750307    Top1 75.409836    Top5 95.081967    LR 0.000080    Time 0.168924    
2024-04-23 19:08:54,471 - --- validate (epoch=114)-----------
2024-04-23 19:08:54,472 - 3925 samples (32 per mini-batch)
2024-04-23 19:08:55,682 - Epoch: [155][  250/  267]    Overall Loss 2.380558    Objective Loss 2.380558                                        LR 0.100000    Time 0.246373    
2024-04-23 19:08:57,554 - Epoch: [155][  260/  267]    Overall Loss 2.381693    Objective Loss 2.381693                                        LR 0.100000    Time 0.244085    
2024-04-23 19:08:59,263 - Epoch: [155][  267/  267]    Overall Loss 2.380991    Objective Loss 2.380991    Top1 6.976744    Top5 39.534884    LR 0.100000    Time 0.244077    
2024-04-23 19:08:59,566 - --- validate (epoch=155)-----------
2024-04-23 19:08:59,567 - 946 samples (32 per mini-batch)
2024-04-23 19:09:01,606 - Epoch: [155][   10/   30]    Loss 2.334717    Top1 11.250000    Top5 49.062500    
2024-04-23 19:09:02,687 - Epoch: [155][   20/   30]    Loss 2.334009    Top1 9.687500    Top5 49.843750    
2024-04-23 19:09:04,110 - Epoch: [155][   30/   30]    Loss 2.338310    Top1 9.830867    Top5 50.105708    
2024-04-23 19:09:04,251 - ==> Top1: 9.831    Top5: 50.106    Loss: 2.338

2024-04-23 19:09:04,252 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 19:09:04,256 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:09:04,257 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:09:04,280 - 

2024-04-23 19:09:04,280 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:09:06,187 - Epoch: [156][   10/  267]    Overall Loss 2.387663    Objective Loss 2.387663                                        LR 0.100000    Time 0.190362    
2024-04-23 19:09:07,596 - Epoch: [156][   20/  267]    Overall Loss 2.386549    Objective Loss 2.386549                                        LR 0.100000    Time 0.165474    
2024-04-23 19:09:09,191 - Epoch: [156][   30/  267]    Overall Loss 2.381447    Objective Loss 2.381447                                        LR 0.100000    Time 0.163364    
2024-04-23 19:09:10,405 - Epoch: [156][   40/  267]    Overall Loss 2.380958    Objective Loss 2.380958                                        LR 0.100000    Time 0.152824    
2024-04-23 19:09:11,986 - Epoch: [156][   50/  267]    Overall Loss 2.371364    Objective Loss 2.371364                                        LR 0.100000    Time 0.153838    
2024-04-23 19:09:13,335 - Epoch: [156][   60/  267]    Overall Loss 2.381130    Objective Loss 2.381130                                        LR 0.100000    Time 0.150626    
2024-04-23 19:09:14,600 - Epoch: [156][   70/  267]    Overall Loss 2.376794    Objective Loss 2.376794                                        LR 0.100000    Time 0.147156    
2024-04-23 19:09:15,804 - Epoch: [156][   80/  267]    Overall Loss 2.376766    Objective Loss 2.376766                                        LR 0.100000    Time 0.143779    
2024-04-23 19:09:17,485 - Epoch: [156][   90/  267]    Overall Loss 2.374402    Objective Loss 2.374402                                        LR 0.100000    Time 0.146450    
2024-04-23 19:09:18,684 - Epoch: [156][  100/  267]    Overall Loss 2.371667    Objective Loss 2.371667                                        LR 0.100000    Time 0.143769    
2024-04-23 19:09:20,363 - Epoch: [156][  110/  267]    Overall Loss 2.375649    Objective Loss 2.375649                                        LR 0.100000    Time 0.145943    
2024-04-23 19:09:21,744 - Epoch: [156][  120/  267]    Overall Loss 2.374743    Objective Loss 2.374743                                        LR 0.100000    Time 0.145273    
2024-04-23 19:09:22,162 - Epoch: [114][  100/  123]    Loss 0.675736    Top1 77.906250    Top5 97.343750    
2024-04-23 19:09:22,873 - Epoch: [156][  130/  267]    Overall Loss 2.374084    Objective Loss 2.374084                                        LR 0.100000    Time 0.142764    
2024-04-23 19:09:24,285 - Epoch: [156][  140/  267]    Overall Loss 2.375258    Objective Loss 2.375258                                        LR 0.100000    Time 0.142640    
2024-04-23 19:09:25,336 - Epoch: [156][  150/  267]    Overall Loss 2.373981    Objective Loss 2.373981                                        LR 0.100000    Time 0.140125    
2024-04-23 19:09:26,785 - Epoch: [156][  160/  267]    Overall Loss 2.372524    Objective Loss 2.372524                                        LR 0.100000    Time 0.140411    
2024-04-23 19:09:27,852 - Epoch: [156][  170/  267]    Overall Loss 2.371690    Objective Loss 2.371690                                        LR 0.100000    Time 0.138414    
2024-04-23 19:09:28,916 - Epoch: [114][  123/  123]    Loss 0.675982    Top1 77.707006    Top5 97.426752    
2024-04-23 19:09:29,224 - Epoch: [156][  180/  267]    Overall Loss 2.373404    Objective Loss 2.373404                                        LR 0.100000    Time 0.138334    
2024-04-23 19:09:29,230 - ==> Top1: 77.707    Top5: 97.427    Loss: 0.676

2024-04-23 19:09:29,242 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:09:29,243 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:09:29,304 - 

2024-04-23 19:09:29,305 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:09:30,434 - Epoch: [156][  190/  267]    Overall Loss 2.373510    Objective Loss 2.373510                                        LR 0.100000    Time 0.137410    
2024-04-23 19:09:33,188 - Epoch: [156][  200/  267]    Overall Loss 2.373392    Objective Loss 2.373392                                        LR 0.100000    Time 0.144293    
2024-04-23 19:09:34,888 - Epoch: [156][  210/  267]    Overall Loss 2.373693    Objective Loss 2.373693                                        LR 0.100000    Time 0.145497    
2024-04-23 19:09:36,827 - Epoch: [156][  220/  267]    Overall Loss 2.374329    Objective Loss 2.374329                                        LR 0.100000    Time 0.147685    
2024-04-23 19:09:38,191 - Epoch: [156][  230/  267]    Overall Loss 2.373699    Objective Loss 2.373699                                        LR 0.100000    Time 0.147177    
2024-04-23 19:09:40,242 - Epoch: [156][  240/  267]    Overall Loss 2.373848    Objective Loss 2.373848                                        LR 0.100000    Time 0.149580    
2024-04-23 19:09:41,958 - Epoch: [156][  250/  267]    Overall Loss 2.374371    Objective Loss 2.374371                                        LR 0.100000    Time 0.150449    
2024-04-23 19:09:43,632 - Epoch: [156][  260/  267]    Overall Loss 2.374324    Objective Loss 2.374324                                        LR 0.100000    Time 0.151090    
2024-04-23 19:09:44,333 - Epoch: [156][  267/  267]    Overall Loss 2.374599    Objective Loss 2.374599    Top1 11.627907    Top5 48.837209    LR 0.100000    Time 0.149748    
2024-04-23 19:09:44,445 - --- validate (epoch=156)-----------
2024-04-23 19:09:44,446 - 946 samples (32 per mini-batch)
2024-04-23 19:09:46,757 - Epoch: [156][   10/   30]    Loss 2.397972    Top1 10.000000    Top5 49.687500    
2024-04-23 19:09:48,022 - Epoch: [156][   20/   30]    Loss 2.406016    Top1 10.625000    Top5 49.687500    
2024-04-23 19:09:49,665 - Epoch: [156][   30/   30]    Loss 2.404490    Top1 9.830867    Top5 49.894292    
2024-04-23 19:09:49,781 - ==> Top1: 9.831    Top5: 49.894    Loss: 2.404

2024-04-23 19:09:49,783 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 19:09:49,787 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:09:49,788 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:09:49,801 - 

2024-04-23 19:09:49,802 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:09:51,878 - Epoch: [157][   10/  267]    Overall Loss 2.370708    Objective Loss 2.370708                                        LR 0.100000    Time 0.207276    
2024-04-23 19:09:53,228 - Epoch: [157][   20/  267]    Overall Loss 2.348813    Objective Loss 2.348813                                        LR 0.100000    Time 0.171007    
2024-04-23 19:09:53,748 - Epoch: [115][  100/  296]    Overall Loss 0.756416    Objective Loss 0.756416                                        LR 0.000080    Time 0.244231    
2024-04-23 19:09:55,131 - Epoch: [157][   30/  267]    Overall Loss 2.346486    Objective Loss 2.346486                                        LR 0.100000    Time 0.177354    
2024-04-23 19:09:56,038 - Epoch: [157][   40/  267]    Overall Loss 2.353937    Objective Loss 2.353937                                        LR 0.100000    Time 0.155649    
2024-04-23 19:09:57,150 - Epoch: [157][   50/  267]    Overall Loss 2.356087    Objective Loss 2.356087                                        LR 0.100000    Time 0.146729    
2024-04-23 19:09:58,328 - Epoch: [157][   60/  267]    Overall Loss 2.354088    Objective Loss 2.354088                                        LR 0.100000    Time 0.141857    
2024-04-23 19:10:00,227 - Epoch: [157][   70/  267]    Overall Loss 2.359776    Objective Loss 2.359776                                        LR 0.100000    Time 0.148676    
2024-04-23 19:10:01,940 - Epoch: [157][   80/  267]    Overall Loss 2.360927    Objective Loss 2.360927                                        LR 0.100000    Time 0.151471    
2024-04-23 19:10:03,866 - Epoch: [157][   90/  267]    Overall Loss 2.365644    Objective Loss 2.365644                                        LR 0.100000    Time 0.156008    
2024-04-23 19:10:06,051 - Epoch: [157][  100/  267]    Overall Loss 2.367001    Objective Loss 2.367001                                        LR 0.100000    Time 0.162233    
2024-04-23 19:10:07,810 - Epoch: [157][  110/  267]    Overall Loss 2.365967    Objective Loss 2.365967                                        LR 0.100000    Time 0.163450    
2024-04-23 19:10:10,000 - Epoch: [157][  120/  267]    Overall Loss 2.362221    Objective Loss 2.362221                                        LR 0.100000    Time 0.168056    
2024-04-23 19:10:11,905 - Epoch: [157][  130/  267]    Overall Loss 2.366373    Objective Loss 2.366373                                        LR 0.100000    Time 0.169765    
2024-04-23 19:10:13,635 - Epoch: [157][  140/  267]    Overall Loss 2.366541    Objective Loss 2.366541                                        LR 0.100000    Time 0.169973    
2024-04-23 19:10:15,576 - Epoch: [157][  150/  267]    Overall Loss 2.366601    Objective Loss 2.366601                                        LR 0.100000    Time 0.171568    
2024-04-23 19:10:16,141 - Epoch: [115][  200/  296]    Overall Loss 0.758866    Objective Loss 0.758866                                        LR 0.000080    Time 0.233982    
2024-04-23 19:10:16,967 - Epoch: [157][  160/  267]    Overall Loss 2.367599    Objective Loss 2.367599                                        LR 0.100000    Time 0.169520    
2024-04-23 19:10:18,051 - Epoch: [157][  170/  267]    Overall Loss 2.368094    Objective Loss 2.368094                                        LR 0.100000    Time 0.165914    
2024-04-23 19:10:19,487 - Epoch: [157][  180/  267]    Overall Loss 2.365918    Objective Loss 2.365918                                        LR 0.100000    Time 0.164659    
2024-04-23 19:10:20,929 - Epoch: [157][  190/  267]    Overall Loss 2.365969    Objective Loss 2.365969                                        LR 0.100000    Time 0.163571    
2024-04-23 19:10:22,286 - Epoch: [157][  200/  267]    Overall Loss 2.365319    Objective Loss 2.365319                                        LR 0.100000    Time 0.162162    
2024-04-23 19:10:24,103 - Epoch: [157][  210/  267]    Overall Loss 2.363948    Objective Loss 2.363948                                        LR 0.100000    Time 0.163081    
2024-04-23 19:10:25,987 - Epoch: [157][  220/  267]    Overall Loss 2.363382    Objective Loss 2.363382                                        LR 0.100000    Time 0.164213    
2024-04-23 19:10:28,117 - Epoch: [157][  230/  267]    Overall Loss 2.361405    Objective Loss 2.361405                                        LR 0.100000    Time 0.166322    
2024-04-23 19:10:30,166 - Epoch: [157][  240/  267]    Overall Loss 2.360745    Objective Loss 2.360745                                        LR 0.100000    Time 0.167920    
2024-04-23 19:10:32,231 - Epoch: [157][  250/  267]    Overall Loss 2.361714    Objective Loss 2.361714                                        LR 0.100000    Time 0.169453    
2024-04-23 19:10:34,259 - Epoch: [157][  260/  267]    Overall Loss 2.361906    Objective Loss 2.361906                                        LR 0.100000    Time 0.170721    
2024-04-23 19:10:35,406 - Epoch: [157][  267/  267]    Overall Loss 2.361975    Objective Loss 2.361975    Top1 2.325581    Top5 53.488372    LR 0.100000    Time 0.170534    
2024-04-23 19:10:35,602 - --- validate (epoch=157)-----------
2024-04-23 19:10:35,603 - 946 samples (32 per mini-batch)
2024-04-23 19:10:36,355 - Epoch: [115][  296/  296]    Overall Loss 0.756947    Objective Loss 0.756947    Top1 75.409836    Top5 93.442623    LR 0.000080    Time 0.226323    
2024-04-23 19:10:36,602 - --- validate (epoch=115)-----------
2024-04-23 19:10:36,603 - 3925 samples (32 per mini-batch)
2024-04-23 19:10:38,133 - Epoch: [157][   10/   30]    Loss 2.367353    Top1 9.062500    Top5 51.562500    
2024-04-23 19:10:40,004 - Epoch: [157][   20/   30]    Loss 2.385102    Top1 9.218750    Top5 50.312500    
2024-04-23 19:10:41,854 - Epoch: [157][   30/   30]    Loss 2.389502    Top1 9.196617    Top5 50.528541    
2024-04-23 19:10:42,173 - ==> Top1: 9.197    Top5: 50.529    Loss: 2.390

2024-04-23 19:10:42,175 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 19:10:42,180 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:10:42,181 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:10:42,196 - 

2024-04-23 19:10:42,196 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:10:45,367 - Epoch: [158][   10/  267]    Overall Loss 2.389810    Objective Loss 2.389810                                        LR 0.100000    Time 0.316629    
2024-04-23 19:10:47,251 - Epoch: [158][   20/  267]    Overall Loss 2.376159    Objective Loss 2.376159                                        LR 0.100000    Time 0.252358    
2024-04-23 19:10:49,952 - Epoch: [158][   30/  267]    Overall Loss 2.384115    Objective Loss 2.384115                                        LR 0.100000    Time 0.258160    
2024-04-23 19:10:51,937 - Epoch: [158][   40/  267]    Overall Loss 2.377656    Objective Loss 2.377656                                        LR 0.100000    Time 0.243175    
2024-04-23 19:10:54,181 - Epoch: [158][   50/  267]    Overall Loss 2.375678    Objective Loss 2.375678                                        LR 0.100000    Time 0.239363    
2024-04-23 19:10:56,055 - Epoch: [158][   60/  267]    Overall Loss 2.379200    Objective Loss 2.379200                                        LR 0.100000    Time 0.230652    
2024-04-23 19:10:58,514 - Epoch: [158][   70/  267]    Overall Loss 2.376247    Objective Loss 2.376247                                        LR 0.100000    Time 0.232796    
2024-04-23 19:10:59,894 - Epoch: [115][  100/  123]    Loss 0.684494    Top1 77.937500    Top5 97.125000    
2024-04-23 19:11:00,453 - Epoch: [158][   80/  267]    Overall Loss 2.374977    Objective Loss 2.374977                                        LR 0.100000    Time 0.227899    
2024-04-23 19:11:03,018 - Epoch: [158][   90/  267]    Overall Loss 2.373457    Objective Loss 2.373457                                        LR 0.100000    Time 0.231042    
2024-04-23 19:11:04,480 - Epoch: [115][  123/  123]    Loss 0.682553    Top1 77.681529    Top5 97.299363    
2024-04-23 19:11:04,583 - Epoch: [158][  100/  267]    Overall Loss 2.369409    Objective Loss 2.369409                                        LR 0.100000    Time 0.223571    
2024-04-23 19:11:04,733 - ==> Top1: 77.682    Top5: 97.299    Loss: 0.683

2024-04-23 19:11:04,745 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:11:04,746 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:11:04,824 - 

2024-04-23 19:11:04,824 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:11:06,404 - Epoch: [158][  110/  267]    Overall Loss 2.371699    Objective Loss 2.371699                                        LR 0.100000    Time 0.219778    
2024-04-23 19:11:08,250 - Epoch: [158][  120/  267]    Overall Loss 2.370690    Objective Loss 2.370690                                        LR 0.100000    Time 0.216818    
2024-04-23 19:11:10,886 - Epoch: [158][  130/  267]    Overall Loss 2.373885    Objective Loss 2.373885                                        LR 0.100000    Time 0.220397    
2024-04-23 19:11:12,838 - Epoch: [158][  140/  267]    Overall Loss 2.373972    Objective Loss 2.373972                                        LR 0.100000    Time 0.218579    
2024-04-23 19:11:15,100 - Epoch: [158][  150/  267]    Overall Loss 2.374747    Objective Loss 2.374747                                        LR 0.100000    Time 0.219065    
2024-04-23 19:11:16,718 - Epoch: [158][  160/  267]    Overall Loss 2.375223    Objective Loss 2.375223                                        LR 0.100000    Time 0.215464    
2024-04-23 19:11:18,856 - Epoch: [158][  170/  267]    Overall Loss 2.373722    Objective Loss 2.373722                                        LR 0.100000    Time 0.215354    
2024-04-23 19:11:20,581 - Epoch: [158][  180/  267]    Overall Loss 2.372028    Objective Loss 2.372028                                        LR 0.100000    Time 0.212958    
2024-04-23 19:11:22,968 - Epoch: [158][  190/  267]    Overall Loss 2.371332    Objective Loss 2.371332                                        LR 0.100000    Time 0.214291    
2024-04-23 19:11:25,101 - Epoch: [158][  200/  267]    Overall Loss 2.372336    Objective Loss 2.372336                                        LR 0.100000    Time 0.214230    
2024-04-23 19:11:26,910 - Epoch: [158][  210/  267]    Overall Loss 2.371996    Objective Loss 2.371996                                        LR 0.100000    Time 0.212630    
2024-04-23 19:11:27,593 - Epoch: [116][  100/  296]    Overall Loss 0.722617    Objective Loss 0.722617                                        LR 0.000080    Time 0.227487    
2024-04-23 19:11:29,144 - Epoch: [158][  220/  267]    Overall Loss 2.370251    Objective Loss 2.370251                                        LR 0.100000    Time 0.213105    
2024-04-23 19:11:31,347 - Epoch: [158][  230/  267]    Overall Loss 2.369475    Objective Loss 2.369475                                        LR 0.100000    Time 0.213405    
2024-04-23 19:11:33,283 - Epoch: [158][  240/  267]    Overall Loss 2.369712    Objective Loss 2.369712                                        LR 0.100000    Time 0.212567    
2024-04-23 19:11:35,423 - Epoch: [158][  250/  267]    Overall Loss 2.371223    Objective Loss 2.371223                                        LR 0.100000    Time 0.212613    
2024-04-23 19:11:37,761 - Epoch: [158][  260/  267]    Overall Loss 2.370263    Objective Loss 2.370263                                        LR 0.100000    Time 0.213416    
2024-04-23 19:11:38,647 - Epoch: [158][  267/  267]    Overall Loss 2.369667    Objective Loss 2.369667    Top1 13.953488    Top5 51.162791    LR 0.100000    Time 0.211134    
2024-04-23 19:11:38,824 - --- validate (epoch=158)-----------
2024-04-23 19:11:38,825 - 946 samples (32 per mini-batch)
2024-04-23 19:11:41,843 - Epoch: [158][   10/   30]    Loss 2.340227    Top1 11.875000    Top5 50.000000    
2024-04-23 19:11:43,759 - Epoch: [158][   20/   30]    Loss 2.340422    Top1 10.781250    Top5 50.937500    
2024-04-23 19:11:45,490 - Epoch: [158][   30/   30]    Loss 2.332146    Top1 10.359408    Top5 51.902748    
2024-04-23 19:11:45,722 - ==> Top1: 10.359    Top5: 51.903    Loss: 2.332

2024-04-23 19:11:45,724 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 19:11:45,728 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:11:45,728 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:11:45,742 - 

2024-04-23 19:11:45,743 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:11:48,241 - Epoch: [116][  200/  296]    Overall Loss 0.749534    Objective Loss 0.749534                                        LR 0.000080    Time 0.216885    
2024-04-23 19:11:50,120 - Epoch: [159][   10/  267]    Overall Loss 2.338279    Objective Loss 2.338279                                        LR 0.100000    Time 0.437257    
2024-04-23 19:11:52,222 - Epoch: [159][   20/  267]    Overall Loss 2.349660    Objective Loss 2.349660                                        LR 0.100000    Time 0.323588    
2024-04-23 19:11:54,835 - Epoch: [159][   30/  267]    Overall Loss 2.355703    Objective Loss 2.355703                                        LR 0.100000    Time 0.302734    
2024-04-23 19:11:56,851 - Epoch: [159][   40/  267]    Overall Loss 2.362056    Objective Loss 2.362056                                        LR 0.100000    Time 0.277369    
2024-04-23 19:11:59,046 - Epoch: [159][   50/  267]    Overall Loss 2.361640    Objective Loss 2.361640                                        LR 0.100000    Time 0.265743    
2024-04-23 19:12:01,262 - Epoch: [159][   60/  267]    Overall Loss 2.360286    Objective Loss 2.360286                                        LR 0.100000    Time 0.258336    
2024-04-23 19:12:03,158 - Epoch: [159][   70/  267]    Overall Loss 2.360666    Objective Loss 2.360666                                        LR 0.100000    Time 0.248473    
2024-04-23 19:12:05,331 - Epoch: [159][   80/  267]    Overall Loss 2.359176    Objective Loss 2.359176                                        LR 0.100000    Time 0.244539    
2024-04-23 19:12:07,346 - Epoch: [159][   90/  267]    Overall Loss 2.359851    Objective Loss 2.359851                                        LR 0.100000    Time 0.239727    
2024-04-23 19:12:09,251 - Epoch: [159][  100/  267]    Overall Loss 2.359882    Objective Loss 2.359882                                        LR 0.100000    Time 0.234776    
2024-04-23 19:12:09,301 - Epoch: [116][  296/  296]    Overall Loss 0.749588    Objective Loss 0.749588    Top1 75.409836    Top5 96.721311    LR 0.000080    Time 0.217626    
2024-04-23 19:12:09,618 - --- validate (epoch=116)-----------
2024-04-23 19:12:09,619 - 3925 samples (32 per mini-batch)
2024-04-23 19:12:10,837 - Epoch: [159][  110/  267]    Overall Loss 2.356756    Objective Loss 2.356756                                        LR 0.100000    Time 0.227823    
2024-04-23 19:12:12,693 - Epoch: [159][  120/  267]    Overall Loss 2.359376    Objective Loss 2.359376                                        LR 0.100000    Time 0.224282    
2024-04-23 19:12:14,237 - Epoch: [159][  130/  267]    Overall Loss 2.363946    Objective Loss 2.363946                                        LR 0.100000    Time 0.218887    
2024-04-23 19:12:16,117 - Epoch: [159][  140/  267]    Overall Loss 2.361618    Objective Loss 2.361618                                        LR 0.100000    Time 0.216658    
2024-04-23 19:12:18,231 - Epoch: [159][  150/  267]    Overall Loss 2.364213    Objective Loss 2.364213                                        LR 0.100000    Time 0.216279    
2024-04-23 19:12:20,393 - Epoch: [159][  160/  267]    Overall Loss 2.365499    Objective Loss 2.365499                                        LR 0.100000    Time 0.216248    
2024-04-23 19:12:22,550 - Epoch: [159][  170/  267]    Overall Loss 2.366487    Objective Loss 2.366487                                        LR 0.100000    Time 0.216196    
2024-04-23 19:12:25,261 - Epoch: [159][  180/  267]    Overall Loss 2.367318    Objective Loss 2.367318                                        LR 0.100000    Time 0.219214    
2024-04-23 19:12:27,177 - Epoch: [159][  190/  267]    Overall Loss 2.365703    Objective Loss 2.365703                                        LR 0.100000    Time 0.217744    
2024-04-23 19:12:29,715 - Epoch: [159][  200/  267]    Overall Loss 2.364732    Objective Loss 2.364732                                        LR 0.100000    Time 0.219530    
2024-04-23 19:12:31,685 - Epoch: [159][  210/  267]    Overall Loss 2.366020    Objective Loss 2.366020                                        LR 0.100000    Time 0.218445    
2024-04-23 19:12:34,526 - Epoch: [159][  220/  267]    Overall Loss 2.365634    Objective Loss 2.365634                                        LR 0.100000    Time 0.221417    
2024-04-23 19:12:34,658 - Epoch: [116][  100/  123]    Loss 0.679805    Top1 77.968750    Top5 97.218750    
2024-04-23 19:12:36,909 - Epoch: [159][  230/  267]    Overall Loss 2.365594    Objective Loss 2.365594                                        LR 0.100000    Time 0.222138    
2024-04-23 19:12:39,551 - Epoch: [159][  240/  267]    Overall Loss 2.365856    Objective Loss 2.365856                                        LR 0.100000    Time 0.223879    
2024-04-23 19:12:41,321 - Epoch: [159][  250/  267]    Overall Loss 2.365794    Objective Loss 2.365794                                        LR 0.100000    Time 0.221990    
2024-04-23 19:12:41,339 - Epoch: [116][  123/  123]    Loss 0.669639    Top1 78.012739    Top5 97.222930    
2024-04-23 19:12:41,539 - ==> Top1: 78.013    Top5: 97.223    Loss: 0.670

2024-04-23 19:12:41,548 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:12:41,549 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:12:41,603 - 

2024-04-23 19:12:41,604 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:12:44,393 - Epoch: [159][  260/  267]    Overall Loss 2.365985    Objective Loss 2.365985                                        LR 0.100000    Time 0.225260    
2024-04-23 19:12:45,381 - Epoch: [159][  267/  267]    Overall Loss 2.365807    Objective Loss 2.365807    Top1 9.302326    Top5 62.790698    LR 0.100000    Time 0.223044    
2024-04-23 19:12:45,641 - --- validate (epoch=159)-----------
2024-04-23 19:12:45,642 - 946 samples (32 per mini-batch)
2024-04-23 19:12:49,908 - Epoch: [159][   10/   30]    Loss 2.330937    Top1 11.250000    Top5 51.875000    
2024-04-23 19:12:52,354 - Epoch: [159][   20/   30]    Loss 2.349675    Top1 10.156250    Top5 50.468750    
2024-04-23 19:12:54,685 - Epoch: [159][   30/   30]    Loss 2.345773    Top1 9.830867    Top5 52.114165    
2024-04-23 19:12:54,900 - ==> Top1: 9.831    Top5: 52.114    Loss: 2.346

2024-04-23 19:12:54,902 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 19:12:54,907 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:12:54,907 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:12:54,924 - 

2024-04-23 19:12:54,925 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:12:58,743 - Epoch: [160][   10/  267]    Overall Loss 2.331326    Objective Loss 2.331326                                        LR 0.100000    Time 0.381314    
2024-04-23 19:13:01,172 - Epoch: [160][   20/  267]    Overall Loss 2.353991    Objective Loss 2.353991                                        LR 0.100000    Time 0.311984    
2024-04-23 19:13:04,267 - Epoch: [160][   30/  267]    Overall Loss 2.353407    Objective Loss 2.353407                                        LR 0.100000    Time 0.311055    
2024-04-23 19:13:06,385 - Epoch: [160][   40/  267]    Overall Loss 2.364150    Objective Loss 2.364150                                        LR 0.100000    Time 0.286178    
2024-04-23 19:13:07,536 - Epoch: [117][  100/  296]    Overall Loss 0.740875    Objective Loss 0.740875                                        LR 0.000080    Time 0.259122    
2024-04-23 19:13:09,257 - Epoch: [160][   50/  267]    Overall Loss 2.364297    Objective Loss 2.364297                                        LR 0.100000    Time 0.286310    
2024-04-23 19:13:11,366 - Epoch: [160][   60/  267]    Overall Loss 2.363808    Objective Loss 2.363808                                        LR 0.100000    Time 0.273703    
2024-04-23 19:13:14,385 - Epoch: [160][   70/  267]    Overall Loss 2.363605    Objective Loss 2.363605                                        LR 0.100000    Time 0.277684    
2024-04-23 19:13:16,516 - Epoch: [160][   80/  267]    Overall Loss 2.363474    Objective Loss 2.363474                                        LR 0.100000    Time 0.269578    
2024-04-23 19:13:19,340 - Epoch: [160][   90/  267]    Overall Loss 2.367058    Objective Loss 2.367058                                        LR 0.100000    Time 0.270970    
2024-04-23 19:13:21,630 - Epoch: [160][  100/  267]    Overall Loss 2.367953    Objective Loss 2.367953                                        LR 0.100000    Time 0.266740    
2024-04-23 19:13:24,188 - Epoch: [160][  110/  267]    Overall Loss 2.364986    Objective Loss 2.364986                                        LR 0.100000    Time 0.265718    
2024-04-23 19:13:27,082 - Epoch: [160][  120/  267]    Overall Loss 2.368953    Objective Loss 2.368953                                        LR 0.100000    Time 0.267665    
2024-04-23 19:13:29,141 - Epoch: [160][  130/  267]    Overall Loss 2.369051    Objective Loss 2.369051                                        LR 0.100000    Time 0.262887    
2024-04-23 19:13:32,274 - Epoch: [160][  140/  267]    Overall Loss 2.369090    Objective Loss 2.369090                                        LR 0.100000    Time 0.266470    
2024-04-23 19:13:32,481 - Epoch: [117][  200/  296]    Overall Loss 0.745831    Objective Loss 0.745831                                        LR 0.000080    Time 0.254181    
2024-04-23 19:13:34,446 - Epoch: [160][  150/  267]    Overall Loss 2.368386    Objective Loss 2.368386                                        LR 0.100000    Time 0.263165    
2024-04-23 19:13:37,234 - Epoch: [160][  160/  267]    Overall Loss 2.367908    Objective Loss 2.367908                                        LR 0.100000    Time 0.264125    
2024-04-23 19:13:39,410 - Epoch: [160][  170/  267]    Overall Loss 2.367128    Objective Loss 2.367128                                        LR 0.100000    Time 0.261369    
2024-04-23 19:13:42,459 - Epoch: [160][  180/  267]    Overall Loss 2.366376    Objective Loss 2.366376                                        LR 0.100000    Time 0.263770    
2024-04-23 19:13:44,927 - Epoch: [160][  190/  267]    Overall Loss 2.364095    Objective Loss 2.364095                                        LR 0.100000    Time 0.262855    
2024-04-23 19:13:47,767 - Epoch: [160][  200/  267]    Overall Loss 2.363348    Objective Loss 2.363348                                        LR 0.100000    Time 0.263900    
2024-04-23 19:13:49,821 - Epoch: [160][  210/  267]    Overall Loss 2.363220    Objective Loss 2.363220                                        LR 0.100000    Time 0.261103    
2024-04-23 19:13:52,586 - Epoch: [160][  220/  267]    Overall Loss 2.362745    Objective Loss 2.362745                                        LR 0.100000    Time 0.261787    
2024-04-23 19:13:54,564 - Epoch: [160][  230/  267]    Overall Loss 2.364288    Objective Loss 2.364288                                        LR 0.100000    Time 0.258989    
2024-04-23 19:13:55,937 - Epoch: [117][  296/  296]    Overall Loss 0.751649    Objective Loss 0.751649    Top1 78.688525    Top5 93.442623    LR 0.000080    Time 0.250923    
2024-04-23 19:13:56,310 - --- validate (epoch=117)-----------
2024-04-23 19:13:56,312 - 3925 samples (32 per mini-batch)
2024-04-23 19:13:56,623 - Epoch: [160][  240/  267]    Overall Loss 2.366285    Objective Loss 2.366285                                        LR 0.100000    Time 0.256768    
2024-04-23 19:13:58,161 - Epoch: [160][  250/  267]    Overall Loss 2.365004    Objective Loss 2.365004                                        LR 0.100000    Time 0.252639    
2024-04-23 19:14:00,383 - Epoch: [160][  260/  267]    Overall Loss 2.364324    Objective Loss 2.364324                                        LR 0.100000    Time 0.251461    
2024-04-23 19:14:00,959 - Epoch: [160][  267/  267]    Overall Loss 2.364732    Objective Loss 2.364732    Top1 11.627907    Top5 53.488372    LR 0.100000    Time 0.247018    
2024-04-23 19:14:01,092 - --- validate (epoch=160)-----------
2024-04-23 19:14:01,093 - 946 samples (32 per mini-batch)
2024-04-23 19:14:04,093 - Epoch: [160][   10/   30]    Loss 2.433684    Top1 10.312500    Top5 47.812500    
2024-04-23 19:14:06,226 - Epoch: [160][   20/   30]    Loss 2.415007    Top1 10.781250    Top5 50.000000    
2024-04-23 19:14:08,430 - Epoch: [160][   30/   30]    Loss 2.415029    Top1 10.570825    Top5 50.317125    
2024-04-23 19:14:08,619 - ==> Top1: 10.571    Top5: 50.317    Loss: 2.415

2024-04-23 19:14:08,620 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 19:14:08,623 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:14:08,624 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:14:08,635 - 

2024-04-23 19:14:08,636 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:14:12,256 - Epoch: [161][   10/  267]    Overall Loss 2.409217    Objective Loss 2.409217                                        LR 0.100000    Time 0.361685    
2024-04-23 19:14:14,261 - Epoch: [161][   20/  267]    Overall Loss 2.391021    Objective Loss 2.391021                                        LR 0.100000    Time 0.280942    
2024-04-23 19:14:17,006 - Epoch: [161][   30/  267]    Overall Loss 2.397977    Objective Loss 2.397977                                        LR 0.100000    Time 0.278683    
2024-04-23 19:14:18,313 - Epoch: [161][   40/  267]    Overall Loss 2.404287    Objective Loss 2.404287                                        LR 0.100000    Time 0.241627    
2024-04-23 19:14:19,736 - Epoch: [117][  100/  123]    Loss 0.686244    Top1 77.593750    Top5 97.312500    
2024-04-23 19:14:20,885 - Epoch: [161][   50/  267]    Overall Loss 2.408482    Objective Loss 2.408482                                        LR 0.100000    Time 0.244687    
2024-04-23 19:14:22,758 - Epoch: [161][   60/  267]    Overall Loss 2.406858    Objective Loss 2.406858                                        LR 0.100000    Time 0.235061    
2024-04-23 19:14:25,042 - Epoch: [117][  123/  123]    Loss 0.679944    Top1 78.012739    Top5 97.350318    
2024-04-23 19:14:25,332 - ==> Top1: 78.013    Top5: 97.350    Loss: 0.680

2024-04-23 19:14:25,342 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:14:25,343 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:14:25,408 - 

2024-04-23 19:14:25,408 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:14:25,412 - Epoch: [161][   70/  267]    Overall Loss 2.399357    Objective Loss 2.399357                                        LR 0.100000    Time 0.239349    
2024-04-23 19:14:27,768 - Epoch: [161][   80/  267]    Overall Loss 2.393839    Objective Loss 2.393839                                        LR 0.100000    Time 0.238857    
2024-04-23 19:14:30,781 - Epoch: [161][   90/  267]    Overall Loss 2.392585    Objective Loss 2.392585                                        LR 0.100000    Time 0.245753    
2024-04-23 19:14:32,752 - Epoch: [161][  100/  267]    Overall Loss 2.391463    Objective Loss 2.391463                                        LR 0.100000    Time 0.240821    
2024-04-23 19:14:35,616 - Epoch: [161][  110/  267]    Overall Loss 2.388649    Objective Loss 2.388649                                        LR 0.100000    Time 0.244942    
2024-04-23 19:14:37,568 - Epoch: [161][  120/  267]    Overall Loss 2.384105    Objective Loss 2.384105                                        LR 0.100000    Time 0.240772    
2024-04-23 19:14:40,185 - Epoch: [161][  130/  267]    Overall Loss 2.383130    Objective Loss 2.383130                                        LR 0.100000    Time 0.242355    
2024-04-23 19:14:42,107 - Epoch: [161][  140/  267]    Overall Loss 2.380199    Objective Loss 2.380199                                        LR 0.100000    Time 0.238752    
2024-04-23 19:14:44,886 - Epoch: [161][  150/  267]    Overall Loss 2.378660    Objective Loss 2.378660                                        LR 0.100000    Time 0.241350    
2024-04-23 19:14:46,732 - Epoch: [161][  160/  267]    Overall Loss 2.379171    Objective Loss 2.379171                                        LR 0.100000    Time 0.237781    
2024-04-23 19:14:48,796 - Epoch: [118][  100/  296]    Overall Loss 0.748865    Objective Loss 0.748865                                        LR 0.000080    Time 0.233660    
2024-04-23 19:14:49,488 - Epoch: [161][  170/  267]    Overall Loss 2.378126    Objective Loss 2.378126                                        LR 0.100000    Time 0.239989    
2024-04-23 19:14:51,068 - Epoch: [161][  180/  267]    Overall Loss 2.377569    Objective Loss 2.377569                                        LR 0.100000    Time 0.235420    
2024-04-23 19:14:53,812 - Epoch: [161][  190/  267]    Overall Loss 2.379045    Objective Loss 2.379045                                        LR 0.100000    Time 0.237457    
2024-04-23 19:14:55,552 - Epoch: [161][  200/  267]    Overall Loss 2.377776    Objective Loss 2.377776                                        LR 0.100000    Time 0.234272    
2024-04-23 19:14:58,055 - Epoch: [161][  210/  267]    Overall Loss 2.376068    Objective Loss 2.376068                                        LR 0.100000    Time 0.235022    
2024-04-23 19:14:59,994 - Epoch: [161][  220/  267]    Overall Loss 2.376324    Objective Loss 2.376324                                        LR 0.100000    Time 0.233142    
2024-04-23 19:15:02,727 - Epoch: [161][  230/  267]    Overall Loss 2.376948    Objective Loss 2.376948                                        LR 0.100000    Time 0.234878    
2024-04-23 19:15:04,954 - Epoch: [161][  240/  267]    Overall Loss 2.377115    Objective Loss 2.377115                                        LR 0.100000    Time 0.234357    
2024-04-23 19:15:07,771 - Epoch: [161][  250/  267]    Overall Loss 2.377334    Objective Loss 2.377334                                        LR 0.100000    Time 0.236241    
2024-04-23 19:15:09,825 - Epoch: [161][  260/  267]    Overall Loss 2.379378    Objective Loss 2.379378                                        LR 0.100000    Time 0.235041    
2024-04-23 19:15:10,897 - Epoch: [118][  200/  296]    Overall Loss 0.741960    Objective Loss 0.741960                                        LR 0.000080    Time 0.227241    
2024-04-23 19:15:10,906 - Epoch: [161][  267/  267]    Overall Loss 2.380254    Objective Loss 2.380254    Top1 2.325581    Top5 48.837209    LR 0.100000    Time 0.232919    
2024-04-23 19:15:11,127 - --- validate (epoch=161)-----------
2024-04-23 19:15:11,128 - 946 samples (32 per mini-batch)
2024-04-23 19:15:15,099 - Epoch: [161][   10/   30]    Loss 2.433888    Top1 10.000000    Top5 47.187500    
2024-04-23 19:15:16,957 - Epoch: [161][   20/   30]    Loss 2.402589    Top1 10.468750    Top5 51.562500    
2024-04-23 19:15:19,523 - Epoch: [161][   30/   30]    Loss 2.402668    Top1 10.359408    Top5 51.691332    
2024-04-23 19:15:19,732 - ==> Top1: 10.359    Top5: 51.691    Loss: 2.403

2024-04-23 19:15:19,733 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 19:15:19,738 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:15:19,739 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:15:19,758 - 

2024-04-23 19:15:19,759 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:15:23,526 - Epoch: [162][   10/  267]    Overall Loss 2.425787    Objective Loss 2.425787                                        LR 0.100000    Time 0.376426    
2024-04-23 19:15:25,931 - Epoch: [162][   20/  267]    Overall Loss 2.391584    Objective Loss 2.391584                                        LR 0.100000    Time 0.308255    
2024-04-23 19:15:28,825 - Epoch: [162][   30/  267]    Overall Loss 2.389784    Objective Loss 2.389784                                        LR 0.100000    Time 0.301870    
2024-04-23 19:15:30,805 - Epoch: [162][   40/  267]    Overall Loss 2.382679    Objective Loss 2.382679                                        LR 0.100000    Time 0.275823    
2024-04-23 19:15:32,651 - Epoch: [118][  296/  296]    Overall Loss 0.745751    Objective Loss 0.745751    Top1 86.885246    Top5 98.360656    LR 0.000080    Time 0.226971    
2024-04-23 19:15:32,952 - --- validate (epoch=118)-----------
2024-04-23 19:15:32,954 - 3925 samples (32 per mini-batch)
2024-04-23 19:15:33,255 - Epoch: [162][   50/  267]    Overall Loss 2.381978    Objective Loss 2.381978                                        LR 0.100000    Time 0.269597    
2024-04-23 19:15:35,423 - Epoch: [162][   60/  267]    Overall Loss 2.375260    Objective Loss 2.375260                                        LR 0.100000    Time 0.260737    
2024-04-23 19:15:37,545 - Epoch: [162][   70/  267]    Overall Loss 2.368984    Objective Loss 2.368984                                        LR 0.100000    Time 0.253754    
2024-04-23 19:15:40,240 - Epoch: [162][   80/  267]    Overall Loss 2.372937    Objective Loss 2.372937                                        LR 0.100000    Time 0.255691    
2024-04-23 19:15:42,683 - Epoch: [162][   90/  267]    Overall Loss 2.372879    Objective Loss 2.372879                                        LR 0.100000    Time 0.254394    
2024-04-23 19:15:45,022 - Epoch: [162][  100/  267]    Overall Loss 2.370175    Objective Loss 2.370175                                        LR 0.100000    Time 0.252311    
2024-04-23 19:15:47,505 - Epoch: [162][  110/  267]    Overall Loss 2.370451    Objective Loss 2.370451                                        LR 0.100000    Time 0.251917    
2024-04-23 19:15:49,875 - Epoch: [162][  120/  267]    Overall Loss 2.370302    Objective Loss 2.370302                                        LR 0.100000    Time 0.250654    
2024-04-23 19:15:52,457 - Epoch: [162][  130/  267]    Overall Loss 2.371853    Objective Loss 2.371853                                        LR 0.100000    Time 0.251210    
2024-04-23 19:15:54,629 - Epoch: [162][  140/  267]    Overall Loss 2.372249    Objective Loss 2.372249                                        LR 0.100000    Time 0.248758    
2024-04-23 19:15:56,815 - Epoch: [162][  150/  267]    Overall Loss 2.372484    Objective Loss 2.372484                                        LR 0.100000    Time 0.246724    
2024-04-23 19:15:59,022 - Epoch: [162][  160/  267]    Overall Loss 2.374210    Objective Loss 2.374210                                        LR 0.100000    Time 0.245079    
2024-04-23 19:15:59,108 - Epoch: [118][  100/  123]    Loss 0.671151    Top1 78.406250    Top5 97.218750    
2024-04-23 19:16:01,070 - Epoch: [162][  170/  267]    Overall Loss 2.373081    Objective Loss 2.373081                                        LR 0.100000    Time 0.242695    
2024-04-23 19:16:03,693 - Epoch: [162][  180/  267]    Overall Loss 2.372385    Objective Loss 2.372385                                        LR 0.100000    Time 0.243767    
2024-04-23 19:16:04,739 - Epoch: [118][  123/  123]    Loss 0.671384    Top1 78.267516    Top5 97.095541    
2024-04-23 19:16:05,035 - ==> Top1: 78.268    Top5: 97.096    Loss: 0.671

2024-04-23 19:16:05,046 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:16:05,047 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:16:05,100 - 

2024-04-23 19:16:05,101 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:16:05,496 - Epoch: [162][  190/  267]    Overall Loss 2.372847    Objective Loss 2.372847                                        LR 0.100000    Time 0.240413    
2024-04-23 19:16:07,793 - Epoch: [162][  200/  267]    Overall Loss 2.370199    Objective Loss 2.370199                                        LR 0.100000    Time 0.239861    
2024-04-23 19:16:10,433 - Epoch: [162][  210/  267]    Overall Loss 2.369161    Objective Loss 2.369161                                        LR 0.100000    Time 0.240997    
2024-04-23 19:16:12,316 - Epoch: [162][  220/  267]    Overall Loss 2.370967    Objective Loss 2.370967                                        LR 0.100000    Time 0.238585    
2024-04-23 19:16:15,155 - Epoch: [162][  230/  267]    Overall Loss 2.371849    Objective Loss 2.371849                                        LR 0.100000    Time 0.240538    
2024-04-23 19:16:17,294 - Epoch: [162][  240/  267]    Overall Loss 2.371650    Objective Loss 2.371650                                        LR 0.100000    Time 0.239417    
2024-04-23 19:16:20,152 - Epoch: [162][  250/  267]    Overall Loss 2.369999    Objective Loss 2.369999                                        LR 0.100000    Time 0.241261    
2024-04-23 19:16:22,506 - Epoch: [162][  260/  267]    Overall Loss 2.369162    Objective Loss 2.369162                                        LR 0.100000    Time 0.241027    
2024-04-23 19:16:23,992 - Epoch: [162][  267/  267]    Overall Loss 2.367825    Objective Loss 2.367825    Top1 18.604651    Top5 60.465116    LR 0.100000    Time 0.240265    
2024-04-23 19:16:24,205 - --- validate (epoch=162)-----------
2024-04-23 19:16:24,207 - 946 samples (32 per mini-batch)
2024-04-23 19:16:28,124 - Epoch: [162][   10/   30]    Loss 2.363380    Top1 10.000000    Top5 51.250000    
2024-04-23 19:16:29,861 - Epoch: [162][   20/   30]    Loss 2.361378    Top1 9.843750    Top5 52.031250    
2024-04-23 19:16:30,815 - Epoch: [119][  100/  296]    Overall Loss 0.736504    Objective Loss 0.736504                                        LR 0.000080    Time 0.256929    
2024-04-23 19:16:32,565 - Epoch: [162][   30/   30]    Loss 2.362367    Top1 10.253700    Top5 51.268499    
2024-04-23 19:16:32,792 - ==> Top1: 10.254    Top5: 51.268    Loss: 2.362

2024-04-23 19:16:32,794 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 19:16:32,800 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:16:32,801 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:16:32,822 - 

2024-04-23 19:16:32,822 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:16:35,945 - Epoch: [163][   10/  267]    Overall Loss 2.340360    Objective Loss 2.340360                                        LR 0.100000    Time 0.311912    
2024-04-23 19:16:37,695 - Epoch: [163][   20/  267]    Overall Loss 2.355875    Objective Loss 2.355875                                        LR 0.100000    Time 0.243292    
2024-04-23 19:16:40,280 - Epoch: [163][   30/  267]    Overall Loss 2.380073    Objective Loss 2.380073                                        LR 0.100000    Time 0.248283    
2024-04-23 19:16:42,706 - Epoch: [163][   40/  267]    Overall Loss 2.377541    Objective Loss 2.377541                                        LR 0.100000    Time 0.246802    
2024-04-23 19:16:44,515 - Epoch: [163][   50/  267]    Overall Loss 2.373899    Objective Loss 2.373899                                        LR 0.100000    Time 0.233553    
2024-04-23 19:16:46,858 - Epoch: [163][   60/  267]    Overall Loss 2.374721    Objective Loss 2.374721                                        LR 0.100000    Time 0.233619    
2024-04-23 19:16:48,570 - Epoch: [163][   70/  267]    Overall Loss 2.375735    Objective Loss 2.375735                                        LR 0.100000    Time 0.224658    
2024-04-23 19:16:51,448 - Epoch: [163][   80/  267]    Overall Loss 2.372760    Objective Loss 2.372760                                        LR 0.100000    Time 0.232508    
2024-04-23 19:16:52,747 - Epoch: [119][  200/  296]    Overall Loss 0.754945    Objective Loss 0.754945                                        LR 0.000080    Time 0.238022    
2024-04-23 19:16:53,451 - Epoch: [163][   90/  267]    Overall Loss 2.374168    Objective Loss 2.374168                                        LR 0.100000    Time 0.228886    
2024-04-23 19:16:55,843 - Epoch: [163][  100/  267]    Overall Loss 2.374854    Objective Loss 2.374854                                        LR 0.100000    Time 0.229880    
2024-04-23 19:16:57,643 - Epoch: [163][  110/  267]    Overall Loss 2.375681    Objective Loss 2.375681                                        LR 0.100000    Time 0.225317    
2024-04-23 19:17:00,545 - Epoch: [163][  120/  267]    Overall Loss 2.374448    Objective Loss 2.374448                                        LR 0.100000    Time 0.230702    
2024-04-23 19:17:02,667 - Epoch: [163][  130/  267]    Overall Loss 2.375523    Objective Loss 2.375523                                        LR 0.100000    Time 0.229254    
2024-04-23 19:17:05,516 - Epoch: [163][  140/  267]    Overall Loss 2.373805    Objective Loss 2.373805                                        LR 0.100000    Time 0.233212    
2024-04-23 19:17:07,689 - Epoch: [163][  150/  267]    Overall Loss 2.374070    Objective Loss 2.374070                                        LR 0.100000    Time 0.232134    
2024-04-23 19:17:10,944 - Epoch: [163][  160/  267]    Overall Loss 2.373892    Objective Loss 2.373892                                        LR 0.100000    Time 0.237950    
2024-04-23 19:17:13,133 - Epoch: [163][  170/  267]    Overall Loss 2.375191    Objective Loss 2.375191                                        LR 0.100000    Time 0.236807    
2024-04-23 19:17:15,985 - Epoch: [163][  180/  267]    Overall Loss 2.374689    Objective Loss 2.374689                                        LR 0.100000    Time 0.239478    
2024-04-23 19:17:16,860 - Epoch: [119][  296/  296]    Overall Loss 0.747116    Objective Loss 0.747116    Top1 72.131148    Top5 98.360656    LR 0.000080    Time 0.242221    
2024-04-23 19:17:17,155 - --- validate (epoch=119)-----------
2024-04-23 19:17:17,156 - 3925 samples (32 per mini-batch)
2024-04-23 19:17:17,332 - Epoch: [163][  190/  267]    Overall Loss 2.373976    Objective Loss 2.373976                                        LR 0.100000    Time 0.233951    
2024-04-23 19:17:19,802 - Epoch: [163][  200/  267]    Overall Loss 2.374745    Objective Loss 2.374745                                        LR 0.100000    Time 0.234593    
2024-04-23 19:17:21,675 - Epoch: [163][  210/  267]    Overall Loss 2.374271    Objective Loss 2.374271                                        LR 0.100000    Time 0.232328    
2024-04-23 19:17:24,442 - Epoch: [163][  220/  267]    Overall Loss 2.374118    Objective Loss 2.374118                                        LR 0.100000    Time 0.234332    
2024-04-23 19:17:26,541 - Epoch: [163][  230/  267]    Overall Loss 2.374598    Objective Loss 2.374598                                        LR 0.100000    Time 0.233256    
2024-04-23 19:17:29,143 - Epoch: [163][  240/  267]    Overall Loss 2.374139    Objective Loss 2.374139                                        LR 0.100000    Time 0.234366    
2024-04-23 19:17:30,649 - Epoch: [163][  250/  267]    Overall Loss 2.374629    Objective Loss 2.374629                                        LR 0.100000    Time 0.231007    
2024-04-23 19:17:33,359 - Epoch: [163][  260/  267]    Overall Loss 2.374207    Objective Loss 2.374207                                        LR 0.100000    Time 0.232533    
2024-04-23 19:17:34,767 - Epoch: [163][  267/  267]    Overall Loss 2.374576    Objective Loss 2.374576    Top1 4.651163    Top5 44.186047    LR 0.100000    Time 0.231704    
2024-04-23 19:17:35,014 - --- validate (epoch=163)-----------
2024-04-23 19:17:35,015 - 946 samples (32 per mini-batch)
2024-04-23 19:17:38,898 - Epoch: [163][   10/   30]    Loss 2.351754    Top1 8.750000    Top5 52.187500    
2024-04-23 19:17:41,054 - Epoch: [163][   20/   30]    Loss 2.360982    Top1 8.593750    Top5 50.000000    
2024-04-23 19:17:43,534 - Epoch: [119][  100/  123]    Loss 0.676729    Top1 77.843750    Top5 97.375000    
2024-04-23 19:17:43,758 - Epoch: [163][   30/   30]    Loss 2.356862    Top1 9.196617    Top5 50.317125    
2024-04-23 19:17:43,952 - ==> Top1: 9.197    Top5: 50.317    Loss: 2.357

2024-04-23 19:17:43,954 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 19:17:43,960 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:17:43,961 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:17:43,977 - 

2024-04-23 19:17:43,978 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:17:47,778 - Epoch: [164][   10/  267]    Overall Loss 2.336339    Objective Loss 2.336339                                        LR 0.100000    Time 0.379531    
2024-04-23 19:17:49,170 - Epoch: [119][  123/  123]    Loss 0.672468    Top1 77.987261    Top5 97.299363    
2024-04-23 19:17:49,392 - ==> Top1: 77.987    Top5: 97.299    Loss: 0.672

2024-04-23 19:17:49,402 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:17:49,403 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:17:49,451 - 

2024-04-23 19:17:49,451 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:17:49,526 - Epoch: [164][   20/  267]    Overall Loss 2.361260    Objective Loss 2.361260                                        LR 0.100000    Time 0.277033    
2024-04-23 19:17:51,233 - Epoch: [164][   30/  267]    Overall Loss 2.357661    Objective Loss 2.357661                                        LR 0.100000    Time 0.241509    
2024-04-23 19:17:53,299 - Epoch: [164][   40/  267]    Overall Loss 2.357386    Objective Loss 2.357386                                        LR 0.100000    Time 0.232709    
2024-04-23 19:17:54,646 - Epoch: [164][   50/  267]    Overall Loss 2.362945    Objective Loss 2.362945                                        LR 0.100000    Time 0.213052    
2024-04-23 19:17:56,101 - Epoch: [164][   60/  267]    Overall Loss 2.364864    Objective Loss 2.364864                                        LR 0.100000    Time 0.201756    
2024-04-23 19:17:58,187 - Epoch: [164][   70/  267]    Overall Loss 2.363572    Objective Loss 2.363572                                        LR 0.100000    Time 0.202687    
2024-04-23 19:18:00,252 - Epoch: [164][   80/  267]    Overall Loss 2.364070    Objective Loss 2.364070                                        LR 0.100000    Time 0.203123    
2024-04-23 19:18:02,349 - Epoch: [164][   90/  267]    Overall Loss 2.362884    Objective Loss 2.362884                                        LR 0.100000    Time 0.203809    
2024-04-23 19:18:04,421 - Epoch: [164][  100/  267]    Overall Loss 2.366492    Objective Loss 2.366492                                        LR 0.100000    Time 0.204115    
2024-04-23 19:18:06,867 - Epoch: [164][  110/  267]    Overall Loss 2.363265    Objective Loss 2.363265                                        LR 0.100000    Time 0.207776    
2024-04-23 19:18:09,836 - Epoch: [164][  120/  267]    Overall Loss 2.361093    Objective Loss 2.361093                                        LR 0.100000    Time 0.215169    
2024-04-23 19:18:12,710 - Epoch: [164][  130/  267]    Overall Loss 2.358097    Objective Loss 2.358097                                        LR 0.100000    Time 0.220705    
2024-04-23 19:18:13,418 - Epoch: [120][  100/  296]    Overall Loss 0.743245    Objective Loss 0.743245                                        LR 0.000080    Time 0.239451    
2024-04-23 19:18:15,260 - Epoch: [164][  140/  267]    Overall Loss 2.356593    Objective Loss 2.356593                                        LR 0.100000    Time 0.223123    
2024-04-23 19:18:17,489 - Epoch: [164][  150/  267]    Overall Loss 2.357173    Objective Loss 2.357173                                        LR 0.100000    Time 0.223079    
2024-04-23 19:18:19,538 - Epoch: [164][  160/  267]    Overall Loss 2.355881    Objective Loss 2.355881                                        LR 0.100000    Time 0.221922    
2024-04-23 19:18:22,018 - Epoch: [164][  170/  267]    Overall Loss 2.356117    Objective Loss 2.356117                                        LR 0.100000    Time 0.223436    
2024-04-23 19:18:24,030 - Epoch: [164][  180/  267]    Overall Loss 2.357470    Objective Loss 2.357470                                        LR 0.100000    Time 0.222185    
2024-04-23 19:18:26,667 - Epoch: [164][  190/  267]    Overall Loss 2.358743    Objective Loss 2.358743                                        LR 0.100000    Time 0.224356    
2024-04-23 19:18:28,919 - Epoch: [164][  200/  267]    Overall Loss 2.359939    Objective Loss 2.359939                                        LR 0.100000    Time 0.224380    
2024-04-23 19:18:31,005 - Epoch: [164][  210/  267]    Overall Loss 2.359466    Objective Loss 2.359466                                        LR 0.100000    Time 0.223613    
2024-04-23 19:18:33,113 - Epoch: [164][  220/  267]    Overall Loss 2.361514    Objective Loss 2.361514                                        LR 0.100000    Time 0.223016    
2024-04-23 19:18:35,884 - Epoch: [164][  230/  267]    Overall Loss 2.362283    Objective Loss 2.362283                                        LR 0.100000    Time 0.225356    
2024-04-23 19:18:37,106 - Epoch: [120][  200/  296]    Overall Loss 0.747244    Objective Loss 0.747244                                        LR 0.000080    Time 0.238066    
2024-04-23 19:18:37,830 - Epoch: [164][  240/  267]    Overall Loss 2.362690    Objective Loss 2.362690                                        LR 0.100000    Time 0.224064    
2024-04-23 19:18:40,380 - Epoch: [164][  250/  267]    Overall Loss 2.362583    Objective Loss 2.362583                                        LR 0.100000    Time 0.225290    
2024-04-23 19:18:42,329 - Epoch: [164][  260/  267]    Overall Loss 2.362870    Objective Loss 2.362870                                        LR 0.100000    Time 0.224106    
2024-04-23 19:18:43,877 - Epoch: [164][  267/  267]    Overall Loss 2.363303    Objective Loss 2.363303    Top1 11.627907    Top5 55.813953    LR 0.100000    Time 0.224020    
2024-04-23 19:18:44,150 - --- validate (epoch=164)-----------
2024-04-23 19:18:44,152 - 946 samples (32 per mini-batch)
2024-04-23 19:18:47,870 - Epoch: [164][   10/   30]    Loss 2.345881    Top1 9.687500    Top5 50.937500    
2024-04-23 19:18:49,811 - Epoch: [164][   20/   30]    Loss 2.350397    Top1 11.093750    Top5 50.312500    
2024-04-23 19:18:51,627 - Epoch: [164][   30/   30]    Loss 2.350105    Top1 10.570825    Top5 49.894292    
2024-04-23 19:18:51,816 - ==> Top1: 10.571    Top5: 49.894    Loss: 2.350

2024-04-23 19:18:51,818 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 19:18:51,824 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:18:51,825 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:18:51,844 - 

2024-04-23 19:18:51,844 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:18:55,933 - Epoch: [165][   10/  267]    Overall Loss 2.367895    Objective Loss 2.367895                                        LR 0.100000    Time 0.408495    
2024-04-23 19:18:57,903 - Epoch: [165][   20/  267]    Overall Loss 2.378751    Objective Loss 2.378751                                        LR 0.100000    Time 0.302584    
2024-04-23 19:18:57,944 - Epoch: [120][  296/  296]    Overall Loss 0.753895    Objective Loss 0.753895    Top1 77.049180    Top5 100.000000    LR 0.000080    Time 0.231190    
2024-04-23 19:18:58,247 - --- validate (epoch=120)-----------
2024-04-23 19:18:58,249 - 3925 samples (32 per mini-batch)
2024-04-23 19:18:59,436 - Epoch: [165][   30/  267]    Overall Loss 2.376933    Objective Loss 2.376933                                        LR 0.100000    Time 0.252743    
2024-04-23 19:19:01,211 - Epoch: [165][   40/  267]    Overall Loss 2.361420    Objective Loss 2.361420                                        LR 0.100000    Time 0.233860    
2024-04-23 19:19:03,682 - Epoch: [165][   50/  267]    Overall Loss 2.372151    Objective Loss 2.372151                                        LR 0.100000    Time 0.236448    
2024-04-23 19:19:05,577 - Epoch: [165][   60/  267]    Overall Loss 2.379299    Objective Loss 2.379299                                        LR 0.100000    Time 0.228566    
2024-04-23 19:19:08,108 - Epoch: [165][   70/  267]    Overall Loss 2.378973    Objective Loss 2.378973                                        LR 0.100000    Time 0.232027    
2024-04-23 19:19:09,837 - Epoch: [165][   80/  267]    Overall Loss 2.377444    Objective Loss 2.377444                                        LR 0.100000    Time 0.224595    
2024-04-23 19:19:12,240 - Epoch: [165][   90/  267]    Overall Loss 2.381694    Objective Loss 2.381694                                        LR 0.100000    Time 0.226300    
2024-04-23 19:19:13,599 - Epoch: [165][  100/  267]    Overall Loss 2.380999    Objective Loss 2.380999                                        LR 0.100000    Time 0.217239    
2024-04-23 19:19:16,128 - Epoch: [165][  110/  267]    Overall Loss 2.379211    Objective Loss 2.379211                                        LR 0.100000    Time 0.220461    
2024-04-23 19:19:17,832 - Epoch: [165][  120/  267]    Overall Loss 2.379717    Objective Loss 2.379717                                        LR 0.100000    Time 0.216263    
2024-04-23 19:19:20,147 - Epoch: [165][  130/  267]    Overall Loss 2.378740    Objective Loss 2.378740                                        LR 0.100000    Time 0.217416    
2024-04-23 19:19:21,204 - Epoch: [120][  100/  123]    Loss 0.679031    Top1 77.875000    Top5 97.406250    
2024-04-23 19:19:21,790 - Epoch: [165][  140/  267]    Overall Loss 2.375509    Objective Loss 2.375509                                        LR 0.100000    Time 0.213595    
2024-04-23 19:19:23,861 - Epoch: [165][  150/  267]    Overall Loss 2.375970    Objective Loss 2.375970                                        LR 0.100000    Time 0.213145    
2024-04-23 19:19:25,255 - Epoch: [165][  160/  267]    Overall Loss 2.375521    Objective Loss 2.375521                                        LR 0.100000    Time 0.208516    
2024-04-23 19:19:25,740 - Epoch: [120][  123/  123]    Loss 0.676608    Top1 77.961783    Top5 97.477707    
2024-04-23 19:19:26,037 - ==> Top1: 77.962    Top5: 97.478    Loss: 0.677

2024-04-23 19:19:26,047 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:19:26,048 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:19:26,096 - 

2024-04-23 19:19:26,097 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:19:26,671 - Epoch: [165][  170/  267]    Overall Loss 2.376401    Objective Loss 2.376401                                        LR 0.100000    Time 0.204569    
2024-04-23 19:19:28,245 - Epoch: [165][  180/  267]    Overall Loss 2.376000    Objective Loss 2.376000                                        LR 0.100000    Time 0.201937    
2024-04-23 19:19:30,437 - Epoch: [165][  190/  267]    Overall Loss 2.375470    Objective Loss 2.375470                                        LR 0.100000    Time 0.202813    
2024-04-23 19:19:32,112 - Epoch: [165][  200/  267]    Overall Loss 2.373684    Objective Loss 2.373684                                        LR 0.100000    Time 0.201030    
2024-04-23 19:19:34,506 - Epoch: [165][  210/  267]    Overall Loss 2.372617    Objective Loss 2.372617                                        LR 0.100000    Time 0.202840    
2024-04-23 19:19:36,191 - Epoch: [165][  220/  267]    Overall Loss 2.372209    Objective Loss 2.372209                                        LR 0.100000    Time 0.201271    
2024-04-23 19:19:38,790 - Epoch: [165][  230/  267]    Overall Loss 2.372511    Objective Loss 2.372511                                        LR 0.100000    Time 0.203805    
2024-04-23 19:19:40,587 - Epoch: [165][  240/  267]    Overall Loss 2.371895    Objective Loss 2.371895                                        LR 0.100000    Time 0.202788    
2024-04-23 19:19:43,146 - Epoch: [165][  250/  267]    Overall Loss 2.372558    Objective Loss 2.372558                                        LR 0.100000    Time 0.204900    
2024-04-23 19:19:44,932 - Epoch: [165][  260/  267]    Overall Loss 2.371759    Objective Loss 2.371759                                        LR 0.100000    Time 0.203877    
2024-04-23 19:19:46,223 - Epoch: [165][  267/  267]    Overall Loss 2.372386    Objective Loss 2.372386    Top1 20.930233    Top5 51.162791    LR 0.100000    Time 0.203360    
2024-04-23 19:19:46,444 - --- validate (epoch=165)-----------
2024-04-23 19:19:46,445 - 946 samples (32 per mini-batch)
2024-04-23 19:19:49,798 - Epoch: [121][  100/  296]    Overall Loss 0.729540    Objective Loss 0.729540                                        LR 0.000080    Time 0.236809    
2024-04-23 19:19:51,092 - Epoch: [165][   10/   30]    Loss 2.366379    Top1 8.750000    Top5 47.187500    
2024-04-23 19:19:53,704 - Epoch: [165][   20/   30]    Loss 2.360922    Top1 9.062500    Top5 49.062500    
2024-04-23 19:19:56,759 - Epoch: [165][   30/   30]    Loss 2.352810    Top1 10.253700    Top5 50.317125    
2024-04-23 19:19:57,036 - ==> Top1: 10.254    Top5: 50.317    Loss: 2.353

2024-04-23 19:19:57,038 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 19:19:57,044 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:19:57,045 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:19:57,064 - 

2024-04-23 19:19:57,065 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:20:01,162 - Epoch: [166][   10/  267]    Overall Loss 2.374242    Objective Loss 2.374242                                        LR 0.100000    Time 0.409284    
2024-04-23 19:20:03,132 - Epoch: [166][   20/  267]    Overall Loss 2.386019    Objective Loss 2.386019                                        LR 0.100000    Time 0.303025    
2024-04-23 19:20:06,188 - Epoch: [166][   30/  267]    Overall Loss 2.376671    Objective Loss 2.376671                                        LR 0.100000    Time 0.303781    
2024-04-23 19:20:08,792 - Epoch: [166][   40/  267]    Overall Loss 2.360748    Objective Loss 2.360748                                        LR 0.100000    Time 0.292856    
2024-04-23 19:20:11,518 - Epoch: [166][   50/  267]    Overall Loss 2.374164    Objective Loss 2.374164                                        LR 0.100000    Time 0.288752    
2024-04-23 19:20:13,478 - Epoch: [166][   60/  267]    Overall Loss 2.366362    Objective Loss 2.366362                                        LR 0.100000    Time 0.273257    
2024-04-23 19:20:14,709 - Epoch: [121][  200/  296]    Overall Loss 0.731752    Objective Loss 0.731752                                        LR 0.000080    Time 0.242861    
2024-04-23 19:20:16,049 - Epoch: [166][   70/  267]    Overall Loss 2.361607    Objective Loss 2.361607                                        LR 0.100000    Time 0.270903    
2024-04-23 19:20:17,834 - Epoch: [166][   80/  267]    Overall Loss 2.360499    Objective Loss 2.360499                                        LR 0.100000    Time 0.259309    
2024-04-23 19:20:20,660 - Epoch: [166][   90/  267]    Overall Loss 2.363913    Objective Loss 2.363913                                        LR 0.100000    Time 0.261866    
2024-04-23 19:20:22,666 - Epoch: [166][  100/  267]    Overall Loss 2.359432    Objective Loss 2.359432                                        LR 0.100000    Time 0.255711    
2024-04-23 19:20:25,471 - Epoch: [166][  110/  267]    Overall Loss 2.358964    Objective Loss 2.358964                                        LR 0.100000    Time 0.257940    
2024-04-23 19:20:27,387 - Epoch: [166][  120/  267]    Overall Loss 2.357477    Objective Loss 2.357477                                        LR 0.100000    Time 0.252394    
2024-04-23 19:20:29,821 - Epoch: [166][  130/  267]    Overall Loss 2.359591    Objective Loss 2.359591                                        LR 0.100000    Time 0.251679    
2024-04-23 19:20:31,526 - Epoch: [166][  140/  267]    Overall Loss 2.363196    Objective Loss 2.363196                                        LR 0.100000    Time 0.245863    
2024-04-23 19:20:33,998 - Epoch: [166][  150/  267]    Overall Loss 2.361221    Objective Loss 2.361221                                        LR 0.100000    Time 0.245939    
2024-04-23 19:20:35,943 - Epoch: [166][  160/  267]    Overall Loss 2.362123    Objective Loss 2.362123                                        LR 0.100000    Time 0.242703    
2024-04-23 19:20:36,794 - Epoch: [121][  296/  296]    Overall Loss 0.739809    Objective Loss 0.739809    Top1 85.245902    Top5 95.081967    LR 0.000080    Time 0.238647    
2024-04-23 19:20:37,080 - --- validate (epoch=121)-----------
2024-04-23 19:20:37,081 - 3925 samples (32 per mini-batch)
2024-04-23 19:20:37,541 - Epoch: [166][  170/  267]    Overall Loss 2.362100    Objective Loss 2.362100                                        LR 0.100000    Time 0.237810    
2024-04-23 19:20:39,010 - Epoch: [166][  180/  267]    Overall Loss 2.359607    Objective Loss 2.359607                                        LR 0.100000    Time 0.232744    
2024-04-23 19:20:41,744 - Epoch: [166][  190/  267]    Overall Loss 2.360639    Objective Loss 2.360639                                        LR 0.100000    Time 0.234869    
2024-04-23 19:20:43,710 - Epoch: [166][  200/  267]    Overall Loss 2.359347    Objective Loss 2.359347                                        LR 0.100000    Time 0.232942    
2024-04-23 19:20:46,514 - Epoch: [166][  210/  267]    Overall Loss 2.357928    Objective Loss 2.357928                                        LR 0.100000    Time 0.235190    
2024-04-23 19:20:48,509 - Epoch: [166][  220/  267]    Overall Loss 2.360653    Objective Loss 2.360653                                        LR 0.100000    Time 0.233559    
2024-04-23 19:20:51,042 - Epoch: [166][  230/  267]    Overall Loss 2.360608    Objective Loss 2.360608                                        LR 0.100000    Time 0.234403    
2024-04-23 19:20:53,630 - Epoch: [166][  240/  267]    Overall Loss 2.361775    Objective Loss 2.361775                                        LR 0.100000    Time 0.235408    
2024-04-23 19:20:55,895 - Epoch: [166][  250/  267]    Overall Loss 2.360844    Objective Loss 2.360844                                        LR 0.100000    Time 0.235039    
2024-04-23 19:20:58,693 - Epoch: [166][  260/  267]    Overall Loss 2.360593    Objective Loss 2.360593                                        LR 0.100000    Time 0.236754    
2024-04-23 19:20:59,444 - Epoch: [166][  267/  267]    Overall Loss 2.361342    Objective Loss 2.361342    Top1 9.302326    Top5 51.162791    LR 0.100000    Time 0.233353    
2024-04-23 19:20:59,656 - --- validate (epoch=166)-----------
2024-04-23 19:20:59,657 - 946 samples (32 per mini-batch)
2024-04-23 19:21:03,546 - Epoch: [121][  100/  123]    Loss 0.663084    Top1 78.593750    Top5 97.406250    
2024-04-23 19:21:03,779 - Epoch: [166][   10/   30]    Loss 2.340049    Top1 10.000000    Top5 48.750000    
2024-04-23 19:21:06,337 - Epoch: [166][   20/   30]    Loss 2.334300    Top1 9.531250    Top5 49.062500    
2024-04-23 19:21:08,845 - Epoch: [166][   30/   30]    Loss 2.340953    Top1 8.456660    Top5 47.780127    
2024-04-23 19:21:08,995 - ==> Top1: 8.457    Top5: 47.780    Loss: 2.341

2024-04-23 19:21:08,997 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 19:21:09,002 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:21:09,003 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:21:09,018 - 

2024-04-23 19:21:09,018 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:21:09,278 - Epoch: [121][  123/  123]    Loss 0.670817    Top1 78.089172    Top5 97.273885    
2024-04-23 19:21:09,531 - ==> Top1: 78.089    Top5: 97.274    Loss: 0.671

2024-04-23 19:21:09,542 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:21:09,543 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:21:09,596 - 

2024-04-23 19:21:09,597 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:21:12,697 - Epoch: [167][   10/  267]    Overall Loss 2.340760    Objective Loss 2.340760                                        LR 0.100000    Time 0.367501    
2024-04-23 19:21:15,384 - Epoch: [167][   20/  267]    Overall Loss 2.365767    Objective Loss 2.365767                                        LR 0.100000    Time 0.317898    
2024-04-23 19:21:17,744 - Epoch: [167][   30/  267]    Overall Loss 2.369862    Objective Loss 2.369862                                        LR 0.100000    Time 0.290496    
2024-04-23 19:21:19,868 - Epoch: [167][   40/  267]    Overall Loss 2.374694    Objective Loss 2.374694                                        LR 0.100000    Time 0.270902    
2024-04-23 19:21:22,501 - Epoch: [167][   50/  267]    Overall Loss 2.373928    Objective Loss 2.373928                                        LR 0.100000    Time 0.269335    
2024-04-23 19:21:24,590 - Epoch: [167][   60/  267]    Overall Loss 2.372814    Objective Loss 2.372814                                        LR 0.100000    Time 0.259215    
2024-04-23 19:21:27,339 - Epoch: [167][   70/  267]    Overall Loss 2.375868    Objective Loss 2.375868                                        LR 0.100000    Time 0.261411    
2024-04-23 19:21:29,162 - Epoch: [167][   80/  267]    Overall Loss 2.378635    Objective Loss 2.378635                                        LR 0.100000    Time 0.251477    
2024-04-23 19:21:31,699 - Epoch: [167][   90/  267]    Overall Loss 2.379221    Objective Loss 2.379221                                        LR 0.100000    Time 0.251693    
2024-04-23 19:21:33,647 - Epoch: [167][  100/  267]    Overall Loss 2.378692    Objective Loss 2.378692                                        LR 0.100000    Time 0.245975    
2024-04-23 19:21:34,492 - Epoch: [122][  100/  296]    Overall Loss 0.727596    Objective Loss 0.727596                                        LR 0.000080    Time 0.248742    
2024-04-23 19:21:36,781 - Epoch: [167][  110/  267]    Overall Loss 2.377177    Objective Loss 2.377177                                        LR 0.100000    Time 0.252077    
2024-04-23 19:21:38,948 - Epoch: [167][  120/  267]    Overall Loss 2.376344    Objective Loss 2.376344                                        LR 0.100000    Time 0.249107    
2024-04-23 19:21:42,353 - Epoch: [167][  130/  267]    Overall Loss 2.377891    Objective Loss 2.377891                                        LR 0.100000    Time 0.256114    
2024-04-23 19:21:44,405 - Epoch: [167][  140/  267]    Overall Loss 2.379947    Objective Loss 2.379947                                        LR 0.100000    Time 0.252460    
2024-04-23 19:21:47,362 - Epoch: [167][  150/  267]    Overall Loss 2.381601    Objective Loss 2.381601                                        LR 0.100000    Time 0.255321    
2024-04-23 19:21:49,167 - Epoch: [167][  160/  267]    Overall Loss 2.382986    Objective Loss 2.382986                                        LR 0.100000    Time 0.250629    
2024-04-23 19:21:51,886 - Epoch: [167][  170/  267]    Overall Loss 2.383327    Objective Loss 2.383327                                        LR 0.100000    Time 0.251864    
2024-04-23 19:21:53,876 - Epoch: [167][  180/  267]    Overall Loss 2.381621    Objective Loss 2.381621                                        LR 0.100000    Time 0.248908    
2024-04-23 19:21:56,764 - Epoch: [167][  190/  267]    Overall Loss 2.382232    Objective Loss 2.382232                                        LR 0.100000    Time 0.250991    
2024-04-23 19:21:58,717 - Epoch: [167][  200/  267]    Overall Loss 2.381277    Objective Loss 2.381277                                        LR 0.100000    Time 0.248191    
2024-04-23 19:21:59,715 - Epoch: [122][  200/  296]    Overall Loss 0.740882    Objective Loss 0.740882                                        LR 0.000080    Time 0.250381    
2024-04-23 19:22:01,512 - Epoch: [167][  210/  267]    Overall Loss 2.379932    Objective Loss 2.379932                                        LR 0.100000    Time 0.249672    
2024-04-23 19:22:03,588 - Epoch: [167][  220/  267]    Overall Loss 2.379306    Objective Loss 2.379306                                        LR 0.100000    Time 0.247746    
2024-04-23 19:22:06,479 - Epoch: [167][  230/  267]    Overall Loss 2.377297    Objective Loss 2.377297                                        LR 0.100000    Time 0.249535    
2024-04-23 19:22:08,354 - Epoch: [167][  240/  267]    Overall Loss 2.377668    Objective Loss 2.377668                                        LR 0.100000    Time 0.246933    
2024-04-23 19:22:11,032 - Epoch: [167][  250/  267]    Overall Loss 2.375637    Objective Loss 2.375637                                        LR 0.100000    Time 0.247758    
2024-04-23 19:22:12,939 - Epoch: [167][  260/  267]    Overall Loss 2.374409    Objective Loss 2.374409                                        LR 0.100000    Time 0.245551    
2024-04-23 19:22:14,531 - Epoch: [167][  267/  267]    Overall Loss 2.373329    Objective Loss 2.373329    Top1 6.976744    Top5 46.511628    LR 0.100000    Time 0.245068    
2024-04-23 19:22:14,732 - --- validate (epoch=167)-----------
2024-04-23 19:22:14,733 - 946 samples (32 per mini-batch)
2024-04-23 19:22:18,817 - Epoch: [167][   10/   30]    Loss 2.343345    Top1 8.437500    Top5 47.812500    
2024-04-23 19:22:20,870 - Epoch: [122][  296/  296]    Overall Loss 0.750115    Objective Loss 0.750115    Top1 70.491803    Top5 93.442623    LR 0.000080    Time 0.240583    
2024-04-23 19:22:20,896 - Epoch: [167][   20/   30]    Loss 2.336497    Top1 9.687500    Top5 50.468750    
2024-04-23 19:22:21,189 - --- validate (epoch=122)-----------
2024-04-23 19:22:21,190 - 3925 samples (32 per mini-batch)
2024-04-23 19:22:22,762 - Epoch: [167][   30/   30]    Loss 2.337371    Top1 9.830867    Top5 49.260042    
2024-04-23 19:22:22,996 - ==> Top1: 9.831    Top5: 49.260    Loss: 2.337

2024-04-23 19:22:22,998 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 19:22:23,004 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:22:23,005 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:22:23,027 - 

2024-04-23 19:22:23,029 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:22:26,881 - Epoch: [168][   10/  267]    Overall Loss 2.392090    Objective Loss 2.392090                                        LR 0.100000    Time 0.384751    
2024-04-23 19:22:29,119 - Epoch: [168][   20/  267]    Overall Loss 2.378979    Objective Loss 2.378979                                        LR 0.100000    Time 0.304127    
2024-04-23 19:22:31,269 - Epoch: [168][   30/  267]    Overall Loss 2.363480    Objective Loss 2.363480                                        LR 0.100000    Time 0.274311    
2024-04-23 19:22:33,995 - Epoch: [168][   40/  267]    Overall Loss 2.364208    Objective Loss 2.364208                                        LR 0.100000    Time 0.273797    
2024-04-23 19:22:35,717 - Epoch: [168][   50/  267]    Overall Loss 2.355096    Objective Loss 2.355096                                        LR 0.100000    Time 0.253421    
2024-04-23 19:22:38,262 - Epoch: [168][   60/  267]    Overall Loss 2.359550    Objective Loss 2.359550                                        LR 0.100000    Time 0.253556    
2024-04-23 19:22:40,024 - Epoch: [168][   70/  267]    Overall Loss 2.360195    Objective Loss 2.360195                                        LR 0.100000    Time 0.242460    
2024-04-23 19:22:41,940 - Epoch: [168][   80/  267]    Overall Loss 2.355579    Objective Loss 2.355579                                        LR 0.100000    Time 0.236069    
2024-04-23 19:22:43,499 - Epoch: [168][   90/  267]    Overall Loss 2.353095    Objective Loss 2.353095                                        LR 0.100000    Time 0.227129    
2024-04-23 19:22:45,532 - Epoch: [168][  100/  267]    Overall Loss 2.351131    Objective Loss 2.351131                                        LR 0.100000    Time 0.224715    
2024-04-23 19:22:45,750 - Epoch: [122][  100/  123]    Loss 0.669581    Top1 77.875000    Top5 97.281250    
2024-04-23 19:22:47,411 - Epoch: [168][  110/  267]    Overall Loss 2.352497    Objective Loss 2.352497                                        LR 0.100000    Time 0.221346    
2024-04-23 19:22:49,505 - Epoch: [122][  123/  123]    Loss 0.677698    Top1 77.808917    Top5 97.401274    
2024-04-23 19:22:49,541 - Epoch: [168][  120/  267]    Overall Loss 2.354846    Objective Loss 2.354846                                        LR 0.100000    Time 0.220621    
2024-04-23 19:22:49,768 - ==> Top1: 77.809    Top5: 97.401    Loss: 0.678

2024-04-23 19:22:49,774 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:22:49,774 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:22:49,815 - 

2024-04-23 19:22:49,815 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:22:52,492 - Epoch: [168][  130/  267]    Overall Loss 2.359765    Objective Loss 2.359765                                        LR 0.100000    Time 0.226337    
2024-04-23 19:22:54,516 - Epoch: [168][  140/  267]    Overall Loss 2.360673    Objective Loss 2.360673                                        LR 0.100000    Time 0.224613    
2024-04-23 19:22:57,395 - Epoch: [168][  150/  267]    Overall Loss 2.365044    Objective Loss 2.365044                                        LR 0.100000    Time 0.228816    
2024-04-23 19:22:59,630 - Epoch: [168][  160/  267]    Overall Loss 2.366242    Objective Loss 2.366242                                        LR 0.100000    Time 0.228473    
2024-04-23 19:23:02,747 - Epoch: [168][  170/  267]    Overall Loss 2.366383    Objective Loss 2.366383                                        LR 0.100000    Time 0.233350    
2024-04-23 19:23:04,542 - Epoch: [168][  180/  267]    Overall Loss 2.366003    Objective Loss 2.366003                                        LR 0.100000    Time 0.230343    
2024-04-23 19:23:06,583 - Epoch: [123][  100/  296]    Overall Loss 0.732547    Objective Loss 0.732547                                        LR 0.000080    Time 0.167486    
2024-04-23 19:23:07,123 - Epoch: [168][  190/  267]    Overall Loss 2.364538    Objective Loss 2.364538                                        LR 0.100000    Time 0.231789    
2024-04-23 19:23:08,883 - Epoch: [168][  200/  267]    Overall Loss 2.365238    Objective Loss 2.365238                                        LR 0.100000    Time 0.228984    
2024-04-23 19:23:11,273 - Epoch: [168][  210/  267]    Overall Loss 2.364948    Objective Loss 2.364948                                        LR 0.100000    Time 0.229443    
2024-04-23 19:23:13,107 - Epoch: [168][  220/  267]    Overall Loss 2.362764    Objective Loss 2.362764                                        LR 0.100000    Time 0.227337    
2024-04-23 19:23:15,873 - Epoch: [168][  230/  267]    Overall Loss 2.363489    Objective Loss 2.363489                                        LR 0.100000    Time 0.229471    
2024-04-23 19:23:18,455 - Epoch: [168][  240/  267]    Overall Loss 2.364581    Objective Loss 2.364581                                        LR 0.100000    Time 0.230656    
2024-04-23 19:23:22,077 - Epoch: [168][  250/  267]    Overall Loss 2.364421    Objective Loss 2.364421                                        LR 0.100000    Time 0.235907    
2024-04-23 19:23:24,157 - Epoch: [168][  260/  267]    Overall Loss 2.364779    Objective Loss 2.364779                                        LR 0.100000    Time 0.234820    
2024-04-23 19:23:25,711 - Epoch: [168][  267/  267]    Overall Loss 2.364433    Objective Loss 2.364433    Top1 16.279070    Top5 60.465116    LR 0.100000    Time 0.234476    
2024-04-23 19:23:25,954 - --- validate (epoch=168)-----------
2024-04-23 19:23:25,955 - 946 samples (32 per mini-batch)
2024-04-23 19:23:29,338 - Epoch: [168][   10/   30]    Loss 2.369463    Top1 9.375000    Top5 52.500000    
2024-04-23 19:23:29,846 - Epoch: [123][  200/  296]    Overall Loss 0.709608    Objective Loss 0.709608                                        LR 0.000080    Time 0.199961    
2024-04-23 19:23:31,471 - Epoch: [168][   20/   30]    Loss 2.359367    Top1 10.156250    Top5 52.812500    
2024-04-23 19:23:34,158 - Epoch: [168][   30/   30]    Loss 2.362600    Top1 10.253700    Top5 51.902748    
2024-04-23 19:23:34,372 - ==> Top1: 10.254    Top5: 51.903    Loss: 2.363

2024-04-23 19:23:34,374 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 19:23:34,380 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:23:34,380 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:23:34,397 - 

2024-04-23 19:23:34,398 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:23:37,796 - Epoch: [169][   10/  267]    Overall Loss 2.345991    Objective Loss 2.345991                                        LR 0.100000    Time 0.339330    
2024-04-23 19:23:40,108 - Epoch: [169][   20/  267]    Overall Loss 2.353066    Objective Loss 2.353066                                        LR 0.100000    Time 0.285113    
2024-04-23 19:23:42,632 - Epoch: [169][   30/  267]    Overall Loss 2.358408    Objective Loss 2.358408                                        LR 0.100000    Time 0.274126    
2024-04-23 19:23:45,042 - Epoch: [169][   40/  267]    Overall Loss 2.362412    Objective Loss 2.362412                                        LR 0.100000    Time 0.265772    
2024-04-23 19:23:46,761 - Epoch: [169][   50/  267]    Overall Loss 2.358628    Objective Loss 2.358628                                        LR 0.100000    Time 0.246949    
2024-04-23 19:23:47,189 - Epoch: [123][  296/  296]    Overall Loss 0.718984    Objective Loss 0.718984    Top1 72.131148    Top5 100.000000    LR 0.000080    Time 0.193642    
2024-04-23 19:23:47,505 - --- validate (epoch=123)-----------
2024-04-23 19:23:47,506 - 3925 samples (32 per mini-batch)
2024-04-23 19:23:47,686 - Epoch: [169][   60/  267]    Overall Loss 2.358687    Objective Loss 2.358687                                        LR 0.100000    Time 0.221174    
2024-04-23 19:23:48,616 - Epoch: [169][   70/  267]    Overall Loss 2.357094    Objective Loss 2.357094                                        LR 0.100000    Time 0.202827    
2024-04-23 19:23:49,903 - Epoch: [169][   80/  267]    Overall Loss 2.357190    Objective Loss 2.357190                                        LR 0.100000    Time 0.193543    
2024-04-23 19:23:51,854 - Epoch: [169][   90/  267]    Overall Loss 2.358042    Objective Loss 2.358042                                        LR 0.100000    Time 0.193681    
2024-04-23 19:23:53,392 - Epoch: [169][  100/  267]    Overall Loss 2.360049    Objective Loss 2.360049                                        LR 0.100000    Time 0.189674    
2024-04-23 19:23:55,509 - Epoch: [169][  110/  267]    Overall Loss 2.360511    Objective Loss 2.360511                                        LR 0.100000    Time 0.191642    
2024-04-23 19:23:57,097 - Epoch: [169][  120/  267]    Overall Loss 2.359605    Objective Loss 2.359605                                        LR 0.100000    Time 0.188872    
2024-04-23 19:23:59,227 - Epoch: [169][  130/  267]    Overall Loss 2.361153    Objective Loss 2.361153                                        LR 0.100000    Time 0.190716    
2024-04-23 19:24:00,608 - Epoch: [169][  140/  267]    Overall Loss 2.359370    Objective Loss 2.359370                                        LR 0.100000    Time 0.186938    
2024-04-23 19:24:02,492 - Epoch: [169][  150/  267]    Overall Loss 2.358541    Objective Loss 2.358541                                        LR 0.100000    Time 0.187021    
2024-04-23 19:24:04,114 - Epoch: [169][  160/  267]    Overall Loss 2.360210    Objective Loss 2.360210                                        LR 0.100000    Time 0.185448    
2024-04-23 19:24:06,211 - Epoch: [169][  170/  267]    Overall Loss 2.358212    Objective Loss 2.358212                                        LR 0.100000    Time 0.186859    
2024-04-23 19:24:07,477 - Epoch: [123][  100/  123]    Loss 0.688395    Top1 77.593750    Top5 97.218750    
2024-04-23 19:24:07,685 - Epoch: [169][  180/  267]    Overall Loss 2.358942    Objective Loss 2.358942                                        LR 0.100000    Time 0.184652    
2024-04-23 19:24:09,600 - Epoch: [169][  190/  267]    Overall Loss 2.359042    Objective Loss 2.359042                                        LR 0.100000    Time 0.184997    
2024-04-23 19:24:11,102 - Epoch: [169][  200/  267]    Overall Loss 2.357514    Objective Loss 2.357514                                        LR 0.100000    Time 0.183243    
2024-04-23 19:24:11,415 - Epoch: [123][  123/  123]    Loss 0.673722    Top1 78.038217    Top5 97.273885    
2024-04-23 19:24:11,639 - ==> Top1: 78.038    Top5: 97.274    Loss: 0.674

2024-04-23 19:24:11,649 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:24:11,650 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:24:11,692 - 

2024-04-23 19:24:11,693 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:24:11,784 - Epoch: [169][  210/  267]    Overall Loss 2.358049    Objective Loss 2.358049                                        LR 0.100000    Time 0.177758    
2024-04-23 19:24:12,560 - Epoch: [169][  220/  267]    Overall Loss 2.359121    Objective Loss 2.359121                                        LR 0.100000    Time 0.173196    
2024-04-23 19:24:13,792 - Epoch: [169][  230/  267]    Overall Loss 2.359300    Objective Loss 2.359300                                        LR 0.100000    Time 0.171012    
2024-04-23 19:24:15,604 - Epoch: [169][  240/  267]    Overall Loss 2.361620    Objective Loss 2.361620                                        LR 0.100000    Time 0.171427    
2024-04-23 19:24:16,904 - Epoch: [169][  250/  267]    Overall Loss 2.362151    Objective Loss 2.362151                                        LR 0.100000    Time 0.169757    
2024-04-23 19:24:18,913 - Epoch: [169][  260/  267]    Overall Loss 2.361010    Objective Loss 2.361010                                        LR 0.100000    Time 0.170946    
2024-04-23 19:24:19,619 - Epoch: [169][  267/  267]    Overall Loss 2.360683    Objective Loss 2.360683    Top1 11.627907    Top5 44.186047    LR 0.100000    Time 0.169101    
2024-04-23 19:24:19,773 - --- validate (epoch=169)-----------
2024-04-23 19:24:19,774 - 946 samples (32 per mini-batch)
2024-04-23 19:24:22,819 - Epoch: [169][   10/   30]    Loss 2.394852    Top1 9.375000    Top5 52.187500    
2024-04-23 19:24:24,105 - Epoch: [169][   20/   30]    Loss 2.390262    Top1 10.781250    Top5 50.156250    
2024-04-23 19:24:25,932 - Epoch: [169][   30/   30]    Loss 2.391420    Top1 10.465116    Top5 49.048626    
2024-04-23 19:24:26,108 - ==> Top1: 10.465    Top5: 49.049    Loss: 2.391

2024-04-23 19:24:26,110 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 19:24:26,116 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:24:26,116 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:24:26,131 - 

2024-04-23 19:24:26,132 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:24:29,730 - Epoch: [170][   10/  267]    Overall Loss 2.375167    Objective Loss 2.375167                                        LR 0.100000    Time 0.359420    
2024-04-23 19:24:30,197 - Epoch: [124][  100/  296]    Overall Loss 0.746778    Objective Loss 0.746778                                        LR 0.000080    Time 0.184835    
2024-04-23 19:24:32,045 - Epoch: [170][   20/  267]    Overall Loss 2.364532    Objective Loss 2.364532                                        LR 0.100000    Time 0.295329    
2024-04-23 19:24:35,070 - Epoch: [170][   30/  267]    Overall Loss 2.382006    Objective Loss 2.382006                                        LR 0.100000    Time 0.297623    
2024-04-23 19:24:37,386 - Epoch: [170][   40/  267]    Overall Loss 2.380708    Objective Loss 2.380708                                        LR 0.100000    Time 0.281034    
2024-04-23 19:24:39,662 - Epoch: [170][   50/  267]    Overall Loss 2.375432    Objective Loss 2.375432                                        LR 0.100000    Time 0.270298    
2024-04-23 19:24:42,453 - Epoch: [170][   60/  267]    Overall Loss 2.374962    Objective Loss 2.374962                                        LR 0.100000    Time 0.271721    
2024-04-23 19:24:44,434 - Epoch: [170][   70/  267]    Overall Loss 2.369478    Objective Loss 2.369478                                        LR 0.100000    Time 0.261088    
2024-04-23 19:24:46,973 - Epoch: [170][   80/  267]    Overall Loss 2.369820    Objective Loss 2.369820                                        LR 0.100000    Time 0.260155    
2024-04-23 19:24:48,978 - Epoch: [170][   90/  267]    Overall Loss 2.366900    Objective Loss 2.366900                                        LR 0.100000    Time 0.253493    
2024-04-23 19:24:51,775 - Epoch: [170][  100/  267]    Overall Loss 2.369486    Objective Loss 2.369486                                        LR 0.100000    Time 0.256067    
2024-04-23 19:24:53,726 - Epoch: [170][  110/  267]    Overall Loss 2.371725    Objective Loss 2.371725                                        LR 0.100000    Time 0.250497    
2024-04-23 19:24:54,365 - Epoch: [124][  200/  296]    Overall Loss 0.742431    Objective Loss 0.742431                                        LR 0.000080    Time 0.213160    
2024-04-23 19:24:56,130 - Epoch: [170][  120/  267]    Overall Loss 2.372682    Objective Loss 2.372682                                        LR 0.100000    Time 0.249628    
2024-04-23 19:24:57,849 - Epoch: [170][  130/  267]    Overall Loss 2.369827    Objective Loss 2.369827                                        LR 0.100000    Time 0.243635    
2024-04-23 19:24:59,682 - Epoch: [170][  140/  267]    Overall Loss 2.366977    Objective Loss 2.366977                                        LR 0.100000    Time 0.239307    
2024-04-23 19:25:01,857 - Epoch: [170][  150/  267]    Overall Loss 2.365998    Objective Loss 2.365998                                        LR 0.100000    Time 0.237836    
2024-04-23 19:25:04,870 - Epoch: [170][  160/  267]    Overall Loss 2.368996    Objective Loss 2.368996                                        LR 0.100000    Time 0.241775    
2024-04-23 19:25:06,922 - Epoch: [170][  170/  267]    Overall Loss 2.367672    Objective Loss 2.367672                                        LR 0.100000    Time 0.239609    
2024-04-23 19:25:09,382 - Epoch: [170][  180/  267]    Overall Loss 2.368988    Objective Loss 2.368988                                        LR 0.100000    Time 0.239944    
2024-04-23 19:25:11,082 - Epoch: [170][  190/  267]    Overall Loss 2.369446    Objective Loss 2.369446                                        LR 0.100000    Time 0.236246    
2024-04-23 19:25:13,559 - Epoch: [170][  200/  267]    Overall Loss 2.368992    Objective Loss 2.368992                                        LR 0.100000    Time 0.236804    
2024-04-23 19:25:15,007 - Epoch: [170][  210/  267]    Overall Loss 2.368541    Objective Loss 2.368541                                        LR 0.100000    Time 0.232410    
2024-04-23 19:25:15,061 - Epoch: [124][  296/  296]    Overall Loss 0.728876    Objective Loss 0.728876    Top1 78.688525    Top5 96.721311    LR 0.000080    Time 0.213880    
2024-04-23 19:25:15,375 - --- validate (epoch=124)-----------
2024-04-23 19:25:15,377 - 3925 samples (32 per mini-batch)
2024-04-23 19:25:16,678 - Epoch: [170][  220/  267]    Overall Loss 2.369035    Objective Loss 2.369035                                        LR 0.100000    Time 0.229431    
2024-04-23 19:25:18,309 - Epoch: [170][  230/  267]    Overall Loss 2.370502    Objective Loss 2.370502                                        LR 0.100000    Time 0.226533    
2024-04-23 19:25:20,800 - Epoch: [170][  240/  267]    Overall Loss 2.370336    Objective Loss 2.370336                                        LR 0.100000    Time 0.227455    
2024-04-23 19:25:22,804 - Epoch: [170][  250/  267]    Overall Loss 2.369127    Objective Loss 2.369127                                        LR 0.100000    Time 0.226360    
2024-04-23 19:25:25,139 - Epoch: [170][  260/  267]    Overall Loss 2.369623    Objective Loss 2.369623                                        LR 0.100000    Time 0.226623    
2024-04-23 19:25:26,091 - Epoch: [170][  267/  267]    Overall Loss 2.369734    Objective Loss 2.369734    Top1 2.325581    Top5 44.186047    LR 0.100000    Time 0.224238    
2024-04-23 19:25:26,413 - --- validate (epoch=170)-----------
2024-04-23 19:25:26,415 - 946 samples (32 per mini-batch)
2024-04-23 19:25:29,451 - Epoch: [170][   10/   30]    Loss 2.375644    Top1 9.062500    Top5 51.250000    
2024-04-23 19:25:31,315 - Epoch: [170][   20/   30]    Loss 2.345895    Top1 10.156250    Top5 53.593750    
2024-04-23 19:25:33,425 - Epoch: [170][   30/   30]    Loss 2.365311    Top1 9.196617    Top5 50.951374    
2024-04-23 19:25:33,587 - ==> Top1: 9.197    Top5: 50.951    Loss: 2.365

2024-04-23 19:25:33,589 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 19:25:33,592 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:25:33,592 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:25:33,608 - 

2024-04-23 19:25:33,608 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:25:36,493 - Epoch: [171][   10/  267]    Overall Loss 2.389692    Objective Loss 2.389692                                        LR 0.100000    Time 0.288153    
2024-04-23 19:25:37,793 - Epoch: [124][  100/  123]    Loss 0.686118    Top1 78.000000    Top5 97.093750    
2024-04-23 19:25:39,094 - Epoch: [171][   20/  267]    Overall Loss 2.379598    Objective Loss 2.379598                                        LR 0.100000    Time 0.273919    
2024-04-23 19:25:41,117 - Epoch: [171][   30/  267]    Overall Loss 2.373108    Objective Loss 2.373108                                        LR 0.100000    Time 0.249946    
2024-04-23 19:25:42,878 - Epoch: [171][   40/  267]    Overall Loss 2.374139    Objective Loss 2.374139                                        LR 0.100000    Time 0.231430    
2024-04-23 19:25:42,885 - Epoch: [124][  123/  123]    Loss 0.684258    Top1 78.140127    Top5 97.197452    
2024-04-23 19:25:43,105 - ==> Top1: 78.140    Top5: 97.197    Loss: 0.684

2024-04-23 19:25:43,115 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:25:43,116 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:25:43,161 - 

2024-04-23 19:25:43,162 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:25:44,772 - Epoch: [171][   50/  267]    Overall Loss 2.373769    Objective Loss 2.373769                                        LR 0.100000    Time 0.222943    
2024-04-23 19:25:47,284 - Epoch: [171][   60/  267]    Overall Loss 2.372247    Objective Loss 2.372247                                        LR 0.100000    Time 0.227598    
2024-04-23 19:25:49,498 - Epoch: [171][   70/  267]    Overall Loss 2.380730    Objective Loss 2.380730                                        LR 0.100000    Time 0.226675    
2024-04-23 19:25:51,727 - Epoch: [171][   80/  267]    Overall Loss 2.376863    Objective Loss 2.376863                                        LR 0.100000    Time 0.226153    
2024-04-23 19:25:53,926 - Epoch: [171][   90/  267]    Overall Loss 2.380666    Objective Loss 2.380666                                        LR 0.100000    Time 0.225432    
2024-04-23 19:25:56,328 - Epoch: [171][  100/  267]    Overall Loss 2.382254    Objective Loss 2.382254                                        LR 0.100000    Time 0.226881    
2024-04-23 19:25:58,221 - Epoch: [171][  110/  267]    Overall Loss 2.379090    Objective Loss 2.379090                                        LR 0.100000    Time 0.223440    
2024-04-23 19:26:00,764 - Epoch: [171][  120/  267]    Overall Loss 2.376672    Objective Loss 2.376672                                        LR 0.100000    Time 0.225994    
2024-04-23 19:26:02,691 - Epoch: [171][  130/  267]    Overall Loss 2.375449    Objective Loss 2.375449                                        LR 0.100000    Time 0.223409    
2024-04-23 19:26:04,839 - Epoch: [171][  140/  267]    Overall Loss 2.378719    Objective Loss 2.378719                                        LR 0.100000    Time 0.222772    
2024-04-23 19:26:06,845 - Epoch: [171][  150/  267]    Overall Loss 2.378736    Objective Loss 2.378736                                        LR 0.100000    Time 0.221276    
2024-04-23 19:26:08,318 - Epoch: [125][  100/  296]    Overall Loss 0.718699    Objective Loss 0.718699                                        LR 0.000080    Time 0.251350    
2024-04-23 19:26:09,524 - Epoch: [171][  160/  267]    Overall Loss 2.377743    Objective Loss 2.377743                                        LR 0.100000    Time 0.224172    
2024-04-23 19:26:11,386 - Epoch: [171][  170/  267]    Overall Loss 2.375336    Objective Loss 2.375336                                        LR 0.100000    Time 0.221918    
2024-04-23 19:26:13,972 - Epoch: [171][  180/  267]    Overall Loss 2.376072    Objective Loss 2.376072                                        LR 0.100000    Time 0.223946    
2024-04-23 19:26:16,288 - Epoch: [171][  190/  267]    Overall Loss 2.379973    Objective Loss 2.379973                                        LR 0.100000    Time 0.224331    
2024-04-23 19:26:19,109 - Epoch: [171][  200/  267]    Overall Loss 2.378455    Objective Loss 2.378455                                        LR 0.100000    Time 0.227207    
2024-04-23 19:26:21,042 - Epoch: [171][  210/  267]    Overall Loss 2.376148    Objective Loss 2.376148                                        LR 0.100000    Time 0.225579    
2024-04-23 19:26:23,767 - Epoch: [171][  220/  267]    Overall Loss 2.376218    Objective Loss 2.376218                                        LR 0.100000    Time 0.227698    
2024-04-23 19:26:25,807 - Epoch: [171][  230/  267]    Overall Loss 2.376438    Objective Loss 2.376438                                        LR 0.100000    Time 0.226655    
2024-04-23 19:26:28,769 - Epoch: [171][  240/  267]    Overall Loss 2.374574    Objective Loss 2.374574                                        LR 0.100000    Time 0.229540    
2024-04-23 19:26:30,552 - Epoch: [171][  250/  267]    Overall Loss 2.372836    Objective Loss 2.372836                                        LR 0.100000    Time 0.227478    
2024-04-23 19:26:32,357 - Epoch: [125][  200/  296]    Overall Loss 0.738548    Objective Loss 0.738548                                        LR 0.000080    Time 0.245769    
2024-04-23 19:26:33,225 - Epoch: [171][  260/  267]    Overall Loss 2.371531    Objective Loss 2.371531                                        LR 0.100000    Time 0.228985    
2024-04-23 19:26:34,280 - Epoch: [171][  267/  267]    Overall Loss 2.372577    Objective Loss 2.372577    Top1 9.302326    Top5 53.488372    LR 0.100000    Time 0.226924    
2024-04-23 19:26:34,571 - --- validate (epoch=171)-----------
2024-04-23 19:26:34,573 - 946 samples (32 per mini-batch)
2024-04-23 19:26:38,833 - Epoch: [171][   10/   30]    Loss 2.361696    Top1 9.062500    Top5 52.812500    
2024-04-23 19:26:40,784 - Epoch: [171][   20/   30]    Loss 2.383461    Top1 7.812500    Top5 51.250000    
2024-04-23 19:26:42,982 - Epoch: [171][   30/   30]    Loss 2.378610    Top1 8.456660    Top5 50.105708    
2024-04-23 19:26:43,212 - ==> Top1: 8.457    Top5: 50.106    Loss: 2.379

2024-04-23 19:26:43,214 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 19:26:43,218 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:26:43,219 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:26:43,235 - 

2024-04-23 19:26:43,236 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:26:46,904 - Epoch: [172][   10/  267]    Overall Loss 2.386147    Objective Loss 2.386147                                        LR 0.100000    Time 0.366495    
2024-04-23 19:26:49,263 - Epoch: [172][   20/  267]    Overall Loss 2.382683    Objective Loss 2.382683                                        LR 0.100000    Time 0.301064    
2024-04-23 19:26:50,495 - Epoch: [125][  296/  296]    Overall Loss 0.744536    Objective Loss 0.744536    Top1 77.049180    Top5 96.721311    LR 0.000080    Time 0.227272    
2024-04-23 19:26:50,818 - --- validate (epoch=125)-----------
2024-04-23 19:26:50,819 - 3925 samples (32 per mini-batch)
2024-04-23 19:26:50,822 - Epoch: [172][   30/  267]    Overall Loss 2.377378    Objective Loss 2.377378                                        LR 0.100000    Time 0.252586    
2024-04-23 19:26:51,951 - Epoch: [172][   40/  267]    Overall Loss 2.369206    Objective Loss 2.369206                                        LR 0.100000    Time 0.217629    
2024-04-23 19:26:54,569 - Epoch: [172][   50/  267]    Overall Loss 2.366619    Objective Loss 2.366619                                        LR 0.100000    Time 0.226403    
2024-04-23 19:26:56,277 - Epoch: [172][   60/  267]    Overall Loss 2.365854    Objective Loss 2.365854                                        LR 0.100000    Time 0.217080    
2024-04-23 19:26:58,854 - Epoch: [172][   70/  267]    Overall Loss 2.369826    Objective Loss 2.369826                                        LR 0.100000    Time 0.222849    
2024-04-23 19:27:00,807 - Epoch: [172][   80/  267]    Overall Loss 2.368196    Objective Loss 2.368196                                        LR 0.100000    Time 0.219372    
2024-04-23 19:27:03,658 - Epoch: [172][   90/  267]    Overall Loss 2.370619    Objective Loss 2.370619                                        LR 0.100000    Time 0.226640    
2024-04-23 19:27:05,597 - Epoch: [172][  100/  267]    Overall Loss 2.371108    Objective Loss 2.371108                                        LR 0.100000    Time 0.223339    
2024-04-23 19:27:08,237 - Epoch: [172][  110/  267]    Overall Loss 2.367837    Objective Loss 2.367837                                        LR 0.100000    Time 0.227008    
2024-04-23 19:27:10,212 - Epoch: [172][  120/  267]    Overall Loss 2.364267    Objective Loss 2.364267                                        LR 0.100000    Time 0.224519    
2024-04-23 19:27:12,798 - Epoch: [172][  130/  267]    Overall Loss 2.364426    Objective Loss 2.364426                                        LR 0.100000    Time 0.227118    
2024-04-23 19:27:14,601 - Epoch: [172][  140/  267]    Overall Loss 2.369408    Objective Loss 2.369408                                        LR 0.100000    Time 0.223759    
2024-04-23 19:27:14,740 - Epoch: [125][  100/  123]    Loss 0.679693    Top1 78.531250    Top5 97.375000    
2024-04-23 19:27:16,843 - Epoch: [172][  150/  267]    Overall Loss 2.367456    Objective Loss 2.367456                                        LR 0.100000    Time 0.223764    
2024-04-23 19:27:18,461 - Epoch: [172][  160/  267]    Overall Loss 2.365710    Objective Loss 2.365710                                        LR 0.100000    Time 0.219869    
2024-04-23 19:27:19,918 - Epoch: [125][  123/  123]    Loss 0.671539    Top1 78.420382    Top5 97.426752    
2024-04-23 19:27:20,110 - Epoch: [172][  170/  267]    Overall Loss 2.365643    Objective Loss 2.365643                                        LR 0.100000    Time 0.216619    
2024-04-23 19:27:20,154 - ==> Top1: 78.420    Top5: 97.427    Loss: 0.672

2024-04-23 19:27:20,163 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:27:20,164 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:27:20,208 - 

2024-04-23 19:27:20,209 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:27:20,957 - Epoch: [172][  180/  267]    Overall Loss 2.365877    Objective Loss 2.365877                                        LR 0.100000    Time 0.209268    
2024-04-23 19:27:23,023 - Epoch: [172][  190/  267]    Overall Loss 2.366085    Objective Loss 2.366085                                        LR 0.100000    Time 0.209116    
2024-04-23 19:27:24,671 - Epoch: [172][  200/  267]    Overall Loss 2.367824    Objective Loss 2.367824                                        LR 0.100000    Time 0.206889    
2024-04-23 19:27:27,006 - Epoch: [172][  210/  267]    Overall Loss 2.367854    Objective Loss 2.367854                                        LR 0.100000    Time 0.208140    
2024-04-23 19:27:28,826 - Epoch: [172][  220/  267]    Overall Loss 2.367511    Objective Loss 2.367511                                        LR 0.100000    Time 0.206938    
2024-04-23 19:27:31,837 - Epoch: [172][  230/  267]    Overall Loss 2.366776    Objective Loss 2.366776                                        LR 0.100000    Time 0.211022    
2024-04-23 19:27:35,434 - Epoch: [172][  240/  267]    Overall Loss 2.367376    Objective Loss 2.367376                                        LR 0.100000    Time 0.217202    
2024-04-23 19:27:38,468 - Epoch: [172][  250/  267]    Overall Loss 2.367128    Objective Loss 2.367128                                        LR 0.100000    Time 0.220637    
2024-04-23 19:27:40,348 - Epoch: [172][  260/  267]    Overall Loss 2.366326    Objective Loss 2.366326                                        LR 0.100000    Time 0.219369    
2024-04-23 19:27:41,745 - Epoch: [172][  267/  267]    Overall Loss 2.366821    Objective Loss 2.366821    Top1 16.279070    Top5 55.813953    LR 0.100000    Time 0.218842    
2024-04-23 19:27:41,947 - --- validate (epoch=172)-----------
2024-04-23 19:27:41,949 - 946 samples (32 per mini-batch)
2024-04-23 19:27:44,769 - Epoch: [172][   10/   30]    Loss 2.334013    Top1 13.125000    Top5 52.187500    
2024-04-23 19:27:45,573 - Epoch: [126][  100/  296]    Overall Loss 0.738617    Objective Loss 0.738617                                        LR 0.000080    Time 0.253448    
2024-04-23 19:27:46,192 - Epoch: [172][   20/   30]    Loss 2.366679    Top1 10.625000    Top5 49.062500    
2024-04-23 19:27:48,689 - Epoch: [172][   30/   30]    Loss 2.367961    Top1 10.359408    Top5 48.837209    
2024-04-23 19:27:48,875 - ==> Top1: 10.359    Top5: 48.837    Loss: 2.368

2024-04-23 19:27:48,876 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 19:27:48,880 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:27:48,880 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:27:48,891 - 

2024-04-23 19:27:48,892 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:27:52,691 - Epoch: [173][   10/  267]    Overall Loss 2.381357    Objective Loss 2.381357                                        LR 0.100000    Time 0.379505    
2024-04-23 19:27:55,655 - Epoch: [173][   20/  267]    Overall Loss 2.377108    Objective Loss 2.377108                                        LR 0.100000    Time 0.337749    
2024-04-23 19:27:59,232 - Epoch: [173][   30/  267]    Overall Loss 2.365244    Objective Loss 2.365244                                        LR 0.100000    Time 0.344301    
2024-04-23 19:28:01,540 - Epoch: [173][   40/  267]    Overall Loss 2.363572    Objective Loss 2.363572                                        LR 0.100000    Time 0.315835    
2024-04-23 19:28:03,995 - Epoch: [173][   50/  267]    Overall Loss 2.359266    Objective Loss 2.359266                                        LR 0.100000    Time 0.301712    
2024-04-23 19:28:06,211 - Epoch: [173][   60/  267]    Overall Loss 2.369282    Objective Loss 2.369282                                        LR 0.100000    Time 0.288315    
2024-04-23 19:28:08,510 - Epoch: [173][   70/  267]    Overall Loss 2.369512    Objective Loss 2.369512                                        LR 0.100000    Time 0.279928    
2024-04-23 19:28:10,784 - Epoch: [173][   80/  267]    Overall Loss 2.372195    Objective Loss 2.372195                                        LR 0.100000    Time 0.273320    
2024-04-23 19:28:11,268 - Epoch: [126][  200/  296]    Overall Loss 0.758037    Objective Loss 0.758037                                        LR 0.000080    Time 0.255100    
2024-04-23 19:28:13,210 - Epoch: [173][   90/  267]    Overall Loss 2.367957    Objective Loss 2.367957                                        LR 0.100000    Time 0.269871    
2024-04-23 19:28:15,516 - Epoch: [173][  100/  267]    Overall Loss 2.368822    Objective Loss 2.368822                                        LR 0.100000    Time 0.265907    
2024-04-23 19:28:17,810 - Epoch: [173][  110/  267]    Overall Loss 2.370217    Objective Loss 2.370217                                        LR 0.100000    Time 0.262559    
2024-04-23 19:28:19,903 - Epoch: [173][  120/  267]    Overall Loss 2.370756    Objective Loss 2.370756                                        LR 0.100000    Time 0.258102    
2024-04-23 19:28:22,007 - Epoch: [173][  130/  267]    Overall Loss 2.373945    Objective Loss 2.373945                                        LR 0.100000    Time 0.254411    
2024-04-23 19:28:24,729 - Epoch: [173][  140/  267]    Overall Loss 2.380077    Objective Loss 2.380077                                        LR 0.100000    Time 0.255665    
2024-04-23 19:28:27,002 - Epoch: [173][  150/  267]    Overall Loss 2.378708    Objective Loss 2.378708                                        LR 0.100000    Time 0.253745    
2024-04-23 19:28:30,048 - Epoch: [173][  160/  267]    Overall Loss 2.375450    Objective Loss 2.375450                                        LR 0.100000    Time 0.256899    
2024-04-23 19:28:32,292 - Epoch: [173][  170/  267]    Overall Loss 2.379744    Objective Loss 2.379744                                        LR 0.100000    Time 0.254968    
2024-04-23 19:28:35,805 - Epoch: [173][  180/  267]    Overall Loss 2.379378    Objective Loss 2.379378                                        LR 0.100000    Time 0.260310    
2024-04-23 19:28:36,036 - Epoch: [126][  296/  296]    Overall Loss 0.745449    Objective Loss 0.745449    Top1 68.852459    Top5 96.721311    LR 0.000080    Time 0.255975    
2024-04-23 19:28:36,269 - --- validate (epoch=126)-----------
2024-04-23 19:28:36,271 - 3925 samples (32 per mini-batch)
2024-04-23 19:28:37,919 - Epoch: [173][  190/  267]    Overall Loss 2.378137    Objective Loss 2.378137                                        LR 0.100000    Time 0.257719    
2024-04-23 19:28:41,361 - Epoch: [173][  200/  267]    Overall Loss 2.375890    Objective Loss 2.375890                                        LR 0.100000    Time 0.262029    
2024-04-23 19:28:43,513 - Epoch: [173][  210/  267]    Overall Loss 2.376416    Objective Loss 2.376416                                        LR 0.100000    Time 0.259787    
2024-04-23 19:28:46,702 - Epoch: [173][  220/  267]    Overall Loss 2.374937    Objective Loss 2.374937                                        LR 0.100000    Time 0.262461    
2024-04-23 19:28:48,992 - Epoch: [173][  230/  267]    Overall Loss 2.377460    Objective Loss 2.377460                                        LR 0.100000    Time 0.260993    
2024-04-23 19:28:52,028 - Epoch: [173][  240/  267]    Overall Loss 2.377492    Objective Loss 2.377492                                        LR 0.100000    Time 0.262760    
2024-04-23 19:28:54,500 - Epoch: [173][  250/  267]    Overall Loss 2.376303    Objective Loss 2.376303                                        LR 0.100000    Time 0.262123    
2024-04-23 19:28:57,621 - Epoch: [173][  260/  267]    Overall Loss 2.375566    Objective Loss 2.375566                                        LR 0.100000    Time 0.264030    
2024-04-23 19:28:58,547 - Epoch: [173][  267/  267]    Overall Loss 2.375925    Objective Loss 2.375925    Top1 6.976744    Top5 44.186047    LR 0.100000    Time 0.260569    
2024-04-23 19:28:58,750 - --- validate (epoch=173)-----------
2024-04-23 19:28:58,751 - 946 samples (32 per mini-batch)
2024-04-23 19:29:00,573 - Epoch: [126][  100/  123]    Loss 0.689969    Top1 77.625000    Top5 97.156250    
2024-04-23 19:29:02,949 - Epoch: [173][   10/   30]    Loss 2.320030    Top1 12.812500    Top5 50.937500    
2024-04-23 19:29:05,114 - Epoch: [173][   20/   30]    Loss 2.334581    Top1 9.531250    Top5 49.531250    
2024-04-23 19:29:07,331 - Epoch: [126][  123/  123]    Loss 0.671102    Top1 78.038217    Top5 97.273885    
2024-04-23 19:29:07,601 - ==> Top1: 78.038    Top5: 97.274    Loss: 0.671

2024-04-23 19:29:07,612 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:29:07,613 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:29:07,664 - 

2024-04-23 19:29:07,665 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:29:08,128 - Epoch: [173][   30/   30]    Loss 2.328287    Top1 9.830867    Top5 50.317125    
2024-04-23 19:29:08,398 - ==> Top1: 9.831    Top5: 50.317    Loss: 2.328

2024-04-23 19:29:08,400 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 19:29:08,407 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:29:08,408 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:29:08,424 - 

2024-04-23 19:29:08,425 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:29:12,310 - Epoch: [174][   10/  267]    Overall Loss 2.377872    Objective Loss 2.377872                                        LR 0.100000    Time 0.387998    
2024-04-23 19:29:14,506 - Epoch: [174][   20/  267]    Overall Loss 2.386346    Objective Loss 2.386346                                        LR 0.100000    Time 0.303634    
2024-04-23 19:29:17,222 - Epoch: [174][   30/  267]    Overall Loss 2.384276    Objective Loss 2.384276                                        LR 0.100000    Time 0.292861    
2024-04-23 19:29:19,435 - Epoch: [174][   40/  267]    Overall Loss 2.374652    Objective Loss 2.374652                                        LR 0.100000    Time 0.274898    
2024-04-23 19:29:22,371 - Epoch: [174][   50/  267]    Overall Loss 2.383008    Objective Loss 2.383008                                        LR 0.100000    Time 0.278577    
2024-04-23 19:29:24,411 - Epoch: [174][   60/  267]    Overall Loss 2.380076    Objective Loss 2.380076                                        LR 0.100000    Time 0.266111    
2024-04-23 19:29:26,172 - Epoch: [127][  100/  296]    Overall Loss 0.740139    Objective Loss 0.740139                                        LR 0.000080    Time 0.184854    
2024-04-23 19:29:27,561 - Epoch: [174][   70/  267]    Overall Loss 2.377737    Objective Loss 2.377737                                        LR 0.100000    Time 0.273051    
2024-04-23 19:29:29,089 - Epoch: [174][   80/  267]    Overall Loss 2.375105    Objective Loss 2.375105                                        LR 0.100000    Time 0.257989    
2024-04-23 19:29:31,801 - Epoch: [174][   90/  267]    Overall Loss 2.369567    Objective Loss 2.369567                                        LR 0.100000    Time 0.259435    
2024-04-23 19:29:33,928 - Epoch: [174][  100/  267]    Overall Loss 2.366013    Objective Loss 2.366013                                        LR 0.100000    Time 0.254725    
2024-04-23 19:29:36,411 - Epoch: [174][  110/  267]    Overall Loss 2.366924    Objective Loss 2.366924                                        LR 0.100000    Time 0.254124    
2024-04-23 19:29:37,758 - Epoch: [174][  120/  267]    Overall Loss 2.365432    Objective Loss 2.365432                                        LR 0.100000    Time 0.244148    
2024-04-23 19:29:39,254 - Epoch: [174][  130/  267]    Overall Loss 2.364707    Objective Loss 2.364707                                        LR 0.100000    Time 0.236856    
2024-04-23 19:29:40,466 - Epoch: [174][  140/  267]    Overall Loss 2.366531    Objective Loss 2.366531                                        LR 0.100000    Time 0.228575    
2024-04-23 19:29:41,910 - Epoch: [174][  150/  267]    Overall Loss 2.367433    Objective Loss 2.367433                                        LR 0.100000    Time 0.222946    
2024-04-23 19:29:42,991 - Epoch: [174][  160/  267]    Overall Loss 2.365907    Objective Loss 2.365907                                        LR 0.100000    Time 0.215757    
2024-04-23 19:29:44,718 - Epoch: [174][  170/  267]    Overall Loss 2.368252    Objective Loss 2.368252                                        LR 0.100000    Time 0.213207    
2024-04-23 19:29:45,462 - Epoch: [127][  200/  296]    Overall Loss 0.744814    Objective Loss 0.744814                                        LR 0.000080    Time 0.188772    
2024-04-23 19:29:46,214 - Epoch: [174][  180/  267]    Overall Loss 2.370027    Objective Loss 2.370027                                        LR 0.100000    Time 0.209662    
2024-04-23 19:29:47,676 - Epoch: [174][  190/  267]    Overall Loss 2.368790    Objective Loss 2.368790                                        LR 0.100000    Time 0.206306    
2024-04-23 19:29:48,521 - Epoch: [174][  200/  267]    Overall Loss 2.369461    Objective Loss 2.369461                                        LR 0.100000    Time 0.200207    
2024-04-23 19:29:50,628 - Epoch: [174][  210/  267]    Overall Loss 2.370985    Objective Loss 2.370985                                        LR 0.100000    Time 0.200696    
2024-04-23 19:29:51,842 - Epoch: [174][  220/  267]    Overall Loss 2.371022    Objective Loss 2.371022                                        LR 0.100000    Time 0.197079    
2024-04-23 19:29:53,148 - Epoch: [174][  230/  267]    Overall Loss 2.370649    Objective Loss 2.370649                                        LR 0.100000    Time 0.194178    
2024-04-23 19:29:54,567 - Epoch: [174][  240/  267]    Overall Loss 2.373455    Objective Loss 2.373455                                        LR 0.100000    Time 0.191989    
2024-04-23 19:29:56,965 - Epoch: [174][  250/  267]    Overall Loss 2.372636    Objective Loss 2.372636                                        LR 0.100000    Time 0.193891    
2024-04-23 19:29:58,598 - Epoch: [174][  260/  267]    Overall Loss 2.372221    Objective Loss 2.372221                                        LR 0.100000    Time 0.192705    
2024-04-23 19:29:59,509 - Epoch: [174][  267/  267]    Overall Loss 2.372616    Objective Loss 2.372616    Top1 11.627907    Top5 44.186047    LR 0.100000    Time 0.191056    
2024-04-23 19:29:59,642 - --- validate (epoch=174)-----------
2024-04-23 19:29:59,642 - 946 samples (32 per mini-batch)
2024-04-23 19:30:02,478 - Epoch: [174][   10/   30]    Loss 2.441078    Top1 9.062500    Top5 53.125000    
2024-04-23 19:30:04,417 - Epoch: [174][   20/   30]    Loss 2.457557    Top1 9.531250    Top5 49.843750    
2024-04-23 19:30:06,405 - Epoch: [174][   30/   30]    Loss 2.443304    Top1 10.465116    Top5 50.105708    
2024-04-23 19:30:06,533 - ==> Top1: 10.465    Top5: 50.106    Loss: 2.443

2024-04-23 19:30:06,534 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 19:30:06,536 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:30:06,537 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:30:06,549 - 

2024-04-23 19:30:06,549 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:30:07,612 - Epoch: [127][  296/  296]    Overall Loss 0.739804    Objective Loss 0.739804    Top1 73.770492    Top5 95.081967    LR 0.000080    Time 0.202319    
2024-04-23 19:30:07,820 - --- validate (epoch=127)-----------
2024-04-23 19:30:07,821 - 3925 samples (32 per mini-batch)
2024-04-23 19:30:09,903 - Epoch: [175][   10/  267]    Overall Loss 2.361437    Objective Loss 2.361437                                        LR 0.100000    Time 0.335089    
2024-04-23 19:30:12,309 - Epoch: [175][   20/  267]    Overall Loss 2.379884    Objective Loss 2.379884                                        LR 0.100000    Time 0.287659    
2024-04-23 19:30:14,485 - Epoch: [175][   30/  267]    Overall Loss 2.376032    Objective Loss 2.376032                                        LR 0.100000    Time 0.264210    
2024-04-23 19:30:15,607 - Epoch: [175][   40/  267]    Overall Loss 2.373738    Objective Loss 2.373738                                        LR 0.100000    Time 0.226154    
2024-04-23 19:30:17,666 - Epoch: [175][   50/  267]    Overall Loss 2.370581    Objective Loss 2.370581                                        LR 0.100000    Time 0.222053    
2024-04-23 19:30:19,600 - Epoch: [175][   60/  267]    Overall Loss 2.370002    Objective Loss 2.370002                                        LR 0.100000    Time 0.217236    
2024-04-23 19:30:22,177 - Epoch: [175][   70/  267]    Overall Loss 2.375100    Objective Loss 2.375100                                        LR 0.100000    Time 0.222975    
2024-04-23 19:30:24,031 - Epoch: [175][   80/  267]    Overall Loss 2.373631    Objective Loss 2.373631                                        LR 0.100000    Time 0.218244    
2024-04-23 19:30:26,467 - Epoch: [175][   90/  267]    Overall Loss 2.370640    Objective Loss 2.370640                                        LR 0.100000    Time 0.221038    
2024-04-23 19:30:28,503 - Epoch: [175][  100/  267]    Overall Loss 2.370425    Objective Loss 2.370425                                        LR 0.100000    Time 0.219271    
2024-04-23 19:30:31,415 - Epoch: [175][  110/  267]    Overall Loss 2.370714    Objective Loss 2.370714                                        LR 0.100000    Time 0.225785    
2024-04-23 19:30:33,465 - Epoch: [175][  120/  267]    Overall Loss 2.373607    Objective Loss 2.373607                                        LR 0.100000    Time 0.224027    
2024-04-23 19:30:33,914 - Epoch: [127][  100/  123]    Loss 0.687611    Top1 77.750000    Top5 97.031250    
2024-04-23 19:30:36,074 - Epoch: [175][  130/  267]    Overall Loss 2.371949    Objective Loss 2.371949                                        LR 0.100000    Time 0.226825    
2024-04-23 19:30:38,044 - Epoch: [175][  140/  267]    Overall Loss 2.371506    Objective Loss 2.371506                                        LR 0.100000    Time 0.224672    
2024-04-23 19:30:39,436 - Epoch: [127][  123/  123]    Loss 0.671372    Top1 78.012739    Top5 97.222930    
2024-04-23 19:30:39,686 - ==> Top1: 78.013    Top5: 97.223    Loss: 0.671

2024-04-23 19:30:39,695 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:30:39,696 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:30:39,745 - 

2024-04-23 19:30:39,746 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:30:40,712 - Epoch: [175][  150/  267]    Overall Loss 2.370605    Objective Loss 2.370605                                        LR 0.100000    Time 0.227456    
2024-04-23 19:30:42,954 - Epoch: [175][  160/  267]    Overall Loss 2.372968    Objective Loss 2.372968                                        LR 0.100000    Time 0.227234    
2024-04-23 19:30:45,720 - Epoch: [175][  170/  267]    Overall Loss 2.374041    Objective Loss 2.374041                                        LR 0.100000    Time 0.230124    
2024-04-23 19:30:47,667 - Epoch: [175][  180/  267]    Overall Loss 2.373187    Objective Loss 2.373187                                        LR 0.100000    Time 0.228136    
2024-04-23 19:30:49,531 - Epoch: [175][  190/  267]    Overall Loss 2.372774    Objective Loss 2.372774                                        LR 0.100000    Time 0.225926    
2024-04-23 19:30:50,568 - Epoch: [175][  200/  267]    Overall Loss 2.373154    Objective Loss 2.373154                                        LR 0.100000    Time 0.219801    
2024-04-23 19:30:51,605 - Epoch: [175][  210/  267]    Overall Loss 2.375340    Objective Loss 2.375340                                        LR 0.100000    Time 0.214263    
2024-04-23 19:30:52,534 - Epoch: [175][  220/  267]    Overall Loss 2.375032    Objective Loss 2.375032                                        LR 0.100000    Time 0.208736    
2024-04-23 19:30:53,716 - Epoch: [175][  230/  267]    Overall Loss 2.374518    Objective Loss 2.374518                                        LR 0.100000    Time 0.204790    
2024-04-23 19:30:54,793 - Epoch: [175][  240/  267]    Overall Loss 2.375183    Objective Loss 2.375183                                        LR 0.100000    Time 0.200737    
2024-04-23 19:30:56,276 - Epoch: [175][  250/  267]    Overall Loss 2.374465    Objective Loss 2.374465                                        LR 0.100000    Time 0.198627    
2024-04-23 19:30:58,097 - Epoch: [175][  260/  267]    Overall Loss 2.375925    Objective Loss 2.375925                                        LR 0.100000    Time 0.197981    
2024-04-23 19:30:59,331 - Epoch: [175][  267/  267]    Overall Loss 2.376622    Objective Loss 2.376622    Top1 6.976744    Top5 37.209302    LR 0.100000    Time 0.197406    
2024-04-23 19:30:59,485 - --- validate (epoch=175)-----------
2024-04-23 19:30:59,487 - 946 samples (32 per mini-batch)
2024-04-23 19:31:02,837 - Epoch: [175][   10/   30]    Loss 2.397766    Top1 10.312500    Top5 52.500000    
2024-04-23 19:31:04,508 - Epoch: [128][  100/  296]    Overall Loss 0.720898    Objective Loss 0.720898                                        LR 0.000080    Time 0.247414    
2024-04-23 19:31:04,760 - Epoch: [175][   20/   30]    Loss 2.417810    Top1 9.843750    Top5 51.718750    
2024-04-23 19:31:06,538 - Epoch: [175][   30/   30]    Loss 2.405520    Top1 9.830867    Top5 51.797040    
2024-04-23 19:31:06,697 - ==> Top1: 9.831    Top5: 51.797    Loss: 2.406

2024-04-23 19:31:06,699 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 19:31:06,703 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:31:06,703 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:31:06,719 - 

2024-04-23 19:31:06,720 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:31:09,940 - Epoch: [176][   10/  267]    Overall Loss 2.348757    Objective Loss 2.348757                                        LR 0.100000    Time 0.321710    
2024-04-23 19:31:12,012 - Epoch: [176][   20/  267]    Overall Loss 2.375718    Objective Loss 2.375718                                        LR 0.100000    Time 0.264214    
2024-04-23 19:31:14,617 - Epoch: [176][   30/  267]    Overall Loss 2.384230    Objective Loss 2.384230                                        LR 0.100000    Time 0.262890    
2024-04-23 19:31:16,417 - Epoch: [176][   40/  267]    Overall Loss 2.387672    Objective Loss 2.387672                                        LR 0.100000    Time 0.242099    
2024-04-23 19:31:19,307 - Epoch: [176][   50/  267]    Overall Loss 2.387683    Objective Loss 2.387683                                        LR 0.100000    Time 0.251416    
2024-04-23 19:31:21,690 - Epoch: [176][   60/  267]    Overall Loss 2.384103    Objective Loss 2.384103                                        LR 0.100000    Time 0.249187    
2024-04-23 19:31:24,518 - Epoch: [176][   70/  267]    Overall Loss 2.382427    Objective Loss 2.382427                                        LR 0.100000    Time 0.253946    
2024-04-23 19:31:27,124 - Epoch: [176][   80/  267]    Overall Loss 2.383770    Objective Loss 2.383770                                        LR 0.100000    Time 0.254737    
2024-04-23 19:31:28,718 - Epoch: [128][  200/  296]    Overall Loss 0.707361    Objective Loss 0.707361                                        LR 0.000080    Time 0.244658    
2024-04-23 19:31:29,368 - Epoch: [176][   90/  267]    Overall Loss 2.383645    Objective Loss 2.383645                                        LR 0.100000    Time 0.251326    
2024-04-23 19:31:31,256 - Epoch: [176][  100/  267]    Overall Loss 2.380083    Objective Loss 2.380083                                        LR 0.100000    Time 0.245049    
2024-04-23 19:31:32,994 - Epoch: [176][  110/  267]    Overall Loss 2.379675    Objective Loss 2.379675                                        LR 0.100000    Time 0.238543    
2024-04-23 19:31:34,234 - Epoch: [176][  120/  267]    Overall Loss 2.375968    Objective Loss 2.375968                                        LR 0.100000    Time 0.228973    
2024-04-23 19:31:36,058 - Epoch: [176][  130/  267]    Overall Loss 2.375675    Objective Loss 2.375675                                        LR 0.100000    Time 0.225376    
2024-04-23 19:31:37,552 - Epoch: [176][  140/  267]    Overall Loss 2.373963    Objective Loss 2.373963                                        LR 0.100000    Time 0.219921    
2024-04-23 19:31:39,653 - Epoch: [176][  150/  267]    Overall Loss 2.370887    Objective Loss 2.370887                                        LR 0.100000    Time 0.219246    
2024-04-23 19:31:41,338 - Epoch: [176][  160/  267]    Overall Loss 2.368980    Objective Loss 2.368980                                        LR 0.100000    Time 0.216052    
2024-04-23 19:31:43,376 - Epoch: [176][  170/  267]    Overall Loss 2.368185    Objective Loss 2.368185                                        LR 0.100000    Time 0.215317    
2024-04-23 19:31:45,778 - Epoch: [176][  180/  267]    Overall Loss 2.370419    Objective Loss 2.370419                                        LR 0.100000    Time 0.216683    
2024-04-23 19:31:49,009 - Epoch: [176][  190/  267]    Overall Loss 2.370269    Objective Loss 2.370269                                        LR 0.100000    Time 0.222267    
2024-04-23 19:31:50,073 - Epoch: [128][  296/  296]    Overall Loss 0.717629    Objective Loss 0.717629    Top1 83.606557    Top5 93.442623    LR 0.000080    Time 0.237380    
2024-04-23 19:31:50,413 - --- validate (epoch=128)-----------
2024-04-23 19:31:50,415 - 3925 samples (32 per mini-batch)
2024-04-23 19:31:50,509 - Epoch: [176][  200/  267]    Overall Loss 2.371097    Objective Loss 2.371097                                        LR 0.100000    Time 0.218644    
2024-04-23 19:31:52,364 - Epoch: [176][  210/  267]    Overall Loss 2.372272    Objective Loss 2.372272                                        LR 0.100000    Time 0.217050    
2024-04-23 19:31:54,165 - Epoch: [176][  220/  267]    Overall Loss 2.372550    Objective Loss 2.372550                                        LR 0.100000    Time 0.215357    
2024-04-23 19:31:56,715 - Epoch: [176][  230/  267]    Overall Loss 2.373060    Objective Loss 2.373060                                        LR 0.100000    Time 0.217068    
2024-04-23 19:31:58,476 - Epoch: [176][  240/  267]    Overall Loss 2.373874    Objective Loss 2.373874                                        LR 0.100000    Time 0.215351    
2024-04-23 19:32:00,881 - Epoch: [176][  250/  267]    Overall Loss 2.372658    Objective Loss 2.372658                                        LR 0.100000    Time 0.216346    
2024-04-23 19:32:02,745 - Epoch: [176][  260/  267]    Overall Loss 2.373311    Objective Loss 2.373311                                        LR 0.100000    Time 0.215184    
2024-04-23 19:32:04,161 - Epoch: [176][  267/  267]    Overall Loss 2.374295    Objective Loss 2.374295    Top1 4.651163    Top5 37.209302    LR 0.100000    Time 0.214836    
2024-04-23 19:32:04,382 - --- validate (epoch=176)-----------
2024-04-23 19:32:04,384 - 946 samples (32 per mini-batch)
2024-04-23 19:32:07,784 - Epoch: [176][   10/   30]    Loss 2.352434    Top1 11.875000    Top5 49.375000    
2024-04-23 19:32:09,742 - Epoch: [176][   20/   30]    Loss 2.344792    Top1 11.093750    Top5 51.562500    
2024-04-23 19:32:11,760 - Epoch: [176][   30/   30]    Loss 2.351268    Top1 10.253700    Top5 50.528541    
2024-04-23 19:32:11,926 - ==> Top1: 10.254    Top5: 50.529    Loss: 2.351

2024-04-23 19:32:11,926 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 19:32:11,929 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:32:11,929 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:32:11,937 - 

2024-04-23 19:32:11,938 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:32:13,760 - Epoch: [128][  100/  123]    Loss 0.662410    Top1 78.375000    Top5 97.281250    
2024-04-23 19:32:15,232 - Epoch: [177][   10/  267]    Overall Loss 2.393970    Objective Loss 2.393970                                        LR 0.100000    Time 0.329073    
2024-04-23 19:32:17,044 - Epoch: [177][   20/  267]    Overall Loss 2.359699    Objective Loss 2.359699                                        LR 0.100000    Time 0.254997    
2024-04-23 19:32:18,528 - Epoch: [128][  123/  123]    Loss 0.670784    Top1 78.140127    Top5 97.146497    
2024-04-23 19:32:18,789 - ==> Top1: 78.140    Top5: 97.146    Loss: 0.671

2024-04-23 19:32:18,798 - ==> Best [Top1: 78.522   Top5: 97.121   Sparsity:0.00   Params: 376752 on epoch: 110]
2024-04-23 19:32:18,798 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:32:18,846 - Epoch: [177][   30/  267]    Overall Loss 2.364646    Objective Loss 2.364646                                        LR 0.100000    Time 0.229982    
2024-04-23 19:32:18,858 - 

2024-04-23 19:32:18,859 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:32:19,920 - Epoch: [177][   40/  267]    Overall Loss 2.368102    Objective Loss 2.368102                                        LR 0.100000    Time 0.199260    
2024-04-23 19:32:21,948 - Epoch: [177][   50/  267]    Overall Loss 2.374372    Objective Loss 2.374372                                        LR 0.100000    Time 0.199922    
2024-04-23 19:32:23,264 - Epoch: [177][   60/  267]    Overall Loss 2.374214    Objective Loss 2.374214                                        LR 0.100000    Time 0.188493    
2024-04-23 19:32:25,718 - Epoch: [177][   70/  267]    Overall Loss 2.374473    Objective Loss 2.374473                                        LR 0.100000    Time 0.196581    
2024-04-23 19:32:27,392 - Epoch: [177][   80/  267]    Overall Loss 2.375016    Objective Loss 2.375016                                        LR 0.100000    Time 0.192900    
2024-04-23 19:32:30,231 - Epoch: [177][   90/  267]    Overall Loss 2.377114    Objective Loss 2.377114                                        LR 0.100000    Time 0.202980    
2024-04-23 19:32:32,332 - Epoch: [177][  100/  267]    Overall Loss 2.373275    Objective Loss 2.373275                                        LR 0.100000    Time 0.203660    
2024-04-23 19:32:35,030 - Epoch: [177][  110/  267]    Overall Loss 2.375970    Objective Loss 2.375970                                        LR 0.100000    Time 0.209638    
2024-04-23 19:32:37,272 - Epoch: [177][  120/  267]    Overall Loss 2.371612    Objective Loss 2.371612                                        LR 0.100000    Time 0.210827    
2024-04-23 19:32:39,672 - Epoch: [177][  130/  267]    Overall Loss 2.370527    Objective Loss 2.370527                                        LR 0.100000    Time 0.213046    
2024-04-23 19:32:41,807 - Epoch: [177][  140/  267]    Overall Loss 2.372225    Objective Loss 2.372225                                        LR 0.100000    Time 0.213054    
2024-04-23 19:32:43,942 - Epoch: [129][  100/  296]    Overall Loss 0.709305    Objective Loss 0.709305                                        LR 0.000080    Time 0.250607    
2024-04-23 19:32:44,147 - Epoch: [177][  150/  267]    Overall Loss 2.371404    Objective Loss 2.371404                                        LR 0.100000    Time 0.214435    
2024-04-23 19:32:46,013 - Epoch: [177][  160/  267]    Overall Loss 2.371075    Objective Loss 2.371075                                        LR 0.100000    Time 0.212678    
2024-04-23 19:32:47,844 - Epoch: [177][  170/  267]    Overall Loss 2.372585    Objective Loss 2.372585                                        LR 0.100000    Time 0.210920    
2024-04-23 19:32:49,573 - Epoch: [177][  180/  267]    Overall Loss 2.371118    Objective Loss 2.371118                                        LR 0.100000    Time 0.208792    
2024-04-23 19:32:51,805 - Epoch: [177][  190/  267]    Overall Loss 2.371117    Objective Loss 2.371117                                        LR 0.100000    Time 0.209534    
2024-04-23 19:32:53,416 - Epoch: [177][  200/  267]    Overall Loss 2.369332    Objective Loss 2.369332                                        LR 0.100000    Time 0.207102    
2024-04-23 19:32:55,479 - Epoch: [177][  210/  267]    Overall Loss 2.366977    Objective Loss 2.366977                                        LR 0.100000    Time 0.207050    
2024-04-23 19:32:57,225 - Epoch: [177][  220/  267]    Overall Loss 2.368356    Objective Loss 2.368356                                        LR 0.100000    Time 0.205559    
2024-04-23 19:32:59,627 - Epoch: [177][  230/  267]    Overall Loss 2.367753    Objective Loss 2.367753                                        LR 0.100000    Time 0.207055    
2024-04-23 19:33:01,165 - Epoch: [177][  240/  267]    Overall Loss 2.366624    Objective Loss 2.366624                                        LR 0.100000    Time 0.204824    
2024-04-23 19:33:02,346 - Epoch: [129][  200/  296]    Overall Loss 0.737614    Objective Loss 0.737614                                        LR 0.000080    Time 0.217228    
2024-04-23 19:33:03,303 - Epoch: [177][  250/  267]    Overall Loss 2.366061    Objective Loss 2.366061                                        LR 0.100000    Time 0.205172    
2024-04-23 19:33:05,237 - Epoch: [177][  260/  267]    Overall Loss 2.366535    Objective Loss 2.366535                                        LR 0.100000    Time 0.204693    
2024-04-23 19:33:06,287 - Epoch: [177][  267/  267]    Overall Loss 2.367598    Objective Loss 2.367598    Top1 6.976744    Top5 46.511628    LR 0.100000    Time 0.203255    
2024-04-23 19:33:06,482 - --- validate (epoch=177)-----------
2024-04-23 19:33:06,483 - 946 samples (32 per mini-batch)
2024-04-23 19:33:09,762 - Epoch: [177][   10/   30]    Loss 2.297145    Top1 11.250000    Top5 55.937500    
2024-04-23 19:33:11,540 - Epoch: [177][   20/   30]    Loss 2.339467    Top1 9.687500    Top5 51.875000    
2024-04-23 19:33:13,664 - Epoch: [177][   30/   30]    Loss 2.350796    Top1 8.456660    Top5 49.894292    
2024-04-23 19:33:13,813 - ==> Top1: 8.457    Top5: 49.894    Loss: 2.351

2024-04-23 19:33:13,814 - ==> Confusion:
[[  0   0   0  87   0   0   0   0   0   0]
 [  0   0   0  98   0   0   0   0   0   0]
 [  0   0   0  99   0   0   0   0   0   0]
 [  0   0   0  80   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  95   0   0   0   0   0   0]
 [  0   0   0 104   0   0   0   0   0   0]
 [  0   0   0  93   0   0   0   0   0   0]
 [  0   0   0  97   0   0   0   0   0   0]
 [  0   0   0 100   0   0   0   0   0   0]]

2024-04-23 19:33:13,816 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:33:13,816 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:33:13,825 - 

2024-04-23 19:33:13,826 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:33:16,836 - Epoch: [178][   10/  267]    Overall Loss 2.373498    Objective Loss 2.373498                                        LR 0.100000    Time 0.300709    
2024-04-23 19:33:18,714 - Epoch: [178][   20/  267]    Overall Loss 2.357983    Objective Loss 2.357983                                        LR 0.100000    Time 0.244109    
2024-04-23 19:33:19,746 - Epoch: [129][  296/  296]    Overall Loss 0.724240    Objective Loss 0.724240    Top1 81.967213    Top5 100.000000    LR 0.000080    Time 0.205505    
2024-04-23 19:33:20,012 - --- validate (epoch=129)-----------
2024-04-23 19:33:20,013 - 3925 samples (32 per mini-batch)
2024-04-23 19:33:20,142 - Epoch: [178][   30/  267]    Overall Loss 2.351707    Objective Loss 2.351707                                        LR 0.100000    Time 0.210238    
2024-04-23 19:33:22,068 - Epoch: [178][   40/  267]    Overall Loss 2.344633    Objective Loss 2.344633                                        LR 0.100000    Time 0.205776    
2024-04-23 19:33:23,900 - Epoch: [178][   50/  267]    Overall Loss 2.343956    Objective Loss 2.343956                                        LR 0.100000    Time 0.201189    
2024-04-23 19:33:26,511 - Epoch: [178][   60/  267]    Overall Loss 2.351654    Objective Loss 2.351654                                        LR 0.100000    Time 0.211126    
2024-04-23 19:33:28,108 - Epoch: [178][   70/  267]    Overall Loss 2.355269    Objective Loss 2.355269                                        LR 0.100000    Time 0.203744    
2024-04-23 19:33:30,759 - Epoch: [178][   80/  267]    Overall Loss 2.359599    Objective Loss 2.359599                                        LR 0.100000    Time 0.211381    
2024-04-23 19:33:32,690 - Epoch: [178][   90/  267]    Overall Loss 2.362416    Objective Loss 2.362416                                        LR 0.100000    Time 0.209327    
2024-04-23 19:33:35,371 - Epoch: [178][  100/  267]    Overall Loss 2.360726    Objective Loss 2.360726                                        LR 0.100000    Time 0.215170    
2024-04-23 19:33:37,115 - Epoch: [178][  110/  267]    Overall Loss 2.365838    Objective Loss 2.365838                                        LR 0.100000    Time 0.211440    
2024-04-23 19:33:39,539 - Epoch: [178][  120/  267]    Overall Loss 2.367652    Objective Loss 2.367652                                        LR 0.100000    Time 0.213998    
2024-04-23 19:33:41,427 - Epoch: [178][  130/  267]    Overall Loss 2.365106    Objective Loss 2.365106                                        LR 0.100000    Time 0.212046    
2024-04-23 19:33:44,044 - Epoch: [178][  140/  267]    Overall Loss 2.366061    Objective Loss 2.366061                                        LR 0.100000    Time 0.215568    
2024-04-23 19:33:44,682 - Epoch: [129][  100/  123]    Loss 0.650829    Top1 79.031250    Top5 97.656250    
2024-04-23 19:33:45,840 - Epoch: [178][  150/  267]    Overall Loss 2.368049    Objective Loss 2.368049                                        LR 0.100000    Time 0.213150    
2024-04-23 19:33:48,517 - Epoch: [178][  160/  267]    Overall Loss 2.369504    Objective Loss 2.369504                                        LR 0.100000    Time 0.216544    
2024-04-23 19:33:49,862 - Epoch: [129][  123/  123]    Loss 0.664397    Top1 78.624204    Top5 97.579618    
2024-04-23 19:33:50,029 - Epoch: [178][  170/  267]    Overall Loss 2.369911    Objective Loss 2.369911                                        LR 0.100000    Time 0.212686    
2024-04-23 19:33:50,098 - ==> Top1: 78.624    Top5: 97.580    Loss: 0.664

2024-04-23 19:33:50,111 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:33:50,112 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:33:50,178 - 

2024-04-23 19:33:50,179 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:33:51,416 - Epoch: [178][  180/  267]    Overall Loss 2.368503    Objective Loss 2.368503                                        LR 0.100000    Time 0.208565    
2024-04-23 19:33:52,874 - Epoch: [178][  190/  267]    Overall Loss 2.367536    Objective Loss 2.367536                                        LR 0.100000    Time 0.205243    
2024-04-23 19:33:55,136 - Epoch: [178][  200/  267]    Overall Loss 2.367598    Objective Loss 2.367598                                        LR 0.100000    Time 0.206274    
2024-04-23 19:33:56,932 - Epoch: [178][  210/  267]    Overall Loss 2.368275    Objective Loss 2.368275                                        LR 0.100000    Time 0.204990    
2024-04-23 19:33:59,656 - Epoch: [178][  220/  267]    Overall Loss 2.367752    Objective Loss 2.367752                                        LR 0.100000    Time 0.208040    
2024-04-23 19:34:01,362 - Epoch: [178][  230/  267]    Overall Loss 2.366328    Objective Loss 2.366328                                        LR 0.100000    Time 0.206399    
2024-04-23 19:34:03,998 - Epoch: [178][  240/  267]    Overall Loss 2.366664    Objective Loss 2.366664                                        LR 0.100000    Time 0.208775    
2024-04-23 19:34:05,739 - Epoch: [178][  250/  267]    Overall Loss 2.366462    Objective Loss 2.366462                                        LR 0.100000    Time 0.207374    
2024-04-23 19:34:08,098 - Epoch: [178][  260/  267]    Overall Loss 2.366883    Objective Loss 2.366883                                        LR 0.100000    Time 0.208461    
2024-04-23 19:34:08,871 - Epoch: [178][  267/  267]    Overall Loss 2.366517    Objective Loss 2.366517    Top1 9.302326    Top5 53.488372    LR 0.100000    Time 0.205886    
2024-04-23 19:34:09,055 - --- validate (epoch=178)-----------
2024-04-23 19:34:09,056 - 946 samples (32 per mini-batch)
2024-04-23 19:34:12,477 - Epoch: [178][   10/   30]    Loss 2.364084    Top1 8.750000    Top5 48.750000    
2024-04-23 19:34:13,172 - Epoch: [130][  100/  296]    Overall Loss 0.743550    Objective Loss 0.743550                                        LR 0.000080    Time 0.229721    
2024-04-23 19:34:14,177 - Epoch: [178][   20/   30]    Loss 2.358603    Top1 10.625000    Top5 50.156250    
2024-04-23 19:34:16,289 - Epoch: [178][   30/   30]    Loss 2.355555    Top1 10.042283    Top5 49.577167    
2024-04-23 19:34:16,462 - ==> Top1: 10.042    Top5: 49.577    Loss: 2.356

2024-04-23 19:34:16,463 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 19:34:16,467 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:34:16,468 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:34:16,482 - 

2024-04-23 19:34:16,483 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:34:19,790 - Epoch: [179][   10/  267]    Overall Loss 2.403703    Objective Loss 2.403703                                        LR 0.100000    Time 0.330430    
2024-04-23 19:34:21,687 - Epoch: [179][   20/  267]    Overall Loss 2.377480    Objective Loss 2.377480                                        LR 0.100000    Time 0.259921    
2024-04-23 19:34:24,307 - Epoch: [179][   30/  267]    Overall Loss 2.374113    Objective Loss 2.374113                                        LR 0.100000    Time 0.260490    
2024-04-23 19:34:26,861 - Epoch: [179][   40/  267]    Overall Loss 2.365851    Objective Loss 2.365851                                        LR 0.100000    Time 0.259148    
2024-04-23 19:34:30,033 - Epoch: [179][   50/  267]    Overall Loss 2.372521    Objective Loss 2.372521                                        LR 0.100000    Time 0.270697    
2024-04-23 19:34:32,038 - Epoch: [179][   60/  267]    Overall Loss 2.365743    Objective Loss 2.365743                                        LR 0.100000    Time 0.258938    
2024-04-23 19:34:34,928 - Epoch: [179][   70/  267]    Overall Loss 2.363783    Objective Loss 2.363783                                        LR 0.100000    Time 0.263194    
2024-04-23 19:34:36,227 - Epoch: [130][  200/  296]    Overall Loss 0.732761    Objective Loss 0.732761                                        LR 0.000080    Time 0.230038    
2024-04-23 19:34:37,166 - Epoch: [179][   80/  267]    Overall Loss 2.365981    Objective Loss 2.365981                                        LR 0.100000    Time 0.258227    
2024-04-23 19:34:40,122 - Epoch: [179][   90/  267]    Overall Loss 2.369350    Objective Loss 2.369350                                        LR 0.100000    Time 0.262351    
2024-04-23 19:34:42,208 - Epoch: [179][  100/  267]    Overall Loss 2.368392    Objective Loss 2.368392                                        LR 0.100000    Time 0.256944    
2024-04-23 19:34:45,184 - Epoch: [179][  110/  267]    Overall Loss 2.364058    Objective Loss 2.364058                                        LR 0.100000    Time 0.260618    
2024-04-23 19:34:47,827 - Epoch: [179][  120/  267]    Overall Loss 2.364277    Objective Loss 2.364277                                        LR 0.100000    Time 0.260889    
2024-04-23 19:34:50,699 - Epoch: [179][  130/  267]    Overall Loss 2.364425    Objective Loss 2.364425                                        LR 0.100000    Time 0.262889    
2024-04-23 19:34:52,813 - Epoch: [179][  140/  267]    Overall Loss 2.365042    Objective Loss 2.365042                                        LR 0.100000    Time 0.259189    
2024-04-23 19:34:55,516 - Epoch: [179][  150/  267]    Overall Loss 2.365764    Objective Loss 2.365764                                        LR 0.100000    Time 0.259914    
2024-04-23 19:34:57,110 - Epoch: [179][  160/  267]    Overall Loss 2.365319    Objective Loss 2.365319                                        LR 0.100000    Time 0.253608    
2024-04-23 19:34:59,968 - Epoch: [130][  296/  296]    Overall Loss 0.732371    Objective Loss 0.732371    Top1 73.770492    Top5 96.721311    LR 0.000080    Time 0.235570    
2024-04-23 19:34:59,983 - Epoch: [179][  170/  267]    Overall Loss 2.367352    Objective Loss 2.367352                                        LR 0.100000    Time 0.255580    
2024-04-23 19:35:00,150 - --- validate (epoch=130)-----------
2024-04-23 19:35:00,152 - 3925 samples (32 per mini-batch)
2024-04-23 19:35:02,263 - Epoch: [179][  180/  267]    Overall Loss 2.366855    Objective Loss 2.366855                                        LR 0.100000    Time 0.254026    
2024-04-23 19:35:05,341 - Epoch: [179][  190/  267]    Overall Loss 2.365542    Objective Loss 2.365542                                        LR 0.100000    Time 0.256835    
2024-04-23 19:35:07,390 - Epoch: [179][  200/  267]    Overall Loss 2.366565    Objective Loss 2.366565                                        LR 0.100000    Time 0.254221    
2024-04-23 19:35:09,844 - Epoch: [179][  210/  267]    Overall Loss 2.367092    Objective Loss 2.367092                                        LR 0.100000    Time 0.253788    
2024-04-23 19:35:11,920 - Epoch: [179][  220/  267]    Overall Loss 2.367468    Objective Loss 2.367468                                        LR 0.100000    Time 0.251677    
2024-04-23 19:35:14,756 - Epoch: [179][  230/  267]    Overall Loss 2.368644    Objective Loss 2.368644                                        LR 0.100000    Time 0.253051    
2024-04-23 19:35:16,627 - Epoch: [179][  240/  267]    Overall Loss 2.370195    Objective Loss 2.370195                                        LR 0.100000    Time 0.250289    
2024-04-23 19:35:19,425 - Epoch: [179][  250/  267]    Overall Loss 2.370908    Objective Loss 2.370908                                        LR 0.100000    Time 0.251458    
2024-04-23 19:35:21,614 - Epoch: [179][  260/  267]    Overall Loss 2.370274    Objective Loss 2.370274                                        LR 0.100000    Time 0.250195    
2024-04-23 19:35:23,129 - Epoch: [179][  267/  267]    Overall Loss 2.369864    Objective Loss 2.369864    Top1 16.279070    Top5 44.186047    LR 0.100000    Time 0.249299    
2024-04-23 19:35:23,383 - --- validate (epoch=179)-----------
2024-04-23 19:35:23,385 - 946 samples (32 per mini-batch)
2024-04-23 19:35:27,193 - Epoch: [179][   10/   30]    Loss 2.331409    Top1 8.750000    Top5 50.937500    
2024-04-23 19:35:27,719 - Epoch: [130][  100/  123]    Loss 0.671046    Top1 78.468750    Top5 97.531250    
2024-04-23 19:35:29,301 - Epoch: [179][   20/   30]    Loss 2.336634    Top1 10.156250    Top5 48.437500    
2024-04-23 19:35:31,931 - Epoch: [130][  123/  123]    Loss 0.678505    Top1 78.318471    Top5 97.299363    
2024-04-23 19:35:31,940 - Epoch: [179][   30/   30]    Loss 2.333804    Top1 9.830867    Top5 49.894292    
2024-04-23 19:35:32,082 - ==> Top1: 9.831    Top5: 49.894    Loss: 2.334

2024-04-23 19:35:32,083 - ==> Confusion:
[[  0   0   0   0  87   0   0   0   0   0]
 [  0   0   0   0  98   0   0   0   0   0]
 [  0   0   0   0  99   0   0   0   0   0]
 [  0   0   0   0  80   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  95   0   0   0   0   0]
 [  0   0   0   0 104   0   0   0   0   0]
 [  0   0   0   0  93   0   0   0   0   0]
 [  0   0   0   0  97   0   0   0   0   0]
 [  0   0   0   0 100   0   0   0   0   0]]

2024-04-23 19:35:32,087 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:35:32,088 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:35:32,106 - 

2024-04-23 19:35:32,107 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:35:32,207 - ==> Top1: 78.318    Top5: 97.299    Loss: 0.679

2024-04-23 19:35:32,216 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:35:32,217 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:35:32,262 - 

2024-04-23 19:35:32,263 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:35:35,632 - Epoch: [180][   10/  267]    Overall Loss 2.335213    Objective Loss 2.335213                                        LR 0.100000    Time 0.352096    
2024-04-23 19:35:37,862 - Epoch: [180][   20/  267]    Overall Loss 2.361279    Objective Loss 2.361279                                        LR 0.100000    Time 0.287396    
2024-04-23 19:35:40,641 - Epoch: [180][   30/  267]    Overall Loss 2.368007    Objective Loss 2.368007                                        LR 0.100000    Time 0.284133    
2024-04-23 19:35:43,170 - Epoch: [180][   40/  267]    Overall Loss 2.364219    Objective Loss 2.364219                                        LR 0.100000    Time 0.276234    
2024-04-23 19:35:45,678 - Epoch: [180][   50/  267]    Overall Loss 2.365649    Objective Loss 2.365649                                        LR 0.100000    Time 0.271096    
2024-04-23 19:35:48,590 - Epoch: [180][   60/  267]    Overall Loss 2.366548    Objective Loss 2.366548                                        LR 0.100000    Time 0.274411    
2024-04-23 19:35:50,577 - Epoch: [180][   70/  267]    Overall Loss 2.368148    Objective Loss 2.368148                                        LR 0.100000    Time 0.263542    
2024-04-23 19:35:53,418 - Epoch: [180][   80/  267]    Overall Loss 2.366158    Objective Loss 2.366158                                        LR 0.100000    Time 0.266085    
2024-04-23 19:35:55,201 - Epoch: [180][   90/  267]    Overall Loss 2.367267    Objective Loss 2.367267                                        LR 0.100000    Time 0.256295    
2024-04-23 19:35:57,647 - Epoch: [131][  100/  296]    Overall Loss 0.721599    Objective Loss 0.721599                                        LR 0.000080    Time 0.253633    
2024-04-23 19:35:57,917 - Epoch: [180][  100/  267]    Overall Loss 2.368447    Objective Loss 2.368447                                        LR 0.100000    Time 0.257801    
2024-04-23 19:35:59,779 - Epoch: [180][  110/  267]    Overall Loss 2.371646    Objective Loss 2.371646                                        LR 0.100000    Time 0.251255    
2024-04-23 19:36:02,490 - Epoch: [180][  120/  267]    Overall Loss 2.371765    Objective Loss 2.371765                                        LR 0.100000    Time 0.252890    
2024-04-23 19:36:04,106 - Epoch: [180][  130/  267]    Overall Loss 2.374107    Objective Loss 2.374107                                        LR 0.100000    Time 0.245842    
2024-04-23 19:36:07,187 - Epoch: [180][  140/  267]    Overall Loss 2.372687    Objective Loss 2.372687                                        LR 0.100000    Time 0.250272    
2024-04-23 19:36:09,029 - Epoch: [180][  150/  267]    Overall Loss 2.370866    Objective Loss 2.370866                                        LR 0.100000    Time 0.245844    
2024-04-23 19:36:10,996 - Epoch: [180][  160/  267]    Overall Loss 2.369652    Objective Loss 2.369652                                        LR 0.100000    Time 0.242752    
2024-04-23 19:36:13,042 - Epoch: [180][  170/  267]    Overall Loss 2.367819    Objective Loss 2.367819                                        LR 0.100000    Time 0.240495    
2024-04-23 19:36:15,919 - Epoch: [180][  180/  267]    Overall Loss 2.367703    Objective Loss 2.367703                                        LR 0.100000    Time 0.243094    
2024-04-23 19:36:17,942 - Epoch: [180][  190/  267]    Overall Loss 2.369757    Objective Loss 2.369757                                        LR 0.100000    Time 0.240935    
2024-04-23 19:36:20,599 - Epoch: [180][  200/  267]    Overall Loss 2.368260    Objective Loss 2.368260                                        LR 0.100000    Time 0.242157    
2024-04-23 19:36:20,809 - Epoch: [131][  200/  296]    Overall Loss 0.721570    Objective Loss 0.721570                                        LR 0.000080    Time 0.242517    
2024-04-23 19:36:22,866 - Epoch: [180][  210/  267]    Overall Loss 2.366688    Objective Loss 2.366688                                        LR 0.100000    Time 0.241408    
2024-04-23 19:36:25,228 - Epoch: [180][  220/  267]    Overall Loss 2.364691    Objective Loss 2.364691                                        LR 0.100000    Time 0.241160    
2024-04-23 19:36:27,496 - Epoch: [180][  230/  267]    Overall Loss 2.365236    Objective Loss 2.365236                                        LR 0.100000    Time 0.240523    
2024-04-23 19:36:29,911 - Epoch: [180][  240/  267]    Overall Loss 2.366004    Objective Loss 2.366004                                        LR 0.100000    Time 0.240550    
2024-04-23 19:36:31,523 - Epoch: [180][  250/  267]    Overall Loss 2.366580    Objective Loss 2.366580                                        LR 0.100000    Time 0.237365    
2024-04-23 19:36:34,585 - Epoch: [180][  260/  267]    Overall Loss 2.366535    Objective Loss 2.366535                                        LR 0.100000    Time 0.240001    
2024-04-23 19:36:35,752 - Epoch: [180][  267/  267]    Overall Loss 2.366065    Objective Loss 2.366065    Top1 9.302326    Top5 53.488372    LR 0.100000    Time 0.238074    
2024-04-23 19:36:35,967 - --- validate (epoch=180)-----------
2024-04-23 19:36:35,968 - 946 samples (32 per mini-batch)
2024-04-23 19:36:39,517 - Epoch: [180][   10/   30]    Loss 2.325509    Top1 9.375000    Top5 53.437500    
2024-04-23 19:36:41,511 - Epoch: [180][   20/   30]    Loss 2.335934    Top1 9.062500    Top5 52.343750    
2024-04-23 19:36:42,438 - Epoch: [131][  296/  296]    Overall Loss 0.725731    Objective Loss 0.725731    Top1 72.131148    Top5 98.360656    LR 0.000080    Time 0.236873    
2024-04-23 19:36:42,750 - --- validate (epoch=131)-----------
2024-04-23 19:36:42,751 - 3925 samples (32 per mini-batch)
2024-04-23 19:36:42,838 - Epoch: [180][   30/   30]    Loss 2.348070    Top1 10.253700    Top5 50.845666    
2024-04-23 19:36:43,007 - ==> Top1: 10.254    Top5: 50.846    Loss: 2.348

2024-04-23 19:36:43,009 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 19:36:43,014 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:36:43,014 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:36:43,030 - 

2024-04-23 19:36:43,031 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:36:46,994 - Epoch: [181][   10/  267]    Overall Loss 2.381404    Objective Loss 2.381404                                        LR 0.100000    Time 0.395765    
2024-04-23 19:36:49,521 - Epoch: [181][   20/  267]    Overall Loss 2.373716    Objective Loss 2.373716                                        LR 0.100000    Time 0.324047    
2024-04-23 19:36:52,927 - Epoch: [181][   30/  267]    Overall Loss 2.366957    Objective Loss 2.366957                                        LR 0.100000    Time 0.329447    
2024-04-23 19:36:55,462 - Epoch: [181][   40/  267]    Overall Loss 2.368176    Objective Loss 2.368176                                        LR 0.100000    Time 0.310376    
2024-04-23 19:36:58,506 - Epoch: [181][   50/  267]    Overall Loss 2.361564    Objective Loss 2.361564                                        LR 0.100000    Time 0.309126    
2024-04-23 19:37:00,659 - Epoch: [181][   60/  267]    Overall Loss 2.367868    Objective Loss 2.367868                                        LR 0.100000    Time 0.293427    
2024-04-23 19:37:03,900 - Epoch: [181][   70/  267]    Overall Loss 2.365184    Objective Loss 2.365184                                        LR 0.100000    Time 0.297762    
2024-04-23 19:37:05,724 - Epoch: [181][   80/  267]    Overall Loss 2.363621    Objective Loss 2.363621                                        LR 0.100000    Time 0.283301    
2024-04-23 19:37:07,696 - Epoch: [181][   90/  267]    Overall Loss 2.365489    Objective Loss 2.365489                                        LR 0.100000    Time 0.273696    
2024-04-23 19:37:09,372 - Epoch: [181][  100/  267]    Overall Loss 2.364931    Objective Loss 2.364931                                        LR 0.100000    Time 0.263061    
2024-04-23 19:37:11,204 - Epoch: [131][  100/  123]    Loss 0.675928    Top1 78.468750    Top5 97.031250    
2024-04-23 19:37:11,790 - Epoch: [181][  110/  267]    Overall Loss 2.369912    Objective Loss 2.369912                                        LR 0.100000    Time 0.261095    
2024-04-23 19:37:13,385 - Epoch: [181][  120/  267]    Overall Loss 2.368381    Objective Loss 2.368381                                        LR 0.100000    Time 0.252607    
2024-04-23 19:37:15,669 - Epoch: [181][  130/  267]    Overall Loss 2.368300    Objective Loss 2.368300                                        LR 0.100000    Time 0.250719    
2024-04-23 19:37:16,377 - Epoch: [131][  123/  123]    Loss 0.671553    Top1 78.394904    Top5 97.197452    
2024-04-23 19:37:16,632 - ==> Top1: 78.395    Top5: 97.197    Loss: 0.672

2024-04-23 19:37:16,642 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:37:16,643 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:37:16,698 - 

2024-04-23 19:37:16,699 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:37:17,270 - Epoch: [181][  140/  267]    Overall Loss 2.374603    Objective Loss 2.374603                                        LR 0.100000    Time 0.244234    
2024-04-23 19:37:19,384 - Epoch: [181][  150/  267]    Overall Loss 2.376004    Objective Loss 2.376004                                        LR 0.100000    Time 0.242025    
2024-04-23 19:37:21,271 - Epoch: [181][  160/  267]    Overall Loss 2.374945    Objective Loss 2.374945                                        LR 0.100000    Time 0.238681    
2024-04-23 19:37:23,483 - Epoch: [181][  170/  267]    Overall Loss 2.375484    Objective Loss 2.375484                                        LR 0.100000    Time 0.237636    
2024-04-23 19:37:25,561 - Epoch: [181][  180/  267]    Overall Loss 2.376829    Objective Loss 2.376829                                        LR 0.100000    Time 0.235968    
2024-04-23 19:37:27,091 - Epoch: [181][  190/  267]    Overall Loss 2.377516    Objective Loss 2.377516                                        LR 0.100000    Time 0.231591    
2024-04-23 19:37:29,450 - Epoch: [181][  200/  267]    Overall Loss 2.376078    Objective Loss 2.376078                                        LR 0.100000    Time 0.231796    
2024-04-23 19:37:31,437 - Epoch: [181][  210/  267]    Overall Loss 2.375810    Objective Loss 2.375810                                        LR 0.100000    Time 0.230205    
2024-04-23 19:37:34,044 - Epoch: [181][  220/  267]    Overall Loss 2.374540    Objective Loss 2.374540                                        LR 0.100000    Time 0.231578    
2024-04-23 19:37:35,853 - Epoch: [181][  230/  267]    Overall Loss 2.375034    Objective Loss 2.375034                                        LR 0.100000    Time 0.229365    
2024-04-23 19:37:38,222 - Epoch: [181][  240/  267]    Overall Loss 2.373708    Objective Loss 2.373708                                        LR 0.100000    Time 0.229665    
2024-04-23 19:37:39,472 - Epoch: [181][  250/  267]    Overall Loss 2.373001    Objective Loss 2.373001                                        LR 0.100000    Time 0.225467    
2024-04-23 19:37:39,869 - Epoch: [132][  100/  296]    Overall Loss 0.719486    Objective Loss 0.719486                                        LR 0.000080    Time 0.231512    
2024-04-23 19:37:41,439 - Epoch: [181][  260/  267]    Overall Loss 2.372113    Objective Loss 2.372113                                        LR 0.100000    Time 0.224351    
2024-04-23 19:37:42,338 - Epoch: [181][  267/  267]    Overall Loss 2.370536    Objective Loss 2.370536    Top1 11.627907    Top5 53.488372    LR 0.100000    Time 0.221825    
2024-04-23 19:37:42,613 - --- validate (epoch=181)-----------
2024-04-23 19:37:42,615 - 946 samples (32 per mini-batch)
2024-04-23 19:37:46,723 - Epoch: [181][   10/   30]    Loss 2.368392    Top1 10.000000    Top5 49.375000    
2024-04-23 19:37:48,874 - Epoch: [181][   20/   30]    Loss 2.352803    Top1 10.625000    Top5 51.093750    
2024-04-23 19:37:51,164 - Epoch: [181][   30/   30]    Loss 2.355158    Top1 10.465116    Top5 51.268499    
2024-04-23 19:37:51,293 - ==> Top1: 10.465    Top5: 51.268    Loss: 2.355

2024-04-23 19:37:51,295 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 19:37:51,300 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:37:51,301 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:37:51,319 - 

2024-04-23 19:37:51,320 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:37:54,614 - Epoch: [182][   10/  267]    Overall Loss 2.376635    Objective Loss 2.376635                                        LR 0.100000    Time 0.329093    
2024-04-23 19:37:56,553 - Epoch: [182][   20/  267]    Overall Loss 2.379003    Objective Loss 2.379003                                        LR 0.100000    Time 0.261302    
2024-04-23 19:37:59,266 - Epoch: [182][   30/  267]    Overall Loss 2.374237    Objective Loss 2.374237                                        LR 0.100000    Time 0.264540    
2024-04-23 19:38:01,393 - Epoch: [182][   40/  267]    Overall Loss 2.368946    Objective Loss 2.368946                                        LR 0.100000    Time 0.251521    
2024-04-23 19:38:01,978 - Epoch: [132][  200/  296]    Overall Loss 0.722384    Objective Loss 0.722384                                        LR 0.000080    Time 0.226202    
2024-04-23 19:38:03,733 - Epoch: [182][   50/  267]    Overall Loss 2.366636    Objective Loss 2.366636                                        LR 0.100000    Time 0.247962    
2024-04-23 19:38:05,641 - Epoch: [182][   60/  267]    Overall Loss 2.360792    Objective Loss 2.360792                                        LR 0.100000    Time 0.238407    
2024-04-23 19:38:08,135 - Epoch: [182][   70/  267]    Overall Loss 2.368461    Objective Loss 2.368461                                        LR 0.100000    Time 0.239946    
2024-04-23 19:38:09,940 - Epoch: [182][   80/  267]    Overall Loss 2.365996    Objective Loss 2.365996                                        LR 0.100000    Time 0.232468    
2024-04-23 19:38:12,265 - Epoch: [182][   90/  267]    Overall Loss 2.366316    Objective Loss 2.366316                                        LR 0.100000    Time 0.232443    
2024-04-23 19:38:13,947 - Epoch: [182][  100/  267]    Overall Loss 2.368549    Objective Loss 2.368549                                        LR 0.100000    Time 0.225985    
2024-04-23 19:38:16,675 - Epoch: [182][  110/  267]    Overall Loss 2.366158    Objective Loss 2.366158                                        LR 0.100000    Time 0.230218    
2024-04-23 19:38:18,320 - Epoch: [182][  120/  267]    Overall Loss 2.365861    Objective Loss 2.365861                                        LR 0.100000    Time 0.224707    
2024-04-23 19:38:20,724 - Epoch: [182][  130/  267]    Overall Loss 2.364954    Objective Loss 2.364954                                        LR 0.100000    Time 0.225896    
2024-04-23 19:38:21,975 - Epoch: [132][  296/  296]    Overall Loss 0.724729    Objective Loss 0.724729    Top1 75.409836    Top5 100.000000    LR 0.000080    Time 0.220337    
2024-04-23 19:38:22,199 - --- validate (epoch=132)-----------
2024-04-23 19:38:22,200 - 3925 samples (32 per mini-batch)
2024-04-23 19:38:22,452 - Epoch: [182][  140/  267]    Overall Loss 2.364032    Objective Loss 2.364032                                        LR 0.100000    Time 0.222088    
2024-04-23 19:38:24,873 - Epoch: [182][  150/  267]    Overall Loss 2.365039    Objective Loss 2.365039                                        LR 0.100000    Time 0.223404    
2024-04-23 19:38:26,614 - Epoch: [182][  160/  267]    Overall Loss 2.367034    Objective Loss 2.367034                                        LR 0.100000    Time 0.220301    
2024-04-23 19:38:28,933 - Epoch: [182][  170/  267]    Overall Loss 2.366923    Objective Loss 2.366923                                        LR 0.100000    Time 0.220967    
2024-04-23 19:38:30,846 - Epoch: [182][  180/  267]    Overall Loss 2.367861    Objective Loss 2.367861                                        LR 0.100000    Time 0.219306    
2024-04-23 19:38:32,810 - Epoch: [182][  190/  267]    Overall Loss 2.369550    Objective Loss 2.369550                                        LR 0.100000    Time 0.218081    
2024-04-23 19:38:35,545 - Epoch: [182][  200/  267]    Overall Loss 2.368682    Objective Loss 2.368682                                        LR 0.100000    Time 0.220841    
2024-04-23 19:38:37,584 - Epoch: [182][  210/  267]    Overall Loss 2.367316    Objective Loss 2.367316                                        LR 0.100000    Time 0.220019    
2024-04-23 19:38:40,131 - Epoch: [182][  220/  267]    Overall Loss 2.366866    Objective Loss 2.366866                                        LR 0.100000    Time 0.221579    
2024-04-23 19:38:42,021 - Epoch: [182][  230/  267]    Overall Loss 2.367313    Objective Loss 2.367313                                        LR 0.100000    Time 0.220152    
2024-04-23 19:38:44,434 - Epoch: [182][  240/  267]    Overall Loss 2.369144    Objective Loss 2.369144                                        LR 0.100000    Time 0.221021    
2024-04-23 19:38:46,310 - Epoch: [182][  250/  267]    Overall Loss 2.370559    Objective Loss 2.370559                                        LR 0.100000    Time 0.219676    
2024-04-23 19:38:47,069 - Epoch: [132][  100/  123]    Loss 0.670939    Top1 77.812500    Top5 97.375000    
2024-04-23 19:38:48,684 - Epoch: [182][  260/  267]    Overall Loss 2.371736    Objective Loss 2.371736                                        LR 0.100000    Time 0.220346    
2024-04-23 19:38:49,516 - Epoch: [182][  267/  267]    Overall Loss 2.371637    Objective Loss 2.371637    Top1 11.627907    Top5 55.813953    LR 0.100000    Time 0.217674    
2024-04-23 19:38:49,793 - --- validate (epoch=182)-----------
2024-04-23 19:38:49,795 - 946 samples (32 per mini-batch)
2024-04-23 19:38:51,316 - Epoch: [132][  123/  123]    Loss 0.674954    Top1 77.656051    Top5 97.171975    
2024-04-23 19:38:51,673 - ==> Top1: 77.656    Top5: 97.172    Loss: 0.675

2024-04-23 19:38:51,684 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:38:51,685 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:38:51,744 - 

2024-04-23 19:38:51,745 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:38:53,982 - Epoch: [182][   10/   30]    Loss 2.340599    Top1 11.562500    Top5 52.812500    
2024-04-23 19:38:56,287 - Epoch: [182][   20/   30]    Loss 2.349364    Top1 11.406250    Top5 52.031250    
2024-04-23 19:38:58,606 - Epoch: [182][   30/   30]    Loss 2.364173    Top1 9.830867    Top5 50.634249    
2024-04-23 19:38:58,824 - ==> Top1: 9.831    Top5: 50.634    Loss: 2.364

2024-04-23 19:38:58,827 - ==> Confusion:
[[  0   0   0   0   0   0   0  87   0   0]
 [  0   0   0   0   0   0   0  98   0   0]
 [  0   0   0   0   0   0   0  99   0   0]
 [  0   0   0   0   0   0   0  80   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  95   0   0]
 [  0   0   0   0   0   0   0 104   0   0]
 [  0   0   0   0   0   0   0  93   0   0]
 [  0   0   0   0   0   0   0  97   0   0]
 [  0   0   0   0   0   0   0 100   0   0]]

2024-04-23 19:38:58,833 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:38:58,834 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:38:58,852 - 

2024-04-23 19:38:58,854 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:39:02,986 - Epoch: [183][   10/  267]    Overall Loss 2.376986    Objective Loss 2.376986                                        LR 0.100000    Time 0.412735    
2024-04-23 19:39:05,297 - Epoch: [183][   20/  267]    Overall Loss 2.359872    Objective Loss 2.359872                                        LR 0.100000    Time 0.321761    
2024-04-23 19:39:08,323 - Epoch: [183][   30/  267]    Overall Loss 2.358000    Objective Loss 2.358000                                        LR 0.100000    Time 0.315263    
2024-04-23 19:39:10,476 - Epoch: [183][   40/  267]    Overall Loss 2.361611    Objective Loss 2.361611                                        LR 0.100000    Time 0.290194    
2024-04-23 19:39:13,651 - Epoch: [183][   50/  267]    Overall Loss 2.363389    Objective Loss 2.363389                                        LR 0.100000    Time 0.295585    
2024-04-23 19:39:16,027 - Epoch: [183][   60/  267]    Overall Loss 2.371961    Objective Loss 2.371961                                        LR 0.100000    Time 0.285876    
2024-04-23 19:39:18,634 - Epoch: [133][  100/  296]    Overall Loss 0.733356    Objective Loss 0.733356                                        LR 0.000080    Time 0.268689    
2024-04-23 19:39:19,534 - Epoch: [183][   70/  267]    Overall Loss 2.376177    Objective Loss 2.376177                                        LR 0.100000    Time 0.295089    
2024-04-23 19:39:21,360 - Epoch: [183][   80/  267]    Overall Loss 2.376617    Objective Loss 2.376617                                        LR 0.100000    Time 0.280991    
2024-04-23 19:39:23,329 - Epoch: [183][   90/  267]    Overall Loss 2.381321    Objective Loss 2.381321                                        LR 0.100000    Time 0.271613    
2024-04-23 19:39:24,881 - Epoch: [183][  100/  267]    Overall Loss 2.382647    Objective Loss 2.382647                                        LR 0.100000    Time 0.259947    
2024-04-23 19:39:27,101 - Epoch: [183][  110/  267]    Overall Loss 2.380782    Objective Loss 2.380782                                        LR 0.100000    Time 0.256464    
2024-04-23 19:39:29,807 - Epoch: [183][  120/  267]    Overall Loss 2.379624    Objective Loss 2.379624                                        LR 0.100000    Time 0.257613    
2024-04-23 19:39:32,012 - Epoch: [183][  130/  267]    Overall Loss 2.379785    Objective Loss 2.379785                                        LR 0.100000    Time 0.254728    
2024-04-23 19:39:35,107 - Epoch: [183][  140/  267]    Overall Loss 2.381942    Objective Loss 2.381942                                        LR 0.100000    Time 0.258617    
2024-04-23 19:39:37,198 - Epoch: [183][  150/  267]    Overall Loss 2.382085    Objective Loss 2.382085                                        LR 0.100000    Time 0.255272    
2024-04-23 19:39:39,750 - Epoch: [183][  160/  267]    Overall Loss 2.382911    Objective Loss 2.382911                                        LR 0.100000    Time 0.255248    
2024-04-23 19:39:39,879 - Epoch: [133][  200/  296]    Overall Loss 0.724912    Objective Loss 0.724912                                        LR 0.000080    Time 0.240466    
2024-04-23 19:39:41,856 - Epoch: [183][  170/  267]    Overall Loss 2.381607    Objective Loss 2.381607                                        LR 0.100000    Time 0.252606    
2024-04-23 19:39:44,905 - Epoch: [183][  180/  267]    Overall Loss 2.380288    Objective Loss 2.380288                                        LR 0.100000    Time 0.255495    
2024-04-23 19:39:46,868 - Epoch: [183][  190/  267]    Overall Loss 2.379802    Objective Loss 2.379802                                        LR 0.100000    Time 0.252362    
2024-04-23 19:39:50,155 - Epoch: [183][  200/  267]    Overall Loss 2.381776    Objective Loss 2.381776                                        LR 0.100000    Time 0.256162    
2024-04-23 19:39:52,405 - Epoch: [183][  210/  267]    Overall Loss 2.380178    Objective Loss 2.380178                                        LR 0.100000    Time 0.254660    
2024-04-23 19:39:54,705 - Epoch: [183][  220/  267]    Overall Loss 2.379996    Objective Loss 2.379996                                        LR 0.100000    Time 0.253526    
2024-04-23 19:39:56,269 - Epoch: [183][  230/  267]    Overall Loss 2.379011    Objective Loss 2.379011                                        LR 0.100000    Time 0.249295    
2024-04-23 19:39:59,413 - Epoch: [183][  240/  267]    Overall Loss 2.380194    Objective Loss 2.380194                                        LR 0.100000    Time 0.251998    
2024-04-23 19:40:00,943 - Epoch: [183][  250/  267]    Overall Loss 2.380696    Objective Loss 2.380696                                        LR 0.100000    Time 0.248029    
2024-04-23 19:40:01,167 - Epoch: [133][  296/  296]    Overall Loss 0.722893    Objective Loss 0.722893    Top1 77.049180    Top5 96.721311    LR 0.000080    Time 0.234336    
2024-04-23 19:40:01,481 - --- validate (epoch=133)-----------
2024-04-23 19:40:01,482 - 3925 samples (32 per mini-batch)
2024-04-23 19:40:02,301 - Epoch: [183][  260/  267]    Overall Loss 2.381244    Objective Loss 2.381244                                        LR 0.100000    Time 0.243703    
2024-04-23 19:40:03,960 - Epoch: [183][  267/  267]    Overall Loss 2.381494    Objective Loss 2.381494    Top1 4.651163    Top5 53.488372    LR 0.100000    Time 0.243519    
2024-04-23 19:40:04,242 - --- validate (epoch=183)-----------
2024-04-23 19:40:04,244 - 946 samples (32 per mini-batch)
2024-04-23 19:40:08,329 - Epoch: [183][   10/   30]    Loss 2.422254    Top1 11.875000    Top5 47.500000    
2024-04-23 19:40:10,781 - Epoch: [183][   20/   30]    Loss 2.398462    Top1 10.781250    Top5 50.937500    
2024-04-23 19:40:14,002 - Epoch: [183][   30/   30]    Loss 2.403053    Top1 10.465116    Top5 50.422833    
2024-04-23 19:40:14,214 - ==> Top1: 10.465    Top5: 50.423    Loss: 2.403

2024-04-23 19:40:14,216 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 19:40:14,224 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:40:14,224 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:40:14,241 - 

2024-04-23 19:40:14,242 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:40:18,009 - Epoch: [184][   10/  267]    Overall Loss 2.394982    Objective Loss 2.394982                                        LR 0.100000    Time 0.376285    
2024-04-23 19:40:20,412 - Epoch: [184][   20/  267]    Overall Loss 2.361507    Objective Loss 2.361507                                        LR 0.100000    Time 0.308153    
2024-04-23 19:40:23,356 - Epoch: [184][   30/  267]    Overall Loss 2.363987    Objective Loss 2.363987                                        LR 0.100000    Time 0.303475    
2024-04-23 19:40:25,596 - Epoch: [184][   40/  267]    Overall Loss 2.367855    Objective Loss 2.367855                                        LR 0.100000    Time 0.283515    
2024-04-23 19:40:28,808 - Epoch: [184][   50/  267]    Overall Loss 2.371009    Objective Loss 2.371009                                        LR 0.100000    Time 0.290967    
2024-04-23 19:40:29,139 - Epoch: [133][  100/  123]    Loss 0.656059    Top1 78.468750    Top5 97.343750    
2024-04-23 19:40:30,810 - Epoch: [184][   60/  267]    Overall Loss 2.369332    Objective Loss 2.369332                                        LR 0.100000    Time 0.275783    
2024-04-23 19:40:33,617 - Epoch: [184][   70/  267]    Overall Loss 2.366784    Objective Loss 2.366784                                        LR 0.100000    Time 0.276425    
2024-04-23 19:40:34,990 - Epoch: [133][  123/  123]    Loss 0.672690    Top1 78.012739    Top5 97.121019    
2024-04-23 19:40:35,188 - Epoch: [184][   80/  267]    Overall Loss 2.367003    Objective Loss 2.367003                                        LR 0.100000    Time 0.261480    
2024-04-23 19:40:35,284 - ==> Top1: 78.013    Top5: 97.121    Loss: 0.673

2024-04-23 19:40:35,297 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:40:35,298 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:40:35,352 - 

2024-04-23 19:40:35,353 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:40:38,025 - Epoch: [184][   90/  267]    Overall Loss 2.365570    Objective Loss 2.365570                                        LR 0.100000    Time 0.263922    
2024-04-23 19:40:40,133 - Epoch: [184][  100/  267]    Overall Loss 2.370298    Objective Loss 2.370298                                        LR 0.100000    Time 0.258575    
2024-04-23 19:40:43,110 - Epoch: [184][  110/  267]    Overall Loss 2.366979    Objective Loss 2.366979                                        LR 0.100000    Time 0.262106    
2024-04-23 19:40:45,163 - Epoch: [184][  120/  267]    Overall Loss 2.365725    Objective Loss 2.365725                                        LR 0.100000    Time 0.257344    
2024-04-23 19:40:48,252 - Epoch: [184][  130/  267]    Overall Loss 2.366771    Objective Loss 2.366771                                        LR 0.100000    Time 0.261292    
2024-04-23 19:40:50,212 - Epoch: [184][  140/  267]    Overall Loss 2.365671    Objective Loss 2.365671                                        LR 0.100000    Time 0.256608    
2024-04-23 19:40:53,148 - Epoch: [184][  150/  267]    Overall Loss 2.364510    Objective Loss 2.364510                                        LR 0.100000    Time 0.259053    
2024-04-23 19:40:55,020 - Epoch: [184][  160/  267]    Overall Loss 2.366459    Objective Loss 2.366459                                        LR 0.100000    Time 0.254541    
2024-04-23 19:40:57,183 - Epoch: [184][  170/  267]    Overall Loss 2.366862    Objective Loss 2.366862                                        LR 0.100000    Time 0.252274    
2024-04-23 19:40:59,114 - Epoch: [184][  180/  267]    Overall Loss 2.368881    Objective Loss 2.368881                                        LR 0.100000    Time 0.248970    
2024-04-23 19:41:00,676 - Epoch: [134][  100/  296]    Overall Loss 0.713233    Objective Loss 0.713233                                        LR 0.000080    Time 0.253012    
2024-04-23 19:41:01,876 - Epoch: [184][  190/  267]    Overall Loss 2.367663    Objective Loss 2.367663                                        LR 0.100000    Time 0.250387    
2024-04-23 19:41:03,489 - Epoch: [184][  200/  267]    Overall Loss 2.367970    Objective Loss 2.367970                                        LR 0.100000    Time 0.245916    
2024-04-23 19:41:05,699 - Epoch: [184][  210/  267]    Overall Loss 2.367328    Objective Loss 2.367328                                        LR 0.100000    Time 0.244716    
2024-04-23 19:41:08,129 - Epoch: [184][  220/  267]    Overall Loss 2.365924    Objective Loss 2.365924                                        LR 0.100000    Time 0.244625    
2024-04-23 19:41:11,336 - Epoch: [184][  230/  267]    Overall Loss 2.366498    Objective Loss 2.366498                                        LR 0.100000    Time 0.247914    
2024-04-23 19:41:13,525 - Epoch: [184][  240/  267]    Overall Loss 2.366505    Objective Loss 2.366505                                        LR 0.100000    Time 0.246695    
2024-04-23 19:41:16,371 - Epoch: [184][  250/  267]    Overall Loss 2.367286    Objective Loss 2.367286                                        LR 0.100000    Time 0.248198    
2024-04-23 19:41:18,844 - Epoch: [184][  260/  267]    Overall Loss 2.369945    Objective Loss 2.369945                                        LR 0.100000    Time 0.248151    
2024-04-23 19:41:20,094 - Epoch: [184][  267/  267]    Overall Loss 2.369806    Objective Loss 2.369806    Top1 11.627907    Top5 46.511628    LR 0.100000    Time 0.246319    
2024-04-23 19:41:20,306 - --- validate (epoch=184)-----------
2024-04-23 19:41:20,307 - 946 samples (32 per mini-batch)
2024-04-23 19:41:24,364 - Epoch: [184][   10/   30]    Loss 2.364616    Top1 10.937500    Top5 51.875000    
2024-04-23 19:41:24,472 - Epoch: [134][  200/  296]    Overall Loss 0.734825    Objective Loss 0.734825                                        LR 0.000080    Time 0.245392    
2024-04-23 19:41:26,709 - Epoch: [184][   20/   30]    Loss 2.346891    Top1 10.156250    Top5 52.656250    
2024-04-23 19:41:28,986 - Epoch: [184][   30/   30]    Loss 2.362318    Top1 10.465116    Top5 51.057082    
2024-04-23 19:41:29,193 - ==> Top1: 10.465    Top5: 51.057    Loss: 2.362

2024-04-23 19:41:29,194 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 19:41:29,199 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:41:29,199 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:41:29,212 - 

2024-04-23 19:41:29,213 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:41:33,341 - Epoch: [185][   10/  267]    Overall Loss 2.383590    Objective Loss 2.383590                                        LR 0.100000    Time 0.412303    
2024-04-23 19:41:35,496 - Epoch: [185][   20/  267]    Overall Loss 2.374956    Objective Loss 2.374956                                        LR 0.100000    Time 0.313733    
2024-04-23 19:41:38,107 - Epoch: [185][   30/  267]    Overall Loss 2.382672    Objective Loss 2.382672                                        LR 0.100000    Time 0.296119    
2024-04-23 19:41:39,728 - Epoch: [185][   40/  267]    Overall Loss 2.366766    Objective Loss 2.366766                                        LR 0.100000    Time 0.262544    
2024-04-23 19:41:42,093 - Epoch: [185][   50/  267]    Overall Loss 2.361932    Objective Loss 2.361932                                        LR 0.100000    Time 0.257276    
2024-04-23 19:41:43,015 - Epoch: [185][   60/  267]    Overall Loss 2.367397    Objective Loss 2.367397                                        LR 0.100000    Time 0.229722    
2024-04-23 19:41:44,360 - Epoch: [185][   70/  267]    Overall Loss 2.369240    Objective Loss 2.369240                                        LR 0.100000    Time 0.216085    
2024-04-23 19:41:45,838 - Epoch: [134][  296/  296]    Overall Loss 0.731249    Objective Loss 0.731249    Top1 73.770492    Top5 95.081967    LR 0.000080    Time 0.237919    
2024-04-23 19:41:46,092 - Epoch: [185][   80/  267]    Overall Loss 2.370072    Objective Loss 2.370072                                        LR 0.100000    Time 0.210689    
2024-04-23 19:41:46,210 - --- validate (epoch=134)-----------
2024-04-23 19:41:46,212 - 3925 samples (32 per mini-batch)
2024-04-23 19:41:48,761 - Epoch: [185][   90/  267]    Overall Loss 2.370861    Objective Loss 2.370861                                        LR 0.100000    Time 0.216910    
2024-04-23 19:41:50,814 - Epoch: [185][  100/  267]    Overall Loss 2.371836    Objective Loss 2.371836                                        LR 0.100000    Time 0.215720    
2024-04-23 19:41:52,564 - Epoch: [185][  110/  267]    Overall Loss 2.371909    Objective Loss 2.371909                                        LR 0.100000    Time 0.211960    
2024-04-23 19:41:54,792 - Epoch: [185][  120/  267]    Overall Loss 2.373306    Objective Loss 2.373306                                        LR 0.100000    Time 0.212842    
2024-04-23 19:41:56,004 - Epoch: [185][  130/  267]    Overall Loss 2.374334    Objective Loss 2.374334                                        LR 0.100000    Time 0.205773    
2024-04-23 19:41:58,019 - Epoch: [185][  140/  267]    Overall Loss 2.375784    Objective Loss 2.375784                                        LR 0.100000    Time 0.205454    
2024-04-23 19:41:59,869 - Epoch: [185][  150/  267]    Overall Loss 2.374353    Objective Loss 2.374353                                        LR 0.100000    Time 0.204072    
2024-04-23 19:42:03,025 - Epoch: [185][  160/  267]    Overall Loss 2.374544    Objective Loss 2.374544                                        LR 0.100000    Time 0.211025    
2024-04-23 19:42:04,914 - Epoch: [185][  170/  267]    Overall Loss 2.371146    Objective Loss 2.371146                                        LR 0.100000    Time 0.209706    
2024-04-23 19:42:07,508 - Epoch: [185][  180/  267]    Overall Loss 2.374112    Objective Loss 2.374112                                        LR 0.100000    Time 0.212451    
2024-04-23 19:42:09,437 - Epoch: [185][  190/  267]    Overall Loss 2.374051    Objective Loss 2.374051                                        LR 0.100000    Time 0.211406    
2024-04-23 19:42:10,344 - Epoch: [134][  100/  123]    Loss 0.682251    Top1 77.375000    Top5 97.125000    
2024-04-23 19:42:12,532 - Epoch: [185][  200/  267]    Overall Loss 2.373984    Objective Loss 2.373984                                        LR 0.100000    Time 0.216299    
2024-04-23 19:42:14,488 - Epoch: [185][  210/  267]    Overall Loss 2.375823    Objective Loss 2.375823                                        LR 0.100000    Time 0.215299    
2024-04-23 19:42:15,251 - Epoch: [134][  123/  123]    Loss 0.682672    Top1 77.681529    Top5 97.197452    
2024-04-23 19:42:15,503 - ==> Top1: 77.682    Top5: 97.197    Loss: 0.683

2024-04-23 19:42:15,514 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:42:15,515 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:42:15,571 - 

2024-04-23 19:42:15,572 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:42:16,588 - Epoch: [185][  220/  267]    Overall Loss 2.377152    Objective Loss 2.377152                                        LR 0.100000    Time 0.215048    
2024-04-23 19:42:18,388 - Epoch: [185][  230/  267]    Overall Loss 2.376900    Objective Loss 2.376900                                        LR 0.100000    Time 0.213511    
2024-04-23 19:42:20,898 - Epoch: [185][  240/  267]    Overall Loss 2.376549    Objective Loss 2.376549                                        LR 0.100000    Time 0.215058    
2024-04-23 19:42:23,183 - Epoch: [185][  250/  267]    Overall Loss 2.377972    Objective Loss 2.377972                                        LR 0.100000    Time 0.215585    
2024-04-23 19:42:24,833 - Epoch: [185][  260/  267]    Overall Loss 2.376099    Objective Loss 2.376099                                        LR 0.100000    Time 0.213627    
2024-04-23 19:42:26,093 - Epoch: [185][  267/  267]    Overall Loss 2.375416    Objective Loss 2.375416    Top1 11.627907    Top5 60.465116    LR 0.100000    Time 0.212736    
2024-04-23 19:42:26,379 - --- validate (epoch=185)-----------
2024-04-23 19:42:26,380 - 946 samples (32 per mini-batch)
2024-04-23 19:42:30,374 - Epoch: [185][   10/   30]    Loss 2.354233    Top1 11.562500    Top5 48.750000    
2024-04-23 19:42:32,300 - Epoch: [185][   20/   30]    Loss 2.368246    Top1 10.000000    Top5 49.062500    
2024-04-23 19:42:34,456 - Epoch: [185][   30/   30]    Loss 2.363257    Top1 10.042283    Top5 49.894292    
2024-04-23 19:42:34,665 - ==> Top1: 10.042    Top5: 49.894    Loss: 2.363

2024-04-23 19:42:34,667 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 19:42:34,673 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:42:34,674 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:42:34,691 - 

2024-04-23 19:42:34,692 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:42:38,278 - Epoch: [186][   10/  267]    Overall Loss 2.346525    Objective Loss 2.346525                                        LR 0.100000    Time 0.358213    
2024-04-23 19:42:40,290 - Epoch: [135][  100/  296]    Overall Loss 0.732952    Objective Loss 0.732952                                        LR 0.000080    Time 0.246970    
2024-04-23 19:42:40,466 - Epoch: [186][   20/  267]    Overall Loss 2.373366    Objective Loss 2.373366                                        LR 0.100000    Time 0.288335    
2024-04-23 19:42:43,079 - Epoch: [186][   30/  267]    Overall Loss 2.385492    Objective Loss 2.385492                                        LR 0.100000    Time 0.279228    
2024-04-23 19:42:45,111 - Epoch: [186][   40/  267]    Overall Loss 2.376577    Objective Loss 2.376577                                        LR 0.100000    Time 0.260137    
2024-04-23 19:42:46,982 - Epoch: [186][   50/  267]    Overall Loss 2.371587    Objective Loss 2.371587                                        LR 0.100000    Time 0.245481    
2024-04-23 19:42:49,373 - Epoch: [186][   60/  267]    Overall Loss 2.372065    Objective Loss 2.372065                                        LR 0.100000    Time 0.244370    
2024-04-23 19:42:51,819 - Epoch: [186][   70/  267]    Overall Loss 2.368213    Objective Loss 2.368213                                        LR 0.100000    Time 0.244355    
2024-04-23 19:42:54,821 - Epoch: [186][   80/  267]    Overall Loss 2.368811    Objective Loss 2.368811                                        LR 0.100000    Time 0.251286    
2024-04-23 19:42:56,970 - Epoch: [186][   90/  267]    Overall Loss 2.368643    Objective Loss 2.368643                                        LR 0.100000    Time 0.247210    
2024-04-23 19:42:59,251 - Epoch: [186][  100/  267]    Overall Loss 2.363216    Objective Loss 2.363216                                        LR 0.100000    Time 0.245273    
2024-04-23 19:43:00,258 - Epoch: [135][  200/  296]    Overall Loss 0.722190    Objective Loss 0.722190                                        LR 0.000080    Time 0.223224    
2024-04-23 19:43:01,242 - Epoch: [186][  110/  267]    Overall Loss 2.366320    Objective Loss 2.366320                                        LR 0.100000    Time 0.241048    
2024-04-23 19:43:03,934 - Epoch: [186][  120/  267]    Overall Loss 2.368213    Objective Loss 2.368213                                        LR 0.100000    Time 0.243374    
2024-04-23 19:43:05,757 - Epoch: [186][  130/  267]    Overall Loss 2.369836    Objective Loss 2.369836                                        LR 0.100000    Time 0.238659    
2024-04-23 19:43:08,819 - Epoch: [186][  140/  267]    Overall Loss 2.366001    Objective Loss 2.366001                                        LR 0.100000    Time 0.243464    
2024-04-23 19:43:10,872 - Epoch: [186][  150/  267]    Overall Loss 2.367245    Objective Loss 2.367245                                        LR 0.100000    Time 0.240901    
2024-04-23 19:43:13,913 - Epoch: [186][  160/  267]    Overall Loss 2.367991    Objective Loss 2.367991                                        LR 0.100000    Time 0.244833    
2024-04-23 19:43:16,391 - Epoch: [186][  170/  267]    Overall Loss 2.366676    Objective Loss 2.366676                                        LR 0.100000    Time 0.244992    
2024-04-23 19:43:19,656 - Epoch: [186][  180/  267]    Overall Loss 2.364927    Objective Loss 2.364927                                        LR 0.100000    Time 0.249505    
2024-04-23 19:43:21,951 - Epoch: [186][  190/  267]    Overall Loss 2.366370    Objective Loss 2.366370                                        LR 0.100000    Time 0.248443    
2024-04-23 19:43:23,139 - Epoch: [135][  296/  296]    Overall Loss 0.737033    Objective Loss 0.737033    Top1 73.770492    Top5 98.360656    LR 0.000080    Time 0.228070    
2024-04-23 19:43:23,453 - --- validate (epoch=135)-----------
2024-04-23 19:43:23,454 - 3925 samples (32 per mini-batch)
2024-04-23 19:43:24,271 - Epoch: [186][  200/  267]    Overall Loss 2.366500    Objective Loss 2.366500                                        LR 0.100000    Time 0.247611    
2024-04-23 19:43:26,435 - Epoch: [186][  210/  267]    Overall Loss 2.365418    Objective Loss 2.365418                                        LR 0.100000    Time 0.246111    
2024-04-23 19:43:29,228 - Epoch: [186][  220/  267]    Overall Loss 2.364690    Objective Loss 2.364690                                        LR 0.100000    Time 0.247609    
2024-04-23 19:43:31,330 - Epoch: [186][  230/  267]    Overall Loss 2.364512    Objective Loss 2.364512                                        LR 0.100000    Time 0.245972    
2024-04-23 19:43:33,977 - Epoch: [186][  240/  267]    Overall Loss 2.365702    Objective Loss 2.365702                                        LR 0.100000    Time 0.246742    
2024-04-23 19:43:35,795 - Epoch: [186][  250/  267]    Overall Loss 2.365213    Objective Loss 2.365213                                        LR 0.100000    Time 0.244136    
2024-04-23 19:43:37,599 - Epoch: [186][  260/  267]    Overall Loss 2.367358    Objective Loss 2.367358                                        LR 0.100000    Time 0.241670    
2024-04-23 19:43:38,572 - Epoch: [186][  267/  267]    Overall Loss 2.366569    Objective Loss 2.366569    Top1 11.627907    Top5 46.511628    LR 0.100000    Time 0.238972    
2024-04-23 19:43:38,832 - --- validate (epoch=186)-----------
2024-04-23 19:43:38,834 - 946 samples (32 per mini-batch)
2024-04-23 19:43:42,345 - Epoch: [186][   10/   30]    Loss 2.352870    Top1 9.687500    Top5 51.875000    
2024-04-23 19:43:44,251 - Epoch: [186][   20/   30]    Loss 2.351271    Top1 10.781250    Top5 50.312500    
2024-04-23 19:43:46,264 - Epoch: [135][  100/  123]    Loss 0.671337    Top1 78.312500    Top5 97.468750    
2024-04-23 19:43:46,657 - Epoch: [186][   30/   30]    Loss 2.361692    Top1 10.253700    Top5 48.837209    
2024-04-23 19:43:46,906 - ==> Top1: 10.254    Top5: 48.837    Loss: 2.362

2024-04-23 19:43:46,907 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 19:43:46,911 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:43:46,912 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:43:46,926 - 

2024-04-23 19:43:46,927 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:43:50,436 - Epoch: [187][   10/  267]    Overall Loss 2.340508    Objective Loss 2.340508                                        LR 0.100000    Time 0.350511    
2024-04-23 19:43:51,064 - Epoch: [135][  123/  123]    Loss 0.675328    Top1 78.038217    Top5 97.248408    
2024-04-23 19:43:51,348 - ==> Top1: 78.038    Top5: 97.248    Loss: 0.675

2024-04-23 19:43:51,358 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:43:51,359 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:43:51,408 - 

2024-04-23 19:43:51,408 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:43:52,239 - Epoch: [187][   20/  267]    Overall Loss 2.341739    Objective Loss 2.341739                                        LR 0.100000    Time 0.265299    
2024-04-23 19:43:54,422 - Epoch: [187][   30/  267]    Overall Loss 2.344680    Objective Loss 2.344680                                        LR 0.100000    Time 0.249532    
2024-04-23 19:43:56,292 - Epoch: [187][   40/  267]    Overall Loss 2.358625    Objective Loss 2.358625                                        LR 0.100000    Time 0.233843    
2024-04-23 19:43:58,727 - Epoch: [187][   50/  267]    Overall Loss 2.359617    Objective Loss 2.359617                                        LR 0.100000    Time 0.235696    
2024-04-23 19:44:00,580 - Epoch: [187][   60/  267]    Overall Loss 2.360345    Objective Loss 2.360345                                        LR 0.100000    Time 0.227253    
2024-04-23 19:44:03,011 - Epoch: [187][   70/  267]    Overall Loss 2.364059    Objective Loss 2.364059                                        LR 0.100000    Time 0.229468    
2024-04-23 19:44:04,806 - Epoch: [187][   80/  267]    Overall Loss 2.361906    Objective Loss 2.361906                                        LR 0.100000    Time 0.223199    
2024-04-23 19:44:06,295 - Epoch: [187][   90/  267]    Overall Loss 2.360847    Objective Loss 2.360847                                        LR 0.100000    Time 0.214913    
2024-04-23 19:44:07,164 - Epoch: [187][  100/  267]    Overall Loss 2.364585    Objective Loss 2.364585                                        LR 0.100000    Time 0.202082    
2024-04-23 19:44:09,005 - Epoch: [187][  110/  267]    Overall Loss 2.364309    Objective Loss 2.364309                                        LR 0.100000    Time 0.200424    
2024-04-23 19:44:10,501 - Epoch: [187][  120/  267]    Overall Loss 2.363325    Objective Loss 2.363325                                        LR 0.100000    Time 0.196162    
2024-04-23 19:44:12,675 - Epoch: [187][  130/  267]    Overall Loss 2.361994    Objective Loss 2.361994                                        LR 0.100000    Time 0.197769    
2024-04-23 19:44:14,303 - Epoch: [187][  140/  267]    Overall Loss 2.361897    Objective Loss 2.361897                                        LR 0.100000    Time 0.195253    
2024-04-23 19:44:14,494 - Epoch: [136][  100/  296]    Overall Loss 0.724393    Objective Loss 0.724393                                        LR 0.000080    Time 0.230625    
2024-04-23 19:44:16,786 - Epoch: [187][  150/  267]    Overall Loss 2.364317    Objective Loss 2.364317                                        LR 0.100000    Time 0.198775    
2024-04-23 19:44:18,737 - Epoch: [187][  160/  267]    Overall Loss 2.366428    Objective Loss 2.366428                                        LR 0.100000    Time 0.198523    
2024-04-23 19:44:21,233 - Epoch: [187][  170/  267]    Overall Loss 2.364912    Objective Loss 2.364912                                        LR 0.100000    Time 0.201512    
2024-04-23 19:44:23,487 - Epoch: [187][  180/  267]    Overall Loss 2.362959    Objective Loss 2.362959                                        LR 0.100000    Time 0.202827    
2024-04-23 19:44:25,877 - Epoch: [187][  190/  267]    Overall Loss 2.362771    Objective Loss 2.362771                                        LR 0.100000    Time 0.204715    
2024-04-23 19:44:27,745 - Epoch: [187][  200/  267]    Overall Loss 2.362307    Objective Loss 2.362307                                        LR 0.100000    Time 0.203805    
2024-04-23 19:44:30,546 - Epoch: [187][  210/  267]    Overall Loss 2.360719    Objective Loss 2.360719                                        LR 0.100000    Time 0.207428    
2024-04-23 19:44:32,266 - Epoch: [187][  220/  267]    Overall Loss 2.361290    Objective Loss 2.361290                                        LR 0.100000    Time 0.205794    
2024-04-23 19:44:34,189 - Epoch: [187][  230/  267]    Overall Loss 2.359979    Objective Loss 2.359979                                        LR 0.100000    Time 0.205197    
2024-04-23 19:44:36,732 - Epoch: [187][  240/  267]    Overall Loss 2.360586    Objective Loss 2.360586                                        LR 0.100000    Time 0.207234    
2024-04-23 19:44:37,176 - Epoch: [136][  200/  296]    Overall Loss 0.726573    Objective Loss 0.726573                                        LR 0.000080    Time 0.228629    
2024-04-23 19:44:38,787 - Epoch: [187][  250/  267]    Overall Loss 2.362281    Objective Loss 2.362281                                        LR 0.100000    Time 0.207151    
2024-04-23 19:44:41,741 - Epoch: [187][  260/  267]    Overall Loss 2.362469    Objective Loss 2.362469                                        LR 0.100000    Time 0.210534    
2024-04-23 19:44:43,190 - Epoch: [187][  267/  267]    Overall Loss 2.362308    Objective Loss 2.362308    Top1 6.976744    Top5 39.534884    LR 0.100000    Time 0.210432    
2024-04-23 19:44:43,473 - --- validate (epoch=187)-----------
2024-04-23 19:44:43,474 - 946 samples (32 per mini-batch)
2024-04-23 19:44:47,398 - Epoch: [187][   10/   30]    Loss 2.421614    Top1 6.562500    Top5 48.437500    
2024-04-23 19:44:49,276 - Epoch: [187][   20/   30]    Loss 2.406331    Top1 8.906250    Top5 48.906250    
2024-04-23 19:44:51,471 - Epoch: [187][   30/   30]    Loss 2.398366    Top1 9.196617    Top5 49.048626    
2024-04-23 19:44:51,716 - ==> Top1: 9.197    Top5: 49.049    Loss: 2.398

2024-04-23 19:44:51,718 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 19:44:51,722 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:44:51,722 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:44:51,740 - 

2024-04-23 19:44:51,741 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:44:55,884 - Epoch: [188][   10/  267]    Overall Loss 2.408914    Objective Loss 2.408914                                        LR 0.100000    Time 0.413969    
2024-04-23 19:44:57,940 - Epoch: [188][   20/  267]    Overall Loss 2.393963    Objective Loss 2.393963                                        LR 0.100000    Time 0.309593    
2024-04-23 19:44:59,242 - Epoch: [136][  296/  296]    Overall Loss 0.724874    Objective Loss 0.724874    Top1 80.327869    Top5 96.721311    LR 0.000080    Time 0.228948    
2024-04-23 19:44:59,602 - --- validate (epoch=136)-----------
2024-04-23 19:44:59,603 - 3925 samples (32 per mini-batch)
2024-04-23 19:45:00,550 - Epoch: [188][   30/  267]    Overall Loss 2.377582    Objective Loss 2.377582                                        LR 0.100000    Time 0.293321    
2024-04-23 19:45:02,499 - Epoch: [188][   40/  267]    Overall Loss 2.385428    Objective Loss 2.385428                                        LR 0.100000    Time 0.268620    
2024-04-23 19:45:04,338 - Epoch: [188][   50/  267]    Overall Loss 2.386487    Objective Loss 2.386487                                        LR 0.100000    Time 0.251612    
2024-04-23 19:45:06,199 - Epoch: [188][   60/  267]    Overall Loss 2.386571    Objective Loss 2.386571                                        LR 0.100000    Time 0.240657    
2024-04-23 19:45:08,878 - Epoch: [188][   70/  267]    Overall Loss 2.390169    Objective Loss 2.390169                                        LR 0.100000    Time 0.244511    
2024-04-23 19:45:10,716 - Epoch: [188][   80/  267]    Overall Loss 2.388467    Objective Loss 2.388467                                        LR 0.100000    Time 0.236888    
2024-04-23 19:45:13,412 - Epoch: [188][   90/  267]    Overall Loss 2.385520    Objective Loss 2.385520                                        LR 0.100000    Time 0.240486    
2024-04-23 19:45:15,379 - Epoch: [188][  100/  267]    Overall Loss 2.384724    Objective Loss 2.384724                                        LR 0.100000    Time 0.236082    
2024-04-23 19:45:18,370 - Epoch: [188][  110/  267]    Overall Loss 2.382643    Objective Loss 2.382643                                        LR 0.100000    Time 0.241787    
2024-04-23 19:45:20,562 - Epoch: [188][  120/  267]    Overall Loss 2.382181    Objective Loss 2.382181                                        LR 0.100000    Time 0.239881    
2024-04-23 19:45:23,815 - Epoch: [188][  130/  267]    Overall Loss 2.379110    Objective Loss 2.379110                                        LR 0.100000    Time 0.246424    
2024-04-23 19:45:26,097 - Epoch: [188][  140/  267]    Overall Loss 2.380734    Objective Loss 2.380734                                        LR 0.100000    Time 0.245100    
2024-04-23 19:45:27,027 - Epoch: [136][  100/  123]    Loss 0.690161    Top1 77.781250    Top5 97.218750    
2024-04-23 19:45:29,012 - Epoch: [188][  150/  267]    Overall Loss 2.381900    Objective Loss 2.381900                                        LR 0.100000    Time 0.248172    
2024-04-23 19:45:30,863 - Epoch: [188][  160/  267]    Overall Loss 2.383350    Objective Loss 2.383350                                        LR 0.100000    Time 0.244206    
2024-04-23 19:45:32,318 - Epoch: [136][  123/  123]    Loss 0.678731    Top1 78.114650    Top5 97.401274    
2024-04-23 19:45:32,568 - ==> Top1: 78.115    Top5: 97.401    Loss: 0.679

2024-04-23 19:45:32,578 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:45:32,578 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:45:32,625 - 

2024-04-23 19:45:32,626 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:45:32,814 - Epoch: [188][  170/  267]    Overall Loss 2.384545    Objective Loss 2.384545                                        LR 0.100000    Time 0.241305    
2024-04-23 19:45:35,561 - Epoch: [188][  180/  267]    Overall Loss 2.384606    Objective Loss 2.384606                                        LR 0.100000    Time 0.243144    
2024-04-23 19:45:37,504 - Epoch: [188][  190/  267]    Overall Loss 2.381617    Objective Loss 2.381617                                        LR 0.100000    Time 0.240555    
2024-04-23 19:45:39,850 - Epoch: [188][  200/  267]    Overall Loss 2.379968    Objective Loss 2.379968                                        LR 0.100000    Time 0.240252    
2024-04-23 19:45:41,295 - Epoch: [188][  210/  267]    Overall Loss 2.380567    Objective Loss 2.380567                                        LR 0.100000    Time 0.235677    
2024-04-23 19:45:43,797 - Epoch: [188][  220/  267]    Overall Loss 2.378686    Objective Loss 2.378686                                        LR 0.100000    Time 0.236327    
2024-04-23 19:45:45,475 - Epoch: [188][  230/  267]    Overall Loss 2.379491    Objective Loss 2.379491                                        LR 0.100000    Time 0.233336    
2024-04-23 19:45:47,856 - Epoch: [188][  240/  267]    Overall Loss 2.381011    Objective Loss 2.381011                                        LR 0.100000    Time 0.233523    
2024-04-23 19:45:49,244 - Epoch: [188][  250/  267]    Overall Loss 2.380608    Objective Loss 2.380608                                        LR 0.100000    Time 0.229720    
2024-04-23 19:45:51,526 - Epoch: [188][  260/  267]    Overall Loss 2.380176    Objective Loss 2.380176                                        LR 0.100000    Time 0.229648    
2024-04-23 19:45:52,826 - Epoch: [188][  267/  267]    Overall Loss 2.379472    Objective Loss 2.379472    Top1 11.627907    Top5 39.534884    LR 0.100000    Time 0.228488    
2024-04-23 19:45:53,062 - --- validate (epoch=188)-----------
2024-04-23 19:45:53,064 - 946 samples (32 per mini-batch)
2024-04-23 19:45:53,527 - Epoch: [137][  100/  296]    Overall Loss 0.717514    Objective Loss 0.717514                                        LR 0.000080    Time 0.208810    
2024-04-23 19:45:56,960 - Epoch: [188][   10/   30]    Loss 2.329219    Top1 11.250000    Top5 53.125000    
2024-04-23 19:45:59,242 - Epoch: [188][   20/   30]    Loss 2.332478    Top1 10.781250    Top5 51.562500    
2024-04-23 19:46:01,939 - Epoch: [188][   30/   30]    Loss 2.334770    Top1 10.253700    Top5 52.114165    
2024-04-23 19:46:02,097 - ==> Top1: 10.254    Top5: 52.114    Loss: 2.335

2024-04-23 19:46:02,098 - ==> Confusion:
[[  0   0   0   0   0   0   0   0  87   0]
 [  0   0   0   0   0   0   0   0  98   0]
 [  0   0   0   0   0   0   0   0  99   0]
 [  0   0   0   0   0   0   0   0  80   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  95   0]
 [  0   0   0   0   0   0   0   0 104   0]
 [  0   0   0   0   0   0   0   0  93   0]
 [  0   0   0   0   0   0   0   0  97   0]
 [  0   0   0   0   0   0   0   0 100   0]]

2024-04-23 19:46:02,103 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:46:02,103 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:46:02,118 - 

2024-04-23 19:46:02,119 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:46:05,893 - Epoch: [189][   10/  267]    Overall Loss 2.340229    Objective Loss 2.340229                                        LR 0.100000    Time 0.377055    
2024-04-23 19:46:08,042 - Epoch: [189][   20/  267]    Overall Loss 2.353234    Objective Loss 2.353234                                        LR 0.100000    Time 0.295774    
2024-04-23 19:46:10,621 - Epoch: [189][   30/  267]    Overall Loss 2.357955    Objective Loss 2.357955                                        LR 0.100000    Time 0.283051    
2024-04-23 19:46:12,575 - Epoch: [189][   40/  267]    Overall Loss 2.361488    Objective Loss 2.361488                                        LR 0.100000    Time 0.261062    
2024-04-23 19:46:15,852 - Epoch: [189][   50/  267]    Overall Loss 2.361441    Objective Loss 2.361441                                        LR 0.100000    Time 0.274337    
2024-04-23 19:46:15,915 - Epoch: [137][  200/  296]    Overall Loss 0.713002    Objective Loss 0.713002                                        LR 0.000080    Time 0.216247    
2024-04-23 19:46:18,033 - Epoch: [189][   60/  267]    Overall Loss 2.365899    Objective Loss 2.365899                                        LR 0.100000    Time 0.264919    
2024-04-23 19:46:20,907 - Epoch: [189][   70/  267]    Overall Loss 2.364658    Objective Loss 2.364658                                        LR 0.100000    Time 0.268080    
2024-04-23 19:46:22,734 - Epoch: [189][   80/  267]    Overall Loss 2.370871    Objective Loss 2.370871                                        LR 0.100000    Time 0.257356    
2024-04-23 19:46:25,547 - Epoch: [189][   90/  267]    Overall Loss 2.371550    Objective Loss 2.371550                                        LR 0.100000    Time 0.259970    
2024-04-23 19:46:27,531 - Epoch: [189][  100/  267]    Overall Loss 2.370234    Objective Loss 2.370234                                        LR 0.100000    Time 0.253772    
2024-04-23 19:46:30,116 - Epoch: [189][  110/  267]    Overall Loss 2.370903    Objective Loss 2.370903                                        LR 0.100000    Time 0.254173    
2024-04-23 19:46:32,059 - Epoch: [189][  120/  267]    Overall Loss 2.371828    Objective Loss 2.371828                                        LR 0.100000    Time 0.249152    
2024-04-23 19:46:34,649 - Epoch: [189][  130/  267]    Overall Loss 2.369955    Objective Loss 2.369955                                        LR 0.100000    Time 0.249889    
2024-04-23 19:46:36,566 - Epoch: [189][  140/  267]    Overall Loss 2.368669    Objective Loss 2.368669                                        LR 0.100000    Time 0.245710    
2024-04-23 19:46:38,700 - Epoch: [137][  296/  296]    Overall Loss 0.712514    Objective Loss 0.712514    Top1 80.327869    Top5 98.360656    LR 0.000080    Time 0.223024    
2024-04-23 19:46:38,808 - Epoch: [189][  150/  267]    Overall Loss 2.368630    Objective Loss 2.368630                                        LR 0.100000    Time 0.244262    
2024-04-23 19:46:39,006 - --- validate (epoch=137)-----------
2024-04-23 19:46:39,008 - 3925 samples (32 per mini-batch)
2024-04-23 19:46:40,932 - Epoch: [189][  160/  267]    Overall Loss 2.370910    Objective Loss 2.370910                                        LR 0.100000    Time 0.242251    
2024-04-23 19:46:43,433 - Epoch: [189][  170/  267]    Overall Loss 2.370110    Objective Loss 2.370110                                        LR 0.100000    Time 0.242698    
2024-04-23 19:46:46,068 - Epoch: [189][  180/  267]    Overall Loss 2.373016    Objective Loss 2.373016                                        LR 0.100000    Time 0.243837    
2024-04-23 19:46:48,660 - Epoch: [189][  190/  267]    Overall Loss 2.369906    Objective Loss 2.369906                                        LR 0.100000    Time 0.244630    
2024-04-23 19:46:51,314 - Epoch: [189][  200/  267]    Overall Loss 2.369839    Objective Loss 2.369839                                        LR 0.100000    Time 0.245651    
2024-04-23 19:46:53,399 - Epoch: [189][  210/  267]    Overall Loss 2.369323    Objective Loss 2.369323                                        LR 0.100000    Time 0.243868    
2024-04-23 19:46:56,263 - Epoch: [189][  220/  267]    Overall Loss 2.369093    Objective Loss 2.369093                                        LR 0.100000    Time 0.245788    
2024-04-23 19:46:58,192 - Epoch: [189][  230/  267]    Overall Loss 2.368907    Objective Loss 2.368907                                        LR 0.100000    Time 0.243480    
2024-04-23 19:47:00,566 - Epoch: [189][  240/  267]    Overall Loss 2.369290    Objective Loss 2.369290                                        LR 0.100000    Time 0.243216    
2024-04-23 19:47:02,288 - Epoch: [189][  250/  267]    Overall Loss 2.371087    Objective Loss 2.371087                                        LR 0.100000    Time 0.240360    
2024-04-23 19:47:05,124 - Epoch: [189][  260/  267]    Overall Loss 2.372331    Objective Loss 2.372331                                        LR 0.100000    Time 0.242011    
2024-04-23 19:47:05,686 - Epoch: [137][  100/  123]    Loss 0.676688    Top1 77.281250    Top5 97.312500    
2024-04-23 19:47:06,125 - Epoch: [189][  267/  267]    Overall Loss 2.373614    Objective Loss 2.373614    Top1 9.302326    Top5 51.162791    LR 0.100000    Time 0.239408    
2024-04-23 19:47:06,356 - --- validate (epoch=189)-----------
2024-04-23 19:47:06,358 - 946 samples (32 per mini-batch)
2024-04-23 19:47:09,885 - Epoch: [189][   10/   30]    Loss 2.390219    Top1 10.000000    Top5 48.750000    
2024-04-23 19:47:10,883 - Epoch: [137][  123/  123]    Loss 0.681510    Top1 77.401274    Top5 97.197452    
2024-04-23 19:47:11,140 - ==> Top1: 77.401    Top5: 97.197    Loss: 0.682

2024-04-23 19:47:11,152 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:47:11,153 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:47:11,205 - 

2024-04-23 19:47:11,206 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:47:11,414 - Epoch: [189][   20/   30]    Loss 2.376535    Top1 12.031250    Top5 50.937500    
2024-04-23 19:47:13,360 - Epoch: [189][   30/   30]    Loss 2.388455    Top1 10.570825    Top5 50.317125    
2024-04-23 19:47:13,627 - ==> Top1: 10.571    Top5: 50.317    Loss: 2.388

2024-04-23 19:47:13,629 - ==> Confusion:
[[  0   0   0   0   0   0   0   0   0  87]
 [  0   0   0   0   0   0   0   0   0  98]
 [  0   0   0   0   0   0   0   0   0  99]
 [  0   0   0   0   0   0   0   0   0  80]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  95]
 [  0   0   0   0   0   0   0   0   0 104]
 [  0   0   0   0   0   0   0   0   0  93]
 [  0   0   0   0   0   0   0   0   0  97]
 [  0   0   0   0   0   0   0   0   0 100]]

2024-04-23 19:47:13,634 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:47:13,635 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:47:13,652 - 

2024-04-23 19:47:13,652 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:47:17,709 - Epoch: [190][   10/  267]    Overall Loss 2.373615    Objective Loss 2.373615                                        LR 0.100000    Time 0.405361    
2024-04-23 19:47:19,909 - Epoch: [190][   20/  267]    Overall Loss 2.344600    Objective Loss 2.344600                                        LR 0.100000    Time 0.312534    
2024-04-23 19:47:21,790 - Epoch: [190][   30/  267]    Overall Loss 2.358731    Objective Loss 2.358731                                        LR 0.100000    Time 0.270950    
2024-04-23 19:47:24,431 - Epoch: [190][   40/  267]    Overall Loss 2.361236    Objective Loss 2.361236                                        LR 0.100000    Time 0.269162    
2024-04-23 19:47:27,484 - Epoch: [190][   50/  267]    Overall Loss 2.359981    Objective Loss 2.359981                                        LR 0.100000    Time 0.276317    
2024-04-23 19:47:29,999 - Epoch: [190][   60/  267]    Overall Loss 2.360747    Objective Loss 2.360747                                        LR 0.100000    Time 0.272145    
2024-04-23 19:47:32,939 - Epoch: [190][   70/  267]    Overall Loss 2.362981    Objective Loss 2.362981                                        LR 0.100000    Time 0.275215    
2024-04-23 19:47:35,131 - Epoch: [190][   80/  267]    Overall Loss 2.368131    Objective Loss 2.368131                                        LR 0.100000    Time 0.268178    
2024-04-23 19:47:38,078 - Epoch: [138][  100/  296]    Overall Loss 0.703243    Objective Loss 0.703243                                        LR 0.000080    Time 0.268513    
2024-04-23 19:47:38,301 - Epoch: [190][   90/  267]    Overall Loss 2.369703    Objective Loss 2.369703                                        LR 0.100000    Time 0.273568    
2024-04-23 19:47:40,610 - Epoch: [190][  100/  267]    Overall Loss 2.367479    Objective Loss 2.367479                                        LR 0.100000    Time 0.269273    
2024-04-23 19:47:43,689 - Epoch: [190][  110/  267]    Overall Loss 2.363824    Objective Loss 2.363824                                        LR 0.100000    Time 0.272758    
2024-04-23 19:47:46,065 - Epoch: [190][  120/  267]    Overall Loss 2.362827    Objective Loss 2.362827                                        LR 0.100000    Time 0.269804    
2024-04-23 19:47:49,060 - Epoch: [190][  130/  267]    Overall Loss 2.362850    Objective Loss 2.362850                                        LR 0.100000    Time 0.272063    
2024-04-23 19:47:51,576 - Epoch: [190][  140/  267]    Overall Loss 2.366486    Objective Loss 2.366486                                        LR 0.100000    Time 0.270578    
2024-04-23 19:47:54,743 - Epoch: [190][  150/  267]    Overall Loss 2.369242    Objective Loss 2.369242                                        LR 0.100000    Time 0.273622    
2024-04-23 19:47:57,166 - Epoch: [190][  160/  267]    Overall Loss 2.369800    Objective Loss 2.369800                                        LR 0.100000    Time 0.271644    
2024-04-23 19:48:00,296 - Epoch: [190][  170/  267]    Overall Loss 2.368942    Objective Loss 2.368942                                        LR 0.100000    Time 0.274062    
2024-04-23 19:48:02,268 - Epoch: [190][  180/  267]    Overall Loss 2.369985    Objective Loss 2.369985                                        LR 0.100000    Time 0.269782    
2024-04-23 19:48:03,938 - Epoch: [138][  200/  296]    Overall Loss 0.698385    Objective Loss 0.698385                                        LR 0.000080    Time 0.263450    
2024-04-23 19:48:05,429 - Epoch: [190][  190/  267]    Overall Loss 2.369808    Objective Loss 2.369808                                        LR 0.100000    Time 0.272204    
2024-04-23 19:48:07,681 - Epoch: [190][  200/  267]    Overall Loss 2.370265    Objective Loss 2.370265                                        LR 0.100000    Time 0.269837    
2024-04-23 19:48:10,823 - Epoch: [190][  210/  267]    Overall Loss 2.369080    Objective Loss 2.369080                                        LR 0.100000    Time 0.271934    
2024-04-23 19:48:13,252 - Epoch: [190][  220/  267]    Overall Loss 2.367756    Objective Loss 2.367756                                        LR 0.100000    Time 0.270604    
2024-04-23 19:48:16,537 - Epoch: [190][  230/  267]    Overall Loss 2.368949    Objective Loss 2.368949                                        LR 0.100000    Time 0.273109    
2024-04-23 19:48:18,811 - Epoch: [190][  240/  267]    Overall Loss 2.368071    Objective Loss 2.368071                                        LR 0.100000    Time 0.271189    
2024-04-23 19:48:21,614 - Epoch: [190][  250/  267]    Overall Loss 2.367503    Objective Loss 2.367503                                        LR 0.100000    Time 0.271545    
2024-04-23 19:48:23,296 - Epoch: [190][  260/  267]    Overall Loss 2.368279    Objective Loss 2.368279                                        LR 0.100000    Time 0.267553    
2024-04-23 19:48:24,561 - Epoch: [190][  267/  267]    Overall Loss 2.368739    Objective Loss 2.368739    Top1 11.627907    Top5 48.837209    LR 0.100000    Time 0.265271    
2024-04-23 19:48:24,742 - --- validate (epoch=190)-----------
2024-04-23 19:48:24,743 - 946 samples (32 per mini-batch)
2024-04-23 19:48:27,552 - Epoch: [190][   10/   30]    Loss 2.411907    Top1 10.000000    Top5 51.562500    
2024-04-23 19:48:27,899 - Epoch: [138][  296/  296]    Overall Loss 0.699452    Objective Loss 0.699452    Top1 72.131148    Top5 96.721311    LR 0.000080    Time 0.258883    
2024-04-23 19:48:28,177 - --- validate (epoch=138)-----------
2024-04-23 19:48:28,178 - 3925 samples (32 per mini-batch)
2024-04-23 19:48:28,761 - Epoch: [190][   20/   30]    Loss 2.398150    Top1 11.718750    Top5 52.187500    
2024-04-23 19:48:30,799 - Epoch: [190][   30/   30]    Loss 2.413745    Top1 10.993658    Top5 51.057082    
2024-04-23 19:48:30,960 - ==> Top1: 10.994    Top5: 51.057    Loss: 2.414

2024-04-23 19:48:30,963 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 19:48:30,968 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:48:30,969 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:48:30,984 - 

2024-04-23 19:48:30,985 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:48:34,321 - Epoch: [191][   10/  267]    Overall Loss 2.381661    Objective Loss 2.381661                                        LR 0.100000    Time 0.333280    
2024-04-23 19:48:36,744 - Epoch: [191][   20/  267]    Overall Loss 2.390678    Objective Loss 2.390678                                        LR 0.100000    Time 0.287632    
2024-04-23 19:48:39,867 - Epoch: [191][   30/  267]    Overall Loss 2.365793    Objective Loss 2.365793                                        LR 0.100000    Time 0.295766    
2024-04-23 19:48:41,937 - Epoch: [191][   40/  267]    Overall Loss 2.358632    Objective Loss 2.358632                                        LR 0.100000    Time 0.273502    
2024-04-23 19:48:44,345 - Epoch: [191][   50/  267]    Overall Loss 2.358272    Objective Loss 2.358272                                        LR 0.100000    Time 0.266903    
2024-04-23 19:48:46,449 - Epoch: [191][   60/  267]    Overall Loss 2.355068    Objective Loss 2.355068                                        LR 0.100000    Time 0.257438    
2024-04-23 19:48:48,466 - Epoch: [191][   70/  267]    Overall Loss 2.356047    Objective Loss 2.356047                                        LR 0.100000    Time 0.249422    
2024-04-23 19:48:50,455 - Epoch: [191][   80/  267]    Overall Loss 2.355275    Objective Loss 2.355275                                        LR 0.100000    Time 0.243069    
2024-04-23 19:48:52,252 - Epoch: [191][   90/  267]    Overall Loss 2.353898    Objective Loss 2.353898                                        LR 0.100000    Time 0.235987    
2024-04-23 19:48:52,518 - Epoch: [138][  100/  123]    Loss 0.650460    Top1 79.250000    Top5 97.531250    
2024-04-23 19:48:54,090 - Epoch: [191][  100/  267]    Overall Loss 2.351807    Objective Loss 2.351807                                        LR 0.100000    Time 0.230744    
2024-04-23 19:48:56,280 - Epoch: [191][  110/  267]    Overall Loss 2.350477    Objective Loss 2.350477                                        LR 0.100000    Time 0.229646    
2024-04-23 19:48:56,990 - Epoch: [138][  123/  123]    Loss 0.664922    Top1 78.598726    Top5 97.401274    
2024-04-23 19:48:57,198 - ==> Top1: 78.599    Top5: 97.401    Loss: 0.665

2024-04-23 19:48:57,208 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:48:57,209 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:48:57,274 - 

2024-04-23 19:48:57,275 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:48:57,718 - Epoch: [191][  120/  267]    Overall Loss 2.351197    Objective Loss 2.351197                                        LR 0.100000    Time 0.222470    
2024-04-23 19:48:59,862 - Epoch: [191][  130/  267]    Overall Loss 2.351803    Objective Loss 2.351803                                        LR 0.100000    Time 0.221823    
2024-04-23 19:49:02,306 - Epoch: [191][  140/  267]    Overall Loss 2.354464    Objective Loss 2.354464                                        LR 0.100000    Time 0.223412    
2024-04-23 19:49:04,049 - Epoch: [191][  150/  267]    Overall Loss 2.354354    Objective Loss 2.354354                                        LR 0.100000    Time 0.220120    
2024-04-23 19:49:06,623 - Epoch: [191][  160/  267]    Overall Loss 2.356890    Objective Loss 2.356890                                        LR 0.100000    Time 0.222432    
2024-04-23 19:49:08,257 - Epoch: [191][  170/  267]    Overall Loss 2.357712    Objective Loss 2.357712                                        LR 0.100000    Time 0.218947    
2024-04-23 19:49:10,066 - Epoch: [191][  180/  267]    Overall Loss 2.356983    Objective Loss 2.356983                                        LR 0.100000    Time 0.216819    
2024-04-23 19:49:11,361 - Epoch: [191][  190/  267]    Overall Loss 2.357132    Objective Loss 2.357132                                        LR 0.100000    Time 0.212212    
2024-04-23 19:49:13,880 - Epoch: [191][  200/  267]    Overall Loss 2.356643    Objective Loss 2.356643                                        LR 0.100000    Time 0.214176    
2024-04-23 19:49:15,698 - Epoch: [191][  210/  267]    Overall Loss 2.358433    Objective Loss 2.358433                                        LR 0.100000    Time 0.212619    
2024-04-23 19:49:18,046 - Epoch: [191][  220/  267]    Overall Loss 2.359366    Objective Loss 2.359366                                        LR 0.100000    Time 0.213617    
2024-04-23 19:49:18,276 - Epoch: [139][  100/  296]    Overall Loss 0.693061    Objective Loss 0.693061                                        LR 0.000080    Time 0.209788    
2024-04-23 19:49:20,097 - Epoch: [191][  230/  267]    Overall Loss 2.359703    Objective Loss 2.359703                                        LR 0.100000    Time 0.213233    
2024-04-23 19:49:22,583 - Epoch: [191][  240/  267]    Overall Loss 2.361067    Objective Loss 2.361067                                        LR 0.100000    Time 0.214695    
2024-04-23 19:49:24,675 - Epoch: [191][  250/  267]    Overall Loss 2.361505    Objective Loss 2.361505                                        LR 0.100000    Time 0.214463    
2024-04-23 19:49:27,306 - Epoch: [191][  260/  267]    Overall Loss 2.360388    Objective Loss 2.360388                                        LR 0.100000    Time 0.216322    
2024-04-23 19:49:28,092 - Epoch: [191][  267/  267]    Overall Loss 2.360073    Objective Loss 2.360073    Top1 13.953488    Top5 58.139535    LR 0.100000    Time 0.213586    
2024-04-23 19:49:28,280 - --- validate (epoch=191)-----------
2024-04-23 19:49:28,281 - 946 samples (32 per mini-batch)
2024-04-23 19:49:31,509 - Epoch: [191][   10/   30]    Loss 2.370076    Top1 9.062500    Top5 50.312500    
2024-04-23 19:49:34,094 - Epoch: [191][   20/   30]    Loss 2.377120    Top1 10.000000    Top5 48.125000    
2024-04-23 19:49:36,716 - Epoch: [191][   30/   30]    Loss 2.380017    Top1 9.196617    Top5 48.097252    
2024-04-23 19:49:36,955 - ==> Top1: 9.197    Top5: 48.097    Loss: 2.380

2024-04-23 19:49:36,956 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 19:49:36,961 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:49:36,962 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:49:36,980 - 

2024-04-23 19:49:36,981 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:49:41,157 - Epoch: [192][   10/  267]    Overall Loss 2.370705    Objective Loss 2.370705                                        LR 0.100000    Time 0.417176    
2024-04-23 19:49:41,580 - Epoch: [139][  200/  296]    Overall Loss 0.716502    Objective Loss 0.716502                                        LR 0.000080    Time 0.221321    
2024-04-23 19:49:43,766 - Epoch: [192][   20/  267]    Overall Loss 2.361009    Objective Loss 2.361009                                        LR 0.100000    Time 0.338910    
2024-04-23 19:49:46,268 - Epoch: [192][   30/  267]    Overall Loss 2.360442    Objective Loss 2.360442                                        LR 0.100000    Time 0.309239    
2024-04-23 19:49:48,634 - Epoch: [192][   40/  267]    Overall Loss 2.365123    Objective Loss 2.365123                                        LR 0.100000    Time 0.291016    
2024-04-23 19:49:51,472 - Epoch: [192][   50/  267]    Overall Loss 2.361876    Objective Loss 2.361876                                        LR 0.100000    Time 0.289523    
2024-04-23 19:49:54,212 - Epoch: [192][   60/  267]    Overall Loss 2.360175    Objective Loss 2.360175                                        LR 0.100000    Time 0.286876    
2024-04-23 19:49:56,673 - Epoch: [192][   70/  267]    Overall Loss 2.361963    Objective Loss 2.361963                                        LR 0.100000    Time 0.281014    
2024-04-23 19:49:59,109 - Epoch: [192][   80/  267]    Overall Loss 2.366337    Objective Loss 2.366337                                        LR 0.100000    Time 0.276231    
2024-04-23 19:50:01,707 - Epoch: [192][   90/  267]    Overall Loss 2.365161    Objective Loss 2.365161                                        LR 0.100000    Time 0.274377    
2024-04-23 19:50:04,315 - Epoch: [192][  100/  267]    Overall Loss 2.360202    Objective Loss 2.360202                                        LR 0.100000    Time 0.272981    
2024-04-23 19:50:06,658 - Epoch: [192][  110/  267]    Overall Loss 2.359063    Objective Loss 2.359063                                        LR 0.100000    Time 0.269443    
2024-04-23 19:50:06,736 - Epoch: [139][  296/  296]    Overall Loss 0.713173    Objective Loss 0.713173    Top1 68.852459    Top5 98.360656    LR 0.000080    Time 0.234465    
2024-04-23 19:50:07,043 - --- validate (epoch=139)-----------
2024-04-23 19:50:07,045 - 3925 samples (32 per mini-batch)
2024-04-23 19:50:08,665 - Epoch: [192][  120/  267]    Overall Loss 2.360770    Objective Loss 2.360770                                        LR 0.100000    Time 0.263692    
2024-04-23 19:50:11,121 - Epoch: [192][  130/  267]    Overall Loss 2.360944    Objective Loss 2.360944                                        LR 0.100000    Time 0.262278    
2024-04-23 19:50:13,636 - Epoch: [192][  140/  267]    Overall Loss 2.359511    Objective Loss 2.359511                                        LR 0.100000    Time 0.261492    
2024-04-23 19:50:16,145 - Epoch: [192][  150/  267]    Overall Loss 2.360106    Objective Loss 2.360106                                        LR 0.100000    Time 0.260761    
2024-04-23 19:50:18,564 - Epoch: [192][  160/  267]    Overall Loss 2.361800    Objective Loss 2.361800                                        LR 0.100000    Time 0.259565    
2024-04-23 19:50:21,152 - Epoch: [192][  170/  267]    Overall Loss 2.360794    Objective Loss 2.360794                                        LR 0.100000    Time 0.259501    
2024-04-23 19:50:23,559 - Epoch: [192][  180/  267]    Overall Loss 2.361104    Objective Loss 2.361104                                        LR 0.100000    Time 0.258439    
2024-04-23 19:50:26,372 - Epoch: [192][  190/  267]    Overall Loss 2.363643    Objective Loss 2.363643                                        LR 0.100000    Time 0.259631    
2024-04-23 19:50:29,150 - Epoch: [192][  200/  267]    Overall Loss 2.365123    Objective Loss 2.365123                                        LR 0.100000    Time 0.260524    
2024-04-23 19:50:31,292 - Epoch: [192][  210/  267]    Overall Loss 2.366100    Objective Loss 2.366100                                        LR 0.100000    Time 0.258297    
2024-04-23 19:50:34,189 - Epoch: [192][  220/  267]    Overall Loss 2.367185    Objective Loss 2.367185                                        LR 0.100000    Time 0.259711    
2024-04-23 19:50:35,097 - Epoch: [139][  100/  123]    Loss 0.652549    Top1 78.562500    Top5 97.531250    
2024-04-23 19:50:36,339 - Epoch: [192][  230/  267]    Overall Loss 2.365284    Objective Loss 2.365284                                        LR 0.100000    Time 0.257755    
2024-04-23 19:50:39,399 - Epoch: [192][  240/  267]    Overall Loss 2.365298    Objective Loss 2.365298                                        LR 0.100000    Time 0.259753    
2024-04-23 19:50:40,934 - Epoch: [139][  123/  123]    Loss 0.668753    Top1 77.936306    Top5 97.375796    
2024-04-23 19:50:41,194 - ==> Top1: 77.936    Top5: 97.376    Loss: 0.669

2024-04-23 19:50:41,202 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:50:41,202 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:50:41,253 - 

2024-04-23 19:50:41,254 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:50:41,527 - Epoch: [192][  250/  267]    Overall Loss 2.365525    Objective Loss 2.365525                                        LR 0.100000    Time 0.257865    
2024-04-23 19:50:44,705 - Epoch: [192][  260/  267]    Overall Loss 2.366185    Objective Loss 2.366185                                        LR 0.100000    Time 0.260158    
2024-04-23 19:50:45,617 - Epoch: [192][  267/  267]    Overall Loss 2.366352    Objective Loss 2.366352    Top1 6.976744    Top5 48.837209    LR 0.100000    Time 0.256741    
2024-04-23 19:50:45,841 - --- validate (epoch=192)-----------
2024-04-23 19:50:45,843 - 946 samples (32 per mini-batch)
2024-04-23 19:50:49,673 - Epoch: [192][   10/   30]    Loss 2.325476    Top1 9.375000    Top5 50.937500    
2024-04-23 19:50:51,822 - Epoch: [192][   20/   30]    Loss 2.325684    Top1 9.843750    Top5 49.687500    
2024-04-23 19:50:53,914 - Epoch: [192][   30/   30]    Loss 2.327985    Top1 10.042283    Top5 50.528541    
2024-04-23 19:50:54,049 - ==> Top1: 10.042    Top5: 50.529    Loss: 2.328

2024-04-23 19:50:54,051 - ==> Confusion:
[[  0   0   0   0   0  87   0   0   0   0]
 [  0   0   0   0   0  98   0   0   0   0]
 [  0   0   0   0   0  99   0   0   0   0]
 [  0   0   0   0   0  80   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  95   0   0   0   0]
 [  0   0   0   0   0 104   0   0   0   0]
 [  0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   0   0  97   0   0   0   0]
 [  0   0   0   0   0 100   0   0   0   0]]

2024-04-23 19:50:54,055 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:50:54,056 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:50:54,070 - 

2024-04-23 19:50:54,071 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:50:57,514 - Epoch: [193][   10/  267]    Overall Loss 2.337147    Objective Loss 2.337147                                        LR 0.100000    Time 0.343950    
2024-04-23 19:50:59,534 - Epoch: [193][   20/  267]    Overall Loss 2.347808    Objective Loss 2.347808                                        LR 0.100000    Time 0.272828    
2024-04-23 19:51:02,694 - Epoch: [193][   30/  267]    Overall Loss 2.356339    Objective Loss 2.356339                                        LR 0.100000    Time 0.287135    
2024-04-23 19:51:05,051 - Epoch: [140][  100/  296]    Overall Loss 0.673139    Objective Loss 0.673139                                        LR 0.000080    Time 0.237764    
2024-04-23 19:51:05,098 - Epoch: [193][   40/  267]    Overall Loss 2.360713    Objective Loss 2.360713                                        LR 0.100000    Time 0.275369    
2024-04-23 19:51:08,166 - Epoch: [193][   50/  267]    Overall Loss 2.360737    Objective Loss 2.360737                                        LR 0.100000    Time 0.281571    
2024-04-23 19:51:10,252 - Epoch: [193][   60/  267]    Overall Loss 2.366070    Objective Loss 2.366070                                        LR 0.100000    Time 0.269361    
2024-04-23 19:51:13,408 - Epoch: [193][   70/  267]    Overall Loss 2.368466    Objective Loss 2.368466                                        LR 0.100000    Time 0.275925    
2024-04-23 19:51:15,566 - Epoch: [193][   80/  267]    Overall Loss 2.366111    Objective Loss 2.366111                                        LR 0.100000    Time 0.268358    
2024-04-23 19:51:18,629 - Epoch: [193][   90/  267]    Overall Loss 2.367965    Objective Loss 2.367965                                        LR 0.100000    Time 0.272543    
2024-04-23 19:51:20,949 - Epoch: [193][  100/  267]    Overall Loss 2.367153    Objective Loss 2.367153                                        LR 0.100000    Time 0.268463    
2024-04-23 19:51:23,584 - Epoch: [193][  110/  267]    Overall Loss 2.365711    Objective Loss 2.365711                                        LR 0.100000    Time 0.267983    
2024-04-23 19:51:25,535 - Epoch: [193][  120/  267]    Overall Loss 2.366982    Objective Loss 2.366982                                        LR 0.100000    Time 0.261882    
2024-04-23 19:51:28,386 - Epoch: [193][  130/  267]    Overall Loss 2.364652    Objective Loss 2.364652                                        LR 0.100000    Time 0.263641    
2024-04-23 19:51:30,419 - Epoch: [193][  140/  267]    Overall Loss 2.365455    Objective Loss 2.365455                                        LR 0.100000    Time 0.259312    
2024-04-23 19:51:30,588 - Epoch: [140][  200/  296]    Overall Loss 0.704486    Objective Loss 0.704486                                        LR 0.000080    Time 0.246468    
2024-04-23 19:51:33,259 - Epoch: [193][  150/  267]    Overall Loss 2.366822    Objective Loss 2.366822                                        LR 0.100000    Time 0.260935    
2024-04-23 19:51:34,887 - Epoch: [193][  160/  267]    Overall Loss 2.367066    Objective Loss 2.367066                                        LR 0.100000    Time 0.254790    
2024-04-23 19:51:37,468 - Epoch: [193][  170/  267]    Overall Loss 2.367467    Objective Loss 2.367467                                        LR 0.100000    Time 0.254958    
2024-04-23 19:51:39,383 - Epoch: [193][  180/  267]    Overall Loss 2.367301    Objective Loss 2.367301                                        LR 0.100000    Time 0.251417    
2024-04-23 19:51:42,468 - Epoch: [193][  190/  267]    Overall Loss 2.369268    Objective Loss 2.369268                                        LR 0.100000    Time 0.254407    
2024-04-23 19:51:44,884 - Epoch: [193][  200/  267]    Overall Loss 2.368980    Objective Loss 2.368980                                        LR 0.100000    Time 0.253743    
2024-04-23 19:51:47,676 - Epoch: [193][  210/  267]    Overall Loss 2.370307    Objective Loss 2.370307                                        LR 0.100000    Time 0.254940    
2024-04-23 19:51:49,718 - Epoch: [193][  220/  267]    Overall Loss 2.370279    Objective Loss 2.370279                                        LR 0.100000    Time 0.252622    
2024-04-23 19:51:52,615 - Epoch: [193][  230/  267]    Overall Loss 2.367293    Objective Loss 2.367293                                        LR 0.100000    Time 0.254221    
2024-04-23 19:51:53,650 - Epoch: [140][  296/  296]    Overall Loss 0.713775    Objective Loss 0.713775    Top1 81.967213    Top5 96.721311    LR 0.000080    Time 0.244381    
2024-04-23 19:51:53,970 - --- validate (epoch=140)-----------
2024-04-23 19:51:53,972 - 3925 samples (32 per mini-batch)
2024-04-23 19:51:54,177 - Epoch: [193][  240/  267]    Overall Loss 2.369986    Objective Loss 2.369986                                        LR 0.100000    Time 0.250126    
2024-04-23 19:51:56,862 - Epoch: [193][  250/  267]    Overall Loss 2.369773    Objective Loss 2.369773                                        LR 0.100000    Time 0.250848    
2024-04-23 19:51:59,326 - Epoch: [193][  260/  267]    Overall Loss 2.370830    Objective Loss 2.370830                                        LR 0.100000    Time 0.250668    
2024-04-23 19:52:01,463 - Epoch: [193][  267/  267]    Overall Loss 2.370480    Objective Loss 2.370480    Top1 16.279070    Top5 48.837209    LR 0.100000    Time 0.252089    
2024-04-23 19:52:01,700 - --- validate (epoch=193)-----------
2024-04-23 19:52:01,702 - 946 samples (32 per mini-batch)
2024-04-23 19:52:06,303 - Epoch: [193][   10/   30]    Loss 2.349528    Top1 12.812500    Top5 52.187500    
2024-04-23 19:52:09,091 - Epoch: [193][   20/   30]    Loss 2.360685    Top1 10.937500    Top5 50.000000    
2024-04-23 19:52:12,154 - Epoch: [193][   30/   30]    Loss 2.356696    Top1 10.993658    Top5 50.739958    
2024-04-23 19:52:12,415 - ==> Top1: 10.994    Top5: 50.740    Loss: 2.357

2024-04-23 19:52:12,418 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 19:52:12,424 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:52:12,425 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:52:12,448 - 

2024-04-23 19:52:12,449 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:52:16,740 - Epoch: [194][   10/  267]    Overall Loss 2.362049    Objective Loss 2.362049                                        LR 0.100000    Time 0.428688    
2024-04-23 19:52:19,381 - Epoch: [194][   20/  267]    Overall Loss 2.371037    Objective Loss 2.371037                                        LR 0.100000    Time 0.346232    
2024-04-23 19:52:22,371 - Epoch: [194][   30/  267]    Overall Loss 2.349449    Objective Loss 2.349449                                        LR 0.100000    Time 0.330387    
2024-04-23 19:52:24,551 - Epoch: [194][   40/  267]    Overall Loss 2.357821    Objective Loss 2.357821                                        LR 0.100000    Time 0.302230    
2024-04-23 19:52:24,652 - Epoch: [140][  100/  123]    Loss 0.670829    Top1 78.125000    Top5 97.343750    
2024-04-23 19:52:26,340 - Epoch: [194][   50/  267]    Overall Loss 2.362180    Objective Loss 2.362180                                        LR 0.100000    Time 0.277472    
2024-04-23 19:52:28,611 - Epoch: [194][   60/  267]    Overall Loss 2.359562    Objective Loss 2.359562                                        LR 0.100000    Time 0.269015    
2024-04-23 19:52:30,198 - Epoch: [140][  123/  123]    Loss 0.667582    Top1 78.191083    Top5 97.324841    
2024-04-23 19:52:30,394 - Epoch: [194][   70/  267]    Overall Loss 2.358298    Objective Loss 2.358298                                        LR 0.100000    Time 0.256023    
2024-04-23 19:52:30,529 - ==> Top1: 78.191    Top5: 97.325    Loss: 0.668

2024-04-23 19:52:30,540 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:52:30,541 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:52:30,599 - 

2024-04-23 19:52:30,600 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:52:32,423 - Epoch: [194][   80/  267]    Overall Loss 2.357314    Objective Loss 2.357314                                        LR 0.100000    Time 0.249342    
2024-04-23 19:52:34,963 - Epoch: [194][   90/  267]    Overall Loss 2.354508    Objective Loss 2.354508                                        LR 0.100000    Time 0.249829    
2024-04-23 19:52:37,034 - Epoch: [194][  100/  267]    Overall Loss 2.353808    Objective Loss 2.353808                                        LR 0.100000    Time 0.245532    
2024-04-23 19:52:39,366 - Epoch: [194][  110/  267]    Overall Loss 2.356006    Objective Loss 2.356006                                        LR 0.100000    Time 0.244383    
2024-04-23 19:52:41,502 - Epoch: [194][  120/  267]    Overall Loss 2.355726    Objective Loss 2.355726                                        LR 0.100000    Time 0.241794    
2024-04-23 19:52:44,059 - Epoch: [194][  130/  267]    Overall Loss 2.359205    Objective Loss 2.359205                                        LR 0.100000    Time 0.242835    
2024-04-23 19:52:46,126 - Epoch: [194][  140/  267]    Overall Loss 2.360786    Objective Loss 2.360786                                        LR 0.100000    Time 0.240234    
2024-04-23 19:52:48,281 - Epoch: [194][  150/  267]    Overall Loss 2.361393    Objective Loss 2.361393                                        LR 0.100000    Time 0.238566    
2024-04-23 19:52:49,348 - Epoch: [194][  160/  267]    Overall Loss 2.361948    Objective Loss 2.361948                                        LR 0.100000    Time 0.230308    
2024-04-23 19:52:51,002 - Epoch: [194][  170/  267]    Overall Loss 2.362395    Objective Loss 2.362395                                        LR 0.100000    Time 0.226477    
2024-04-23 19:52:52,063 - Epoch: [194][  180/  267]    Overall Loss 2.362854    Objective Loss 2.362854                                        LR 0.100000    Time 0.219775    
2024-04-23 19:52:53,775 - Epoch: [194][  190/  267]    Overall Loss 2.363512    Objective Loss 2.363512                                        LR 0.100000    Time 0.217192    
2024-04-23 19:52:54,999 - Epoch: [141][  100/  296]    Overall Loss 0.725789    Objective Loss 0.725789                                        LR 0.000080    Time 0.243765    
2024-04-23 19:52:55,171 - Epoch: [194][  200/  267]    Overall Loss 2.363417    Objective Loss 2.363417                                        LR 0.100000    Time 0.213304    
2024-04-23 19:52:57,430 - Epoch: [194][  210/  267]    Overall Loss 2.363044    Objective Loss 2.363044                                        LR 0.100000    Time 0.213889    
2024-04-23 19:52:58,807 - Epoch: [194][  220/  267]    Overall Loss 2.362724    Objective Loss 2.362724                                        LR 0.100000    Time 0.210415    
2024-04-23 19:53:00,570 - Epoch: [194][  230/  267]    Overall Loss 2.364906    Objective Loss 2.364906                                        LR 0.100000    Time 0.208922    
2024-04-23 19:53:01,877 - Epoch: [194][  240/  267]    Overall Loss 2.367233    Objective Loss 2.367233                                        LR 0.100000    Time 0.205651    
2024-04-23 19:53:03,730 - Epoch: [194][  250/  267]    Overall Loss 2.368892    Objective Loss 2.368892                                        LR 0.100000    Time 0.204827    
2024-04-23 19:53:04,999 - Epoch: [194][  260/  267]    Overall Loss 2.368776    Objective Loss 2.368776                                        LR 0.100000    Time 0.201816    
2024-04-23 19:53:05,930 - Epoch: [194][  267/  267]    Overall Loss 2.367955    Objective Loss 2.367955    Top1 9.302326    Top5 55.813953    LR 0.100000    Time 0.200006    
2024-04-23 19:53:06,063 - --- validate (epoch=194)-----------
2024-04-23 19:53:06,063 - 946 samples (32 per mini-batch)
2024-04-23 19:53:08,641 - Epoch: [194][   10/   30]    Loss 2.406717    Top1 13.125000    Top5 53.125000    
2024-04-23 19:53:10,192 - Epoch: [194][   20/   30]    Loss 2.395901    Top1 10.781250    Top5 52.343750    
2024-04-23 19:53:11,811 - Epoch: [194][   30/   30]    Loss 2.407579    Top1 10.465116    Top5 51.268499    
2024-04-23 19:53:11,904 - ==> Top1: 10.465    Top5: 51.268    Loss: 2.408

2024-04-23 19:53:11,905 - ==> Confusion:
[[  0   0  87   0   0   0   0   0   0   0]
 [  0   0  98   0   0   0   0   0   0   0]
 [  0   0  99   0   0   0   0   0   0   0]
 [  0   0  80   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  95   0   0   0   0   0   0   0]
 [  0   0 104   0   0   0   0   0   0   0]
 [  0   0  93   0   0   0   0   0   0   0]
 [  0   0  97   0   0   0   0   0   0   0]
 [  0   0 100   0   0   0   0   0   0   0]]

2024-04-23 19:53:11,909 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:53:11,909 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:53:11,922 - 

2024-04-23 19:53:11,923 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:53:14,610 - Epoch: [195][   10/  267]    Overall Loss 2.421699    Objective Loss 2.421699                                        LR 0.100000    Time 0.268434    
2024-04-23 19:53:16,283 - Epoch: [195][   20/  267]    Overall Loss 2.375653    Objective Loss 2.375653                                        LR 0.100000    Time 0.217710    
2024-04-23 19:53:16,536 - Epoch: [141][  200/  296]    Overall Loss 0.710149    Objective Loss 0.710149                                        LR 0.000080    Time 0.229469    
2024-04-23 19:53:18,750 - Epoch: [195][   30/  267]    Overall Loss 2.364380    Objective Loss 2.364380                                        LR 0.100000    Time 0.227263    
2024-04-23 19:53:20,351 - Epoch: [195][   40/  267]    Overall Loss 2.358489    Objective Loss 2.358489                                        LR 0.100000    Time 0.210401    
2024-04-23 19:53:22,548 - Epoch: [195][   50/  267]    Overall Loss 2.358367    Objective Loss 2.358367                                        LR 0.100000    Time 0.212194    
2024-04-23 19:53:24,137 - Epoch: [195][   60/  267]    Overall Loss 2.367337    Objective Loss 2.367337                                        LR 0.100000    Time 0.203265    
2024-04-23 19:53:26,554 - Epoch: [195][   70/  267]    Overall Loss 2.368496    Objective Loss 2.368496                                        LR 0.100000    Time 0.208723    
2024-04-23 19:53:28,380 - Epoch: [195][   80/  267]    Overall Loss 2.371830    Objective Loss 2.371830                                        LR 0.100000    Time 0.205419    
2024-04-23 19:53:30,647 - Epoch: [195][   90/  267]    Overall Loss 2.371041    Objective Loss 2.371041                                        LR 0.100000    Time 0.207752    
2024-04-23 19:53:32,653 - Epoch: [195][  100/  267]    Overall Loss 2.376127    Objective Loss 2.376127                                        LR 0.100000    Time 0.207001    
2024-04-23 19:53:34,842 - Epoch: [195][  110/  267]    Overall Loss 2.371848    Objective Loss 2.371848                                        LR 0.100000    Time 0.208057    
2024-04-23 19:53:36,935 - Epoch: [195][  120/  267]    Overall Loss 2.370996    Objective Loss 2.370996                                        LR 0.100000    Time 0.208135    
2024-04-23 19:53:37,199 - Epoch: [141][  296/  296]    Overall Loss 0.720457    Objective Loss 0.720457    Top1 70.491803    Top5 96.721311    LR 0.000080    Time 0.224788    
2024-04-23 19:53:37,533 - --- validate (epoch=141)-----------
2024-04-23 19:53:37,534 - 3925 samples (32 per mini-batch)
2024-04-23 19:53:38,341 - Epoch: [195][  130/  267]    Overall Loss 2.371677    Objective Loss 2.371677                                        LR 0.100000    Time 0.202923    
2024-04-23 19:53:40,433 - Epoch: [195][  140/  267]    Overall Loss 2.368438    Objective Loss 2.368438                                        LR 0.100000    Time 0.203349    
2024-04-23 19:53:42,679 - Epoch: [195][  150/  267]    Overall Loss 2.364690    Objective Loss 2.364690                                        LR 0.100000    Time 0.204747    
2024-04-23 19:53:44,876 - Epoch: [195][  160/  267]    Overall Loss 2.367407    Objective Loss 2.367407                                        LR 0.100000    Time 0.205665    
2024-04-23 19:53:47,201 - Epoch: [195][  170/  267]    Overall Loss 2.367531    Objective Loss 2.367531                                        LR 0.100000    Time 0.207228    
2024-04-23 19:53:49,083 - Epoch: [195][  180/  267]    Overall Loss 2.368780    Objective Loss 2.368780                                        LR 0.100000    Time 0.206147    
2024-04-23 19:53:51,883 - Epoch: [195][  190/  267]    Overall Loss 2.369243    Objective Loss 2.369243                                        LR 0.100000    Time 0.210021    
2024-04-23 19:53:53,659 - Epoch: [195][  200/  267]    Overall Loss 2.370232    Objective Loss 2.370232                                        LR 0.100000    Time 0.208389    
2024-04-23 19:53:56,552 - Epoch: [195][  210/  267]    Overall Loss 2.370971    Objective Loss 2.370971                                        LR 0.100000    Time 0.212227    
2024-04-23 19:53:58,482 - Epoch: [195][  220/  267]    Overall Loss 2.370872    Objective Loss 2.370872                                        LR 0.100000    Time 0.211335    
2024-04-23 19:54:00,818 - Epoch: [195][  230/  267]    Overall Loss 2.369786    Objective Loss 2.369786                                        LR 0.100000    Time 0.212294    
2024-04-23 19:54:02,309 - Epoch: [141][  100/  123]    Loss 0.676804    Top1 78.093750    Top5 97.281250    
2024-04-23 19:54:02,712 - Epoch: [195][  240/  267]    Overall Loss 2.369161    Objective Loss 2.369161                                        LR 0.100000    Time 0.211328    
2024-04-23 19:54:05,726 - Epoch: [195][  250/  267]    Overall Loss 2.369720    Objective Loss 2.369720                                        LR 0.100000    Time 0.214921    
2024-04-23 19:54:07,803 - Epoch: [195][  260/  267]    Overall Loss 2.369309    Objective Loss 2.369309                                        LR 0.100000    Time 0.214630    
2024-04-23 19:54:08,611 - Epoch: [141][  123/  123]    Loss 0.675811    Top1 78.140127    Top5 97.299363    
2024-04-23 19:54:08,900 - ==> Top1: 78.140    Top5: 97.299    Loss: 0.676

2024-04-23 19:54:08,906 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:54:08,907 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:54:08,972 - 

2024-04-23 19:54:08,973 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:54:09,122 - Epoch: [195][  267/  267]    Overall Loss 2.369182    Objective Loss 2.369182    Top1 11.627907    Top5 58.139535    LR 0.100000    Time 0.213935    
2024-04-23 19:54:09,285 - --- validate (epoch=195)-----------
2024-04-23 19:54:09,285 - 946 samples (32 per mini-batch)
2024-04-23 19:54:12,190 - Epoch: [195][   10/   30]    Loss 2.358172    Top1 8.750000    Top5 49.687500    
2024-04-23 19:54:14,029 - Epoch: [195][   20/   30]    Loss 2.344403    Top1 9.218750    Top5 49.062500    
2024-04-23 19:54:15,320 - Epoch: [195][   30/   30]    Loss 2.340789    Top1 9.196617    Top5 50.105708    
2024-04-23 19:54:15,413 - ==> Top1: 9.197    Top5: 50.106    Loss: 2.341

2024-04-23 19:54:15,415 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 19:54:15,419 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:54:15,419 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:54:15,432 - 

2024-04-23 19:54:15,432 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:54:18,074 - Epoch: [196][   10/  267]    Overall Loss 2.377997    Objective Loss 2.377997                                        LR 0.100000    Time 0.263921    
2024-04-23 19:54:19,709 - Epoch: [196][   20/  267]    Overall Loss 2.365957    Objective Loss 2.365957                                        LR 0.100000    Time 0.213572    
2024-04-23 19:54:22,446 - Epoch: [196][   30/  267]    Overall Loss 2.383137    Objective Loss 2.383137                                        LR 0.100000    Time 0.233510    
2024-04-23 19:54:24,448 - Epoch: [196][   40/  267]    Overall Loss 2.376808    Objective Loss 2.376808                                        LR 0.100000    Time 0.225104    
2024-04-23 19:54:27,400 - Epoch: [196][   50/  267]    Overall Loss 2.368207    Objective Loss 2.368207                                        LR 0.100000    Time 0.239057    
2024-04-23 19:54:29,077 - Epoch: [142][  100/  296]    Overall Loss 0.709217    Objective Loss 0.709217                                        LR 0.000080    Time 0.200840    
2024-04-23 19:54:29,722 - Epoch: [196][   60/  267]    Overall Loss 2.370915    Objective Loss 2.370915                                        LR 0.100000    Time 0.237864    
2024-04-23 19:54:32,910 - Epoch: [196][   70/  267]    Overall Loss 2.371230    Objective Loss 2.371230                                        LR 0.100000    Time 0.249387    
2024-04-23 19:54:34,640 - Epoch: [196][   80/  267]    Overall Loss 2.369360    Objective Loss 2.369360                                        LR 0.100000    Time 0.239805    
2024-04-23 19:54:37,152 - Epoch: [196][   90/  267]    Overall Loss 2.370059    Objective Loss 2.370059                                        LR 0.100000    Time 0.241039    
2024-04-23 19:54:38,831 - Epoch: [196][  100/  267]    Overall Loss 2.368794    Objective Loss 2.368794                                        LR 0.100000    Time 0.233698    
2024-04-23 19:54:41,305 - Epoch: [196][  110/  267]    Overall Loss 2.370825    Objective Loss 2.370825                                        LR 0.100000    Time 0.234916    
2024-04-23 19:54:42,977 - Epoch: [196][  120/  267]    Overall Loss 2.371489    Objective Loss 2.371489                                        LR 0.100000    Time 0.229246    
2024-04-23 19:54:45,175 - Epoch: [196][  130/  267]    Overall Loss 2.374583    Objective Loss 2.374583                                        LR 0.100000    Time 0.228493    
2024-04-23 19:54:46,054 - Epoch: [142][  200/  296]    Overall Loss 0.705384    Objective Loss 0.705384                                        LR 0.000080    Time 0.185210    
2024-04-23 19:54:46,566 - Epoch: [196][  140/  267]    Overall Loss 2.370617    Objective Loss 2.370617                                        LR 0.100000    Time 0.222087    
2024-04-23 19:54:49,087 - Epoch: [196][  150/  267]    Overall Loss 2.371321    Objective Loss 2.371321                                        LR 0.100000    Time 0.224067    
2024-04-23 19:54:50,836 - Epoch: [196][  160/  267]    Overall Loss 2.370241    Objective Loss 2.370241                                        LR 0.100000    Time 0.220978    
2024-04-23 19:54:53,319 - Epoch: [196][  170/  267]    Overall Loss 2.369753    Objective Loss 2.369753                                        LR 0.100000    Time 0.222567    
2024-04-23 19:54:55,290 - Epoch: [196][  180/  267]    Overall Loss 2.374481    Objective Loss 2.374481                                        LR 0.100000    Time 0.221137    
2024-04-23 19:54:57,459 - Epoch: [196][  190/  267]    Overall Loss 2.374982    Objective Loss 2.374982                                        LR 0.100000    Time 0.220897    
2024-04-23 19:54:59,463 - Epoch: [196][  200/  267]    Overall Loss 2.378320    Objective Loss 2.378320                                        LR 0.100000    Time 0.219863    
2024-04-23 19:55:01,938 - Epoch: [196][  210/  267]    Overall Loss 2.378325    Objective Loss 2.378325                                        LR 0.100000    Time 0.221162    
2024-04-23 19:55:02,950 - Epoch: [142][  296/  296]    Overall Loss 0.709756    Objective Loss 0.709756    Top1 80.327869    Top5 95.081967    LR 0.000080    Time 0.182161    
2024-04-23 19:55:03,101 - --- validate (epoch=142)-----------
2024-04-23 19:55:03,102 - 3925 samples (32 per mini-batch)
2024-04-23 19:55:04,731 - Epoch: [196][  220/  267]    Overall Loss 2.377726    Objective Loss 2.377726                                        LR 0.100000    Time 0.223792    
2024-04-23 19:55:06,613 - Epoch: [196][  230/  267]    Overall Loss 2.377378    Objective Loss 2.377378                                        LR 0.100000    Time 0.222233    
2024-04-23 19:55:09,303 - Epoch: [196][  240/  267]    Overall Loss 2.376062    Objective Loss 2.376062                                        LR 0.100000    Time 0.224168    
2024-04-23 19:55:11,358 - Epoch: [196][  250/  267]    Overall Loss 2.377290    Objective Loss 2.377290                                        LR 0.100000    Time 0.223409    
2024-04-23 19:55:14,266 - Epoch: [196][  260/  267]    Overall Loss 2.376687    Objective Loss 2.376687                                        LR 0.100000    Time 0.225987    
2024-04-23 19:55:15,272 - Epoch: [196][  267/  267]    Overall Loss 2.375833    Objective Loss 2.375833    Top1 20.930233    Top5 53.488372    LR 0.100000    Time 0.223823    
2024-04-23 19:55:15,477 - --- validate (epoch=196)-----------
2024-04-23 19:55:15,478 - 946 samples (32 per mini-batch)
2024-04-23 19:55:19,467 - Epoch: [196][   10/   30]    Loss 2.344007    Top1 11.562500    Top5 54.687500    
2024-04-23 19:55:21,489 - Epoch: [196][   20/   30]    Loss 2.364869    Top1 11.093750    Top5 51.875000    
2024-04-23 19:55:24,027 - Epoch: [196][   30/   30]    Loss 2.365281    Top1 10.359408    Top5 52.008457    
2024-04-23 19:55:24,234 - ==> Top1: 10.359    Top5: 52.008    Loss: 2.365

2024-04-23 19:55:24,235 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 19:55:24,240 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:55:24,240 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:55:24,253 - 

2024-04-23 19:55:24,254 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:55:28,322 - Epoch: [197][   10/  267]    Overall Loss 2.400413    Objective Loss 2.400413                                        LR 0.100000    Time 0.406493    
2024-04-23 19:55:28,413 - Epoch: [142][  100/  123]    Loss 0.682091    Top1 78.062500    Top5 97.437500    
2024-04-23 19:55:31,246 - Epoch: [197][   20/  267]    Overall Loss 2.394881    Objective Loss 2.394881                                        LR 0.100000    Time 0.349258    
2024-04-23 19:55:34,485 - Epoch: [197][   30/  267]    Overall Loss 2.383516    Objective Loss 2.383516                                        LR 0.100000    Time 0.340726    
2024-04-23 19:55:34,821 - Epoch: [142][  123/  123]    Loss 0.676794    Top1 78.191083    Top5 97.350318    
2024-04-23 19:55:35,047 - ==> Top1: 78.191    Top5: 97.350    Loss: 0.677

2024-04-23 19:55:35,053 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:55:35,053 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:55:35,095 - 

2024-04-23 19:55:35,096 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:55:36,778 - Epoch: [197][   40/  267]    Overall Loss 2.378949    Objective Loss 2.378949                                        LR 0.100000    Time 0.312785    
2024-04-23 19:55:39,557 - Epoch: [197][   50/  267]    Overall Loss 2.379234    Objective Loss 2.379234                                        LR 0.100000    Time 0.305761    
2024-04-23 19:55:41,393 - Epoch: [197][   60/  267]    Overall Loss 2.375457    Objective Loss 2.375457                                        LR 0.100000    Time 0.285344    
2024-04-23 19:55:44,123 - Epoch: [197][   70/  267]    Overall Loss 2.373343    Objective Loss 2.373343                                        LR 0.100000    Time 0.283545    
2024-04-23 19:55:45,999 - Epoch: [197][   80/  267]    Overall Loss 2.369896    Objective Loss 2.369896                                        LR 0.100000    Time 0.271510    
2024-04-23 19:55:48,758 - Epoch: [197][   90/  267]    Overall Loss 2.363240    Objective Loss 2.363240                                        LR 0.100000    Time 0.271965    
2024-04-23 19:55:50,665 - Epoch: [197][  100/  267]    Overall Loss 2.364677    Objective Loss 2.364677                                        LR 0.100000    Time 0.263809    
2024-04-23 19:55:53,504 - Epoch: [197][  110/  267]    Overall Loss 2.365335    Objective Loss 2.365335                                        LR 0.100000    Time 0.265610    
2024-04-23 19:55:53,963 - Epoch: [143][  100/  296]    Overall Loss 0.725644    Objective Loss 0.725644                                        LR 0.000080    Time 0.188466    
2024-04-23 19:55:55,265 - Epoch: [197][  120/  267]    Overall Loss 2.362767    Objective Loss 2.362767                                        LR 0.100000    Time 0.258126    
2024-04-23 19:55:57,536 - Epoch: [197][  130/  267]    Overall Loss 2.363700    Objective Loss 2.363700                                        LR 0.100000    Time 0.255719    
2024-04-23 19:55:58,667 - Epoch: [197][  140/  267]    Overall Loss 2.365381    Objective Loss 2.365381                                        LR 0.100000    Time 0.245515    
2024-04-23 19:56:00,752 - Epoch: [197][  150/  267]    Overall Loss 2.365564    Objective Loss 2.365564                                        LR 0.100000    Time 0.243029    
2024-04-23 19:56:02,480 - Epoch: [197][  160/  267]    Overall Loss 2.364922    Objective Loss 2.364922                                        LR 0.100000    Time 0.238623    
2024-04-23 19:56:05,010 - Epoch: [197][  170/  267]    Overall Loss 2.365396    Objective Loss 2.365396                                        LR 0.100000    Time 0.239448    
2024-04-23 19:56:06,822 - Epoch: [197][  180/  267]    Overall Loss 2.364903    Objective Loss 2.364903                                        LR 0.100000    Time 0.236199    
2024-04-23 19:56:09,374 - Epoch: [197][  190/  267]    Overall Loss 2.365722    Objective Loss 2.365722                                        LR 0.100000    Time 0.237182    
2024-04-23 19:56:11,187 - Epoch: [197][  200/  267]    Overall Loss 2.365303    Objective Loss 2.365303                                        LR 0.100000    Time 0.234374    
2024-04-23 19:56:12,958 - Epoch: [143][  200/  296]    Overall Loss 0.710727    Objective Loss 0.710727                                        LR 0.000080    Time 0.189101    
2024-04-23 19:56:13,706 - Epoch: [197][  210/  267]    Overall Loss 2.363975    Objective Loss 2.363975                                        LR 0.100000    Time 0.235192    
2024-04-23 19:56:15,438 - Epoch: [197][  220/  267]    Overall Loss 2.366615    Objective Loss 2.366615                                        LR 0.100000    Time 0.232360    
2024-04-23 19:56:19,161 - Epoch: [197][  230/  267]    Overall Loss 2.367227    Objective Loss 2.367227                                        LR 0.100000    Time 0.238427    
2024-04-23 19:56:21,571 - Epoch: [197][  240/  267]    Overall Loss 2.367557    Objective Loss 2.367557                                        LR 0.100000    Time 0.238522    
2024-04-23 19:56:24,788 - Epoch: [143][  296/  296]    Overall Loss 0.713507    Objective Loss 0.713507    Top1 78.688525    Top5 96.721311    LR 0.000080    Time 0.167682    
2024-04-23 19:56:24,911 - --- validate (epoch=143)-----------
2024-04-23 19:56:24,912 - 3925 samples (32 per mini-batch)
2024-04-23 19:56:24,991 - Epoch: [197][  250/  267]    Overall Loss 2.366999    Objective Loss 2.366999                                        LR 0.100000    Time 0.242653    
2024-04-23 19:56:28,037 - Epoch: [197][  260/  267]    Overall Loss 2.366821    Objective Loss 2.366821                                        LR 0.100000    Time 0.245022    
2024-04-23 19:56:30,306 - Epoch: [197][  267/  267]    Overall Loss 2.367178    Objective Loss 2.367178    Top1 6.976744    Top5 53.488372    LR 0.100000    Time 0.247087    
2024-04-23 19:56:30,539 - --- validate (epoch=197)-----------
2024-04-23 19:56:30,541 - 946 samples (32 per mini-batch)
2024-04-23 19:56:34,326 - Epoch: [197][   10/   30]    Loss 2.351553    Top1 12.812500    Top5 54.062500    
2024-04-23 19:56:35,720 - Epoch: [197][   20/   30]    Loss 2.379483    Top1 10.312500    Top5 51.875000    
2024-04-23 19:56:37,335 - Epoch: [197][   30/   30]    Loss 2.374195    Top1 10.359408    Top5 51.268499    
2024-04-23 19:56:37,474 - ==> Top1: 10.359    Top5: 51.268    Loss: 2.374

2024-04-23 19:56:37,476 - ==> Confusion:
[[  0  87   0   0   0   0   0   0   0   0]
 [  0  98   0   0   0   0   0   0   0   0]
 [  0  99   0   0   0   0   0   0   0   0]
 [  0  80   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0 104   0   0   0   0   0   0   0   0]
 [  0  93   0   0   0   0   0   0   0   0]
 [  0  97   0   0   0   0   0   0   0   0]
 [  0 100   0   0   0   0   0   0   0   0]]

2024-04-23 19:56:37,481 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:56:37,481 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:56:37,497 - 

2024-04-23 19:56:37,498 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:56:40,551 - Epoch: [198][   10/  267]    Overall Loss 2.387835    Objective Loss 2.387835                                        LR 0.100000    Time 0.305005    
2024-04-23 19:56:41,988 - Epoch: [198][   20/  267]    Overall Loss 2.399649    Objective Loss 2.399649                                        LR 0.100000    Time 0.224247    
2024-04-23 19:56:43,951 - Epoch: [198][   30/  267]    Overall Loss 2.389510    Objective Loss 2.389510                                        LR 0.100000    Time 0.214832    
2024-04-23 19:56:45,661 - Epoch: [198][   40/  267]    Overall Loss 2.388194    Objective Loss 2.388194                                        LR 0.100000    Time 0.203785    
2024-04-23 19:56:47,731 - Epoch: [198][   50/  267]    Overall Loss 2.380604    Objective Loss 2.380604                                        LR 0.100000    Time 0.204374    
2024-04-23 19:56:49,299 - Epoch: [198][   60/  267]    Overall Loss 2.371480    Objective Loss 2.371480                                        LR 0.100000    Time 0.196390    
2024-04-23 19:56:50,032 - Epoch: [143][  100/  123]    Loss 0.679316    Top1 78.062500    Top5 97.406250    
2024-04-23 19:56:51,387 - Epoch: [198][   70/  267]    Overall Loss 2.372239    Objective Loss 2.372239                                        LR 0.100000    Time 0.198122    
2024-04-23 19:56:52,696 - Epoch: [198][   80/  267]    Overall Loss 2.373204    Objective Loss 2.373204                                        LR 0.100000    Time 0.189685    
2024-04-23 19:56:54,470 - Epoch: [198][   90/  267]    Overall Loss 2.371122    Objective Loss 2.371122                                        LR 0.100000    Time 0.188287    
2024-04-23 19:56:55,702 - Epoch: [198][  100/  267]    Overall Loss 2.367389    Objective Loss 2.367389                                        LR 0.100000    Time 0.181758    
2024-04-23 19:56:56,355 - Epoch: [143][  123/  123]    Loss 0.670067    Top1 78.369427    Top5 97.426752    
2024-04-23 19:56:56,658 - ==> Top1: 78.369    Top5: 97.427    Loss: 0.670

2024-04-23 19:56:56,671 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:56:56,672 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:56:56,757 - 

2024-04-23 19:56:56,759 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:56:57,706 - Epoch: [198][  110/  267]    Overall Loss 2.367978    Objective Loss 2.367978                                        LR 0.100000    Time 0.183425    
2024-04-23 19:56:59,960 - Epoch: [198][  120/  267]    Overall Loss 2.369614    Objective Loss 2.369614                                        LR 0.100000    Time 0.186876    
2024-04-23 19:57:02,965 - Epoch: [198][  130/  267]    Overall Loss 2.367747    Objective Loss 2.367747                                        LR 0.100000    Time 0.195599    
2024-04-23 19:57:04,921 - Epoch: [198][  140/  267]    Overall Loss 2.366478    Objective Loss 2.366478                                        LR 0.100000    Time 0.195574    
2024-04-23 19:57:07,444 - Epoch: [198][  150/  267]    Overall Loss 2.367633    Objective Loss 2.367633                                        LR 0.100000    Time 0.199335    
2024-04-23 19:57:09,296 - Epoch: [198][  160/  267]    Overall Loss 2.370205    Objective Loss 2.370205                                        LR 0.100000    Time 0.198436    
2024-04-23 19:57:12,004 - Epoch: [198][  170/  267]    Overall Loss 2.369606    Objective Loss 2.369606                                        LR 0.100000    Time 0.202677    
2024-04-23 19:57:14,429 - Epoch: [198][  180/  267]    Overall Loss 2.370984    Objective Loss 2.370984                                        LR 0.100000    Time 0.204870    
2024-04-23 19:57:16,411 - Epoch: [198][  190/  267]    Overall Loss 2.370971    Objective Loss 2.370971                                        LR 0.100000    Time 0.204504    
2024-04-23 19:57:18,988 - Epoch: [198][  200/  267]    Overall Loss 2.369212    Objective Loss 2.369212                                        LR 0.100000    Time 0.207152    
2024-04-23 19:57:20,712 - Epoch: [198][  210/  267]    Overall Loss 2.368452    Objective Loss 2.368452                                        LR 0.100000    Time 0.205482    
2024-04-23 19:57:21,845 - Epoch: [144][  100/  296]    Overall Loss 0.719725    Objective Loss 0.719725                                        LR 0.000080    Time 0.250638    
2024-04-23 19:57:23,275 - Epoch: [198][  220/  267]    Overall Loss 2.367807    Objective Loss 2.367807                                        LR 0.100000    Time 0.207777    
2024-04-23 19:57:25,214 - Epoch: [198][  230/  267]    Overall Loss 2.367266    Objective Loss 2.367266                                        LR 0.100000    Time 0.207166    
2024-04-23 19:57:27,649 - Epoch: [198][  240/  267]    Overall Loss 2.365697    Objective Loss 2.365697                                        LR 0.100000    Time 0.208667    
2024-04-23 19:57:28,902 - Epoch: [198][  250/  267]    Overall Loss 2.366572    Objective Loss 2.366572                                        LR 0.100000    Time 0.205320    
2024-04-23 19:57:31,114 - Epoch: [198][  260/  267]    Overall Loss 2.365884    Objective Loss 2.365884                                        LR 0.100000    Time 0.205916    
2024-04-23 19:57:31,901 - Epoch: [198][  267/  267]    Overall Loss 2.365874    Objective Loss 2.365874    Top1 6.976744    Top5 39.534884    LR 0.100000    Time 0.203453    
2024-04-23 19:57:32,105 - --- validate (epoch=198)-----------
2024-04-23 19:57:32,106 - 946 samples (32 per mini-batch)
2024-04-23 19:57:35,358 - Epoch: [198][   10/   30]    Loss 2.345282    Top1 8.437500    Top5 50.312500    
2024-04-23 19:57:37,650 - Epoch: [198][   20/   30]    Loss 2.357159    Top1 9.062500    Top5 47.812500    
2024-04-23 19:57:40,101 - Epoch: [198][   30/   30]    Loss 2.366061    Top1 9.196617    Top5 47.780127    
2024-04-23 19:57:40,399 - ==> Top1: 9.197    Top5: 47.780    Loss: 2.366

2024-04-23 19:57:40,402 - ==> Confusion:
[[ 87   0   0   0   0   0   0   0   0   0]
 [ 98   0   0   0   0   0   0   0   0   0]
 [ 99   0   0   0   0   0   0   0   0   0]
 [ 80   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 95   0   0   0   0   0   0   0   0   0]
 [104   0   0   0   0   0   0   0   0   0]
 [ 93   0   0   0   0   0   0   0   0   0]
 [ 97   0   0   0   0   0   0   0   0   0]
 [100   0   0   0   0   0   0   0   0   0]]

2024-04-23 19:57:40,408 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:57:40,409 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:57:40,425 - 

2024-04-23 19:57:40,426 - Training epoch: 8523 samples (32 per mini-batch)
2024-04-23 19:57:42,149 - Epoch: [144][  200/  296]    Overall Loss 0.706010    Objective Loss 0.706010                                        LR 0.000080    Time 0.226739    
2024-04-23 19:57:44,015 - Epoch: [199][   10/  267]    Overall Loss 2.352182    Objective Loss 2.352182                                        LR 0.100000    Time 0.358493    
2024-04-23 19:57:45,803 - Epoch: [199][   20/  267]    Overall Loss 2.366743    Objective Loss 2.366743                                        LR 0.100000    Time 0.268517    
2024-04-23 19:57:48,153 - Epoch: [199][   30/  267]    Overall Loss 2.369057    Objective Loss 2.369057                                        LR 0.100000    Time 0.257235    
2024-04-23 19:57:49,783 - Epoch: [199][   40/  267]    Overall Loss 2.367525    Objective Loss 2.367525                                        LR 0.100000    Time 0.233624    
2024-04-23 19:57:51,482 - Epoch: [199][   50/  267]    Overall Loss 2.364357    Objective Loss 2.364357                                        LR 0.100000    Time 0.220814    
2024-04-23 19:57:52,545 - Epoch: [199][   60/  267]    Overall Loss 2.364297    Objective Loss 2.364297                                        LR 0.100000    Time 0.201688    
2024-04-23 19:57:54,616 - Epoch: [199][   70/  267]    Overall Loss 2.368340    Objective Loss 2.368340                                        LR 0.100000    Time 0.202434    
2024-04-23 19:57:56,140 - Epoch: [199][   80/  267]    Overall Loss 2.366276    Objective Loss 2.366276                                        LR 0.100000    Time 0.196129    
2024-04-23 19:57:58,416 - Epoch: [199][   90/  267]    Overall Loss 2.368418    Objective Loss 2.368418                                        LR 0.100000    Time 0.199596    
2024-04-23 19:58:00,248 - Epoch: [199][  100/  267]    Overall Loss 2.361627    Objective Loss 2.361627                                        LR 0.100000    Time 0.197931    
2024-04-23 19:58:01,404 - Epoch: [199][  110/  267]    Overall Loss 2.364520    Objective Loss 2.364520                                        LR 0.100000    Time 0.190421    
2024-04-23 19:58:01,646 - Epoch: [144][  296/  296]    Overall Loss 0.711046    Objective Loss 0.711046    Top1 78.688525    Top5 100.000000    LR 0.000080    Time 0.219011    
2024-04-23 19:58:02,037 - --- validate (epoch=144)-----------
2024-04-23 19:58:02,038 - 3925 samples (32 per mini-batch)
2024-04-23 19:58:02,866 - Epoch: [199][  120/  267]    Overall Loss 2.366360    Objective Loss 2.366360                                        LR 0.100000    Time 0.186714    
2024-04-23 19:58:04,620 - Epoch: [199][  130/  267]    Overall Loss 2.363292    Objective Loss 2.363292                                        LR 0.100000    Time 0.185830    
2024-04-23 19:58:07,019 - Epoch: [199][  140/  267]    Overall Loss 2.363036    Objective Loss 2.363036                                        LR 0.100000    Time 0.189668    
2024-04-23 19:58:08,729 - Epoch: [199][  150/  267]    Overall Loss 2.364315    Objective Loss 2.364315                                        LR 0.100000    Time 0.188403    
2024-04-23 19:58:11,233 - Epoch: [199][  160/  267]    Overall Loss 2.366183    Objective Loss 2.366183                                        LR 0.100000    Time 0.192258    
2024-04-23 19:58:13,078 - Epoch: [199][  170/  267]    Overall Loss 2.363993    Objective Loss 2.363993                                        LR 0.100000    Time 0.191786    
2024-04-23 19:58:15,707 - Epoch: [199][  180/  267]    Overall Loss 2.363974    Objective Loss 2.363974                                        LR 0.100000    Time 0.195723    
2024-04-23 19:58:17,512 - Epoch: [199][  190/  267]    Overall Loss 2.364508    Objective Loss 2.364508                                        LR 0.100000    Time 0.194906    
2024-04-23 19:58:20,922 - Epoch: [199][  200/  267]    Overall Loss 2.364985    Objective Loss 2.364985                                        LR 0.100000    Time 0.202198    
2024-04-23 19:58:23,641 - Epoch: [199][  210/  267]    Overall Loss 2.367670    Objective Loss 2.367670                                        LR 0.100000    Time 0.205508    
2024-04-23 19:58:26,916 - Epoch: [199][  220/  267]    Overall Loss 2.367217    Objective Loss 2.367217                                        LR 0.100000    Time 0.211032    
2024-04-23 19:58:28,581 - Epoch: [144][  100/  123]    Loss 0.680796    Top1 78.062500    Top5 97.250000    
2024-04-23 19:58:28,827 - Epoch: [199][  230/  267]    Overall Loss 2.367792    Objective Loss 2.367792                                        LR 0.100000    Time 0.210156    
2024-04-23 19:58:31,574 - Epoch: [199][  240/  267]    Overall Loss 2.367957    Objective Loss 2.367957                                        LR 0.100000    Time 0.212833    
2024-04-23 19:58:33,551 - Epoch: [199][  250/  267]    Overall Loss 2.367517    Objective Loss 2.367517                                        LR 0.100000    Time 0.212205    
2024-04-23 19:58:33,861 - Epoch: [144][  123/  123]    Loss 0.679168    Top1 77.987261    Top5 97.350318    
2024-04-23 19:58:34,126 - ==> Top1: 77.987    Top5: 97.350    Loss: 0.679

2024-04-23 19:58:34,138 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 19:58:34,139 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 19:58:34,194 - 

2024-04-23 19:58:34,195 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 19:58:35,552 - Epoch: [199][  260/  267]    Overall Loss 2.367144    Objective Loss 2.367144                                        LR 0.100000    Time 0.211729    
2024-04-23 19:58:36,556 - Epoch: [199][  267/  267]    Overall Loss 2.368024    Objective Loss 2.368024    Top1 9.302326    Top5 41.860465    LR 0.100000    Time 0.209934    
2024-04-23 19:58:36,752 - --- validate (epoch=199)-----------
2024-04-23 19:58:36,754 - 946 samples (32 per mini-batch)
2024-04-23 19:58:39,915 - Epoch: [199][   10/   30]    Loss 2.330226    Top1 10.312500    Top5 53.750000    
2024-04-23 19:58:41,724 - Epoch: [199][   20/   30]    Loss 2.342982    Top1 11.093750    Top5 54.531250    
2024-04-23 19:58:44,026 - Epoch: [199][   30/   30]    Loss 2.356201    Top1 10.993658    Top5 52.114165    
2024-04-23 19:58:44,242 - ==> Top1: 10.994    Top5: 52.114    Loss: 2.356

2024-04-23 19:58:44,244 - ==> Confusion:
[[  0   0   0   0   0   0  87   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0]
 [  0   0   0   0   0   0  99   0   0   0]
 [  0   0   0   0   0   0  80   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  95   0   0   0]
 [  0   0   0   0   0   0 104   0   0   0]
 [  0   0   0   0   0   0  93   0   0   0]
 [  0   0   0   0   0   0  97   0   0   0]
 [  0   0   0   0   0   0 100   0   0   0]]

2024-04-23 19:58:44,250 - ==> Best [Top1: 10.994   Top5: 52.220   Sparsity:0.00   Params: 96528 on epoch: 121]
2024-04-23 19:58:44,251 - Saving checkpoint to: logs/2024.04.23-154956/qat_checkpoint.pth.tar
2024-04-23 19:58:44,268 - --- test ---------------------
2024-04-23 19:58:44,269 - 3925 samples (32 per mini-batch)
2024-04-23 19:58:48,219 - Test: [   10/  123]    Loss 2.347560    Top1 8.125000    Top5 51.875000    
2024-04-23 19:58:50,703 - Test: [   20/  123]    Loss 2.353786    Top1 8.593750    Top5 52.968750    
2024-04-23 19:58:53,565 - Test: [   30/  123]    Loss 2.356040    Top1 9.062500    Top5 51.875000    
2024-04-23 19:58:55,760 - Test: [   40/  123]    Loss 2.365944    Top1 9.375000    Top5 50.000000    
2024-04-23 19:58:58,060 - Epoch: [145][  100/  296]    Overall Loss 0.704919    Objective Loss 0.704919                                        LR 0.000080    Time 0.238436    
2024-04-23 19:58:58,856 - Test: [   50/  123]    Loss 2.368712    Top1 9.437500    Top5 49.562500    
2024-04-23 19:59:01,262 - Test: [   60/  123]    Loss 2.369020    Top1 9.635417    Top5 49.687500    
2024-04-23 19:59:04,006 - Test: [   70/  123]    Loss 2.367217    Top1 9.776786    Top5 49.910714    
2024-04-23 19:59:06,034 - Test: [   80/  123]    Loss 2.366539    Top1 9.726563    Top5 49.453125    
2024-04-23 19:59:09,329 - Test: [   90/  123]    Loss 2.368990    Top1 9.444444    Top5 49.409722    
2024-04-23 19:59:12,339 - Test: [  100/  123]    Loss 2.366994    Top1 9.656250    Top5 49.718750    
2024-04-23 19:59:15,985 - Test: [  110/  123]    Loss 2.366949    Top1 9.886364    Top5 49.545455    
2024-04-23 19:59:18,412 - Test: [  120/  123]    Loss 2.366650    Top1 9.843750    Top5 49.479167    
2024-04-23 19:59:19,342 - Test: [  123/  123]    Loss 2.365958    Top1 9.910828    Top5 49.528662    
2024-04-23 19:59:19,571 - ==> Top1: 9.911    Top5: 49.529    Loss: 2.366

2024-04-23 19:59:19,574 - ==> Confusion:
[[  0   0   0   0   0   0 387   0   0   0]
 [  0   0   0   0   0   0 395   0   0   0]
 [  0   0   0   0   0   0 357   0   0   0]
 [  0   0   0   0   0   0 386   0   0   0]
 [  0   0   0   0   0   0 409   0   0   0]
 [  0   0   0   0   0   0 394   0   0   0]
 [  0   0   0   0   0   0 389   0   0   0]
 [  0   0   0   0   0   0 419   0   0   0]
 [  0   0   0   0   0   0 399   0   0   0]
 [  0   0   0   0   0   0 390   0   0   0]]

2024-04-23 19:59:19,585 - 
2024-04-23 19:59:19,586 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.23-154956/2024.04.23-154956.log
2024-04-23 19:59:22,531 - Epoch: [145][  200/  296]    Overall Loss 0.699028    Objective Loss 0.699028                                        LR 0.000080    Time 0.241473    
2024-04-23 19:59:41,729 - Epoch: [145][  296/  296]    Overall Loss 0.710572    Objective Loss 0.710572    Top1 83.606557    Top5 96.721311    LR 0.000080    Time 0.227961    
2024-04-23 19:59:41,978 - --- validate (epoch=145)-----------
2024-04-23 19:59:41,979 - 3925 samples (32 per mini-batch)
2024-04-23 20:00:02,880 - Epoch: [145][  100/  123]    Loss 0.674240    Top1 78.187500    Top5 97.500000    
2024-04-23 20:00:08,084 - Epoch: [145][  123/  123]    Loss 0.682793    Top1 77.961783    Top5 97.477707    
2024-04-23 20:00:08,336 - ==> Top1: 77.962    Top5: 97.478    Loss: 0.683

2024-04-23 20:00:08,344 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 20:00:08,345 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:00:08,384 - 

2024-04-23 20:00:08,384 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:00:28,882 - Epoch: [146][  100/  296]    Overall Loss 0.714245    Objective Loss 0.714245                                        LR 0.000080    Time 0.204799    
2024-04-23 20:00:48,134 - Epoch: [146][  200/  296]    Overall Loss 0.719484    Objective Loss 0.719484                                        LR 0.000080    Time 0.198576    
2024-04-23 20:01:09,416 - Epoch: [146][  296/  296]    Overall Loss 0.716267    Objective Loss 0.716267    Top1 77.049180    Top5 100.000000    LR 0.000080    Time 0.206008    
2024-04-23 20:01:09,594 - --- validate (epoch=146)-----------
2024-04-23 20:01:09,595 - 3925 samples (32 per mini-batch)
2024-04-23 20:01:29,206 - Epoch: [146][  100/  123]    Loss 0.661024    Top1 78.406250    Top5 97.687500    
2024-04-23 20:01:32,791 - Epoch: [146][  123/  123]    Loss 0.677400    Top1 78.063694    Top5 97.477707    
2024-04-23 20:01:33,086 - ==> Top1: 78.064    Top5: 97.478    Loss: 0.677

2024-04-23 20:01:33,094 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 20:01:33,095 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:01:33,143 - 

2024-04-23 20:01:33,144 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:01:54,026 - Epoch: [147][  100/  296]    Overall Loss 0.703822    Objective Loss 0.703822                                        LR 0.000080    Time 0.208630    
2024-04-23 20:02:13,139 - Epoch: [147][  200/  296]    Overall Loss 0.717277    Objective Loss 0.717277                                        LR 0.000080    Time 0.199789    
2024-04-23 20:02:30,500 - Epoch: [147][  296/  296]    Overall Loss 0.719217    Objective Loss 0.719217    Top1 78.688525    Top5 98.360656    LR 0.000080    Time 0.193594    
2024-04-23 20:02:30,661 - --- validate (epoch=147)-----------
2024-04-23 20:02:30,662 - 3925 samples (32 per mini-batch)
2024-04-23 20:02:54,287 - Epoch: [147][  100/  123]    Loss 0.656846    Top1 78.593750    Top5 97.312500    
2024-04-23 20:02:58,730 - Epoch: [147][  123/  123]    Loss 0.669117    Top1 78.445860    Top5 97.121019    
2024-04-23 20:02:58,918 - ==> Top1: 78.446    Top5: 97.121    Loss: 0.669

2024-04-23 20:02:58,925 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 20:02:58,926 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:02:58,983 - 

2024-04-23 20:02:58,984 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:03:18,850 - Epoch: [148][  100/  296]    Overall Loss 0.709779    Objective Loss 0.709779                                        LR 0.000080    Time 0.198490    
2024-04-23 20:03:38,071 - Epoch: [148][  200/  296]    Overall Loss 0.720335    Objective Loss 0.720335                                        LR 0.000080    Time 0.195275    
2024-04-23 20:03:57,413 - Epoch: [148][  296/  296]    Overall Loss 0.711130    Objective Loss 0.711130    Top1 73.770492    Top5 95.081967    LR 0.000080    Time 0.197240    
2024-04-23 20:03:57,698 - --- validate (epoch=148)-----------
2024-04-23 20:03:57,699 - 3925 samples (32 per mini-batch)
2024-04-23 20:04:21,881 - Epoch: [148][  100/  123]    Loss 0.676684    Top1 78.062500    Top5 97.218750    
2024-04-23 20:04:27,184 - Epoch: [148][  123/  123]    Loss 0.680085    Top1 77.987261    Top5 97.299363    
2024-04-23 20:04:27,473 - ==> Top1: 77.987    Top5: 97.299    Loss: 0.680

2024-04-23 20:04:27,482 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 20:04:27,482 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:04:27,527 - 

2024-04-23 20:04:27,528 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:04:42,818 - Epoch: [149][  100/  296]    Overall Loss 0.724695    Objective Loss 0.724695                                        LR 0.000080    Time 0.152732    
2024-04-23 20:04:55,736 - Epoch: [149][  200/  296]    Overall Loss 0.712068    Objective Loss 0.712068                                        LR 0.000080    Time 0.140876    
2024-04-23 20:05:08,987 - Epoch: [149][  296/  296]    Overall Loss 0.715930    Objective Loss 0.715930    Top1 85.245902    Top5 98.360656    LR 0.000080    Time 0.139903    
2024-04-23 20:05:09,241 - --- validate (epoch=149)-----------
2024-04-23 20:05:09,241 - 3925 samples (32 per mini-batch)
2024-04-23 20:05:24,134 - Epoch: [149][  100/  123]    Loss 0.668853    Top1 78.531250    Top5 97.406250    
2024-04-23 20:05:26,127 - Epoch: [149][  123/  123]    Loss 0.671792    Top1 78.267516    Top5 97.528662    
2024-04-23 20:05:26,343 - ==> Top1: 78.268    Top5: 97.529    Loss: 0.672

2024-04-23 20:05:26,354 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 20:05:26,354 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:05:26,390 - 

2024-04-23 20:05:26,391 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:05:41,885 - Epoch: [150][  100/  296]    Overall Loss 0.698866    Objective Loss 0.698866                                        LR 0.000020    Time 0.154788    
2024-04-23 20:05:56,641 - Epoch: [150][  200/  296]    Overall Loss 0.695001    Objective Loss 0.695001                                        LR 0.000020    Time 0.151092    
2024-04-23 20:06:10,138 - Epoch: [150][  296/  296]    Overall Loss 0.702296    Objective Loss 0.702296    Top1 73.770492    Top5 100.000000    LR 0.000020    Time 0.147636    
2024-04-23 20:06:10,347 - --- validate (epoch=150)-----------
2024-04-23 20:06:10,347 - 3925 samples (32 per mini-batch)
2024-04-23 20:06:28,428 - Epoch: [150][  100/  123]    Loss 0.666218    Top1 78.531250    Top5 97.468750    
2024-04-23 20:06:31,414 - Epoch: [150][  123/  123]    Loss 0.667869    Top1 78.318471    Top5 97.426752    
2024-04-23 20:06:31,620 - ==> Top1: 78.318    Top5: 97.427    Loss: 0.668

2024-04-23 20:06:31,630 - ==> Best [Top1: 78.624   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 129]
2024-04-23 20:06:31,631 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:06:31,682 - 

2024-04-23 20:06:31,683 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:06:47,236 - Epoch: [151][  100/  296]    Overall Loss 0.704221    Objective Loss 0.704221                                        LR 0.000020    Time 0.155350    
2024-04-23 20:07:00,917 - Epoch: [151][  200/  296]    Overall Loss 0.713488    Objective Loss 0.713488                                        LR 0.000020    Time 0.146002    
2024-04-23 20:07:17,084 - Epoch: [151][  296/  296]    Overall Loss 0.702812    Objective Loss 0.702812    Top1 72.131148    Top5 95.081967    LR 0.000020    Time 0.153218    
2024-04-23 20:07:17,319 - --- validate (epoch=151)-----------
2024-04-23 20:07:17,320 - 3925 samples (32 per mini-batch)
2024-04-23 20:07:33,760 - Epoch: [151][  100/  123]    Loss 0.651191    Top1 79.218750    Top5 97.625000    
2024-04-23 20:07:37,721 - Epoch: [151][  123/  123]    Loss 0.666237    Top1 78.675159    Top5 97.579618    
2024-04-23 20:07:37,932 - ==> Top1: 78.675    Top5: 97.580    Loss: 0.666

2024-04-23 20:07:37,940 - ==> Best [Top1: 78.675   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 151]
2024-04-23 20:07:37,940 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:07:37,989 - 

2024-04-23 20:07:37,990 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:07:55,734 - Epoch: [152][  100/  296]    Overall Loss 0.708882    Objective Loss 0.708882                                        LR 0.000020    Time 0.177269    
2024-04-23 20:08:19,365 - Epoch: [152][  200/  296]    Overall Loss 0.713239    Objective Loss 0.713239                                        LR 0.000020    Time 0.206714    
2024-04-23 20:08:40,365 - Epoch: [152][  296/  296]    Overall Loss 0.708212    Objective Loss 0.708212    Top1 77.049180    Top5 95.081967    LR 0.000020    Time 0.210573    
2024-04-23 20:08:40,534 - --- validate (epoch=152)-----------
2024-04-23 20:08:40,535 - 3925 samples (32 per mini-batch)
2024-04-23 20:09:02,064 - Epoch: [152][  100/  123]    Loss 0.648072    Top1 79.031250    Top5 97.593750    
2024-04-23 20:09:06,016 - Epoch: [152][  123/  123]    Loss 0.662700    Top1 78.751592    Top5 97.375796    
2024-04-23 20:09:06,247 - ==> Top1: 78.752    Top5: 97.376    Loss: 0.663

2024-04-23 20:09:06,256 - ==> Best [Top1: 78.752   Top5: 97.376   Sparsity:0.00   Params: 376752 on epoch: 152]
2024-04-23 20:09:06,256 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:09:06,305 - 

2024-04-23 20:09:06,305 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:09:25,529 - Epoch: [153][  100/  296]    Overall Loss 0.656009    Objective Loss 0.656009                                        LR 0.000020    Time 0.192058    
2024-04-23 20:09:43,715 - Epoch: [153][  200/  296]    Overall Loss 0.669474    Objective Loss 0.669474                                        LR 0.000020    Time 0.186874    
2024-04-23 20:10:01,165 - Epoch: [153][  296/  296]    Overall Loss 0.677165    Objective Loss 0.677165    Top1 70.491803    Top5 95.081967    LR 0.000020    Time 0.185173    
2024-04-23 20:10:01,518 - --- validate (epoch=153)-----------
2024-04-23 20:10:01,519 - 3925 samples (32 per mini-batch)
2024-04-23 20:10:22,242 - Epoch: [153][  100/  123]    Loss 0.665886    Top1 78.468750    Top5 97.593750    
2024-04-23 20:10:26,467 - Epoch: [153][  123/  123]    Loss 0.663411    Top1 78.522293    Top5 97.477707    
2024-04-23 20:10:26,668 - ==> Top1: 78.522    Top5: 97.478    Loss: 0.663

2024-04-23 20:10:26,676 - ==> Best [Top1: 78.752   Top5: 97.376   Sparsity:0.00   Params: 376752 on epoch: 152]
2024-04-23 20:10:26,677 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:10:26,722 - 

2024-04-23 20:10:26,723 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:10:47,434 - Epoch: [154][  100/  296]    Overall Loss 0.687165    Objective Loss 0.687165                                        LR 0.000020    Time 0.206929    
2024-04-23 20:11:05,296 - Epoch: [154][  200/  296]    Overall Loss 0.691123    Objective Loss 0.691123                                        LR 0.000020    Time 0.192689    
2024-04-23 20:11:21,893 - Epoch: [154][  296/  296]    Overall Loss 0.692479    Objective Loss 0.692479    Top1 72.131148    Top5 96.721311    LR 0.000020    Time 0.186213    
2024-04-23 20:11:22,147 - --- validate (epoch=154)-----------
2024-04-23 20:11:22,148 - 3925 samples (32 per mini-batch)
2024-04-23 20:11:46,017 - Epoch: [154][  100/  123]    Loss 0.654341    Top1 79.125000    Top5 97.593750    
2024-04-23 20:11:50,294 - Epoch: [154][  123/  123]    Loss 0.664786    Top1 78.929936    Top5 97.426752    
2024-04-23 20:11:50,560 - ==> Top1: 78.930    Top5: 97.427    Loss: 0.665

2024-04-23 20:11:50,571 - ==> Best [Top1: 78.930   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 154]
2024-04-23 20:11:50,571 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:11:50,636 - 

2024-04-23 20:11:50,637 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:12:10,634 - Epoch: [155][  100/  296]    Overall Loss 0.718728    Objective Loss 0.718728                                        LR 0.000020    Time 0.199793    
2024-04-23 20:12:28,796 - Epoch: [155][  200/  296]    Overall Loss 0.702571    Objective Loss 0.702571                                        LR 0.000020    Time 0.190628    
2024-04-23 20:12:46,280 - Epoch: [155][  296/  296]    Overall Loss 0.701900    Objective Loss 0.701900    Top1 77.049180    Top5 98.360656    LR 0.000020    Time 0.187818    
2024-04-23 20:12:46,573 - --- validate (epoch=155)-----------
2024-04-23 20:12:46,574 - 3925 samples (32 per mini-batch)
2024-04-23 20:13:08,397 - Epoch: [155][  100/  123]    Loss 0.650643    Top1 79.562500    Top5 97.718750    
2024-04-23 20:13:13,230 - Epoch: [155][  123/  123]    Loss 0.660509    Top1 79.184713    Top5 97.426752    
2024-04-23 20:13:13,423 - ==> Top1: 79.185    Top5: 97.427    Loss: 0.661

2024-04-23 20:13:13,433 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:13:13,433 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:13:13,490 - 

2024-04-23 20:13:13,490 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:13:33,541 - Epoch: [156][  100/  296]    Overall Loss 0.692561    Objective Loss 0.692561                                        LR 0.000020    Time 0.200329    
2024-04-23 20:13:51,222 - Epoch: [156][  200/  296]    Overall Loss 0.673321    Objective Loss 0.673321                                        LR 0.000020    Time 0.188484    
2024-04-23 20:14:08,482 - Epoch: [156][  296/  296]    Overall Loss 0.675497    Objective Loss 0.675497    Top1 78.688525    Top5 98.360656    LR 0.000020    Time 0.185612    
2024-04-23 20:14:08,741 - --- validate (epoch=156)-----------
2024-04-23 20:14:08,743 - 3925 samples (32 per mini-batch)
2024-04-23 20:14:30,146 - Epoch: [156][  100/  123]    Loss 0.662770    Top1 78.750000    Top5 97.406250    
2024-04-23 20:14:34,421 - Epoch: [156][  123/  123]    Loss 0.662766    Top1 78.853503    Top5 97.426752    
2024-04-23 20:14:34,674 - ==> Top1: 78.854    Top5: 97.427    Loss: 0.663

2024-04-23 20:14:34,683 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:14:34,683 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:14:34,730 - 

2024-04-23 20:14:34,730 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:14:54,433 - Epoch: [157][  100/  296]    Overall Loss 0.694447    Objective Loss 0.694447                                        LR 0.000020    Time 0.196838    
2024-04-23 20:15:12,825 - Epoch: [157][  200/  296]    Overall Loss 0.687910    Objective Loss 0.687910                                        LR 0.000020    Time 0.190294    
2024-04-23 20:15:29,303 - Epoch: [157][  296/  296]    Overall Loss 0.693694    Objective Loss 0.693694    Top1 85.245902    Top5 96.721311    LR 0.000020    Time 0.184193    
2024-04-23 20:15:29,518 - --- validate (epoch=157)-----------
2024-04-23 20:15:29,518 - 3925 samples (32 per mini-batch)
2024-04-23 20:15:49,486 - Epoch: [157][  100/  123]    Loss 0.655523    Top1 78.968750    Top5 97.468750    
2024-04-23 20:15:53,695 - Epoch: [157][  123/  123]    Loss 0.669111    Top1 78.369427    Top5 97.426752    
2024-04-23 20:15:53,867 - ==> Top1: 78.369    Top5: 97.427    Loss: 0.669

2024-04-23 20:15:53,874 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:15:53,874 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:15:53,925 - 

2024-04-23 20:15:53,926 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:16:14,485 - Epoch: [158][  100/  296]    Overall Loss 0.685551    Objective Loss 0.685551                                        LR 0.000020    Time 0.205426    
2024-04-23 20:16:33,019 - Epoch: [158][  200/  296]    Overall Loss 0.694708    Objective Loss 0.694708                                        LR 0.000020    Time 0.195299    
2024-04-23 20:16:51,277 - Epoch: [158][  296/  296]    Overall Loss 0.693859    Objective Loss 0.693859    Top1 73.770492    Top5 95.081967    LR 0.000020    Time 0.193588    
2024-04-23 20:16:51,466 - --- validate (epoch=158)-----------
2024-04-23 20:16:51,467 - 3925 samples (32 per mini-batch)
2024-04-23 20:17:13,373 - Epoch: [158][  100/  123]    Loss 0.667794    Top1 77.906250    Top5 97.593750    
2024-04-23 20:17:17,941 - Epoch: [158][  123/  123]    Loss 0.663149    Top1 78.318471    Top5 97.554140    
2024-04-23 20:17:18,188 - ==> Top1: 78.318    Top5: 97.554    Loss: 0.663

2024-04-23 20:17:18,197 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:17:18,197 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:17:18,244 - 

2024-04-23 20:17:18,245 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:17:37,207 - Epoch: [159][  100/  296]    Overall Loss 0.684242    Objective Loss 0.684242                                        LR 0.000020    Time 0.189459    
2024-04-23 20:17:54,283 - Epoch: [159][  200/  296]    Overall Loss 0.704801    Objective Loss 0.704801                                        LR 0.000020    Time 0.180024    
2024-04-23 20:18:09,906 - Epoch: [159][  296/  296]    Overall Loss 0.702722    Objective Loss 0.702722    Top1 81.967213    Top5 98.360656    LR 0.000020    Time 0.174364    
2024-04-23 20:18:10,189 - --- validate (epoch=159)-----------
2024-04-23 20:18:10,192 - 3925 samples (32 per mini-batch)
2024-04-23 20:18:30,170 - Epoch: [159][  100/  123]    Loss 0.665629    Top1 78.656250    Top5 97.187500    
2024-04-23 20:18:34,168 - Epoch: [159][  123/  123]    Loss 0.662194    Top1 78.496815    Top5 97.401274    
2024-04-23 20:18:34,375 - ==> Top1: 78.497    Top5: 97.401    Loss: 0.662

2024-04-23 20:18:34,379 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:18:34,380 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:18:34,408 - 

2024-04-23 20:18:34,409 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:18:56,055 - Epoch: [160][  100/  296]    Overall Loss 0.722596    Objective Loss 0.722596                                        LR 0.000020    Time 0.216290    
2024-04-23 20:19:12,149 - Epoch: [160][  200/  296]    Overall Loss 0.701931    Objective Loss 0.701931                                        LR 0.000020    Time 0.188533    
2024-04-23 20:19:29,004 - Epoch: [160][  296/  296]    Overall Loss 0.695846    Objective Loss 0.695846    Top1 77.049180    Top5 98.360656    LR 0.000020    Time 0.184278    
2024-04-23 20:19:29,306 - --- validate (epoch=160)-----------
2024-04-23 20:19:29,306 - 3925 samples (32 per mini-batch)
2024-04-23 20:19:51,526 - Epoch: [160][  100/  123]    Loss 0.667391    Top1 78.500000    Top5 97.250000    
2024-04-23 20:19:55,782 - Epoch: [160][  123/  123]    Loss 0.664143    Top1 78.598726    Top5 97.299363    
2024-04-23 20:19:55,995 - ==> Top1: 78.599    Top5: 97.299    Loss: 0.664

2024-04-23 20:19:56,005 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:19:56,006 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:19:56,053 - 

2024-04-23 20:19:56,054 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:20:17,734 - Epoch: [161][  100/  296]    Overall Loss 0.712731    Objective Loss 0.712731                                        LR 0.000020    Time 0.216625    
2024-04-23 20:20:36,815 - Epoch: [161][  200/  296]    Overall Loss 0.715104    Objective Loss 0.715104                                        LR 0.000020    Time 0.203628    
2024-04-23 20:20:55,801 - Epoch: [161][  296/  296]    Overall Loss 0.719537    Objective Loss 0.719537    Top1 72.131148    Top5 98.360656    LR 0.000020    Time 0.201683    
2024-04-23 20:20:56,005 - --- validate (epoch=161)-----------
2024-04-23 20:20:56,006 - 3925 samples (32 per mini-batch)
2024-04-23 20:21:15,165 - Epoch: [161][  100/  123]    Loss 0.658399    Top1 79.031250    Top5 97.437500    
2024-04-23 20:21:19,477 - Epoch: [161][  123/  123]    Loss 0.661336    Top1 78.675159    Top5 97.375796    
2024-04-23 20:21:19,739 - ==> Top1: 78.675    Top5: 97.376    Loss: 0.661

2024-04-23 20:21:19,749 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:21:19,749 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:21:19,802 - 

2024-04-23 20:21:19,803 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:21:40,132 - Epoch: [162][  100/  296]    Overall Loss 0.675919    Objective Loss 0.675919                                        LR 0.000020    Time 0.203109    
2024-04-23 20:21:57,585 - Epoch: [162][  200/  296]    Overall Loss 0.679360    Objective Loss 0.679360                                        LR 0.000020    Time 0.188723    
2024-04-23 20:22:18,695 - Epoch: [162][  296/  296]    Overall Loss 0.690026    Objective Loss 0.690026    Top1 80.327869    Top5 98.360656    LR 0.000020    Time 0.198786    
2024-04-23 20:22:18,922 - --- validate (epoch=162)-----------
2024-04-23 20:22:18,923 - 3925 samples (32 per mini-batch)
2024-04-23 20:22:41,129 - Epoch: [162][  100/  123]    Loss 0.663575    Top1 78.562500    Top5 97.218750    
2024-04-23 20:22:44,658 - Epoch: [162][  123/  123]    Loss 0.662167    Top1 78.496815    Top5 97.273885    
2024-04-23 20:22:44,968 - ==> Top1: 78.497    Top5: 97.274    Loss: 0.662

2024-04-23 20:22:44,973 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:22:44,973 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:22:45,012 - 

2024-04-23 20:22:45,013 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:23:06,510 - Epoch: [163][  100/  296]    Overall Loss 0.683292    Objective Loss 0.683292                                        LR 0.000020    Time 0.214798    
2024-04-23 20:23:24,942 - Epoch: [163][  200/  296]    Overall Loss 0.683430    Objective Loss 0.683430                                        LR 0.000020    Time 0.199472    
2024-04-23 20:23:42,099 - Epoch: [163][  296/  296]    Overall Loss 0.684531    Objective Loss 0.684531    Top1 72.131148    Top5 95.081967    LR 0.000020    Time 0.192688    
2024-04-23 20:23:42,447 - --- validate (epoch=163)-----------
2024-04-23 20:23:42,447 - 3925 samples (32 per mini-batch)
2024-04-23 20:24:02,771 - Epoch: [163][  100/  123]    Loss 0.667356    Top1 78.687500    Top5 97.437500    
2024-04-23 20:24:07,359 - Epoch: [163][  123/  123]    Loss 0.665985    Top1 78.751592    Top5 97.401274    
2024-04-23 20:24:07,644 - ==> Top1: 78.752    Top5: 97.401    Loss: 0.666

2024-04-23 20:24:07,653 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:24:07,654 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:24:07,720 - 

2024-04-23 20:24:07,721 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:24:27,765 - Epoch: [164][  100/  296]    Overall Loss 0.676685    Objective Loss 0.676685                                        LR 0.000020    Time 0.200260    
2024-04-23 20:24:45,066 - Epoch: [164][  200/  296]    Overall Loss 0.686543    Objective Loss 0.686543                                        LR 0.000020    Time 0.186551    
2024-04-23 20:25:03,620 - Epoch: [164][  296/  296]    Overall Loss 0.687829    Objective Loss 0.687829    Top1 78.688525    Top5 98.360656    LR 0.000020    Time 0.188678    
2024-04-23 20:25:03,828 - --- validate (epoch=164)-----------
2024-04-23 20:25:03,829 - 3925 samples (32 per mini-batch)
2024-04-23 20:25:24,482 - Epoch: [164][  100/  123]    Loss 0.672419    Top1 78.718750    Top5 97.531250    
2024-04-23 20:25:29,534 - Epoch: [164][  123/  123]    Loss 0.665532    Top1 78.904459    Top5 97.401274    
2024-04-23 20:25:29,815 - ==> Top1: 78.904    Top5: 97.401    Loss: 0.666

2024-04-23 20:25:29,825 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:25:29,825 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:25:29,872 - 

2024-04-23 20:25:29,872 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:25:49,305 - Epoch: [165][  100/  296]    Overall Loss 0.680207    Objective Loss 0.680207                                        LR 0.000020    Time 0.194166    
2024-04-23 20:26:06,205 - Epoch: [165][  200/  296]    Overall Loss 0.682937    Objective Loss 0.682937                                        LR 0.000020    Time 0.181497    
2024-04-23 20:26:21,910 - Epoch: [165][  296/  296]    Overall Loss 0.678826    Objective Loss 0.678826    Top1 81.967213    Top5 95.081967    LR 0.000020    Time 0.175641    
2024-04-23 20:26:22,220 - --- validate (epoch=165)-----------
2024-04-23 20:26:22,221 - 3925 samples (32 per mini-batch)
2024-04-23 20:26:42,172 - Epoch: [165][  100/  123]    Loss 0.658565    Top1 79.062500    Top5 97.375000    
2024-04-23 20:26:46,713 - Epoch: [165][  123/  123]    Loss 0.661195    Top1 78.955414    Top5 97.375796    
2024-04-23 20:26:46,995 - ==> Top1: 78.955    Top5: 97.376    Loss: 0.661

2024-04-23 20:26:47,002 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:26:47,003 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:26:47,045 - 

2024-04-23 20:26:47,046 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:27:08,963 - Epoch: [166][  100/  296]    Overall Loss 0.707186    Objective Loss 0.707186                                        LR 0.000020    Time 0.218998    
2024-04-23 20:27:27,609 - Epoch: [166][  200/  296]    Overall Loss 0.698413    Objective Loss 0.698413                                        LR 0.000020    Time 0.202653    
2024-04-23 20:27:46,487 - Epoch: [166][  296/  296]    Overall Loss 0.690224    Objective Loss 0.690224    Top1 73.770492    Top5 98.360656    LR 0.000020    Time 0.200668    
2024-04-23 20:27:46,774 - --- validate (epoch=166)-----------
2024-04-23 20:27:46,775 - 3925 samples (32 per mini-batch)
2024-04-23 20:28:02,549 - Epoch: [166][  100/  123]    Loss 0.650502    Top1 78.937500    Top5 97.531250    
2024-04-23 20:28:06,264 - Epoch: [166][  123/  123]    Loss 0.663040    Top1 78.496815    Top5 97.324841    
2024-04-23 20:28:06,560 - ==> Top1: 78.497    Top5: 97.325    Loss: 0.663

2024-04-23 20:28:06,570 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:28:06,570 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:28:06,617 - 

2024-04-23 20:28:06,617 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:28:25,771 - Epoch: [167][  100/  296]    Overall Loss 0.704175    Objective Loss 0.704175                                        LR 0.000020    Time 0.191365    
2024-04-23 20:28:41,245 - Epoch: [167][  200/  296]    Overall Loss 0.690573    Objective Loss 0.690573                                        LR 0.000020    Time 0.172956    
2024-04-23 20:28:55,413 - Epoch: [167][  296/  296]    Overall Loss 0.690713    Objective Loss 0.690713    Top1 81.967213    Top5 96.721311    LR 0.000020    Time 0.164679    
2024-04-23 20:28:55,700 - --- validate (epoch=167)-----------
2024-04-23 20:28:55,701 - 3925 samples (32 per mini-batch)
2024-04-23 20:29:09,929 - Epoch: [167][  100/  123]    Loss 0.665253    Top1 78.156250    Top5 97.531250    
2024-04-23 20:29:12,496 - Epoch: [167][  123/  123]    Loss 0.662236    Top1 78.394904    Top5 97.375796    
2024-04-23 20:29:12,712 - ==> Top1: 78.395    Top5: 97.376    Loss: 0.662

2024-04-23 20:29:12,718 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:29:12,719 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:29:12,760 - 

2024-04-23 20:29:12,761 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:29:27,855 - Epoch: [168][  100/  296]    Overall Loss 0.709049    Objective Loss 0.709049                                        LR 0.000020    Time 0.150788    
2024-04-23 20:29:43,283 - Epoch: [168][  200/  296]    Overall Loss 0.707693    Objective Loss 0.707693                                        LR 0.000020    Time 0.152445    
2024-04-23 20:29:57,539 - Epoch: [168][  296/  296]    Overall Loss 0.701221    Objective Loss 0.701221    Top1 86.885246    Top5 100.000000    LR 0.000020    Time 0.151111    
2024-04-23 20:29:57,775 - --- validate (epoch=168)-----------
2024-04-23 20:29:57,776 - 3925 samples (32 per mini-batch)
2024-04-23 20:30:17,148 - Epoch: [168][  100/  123]    Loss 0.660819    Top1 78.718750    Top5 97.250000    
2024-04-23 20:30:20,346 - Epoch: [168][  123/  123]    Loss 0.661619    Top1 78.496815    Top5 97.426752    
2024-04-23 20:30:20,644 - ==> Top1: 78.497    Top5: 97.427    Loss: 0.662

2024-04-23 20:30:20,653 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:30:20,653 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:30:20,700 - 

2024-04-23 20:30:20,701 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:30:40,052 - Epoch: [169][  100/  296]    Overall Loss 0.713885    Objective Loss 0.713885                                        LR 0.000020    Time 0.193337    
2024-04-23 20:30:55,132 - Epoch: [169][  200/  296]    Overall Loss 0.689686    Objective Loss 0.689686                                        LR 0.000020    Time 0.171992    
2024-04-23 20:31:08,383 - Epoch: [169][  296/  296]    Overall Loss 0.690965    Objective Loss 0.690965    Top1 78.688525    Top5 95.081967    LR 0.000020    Time 0.160927    
2024-04-23 20:31:08,606 - --- validate (epoch=169)-----------
2024-04-23 20:31:08,607 - 3925 samples (32 per mini-batch)
2024-04-23 20:31:28,452 - Epoch: [169][  100/  123]    Loss 0.678708    Top1 78.281250    Top5 97.312500    
2024-04-23 20:31:32,380 - Epoch: [169][  123/  123]    Loss 0.660403    Top1 78.726115    Top5 97.452229    
2024-04-23 20:31:32,663 - ==> Top1: 78.726    Top5: 97.452    Loss: 0.660

2024-04-23 20:31:32,672 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:31:32,673 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:31:32,716 - 

2024-04-23 20:31:32,717 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:31:50,263 - Epoch: [170][  100/  296]    Overall Loss 0.692715    Objective Loss 0.692715                                        LR 0.000020    Time 0.175295    
2024-04-23 20:32:06,798 - Epoch: [170][  200/  296]    Overall Loss 0.696460    Objective Loss 0.696460                                        LR 0.000020    Time 0.170239    
2024-04-23 20:32:19,487 - Epoch: [170][  296/  296]    Overall Loss 0.699292    Objective Loss 0.699292    Top1 73.770492    Top5 100.000000    LR 0.000020    Time 0.157844    
2024-04-23 20:32:19,766 - --- validate (epoch=170)-----------
2024-04-23 20:32:19,766 - 3925 samples (32 per mini-batch)
2024-04-23 20:32:39,215 - Epoch: [170][  100/  123]    Loss 0.672608    Top1 78.250000    Top5 97.375000    
2024-04-23 20:32:42,779 - Epoch: [170][  123/  123]    Loss 0.658764    Top1 78.777070    Top5 97.477707    
2024-04-23 20:32:42,911 - ==> Top1: 78.777    Top5: 97.478    Loss: 0.659

2024-04-23 20:32:42,916 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:32:42,917 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:32:42,955 - 

2024-04-23 20:32:42,956 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:32:56,917 - Epoch: [171][  100/  296]    Overall Loss 0.677626    Objective Loss 0.677626                                        LR 0.000020    Time 0.139448    
2024-04-23 20:33:09,005 - Epoch: [171][  200/  296]    Overall Loss 0.689945    Objective Loss 0.689945                                        LR 0.000020    Time 0.130090    
2024-04-23 20:33:19,553 - Epoch: [171][  296/  296]    Overall Loss 0.692153    Objective Loss 0.692153    Top1 70.491803    Top5 100.000000    LR 0.000020    Time 0.123492    
2024-04-23 20:33:19,799 - --- validate (epoch=171)-----------
2024-04-23 20:33:19,800 - 3925 samples (32 per mini-batch)
2024-04-23 20:33:38,939 - Epoch: [171][  100/  123]    Loss 0.657686    Top1 78.750000    Top5 97.593750    
2024-04-23 20:33:43,332 - Epoch: [171][  123/  123]    Loss 0.663041    Top1 78.624204    Top5 97.528662    
2024-04-23 20:33:43,573 - ==> Top1: 78.624    Top5: 97.529    Loss: 0.663

2024-04-23 20:33:43,578 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:33:43,579 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:33:43,618 - 

2024-04-23 20:33:43,619 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:34:03,112 - Epoch: [172][  100/  296]    Overall Loss 0.687896    Objective Loss 0.687896                                        LR 0.000020    Time 0.194756    
2024-04-23 20:34:12,612 - Epoch: [172][  200/  296]    Overall Loss 0.685265    Objective Loss 0.685265                                        LR 0.000020    Time 0.144809    
2024-04-23 20:34:27,695 - Epoch: [172][  296/  296]    Overall Loss 0.683771    Objective Loss 0.683771    Top1 73.770492    Top5 93.442623    LR 0.000020    Time 0.148758    
2024-04-23 20:34:27,909 - --- validate (epoch=172)-----------
2024-04-23 20:34:27,909 - 3925 samples (32 per mini-batch)
2024-04-23 20:34:44,167 - Epoch: [172][  100/  123]    Loss 0.658903    Top1 78.750000    Top5 97.437500    
2024-04-23 20:34:46,921 - Epoch: [172][  123/  123]    Loss 0.661525    Top1 78.726115    Top5 97.477707    
2024-04-23 20:34:47,233 - ==> Top1: 78.726    Top5: 97.478    Loss: 0.662

2024-04-23 20:34:47,239 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:34:47,240 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:34:47,279 - 

2024-04-23 20:34:47,279 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:34:59,424 - Epoch: [173][  100/  296]    Overall Loss 0.705106    Objective Loss 0.705106                                        LR 0.000020    Time 0.121306    
2024-04-23 20:35:12,814 - Epoch: [173][  200/  296]    Overall Loss 0.698464    Objective Loss 0.698464                                        LR 0.000020    Time 0.127520    
2024-04-23 20:35:24,914 - Epoch: [173][  296/  296]    Overall Loss 0.692861    Objective Loss 0.692861    Top1 75.409836    Top5 98.360656    LR 0.000020    Time 0.126993    
2024-04-23 20:35:25,144 - --- validate (epoch=173)-----------
2024-04-23 20:35:25,145 - 3925 samples (32 per mini-batch)
2024-04-23 20:35:39,709 - Epoch: [173][  100/  123]    Loss 0.658486    Top1 78.812500    Top5 97.250000    
2024-04-23 20:35:42,406 - Epoch: [173][  123/  123]    Loss 0.662160    Top1 78.624204    Top5 97.324841    
2024-04-23 20:35:42,636 - ==> Top1: 78.624    Top5: 97.325    Loss: 0.662

2024-04-23 20:35:42,644 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:35:42,645 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:35:42,688 - 

2024-04-23 20:35:42,688 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:36:00,742 - Epoch: [174][  100/  296]    Overall Loss 0.686883    Objective Loss 0.686883                                        LR 0.000020    Time 0.180364    
2024-04-23 20:36:15,915 - Epoch: [174][  200/  296]    Overall Loss 0.677864    Objective Loss 0.677864                                        LR 0.000020    Time 0.165960    
2024-04-23 20:36:31,700 - Epoch: [174][  296/  296]    Overall Loss 0.682742    Objective Loss 0.682742    Top1 75.409836    Top5 95.081967    LR 0.000020    Time 0.165412    
2024-04-23 20:36:31,949 - --- validate (epoch=174)-----------
2024-04-23 20:36:31,949 - 3925 samples (32 per mini-batch)
2024-04-23 20:36:48,827 - Epoch: [174][  100/  123]    Loss 0.665614    Top1 78.562500    Top5 97.593750    
2024-04-23 20:36:52,207 - Epoch: [174][  123/  123]    Loss 0.662392    Top1 78.547771    Top5 97.452229    
2024-04-23 20:36:52,440 - ==> Top1: 78.548    Top5: 97.452    Loss: 0.662

2024-04-23 20:36:52,449 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:36:52,450 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:36:52,494 - 

2024-04-23 20:36:52,495 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:37:12,459 - Epoch: [175][  100/  296]    Overall Loss 0.697856    Objective Loss 0.697856                                        LR 0.000020    Time 0.199467    
2024-04-23 20:37:23,941 - Epoch: [175][  200/  296]    Overall Loss 0.691177    Objective Loss 0.691177                                        LR 0.000020    Time 0.157064    
2024-04-23 20:37:34,827 - Epoch: [175][  296/  296]    Overall Loss 0.692703    Objective Loss 0.692703    Top1 75.409836    Top5 98.360656    LR 0.000020    Time 0.142847    
2024-04-23 20:37:35,038 - --- validate (epoch=175)-----------
2024-04-23 20:37:35,039 - 3925 samples (32 per mini-batch)
2024-04-23 20:37:51,864 - Epoch: [175][  100/  123]    Loss 0.638916    Top1 79.062500    Top5 97.656250    
2024-04-23 20:37:55,232 - Epoch: [175][  123/  123]    Loss 0.658961    Top1 78.547771    Top5 97.554140    
2024-04-23 20:37:55,439 - ==> Top1: 78.548    Top5: 97.554    Loss: 0.659

2024-04-23 20:37:55,444 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:37:55,445 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:37:55,483 - 

2024-04-23 20:37:55,484 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:38:13,258 - Epoch: [176][  100/  296]    Overall Loss 0.674216    Objective Loss 0.674216                                        LR 0.000020    Time 0.177569    
2024-04-23 20:38:31,554 - Epoch: [176][  200/  296]    Overall Loss 0.664322    Objective Loss 0.664322                                        LR 0.000020    Time 0.180176    
2024-04-23 20:38:49,003 - Epoch: [176][  296/  296]    Overall Loss 0.664666    Objective Loss 0.664666    Top1 73.770492    Top5 98.360656    LR 0.000020    Time 0.180637    
2024-04-23 20:38:49,219 - --- validate (epoch=176)-----------
2024-04-23 20:38:49,220 - 3925 samples (32 per mini-batch)
2024-04-23 20:39:10,298 - Epoch: [176][  100/  123]    Loss 0.679660    Top1 78.250000    Top5 97.593750    
2024-04-23 20:39:14,961 - Epoch: [176][  123/  123]    Loss 0.662964    Top1 78.573248    Top5 97.528662    
2024-04-23 20:39:15,193 - ==> Top1: 78.573    Top5: 97.529    Loss: 0.663

2024-04-23 20:39:15,199 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:39:15,199 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:39:15,240 - 

2024-04-23 20:39:15,240 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:39:34,420 - Epoch: [177][  100/  296]    Overall Loss 0.682561    Objective Loss 0.682561                                        LR 0.000020    Time 0.191633    
2024-04-23 20:39:52,452 - Epoch: [177][  200/  296]    Overall Loss 0.689520    Objective Loss 0.689520                                        LR 0.000020    Time 0.185900    
2024-04-23 20:40:07,620 - Epoch: [177][  296/  296]    Overall Loss 0.696857    Objective Loss 0.696857    Top1 78.688525    Top5 96.721311    LR 0.000020    Time 0.176803    
2024-04-23 20:40:07,842 - --- validate (epoch=177)-----------
2024-04-23 20:40:07,843 - 3925 samples (32 per mini-batch)
2024-04-23 20:40:30,894 - Epoch: [177][  100/  123]    Loss 0.662393    Top1 78.250000    Top5 97.500000    
2024-04-23 20:40:35,565 - Epoch: [177][  123/  123]    Loss 0.661453    Top1 78.522293    Top5 97.375796    
2024-04-23 20:40:35,864 - ==> Top1: 78.522    Top5: 97.376    Loss: 0.661

2024-04-23 20:40:35,869 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:40:35,870 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:40:35,908 - 

2024-04-23 20:40:35,908 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:40:56,532 - Epoch: [178][  100/  296]    Overall Loss 0.695781    Objective Loss 0.695781                                        LR 0.000020    Time 0.206066    
2024-04-23 20:41:14,888 - Epoch: [178][  200/  296]    Overall Loss 0.688901    Objective Loss 0.688901                                        LR 0.000020    Time 0.194726    
2024-04-23 20:41:32,713 - Epoch: [178][  296/  296]    Overall Loss 0.681822    Objective Loss 0.681822    Top1 73.770492    Top5 100.000000    LR 0.000020    Time 0.191738    
2024-04-23 20:41:32,930 - --- validate (epoch=178)-----------
2024-04-23 20:41:32,931 - 3925 samples (32 per mini-batch)
2024-04-23 20:41:54,668 - Epoch: [178][  100/  123]    Loss 0.671646    Top1 78.031250    Top5 97.593750    
2024-04-23 20:41:59,795 - Epoch: [178][  123/  123]    Loss 0.666844    Top1 78.318471    Top5 97.452229    
2024-04-23 20:41:59,982 - ==> Top1: 78.318    Top5: 97.452    Loss: 0.667

2024-04-23 20:41:59,991 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:41:59,992 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:42:00,033 - 

2024-04-23 20:42:00,034 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:42:18,821 - Epoch: [179][  100/  296]    Overall Loss 0.668736    Objective Loss 0.668736                                        LR 0.000020    Time 0.187703    
2024-04-23 20:42:35,850 - Epoch: [179][  200/  296]    Overall Loss 0.682415    Objective Loss 0.682415                                        LR 0.000020    Time 0.178920    
2024-04-23 20:42:52,192 - Epoch: [179][  296/  296]    Overall Loss 0.681897    Objective Loss 0.681897    Top1 75.409836    Top5 95.081967    LR 0.000020    Time 0.176045    
2024-04-23 20:42:52,422 - --- validate (epoch=179)-----------
2024-04-23 20:42:52,423 - 3925 samples (32 per mini-batch)
2024-04-23 20:43:14,049 - Epoch: [179][  100/  123]    Loss 0.670382    Top1 78.250000    Top5 97.562500    
2024-04-23 20:43:18,445 - Epoch: [179][  123/  123]    Loss 0.658883    Top1 78.700637    Top5 97.477707    
2024-04-23 20:43:18,703 - ==> Top1: 78.701    Top5: 97.478    Loss: 0.659

2024-04-23 20:43:18,714 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:43:18,715 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:43:18,769 - 

2024-04-23 20:43:18,770 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:43:38,269 - Epoch: [180][  100/  296]    Overall Loss 0.688276    Objective Loss 0.688276                                        LR 0.000020    Time 0.194819    
2024-04-23 20:44:00,419 - Epoch: [180][  200/  296]    Overall Loss 0.695562    Objective Loss 0.695562                                        LR 0.000020    Time 0.208067    
2024-04-23 20:44:21,542 - Epoch: [180][  296/  296]    Overall Loss 0.689836    Objective Loss 0.689836    Top1 77.049180    Top5 95.081967    LR 0.000020    Time 0.211897    
2024-04-23 20:44:21,766 - --- validate (epoch=180)-----------
2024-04-23 20:44:21,766 - 3925 samples (32 per mini-batch)
2024-04-23 20:44:44,009 - Epoch: [180][  100/  123]    Loss 0.659712    Top1 78.031250    Top5 97.500000    
2024-04-23 20:44:48,256 - Epoch: [180][  123/  123]    Loss 0.661120    Top1 78.292994    Top5 97.528662    
2024-04-23 20:44:48,505 - ==> Top1: 78.293    Top5: 97.529    Loss: 0.661

2024-04-23 20:44:48,514 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:44:48,515 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:44:48,556 - 

2024-04-23 20:44:48,557 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:45:10,024 - Epoch: [181][  100/  296]    Overall Loss 0.706570    Objective Loss 0.706570                                        LR 0.000020    Time 0.214507    
2024-04-23 20:45:28,081 - Epoch: [181][  200/  296]    Overall Loss 0.688189    Objective Loss 0.688189                                        LR 0.000020    Time 0.197465    
2024-04-23 20:45:46,325 - Epoch: [181][  296/  296]    Overall Loss 0.686433    Objective Loss 0.686433    Top1 73.770492    Top5 96.721311    LR 0.000020    Time 0.195008    
2024-04-23 20:45:46,516 - --- validate (epoch=181)-----------
2024-04-23 20:45:46,517 - 3925 samples (32 per mini-batch)
2024-04-23 20:46:12,047 - Epoch: [181][  100/  123]    Loss 0.666855    Top1 78.656250    Top5 97.500000    
2024-04-23 20:46:15,899 - Epoch: [181][  123/  123]    Loss 0.665205    Top1 78.624204    Top5 97.554140    
2024-04-23 20:46:16,139 - ==> Top1: 78.624    Top5: 97.554    Loss: 0.665

2024-04-23 20:46:16,148 - ==> Best [Top1: 79.185   Top5: 97.427   Sparsity:0.00   Params: 376752 on epoch: 155]
2024-04-23 20:46:16,148 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:46:16,209 - 

2024-04-23 20:46:16,210 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:46:36,556 - Epoch: [182][  100/  296]    Overall Loss 0.673645    Objective Loss 0.673645                                        LR 0.000020    Time 0.203272    
2024-04-23 20:46:53,255 - Epoch: [182][  200/  296]    Overall Loss 0.673871    Objective Loss 0.673871                                        LR 0.000020    Time 0.185055    
2024-04-23 20:47:08,447 - Epoch: [182][  296/  296]    Overall Loss 0.681653    Objective Loss 0.681653    Top1 86.885246    Top5 98.360656    LR 0.000020    Time 0.176312    
2024-04-23 20:47:08,771 - --- validate (epoch=182)-----------
2024-04-23 20:47:08,772 - 3925 samples (32 per mini-batch)
2024-04-23 20:47:30,234 - Epoch: [182][  100/  123]    Loss 0.661100    Top1 78.937500    Top5 97.593750    
2024-04-23 20:47:35,561 - Epoch: [182][  123/  123]    Loss 0.655468    Top1 79.210191    Top5 97.579618    
2024-04-23 20:47:35,807 - ==> Top1: 79.210    Top5: 97.580    Loss: 0.655

2024-04-23 20:47:35,817 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 20:47:35,818 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:47:35,870 - 

2024-04-23 20:47:35,871 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:47:52,139 - Epoch: [183][  100/  296]    Overall Loss 0.670167    Objective Loss 0.670167                                        LR 0.000020    Time 0.162520    
2024-04-23 20:48:08,935 - Epoch: [183][  200/  296]    Overall Loss 0.681597    Objective Loss 0.681597                                        LR 0.000020    Time 0.165163    
2024-04-23 20:48:26,351 - Epoch: [183][  296/  296]    Overall Loss 0.684720    Objective Loss 0.684720    Top1 77.049180    Top5 96.721311    LR 0.000020    Time 0.170374    
2024-04-23 20:48:26,546 - --- validate (epoch=183)-----------
2024-04-23 20:48:26,547 - 3925 samples (32 per mini-batch)
2024-04-23 20:48:47,809 - Epoch: [183][  100/  123]    Loss 0.669736    Top1 78.218750    Top5 97.531250    
2024-04-23 20:48:52,519 - Epoch: [183][  123/  123]    Loss 0.662435    Top1 78.649682    Top5 97.503185    
2024-04-23 20:48:52,825 - ==> Top1: 78.650    Top5: 97.503    Loss: 0.662

2024-04-23 20:48:52,836 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 20:48:52,837 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:48:52,903 - 

2024-04-23 20:48:52,905 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:49:15,572 - Epoch: [184][  100/  296]    Overall Loss 0.650267    Objective Loss 0.650267                                        LR 0.000020    Time 0.226478    
2024-04-23 20:49:35,408 - Epoch: [184][  200/  296]    Overall Loss 0.658067    Objective Loss 0.658067                                        LR 0.000020    Time 0.212339    
2024-04-23 20:49:54,798 - Epoch: [184][  296/  296]    Overall Loss 0.665817    Objective Loss 0.665817    Top1 83.606557    Top5 98.360656    LR 0.000020    Time 0.208936    
2024-04-23 20:49:55,157 - --- validate (epoch=184)-----------
2024-04-23 20:49:55,158 - 3925 samples (32 per mini-batch)
2024-04-23 20:50:18,229 - Epoch: [184][  100/  123]    Loss 0.663975    Top1 78.906250    Top5 97.593750    
2024-04-23 20:50:22,809 - Epoch: [184][  123/  123]    Loss 0.659966    Top1 78.980892    Top5 97.630573    
2024-04-23 20:50:22,951 - ==> Top1: 78.981    Top5: 97.631    Loss: 0.660

2024-04-23 20:50:22,959 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 20:50:22,959 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:50:23,003 - 

2024-04-23 20:50:23,004 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:50:44,478 - Epoch: [185][  100/  296]    Overall Loss 0.681944    Objective Loss 0.681944                                        LR 0.000020    Time 0.214576    
2024-04-23 20:51:04,116 - Epoch: [185][  200/  296]    Overall Loss 0.675644    Objective Loss 0.675644                                        LR 0.000020    Time 0.205388    
2024-04-23 20:51:20,046 - Epoch: [185][  296/  296]    Overall Loss 0.676888    Objective Loss 0.676888    Top1 78.688525    Top5 98.360656    LR 0.000020    Time 0.192535    
2024-04-23 20:51:20,391 - --- validate (epoch=185)-----------
2024-04-23 20:51:20,392 - 3925 samples (32 per mini-batch)
2024-04-23 20:51:43,586 - Epoch: [185][  100/  123]    Loss 0.666847    Top1 78.562500    Top5 97.250000    
2024-04-23 20:51:47,688 - Epoch: [185][  123/  123]    Loss 0.661016    Top1 78.700637    Top5 97.375796    
2024-04-23 20:51:47,958 - ==> Top1: 78.701    Top5: 97.376    Loss: 0.661

2024-04-23 20:51:47,969 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 20:51:47,969 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:51:48,012 - 

2024-04-23 20:51:48,013 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:52:07,075 - Epoch: [186][  100/  296]    Overall Loss 0.676287    Objective Loss 0.676287                                        LR 0.000020    Time 0.190445    
2024-04-23 20:52:24,228 - Epoch: [186][  200/  296]    Overall Loss 0.680480    Objective Loss 0.680480                                        LR 0.000020    Time 0.180907    
2024-04-23 20:52:41,034 - Epoch: [186][  296/  296]    Overall Loss 0.674683    Objective Loss 0.674683    Top1 70.491803    Top5 96.721311    LR 0.000020    Time 0.178963    
2024-04-23 20:52:41,339 - --- validate (epoch=186)-----------
2024-04-23 20:52:41,340 - 3925 samples (32 per mini-batch)
2024-04-23 20:53:04,110 - Epoch: [186][  100/  123]    Loss 0.654058    Top1 78.968750    Top5 97.375000    
2024-04-23 20:53:08,604 - Epoch: [186][  123/  123]    Loss 0.660894    Top1 78.751592    Top5 97.375796    
2024-04-23 20:53:08,849 - ==> Top1: 78.752    Top5: 97.376    Loss: 0.661

2024-04-23 20:53:08,859 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 20:53:08,860 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:53:08,912 - 

2024-04-23 20:53:08,912 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:53:27,848 - Epoch: [187][  100/  296]    Overall Loss 0.673654    Objective Loss 0.673654                                        LR 0.000020    Time 0.189182    
2024-04-23 20:53:46,616 - Epoch: [187][  200/  296]    Overall Loss 0.698899    Objective Loss 0.698899                                        LR 0.000020    Time 0.188350    
2024-04-23 20:54:03,650 - Epoch: [187][  296/  296]    Overall Loss 0.686415    Objective Loss 0.686415    Top1 73.770492    Top5 95.081967    LR 0.000020    Time 0.184764    
2024-04-23 20:54:03,888 - --- validate (epoch=187)-----------
2024-04-23 20:54:03,889 - 3925 samples (32 per mini-batch)
2024-04-23 20:54:22,678 - Epoch: [187][  100/  123]    Loss 0.648134    Top1 79.093750    Top5 97.656250    
2024-04-23 20:54:27,073 - Epoch: [187][  123/  123]    Loss 0.660277    Top1 78.675159    Top5 97.477707    
2024-04-23 20:54:27,311 - ==> Top1: 78.675    Top5: 97.478    Loss: 0.660

2024-04-23 20:54:27,322 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 20:54:27,322 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:54:27,368 - 

2024-04-23 20:54:27,369 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:54:48,695 - Epoch: [188][  100/  296]    Overall Loss 0.671409    Objective Loss 0.671409                                        LR 0.000020    Time 0.213059    
2024-04-23 20:55:07,417 - Epoch: [188][  200/  296]    Overall Loss 0.684718    Objective Loss 0.684718                                        LR 0.000020    Time 0.200055    
2024-04-23 20:55:23,845 - Epoch: [188][  296/  296]    Overall Loss 0.682313    Objective Loss 0.682313    Top1 78.688525    Top5 96.721311    LR 0.000020    Time 0.190624    
2024-04-23 20:55:24,111 - --- validate (epoch=188)-----------
2024-04-23 20:55:24,112 - 3925 samples (32 per mini-batch)
2024-04-23 20:55:45,677 - Epoch: [188][  100/  123]    Loss 0.660147    Top1 78.375000    Top5 97.312500    
2024-04-23 20:55:49,827 - Epoch: [188][  123/  123]    Loss 0.659993    Top1 78.649682    Top5 97.299363    
2024-04-23 20:55:49,975 - ==> Top1: 78.650    Top5: 97.299    Loss: 0.660

2024-04-23 20:55:49,984 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 20:55:49,984 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:55:50,037 - 

2024-04-23 20:55:50,037 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:56:10,742 - Epoch: [189][  100/  296]    Overall Loss 0.702088    Objective Loss 0.702088                                        LR 0.000020    Time 0.206867    
2024-04-23 20:56:31,942 - Epoch: [189][  200/  296]    Overall Loss 0.681788    Objective Loss 0.681788                                        LR 0.000020    Time 0.209347    
2024-04-23 20:56:47,850 - Epoch: [189][  296/  296]    Overall Loss 0.674493    Objective Loss 0.674493    Top1 80.327869    Top5 100.000000    LR 0.000020    Time 0.195142    
2024-04-23 20:56:48,168 - --- validate (epoch=189)-----------
2024-04-23 20:56:48,169 - 3925 samples (32 per mini-batch)
2024-04-23 20:57:09,589 - Epoch: [189][  100/  123]    Loss 0.675532    Top1 78.375000    Top5 97.343750    
2024-04-23 20:57:12,804 - Epoch: [189][  123/  123]    Loss 0.661256    Top1 78.955414    Top5 97.426752    
2024-04-23 20:57:13,010 - ==> Top1: 78.955    Top5: 97.427    Loss: 0.661

2024-04-23 20:57:13,015 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 20:57:13,015 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:57:13,055 - 

2024-04-23 20:57:13,055 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:57:33,317 - Epoch: [190][  100/  296]    Overall Loss 0.677772    Objective Loss 0.677772                                        LR 0.000020    Time 0.202442    
2024-04-23 20:57:50,760 - Epoch: [190][  200/  296]    Overall Loss 0.695630    Objective Loss 0.695630                                        LR 0.000020    Time 0.188345    
2024-04-23 20:58:06,000 - Epoch: [190][  296/  296]    Overall Loss 0.686555    Objective Loss 0.686555    Top1 77.049180    Top5 96.721311    LR 0.000020    Time 0.178694    
2024-04-23 20:58:06,343 - --- validate (epoch=190)-----------
2024-04-23 20:58:06,344 - 3925 samples (32 per mini-batch)
2024-04-23 20:58:27,870 - Epoch: [190][  100/  123]    Loss 0.672556    Top1 78.906250    Top5 97.593750    
2024-04-23 20:58:31,269 - Epoch: [190][  123/  123]    Loss 0.662576    Top1 79.057325    Top5 97.579618    
2024-04-23 20:58:31,436 - ==> Top1: 79.057    Top5: 97.580    Loss: 0.663

2024-04-23 20:58:31,444 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 20:58:31,445 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:58:31,487 - 

2024-04-23 20:58:31,488 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 20:58:52,628 - Epoch: [191][  100/  296]    Overall Loss 0.661312    Objective Loss 0.661312                                        LR 0.000020    Time 0.211229    
2024-04-23 20:59:10,184 - Epoch: [191][  200/  296]    Overall Loss 0.656556    Objective Loss 0.656556                                        LR 0.000020    Time 0.193307    
2024-04-23 20:59:26,864 - Epoch: [191][  296/  296]    Overall Loss 0.673983    Objective Loss 0.673983    Top1 73.770492    Top5 100.000000    LR 0.000020    Time 0.186914    
2024-04-23 20:59:27,041 - --- validate (epoch=191)-----------
2024-04-23 20:59:27,041 - 3925 samples (32 per mini-batch)
2024-04-23 20:59:48,384 - Epoch: [191][  100/  123]    Loss 0.649314    Top1 78.687500    Top5 97.718750    
2024-04-23 20:59:52,911 - Epoch: [191][  123/  123]    Loss 0.660194    Top1 78.547771    Top5 97.528662    
2024-04-23 20:59:53,214 - ==> Top1: 78.548    Top5: 97.529    Loss: 0.660

2024-04-23 20:59:53,220 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 20:59:53,221 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 20:59:53,272 - 

2024-04-23 20:59:53,273 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:00:13,362 - Epoch: [192][  100/  296]    Overall Loss 0.709994    Objective Loss 0.709994                                        LR 0.000020    Time 0.200705    
2024-04-23 21:00:33,837 - Epoch: [192][  200/  296]    Overall Loss 0.706057    Objective Loss 0.706057                                        LR 0.000020    Time 0.202644    
2024-04-23 21:00:51,783 - Epoch: [192][  296/  296]    Overall Loss 0.697689    Objective Loss 0.697689    Top1 81.967213    Top5 100.000000    LR 0.000020    Time 0.197500    
2024-04-23 21:00:51,963 - --- validate (epoch=192)-----------
2024-04-23 21:00:51,964 - 3925 samples (32 per mini-batch)
2024-04-23 21:01:14,277 - Epoch: [192][  100/  123]    Loss 0.664183    Top1 78.625000    Top5 97.468750    
2024-04-23 21:01:17,541 - Epoch: [192][  123/  123]    Loss 0.664810    Top1 78.496815    Top5 97.452229    
2024-04-23 21:01:17,817 - ==> Top1: 78.497    Top5: 97.452    Loss: 0.665

2024-04-23 21:01:17,826 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:01:17,827 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:01:17,872 - 

2024-04-23 21:01:17,872 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:01:36,871 - Epoch: [193][  100/  296]    Overall Loss 0.680133    Objective Loss 0.680133                                        LR 0.000020    Time 0.189805    
2024-04-23 21:01:54,199 - Epoch: [193][  200/  296]    Overall Loss 0.680414    Objective Loss 0.680414                                        LR 0.000020    Time 0.181463    
2024-04-23 21:02:08,498 - Epoch: [193][  296/  296]    Overall Loss 0.686486    Objective Loss 0.686486    Top1 78.688525    Top5 96.721311    LR 0.000020    Time 0.170866    
2024-04-23 21:02:08,731 - --- validate (epoch=193)-----------
2024-04-23 21:02:08,732 - 3925 samples (32 per mini-batch)
2024-04-23 21:02:29,672 - Epoch: [193][  100/  123]    Loss 0.651455    Top1 79.000000    Top5 97.562500    
2024-04-23 21:02:34,064 - Epoch: [193][  123/  123]    Loss 0.660620    Top1 78.598726    Top5 97.452229    
2024-04-23 21:02:34,261 - ==> Top1: 78.599    Top5: 97.452    Loss: 0.661

2024-04-23 21:02:34,271 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:02:34,272 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:02:34,321 - 

2024-04-23 21:02:34,322 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:02:58,824 - Epoch: [194][  100/  296]    Overall Loss 0.663958    Objective Loss 0.663958                                        LR 0.000020    Time 0.244832    
2024-04-23 21:03:20,986 - Epoch: [194][  200/  296]    Overall Loss 0.662860    Objective Loss 0.662860                                        LR 0.000020    Time 0.233143    
2024-04-23 21:03:42,161 - Epoch: [194][  296/  296]    Overall Loss 0.681064    Objective Loss 0.681064    Top1 68.852459    Top5 98.360656    LR 0.000020    Time 0.229012    
2024-04-23 21:03:42,321 - --- validate (epoch=194)-----------
2024-04-23 21:03:42,322 - 3925 samples (32 per mini-batch)
2024-04-23 21:04:06,038 - Epoch: [194][  100/  123]    Loss 0.650724    Top1 79.687500    Top5 97.531250    
2024-04-23 21:04:10,182 - Epoch: [194][  123/  123]    Loss 0.660341    Top1 78.878981    Top5 97.579618    
2024-04-23 21:04:10,348 - ==> Top1: 78.879    Top5: 97.580    Loss: 0.660

2024-04-23 21:04:10,356 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:04:10,356 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:04:10,396 - 

2024-04-23 21:04:10,396 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:04:29,735 - Epoch: [195][  100/  296]    Overall Loss 0.658981    Objective Loss 0.658981                                        LR 0.000020    Time 0.193219    
2024-04-23 21:04:46,164 - Epoch: [195][  200/  296]    Overall Loss 0.671914    Objective Loss 0.671914                                        LR 0.000020    Time 0.178670    
2024-04-23 21:05:03,211 - Epoch: [195][  296/  296]    Overall Loss 0.678479    Objective Loss 0.678479    Top1 77.049180    Top5 98.360656    LR 0.000020    Time 0.178266    
2024-04-23 21:05:03,426 - --- validate (epoch=195)-----------
2024-04-23 21:05:03,427 - 3925 samples (32 per mini-batch)
2024-04-23 21:05:29,959 - Epoch: [195][  100/  123]    Loss 0.653913    Top1 79.437500    Top5 97.375000    
2024-04-23 21:05:35,137 - Epoch: [195][  123/  123]    Loss 0.661977    Top1 79.108280    Top5 97.528662    
2024-04-23 21:05:35,325 - ==> Top1: 79.108    Top5: 97.529    Loss: 0.662

2024-04-23 21:05:35,334 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:05:35,335 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:05:35,378 - 

2024-04-23 21:05:35,380 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:05:55,563 - Epoch: [196][  100/  296]    Overall Loss 0.674889    Objective Loss 0.674889                                        LR 0.000020    Time 0.201651    
2024-04-23 21:06:09,811 - Epoch: [196][  200/  296]    Overall Loss 0.677887    Objective Loss 0.677887                                        LR 0.000020    Time 0.171985    
2024-04-23 21:06:22,931 - Epoch: [196][  296/  296]    Overall Loss 0.683320    Objective Loss 0.683320    Top1 70.491803    Top5 96.721311    LR 0.000020    Time 0.160484    
2024-04-23 21:06:23,198 - --- validate (epoch=196)-----------
2024-04-23 21:06:23,199 - 3925 samples (32 per mini-batch)
2024-04-23 21:06:41,499 - Epoch: [196][  100/  123]    Loss 0.650679    Top1 79.031250    Top5 97.531250    
2024-04-23 21:06:44,932 - Epoch: [196][  123/  123]    Loss 0.661586    Top1 78.777070    Top5 97.452229    
2024-04-23 21:06:45,146 - ==> Top1: 78.777    Top5: 97.452    Loss: 0.662

2024-04-23 21:06:45,155 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:06:45,156 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:06:45,195 - 

2024-04-23 21:06:45,196 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:07:02,502 - Epoch: [197][  100/  296]    Overall Loss 0.694703    Objective Loss 0.694703                                        LR 0.000020    Time 0.172885    
2024-04-23 21:07:17,635 - Epoch: [197][  200/  296]    Overall Loss 0.691906    Objective Loss 0.691906                                        LR 0.000020    Time 0.162026    
2024-04-23 21:07:33,092 - Epoch: [197][  296/  296]    Overall Loss 0.675053    Objective Loss 0.675053    Top1 80.327869    Top5 96.721311    LR 0.000020    Time 0.161648    
2024-04-23 21:07:33,305 - --- validate (epoch=197)-----------
2024-04-23 21:07:33,306 - 3925 samples (32 per mini-batch)
2024-04-23 21:07:53,704 - Epoch: [197][  100/  123]    Loss 0.650755    Top1 79.250000    Top5 97.468750    
2024-04-23 21:07:57,750 - Epoch: [197][  123/  123]    Loss 0.659184    Top1 78.878981    Top5 97.477707    
2024-04-23 21:07:57,951 - ==> Top1: 78.879    Top5: 97.478    Loss: 0.659

2024-04-23 21:07:57,958 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:07:57,958 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:07:57,994 - 

2024-04-23 21:07:57,995 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:08:19,327 - Epoch: [198][  100/  296]    Overall Loss 0.649558    Objective Loss 0.649558                                        LR 0.000020    Time 0.213148    
2024-04-23 21:08:38,061 - Epoch: [198][  200/  296]    Overall Loss 0.668957    Objective Loss 0.668957                                        LR 0.000020    Time 0.200161    
2024-04-23 21:08:50,861 - Epoch: [198][  296/  296]    Overall Loss 0.676776    Objective Loss 0.676776    Top1 86.885246    Top5 96.721311    LR 0.000020    Time 0.178434    
2024-04-23 21:08:51,202 - --- validate (epoch=198)-----------
2024-04-23 21:08:51,203 - 3925 samples (32 per mini-batch)
2024-04-23 21:09:04,116 - Epoch: [198][  100/  123]    Loss 0.662013    Top1 79.000000    Top5 97.281250    
2024-04-23 21:09:07,055 - Epoch: [198][  123/  123]    Loss 0.660643    Top1 78.828025    Top5 97.426752    
2024-04-23 21:09:07,302 - ==> Top1: 78.828    Top5: 97.427    Loss: 0.661

2024-04-23 21:09:07,311 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:09:07,311 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:09:07,363 - 

2024-04-23 21:09:07,364 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:09:22,437 - Epoch: [199][  100/  296]    Overall Loss 0.699788    Objective Loss 0.699788                                        LR 0.000020    Time 0.150578    
2024-04-23 21:09:37,025 - Epoch: [199][  200/  296]    Overall Loss 0.684950    Objective Loss 0.684950                                        LR 0.000020    Time 0.148153    
2024-04-23 21:09:52,816 - Epoch: [199][  296/  296]    Overall Loss 0.675722    Objective Loss 0.675722    Top1 77.049180    Top5 100.000000    LR 0.000020    Time 0.153397    
2024-04-23 21:09:53,022 - --- validate (epoch=199)-----------
2024-04-23 21:09:53,023 - 3925 samples (32 per mini-batch)
2024-04-23 21:10:12,261 - Epoch: [199][  100/  123]    Loss 0.666731    Top1 78.812500    Top5 97.218750    
2024-04-23 21:10:15,444 - Epoch: [199][  123/  123]    Loss 0.657653    Top1 78.700637    Top5 97.477707    
2024-04-23 21:10:15,682 - ==> Top1: 78.701    Top5: 97.478    Loss: 0.658

2024-04-23 21:10:15,689 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:10:15,690 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:10:15,730 - 

2024-04-23 21:10:15,730 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:10:33,902 - Epoch: [200][  100/  296]    Overall Loss 0.678814    Objective Loss 0.678814                                        LR 0.000005    Time 0.181549    
2024-04-23 21:10:52,377 - Epoch: [200][  200/  296]    Overall Loss 0.668979    Objective Loss 0.668979                                        LR 0.000005    Time 0.183064    
2024-04-23 21:11:07,364 - Epoch: [200][  296/  296]    Overall Loss 0.668537    Objective Loss 0.668537    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.174273    
2024-04-23 21:11:07,588 - --- validate (epoch=200)-----------
2024-04-23 21:11:07,589 - 3925 samples (32 per mini-batch)
2024-04-23 21:11:23,929 - Epoch: [200][  100/  123]    Loss 0.654914    Top1 79.218750    Top5 97.437500    
2024-04-23 21:11:27,124 - Epoch: [200][  123/  123]    Loss 0.656732    Top1 79.006369    Top5 97.605096    
2024-04-23 21:11:27,378 - ==> Top1: 79.006    Top5: 97.605    Loss: 0.657

2024-04-23 21:11:27,387 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:11:27,387 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:11:27,432 - 

2024-04-23 21:11:27,432 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:11:41,025 - Epoch: [201][  100/  296]    Overall Loss 0.683010    Objective Loss 0.683010                                        LR 0.000005    Time 0.135772    
2024-04-23 21:11:57,243 - Epoch: [201][  200/  296]    Overall Loss 0.674080    Objective Loss 0.674080                                        LR 0.000005    Time 0.148892    
2024-04-23 21:12:16,592 - Epoch: [201][  296/  296]    Overall Loss 0.676479    Objective Loss 0.676479    Top1 63.934426    Top5 96.721311    LR 0.000005    Time 0.165917    
2024-04-23 21:12:16,785 - --- validate (epoch=201)-----------
2024-04-23 21:12:16,786 - 3925 samples (32 per mini-batch)
2024-04-23 21:12:39,245 - Epoch: [201][  100/  123]    Loss 0.657432    Top1 79.031250    Top5 97.562500    
2024-04-23 21:12:42,758 - Epoch: [201][  123/  123]    Loss 0.658419    Top1 78.929936    Top5 97.605096    
2024-04-23 21:12:42,997 - ==> Top1: 78.930    Top5: 97.605    Loss: 0.658

2024-04-23 21:12:43,005 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:12:43,005 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:12:43,041 - 

2024-04-23 21:12:43,041 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:13:00,406 - Epoch: [202][  100/  296]    Overall Loss 0.699621    Objective Loss 0.699621                                        LR 0.000005    Time 0.173501    
2024-04-23 21:13:13,106 - Epoch: [202][  200/  296]    Overall Loss 0.680993    Objective Loss 0.680993                                        LR 0.000005    Time 0.150178    
2024-04-23 21:13:27,275 - Epoch: [202][  296/  296]    Overall Loss 0.683614    Objective Loss 0.683614    Top1 68.852459    Top5 95.081967    LR 0.000005    Time 0.149287    
2024-04-23 21:13:27,503 - --- validate (epoch=202)-----------
2024-04-23 21:13:27,504 - 3925 samples (32 per mini-batch)
2024-04-23 21:13:41,329 - Epoch: [202][  100/  123]    Loss 0.642506    Top1 79.218750    Top5 97.687500    
2024-04-23 21:13:44,272 - Epoch: [202][  123/  123]    Loss 0.659866    Top1 78.675159    Top5 97.579618    
2024-04-23 21:13:44,463 - ==> Top1: 78.675    Top5: 97.580    Loss: 0.660

2024-04-23 21:13:44,471 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:13:44,472 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:13:44,511 - 

2024-04-23 21:13:44,512 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:13:59,993 - Epoch: [203][  100/  296]    Overall Loss 0.692947    Objective Loss 0.692947                                        LR 0.000005    Time 0.154640    
2024-04-23 21:14:22,089 - Epoch: [203][  200/  296]    Overall Loss 0.687371    Objective Loss 0.687371                                        LR 0.000005    Time 0.187715    
2024-04-23 21:14:35,835 - Epoch: [203][  296/  296]    Overall Loss 0.672677    Objective Loss 0.672677    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.173222    
2024-04-23 21:14:36,038 - --- validate (epoch=203)-----------
2024-04-23 21:14:36,039 - 3925 samples (32 per mini-batch)
2024-04-23 21:15:00,358 - Epoch: [203][  100/  123]    Loss 0.668985    Top1 78.656250    Top5 97.531250    
2024-04-23 21:15:04,881 - Epoch: [203][  123/  123]    Loss 0.663084    Top1 78.700637    Top5 97.605096    
2024-04-23 21:15:05,041 - ==> Top1: 78.701    Top5: 97.605    Loss: 0.663

2024-04-23 21:15:05,050 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:15:05,050 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:15:05,093 - 

2024-04-23 21:15:05,094 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:15:29,680 - Epoch: [204][  100/  296]    Overall Loss 0.718995    Objective Loss 0.718995                                        LR 0.000005    Time 0.245680    
2024-04-23 21:15:47,752 - Epoch: [204][  200/  296]    Overall Loss 0.709165    Objective Loss 0.709165                                        LR 0.000005    Time 0.213120    
2024-04-23 21:16:04,423 - Epoch: [204][  296/  296]    Overall Loss 0.688264    Objective Loss 0.688264    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.200269    
2024-04-23 21:16:04,679 - --- validate (epoch=204)-----------
2024-04-23 21:16:04,680 - 3925 samples (32 per mini-batch)
2024-04-23 21:16:26,936 - Epoch: [204][  100/  123]    Loss 0.669293    Top1 78.718750    Top5 97.343750    
2024-04-23 21:16:30,821 - Epoch: [204][  123/  123]    Loss 0.663441    Top1 78.598726    Top5 97.477707    
2024-04-23 21:16:31,130 - ==> Top1: 78.599    Top5: 97.478    Loss: 0.663

2024-04-23 21:16:31,138 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:16:31,138 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:16:31,176 - 

2024-04-23 21:16:31,177 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:16:51,793 - Epoch: [205][  100/  296]    Overall Loss 0.689919    Objective Loss 0.689919                                        LR 0.000005    Time 0.205993    
2024-04-23 21:17:08,547 - Epoch: [205][  200/  296]    Overall Loss 0.687210    Objective Loss 0.687210                                        LR 0.000005    Time 0.186687    
2024-04-23 21:17:26,305 - Epoch: [205][  296/  296]    Overall Loss 0.677408    Objective Loss 0.677408    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.186082    
2024-04-23 21:17:26,553 - --- validate (epoch=205)-----------
2024-04-23 21:17:26,554 - 3925 samples (32 per mini-batch)
2024-04-23 21:17:48,106 - Epoch: [205][  100/  123]    Loss 0.662032    Top1 78.625000    Top5 97.531250    
2024-04-23 21:17:53,378 - Epoch: [205][  123/  123]    Loss 0.659862    Top1 78.802548    Top5 97.554140    
2024-04-23 21:17:53,623 - ==> Top1: 78.803    Top5: 97.554    Loss: 0.660

2024-04-23 21:17:53,631 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:17:53,631 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:17:53,670 - 

2024-04-23 21:17:53,671 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:18:12,106 - Epoch: [206][  100/  296]    Overall Loss 0.678538    Objective Loss 0.678538                                        LR 0.000005    Time 0.184184    
2024-04-23 21:18:29,295 - Epoch: [206][  200/  296]    Overall Loss 0.673421    Objective Loss 0.673421                                        LR 0.000005    Time 0.177958    
2024-04-23 21:18:43,596 - Epoch: [206][  296/  296]    Overall Loss 0.673694    Objective Loss 0.673694    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.168502    
2024-04-23 21:18:43,869 - --- validate (epoch=206)-----------
2024-04-23 21:18:43,870 - 3925 samples (32 per mini-batch)
2024-04-23 21:19:04,024 - Epoch: [206][  100/  123]    Loss 0.659877    Top1 79.093750    Top5 97.375000    
2024-04-23 21:19:08,393 - Epoch: [206][  123/  123]    Loss 0.664319    Top1 78.547771    Top5 97.477707    
2024-04-23 21:19:08,585 - ==> Top1: 78.548    Top5: 97.478    Loss: 0.664

2024-04-23 21:19:08,594 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:19:08,595 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:19:08,637 - 

2024-04-23 21:19:08,638 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:19:28,654 - Epoch: [207][  100/  296]    Overall Loss 0.649429    Objective Loss 0.649429                                        LR 0.000005    Time 0.199986    
2024-04-23 21:19:46,145 - Epoch: [207][  200/  296]    Overall Loss 0.663048    Objective Loss 0.663048                                        LR 0.000005    Time 0.187375    
2024-04-23 21:20:02,065 - Epoch: [207][  296/  296]    Overall Loss 0.673580    Objective Loss 0.673580    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.180331    
2024-04-23 21:20:02,309 - --- validate (epoch=207)-----------
2024-04-23 21:20:02,310 - 3925 samples (32 per mini-batch)
2024-04-23 21:20:24,679 - Epoch: [207][  100/  123]    Loss 0.653700    Top1 78.937500    Top5 97.593750    
2024-04-23 21:20:29,913 - Epoch: [207][  123/  123]    Loss 0.658182    Top1 79.031847    Top5 97.579618    
2024-04-23 21:20:30,138 - ==> Top1: 79.032    Top5: 97.580    Loss: 0.658

2024-04-23 21:20:30,147 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:20:30,147 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:20:30,186 - 

2024-04-23 21:20:30,186 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:20:50,664 - Epoch: [208][  100/  296]    Overall Loss 0.662018    Objective Loss 0.662018                                        LR 0.000005    Time 0.204607    
2024-04-23 21:21:08,436 - Epoch: [208][  200/  296]    Overall Loss 0.669849    Objective Loss 0.669849                                        LR 0.000005    Time 0.191083    
2024-04-23 21:21:26,373 - Epoch: [208][  296/  296]    Overall Loss 0.672801    Objective Loss 0.672801    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.189656    
2024-04-23 21:21:26,559 - --- validate (epoch=208)-----------
2024-04-23 21:21:26,560 - 3925 samples (32 per mini-batch)
2024-04-23 21:21:47,551 - Epoch: [208][  100/  123]    Loss 0.678267    Top1 78.468750    Top5 97.593750    
2024-04-23 21:21:51,337 - Epoch: [208][  123/  123]    Loss 0.663333    Top1 78.802548    Top5 97.503185    
2024-04-23 21:21:51,581 - ==> Top1: 78.803    Top5: 97.503    Loss: 0.663

2024-04-23 21:21:51,588 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:21:51,589 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:21:51,646 - 

2024-04-23 21:21:51,647 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:22:10,504 - Epoch: [209][  100/  296]    Overall Loss 0.688722    Objective Loss 0.688722                                        LR 0.000005    Time 0.188392    
2024-04-23 21:22:28,668 - Epoch: [209][  200/  296]    Overall Loss 0.680186    Objective Loss 0.680186                                        LR 0.000005    Time 0.184928    
2024-04-23 21:22:45,540 - Epoch: [209][  296/  296]    Overall Loss 0.675448    Objective Loss 0.675448    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.181898    
2024-04-23 21:22:45,783 - --- validate (epoch=209)-----------
2024-04-23 21:22:45,783 - 3925 samples (32 per mini-batch)
2024-04-23 21:23:06,020 - Epoch: [209][  100/  123]    Loss 0.669427    Top1 78.406250    Top5 97.250000    
2024-04-23 21:23:09,960 - Epoch: [209][  123/  123]    Loss 0.664409    Top1 78.522293    Top5 97.426752    
2024-04-23 21:23:10,232 - ==> Top1: 78.522    Top5: 97.427    Loss: 0.664

2024-04-23 21:23:10,241 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:23:10,241 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:23:10,286 - 

2024-04-23 21:23:10,287 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:23:32,375 - Epoch: [210][  100/  296]    Overall Loss 0.655723    Objective Loss 0.655723                                        LR 0.000005    Time 0.220693    
2024-04-23 21:23:51,004 - Epoch: [210][  200/  296]    Overall Loss 0.675447    Objective Loss 0.675447                                        LR 0.000005    Time 0.203402    
2024-04-23 21:24:09,195 - Epoch: [210][  296/  296]    Overall Loss 0.672840    Objective Loss 0.672840    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.198840    
2024-04-23 21:24:09,392 - --- validate (epoch=210)-----------
2024-04-23 21:24:09,393 - 3925 samples (32 per mini-batch)
2024-04-23 21:24:30,193 - Epoch: [210][  100/  123]    Loss 0.655297    Top1 78.906250    Top5 97.687500    
2024-04-23 21:24:35,646 - Epoch: [210][  123/  123]    Loss 0.659267    Top1 78.853503    Top5 97.605096    
2024-04-23 21:24:35,842 - ==> Top1: 78.854    Top5: 97.605    Loss: 0.659

2024-04-23 21:24:35,852 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:24:35,852 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:24:35,900 - 

2024-04-23 21:24:35,901 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:24:57,138 - Epoch: [211][  100/  296]    Overall Loss 0.670293    Objective Loss 0.670293                                        LR 0.000005    Time 0.212203    
2024-04-23 21:25:16,834 - Epoch: [211][  200/  296]    Overall Loss 0.666255    Objective Loss 0.666255                                        LR 0.000005    Time 0.204494    
2024-04-23 21:25:35,137 - Epoch: [211][  296/  296]    Overall Loss 0.674968    Objective Loss 0.674968    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.199953    
2024-04-23 21:25:35,330 - --- validate (epoch=211)-----------
2024-04-23 21:25:35,331 - 3925 samples (32 per mini-batch)
2024-04-23 21:25:57,254 - Epoch: [211][  100/  123]    Loss 0.652152    Top1 79.437500    Top5 97.531250    
2024-04-23 21:26:01,665 - Epoch: [211][  123/  123]    Loss 0.658513    Top1 79.133758    Top5 97.579618    
2024-04-23 21:26:01,868 - ==> Top1: 79.134    Top5: 97.580    Loss: 0.659

2024-04-23 21:26:01,877 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:26:01,878 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:26:01,920 - 

2024-04-23 21:26:01,921 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:26:23,646 - Epoch: [212][  100/  296]    Overall Loss 0.641814    Objective Loss 0.641814                                        LR 0.000005    Time 0.217072    
2024-04-23 21:26:43,672 - Epoch: [212][  200/  296]    Overall Loss 0.677141    Objective Loss 0.677141                                        LR 0.000005    Time 0.208583    
2024-04-23 21:27:03,044 - Epoch: [212][  296/  296]    Overall Loss 0.672701    Objective Loss 0.672701    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.206330    
2024-04-23 21:27:03,254 - --- validate (epoch=212)-----------
2024-04-23 21:27:03,255 - 3925 samples (32 per mini-batch)
2024-04-23 21:27:22,422 - Epoch: [212][  100/  123]    Loss 0.665873    Top1 78.437500    Top5 97.562500    
2024-04-23 21:27:26,845 - Epoch: [212][  123/  123]    Loss 0.663329    Top1 78.700637    Top5 97.503185    
2024-04-23 21:27:27,106 - ==> Top1: 78.701    Top5: 97.503    Loss: 0.663

2024-04-23 21:27:27,115 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:27:27,115 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:27:27,157 - 

2024-04-23 21:27:27,158 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:27:44,258 - Epoch: [213][  100/  296]    Overall Loss 0.674767    Objective Loss 0.674767                                        LR 0.000005    Time 0.170825    
2024-04-23 21:28:05,360 - Epoch: [213][  200/  296]    Overall Loss 0.688998    Objective Loss 0.688998                                        LR 0.000005    Time 0.190836    
2024-04-23 21:28:24,846 - Epoch: [213][  296/  296]    Overall Loss 0.678943    Objective Loss 0.678943    Top1 67.213115    Top5 98.360656    LR 0.000005    Time 0.194720    
2024-04-23 21:28:24,984 - --- validate (epoch=213)-----------
2024-04-23 21:28:24,984 - 3925 samples (32 per mini-batch)
2024-04-23 21:28:41,500 - Epoch: [213][  100/  123]    Loss 0.662203    Top1 79.093750    Top5 97.437500    
2024-04-23 21:28:46,412 - Epoch: [213][  123/  123]    Loss 0.661231    Top1 79.133758    Top5 97.630573    
2024-04-23 21:28:46,677 - ==> Top1: 79.134    Top5: 97.631    Loss: 0.661

2024-04-23 21:28:46,688 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:28:46,688 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:28:46,746 - 

2024-04-23 21:28:46,747 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:29:09,570 - Epoch: [214][  100/  296]    Overall Loss 0.662320    Objective Loss 0.662320                                        LR 0.000005    Time 0.228055    
2024-04-23 21:29:29,691 - Epoch: [214][  200/  296]    Overall Loss 0.665939    Objective Loss 0.665939                                        LR 0.000005    Time 0.214546    
2024-04-23 21:29:43,961 - Epoch: [214][  296/  296]    Overall Loss 0.671407    Objective Loss 0.671407    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.193114    
2024-04-23 21:29:44,185 - --- validate (epoch=214)-----------
2024-04-23 21:29:44,186 - 3925 samples (32 per mini-batch)
2024-04-23 21:30:03,423 - Epoch: [214][  100/  123]    Loss 0.656497    Top1 79.000000    Top5 97.500000    
2024-04-23 21:30:06,669 - Epoch: [214][  123/  123]    Loss 0.659660    Top1 78.802548    Top5 97.528662    
2024-04-23 21:30:06,906 - ==> Top1: 78.803    Top5: 97.529    Loss: 0.660

2024-04-23 21:30:06,915 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:30:06,916 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:30:06,959 - 

2024-04-23 21:30:06,959 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:30:24,909 - Epoch: [215][  100/  296]    Overall Loss 0.680341    Objective Loss 0.680341                                        LR 0.000005    Time 0.179312    
2024-04-23 21:30:42,963 - Epoch: [215][  200/  296]    Overall Loss 0.674459    Objective Loss 0.674459                                        LR 0.000005    Time 0.179840    
2024-04-23 21:31:01,357 - Epoch: [215][  296/  296]    Overall Loss 0.682646    Objective Loss 0.682646    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.183605    
2024-04-23 21:31:01,635 - --- validate (epoch=215)-----------
2024-04-23 21:31:01,636 - 3925 samples (32 per mini-batch)
2024-04-23 21:31:23,183 - Epoch: [215][  100/  123]    Loss 0.650918    Top1 78.875000    Top5 97.468750    
2024-04-23 21:31:26,941 - Epoch: [215][  123/  123]    Loss 0.659285    Top1 78.777070    Top5 97.605096    
2024-04-23 21:31:27,144 - ==> Top1: 78.777    Top5: 97.605    Loss: 0.659

2024-04-23 21:31:27,153 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:31:27,153 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:31:27,200 - 

2024-04-23 21:31:27,201 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:31:45,838 - Epoch: [216][  100/  296]    Overall Loss 0.659469    Objective Loss 0.659469                                        LR 0.000005    Time 0.186190    
2024-04-23 21:32:04,826 - Epoch: [216][  200/  296]    Overall Loss 0.681010    Objective Loss 0.681010                                        LR 0.000005    Time 0.187958    
2024-04-23 21:32:21,758 - Epoch: [216][  296/  296]    Overall Loss 0.685761    Objective Loss 0.685761    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.184150    
2024-04-23 21:32:21,939 - --- validate (epoch=216)-----------
2024-04-23 21:32:21,940 - 3925 samples (32 per mini-batch)
2024-04-23 21:32:43,230 - Epoch: [216][  100/  123]    Loss 0.667010    Top1 78.187500    Top5 97.406250    
2024-04-23 21:32:47,681 - Epoch: [216][  123/  123]    Loss 0.658768    Top1 78.649682    Top5 97.477707    
2024-04-23 21:32:47,886 - ==> Top1: 78.650    Top5: 97.478    Loss: 0.659

2024-04-23 21:32:47,895 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:32:47,896 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:32:47,937 - 

2024-04-23 21:32:47,938 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:33:08,418 - Epoch: [217][  100/  296]    Overall Loss 0.672301    Objective Loss 0.672301                                        LR 0.000005    Time 0.204610    
2024-04-23 21:33:30,028 - Epoch: [217][  200/  296]    Overall Loss 0.669254    Objective Loss 0.669254                                        LR 0.000005    Time 0.210271    
2024-04-23 21:33:50,864 - Epoch: [217][  296/  296]    Overall Loss 0.669622    Objective Loss 0.669622    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.212416    
2024-04-23 21:33:51,104 - --- validate (epoch=217)-----------
2024-04-23 21:33:51,105 - 3925 samples (32 per mini-batch)
2024-04-23 21:34:11,474 - Epoch: [217][  100/  123]    Loss 0.656887    Top1 79.031250    Top5 97.437500    
2024-04-23 21:34:15,359 - Epoch: [217][  123/  123]    Loss 0.658680    Top1 79.082803    Top5 97.503185    
2024-04-23 21:34:15,580 - ==> Top1: 79.083    Top5: 97.503    Loss: 0.659

2024-04-23 21:34:15,592 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:34:15,593 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:34:15,663 - 

2024-04-23 21:34:15,664 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:34:32,934 - Epoch: [218][  100/  296]    Overall Loss 0.676392    Objective Loss 0.676392                                        LR 0.000005    Time 0.172512    
2024-04-23 21:34:50,865 - Epoch: [218][  200/  296]    Overall Loss 0.660193    Objective Loss 0.660193                                        LR 0.000005    Time 0.175830    
2024-04-23 21:35:02,875 - Epoch: [218][  296/  296]    Overall Loss 0.658387    Objective Loss 0.658387    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.159328    
2024-04-23 21:35:03,090 - --- validate (epoch=218)-----------
2024-04-23 21:35:03,090 - 3925 samples (32 per mini-batch)
2024-04-23 21:35:17,093 - Epoch: [218][  100/  123]    Loss 0.675180    Top1 78.718750    Top5 97.406250    
2024-04-23 21:35:21,459 - Epoch: [218][  123/  123]    Loss 0.659676    Top1 79.108280    Top5 97.528662    
2024-04-23 21:35:21,656 - ==> Top1: 79.108    Top5: 97.529    Loss: 0.660

2024-04-23 21:35:21,666 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:35:21,666 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:35:21,714 - 

2024-04-23 21:35:21,715 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:35:42,391 - Epoch: [219][  100/  296]    Overall Loss 0.668238    Objective Loss 0.668238                                        LR 0.000005    Time 0.206600    
2024-04-23 21:36:04,668 - Epoch: [219][  200/  296]    Overall Loss 0.665146    Objective Loss 0.665146                                        LR 0.000005    Time 0.214599    
2024-04-23 21:36:23,389 - Epoch: [219][  296/  296]    Overall Loss 0.671573    Objective Loss 0.671573    Top1 81.967213    Top5 95.081967    LR 0.000005    Time 0.208198    
2024-04-23 21:36:23,670 - --- validate (epoch=219)-----------
2024-04-23 21:36:23,671 - 3925 samples (32 per mini-batch)
2024-04-23 21:36:41,922 - Epoch: [219][  100/  123]    Loss 0.665790    Top1 78.406250    Top5 97.625000    
2024-04-23 21:36:45,537 - Epoch: [219][  123/  123]    Loss 0.660334    Top1 78.751592    Top5 97.528662    
2024-04-23 21:36:45,755 - ==> Top1: 78.752    Top5: 97.529    Loss: 0.660

2024-04-23 21:36:45,765 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:36:45,765 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:36:45,815 - 

2024-04-23 21:36:45,815 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:37:03,971 - Epoch: [220][  100/  296]    Overall Loss 0.690995    Objective Loss 0.690995                                        LR 0.000005    Time 0.181371    
2024-04-23 21:37:19,530 - Epoch: [220][  200/  296]    Overall Loss 0.691327    Objective Loss 0.691327                                        LR 0.000005    Time 0.168397    
2024-04-23 21:37:35,042 - Epoch: [220][  296/  296]    Overall Loss 0.673749    Objective Loss 0.673749    Top1 85.245902    Top5 96.721311    LR 0.000005    Time 0.166122    
2024-04-23 21:37:35,256 - --- validate (epoch=220)-----------
2024-04-23 21:37:35,256 - 3925 samples (32 per mini-batch)
2024-04-23 21:37:57,912 - Epoch: [220][  100/  123]    Loss 0.636168    Top1 79.843750    Top5 97.687500    
2024-04-23 21:38:02,697 - Epoch: [220][  123/  123]    Loss 0.658489    Top1 79.082803    Top5 97.630573    
2024-04-23 21:38:03,056 - ==> Top1: 79.083    Top5: 97.631    Loss: 0.658

2024-04-23 21:38:03,064 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:38:03,064 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:38:03,108 - 

2024-04-23 21:38:03,108 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:38:28,381 - Epoch: [221][  100/  296]    Overall Loss 0.687096    Objective Loss 0.687096                                        LR 0.000005    Time 0.252533    
2024-04-23 21:38:49,285 - Epoch: [221][  200/  296]    Overall Loss 0.667286    Objective Loss 0.667286                                        LR 0.000005    Time 0.230708    
2024-04-23 21:39:05,487 - Epoch: [221][  296/  296]    Overall Loss 0.667405    Objective Loss 0.667405    Top1 75.409836    Top5 91.803279    LR 0.000005    Time 0.210570    
2024-04-23 21:39:05,721 - --- validate (epoch=221)-----------
2024-04-23 21:39:05,722 - 3925 samples (32 per mini-batch)
2024-04-23 21:39:25,010 - Epoch: [221][  100/  123]    Loss 0.664794    Top1 78.875000    Top5 97.406250    
2024-04-23 21:39:28,552 - Epoch: [221][  123/  123]    Loss 0.659541    Top1 79.057325    Top5 97.528662    
2024-04-23 21:39:28,715 - ==> Top1: 79.057    Top5: 97.529    Loss: 0.660

2024-04-23 21:39:28,722 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:39:28,722 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:39:28,765 - 

2024-04-23 21:39:28,766 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:39:51,621 - Epoch: [222][  100/  296]    Overall Loss 0.641558    Objective Loss 0.641558                                        LR 0.000005    Time 0.228369    
2024-04-23 21:40:10,883 - Epoch: [222][  200/  296]    Overall Loss 0.650577    Objective Loss 0.650577                                        LR 0.000005    Time 0.210412    
2024-04-23 21:40:29,335 - Epoch: [222][  296/  296]    Overall Loss 0.651095    Objective Loss 0.651095    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.204453    
2024-04-23 21:40:29,705 - --- validate (epoch=222)-----------
2024-04-23 21:40:29,705 - 3925 samples (32 per mini-batch)
2024-04-23 21:40:48,246 - Epoch: [222][  100/  123]    Loss 0.651778    Top1 78.906250    Top5 97.812500    
2024-04-23 21:40:51,358 - Epoch: [222][  123/  123]    Loss 0.656736    Top1 78.955414    Top5 97.707006    
2024-04-23 21:40:51,620 - ==> Top1: 78.955    Top5: 97.707    Loss: 0.657

2024-04-23 21:40:51,629 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:40:51,630 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:40:51,674 - 

2024-04-23 21:40:51,675 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:41:12,861 - Epoch: [223][  100/  296]    Overall Loss 0.686340    Objective Loss 0.686340                                        LR 0.000005    Time 0.211719    
2024-04-23 21:41:32,507 - Epoch: [223][  200/  296]    Overall Loss 0.675629    Objective Loss 0.675629                                        LR 0.000005    Time 0.204016    
2024-04-23 21:41:49,293 - Epoch: [223][  296/  296]    Overall Loss 0.676949    Objective Loss 0.676949    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.194503    
2024-04-23 21:41:49,589 - --- validate (epoch=223)-----------
2024-04-23 21:41:49,590 - 3925 samples (32 per mini-batch)
2024-04-23 21:42:12,742 - Epoch: [223][  100/  123]    Loss 0.670875    Top1 78.281250    Top5 97.312500    
2024-04-23 21:42:16,692 - Epoch: [223][  123/  123]    Loss 0.657349    Top1 78.802548    Top5 97.554140    
2024-04-23 21:42:16,932 - ==> Top1: 78.803    Top5: 97.554    Loss: 0.657

2024-04-23 21:42:16,938 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:42:16,939 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:42:16,980 - 

2024-04-23 21:42:16,980 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:42:35,874 - Epoch: [224][  100/  296]    Overall Loss 0.676916    Objective Loss 0.676916                                        LR 0.000005    Time 0.188755    
2024-04-23 21:42:52,490 - Epoch: [224][  200/  296]    Overall Loss 0.678177    Objective Loss 0.678177                                        LR 0.000005    Time 0.177380    
2024-04-23 21:43:08,629 - Epoch: [224][  296/  296]    Overall Loss 0.676252    Objective Loss 0.676252    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.174329    
2024-04-23 21:43:08,900 - --- validate (epoch=224)-----------
2024-04-23 21:43:08,900 - 3925 samples (32 per mini-batch)
2024-04-23 21:43:31,059 - Epoch: [224][  100/  123]    Loss 0.652300    Top1 79.531250    Top5 97.531250    
2024-04-23 21:43:34,824 - Epoch: [224][  123/  123]    Loss 0.654625    Top1 79.210191    Top5 97.528662    
2024-04-23 21:43:35,069 - ==> Top1: 79.210    Top5: 97.529    Loss: 0.655

2024-04-23 21:43:35,078 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:43:35,079 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:43:35,122 - 

2024-04-23 21:43:35,122 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:43:52,719 - Epoch: [225][  100/  296]    Overall Loss 0.646349    Objective Loss 0.646349                                        LR 0.000005    Time 0.175798    
2024-04-23 21:44:08,912 - Epoch: [225][  200/  296]    Overall Loss 0.665628    Objective Loss 0.665628                                        LR 0.000005    Time 0.168779    
2024-04-23 21:44:24,831 - Epoch: [225][  296/  296]    Overall Loss 0.673343    Objective Loss 0.673343    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.167766    
2024-04-23 21:44:25,107 - --- validate (epoch=225)-----------
2024-04-23 21:44:25,108 - 3925 samples (32 per mini-batch)
2024-04-23 21:44:47,423 - Epoch: [225][  100/  123]    Loss 0.634204    Top1 79.406250    Top5 98.000000    
2024-04-23 21:44:52,035 - Epoch: [225][  123/  123]    Loss 0.658625    Top1 78.878981    Top5 97.528662    
2024-04-23 21:44:52,286 - ==> Top1: 78.879    Top5: 97.529    Loss: 0.659

2024-04-23 21:44:52,293 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:44:52,293 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:44:52,361 - 

2024-04-23 21:44:52,362 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:45:12,082 - Epoch: [226][  100/  296]    Overall Loss 0.648903    Objective Loss 0.648903                                        LR 0.000005    Time 0.196998    
2024-04-23 21:45:29,631 - Epoch: [226][  200/  296]    Overall Loss 0.653872    Objective Loss 0.653872                                        LR 0.000005    Time 0.186172    
2024-04-23 21:45:47,474 - Epoch: [226][  296/  296]    Overall Loss 0.668067    Objective Loss 0.668067    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.186031    
2024-04-23 21:45:47,845 - --- validate (epoch=226)-----------
2024-04-23 21:45:47,846 - 3925 samples (32 per mini-batch)
2024-04-23 21:46:09,392 - Epoch: [226][  100/  123]    Loss 0.657255    Top1 79.093750    Top5 97.406250    
2024-04-23 21:46:12,720 - Epoch: [226][  123/  123]    Loss 0.655463    Top1 78.980892    Top5 97.554140    
2024-04-23 21:46:12,956 - ==> Top1: 78.981    Top5: 97.554    Loss: 0.655

2024-04-23 21:46:12,963 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:46:12,963 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:46:13,009 - 

2024-04-23 21:46:13,010 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:46:37,518 - Epoch: [227][  100/  296]    Overall Loss 0.708912    Objective Loss 0.708912                                        LR 0.000005    Time 0.244928    
2024-04-23 21:46:56,402 - Epoch: [227][  200/  296]    Overall Loss 0.682179    Objective Loss 0.682179                                        LR 0.000005    Time 0.216809    
2024-04-23 21:47:15,285 - Epoch: [227][  296/  296]    Overall Loss 0.667625    Objective Loss 0.667625    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.210242    
2024-04-23 21:47:15,634 - --- validate (epoch=227)-----------
2024-04-23 21:47:15,635 - 3925 samples (32 per mini-batch)
2024-04-23 21:47:36,648 - Epoch: [227][  100/  123]    Loss 0.648498    Top1 78.750000    Top5 97.781250    
2024-04-23 21:47:40,423 - Epoch: [227][  123/  123]    Loss 0.659623    Top1 78.598726    Top5 97.605096    
2024-04-23 21:47:40,612 - ==> Top1: 78.599    Top5: 97.605    Loss: 0.660

2024-04-23 21:47:40,620 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:47:40,621 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:47:40,662 - 

2024-04-23 21:47:40,663 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:48:00,866 - Epoch: [228][  100/  296]    Overall Loss 0.690829    Objective Loss 0.690829                                        LR 0.000005    Time 0.201878    
2024-04-23 21:48:18,383 - Epoch: [228][  200/  296]    Overall Loss 0.680423    Objective Loss 0.680423                                        LR 0.000005    Time 0.188438    
2024-04-23 21:48:34,907 - Epoch: [228][  296/  296]    Overall Loss 0.680256    Objective Loss 0.680256    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.183094    
2024-04-23 21:48:35,202 - --- validate (epoch=228)-----------
2024-04-23 21:48:35,203 - 3925 samples (32 per mini-batch)
2024-04-23 21:48:58,877 - Epoch: [228][  100/  123]    Loss 0.672199    Top1 78.343750    Top5 97.562500    
2024-04-23 21:49:02,265 - Epoch: [228][  123/  123]    Loss 0.658239    Top1 78.929936    Top5 97.656051    
2024-04-23 21:49:02,449 - ==> Top1: 78.930    Top5: 97.656    Loss: 0.658

2024-04-23 21:49:02,456 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:49:02,456 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:49:02,501 - 

2024-04-23 21:49:02,502 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:49:24,386 - Epoch: [229][  100/  296]    Overall Loss 0.644684    Objective Loss 0.644684                                        LR 0.000005    Time 0.218680    
2024-04-23 21:49:42,519 - Epoch: [229][  200/  296]    Overall Loss 0.663407    Objective Loss 0.663407                                        LR 0.000005    Time 0.199923    
2024-04-23 21:50:02,123 - Epoch: [229][  296/  296]    Overall Loss 0.665624    Objective Loss 0.665624    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.201269    
2024-04-23 21:50:02,429 - --- validate (epoch=229)-----------
2024-04-23 21:50:02,430 - 3925 samples (32 per mini-batch)
2024-04-23 21:50:20,591 - Epoch: [229][  100/  123]    Loss 0.644451    Top1 79.000000    Top5 97.656250    
2024-04-23 21:50:24,359 - Epoch: [229][  123/  123]    Loss 0.663423    Top1 78.445860    Top5 97.554140    
2024-04-23 21:50:24,614 - ==> Top1: 78.446    Top5: 97.554    Loss: 0.663

2024-04-23 21:50:24,623 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:50:24,624 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:50:24,664 - 

2024-04-23 21:50:24,664 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:50:40,865 - Epoch: [230][  100/  296]    Overall Loss 0.680263    Objective Loss 0.680263                                        LR 0.000005    Time 0.161842    
2024-04-23 21:50:54,573 - Epoch: [230][  200/  296]    Overall Loss 0.668252    Objective Loss 0.668252                                        LR 0.000005    Time 0.149387    
2024-04-23 21:51:10,025 - Epoch: [230][  296/  296]    Overall Loss 0.673615    Objective Loss 0.673615    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.153086    
2024-04-23 21:51:10,305 - --- validate (epoch=230)-----------
2024-04-23 21:51:10,306 - 3925 samples (32 per mini-batch)
2024-04-23 21:51:28,578 - Epoch: [230][  100/  123]    Loss 0.666541    Top1 78.906250    Top5 97.468750    
2024-04-23 21:51:31,410 - Epoch: [230][  123/  123]    Loss 0.659179    Top1 79.057325    Top5 97.579618    
2024-04-23 21:51:31,571 - ==> Top1: 79.057    Top5: 97.580    Loss: 0.659

2024-04-23 21:51:31,578 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:51:31,578 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:51:31,612 - 

2024-04-23 21:51:31,613 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:51:52,670 - Epoch: [231][  100/  296]    Overall Loss 0.673835    Objective Loss 0.673835                                        LR 0.000005    Time 0.210406    
2024-04-23 21:52:09,326 - Epoch: [231][  200/  296]    Overall Loss 0.662528    Objective Loss 0.662528                                        LR 0.000005    Time 0.188403    
2024-04-23 21:52:23,648 - Epoch: [231][  296/  296]    Overall Loss 0.661623    Objective Loss 0.661623    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.175633    
2024-04-23 21:52:23,881 - --- validate (epoch=231)-----------
2024-04-23 21:52:23,882 - 3925 samples (32 per mini-batch)
2024-04-23 21:52:40,063 - Epoch: [231][  100/  123]    Loss 0.660615    Top1 79.250000    Top5 97.562500    
2024-04-23 21:52:43,203 - Epoch: [231][  123/  123]    Loss 0.658106    Top1 79.057325    Top5 97.707006    
2024-04-23 21:52:43,470 - ==> Top1: 79.057    Top5: 97.707    Loss: 0.658

2024-04-23 21:52:43,479 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:52:43,480 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:52:43,516 - 

2024-04-23 21:52:43,517 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:53:01,728 - Epoch: [232][  100/  296]    Overall Loss 0.671620    Objective Loss 0.671620                                        LR 0.000005    Time 0.181939    
2024-04-23 21:53:17,120 - Epoch: [232][  200/  296]    Overall Loss 0.681569    Objective Loss 0.681569                                        LR 0.000005    Time 0.167848    
2024-04-23 21:53:32,987 - Epoch: [232][  296/  296]    Overall Loss 0.675120    Objective Loss 0.675120    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.166971    
2024-04-23 21:53:33,226 - --- validate (epoch=232)-----------
2024-04-23 21:53:33,227 - 3925 samples (32 per mini-batch)
2024-04-23 21:53:52,795 - Epoch: [232][  100/  123]    Loss 0.657247    Top1 78.937500    Top5 97.625000    
2024-04-23 21:53:57,189 - Epoch: [232][  123/  123]    Loss 0.657904    Top1 78.675159    Top5 97.605096    
2024-04-23 21:53:57,451 - ==> Top1: 78.675    Top5: 97.605    Loss: 0.658

2024-04-23 21:53:57,461 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:53:57,461 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:53:57,506 - 

2024-04-23 21:53:57,506 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:54:17,628 - Epoch: [233][  100/  296]    Overall Loss 0.684404    Objective Loss 0.684404                                        LR 0.000005    Time 0.201063    
2024-04-23 21:54:34,638 - Epoch: [233][  200/  296]    Overall Loss 0.684337    Objective Loss 0.684337                                        LR 0.000005    Time 0.185501    
2024-04-23 21:54:53,068 - Epoch: [233][  296/  296]    Overall Loss 0.679843    Objective Loss 0.679843    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.187551    
2024-04-23 21:54:53,282 - --- validate (epoch=233)-----------
2024-04-23 21:54:53,283 - 3925 samples (32 per mini-batch)
2024-04-23 21:55:15,924 - Epoch: [233][  100/  123]    Loss 0.648445    Top1 78.812500    Top5 97.656250    
2024-04-23 21:55:20,037 - Epoch: [233][  123/  123]    Loss 0.659544    Top1 78.726115    Top5 97.554140    
2024-04-23 21:55:20,243 - ==> Top1: 78.726    Top5: 97.554    Loss: 0.660

2024-04-23 21:55:20,252 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:55:20,253 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:55:20,296 - 

2024-04-23 21:55:20,297 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:55:38,303 - Epoch: [234][  100/  296]    Overall Loss 0.636007    Objective Loss 0.636007                                        LR 0.000005    Time 0.179889    
2024-04-23 21:55:56,119 - Epoch: [234][  200/  296]    Overall Loss 0.658746    Objective Loss 0.658746                                        LR 0.000005    Time 0.178945    
2024-04-23 21:56:13,250 - Epoch: [234][  296/  296]    Overall Loss 0.674415    Objective Loss 0.674415    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.178729    
2024-04-23 21:56:13,531 - --- validate (epoch=234)-----------
2024-04-23 21:56:13,532 - 3925 samples (32 per mini-batch)
2024-04-23 21:56:34,341 - Epoch: [234][  100/  123]    Loss 0.668164    Top1 78.218750    Top5 97.531250    
2024-04-23 21:56:39,195 - Epoch: [234][  123/  123]    Loss 0.661278    Top1 78.675159    Top5 97.681529    
2024-04-23 21:56:39,416 - ==> Top1: 78.675    Top5: 97.682    Loss: 0.661

2024-04-23 21:56:39,424 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:56:39,425 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:56:39,472 - 

2024-04-23 21:56:39,473 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:56:58,096 - Epoch: [235][  100/  296]    Overall Loss 0.645949    Objective Loss 0.645949                                        LR 0.000005    Time 0.186063    
2024-04-23 21:57:14,224 - Epoch: [235][  200/  296]    Overall Loss 0.660430    Objective Loss 0.660430                                        LR 0.000005    Time 0.173588    
2024-04-23 21:57:30,685 - Epoch: [235][  296/  296]    Overall Loss 0.663676    Objective Loss 0.663676    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.172852    
2024-04-23 21:57:30,964 - --- validate (epoch=235)-----------
2024-04-23 21:57:30,964 - 3925 samples (32 per mini-batch)
2024-04-23 21:57:52,545 - Epoch: [235][  100/  123]    Loss 0.652720    Top1 79.000000    Top5 97.687500    
2024-04-23 21:57:57,185 - Epoch: [235][  123/  123]    Loss 0.656437    Top1 78.828025    Top5 97.681529    
2024-04-23 21:57:57,335 - ==> Top1: 78.828    Top5: 97.682    Loss: 0.656

2024-04-23 21:57:57,338 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:57:57,339 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:57:57,379 - 

2024-04-23 21:57:57,380 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:58:17,709 - Epoch: [236][  100/  296]    Overall Loss 0.704311    Objective Loss 0.704311                                        LR 0.000005    Time 0.203121    
2024-04-23 21:58:37,504 - Epoch: [236][  200/  296]    Overall Loss 0.666962    Objective Loss 0.666962                                        LR 0.000005    Time 0.200455    
2024-04-23 21:58:54,495 - Epoch: [236][  296/  296]    Overall Loss 0.669018    Objective Loss 0.669018    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.192793    
2024-04-23 21:58:54,748 - --- validate (epoch=236)-----------
2024-04-23 21:58:54,749 - 3925 samples (32 per mini-batch)
2024-04-23 21:59:15,230 - Epoch: [236][  100/  123]    Loss 0.652998    Top1 79.062500    Top5 97.750000    
2024-04-23 21:59:19,241 - Epoch: [236][  123/  123]    Loss 0.658456    Top1 79.159236    Top5 97.605096    
2024-04-23 21:59:19,410 - ==> Top1: 79.159    Top5: 97.605    Loss: 0.658

2024-04-23 21:59:19,418 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 21:59:19,419 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 21:59:19,464 - 

2024-04-23 21:59:19,464 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 21:59:40,828 - Epoch: [237][  100/  296]    Overall Loss 0.695615    Objective Loss 0.695615                                        LR 0.000005    Time 0.213483    
2024-04-23 22:00:00,218 - Epoch: [237][  200/  296]    Overall Loss 0.686063    Objective Loss 0.686063                                        LR 0.000005    Time 0.203618    
2024-04-23 22:00:18,861 - Epoch: [237][  296/  296]    Overall Loss 0.682683    Objective Loss 0.682683    Top1 68.852459    Top5 91.803279    LR 0.000005    Time 0.200517    
2024-04-23 22:00:19,149 - --- validate (epoch=237)-----------
2024-04-23 22:00:19,150 - 3925 samples (32 per mini-batch)
2024-04-23 22:00:43,701 - Epoch: [237][  100/  123]    Loss 0.666104    Top1 78.687500    Top5 97.656250    
2024-04-23 22:00:47,636 - Epoch: [237][  123/  123]    Loss 0.660975    Top1 78.904459    Top5 97.630573    
2024-04-23 22:00:47,809 - ==> Top1: 78.904    Top5: 97.631    Loss: 0.661

2024-04-23 22:00:47,818 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:00:47,818 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:00:47,863 - 

2024-04-23 22:00:47,863 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:01:07,227 - Epoch: [238][  100/  296]    Overall Loss 0.703269    Objective Loss 0.703269                                        LR 0.000005    Time 0.193478    
2024-04-23 22:01:25,719 - Epoch: [238][  200/  296]    Overall Loss 0.686748    Objective Loss 0.686748                                        LR 0.000005    Time 0.189111    
2024-04-23 22:01:41,508 - Epoch: [238][  296/  296]    Overall Loss 0.686874    Objective Loss 0.686874    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.181069    
2024-04-23 22:01:41,847 - --- validate (epoch=238)-----------
2024-04-23 22:01:41,848 - 3925 samples (32 per mini-batch)
2024-04-23 22:02:02,265 - Epoch: [238][  100/  123]    Loss 0.655424    Top1 79.156250    Top5 97.468750    
2024-04-23 22:02:07,222 - Epoch: [238][  123/  123]    Loss 0.658931    Top1 78.802548    Top5 97.503185    
2024-04-23 22:02:07,451 - ==> Top1: 78.803    Top5: 97.503    Loss: 0.659

2024-04-23 22:02:07,460 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:02:07,460 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:02:07,509 - 

2024-04-23 22:02:07,509 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:02:27,917 - Epoch: [239][  100/  296]    Overall Loss 0.658372    Objective Loss 0.658372                                        LR 0.000005    Time 0.203912    
2024-04-23 22:02:46,373 - Epoch: [239][  200/  296]    Overall Loss 0.663039    Objective Loss 0.663039                                        LR 0.000005    Time 0.194161    
2024-04-23 22:03:04,786 - Epoch: [239][  296/  296]    Overall Loss 0.671306    Objective Loss 0.671306    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.193347    
2024-04-23 22:03:05,088 - --- validate (epoch=239)-----------
2024-04-23 22:03:05,089 - 3925 samples (32 per mini-batch)
2024-04-23 22:03:25,228 - Epoch: [239][  100/  123]    Loss 0.658794    Top1 78.937500    Top5 97.437500    
2024-04-23 22:03:29,153 - Epoch: [239][  123/  123]    Loss 0.660726    Top1 78.980892    Top5 97.554140    
2024-04-23 22:03:29,337 - ==> Top1: 78.981    Top5: 97.554    Loss: 0.661

2024-04-23 22:03:29,346 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:03:29,347 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:03:29,391 - 

2024-04-23 22:03:29,391 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:03:48,402 - Epoch: [240][  100/  296]    Overall Loss 0.682174    Objective Loss 0.682174                                        LR 0.000005    Time 0.189930    
2024-04-23 22:04:05,868 - Epoch: [240][  200/  296]    Overall Loss 0.678562    Objective Loss 0.678562                                        LR 0.000005    Time 0.182214    
2024-04-23 22:04:24,737 - Epoch: [240][  296/  296]    Overall Loss 0.659908    Objective Loss 0.659908    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.186820    
2024-04-23 22:04:24,912 - --- validate (epoch=240)-----------
2024-04-23 22:04:24,913 - 3925 samples (32 per mini-batch)
2024-04-23 22:04:45,517 - Epoch: [240][  100/  123]    Loss 0.661044    Top1 78.875000    Top5 97.437500    
2024-04-23 22:04:50,526 - Epoch: [240][  123/  123]    Loss 0.664979    Top1 78.624204    Top5 97.452229    
2024-04-23 22:04:50,697 - ==> Top1: 78.624    Top5: 97.452    Loss: 0.665

2024-04-23 22:04:50,702 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:04:50,703 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:04:50,738 - 

2024-04-23 22:04:50,739 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:05:07,246 - Epoch: [241][  100/  296]    Overall Loss 0.660744    Objective Loss 0.660744                                        LR 0.000005    Time 0.164896    
2024-04-23 22:05:23,895 - Epoch: [241][  200/  296]    Overall Loss 0.678336    Objective Loss 0.678336                                        LR 0.000005    Time 0.165608    
2024-04-23 22:05:40,090 - Epoch: [241][  296/  296]    Overall Loss 0.663731    Objective Loss 0.663731    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.166558    
2024-04-23 22:05:40,276 - --- validate (epoch=241)-----------
2024-04-23 22:05:40,276 - 3925 samples (32 per mini-batch)
2024-04-23 22:06:00,116 - Epoch: [241][  100/  123]    Loss 0.667693    Top1 78.281250    Top5 97.593750    
2024-04-23 22:06:05,211 - Epoch: [241][  123/  123]    Loss 0.659041    Top1 78.777070    Top5 97.477707    
2024-04-23 22:06:05,389 - ==> Top1: 78.777    Top5: 97.478    Loss: 0.659

2024-04-23 22:06:05,394 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:06:05,394 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:06:05,429 - 

2024-04-23 22:06:05,429 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:06:27,023 - Epoch: [242][  100/  296]    Overall Loss 0.640341    Objective Loss 0.640341                                        LR 0.000005    Time 0.215754    
2024-04-23 22:06:44,045 - Epoch: [242][  200/  296]    Overall Loss 0.652761    Objective Loss 0.652761                                        LR 0.000005    Time 0.192912    
2024-04-23 22:07:00,408 - Epoch: [242][  296/  296]    Overall Loss 0.660777    Objective Loss 0.660777    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.185577    
2024-04-23 22:07:00,603 - --- validate (epoch=242)-----------
2024-04-23 22:07:00,604 - 3925 samples (32 per mini-batch)
2024-04-23 22:07:23,394 - Epoch: [242][  100/  123]    Loss 0.663984    Top1 78.375000    Top5 97.500000    
2024-04-23 22:07:28,024 - Epoch: [242][  123/  123]    Loss 0.658729    Top1 78.624204    Top5 97.554140    
2024-04-23 22:07:28,200 - ==> Top1: 78.624    Top5: 97.554    Loss: 0.659

2024-04-23 22:07:28,208 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:07:28,209 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:07:28,251 - 

2024-04-23 22:07:28,251 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:07:43,887 - Epoch: [243][  100/  296]    Overall Loss 0.694067    Objective Loss 0.694067                                        LR 0.000005    Time 0.156211    
2024-04-23 22:07:55,251 - Epoch: [243][  200/  296]    Overall Loss 0.681506    Objective Loss 0.681506                                        LR 0.000005    Time 0.134853    
2024-04-23 22:08:05,912 - Epoch: [243][  296/  296]    Overall Loss 0.669990    Objective Loss 0.669990    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.127090    
2024-04-23 22:08:06,168 - --- validate (epoch=243)-----------
2024-04-23 22:08:06,168 - 3925 samples (32 per mini-batch)
2024-04-23 22:08:21,514 - Epoch: [243][  100/  123]    Loss 0.665020    Top1 78.312500    Top5 97.593750    
2024-04-23 22:08:25,227 - Epoch: [243][  123/  123]    Loss 0.663483    Top1 78.547771    Top5 97.707006    
2024-04-23 22:08:25,354 - ==> Top1: 78.548    Top5: 97.707    Loss: 0.663

2024-04-23 22:08:25,359 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:08:25,359 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:08:25,399 - 

2024-04-23 22:08:25,400 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:08:41,034 - Epoch: [244][  100/  296]    Overall Loss 0.671621    Objective Loss 0.671621                                        LR 0.000005    Time 0.156179    
2024-04-23 22:08:56,360 - Epoch: [244][  200/  296]    Overall Loss 0.663846    Objective Loss 0.663846                                        LR 0.000005    Time 0.154631    
2024-04-23 22:09:07,153 - Epoch: [244][  296/  296]    Overall Loss 0.672116    Objective Loss 0.672116    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.140900    
2024-04-23 22:09:07,263 - --- validate (epoch=244)-----------
2024-04-23 22:09:07,264 - 3925 samples (32 per mini-batch)
2024-04-23 22:09:21,948 - Epoch: [244][  100/  123]    Loss 0.658951    Top1 78.937500    Top5 97.500000    
2024-04-23 22:09:24,942 - Epoch: [244][  123/  123]    Loss 0.656999    Top1 78.802548    Top5 97.503185    
2024-04-23 22:09:25,094 - ==> Top1: 78.803    Top5: 97.503    Loss: 0.657

2024-04-23 22:09:25,103 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:09:25,103 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:09:25,146 - 

2024-04-23 22:09:25,146 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:09:46,602 - Epoch: [245][  100/  296]    Overall Loss 0.658035    Objective Loss 0.658035                                        LR 0.000005    Time 0.214405    
2024-04-23 22:10:07,231 - Epoch: [245][  200/  296]    Overall Loss 0.670328    Objective Loss 0.670328                                        LR 0.000005    Time 0.210281    
2024-04-23 22:10:23,494 - Epoch: [245][  296/  296]    Overall Loss 0.665830    Objective Loss 0.665830    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.196978    
2024-04-23 22:10:23,794 - --- validate (epoch=245)-----------
2024-04-23 22:10:23,795 - 3925 samples (32 per mini-batch)
2024-04-23 22:10:46,228 - Epoch: [245][  100/  123]    Loss 0.646198    Top1 79.218750    Top5 97.531250    
2024-04-23 22:10:51,103 - Epoch: [245][  123/  123]    Loss 0.659426    Top1 78.904459    Top5 97.503185    
2024-04-23 22:10:51,391 - ==> Top1: 78.904    Top5: 97.503    Loss: 0.659

2024-04-23 22:10:51,401 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:10:51,402 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:10:51,454 - 

2024-04-23 22:10:51,455 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:11:07,685 - Epoch: [246][  100/  296]    Overall Loss 0.666242    Objective Loss 0.666242                                        LR 0.000005    Time 0.162131    
2024-04-23 22:11:25,551 - Epoch: [246][  200/  296]    Overall Loss 0.665465    Objective Loss 0.665465                                        LR 0.000005    Time 0.170306    
2024-04-23 22:11:43,322 - Epoch: [246][  296/  296]    Overall Loss 0.668894    Objective Loss 0.668894    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.175059    
2024-04-23 22:11:43,559 - --- validate (epoch=246)-----------
2024-04-23 22:11:43,560 - 3925 samples (32 per mini-batch)
2024-04-23 22:12:06,201 - Epoch: [246][  100/  123]    Loss 0.663594    Top1 78.593750    Top5 97.718750    
2024-04-23 22:12:11,312 - Epoch: [246][  123/  123]    Loss 0.660751    Top1 78.878981    Top5 97.656051    
2024-04-23 22:12:11,624 - ==> Top1: 78.879    Top5: 97.656    Loss: 0.661

2024-04-23 22:12:11,635 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:12:11,636 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:12:11,684 - 

2024-04-23 22:12:11,685 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:12:32,722 - Epoch: [247][  100/  296]    Overall Loss 0.654978    Objective Loss 0.654978                                        LR 0.000005    Time 0.210212    
2024-04-23 22:12:50,312 - Epoch: [247][  200/  296]    Overall Loss 0.661550    Objective Loss 0.661550                                        LR 0.000005    Time 0.192982    
2024-04-23 22:13:07,429 - Epoch: [247][  296/  296]    Overall Loss 0.665349    Objective Loss 0.665349    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.188163    
2024-04-23 22:13:07,730 - --- validate (epoch=247)-----------
2024-04-23 22:13:07,731 - 3925 samples (32 per mini-batch)
2024-04-23 22:13:28,556 - Epoch: [247][  100/  123]    Loss 0.662701    Top1 78.312500    Top5 97.531250    
2024-04-23 22:13:33,843 - Epoch: [247][  123/  123]    Loss 0.663664    Top1 78.547771    Top5 97.554140    
2024-04-23 22:13:34,207 - ==> Top1: 78.548    Top5: 97.554    Loss: 0.664

2024-04-23 22:13:34,218 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:13:34,218 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:13:34,269 - 

2024-04-23 22:13:34,269 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:13:54,961 - Epoch: [248][  100/  296]    Overall Loss 0.638858    Objective Loss 0.638858                                        LR 0.000005    Time 0.206734    
2024-04-23 22:14:12,106 - Epoch: [248][  200/  296]    Overall Loss 0.647496    Objective Loss 0.647496                                        LR 0.000005    Time 0.188997    
2024-04-23 22:14:28,354 - Epoch: [248][  296/  296]    Overall Loss 0.664187    Objective Loss 0.664187    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.182538    
2024-04-23 22:14:28,648 - --- validate (epoch=248)-----------
2024-04-23 22:14:28,649 - 3925 samples (32 per mini-batch)
2024-04-23 22:14:52,826 - Epoch: [248][  100/  123]    Loss 0.662566    Top1 79.062500    Top5 97.781250    
2024-04-23 22:14:56,605 - Epoch: [248][  123/  123]    Loss 0.658558    Top1 78.980892    Top5 97.579618    
2024-04-23 22:14:56,889 - ==> Top1: 78.981    Top5: 97.580    Loss: 0.659

2024-04-23 22:14:56,900 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:14:56,900 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:14:56,945 - 

2024-04-23 22:14:56,946 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:15:17,570 - Epoch: [249][  100/  296]    Overall Loss 0.673526    Objective Loss 0.673526                                        LR 0.000005    Time 0.206079    
2024-04-23 22:15:36,017 - Epoch: [249][  200/  296]    Overall Loss 0.681116    Objective Loss 0.681116                                        LR 0.000005    Time 0.195195    
2024-04-23 22:15:52,880 - Epoch: [249][  296/  296]    Overall Loss 0.679314    Objective Loss 0.679314    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.188807    
2024-04-23 22:15:53,127 - --- validate (epoch=249)-----------
2024-04-23 22:15:53,128 - 3925 samples (32 per mini-batch)
2024-04-23 22:16:14,108 - Epoch: [249][  100/  123]    Loss 0.654613    Top1 79.437500    Top5 97.375000    
2024-04-23 22:16:18,617 - Epoch: [249][  123/  123]    Loss 0.658592    Top1 78.878981    Top5 97.605096    
2024-04-23 22:16:18,788 - ==> Top1: 78.879    Top5: 97.605    Loss: 0.659

2024-04-23 22:16:18,797 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:16:18,797 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:16:18,846 - 

2024-04-23 22:16:18,846 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:16:34,804 - Epoch: [250][  100/  296]    Overall Loss 0.676901    Objective Loss 0.676901                                        LR 0.000005    Time 0.159415    
2024-04-23 22:16:50,520 - Epoch: [250][  200/  296]    Overall Loss 0.679576    Objective Loss 0.679576                                        LR 0.000005    Time 0.158206    
2024-04-23 22:17:09,389 - Epoch: [250][  296/  296]    Overall Loss 0.661911    Objective Loss 0.661911    Top1 68.852459    Top5 91.803279    LR 0.000005    Time 0.170587    
2024-04-23 22:17:09,607 - --- validate (epoch=250)-----------
2024-04-23 22:17:09,608 - 3925 samples (32 per mini-batch)
2024-04-23 22:17:28,870 - Epoch: [250][  100/  123]    Loss 0.670525    Top1 78.093750    Top5 97.437500    
2024-04-23 22:17:34,141 - Epoch: [250][  123/  123]    Loss 0.659728    Top1 78.675159    Top5 97.579618    
2024-04-23 22:17:34,409 - ==> Top1: 78.675    Top5: 97.580    Loss: 0.660

2024-04-23 22:17:34,416 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:17:34,417 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:17:34,450 - 

2024-04-23 22:17:34,450 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:17:53,817 - Epoch: [251][  100/  296]    Overall Loss 0.661770    Objective Loss 0.661770                                        LR 0.000005    Time 0.193507    
2024-04-23 22:18:06,849 - Epoch: [251][  200/  296]    Overall Loss 0.668314    Objective Loss 0.668314                                        LR 0.000005    Time 0.161832    
2024-04-23 22:18:20,103 - Epoch: [251][  296/  296]    Overall Loss 0.668004    Objective Loss 0.668004    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.154074    
2024-04-23 22:18:20,367 - --- validate (epoch=251)-----------
2024-04-23 22:18:20,368 - 3925 samples (32 per mini-batch)
2024-04-23 22:18:41,589 - Epoch: [251][  100/  123]    Loss 0.657491    Top1 78.750000    Top5 97.656250    
2024-04-23 22:18:45,381 - Epoch: [251][  123/  123]    Loss 0.663755    Top1 78.496815    Top5 97.554140    
2024-04-23 22:18:45,527 - ==> Top1: 78.497    Top5: 97.554    Loss: 0.664

2024-04-23 22:18:45,538 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:18:45,538 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:18:45,583 - 

2024-04-23 22:18:45,584 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:19:04,945 - Epoch: [252][  100/  296]    Overall Loss 0.674193    Objective Loss 0.674193                                        LR 0.000005    Time 0.193433    
2024-04-23 22:19:21,192 - Epoch: [252][  200/  296]    Overall Loss 0.690209    Objective Loss 0.690209                                        LR 0.000005    Time 0.177882    
2024-04-23 22:19:40,210 - Epoch: [252][  296/  296]    Overall Loss 0.691071    Objective Loss 0.691071    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.184390    
2024-04-23 22:19:40,511 - --- validate (epoch=252)-----------
2024-04-23 22:19:40,512 - 3925 samples (32 per mini-batch)
2024-04-23 22:20:01,267 - Epoch: [252][  100/  123]    Loss 0.657463    Top1 78.406250    Top5 97.656250    
2024-04-23 22:20:05,686 - Epoch: [252][  123/  123]    Loss 0.666509    Top1 78.318471    Top5 97.579618    
2024-04-23 22:20:06,003 - ==> Top1: 78.318    Top5: 97.580    Loss: 0.667

2024-04-23 22:20:06,013 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:20:06,014 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:20:06,056 - 

2024-04-23 22:20:06,057 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:20:26,348 - Epoch: [253][  100/  296]    Overall Loss 0.674422    Objective Loss 0.674422                                        LR 0.000005    Time 0.202731    
2024-04-23 22:20:43,663 - Epoch: [253][  200/  296]    Overall Loss 0.657203    Objective Loss 0.657203                                        LR 0.000005    Time 0.187842    
2024-04-23 22:20:59,629 - Epoch: [253][  296/  296]    Overall Loss 0.655498    Objective Loss 0.655498    Top1 85.245902    Top5 95.081967    LR 0.000005    Time 0.180809    
2024-04-23 22:20:59,924 - --- validate (epoch=253)-----------
2024-04-23 22:20:59,925 - 3925 samples (32 per mini-batch)
2024-04-23 22:21:18,108 - Epoch: [253][  100/  123]    Loss 0.644002    Top1 78.812500    Top5 97.843750    
2024-04-23 22:21:22,166 - Epoch: [253][  123/  123]    Loss 0.658755    Top1 78.471338    Top5 97.630573    
2024-04-23 22:21:22,426 - ==> Top1: 78.471    Top5: 97.631    Loss: 0.659

2024-04-23 22:21:22,438 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:21:22,439 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:21:22,489 - 

2024-04-23 22:21:22,490 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:21:38,249 - Epoch: [254][  100/  296]    Overall Loss 0.688501    Objective Loss 0.688501                                        LR 0.000005    Time 0.157350    
2024-04-23 22:21:52,787 - Epoch: [254][  200/  296]    Overall Loss 0.677868    Objective Loss 0.677868                                        LR 0.000005    Time 0.151287    
2024-04-23 22:22:09,482 - Epoch: [254][  296/  296]    Overall Loss 0.684525    Objective Loss 0.684525    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.158570    
2024-04-23 22:22:09,719 - --- validate (epoch=254)-----------
2024-04-23 22:22:09,720 - 3925 samples (32 per mini-batch)
2024-04-23 22:22:32,152 - Epoch: [254][  100/  123]    Loss 0.660191    Top1 78.531250    Top5 97.593750    
2024-04-23 22:22:35,522 - Epoch: [254][  123/  123]    Loss 0.664899    Top1 78.675159    Top5 97.401274    
2024-04-23 22:22:35,765 - ==> Top1: 78.675    Top5: 97.401    Loss: 0.665

2024-04-23 22:22:35,773 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:22:35,774 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:22:35,820 - 

2024-04-23 22:22:35,821 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:22:47,098 - Epoch: [255][  100/  296]    Overall Loss 0.693597    Objective Loss 0.693597                                        LR 0.000005    Time 0.112611    
2024-04-23 22:22:58,954 - Epoch: [255][  200/  296]    Overall Loss 0.689656    Objective Loss 0.689656                                        LR 0.000005    Time 0.115506    
2024-04-23 22:23:08,881 - Epoch: [255][  296/  296]    Overall Loss 0.674819    Objective Loss 0.674819    Top1 78.688525    Top5 93.442623    LR 0.000005    Time 0.111534    
2024-04-23 22:23:09,156 - --- validate (epoch=255)-----------
2024-04-23 22:23:09,157 - 3925 samples (32 per mini-batch)
2024-04-23 22:23:25,762 - Epoch: [255][  100/  123]    Loss 0.674606    Top1 78.125000    Top5 97.437500    
2024-04-23 22:23:30,500 - Epoch: [255][  123/  123]    Loss 0.660921    Top1 78.675159    Top5 97.528662    
2024-04-23 22:23:30,658 - ==> Top1: 78.675    Top5: 97.529    Loss: 0.661

2024-04-23 22:23:30,667 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:23:30,667 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:23:30,712 - 

2024-04-23 22:23:30,712 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:23:49,936 - Epoch: [256][  100/  296]    Overall Loss 0.693561    Objective Loss 0.693561                                        LR 0.000005    Time 0.192057    
2024-04-23 22:24:05,755 - Epoch: [256][  200/  296]    Overall Loss 0.682397    Objective Loss 0.682397                                        LR 0.000005    Time 0.175039    
2024-04-23 22:24:16,396 - Epoch: [256][  296/  296]    Overall Loss 0.678540    Objective Loss 0.678540    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.154172    
2024-04-23 22:24:16,629 - --- validate (epoch=256)-----------
2024-04-23 22:24:16,630 - 3925 samples (32 per mini-batch)
2024-04-23 22:24:35,384 - Epoch: [256][  100/  123]    Loss 0.656214    Top1 78.968750    Top5 97.875000    
2024-04-23 22:24:38,536 - Epoch: [256][  123/  123]    Loss 0.657826    Top1 78.904459    Top5 97.681529    
2024-04-23 22:24:38,764 - ==> Top1: 78.904    Top5: 97.682    Loss: 0.658

2024-04-23 22:24:38,774 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:24:38,774 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:24:38,811 - 

2024-04-23 22:24:38,811 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:24:56,502 - Epoch: [257][  100/  296]    Overall Loss 0.688666    Objective Loss 0.688666                                        LR 0.000005    Time 0.176735    
2024-04-23 22:25:11,596 - Epoch: [257][  200/  296]    Overall Loss 0.677880    Objective Loss 0.677880                                        LR 0.000005    Time 0.163762    
2024-04-23 22:25:25,714 - Epoch: [257][  296/  296]    Overall Loss 0.676963    Objective Loss 0.676963    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.158295    
2024-04-23 22:25:25,898 - --- validate (epoch=257)-----------
2024-04-23 22:25:25,899 - 3925 samples (32 per mini-batch)
2024-04-23 22:25:46,774 - Epoch: [257][  100/  123]    Loss 0.671788    Top1 78.125000    Top5 97.406250    
2024-04-23 22:25:51,423 - Epoch: [257][  123/  123]    Loss 0.658187    Top1 78.522293    Top5 97.656051    
2024-04-23 22:25:51,740 - ==> Top1: 78.522    Top5: 97.656    Loss: 0.658

2024-04-23 22:25:51,752 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:25:51,753 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:25:51,800 - 

2024-04-23 22:25:51,801 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:26:15,600 - Epoch: [258][  100/  296]    Overall Loss 0.661005    Objective Loss 0.661005                                        LR 0.000005    Time 0.237823    
2024-04-23 22:26:33,410 - Epoch: [258][  200/  296]    Overall Loss 0.656328    Objective Loss 0.656328                                        LR 0.000005    Time 0.207873    
2024-04-23 22:26:52,476 - Epoch: [258][  296/  296]    Overall Loss 0.674563    Objective Loss 0.674563    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.204815    
2024-04-23 22:26:52,765 - --- validate (epoch=258)-----------
2024-04-23 22:26:52,766 - 3925 samples (32 per mini-batch)
2024-04-23 22:27:10,175 - Epoch: [258][  100/  123]    Loss 0.656216    Top1 78.781250    Top5 97.531250    
2024-04-23 22:27:13,401 - Epoch: [258][  123/  123]    Loss 0.660210    Top1 78.751592    Top5 97.554140    
2024-04-23 22:27:13,790 - ==> Top1: 78.752    Top5: 97.554    Loss: 0.660

2024-04-23 22:27:13,799 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:27:13,799 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:27:13,838 - 

2024-04-23 22:27:13,839 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:27:35,056 - Epoch: [259][  100/  296]    Overall Loss 0.643526    Objective Loss 0.643526                                        LR 0.000005    Time 0.211995    
2024-04-23 22:27:52,814 - Epoch: [259][  200/  296]    Overall Loss 0.663248    Objective Loss 0.663248                                        LR 0.000005    Time 0.194706    
2024-04-23 22:28:01,296 - Epoch: [259][  296/  296]    Overall Loss 0.667349    Objective Loss 0.667349    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.160175    
2024-04-23 22:28:01,501 - --- validate (epoch=259)-----------
2024-04-23 22:28:01,502 - 3925 samples (32 per mini-batch)
2024-04-23 22:28:14,942 - Epoch: [259][  100/  123]    Loss 0.659135    Top1 79.125000    Top5 97.531250    
2024-04-23 22:28:18,521 - Epoch: [259][  123/  123]    Loss 0.656045    Top1 79.159236    Top5 97.630573    
2024-04-23 22:28:18,729 - ==> Top1: 79.159    Top5: 97.631    Loss: 0.656

2024-04-23 22:28:18,741 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:28:18,742 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:28:18,784 - 

2024-04-23 22:28:18,785 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:28:37,193 - Epoch: [260][  100/  296]    Overall Loss 0.653097    Objective Loss 0.653097                                        LR 0.000005    Time 0.183900    
2024-04-23 22:28:55,055 - Epoch: [260][  200/  296]    Overall Loss 0.667577    Objective Loss 0.667577                                        LR 0.000005    Time 0.181173    
2024-04-23 22:29:08,082 - Epoch: [260][  296/  296]    Overall Loss 0.667401    Objective Loss 0.667401    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.166373    
2024-04-23 22:29:08,313 - --- validate (epoch=260)-----------
2024-04-23 22:29:08,314 - 3925 samples (32 per mini-batch)
2024-04-23 22:29:25,776 - Epoch: [260][  100/  123]    Loss 0.665105    Top1 78.843750    Top5 97.468750    
2024-04-23 22:29:29,116 - Epoch: [260][  123/  123]    Loss 0.659839    Top1 78.726115    Top5 97.605096    
2024-04-23 22:29:29,315 - ==> Top1: 78.726    Top5: 97.605    Loss: 0.660

2024-04-23 22:29:29,324 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:29:29,324 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:29:29,372 - 

2024-04-23 22:29:29,373 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:29:46,974 - Epoch: [261][  100/  296]    Overall Loss 0.633771    Objective Loss 0.633771                                        LR 0.000005    Time 0.175850    
2024-04-23 22:30:01,878 - Epoch: [261][  200/  296]    Overall Loss 0.665734    Objective Loss 0.665734                                        LR 0.000005    Time 0.162363    
2024-04-23 22:30:14,483 - Epoch: [261][  296/  296]    Overall Loss 0.671525    Objective Loss 0.671525    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.152240    
2024-04-23 22:30:14,721 - --- validate (epoch=261)-----------
2024-04-23 22:30:14,721 - 3925 samples (32 per mini-batch)
2024-04-23 22:30:32,987 - Epoch: [261][  100/  123]    Loss 0.663287    Top1 78.500000    Top5 97.437500    
2024-04-23 22:30:37,451 - Epoch: [261][  123/  123]    Loss 0.659771    Top1 78.853503    Top5 97.554140    
2024-04-23 22:30:37,668 - ==> Top1: 78.854    Top5: 97.554    Loss: 0.660

2024-04-23 22:30:37,673 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:30:37,673 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:30:37,709 - 

2024-04-23 22:30:37,710 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:30:51,983 - Epoch: [262][  100/  296]    Overall Loss 0.668846    Objective Loss 0.668846                                        LR 0.000005    Time 0.142581    
2024-04-23 22:31:08,915 - Epoch: [262][  200/  296]    Overall Loss 0.662544    Objective Loss 0.662544                                        LR 0.000005    Time 0.155868    
2024-04-23 22:31:26,131 - Epoch: [262][  296/  296]    Overall Loss 0.668756    Objective Loss 0.668756    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.163425    
2024-04-23 22:31:26,346 - --- validate (epoch=262)-----------
2024-04-23 22:31:26,347 - 3925 samples (32 per mini-batch)
2024-04-23 22:31:44,920 - Epoch: [262][  100/  123]    Loss 0.658366    Top1 79.187500    Top5 97.656250    
2024-04-23 22:31:49,332 - Epoch: [262][  123/  123]    Loss 0.659080    Top1 79.108280    Top5 97.605096    
2024-04-23 22:31:49,558 - ==> Top1: 79.108    Top5: 97.605    Loss: 0.659

2024-04-23 22:31:49,564 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:31:49,564 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:31:49,598 - 

2024-04-23 22:31:49,598 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:32:07,516 - Epoch: [263][  100/  296]    Overall Loss 0.653583    Objective Loss 0.653583                                        LR 0.000005    Time 0.179008    
2024-04-23 22:32:28,193 - Epoch: [263][  200/  296]    Overall Loss 0.674110    Objective Loss 0.674110                                        LR 0.000005    Time 0.192810    
2024-04-23 22:32:47,965 - Epoch: [263][  296/  296]    Overall Loss 0.673846    Objective Loss 0.673846    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.197021    
2024-04-23 22:32:48,225 - --- validate (epoch=263)-----------
2024-04-23 22:32:48,226 - 3925 samples (32 per mini-batch)
2024-04-23 22:33:13,382 - Epoch: [263][  100/  123]    Loss 0.668161    Top1 78.468750    Top5 97.281250    
2024-04-23 22:33:18,109 - Epoch: [263][  123/  123]    Loss 0.661373    Top1 78.675159    Top5 97.477707    
2024-04-23 22:33:18,240 - ==> Top1: 78.675    Top5: 97.478    Loss: 0.661

2024-04-23 22:33:18,249 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:33:18,250 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:33:18,295 - 

2024-04-23 22:33:18,296 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:33:39,191 - Epoch: [264][  100/  296]    Overall Loss 0.666470    Objective Loss 0.666470                                        LR 0.000005    Time 0.208786    
2024-04-23 22:33:57,030 - Epoch: [264][  200/  296]    Overall Loss 0.655019    Objective Loss 0.655019                                        LR 0.000005    Time 0.193507    
2024-04-23 22:34:16,937 - Epoch: [264][  296/  296]    Overall Loss 0.660953    Objective Loss 0.660953    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.197948    
2024-04-23 22:34:17,157 - --- validate (epoch=264)-----------
2024-04-23 22:34:17,158 - 3925 samples (32 per mini-batch)
2024-04-23 22:34:42,086 - Epoch: [264][  100/  123]    Loss 0.653840    Top1 78.781250    Top5 97.750000    
2024-04-23 22:34:47,030 - Epoch: [264][  123/  123]    Loss 0.658266    Top1 78.777070    Top5 97.528662    
2024-04-23 22:34:47,217 - ==> Top1: 78.777    Top5: 97.529    Loss: 0.658

2024-04-23 22:34:47,222 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:34:47,222 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:34:47,264 - 

2024-04-23 22:34:47,265 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:35:09,704 - Epoch: [265][  100/  296]    Overall Loss 0.687395    Objective Loss 0.687395                                        LR 0.000005    Time 0.224238    
2024-04-23 22:35:28,919 - Epoch: [265][  200/  296]    Overall Loss 0.689965    Objective Loss 0.689965                                        LR 0.000005    Time 0.208117    
2024-04-23 22:35:45,737 - Epoch: [265][  296/  296]    Overall Loss 0.687841    Objective Loss 0.687841    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.197392    
2024-04-23 22:35:46,031 - --- validate (epoch=265)-----------
2024-04-23 22:35:46,032 - 3925 samples (32 per mini-batch)
2024-04-23 22:36:06,788 - Epoch: [265][  100/  123]    Loss 0.650560    Top1 79.156250    Top5 97.625000    
2024-04-23 22:36:10,661 - Epoch: [265][  123/  123]    Loss 0.660018    Top1 78.751592    Top5 97.605096    
2024-04-23 22:36:11,025 - ==> Top1: 78.752    Top5: 97.605    Loss: 0.660

2024-04-23 22:36:11,035 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:36:11,036 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:36:11,080 - 

2024-04-23 22:36:11,081 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:36:32,697 - Epoch: [266][  100/  296]    Overall Loss 0.659672    Objective Loss 0.659672                                        LR 0.000005    Time 0.216004    
2024-04-23 22:36:49,673 - Epoch: [266][  200/  296]    Overall Loss 0.657210    Objective Loss 0.657210                                        LR 0.000005    Time 0.192809    
2024-04-23 22:37:05,486 - Epoch: [266][  296/  296]    Overall Loss 0.659484    Objective Loss 0.659484    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.183642    
2024-04-23 22:37:05,898 - --- validate (epoch=266)-----------
2024-04-23 22:37:05,899 - 3925 samples (32 per mini-batch)
2024-04-23 22:37:27,391 - Epoch: [266][  100/  123]    Loss 0.633589    Top1 79.687500    Top5 97.687500    
2024-04-23 22:37:30,855 - Epoch: [266][  123/  123]    Loss 0.657089    Top1 79.057325    Top5 97.579618    
2024-04-23 22:37:31,008 - ==> Top1: 79.057    Top5: 97.580    Loss: 0.657

2024-04-23 22:37:31,016 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:37:31,016 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:37:31,070 - 

2024-04-23 22:37:31,070 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:37:51,018 - Epoch: [267][  100/  296]    Overall Loss 0.655783    Objective Loss 0.655783                                        LR 0.000005    Time 0.199324    
2024-04-23 22:38:10,442 - Epoch: [267][  200/  296]    Overall Loss 0.654476    Objective Loss 0.654476                                        LR 0.000005    Time 0.196708    
2024-04-23 22:38:26,682 - Epoch: [267][  296/  296]    Overall Loss 0.660271    Objective Loss 0.660271    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.187719    
2024-04-23 22:38:26,994 - --- validate (epoch=267)-----------
2024-04-23 22:38:26,995 - 3925 samples (32 per mini-batch)
2024-04-23 22:38:47,036 - Epoch: [267][  100/  123]    Loss 0.668496    Top1 78.406250    Top5 97.531250    
2024-04-23 22:38:50,861 - Epoch: [267][  123/  123]    Loss 0.660224    Top1 78.751592    Top5 97.554140    
2024-04-23 22:38:51,111 - ==> Top1: 78.752    Top5: 97.554    Loss: 0.660

2024-04-23 22:38:51,117 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:38:51,117 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:38:51,157 - 

2024-04-23 22:38:51,158 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:39:10,411 - Epoch: [268][  100/  296]    Overall Loss 0.644859    Objective Loss 0.644859                                        LR 0.000005    Time 0.192354    
2024-04-23 22:39:30,735 - Epoch: [268][  200/  296]    Overall Loss 0.643327    Objective Loss 0.643327                                        LR 0.000005    Time 0.197708    
2024-04-23 22:39:48,850 - Epoch: [268][  296/  296]    Overall Loss 0.648270    Objective Loss 0.648270    Top1 86.885246    Top5 93.442623    LR 0.000005    Time 0.194745    
2024-04-23 22:39:49,145 - --- validate (epoch=268)-----------
2024-04-23 22:39:49,146 - 3925 samples (32 per mini-batch)
2024-04-23 22:40:10,560 - Epoch: [268][  100/  123]    Loss 0.673485    Top1 78.406250    Top5 97.562500    
2024-04-23 22:40:15,426 - Epoch: [268][  123/  123]    Loss 0.661087    Top1 78.955414    Top5 97.605096    
2024-04-23 22:40:15,585 - ==> Top1: 78.955    Top5: 97.605    Loss: 0.661

2024-04-23 22:40:15,596 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:40:15,596 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:40:15,644 - 

2024-04-23 22:40:15,645 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:40:33,918 - Epoch: [269][  100/  296]    Overall Loss 0.642581    Objective Loss 0.642581                                        LR 0.000005    Time 0.182560    
2024-04-23 22:40:48,342 - Epoch: [269][  200/  296]    Overall Loss 0.661622    Objective Loss 0.661622                                        LR 0.000005    Time 0.163318    
2024-04-23 22:40:59,556 - Epoch: [269][  296/  296]    Overall Loss 0.663965    Objective Loss 0.663965    Top1 73.770492    Top5 93.442623    LR 0.000005    Time 0.148187    
2024-04-23 22:40:59,769 - --- validate (epoch=269)-----------
2024-04-23 22:40:59,770 - 3925 samples (32 per mini-batch)
2024-04-23 22:41:13,781 - Epoch: [269][  100/  123]    Loss 0.661276    Top1 79.062500    Top5 97.562500    
2024-04-23 22:41:16,373 - Epoch: [269][  123/  123]    Loss 0.657886    Top1 78.955414    Top5 97.579618    
2024-04-23 22:41:16,591 - ==> Top1: 78.955    Top5: 97.580    Loss: 0.658

2024-04-23 22:41:16,600 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:41:16,601 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:41:16,638 - 

2024-04-23 22:41:16,639 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:41:32,224 - Epoch: [270][  100/  296]    Overall Loss 0.660140    Objective Loss 0.660140                                        LR 0.000005    Time 0.155689    
2024-04-23 22:41:49,074 - Epoch: [270][  200/  296]    Overall Loss 0.658955    Objective Loss 0.658955                                        LR 0.000005    Time 0.162015    
2024-04-23 22:42:07,007 - Epoch: [270][  296/  296]    Overall Loss 0.653372    Objective Loss 0.653372    Top1 78.688525    Top5 88.524590    LR 0.000005    Time 0.170003    
2024-04-23 22:42:07,343 - --- validate (epoch=270)-----------
2024-04-23 22:42:07,344 - 3925 samples (32 per mini-batch)
2024-04-23 22:42:24,902 - Epoch: [270][  100/  123]    Loss 0.655626    Top1 78.500000    Top5 97.562500    
2024-04-23 22:42:28,077 - Epoch: [270][  123/  123]    Loss 0.660220    Top1 78.802548    Top5 97.630573    
2024-04-23 22:42:28,298 - ==> Top1: 78.803    Top5: 97.631    Loss: 0.660

2024-04-23 22:42:28,306 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:42:28,306 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:42:28,349 - 

2024-04-23 22:42:28,350 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:42:47,598 - Epoch: [271][  100/  296]    Overall Loss 0.656261    Objective Loss 0.656261                                        LR 0.000005    Time 0.192320    
2024-04-23 22:43:05,598 - Epoch: [271][  200/  296]    Overall Loss 0.659805    Objective Loss 0.659805                                        LR 0.000005    Time 0.186081    
2024-04-23 22:43:21,319 - Epoch: [271][  296/  296]    Overall Loss 0.667904    Objective Loss 0.667904    Top1 70.491803    Top5 100.000000    LR 0.000005    Time 0.178788    
2024-04-23 22:43:21,520 - --- validate (epoch=271)-----------
2024-04-23 22:43:21,520 - 3925 samples (32 per mini-batch)
2024-04-23 22:43:39,857 - Epoch: [271][  100/  123]    Loss 0.674288    Top1 78.437500    Top5 97.500000    
2024-04-23 22:43:42,896 - Epoch: [271][  123/  123]    Loss 0.656180    Top1 79.057325    Top5 97.681529    
2024-04-23 22:43:43,103 - ==> Top1: 79.057    Top5: 97.682    Loss: 0.656

2024-04-23 22:43:43,108 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:43:43,108 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:43:43,131 - 

2024-04-23 22:43:43,131 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:44:02,022 - Epoch: [272][  100/  296]    Overall Loss 0.671762    Objective Loss 0.671762                                        LR 0.000005    Time 0.188746    
2024-04-23 22:44:22,342 - Epoch: [272][  200/  296]    Overall Loss 0.686935    Objective Loss 0.686935                                        LR 0.000005    Time 0.195895    
2024-04-23 22:44:42,388 - Epoch: [272][  296/  296]    Overall Loss 0.674514    Objective Loss 0.674514    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.200035    
2024-04-23 22:44:42,583 - --- validate (epoch=272)-----------
2024-04-23 22:44:42,584 - 3925 samples (32 per mini-batch)
2024-04-23 22:45:06,333 - Epoch: [272][  100/  123]    Loss 0.679863    Top1 78.625000    Top5 97.375000    
2024-04-23 22:45:10,874 - Epoch: [272][  123/  123]    Loss 0.663807    Top1 78.777070    Top5 97.477707    
2024-04-23 22:45:11,116 - ==> Top1: 78.777    Top5: 97.478    Loss: 0.664

2024-04-23 22:45:11,126 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:45:11,126 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:45:11,184 - 

2024-04-23 22:45:11,184 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:45:32,610 - Epoch: [273][  100/  296]    Overall Loss 0.661611    Objective Loss 0.661611                                        LR 0.000005    Time 0.214077    
2024-04-23 22:45:49,924 - Epoch: [273][  200/  296]    Overall Loss 0.658886    Objective Loss 0.658886                                        LR 0.000005    Time 0.193528    
2024-04-23 22:46:07,040 - Epoch: [273][  296/  296]    Overall Loss 0.662716    Objective Loss 0.662716    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.188532    
2024-04-23 22:46:07,157 - --- validate (epoch=273)-----------
2024-04-23 22:46:07,158 - 3925 samples (32 per mini-batch)
2024-04-23 22:46:28,081 - Epoch: [273][  100/  123]    Loss 0.654914    Top1 79.187500    Top5 97.406250    
2024-04-23 22:46:31,522 - Epoch: [273][  123/  123]    Loss 0.660338    Top1 78.828025    Top5 97.528662    
2024-04-23 22:46:31,718 - ==> Top1: 78.828    Top5: 97.529    Loss: 0.660

2024-04-23 22:46:31,726 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:46:31,727 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:46:31,771 - 

2024-04-23 22:46:31,771 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:46:52,418 - Epoch: [274][  100/  296]    Overall Loss 0.666898    Objective Loss 0.666898                                        LR 0.000005    Time 0.206298    
2024-04-23 22:47:10,618 - Epoch: [274][  200/  296]    Overall Loss 0.666232    Objective Loss 0.666232                                        LR 0.000005    Time 0.194067    
2024-04-23 22:47:28,613 - Epoch: [274][  296/  296]    Overall Loss 0.663505    Objective Loss 0.663505    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.191864    
2024-04-23 22:47:28,997 - --- validate (epoch=274)-----------
2024-04-23 22:47:28,998 - 3925 samples (32 per mini-batch)
2024-04-23 22:47:48,257 - Epoch: [274][  100/  123]    Loss 0.674642    Top1 78.156250    Top5 97.468750    
2024-04-23 22:47:52,501 - Epoch: [274][  123/  123]    Loss 0.660631    Top1 78.573248    Top5 97.630573    
2024-04-23 22:47:52,803 - ==> Top1: 78.573    Top5: 97.631    Loss: 0.661

2024-04-23 22:47:52,813 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:47:52,814 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:47:52,860 - 

2024-04-23 22:47:52,860 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:48:14,890 - Epoch: [275][  100/  296]    Overall Loss 0.709455    Objective Loss 0.709455                                        LR 0.000005    Time 0.220121    
2024-04-23 22:48:33,449 - Epoch: [275][  200/  296]    Overall Loss 0.704175    Objective Loss 0.704175                                        LR 0.000005    Time 0.202774    
2024-04-23 22:48:43,998 - Epoch: [275][  296/  296]    Overall Loss 0.677870    Objective Loss 0.677870    Top1 75.409836    Top5 90.163934    LR 0.000005    Time 0.172595    
2024-04-23 22:48:44,159 - --- validate (epoch=275)-----------
2024-04-23 22:48:44,160 - 3925 samples (32 per mini-batch)
2024-04-23 22:49:01,901 - Epoch: [275][  100/  123]    Loss 0.655171    Top1 78.656250    Top5 97.875000    
2024-04-23 22:49:04,553 - Epoch: [275][  123/  123]    Loss 0.662529    Top1 78.496815    Top5 97.656051    
2024-04-23 22:49:04,799 - ==> Top1: 78.497    Top5: 97.656    Loss: 0.663

2024-04-23 22:49:04,808 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:49:04,809 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:49:04,858 - 

2024-04-23 22:49:04,859 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:49:25,320 - Epoch: [276][  100/  296]    Overall Loss 0.671838    Objective Loss 0.671838                                        LR 0.000005    Time 0.204467    
2024-04-23 22:49:44,604 - Epoch: [276][  200/  296]    Overall Loss 0.687445    Objective Loss 0.687445                                        LR 0.000005    Time 0.198576    
2024-04-23 22:50:01,642 - Epoch: [276][  296/  296]    Overall Loss 0.673470    Objective Loss 0.673470    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.191683    
2024-04-23 22:50:01,939 - --- validate (epoch=276)-----------
2024-04-23 22:50:01,940 - 3925 samples (32 per mini-batch)
2024-04-23 22:50:23,306 - Epoch: [276][  100/  123]    Loss 0.656490    Top1 78.593750    Top5 97.625000    
2024-04-23 22:50:27,978 - Epoch: [276][  123/  123]    Loss 0.662139    Top1 78.598726    Top5 97.579618    
2024-04-23 22:50:28,211 - ==> Top1: 78.599    Top5: 97.580    Loss: 0.662

2024-04-23 22:50:28,221 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:50:28,222 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:50:28,284 - 

2024-04-23 22:50:28,285 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:50:50,349 - Epoch: [277][  100/  296]    Overall Loss 0.657042    Objective Loss 0.657042                                        LR 0.000005    Time 0.220474    
2024-04-23 22:51:09,875 - Epoch: [277][  200/  296]    Overall Loss 0.665025    Objective Loss 0.665025                                        LR 0.000005    Time 0.207786    
2024-04-23 22:51:27,665 - Epoch: [277][  296/  296]    Overall Loss 0.677549    Objective Loss 0.677549    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.200447    
2024-04-23 22:51:27,912 - --- validate (epoch=277)-----------
2024-04-23 22:51:27,914 - 3925 samples (32 per mini-batch)
2024-04-23 22:51:48,632 - Epoch: [277][  100/  123]    Loss 0.666928    Top1 78.562500    Top5 97.531250    
2024-04-23 22:51:53,241 - Epoch: [277][  123/  123]    Loss 0.659491    Top1 78.777070    Top5 97.579618    
2024-04-23 22:51:53,474 - ==> Top1: 78.777    Top5: 97.580    Loss: 0.659

2024-04-23 22:51:53,481 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:51:53,481 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:51:53,523 - 

2024-04-23 22:51:53,524 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:52:12,103 - Epoch: [278][  100/  296]    Overall Loss 0.658178    Objective Loss 0.658178                                        LR 0.000005    Time 0.185628    
2024-04-23 22:52:26,856 - Epoch: [278][  200/  296]    Overall Loss 0.681398    Objective Loss 0.681398                                        LR 0.000005    Time 0.166495    
2024-04-23 22:52:43,894 - Epoch: [278][  296/  296]    Overall Loss 0.677161    Objective Loss 0.677161    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.170004    
2024-04-23 22:52:44,168 - --- validate (epoch=278)-----------
2024-04-23 22:52:44,169 - 3925 samples (32 per mini-batch)
2024-04-23 22:53:05,150 - Epoch: [278][  100/  123]    Loss 0.655635    Top1 78.562500    Top5 97.656250    
2024-04-23 22:53:08,853 - Epoch: [278][  123/  123]    Loss 0.657463    Top1 78.777070    Top5 97.656051    
2024-04-23 22:53:09,054 - ==> Top1: 78.777    Top5: 97.656    Loss: 0.657

2024-04-23 22:53:09,061 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:53:09,061 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:53:09,115 - 

2024-04-23 22:53:09,116 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:53:29,464 - Epoch: [279][  100/  296]    Overall Loss 0.673117    Objective Loss 0.673117                                        LR 0.000005    Time 0.203319    
2024-04-23 22:53:49,020 - Epoch: [279][  200/  296]    Overall Loss 0.686615    Objective Loss 0.686615                                        LR 0.000005    Time 0.199356    
2024-04-23 22:54:06,073 - Epoch: [279][  296/  296]    Overall Loss 0.684160    Objective Loss 0.684160    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.192257    
2024-04-23 22:54:06,308 - --- validate (epoch=279)-----------
2024-04-23 22:54:06,309 - 3925 samples (32 per mini-batch)
2024-04-23 22:54:28,858 - Epoch: [279][  100/  123]    Loss 0.658514    Top1 78.906250    Top5 97.750000    
2024-04-23 22:54:33,656 - Epoch: [279][  123/  123]    Loss 0.662438    Top1 78.777070    Top5 97.503185    
2024-04-23 22:54:33,834 - ==> Top1: 78.777    Top5: 97.503    Loss: 0.662

2024-04-23 22:54:33,841 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:54:33,841 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:54:33,886 - 

2024-04-23 22:54:33,886 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:54:56,227 - Epoch: [280][  100/  296]    Overall Loss 0.670029    Objective Loss 0.670029                                        LR 0.000005    Time 0.223242    
2024-04-23 22:55:16,074 - Epoch: [280][  200/  296]    Overall Loss 0.667361    Objective Loss 0.667361                                        LR 0.000005    Time 0.210778    
2024-04-23 22:55:33,918 - Epoch: [280][  296/  296]    Overall Loss 0.665887    Objective Loss 0.665887    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.202647    
2024-04-23 22:55:34,241 - --- validate (epoch=280)-----------
2024-04-23 22:55:34,242 - 3925 samples (32 per mini-batch)
2024-04-23 22:55:54,343 - Epoch: [280][  100/  123]    Loss 0.684016    Top1 77.781250    Top5 97.406250    
2024-04-23 22:55:57,924 - Epoch: [280][  123/  123]    Loss 0.661510    Top1 78.573248    Top5 97.554140    
2024-04-23 22:55:58,256 - ==> Top1: 78.573    Top5: 97.554    Loss: 0.662

2024-04-23 22:55:58,268 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:55:58,269 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:55:58,321 - 

2024-04-23 22:55:58,321 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:56:19,323 - Epoch: [281][  100/  296]    Overall Loss 0.686630    Objective Loss 0.686630                                        LR 0.000005    Time 0.209855    
2024-04-23 22:56:37,022 - Epoch: [281][  200/  296]    Overall Loss 0.696456    Objective Loss 0.696456                                        LR 0.000005    Time 0.193344    
2024-04-23 22:56:54,605 - Epoch: [281][  296/  296]    Overall Loss 0.677717    Objective Loss 0.677717    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.189992    
2024-04-23 22:56:54,895 - --- validate (epoch=281)-----------
2024-04-23 22:56:54,896 - 3925 samples (32 per mini-batch)
2024-04-23 22:57:14,314 - Epoch: [281][  100/  123]    Loss 0.654575    Top1 78.843750    Top5 97.843750    
2024-04-23 22:57:17,953 - Epoch: [281][  123/  123]    Loss 0.656385    Top1 78.980892    Top5 97.656051    
2024-04-23 22:57:18,210 - ==> Top1: 78.981    Top5: 97.656    Loss: 0.656

2024-04-23 22:57:18,218 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:57:18,219 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:57:18,256 - 

2024-04-23 22:57:18,257 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:57:37,765 - Epoch: [282][  100/  296]    Overall Loss 0.658970    Objective Loss 0.658970                                        LR 0.000005    Time 0.194887    
2024-04-23 22:57:56,276 - Epoch: [282][  200/  296]    Overall Loss 0.668720    Objective Loss 0.668720                                        LR 0.000005    Time 0.189917    
2024-04-23 22:58:14,592 - Epoch: [282][  296/  296]    Overall Loss 0.664935    Objective Loss 0.664935    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.190151    
2024-04-23 22:58:14,904 - --- validate (epoch=282)-----------
2024-04-23 22:58:14,905 - 3925 samples (32 per mini-batch)
2024-04-23 22:58:29,878 - Epoch: [282][  100/  123]    Loss 0.662841    Top1 78.906250    Top5 97.562500    
2024-04-23 22:58:34,762 - Epoch: [282][  123/  123]    Loss 0.660947    Top1 78.878981    Top5 97.579618    
2024-04-23 22:58:34,978 - ==> Top1: 78.879    Top5: 97.580    Loss: 0.661

2024-04-23 22:58:34,987 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:58:34,988 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:58:35,031 - 

2024-04-23 22:58:35,032 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 22:58:56,233 - Epoch: [283][  100/  296]    Overall Loss 0.663256    Objective Loss 0.663256                                        LR 0.000005    Time 0.211821    
2024-04-23 22:59:11,463 - Epoch: [283][  200/  296]    Overall Loss 0.657512    Objective Loss 0.657512                                        LR 0.000005    Time 0.181977    
2024-04-23 22:59:22,412 - Epoch: [283][  296/  296]    Overall Loss 0.670694    Objective Loss 0.670694    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.159902    
2024-04-23 22:59:22,718 - --- validate (epoch=283)-----------
2024-04-23 22:59:22,719 - 3925 samples (32 per mini-batch)
2024-04-23 22:59:43,101 - Epoch: [283][  100/  123]    Loss 0.672346    Top1 77.937500    Top5 97.500000    
2024-04-23 22:59:48,037 - Epoch: [283][  123/  123]    Loss 0.660712    Top1 78.445860    Top5 97.503185    
2024-04-23 22:59:48,311 - ==> Top1: 78.446    Top5: 97.503    Loss: 0.661

2024-04-23 22:59:48,322 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 22:59:48,322 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 22:59:48,368 - 

2024-04-23 22:59:48,369 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:00:09,679 - Epoch: [284][  100/  296]    Overall Loss 0.648540    Objective Loss 0.648540                                        LR 0.000005    Time 0.212933    
2024-04-23 23:00:26,453 - Epoch: [284][  200/  296]    Overall Loss 0.650640    Objective Loss 0.650640                                        LR 0.000005    Time 0.190264    
2024-04-23 23:00:42,313 - Epoch: [284][  296/  296]    Overall Loss 0.648835    Objective Loss 0.648835    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.182086    
2024-04-23 23:00:42,575 - --- validate (epoch=284)-----------
2024-04-23 23:00:42,576 - 3925 samples (32 per mini-batch)
2024-04-23 23:01:03,930 - Epoch: [284][  100/  123]    Loss 0.659591    Top1 78.468750    Top5 97.593750    
2024-04-23 23:01:08,800 - Epoch: [284][  123/  123]    Loss 0.658359    Top1 78.675159    Top5 97.528662    
2024-04-23 23:01:09,040 - ==> Top1: 78.675    Top5: 97.529    Loss: 0.658

2024-04-23 23:01:09,049 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 23:01:09,049 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:01:09,086 - 

2024-04-23 23:01:09,087 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:01:25,604 - Epoch: [285][  100/  296]    Overall Loss 0.634280    Objective Loss 0.634280                                        LR 0.000005    Time 0.165023    
2024-04-23 23:01:41,496 - Epoch: [285][  200/  296]    Overall Loss 0.647295    Objective Loss 0.647295                                        LR 0.000005    Time 0.161891    
2024-04-23 23:01:56,220 - Epoch: [285][  296/  296]    Overall Loss 0.652081    Objective Loss 0.652081    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.159082    
2024-04-23 23:01:56,500 - --- validate (epoch=285)-----------
2024-04-23 23:01:56,500 - 3925 samples (32 per mini-batch)
2024-04-23 23:02:13,878 - Epoch: [285][  100/  123]    Loss 0.669201    Top1 78.343750    Top5 97.593750    
2024-04-23 23:02:18,079 - Epoch: [285][  123/  123]    Loss 0.658821    Top1 78.777070    Top5 97.605096    
2024-04-23 23:02:18,277 - ==> Top1: 78.777    Top5: 97.605    Loss: 0.659

2024-04-23 23:02:18,287 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 23:02:18,287 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:02:18,325 - 

2024-04-23 23:02:18,326 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:02:35,952 - Epoch: [286][  100/  296]    Overall Loss 0.658509    Objective Loss 0.658509                                        LR 0.000005    Time 0.176070    
2024-04-23 23:02:54,685 - Epoch: [286][  200/  296]    Overall Loss 0.678822    Objective Loss 0.678822                                        LR 0.000005    Time 0.181622    
2024-04-23 23:03:10,407 - Epoch: [286][  296/  296]    Overall Loss 0.668117    Objective Loss 0.668117    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.175784    
2024-04-23 23:03:10,691 - --- validate (epoch=286)-----------
2024-04-23 23:03:10,692 - 3925 samples (32 per mini-batch)
2024-04-23 23:03:30,891 - Epoch: [286][  100/  123]    Loss 0.679076    Top1 77.906250    Top5 97.468750    
2024-04-23 23:03:34,488 - Epoch: [286][  123/  123]    Loss 0.663704    Top1 78.547771    Top5 97.477707    
2024-04-23 23:03:34,704 - ==> Top1: 78.548    Top5: 97.478    Loss: 0.664

2024-04-23 23:03:34,717 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 23:03:34,717 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:03:34,791 - 

2024-04-23 23:03:34,791 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:03:52,221 - Epoch: [287][  100/  296]    Overall Loss 0.650491    Objective Loss 0.650491                                        LR 0.000005    Time 0.174115    
2024-04-23 23:04:06,903 - Epoch: [287][  200/  296]    Overall Loss 0.657927    Objective Loss 0.657927                                        LR 0.000005    Time 0.160384    
2024-04-23 23:04:19,254 - Epoch: [287][  296/  296]    Overall Loss 0.659343    Objective Loss 0.659343    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.150048    
2024-04-23 23:04:19,577 - --- validate (epoch=287)-----------
2024-04-23 23:04:19,578 - 3925 samples (32 per mini-batch)
2024-04-23 23:04:31,227 - Epoch: [287][  100/  123]    Loss 0.662227    Top1 78.406250    Top5 97.343750    
2024-04-23 23:04:33,303 - Epoch: [287][  123/  123]    Loss 0.661094    Top1 78.471338    Top5 97.528662    
2024-04-23 23:04:33,520 - ==> Top1: 78.471    Top5: 97.529    Loss: 0.661

2024-04-23 23:04:33,529 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 23:04:33,529 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:04:33,564 - 

2024-04-23 23:04:33,564 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:04:50,768 - Epoch: [288][  100/  296]    Overall Loss 0.700649    Objective Loss 0.700649                                        LR 0.000005    Time 0.171871    
2024-04-23 23:05:06,881 - Epoch: [288][  200/  296]    Overall Loss 0.690417    Objective Loss 0.690417                                        LR 0.000005    Time 0.166419    
2024-04-23 23:05:18,100 - Epoch: [288][  296/  296]    Overall Loss 0.675752    Objective Loss 0.675752    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.150303    
2024-04-23 23:05:18,323 - --- validate (epoch=288)-----------
2024-04-23 23:05:18,324 - 3925 samples (32 per mini-batch)
2024-04-23 23:05:33,832 - Epoch: [288][  100/  123]    Loss 0.670584    Top1 78.687500    Top5 97.656250    
2024-04-23 23:05:37,282 - Epoch: [288][  123/  123]    Loss 0.661870    Top1 78.853503    Top5 97.681529    
2024-04-23 23:05:37,497 - ==> Top1: 78.854    Top5: 97.682    Loss: 0.662

2024-04-23 23:05:37,508 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 23:05:37,508 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:05:37,546 - 

2024-04-23 23:05:37,547 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:05:56,954 - Epoch: [289][  100/  296]    Overall Loss 0.644554    Objective Loss 0.644554                                        LR 0.000005    Time 0.193901    
2024-04-23 23:06:14,724 - Epoch: [289][  200/  296]    Overall Loss 0.661563    Objective Loss 0.661563                                        LR 0.000005    Time 0.185725    
2024-04-23 23:06:28,980 - Epoch: [289][  296/  296]    Overall Loss 0.679023    Objective Loss 0.679023    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.173602    
2024-04-23 23:06:29,245 - --- validate (epoch=289)-----------
2024-04-23 23:06:29,246 - 3925 samples (32 per mini-batch)
2024-04-23 23:06:41,268 - Epoch: [289][  100/  123]    Loss 0.668763    Top1 78.312500    Top5 97.625000    
2024-04-23 23:06:43,318 - Epoch: [289][  123/  123]    Loss 0.663505    Top1 78.649682    Top5 97.426752    
2024-04-23 23:06:43,519 - ==> Top1: 78.650    Top5: 97.427    Loss: 0.664

2024-04-23 23:06:43,526 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 23:06:43,526 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:06:43,570 - 

2024-04-23 23:06:43,571 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:06:55,797 - Epoch: [290][  100/  296]    Overall Loss 0.690127    Objective Loss 0.690127                                        LR 0.000005    Time 0.122114    
2024-04-23 23:07:05,536 - Epoch: [290][  200/  296]    Overall Loss 0.681128    Objective Loss 0.681128                                        LR 0.000005    Time 0.109685    
2024-04-23 23:07:17,339 - Epoch: [290][  296/  296]    Overall Loss 0.671026    Objective Loss 0.671026    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.113942    
2024-04-23 23:07:17,528 - --- validate (epoch=290)-----------
2024-04-23 23:07:17,529 - 3925 samples (32 per mini-batch)
2024-04-23 23:07:40,213 - Epoch: [290][  100/  123]    Loss 0.663130    Top1 78.375000    Top5 97.375000    
2024-04-23 23:07:45,055 - Epoch: [290][  123/  123]    Loss 0.660862    Top1 78.700637    Top5 97.503185    
2024-04-23 23:07:45,337 - ==> Top1: 78.701    Top5: 97.503    Loss: 0.661

2024-04-23 23:07:45,347 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 23:07:45,348 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:07:45,389 - 

2024-04-23 23:07:45,390 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:08:07,537 - Epoch: [291][  100/  296]    Overall Loss 0.676369    Objective Loss 0.676369                                        LR 0.000005    Time 0.221293    
2024-04-23 23:08:28,123 - Epoch: [291][  200/  296]    Overall Loss 0.670074    Objective Loss 0.670074                                        LR 0.000005    Time 0.213493    
2024-04-23 23:08:43,243 - Epoch: [291][  296/  296]    Overall Loss 0.672893    Objective Loss 0.672893    Top1 88.524590    Top5 100.000000    LR 0.000005    Time 0.195282    
2024-04-23 23:08:43,399 - --- validate (epoch=291)-----------
2024-04-23 23:08:43,400 - 3925 samples (32 per mini-batch)
2024-04-23 23:09:03,353 - Epoch: [291][  100/  123]    Loss 0.663358    Top1 79.000000    Top5 97.500000    
2024-04-23 23:09:07,098 - Epoch: [291][  123/  123]    Loss 0.660273    Top1 79.031847    Top5 97.477707    
2024-04-23 23:09:07,358 - ==> Top1: 79.032    Top5: 97.478    Loss: 0.660

2024-04-23 23:09:07,369 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 23:09:07,369 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:09:07,410 - 

2024-04-23 23:09:07,411 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:09:24,637 - Epoch: [292][  100/  296]    Overall Loss 0.670021    Objective Loss 0.670021                                        LR 0.000005    Time 0.172095    
2024-04-23 23:09:42,194 - Epoch: [292][  200/  296]    Overall Loss 0.670364    Objective Loss 0.670364                                        LR 0.000005    Time 0.173751    
2024-04-23 23:09:58,996 - Epoch: [292][  296/  296]    Overall Loss 0.666677    Objective Loss 0.666677    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.174108    
2024-04-23 23:09:59,302 - --- validate (epoch=292)-----------
2024-04-23 23:09:59,303 - 3925 samples (32 per mini-batch)
2024-04-23 23:10:21,289 - Epoch: [292][  100/  123]    Loss 0.648152    Top1 79.375000    Top5 97.781250    
2024-04-23 23:10:25,825 - Epoch: [292][  123/  123]    Loss 0.658270    Top1 79.133758    Top5 97.503185    
2024-04-23 23:10:26,053 - ==> Top1: 79.134    Top5: 97.503    Loss: 0.658

2024-04-23 23:10:26,063 - ==> Best [Top1: 79.210   Top5: 97.580   Sparsity:0.00   Params: 376752 on epoch: 182]
2024-04-23 23:10:26,063 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:10:26,105 - 

2024-04-23 23:10:26,106 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:10:51,498 - Epoch: [293][  100/  296]    Overall Loss 0.676657    Objective Loss 0.676657                                        LR 0.000005    Time 0.253778    
2024-04-23 23:11:12,615 - Epoch: [293][  200/  296]    Overall Loss 0.669850    Objective Loss 0.669850                                        LR 0.000005    Time 0.232393    
2024-04-23 23:11:31,128 - Epoch: [293][  296/  296]    Overall Loss 0.675322    Objective Loss 0.675322    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.219521    
2024-04-23 23:11:31,427 - --- validate (epoch=293)-----------
2024-04-23 23:11:31,428 - 3925 samples (32 per mini-batch)
2024-04-23 23:11:55,537 - Epoch: [293][  100/  123]    Loss 0.649895    Top1 79.343750    Top5 97.375000    
2024-04-23 23:12:00,333 - Epoch: [293][  123/  123]    Loss 0.657175    Top1 79.261146    Top5 97.528662    
2024-04-23 23:12:00,526 - ==> Top1: 79.261    Top5: 97.529    Loss: 0.657

2024-04-23 23:12:00,536 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:12:00,536 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:12:00,590 - 

2024-04-23 23:12:00,590 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:12:19,844 - Epoch: [294][  100/  296]    Overall Loss 0.681171    Objective Loss 0.681171                                        LR 0.000005    Time 0.192369    
2024-04-23 23:12:38,463 - Epoch: [294][  200/  296]    Overall Loss 0.681596    Objective Loss 0.681596                                        LR 0.000005    Time 0.189196    
2024-04-23 23:12:56,417 - Epoch: [294][  296/  296]    Overall Loss 0.681828    Objective Loss 0.681828    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.188436    
2024-04-23 23:12:56,660 - --- validate (epoch=294)-----------
2024-04-23 23:12:56,661 - 3925 samples (32 per mini-batch)
2024-04-23 23:13:12,409 - Epoch: [294][  100/  123]    Loss 0.656725    Top1 78.656250    Top5 97.562500    
2024-04-23 23:13:15,439 - Epoch: [294][  123/  123]    Loss 0.659291    Top1 78.751592    Top5 97.605096    
2024-04-23 23:13:15,739 - ==> Top1: 78.752    Top5: 97.605    Loss: 0.659

2024-04-23 23:13:15,747 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:13:15,747 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:13:15,811 - 

2024-04-23 23:13:15,812 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:13:29,274 - Epoch: [295][  100/  296]    Overall Loss 0.695753    Objective Loss 0.695753                                        LR 0.000005    Time 0.134470    
2024-04-23 23:13:43,168 - Epoch: [295][  200/  296]    Overall Loss 0.672384    Objective Loss 0.672384                                        LR 0.000005    Time 0.136623    
2024-04-23 23:13:57,649 - Epoch: [295][  296/  296]    Overall Loss 0.665976    Objective Loss 0.665976    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.141189    
2024-04-23 23:13:57,858 - --- validate (epoch=295)-----------
2024-04-23 23:13:57,859 - 3925 samples (32 per mini-batch)
2024-04-23 23:14:17,311 - Epoch: [295][  100/  123]    Loss 0.663482    Top1 78.781250    Top5 97.500000    
2024-04-23 23:14:20,838 - Epoch: [295][  123/  123]    Loss 0.658964    Top1 78.726115    Top5 97.554140    
2024-04-23 23:14:21,035 - ==> Top1: 78.726    Top5: 97.554    Loss: 0.659

2024-04-23 23:14:21,043 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:14:21,044 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:14:21,079 - 

2024-04-23 23:14:21,080 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:14:35,984 - Epoch: [296][  100/  296]    Overall Loss 0.667466    Objective Loss 0.667466                                        LR 0.000005    Time 0.148881    
2024-04-23 23:14:58,631 - Epoch: [296][  200/  296]    Overall Loss 0.684468    Objective Loss 0.684468                                        LR 0.000005    Time 0.187588    
2024-04-23 23:15:16,100 - Epoch: [296][  296/  296]    Overall Loss 0.681931    Objective Loss 0.681931    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.185716    
2024-04-23 23:15:16,291 - --- validate (epoch=296)-----------
2024-04-23 23:15:16,292 - 3925 samples (32 per mini-batch)
2024-04-23 23:15:35,679 - Epoch: [296][  100/  123]    Loss 0.663355    Top1 78.875000    Top5 97.468750    
2024-04-23 23:15:38,665 - Epoch: [296][  123/  123]    Loss 0.657658    Top1 78.955414    Top5 97.605096    
2024-04-23 23:15:38,889 - ==> Top1: 78.955    Top5: 97.605    Loss: 0.658

2024-04-23 23:15:38,897 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:15:38,898 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:15:38,951 - 

2024-04-23 23:15:38,952 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:15:55,974 - Epoch: [297][  100/  296]    Overall Loss 0.647562    Objective Loss 0.647562                                        LR 0.000005    Time 0.170053    
2024-04-23 23:16:10,089 - Epoch: [297][  200/  296]    Overall Loss 0.667352    Objective Loss 0.667352                                        LR 0.000005    Time 0.155519    
2024-04-23 23:16:25,432 - Epoch: [297][  296/  296]    Overall Loss 0.666281    Objective Loss 0.666281    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.156864    
2024-04-23 23:16:25,673 - --- validate (epoch=297)-----------
2024-04-23 23:16:25,674 - 3925 samples (32 per mini-batch)
2024-04-23 23:16:42,538 - Epoch: [297][  100/  123]    Loss 0.644329    Top1 79.468750    Top5 97.812500    
2024-04-23 23:16:45,188 - Epoch: [297][  123/  123]    Loss 0.659190    Top1 78.955414    Top5 97.630573    
2024-04-23 23:16:45,373 - ==> Top1: 78.955    Top5: 97.631    Loss: 0.659

2024-04-23 23:16:45,377 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:16:45,377 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:16:45,403 - 

2024-04-23 23:16:45,403 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:17:04,944 - Epoch: [298][  100/  296]    Overall Loss 0.668422    Objective Loss 0.668422                                        LR 0.000005    Time 0.195224    
2024-04-23 23:17:17,839 - Epoch: [298][  200/  296]    Overall Loss 0.660633    Objective Loss 0.660633                                        LR 0.000005    Time 0.162014    
2024-04-23 23:17:33,726 - Epoch: [298][  296/  296]    Overall Loss 0.652606    Objective Loss 0.652606    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.163092    
2024-04-23 23:17:33,978 - --- validate (epoch=298)-----------
2024-04-23 23:17:33,979 - 3925 samples (32 per mini-batch)
2024-04-23 23:17:51,500 - Epoch: [298][  100/  123]    Loss 0.662662    Top1 78.687500    Top5 97.468750    
2024-04-23 23:17:55,469 - Epoch: [298][  123/  123]    Loss 0.658018    Top1 78.649682    Top5 97.554140    
2024-04-23 23:17:55,624 - ==> Top1: 78.650    Top5: 97.554    Loss: 0.658

2024-04-23 23:17:55,628 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:17:55,628 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:17:55,656 - 

2024-04-23 23:17:55,656 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:18:18,685 - Epoch: [299][  100/  296]    Overall Loss 0.670723    Objective Loss 0.670723                                        LR 0.000005    Time 0.230113    
2024-04-23 23:18:37,773 - Epoch: [299][  200/  296]    Overall Loss 0.677572    Objective Loss 0.677572                                        LR 0.000005    Time 0.210412    
2024-04-23 23:18:51,337 - Epoch: [299][  296/  296]    Overall Loss 0.670981    Objective Loss 0.670981    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.187945    
2024-04-23 23:18:51,499 - --- validate (epoch=299)-----------
2024-04-23 23:18:51,499 - 3925 samples (32 per mini-batch)
2024-04-23 23:19:10,407 - Epoch: [299][  100/  123]    Loss 0.652057    Top1 79.187500    Top5 97.468750    
2024-04-23 23:19:14,220 - Epoch: [299][  123/  123]    Loss 0.663245    Top1 78.980892    Top5 97.477707    
2024-04-23 23:19:14,457 - ==> Top1: 78.981    Top5: 97.478    Loss: 0.663

2024-04-23 23:19:14,466 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:19:14,466 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:19:14,504 - 

2024-04-23 23:19:14,504 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:19:35,353 - Epoch: [300][  100/  296]    Overall Loss 0.675553    Objective Loss 0.675553                                        LR 0.000005    Time 0.208304    
2024-04-23 23:19:55,259 - Epoch: [300][  200/  296]    Overall Loss 0.667842    Objective Loss 0.667842                                        LR 0.000005    Time 0.203598    
2024-04-23 23:20:12,139 - Epoch: [300][  296/  296]    Overall Loss 0.667607    Objective Loss 0.667607    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.194542    
2024-04-23 23:20:12,387 - --- validate (epoch=300)-----------
2024-04-23 23:20:12,388 - 3925 samples (32 per mini-batch)
2024-04-23 23:20:32,730 - Epoch: [300][  100/  123]    Loss 0.664475    Top1 78.500000    Top5 97.656250    
2024-04-23 23:20:36,667 - Epoch: [300][  123/  123]    Loss 0.660181    Top1 78.853503    Top5 97.579618    
2024-04-23 23:20:36,909 - ==> Top1: 78.854    Top5: 97.580    Loss: 0.660

2024-04-23 23:20:36,920 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:20:36,921 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:20:36,977 - 

2024-04-23 23:20:36,978 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:21:02,831 - Epoch: [301][  100/  296]    Overall Loss 0.657304    Objective Loss 0.657304                                        LR 0.000005    Time 0.258408    
2024-04-23 23:21:23,636 - Epoch: [301][  200/  296]    Overall Loss 0.655486    Objective Loss 0.655486                                        LR 0.000005    Time 0.233156    
2024-04-23 23:21:40,702 - Epoch: [301][  296/  296]    Overall Loss 0.656922    Objective Loss 0.656922    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.215146    
2024-04-23 23:21:40,938 - --- validate (epoch=301)-----------
2024-04-23 23:21:40,939 - 3925 samples (32 per mini-batch)
2024-04-23 23:22:03,596 - Epoch: [301][  100/  123]    Loss 0.649812    Top1 79.156250    Top5 97.531250    
2024-04-23 23:22:07,637 - Epoch: [301][  123/  123]    Loss 0.657863    Top1 79.006369    Top5 97.528662    
2024-04-23 23:22:07,888 - ==> Top1: 79.006    Top5: 97.529    Loss: 0.658

2024-04-23 23:22:07,897 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:22:07,898 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:22:07,943 - 

2024-04-23 23:22:07,944 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:22:28,450 - Epoch: [302][  100/  296]    Overall Loss 0.660251    Objective Loss 0.660251                                        LR 0.000005    Time 0.204910    
2024-04-23 23:22:45,413 - Epoch: [302][  200/  296]    Overall Loss 0.670466    Objective Loss 0.670466                                        LR 0.000005    Time 0.187182    
2024-04-23 23:23:04,861 - Epoch: [302][  296/  296]    Overall Loss 0.675440    Objective Loss 0.675440    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.192132    
2024-04-23 23:23:05,321 - --- validate (epoch=302)-----------
2024-04-23 23:23:05,322 - 3925 samples (32 per mini-batch)
2024-04-23 23:23:22,124 - Epoch: [302][  100/  123]    Loss 0.666086    Top1 78.718750    Top5 97.625000    
2024-04-23 23:23:26,840 - Epoch: [302][  123/  123]    Loss 0.658479    Top1 78.777070    Top5 97.681529    
2024-04-23 23:23:27,009 - ==> Top1: 78.777    Top5: 97.682    Loss: 0.658

2024-04-23 23:23:27,019 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:23:27,020 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:23:27,067 - 

2024-04-23 23:23:27,068 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:23:44,799 - Epoch: [303][  100/  296]    Overall Loss 0.666840    Objective Loss 0.666840                                        LR 0.000005    Time 0.177141    
2024-04-23 23:23:54,710 - Epoch: [303][  200/  296]    Overall Loss 0.657910    Objective Loss 0.657910                                        LR 0.000005    Time 0.138052    
2024-04-23 23:24:05,954 - Epoch: [303][  296/  296]    Overall Loss 0.664807    Objective Loss 0.664807    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.131209    
2024-04-23 23:24:06,132 - --- validate (epoch=303)-----------
2024-04-23 23:24:06,133 - 3925 samples (32 per mini-batch)
2024-04-23 23:24:21,323 - Epoch: [303][  100/  123]    Loss 0.640218    Top1 79.593750    Top5 97.562500    
2024-04-23 23:24:24,340 - Epoch: [303][  123/  123]    Loss 0.658961    Top1 78.929936    Top5 97.579618    
2024-04-23 23:24:24,498 - ==> Top1: 78.930    Top5: 97.580    Loss: 0.659

2024-04-23 23:24:24,506 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:24:24,506 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:24:24,548 - 

2024-04-23 23:24:24,549 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:24:42,934 - Epoch: [304][  100/  296]    Overall Loss 0.649463    Objective Loss 0.649463                                        LR 0.000005    Time 0.183698    
2024-04-23 23:24:59,921 - Epoch: [304][  200/  296]    Overall Loss 0.660086    Objective Loss 0.660086                                        LR 0.000005    Time 0.176697    
2024-04-23 23:25:20,324 - Epoch: [304][  296/  296]    Overall Loss 0.659607    Objective Loss 0.659607    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.188268    
2024-04-23 23:25:20,578 - --- validate (epoch=304)-----------
2024-04-23 23:25:20,579 - 3925 samples (32 per mini-batch)
2024-04-23 23:25:40,083 - Epoch: [304][  100/  123]    Loss 0.664184    Top1 79.000000    Top5 97.468750    
2024-04-23 23:25:43,732 - Epoch: [304][  123/  123]    Loss 0.663990    Top1 78.828025    Top5 97.503185    
2024-04-23 23:25:43,859 - ==> Top1: 78.828    Top5: 97.503    Loss: 0.664

2024-04-23 23:25:43,868 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:25:43,868 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:25:43,908 - 

2024-04-23 23:25:43,909 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:26:00,426 - Epoch: [305][  100/  296]    Overall Loss 0.678356    Objective Loss 0.678356                                        LR 0.000005    Time 0.165007    
2024-04-23 23:26:16,703 - Epoch: [305][  200/  296]    Overall Loss 0.666095    Objective Loss 0.666095                                        LR 0.000005    Time 0.163811    
2024-04-23 23:26:30,044 - Epoch: [305][  296/  296]    Overall Loss 0.668625    Objective Loss 0.668625    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.155700    
2024-04-23 23:26:30,187 - --- validate (epoch=305)-----------
2024-04-23 23:26:30,188 - 3925 samples (32 per mini-batch)
2024-04-23 23:26:45,392 - Epoch: [305][  100/  123]    Loss 0.652083    Top1 78.968750    Top5 97.406250    
2024-04-23 23:26:48,779 - Epoch: [305][  123/  123]    Loss 0.659951    Top1 78.573248    Top5 97.528662    
2024-04-23 23:26:48,891 - ==> Top1: 78.573    Top5: 97.529    Loss: 0.660

2024-04-23 23:26:48,897 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:26:48,897 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:26:48,943 - 

2024-04-23 23:26:48,943 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:27:07,038 - Epoch: [306][  100/  296]    Overall Loss 0.664721    Objective Loss 0.664721                                        LR 0.000005    Time 0.180782    
2024-04-23 23:27:24,531 - Epoch: [306][  200/  296]    Overall Loss 0.681301    Objective Loss 0.681301                                        LR 0.000005    Time 0.177777    
2024-04-23 23:27:41,091 - Epoch: [306][  296/  296]    Overall Loss 0.672071    Objective Loss 0.672071    Top1 81.967213    Top5 95.081967    LR 0.000005    Time 0.176012    
2024-04-23 23:27:41,351 - --- validate (epoch=306)-----------
2024-04-23 23:27:41,352 - 3925 samples (32 per mini-batch)
2024-04-23 23:28:01,532 - Epoch: [306][  100/  123]    Loss 0.655881    Top1 78.843750    Top5 97.656250    
2024-04-23 23:28:05,392 - Epoch: [306][  123/  123]    Loss 0.658217    Top1 78.726115    Top5 97.605096    
2024-04-23 23:28:05,702 - ==> Top1: 78.726    Top5: 97.605    Loss: 0.658

2024-04-23 23:28:05,710 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:28:05,710 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:28:05,772 - 

2024-04-23 23:28:05,773 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:28:26,377 - Epoch: [307][  100/  296]    Overall Loss 0.684299    Objective Loss 0.684299                                        LR 0.000005    Time 0.205847    
2024-04-23 23:28:43,481 - Epoch: [307][  200/  296]    Overall Loss 0.682323    Objective Loss 0.682323                                        LR 0.000005    Time 0.188365    
2024-04-23 23:28:59,267 - Epoch: [307][  296/  296]    Overall Loss 0.674239    Objective Loss 0.674239    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.180556    
2024-04-23 23:28:59,527 - --- validate (epoch=307)-----------
2024-04-23 23:28:59,529 - 3925 samples (32 per mini-batch)
2024-04-23 23:29:20,767 - Epoch: [307][  100/  123]    Loss 0.654721    Top1 78.937500    Top5 97.468750    
2024-04-23 23:29:24,974 - Epoch: [307][  123/  123]    Loss 0.657155    Top1 78.802548    Top5 97.503185    
2024-04-23 23:29:25,242 - ==> Top1: 78.803    Top5: 97.503    Loss: 0.657

2024-04-23 23:29:25,252 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:29:25,253 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:29:25,300 - 

2024-04-23 23:29:25,301 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:29:44,750 - Epoch: [308][  100/  296]    Overall Loss 0.681032    Objective Loss 0.681032                                        LR 0.000005    Time 0.194329    
2024-04-23 23:30:03,423 - Epoch: [308][  200/  296]    Overall Loss 0.672719    Objective Loss 0.672719                                        LR 0.000005    Time 0.190443    
2024-04-23 23:30:20,600 - Epoch: [308][  296/  296]    Overall Loss 0.674309    Objective Loss 0.674309    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.186659    
2024-04-23 23:30:20,961 - --- validate (epoch=308)-----------
2024-04-23 23:30:20,962 - 3925 samples (32 per mini-batch)
2024-04-23 23:30:42,504 - Epoch: [308][  100/  123]    Loss 0.672295    Top1 78.187500    Top5 97.500000    
2024-04-23 23:30:46,410 - Epoch: [308][  123/  123]    Loss 0.661186    Top1 78.496815    Top5 97.630573    
2024-04-23 23:30:46,605 - ==> Top1: 78.497    Top5: 97.631    Loss: 0.661

2024-04-23 23:30:46,613 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:30:46,614 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:30:46,660 - 

2024-04-23 23:30:46,661 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:31:07,126 - Epoch: [309][  100/  296]    Overall Loss 0.663779    Objective Loss 0.663779                                        LR 0.000005    Time 0.204484    
2024-04-23 23:31:26,264 - Epoch: [309][  200/  296]    Overall Loss 0.657373    Objective Loss 0.657373                                        LR 0.000005    Time 0.197861    
2024-04-23 23:31:46,138 - Epoch: [309][  296/  296]    Overall Loss 0.655913    Objective Loss 0.655913    Top1 83.606557    Top5 93.442623    LR 0.000005    Time 0.200776    
2024-04-23 23:31:46,370 - --- validate (epoch=309)-----------
2024-04-23 23:31:46,371 - 3925 samples (32 per mini-batch)
2024-04-23 23:32:11,952 - Epoch: [309][  100/  123]    Loss 0.669667    Top1 78.406250    Top5 97.406250    
2024-04-23 23:32:16,911 - Epoch: [309][  123/  123]    Loss 0.662351    Top1 78.726115    Top5 97.503185    
2024-04-23 23:32:17,094 - ==> Top1: 78.726    Top5: 97.503    Loss: 0.662

2024-04-23 23:32:17,104 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:32:17,105 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:32:17,164 - 

2024-04-23 23:32:17,165 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:32:30,731 - Epoch: [310][  100/  296]    Overall Loss 0.619759    Objective Loss 0.619759                                        LR 0.000005    Time 0.135533    
2024-04-23 23:32:45,660 - Epoch: [310][  200/  296]    Overall Loss 0.655614    Objective Loss 0.655614                                        LR 0.000005    Time 0.142337    
2024-04-23 23:32:57,442 - Epoch: [310][  296/  296]    Overall Loss 0.659836    Objective Loss 0.659836    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.135940    
2024-04-23 23:32:57,555 - --- validate (epoch=310)-----------
2024-04-23 23:32:57,555 - 3925 samples (32 per mini-batch)
2024-04-23 23:33:11,299 - Epoch: [310][  100/  123]    Loss 0.647399    Top1 79.125000    Top5 97.531250    
2024-04-23 23:33:13,944 - Epoch: [310][  123/  123]    Loss 0.659441    Top1 78.726115    Top5 97.554140    
2024-04-23 23:33:14,058 - ==> Top1: 78.726    Top5: 97.554    Loss: 0.659

2024-04-23 23:33:14,066 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:33:14,066 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:33:14,105 - 

2024-04-23 23:33:14,105 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:33:25,830 - Epoch: [311][  100/  296]    Overall Loss 0.671790    Objective Loss 0.671790                                        LR 0.000005    Time 0.117128    
2024-04-23 23:33:38,931 - Epoch: [311][  200/  296]    Overall Loss 0.679253    Objective Loss 0.679253                                        LR 0.000005    Time 0.124000    
2024-04-23 23:33:52,148 - Epoch: [311][  296/  296]    Overall Loss 0.677650    Objective Loss 0.677650    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.128389    
2024-04-23 23:33:52,394 - --- validate (epoch=311)-----------
2024-04-23 23:33:52,395 - 3925 samples (32 per mini-batch)
2024-04-23 23:34:09,846 - Epoch: [311][  100/  123]    Loss 0.645942    Top1 79.156250    Top5 97.562500    
2024-04-23 23:34:12,591 - Epoch: [311][  123/  123]    Loss 0.658658    Top1 78.828025    Top5 97.375796    
2024-04-23 23:34:12,827 - ==> Top1: 78.828    Top5: 97.376    Loss: 0.659

2024-04-23 23:34:12,835 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:34:12,836 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:34:12,891 - 

2024-04-23 23:34:12,891 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:34:29,712 - Epoch: [312][  100/  296]    Overall Loss 0.659349    Objective Loss 0.659349                                        LR 0.000005    Time 0.168072    
2024-04-23 23:34:43,484 - Epoch: [312][  200/  296]    Overall Loss 0.656877    Objective Loss 0.656877                                        LR 0.000005    Time 0.152836    
2024-04-23 23:34:57,339 - Epoch: [312][  296/  296]    Overall Loss 0.663052    Objective Loss 0.663052    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.150036    
2024-04-23 23:34:57,450 - --- validate (epoch=312)-----------
2024-04-23 23:34:57,450 - 3925 samples (32 per mini-batch)
2024-04-23 23:35:15,819 - Epoch: [312][  100/  123]    Loss 0.647472    Top1 79.062500    Top5 97.625000    
2024-04-23 23:35:18,930 - Epoch: [312][  123/  123]    Loss 0.655954    Top1 78.955414    Top5 97.630573    
2024-04-23 23:35:19,218 - ==> Top1: 78.955    Top5: 97.631    Loss: 0.656

2024-04-23 23:35:19,223 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:35:19,223 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:35:19,259 - 

2024-04-23 23:35:19,259 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:35:36,106 - Epoch: [313][  100/  296]    Overall Loss 0.676427    Objective Loss 0.676427                                        LR 0.000005    Time 0.168329    
2024-04-23 23:35:49,639 - Epoch: [313][  200/  296]    Overall Loss 0.657284    Objective Loss 0.657284                                        LR 0.000005    Time 0.151762    
2024-04-23 23:36:01,739 - Epoch: [313][  296/  296]    Overall Loss 0.664821    Objective Loss 0.664821    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.143378    
2024-04-23 23:36:01,929 - --- validate (epoch=313)-----------
2024-04-23 23:36:01,930 - 3925 samples (32 per mini-batch)
2024-04-23 23:36:20,320 - Epoch: [313][  100/  123]    Loss 0.646464    Top1 79.156250    Top5 97.656250    
2024-04-23 23:36:24,498 - Epoch: [313][  123/  123]    Loss 0.655049    Top1 79.057325    Top5 97.477707    
2024-04-23 23:36:24,758 - ==> Top1: 79.057    Top5: 97.478    Loss: 0.655

2024-04-23 23:36:24,767 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:36:24,768 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:36:24,806 - 

2024-04-23 23:36:24,806 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:36:40,192 - Epoch: [314][  100/  296]    Overall Loss 0.672055    Objective Loss 0.672055                                        LR 0.000005    Time 0.153722    
2024-04-23 23:36:56,107 - Epoch: [314][  200/  296]    Overall Loss 0.660123    Objective Loss 0.660123                                        LR 0.000005    Time 0.156371    
2024-04-23 23:37:11,231 - Epoch: [314][  296/  296]    Overall Loss 0.668731    Objective Loss 0.668731    Top1 81.967213    Top5 93.442623    LR 0.000005    Time 0.156712    
2024-04-23 23:37:11,482 - --- validate (epoch=314)-----------
2024-04-23 23:37:11,482 - 3925 samples (32 per mini-batch)
2024-04-23 23:37:28,147 - Epoch: [314][  100/  123]    Loss 0.650021    Top1 79.218750    Top5 97.406250    
2024-04-23 23:37:31,630 - Epoch: [314][  123/  123]    Loss 0.653221    Top1 79.031847    Top5 97.503185    
2024-04-23 23:37:32,192 - ==> Top1: 79.032    Top5: 97.503    Loss: 0.653

2024-04-23 23:37:32,203 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:37:32,204 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:37:32,249 - 

2024-04-23 23:37:32,249 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:37:44,434 - Epoch: [315][  100/  296]    Overall Loss 0.682962    Objective Loss 0.682962                                        LR 0.000005    Time 0.121721    
2024-04-23 23:37:55,301 - Epoch: [315][  200/  296]    Overall Loss 0.656384    Objective Loss 0.656384                                        LR 0.000005    Time 0.115133    
2024-04-23 23:38:09,195 - Epoch: [315][  296/  296]    Overall Loss 0.658989    Objective Loss 0.658989    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.124693    
2024-04-23 23:38:09,592 - --- validate (epoch=315)-----------
2024-04-23 23:38:09,593 - 3925 samples (32 per mini-batch)
2024-04-23 23:38:26,425 - Epoch: [315][  100/  123]    Loss 0.650847    Top1 78.843750    Top5 97.625000    
2024-04-23 23:38:30,167 - Epoch: [315][  123/  123]    Loss 0.658041    Top1 78.828025    Top5 97.503185    
2024-04-23 23:38:30,333 - ==> Top1: 78.828    Top5: 97.503    Loss: 0.658

2024-04-23 23:38:30,342 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:38:30,342 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:38:30,382 - 

2024-04-23 23:38:30,383 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:38:47,068 - Epoch: [316][  100/  296]    Overall Loss 0.696063    Objective Loss 0.696063                                        LR 0.000005    Time 0.166716    
2024-04-23 23:39:03,423 - Epoch: [316][  200/  296]    Overall Loss 0.668412    Objective Loss 0.668412                                        LR 0.000005    Time 0.165060    
2024-04-23 23:39:18,088 - Epoch: [316][  296/  296]    Overall Loss 0.664364    Objective Loss 0.664364    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.161025    
2024-04-23 23:39:18,190 - --- validate (epoch=316)-----------
2024-04-23 23:39:18,191 - 3925 samples (32 per mini-batch)
2024-04-23 23:39:32,898 - Epoch: [316][  100/  123]    Loss 0.672211    Top1 78.500000    Top5 97.312500    
2024-04-23 23:39:35,395 - Epoch: [316][  123/  123]    Loss 0.655175    Top1 78.980892    Top5 97.554140    
2024-04-23 23:39:35,504 - ==> Top1: 78.981    Top5: 97.554    Loss: 0.655

2024-04-23 23:39:35,511 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:39:35,511 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:39:35,542 - 

2024-04-23 23:39:35,542 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:39:50,951 - Epoch: [317][  100/  296]    Overall Loss 0.671812    Objective Loss 0.671812                                        LR 0.000005    Time 0.153969    
2024-04-23 23:40:04,924 - Epoch: [317][  200/  296]    Overall Loss 0.673174    Objective Loss 0.673174                                        LR 0.000005    Time 0.146784    
2024-04-23 23:40:17,617 - Epoch: [317][  296/  296]    Overall Loss 0.664212    Objective Loss 0.664212    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.142018    
2024-04-23 23:40:17,809 - --- validate (epoch=317)-----------
2024-04-23 23:40:17,810 - 3925 samples (32 per mini-batch)
2024-04-23 23:40:38,350 - Epoch: [317][  100/  123]    Loss 0.657116    Top1 79.062500    Top5 97.500000    
2024-04-23 23:40:42,586 - Epoch: [317][  123/  123]    Loss 0.655340    Top1 79.133758    Top5 97.579618    
2024-04-23 23:40:42,814 - ==> Top1: 79.134    Top5: 97.580    Loss: 0.655

2024-04-23 23:40:42,821 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:40:42,821 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:40:42,860 - 

2024-04-23 23:40:42,860 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:40:59,206 - Epoch: [318][  100/  296]    Overall Loss 0.671249    Objective Loss 0.671249                                        LR 0.000005    Time 0.163313    
2024-04-23 23:41:12,325 - Epoch: [318][  200/  296]    Overall Loss 0.670926    Objective Loss 0.670926                                        LR 0.000005    Time 0.147188    
2024-04-23 23:41:26,069 - Epoch: [318][  296/  296]    Overall Loss 0.672666    Objective Loss 0.672666    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.145837    
2024-04-23 23:41:26,229 - --- validate (epoch=318)-----------
2024-04-23 23:41:26,230 - 3925 samples (32 per mini-batch)
2024-04-23 23:41:38,815 - Epoch: [318][  100/  123]    Loss 0.664883    Top1 78.781250    Top5 97.437500    
2024-04-23 23:41:40,976 - Epoch: [318][  123/  123]    Loss 0.651600    Top1 79.235669    Top5 97.605096    
2024-04-23 23:41:41,160 - ==> Top1: 79.236    Top5: 97.605    Loss: 0.652

2024-04-23 23:41:41,167 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:41:41,167 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:41:41,211 - 

2024-04-23 23:41:41,212 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:41:54,166 - Epoch: [319][  100/  296]    Overall Loss 0.656981    Objective Loss 0.656981                                        LR 0.000005    Time 0.129402    
2024-04-23 23:42:08,398 - Epoch: [319][  200/  296]    Overall Loss 0.659706    Objective Loss 0.659706                                        LR 0.000005    Time 0.135795    
2024-04-23 23:42:21,086 - Epoch: [319][  296/  296]    Overall Loss 0.669934    Objective Loss 0.669934    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.134579    
2024-04-23 23:42:21,232 - --- validate (epoch=319)-----------
2024-04-23 23:42:21,233 - 3925 samples (32 per mini-batch)
2024-04-23 23:42:35,662 - Epoch: [319][  100/  123]    Loss 0.643654    Top1 79.250000    Top5 97.625000    
2024-04-23 23:42:37,601 - Epoch: [319][  123/  123]    Loss 0.659856    Top1 78.726115    Top5 97.605096    
2024-04-23 23:42:37,798 - ==> Top1: 78.726    Top5: 97.605    Loss: 0.660

2024-04-23 23:42:37,810 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:42:37,811 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:42:37,850 - 

2024-04-23 23:42:37,850 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:42:51,213 - Epoch: [320][  100/  296]    Overall Loss 0.668365    Objective Loss 0.668365                                        LR 0.000005    Time 0.133480    
2024-04-23 23:43:04,316 - Epoch: [320][  200/  296]    Overall Loss 0.663035    Objective Loss 0.663035                                        LR 0.000005    Time 0.132194    
2024-04-23 23:43:14,759 - Epoch: [320][  296/  296]    Overall Loss 0.664107    Objective Loss 0.664107    Top1 88.524590    Top5 100.000000    LR 0.000005    Time 0.124557    
2024-04-23 23:43:14,988 - --- validate (epoch=320)-----------
2024-04-23 23:43:14,988 - 3925 samples (32 per mini-batch)
2024-04-23 23:43:32,269 - Epoch: [320][  100/  123]    Loss 0.666486    Top1 78.593750    Top5 97.375000    
2024-04-23 23:43:35,482 - Epoch: [320][  123/  123]    Loss 0.655285    Top1 79.031847    Top5 97.503185    
2024-04-23 23:43:35,765 - ==> Top1: 79.032    Top5: 97.503    Loss: 0.655

2024-04-23 23:43:35,771 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:43:35,772 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:43:35,805 - 

2024-04-23 23:43:35,805 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:43:54,460 - Epoch: [321][  100/  296]    Overall Loss 0.643804    Objective Loss 0.643804                                        LR 0.000005    Time 0.186409    
2024-04-23 23:44:10,023 - Epoch: [321][  200/  296]    Overall Loss 0.658323    Objective Loss 0.658323                                        LR 0.000005    Time 0.170966    
2024-04-23 23:44:24,477 - Epoch: [321][  296/  296]    Overall Loss 0.659548    Objective Loss 0.659548    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.164310    
2024-04-23 23:44:24,665 - --- validate (epoch=321)-----------
2024-04-23 23:44:24,666 - 3925 samples (32 per mini-batch)
2024-04-23 23:44:43,165 - Epoch: [321][  100/  123]    Loss 0.663020    Top1 78.593750    Top5 97.562500    
2024-04-23 23:44:47,324 - Epoch: [321][  123/  123]    Loss 0.659201    Top1 78.802548    Top5 97.503185    
2024-04-23 23:44:47,480 - ==> Top1: 78.803    Top5: 97.503    Loss: 0.659

2024-04-23 23:44:47,488 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:44:47,489 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:44:47,530 - 

2024-04-23 23:44:47,530 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:45:07,827 - Epoch: [322][  100/  296]    Overall Loss 0.667229    Objective Loss 0.667229                                        LR 0.000005    Time 0.202830    
2024-04-23 23:45:24,577 - Epoch: [322][  200/  296]    Overall Loss 0.666767    Objective Loss 0.666767                                        LR 0.000005    Time 0.185102    
2024-04-23 23:45:38,532 - Epoch: [322][  296/  296]    Overall Loss 0.674002    Objective Loss 0.674002    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.172172    
2024-04-23 23:45:38,750 - --- validate (epoch=322)-----------
2024-04-23 23:45:38,750 - 3925 samples (32 per mini-batch)
2024-04-23 23:45:52,832 - Epoch: [322][  100/  123]    Loss 0.643910    Top1 79.781250    Top5 97.687500    
2024-04-23 23:45:55,893 - Epoch: [322][  123/  123]    Loss 0.654281    Top1 79.235669    Top5 97.656051    
2024-04-23 23:45:56,028 - ==> Top1: 79.236    Top5: 97.656    Loss: 0.654

2024-04-23 23:45:56,032 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:45:56,032 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:45:56,063 - 

2024-04-23 23:45:56,063 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:46:09,831 - Epoch: [323][  100/  296]    Overall Loss 0.640362    Objective Loss 0.640362                                        LR 0.000005    Time 0.137550    
2024-04-23 23:46:22,353 - Epoch: [323][  200/  296]    Overall Loss 0.650980    Objective Loss 0.650980                                        LR 0.000005    Time 0.131318    
2024-04-23 23:46:34,849 - Epoch: [323][  296/  296]    Overall Loss 0.651834    Objective Loss 0.651834    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.130901    
2024-04-23 23:46:35,104 - --- validate (epoch=323)-----------
2024-04-23 23:46:35,105 - 3925 samples (32 per mini-batch)
2024-04-23 23:46:50,016 - Epoch: [323][  100/  123]    Loss 0.657258    Top1 78.812500    Top5 97.406250    
2024-04-23 23:46:51,775 - Epoch: [323][  123/  123]    Loss 0.655575    Top1 78.878981    Top5 97.503185    
2024-04-23 23:46:52,055 - ==> Top1: 78.879    Top5: 97.503    Loss: 0.656

2024-04-23 23:46:52,064 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:46:52,064 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:46:52,104 - 

2024-04-23 23:46:52,105 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:47:03,416 - Epoch: [324][  100/  296]    Overall Loss 0.689697    Objective Loss 0.689697                                        LR 0.000005    Time 0.112971    
2024-04-23 23:47:12,812 - Epoch: [324][  200/  296]    Overall Loss 0.676221    Objective Loss 0.676221                                        LR 0.000005    Time 0.103399    
2024-04-23 23:47:24,824 - Epoch: [324][  296/  296]    Overall Loss 0.671493    Objective Loss 0.671493    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.110408    
2024-04-23 23:47:24,970 - --- validate (epoch=324)-----------
2024-04-23 23:47:24,971 - 3925 samples (32 per mini-batch)
2024-04-23 23:47:42,154 - Epoch: [324][  100/  123]    Loss 0.661657    Top1 78.906250    Top5 97.750000    
2024-04-23 23:47:45,864 - Epoch: [324][  123/  123]    Loss 0.655955    Top1 78.980892    Top5 97.681529    
2024-04-23 23:47:46,020 - ==> Top1: 78.981    Top5: 97.682    Loss: 0.656

2024-04-23 23:47:46,029 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:47:46,030 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:47:46,071 - 

2024-04-23 23:47:46,071 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:48:00,849 - Epoch: [325][  100/  296]    Overall Loss 0.635866    Objective Loss 0.635866                                        LR 0.000005    Time 0.147629    
2024-04-23 23:48:14,445 - Epoch: [325][  200/  296]    Overall Loss 0.646939    Objective Loss 0.646939                                        LR 0.000005    Time 0.141728    
2024-04-23 23:48:27,530 - Epoch: [325][  296/  296]    Overall Loss 0.650701    Objective Loss 0.650701    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.139926    
2024-04-23 23:48:27,677 - --- validate (epoch=325)-----------
2024-04-23 23:48:27,678 - 3925 samples (32 per mini-batch)
2024-04-23 23:48:41,744 - Epoch: [325][  100/  123]    Loss 0.653352    Top1 79.281250    Top5 97.593750    
2024-04-23 23:48:44,019 - Epoch: [325][  123/  123]    Loss 0.655648    Top1 79.031847    Top5 97.681529    
2024-04-23 23:48:44,214 - ==> Top1: 79.032    Top5: 97.682    Loss: 0.656

2024-04-23 23:48:44,222 - ==> Best [Top1: 79.261   Top5: 97.529   Sparsity:0.00   Params: 376752 on epoch: 293]
2024-04-23 23:48:44,223 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:48:44,258 - 

2024-04-23 23:48:44,259 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:48:57,632 - Epoch: [326][  100/  296]    Overall Loss 0.670926    Objective Loss 0.670926                                        LR 0.000005    Time 0.133603    
2024-04-23 23:49:13,334 - Epoch: [326][  200/  296]    Overall Loss 0.659034    Objective Loss 0.659034                                        LR 0.000005    Time 0.145244    
2024-04-23 23:49:28,182 - Epoch: [326][  296/  296]    Overall Loss 0.659203    Objective Loss 0.659203    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.148253    
2024-04-23 23:49:28,341 - --- validate (epoch=326)-----------
2024-04-23 23:49:28,342 - 3925 samples (32 per mini-batch)
2024-04-23 23:49:44,539 - Epoch: [326][  100/  123]    Loss 0.640195    Top1 79.875000    Top5 97.593750    
2024-04-23 23:49:47,521 - Epoch: [326][  123/  123]    Loss 0.655809    Top1 79.312102    Top5 97.630573    
2024-04-23 23:49:47,701 - ==> Top1: 79.312    Top5: 97.631    Loss: 0.656

2024-04-23 23:49:47,712 - ==> Best [Top1: 79.312   Top5: 97.631   Sparsity:0.00   Params: 376752 on epoch: 326]
2024-04-23 23:49:47,713 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:49:47,763 - 

2024-04-23 23:49:47,763 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:50:04,061 - Epoch: [327][  100/  296]    Overall Loss 0.671032    Objective Loss 0.671032                                        LR 0.000005    Time 0.162829    
2024-04-23 23:50:19,503 - Epoch: [327][  200/  296]    Overall Loss 0.678491    Objective Loss 0.678491                                        LR 0.000005    Time 0.158554    
2024-04-23 23:50:34,734 - Epoch: [327][  296/  296]    Overall Loss 0.672066    Objective Loss 0.672066    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.158545    
2024-04-23 23:50:34,963 - --- validate (epoch=327)-----------
2024-04-23 23:50:34,964 - 3925 samples (32 per mini-batch)
2024-04-23 23:50:51,187 - Epoch: [327][  100/  123]    Loss 0.656900    Top1 78.937500    Top5 97.593750    
2024-04-23 23:50:54,801 - Epoch: [327][  123/  123]    Loss 0.660488    Top1 78.929936    Top5 97.528662    
2024-04-23 23:50:54,963 - ==> Top1: 78.930    Top5: 97.529    Loss: 0.660

2024-04-23 23:50:54,968 - ==> Best [Top1: 79.312   Top5: 97.631   Sparsity:0.00   Params: 376752 on epoch: 326]
2024-04-23 23:50:54,968 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:50:54,999 - 

2024-04-23 23:50:55,000 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:51:12,377 - Epoch: [328][  100/  296]    Overall Loss 0.668377    Objective Loss 0.668377                                        LR 0.000005    Time 0.173646    
2024-04-23 23:51:26,882 - Epoch: [328][  200/  296]    Overall Loss 0.666132    Objective Loss 0.666132                                        LR 0.000005    Time 0.159277    
2024-04-23 23:51:40,406 - Epoch: [328][  296/  296]    Overall Loss 0.667748    Objective Loss 0.667748    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.153271    
2024-04-23 23:51:40,601 - --- validate (epoch=328)-----------
2024-04-23 23:51:40,602 - 3925 samples (32 per mini-batch)
2024-04-23 23:51:54,360 - Epoch: [328][  100/  123]    Loss 0.664575    Top1 78.656250    Top5 97.437500    
2024-04-23 23:51:56,713 - Epoch: [328][  123/  123]    Loss 0.659381    Top1 79.031847    Top5 97.528662    
2024-04-23 23:51:56,939 - ==> Top1: 79.032    Top5: 97.529    Loss: 0.659

2024-04-23 23:51:56,949 - ==> Best [Top1: 79.312   Top5: 97.631   Sparsity:0.00   Params: 376752 on epoch: 326]
2024-04-23 23:51:56,950 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:51:56,998 - 

2024-04-23 23:51:56,998 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:52:09,072 - Epoch: [329][  100/  296]    Overall Loss 0.650326    Objective Loss 0.650326                                        LR 0.000005    Time 0.120587    
2024-04-23 23:52:20,283 - Epoch: [329][  200/  296]    Overall Loss 0.649426    Objective Loss 0.649426                                        LR 0.000005    Time 0.116283    
2024-04-23 23:52:32,678 - Epoch: [329][  296/  296]    Overall Loss 0.658958    Objective Loss 0.658958    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.120404    
2024-04-23 23:52:32,836 - --- validate (epoch=329)-----------
2024-04-23 23:52:32,837 - 3925 samples (32 per mini-batch)
2024-04-23 23:52:49,453 - Epoch: [329][  100/  123]    Loss 0.658484    Top1 78.750000    Top5 97.468750    
2024-04-23 23:52:53,227 - Epoch: [329][  123/  123]    Loss 0.656798    Top1 78.904459    Top5 97.554140    
2024-04-23 23:52:53,428 - ==> Top1: 78.904    Top5: 97.554    Loss: 0.657

2024-04-23 23:52:53,437 - ==> Best [Top1: 79.312   Top5: 97.631   Sparsity:0.00   Params: 376752 on epoch: 326]
2024-04-23 23:52:53,438 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:52:53,479 - 

2024-04-23 23:52:53,480 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:53:07,985 - Epoch: [330][  100/  296]    Overall Loss 0.691867    Objective Loss 0.691867                                        LR 0.000005    Time 0.144910    
2024-04-23 23:53:20,867 - Epoch: [330][  200/  296]    Overall Loss 0.670195    Objective Loss 0.670195                                        LR 0.000005    Time 0.136794    
2024-04-23 23:53:33,446 - Epoch: [330][  296/  296]    Overall Loss 0.672062    Objective Loss 0.672062    Top1 86.885246    Top5 100.000000    LR 0.000005    Time 0.134881    
2024-04-23 23:53:33,692 - --- validate (epoch=330)-----------
2024-04-23 23:53:33,693 - 3925 samples (32 per mini-batch)
2024-04-23 23:53:47,466 - Epoch: [330][  100/  123]    Loss 0.673398    Top1 78.687500    Top5 97.593750    
2024-04-23 23:53:50,416 - Epoch: [330][  123/  123]    Loss 0.658387    Top1 79.184713    Top5 97.579618    
2024-04-23 23:53:50,601 - ==> Top1: 79.185    Top5: 97.580    Loss: 0.658

2024-04-23 23:53:50,610 - ==> Best [Top1: 79.312   Top5: 97.631   Sparsity:0.00   Params: 376752 on epoch: 326]
2024-04-23 23:53:50,611 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:53:50,651 - 

2024-04-23 23:53:50,651 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:54:02,421 - Epoch: [331][  100/  296]    Overall Loss 0.653543    Objective Loss 0.653543                                        LR 0.000005    Time 0.117556    
2024-04-23 23:54:15,487 - Epoch: [331][  200/  296]    Overall Loss 0.662624    Objective Loss 0.662624                                        LR 0.000005    Time 0.124042    
2024-04-23 23:54:28,203 - Epoch: [331][  296/  296]    Overall Loss 0.664193    Objective Loss 0.664193    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.126726    
2024-04-23 23:54:28,467 - --- validate (epoch=331)-----------
2024-04-23 23:54:28,468 - 3925 samples (32 per mini-batch)
2024-04-23 23:54:44,836 - Epoch: [331][  100/  123]    Loss 0.650607    Top1 79.281250    Top5 97.625000    
2024-04-23 23:54:48,297 - Epoch: [331][  123/  123]    Loss 0.656141    Top1 79.031847    Top5 97.605096    
2024-04-23 23:54:48,462 - ==> Top1: 79.032    Top5: 97.605    Loss: 0.656

2024-04-23 23:54:48,471 - ==> Best [Top1: 79.312   Top5: 97.631   Sparsity:0.00   Params: 376752 on epoch: 326]
2024-04-23 23:54:48,471 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:54:48,506 - 

2024-04-23 23:54:48,507 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:55:05,708 - Epoch: [332][  100/  296]    Overall Loss 0.659245    Objective Loss 0.659245                                        LR 0.000005    Time 0.171880    
2024-04-23 23:55:19,990 - Epoch: [332][  200/  296]    Overall Loss 0.663064    Objective Loss 0.663064                                        LR 0.000005    Time 0.157281    
2024-04-23 23:55:32,646 - Epoch: [332][  296/  296]    Overall Loss 0.660477    Objective Loss 0.660477    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.148987    
2024-04-23 23:55:32,877 - --- validate (epoch=332)-----------
2024-04-23 23:55:32,878 - 3925 samples (32 per mini-batch)
2024-04-23 23:55:49,699 - Epoch: [332][  100/  123]    Loss 0.669832    Top1 79.000000    Top5 97.406250    
2024-04-23 23:55:52,894 - Epoch: [332][  123/  123]    Loss 0.654389    Top1 79.184713    Top5 97.528662    
2024-04-23 23:55:53,015 - ==> Top1: 79.185    Top5: 97.529    Loss: 0.654

2024-04-23 23:55:53,023 - ==> Best [Top1: 79.312   Top5: 97.631   Sparsity:0.00   Params: 376752 on epoch: 326]
2024-04-23 23:55:53,023 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:55:53,061 - 

2024-04-23 23:55:53,062 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:56:10,995 - Epoch: [333][  100/  296]    Overall Loss 0.642530    Objective Loss 0.642530                                        LR 0.000005    Time 0.179197    
2024-04-23 23:56:26,531 - Epoch: [333][  200/  296]    Overall Loss 0.663607    Objective Loss 0.663607                                        LR 0.000005    Time 0.167207    
2024-04-23 23:56:39,558 - Epoch: [333][  296/  296]    Overall Loss 0.677406    Objective Loss 0.677406    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.156949    
2024-04-23 23:56:39,762 - --- validate (epoch=333)-----------
2024-04-23 23:56:39,763 - 3925 samples (32 per mini-batch)
2024-04-23 23:56:58,230 - Epoch: [333][  100/  123]    Loss 0.661130    Top1 79.125000    Top5 97.656250    
2024-04-23 23:57:01,616 - Epoch: [333][  123/  123]    Loss 0.656953    Top1 79.337580    Top5 97.656051    
2024-04-23 23:57:02,042 - ==> Top1: 79.338    Top5: 97.656    Loss: 0.657

2024-04-23 23:57:02,050 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-23 23:57:02,051 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:57:02,102 - 

2024-04-23 23:57:02,102 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:57:18,685 - Epoch: [334][  100/  296]    Overall Loss 0.661563    Objective Loss 0.661563                                        LR 0.000005    Time 0.165696    
2024-04-23 23:57:32,278 - Epoch: [334][  200/  296]    Overall Loss 0.658044    Objective Loss 0.658044                                        LR 0.000005    Time 0.150753    
2024-04-23 23:57:46,001 - Epoch: [334][  296/  296]    Overall Loss 0.666231    Objective Loss 0.666231    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.148183    
2024-04-23 23:57:46,201 - --- validate (epoch=334)-----------
2024-04-23 23:57:46,202 - 3925 samples (32 per mini-batch)
2024-04-23 23:58:04,123 - Epoch: [334][  100/  123]    Loss 0.651900    Top1 78.875000    Top5 97.656250    
2024-04-23 23:58:08,311 - Epoch: [334][  123/  123]    Loss 0.655855    Top1 79.108280    Top5 97.528662    
2024-04-23 23:58:08,618 - ==> Top1: 79.108    Top5: 97.529    Loss: 0.656

2024-04-23 23:58:08,626 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-23 23:58:08,627 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:58:08,669 - 

2024-04-23 23:58:08,669 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:58:20,933 - Epoch: [335][  100/  296]    Overall Loss 0.676912    Objective Loss 0.676912                                        LR 0.000005    Time 0.122498    
2024-04-23 23:58:33,871 - Epoch: [335][  200/  296]    Overall Loss 0.671412    Objective Loss 0.671412                                        LR 0.000005    Time 0.125869    
2024-04-23 23:58:47,053 - Epoch: [335][  296/  296]    Overall Loss 0.673284    Objective Loss 0.673284    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.129535    
2024-04-23 23:58:47,210 - --- validate (epoch=335)-----------
2024-04-23 23:58:47,211 - 3925 samples (32 per mini-batch)
2024-04-23 23:59:06,149 - Epoch: [335][  100/  123]    Loss 0.642623    Top1 79.406250    Top5 97.656250    
2024-04-23 23:59:09,659 - Epoch: [335][  123/  123]    Loss 0.660387    Top1 78.802548    Top5 97.528662    
2024-04-23 23:59:09,984 - ==> Top1: 78.803    Top5: 97.529    Loss: 0.660

2024-04-23 23:59:09,994 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-23 23:59:09,995 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-23 23:59:10,047 - 

2024-04-23 23:59:10,047 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-23 23:59:25,899 - Epoch: [336][  100/  296]    Overall Loss 0.707695    Objective Loss 0.707695                                        LR 0.000005    Time 0.158391    
2024-04-23 23:59:39,017 - Epoch: [336][  200/  296]    Overall Loss 0.679934    Objective Loss 0.679934                                        LR 0.000005    Time 0.144726    
2024-04-23 23:59:52,421 - Epoch: [336][  296/  296]    Overall Loss 0.677216    Objective Loss 0.677216    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.143026    
2024-04-23 23:59:52,664 - --- validate (epoch=336)-----------
2024-04-23 23:59:52,665 - 3925 samples (32 per mini-batch)
2024-04-24 00:00:08,116 - Epoch: [336][  100/  123]    Loss 0.654446    Top1 79.531250    Top5 97.343750    
2024-04-24 00:00:11,361 - Epoch: [336][  123/  123]    Loss 0.658786    Top1 78.980892    Top5 97.503185    
2024-04-24 00:00:11,545 - ==> Top1: 78.981    Top5: 97.503    Loss: 0.659

2024-04-24 00:00:11,549 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:00:11,550 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:00:11,581 - 

2024-04-24 00:00:11,582 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:00:28,289 - Epoch: [337][  100/  296]    Overall Loss 0.674178    Objective Loss 0.674178                                        LR 0.000005    Time 0.166923    
2024-04-24 00:00:42,665 - Epoch: [337][  200/  296]    Overall Loss 0.666094    Objective Loss 0.666094                                        LR 0.000005    Time 0.155274    
2024-04-24 00:00:54,375 - Epoch: [337][  296/  296]    Overall Loss 0.683473    Objective Loss 0.683473    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.144433    
2024-04-24 00:00:54,527 - --- validate (epoch=337)-----------
2024-04-24 00:00:54,527 - 3925 samples (32 per mini-batch)
2024-04-24 00:01:07,052 - Epoch: [337][  100/  123]    Loss 0.663844    Top1 78.781250    Top5 97.625000    
2024-04-24 00:01:09,538 - Epoch: [337][  123/  123]    Loss 0.660173    Top1 78.726115    Top5 97.630573    
2024-04-24 00:01:09,761 - ==> Top1: 78.726    Top5: 97.631    Loss: 0.660

2024-04-24 00:01:09,769 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:01:09,769 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:01:09,805 - 

2024-04-24 00:01:09,806 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:01:21,557 - Epoch: [338][  100/  296]    Overall Loss 0.660475    Objective Loss 0.660475                                        LR 0.000005    Time 0.117376    
2024-04-24 00:01:29,520 - Epoch: [338][  200/  296]    Overall Loss 0.663610    Objective Loss 0.663610                                        LR 0.000005    Time 0.098441    
2024-04-24 00:01:39,953 - Epoch: [338][  296/  296]    Overall Loss 0.664995    Objective Loss 0.664995    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.101721    
2024-04-24 00:01:40,107 - --- validate (epoch=338)-----------
2024-04-24 00:01:40,107 - 3925 samples (32 per mini-batch)
2024-04-24 00:01:59,687 - Epoch: [338][  100/  123]    Loss 0.658429    Top1 78.812500    Top5 97.562500    
2024-04-24 00:02:02,984 - Epoch: [338][  123/  123]    Loss 0.660825    Top1 78.598726    Top5 97.528662    
2024-04-24 00:02:03,228 - ==> Top1: 78.599    Top5: 97.529    Loss: 0.661

2024-04-24 00:02:03,237 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:02:03,237 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:02:03,278 - 

2024-04-24 00:02:03,278 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:02:19,689 - Epoch: [339][  100/  296]    Overall Loss 0.634602    Objective Loss 0.634602                                        LR 0.000005    Time 0.163959    
2024-04-24 00:02:35,446 - Epoch: [339][  200/  296]    Overall Loss 0.642593    Objective Loss 0.642593                                        LR 0.000005    Time 0.160698    
2024-04-24 00:02:50,825 - Epoch: [339][  296/  296]    Overall Loss 0.655033    Objective Loss 0.655033    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.160498    
2024-04-24 00:02:51,216 - --- validate (epoch=339)-----------
2024-04-24 00:02:51,216 - 3925 samples (32 per mini-batch)
2024-04-24 00:03:10,374 - Epoch: [339][  100/  123]    Loss 0.663801    Top1 79.000000    Top5 97.593750    
2024-04-24 00:03:14,409 - Epoch: [339][  123/  123]    Loss 0.660060    Top1 78.904459    Top5 97.426752    
2024-04-24 00:03:14,678 - ==> Top1: 78.904    Top5: 97.427    Loss: 0.660

2024-04-24 00:03:14,688 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:03:14,688 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:03:14,728 - 

2024-04-24 00:03:14,729 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:03:29,308 - Epoch: [340][  100/  296]    Overall Loss 0.681002    Objective Loss 0.681002                                        LR 0.000005    Time 0.145660    
2024-04-24 00:03:43,627 - Epoch: [340][  200/  296]    Overall Loss 0.665423    Objective Loss 0.665423                                        LR 0.000005    Time 0.144360    
2024-04-24 00:03:58,236 - Epoch: [340][  296/  296]    Overall Loss 0.659438    Objective Loss 0.659438    Top1 70.491803    Top5 98.360656    LR 0.000005    Time 0.146840    
2024-04-24 00:03:58,454 - --- validate (epoch=340)-----------
2024-04-24 00:03:58,455 - 3925 samples (32 per mini-batch)
2024-04-24 00:04:15,735 - Epoch: [340][  100/  123]    Loss 0.650160    Top1 79.000000    Top5 97.656250    
2024-04-24 00:04:19,462 - Epoch: [340][  123/  123]    Loss 0.656810    Top1 79.057325    Top5 97.579618    
2024-04-24 00:04:19,681 - ==> Top1: 79.057    Top5: 97.580    Loss: 0.657

2024-04-24 00:04:19,689 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:04:19,690 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:04:19,731 - 

2024-04-24 00:04:19,731 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:04:37,049 - Epoch: [341][  100/  296]    Overall Loss 0.632032    Objective Loss 0.632032                                        LR 0.000005    Time 0.173042    
2024-04-24 00:04:53,948 - Epoch: [341][  200/  296]    Overall Loss 0.640600    Objective Loss 0.640600                                        LR 0.000005    Time 0.170944    
2024-04-24 00:05:07,077 - Epoch: [341][  296/  296]    Overall Loss 0.649023    Objective Loss 0.649023    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.159813    
2024-04-24 00:05:07,283 - --- validate (epoch=341)-----------
2024-04-24 00:05:07,284 - 3925 samples (32 per mini-batch)
2024-04-24 00:05:23,344 - Epoch: [341][  100/  123]    Loss 0.658867    Top1 78.687500    Top5 97.593750    
2024-04-24 00:05:27,282 - Epoch: [341][  123/  123]    Loss 0.657971    Top1 78.828025    Top5 97.579618    
2024-04-24 00:05:27,436 - ==> Top1: 78.828    Top5: 97.580    Loss: 0.658

2024-04-24 00:05:27,444 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:05:27,445 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:05:27,485 - 

2024-04-24 00:05:27,485 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:05:44,133 - Epoch: [342][  100/  296]    Overall Loss 0.668705    Objective Loss 0.668705                                        LR 0.000005    Time 0.166344    
2024-04-24 00:05:57,069 - Epoch: [342][  200/  296]    Overall Loss 0.650438    Objective Loss 0.650438                                        LR 0.000005    Time 0.147791    
2024-04-24 00:06:09,797 - Epoch: [342][  296/  296]    Overall Loss 0.655573    Objective Loss 0.655573    Top1 75.409836    Top5 93.442623    LR 0.000005    Time 0.142815    
2024-04-24 00:06:09,969 - --- validate (epoch=342)-----------
2024-04-24 00:06:09,970 - 3925 samples (32 per mini-batch)
2024-04-24 00:06:28,332 - Epoch: [342][  100/  123]    Loss 0.666305    Top1 78.812500    Top5 97.656250    
2024-04-24 00:06:30,551 - Epoch: [342][  123/  123]    Loss 0.656392    Top1 78.929936    Top5 97.605096    
2024-04-24 00:06:30,789 - ==> Top1: 78.930    Top5: 97.605    Loss: 0.656

2024-04-24 00:06:30,797 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:06:30,797 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:06:30,833 - 

2024-04-24 00:06:30,834 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:06:45,946 - Epoch: [343][  100/  296]    Overall Loss 0.642365    Objective Loss 0.642365                                        LR 0.000005    Time 0.150974    
2024-04-24 00:07:00,098 - Epoch: [343][  200/  296]    Overall Loss 0.651177    Objective Loss 0.651177                                        LR 0.000005    Time 0.146171    
2024-04-24 00:07:13,191 - Epoch: [343][  296/  296]    Overall Loss 0.654145    Objective Loss 0.654145    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.142959    
2024-04-24 00:07:13,443 - --- validate (epoch=343)-----------
2024-04-24 00:07:13,444 - 3925 samples (32 per mini-batch)
2024-04-24 00:07:30,741 - Epoch: [343][  100/  123]    Loss 0.669035    Top1 78.593750    Top5 97.437500    
2024-04-24 00:07:33,636 - Epoch: [343][  123/  123]    Loss 0.659609    Top1 78.929936    Top5 97.503185    
2024-04-24 00:07:33,899 - ==> Top1: 78.930    Top5: 97.503    Loss: 0.660

2024-04-24 00:07:33,908 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:07:33,909 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:07:33,948 - 

2024-04-24 00:07:33,949 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:07:49,597 - Epoch: [344][  100/  296]    Overall Loss 0.661034    Objective Loss 0.661034                                        LR 0.000005    Time 0.156348    
2024-04-24 00:08:02,579 - Epoch: [344][  200/  296]    Overall Loss 0.667381    Objective Loss 0.667381                                        LR 0.000005    Time 0.143020    
2024-04-24 00:08:13,746 - Epoch: [344][  296/  296]    Overall Loss 0.666795    Objective Loss 0.666795    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.134325    
2024-04-24 00:08:14,056 - --- validate (epoch=344)-----------
2024-04-24 00:08:14,057 - 3925 samples (32 per mini-batch)
2024-04-24 00:08:32,944 - Epoch: [344][  100/  123]    Loss 0.667763    Top1 78.562500    Top5 97.562500    
2024-04-24 00:08:35,910 - Epoch: [344][  123/  123]    Loss 0.659860    Top1 79.082803    Top5 97.477707    
2024-04-24 00:08:36,062 - ==> Top1: 79.083    Top5: 97.478    Loss: 0.660

2024-04-24 00:08:36,071 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:08:36,072 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:08:36,108 - 

2024-04-24 00:08:36,109 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:08:53,911 - Epoch: [345][  100/  296]    Overall Loss 0.663706    Objective Loss 0.663706                                        LR 0.000005    Time 0.177887    
2024-04-24 00:09:09,798 - Epoch: [345][  200/  296]    Overall Loss 0.670503    Objective Loss 0.670503                                        LR 0.000005    Time 0.168306    
2024-04-24 00:09:25,297 - Epoch: [345][  296/  296]    Overall Loss 0.671002    Objective Loss 0.671002    Top1 78.688525    Top5 93.442623    LR 0.000005    Time 0.166028    
2024-04-24 00:09:25,427 - --- validate (epoch=345)-----------
2024-04-24 00:09:25,428 - 3925 samples (32 per mini-batch)
2024-04-24 00:09:43,192 - Epoch: [345][  100/  123]    Loss 0.663770    Top1 78.468750    Top5 97.437500    
2024-04-24 00:09:46,979 - Epoch: [345][  123/  123]    Loss 0.661614    Top1 78.598726    Top5 97.503185    
2024-04-24 00:09:47,116 - ==> Top1: 78.599    Top5: 97.503    Loss: 0.662

2024-04-24 00:09:47,120 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:09:47,120 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:09:47,147 - 

2024-04-24 00:09:47,148 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:10:01,370 - Epoch: [346][  100/  296]    Overall Loss 0.649057    Objective Loss 0.649057                                        LR 0.000005    Time 0.142094    
2024-04-24 00:10:15,864 - Epoch: [346][  200/  296]    Overall Loss 0.651620    Objective Loss 0.651620                                        LR 0.000005    Time 0.143455    
2024-04-24 00:10:29,851 - Epoch: [346][  296/  296]    Overall Loss 0.647074    Objective Loss 0.647074    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.144142    
2024-04-24 00:10:30,057 - --- validate (epoch=346)-----------
2024-04-24 00:10:30,058 - 3925 samples (32 per mini-batch)
2024-04-24 00:10:47,174 - Epoch: [346][  100/  123]    Loss 0.660750    Top1 78.968750    Top5 97.687500    
2024-04-24 00:10:50,422 - Epoch: [346][  123/  123]    Loss 0.659598    Top1 78.955414    Top5 97.681529    
2024-04-24 00:10:50,607 - ==> Top1: 78.955    Top5: 97.682    Loss: 0.660

2024-04-24 00:10:50,613 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:10:50,613 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:10:50,667 - 

2024-04-24 00:10:50,668 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:11:07,368 - Epoch: [347][  100/  296]    Overall Loss 0.649883    Objective Loss 0.649883                                        LR 0.000005    Time 0.166861    
2024-04-24 00:11:22,632 - Epoch: [347][  200/  296]    Overall Loss 0.649286    Objective Loss 0.649286                                        LR 0.000005    Time 0.159687    
2024-04-24 00:11:36,748 - Epoch: [347][  296/  296]    Overall Loss 0.654618    Objective Loss 0.654618    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.155544    
2024-04-24 00:11:36,939 - --- validate (epoch=347)-----------
2024-04-24 00:11:36,939 - 3925 samples (32 per mini-batch)
2024-04-24 00:11:53,912 - Epoch: [347][  100/  123]    Loss 0.658396    Top1 78.781250    Top5 97.562500    
2024-04-24 00:11:57,430 - Epoch: [347][  123/  123]    Loss 0.658309    Top1 79.006369    Top5 97.554140    
2024-04-24 00:11:57,642 - ==> Top1: 79.006    Top5: 97.554    Loss: 0.658

2024-04-24 00:11:57,648 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:11:57,649 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:11:57,677 - 

2024-04-24 00:11:57,678 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:12:14,455 - Epoch: [348][  100/  296]    Overall Loss 0.664555    Objective Loss 0.664555                                        LR 0.000005    Time 0.167626    
2024-04-24 00:12:28,166 - Epoch: [348][  200/  296]    Overall Loss 0.656648    Objective Loss 0.656648                                        LR 0.000005    Time 0.152298    
2024-04-24 00:12:42,286 - Epoch: [348][  296/  296]    Overall Loss 0.661525    Objective Loss 0.661525    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.150563    
2024-04-24 00:12:42,461 - --- validate (epoch=348)-----------
2024-04-24 00:12:42,462 - 3925 samples (32 per mini-batch)
2024-04-24 00:13:00,502 - Epoch: [348][  100/  123]    Loss 0.653224    Top1 79.343750    Top5 97.625000    
2024-04-24 00:13:03,625 - Epoch: [348][  123/  123]    Loss 0.656987    Top1 79.057325    Top5 97.707006    
2024-04-24 00:13:03,836 - ==> Top1: 79.057    Top5: 97.707    Loss: 0.657

2024-04-24 00:13:03,842 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:13:03,843 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:13:03,888 - 

2024-04-24 00:13:03,888 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:13:20,806 - Epoch: [349][  100/  296]    Overall Loss 0.669146    Objective Loss 0.669146                                        LR 0.000005    Time 0.169036    
2024-04-24 00:13:35,311 - Epoch: [349][  200/  296]    Overall Loss 0.682862    Objective Loss 0.682862                                        LR 0.000005    Time 0.156978    
2024-04-24 00:13:50,830 - Epoch: [349][  296/  296]    Overall Loss 0.671704    Objective Loss 0.671704    Top1 65.573770    Top5 96.721311    LR 0.000005    Time 0.158451    
2024-04-24 00:13:51,073 - --- validate (epoch=349)-----------
2024-04-24 00:13:51,074 - 3925 samples (32 per mini-batch)
2024-04-24 00:14:06,894 - Epoch: [349][  100/  123]    Loss 0.650333    Top1 78.843750    Top5 97.562500    
2024-04-24 00:14:09,729 - Epoch: [349][  123/  123]    Loss 0.657380    Top1 78.726115    Top5 97.554140    
2024-04-24 00:14:09,890 - ==> Top1: 78.726    Top5: 97.554    Loss: 0.657

2024-04-24 00:14:09,899 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:14:09,899 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:14:09,941 - 

2024-04-24 00:14:09,942 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:14:26,507 - Epoch: [350][  100/  296]    Overall Loss 0.652603    Objective Loss 0.652603                                        LR 0.000005    Time 0.165515    
2024-04-24 00:14:40,527 - Epoch: [350][  200/  296]    Overall Loss 0.650156    Objective Loss 0.650156                                        LR 0.000005    Time 0.152794    
2024-04-24 00:14:56,954 - Epoch: [350][  296/  296]    Overall Loss 0.658117    Objective Loss 0.658117    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.158699    
2024-04-24 00:14:57,122 - --- validate (epoch=350)-----------
2024-04-24 00:14:57,123 - 3925 samples (32 per mini-batch)
2024-04-24 00:15:14,440 - Epoch: [350][  100/  123]    Loss 0.664940    Top1 79.062500    Top5 97.531250    
2024-04-24 00:15:17,576 - Epoch: [350][  123/  123]    Loss 0.657317    Top1 79.031847    Top5 97.605096    
2024-04-24 00:15:17,724 - ==> Top1: 79.032    Top5: 97.605    Loss: 0.657

2024-04-24 00:15:17,732 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:15:17,732 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:15:17,775 - 

2024-04-24 00:15:17,776 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:15:34,092 - Epoch: [351][  100/  296]    Overall Loss 0.652932    Objective Loss 0.652932                                        LR 0.000005    Time 0.163026    
2024-04-24 00:15:49,143 - Epoch: [351][  200/  296]    Overall Loss 0.647660    Objective Loss 0.647660                                        LR 0.000005    Time 0.156705    
2024-04-24 00:16:03,243 - Epoch: [351][  296/  296]    Overall Loss 0.667643    Objective Loss 0.667643    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.153478    
2024-04-24 00:16:03,456 - --- validate (epoch=351)-----------
2024-04-24 00:16:03,457 - 3925 samples (32 per mini-batch)
2024-04-24 00:16:22,093 - Epoch: [351][  100/  123]    Loss 0.660762    Top1 78.750000    Top5 97.468750    
2024-04-24 00:16:25,147 - Epoch: [351][  123/  123]    Loss 0.656158    Top1 78.649682    Top5 97.452229    
2024-04-24 00:16:25,358 - ==> Top1: 78.650    Top5: 97.452    Loss: 0.656

2024-04-24 00:16:25,368 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:16:25,368 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:16:25,409 - 

2024-04-24 00:16:25,409 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:16:43,233 - Epoch: [352][  100/  296]    Overall Loss 0.673556    Objective Loss 0.673556                                        LR 0.000005    Time 0.178110    
2024-04-24 00:16:56,476 - Epoch: [352][  200/  296]    Overall Loss 0.660250    Objective Loss 0.660250                                        LR 0.000005    Time 0.155204    
2024-04-24 00:17:09,146 - Epoch: [352][  296/  296]    Overall Loss 0.666868    Objective Loss 0.666868    Top1 70.491803    Top5 95.081967    LR 0.000005    Time 0.147630    
2024-04-24 00:17:09,333 - --- validate (epoch=352)-----------
2024-04-24 00:17:09,334 - 3925 samples (32 per mini-batch)
2024-04-24 00:17:26,481 - Epoch: [352][  100/  123]    Loss 0.667914    Top1 78.656250    Top5 97.625000    
2024-04-24 00:17:29,695 - Epoch: [352][  123/  123]    Loss 0.659693    Top1 78.929936    Top5 97.477707    
2024-04-24 00:17:30,105 - ==> Top1: 78.930    Top5: 97.478    Loss: 0.660

2024-04-24 00:17:30,114 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:17:30,115 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:17:30,157 - 

2024-04-24 00:17:30,157 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:17:47,584 - Epoch: [353][  100/  296]    Overall Loss 0.681822    Objective Loss 0.681822                                        LR 0.000005    Time 0.174128    
2024-04-24 00:18:04,863 - Epoch: [353][  200/  296]    Overall Loss 0.660249    Objective Loss 0.660249                                        LR 0.000005    Time 0.173398    
2024-04-24 00:18:19,828 - Epoch: [353][  296/  296]    Overall Loss 0.657173    Objective Loss 0.657173    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.167680    
2024-04-24 00:18:20,005 - --- validate (epoch=353)-----------
2024-04-24 00:18:20,006 - 3925 samples (32 per mini-batch)
2024-04-24 00:18:39,975 - Epoch: [353][  100/  123]    Loss 0.650925    Top1 79.250000    Top5 97.687500    
2024-04-24 00:18:44,059 - Epoch: [353][  123/  123]    Loss 0.654057    Top1 79.057325    Top5 97.605096    
2024-04-24 00:18:44,249 - ==> Top1: 79.057    Top5: 97.605    Loss: 0.654

2024-04-24 00:18:44,258 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:18:44,258 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:18:44,302 - 

2024-04-24 00:18:44,302 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:18:59,457 - Epoch: [354][  100/  296]    Overall Loss 0.630785    Objective Loss 0.630785                                        LR 0.000005    Time 0.151409    
2024-04-24 00:19:15,977 - Epoch: [354][  200/  296]    Overall Loss 0.642311    Objective Loss 0.642311                                        LR 0.000005    Time 0.158243    
2024-04-24 00:19:31,463 - Epoch: [354][  296/  296]    Overall Loss 0.653809    Objective Loss 0.653809    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.159195    
2024-04-24 00:19:31,655 - --- validate (epoch=354)-----------
2024-04-24 00:19:31,656 - 3925 samples (32 per mini-batch)
2024-04-24 00:19:50,144 - Epoch: [354][  100/  123]    Loss 0.661342    Top1 78.312500    Top5 97.687500    
2024-04-24 00:19:53,957 - Epoch: [354][  123/  123]    Loss 0.661458    Top1 78.547771    Top5 97.554140    
2024-04-24 00:19:54,081 - ==> Top1: 78.548    Top5: 97.554    Loss: 0.661

2024-04-24 00:19:54,090 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:19:54,091 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:19:54,130 - 

2024-04-24 00:19:54,130 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:20:09,941 - Epoch: [355][  100/  296]    Overall Loss 0.641937    Objective Loss 0.641937                                        LR 0.000005    Time 0.157982    
2024-04-24 00:20:23,289 - Epoch: [355][  200/  296]    Overall Loss 0.660630    Objective Loss 0.660630                                        LR 0.000005    Time 0.145662    
2024-04-24 00:20:32,226 - Epoch: [355][  296/  296]    Overall Loss 0.654843    Objective Loss 0.654843    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.128576    
2024-04-24 00:20:32,401 - --- validate (epoch=355)-----------
2024-04-24 00:20:32,401 - 3925 samples (32 per mini-batch)
2024-04-24 00:20:45,561 - Epoch: [355][  100/  123]    Loss 0.666848    Top1 78.656250    Top5 97.281250    
2024-04-24 00:20:48,628 - Epoch: [355][  123/  123]    Loss 0.656785    Top1 78.955414    Top5 97.477707    
2024-04-24 00:20:48,816 - ==> Top1: 78.955    Top5: 97.478    Loss: 0.657

2024-04-24 00:20:48,825 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:20:48,826 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:20:48,870 - 

2024-04-24 00:20:48,870 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:21:04,592 - Epoch: [356][  100/  296]    Overall Loss 0.653754    Objective Loss 0.653754                                        LR 0.000005    Time 0.157078    
2024-04-24 00:21:19,177 - Epoch: [356][  200/  296]    Overall Loss 0.663443    Objective Loss 0.663443                                        LR 0.000005    Time 0.151410    
2024-04-24 00:21:32,011 - Epoch: [356][  296/  296]    Overall Loss 0.662370    Objective Loss 0.662370    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.145620    
2024-04-24 00:21:32,296 - --- validate (epoch=356)-----------
2024-04-24 00:21:32,297 - 3925 samples (32 per mini-batch)
2024-04-24 00:21:47,927 - Epoch: [356][  100/  123]    Loss 0.670374    Top1 78.656250    Top5 97.437500    
2024-04-24 00:21:50,950 - Epoch: [356][  123/  123]    Loss 0.658654    Top1 78.853503    Top5 97.477707    
2024-04-24 00:21:51,109 - ==> Top1: 78.854    Top5: 97.478    Loss: 0.659

2024-04-24 00:21:51,118 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:21:51,119 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:21:51,156 - 

2024-04-24 00:21:51,156 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:22:08,494 - Epoch: [357][  100/  296]    Overall Loss 0.682927    Objective Loss 0.682927                                        LR 0.000005    Time 0.173255    
2024-04-24 00:22:24,362 - Epoch: [357][  200/  296]    Overall Loss 0.687705    Objective Loss 0.687705                                        LR 0.000005    Time 0.165905    
2024-04-24 00:22:39,843 - Epoch: [357][  296/  296]    Overall Loss 0.675275    Objective Loss 0.675275    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.164358    
2024-04-24 00:22:40,183 - --- validate (epoch=357)-----------
2024-04-24 00:22:40,184 - 3925 samples (32 per mini-batch)
2024-04-24 00:22:56,627 - Epoch: [357][  100/  123]    Loss 0.651025    Top1 78.843750    Top5 97.875000    
2024-04-24 00:22:59,609 - Epoch: [357][  123/  123]    Loss 0.659611    Top1 78.649682    Top5 97.681529    
2024-04-24 00:22:59,818 - ==> Top1: 78.650    Top5: 97.682    Loss: 0.660

2024-04-24 00:22:59,827 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:22:59,827 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:22:59,869 - 

2024-04-24 00:22:59,869 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:23:15,832 - Epoch: [358][  100/  296]    Overall Loss 0.678411    Objective Loss 0.678411                                        LR 0.000005    Time 0.159487    
2024-04-24 00:23:30,923 - Epoch: [358][  200/  296]    Overall Loss 0.653222    Objective Loss 0.653222                                        LR 0.000005    Time 0.155135    
2024-04-24 00:23:44,393 - Epoch: [358][  296/  296]    Overall Loss 0.656186    Objective Loss 0.656186    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.150294    
2024-04-24 00:23:44,601 - --- validate (epoch=358)-----------
2024-04-24 00:23:44,602 - 3925 samples (32 per mini-batch)
2024-04-24 00:24:05,062 - Epoch: [358][  100/  123]    Loss 0.655751    Top1 78.937500    Top5 97.531250    
2024-04-24 00:24:09,384 - Epoch: [358][  123/  123]    Loss 0.659586    Top1 78.828025    Top5 97.477707    
2024-04-24 00:24:09,564 - ==> Top1: 78.828    Top5: 97.478    Loss: 0.660

2024-04-24 00:24:09,573 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:24:09,573 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:24:09,615 - 

2024-04-24 00:24:09,615 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:24:25,945 - Epoch: [359][  100/  296]    Overall Loss 0.643051    Objective Loss 0.643051                                        LR 0.000005    Time 0.163164    
2024-04-24 00:24:40,162 - Epoch: [359][  200/  296]    Overall Loss 0.666367    Objective Loss 0.666367                                        LR 0.000005    Time 0.152602    
2024-04-24 00:24:54,656 - Epoch: [359][  296/  296]    Overall Loss 0.666015    Objective Loss 0.666015    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.152036    
2024-04-24 00:24:54,812 - --- validate (epoch=359)-----------
2024-04-24 00:24:54,813 - 3925 samples (32 per mini-batch)
2024-04-24 00:25:14,004 - Epoch: [359][  100/  123]    Loss 0.663101    Top1 78.812500    Top5 97.656250    
2024-04-24 00:25:17,258 - Epoch: [359][  123/  123]    Loss 0.660083    Top1 78.828025    Top5 97.579618    
2024-04-24 00:25:17,478 - ==> Top1: 78.828    Top5: 97.580    Loss: 0.660

2024-04-24 00:25:17,487 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:25:17,487 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:25:17,523 - 

2024-04-24 00:25:17,524 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:25:32,177 - Epoch: [360][  100/  296]    Overall Loss 0.656044    Objective Loss 0.656044                                        LR 0.000005    Time 0.146387    
2024-04-24 00:25:45,235 - Epoch: [360][  200/  296]    Overall Loss 0.668538    Objective Loss 0.668538                                        LR 0.000005    Time 0.138415    
2024-04-24 00:25:56,863 - Epoch: [360][  296/  296]    Overall Loss 0.671594    Objective Loss 0.671594    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.132765    
2024-04-24 00:25:56,969 - --- validate (epoch=360)-----------
2024-04-24 00:25:56,970 - 3925 samples (32 per mini-batch)
2024-04-24 00:26:18,634 - Epoch: [360][  100/  123]    Loss 0.652413    Top1 79.312500    Top5 97.593750    
2024-04-24 00:26:22,432 - Epoch: [360][  123/  123]    Loss 0.656614    Top1 79.184713    Top5 97.605096    
2024-04-24 00:26:22,653 - ==> Top1: 79.185    Top5: 97.605    Loss: 0.657

2024-04-24 00:26:22,663 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:26:22,663 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:26:22,705 - 

2024-04-24 00:26:22,706 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:26:40,025 - Epoch: [361][  100/  296]    Overall Loss 0.676104    Objective Loss 0.676104                                        LR 0.000005    Time 0.173039    
2024-04-24 00:26:52,845 - Epoch: [361][  200/  296]    Overall Loss 0.673868    Objective Loss 0.673868                                        LR 0.000005    Time 0.150555    
2024-04-24 00:27:05,653 - Epoch: [361][  296/  296]    Overall Loss 0.672290    Objective Loss 0.672290    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.144957    
2024-04-24 00:27:05,872 - --- validate (epoch=361)-----------
2024-04-24 00:27:05,872 - 3925 samples (32 per mini-batch)
2024-04-24 00:27:23,218 - Epoch: [361][  100/  123]    Loss 0.665924    Top1 78.437500    Top5 97.562500    
2024-04-24 00:27:26,310 - Epoch: [361][  123/  123]    Loss 0.661973    Top1 78.471338    Top5 97.554140    
2024-04-24 00:27:26,514 - ==> Top1: 78.471    Top5: 97.554    Loss: 0.662

2024-04-24 00:27:26,523 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:27:26,523 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:27:26,566 - 

2024-04-24 00:27:26,567 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:27:43,344 - Epoch: [362][  100/  296]    Overall Loss 0.641188    Objective Loss 0.641188                                        LR 0.000005    Time 0.167628    
2024-04-24 00:27:55,833 - Epoch: [362][  200/  296]    Overall Loss 0.637331    Objective Loss 0.637331                                        LR 0.000005    Time 0.146196    
2024-04-24 00:28:10,274 - Epoch: [362][  296/  296]    Overall Loss 0.637550    Objective Loss 0.637550    Top1 88.524590    Top5 98.360656    LR 0.000005    Time 0.147526    
2024-04-24 00:28:10,566 - --- validate (epoch=362)-----------
2024-04-24 00:28:10,567 - 3925 samples (32 per mini-batch)
2024-04-24 00:28:29,741 - Epoch: [362][  100/  123]    Loss 0.663273    Top1 78.843750    Top5 97.500000    
2024-04-24 00:28:33,008 - Epoch: [362][  123/  123]    Loss 0.659162    Top1 79.082803    Top5 97.579618    
2024-04-24 00:28:33,274 - ==> Top1: 79.083    Top5: 97.580    Loss: 0.659

2024-04-24 00:28:33,281 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:28:33,281 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:28:33,328 - 

2024-04-24 00:28:33,329 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:28:49,890 - Epoch: [363][  100/  296]    Overall Loss 0.621898    Objective Loss 0.621898                                        LR 0.000005    Time 0.165476    
2024-04-24 00:29:04,488 - Epoch: [363][  200/  296]    Overall Loss 0.658258    Objective Loss 0.658258                                        LR 0.000005    Time 0.155670    
2024-04-24 00:29:19,582 - Epoch: [363][  296/  296]    Overall Loss 0.663829    Objective Loss 0.663829    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.156142    
2024-04-24 00:29:19,884 - --- validate (epoch=363)-----------
2024-04-24 00:29:19,885 - 3925 samples (32 per mini-batch)
2024-04-24 00:29:36,623 - Epoch: [363][  100/  123]    Loss 0.647018    Top1 79.343750    Top5 97.531250    
2024-04-24 00:29:40,477 - Epoch: [363][  123/  123]    Loss 0.660891    Top1 78.777070    Top5 97.554140    
2024-04-24 00:29:40,820 - ==> Top1: 78.777    Top5: 97.554    Loss: 0.661

2024-04-24 00:29:40,827 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:29:40,828 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:29:40,865 - 

2024-04-24 00:29:40,866 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:29:53,641 - Epoch: [364][  100/  296]    Overall Loss 0.675716    Objective Loss 0.675716                                        LR 0.000005    Time 0.127604    
2024-04-24 00:30:08,596 - Epoch: [364][  200/  296]    Overall Loss 0.661040    Objective Loss 0.661040                                        LR 0.000005    Time 0.138507    
2024-04-24 00:30:22,929 - Epoch: [364][  296/  296]    Overall Loss 0.658273    Objective Loss 0.658273    Top1 86.885246    Top5 96.721311    LR 0.000005    Time 0.141969    
2024-04-24 00:30:23,109 - --- validate (epoch=364)-----------
2024-04-24 00:30:23,110 - 3925 samples (32 per mini-batch)
2024-04-24 00:30:39,139 - Epoch: [364][  100/  123]    Loss 0.657532    Top1 79.000000    Top5 97.750000    
2024-04-24 00:30:42,479 - Epoch: [364][  123/  123]    Loss 0.659927    Top1 78.751592    Top5 97.630573    
2024-04-24 00:30:42,680 - ==> Top1: 78.752    Top5: 97.631    Loss: 0.660

2024-04-24 00:30:42,688 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:30:42,689 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:30:42,728 - 

2024-04-24 00:30:42,728 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:30:58,756 - Epoch: [365][  100/  296]    Overall Loss 0.632281    Objective Loss 0.632281                                        LR 0.000005    Time 0.160154    
2024-04-24 00:31:12,446 - Epoch: [365][  200/  296]    Overall Loss 0.662309    Objective Loss 0.662309                                        LR 0.000005    Time 0.148464    
2024-04-24 00:31:24,534 - Epoch: [365][  296/  296]    Overall Loss 0.663725    Objective Loss 0.663725    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.141114    
2024-04-24 00:31:24,722 - --- validate (epoch=365)-----------
2024-04-24 00:31:24,723 - 3925 samples (32 per mini-batch)
2024-04-24 00:31:41,544 - Epoch: [365][  100/  123]    Loss 0.650591    Top1 79.125000    Top5 97.687500    
2024-04-24 00:31:44,365 - Epoch: [365][  123/  123]    Loss 0.656560    Top1 79.006369    Top5 97.605096    
2024-04-24 00:31:44,663 - ==> Top1: 79.006    Top5: 97.605    Loss: 0.657

2024-04-24 00:31:44,671 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:31:44,672 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:31:44,714 - 

2024-04-24 00:31:44,715 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:32:00,661 - Epoch: [366][  100/  296]    Overall Loss 0.665955    Objective Loss 0.665955                                        LR 0.000005    Time 0.159336    
2024-04-24 00:32:15,654 - Epoch: [366][  200/  296]    Overall Loss 0.662560    Objective Loss 0.662560                                        LR 0.000005    Time 0.154561    
2024-04-24 00:32:27,148 - Epoch: [366][  296/  296]    Overall Loss 0.666698    Objective Loss 0.666698    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.143222    
2024-04-24 00:32:27,256 - --- validate (epoch=366)-----------
2024-04-24 00:32:27,256 - 3925 samples (32 per mini-batch)
2024-04-24 00:32:39,498 - Epoch: [366][  100/  123]    Loss 0.653318    Top1 78.906250    Top5 97.500000    
2024-04-24 00:32:42,591 - Epoch: [366][  123/  123]    Loss 0.659104    Top1 78.700637    Top5 97.503185    
2024-04-24 00:32:42,829 - ==> Top1: 78.701    Top5: 97.503    Loss: 0.659

2024-04-24 00:32:42,836 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:32:42,837 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:32:42,899 - 

2024-04-24 00:32:42,900 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:32:58,028 - Epoch: [367][  100/  296]    Overall Loss 0.656866    Objective Loss 0.656866                                        LR 0.000005    Time 0.151147    
2024-04-24 00:33:11,162 - Epoch: [367][  200/  296]    Overall Loss 0.652171    Objective Loss 0.652171                                        LR 0.000005    Time 0.141174    
2024-04-24 00:33:23,621 - Epoch: [367][  296/  296]    Overall Loss 0.652675    Objective Loss 0.652675    Top1 68.852459    Top5 96.721311    LR 0.000005    Time 0.137438    
2024-04-24 00:33:23,706 - --- validate (epoch=367)-----------
2024-04-24 00:33:23,707 - 3925 samples (32 per mini-batch)
2024-04-24 00:33:41,690 - Epoch: [367][  100/  123]    Loss 0.670912    Top1 78.687500    Top5 97.343750    
2024-04-24 00:33:44,242 - Epoch: [367][  123/  123]    Loss 0.660713    Top1 78.751592    Top5 97.554140    
2024-04-24 00:33:44,383 - ==> Top1: 78.752    Top5: 97.554    Loss: 0.661

2024-04-24 00:33:44,392 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:33:44,392 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:33:44,431 - 

2024-04-24 00:33:44,431 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:33:57,003 - Epoch: [368][  100/  296]    Overall Loss 0.643325    Objective Loss 0.643325                                        LR 0.000005    Time 0.125584    
2024-04-24 00:34:08,987 - Epoch: [368][  200/  296]    Overall Loss 0.655137    Objective Loss 0.655137                                        LR 0.000005    Time 0.122643    
2024-04-24 00:34:22,911 - Epoch: [368][  296/  296]    Overall Loss 0.660513    Objective Loss 0.660513    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.129865    
2024-04-24 00:34:23,061 - --- validate (epoch=368)-----------
2024-04-24 00:34:23,062 - 3925 samples (32 per mini-batch)
2024-04-24 00:34:39,590 - Epoch: [368][  100/  123]    Loss 0.646394    Top1 79.406250    Top5 97.843750    
2024-04-24 00:34:43,027 - Epoch: [368][  123/  123]    Loss 0.659277    Top1 79.261146    Top5 97.477707    
2024-04-24 00:34:43,161 - ==> Top1: 79.261    Top5: 97.478    Loss: 0.659

2024-04-24 00:34:43,168 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:34:43,169 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:34:43,207 - 

2024-04-24 00:34:43,207 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:34:59,020 - Epoch: [369][  100/  296]    Overall Loss 0.641284    Objective Loss 0.641284                                        LR 0.000005    Time 0.157982    
2024-04-24 00:35:14,023 - Epoch: [369][  200/  296]    Overall Loss 0.647503    Objective Loss 0.647503                                        LR 0.000005    Time 0.153929    
2024-04-24 00:35:27,131 - Epoch: [369][  296/  296]    Overall Loss 0.650091    Objective Loss 0.650091    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.148247    
2024-04-24 00:35:27,449 - --- validate (epoch=369)-----------
2024-04-24 00:35:27,450 - 3925 samples (32 per mini-batch)
2024-04-24 00:35:43,454 - Epoch: [369][  100/  123]    Loss 0.667165    Top1 78.875000    Top5 97.593750    
2024-04-24 00:35:46,538 - Epoch: [369][  123/  123]    Loss 0.661923    Top1 79.006369    Top5 97.681529    
2024-04-24 00:35:46,657 - ==> Top1: 79.006    Top5: 97.682    Loss: 0.662

2024-04-24 00:35:46,663 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:35:46,664 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:35:46,705 - 

2024-04-24 00:35:46,706 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:36:00,723 - Epoch: [370][  100/  296]    Overall Loss 0.689285    Objective Loss 0.689285                                        LR 0.000005    Time 0.140057    
2024-04-24 00:36:13,631 - Epoch: [370][  200/  296]    Overall Loss 0.681556    Objective Loss 0.681556                                        LR 0.000005    Time 0.134501    
2024-04-24 00:36:22,154 - Epoch: [370][  296/  296]    Overall Loss 0.678398    Objective Loss 0.678398    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.119636    
2024-04-24 00:36:22,248 - --- validate (epoch=370)-----------
2024-04-24 00:36:22,248 - 3925 samples (32 per mini-batch)
2024-04-24 00:36:33,875 - Epoch: [370][  100/  123]    Loss 0.660325    Top1 78.875000    Top5 97.656250    
2024-04-24 00:36:35,986 - Epoch: [370][  123/  123]    Loss 0.655643    Top1 78.878981    Top5 97.630573    
2024-04-24 00:36:36,080 - ==> Top1: 78.879    Top5: 97.631    Loss: 0.656

2024-04-24 00:36:36,088 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:36:36,089 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:36:36,139 - 

2024-04-24 00:36:36,139 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:36:49,486 - Epoch: [371][  100/  296]    Overall Loss 0.655987    Objective Loss 0.655987                                        LR 0.000005    Time 0.133325    
2024-04-24 00:37:00,490 - Epoch: [371][  200/  296]    Overall Loss 0.671848    Objective Loss 0.671848                                        LR 0.000005    Time 0.121620    
2024-04-24 00:37:10,108 - Epoch: [371][  296/  296]    Overall Loss 0.668742    Objective Loss 0.668742    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.114631    
2024-04-24 00:37:10,197 - --- validate (epoch=371)-----------
2024-04-24 00:37:10,198 - 3925 samples (32 per mini-batch)
2024-04-24 00:37:22,675 - Epoch: [371][  100/  123]    Loss 0.678249    Top1 78.625000    Top5 97.375000    
2024-04-24 00:37:24,946 - Epoch: [371][  123/  123]    Loss 0.658297    Top1 79.184713    Top5 97.503185    
2024-04-24 00:37:25,022 - ==> Top1: 79.185    Top5: 97.503    Loss: 0.658

2024-04-24 00:37:25,030 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:37:25,031 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:37:25,071 - 

2024-04-24 00:37:25,072 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:37:37,462 - Epoch: [372][  100/  296]    Overall Loss 0.639880    Objective Loss 0.639880                                        LR 0.000005    Time 0.123762    
2024-04-24 00:37:47,673 - Epoch: [372][  200/  296]    Overall Loss 0.676221    Objective Loss 0.676221                                        LR 0.000005    Time 0.112877    
2024-04-24 00:38:01,443 - Epoch: [372][  296/  296]    Overall Loss 0.675594    Objective Loss 0.675594    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.122753    
2024-04-24 00:38:01,619 - --- validate (epoch=372)-----------
2024-04-24 00:38:01,620 - 3925 samples (32 per mini-batch)
2024-04-24 00:38:18,566 - Epoch: [372][  100/  123]    Loss 0.649100    Top1 79.125000    Top5 97.812500    
2024-04-24 00:38:21,845 - Epoch: [372][  123/  123]    Loss 0.658326    Top1 78.904459    Top5 97.605096    
2024-04-24 00:38:21,956 - ==> Top1: 78.904    Top5: 97.605    Loss: 0.658

2024-04-24 00:38:21,965 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:38:21,965 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:38:22,007 - 

2024-04-24 00:38:22,007 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:38:39,475 - Epoch: [373][  100/  296]    Overall Loss 0.690652    Objective Loss 0.690652                                        LR 0.000005    Time 0.174541    
2024-04-24 00:38:55,195 - Epoch: [373][  200/  296]    Overall Loss 0.688308    Objective Loss 0.688308                                        LR 0.000005    Time 0.165812    
2024-04-24 00:39:10,642 - Epoch: [373][  296/  296]    Overall Loss 0.671393    Objective Loss 0.671393    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.164179    
2024-04-24 00:39:10,811 - --- validate (epoch=373)-----------
2024-04-24 00:39:10,812 - 3925 samples (32 per mini-batch)
2024-04-24 00:39:29,908 - Epoch: [373][  100/  123]    Loss 0.641766    Top1 79.468750    Top5 97.812500    
2024-04-24 00:39:33,950 - Epoch: [373][  123/  123]    Loss 0.656883    Top1 78.904459    Top5 97.554140    
2024-04-24 00:39:34,165 - ==> Top1: 78.904    Top5: 97.554    Loss: 0.657

2024-04-24 00:39:34,173 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:39:34,173 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:39:34,213 - 

2024-04-24 00:39:34,214 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:39:51,111 - Epoch: [374][  100/  296]    Overall Loss 0.659362    Objective Loss 0.659362                                        LR 0.000005    Time 0.168813    
2024-04-24 00:40:04,192 - Epoch: [374][  200/  296]    Overall Loss 0.666342    Objective Loss 0.666342                                        LR 0.000005    Time 0.149744    
2024-04-24 00:40:16,528 - Epoch: [374][  296/  296]    Overall Loss 0.661559    Objective Loss 0.661559    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.142814    
2024-04-24 00:40:16,629 - --- validate (epoch=374)-----------
2024-04-24 00:40:16,630 - 3925 samples (32 per mini-batch)
2024-04-24 00:40:30,483 - Epoch: [374][  100/  123]    Loss 0.639297    Top1 79.406250    Top5 97.968750    
2024-04-24 00:40:33,267 - Epoch: [374][  123/  123]    Loss 0.655654    Top1 78.726115    Top5 97.757962    
2024-04-24 00:40:33,394 - ==> Top1: 78.726    Top5: 97.758    Loss: 0.656

2024-04-24 00:40:33,402 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:40:33,402 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:40:33,443 - 

2024-04-24 00:40:33,444 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:40:48,671 - Epoch: [375][  100/  296]    Overall Loss 0.647820    Objective Loss 0.647820                                        LR 0.000005    Time 0.152139    
2024-04-24 00:41:02,473 - Epoch: [375][  200/  296]    Overall Loss 0.666071    Objective Loss 0.666071                                        LR 0.000005    Time 0.145015    
2024-04-24 00:41:12,353 - Epoch: [375][  296/  296]    Overall Loss 0.679274    Objective Loss 0.679274    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.131318    
2024-04-24 00:41:12,463 - --- validate (epoch=375)-----------
2024-04-24 00:41:12,464 - 3925 samples (32 per mini-batch)
2024-04-24 00:41:22,672 - Epoch: [375][  100/  123]    Loss 0.653990    Top1 79.031250    Top5 97.593750    
2024-04-24 00:41:24,866 - Epoch: [375][  123/  123]    Loss 0.658644    Top1 78.878981    Top5 97.605096    
2024-04-24 00:41:24,973 - ==> Top1: 78.879    Top5: 97.605    Loss: 0.659

2024-04-24 00:41:24,982 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:41:24,983 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:41:25,024 - 

2024-04-24 00:41:25,024 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:41:34,257 - Epoch: [376][  100/  296]    Overall Loss 0.654426    Objective Loss 0.654426                                        LR 0.000005    Time 0.092242    
2024-04-24 00:41:42,890 - Epoch: [376][  200/  296]    Overall Loss 0.677145    Objective Loss 0.677145                                        LR 0.000005    Time 0.089241    
2024-04-24 00:41:51,316 - Epoch: [376][  296/  296]    Overall Loss 0.669393    Objective Loss 0.669393    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.088737    
2024-04-24 00:41:51,434 - --- validate (epoch=376)-----------
2024-04-24 00:41:51,435 - 3925 samples (32 per mini-batch)
2024-04-24 00:42:04,293 - Epoch: [376][  100/  123]    Loss 0.656919    Top1 79.031250    Top5 97.531250    
2024-04-24 00:42:06,969 - Epoch: [376][  123/  123]    Loss 0.655798    Top1 79.108280    Top5 97.579618    
2024-04-24 00:42:07,223 - ==> Top1: 79.108    Top5: 97.580    Loss: 0.656

2024-04-24 00:42:07,232 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:42:07,232 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:42:07,271 - 

2024-04-24 00:42:07,271 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:42:19,136 - Epoch: [377][  100/  296]    Overall Loss 0.671819    Objective Loss 0.671819                                        LR 0.000005    Time 0.118552    
2024-04-24 00:42:29,414 - Epoch: [377][  200/  296]    Overall Loss 0.672802    Objective Loss 0.672802                                        LR 0.000005    Time 0.110619    
2024-04-24 00:42:39,186 - Epoch: [377][  296/  296]    Overall Loss 0.667195    Objective Loss 0.667195    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.107725    
2024-04-24 00:42:39,339 - --- validate (epoch=377)-----------
2024-04-24 00:42:39,339 - 3925 samples (32 per mini-batch)
2024-04-24 00:42:52,160 - Epoch: [377][  100/  123]    Loss 0.664180    Top1 78.406250    Top5 97.500000    
2024-04-24 00:42:54,731 - Epoch: [377][  123/  123]    Loss 0.659462    Top1 78.700637    Top5 97.605096    
2024-04-24 00:42:54,855 - ==> Top1: 78.701    Top5: 97.605    Loss: 0.659

2024-04-24 00:42:54,863 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:42:54,864 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:42:54,908 - 

2024-04-24 00:42:54,908 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:43:08,334 - Epoch: [378][  100/  296]    Overall Loss 0.685180    Objective Loss 0.685180                                        LR 0.000005    Time 0.134156    
2024-04-24 00:43:18,677 - Epoch: [378][  200/  296]    Overall Loss 0.652636    Objective Loss 0.652636                                        LR 0.000005    Time 0.118745    
2024-04-24 00:43:31,588 - Epoch: [378][  296/  296]    Overall Loss 0.657885    Objective Loss 0.657885    Top1 88.524590    Top5 100.000000    LR 0.000005    Time 0.123819    
2024-04-24 00:43:31,719 - --- validate (epoch=378)-----------
2024-04-24 00:43:31,720 - 3925 samples (32 per mini-batch)
2024-04-24 00:43:45,609 - Epoch: [378][  100/  123]    Loss 0.658742    Top1 78.343750    Top5 97.812500    
2024-04-24 00:43:47,904 - Epoch: [378][  123/  123]    Loss 0.658875    Top1 78.522293    Top5 97.630573    
2024-04-24 00:43:48,048 - ==> Top1: 78.522    Top5: 97.631    Loss: 0.659

2024-04-24 00:43:48,057 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:43:48,058 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:43:48,095 - 

2024-04-24 00:43:48,095 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:43:56,977 - Epoch: [379][  100/  296]    Overall Loss 0.673722    Objective Loss 0.673722                                        LR 0.000005    Time 0.088719    
2024-04-24 00:44:04,683 - Epoch: [379][  200/  296]    Overall Loss 0.661931    Objective Loss 0.661931                                        LR 0.000005    Time 0.082843    
2024-04-24 00:44:14,264 - Epoch: [379][  296/  296]    Overall Loss 0.663271    Objective Loss 0.663271    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.088313    
2024-04-24 00:44:14,395 - --- validate (epoch=379)-----------
2024-04-24 00:44:14,396 - 3925 samples (32 per mini-batch)
2024-04-24 00:44:24,397 - Epoch: [379][  100/  123]    Loss 0.673724    Top1 78.218750    Top5 97.375000    
2024-04-24 00:44:26,282 - Epoch: [379][  123/  123]    Loss 0.657419    Top1 78.700637    Top5 97.579618    
2024-04-24 00:44:26,432 - ==> Top1: 78.701    Top5: 97.580    Loss: 0.657

2024-04-24 00:44:26,439 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:44:26,440 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:44:26,478 - 

2024-04-24 00:44:26,478 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:44:35,045 - Epoch: [380][  100/  296]    Overall Loss 0.675759    Objective Loss 0.675759                                        LR 0.000005    Time 0.085570    
2024-04-24 00:44:42,256 - Epoch: [380][  200/  296]    Overall Loss 0.664741    Objective Loss 0.664741                                        LR 0.000005    Time 0.078789    
2024-04-24 00:44:49,943 - Epoch: [380][  296/  296]    Overall Loss 0.668780    Objective Loss 0.668780    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.079177    
2024-04-24 00:44:50,058 - --- validate (epoch=380)-----------
2024-04-24 00:44:50,059 - 3925 samples (32 per mini-batch)
2024-04-24 00:45:01,908 - Epoch: [380][  100/  123]    Loss 0.646317    Top1 79.312500    Top5 97.625000    
2024-04-24 00:45:03,973 - Epoch: [380][  123/  123]    Loss 0.659416    Top1 79.006369    Top5 97.426752    
2024-04-24 00:45:04,064 - ==> Top1: 79.006    Top5: 97.427    Loss: 0.659

2024-04-24 00:45:04,073 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:45:04,073 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:45:04,115 - 

2024-04-24 00:45:04,116 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:45:18,268 - Epoch: [381][  100/  296]    Overall Loss 0.661226    Objective Loss 0.661226                                        LR 0.000005    Time 0.141423    
2024-04-24 00:45:30,455 - Epoch: [381][  200/  296]    Overall Loss 0.667546    Objective Loss 0.667546                                        LR 0.000005    Time 0.131602    
2024-04-24 00:45:41,263 - Epoch: [381][  296/  296]    Overall Loss 0.657715    Objective Loss 0.657715    Top1 88.524590    Top5 98.360656    LR 0.000005    Time 0.125401    
2024-04-24 00:45:41,430 - --- validate (epoch=381)-----------
2024-04-24 00:45:41,431 - 3925 samples (32 per mini-batch)
2024-04-24 00:45:56,292 - Epoch: [381][  100/  123]    Loss 0.687472    Top1 78.343750    Top5 97.312500    
2024-04-24 00:45:58,359 - Epoch: [381][  123/  123]    Loss 0.661931    Top1 78.751592    Top5 97.528662    
2024-04-24 00:45:58,499 - ==> Top1: 78.752    Top5: 97.529    Loss: 0.662

2024-04-24 00:45:58,507 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:45:58,507 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:45:58,544 - 

2024-04-24 00:45:58,544 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:46:07,559 - Epoch: [382][  100/  296]    Overall Loss 0.677628    Objective Loss 0.677628                                        LR 0.000005    Time 0.090079    
2024-04-24 00:46:15,491 - Epoch: [382][  200/  296]    Overall Loss 0.660676    Objective Loss 0.660676                                        LR 0.000005    Time 0.084664    
2024-04-24 00:46:24,097 - Epoch: [382][  296/  296]    Overall Loss 0.659255    Objective Loss 0.659255    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.086259    
2024-04-24 00:46:24,217 - --- validate (epoch=382)-----------
2024-04-24 00:46:24,218 - 3925 samples (32 per mini-batch)
2024-04-24 00:46:35,023 - Epoch: [382][  100/  123]    Loss 0.664883    Top1 78.718750    Top5 97.500000    
2024-04-24 00:46:37,252 - Epoch: [382][  123/  123]    Loss 0.656391    Top1 79.108280    Top5 97.503185    
2024-04-24 00:46:37,372 - ==> Top1: 79.108    Top5: 97.503    Loss: 0.656

2024-04-24 00:46:37,379 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:46:37,380 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:46:37,415 - 

2024-04-24 00:46:37,415 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:46:48,641 - Epoch: [383][  100/  296]    Overall Loss 0.687507    Objective Loss 0.687507                                        LR 0.000005    Time 0.112165    
2024-04-24 00:46:58,950 - Epoch: [383][  200/  296]    Overall Loss 0.696848    Objective Loss 0.696848                                        LR 0.000005    Time 0.107583    
2024-04-24 00:47:09,014 - Epoch: [383][  296/  296]    Overall Loss 0.683679    Objective Loss 0.683679    Top1 86.885246    Top5 100.000000    LR 0.000005    Time 0.106671    
2024-04-24 00:47:09,171 - --- validate (epoch=383)-----------
2024-04-24 00:47:09,172 - 3925 samples (32 per mini-batch)
2024-04-24 00:47:21,809 - Epoch: [383][  100/  123]    Loss 0.650724    Top1 79.000000    Top5 97.500000    
2024-04-24 00:47:24,175 - Epoch: [383][  123/  123]    Loss 0.657421    Top1 78.828025    Top5 97.528662    
2024-04-24 00:47:24,304 - ==> Top1: 78.828    Top5: 97.529    Loss: 0.657

2024-04-24 00:47:24,312 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:47:24,312 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:47:24,348 - 

2024-04-24 00:47:24,349 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:47:35,998 - Epoch: [384][  100/  296]    Overall Loss 0.681642    Objective Loss 0.681642                                        LR 0.000005    Time 0.116422    
2024-04-24 00:47:43,879 - Epoch: [384][  200/  296]    Overall Loss 0.656069    Objective Loss 0.656069                                        LR 0.000005    Time 0.097582    
2024-04-24 00:47:50,286 - Epoch: [384][  296/  296]    Overall Loss 0.644420    Objective Loss 0.644420    Top1 70.491803    Top5 95.081967    LR 0.000005    Time 0.087557    
2024-04-24 00:47:50,417 - --- validate (epoch=384)-----------
2024-04-24 00:47:50,418 - 3925 samples (32 per mini-batch)
2024-04-24 00:48:02,050 - Epoch: [384][  100/  123]    Loss 0.655059    Top1 79.093750    Top5 97.406250    
2024-04-24 00:48:04,745 - Epoch: [384][  123/  123]    Loss 0.650949    Top1 79.337580    Top5 97.503185    
2024-04-24 00:48:04,879 - ==> Top1: 79.338    Top5: 97.503    Loss: 0.651

2024-04-24 00:48:04,889 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:48:04,889 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:48:04,924 - 

2024-04-24 00:48:04,925 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:48:15,558 - Epoch: [385][  100/  296]    Overall Loss 0.674288    Objective Loss 0.674288                                        LR 0.000005    Time 0.106263    
2024-04-24 00:48:24,657 - Epoch: [385][  200/  296]    Overall Loss 0.668862    Objective Loss 0.668862                                        LR 0.000005    Time 0.098600    
2024-04-24 00:48:30,928 - Epoch: [385][  296/  296]    Overall Loss 0.674412    Objective Loss 0.674412    Top1 85.245902    Top5 93.442623    LR 0.000005    Time 0.087784    
2024-04-24 00:48:31,059 - --- validate (epoch=385)-----------
2024-04-24 00:48:31,060 - 3925 samples (32 per mini-batch)
2024-04-24 00:48:42,389 - Epoch: [385][  100/  123]    Loss 0.650604    Top1 79.343750    Top5 97.562500    
2024-04-24 00:48:44,567 - Epoch: [385][  123/  123]    Loss 0.652303    Top1 79.133758    Top5 97.605096    
2024-04-24 00:48:44,663 - ==> Top1: 79.134    Top5: 97.605    Loss: 0.652

2024-04-24 00:48:44,670 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:48:44,671 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:48:44,707 - 

2024-04-24 00:48:44,707 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:48:55,437 - Epoch: [386][  100/  296]    Overall Loss 0.669315    Objective Loss 0.669315                                        LR 0.000005    Time 0.107214    
2024-04-24 00:49:03,816 - Epoch: [386][  200/  296]    Overall Loss 0.653762    Objective Loss 0.653762                                        LR 0.000005    Time 0.095460    
2024-04-24 00:49:11,667 - Epoch: [386][  296/  296]    Overall Loss 0.655970    Objective Loss 0.655970    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.091002    
2024-04-24 00:49:11,839 - --- validate (epoch=386)-----------
2024-04-24 00:49:11,839 - 3925 samples (32 per mini-batch)
2024-04-24 00:49:22,687 - Epoch: [386][  100/  123]    Loss 0.644713    Top1 79.093750    Top5 97.656250    
2024-04-24 00:49:24,505 - Epoch: [386][  123/  123]    Loss 0.655184    Top1 78.828025    Top5 97.630573    
2024-04-24 00:49:24,579 - ==> Top1: 78.828    Top5: 97.631    Loss: 0.655

2024-04-24 00:49:24,587 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:49:24,587 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:49:24,623 - 

2024-04-24 00:49:24,623 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:49:33,363 - Epoch: [387][  100/  296]    Overall Loss 0.669641    Objective Loss 0.669641                                        LR 0.000005    Time 0.087338    
2024-04-24 00:49:42,065 - Epoch: [387][  200/  296]    Overall Loss 0.665353    Objective Loss 0.665353                                        LR 0.000005    Time 0.087139    
2024-04-24 00:49:50,257 - Epoch: [387][  296/  296]    Overall Loss 0.664843    Objective Loss 0.664843    Top1 86.885246    Top5 100.000000    LR 0.000005    Time 0.086529    
2024-04-24 00:49:50,326 - --- validate (epoch=387)-----------
2024-04-24 00:49:50,327 - 3925 samples (32 per mini-batch)
2024-04-24 00:50:04,634 - Epoch: [387][  100/  123]    Loss 0.676060    Top1 78.281250    Top5 97.437500    
2024-04-24 00:50:07,581 - Epoch: [387][  123/  123]    Loss 0.654075    Top1 78.955414    Top5 97.630573    
2024-04-24 00:50:07,803 - ==> Top1: 78.955    Top5: 97.631    Loss: 0.654

2024-04-24 00:50:07,810 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:50:07,811 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:50:07,849 - 

2024-04-24 00:50:07,849 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:50:20,907 - Epoch: [388][  100/  296]    Overall Loss 0.646051    Objective Loss 0.646051                                        LR 0.000005    Time 0.130474    
2024-04-24 00:50:29,230 - Epoch: [388][  200/  296]    Overall Loss 0.654589    Objective Loss 0.654589                                        LR 0.000005    Time 0.106814    
2024-04-24 00:50:35,647 - Epoch: [388][  296/  296]    Overall Loss 0.658308    Objective Loss 0.658308    Top1 68.852459    Top5 95.081967    LR 0.000005    Time 0.093828    
2024-04-24 00:50:35,762 - --- validate (epoch=388)-----------
2024-04-24 00:50:35,762 - 3925 samples (32 per mini-batch)
2024-04-24 00:50:44,700 - Epoch: [388][  100/  123]    Loss 0.651521    Top1 79.125000    Top5 97.625000    
2024-04-24 00:50:46,444 - Epoch: [388][  123/  123]    Loss 0.657285    Top1 78.828025    Top5 97.528662    
2024-04-24 00:50:46,571 - ==> Top1: 78.828    Top5: 97.529    Loss: 0.657

2024-04-24 00:50:46,579 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:50:46,579 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:50:46,621 - 

2024-04-24 00:50:46,622 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:50:59,573 - Epoch: [389][  100/  296]    Overall Loss 0.656227    Objective Loss 0.656227                                        LR 0.000005    Time 0.129450    
2024-04-24 00:51:08,759 - Epoch: [389][  200/  296]    Overall Loss 0.664926    Objective Loss 0.664926                                        LR 0.000005    Time 0.110622    
2024-04-24 00:51:17,304 - Epoch: [389][  296/  296]    Overall Loss 0.671181    Objective Loss 0.671181    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.103593    
2024-04-24 00:51:17,444 - --- validate (epoch=389)-----------
2024-04-24 00:51:17,445 - 3925 samples (32 per mini-batch)
2024-04-24 00:51:27,378 - Epoch: [389][  100/  123]    Loss 0.651907    Top1 78.718750    Top5 97.593750    
2024-04-24 00:51:29,446 - Epoch: [389][  123/  123]    Loss 0.661086    Top1 78.547771    Top5 97.503185    
2024-04-24 00:51:29,586 - ==> Top1: 78.548    Top5: 97.503    Loss: 0.661

2024-04-24 00:51:29,592 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:51:29,592 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:51:29,632 - 

2024-04-24 00:51:29,632 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:51:39,428 - Epoch: [390][  100/  296]    Overall Loss 0.633917    Objective Loss 0.633917                                        LR 0.000005    Time 0.097866    
2024-04-24 00:51:48,359 - Epoch: [390][  200/  296]    Overall Loss 0.645084    Objective Loss 0.645084                                        LR 0.000005    Time 0.093551    
2024-04-24 00:51:56,590 - Epoch: [390][  296/  296]    Overall Loss 0.657290    Objective Loss 0.657290    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.090999    
2024-04-24 00:51:56,714 - --- validate (epoch=390)-----------
2024-04-24 00:51:56,715 - 3925 samples (32 per mini-batch)
2024-04-24 00:52:07,093 - Epoch: [390][  100/  123]    Loss 0.651393    Top1 79.187500    Top5 97.531250    
2024-04-24 00:52:08,897 - Epoch: [390][  123/  123]    Loss 0.653092    Top1 78.980892    Top5 97.605096    
2024-04-24 00:52:09,039 - ==> Top1: 78.981    Top5: 97.605    Loss: 0.653

2024-04-24 00:52:09,047 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:52:09,047 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:52:09,085 - 

2024-04-24 00:52:09,085 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:52:17,779 - Epoch: [391][  100/  296]    Overall Loss 0.675007    Objective Loss 0.675007                                        LR 0.000005    Time 0.086866    
2024-04-24 00:52:26,090 - Epoch: [391][  200/  296]    Overall Loss 0.671408    Objective Loss 0.671408                                        LR 0.000005    Time 0.084954    
2024-04-24 00:52:34,528 - Epoch: [391][  296/  296]    Overall Loss 0.669657    Objective Loss 0.669657    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.085885    
2024-04-24 00:52:34,614 - --- validate (epoch=391)-----------
2024-04-24 00:52:34,614 - 3925 samples (32 per mini-batch)
2024-04-24 00:52:45,203 - Epoch: [391][  100/  123]    Loss 0.666951    Top1 78.687500    Top5 97.406250    
2024-04-24 00:52:47,208 - Epoch: [391][  123/  123]    Loss 0.658772    Top1 78.853503    Top5 97.477707    
2024-04-24 00:52:47,319 - ==> Top1: 78.854    Top5: 97.478    Loss: 0.659

2024-04-24 00:52:47,327 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:52:47,328 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:52:47,364 - 

2024-04-24 00:52:47,364 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:52:57,604 - Epoch: [392][  100/  296]    Overall Loss 0.664590    Objective Loss 0.664590                                        LR 0.000005    Time 0.102315    
2024-04-24 00:53:05,941 - Epoch: [392][  200/  296]    Overall Loss 0.656144    Objective Loss 0.656144                                        LR 0.000005    Time 0.092798    
2024-04-24 00:53:14,022 - Epoch: [392][  296/  296]    Overall Loss 0.664203    Objective Loss 0.664203    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.089981    
2024-04-24 00:53:14,157 - --- validate (epoch=392)-----------
2024-04-24 00:53:14,157 - 3925 samples (32 per mini-batch)
2024-04-24 00:53:24,945 - Epoch: [392][  100/  123]    Loss 0.649315    Top1 79.312500    Top5 97.750000    
2024-04-24 00:53:27,156 - Epoch: [392][  123/  123]    Loss 0.655158    Top1 79.312102    Top5 97.579618    
2024-04-24 00:53:27,279 - ==> Top1: 79.312    Top5: 97.580    Loss: 0.655

2024-04-24 00:53:27,287 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:53:27,288 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:53:27,324 - 

2024-04-24 00:53:27,324 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:53:36,980 - Epoch: [393][  100/  296]    Overall Loss 0.652311    Objective Loss 0.652311                                        LR 0.000005    Time 0.096485    
2024-04-24 00:53:44,953 - Epoch: [393][  200/  296]    Overall Loss 0.663244    Objective Loss 0.663244                                        LR 0.000005    Time 0.088074    
2024-04-24 00:53:53,716 - Epoch: [393][  296/  296]    Overall Loss 0.671415    Objective Loss 0.671415    Top1 78.688525    Top5 93.442623    LR 0.000005    Time 0.089094    
2024-04-24 00:53:53,876 - --- validate (epoch=393)-----------
2024-04-24 00:53:53,876 - 3925 samples (32 per mini-batch)
2024-04-24 00:54:04,278 - Epoch: [393][  100/  123]    Loss 0.656850    Top1 79.281250    Top5 97.281250    
2024-04-24 00:54:06,794 - Epoch: [393][  123/  123]    Loss 0.656388    Top1 78.955414    Top5 97.477707    
2024-04-24 00:54:07,032 - ==> Top1: 78.955    Top5: 97.478    Loss: 0.656

2024-04-24 00:54:07,039 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:54:07,040 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:54:07,075 - 

2024-04-24 00:54:07,075 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:54:18,131 - Epoch: [394][  100/  296]    Overall Loss 0.656656    Objective Loss 0.656656                                        LR 0.000005    Time 0.110485    
2024-04-24 00:54:28,559 - Epoch: [394][  200/  296]    Overall Loss 0.661444    Objective Loss 0.661444                                        LR 0.000005    Time 0.107345    
2024-04-24 00:54:37,367 - Epoch: [394][  296/  296]    Overall Loss 0.656449    Objective Loss 0.656449    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.102264    
2024-04-24 00:54:37,504 - --- validate (epoch=394)-----------
2024-04-24 00:54:37,504 - 3925 samples (32 per mini-batch)
2024-04-24 00:54:48,754 - Epoch: [394][  100/  123]    Loss 0.641430    Top1 79.375000    Top5 97.781250    
2024-04-24 00:54:50,766 - Epoch: [394][  123/  123]    Loss 0.655155    Top1 78.878981    Top5 97.656051    
2024-04-24 00:54:50,861 - ==> Top1: 78.879    Top5: 97.656    Loss: 0.655

2024-04-24 00:54:50,869 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:54:50,869 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:54:50,906 - 

2024-04-24 00:54:50,906 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:54:59,513 - Epoch: [395][  100/  296]    Overall Loss 0.650797    Objective Loss 0.650797                                        LR 0.000005    Time 0.085991    
2024-04-24 00:55:06,478 - Epoch: [395][  200/  296]    Overall Loss 0.653542    Objective Loss 0.653542                                        LR 0.000005    Time 0.077791    
2024-04-24 00:55:13,320 - Epoch: [395][  296/  296]    Overall Loss 0.650435    Objective Loss 0.650435    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.075654    
2024-04-24 00:55:13,420 - --- validate (epoch=395)-----------
2024-04-24 00:55:13,420 - 3925 samples (32 per mini-batch)
2024-04-24 00:55:23,388 - Epoch: [395][  100/  123]    Loss 0.655479    Top1 78.875000    Top5 97.500000    
2024-04-24 00:55:25,182 - Epoch: [395][  123/  123]    Loss 0.657290    Top1 78.828025    Top5 97.503185    
2024-04-24 00:55:25,269 - ==> Top1: 78.828    Top5: 97.503    Loss: 0.657

2024-04-24 00:55:25,277 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:55:25,277 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:55:25,313 - 

2024-04-24 00:55:25,313 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:55:35,335 - Epoch: [396][  100/  296]    Overall Loss 0.661017    Objective Loss 0.661017                                        LR 0.000005    Time 0.100147    
2024-04-24 00:55:44,528 - Epoch: [396][  200/  296]    Overall Loss 0.652067    Objective Loss 0.652067                                        LR 0.000005    Time 0.096007    
2024-04-24 00:55:52,301 - Epoch: [396][  296/  296]    Overall Loss 0.662442    Objective Loss 0.662442    Top1 83.606557    Top5 95.081967    LR 0.000005    Time 0.091104    
2024-04-24 00:55:52,494 - --- validate (epoch=396)-----------
2024-04-24 00:55:52,495 - 3925 samples (32 per mini-batch)
2024-04-24 00:56:03,308 - Epoch: [396][  100/  123]    Loss 0.660605    Top1 78.625000    Top5 97.468750    
2024-04-24 00:56:04,920 - Epoch: [396][  123/  123]    Loss 0.658456    Top1 78.929936    Top5 97.477707    
2024-04-24 00:56:05,070 - ==> Top1: 78.930    Top5: 97.478    Loss: 0.658

2024-04-24 00:56:05,076 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:56:05,077 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:56:05,120 - 

2024-04-24 00:56:05,120 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:56:13,692 - Epoch: [397][  100/  296]    Overall Loss 0.653028    Objective Loss 0.653028                                        LR 0.000005    Time 0.085627    
2024-04-24 00:56:20,588 - Epoch: [397][  200/  296]    Overall Loss 0.648426    Objective Loss 0.648426                                        LR 0.000005    Time 0.077252    
2024-04-24 00:56:26,518 - Epoch: [397][  296/  296]    Overall Loss 0.655790    Objective Loss 0.655790    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.072206    
2024-04-24 00:56:26,667 - --- validate (epoch=397)-----------
2024-04-24 00:56:26,668 - 3925 samples (32 per mini-batch)
2024-04-24 00:56:40,040 - Epoch: [397][  100/  123]    Loss 0.659348    Top1 79.062500    Top5 97.468750    
2024-04-24 00:56:42,343 - Epoch: [397][  123/  123]    Loss 0.656087    Top1 79.057325    Top5 97.554140    
2024-04-24 00:56:42,481 - ==> Top1: 79.057    Top5: 97.554    Loss: 0.656

2024-04-24 00:56:42,489 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:56:42,490 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:56:42,524 - 

2024-04-24 00:56:42,524 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:56:50,824 - Epoch: [398][  100/  296]    Overall Loss 0.645591    Objective Loss 0.645591                                        LR 0.000005    Time 0.082925    
2024-04-24 00:56:57,301 - Epoch: [398][  200/  296]    Overall Loss 0.661979    Objective Loss 0.661979                                        LR 0.000005    Time 0.073814    
2024-04-24 00:57:04,347 - Epoch: [398][  296/  296]    Overall Loss 0.665295    Objective Loss 0.665295    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.073654    
2024-04-24 00:57:04,475 - --- validate (epoch=398)-----------
2024-04-24 00:57:04,475 - 3925 samples (32 per mini-batch)
2024-04-24 00:57:16,530 - Epoch: [398][  100/  123]    Loss 0.665682    Top1 78.468750    Top5 97.406250    
2024-04-24 00:57:19,596 - Epoch: [398][  123/  123]    Loss 0.660363    Top1 78.649682    Top5 97.452229    
2024-04-24 00:57:19,708 - ==> Top1: 78.650    Top5: 97.452    Loss: 0.660

2024-04-24 00:57:19,718 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:57:19,718 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:57:19,755 - 

2024-04-24 00:57:19,755 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:57:29,816 - Epoch: [399][  100/  296]    Overall Loss 0.661961    Objective Loss 0.661961                                        LR 0.000005    Time 0.100549    
2024-04-24 00:57:38,620 - Epoch: [399][  200/  296]    Overall Loss 0.651394    Objective Loss 0.651394                                        LR 0.000005    Time 0.094264    
2024-04-24 00:57:46,637 - Epoch: [399][  296/  296]    Overall Loss 0.652331    Objective Loss 0.652331    Top1 81.967213    Top5 95.081967    LR 0.000005    Time 0.090754    
2024-04-24 00:57:46,773 - --- validate (epoch=399)-----------
2024-04-24 00:57:46,773 - 3925 samples (32 per mini-batch)
2024-04-24 00:57:57,503 - Epoch: [399][  100/  123]    Loss 0.666815    Top1 79.062500    Top5 97.531250    
2024-04-24 00:57:59,647 - Epoch: [399][  123/  123]    Loss 0.659209    Top1 78.955414    Top5 97.579618    
2024-04-24 00:57:59,807 - ==> Top1: 78.955    Top5: 97.580    Loss: 0.659

2024-04-24 00:57:59,815 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:57:59,815 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:57:59,853 - 

2024-04-24 00:57:59,853 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:58:07,659 - Epoch: [400][  100/  296]    Overall Loss 0.639861    Objective Loss 0.639861                                        LR 0.000005    Time 0.077977    
2024-04-24 00:58:15,047 - Epoch: [400][  200/  296]    Overall Loss 0.656331    Objective Loss 0.656331                                        LR 0.000005    Time 0.075892    
2024-04-24 00:58:21,469 - Epoch: [400][  296/  296]    Overall Loss 0.654590    Objective Loss 0.654590    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.072954    
2024-04-24 00:58:21,600 - --- validate (epoch=400)-----------
2024-04-24 00:58:21,601 - 3925 samples (32 per mini-batch)
2024-04-24 00:58:30,782 - Epoch: [400][  100/  123]    Loss 0.662101    Top1 78.781250    Top5 97.687500    
2024-04-24 00:58:32,672 - Epoch: [400][  123/  123]    Loss 0.658306    Top1 78.929936    Top5 97.554140    
2024-04-24 00:58:32,818 - ==> Top1: 78.930    Top5: 97.554    Loss: 0.658

2024-04-24 00:58:32,826 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:58:32,827 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:58:32,863 - 

2024-04-24 00:58:32,863 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:58:41,256 - Epoch: [401][  100/  296]    Overall Loss 0.683378    Objective Loss 0.683378                                        LR 0.000005    Time 0.083867    
2024-04-24 00:58:47,165 - Epoch: [401][  200/  296]    Overall Loss 0.668863    Objective Loss 0.668863                                        LR 0.000005    Time 0.071438    
2024-04-24 00:58:54,336 - Epoch: [401][  296/  296]    Overall Loss 0.669619    Objective Loss 0.669619    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.072472    
2024-04-24 00:58:54,436 - --- validate (epoch=401)-----------
2024-04-24 00:58:54,437 - 3925 samples (32 per mini-batch)
2024-04-24 00:59:04,915 - Epoch: [401][  100/  123]    Loss 0.655865    Top1 78.718750    Top5 97.625000    
2024-04-24 00:59:06,793 - Epoch: [401][  123/  123]    Loss 0.657301    Top1 78.700637    Top5 97.656051    
2024-04-24 00:59:06,906 - ==> Top1: 78.701    Top5: 97.656    Loss: 0.657

2024-04-24 00:59:06,914 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:59:06,914 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:59:06,950 - 

2024-04-24 00:59:06,951 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:59:17,038 - Epoch: [402][  100/  296]    Overall Loss 0.632850    Objective Loss 0.632850                                        LR 0.000005    Time 0.100805    
2024-04-24 00:59:26,385 - Epoch: [402][  200/  296]    Overall Loss 0.634328    Objective Loss 0.634328                                        LR 0.000005    Time 0.097099    
2024-04-24 00:59:33,914 - Epoch: [402][  296/  296]    Overall Loss 0.645013    Objective Loss 0.645013    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.091022    
2024-04-24 00:59:34,041 - --- validate (epoch=402)-----------
2024-04-24 00:59:34,042 - 3925 samples (32 per mini-batch)
2024-04-24 00:59:43,678 - Epoch: [402][  100/  123]    Loss 0.662413    Top1 78.812500    Top5 97.625000    
2024-04-24 00:59:45,965 - Epoch: [402][  123/  123]    Loss 0.657364    Top1 78.878981    Top5 97.554140    
2024-04-24 00:59:46,054 - ==> Top1: 78.879    Top5: 97.554    Loss: 0.657

2024-04-24 00:59:46,061 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 00:59:46,062 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 00:59:46,096 - 

2024-04-24 00:59:46,096 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 00:59:56,377 - Epoch: [403][  100/  296]    Overall Loss 0.635902    Objective Loss 0.635902                                        LR 0.000005    Time 0.102737    
2024-04-24 01:00:07,176 - Epoch: [403][  200/  296]    Overall Loss 0.653369    Objective Loss 0.653369                                        LR 0.000005    Time 0.105318    
2024-04-24 01:00:18,116 - Epoch: [403][  296/  296]    Overall Loss 0.654335    Objective Loss 0.654335    Top1 85.245902    Top5 96.721311    LR 0.000005    Time 0.108093    
2024-04-24 01:00:18,207 - --- validate (epoch=403)-----------
2024-04-24 01:00:18,208 - 3925 samples (32 per mini-batch)
2024-04-24 01:00:28,750 - Epoch: [403][  100/  123]    Loss 0.647022    Top1 78.843750    Top5 97.718750    
2024-04-24 01:00:30,495 - Epoch: [403][  123/  123]    Loss 0.657019    Top1 78.700637    Top5 97.554140    
2024-04-24 01:00:30,624 - ==> Top1: 78.701    Top5: 97.554    Loss: 0.657

2024-04-24 01:00:30,632 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:00:30,633 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:00:30,669 - 

2024-04-24 01:00:30,669 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:00:39,787 - Epoch: [404][  100/  296]    Overall Loss 0.645068    Objective Loss 0.645068                                        LR 0.000005    Time 0.091098    
2024-04-24 01:00:47,408 - Epoch: [404][  200/  296]    Overall Loss 0.658368    Objective Loss 0.658368                                        LR 0.000005    Time 0.083614    
2024-04-24 01:00:55,387 - Epoch: [404][  296/  296]    Overall Loss 0.663174    Objective Loss 0.663174    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.083429    
2024-04-24 01:00:55,531 - --- validate (epoch=404)-----------
2024-04-24 01:00:55,532 - 3925 samples (32 per mini-batch)
2024-04-24 01:01:05,057 - Epoch: [404][  100/  123]    Loss 0.656425    Top1 78.718750    Top5 97.437500    
2024-04-24 01:01:06,932 - Epoch: [404][  123/  123]    Loss 0.655786    Top1 78.751592    Top5 97.528662    
2024-04-24 01:01:07,081 - ==> Top1: 78.752    Top5: 97.529    Loss: 0.656

2024-04-24 01:01:07,090 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:01:07,091 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:01:07,132 - 

2024-04-24 01:01:07,132 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:01:16,936 - Epoch: [405][  100/  296]    Overall Loss 0.649916    Objective Loss 0.649916                                        LR 0.000005    Time 0.097969    
2024-04-24 01:01:23,939 - Epoch: [405][  200/  296]    Overall Loss 0.659698    Objective Loss 0.659698                                        LR 0.000005    Time 0.083962    
2024-04-24 01:01:31,105 - Epoch: [405][  296/  296]    Overall Loss 0.658013    Objective Loss 0.658013    Top1 85.245902    Top5 96.721311    LR 0.000005    Time 0.080918    
2024-04-24 01:01:31,231 - --- validate (epoch=405)-----------
2024-04-24 01:01:31,232 - 3925 samples (32 per mini-batch)
2024-04-24 01:01:41,591 - Epoch: [405][  100/  123]    Loss 0.654498    Top1 79.062500    Top5 97.406250    
2024-04-24 01:01:43,550 - Epoch: [405][  123/  123]    Loss 0.656174    Top1 78.828025    Top5 97.477707    
2024-04-24 01:01:43,674 - ==> Top1: 78.828    Top5: 97.478    Loss: 0.656

2024-04-24 01:01:43,682 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:01:43,682 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:01:43,719 - 

2024-04-24 01:01:43,720 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:01:52,955 - Epoch: [406][  100/  296]    Overall Loss 0.639886    Objective Loss 0.639886                                        LR 0.000005    Time 0.092277    
2024-04-24 01:02:01,344 - Epoch: [406][  200/  296]    Overall Loss 0.664222    Objective Loss 0.664222                                        LR 0.000005    Time 0.088048    
2024-04-24 01:02:09,089 - Epoch: [406][  296/  296]    Overall Loss 0.652973    Objective Loss 0.652973    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.085634    
2024-04-24 01:02:09,233 - --- validate (epoch=406)-----------
2024-04-24 01:02:09,234 - 3925 samples (32 per mini-batch)
2024-04-24 01:02:21,186 - Epoch: [406][  100/  123]    Loss 0.656772    Top1 78.500000    Top5 97.593750    
2024-04-24 01:02:23,627 - Epoch: [406][  123/  123]    Loss 0.661214    Top1 78.598726    Top5 97.554140    
2024-04-24 01:02:23,709 - ==> Top1: 78.599    Top5: 97.554    Loss: 0.661

2024-04-24 01:02:23,717 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:02:23,718 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:02:23,754 - 

2024-04-24 01:02:23,754 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:02:33,336 - Epoch: [407][  100/  296]    Overall Loss 0.649209    Objective Loss 0.649209                                        LR 0.000005    Time 0.095734    
2024-04-24 01:02:41,286 - Epoch: [407][  200/  296]    Overall Loss 0.650362    Objective Loss 0.650362                                        LR 0.000005    Time 0.087578    
2024-04-24 01:02:50,119 - Epoch: [407][  296/  296]    Overall Loss 0.645470    Objective Loss 0.645470    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.088987    
2024-04-24 01:02:50,238 - --- validate (epoch=407)-----------
2024-04-24 01:02:50,238 - 3925 samples (32 per mini-batch)
2024-04-24 01:03:01,729 - Epoch: [407][  100/  123]    Loss 0.653098    Top1 78.875000    Top5 97.812500    
2024-04-24 01:03:03,979 - Epoch: [407][  123/  123]    Loss 0.655853    Top1 78.726115    Top5 97.579618    
2024-04-24 01:03:04,144 - ==> Top1: 78.726    Top5: 97.580    Loss: 0.656

2024-04-24 01:03:04,152 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:03:04,152 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:03:04,186 - 

2024-04-24 01:03:04,186 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:03:12,769 - Epoch: [408][  100/  296]    Overall Loss 0.664384    Objective Loss 0.664384                                        LR 0.000005    Time 0.085749    
2024-04-24 01:03:20,867 - Epoch: [408][  200/  296]    Overall Loss 0.663139    Objective Loss 0.663139                                        LR 0.000005    Time 0.083334    
2024-04-24 01:03:27,661 - Epoch: [408][  296/  296]    Overall Loss 0.662393    Objective Loss 0.662393    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.079236    
2024-04-24 01:03:27,805 - --- validate (epoch=408)-----------
2024-04-24 01:03:27,805 - 3925 samples (32 per mini-batch)
2024-04-24 01:03:41,109 - Epoch: [408][  100/  123]    Loss 0.650201    Top1 79.500000    Top5 97.812500    
2024-04-24 01:03:43,193 - Epoch: [408][  123/  123]    Loss 0.655519    Top1 79.108280    Top5 97.656051    
2024-04-24 01:03:43,320 - ==> Top1: 79.108    Top5: 97.656    Loss: 0.656

2024-04-24 01:03:43,328 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:03:43,328 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:03:43,365 - 

2024-04-24 01:03:43,365 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:03:52,605 - Epoch: [409][  100/  296]    Overall Loss 0.626554    Objective Loss 0.626554                                        LR 0.000005    Time 0.092327    
2024-04-24 01:04:00,252 - Epoch: [409][  200/  296]    Overall Loss 0.657414    Objective Loss 0.657414                                        LR 0.000005    Time 0.084360    
2024-04-24 01:04:06,692 - Epoch: [409][  296/  296]    Overall Loss 0.653995    Objective Loss 0.653995    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.078735    
2024-04-24 01:04:06,882 - --- validate (epoch=409)-----------
2024-04-24 01:04:06,883 - 3925 samples (32 per mini-batch)
2024-04-24 01:04:21,070 - Epoch: [409][  100/  123]    Loss 0.655796    Top1 78.937500    Top5 97.531250    
2024-04-24 01:04:23,785 - Epoch: [409][  123/  123]    Loss 0.659974    Top1 78.980892    Top5 97.528662    
2024-04-24 01:04:24,016 - ==> Top1: 78.981    Top5: 97.529    Loss: 0.660

2024-04-24 01:04:24,024 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:04:24,025 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:04:24,060 - 

2024-04-24 01:04:24,060 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:04:33,226 - Epoch: [410][  100/  296]    Overall Loss 0.634435    Objective Loss 0.634435                                        LR 0.000005    Time 0.091576    
2024-04-24 01:04:40,830 - Epoch: [410][  200/  296]    Overall Loss 0.649354    Objective Loss 0.649354                                        LR 0.000005    Time 0.083774    
2024-04-24 01:04:48,617 - Epoch: [410][  296/  296]    Overall Loss 0.656279    Objective Loss 0.656279    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.082894    
2024-04-24 01:04:48,707 - --- validate (epoch=410)-----------
2024-04-24 01:04:48,708 - 3925 samples (32 per mini-batch)
2024-04-24 01:04:56,693 - Epoch: [410][  100/  123]    Loss 0.659523    Top1 78.562500    Top5 97.531250    
2024-04-24 01:04:58,330 - Epoch: [410][  123/  123]    Loss 0.657044    Top1 78.675159    Top5 97.554140    
2024-04-24 01:04:58,399 - ==> Top1: 78.675    Top5: 97.554    Loss: 0.657

2024-04-24 01:04:58,407 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:04:58,408 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:04:58,443 - 

2024-04-24 01:04:58,443 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:05:06,737 - Epoch: [411][  100/  296]    Overall Loss 0.640110    Objective Loss 0.640110                                        LR 0.000005    Time 0.082865    
2024-04-24 01:05:14,340 - Epoch: [411][  200/  296]    Overall Loss 0.657078    Objective Loss 0.657078                                        LR 0.000005    Time 0.079412    
2024-04-24 01:05:23,175 - Epoch: [411][  296/  296]    Overall Loss 0.661344    Objective Loss 0.661344    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.083481    
2024-04-24 01:05:23,291 - --- validate (epoch=411)-----------
2024-04-24 01:05:23,291 - 3925 samples (32 per mini-batch)
2024-04-24 01:05:33,765 - Epoch: [411][  100/  123]    Loss 0.653715    Top1 78.968750    Top5 97.812500    
2024-04-24 01:05:35,717 - Epoch: [411][  123/  123]    Loss 0.653828    Top1 78.904459    Top5 97.656051    
2024-04-24 01:05:35,849 - ==> Top1: 78.904    Top5: 97.656    Loss: 0.654

2024-04-24 01:05:35,853 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:05:35,853 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:05:35,880 - 

2024-04-24 01:05:35,880 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:05:46,097 - Epoch: [412][  100/  296]    Overall Loss 0.641970    Objective Loss 0.641970                                        LR 0.000005    Time 0.102090    
2024-04-24 01:05:53,718 - Epoch: [412][  200/  296]    Overall Loss 0.659723    Objective Loss 0.659723                                        LR 0.000005    Time 0.089118    
2024-04-24 01:06:02,500 - Epoch: [412][  296/  296]    Overall Loss 0.657565    Objective Loss 0.657565    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.089864    
2024-04-24 01:06:02,626 - --- validate (epoch=412)-----------
2024-04-24 01:06:02,626 - 3925 samples (32 per mini-batch)
2024-04-24 01:06:14,444 - Epoch: [412][  100/  123]    Loss 0.650177    Top1 78.781250    Top5 97.656250    
2024-04-24 01:06:17,117 - Epoch: [412][  123/  123]    Loss 0.656414    Top1 78.904459    Top5 97.554140    
2024-04-24 01:06:17,251 - ==> Top1: 78.904    Top5: 97.554    Loss: 0.656

2024-04-24 01:06:17,258 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:06:17,259 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:06:17,295 - 

2024-04-24 01:06:17,295 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:06:28,994 - Epoch: [413][  100/  296]    Overall Loss 0.642651    Objective Loss 0.642651                                        LR 0.000005    Time 0.116906    
2024-04-24 01:06:38,270 - Epoch: [413][  200/  296]    Overall Loss 0.652806    Objective Loss 0.652806                                        LR 0.000005    Time 0.104796    
2024-04-24 01:06:48,098 - Epoch: [413][  296/  296]    Overall Loss 0.654495    Objective Loss 0.654495    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.103987    
2024-04-24 01:06:48,220 - --- validate (epoch=413)-----------
2024-04-24 01:06:48,221 - 3925 samples (32 per mini-batch)
2024-04-24 01:06:58,220 - Epoch: [413][  100/  123]    Loss 0.651216    Top1 79.093750    Top5 97.718750    
2024-04-24 01:06:59,803 - Epoch: [413][  123/  123]    Loss 0.656532    Top1 79.006369    Top5 97.579618    
2024-04-24 01:06:59,926 - ==> Top1: 79.006    Top5: 97.580    Loss: 0.657

2024-04-24 01:06:59,932 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:06:59,933 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:06:59,966 - 

2024-04-24 01:06:59,966 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:07:09,205 - Epoch: [414][  100/  296]    Overall Loss 0.646416    Objective Loss 0.646416                                        LR 0.000005    Time 0.092299    
2024-04-24 01:07:17,539 - Epoch: [414][  200/  296]    Overall Loss 0.666915    Objective Loss 0.666915                                        LR 0.000005    Time 0.087768    
2024-04-24 01:07:25,437 - Epoch: [414][  296/  296]    Overall Loss 0.662881    Objective Loss 0.662881    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.085963    
2024-04-24 01:07:25,559 - --- validate (epoch=414)-----------
2024-04-24 01:07:25,560 - 3925 samples (32 per mini-batch)
2024-04-24 01:07:35,873 - Epoch: [414][  100/  123]    Loss 0.660055    Top1 78.593750    Top5 97.562500    
2024-04-24 01:07:37,890 - Epoch: [414][  123/  123]    Loss 0.658502    Top1 78.700637    Top5 97.630573    
2024-04-24 01:07:37,973 - ==> Top1: 78.701    Top5: 97.631    Loss: 0.659

2024-04-24 01:07:37,981 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:07:37,981 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:07:38,015 - 

2024-04-24 01:07:38,016 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:07:46,292 - Epoch: [415][  100/  296]    Overall Loss 0.666725    Objective Loss 0.666725                                        LR 0.000005    Time 0.082690    
2024-04-24 01:07:52,663 - Epoch: [415][  200/  296]    Overall Loss 0.660000    Objective Loss 0.660000                                        LR 0.000005    Time 0.073166    
2024-04-24 01:07:58,290 - Epoch: [415][  296/  296]    Overall Loss 0.650588    Objective Loss 0.650588    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.068423    
2024-04-24 01:07:58,423 - --- validate (epoch=415)-----------
2024-04-24 01:07:58,424 - 3925 samples (32 per mini-batch)
2024-04-24 01:08:07,867 - Epoch: [415][  100/  123]    Loss 0.653088    Top1 79.156250    Top5 97.500000    
2024-04-24 01:08:09,394 - Epoch: [415][  123/  123]    Loss 0.655613    Top1 79.006369    Top5 97.426752    
2024-04-24 01:08:09,495 - ==> Top1: 79.006    Top5: 97.427    Loss: 0.656

2024-04-24 01:08:09,500 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:08:09,500 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:08:09,527 - 

2024-04-24 01:08:09,527 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:08:17,901 - Epoch: [416][  100/  296]    Overall Loss 0.653800    Objective Loss 0.653800                                        LR 0.000005    Time 0.083670    
2024-04-24 01:08:24,307 - Epoch: [416][  200/  296]    Overall Loss 0.663169    Objective Loss 0.663169                                        LR 0.000005    Time 0.073828    
2024-04-24 01:08:30,343 - Epoch: [416][  296/  296]    Overall Loss 0.655062    Objective Loss 0.655062    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.070256    
2024-04-24 01:08:30,419 - --- validate (epoch=416)-----------
2024-04-24 01:08:30,419 - 3925 samples (32 per mini-batch)
2024-04-24 01:08:41,881 - Epoch: [416][  100/  123]    Loss 0.652973    Top1 79.375000    Top5 97.500000    
2024-04-24 01:08:44,224 - Epoch: [416][  123/  123]    Loss 0.656311    Top1 79.006369    Top5 97.503185    
2024-04-24 01:08:44,314 - ==> Top1: 79.006    Top5: 97.503    Loss: 0.656

2024-04-24 01:08:44,322 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:08:44,322 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:08:44,358 - 

2024-04-24 01:08:44,358 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:08:54,369 - Epoch: [417][  100/  296]    Overall Loss 0.675792    Objective Loss 0.675792                                        LR 0.000005    Time 0.100029    
2024-04-24 01:09:03,649 - Epoch: [417][  200/  296]    Overall Loss 0.661827    Objective Loss 0.661827                                        LR 0.000005    Time 0.096374    
2024-04-24 01:09:12,177 - Epoch: [417][  296/  296]    Overall Loss 0.656176    Objective Loss 0.656176    Top1 68.852459    Top5 98.360656    LR 0.000005    Time 0.093907    
2024-04-24 01:09:12,305 - --- validate (epoch=417)-----------
2024-04-24 01:09:12,305 - 3925 samples (32 per mini-batch)
2024-04-24 01:09:21,858 - Epoch: [417][  100/  123]    Loss 0.652283    Top1 79.406250    Top5 97.562500    
2024-04-24 01:09:24,325 - Epoch: [417][  123/  123]    Loss 0.653846    Top1 79.133758    Top5 97.656051    
2024-04-24 01:09:24,440 - ==> Top1: 79.134    Top5: 97.656    Loss: 0.654

2024-04-24 01:09:24,449 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:09:24,449 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:09:24,487 - 

2024-04-24 01:09:24,487 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:09:35,693 - Epoch: [418][  100/  296]    Overall Loss 0.648453    Objective Loss 0.648453                                        LR 0.000005    Time 0.111984    
2024-04-24 01:09:44,488 - Epoch: [418][  200/  296]    Overall Loss 0.659068    Objective Loss 0.659068                                        LR 0.000005    Time 0.099935    
2024-04-24 01:09:51,258 - Epoch: [418][  296/  296]    Overall Loss 0.655696    Objective Loss 0.655696    Top1 88.524590    Top5 98.360656    LR 0.000005    Time 0.090371    
2024-04-24 01:09:51,382 - --- validate (epoch=418)-----------
2024-04-24 01:09:51,382 - 3925 samples (32 per mini-batch)
2024-04-24 01:10:02,598 - Epoch: [418][  100/  123]    Loss 0.652879    Top1 79.187500    Top5 97.718750    
2024-04-24 01:10:04,753 - Epoch: [418][  123/  123]    Loss 0.655195    Top1 79.159236    Top5 97.630573    
2024-04-24 01:10:04,860 - ==> Top1: 79.159    Top5: 97.631    Loss: 0.655

2024-04-24 01:10:04,866 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:10:04,867 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:10:04,909 - 

2024-04-24 01:10:04,910 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:10:15,823 - Epoch: [419][  100/  296]    Overall Loss 0.662903    Objective Loss 0.662903                                        LR 0.000005    Time 0.109048    
2024-04-24 01:10:23,941 - Epoch: [419][  200/  296]    Overall Loss 0.666057    Objective Loss 0.666057                                        LR 0.000005    Time 0.095082    
2024-04-24 01:10:31,970 - Epoch: [419][  296/  296]    Overall Loss 0.664958    Objective Loss 0.664958    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.091351    
2024-04-24 01:10:32,078 - --- validate (epoch=419)-----------
2024-04-24 01:10:32,079 - 3925 samples (32 per mini-batch)
2024-04-24 01:10:43,218 - Epoch: [419][  100/  123]    Loss 0.666828    Top1 78.343750    Top5 97.500000    
2024-04-24 01:10:45,545 - Epoch: [419][  123/  123]    Loss 0.657745    Top1 78.675159    Top5 97.579618    
2024-04-24 01:10:45,666 - ==> Top1: 78.675    Top5: 97.580    Loss: 0.658

2024-04-24 01:10:45,672 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:10:45,672 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:10:45,701 - 

2024-04-24 01:10:45,701 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:10:54,972 - Epoch: [420][  100/  296]    Overall Loss 0.710270    Objective Loss 0.710270                                        LR 0.000005    Time 0.092629    
2024-04-24 01:11:03,157 - Epoch: [420][  200/  296]    Overall Loss 0.678244    Objective Loss 0.678244                                        LR 0.000005    Time 0.087203    
2024-04-24 01:11:11,063 - Epoch: [420][  296/  296]    Overall Loss 0.661699    Objective Loss 0.661699    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.085608    
2024-04-24 01:11:11,156 - --- validate (epoch=420)-----------
2024-04-24 01:11:11,157 - 3925 samples (32 per mini-batch)
2024-04-24 01:11:22,019 - Epoch: [420][  100/  123]    Loss 0.640644    Top1 79.437500    Top5 97.750000    
2024-04-24 01:11:24,405 - Epoch: [420][  123/  123]    Loss 0.656856    Top1 78.955414    Top5 97.554140    
2024-04-24 01:11:24,499 - ==> Top1: 78.955    Top5: 97.554    Loss: 0.657

2024-04-24 01:11:24,508 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:11:24,508 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:11:24,544 - 

2024-04-24 01:11:24,545 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:11:34,975 - Epoch: [421][  100/  296]    Overall Loss 0.655706    Objective Loss 0.655706                                        LR 0.000005    Time 0.104223    
2024-04-24 01:11:43,229 - Epoch: [421][  200/  296]    Overall Loss 0.655836    Objective Loss 0.655836                                        LR 0.000005    Time 0.093344    
2024-04-24 01:11:50,145 - Epoch: [421][  296/  296]    Overall Loss 0.655985    Objective Loss 0.655985    Top1 81.967213    Top5 95.081967    LR 0.000005    Time 0.086414    
2024-04-24 01:11:50,284 - --- validate (epoch=421)-----------
2024-04-24 01:11:50,285 - 3925 samples (32 per mini-batch)
2024-04-24 01:11:59,747 - Epoch: [421][  100/  123]    Loss 0.649080    Top1 78.406250    Top5 97.843750    
2024-04-24 01:12:01,742 - Epoch: [421][  123/  123]    Loss 0.654904    Top1 78.777070    Top5 97.707006    
2024-04-24 01:12:01,905 - ==> Top1: 78.777    Top5: 97.707    Loss: 0.655

2024-04-24 01:12:01,913 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:12:01,914 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:12:01,948 - 

2024-04-24 01:12:01,948 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:12:11,711 - Epoch: [422][  100/  296]    Overall Loss 0.632235    Objective Loss 0.632235                                        LR 0.000005    Time 0.097541    
2024-04-24 01:12:20,757 - Epoch: [422][  200/  296]    Overall Loss 0.626793    Objective Loss 0.626793                                        LR 0.000005    Time 0.093957    
2024-04-24 01:12:29,688 - Epoch: [422][  296/  296]    Overall Loss 0.651798    Objective Loss 0.651798    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.093632    
2024-04-24 01:12:29,815 - --- validate (epoch=422)-----------
2024-04-24 01:12:29,816 - 3925 samples (32 per mini-batch)
2024-04-24 01:12:41,648 - Epoch: [422][  100/  123]    Loss 0.656812    Top1 79.031250    Top5 97.468750    
2024-04-24 01:12:43,583 - Epoch: [422][  123/  123]    Loss 0.658635    Top1 78.904459    Top5 97.503185    
2024-04-24 01:12:43,679 - ==> Top1: 78.904    Top5: 97.503    Loss: 0.659

2024-04-24 01:12:43,687 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:12:43,688 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:12:43,723 - 

2024-04-24 01:12:43,724 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:12:53,355 - Epoch: [423][  100/  296]    Overall Loss 0.648347    Objective Loss 0.648347                                        LR 0.000005    Time 0.096244    
2024-04-24 01:13:00,591 - Epoch: [423][  200/  296]    Overall Loss 0.648212    Objective Loss 0.648212                                        LR 0.000005    Time 0.084269    
2024-04-24 01:13:08,204 - Epoch: [423][  296/  296]    Overall Loss 0.655344    Objective Loss 0.655344    Top1 86.885246    Top5 100.000000    LR 0.000005    Time 0.082637    
2024-04-24 01:13:08,297 - --- validate (epoch=423)-----------
2024-04-24 01:13:08,298 - 3925 samples (32 per mini-batch)
2024-04-24 01:13:20,233 - Epoch: [423][  100/  123]    Loss 0.651161    Top1 78.531250    Top5 97.656250    
2024-04-24 01:13:22,791 - Epoch: [423][  123/  123]    Loss 0.656594    Top1 78.598726    Top5 97.605096    
2024-04-24 01:13:22,912 - ==> Top1: 78.599    Top5: 97.605    Loss: 0.657

2024-04-24 01:13:22,917 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:13:22,917 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:13:22,950 - 

2024-04-24 01:13:22,951 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:13:34,551 - Epoch: [424][  100/  296]    Overall Loss 0.645884    Objective Loss 0.645884                                        LR 0.000005    Time 0.115938    
2024-04-24 01:13:44,896 - Epoch: [424][  200/  296]    Overall Loss 0.653699    Objective Loss 0.653699                                        LR 0.000005    Time 0.109663    
2024-04-24 01:13:54,896 - Epoch: [424][  296/  296]    Overall Loss 0.662243    Objective Loss 0.662243    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.107859    
2024-04-24 01:13:55,029 - --- validate (epoch=424)-----------
2024-04-24 01:13:55,029 - 3925 samples (32 per mini-batch)
2024-04-24 01:14:06,550 - Epoch: [424][  100/  123]    Loss 0.657063    Top1 78.687500    Top5 97.531250    
2024-04-24 01:14:08,394 - Epoch: [424][  123/  123]    Loss 0.658676    Top1 78.598726    Top5 97.605096    
2024-04-24 01:14:08,479 - ==> Top1: 78.599    Top5: 97.605    Loss: 0.659

2024-04-24 01:14:08,487 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:14:08,488 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:14:08,523 - 

2024-04-24 01:14:08,523 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:14:17,168 - Epoch: [425][  100/  296]    Overall Loss 0.648968    Objective Loss 0.648968                                        LR 0.000005    Time 0.086377    
2024-04-24 01:14:24,494 - Epoch: [425][  200/  296]    Overall Loss 0.645807    Objective Loss 0.645807                                        LR 0.000005    Time 0.079783    
2024-04-24 01:14:32,001 - Epoch: [425][  296/  296]    Overall Loss 0.658805    Objective Loss 0.658805    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.079250    
2024-04-24 01:14:32,151 - --- validate (epoch=425)-----------
2024-04-24 01:14:32,151 - 3925 samples (32 per mini-batch)
2024-04-24 01:14:43,301 - Epoch: [425][  100/  123]    Loss 0.653596    Top1 78.625000    Top5 97.500000    
2024-04-24 01:14:45,172 - Epoch: [425][  123/  123]    Loss 0.656879    Top1 78.751592    Top5 97.579618    
2024-04-24 01:14:45,284 - ==> Top1: 78.752    Top5: 97.580    Loss: 0.657

2024-04-24 01:14:45,292 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:14:45,293 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:14:45,328 - 

2024-04-24 01:14:45,328 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:14:56,060 - Epoch: [426][  100/  296]    Overall Loss 0.651749    Objective Loss 0.651749                                        LR 0.000005    Time 0.107240    
2024-04-24 01:15:04,756 - Epoch: [426][  200/  296]    Overall Loss 0.654809    Objective Loss 0.654809                                        LR 0.000005    Time 0.097065    
2024-04-24 01:15:12,029 - Epoch: [426][  296/  296]    Overall Loss 0.655493    Objective Loss 0.655493    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.090130    
2024-04-24 01:15:12,168 - --- validate (epoch=426)-----------
2024-04-24 01:15:12,168 - 3925 samples (32 per mini-batch)
2024-04-24 01:15:22,165 - Epoch: [426][  100/  123]    Loss 0.652234    Top1 79.500000    Top5 97.593750    
2024-04-24 01:15:23,792 - Epoch: [426][  123/  123]    Loss 0.660007    Top1 79.082803    Top5 97.554140    
2024-04-24 01:15:23,904 - ==> Top1: 79.083    Top5: 97.554    Loss: 0.660

2024-04-24 01:15:23,911 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:15:23,912 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:15:23,946 - 

2024-04-24 01:15:23,946 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:15:33,338 - Epoch: [427][  100/  296]    Overall Loss 0.632918    Objective Loss 0.632918                                        LR 0.000005    Time 0.093846    
2024-04-24 01:15:40,468 - Epoch: [427][  200/  296]    Overall Loss 0.643975    Objective Loss 0.643975                                        LR 0.000005    Time 0.082534    
2024-04-24 01:15:47,315 - Epoch: [427][  296/  296]    Overall Loss 0.647001    Objective Loss 0.647001    Top1 73.770492    Top5 98.360656    LR 0.000005    Time 0.078876    
2024-04-24 01:15:47,422 - --- validate (epoch=427)-----------
2024-04-24 01:15:47,423 - 3925 samples (32 per mini-batch)
2024-04-24 01:15:57,512 - Epoch: [427][  100/  123]    Loss 0.660601    Top1 78.968750    Top5 97.531250    
2024-04-24 01:15:59,238 - Epoch: [427][  123/  123]    Loss 0.660871    Top1 78.878981    Top5 97.605096    
2024-04-24 01:15:59,368 - ==> Top1: 78.879    Top5: 97.605    Loss: 0.661

2024-04-24 01:15:59,376 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:15:59,377 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:15:59,414 - 

2024-04-24 01:15:59,414 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:16:10,108 - Epoch: [428][  100/  296]    Overall Loss 0.680234    Objective Loss 0.680234                                        LR 0.000005    Time 0.106875    
2024-04-24 01:16:18,293 - Epoch: [428][  200/  296]    Overall Loss 0.677775    Objective Loss 0.677775                                        LR 0.000005    Time 0.094324    
2024-04-24 01:16:26,544 - Epoch: [428][  296/  296]    Overall Loss 0.664298    Objective Loss 0.664298    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.091584    
2024-04-24 01:16:26,649 - --- validate (epoch=428)-----------
2024-04-24 01:16:26,650 - 3925 samples (32 per mini-batch)
2024-04-24 01:16:37,799 - Epoch: [428][  100/  123]    Loss 0.670047    Top1 78.468750    Top5 97.437500    
2024-04-24 01:16:40,237 - Epoch: [428][  123/  123]    Loss 0.654933    Top1 78.980892    Top5 97.528662    
2024-04-24 01:16:40,339 - ==> Top1: 78.981    Top5: 97.529    Loss: 0.655

2024-04-24 01:16:40,347 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:16:40,347 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:16:40,387 - 

2024-04-24 01:16:40,387 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:16:49,071 - Epoch: [429][  100/  296]    Overall Loss 0.682916    Objective Loss 0.682916                                        LR 0.000005    Time 0.086763    
2024-04-24 01:16:56,669 - Epoch: [429][  200/  296]    Overall Loss 0.669990    Objective Loss 0.669990                                        LR 0.000005    Time 0.081335    
2024-04-24 01:17:03,726 - Epoch: [429][  296/  296]    Overall Loss 0.667781    Objective Loss 0.667781    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.078778    
2024-04-24 01:17:03,892 - --- validate (epoch=429)-----------
2024-04-24 01:17:03,893 - 3925 samples (32 per mini-batch)
2024-04-24 01:17:14,436 - Epoch: [429][  100/  123]    Loss 0.654791    Top1 79.156250    Top5 97.500000    
2024-04-24 01:17:16,641 - Epoch: [429][  123/  123]    Loss 0.658722    Top1 78.853503    Top5 97.426752    
2024-04-24 01:17:16,771 - ==> Top1: 78.854    Top5: 97.427    Loss: 0.659

2024-04-24 01:17:16,779 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:17:16,779 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:17:16,815 - 

2024-04-24 01:17:16,815 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:17:26,772 - Epoch: [430][  100/  296]    Overall Loss 0.671784    Objective Loss 0.671784                                        LR 0.000005    Time 0.099490    
2024-04-24 01:17:34,976 - Epoch: [430][  200/  296]    Overall Loss 0.679584    Objective Loss 0.679584                                        LR 0.000005    Time 0.090730    
2024-04-24 01:17:42,552 - Epoch: [430][  296/  296]    Overall Loss 0.668497    Objective Loss 0.668497    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.086862    
2024-04-24 01:17:42,626 - --- validate (epoch=430)-----------
2024-04-24 01:17:42,627 - 3925 samples (32 per mini-batch)
2024-04-24 01:17:52,225 - Epoch: [430][  100/  123]    Loss 0.655516    Top1 79.156250    Top5 97.437500    
2024-04-24 01:17:54,154 - Epoch: [430][  123/  123]    Loss 0.659547    Top1 78.751592    Top5 97.579618    
2024-04-24 01:17:54,284 - ==> Top1: 78.752    Top5: 97.580    Loss: 0.660

2024-04-24 01:17:54,292 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:17:54,292 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:17:54,329 - 

2024-04-24 01:17:54,329 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:18:02,042 - Epoch: [431][  100/  296]    Overall Loss 0.656348    Objective Loss 0.656348                                        LR 0.000005    Time 0.077067    
2024-04-24 01:18:10,581 - Epoch: [431][  200/  296]    Overall Loss 0.655998    Objective Loss 0.655998                                        LR 0.000005    Time 0.081206    
2024-04-24 01:18:16,658 - Epoch: [431][  296/  296]    Overall Loss 0.661999    Objective Loss 0.661999    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.075377    
2024-04-24 01:18:16,737 - --- validate (epoch=431)-----------
2024-04-24 01:18:16,737 - 3925 samples (32 per mini-batch)
2024-04-24 01:18:26,040 - Epoch: [431][  100/  123]    Loss 0.648525    Top1 79.093750    Top5 97.687500    
2024-04-24 01:18:27,929 - Epoch: [431][  123/  123]    Loss 0.658813    Top1 78.649682    Top5 97.656051    
2024-04-24 01:18:28,004 - ==> Top1: 78.650    Top5: 97.656    Loss: 0.659

2024-04-24 01:18:28,012 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:18:28,013 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:18:28,049 - 

2024-04-24 01:18:28,049 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:18:36,154 - Epoch: [432][  100/  296]    Overall Loss 0.675977    Objective Loss 0.675977                                        LR 0.000005    Time 0.080986    
2024-04-24 01:18:43,189 - Epoch: [432][  200/  296]    Overall Loss 0.659157    Objective Loss 0.659157                                        LR 0.000005    Time 0.075633    
2024-04-24 01:18:48,997 - Epoch: [432][  296/  296]    Overall Loss 0.661134    Objective Loss 0.661134    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.070704    
2024-04-24 01:18:49,077 - --- validate (epoch=432)-----------
2024-04-24 01:18:49,077 - 3925 samples (32 per mini-batch)
2024-04-24 01:18:56,478 - Epoch: [432][  100/  123]    Loss 0.662514    Top1 78.875000    Top5 97.531250    
2024-04-24 01:18:58,199 - Epoch: [432][  123/  123]    Loss 0.660139    Top1 78.904459    Top5 97.554140    
2024-04-24 01:18:58,276 - ==> Top1: 78.904    Top5: 97.554    Loss: 0.660

2024-04-24 01:18:58,282 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:18:58,282 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:18:58,307 - 

2024-04-24 01:18:58,307 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:19:06,863 - Epoch: [433][  100/  296]    Overall Loss 0.666508    Objective Loss 0.666508                                        LR 0.000005    Time 0.085489    
2024-04-24 01:19:15,636 - Epoch: [433][  200/  296]    Overall Loss 0.673505    Objective Loss 0.673505                                        LR 0.000005    Time 0.086577    
2024-04-24 01:19:23,937 - Epoch: [433][  296/  296]    Overall Loss 0.657979    Objective Loss 0.657979    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.086524    
2024-04-24 01:19:24,173 - --- validate (epoch=433)-----------
2024-04-24 01:19:24,173 - 3925 samples (32 per mini-batch)
2024-04-24 01:19:34,415 - Epoch: [433][  100/  123]    Loss 0.656305    Top1 79.218750    Top5 97.562500    
2024-04-24 01:19:36,373 - Epoch: [433][  123/  123]    Loss 0.662033    Top1 78.853503    Top5 97.605096    
2024-04-24 01:19:36,493 - ==> Top1: 78.854    Top5: 97.605    Loss: 0.662

2024-04-24 01:19:36,501 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:19:36,501 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:19:36,536 - 

2024-04-24 01:19:36,536 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:19:47,014 - Epoch: [434][  100/  296]    Overall Loss 0.661384    Objective Loss 0.661384                                        LR 0.000005    Time 0.104704    
2024-04-24 01:19:55,550 - Epoch: [434][  200/  296]    Overall Loss 0.667799    Objective Loss 0.667799                                        LR 0.000005    Time 0.094999    
2024-04-24 01:20:03,632 - Epoch: [434][  296/  296]    Overall Loss 0.661622    Objective Loss 0.661622    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.091469    
2024-04-24 01:20:03,733 - --- validate (epoch=434)-----------
2024-04-24 01:20:03,734 - 3925 samples (32 per mini-batch)
2024-04-24 01:20:13,632 - Epoch: [434][  100/  123]    Loss 0.662571    Top1 78.593750    Top5 97.375000    
2024-04-24 01:20:15,599 - Epoch: [434][  123/  123]    Loss 0.660955    Top1 78.675159    Top5 97.579618    
2024-04-24 01:20:15,724 - ==> Top1: 78.675    Top5: 97.580    Loss: 0.661

2024-04-24 01:20:15,734 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:20:15,734 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:20:15,773 - 

2024-04-24 01:20:15,773 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:20:25,767 - Epoch: [435][  100/  296]    Overall Loss 0.666271    Objective Loss 0.666271                                        LR 0.000005    Time 0.099857    
2024-04-24 01:20:33,053 - Epoch: [435][  200/  296]    Overall Loss 0.676066    Objective Loss 0.676066                                        LR 0.000005    Time 0.086326    
2024-04-24 01:20:39,439 - Epoch: [435][  296/  296]    Overall Loss 0.669129    Objective Loss 0.669129    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.079877    
2024-04-24 01:20:39,510 - --- validate (epoch=435)-----------
2024-04-24 01:20:39,511 - 3925 samples (32 per mini-batch)
2024-04-24 01:20:49,811 - Epoch: [435][  100/  123]    Loss 0.658917    Top1 78.625000    Top5 97.562500    
2024-04-24 01:20:51,741 - Epoch: [435][  123/  123]    Loss 0.659878    Top1 78.675159    Top5 97.630573    
2024-04-24 01:20:51,823 - ==> Top1: 78.675    Top5: 97.631    Loss: 0.660

2024-04-24 01:20:51,831 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:20:51,832 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:20:51,878 - 

2024-04-24 01:20:51,878 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:20:59,804 - Epoch: [436][  100/  296]    Overall Loss 0.668104    Objective Loss 0.668104                                        LR 0.000005    Time 0.079188    
2024-04-24 01:21:05,745 - Epoch: [436][  200/  296]    Overall Loss 0.665315    Objective Loss 0.665315                                        LR 0.000005    Time 0.069264    
2024-04-24 01:21:11,482 - Epoch: [436][  296/  296]    Overall Loss 0.660255    Objective Loss 0.660255    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.066161    
2024-04-24 01:21:11,559 - --- validate (epoch=436)-----------
2024-04-24 01:21:11,559 - 3925 samples (32 per mini-batch)
2024-04-24 01:21:21,240 - Epoch: [436][  100/  123]    Loss 0.652340    Top1 78.937500    Top5 97.625000    
2024-04-24 01:21:22,976 - Epoch: [436][  123/  123]    Loss 0.659105    Top1 78.904459    Top5 97.579618    
2024-04-24 01:21:23,053 - ==> Top1: 78.904    Top5: 97.580    Loss: 0.659

2024-04-24 01:21:23,060 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:21:23,061 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:21:23,111 - 

2024-04-24 01:21:23,111 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:21:31,456 - Epoch: [437][  100/  296]    Overall Loss 0.650267    Objective Loss 0.650267                                        LR 0.000005    Time 0.083379    
2024-04-24 01:21:38,557 - Epoch: [437][  200/  296]    Overall Loss 0.644686    Objective Loss 0.644686                                        LR 0.000005    Time 0.077164    
2024-04-24 01:21:45,369 - Epoch: [437][  296/  296]    Overall Loss 0.642891    Objective Loss 0.642891    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.075129    
2024-04-24 01:21:45,438 - --- validate (epoch=437)-----------
2024-04-24 01:21:45,438 - 3925 samples (32 per mini-batch)
2024-04-24 01:21:54,803 - Epoch: [437][  100/  123]    Loss 0.668452    Top1 78.187500    Top5 97.531250    
2024-04-24 01:21:56,729 - Epoch: [437][  123/  123]    Loss 0.660580    Top1 78.573248    Top5 97.554140    
2024-04-24 01:21:56,827 - ==> Top1: 78.573    Top5: 97.554    Loss: 0.661

2024-04-24 01:21:56,834 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:21:56,835 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:21:56,872 - 

2024-04-24 01:21:56,872 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:22:04,497 - Epoch: [438][  100/  296]    Overall Loss 0.642688    Objective Loss 0.642688                                        LR 0.000005    Time 0.076180    
2024-04-24 01:22:11,226 - Epoch: [438][  200/  296]    Overall Loss 0.655842    Objective Loss 0.655842                                        LR 0.000005    Time 0.071702    
2024-04-24 01:22:16,720 - Epoch: [438][  296/  296]    Overall Loss 0.658462    Objective Loss 0.658462    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.066990    
2024-04-24 01:22:16,789 - --- validate (epoch=438)-----------
2024-04-24 01:22:16,790 - 3925 samples (32 per mini-batch)
2024-04-24 01:22:26,623 - Epoch: [438][  100/  123]    Loss 0.666282    Top1 78.625000    Top5 97.468750    
2024-04-24 01:22:28,734 - Epoch: [438][  123/  123]    Loss 0.658360    Top1 78.878981    Top5 97.579618    
2024-04-24 01:22:28,826 - ==> Top1: 78.879    Top5: 97.580    Loss: 0.658

2024-04-24 01:22:28,835 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:22:28,836 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:22:28,870 - 

2024-04-24 01:22:28,870 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:22:36,551 - Epoch: [439][  100/  296]    Overall Loss 0.671456    Objective Loss 0.671456                                        LR 0.000005    Time 0.076750    
2024-04-24 01:22:43,576 - Epoch: [439][  200/  296]    Overall Loss 0.643115    Objective Loss 0.643115                                        LR 0.000005    Time 0.073475    
2024-04-24 01:22:50,121 - Epoch: [439][  296/  296]    Overall Loss 0.650180    Objective Loss 0.650180    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.071741    
2024-04-24 01:22:50,193 - --- validate (epoch=439)-----------
2024-04-24 01:22:50,194 - 3925 samples (32 per mini-batch)
2024-04-24 01:22:58,983 - Epoch: [439][  100/  123]    Loss 0.658089    Top1 78.781250    Top5 97.406250    
2024-04-24 01:23:00,647 - Epoch: [439][  123/  123]    Loss 0.656841    Top1 78.777070    Top5 97.503185    
2024-04-24 01:23:00,721 - ==> Top1: 78.777    Top5: 97.503    Loss: 0.657

2024-04-24 01:23:00,724 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:23:00,724 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:23:00,748 - 

2024-04-24 01:23:00,748 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:23:09,160 - Epoch: [440][  100/  296]    Overall Loss 0.653300    Objective Loss 0.653300                                        LR 0.000005    Time 0.084066    
2024-04-24 01:23:16,457 - Epoch: [440][  200/  296]    Overall Loss 0.660373    Objective Loss 0.660373                                        LR 0.000005    Time 0.078498    
2024-04-24 01:23:22,053 - Epoch: [440][  296/  296]    Overall Loss 0.656089    Objective Loss 0.656089    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.071927    
2024-04-24 01:23:22,173 - --- validate (epoch=440)-----------
2024-04-24 01:23:22,174 - 3925 samples (32 per mini-batch)
2024-04-24 01:23:31,538 - Epoch: [440][  100/  123]    Loss 0.649371    Top1 79.281250    Top5 97.718750    
2024-04-24 01:23:33,376 - Epoch: [440][  123/  123]    Loss 0.655224    Top1 79.006369    Top5 97.528662    
2024-04-24 01:23:33,500 - ==> Top1: 79.006    Top5: 97.529    Loss: 0.655

2024-04-24 01:23:33,508 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:23:33,508 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:23:33,542 - 

2024-04-24 01:23:33,542 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:23:42,631 - Epoch: [441][  100/  296]    Overall Loss 0.651053    Objective Loss 0.651053                                        LR 0.000005    Time 0.090825    
2024-04-24 01:23:49,660 - Epoch: [441][  200/  296]    Overall Loss 0.658251    Objective Loss 0.658251                                        LR 0.000005    Time 0.080531    
2024-04-24 01:23:55,195 - Epoch: [441][  296/  296]    Overall Loss 0.663808    Objective Loss 0.663808    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.073098    
2024-04-24 01:23:55,292 - --- validate (epoch=441)-----------
2024-04-24 01:23:55,292 - 3925 samples (32 per mini-batch)
2024-04-24 01:24:04,553 - Epoch: [441][  100/  123]    Loss 0.655886    Top1 79.312500    Top5 97.468750    
2024-04-24 01:24:06,211 - Epoch: [441][  123/  123]    Loss 0.663434    Top1 78.751592    Top5 97.503185    
2024-04-24 01:24:06,315 - ==> Top1: 78.752    Top5: 97.503    Loss: 0.663

2024-04-24 01:24:06,323 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:24:06,324 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:24:06,360 - 

2024-04-24 01:24:06,360 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:24:14,551 - Epoch: [442][  100/  296]    Overall Loss 0.664633    Objective Loss 0.664633                                        LR 0.000005    Time 0.081861    
2024-04-24 01:24:21,471 - Epoch: [442][  200/  296]    Overall Loss 0.682633    Objective Loss 0.682633                                        LR 0.000005    Time 0.075510    
2024-04-24 01:24:27,479 - Epoch: [442][  296/  296]    Overall Loss 0.674637    Objective Loss 0.674637    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.071299    
2024-04-24 01:24:27,564 - --- validate (epoch=442)-----------
2024-04-24 01:24:27,565 - 3925 samples (32 per mini-batch)
2024-04-24 01:24:36,936 - Epoch: [442][  100/  123]    Loss 0.665140    Top1 78.843750    Top5 97.625000    
2024-04-24 01:24:39,005 - Epoch: [442][  123/  123]    Loss 0.659812    Top1 78.980892    Top5 97.554140    
2024-04-24 01:24:39,143 - ==> Top1: 78.981    Top5: 97.554    Loss: 0.660

2024-04-24 01:24:39,151 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:24:39,151 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:24:39,190 - 

2024-04-24 01:24:39,191 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:24:48,420 - Epoch: [443][  100/  296]    Overall Loss 0.637111    Objective Loss 0.637111                                        LR 0.000005    Time 0.092216    
2024-04-24 01:24:55,814 - Epoch: [443][  200/  296]    Overall Loss 0.637802    Objective Loss 0.637802                                        LR 0.000005    Time 0.083047    
2024-04-24 01:25:02,233 - Epoch: [443][  296/  296]    Overall Loss 0.647080    Objective Loss 0.647080    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.077776    
2024-04-24 01:25:02,353 - --- validate (epoch=443)-----------
2024-04-24 01:25:02,354 - 3925 samples (32 per mini-batch)
2024-04-24 01:25:11,774 - Epoch: [443][  100/  123]    Loss 0.657283    Top1 78.968750    Top5 97.500000    
2024-04-24 01:25:13,644 - Epoch: [443][  123/  123]    Loss 0.658003    Top1 79.108280    Top5 97.579618    
2024-04-24 01:25:13,761 - ==> Top1: 79.108    Top5: 97.580    Loss: 0.658

2024-04-24 01:25:13,770 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:25:13,770 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:25:13,806 - 

2024-04-24 01:25:13,806 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:25:22,373 - Epoch: [444][  100/  296]    Overall Loss 0.641858    Objective Loss 0.641858                                        LR 0.000005    Time 0.085619    
2024-04-24 01:25:28,799 - Epoch: [444][  200/  296]    Overall Loss 0.658786    Objective Loss 0.658786                                        LR 0.000005    Time 0.074906    
2024-04-24 01:25:34,370 - Epoch: [444][  296/  296]    Overall Loss 0.663722    Objective Loss 0.663722    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.069418    
2024-04-24 01:25:34,444 - --- validate (epoch=444)-----------
2024-04-24 01:25:34,445 - 3925 samples (32 per mini-batch)
2024-04-24 01:25:42,841 - Epoch: [444][  100/  123]    Loss 0.651091    Top1 79.218750    Top5 97.625000    
2024-04-24 01:25:44,601 - Epoch: [444][  123/  123]    Loss 0.657513    Top1 78.853503    Top5 97.630573    
2024-04-24 01:25:44,684 - ==> Top1: 78.854    Top5: 97.631    Loss: 0.658

2024-04-24 01:25:44,688 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:25:44,688 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:25:44,715 - 

2024-04-24 01:25:44,715 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:25:52,205 - Epoch: [445][  100/  296]    Overall Loss 0.647513    Objective Loss 0.647513                                        LR 0.000005    Time 0.074834    
2024-04-24 01:25:58,979 - Epoch: [445][  200/  296]    Overall Loss 0.660878    Objective Loss 0.660878                                        LR 0.000005    Time 0.071260    
2024-04-24 01:26:05,841 - Epoch: [445][  296/  296]    Overall Loss 0.650864    Objective Loss 0.650864    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.071315    
2024-04-24 01:26:05,924 - --- validate (epoch=445)-----------
2024-04-24 01:26:05,925 - 3925 samples (32 per mini-batch)
2024-04-24 01:26:15,760 - Epoch: [445][  100/  123]    Loss 0.665609    Top1 78.843750    Top5 97.625000    
2024-04-24 01:26:17,537 - Epoch: [445][  123/  123]    Loss 0.656982    Top1 78.980892    Top5 97.630573    
2024-04-24 01:26:17,653 - ==> Top1: 78.981    Top5: 97.631    Loss: 0.657

2024-04-24 01:26:17,661 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:26:17,661 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:26:17,696 - 

2024-04-24 01:26:17,696 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:26:25,803 - Epoch: [446][  100/  296]    Overall Loss 0.642891    Objective Loss 0.642891                                        LR 0.000005    Time 0.081004    
2024-04-24 01:26:31,847 - Epoch: [446][  200/  296]    Overall Loss 0.672477    Objective Loss 0.672477                                        LR 0.000005    Time 0.070693    
2024-04-24 01:26:37,470 - Epoch: [446][  296/  296]    Overall Loss 0.658809    Objective Loss 0.658809    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.066747    
2024-04-24 01:26:37,633 - --- validate (epoch=446)-----------
2024-04-24 01:26:37,633 - 3925 samples (32 per mini-batch)
2024-04-24 01:26:47,669 - Epoch: [446][  100/  123]    Loss 0.653534    Top1 78.968750    Top5 97.625000    
2024-04-24 01:26:49,207 - Epoch: [446][  123/  123]    Loss 0.658814    Top1 78.955414    Top5 97.554140    
2024-04-24 01:26:49,306 - ==> Top1: 78.955    Top5: 97.554    Loss: 0.659

2024-04-24 01:26:49,314 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:26:49,314 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:26:49,351 - 

2024-04-24 01:26:49,351 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:26:58,814 - Epoch: [447][  100/  296]    Overall Loss 0.652148    Objective Loss 0.652148                                        LR 0.000005    Time 0.094576    
2024-04-24 01:27:06,589 - Epoch: [447][  200/  296]    Overall Loss 0.658395    Objective Loss 0.658395                                        LR 0.000005    Time 0.086140    
2024-04-24 01:27:12,861 - Epoch: [447][  296/  296]    Overall Loss 0.655821    Objective Loss 0.655821    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.079376    
2024-04-24 01:27:12,968 - --- validate (epoch=447)-----------
2024-04-24 01:27:12,968 - 3925 samples (32 per mini-batch)
2024-04-24 01:27:22,346 - Epoch: [447][  100/  123]    Loss 0.660419    Top1 78.968750    Top5 97.625000    
2024-04-24 01:27:24,154 - Epoch: [447][  123/  123]    Loss 0.660668    Top1 78.980892    Top5 97.477707    
2024-04-24 01:27:24,283 - ==> Top1: 78.981    Top5: 97.478    Loss: 0.661

2024-04-24 01:27:24,292 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:27:24,292 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:27:24,327 - 

2024-04-24 01:27:24,327 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:27:31,969 - Epoch: [448][  100/  296]    Overall Loss 0.648260    Objective Loss 0.648260                                        LR 0.000005    Time 0.076358    
2024-04-24 01:27:38,451 - Epoch: [448][  200/  296]    Overall Loss 0.636871    Objective Loss 0.636871                                        LR 0.000005    Time 0.070566    
2024-04-24 01:27:44,028 - Epoch: [448][  296/  296]    Overall Loss 0.648505    Objective Loss 0.648505    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.066503    
2024-04-24 01:27:44,105 - --- validate (epoch=448)-----------
2024-04-24 01:27:44,106 - 3925 samples (32 per mini-batch)
2024-04-24 01:27:53,101 - Epoch: [448][  100/  123]    Loss 0.655369    Top1 78.812500    Top5 97.656250    
2024-04-24 01:27:55,018 - Epoch: [448][  123/  123]    Loss 0.654998    Top1 78.904459    Top5 97.656051    
2024-04-24 01:27:55,138 - ==> Top1: 78.904    Top5: 97.656    Loss: 0.655

2024-04-24 01:27:55,146 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:27:55,146 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:27:55,181 - 

2024-04-24 01:27:55,181 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:28:03,112 - Epoch: [449][  100/  296]    Overall Loss 0.650432    Objective Loss 0.650432                                        LR 0.000005    Time 0.079250    
2024-04-24 01:28:09,693 - Epoch: [449][  200/  296]    Overall Loss 0.662997    Objective Loss 0.662997                                        LR 0.000005    Time 0.072499    
2024-04-24 01:28:15,722 - Epoch: [449][  296/  296]    Overall Loss 0.657368    Objective Loss 0.657368    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.069339    
2024-04-24 01:28:15,797 - --- validate (epoch=449)-----------
2024-04-24 01:28:15,798 - 3925 samples (32 per mini-batch)
2024-04-24 01:28:25,556 - Epoch: [449][  100/  123]    Loss 0.658076    Top1 78.625000    Top5 97.718750    
2024-04-24 01:28:27,024 - Epoch: [449][  123/  123]    Loss 0.659932    Top1 78.649682    Top5 97.528662    
2024-04-24 01:28:27,169 - ==> Top1: 78.650    Top5: 97.529    Loss: 0.660

2024-04-24 01:28:27,177 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:28:27,178 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:28:27,212 - 

2024-04-24 01:28:27,212 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:28:36,674 - Epoch: [450][  100/  296]    Overall Loss 0.652158    Objective Loss 0.652158                                        LR 0.000005    Time 0.094553    
2024-04-24 01:28:43,601 - Epoch: [450][  200/  296]    Overall Loss 0.659480    Objective Loss 0.659480                                        LR 0.000005    Time 0.081887    
2024-04-24 01:28:50,476 - Epoch: [450][  296/  296]    Overall Loss 0.669456    Objective Loss 0.669456    Top1 72.131148    Top5 100.000000    LR 0.000005    Time 0.078541    
2024-04-24 01:28:50,615 - --- validate (epoch=450)-----------
2024-04-24 01:28:50,615 - 3925 samples (32 per mini-batch)
2024-04-24 01:28:59,801 - Epoch: [450][  100/  123]    Loss 0.660147    Top1 78.812500    Top5 97.500000    
2024-04-24 01:29:01,811 - Epoch: [450][  123/  123]    Loss 0.656572    Top1 78.828025    Top5 97.554140    
2024-04-24 01:29:01,924 - ==> Top1: 78.828    Top5: 97.554    Loss: 0.657

2024-04-24 01:29:01,932 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:29:01,933 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:29:01,979 - 

2024-04-24 01:29:01,979 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:29:09,862 - Epoch: [451][  100/  296]    Overall Loss 0.668782    Objective Loss 0.668782                                        LR 0.000005    Time 0.078770    
2024-04-24 01:29:15,764 - Epoch: [451][  200/  296]    Overall Loss 0.672340    Objective Loss 0.672340                                        LR 0.000005    Time 0.068871    
2024-04-24 01:29:22,012 - Epoch: [451][  296/  296]    Overall Loss 0.674582    Objective Loss 0.674582    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.067628    
2024-04-24 01:29:22,136 - --- validate (epoch=451)-----------
2024-04-24 01:29:22,137 - 3925 samples (32 per mini-batch)
2024-04-24 01:29:30,315 - Epoch: [451][  100/  123]    Loss 0.659322    Top1 78.718750    Top5 97.656250    
2024-04-24 01:29:32,326 - Epoch: [451][  123/  123]    Loss 0.658478    Top1 78.675159    Top5 97.656051    
2024-04-24 01:29:32,444 - ==> Top1: 78.675    Top5: 97.656    Loss: 0.658

2024-04-24 01:29:32,448 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:29:32,448 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:29:32,473 - 

2024-04-24 01:29:32,473 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:29:42,408 - Epoch: [452][  100/  296]    Overall Loss 0.663943    Objective Loss 0.663943                                        LR 0.000005    Time 0.099294    
2024-04-24 01:29:50,818 - Epoch: [452][  200/  296]    Overall Loss 0.669496    Objective Loss 0.669496                                        LR 0.000005    Time 0.091668    
2024-04-24 01:29:58,380 - Epoch: [452][  296/  296]    Overall Loss 0.665687    Objective Loss 0.665687    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.087470    
2024-04-24 01:29:58,506 - --- validate (epoch=452)-----------
2024-04-24 01:29:58,506 - 3925 samples (32 per mini-batch)
2024-04-24 01:30:07,859 - Epoch: [452][  100/  123]    Loss 0.684999    Top1 77.843750    Top5 97.437500    
2024-04-24 01:30:09,386 - Epoch: [452][  123/  123]    Loss 0.661798    Top1 78.624204    Top5 97.605096    
2024-04-24 01:30:09,491 - ==> Top1: 78.624    Top5: 97.605    Loss: 0.662

2024-04-24 01:30:09,494 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:30:09,494 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:30:09,529 - 

2024-04-24 01:30:09,529 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:30:17,081 - Epoch: [453][  100/  296]    Overall Loss 0.639295    Objective Loss 0.639295                                        LR 0.000005    Time 0.075463    
2024-04-24 01:30:23,738 - Epoch: [453][  200/  296]    Overall Loss 0.656939    Objective Loss 0.656939                                        LR 0.000005    Time 0.070981    
2024-04-24 01:30:30,030 - Epoch: [453][  296/  296]    Overall Loss 0.656451    Objective Loss 0.656451    Top1 67.213115    Top5 98.360656    LR 0.000005    Time 0.069198    
2024-04-24 01:30:30,167 - --- validate (epoch=453)-----------
2024-04-24 01:30:30,168 - 3925 samples (32 per mini-batch)
2024-04-24 01:30:39,197 - Epoch: [453][  100/  123]    Loss 0.651747    Top1 79.000000    Top5 97.437500    
2024-04-24 01:30:41,234 - Epoch: [453][  123/  123]    Loss 0.658911    Top1 78.726115    Top5 97.452229    
2024-04-24 01:30:41,368 - ==> Top1: 78.726    Top5: 97.452    Loss: 0.659

2024-04-24 01:30:41,375 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:30:41,376 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:30:41,410 - 

2024-04-24 01:30:41,411 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:30:49,203 - Epoch: [454][  100/  296]    Overall Loss 0.658581    Objective Loss 0.658581                                        LR 0.000005    Time 0.077861    
2024-04-24 01:30:55,234 - Epoch: [454][  200/  296]    Overall Loss 0.657950    Objective Loss 0.657950                                        LR 0.000005    Time 0.069062    
2024-04-24 01:31:00,906 - Epoch: [454][  296/  296]    Overall Loss 0.657100    Objective Loss 0.657100    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.065808    
2024-04-24 01:31:01,024 - --- validate (epoch=454)-----------
2024-04-24 01:31:01,024 - 3925 samples (32 per mini-batch)
2024-04-24 01:31:09,662 - Epoch: [454][  100/  123]    Loss 0.664444    Top1 78.750000    Top5 97.437500    
2024-04-24 01:31:11,641 - Epoch: [454][  123/  123]    Loss 0.657880    Top1 78.904459    Top5 97.579618    
2024-04-24 01:31:11,750 - ==> Top1: 78.904    Top5: 97.580    Loss: 0.658

2024-04-24 01:31:11,760 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:31:11,760 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:31:11,796 - 

2024-04-24 01:31:11,796 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:31:19,961 - Epoch: [455][  100/  296]    Overall Loss 0.657208    Objective Loss 0.657208                                        LR 0.000005    Time 0.081594    
2024-04-24 01:31:26,065 - Epoch: [455][  200/  296]    Overall Loss 0.640559    Objective Loss 0.640559                                        LR 0.000005    Time 0.071289    
2024-04-24 01:31:31,373 - Epoch: [455][  296/  296]    Overall Loss 0.645919    Objective Loss 0.645919    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.066085    
2024-04-24 01:31:31,459 - --- validate (epoch=455)-----------
2024-04-24 01:31:31,460 - 3925 samples (32 per mini-batch)
2024-04-24 01:31:40,081 - Epoch: [455][  100/  123]    Loss 0.649102    Top1 78.875000    Top5 97.812500    
2024-04-24 01:31:41,637 - Epoch: [455][  123/  123]    Loss 0.654349    Top1 78.802548    Top5 97.732484    
2024-04-24 01:31:41,717 - ==> Top1: 78.803    Top5: 97.732    Loss: 0.654

2024-04-24 01:31:41,724 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:31:41,725 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:31:41,760 - 

2024-04-24 01:31:41,760 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:31:49,083 - Epoch: [456][  100/  296]    Overall Loss 0.663905    Objective Loss 0.663905                                        LR 0.000005    Time 0.073165    
2024-04-24 01:31:55,123 - Epoch: [456][  200/  296]    Overall Loss 0.666941    Objective Loss 0.666941                                        LR 0.000005    Time 0.066760    
2024-04-24 01:32:00,826 - Epoch: [456][  296/  296]    Overall Loss 0.668121    Objective Loss 0.668121    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.064360    
2024-04-24 01:32:00,950 - --- validate (epoch=456)-----------
2024-04-24 01:32:00,951 - 3925 samples (32 per mini-batch)
2024-04-24 01:32:08,682 - Epoch: [456][  100/  123]    Loss 0.641762    Top1 79.250000    Top5 97.937500    
2024-04-24 01:32:10,234 - Epoch: [456][  123/  123]    Loss 0.653908    Top1 78.802548    Top5 97.656051    
2024-04-24 01:32:10,349 - ==> Top1: 78.803    Top5: 97.656    Loss: 0.654

2024-04-24 01:32:10,357 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:32:10,358 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:32:10,394 - 

2024-04-24 01:32:10,394 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:32:18,723 - Epoch: [457][  100/  296]    Overall Loss 0.653745    Objective Loss 0.653745                                        LR 0.000005    Time 0.083228    
2024-04-24 01:32:26,334 - Epoch: [457][  200/  296]    Overall Loss 0.656154    Objective Loss 0.656154                                        LR 0.000005    Time 0.079643    
2024-04-24 01:32:32,444 - Epoch: [457][  296/  296]    Overall Loss 0.658998    Objective Loss 0.658998    Top1 72.131148    Top5 100.000000    LR 0.000005    Time 0.074437    
2024-04-24 01:32:32,524 - --- validate (epoch=457)-----------
2024-04-24 01:32:32,525 - 3925 samples (32 per mini-batch)
2024-04-24 01:32:40,985 - Epoch: [457][  100/  123]    Loss 0.671189    Top1 78.125000    Top5 97.562500    
2024-04-24 01:32:42,616 - Epoch: [457][  123/  123]    Loss 0.663440    Top1 78.343949    Top5 97.605096    
2024-04-24 01:32:42,749 - ==> Top1: 78.344    Top5: 97.605    Loss: 0.663

2024-04-24 01:32:42,757 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:32:42,757 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:32:42,793 - 

2024-04-24 01:32:42,793 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:32:50,430 - Epoch: [458][  100/  296]    Overall Loss 0.685844    Objective Loss 0.685844                                        LR 0.000005    Time 0.076306    
2024-04-24 01:32:56,713 - Epoch: [458][  200/  296]    Overall Loss 0.667922    Objective Loss 0.667922                                        LR 0.000005    Time 0.069541    
2024-04-24 01:33:02,243 - Epoch: [458][  296/  296]    Overall Loss 0.665516    Objective Loss 0.665516    Top1 86.885246    Top5 100.000000    LR 0.000005    Time 0.065654    
2024-04-24 01:33:02,357 - --- validate (epoch=458)-----------
2024-04-24 01:33:02,357 - 3925 samples (32 per mini-batch)
2024-04-24 01:33:11,109 - Epoch: [458][  100/  123]    Loss 0.657181    Top1 79.281250    Top5 97.562500    
2024-04-24 01:33:12,630 - Epoch: [458][  123/  123]    Loss 0.659012    Top1 78.828025    Top5 97.528662    
2024-04-24 01:33:12,751 - ==> Top1: 78.828    Top5: 97.529    Loss: 0.659

2024-04-24 01:33:12,758 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:33:12,759 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:33:12,794 - 

2024-04-24 01:33:12,794 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:33:20,296 - Epoch: [459][  100/  296]    Overall Loss 0.660201    Objective Loss 0.660201                                        LR 0.000005    Time 0.074960    
2024-04-24 01:33:26,884 - Epoch: [459][  200/  296]    Overall Loss 0.658538    Objective Loss 0.658538                                        LR 0.000005    Time 0.070396    
2024-04-24 01:33:34,531 - Epoch: [459][  296/  296]    Overall Loss 0.661639    Objective Loss 0.661639    Top1 85.245902    Top5 96.721311    LR 0.000005    Time 0.073379    
2024-04-24 01:33:34,637 - --- validate (epoch=459)-----------
2024-04-24 01:33:34,638 - 3925 samples (32 per mini-batch)
2024-04-24 01:33:43,274 - Epoch: [459][  100/  123]    Loss 0.659582    Top1 78.843750    Top5 97.750000    
2024-04-24 01:33:45,083 - Epoch: [459][  123/  123]    Loss 0.654960    Top1 79.031847    Top5 97.630573    
2024-04-24 01:33:45,166 - ==> Top1: 79.032    Top5: 97.631    Loss: 0.655

2024-04-24 01:33:45,174 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:33:45,175 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:33:45,209 - 

2024-04-24 01:33:45,209 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:33:52,751 - Epoch: [460][  100/  296]    Overall Loss 0.647954    Objective Loss 0.647954                                        LR 0.000005    Time 0.075350    
2024-04-24 01:33:59,423 - Epoch: [460][  200/  296]    Overall Loss 0.658450    Objective Loss 0.658450                                        LR 0.000005    Time 0.071012    
2024-04-24 01:34:05,913 - Epoch: [460][  296/  296]    Overall Loss 0.641837    Objective Loss 0.641837    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.069887    
2024-04-24 01:34:06,012 - --- validate (epoch=460)-----------
2024-04-24 01:34:06,013 - 3925 samples (32 per mini-batch)
2024-04-24 01:34:14,796 - Epoch: [460][  100/  123]    Loss 0.656959    Top1 78.781250    Top5 97.562500    
2024-04-24 01:34:16,351 - Epoch: [460][  123/  123]    Loss 0.656835    Top1 78.777070    Top5 97.605096    
2024-04-24 01:34:16,479 - ==> Top1: 78.777    Top5: 97.605    Loss: 0.657

2024-04-24 01:34:16,486 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:34:16,487 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:34:16,521 - 

2024-04-24 01:34:16,521 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:34:25,302 - Epoch: [461][  100/  296]    Overall Loss 0.665944    Objective Loss 0.665944                                        LR 0.000005    Time 0.087756    
2024-04-24 01:34:33,042 - Epoch: [461][  200/  296]    Overall Loss 0.656433    Objective Loss 0.656433                                        LR 0.000005    Time 0.082559    
2024-04-24 01:34:39,397 - Epoch: [461][  296/  296]    Overall Loss 0.663564    Objective Loss 0.663564    Top1 90.163934    Top5 100.000000    LR 0.000005    Time 0.077235    
2024-04-24 01:34:39,486 - --- validate (epoch=461)-----------
2024-04-24 01:34:39,487 - 3925 samples (32 per mini-batch)
2024-04-24 01:34:47,559 - Epoch: [461][  100/  123]    Loss 0.668630    Top1 78.375000    Top5 97.406250    
2024-04-24 01:34:49,174 - Epoch: [461][  123/  123]    Loss 0.656280    Top1 78.700637    Top5 97.579618    
2024-04-24 01:34:49,281 - ==> Top1: 78.701    Top5: 97.580    Loss: 0.656

2024-04-24 01:34:49,288 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:34:49,289 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:34:49,323 - 

2024-04-24 01:34:49,323 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:34:57,172 - Epoch: [462][  100/  296]    Overall Loss 0.663801    Objective Loss 0.663801                                        LR 0.000005    Time 0.078426    
2024-04-24 01:35:04,432 - Epoch: [462][  200/  296]    Overall Loss 0.659710    Objective Loss 0.659710                                        LR 0.000005    Time 0.075481    
2024-04-24 01:35:11,613 - Epoch: [462][  296/  296]    Overall Loss 0.656779    Objective Loss 0.656779    Top1 78.688525    Top5 93.442623    LR 0.000005    Time 0.075239    
2024-04-24 01:35:11,747 - --- validate (epoch=462)-----------
2024-04-24 01:35:11,747 - 3925 samples (32 per mini-batch)
2024-04-24 01:35:22,153 - Epoch: [462][  100/  123]    Loss 0.656863    Top1 78.843750    Top5 97.437500    
2024-04-24 01:35:23,964 - Epoch: [462][  123/  123]    Loss 0.660457    Top1 78.649682    Top5 97.426752    
2024-04-24 01:35:24,085 - ==> Top1: 78.650    Top5: 97.427    Loss: 0.660

2024-04-24 01:35:24,093 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:35:24,093 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:35:24,126 - 

2024-04-24 01:35:24,127 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:35:32,523 - Epoch: [463][  100/  296]    Overall Loss 0.670001    Objective Loss 0.670001                                        LR 0.000005    Time 0.083898    
2024-04-24 01:35:40,355 - Epoch: [463][  200/  296]    Overall Loss 0.663514    Objective Loss 0.663514                                        LR 0.000005    Time 0.081080    
2024-04-24 01:35:47,010 - Epoch: [463][  296/  296]    Overall Loss 0.661715    Objective Loss 0.661715    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.077249    
2024-04-24 01:35:47,150 - --- validate (epoch=463)-----------
2024-04-24 01:35:47,150 - 3925 samples (32 per mini-batch)
2024-04-24 01:35:57,024 - Epoch: [463][  100/  123]    Loss 0.676866    Top1 78.562500    Top5 97.281250    
2024-04-24 01:35:58,898 - Epoch: [463][  123/  123]    Loss 0.656727    Top1 78.955414    Top5 97.477707    
2024-04-24 01:35:59,016 - ==> Top1: 78.955    Top5: 97.478    Loss: 0.657

2024-04-24 01:35:59,024 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:35:59,025 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:35:59,059 - 

2024-04-24 01:35:59,059 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:36:06,844 - Epoch: [464][  100/  296]    Overall Loss 0.677991    Objective Loss 0.677991                                        LR 0.000005    Time 0.077782    
2024-04-24 01:36:13,628 - Epoch: [464][  200/  296]    Overall Loss 0.664226    Objective Loss 0.664226                                        LR 0.000005    Time 0.072786    
2024-04-24 01:36:19,501 - Epoch: [464][  296/  296]    Overall Loss 0.657803    Objective Loss 0.657803    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.069005    
2024-04-24 01:36:19,606 - --- validate (epoch=464)-----------
2024-04-24 01:36:19,607 - 3925 samples (32 per mini-batch)
2024-04-24 01:36:29,049 - Epoch: [464][  100/  123]    Loss 0.657964    Top1 78.718750    Top5 97.468750    
2024-04-24 01:36:30,535 - Epoch: [464][  123/  123]    Loss 0.660951    Top1 78.802548    Top5 97.528662    
2024-04-24 01:36:30,658 - ==> Top1: 78.803    Top5: 97.529    Loss: 0.661

2024-04-24 01:36:30,666 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:36:30,666 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:36:30,700 - 

2024-04-24 01:36:30,700 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:36:38,272 - Epoch: [465][  100/  296]    Overall Loss 0.671180    Objective Loss 0.671180                                        LR 0.000005    Time 0.075656    
2024-04-24 01:36:44,765 - Epoch: [465][  200/  296]    Overall Loss 0.662628    Objective Loss 0.662628                                        LR 0.000005    Time 0.070260    
2024-04-24 01:36:51,494 - Epoch: [465][  296/  296]    Overall Loss 0.664776    Objective Loss 0.664776    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.070186    
2024-04-24 01:36:51,594 - --- validate (epoch=465)-----------
2024-04-24 01:36:51,595 - 3925 samples (32 per mini-batch)
2024-04-24 01:37:03,554 - Epoch: [465][  100/  123]    Loss 0.651581    Top1 79.062500    Top5 97.687500    
2024-04-24 01:37:06,063 - Epoch: [465][  123/  123]    Loss 0.657155    Top1 78.853503    Top5 97.477707    
2024-04-24 01:37:06,191 - ==> Top1: 78.854    Top5: 97.478    Loss: 0.657

2024-04-24 01:37:06,198 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:37:06,199 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:37:06,234 - 

2024-04-24 01:37:06,235 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:37:16,669 - Epoch: [466][  100/  296]    Overall Loss 0.696481    Objective Loss 0.696481                                        LR 0.000005    Time 0.104256    
2024-04-24 01:37:24,040 - Epoch: [466][  200/  296]    Overall Loss 0.669850    Objective Loss 0.669850                                        LR 0.000005    Time 0.088953    
2024-04-24 01:37:29,862 - Epoch: [466][  296/  296]    Overall Loss 0.665393    Objective Loss 0.665393    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.079753    
2024-04-24 01:37:30,010 - --- validate (epoch=466)-----------
2024-04-24 01:37:30,011 - 3925 samples (32 per mini-batch)
2024-04-24 01:37:38,639 - Epoch: [466][  100/  123]    Loss 0.665068    Top1 79.000000    Top5 97.531250    
2024-04-24 01:37:40,448 - Epoch: [466][  123/  123]    Loss 0.657107    Top1 79.031847    Top5 97.579618    
2024-04-24 01:37:40,527 - ==> Top1: 79.032    Top5: 97.580    Loss: 0.657

2024-04-24 01:37:40,535 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:37:40,535 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:37:40,570 - 

2024-04-24 01:37:40,570 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:37:49,225 - Epoch: [467][  100/  296]    Overall Loss 0.672795    Objective Loss 0.672795                                        LR 0.000005    Time 0.086512    
2024-04-24 01:37:56,516 - Epoch: [467][  200/  296]    Overall Loss 0.659444    Objective Loss 0.659444                                        LR 0.000005    Time 0.079681    
2024-04-24 01:38:02,990 - Epoch: [467][  296/  296]    Overall Loss 0.653420    Objective Loss 0.653420    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.075689    
2024-04-24 01:38:03,140 - --- validate (epoch=467)-----------
2024-04-24 01:38:03,141 - 3925 samples (32 per mini-batch)
2024-04-24 01:38:11,824 - Epoch: [467][  100/  123]    Loss 0.662197    Top1 78.562500    Top5 97.687500    
2024-04-24 01:38:13,194 - Epoch: [467][  123/  123]    Loss 0.656974    Top1 78.751592    Top5 97.630573    
2024-04-24 01:38:13,287 - ==> Top1: 78.752    Top5: 97.631    Loss: 0.657

2024-04-24 01:38:13,296 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:38:13,296 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:38:13,331 - 

2024-04-24 01:38:13,331 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:38:20,450 - Epoch: [468][  100/  296]    Overall Loss 0.665932    Objective Loss 0.665932                                        LR 0.000005    Time 0.071131    
2024-04-24 01:38:26,848 - Epoch: [468][  200/  296]    Overall Loss 0.665800    Objective Loss 0.665800                                        LR 0.000005    Time 0.067532    
2024-04-24 01:38:33,023 - Epoch: [468][  296/  296]    Overall Loss 0.662395    Objective Loss 0.662395    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.066476    
2024-04-24 01:38:33,122 - --- validate (epoch=468)-----------
2024-04-24 01:38:33,123 - 3925 samples (32 per mini-batch)
2024-04-24 01:38:41,630 - Epoch: [468][  100/  123]    Loss 0.653037    Top1 78.875000    Top5 97.656250    
2024-04-24 01:38:42,986 - Epoch: [468][  123/  123]    Loss 0.653850    Top1 79.031847    Top5 97.579618    
2024-04-24 01:38:43,100 - ==> Top1: 79.032    Top5: 97.580    Loss: 0.654

2024-04-24 01:38:43,109 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:38:43,109 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:38:43,146 - 

2024-04-24 01:38:43,147 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:38:51,762 - Epoch: [469][  100/  296]    Overall Loss 0.630309    Objective Loss 0.630309                                        LR 0.000005    Time 0.086093    
2024-04-24 01:38:58,074 - Epoch: [469][  200/  296]    Overall Loss 0.648644    Objective Loss 0.648644                                        LR 0.000005    Time 0.074576    
2024-04-24 01:39:03,921 - Epoch: [469][  296/  296]    Overall Loss 0.659597    Objective Loss 0.659597    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.070127    
2024-04-24 01:39:04,009 - --- validate (epoch=469)-----------
2024-04-24 01:39:04,010 - 3925 samples (32 per mini-batch)
2024-04-24 01:39:13,314 - Epoch: [469][  100/  123]    Loss 0.661139    Top1 78.593750    Top5 97.531250    
2024-04-24 01:39:14,990 - Epoch: [469][  123/  123]    Loss 0.654546    Top1 78.751592    Top5 97.528662    
2024-04-24 01:39:15,122 - ==> Top1: 78.752    Top5: 97.529    Loss: 0.655

2024-04-24 01:39:15,130 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:39:15,131 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:39:15,166 - 

2024-04-24 01:39:15,166 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:39:25,464 - Epoch: [470][  100/  296]    Overall Loss 0.652449    Objective Loss 0.652449                                        LR 0.000005    Time 0.102934    
2024-04-24 01:39:33,611 - Epoch: [470][  200/  296]    Overall Loss 0.642807    Objective Loss 0.642807                                        LR 0.000005    Time 0.092177    
2024-04-24 01:39:39,772 - Epoch: [470][  296/  296]    Overall Loss 0.642742    Objective Loss 0.642742    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.083081    
2024-04-24 01:39:39,880 - --- validate (epoch=470)-----------
2024-04-24 01:39:39,880 - 3925 samples (32 per mini-batch)
2024-04-24 01:39:49,173 - Epoch: [470][  100/  123]    Loss 0.654334    Top1 79.500000    Top5 97.656250    
2024-04-24 01:39:51,035 - Epoch: [470][  123/  123]    Loss 0.656659    Top1 79.133758    Top5 97.656051    
2024-04-24 01:39:51,150 - ==> Top1: 79.134    Top5: 97.656    Loss: 0.657

2024-04-24 01:39:51,159 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:39:51,160 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:39:51,193 - 

2024-04-24 01:39:51,193 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:40:00,217 - Epoch: [471][  100/  296]    Overall Loss 0.628491    Objective Loss 0.628491                                        LR 0.000005    Time 0.090188    
2024-04-24 01:40:07,366 - Epoch: [471][  200/  296]    Overall Loss 0.634843    Objective Loss 0.634843                                        LR 0.000005    Time 0.080823    
2024-04-24 01:40:13,320 - Epoch: [471][  296/  296]    Overall Loss 0.639793    Objective Loss 0.639793    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.074706    
2024-04-24 01:40:13,469 - --- validate (epoch=471)-----------
2024-04-24 01:40:13,470 - 3925 samples (32 per mini-batch)
2024-04-24 01:40:22,343 - Epoch: [471][  100/  123]    Loss 0.650669    Top1 79.093750    Top5 97.531250    
2024-04-24 01:40:24,302 - Epoch: [471][  123/  123]    Loss 0.657109    Top1 78.878981    Top5 97.554140    
2024-04-24 01:40:24,389 - ==> Top1: 78.879    Top5: 97.554    Loss: 0.657

2024-04-24 01:40:24,398 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:40:24,398 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:40:24,434 - 

2024-04-24 01:40:24,434 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:40:31,252 - Epoch: [472][  100/  296]    Overall Loss 0.637847    Objective Loss 0.637847                                        LR 0.000005    Time 0.068117    
2024-04-24 01:40:36,828 - Epoch: [472][  200/  296]    Overall Loss 0.657338    Objective Loss 0.657338                                        LR 0.000005    Time 0.061911    
2024-04-24 01:40:42,356 - Epoch: [472][  296/  296]    Overall Loss 0.655999    Objective Loss 0.655999    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.060491    
2024-04-24 01:40:42,443 - --- validate (epoch=472)-----------
2024-04-24 01:40:42,443 - 3925 samples (32 per mini-batch)
2024-04-24 01:40:51,707 - Epoch: [472][  100/  123]    Loss 0.648516    Top1 79.375000    Top5 97.781250    
2024-04-24 01:40:53,455 - Epoch: [472][  123/  123]    Loss 0.656156    Top1 79.108280    Top5 97.656051    
2024-04-24 01:40:53,568 - ==> Top1: 79.108    Top5: 97.656    Loss: 0.656

2024-04-24 01:40:53,577 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:40:53,577 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:40:53,611 - 

2024-04-24 01:40:53,611 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:41:01,816 - Epoch: [473][  100/  296]    Overall Loss 0.639485    Objective Loss 0.639485                                        LR 0.000005    Time 0.081980    
2024-04-24 01:41:08,336 - Epoch: [473][  200/  296]    Overall Loss 0.647295    Objective Loss 0.647295                                        LR 0.000005    Time 0.073562    
2024-04-24 01:41:14,233 - Epoch: [473][  296/  296]    Overall Loss 0.649445    Objective Loss 0.649445    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.069609    
2024-04-24 01:41:14,417 - --- validate (epoch=473)-----------
2024-04-24 01:41:14,418 - 3925 samples (32 per mini-batch)
2024-04-24 01:41:23,273 - Epoch: [473][  100/  123]    Loss 0.665825    Top1 78.718750    Top5 97.375000    
2024-04-24 01:41:25,450 - Epoch: [473][  123/  123]    Loss 0.662103    Top1 78.700637    Top5 97.477707    
2024-04-24 01:41:25,592 - ==> Top1: 78.701    Top5: 97.478    Loss: 0.662

2024-04-24 01:41:25,600 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:41:25,600 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:41:25,635 - 

2024-04-24 01:41:25,635 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:41:33,438 - Epoch: [474][  100/  296]    Overall Loss 0.684373    Objective Loss 0.684373                                        LR 0.000005    Time 0.077968    
2024-04-24 01:41:40,318 - Epoch: [474][  200/  296]    Overall Loss 0.680053    Objective Loss 0.680053                                        LR 0.000005    Time 0.073357    
2024-04-24 01:41:46,007 - Epoch: [474][  296/  296]    Overall Loss 0.672331    Objective Loss 0.672331    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.068766    
2024-04-24 01:41:46,089 - --- validate (epoch=474)-----------
2024-04-24 01:41:46,090 - 3925 samples (32 per mini-batch)
2024-04-24 01:41:54,769 - Epoch: [474][  100/  123]    Loss 0.650886    Top1 78.812500    Top5 97.625000    
2024-04-24 01:41:56,992 - Epoch: [474][  123/  123]    Loss 0.654534    Top1 78.828025    Top5 97.579618    
2024-04-24 01:41:57,129 - ==> Top1: 78.828    Top5: 97.580    Loss: 0.655

2024-04-24 01:41:57,137 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:41:57,138 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:41:57,172 - 

2024-04-24 01:41:57,172 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:42:04,870 - Epoch: [475][  100/  296]    Overall Loss 0.680307    Objective Loss 0.680307                                        LR 0.000005    Time 0.076919    
2024-04-24 01:42:10,925 - Epoch: [475][  200/  296]    Overall Loss 0.670651    Objective Loss 0.670651                                        LR 0.000005    Time 0.068703    
2024-04-24 01:42:16,837 - Epoch: [475][  296/  296]    Overall Loss 0.670820    Objective Loss 0.670820    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.066376    
2024-04-24 01:42:16,964 - --- validate (epoch=475)-----------
2024-04-24 01:42:16,964 - 3925 samples (32 per mini-batch)
2024-04-24 01:42:26,365 - Epoch: [475][  100/  123]    Loss 0.648998    Top1 79.093750    Top5 97.625000    
2024-04-24 01:42:28,106 - Epoch: [475][  123/  123]    Loss 0.658777    Top1 78.853503    Top5 97.503185    
2024-04-24 01:42:28,230 - ==> Top1: 78.854    Top5: 97.503    Loss: 0.659

2024-04-24 01:42:28,240 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:42:28,240 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:42:28,277 - 

2024-04-24 01:42:28,277 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:42:38,043 - Epoch: [476][  100/  296]    Overall Loss 0.658176    Objective Loss 0.658176                                        LR 0.000005    Time 0.097598    
2024-04-24 01:42:45,726 - Epoch: [476][  200/  296]    Overall Loss 0.668907    Objective Loss 0.668907                                        LR 0.000005    Time 0.087186    
2024-04-24 01:42:51,856 - Epoch: [476][  296/  296]    Overall Loss 0.666163    Objective Loss 0.666163    Top1 88.524590    Top5 100.000000    LR 0.000005    Time 0.079604    
2024-04-24 01:42:51,962 - --- validate (epoch=476)-----------
2024-04-24 01:42:51,962 - 3925 samples (32 per mini-batch)
2024-04-24 01:43:01,315 - Epoch: [476][  100/  123]    Loss 0.650447    Top1 79.062500    Top5 97.531250    
2024-04-24 01:43:03,327 - Epoch: [476][  123/  123]    Loss 0.657882    Top1 78.904459    Top5 97.528662    
2024-04-24 01:43:03,439 - ==> Top1: 78.904    Top5: 97.529    Loss: 0.658

2024-04-24 01:43:03,448 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:43:03,449 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:43:03,484 - 

2024-04-24 01:43:03,484 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:43:12,038 - Epoch: [477][  100/  296]    Overall Loss 0.658282    Objective Loss 0.658282                                        LR 0.000005    Time 0.085485    
2024-04-24 01:43:19,345 - Epoch: [477][  200/  296]    Overall Loss 0.665968    Objective Loss 0.665968                                        LR 0.000005    Time 0.079254    
2024-04-24 01:43:26,224 - Epoch: [477][  296/  296]    Overall Loss 0.657049    Objective Loss 0.657049    Top1 88.524590    Top5 98.360656    LR 0.000005    Time 0.076776    
2024-04-24 01:43:26,344 - --- validate (epoch=477)-----------
2024-04-24 01:43:26,345 - 3925 samples (32 per mini-batch)
2024-04-24 01:43:34,884 - Epoch: [477][  100/  123]    Loss 0.654376    Top1 78.718750    Top5 97.531250    
2024-04-24 01:43:37,043 - Epoch: [477][  123/  123]    Loss 0.652486    Top1 78.955414    Top5 97.579618    
2024-04-24 01:43:37,182 - ==> Top1: 78.955    Top5: 97.580    Loss: 0.652

2024-04-24 01:43:37,191 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:43:37,192 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:43:37,227 - 

2024-04-24 01:43:37,227 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:43:46,120 - Epoch: [478][  100/  296]    Overall Loss 0.639074    Objective Loss 0.639074                                        LR 0.000005    Time 0.088878    
2024-04-24 01:43:52,665 - Epoch: [478][  200/  296]    Overall Loss 0.637779    Objective Loss 0.637779                                        LR 0.000005    Time 0.077132    
2024-04-24 01:43:58,481 - Epoch: [478][  296/  296]    Overall Loss 0.645347    Objective Loss 0.645347    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.071748    
2024-04-24 01:43:58,613 - --- validate (epoch=478)-----------
2024-04-24 01:43:58,613 - 3925 samples (32 per mini-batch)
2024-04-24 01:44:07,498 - Epoch: [478][  100/  123]    Loss 0.672527    Top1 78.312500    Top5 97.437500    
2024-04-24 01:44:09,326 - Epoch: [478][  123/  123]    Loss 0.654687    Top1 79.082803    Top5 97.605096    
2024-04-24 01:44:09,431 - ==> Top1: 79.083    Top5: 97.605    Loss: 0.655

2024-04-24 01:44:09,439 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:44:09,439 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:44:09,475 - 

2024-04-24 01:44:09,475 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:44:17,478 - Epoch: [479][  100/  296]    Overall Loss 0.659193    Objective Loss 0.659193                                        LR 0.000005    Time 0.079972    
2024-04-24 01:44:24,290 - Epoch: [479][  200/  296]    Overall Loss 0.657687    Objective Loss 0.657687                                        LR 0.000005    Time 0.074023    
2024-04-24 01:44:30,926 - Epoch: [479][  296/  296]    Overall Loss 0.670551    Objective Loss 0.670551    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.072420    
2024-04-24 01:44:31,037 - --- validate (epoch=479)-----------
2024-04-24 01:44:31,038 - 3925 samples (32 per mini-batch)
2024-04-24 01:44:40,326 - Epoch: [479][  100/  123]    Loss 0.647563    Top1 79.468750    Top5 97.593750    
2024-04-24 01:44:41,908 - Epoch: [479][  123/  123]    Loss 0.654576    Top1 79.184713    Top5 97.579618    
2024-04-24 01:44:41,989 - ==> Top1: 79.185    Top5: 97.580    Loss: 0.655

2024-04-24 01:44:41,997 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:44:41,998 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:44:42,033 - 

2024-04-24 01:44:42,034 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:44:50,589 - Epoch: [480][  100/  296]    Overall Loss 0.668795    Objective Loss 0.668795                                        LR 0.000005    Time 0.085482    
2024-04-24 01:44:58,609 - Epoch: [480][  200/  296]    Overall Loss 0.664395    Objective Loss 0.664395                                        LR 0.000005    Time 0.082817    
2024-04-24 01:45:05,072 - Epoch: [480][  296/  296]    Overall Loss 0.665120    Objective Loss 0.665120    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.077777    
2024-04-24 01:45:05,187 - --- validate (epoch=480)-----------
2024-04-24 01:45:05,188 - 3925 samples (32 per mini-batch)
2024-04-24 01:45:13,995 - Epoch: [480][  100/  123]    Loss 0.649364    Top1 78.906250    Top5 97.812500    
2024-04-24 01:45:15,728 - Epoch: [480][  123/  123]    Loss 0.658018    Top1 78.828025    Top5 97.707006    
2024-04-24 01:45:15,829 - ==> Top1: 78.828    Top5: 97.707    Loss: 0.658

2024-04-24 01:45:15,837 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:45:15,837 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:45:15,873 - 

2024-04-24 01:45:15,873 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:45:24,468 - Epoch: [481][  100/  296]    Overall Loss 0.663121    Objective Loss 0.663121                                        LR 0.000005    Time 0.085896    
2024-04-24 01:45:31,079 - Epoch: [481][  200/  296]    Overall Loss 0.657711    Objective Loss 0.657711                                        LR 0.000005    Time 0.075974    
2024-04-24 01:45:36,500 - Epoch: [481][  296/  296]    Overall Loss 0.660555    Objective Loss 0.660555    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.069628    
2024-04-24 01:45:36,628 - --- validate (epoch=481)-----------
2024-04-24 01:45:36,629 - 3925 samples (32 per mini-batch)
2024-04-24 01:45:45,401 - Epoch: [481][  100/  123]    Loss 0.662802    Top1 78.843750    Top5 97.468750    
2024-04-24 01:45:47,106 - Epoch: [481][  123/  123]    Loss 0.656780    Top1 78.878981    Top5 97.528662    
2024-04-24 01:45:47,201 - ==> Top1: 78.879    Top5: 97.529    Loss: 0.657

2024-04-24 01:45:47,209 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:45:47,209 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:45:47,245 - 

2024-04-24 01:45:47,245 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:45:56,093 - Epoch: [482][  100/  296]    Overall Loss 0.602791    Objective Loss 0.602791                                        LR 0.000005    Time 0.088424    
2024-04-24 01:46:03,182 - Epoch: [482][  200/  296]    Overall Loss 0.643073    Objective Loss 0.643073                                        LR 0.000005    Time 0.079631    
2024-04-24 01:46:09,216 - Epoch: [482][  296/  296]    Overall Loss 0.648043    Objective Loss 0.648043    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.074173    
2024-04-24 01:46:09,304 - --- validate (epoch=482)-----------
2024-04-24 01:46:09,305 - 3925 samples (32 per mini-batch)
2024-04-24 01:46:19,380 - Epoch: [482][  100/  123]    Loss 0.663688    Top1 78.843750    Top5 97.406250    
2024-04-24 01:46:21,172 - Epoch: [482][  123/  123]    Loss 0.657293    Top1 78.955414    Top5 97.605096    
2024-04-24 01:46:21,293 - ==> Top1: 78.955    Top5: 97.605    Loss: 0.657

2024-04-24 01:46:21,301 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:46:21,302 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:46:21,335 - 

2024-04-24 01:46:21,335 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:46:29,105 - Epoch: [483][  100/  296]    Overall Loss 0.698464    Objective Loss 0.698464                                        LR 0.000005    Time 0.077639    
2024-04-24 01:46:35,252 - Epoch: [483][  200/  296]    Overall Loss 0.675830    Objective Loss 0.675830                                        LR 0.000005    Time 0.069524    
2024-04-24 01:46:41,588 - Epoch: [483][  296/  296]    Overall Loss 0.668834    Objective Loss 0.668834    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.068367    
2024-04-24 01:46:41,682 - --- validate (epoch=483)-----------
2024-04-24 01:46:41,683 - 3925 samples (32 per mini-batch)
2024-04-24 01:46:50,744 - Epoch: [483][  100/  123]    Loss 0.656741    Top1 78.750000    Top5 97.687500    
2024-04-24 01:46:52,125 - Epoch: [483][  123/  123]    Loss 0.660786    Top1 78.853503    Top5 97.681529    
2024-04-24 01:46:52,223 - ==> Top1: 78.854    Top5: 97.682    Loss: 0.661

2024-04-24 01:46:52,232 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:46:52,232 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:46:52,267 - 

2024-04-24 01:46:52,267 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:47:00,373 - Epoch: [484][  100/  296]    Overall Loss 0.646061    Objective Loss 0.646061                                        LR 0.000005    Time 0.081001    
2024-04-24 01:47:08,121 - Epoch: [484][  200/  296]    Overall Loss 0.660262    Objective Loss 0.660262                                        LR 0.000005    Time 0.079209    
2024-04-24 01:47:15,050 - Epoch: [484][  296/  296]    Overall Loss 0.654300    Objective Loss 0.654300    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.076912    
2024-04-24 01:47:15,152 - --- validate (epoch=484)-----------
2024-04-24 01:47:15,153 - 3925 samples (32 per mini-batch)
2024-04-24 01:47:24,193 - Epoch: [484][  100/  123]    Loss 0.649080    Top1 79.062500    Top5 97.750000    
2024-04-24 01:47:26,603 - Epoch: [484][  123/  123]    Loss 0.655944    Top1 79.108280    Top5 97.579618    
2024-04-24 01:47:26,829 - ==> Top1: 79.108    Top5: 97.580    Loss: 0.656

2024-04-24 01:47:26,837 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:47:26,838 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:47:26,873 - 

2024-04-24 01:47:26,873 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:47:37,558 - Epoch: [485][  100/  296]    Overall Loss 0.654673    Objective Loss 0.654673                                        LR 0.000005    Time 0.106798    
2024-04-24 01:47:46,215 - Epoch: [485][  200/  296]    Overall Loss 0.666019    Objective Loss 0.666019                                        LR 0.000005    Time 0.096663    
2024-04-24 01:47:53,235 - Epoch: [485][  296/  296]    Overall Loss 0.657342    Objective Loss 0.657342    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.089012    
2024-04-24 01:47:53,354 - --- validate (epoch=485)-----------
2024-04-24 01:47:53,354 - 3925 samples (32 per mini-batch)
2024-04-24 01:48:02,509 - Epoch: [485][  100/  123]    Loss 0.675503    Top1 78.250000    Top5 97.625000    
2024-04-24 01:48:04,458 - Epoch: [485][  123/  123]    Loss 0.656534    Top1 78.878981    Top5 97.656051    
2024-04-24 01:48:04,600 - ==> Top1: 78.879    Top5: 97.656    Loss: 0.657

2024-04-24 01:48:04,608 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:48:04,609 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:48:04,644 - 

2024-04-24 01:48:04,644 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:48:13,146 - Epoch: [486][  100/  296]    Overall Loss 0.674638    Objective Loss 0.674638                                        LR 0.000005    Time 0.084973    
2024-04-24 01:48:20,152 - Epoch: [486][  200/  296]    Overall Loss 0.658043    Objective Loss 0.658043                                        LR 0.000005    Time 0.077495    
2024-04-24 01:48:26,129 - Epoch: [486][  296/  296]    Overall Loss 0.656354    Objective Loss 0.656354    Top1 86.885246    Top5 96.721311    LR 0.000005    Time 0.072536    
2024-04-24 01:48:26,218 - --- validate (epoch=486)-----------
2024-04-24 01:48:26,219 - 3925 samples (32 per mini-batch)
2024-04-24 01:48:37,107 - Epoch: [486][  100/  123]    Loss 0.643197    Top1 79.062500    Top5 97.625000    
2024-04-24 01:48:39,342 - Epoch: [486][  123/  123]    Loss 0.656275    Top1 78.828025    Top5 97.605096    
2024-04-24 01:48:39,475 - ==> Top1: 78.828    Top5: 97.605    Loss: 0.656

2024-04-24 01:48:39,483 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:48:39,483 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:48:39,518 - 

2024-04-24 01:48:39,518 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:48:49,654 - Epoch: [487][  100/  296]    Overall Loss 0.637484    Objective Loss 0.637484                                        LR 0.000005    Time 0.101276    
2024-04-24 01:48:58,262 - Epoch: [487][  200/  296]    Overall Loss 0.645477    Objective Loss 0.645477                                        LR 0.000005    Time 0.093645    
2024-04-24 01:49:04,876 - Epoch: [487][  296/  296]    Overall Loss 0.646444    Objective Loss 0.646444    Top1 72.131148    Top5 100.000000    LR 0.000005    Time 0.085598    
2024-04-24 01:49:05,008 - --- validate (epoch=487)-----------
2024-04-24 01:49:05,009 - 3925 samples (32 per mini-batch)
2024-04-24 01:49:15,465 - Epoch: [487][  100/  123]    Loss 0.652255    Top1 78.968750    Top5 97.718750    
2024-04-24 01:49:17,368 - Epoch: [487][  123/  123]    Loss 0.657330    Top1 78.802548    Top5 97.630573    
2024-04-24 01:49:17,508 - ==> Top1: 78.803    Top5: 97.631    Loss: 0.657

2024-04-24 01:49:17,516 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:49:17,516 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:49:17,552 - 

2024-04-24 01:49:17,553 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:49:26,464 - Epoch: [488][  100/  296]    Overall Loss 0.638182    Objective Loss 0.638182                                        LR 0.000005    Time 0.089047    
2024-04-24 01:49:33,386 - Epoch: [488][  200/  296]    Overall Loss 0.636242    Objective Loss 0.636242                                        LR 0.000005    Time 0.079108    
2024-04-24 01:49:39,563 - Epoch: [488][  296/  296]    Overall Loss 0.645386    Objective Loss 0.645386    Top1 80.327869    Top5 95.081967    LR 0.000005    Time 0.074306    
2024-04-24 01:49:39,693 - --- validate (epoch=488)-----------
2024-04-24 01:49:39,693 - 3925 samples (32 per mini-batch)
2024-04-24 01:49:49,346 - Epoch: [488][  100/  123]    Loss 0.656412    Top1 78.937500    Top5 97.500000    
2024-04-24 01:49:51,314 - Epoch: [488][  123/  123]    Loss 0.663527    Top1 78.726115    Top5 97.605096    
2024-04-24 01:49:51,410 - ==> Top1: 78.726    Top5: 97.605    Loss: 0.664

2024-04-24 01:49:51,419 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:49:51,419 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:49:51,454 - 

2024-04-24 01:49:51,454 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:50:00,418 - Epoch: [489][  100/  296]    Overall Loss 0.655079    Objective Loss 0.655079                                        LR 0.000005    Time 0.089566    
2024-04-24 01:50:07,951 - Epoch: [489][  200/  296]    Overall Loss 0.659658    Objective Loss 0.659658                                        LR 0.000005    Time 0.082413    
2024-04-24 01:50:15,022 - Epoch: [489][  296/  296]    Overall Loss 0.664290    Objective Loss 0.664290    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.079559    
2024-04-24 01:50:15,135 - --- validate (epoch=489)-----------
2024-04-24 01:50:15,135 - 3925 samples (32 per mini-batch)
2024-04-24 01:50:23,480 - Epoch: [489][  100/  123]    Loss 0.661242    Top1 78.406250    Top5 97.562500    
2024-04-24 01:50:25,147 - Epoch: [489][  123/  123]    Loss 0.659979    Top1 78.624204    Top5 97.605096    
2024-04-24 01:50:25,274 - ==> Top1: 78.624    Top5: 97.605    Loss: 0.660

2024-04-24 01:50:25,283 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:50:25,283 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:50:25,320 - 

2024-04-24 01:50:25,320 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:50:33,630 - Epoch: [490][  100/  296]    Overall Loss 0.638597    Objective Loss 0.638597                                        LR 0.000005    Time 0.083044    
2024-04-24 01:50:40,550 - Epoch: [490][  200/  296]    Overall Loss 0.646864    Objective Loss 0.646864                                        LR 0.000005    Time 0.076092    
2024-04-24 01:50:46,298 - Epoch: [490][  296/  296]    Overall Loss 0.658736    Objective Loss 0.658736    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.070816    
2024-04-24 01:50:46,405 - --- validate (epoch=490)-----------
2024-04-24 01:50:46,406 - 3925 samples (32 per mini-batch)
2024-04-24 01:50:56,724 - Epoch: [490][  100/  123]    Loss 0.666821    Top1 78.375000    Top5 97.500000    
2024-04-24 01:50:58,897 - Epoch: [490][  123/  123]    Loss 0.658576    Top1 78.598726    Top5 97.503185    
2024-04-24 01:50:59,011 - ==> Top1: 78.599    Top5: 97.503    Loss: 0.659

2024-04-24 01:50:59,019 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:50:59,020 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:50:59,054 - 

2024-04-24 01:50:59,054 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:51:08,027 - Epoch: [491][  100/  296]    Overall Loss 0.664106    Objective Loss 0.664106                                        LR 0.000005    Time 0.089674    
2024-04-24 01:51:14,691 - Epoch: [491][  200/  296]    Overall Loss 0.648943    Objective Loss 0.648943                                        LR 0.000005    Time 0.078130    
2024-04-24 01:51:21,091 - Epoch: [491][  296/  296]    Overall Loss 0.636388    Objective Loss 0.636388    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.074399    
2024-04-24 01:51:21,204 - --- validate (epoch=491)-----------
2024-04-24 01:51:21,205 - 3925 samples (32 per mini-batch)
2024-04-24 01:51:31,147 - Epoch: [491][  100/  123]    Loss 0.674539    Top1 78.687500    Top5 97.562500    
2024-04-24 01:51:33,538 - Epoch: [491][  123/  123]    Loss 0.661732    Top1 78.802548    Top5 97.605096    
2024-04-24 01:51:33,772 - ==> Top1: 78.803    Top5: 97.605    Loss: 0.662

2024-04-24 01:51:33,780 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:51:33,781 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:51:33,816 - 

2024-04-24 01:51:33,817 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:51:43,035 - Epoch: [492][  100/  296]    Overall Loss 0.641867    Objective Loss 0.641867                                        LR 0.000005    Time 0.092131    
2024-04-24 01:51:50,911 - Epoch: [492][  200/  296]    Overall Loss 0.655834    Objective Loss 0.655834                                        LR 0.000005    Time 0.085428    
2024-04-24 01:51:58,260 - Epoch: [492][  296/  296]    Overall Loss 0.658375    Objective Loss 0.658375    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.082533    
2024-04-24 01:51:58,394 - --- validate (epoch=492)-----------
2024-04-24 01:51:58,394 - 3925 samples (32 per mini-batch)
2024-04-24 01:52:07,488 - Epoch: [492][  100/  123]    Loss 0.670487    Top1 78.406250    Top5 97.406250    
2024-04-24 01:52:09,434 - Epoch: [492][  123/  123]    Loss 0.661997    Top1 78.828025    Top5 97.579618    
2024-04-24 01:52:09,562 - ==> Top1: 78.828    Top5: 97.580    Loss: 0.662

2024-04-24 01:52:09,572 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:52:09,572 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:52:09,607 - 

2024-04-24 01:52:09,607 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:52:18,623 - Epoch: [493][  100/  296]    Overall Loss 0.636944    Objective Loss 0.636944                                        LR 0.000005    Time 0.090097    
2024-04-24 01:52:25,661 - Epoch: [493][  200/  296]    Overall Loss 0.657046    Objective Loss 0.657046                                        LR 0.000005    Time 0.080212    
2024-04-24 01:52:31,430 - Epoch: [493][  296/  296]    Overall Loss 0.657075    Objective Loss 0.657075    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.073670    
2024-04-24 01:52:31,529 - --- validate (epoch=493)-----------
2024-04-24 01:52:31,529 - 3925 samples (32 per mini-batch)
2024-04-24 01:52:40,527 - Epoch: [493][  100/  123]    Loss 0.667088    Top1 78.625000    Top5 97.531250    
2024-04-24 01:52:42,379 - Epoch: [493][  123/  123]    Loss 0.660297    Top1 79.057325    Top5 97.630573    
2024-04-24 01:52:42,502 - ==> Top1: 79.057    Top5: 97.631    Loss: 0.660

2024-04-24 01:52:42,511 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:52:42,512 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:52:42,547 - 

2024-04-24 01:52:42,547 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:52:50,941 - Epoch: [494][  100/  296]    Overall Loss 0.652865    Objective Loss 0.652865                                        LR 0.000005    Time 0.083888    
2024-04-24 01:52:58,005 - Epoch: [494][  200/  296]    Overall Loss 0.661434    Objective Loss 0.661434                                        LR 0.000005    Time 0.077238    
2024-04-24 01:53:05,230 - Epoch: [494][  296/  296]    Overall Loss 0.667185    Objective Loss 0.667185    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.076583    
2024-04-24 01:53:05,353 - --- validate (epoch=494)-----------
2024-04-24 01:53:05,354 - 3925 samples (32 per mini-batch)
2024-04-24 01:53:14,029 - Epoch: [494][  100/  123]    Loss 0.658204    Top1 78.531250    Top5 97.656250    
2024-04-24 01:53:15,998 - Epoch: [494][  123/  123]    Loss 0.659082    Top1 78.777070    Top5 97.656051    
2024-04-24 01:53:16,129 - ==> Top1: 78.777    Top5: 97.656    Loss: 0.659

2024-04-24 01:53:16,137 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:53:16,137 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:53:16,173 - 

2024-04-24 01:53:16,173 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:53:24,738 - Epoch: [495][  100/  296]    Overall Loss 0.645872    Objective Loss 0.645872                                        LR 0.000005    Time 0.085588    
2024-04-24 01:53:31,291 - Epoch: [495][  200/  296]    Overall Loss 0.672614    Objective Loss 0.672614                                        LR 0.000005    Time 0.075531    
2024-04-24 01:53:37,347 - Epoch: [495][  296/  296]    Overall Loss 0.661510    Objective Loss 0.661510    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.071479    
2024-04-24 01:53:37,417 - --- validate (epoch=495)-----------
2024-04-24 01:53:37,417 - 3925 samples (32 per mini-batch)
2024-04-24 01:53:46,220 - Epoch: [495][  100/  123]    Loss 0.649180    Top1 79.562500    Top5 97.531250    
2024-04-24 01:53:48,042 - Epoch: [495][  123/  123]    Loss 0.659049    Top1 78.955414    Top5 97.528662    
2024-04-24 01:53:48,126 - ==> Top1: 78.955    Top5: 97.529    Loss: 0.659

2024-04-24 01:53:48,134 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:53:48,135 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:53:48,169 - 

2024-04-24 01:53:48,169 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:53:56,074 - Epoch: [496][  100/  296]    Overall Loss 0.662984    Objective Loss 0.662984                                        LR 0.000005    Time 0.078999    
2024-04-24 01:54:02,916 - Epoch: [496][  200/  296]    Overall Loss 0.648772    Objective Loss 0.648772                                        LR 0.000005    Time 0.073677    
2024-04-24 01:54:08,893 - Epoch: [496][  296/  296]    Overall Loss 0.658491    Objective Loss 0.658491    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.069956    
2024-04-24 01:54:09,008 - --- validate (epoch=496)-----------
2024-04-24 01:54:09,009 - 3925 samples (32 per mini-batch)
2024-04-24 01:54:17,156 - Epoch: [496][  100/  123]    Loss 0.665881    Top1 78.906250    Top5 97.531250    
2024-04-24 01:54:18,532 - Epoch: [496][  123/  123]    Loss 0.655618    Top1 78.828025    Top5 97.656051    
2024-04-24 01:54:18,634 - ==> Top1: 78.828    Top5: 97.656    Loss: 0.656

2024-04-24 01:54:18,642 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:54:18,643 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:54:18,679 - 

2024-04-24 01:54:18,679 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:54:26,775 - Epoch: [497][  100/  296]    Overall Loss 0.672192    Objective Loss 0.672192                                        LR 0.000005    Time 0.080898    
2024-04-24 01:54:33,495 - Epoch: [497][  200/  296]    Overall Loss 0.650715    Objective Loss 0.650715                                        LR 0.000005    Time 0.074023    
2024-04-24 01:54:39,852 - Epoch: [497][  296/  296]    Overall Loss 0.644942    Objective Loss 0.644942    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.071475    
2024-04-24 01:54:39,990 - --- validate (epoch=497)-----------
2024-04-24 01:54:39,990 - 3925 samples (32 per mini-batch)
2024-04-24 01:54:48,159 - Epoch: [497][  100/  123]    Loss 0.651090    Top1 79.062500    Top5 97.843750    
2024-04-24 01:54:49,826 - Epoch: [497][  123/  123]    Loss 0.656540    Top1 78.828025    Top5 97.528662    
2024-04-24 01:54:49,944 - ==> Top1: 78.828    Top5: 97.529    Loss: 0.657

2024-04-24 01:54:49,949 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:54:49,950 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:54:49,975 - 

2024-04-24 01:54:49,975 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:54:59,733 - Epoch: [498][  100/  296]    Overall Loss 0.632742    Objective Loss 0.632742                                        LR 0.000005    Time 0.097498    
2024-04-24 01:55:05,519 - Epoch: [498][  200/  296]    Overall Loss 0.653591    Objective Loss 0.653591                                        LR 0.000005    Time 0.077653    
2024-04-24 01:55:11,464 - Epoch: [498][  296/  296]    Overall Loss 0.647445    Objective Loss 0.647445    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.072534    
2024-04-24 01:55:11,564 - --- validate (epoch=498)-----------
2024-04-24 01:55:11,565 - 3925 samples (32 per mini-batch)
2024-04-24 01:55:19,014 - Epoch: [498][  100/  123]    Loss 0.628062    Top1 79.625000    Top5 97.843750    
2024-04-24 01:55:20,605 - Epoch: [498][  123/  123]    Loss 0.652552    Top1 78.904459    Top5 97.605096    
2024-04-24 01:55:20,725 - ==> Top1: 78.904    Top5: 97.605    Loss: 0.653

2024-04-24 01:55:20,730 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:55:20,730 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:55:20,756 - 

2024-04-24 01:55:20,756 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:55:28,015 - Epoch: [499][  100/  296]    Overall Loss 0.666023    Objective Loss 0.666023                                        LR 0.000005    Time 0.072534    
2024-04-24 01:55:34,903 - Epoch: [499][  200/  296]    Overall Loss 0.651179    Objective Loss 0.651179                                        LR 0.000005    Time 0.070681    
2024-04-24 01:55:42,154 - Epoch: [499][  296/  296]    Overall Loss 0.663426    Objective Loss 0.663426    Top1 73.770492    Top5 95.081967    LR 0.000005    Time 0.072240    
2024-04-24 01:55:42,274 - --- validate (epoch=499)-----------
2024-04-24 01:55:42,275 - 3925 samples (32 per mini-batch)
2024-04-24 01:55:51,567 - Epoch: [499][  100/  123]    Loss 0.666935    Top1 78.781250    Top5 97.687500    
2024-04-24 01:55:53,270 - Epoch: [499][  123/  123]    Loss 0.658431    Top1 79.031847    Top5 97.605096    
2024-04-24 01:55:53,381 - ==> Top1: 79.032    Top5: 97.605    Loss: 0.658

2024-04-24 01:55:53,389 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:55:53,389 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:55:53,425 - 

2024-04-24 01:55:53,425 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:56:00,793 - Epoch: [500][  100/  296]    Overall Loss 0.678650    Objective Loss 0.678650                                        LR 0.000005    Time 0.073621    
2024-04-24 01:56:07,712 - Epoch: [500][  200/  296]    Overall Loss 0.666957    Objective Loss 0.666957                                        LR 0.000005    Time 0.071382    
2024-04-24 01:56:14,059 - Epoch: [500][  296/  296]    Overall Loss 0.666781    Objective Loss 0.666781    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.069657    
2024-04-24 01:56:14,135 - --- validate (epoch=500)-----------
2024-04-24 01:56:14,136 - 3925 samples (32 per mini-batch)
2024-04-24 01:56:22,183 - Epoch: [500][  100/  123]    Loss 0.662275    Top1 78.500000    Top5 97.593750    
2024-04-24 01:56:23,587 - Epoch: [500][  123/  123]    Loss 0.657866    Top1 78.980892    Top5 97.630573    
2024-04-24 01:56:23,690 - ==> Top1: 78.981    Top5: 97.631    Loss: 0.658

2024-04-24 01:56:23,698 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:56:23,698 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:56:23,733 - 

2024-04-24 01:56:23,733 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:56:31,983 - Epoch: [501][  100/  296]    Overall Loss 0.627459    Objective Loss 0.627459                                        LR 0.000005    Time 0.082440    
2024-04-24 01:56:39,012 - Epoch: [501][  200/  296]    Overall Loss 0.632371    Objective Loss 0.632371                                        LR 0.000005    Time 0.076343    
2024-04-24 01:56:44,737 - Epoch: [501][  296/  296]    Overall Loss 0.631508    Objective Loss 0.631508    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.070907    
2024-04-24 01:56:44,817 - --- validate (epoch=501)-----------
2024-04-24 01:56:44,818 - 3925 samples (32 per mini-batch)
2024-04-24 01:56:52,672 - Epoch: [501][  100/  123]    Loss 0.636607    Top1 79.593750    Top5 97.843750    
2024-04-24 01:56:54,018 - Epoch: [501][  123/  123]    Loss 0.655318    Top1 78.929936    Top5 97.605096    
2024-04-24 01:56:54,170 - ==> Top1: 78.930    Top5: 97.605    Loss: 0.655

2024-04-24 01:56:54,179 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:56:54,179 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:56:54,214 - 

2024-04-24 01:56:54,214 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:57:03,828 - Epoch: [502][  100/  296]    Overall Loss 0.654409    Objective Loss 0.654409                                        LR 0.000005    Time 0.096076    
2024-04-24 01:57:10,641 - Epoch: [502][  200/  296]    Overall Loss 0.651540    Objective Loss 0.651540                                        LR 0.000005    Time 0.082076    
2024-04-24 01:57:16,890 - Epoch: [502][  296/  296]    Overall Loss 0.646432    Objective Loss 0.646432    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.076551    
2024-04-24 01:57:17,037 - --- validate (epoch=502)-----------
2024-04-24 01:57:17,038 - 3925 samples (32 per mini-batch)
2024-04-24 01:57:25,825 - Epoch: [502][  100/  123]    Loss 0.657988    Top1 78.843750    Top5 97.375000    
2024-04-24 01:57:27,430 - Epoch: [502][  123/  123]    Loss 0.658083    Top1 78.726115    Top5 97.528662    
2024-04-24 01:57:27,541 - ==> Top1: 78.726    Top5: 97.529    Loss: 0.658

2024-04-24 01:57:27,549 - ==> Best [Top1: 79.338   Top5: 97.656   Sparsity:0.00   Params: 376752 on epoch: 333]
2024-04-24 01:57:27,549 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:57:27,583 - 

2024-04-24 01:57:27,583 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:57:35,058 - Epoch: [503][  100/  296]    Overall Loss 0.654243    Objective Loss 0.654243                                        LR 0.000005    Time 0.074686    
2024-04-24 01:57:41,425 - Epoch: [503][  200/  296]    Overall Loss 0.650972    Objective Loss 0.650972                                        LR 0.000005    Time 0.069151    
2024-04-24 01:57:47,300 - Epoch: [503][  296/  296]    Overall Loss 0.657862    Objective Loss 0.657862    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.066555    
2024-04-24 01:57:47,372 - --- validate (epoch=503)-----------
2024-04-24 01:57:47,373 - 3925 samples (32 per mini-batch)
2024-04-24 01:57:56,057 - Epoch: [503][  100/  123]    Loss 0.651794    Top1 79.531250    Top5 97.531250    
2024-04-24 01:57:57,480 - Epoch: [503][  123/  123]    Loss 0.655468    Top1 79.388535    Top5 97.503185    
2024-04-24 01:57:57,597 - ==> Top1: 79.389    Top5: 97.503    Loss: 0.655

2024-04-24 01:57:57,605 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 01:57:57,606 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:57:57,646 - 

2024-04-24 01:57:57,646 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:58:05,598 - Epoch: [504][  100/  296]    Overall Loss 0.678546    Objective Loss 0.678546                                        LR 0.000005    Time 0.079466    
2024-04-24 01:58:13,120 - Epoch: [504][  200/  296]    Overall Loss 0.663829    Objective Loss 0.663829                                        LR 0.000005    Time 0.077314    
2024-04-24 01:58:19,985 - Epoch: [504][  296/  296]    Overall Loss 0.665123    Objective Loss 0.665123    Top1 80.327869    Top5 93.442623    LR 0.000005    Time 0.075414    
2024-04-24 01:58:20,239 - --- validate (epoch=504)-----------
2024-04-24 01:58:20,240 - 3925 samples (32 per mini-batch)
2024-04-24 01:58:30,328 - Epoch: [504][  100/  123]    Loss 0.649363    Top1 79.843750    Top5 97.593750    
2024-04-24 01:58:32,175 - Epoch: [504][  123/  123]    Loss 0.658126    Top1 79.108280    Top5 97.503185    
2024-04-24 01:58:32,293 - ==> Top1: 79.108    Top5: 97.503    Loss: 0.658

2024-04-24 01:58:32,301 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 01:58:32,301 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:58:32,337 - 

2024-04-24 01:58:32,337 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:58:42,714 - Epoch: [505][  100/  296]    Overall Loss 0.665338    Objective Loss 0.665338                                        LR 0.000005    Time 0.103717    
2024-04-24 01:58:52,020 - Epoch: [505][  200/  296]    Overall Loss 0.653675    Objective Loss 0.653675                                        LR 0.000005    Time 0.098365    
2024-04-24 01:58:59,184 - Epoch: [505][  296/  296]    Overall Loss 0.654984    Objective Loss 0.654984    Top1 70.491803    Top5 96.721311    LR 0.000005    Time 0.090654    
2024-04-24 01:58:59,290 - --- validate (epoch=505)-----------
2024-04-24 01:58:59,291 - 3925 samples (32 per mini-batch)
2024-04-24 01:59:08,635 - Epoch: [505][  100/  123]    Loss 0.645474    Top1 79.375000    Top5 97.687500    
2024-04-24 01:59:10,815 - Epoch: [505][  123/  123]    Loss 0.656800    Top1 78.980892    Top5 97.605096    
2024-04-24 01:59:10,899 - ==> Top1: 78.981    Top5: 97.605    Loss: 0.657

2024-04-24 01:59:10,907 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 01:59:10,908 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:59:10,942 - 

2024-04-24 01:59:10,943 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:59:20,082 - Epoch: [506][  100/  296]    Overall Loss 0.654944    Objective Loss 0.654944                                        LR 0.000005    Time 0.091347    
2024-04-24 01:59:27,198 - Epoch: [506][  200/  296]    Overall Loss 0.655863    Objective Loss 0.655863                                        LR 0.000005    Time 0.081226    
2024-04-24 01:59:33,389 - Epoch: [506][  296/  296]    Overall Loss 0.653691    Objective Loss 0.653691    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.075781    
2024-04-24 01:59:33,513 - --- validate (epoch=506)-----------
2024-04-24 01:59:33,514 - 3925 samples (32 per mini-batch)
2024-04-24 01:59:41,651 - Epoch: [506][  100/  123]    Loss 0.654912    Top1 78.906250    Top5 97.437500    
2024-04-24 01:59:43,427 - Epoch: [506][  123/  123]    Loss 0.658188    Top1 78.878981    Top5 97.579618    
2024-04-24 01:59:43,563 - ==> Top1: 78.879    Top5: 97.580    Loss: 0.658

2024-04-24 01:59:43,572 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 01:59:43,572 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 01:59:43,606 - 

2024-04-24 01:59:43,607 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 01:59:53,565 - Epoch: [507][  100/  296]    Overall Loss 0.675411    Objective Loss 0.675411                                        LR 0.000005    Time 0.099510    
2024-04-24 02:00:00,849 - Epoch: [507][  200/  296]    Overall Loss 0.662005    Objective Loss 0.662005                                        LR 0.000005    Time 0.086138    
2024-04-24 02:00:07,767 - Epoch: [507][  296/  296]    Overall Loss 0.655728    Objective Loss 0.655728    Top1 78.688525    Top5 95.081967    LR 0.000005    Time 0.081551    
2024-04-24 02:00:07,887 - --- validate (epoch=507)-----------
2024-04-24 02:00:07,888 - 3925 samples (32 per mini-batch)
2024-04-24 02:00:19,525 - Epoch: [507][  100/  123]    Loss 0.654538    Top1 78.656250    Top5 97.875000    
2024-04-24 02:00:21,803 - Epoch: [507][  123/  123]    Loss 0.657966    Top1 78.802548    Top5 97.656051    
2024-04-24 02:00:21,910 - ==> Top1: 78.803    Top5: 97.656    Loss: 0.658

2024-04-24 02:00:21,918 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:00:21,918 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:00:21,952 - 

2024-04-24 02:00:21,952 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:00:30,766 - Epoch: [508][  100/  296]    Overall Loss 0.665489    Objective Loss 0.665489                                        LR 0.000005    Time 0.088081    
2024-04-24 02:00:37,858 - Epoch: [508][  200/  296]    Overall Loss 0.651302    Objective Loss 0.651302                                        LR 0.000005    Time 0.079474    
2024-04-24 02:00:45,110 - Epoch: [508][  296/  296]    Overall Loss 0.646584    Objective Loss 0.646584    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.078182    
2024-04-24 02:00:45,259 - --- validate (epoch=508)-----------
2024-04-24 02:00:45,259 - 3925 samples (32 per mini-batch)
2024-04-24 02:00:54,056 - Epoch: [508][  100/  123]    Loss 0.644008    Top1 79.437500    Top5 97.531250    
2024-04-24 02:00:55,941 - Epoch: [508][  123/  123]    Loss 0.658352    Top1 78.929936    Top5 97.630573    
2024-04-24 02:00:56,053 - ==> Top1: 78.930    Top5: 97.631    Loss: 0.658

2024-04-24 02:00:56,061 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:00:56,061 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:00:56,095 - 

2024-04-24 02:00:56,095 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:01:05,207 - Epoch: [509][  100/  296]    Overall Loss 0.676937    Objective Loss 0.676937                                        LR 0.000005    Time 0.091052    
2024-04-24 02:01:12,710 - Epoch: [509][  200/  296]    Overall Loss 0.645720    Objective Loss 0.645720                                        LR 0.000005    Time 0.083017    
2024-04-24 02:01:19,143 - Epoch: [509][  296/  296]    Overall Loss 0.647042    Objective Loss 0.647042    Top1 73.770492    Top5 100.000000    LR 0.000005    Time 0.077811    
2024-04-24 02:01:19,269 - --- validate (epoch=509)-----------
2024-04-24 02:01:19,269 - 3925 samples (32 per mini-batch)
2024-04-24 02:01:29,760 - Epoch: [509][  100/  123]    Loss 0.663396    Top1 79.062500    Top5 97.343750    
2024-04-24 02:01:31,363 - Epoch: [509][  123/  123]    Loss 0.659527    Top1 78.955414    Top5 97.452229    
2024-04-24 02:01:31,453 - ==> Top1: 78.955    Top5: 97.452    Loss: 0.660

2024-04-24 02:01:31,460 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:01:31,461 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:01:31,496 - 

2024-04-24 02:01:31,496 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:01:39,731 - Epoch: [510][  100/  296]    Overall Loss 0.639031    Objective Loss 0.639031                                        LR 0.000005    Time 0.082300    
2024-04-24 02:01:46,461 - Epoch: [510][  200/  296]    Overall Loss 0.648383    Objective Loss 0.648383                                        LR 0.000005    Time 0.074763    
2024-04-24 02:01:52,903 - Epoch: [510][  296/  296]    Overall Loss 0.653057    Objective Loss 0.653057    Top1 83.606557    Top5 95.081967    LR 0.000005    Time 0.072259    
2024-04-24 02:01:53,008 - --- validate (epoch=510)-----------
2024-04-24 02:01:53,009 - 3925 samples (32 per mini-batch)
2024-04-24 02:02:01,933 - Epoch: [510][  100/  123]    Loss 0.636520    Top1 79.343750    Top5 97.593750    
2024-04-24 02:02:03,886 - Epoch: [510][  123/  123]    Loss 0.658083    Top1 78.853503    Top5 97.554140    
2024-04-24 02:02:04,019 - ==> Top1: 78.854    Top5: 97.554    Loss: 0.658

2024-04-24 02:02:04,027 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:02:04,028 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:02:04,062 - 

2024-04-24 02:02:04,062 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:02:12,024 - Epoch: [511][  100/  296]    Overall Loss 0.643920    Objective Loss 0.643920                                        LR 0.000005    Time 0.079547    
2024-04-24 02:02:18,095 - Epoch: [511][  200/  296]    Overall Loss 0.646505    Objective Loss 0.646505                                        LR 0.000005    Time 0.070101    
2024-04-24 02:02:24,457 - Epoch: [511][  296/  296]    Overall Loss 0.650248    Objective Loss 0.650248    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.068843    
2024-04-24 02:02:24,568 - --- validate (epoch=511)-----------
2024-04-24 02:02:24,569 - 3925 samples (32 per mini-batch)
2024-04-24 02:02:31,883 - Epoch: [511][  100/  123]    Loss 0.659958    Top1 79.031250    Top5 97.531250    
2024-04-24 02:02:33,379 - Epoch: [511][  123/  123]    Loss 0.658758    Top1 79.006369    Top5 97.528662    
2024-04-24 02:02:33,454 - ==> Top1: 79.006    Top5: 97.529    Loss: 0.659

2024-04-24 02:02:33,462 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:02:33,462 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:02:33,498 - 

2024-04-24 02:02:33,498 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:02:42,276 - Epoch: [512][  100/  296]    Overall Loss 0.665528    Objective Loss 0.665528                                        LR 0.000005    Time 0.087733    
2024-04-24 02:02:48,816 - Epoch: [512][  200/  296]    Overall Loss 0.675953    Objective Loss 0.675953                                        LR 0.000005    Time 0.076540    
2024-04-24 02:02:54,405 - Epoch: [512][  296/  296]    Overall Loss 0.661186    Objective Loss 0.661186    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.070581    
2024-04-24 02:02:54,496 - --- validate (epoch=512)-----------
2024-04-24 02:02:54,497 - 3925 samples (32 per mini-batch)
2024-04-24 02:03:03,383 - Epoch: [512][  100/  123]    Loss 0.667968    Top1 78.375000    Top5 97.531250    
2024-04-24 02:03:05,282 - Epoch: [512][  123/  123]    Loss 0.659560    Top1 78.853503    Top5 97.579618    
2024-04-24 02:03:05,413 - ==> Top1: 78.854    Top5: 97.580    Loss: 0.660

2024-04-24 02:03:05,421 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:03:05,422 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:03:05,457 - 

2024-04-24 02:03:05,458 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:03:14,048 - Epoch: [513][  100/  296]    Overall Loss 0.649662    Objective Loss 0.649662                                        LR 0.000005    Time 0.085833    
2024-04-24 02:03:20,723 - Epoch: [513][  200/  296]    Overall Loss 0.649007    Objective Loss 0.649007                                        LR 0.000005    Time 0.076262    
2024-04-24 02:03:27,805 - Epoch: [513][  296/  296]    Overall Loss 0.642541    Objective Loss 0.642541    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.075433    
2024-04-24 02:03:27,966 - --- validate (epoch=513)-----------
2024-04-24 02:03:27,966 - 3925 samples (32 per mini-batch)
2024-04-24 02:03:37,443 - Epoch: [513][  100/  123]    Loss 0.673201    Top1 78.625000    Top5 97.406250    
2024-04-24 02:03:39,298 - Epoch: [513][  123/  123]    Loss 0.661229    Top1 78.777070    Top5 97.605096    
2024-04-24 02:03:39,433 - ==> Top1: 78.777    Top5: 97.605    Loss: 0.661

2024-04-24 02:03:39,442 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:03:39,442 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:03:39,476 - 

2024-04-24 02:03:39,476 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:03:47,658 - Epoch: [514][  100/  296]    Overall Loss 0.651413    Objective Loss 0.651413                                        LR 0.000005    Time 0.081769    
2024-04-24 02:03:53,798 - Epoch: [514][  200/  296]    Overall Loss 0.660601    Objective Loss 0.660601                                        LR 0.000005    Time 0.071559    
2024-04-24 02:04:00,698 - Epoch: [514][  296/  296]    Overall Loss 0.657363    Objective Loss 0.657363    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.071645    
2024-04-24 02:04:00,851 - --- validate (epoch=514)-----------
2024-04-24 02:04:00,851 - 3925 samples (32 per mini-batch)
2024-04-24 02:04:09,751 - Epoch: [514][  100/  123]    Loss 0.667901    Top1 78.593750    Top5 97.593750    
2024-04-24 02:04:11,293 - Epoch: [514][  123/  123]    Loss 0.655025    Top1 78.955414    Top5 97.630573    
2024-04-24 02:04:11,391 - ==> Top1: 78.955    Top5: 97.631    Loss: 0.655

2024-04-24 02:04:11,400 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:04:11,400 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:04:11,436 - 

2024-04-24 02:04:11,437 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:04:21,054 - Epoch: [515][  100/  296]    Overall Loss 0.646633    Objective Loss 0.646633                                        LR 0.000005    Time 0.096094    
2024-04-24 02:04:26,907 - Epoch: [515][  200/  296]    Overall Loss 0.645274    Objective Loss 0.645274                                        LR 0.000005    Time 0.077286    
2024-04-24 02:04:33,340 - Epoch: [515][  296/  296]    Overall Loss 0.649809    Objective Loss 0.649809    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.073933    
2024-04-24 02:04:33,460 - --- validate (epoch=515)-----------
2024-04-24 02:04:33,460 - 3925 samples (32 per mini-batch)
2024-04-24 02:04:42,827 - Epoch: [515][  100/  123]    Loss 0.641564    Top1 79.312500    Top5 97.843750    
2024-04-24 02:04:44,610 - Epoch: [515][  123/  123]    Loss 0.659586    Top1 78.828025    Top5 97.681529    
2024-04-24 02:04:44,713 - ==> Top1: 78.828    Top5: 97.682    Loss: 0.660

2024-04-24 02:04:44,719 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:04:44,720 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:04:44,756 - 

2024-04-24 02:04:44,756 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:04:55,980 - Epoch: [516][  100/  296]    Overall Loss 0.647924    Objective Loss 0.647924                                        LR 0.000005    Time 0.112197    
2024-04-24 02:05:03,201 - Epoch: [516][  200/  296]    Overall Loss 0.646629    Objective Loss 0.646629                                        LR 0.000005    Time 0.092176    
2024-04-24 02:05:09,466 - Epoch: [516][  296/  296]    Overall Loss 0.643198    Objective Loss 0.643198    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.083431    
2024-04-24 02:05:09,581 - --- validate (epoch=516)-----------
2024-04-24 02:05:09,582 - 3925 samples (32 per mini-batch)
2024-04-24 02:05:19,296 - Epoch: [516][  100/  123]    Loss 0.650767    Top1 79.125000    Top5 97.593750    
2024-04-24 02:05:21,011 - Epoch: [516][  123/  123]    Loss 0.657587    Top1 78.878981    Top5 97.579618    
2024-04-24 02:05:21,140 - ==> Top1: 78.879    Top5: 97.580    Loss: 0.658

2024-04-24 02:05:21,148 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:05:21,148 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:05:21,185 - 

2024-04-24 02:05:21,186 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:05:29,256 - Epoch: [517][  100/  296]    Overall Loss 0.650220    Objective Loss 0.650220                                        LR 0.000005    Time 0.080634    
2024-04-24 02:05:35,520 - Epoch: [517][  200/  296]    Overall Loss 0.660487    Objective Loss 0.660487                                        LR 0.000005    Time 0.071609    
2024-04-24 02:05:42,350 - Epoch: [517][  296/  296]    Overall Loss 0.656914    Objective Loss 0.656914    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.071442    
2024-04-24 02:05:42,480 - --- validate (epoch=517)-----------
2024-04-24 02:05:42,480 - 3925 samples (32 per mini-batch)
2024-04-24 02:05:50,927 - Epoch: [517][  100/  123]    Loss 0.668985    Top1 78.875000    Top5 97.531250    
2024-04-24 02:05:52,634 - Epoch: [517][  123/  123]    Loss 0.660866    Top1 78.929936    Top5 97.554140    
2024-04-24 02:05:52,739 - ==> Top1: 78.930    Top5: 97.554    Loss: 0.661

2024-04-24 02:05:52,748 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:05:52,749 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:05:52,783 - 

2024-04-24 02:05:52,783 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:06:01,236 - Epoch: [518][  100/  296]    Overall Loss 0.653057    Objective Loss 0.653057                                        LR 0.000005    Time 0.084442    
2024-04-24 02:06:08,171 - Epoch: [518][  200/  296]    Overall Loss 0.651192    Objective Loss 0.651192                                        LR 0.000005    Time 0.076870    
2024-04-24 02:06:14,083 - Epoch: [518][  296/  296]    Overall Loss 0.654097    Objective Loss 0.654097    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.071896    
2024-04-24 02:06:14,219 - --- validate (epoch=518)-----------
2024-04-24 02:06:14,220 - 3925 samples (32 per mini-batch)
2024-04-24 02:06:23,767 - Epoch: [518][  100/  123]    Loss 0.661234    Top1 78.875000    Top5 97.500000    
2024-04-24 02:06:25,728 - Epoch: [518][  123/  123]    Loss 0.659783    Top1 78.726115    Top5 97.579618    
2024-04-24 02:06:25,845 - ==> Top1: 78.726    Top5: 97.580    Loss: 0.660

2024-04-24 02:06:25,854 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:06:25,854 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:06:25,894 - 

2024-04-24 02:06:25,894 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:06:35,416 - Epoch: [519][  100/  296]    Overall Loss 0.660186    Objective Loss 0.660186                                        LR 0.000005    Time 0.095157    
2024-04-24 02:06:42,796 - Epoch: [519][  200/  296]    Overall Loss 0.641110    Objective Loss 0.641110                                        LR 0.000005    Time 0.084450    
2024-04-24 02:06:48,390 - Epoch: [519][  296/  296]    Overall Loss 0.652225    Objective Loss 0.652225    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.075943    
2024-04-24 02:06:48,490 - --- validate (epoch=519)-----------
2024-04-24 02:06:48,491 - 3925 samples (32 per mini-batch)
2024-04-24 02:06:57,649 - Epoch: [519][  100/  123]    Loss 0.661442    Top1 79.031250    Top5 97.343750    
2024-04-24 02:06:58,998 - Epoch: [519][  123/  123]    Loss 0.660081    Top1 78.853503    Top5 97.528662    
2024-04-24 02:06:59,070 - ==> Top1: 78.854    Top5: 97.529    Loss: 0.660

2024-04-24 02:06:59,078 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:06:59,079 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:06:59,114 - 

2024-04-24 02:06:59,114 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:07:07,146 - Epoch: [520][  100/  296]    Overall Loss 0.656388    Objective Loss 0.656388                                        LR 0.000005    Time 0.080270    
2024-04-24 02:07:13,254 - Epoch: [520][  200/  296]    Overall Loss 0.650310    Objective Loss 0.650310                                        LR 0.000005    Time 0.070645    
2024-04-24 02:07:19,049 - Epoch: [520][  296/  296]    Overall Loss 0.649979    Objective Loss 0.649979    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.067291    
2024-04-24 02:07:19,172 - --- validate (epoch=520)-----------
2024-04-24 02:07:19,173 - 3925 samples (32 per mini-batch)
2024-04-24 02:07:28,185 - Epoch: [520][  100/  123]    Loss 0.654975    Top1 79.031250    Top5 97.718750    
2024-04-24 02:07:30,199 - Epoch: [520][  123/  123]    Loss 0.660141    Top1 78.726115    Top5 97.681529    
2024-04-24 02:07:30,325 - ==> Top1: 78.726    Top5: 97.682    Loss: 0.660

2024-04-24 02:07:30,334 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:07:30,335 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:07:30,370 - 

2024-04-24 02:07:30,370 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:07:39,279 - Epoch: [521][  100/  296]    Overall Loss 0.688084    Objective Loss 0.688084                                        LR 0.000005    Time 0.089024    
2024-04-24 02:07:45,380 - Epoch: [521][  200/  296]    Overall Loss 0.662626    Objective Loss 0.662626                                        LR 0.000005    Time 0.074987    
2024-04-24 02:07:51,177 - Epoch: [521][  296/  296]    Overall Loss 0.654575    Objective Loss 0.654575    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.070231    
2024-04-24 02:07:51,300 - --- validate (epoch=521)-----------
2024-04-24 02:07:51,300 - 3925 samples (32 per mini-batch)
2024-04-24 02:08:00,810 - Epoch: [521][  100/  123]    Loss 0.650638    Top1 78.875000    Top5 97.656250    
2024-04-24 02:08:02,820 - Epoch: [521][  123/  123]    Loss 0.654570    Top1 78.955414    Top5 97.605096    
2024-04-24 02:08:02,951 - ==> Top1: 78.955    Top5: 97.605    Loss: 0.655

2024-04-24 02:08:02,955 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:08:02,955 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:08:02,981 - 

2024-04-24 02:08:02,981 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:08:10,772 - Epoch: [522][  100/  296]    Overall Loss 0.670806    Objective Loss 0.670806                                        LR 0.000005    Time 0.077852    
2024-04-24 02:08:16,642 - Epoch: [522][  200/  296]    Overall Loss 0.653374    Objective Loss 0.653374                                        LR 0.000005    Time 0.068248    
2024-04-24 02:08:22,179 - Epoch: [522][  296/  296]    Overall Loss 0.655877    Objective Loss 0.655877    Top1 81.967213    Top5 100.000000    LR 0.000005    Time 0.064803    
2024-04-24 02:08:22,316 - --- validate (epoch=522)-----------
2024-04-24 02:08:22,316 - 3925 samples (32 per mini-batch)
2024-04-24 02:08:31,102 - Epoch: [522][  100/  123]    Loss 0.654970    Top1 79.031250    Top5 97.593750    
2024-04-24 02:08:32,862 - Epoch: [522][  123/  123]    Loss 0.661088    Top1 78.878981    Top5 97.554140    
2024-04-24 02:08:32,989 - ==> Top1: 78.879    Top5: 97.554    Loss: 0.661

2024-04-24 02:08:32,997 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:08:32,997 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:08:33,038 - 

2024-04-24 02:08:33,038 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:08:40,563 - Epoch: [523][  100/  296]    Overall Loss 0.661328    Objective Loss 0.661328                                        LR 0.000005    Time 0.075188    
2024-04-24 02:08:46,268 - Epoch: [523][  200/  296]    Overall Loss 0.673982    Objective Loss 0.673982                                        LR 0.000005    Time 0.066090    
2024-04-24 02:08:51,762 - Epoch: [523][  296/  296]    Overall Loss 0.665073    Objective Loss 0.665073    Top1 88.524590    Top5 96.721311    LR 0.000005    Time 0.063196    
2024-04-24 02:08:51,882 - --- validate (epoch=523)-----------
2024-04-24 02:08:51,882 - 3925 samples (32 per mini-batch)
2024-04-24 02:09:00,762 - Epoch: [523][  100/  123]    Loss 0.666789    Top1 78.843750    Top5 97.437500    
2024-04-24 02:09:02,716 - Epoch: [523][  123/  123]    Loss 0.661940    Top1 78.777070    Top5 97.605096    
2024-04-24 02:09:02,836 - ==> Top1: 78.777    Top5: 97.605    Loss: 0.662

2024-04-24 02:09:02,844 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:09:02,844 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:09:02,880 - 

2024-04-24 02:09:02,880 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:09:10,534 - Epoch: [524][  100/  296]    Overall Loss 0.679306    Objective Loss 0.679306                                        LR 0.000005    Time 0.076479    
2024-04-24 02:09:16,571 - Epoch: [524][  200/  296]    Overall Loss 0.659414    Objective Loss 0.659414                                        LR 0.000005    Time 0.068396    
2024-04-24 02:09:22,126 - Epoch: [524][  296/  296]    Overall Loss 0.644050    Objective Loss 0.644050    Top1 86.885246    Top5 98.360656    LR 0.000005    Time 0.064964    
2024-04-24 02:09:22,236 - --- validate (epoch=524)-----------
2024-04-24 02:09:22,237 - 3925 samples (32 per mini-batch)
2024-04-24 02:09:31,112 - Epoch: [524][  100/  123]    Loss 0.662114    Top1 78.718750    Top5 97.593750    
2024-04-24 02:09:32,886 - Epoch: [524][  123/  123]    Loss 0.657101    Top1 78.929936    Top5 97.630573    
2024-04-24 02:09:33,024 - ==> Top1: 78.930    Top5: 97.631    Loss: 0.657

2024-04-24 02:09:33,032 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:09:33,032 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:09:33,067 - 

2024-04-24 02:09:33,067 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:09:40,577 - Epoch: [525][  100/  296]    Overall Loss 0.680301    Objective Loss 0.680301                                        LR 0.000005    Time 0.075045    
2024-04-24 02:09:46,263 - Epoch: [525][  200/  296]    Overall Loss 0.667880    Objective Loss 0.667880                                        LR 0.000005    Time 0.065923    
2024-04-24 02:09:53,110 - Epoch: [525][  296/  296]    Overall Loss 0.656752    Objective Loss 0.656752    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.067658    
2024-04-24 02:09:53,182 - --- validate (epoch=525)-----------
2024-04-24 02:09:53,183 - 3925 samples (32 per mini-batch)
2024-04-24 02:10:01,356 - Epoch: [525][  100/  123]    Loss 0.670912    Top1 78.343750    Top5 97.406250    
2024-04-24 02:10:03,603 - Epoch: [525][  123/  123]    Loss 0.658750    Top1 78.904459    Top5 97.554140    
2024-04-24 02:10:03,710 - ==> Top1: 78.904    Top5: 97.554    Loss: 0.659

2024-04-24 02:10:03,718 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:10:03,719 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:10:03,755 - 

2024-04-24 02:10:03,756 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:10:11,514 - Epoch: [526][  100/  296]    Overall Loss 0.641795    Objective Loss 0.641795                                        LR 0.000005    Time 0.077534    
2024-04-24 02:10:17,240 - Epoch: [526][  200/  296]    Overall Loss 0.649382    Objective Loss 0.649382                                        LR 0.000005    Time 0.067369    
2024-04-24 02:10:24,152 - Epoch: [526][  296/  296]    Overall Loss 0.647797    Objective Loss 0.647797    Top1 70.491803    Top5 100.000000    LR 0.000005    Time 0.068854    
2024-04-24 02:10:24,263 - --- validate (epoch=526)-----------
2024-04-24 02:10:24,264 - 3925 samples (32 per mini-batch)
2024-04-24 02:10:33,433 - Epoch: [526][  100/  123]    Loss 0.650791    Top1 79.093750    Top5 97.718750    
2024-04-24 02:10:35,172 - Epoch: [526][  123/  123]    Loss 0.655059    Top1 78.980892    Top5 97.579618    
2024-04-24 02:10:35,286 - ==> Top1: 78.981    Top5: 97.580    Loss: 0.655

2024-04-24 02:10:35,294 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:10:35,294 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:10:35,329 - 

2024-04-24 02:10:35,329 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:10:43,507 - Epoch: [527][  100/  296]    Overall Loss 0.646968    Objective Loss 0.646968                                        LR 0.000005    Time 0.081708    
2024-04-24 02:10:50,000 - Epoch: [527][  200/  296]    Overall Loss 0.652173    Objective Loss 0.652173                                        LR 0.000005    Time 0.073287    
2024-04-24 02:10:56,213 - Epoch: [527][  296/  296]    Overall Loss 0.648101    Objective Loss 0.648101    Top1 72.131148    Top5 96.721311    LR 0.000005    Time 0.070489    
2024-04-24 02:10:56,318 - --- validate (epoch=527)-----------
2024-04-24 02:10:56,318 - 3925 samples (32 per mini-batch)
2024-04-24 02:11:05,369 - Epoch: [527][  100/  123]    Loss 0.647504    Top1 79.625000    Top5 97.437500    
2024-04-24 02:11:07,881 - Epoch: [527][  123/  123]    Loss 0.656171    Top1 78.955414    Top5 97.477707    
2024-04-24 02:11:07,976 - ==> Top1: 78.955    Top5: 97.478    Loss: 0.656

2024-04-24 02:11:07,984 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:11:07,985 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:11:08,019 - 

2024-04-24 02:11:08,019 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:11:16,980 - Epoch: [528][  100/  296]    Overall Loss 0.646152    Objective Loss 0.646152                                        LR 0.000005    Time 0.089555    
2024-04-24 02:11:24,231 - Epoch: [528][  200/  296]    Overall Loss 0.634054    Objective Loss 0.634054                                        LR 0.000005    Time 0.081010    
2024-04-24 02:11:30,351 - Epoch: [528][  296/  296]    Overall Loss 0.639499    Objective Loss 0.639499    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.075397    
2024-04-24 02:11:30,457 - --- validate (epoch=528)-----------
2024-04-24 02:11:30,458 - 3925 samples (32 per mini-batch)
2024-04-24 02:11:38,757 - Epoch: [528][  100/  123]    Loss 0.665555    Top1 78.812500    Top5 97.218750    
2024-04-24 02:11:40,822 - Epoch: [528][  123/  123]    Loss 0.658899    Top1 78.700637    Top5 97.452229    
2024-04-24 02:11:40,908 - ==> Top1: 78.701    Top5: 97.452    Loss: 0.659

2024-04-24 02:11:40,916 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:11:40,916 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:11:40,951 - 

2024-04-24 02:11:40,952 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:11:50,380 - Epoch: [529][  100/  296]    Overall Loss 0.710815    Objective Loss 0.710815                                        LR 0.000005    Time 0.094227    
2024-04-24 02:11:57,941 - Epoch: [529][  200/  296]    Overall Loss 0.680107    Objective Loss 0.680107                                        LR 0.000005    Time 0.084888    
2024-04-24 02:12:04,904 - Epoch: [529][  296/  296]    Overall Loss 0.670554    Objective Loss 0.670554    Top1 72.131148    Top5 100.000000    LR 0.000005    Time 0.080864    
2024-04-24 02:12:04,993 - --- validate (epoch=529)-----------
2024-04-24 02:12:04,994 - 3925 samples (32 per mini-batch)
2024-04-24 02:12:14,713 - Epoch: [529][  100/  123]    Loss 0.672799    Top1 78.437500    Top5 97.531250    
2024-04-24 02:12:16,701 - Epoch: [529][  123/  123]    Loss 0.656468    Top1 78.751592    Top5 97.630573    
2024-04-24 02:12:16,826 - ==> Top1: 78.752    Top5: 97.631    Loss: 0.656

2024-04-24 02:12:16,834 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:12:16,834 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:12:16,868 - 

2024-04-24 02:12:16,868 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:12:25,220 - Epoch: [530][  100/  296]    Overall Loss 0.644805    Objective Loss 0.644805                                        LR 0.000005    Time 0.083468    
2024-04-24 02:12:33,071 - Epoch: [530][  200/  296]    Overall Loss 0.644763    Objective Loss 0.644763                                        LR 0.000005    Time 0.080956    
2024-04-24 02:12:39,684 - Epoch: [530][  296/  296]    Overall Loss 0.649331    Objective Loss 0.649331    Top1 80.327869    Top5 96.721311    LR 0.000005    Time 0.077025    
2024-04-24 02:12:39,790 - --- validate (epoch=530)-----------
2024-04-24 02:12:39,790 - 3925 samples (32 per mini-batch)
2024-04-24 02:12:48,717 - Epoch: [530][  100/  123]    Loss 0.660733    Top1 79.250000    Top5 97.593750    
2024-04-24 02:12:50,638 - Epoch: [530][  123/  123]    Loss 0.660096    Top1 79.031847    Top5 97.579618    
2024-04-24 02:12:50,790 - ==> Top1: 79.032    Top5: 97.580    Loss: 0.660

2024-04-24 02:12:50,797 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:12:50,797 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:12:50,828 - 

2024-04-24 02:12:50,828 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:12:59,737 - Epoch: [531][  100/  296]    Overall Loss 0.640200    Objective Loss 0.640200                                        LR 0.000005    Time 0.089028    
2024-04-24 02:13:07,738 - Epoch: [531][  200/  296]    Overall Loss 0.636343    Objective Loss 0.636343                                        LR 0.000005    Time 0.084483    
2024-04-24 02:13:15,061 - Epoch: [531][  296/  296]    Overall Loss 0.642103    Objective Loss 0.642103    Top1 77.049180    Top5 93.442623    LR 0.000005    Time 0.081806    
2024-04-24 02:13:15,180 - --- validate (epoch=531)-----------
2024-04-24 02:13:15,181 - 3925 samples (32 per mini-batch)
2024-04-24 02:13:24,564 - Epoch: [531][  100/  123]    Loss 0.650279    Top1 79.250000    Top5 97.468750    
2024-04-24 02:13:26,365 - Epoch: [531][  123/  123]    Loss 0.655219    Top1 79.057325    Top5 97.503185    
2024-04-24 02:13:26,498 - ==> Top1: 79.057    Top5: 97.503    Loss: 0.655

2024-04-24 02:13:26,504 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:13:26,504 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:13:26,539 - 

2024-04-24 02:13:26,539 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:13:35,461 - Epoch: [532][  100/  296]    Overall Loss 0.660552    Objective Loss 0.660552                                        LR 0.000005    Time 0.089156    
2024-04-24 02:13:41,766 - Epoch: [532][  200/  296]    Overall Loss 0.646568    Objective Loss 0.646568                                        LR 0.000005    Time 0.076078    
2024-04-24 02:13:47,798 - Epoch: [532][  296/  296]    Overall Loss 0.650615    Objective Loss 0.650615    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.071769    
2024-04-24 02:13:47,913 - --- validate (epoch=532)-----------
2024-04-24 02:13:47,913 - 3925 samples (32 per mini-batch)
2024-04-24 02:13:59,229 - Epoch: [532][  100/  123]    Loss 0.649527    Top1 78.906250    Top5 97.656250    
2024-04-24 02:14:01,100 - Epoch: [532][  123/  123]    Loss 0.655082    Top1 78.751592    Top5 97.605096    
2024-04-24 02:14:01,224 - ==> Top1: 78.752    Top5: 97.605    Loss: 0.655

2024-04-24 02:14:01,232 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:14:01,233 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:14:01,266 - 

2024-04-24 02:14:01,267 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:14:09,020 - Epoch: [533][  100/  296]    Overall Loss 0.625154    Objective Loss 0.625154                                        LR 0.000005    Time 0.077476    
2024-04-24 02:14:16,659 - Epoch: [533][  200/  296]    Overall Loss 0.635638    Objective Loss 0.635638                                        LR 0.000005    Time 0.076909    
2024-04-24 02:14:22,607 - Epoch: [533][  296/  296]    Overall Loss 0.639733    Objective Loss 0.639733    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.072045    
2024-04-24 02:14:22,734 - --- validate (epoch=533)-----------
2024-04-24 02:14:22,735 - 3925 samples (32 per mini-batch)
2024-04-24 02:14:31,207 - Epoch: [533][  100/  123]    Loss 0.650802    Top1 78.781250    Top5 97.750000    
2024-04-24 02:14:33,243 - Epoch: [533][  123/  123]    Loss 0.657741    Top1 78.802548    Top5 97.579618    
2024-04-24 02:14:33,352 - ==> Top1: 78.803    Top5: 97.580    Loss: 0.658

2024-04-24 02:14:33,360 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:14:33,361 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:14:33,396 - 

2024-04-24 02:14:33,396 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:14:41,540 - Epoch: [534][  100/  296]    Overall Loss 0.661237    Objective Loss 0.661237                                        LR 0.000005    Time 0.081380    
2024-04-24 02:14:48,632 - Epoch: [534][  200/  296]    Overall Loss 0.676559    Objective Loss 0.676559                                        LR 0.000005    Time 0.076128    
2024-04-24 02:14:54,658 - Epoch: [534][  296/  296]    Overall Loss 0.667167    Objective Loss 0.667167    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.071777    
2024-04-24 02:14:54,776 - --- validate (epoch=534)-----------
2024-04-24 02:14:54,777 - 3925 samples (32 per mini-batch)
2024-04-24 02:15:03,051 - Epoch: [534][  100/  123]    Loss 0.659614    Top1 79.125000    Top5 97.593750    
2024-04-24 02:15:04,626 - Epoch: [534][  123/  123]    Loss 0.654874    Top1 78.853503    Top5 97.579618    
2024-04-24 02:15:04,791 - ==> Top1: 78.854    Top5: 97.580    Loss: 0.655

2024-04-24 02:15:04,801 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:15:04,802 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:15:04,837 - 

2024-04-24 02:15:04,837 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:15:13,562 - Epoch: [535][  100/  296]    Overall Loss 0.658371    Objective Loss 0.658371                                        LR 0.000005    Time 0.087194    
2024-04-24 02:15:21,037 - Epoch: [535][  200/  296]    Overall Loss 0.652794    Objective Loss 0.652794                                        LR 0.000005    Time 0.080948    
2024-04-24 02:15:28,417 - Epoch: [535][  296/  296]    Overall Loss 0.660640    Objective Loss 0.660640    Top1 65.573770    Top5 100.000000    LR 0.000005    Time 0.079612    
2024-04-24 02:15:28,546 - --- validate (epoch=535)-----------
2024-04-24 02:15:28,547 - 3925 samples (32 per mini-batch)
2024-04-24 02:15:38,425 - Epoch: [535][  100/  123]    Loss 0.651180    Top1 78.656250    Top5 97.656250    
2024-04-24 02:15:40,662 - Epoch: [535][  123/  123]    Loss 0.662284    Top1 78.598726    Top5 97.503185    
2024-04-24 02:15:40,780 - ==> Top1: 78.599    Top5: 97.503    Loss: 0.662

2024-04-24 02:15:40,788 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:15:40,789 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:15:40,823 - 

2024-04-24 02:15:40,824 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:15:48,847 - Epoch: [536][  100/  296]    Overall Loss 0.656350    Objective Loss 0.656350                                        LR 0.000005    Time 0.080188    
2024-04-24 02:15:55,962 - Epoch: [536][  200/  296]    Overall Loss 0.663325    Objective Loss 0.663325                                        LR 0.000005    Time 0.075644    
2024-04-24 02:16:02,493 - Epoch: [536][  296/  296]    Overall Loss 0.660730    Objective Loss 0.660730    Top1 85.245902    Top5 96.721311    LR 0.000005    Time 0.073163    
2024-04-24 02:16:02,584 - --- validate (epoch=536)-----------
2024-04-24 02:16:02,585 - 3925 samples (32 per mini-batch)
2024-04-24 02:16:12,032 - Epoch: [536][  100/  123]    Loss 0.664457    Top1 78.937500    Top5 97.500000    
2024-04-24 02:16:14,078 - Epoch: [536][  123/  123]    Loss 0.655926    Top1 78.929936    Top5 97.656051    
2024-04-24 02:16:14,226 - ==> Top1: 78.930    Top5: 97.656    Loss: 0.656

2024-04-24 02:16:14,235 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:16:14,235 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:16:14,271 - 

2024-04-24 02:16:14,271 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:16:23,811 - Epoch: [537][  100/  296]    Overall Loss 0.646404    Objective Loss 0.646404                                        LR 0.000005    Time 0.095337    
2024-04-24 02:16:29,818 - Epoch: [537][  200/  296]    Overall Loss 0.655820    Objective Loss 0.655820                                        LR 0.000005    Time 0.077672    
2024-04-24 02:16:35,341 - Epoch: [537][  296/  296]    Overall Loss 0.656587    Objective Loss 0.656587    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.071123    
2024-04-24 02:16:35,466 - --- validate (epoch=537)-----------
2024-04-24 02:16:35,467 - 3925 samples (32 per mini-batch)
2024-04-24 02:16:46,497 - Epoch: [537][  100/  123]    Loss 0.672510    Top1 78.468750    Top5 97.531250    
2024-04-24 02:16:48,445 - Epoch: [537][  123/  123]    Loss 0.660449    Top1 78.777070    Top5 97.605096    
2024-04-24 02:16:48,579 - ==> Top1: 78.777    Top5: 97.605    Loss: 0.660

2024-04-24 02:16:48,589 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:16:48,590 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:16:48,625 - 

2024-04-24 02:16:48,625 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:16:56,087 - Epoch: [538][  100/  296]    Overall Loss 0.662540    Objective Loss 0.662540                                        LR 0.000005    Time 0.074558    
2024-04-24 02:17:02,530 - Epoch: [538][  200/  296]    Overall Loss 0.649170    Objective Loss 0.649170                                        LR 0.000005    Time 0.069463    
2024-04-24 02:17:08,641 - Epoch: [538][  296/  296]    Overall Loss 0.643176    Objective Loss 0.643176    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.067563    
2024-04-24 02:17:08,749 - --- validate (epoch=538)-----------
2024-04-24 02:17:08,749 - 3925 samples (32 per mini-batch)
2024-04-24 02:17:17,346 - Epoch: [538][  100/  123]    Loss 0.644730    Top1 79.375000    Top5 97.875000    
2024-04-24 02:17:19,103 - Epoch: [538][  123/  123]    Loss 0.656353    Top1 79.031847    Top5 97.656051    
2024-04-24 02:17:19,238 - ==> Top1: 79.032    Top5: 97.656    Loss: 0.656

2024-04-24 02:17:19,249 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:17:19,249 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:17:19,285 - 

2024-04-24 02:17:19,285 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:17:27,957 - Epoch: [539][  100/  296]    Overall Loss 0.664132    Objective Loss 0.664132                                        LR 0.000005    Time 0.086643    
2024-04-24 02:17:34,435 - Epoch: [539][  200/  296]    Overall Loss 0.645869    Objective Loss 0.645869                                        LR 0.000005    Time 0.075677    
2024-04-24 02:17:40,931 - Epoch: [539][  296/  296]    Overall Loss 0.656650    Objective Loss 0.656650    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.073059    
2024-04-24 02:17:41,050 - --- validate (epoch=539)-----------
2024-04-24 02:17:41,051 - 3925 samples (32 per mini-batch)
2024-04-24 02:17:49,931 - Epoch: [539][  100/  123]    Loss 0.654412    Top1 78.875000    Top5 97.718750    
2024-04-24 02:17:51,947 - Epoch: [539][  123/  123]    Loss 0.662723    Top1 78.751592    Top5 97.554140    
2024-04-24 02:17:52,064 - ==> Top1: 78.752    Top5: 97.554    Loss: 0.663

2024-04-24 02:17:52,072 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:17:52,072 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:17:52,107 - 

2024-04-24 02:17:52,108 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:18:02,126 - Epoch: [540][  100/  296]    Overall Loss 0.630167    Objective Loss 0.630167                                        LR 0.000005    Time 0.100111    
2024-04-24 02:18:09,980 - Epoch: [540][  200/  296]    Overall Loss 0.641982    Objective Loss 0.641982                                        LR 0.000005    Time 0.089283    
2024-04-24 02:18:17,026 - Epoch: [540][  296/  296]    Overall Loss 0.647095    Objective Loss 0.647095    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.084112    
2024-04-24 02:18:17,126 - --- validate (epoch=540)-----------
2024-04-24 02:18:17,126 - 3925 samples (32 per mini-batch)
2024-04-24 02:18:28,675 - Epoch: [540][  100/  123]    Loss 0.657017    Top1 79.000000    Top5 97.718750    
2024-04-24 02:18:30,713 - Epoch: [540][  123/  123]    Loss 0.664413    Top1 78.675159    Top5 97.477707    
2024-04-24 02:18:30,838 - ==> Top1: 78.675    Top5: 97.478    Loss: 0.664

2024-04-24 02:18:30,846 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:18:30,846 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:18:30,882 - 

2024-04-24 02:18:30,882 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:18:38,414 - Epoch: [541][  100/  296]    Overall Loss 0.616191    Objective Loss 0.616191                                        LR 0.000005    Time 0.075258    
2024-04-24 02:18:44,464 - Epoch: [541][  200/  296]    Overall Loss 0.612777    Objective Loss 0.612777                                        LR 0.000005    Time 0.067851    
2024-04-24 02:18:50,209 - Epoch: [541][  296/  296]    Overall Loss 0.623431    Objective Loss 0.623431    Top1 75.409836    Top5 100.000000    LR 0.000005    Time 0.065236    
2024-04-24 02:18:50,320 - --- validate (epoch=541)-----------
2024-04-24 02:18:50,321 - 3925 samples (32 per mini-batch)
2024-04-24 02:18:58,221 - Epoch: [541][  100/  123]    Loss 0.656534    Top1 78.906250    Top5 97.656250    
2024-04-24 02:18:59,772 - Epoch: [541][  123/  123]    Loss 0.657104    Top1 79.057325    Top5 97.630573    
2024-04-24 02:18:59,899 - ==> Top1: 79.057    Top5: 97.631    Loss: 0.657

2024-04-24 02:18:59,907 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:18:59,907 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:18:59,941 - 

2024-04-24 02:18:59,941 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:19:09,775 - Epoch: [542][  100/  296]    Overall Loss 0.628020    Objective Loss 0.628020                                        LR 0.000005    Time 0.098281    
2024-04-24 02:19:19,174 - Epoch: [542][  200/  296]    Overall Loss 0.644234    Objective Loss 0.644234                                        LR 0.000005    Time 0.096111    
2024-04-24 02:19:26,278 - Epoch: [542][  296/  296]    Overall Loss 0.646797    Objective Loss 0.646797    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.088926    
2024-04-24 02:19:26,409 - --- validate (epoch=542)-----------
2024-04-24 02:19:26,409 - 3925 samples (32 per mini-batch)
2024-04-24 02:19:34,791 - Epoch: [542][  100/  123]    Loss 0.635859    Top1 79.437500    Top5 97.562500    
2024-04-24 02:19:36,637 - Epoch: [542][  123/  123]    Loss 0.656742    Top1 79.082803    Top5 97.528662    
2024-04-24 02:19:36,765 - ==> Top1: 79.083    Top5: 97.529    Loss: 0.657

2024-04-24 02:19:36,774 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:19:36,774 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:19:36,809 - 

2024-04-24 02:19:36,809 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:19:45,281 - Epoch: [543][  100/  296]    Overall Loss 0.674405    Objective Loss 0.674405                                        LR 0.000005    Time 0.084664    
2024-04-24 02:19:51,925 - Epoch: [543][  200/  296]    Overall Loss 0.671645    Objective Loss 0.671645                                        LR 0.000005    Time 0.075524    
2024-04-24 02:19:57,848 - Epoch: [543][  296/  296]    Overall Loss 0.664119    Objective Loss 0.664119    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.071018    
2024-04-24 02:19:57,980 - --- validate (epoch=543)-----------
2024-04-24 02:19:57,981 - 3925 samples (32 per mini-batch)
2024-04-24 02:20:09,345 - Epoch: [543][  100/  123]    Loss 0.656028    Top1 79.218750    Top5 97.593750    
2024-04-24 02:20:11,284 - Epoch: [543][  123/  123]    Loss 0.656905    Top1 79.006369    Top5 97.528662    
2024-04-24 02:20:11,428 - ==> Top1: 79.006    Top5: 97.529    Loss: 0.657

2024-04-24 02:20:11,436 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:20:11,436 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:20:11,472 - 

2024-04-24 02:20:11,472 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:20:22,082 - Epoch: [544][  100/  296]    Overall Loss 0.658349    Objective Loss 0.658349                                        LR 0.000005    Time 0.106026    
2024-04-24 02:20:30,208 - Epoch: [544][  200/  296]    Overall Loss 0.650819    Objective Loss 0.650819                                        LR 0.000005    Time 0.093605    
2024-04-24 02:20:37,040 - Epoch: [544][  296/  296]    Overall Loss 0.653078    Objective Loss 0.653078    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.086307    
2024-04-24 02:20:37,187 - --- validate (epoch=544)-----------
2024-04-24 02:20:37,188 - 3925 samples (32 per mini-batch)
2024-04-24 02:20:48,023 - Epoch: [544][  100/  123]    Loss 0.658582    Top1 78.750000    Top5 97.562500    
2024-04-24 02:20:49,775 - Epoch: [544][  123/  123]    Loss 0.657282    Top1 78.980892    Top5 97.579618    
2024-04-24 02:20:49,912 - ==> Top1: 78.981    Top5: 97.580    Loss: 0.657

2024-04-24 02:20:49,920 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:20:49,920 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:20:49,956 - 

2024-04-24 02:20:49,956 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:20:58,584 - Epoch: [545][  100/  296]    Overall Loss 0.649524    Objective Loss 0.649524                                        LR 0.000005    Time 0.086219    
2024-04-24 02:21:05,027 - Epoch: [545][  200/  296]    Overall Loss 0.652438    Objective Loss 0.652438                                        LR 0.000005    Time 0.075297    
2024-04-24 02:21:10,546 - Epoch: [545][  296/  296]    Overall Loss 0.644437    Objective Loss 0.644437    Top1 83.606557    Top5 95.081967    LR 0.000005    Time 0.069500    
2024-04-24 02:21:10,654 - --- validate (epoch=545)-----------
2024-04-24 02:21:10,655 - 3925 samples (32 per mini-batch)
2024-04-24 02:21:20,524 - Epoch: [545][  100/  123]    Loss 0.657660    Top1 79.000000    Top5 97.500000    
2024-04-24 02:21:22,771 - Epoch: [545][  123/  123]    Loss 0.656397    Top1 78.904459    Top5 97.528662    
2024-04-24 02:21:22,905 - ==> Top1: 78.904    Top5: 97.529    Loss: 0.656

2024-04-24 02:21:22,914 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:21:22,914 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:21:22,951 - 

2024-04-24 02:21:22,951 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:21:31,099 - Epoch: [546][  100/  296]    Overall Loss 0.658181    Objective Loss 0.658181                                        LR 0.000005    Time 0.081427    
2024-04-24 02:21:37,998 - Epoch: [546][  200/  296]    Overall Loss 0.657723    Objective Loss 0.657723                                        LR 0.000005    Time 0.075179    
2024-04-24 02:21:44,541 - Epoch: [546][  296/  296]    Overall Loss 0.666500    Objective Loss 0.666500    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.072883    
2024-04-24 02:21:44,632 - --- validate (epoch=546)-----------
2024-04-24 02:21:44,632 - 3925 samples (32 per mini-batch)
2024-04-24 02:21:53,560 - Epoch: [546][  100/  123]    Loss 0.667776    Top1 78.531250    Top5 97.500000    
2024-04-24 02:21:55,475 - Epoch: [546][  123/  123]    Loss 0.657155    Top1 78.955414    Top5 97.579618    
2024-04-24 02:21:55,552 - ==> Top1: 78.955    Top5: 97.580    Loss: 0.657

2024-04-24 02:21:55,561 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:21:55,561 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:21:55,594 - 

2024-04-24 02:21:55,594 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:22:03,566 - Epoch: [547][  100/  296]    Overall Loss 0.636856    Objective Loss 0.636856                                        LR 0.000005    Time 0.079666    
2024-04-24 02:22:09,869 - Epoch: [547][  200/  296]    Overall Loss 0.656229    Objective Loss 0.656229                                        LR 0.000005    Time 0.071307    
2024-04-24 02:22:15,711 - Epoch: [547][  296/  296]    Overall Loss 0.657813    Objective Loss 0.657813    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.067897    
2024-04-24 02:22:15,827 - --- validate (epoch=547)-----------
2024-04-24 02:22:15,828 - 3925 samples (32 per mini-batch)
2024-04-24 02:22:25,110 - Epoch: [547][  100/  123]    Loss 0.666767    Top1 78.500000    Top5 97.468750    
2024-04-24 02:22:26,772 - Epoch: [547][  123/  123]    Loss 0.661840    Top1 78.802548    Top5 97.579618    
2024-04-24 02:22:26,873 - ==> Top1: 78.803    Top5: 97.580    Loss: 0.662

2024-04-24 02:22:26,881 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:22:26,882 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:22:26,916 - 

2024-04-24 02:22:26,916 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:22:35,345 - Epoch: [548][  100/  296]    Overall Loss 0.625133    Objective Loss 0.625133                                        LR 0.000005    Time 0.084236    
2024-04-24 02:22:41,556 - Epoch: [548][  200/  296]    Overall Loss 0.640624    Objective Loss 0.640624                                        LR 0.000005    Time 0.073147    
2024-04-24 02:22:47,770 - Epoch: [548][  296/  296]    Overall Loss 0.645589    Objective Loss 0.645589    Top1 81.967213    Top5 95.081967    LR 0.000005    Time 0.070403    
2024-04-24 02:22:47,873 - --- validate (epoch=548)-----------
2024-04-24 02:22:47,874 - 3925 samples (32 per mini-batch)
2024-04-24 02:22:57,004 - Epoch: [548][  100/  123]    Loss 0.646522    Top1 79.468750    Top5 97.687500    
2024-04-24 02:22:58,685 - Epoch: [548][  123/  123]    Loss 0.659728    Top1 78.955414    Top5 97.528662    
2024-04-24 02:22:58,790 - ==> Top1: 78.955    Top5: 97.529    Loss: 0.660

2024-04-24 02:22:58,798 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:22:58,799 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:22:58,832 - 

2024-04-24 02:22:58,833 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:23:06,937 - Epoch: [549][  100/  296]    Overall Loss 0.636958    Objective Loss 0.636958                                        LR 0.000005    Time 0.080997    
2024-04-24 02:23:13,818 - Epoch: [549][  200/  296]    Overall Loss 0.636201    Objective Loss 0.636201                                        LR 0.000005    Time 0.074885    
2024-04-24 02:23:19,555 - Epoch: [549][  296/  296]    Overall Loss 0.629600    Objective Loss 0.629600    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.069968    
2024-04-24 02:23:19,626 - --- validate (epoch=549)-----------
2024-04-24 02:23:19,627 - 3925 samples (32 per mini-batch)
2024-04-24 02:23:28,886 - Epoch: [549][  100/  123]    Loss 0.660571    Top1 79.000000    Top5 97.656250    
2024-04-24 02:23:30,953 - Epoch: [549][  123/  123]    Loss 0.658432    Top1 78.980892    Top5 97.630573    
2024-04-24 02:23:31,055 - ==> Top1: 78.981    Top5: 97.631    Loss: 0.658

2024-04-24 02:23:31,064 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:23:31,064 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:23:31,096 - 

2024-04-24 02:23:31,097 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:23:38,671 - Epoch: [550][  100/  296]    Overall Loss 0.638914    Objective Loss 0.638914                                        LR 0.000005    Time 0.075685    
2024-04-24 02:23:45,295 - Epoch: [550][  200/  296]    Overall Loss 0.656021    Objective Loss 0.656021                                        LR 0.000005    Time 0.070940    
2024-04-24 02:23:51,340 - Epoch: [550][  296/  296]    Overall Loss 0.652760    Objective Loss 0.652760    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.068339    
2024-04-24 02:23:51,423 - --- validate (epoch=550)-----------
2024-04-24 02:23:51,423 - 3925 samples (32 per mini-batch)
2024-04-24 02:24:00,193 - Epoch: [550][  100/  123]    Loss 0.670970    Top1 78.406250    Top5 97.312500    
2024-04-24 02:24:02,267 - Epoch: [550][  123/  123]    Loss 0.658711    Top1 78.700637    Top5 97.477707    
2024-04-24 02:24:02,397 - ==> Top1: 78.701    Top5: 97.478    Loss: 0.659

2024-04-24 02:24:02,405 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:24:02,405 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:24:02,444 - 

2024-04-24 02:24:02,444 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:24:10,390 - Epoch: [551][  100/  296]    Overall Loss 0.688635    Objective Loss 0.688635                                        LR 0.000005    Time 0.079397    
2024-04-24 02:24:17,658 - Epoch: [551][  200/  296]    Overall Loss 0.676383    Objective Loss 0.676383                                        LR 0.000005    Time 0.076012    
2024-04-24 02:24:23,473 - Epoch: [551][  296/  296]    Overall Loss 0.658510    Objective Loss 0.658510    Top1 81.967213    Top5 96.721311    LR 0.000005    Time 0.070983    
2024-04-24 02:24:23,605 - --- validate (epoch=551)-----------
2024-04-24 02:24:23,606 - 3925 samples (32 per mini-batch)
2024-04-24 02:24:33,662 - Epoch: [551][  100/  123]    Loss 0.645580    Top1 79.312500    Top5 97.562500    
2024-04-24 02:24:35,650 - Epoch: [551][  123/  123]    Loss 0.660243    Top1 78.929936    Top5 97.528662    
2024-04-24 02:24:35,775 - ==> Top1: 78.930    Top5: 97.529    Loss: 0.660

2024-04-24 02:24:35,784 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:24:35,784 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:24:35,819 - 

2024-04-24 02:24:35,820 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:24:44,360 - Epoch: [552][  100/  296]    Overall Loss 0.663301    Objective Loss 0.663301                                        LR 0.000005    Time 0.085349    
2024-04-24 02:24:50,155 - Epoch: [552][  200/  296]    Overall Loss 0.644153    Objective Loss 0.644153                                        LR 0.000005    Time 0.071619    
2024-04-24 02:24:57,032 - Epoch: [552][  296/  296]    Overall Loss 0.638530    Objective Loss 0.638530    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.071611    
2024-04-24 02:24:57,168 - --- validate (epoch=552)-----------
2024-04-24 02:24:57,169 - 3925 samples (32 per mini-batch)
2024-04-24 02:25:06,243 - Epoch: [552][  100/  123]    Loss 0.658031    Top1 78.812500    Top5 97.718750    
2024-04-24 02:25:08,216 - Epoch: [552][  123/  123]    Loss 0.657907    Top1 78.904459    Top5 97.656051    
2024-04-24 02:25:08,335 - ==> Top1: 78.904    Top5: 97.656    Loss: 0.658

2024-04-24 02:25:08,343 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:25:08,343 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:25:08,379 - 

2024-04-24 02:25:08,379 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:25:16,591 - Epoch: [553][  100/  296]    Overall Loss 0.657383    Objective Loss 0.657383                                        LR 0.000005    Time 0.082056    
2024-04-24 02:25:24,574 - Epoch: [553][  200/  296]    Overall Loss 0.660902    Objective Loss 0.660902                                        LR 0.000005    Time 0.080910    
2024-04-24 02:25:30,951 - Epoch: [553][  296/  296]    Overall Loss 0.649630    Objective Loss 0.649630    Top1 72.131148    Top5 95.081967    LR 0.000005    Time 0.076193    
2024-04-24 02:25:31,056 - --- validate (epoch=553)-----------
2024-04-24 02:25:31,057 - 3925 samples (32 per mini-batch)
2024-04-24 02:25:39,977 - Epoch: [553][  100/  123]    Loss 0.657244    Top1 78.875000    Top5 97.375000    
2024-04-24 02:25:42,021 - Epoch: [553][  123/  123]    Loss 0.659379    Top1 78.904459    Top5 97.528662    
2024-04-24 02:25:42,145 - ==> Top1: 78.904    Top5: 97.529    Loss: 0.659

2024-04-24 02:25:42,156 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:25:42,156 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:25:42,191 - 

2024-04-24 02:25:42,191 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:25:50,548 - Epoch: [554][  100/  296]    Overall Loss 0.632729    Objective Loss 0.632729                                        LR 0.000005    Time 0.083505    
2024-04-24 02:25:56,388 - Epoch: [554][  200/  296]    Overall Loss 0.652600    Objective Loss 0.652600                                        LR 0.000005    Time 0.070924    
2024-04-24 02:26:02,161 - Epoch: [554][  296/  296]    Overall Loss 0.650174    Objective Loss 0.650174    Top1 72.131148    Top5 90.163934    LR 0.000005    Time 0.067408    
2024-04-24 02:26:02,266 - --- validate (epoch=554)-----------
2024-04-24 02:26:02,267 - 3925 samples (32 per mini-batch)
2024-04-24 02:26:10,219 - Epoch: [554][  100/  123]    Loss 0.657895    Top1 79.281250    Top5 97.562500    
2024-04-24 02:26:12,237 - Epoch: [554][  123/  123]    Loss 0.663290    Top1 78.878981    Top5 97.605096    
2024-04-24 02:26:12,317 - ==> Top1: 78.879    Top5: 97.605    Loss: 0.663

2024-04-24 02:26:12,321 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:26:12,321 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:26:12,345 - 

2024-04-24 02:26:12,345 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:26:20,142 - Epoch: [555][  100/  296]    Overall Loss 0.670376    Objective Loss 0.670376                                        LR 0.000005    Time 0.077914    
2024-04-24 02:26:26,733 - Epoch: [555][  200/  296]    Overall Loss 0.677237    Objective Loss 0.677237                                        LR 0.000005    Time 0.071888    
2024-04-24 02:26:33,831 - Epoch: [555][  296/  296]    Overall Loss 0.662730    Objective Loss 0.662730    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.072537    
2024-04-24 02:26:33,914 - --- validate (epoch=555)-----------
2024-04-24 02:26:33,915 - 3925 samples (32 per mini-batch)
2024-04-24 02:26:44,316 - Epoch: [555][  100/  123]    Loss 0.668439    Top1 79.125000    Top5 97.343750    
2024-04-24 02:26:46,356 - Epoch: [555][  123/  123]    Loss 0.657264    Top1 79.210191    Top5 97.477707    
2024-04-24 02:26:46,448 - ==> Top1: 79.210    Top5: 97.478    Loss: 0.657

2024-04-24 02:26:46,456 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:26:46,456 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:26:46,493 - 

2024-04-24 02:26:46,493 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:26:55,236 - Epoch: [556][  100/  296]    Overall Loss 0.657702    Objective Loss 0.657702                                        LR 0.000005    Time 0.087374    
2024-04-24 02:27:02,240 - Epoch: [556][  200/  296]    Overall Loss 0.658689    Objective Loss 0.658689                                        LR 0.000005    Time 0.078680    
2024-04-24 02:27:07,904 - Epoch: [556][  296/  296]    Overall Loss 0.652774    Objective Loss 0.652774    Top1 80.327869    Top5 100.000000    LR 0.000005    Time 0.072278    
2024-04-24 02:27:08,035 - --- validate (epoch=556)-----------
2024-04-24 02:27:08,036 - 3925 samples (32 per mini-batch)
2024-04-24 02:27:17,245 - Epoch: [556][  100/  123]    Loss 0.664419    Top1 78.562500    Top5 97.375000    
2024-04-24 02:27:19,464 - Epoch: [556][  123/  123]    Loss 0.659858    Top1 79.057325    Top5 97.528662    
2024-04-24 02:27:19,543 - ==> Top1: 79.057    Top5: 97.529    Loss: 0.660

2024-04-24 02:27:19,552 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:27:19,552 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:27:19,587 - 

2024-04-24 02:27:19,587 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:27:28,086 - Epoch: [557][  100/  296]    Overall Loss 0.634935    Objective Loss 0.634935                                        LR 0.000005    Time 0.084939    
2024-04-24 02:27:35,420 - Epoch: [557][  200/  296]    Overall Loss 0.648160    Objective Loss 0.648160                                        LR 0.000005    Time 0.079108    
2024-04-24 02:27:42,300 - Epoch: [557][  296/  296]    Overall Loss 0.649421    Objective Loss 0.649421    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.076679    
2024-04-24 02:27:42,431 - --- validate (epoch=557)-----------
2024-04-24 02:27:42,432 - 3925 samples (32 per mini-batch)
2024-04-24 02:27:52,670 - Epoch: [557][  100/  123]    Loss 0.662765    Top1 79.062500    Top5 97.468750    
2024-04-24 02:27:55,114 - Epoch: [557][  123/  123]    Loss 0.657804    Top1 79.108280    Top5 97.503185    
2024-04-24 02:27:55,244 - ==> Top1: 79.108    Top5: 97.503    Loss: 0.658

2024-04-24 02:27:55,252 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:27:55,253 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:27:55,288 - 

2024-04-24 02:27:55,288 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:28:02,570 - Epoch: [558][  100/  296]    Overall Loss 0.653963    Objective Loss 0.653963                                        LR 0.000005    Time 0.072766    
2024-04-24 02:28:08,702 - Epoch: [558][  200/  296]    Overall Loss 0.655280    Objective Loss 0.655280                                        LR 0.000005    Time 0.067012    
2024-04-24 02:28:14,030 - Epoch: [558][  296/  296]    Overall Loss 0.654742    Objective Loss 0.654742    Top1 70.491803    Top5 100.000000    LR 0.000005    Time 0.063263    
2024-04-24 02:28:14,167 - --- validate (epoch=558)-----------
2024-04-24 02:28:14,168 - 3925 samples (32 per mini-batch)
2024-04-24 02:28:23,253 - Epoch: [558][  100/  123]    Loss 0.641798    Top1 79.156250    Top5 97.718750    
2024-04-24 02:28:24,914 - Epoch: [558][  123/  123]    Loss 0.652931    Top1 79.082803    Top5 97.630573    
2024-04-24 02:28:25,026 - ==> Top1: 79.083    Top5: 97.631    Loss: 0.653

2024-04-24 02:28:25,035 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:28:25,035 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:28:25,079 - 

2024-04-24 02:28:25,080 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:28:35,532 - Epoch: [559][  100/  296]    Overall Loss 0.686225    Objective Loss 0.686225                                        LR 0.000005    Time 0.104462    
2024-04-24 02:28:43,156 - Epoch: [559][  200/  296]    Overall Loss 0.667065    Objective Loss 0.667065                                        LR 0.000005    Time 0.090332    
2024-04-24 02:28:50,579 - Epoch: [559][  296/  296]    Overall Loss 0.647028    Objective Loss 0.647028    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.086097    
2024-04-24 02:28:50,709 - --- validate (epoch=559)-----------
2024-04-24 02:28:50,710 - 3925 samples (32 per mini-batch)
2024-04-24 02:28:59,229 - Epoch: [559][  100/  123]    Loss 0.653236    Top1 78.625000    Top5 97.625000    
2024-04-24 02:29:01,137 - Epoch: [559][  123/  123]    Loss 0.659742    Top1 78.751592    Top5 97.605096    
2024-04-24 02:29:01,269 - ==> Top1: 78.752    Top5: 97.605    Loss: 0.660

2024-04-24 02:29:01,279 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:29:01,279 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:29:01,314 - 

2024-04-24 02:29:01,314 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:29:09,135 - Epoch: [560][  100/  296]    Overall Loss 0.625153    Objective Loss 0.625153                                        LR 0.000005    Time 0.078158    
2024-04-24 02:29:15,601 - Epoch: [560][  200/  296]    Overall Loss 0.637010    Objective Loss 0.637010                                        LR 0.000005    Time 0.071386    
2024-04-24 02:29:22,459 - Epoch: [560][  296/  296]    Overall Loss 0.636185    Objective Loss 0.636185    Top1 88.524590    Top5 100.000000    LR 0.000005    Time 0.071385    
2024-04-24 02:29:22,562 - --- validate (epoch=560)-----------
2024-04-24 02:29:22,563 - 3925 samples (32 per mini-batch)
2024-04-24 02:29:30,360 - Epoch: [560][  100/  123]    Loss 0.669360    Top1 78.625000    Top5 97.500000    
2024-04-24 02:29:31,773 - Epoch: [560][  123/  123]    Loss 0.660975    Top1 78.955414    Top5 97.554140    
2024-04-24 02:29:31,899 - ==> Top1: 78.955    Top5: 97.554    Loss: 0.661

2024-04-24 02:29:31,907 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:29:31,907 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:29:31,944 - 

2024-04-24 02:29:31,944 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:29:39,832 - Epoch: [561][  100/  296]    Overall Loss 0.645243    Objective Loss 0.645243                                        LR 0.000005    Time 0.078816    
2024-04-24 02:29:46,295 - Epoch: [561][  200/  296]    Overall Loss 0.642279    Objective Loss 0.642279                                        LR 0.000005    Time 0.071694    
2024-04-24 02:29:52,427 - Epoch: [561][  296/  296]    Overall Loss 0.649284    Objective Loss 0.649284    Top1 80.327869    Top5 98.360656    LR 0.000005    Time 0.069141    
2024-04-24 02:29:52,581 - --- validate (epoch=561)-----------
2024-04-24 02:29:52,581 - 3925 samples (32 per mini-batch)
2024-04-24 02:30:00,823 - Epoch: [561][  100/  123]    Loss 0.652886    Top1 78.843750    Top5 97.562500    
2024-04-24 02:30:02,882 - Epoch: [561][  123/  123]    Loss 0.659475    Top1 78.573248    Top5 97.528662    
2024-04-24 02:30:02,958 - ==> Top1: 78.573    Top5: 97.529    Loss: 0.659

2024-04-24 02:30:02,967 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:30:02,967 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:30:03,008 - 

2024-04-24 02:30:03,009 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:30:11,496 - Epoch: [562][  100/  296]    Overall Loss 0.632279    Objective Loss 0.632279                                        LR 0.000005    Time 0.084816    
2024-04-24 02:30:18,417 - Epoch: [562][  200/  296]    Overall Loss 0.638056    Objective Loss 0.638056                                        LR 0.000005    Time 0.076989    
2024-04-24 02:30:25,275 - Epoch: [562][  296/  296]    Overall Loss 0.647480    Objective Loss 0.647480    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.075169    
2024-04-24 02:30:25,423 - --- validate (epoch=562)-----------
2024-04-24 02:30:25,423 - 3925 samples (32 per mini-batch)
2024-04-24 02:30:36,226 - Epoch: [562][  100/  123]    Loss 0.658513    Top1 79.187500    Top5 97.406250    
2024-04-24 02:30:37,995 - Epoch: [562][  123/  123]    Loss 0.660037    Top1 78.828025    Top5 97.401274    
2024-04-24 02:30:38,116 - ==> Top1: 78.828    Top5: 97.401    Loss: 0.660

2024-04-24 02:30:38,124 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:30:38,124 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:30:38,161 - 

2024-04-24 02:30:38,161 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:30:45,584 - Epoch: [563][  100/  296]    Overall Loss 0.642394    Objective Loss 0.642394                                        LR 0.000005    Time 0.074167    
2024-04-24 02:30:52,030 - Epoch: [563][  200/  296]    Overall Loss 0.634722    Objective Loss 0.634722                                        LR 0.000005    Time 0.069269    
2024-04-24 02:30:57,978 - Epoch: [563][  296/  296]    Overall Loss 0.637650    Objective Loss 0.637650    Top1 88.524590    Top5 98.360656    LR 0.000005    Time 0.066881    
2024-04-24 02:30:58,136 - --- validate (epoch=563)-----------
2024-04-24 02:30:58,137 - 3925 samples (32 per mini-batch)
2024-04-24 02:31:06,923 - Epoch: [563][  100/  123]    Loss 0.655590    Top1 79.156250    Top5 97.843750    
2024-04-24 02:31:08,609 - Epoch: [563][  123/  123]    Loss 0.657834    Top1 78.929936    Top5 97.630573    
2024-04-24 02:31:08,742 - ==> Top1: 78.930    Top5: 97.631    Loss: 0.658

2024-04-24 02:31:08,750 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:31:08,751 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:31:08,785 - 

2024-04-24 02:31:08,786 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:31:16,637 - Epoch: [564][  100/  296]    Overall Loss 0.655983    Objective Loss 0.655983                                        LR 0.000005    Time 0.078454    
2024-04-24 02:31:23,888 - Epoch: [564][  200/  296]    Overall Loss 0.656824    Objective Loss 0.656824                                        LR 0.000005    Time 0.075459    
2024-04-24 02:31:30,250 - Epoch: [564][  296/  296]    Overall Loss 0.664645    Objective Loss 0.664645    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.072457    
2024-04-24 02:31:30,396 - --- validate (epoch=564)-----------
2024-04-24 02:31:30,397 - 3925 samples (32 per mini-batch)
2024-04-24 02:31:39,152 - Epoch: [564][  100/  123]    Loss 0.645330    Top1 79.343750    Top5 97.562500    
2024-04-24 02:31:40,908 - Epoch: [564][  123/  123]    Loss 0.656500    Top1 78.929936    Top5 97.630573    
2024-04-24 02:31:41,039 - ==> Top1: 78.930    Top5: 97.631    Loss: 0.656

2024-04-24 02:31:41,048 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:31:41,048 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:31:41,084 - 

2024-04-24 02:31:41,084 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:31:50,795 - Epoch: [565][  100/  296]    Overall Loss 0.636157    Objective Loss 0.636157                                        LR 0.000005    Time 0.097049    
2024-04-24 02:31:58,085 - Epoch: [565][  200/  296]    Overall Loss 0.654073    Objective Loss 0.654073                                        LR 0.000005    Time 0.084949    
2024-04-24 02:32:04,247 - Epoch: [565][  296/  296]    Overall Loss 0.655080    Objective Loss 0.655080    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.078201    
2024-04-24 02:32:04,366 - --- validate (epoch=565)-----------
2024-04-24 02:32:04,366 - 3925 samples (32 per mini-batch)
2024-04-24 02:32:13,972 - Epoch: [565][  100/  123]    Loss 0.653271    Top1 79.093750    Top5 97.593750    
2024-04-24 02:32:15,875 - Epoch: [565][  123/  123]    Loss 0.659431    Top1 78.955414    Top5 97.579618    
2024-04-24 02:32:15,963 - ==> Top1: 78.955    Top5: 97.580    Loss: 0.659

2024-04-24 02:32:15,971 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:32:15,972 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:32:16,006 - 

2024-04-24 02:32:16,006 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:32:25,502 - Epoch: [566][  100/  296]    Overall Loss 0.651537    Objective Loss 0.651537                                        LR 0.000005    Time 0.094893    
2024-04-24 02:32:32,893 - Epoch: [566][  200/  296]    Overall Loss 0.647817    Objective Loss 0.647817                                        LR 0.000005    Time 0.084382    
2024-04-24 02:32:40,089 - Epoch: [566][  296/  296]    Overall Loss 0.656576    Objective Loss 0.656576    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.081311    
2024-04-24 02:32:40,184 - --- validate (epoch=566)-----------
2024-04-24 02:32:40,184 - 3925 samples (32 per mini-batch)
2024-04-24 02:32:49,121 - Epoch: [566][  100/  123]    Loss 0.662703    Top1 78.812500    Top5 97.625000    
2024-04-24 02:32:50,821 - Epoch: [566][  123/  123]    Loss 0.656870    Top1 79.133758    Top5 97.656051    
2024-04-24 02:32:50,930 - ==> Top1: 79.134    Top5: 97.656    Loss: 0.657

2024-04-24 02:32:50,940 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:32:50,940 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:32:50,974 - 

2024-04-24 02:32:50,974 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:33:00,162 - Epoch: [567][  100/  296]    Overall Loss 0.626640    Objective Loss 0.626640                                        LR 0.000005    Time 0.091822    
2024-04-24 02:33:08,915 - Epoch: [567][  200/  296]    Overall Loss 0.650698    Objective Loss 0.650698                                        LR 0.000005    Time 0.089640    
2024-04-24 02:33:15,873 - Epoch: [567][  296/  296]    Overall Loss 0.643816    Objective Loss 0.643816    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.084058    
2024-04-24 02:33:16,013 - --- validate (epoch=567)-----------
2024-04-24 02:33:16,013 - 3925 samples (32 per mini-batch)
2024-04-24 02:33:24,021 - Epoch: [567][  100/  123]    Loss 0.645566    Top1 79.218750    Top5 97.625000    
2024-04-24 02:33:26,178 - Epoch: [567][  123/  123]    Loss 0.661440    Top1 78.777070    Top5 97.605096    
2024-04-24 02:33:26,305 - ==> Top1: 78.777    Top5: 97.605    Loss: 0.661

2024-04-24 02:33:26,314 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:33:26,314 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:33:26,351 - 

2024-04-24 02:33:26,351 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:33:34,815 - Epoch: [568][  100/  296]    Overall Loss 0.622474    Objective Loss 0.622474                                        LR 0.000005    Time 0.084591    
2024-04-24 02:33:42,736 - Epoch: [568][  200/  296]    Overall Loss 0.638161    Objective Loss 0.638161                                        LR 0.000005    Time 0.081876    
2024-04-24 02:33:50,036 - Epoch: [568][  296/  296]    Overall Loss 0.640882    Objective Loss 0.640882    Top1 77.049180    Top5 96.721311    LR 0.000005    Time 0.079972    
2024-04-24 02:33:50,223 - --- validate (epoch=568)-----------
2024-04-24 02:33:50,224 - 3925 samples (32 per mini-batch)
2024-04-24 02:33:59,042 - Epoch: [568][  100/  123]    Loss 0.657617    Top1 79.093750    Top5 97.875000    
2024-04-24 02:34:00,974 - Epoch: [568][  123/  123]    Loss 0.658194    Top1 79.159236    Top5 97.656051    
2024-04-24 02:34:01,110 - ==> Top1: 79.159    Top5: 97.656    Loss: 0.658

2024-04-24 02:34:01,119 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:34:01,119 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:34:01,161 - 

2024-04-24 02:34:01,161 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:34:08,976 - Epoch: [569][  100/  296]    Overall Loss 0.620832    Objective Loss 0.620832                                        LR 0.000005    Time 0.078089    
2024-04-24 02:34:15,948 - Epoch: [569][  200/  296]    Overall Loss 0.621140    Objective Loss 0.621140                                        LR 0.000005    Time 0.073879    
2024-04-24 02:34:22,461 - Epoch: [569][  296/  296]    Overall Loss 0.629087    Objective Loss 0.629087    Top1 83.606557    Top5 96.721311    LR 0.000005    Time 0.071904    
2024-04-24 02:34:22,594 - --- validate (epoch=569)-----------
2024-04-24 02:34:22,594 - 3925 samples (32 per mini-batch)
2024-04-24 02:34:31,402 - Epoch: [569][  100/  123]    Loss 0.659234    Top1 79.062500    Top5 97.468750    
2024-04-24 02:34:33,288 - Epoch: [569][  123/  123]    Loss 0.661466    Top1 78.777070    Top5 97.528662    
2024-04-24 02:34:33,377 - ==> Top1: 78.777    Top5: 97.529    Loss: 0.661

2024-04-24 02:34:33,380 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:34:33,380 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:34:33,402 - 

2024-04-24 02:34:33,403 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:34:41,316 - Epoch: [570][  100/  296]    Overall Loss 0.639733    Objective Loss 0.639733                                        LR 0.000005    Time 0.079063    
2024-04-24 02:34:48,458 - Epoch: [570][  200/  296]    Overall Loss 0.636349    Objective Loss 0.636349                                        LR 0.000005    Time 0.075209    
2024-04-24 02:34:55,230 - Epoch: [570][  296/  296]    Overall Loss 0.643438    Objective Loss 0.643438    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.073680    
2024-04-24 02:34:55,356 - --- validate (epoch=570)-----------
2024-04-24 02:34:55,357 - 3925 samples (32 per mini-batch)
2024-04-24 02:35:03,135 - Epoch: [570][  100/  123]    Loss 0.667986    Top1 78.312500    Top5 97.531250    
2024-04-24 02:35:04,950 - Epoch: [570][  123/  123]    Loss 0.660096    Top1 78.828025    Top5 97.707006    
2024-04-24 02:35:05,096 - ==> Top1: 78.828    Top5: 97.707    Loss: 0.660

2024-04-24 02:35:05,104 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:35:05,104 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:35:05,140 - 

2024-04-24 02:35:05,140 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:35:14,295 - Epoch: [571][  100/  296]    Overall Loss 0.647714    Objective Loss 0.647714                                        LR 0.000005    Time 0.091481    
2024-04-24 02:35:21,464 - Epoch: [571][  200/  296]    Overall Loss 0.645036    Objective Loss 0.645036                                        LR 0.000005    Time 0.081555    
2024-04-24 02:35:27,319 - Epoch: [571][  296/  296]    Overall Loss 0.646820    Objective Loss 0.646820    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.074866    
2024-04-24 02:35:27,409 - --- validate (epoch=571)-----------
2024-04-24 02:35:27,409 - 3925 samples (32 per mini-batch)
2024-04-24 02:35:36,053 - Epoch: [571][  100/  123]    Loss 0.663980    Top1 78.718750    Top5 97.343750    
2024-04-24 02:35:37,629 - Epoch: [571][  123/  123]    Loss 0.662497    Top1 78.777070    Top5 97.477707    
2024-04-24 02:35:37,744 - ==> Top1: 78.777    Top5: 97.478    Loss: 0.662

2024-04-24 02:35:37,752 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:35:37,752 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:35:37,788 - 

2024-04-24 02:35:37,788 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:35:45,676 - Epoch: [572][  100/  296]    Overall Loss 0.637034    Objective Loss 0.637034                                        LR 0.000005    Time 0.078820    
2024-04-24 02:35:53,159 - Epoch: [572][  200/  296]    Overall Loss 0.638218    Objective Loss 0.638218                                        LR 0.000005    Time 0.076796    
2024-04-24 02:36:00,057 - Epoch: [572][  296/  296]    Overall Loss 0.645633    Objective Loss 0.645633    Top1 75.409836    Top5 95.081967    LR 0.000005    Time 0.075180    
2024-04-24 02:36:00,180 - --- validate (epoch=572)-----------
2024-04-24 02:36:00,181 - 3925 samples (32 per mini-batch)
2024-04-24 02:36:09,481 - Epoch: [572][  100/  123]    Loss 0.673081    Top1 78.906250    Top5 97.656250    
2024-04-24 02:36:11,370 - Epoch: [572][  123/  123]    Loss 0.657972    Top1 79.108280    Top5 97.656051    
2024-04-24 02:36:11,472 - ==> Top1: 79.108    Top5: 97.656    Loss: 0.658

2024-04-24 02:36:11,481 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:36:11,481 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:36:11,515 - 

2024-04-24 02:36:11,515 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:36:19,264 - Epoch: [573][  100/  296]    Overall Loss 0.629816    Objective Loss 0.629816                                        LR 0.000005    Time 0.077436    
2024-04-24 02:36:26,273 - Epoch: [573][  200/  296]    Overall Loss 0.649721    Objective Loss 0.649721                                        LR 0.000005    Time 0.073741    
2024-04-24 02:36:33,786 - Epoch: [573][  296/  296]    Overall Loss 0.653092    Objective Loss 0.653092    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.075193    
2024-04-24 02:36:33,902 - --- validate (epoch=573)-----------
2024-04-24 02:36:33,903 - 3925 samples (32 per mini-batch)
2024-04-24 02:36:42,963 - Epoch: [573][  100/  123]    Loss 0.665594    Top1 78.843750    Top5 97.531250    
2024-04-24 02:36:44,717 - Epoch: [573][  123/  123]    Loss 0.659001    Top1 79.031847    Top5 97.656051    
2024-04-24 02:36:44,810 - ==> Top1: 79.032    Top5: 97.656    Loss: 0.659

2024-04-24 02:36:44,818 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:36:44,819 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:36:44,854 - 

2024-04-24 02:36:44,854 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:36:52,501 - Epoch: [574][  100/  296]    Overall Loss 0.644677    Objective Loss 0.644677                                        LR 0.000005    Time 0.076414    
2024-04-24 02:37:00,380 - Epoch: [574][  200/  296]    Overall Loss 0.661005    Objective Loss 0.661005                                        LR 0.000005    Time 0.077579    
2024-04-24 02:37:06,992 - Epoch: [574][  296/  296]    Overall Loss 0.649804    Objective Loss 0.649804    Top1 70.491803    Top5 95.081967    LR 0.000005    Time 0.074741    
2024-04-24 02:37:07,073 - --- validate (epoch=574)-----------
2024-04-24 02:37:07,073 - 3925 samples (32 per mini-batch)
2024-04-24 02:37:16,448 - Epoch: [574][  100/  123]    Loss 0.654509    Top1 78.875000    Top5 97.718750    
2024-04-24 02:37:18,421 - Epoch: [574][  123/  123]    Loss 0.659346    Top1 78.904459    Top5 97.605096    
2024-04-24 02:37:18,495 - ==> Top1: 78.904    Top5: 97.605    Loss: 0.659

2024-04-24 02:37:18,504 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:37:18,504 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:37:18,540 - 

2024-04-24 02:37:18,540 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:37:26,962 - Epoch: [575][  100/  296]    Overall Loss 0.649332    Objective Loss 0.649332                                        LR 0.000005    Time 0.084169    
2024-04-24 02:37:33,801 - Epoch: [575][  200/  296]    Overall Loss 0.644539    Objective Loss 0.644539                                        LR 0.000005    Time 0.076249    
2024-04-24 02:37:39,779 - Epoch: [575][  296/  296]    Overall Loss 0.650095    Objective Loss 0.650095    Top1 77.049180    Top5 98.360656    LR 0.000005    Time 0.071701    
2024-04-24 02:37:39,862 - --- validate (epoch=575)-----------
2024-04-24 02:37:39,862 - 3925 samples (32 per mini-batch)
2024-04-24 02:37:48,803 - Epoch: [575][  100/  123]    Loss 0.662907    Top1 78.718750    Top5 97.593750    
2024-04-24 02:37:50,294 - Epoch: [575][  123/  123]    Loss 0.657063    Top1 78.929936    Top5 97.503185    
2024-04-24 02:37:50,370 - ==> Top1: 78.930    Top5: 97.503    Loss: 0.657

2024-04-24 02:37:50,379 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:37:50,379 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:37:50,413 - 

2024-04-24 02:37:50,414 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:37:57,534 - Epoch: [576][  100/  296]    Overall Loss 0.632916    Objective Loss 0.632916                                        LR 0.000005    Time 0.071151    
2024-04-24 02:38:04,183 - Epoch: [576][  200/  296]    Overall Loss 0.643263    Objective Loss 0.643263                                        LR 0.000005    Time 0.068796    
2024-04-24 02:38:11,025 - Epoch: [576][  296/  296]    Overall Loss 0.637488    Objective Loss 0.637488    Top1 85.245902    Top5 100.000000    LR 0.000005    Time 0.069584    
2024-04-24 02:38:11,113 - --- validate (epoch=576)-----------
2024-04-24 02:38:11,114 - 3925 samples (32 per mini-batch)
2024-04-24 02:38:20,170 - Epoch: [576][  100/  123]    Loss 0.664195    Top1 79.093750    Top5 97.468750    
2024-04-24 02:38:21,994 - Epoch: [576][  123/  123]    Loss 0.654377    Top1 79.261146    Top5 97.681529    
2024-04-24 02:38:22,062 - ==> Top1: 79.261    Top5: 97.682    Loss: 0.654

2024-04-24 02:38:22,071 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:38:22,071 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:38:22,105 - 

2024-04-24 02:38:22,105 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:38:30,116 - Epoch: [577][  100/  296]    Overall Loss 0.661131    Objective Loss 0.661131                                        LR 0.000005    Time 0.080055    
2024-04-24 02:38:37,153 - Epoch: [577][  200/  296]    Overall Loss 0.654681    Objective Loss 0.654681                                        LR 0.000005    Time 0.075188    
2024-04-24 02:38:44,244 - Epoch: [577][  296/  296]    Overall Loss 0.651852    Objective Loss 0.651852    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.074741    
2024-04-24 02:38:44,353 - --- validate (epoch=577)-----------
2024-04-24 02:38:44,354 - 3925 samples (32 per mini-batch)
2024-04-24 02:38:52,955 - Epoch: [577][  100/  123]    Loss 0.662045    Top1 78.843750    Top5 97.625000    
2024-04-24 02:38:54,918 - Epoch: [577][  123/  123]    Loss 0.657464    Top1 78.955414    Top5 97.605096    
2024-04-24 02:38:55,033 - ==> Top1: 78.955    Top5: 97.605    Loss: 0.657

2024-04-24 02:38:55,041 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:38:55,042 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:38:55,077 - 

2024-04-24 02:38:55,077 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:39:02,726 - Epoch: [578][  100/  296]    Overall Loss 0.665475    Objective Loss 0.665475                                        LR 0.000005    Time 0.076442    
2024-04-24 02:39:10,322 - Epoch: [578][  200/  296]    Overall Loss 0.672907    Objective Loss 0.672907                                        LR 0.000005    Time 0.076175    
2024-04-24 02:39:17,149 - Epoch: [578][  296/  296]    Overall Loss 0.663296    Objective Loss 0.663296    Top1 78.688525    Top5 96.721311    LR 0.000005    Time 0.074516    
2024-04-24 02:39:17,267 - --- validate (epoch=578)-----------
2024-04-24 02:39:17,267 - 3925 samples (32 per mini-batch)
2024-04-24 02:39:26,928 - Epoch: [578][  100/  123]    Loss 0.672435    Top1 78.843750    Top5 97.312500    
2024-04-24 02:39:28,867 - Epoch: [578][  123/  123]    Loss 0.660060    Top1 79.031847    Top5 97.528662    
2024-04-24 02:39:28,973 - ==> Top1: 79.032    Top5: 97.529    Loss: 0.660

2024-04-24 02:39:28,982 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:39:28,982 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:39:29,017 - 

2024-04-24 02:39:29,017 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:39:37,458 - Epoch: [579][  100/  296]    Overall Loss 0.640135    Objective Loss 0.640135                                        LR 0.000005    Time 0.084350    
2024-04-24 02:39:44,725 - Epoch: [579][  200/  296]    Overall Loss 0.643212    Objective Loss 0.643212                                        LR 0.000005    Time 0.078488    
2024-04-24 02:39:51,160 - Epoch: [579][  296/  296]    Overall Loss 0.651205    Objective Loss 0.651205    Top1 67.213115    Top5 96.721311    LR 0.000005    Time 0.074753    
2024-04-24 02:39:51,259 - --- validate (epoch=579)-----------
2024-04-24 02:39:51,259 - 3925 samples (32 per mini-batch)
2024-04-24 02:39:59,756 - Epoch: [579][  100/  123]    Loss 0.643786    Top1 79.531250    Top5 97.625000    
2024-04-24 02:40:01,613 - Epoch: [579][  123/  123]    Loss 0.655521    Top1 78.955414    Top5 97.452229    
2024-04-24 02:40:01,700 - ==> Top1: 78.955    Top5: 97.452    Loss: 0.656

2024-04-24 02:40:01,708 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:40:01,708 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:40:01,743 - 

2024-04-24 02:40:01,744 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:40:09,889 - Epoch: [580][  100/  296]    Overall Loss 0.664497    Objective Loss 0.664497                                        LR 0.000005    Time 0.081398    
2024-04-24 02:40:16,860 - Epoch: [580][  200/  296]    Overall Loss 0.664098    Objective Loss 0.664098                                        LR 0.000005    Time 0.075523    
2024-04-24 02:40:23,256 - Epoch: [580][  296/  296]    Overall Loss 0.664146    Objective Loss 0.664146    Top1 85.245902    Top5 98.360656    LR 0.000005    Time 0.072619    
2024-04-24 02:40:23,372 - --- validate (epoch=580)-----------
2024-04-24 02:40:23,373 - 3925 samples (32 per mini-batch)
2024-04-24 02:40:31,174 - Epoch: [580][  100/  123]    Loss 0.676165    Top1 77.906250    Top5 97.531250    
2024-04-24 02:40:32,678 - Epoch: [580][  123/  123]    Loss 0.660316    Top1 78.649682    Top5 97.528662    
2024-04-24 02:40:32,792 - ==> Top1: 78.650    Top5: 97.529    Loss: 0.660

2024-04-24 02:40:32,800 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:40:32,801 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:40:32,834 - 

2024-04-24 02:40:32,835 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:40:42,743 - Epoch: [581][  100/  296]    Overall Loss 0.664808    Objective Loss 0.664808                                        LR 0.000005    Time 0.099025    
2024-04-24 02:40:50,624 - Epoch: [581][  200/  296]    Overall Loss 0.666125    Objective Loss 0.666125                                        LR 0.000005    Time 0.088893    
2024-04-24 02:40:57,556 - Epoch: [581][  296/  296]    Overall Loss 0.655348    Objective Loss 0.655348    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.083463    
2024-04-24 02:40:57,663 - --- validate (epoch=581)-----------
2024-04-24 02:40:57,664 - 3925 samples (32 per mini-batch)
2024-04-24 02:41:06,877 - Epoch: [581][  100/  123]    Loss 0.659776    Top1 78.843750    Top5 97.593750    
2024-04-24 02:41:08,335 - Epoch: [581][  123/  123]    Loss 0.657992    Top1 78.980892    Top5 97.426752    
2024-04-24 02:41:08,461 - ==> Top1: 78.981    Top5: 97.427    Loss: 0.658

2024-04-24 02:41:08,470 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:41:08,470 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:41:08,509 - 

2024-04-24 02:41:08,509 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:41:16,838 - Epoch: [582][  100/  296]    Overall Loss 0.650605    Objective Loss 0.650605                                        LR 0.000005    Time 0.083222    
2024-04-24 02:41:23,845 - Epoch: [582][  200/  296]    Overall Loss 0.648729    Objective Loss 0.648729                                        LR 0.000005    Time 0.076620    
2024-04-24 02:41:31,917 - Epoch: [582][  296/  296]    Overall Loss 0.653182    Objective Loss 0.653182    Top1 77.049180    Top5 100.000000    LR 0.000005    Time 0.079028    
2024-04-24 02:41:32,010 - --- validate (epoch=582)-----------
2024-04-24 02:41:32,010 - 3925 samples (32 per mini-batch)
2024-04-24 02:41:40,206 - Epoch: [582][  100/  123]    Loss 0.651218    Top1 79.437500    Top5 97.656250    
2024-04-24 02:41:41,808 - Epoch: [582][  123/  123]    Loss 0.657537    Top1 79.184713    Top5 97.579618    
2024-04-24 02:41:41,933 - ==> Top1: 79.185    Top5: 97.580    Loss: 0.658

2024-04-24 02:41:41,941 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:41:41,942 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:41:41,976 - 

2024-04-24 02:41:41,976 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:41:49,628 - Epoch: [583][  100/  296]    Overall Loss 0.643002    Objective Loss 0.643002                                        LR 0.000005    Time 0.076463    
2024-04-24 02:41:56,561 - Epoch: [583][  200/  296]    Overall Loss 0.627613    Objective Loss 0.627613                                        LR 0.000005    Time 0.072871    
2024-04-24 02:42:02,339 - Epoch: [583][  296/  296]    Overall Loss 0.641912    Objective Loss 0.641912    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.068741    
2024-04-24 02:42:02,488 - --- validate (epoch=583)-----------
2024-04-24 02:42:02,489 - 3925 samples (32 per mini-batch)
2024-04-24 02:42:11,616 - Epoch: [583][  100/  123]    Loss 0.666282    Top1 78.750000    Top5 97.562500    
2024-04-24 02:42:13,097 - Epoch: [583][  123/  123]    Loss 0.656264    Top1 79.031847    Top5 97.681529    
2024-04-24 02:42:13,202 - ==> Top1: 79.032    Top5: 97.682    Loss: 0.656

2024-04-24 02:42:13,210 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:42:13,210 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:42:13,244 - 

2024-04-24 02:42:13,245 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:42:22,419 - Epoch: [584][  100/  296]    Overall Loss 0.653495    Objective Loss 0.653495                                        LR 0.000005    Time 0.091697    
2024-04-24 02:42:30,945 - Epoch: [584][  200/  296]    Overall Loss 0.661587    Objective Loss 0.661587                                        LR 0.000005    Time 0.088448    
2024-04-24 02:42:39,000 - Epoch: [584][  296/  296]    Overall Loss 0.659752    Objective Loss 0.659752    Top1 73.770492    Top5 96.721311    LR 0.000005    Time 0.086956    
2024-04-24 02:42:39,122 - --- validate (epoch=584)-----------
2024-04-24 02:42:39,123 - 3925 samples (32 per mini-batch)
2024-04-24 02:42:47,828 - Epoch: [584][  100/  123]    Loss 0.656906    Top1 78.875000    Top5 97.656250    
2024-04-24 02:42:49,413 - Epoch: [584][  123/  123]    Loss 0.657947    Top1 78.955414    Top5 97.579618    
2024-04-24 02:42:49,532 - ==> Top1: 78.955    Top5: 97.580    Loss: 0.658

2024-04-24 02:42:49,540 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:42:49,540 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:42:49,575 - 

2024-04-24 02:42:49,575 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:42:58,584 - Epoch: [585][  100/  296]    Overall Loss 0.677071    Objective Loss 0.677071                                        LR 0.000005    Time 0.090017    
2024-04-24 02:43:06,202 - Epoch: [585][  200/  296]    Overall Loss 0.655069    Objective Loss 0.655069                                        LR 0.000005    Time 0.083068    
2024-04-24 02:43:12,954 - Epoch: [585][  296/  296]    Overall Loss 0.657377    Objective Loss 0.657377    Top1 83.606557    Top5 98.360656    LR 0.000005    Time 0.078919    
2024-04-24 02:43:13,045 - --- validate (epoch=585)-----------
2024-04-24 02:43:13,046 - 3925 samples (32 per mini-batch)
2024-04-24 02:43:22,490 - Epoch: [585][  100/  123]    Loss 0.639195    Top1 79.625000    Top5 97.656250    
2024-04-24 02:43:24,137 - Epoch: [585][  123/  123]    Loss 0.657225    Top1 79.057325    Top5 97.605096    
2024-04-24 02:43:24,257 - ==> Top1: 79.057    Top5: 97.605    Loss: 0.657

2024-04-24 02:43:24,265 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:43:24,266 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:43:24,300 - 

2024-04-24 02:43:24,301 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:43:33,136 - Epoch: [586][  100/  296]    Overall Loss 0.633145    Objective Loss 0.633145                                        LR 0.000005    Time 0.088294    
2024-04-24 02:43:40,924 - Epoch: [586][  200/  296]    Overall Loss 0.649918    Objective Loss 0.649918                                        LR 0.000005    Time 0.083062    
2024-04-24 02:43:47,627 - Epoch: [586][  296/  296]    Overall Loss 0.651194    Objective Loss 0.651194    Top1 75.409836    Top5 96.721311    LR 0.000005    Time 0.078756    
2024-04-24 02:43:47,762 - --- validate (epoch=586)-----------
2024-04-24 02:43:47,763 - 3925 samples (32 per mini-batch)
2024-04-24 02:43:56,459 - Epoch: [586][  100/  123]    Loss 0.653337    Top1 79.281250    Top5 97.625000    
2024-04-24 02:43:58,689 - Epoch: [586][  123/  123]    Loss 0.657150    Top1 79.031847    Top5 97.656051    
2024-04-24 02:43:58,780 - ==> Top1: 79.032    Top5: 97.656    Loss: 0.657

2024-04-24 02:43:58,789 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:43:58,789 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:43:58,825 - 

2024-04-24 02:43:58,825 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:44:06,685 - Epoch: [587][  100/  296]    Overall Loss 0.643516    Objective Loss 0.643516                                        LR 0.000005    Time 0.078529    
2024-04-24 02:44:13,033 - Epoch: [587][  200/  296]    Overall Loss 0.658927    Objective Loss 0.658927                                        LR 0.000005    Time 0.070976    
2024-04-24 02:44:18,707 - Epoch: [587][  296/  296]    Overall Loss 0.653051    Objective Loss 0.653051    Top1 91.803279    Top5 98.360656    LR 0.000005    Time 0.067112    
2024-04-24 02:44:18,812 - --- validate (epoch=587)-----------
2024-04-24 02:44:18,813 - 3925 samples (32 per mini-batch)
2024-04-24 02:44:27,279 - Epoch: [587][  100/  123]    Loss 0.663530    Top1 78.781250    Top5 97.656250    
2024-04-24 02:44:28,904 - Epoch: [587][  123/  123]    Loss 0.659302    Top1 78.929936    Top5 97.681529    
2024-04-24 02:44:28,986 - ==> Top1: 78.930    Top5: 97.682    Loss: 0.659

2024-04-24 02:44:28,995 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:44:28,996 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:44:29,030 - 

2024-04-24 02:44:29,030 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:44:36,618 - Epoch: [588][  100/  296]    Overall Loss 0.639782    Objective Loss 0.639782                                        LR 0.000005    Time 0.075819    
2024-04-24 02:44:42,558 - Epoch: [588][  200/  296]    Overall Loss 0.643831    Objective Loss 0.643831                                        LR 0.000005    Time 0.067582    
2024-04-24 02:44:48,770 - Epoch: [588][  296/  296]    Overall Loss 0.647577    Objective Loss 0.647577    Top1 78.688525    Top5 100.000000    LR 0.000005    Time 0.066635    
2024-04-24 02:44:48,894 - --- validate (epoch=588)-----------
2024-04-24 02:44:48,895 - 3925 samples (32 per mini-batch)
2024-04-24 02:44:58,157 - Epoch: [588][  100/  123]    Loss 0.658262    Top1 79.031250    Top5 97.687500    
2024-04-24 02:45:00,443 - Epoch: [588][  123/  123]    Loss 0.660433    Top1 78.929936    Top5 97.656051    
2024-04-24 02:45:00,537 - ==> Top1: 78.930    Top5: 97.656    Loss: 0.660

2024-04-24 02:45:00,545 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:45:00,545 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:45:00,581 - 

2024-04-24 02:45:00,581 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:45:08,160 - Epoch: [589][  100/  296]    Overall Loss 0.675954    Objective Loss 0.675954                                        LR 0.000005    Time 0.075731    
2024-04-24 02:45:14,853 - Epoch: [589][  200/  296]    Overall Loss 0.651945    Objective Loss 0.651945                                        LR 0.000005    Time 0.071300    
2024-04-24 02:45:21,005 - Epoch: [589][  296/  296]    Overall Loss 0.654756    Objective Loss 0.654756    Top1 77.049180    Top5 95.081967    LR 0.000005    Time 0.068943    
2024-04-24 02:45:21,113 - --- validate (epoch=589)-----------
2024-04-24 02:45:21,114 - 3925 samples (32 per mini-batch)
2024-04-24 02:45:29,749 - Epoch: [589][  100/  123]    Loss 0.651353    Top1 79.125000    Top5 97.687500    
2024-04-24 02:45:31,722 - Epoch: [589][  123/  123]    Loss 0.658191    Top1 78.929936    Top5 97.605096    
2024-04-24 02:45:31,839 - ==> Top1: 78.930    Top5: 97.605    Loss: 0.658

2024-04-24 02:45:31,848 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:45:31,848 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:45:31,883 - 

2024-04-24 02:45:31,883 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:45:39,787 - Epoch: [590][  100/  296]    Overall Loss 0.657323    Objective Loss 0.657323                                        LR 0.000005    Time 0.078982    
2024-04-24 02:45:45,710 - Epoch: [590][  200/  296]    Overall Loss 0.640829    Objective Loss 0.640829                                        LR 0.000005    Time 0.069082    
2024-04-24 02:45:51,874 - Epoch: [590][  296/  296]    Overall Loss 0.634964    Objective Loss 0.634964    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.067484    
2024-04-24 02:45:51,973 - --- validate (epoch=590)-----------
2024-04-24 02:45:51,973 - 3925 samples (32 per mini-batch)
2024-04-24 02:46:02,965 - Epoch: [590][  100/  123]    Loss 0.667534    Top1 78.718750    Top5 97.593750    
2024-04-24 02:46:04,864 - Epoch: [590][  123/  123]    Loss 0.658370    Top1 78.904459    Top5 97.656051    
2024-04-24 02:46:05,010 - ==> Top1: 78.904    Top5: 97.656    Loss: 0.658

2024-04-24 02:46:05,019 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:46:05,019 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:46:05,055 - 

2024-04-24 02:46:05,055 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:46:13,457 - Epoch: [591][  100/  296]    Overall Loss 0.661084    Objective Loss 0.661084                                        LR 0.000005    Time 0.083939    
2024-04-24 02:46:19,473 - Epoch: [591][  200/  296]    Overall Loss 0.645147    Objective Loss 0.645147                                        LR 0.000005    Time 0.072026    
2024-04-24 02:46:26,703 - Epoch: [591][  296/  296]    Overall Loss 0.645651    Objective Loss 0.645651    Top1 83.606557    Top5 100.000000    LR 0.000005    Time 0.073076    
2024-04-24 02:46:26,859 - --- validate (epoch=591)-----------
2024-04-24 02:46:26,859 - 3925 samples (32 per mini-batch)
2024-04-24 02:46:36,617 - Epoch: [591][  100/  123]    Loss 0.644295    Top1 79.312500    Top5 97.843750    
2024-04-24 02:46:38,467 - Epoch: [591][  123/  123]    Loss 0.653125    Top1 79.031847    Top5 97.656051    
2024-04-24 02:46:38,580 - ==> Top1: 79.032    Top5: 97.656    Loss: 0.653

2024-04-24 02:46:38,589 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:46:38,590 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:46:38,625 - 

2024-04-24 02:46:38,625 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:46:46,290 - Epoch: [592][  100/  296]    Overall Loss 0.625821    Objective Loss 0.625821                                        LR 0.000005    Time 0.076590    
2024-04-24 02:46:53,034 - Epoch: [592][  200/  296]    Overall Loss 0.630011    Objective Loss 0.630011                                        LR 0.000005    Time 0.071993    
2024-04-24 02:46:58,926 - Epoch: [592][  296/  296]    Overall Loss 0.639616    Objective Loss 0.639616    Top1 81.967213    Top5 98.360656    LR 0.000005    Time 0.068530    
2024-04-24 02:46:59,023 - --- validate (epoch=592)-----------
2024-04-24 02:46:59,024 - 3925 samples (32 per mini-batch)
2024-04-24 02:47:07,899 - Epoch: [592][  100/  123]    Loss 0.663491    Top1 78.812500    Top5 97.468750    
2024-04-24 02:47:09,717 - Epoch: [592][  123/  123]    Loss 0.652996    Top1 78.853503    Top5 97.605096    
2024-04-24 02:47:09,837 - ==> Top1: 78.854    Top5: 97.605    Loss: 0.653

2024-04-24 02:47:09,846 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:47:09,846 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:47:09,880 - 

2024-04-24 02:47:09,880 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:47:17,288 - Epoch: [593][  100/  296]    Overall Loss 0.638129    Objective Loss 0.638129                                        LR 0.000005    Time 0.074022    
2024-04-24 02:47:24,215 - Epoch: [593][  200/  296]    Overall Loss 0.633920    Objective Loss 0.633920                                        LR 0.000005    Time 0.071614    
2024-04-24 02:47:31,013 - Epoch: [593][  296/  296]    Overall Loss 0.637275    Objective Loss 0.637275    Top1 75.409836    Top5 98.360656    LR 0.000005    Time 0.071334    
2024-04-24 02:47:31,149 - --- validate (epoch=593)-----------
2024-04-24 02:47:31,150 - 3925 samples (32 per mini-batch)
2024-04-24 02:47:39,921 - Epoch: [593][  100/  123]    Loss 0.691723    Top1 77.812500    Top5 97.437500    
2024-04-24 02:47:41,322 - Epoch: [593][  123/  123]    Loss 0.655641    Top1 79.133758    Top5 97.630573    
2024-04-24 02:47:41,407 - ==> Top1: 79.134    Top5: 97.631    Loss: 0.656

2024-04-24 02:47:41,416 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:47:41,416 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:47:41,452 - 

2024-04-24 02:47:41,453 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:47:53,999 - Epoch: [594][  100/  296]    Overall Loss 0.668317    Objective Loss 0.668317                                        LR 0.000005    Time 0.125424    
2024-04-24 02:48:00,110 - Epoch: [594][  200/  296]    Overall Loss 0.658933    Objective Loss 0.658933                                        LR 0.000005    Time 0.093237    
2024-04-24 02:48:05,679 - Epoch: [594][  296/  296]    Overall Loss 0.657187    Objective Loss 0.657187    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.081795    
2024-04-24 02:48:05,794 - --- validate (epoch=594)-----------
2024-04-24 02:48:05,794 - 3925 samples (32 per mini-batch)
2024-04-24 02:48:15,476 - Epoch: [594][  100/  123]    Loss 0.648364    Top1 79.375000    Top5 97.593750    
2024-04-24 02:48:17,341 - Epoch: [594][  123/  123]    Loss 0.655550    Top1 79.133758    Top5 97.528662    
2024-04-24 02:48:17,436 - ==> Top1: 79.134    Top5: 97.529    Loss: 0.656

2024-04-24 02:48:17,439 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:48:17,439 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:48:17,458 - 

2024-04-24 02:48:17,458 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:48:27,664 - Epoch: [595][  100/  296]    Overall Loss 0.620895    Objective Loss 0.620895                                        LR 0.000005    Time 0.101974    
2024-04-24 02:48:34,475 - Epoch: [595][  200/  296]    Overall Loss 0.642648    Objective Loss 0.642648                                        LR 0.000005    Time 0.085014    
2024-04-24 02:48:41,411 - Epoch: [595][  296/  296]    Overall Loss 0.644486    Objective Loss 0.644486    Top1 86.885246    Top5 100.000000    LR 0.000005    Time 0.080860    
2024-04-24 02:48:41,552 - --- validate (epoch=595)-----------
2024-04-24 02:48:41,553 - 3925 samples (32 per mini-batch)
2024-04-24 02:48:51,146 - Epoch: [595][  100/  123]    Loss 0.653631    Top1 79.062500    Top5 97.281250    
2024-04-24 02:48:53,108 - Epoch: [595][  123/  123]    Loss 0.654374    Top1 78.853503    Top5 97.401274    
2024-04-24 02:48:53,205 - ==> Top1: 78.854    Top5: 97.401    Loss: 0.654

2024-04-24 02:48:53,214 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:48:53,214 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:48:53,248 - 

2024-04-24 02:48:53,249 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:49:00,925 - Epoch: [596][  100/  296]    Overall Loss 0.667615    Objective Loss 0.667615                                        LR 0.000005    Time 0.076707    
2024-04-24 02:49:06,975 - Epoch: [596][  200/  296]    Overall Loss 0.654520    Objective Loss 0.654520                                        LR 0.000005    Time 0.068579    
2024-04-24 02:49:12,983 - Epoch: [596][  296/  296]    Overall Loss 0.656431    Objective Loss 0.656431    Top1 81.967213    Top5 95.081967    LR 0.000005    Time 0.066618    
2024-04-24 02:49:13,083 - --- validate (epoch=596)-----------
2024-04-24 02:49:13,084 - 3925 samples (32 per mini-batch)
2024-04-24 02:49:22,791 - Epoch: [596][  100/  123]    Loss 0.654937    Top1 79.187500    Top5 97.625000    
2024-04-24 02:49:24,477 - Epoch: [596][  123/  123]    Loss 0.657049    Top1 78.929936    Top5 97.630573    
2024-04-24 02:49:24,618 - ==> Top1: 78.930    Top5: 97.631    Loss: 0.657

2024-04-24 02:49:24,626 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:49:24,627 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:49:24,662 - 

2024-04-24 02:49:24,662 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:49:32,667 - Epoch: [597][  100/  296]    Overall Loss 0.646523    Objective Loss 0.646523                                        LR 0.000005    Time 0.080002    
2024-04-24 02:49:38,768 - Epoch: [597][  200/  296]    Overall Loss 0.648303    Objective Loss 0.648303                                        LR 0.000005    Time 0.070480    
2024-04-24 02:49:44,908 - Epoch: [597][  296/  296]    Overall Loss 0.654731    Objective Loss 0.654731    Top1 72.131148    Top5 98.360656    LR 0.000005    Time 0.068350    
2024-04-24 02:49:45,033 - --- validate (epoch=597)-----------
2024-04-24 02:49:45,034 - 3925 samples (32 per mini-batch)
2024-04-24 02:49:53,325 - Epoch: [597][  100/  123]    Loss 0.663282    Top1 79.000000    Top5 97.562500    
2024-04-24 02:49:54,835 - Epoch: [597][  123/  123]    Loss 0.656513    Top1 79.159236    Top5 97.630573    
2024-04-24 02:49:54,952 - ==> Top1: 79.159    Top5: 97.631    Loss: 0.657

2024-04-24 02:49:54,960 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:49:54,961 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:49:54,997 - 

2024-04-24 02:49:54,997 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:50:03,340 - Epoch: [598][  100/  296]    Overall Loss 0.647071    Objective Loss 0.647071                                        LR 0.000005    Time 0.083375    
2024-04-24 02:50:09,986 - Epoch: [598][  200/  296]    Overall Loss 0.651904    Objective Loss 0.651904                                        LR 0.000005    Time 0.074894    
2024-04-24 02:50:15,521 - Epoch: [598][  296/  296]    Overall Loss 0.654357    Objective Loss 0.654357    Top1 88.524590    Top5 100.000000    LR 0.000005    Time 0.069283    
2024-04-24 02:50:15,609 - --- validate (epoch=598)-----------
2024-04-24 02:50:15,610 - 3925 samples (32 per mini-batch)
2024-04-24 02:50:24,181 - Epoch: [598][  100/  123]    Loss 0.665261    Top1 78.781250    Top5 97.531250    
2024-04-24 02:50:25,942 - Epoch: [598][  123/  123]    Loss 0.656803    Top1 79.184713    Top5 97.503185    
2024-04-24 02:50:26,019 - ==> Top1: 79.185    Top5: 97.503    Loss: 0.657

2024-04-24 02:50:26,028 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:50:26,029 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:50:26,064 - 

2024-04-24 02:50:26,064 - Training epoch: 9469 samples (32 per mini-batch)
2024-04-24 02:50:34,579 - Epoch: [599][  100/  296]    Overall Loss 0.651900    Objective Loss 0.651900                                        LR 0.000005    Time 0.085099    
2024-04-24 02:50:41,457 - Epoch: [599][  200/  296]    Overall Loss 0.653280    Objective Loss 0.653280                                        LR 0.000005    Time 0.076912    
2024-04-24 02:50:47,258 - Epoch: [599][  296/  296]    Overall Loss 0.653688    Objective Loss 0.653688    Top1 78.688525    Top5 98.360656    LR 0.000005    Time 0.071546    
2024-04-24 02:50:47,376 - --- validate (epoch=599)-----------
2024-04-24 02:50:47,376 - 3925 samples (32 per mini-batch)
2024-04-24 02:50:55,868 - Epoch: [599][  100/  123]    Loss 0.640495    Top1 79.593750    Top5 97.843750    
2024-04-24 02:50:57,783 - Epoch: [599][  123/  123]    Loss 0.656239    Top1 79.210191    Top5 97.707006    
2024-04-24 02:50:57,910 - ==> Top1: 79.210    Top5: 97.707    Loss: 0.656

2024-04-24 02:50:57,919 - ==> Best [Top1: 79.389   Top5: 97.503   Sparsity:0.00   Params: 376752 on epoch: 503]
2024-04-24 02:50:57,919 - Saving checkpoint to: logs/2024.04.23-154956/checkpoint.pth.tar
2024-04-24 02:50:57,953 - --- test ---------------------
2024-04-24 02:50:57,953 - 3925 samples (32 per mini-batch)
2024-04-24 02:51:06,948 - Test: [  100/  123]    Loss 0.663589    Top1 79.125000    Top5 97.625000    
2024-04-24 02:51:08,999 - Test: [  123/  123]    Loss 0.654979    Top1 79.210191    Top5 97.707006    
2024-04-24 02:51:09,133 - ==> Top1: 79.210    Top5: 97.707    Loss: 0.655

2024-04-24 02:51:09,141 - 
2024-04-24 02:51:09,141 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.23-154956/2024.04.23-154956.log
