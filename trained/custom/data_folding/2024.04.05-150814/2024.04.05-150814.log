2024-04-05 15:08:15,000 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.05-150814/2024.04.05-150814.log
2024-04-05 15:08:20,212 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-04-05 15:08:20,213 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-04-05 15:08:22,477 - Dataset sizes:
	training=50000
	validation=10000
	test=10000
2024-04-05 15:08:22,477 - Reading compression schedule from: policies/schedule-cifar-nas.yaml
2024-04-05 15:08:22,483 - 

2024-04-05 15:08:22,483 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:08:27,929 - Epoch: [0][  100/  500]    Overall Loss 4.459443    Objective Loss 4.459443                                        LR 0.001000    Time 0.054412    
2024-04-05 15:08:32,268 - Epoch: [0][  200/  500]    Overall Loss 4.329781    Objective Loss 4.329781                                        LR 0.001000    Time 0.048874    
2024-04-05 15:08:35,963 - Epoch: [0][  300/  500]    Overall Loss 4.237226    Objective Loss 4.237226                                        LR 0.001000    Time 0.044885    
2024-04-05 15:08:40,413 - Epoch: [0][  400/  500]    Overall Loss 4.158207    Objective Loss 4.158207                                        LR 0.001000    Time 0.044775    
2024-04-05 15:08:44,685 - Epoch: [0][  500/  500]    Overall Loss 4.093476    Objective Loss 4.093476    Top1 10.500000    Top5 42.000000    LR 0.001000    Time 0.044355    
2024-04-05 15:08:44,853 - --- validate (epoch=0)-----------
2024-04-05 15:08:44,854 - 10000 samples (100 per mini-batch)
2024-04-05 15:08:46,325 - Epoch: [0][  100/  100]    Loss 3.756455    Top1 11.600000    Top5 36.450000    
2024-04-05 15:08:46,487 - ==> Top1: 11.600    Top5: 36.450    Loss: 3.756

2024-04-05 15:08:46,494 - ==> Best [Top1: 11.600   Top5: 36.450   Sparsity:0.00   Params: 314624 on epoch: 0]
2024-04-05 15:08:46,495 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:08:46,527 - 

2024-04-05 15:08:46,527 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:08:51,020 - Epoch: [1][  100/  500]    Overall Loss 3.727024    Objective Loss 3.727024                                        LR 0.001000    Time 0.044883    
2024-04-05 15:08:54,944 - Epoch: [1][  200/  500]    Overall Loss 3.687204    Objective Loss 3.687204                                        LR 0.001000    Time 0.042040    
2024-04-05 15:08:58,648 - Epoch: [1][  300/  500]    Overall Loss 3.651189    Objective Loss 3.651189                                        LR 0.001000    Time 0.040358    
2024-04-05 15:09:02,544 - Epoch: [1][  400/  500]    Overall Loss 3.616713    Objective Loss 3.616713                                        LR 0.001000    Time 0.039997    
2024-04-05 15:09:06,973 - Epoch: [1][  500/  500]    Overall Loss 3.583789    Objective Loss 3.583789    Top1 19.000000    Top5 46.000000    LR 0.001000    Time 0.040844    
2024-04-05 15:09:07,100 - --- validate (epoch=1)-----------
2024-04-05 15:09:07,101 - 10000 samples (100 per mini-batch)
2024-04-05 15:09:08,645 - Epoch: [1][  100/  100]    Loss 3.363160    Top1 18.580000    Top5 47.010000    
2024-04-05 15:09:08,832 - ==> Top1: 18.580    Top5: 47.010    Loss: 3.363

2024-04-05 15:09:08,837 - ==> Best [Top1: 18.580   Top5: 47.010   Sparsity:0.00   Params: 314624 on epoch: 1]
2024-04-05 15:09:08,837 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:09:08,874 - 

2024-04-05 15:09:08,874 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:09:13,692 - Epoch: [2][  100/  500]    Overall Loss 3.354333    Objective Loss 3.354333                                        LR 0.001000    Time 0.048123    
2024-04-05 15:09:18,060 - Epoch: [2][  200/  500]    Overall Loss 3.320854    Objective Loss 3.320854                                        LR 0.001000    Time 0.045874    
2024-04-05 15:09:22,353 - Epoch: [2][  300/  500]    Overall Loss 3.298265    Objective Loss 3.298265                                        LR 0.001000    Time 0.044878    
2024-04-05 15:09:26,178 - Epoch: [2][  400/  500]    Overall Loss 3.274885    Objective Loss 3.274885                                        LR 0.001000    Time 0.043209    
2024-04-05 15:09:30,580 - Epoch: [2][  500/  500]    Overall Loss 3.250880    Objective Loss 3.250880    Top1 21.000000    Top5 51.000000    LR 0.001000    Time 0.043362    
2024-04-05 15:09:30,706 - --- validate (epoch=2)-----------
2024-04-05 15:09:30,707 - 10000 samples (100 per mini-batch)
2024-04-05 15:09:32,222 - Epoch: [2][  100/  100]    Loss 3.134898    Top1 23.160000    Top5 53.050000    
2024-04-05 15:09:32,421 - ==> Top1: 23.160    Top5: 53.050    Loss: 3.135

2024-04-05 15:09:32,428 - ==> Best [Top1: 23.160   Top5: 53.050   Sparsity:0.00   Params: 314624 on epoch: 2]
2024-04-05 15:09:32,428 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:09:32,465 - 

2024-04-05 15:09:32,465 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:09:37,555 - Epoch: [3][  100/  500]    Overall Loss 3.072051    Objective Loss 3.072051                                        LR 0.001000    Time 0.050848    
2024-04-05 15:09:41,901 - Epoch: [3][  200/  500]    Overall Loss 3.049370    Objective Loss 3.049370                                        LR 0.001000    Time 0.047127    
2024-04-05 15:09:45,802 - Epoch: [3][  300/  500]    Overall Loss 3.033870    Objective Loss 3.033870                                        LR 0.001000    Time 0.044407    
2024-04-05 15:09:49,181 - Epoch: [3][  400/  500]    Overall Loss 3.017519    Objective Loss 3.017519                                        LR 0.001000    Time 0.041743    
2024-04-05 15:09:52,717 - Epoch: [3][  500/  500]    Overall Loss 2.997855    Objective Loss 2.997855    Top1 28.500000    Top5 57.000000    LR 0.001000    Time 0.040457    
2024-04-05 15:09:52,855 - --- validate (epoch=3)-----------
2024-04-05 15:09:52,856 - 10000 samples (100 per mini-batch)
2024-04-05 15:09:54,399 - Epoch: [3][  100/  100]    Loss 2.860016    Top1 27.650000    Top5 59.200000    
2024-04-05 15:09:54,598 - ==> Top1: 27.650    Top5: 59.200    Loss: 2.860

2024-04-05 15:09:54,604 - ==> Best [Top1: 27.650   Top5: 59.200   Sparsity:0.00   Params: 314624 on epoch: 3]
2024-04-05 15:09:54,604 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:09:54,640 - 

2024-04-05 15:09:54,640 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:09:59,703 - Epoch: [4][  100/  500]    Overall Loss 2.863450    Objective Loss 2.863450                                        LR 0.001000    Time 0.050568    
2024-04-05 15:10:04,049 - Epoch: [4][  200/  500]    Overall Loss 2.851178    Objective Loss 2.851178                                        LR 0.001000    Time 0.046991    
2024-04-05 15:10:08,371 - Epoch: [4][  300/  500]    Overall Loss 2.843632    Objective Loss 2.843632                                        LR 0.001000    Time 0.045718    
2024-04-05 15:10:12,130 - Epoch: [4][  400/  500]    Overall Loss 2.825560    Objective Loss 2.825560                                        LR 0.001000    Time 0.043676    
2024-04-05 15:10:16,513 - Epoch: [4][  500/  500]    Overall Loss 2.805993    Objective Loss 2.805993    Top1 28.500000    Top5 62.000000    LR 0.001000    Time 0.043696    
2024-04-05 15:10:16,716 - --- validate (epoch=4)-----------
2024-04-05 15:10:16,717 - 10000 samples (100 per mini-batch)
2024-04-05 15:10:18,216 - Epoch: [4][  100/  100]    Loss 2.823732    Top1 28.540000    Top5 59.920000    
2024-04-05 15:10:18,414 - ==> Top1: 28.540    Top5: 59.920    Loss: 2.824

2024-04-05 15:10:18,419 - ==> Best [Top1: 28.540   Top5: 59.920   Sparsity:0.00   Params: 314624 on epoch: 4]
2024-04-05 15:10:18,419 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:10:18,456 - 

2024-04-05 15:10:18,457 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:10:23,317 - Epoch: [5][  100/  500]    Overall Loss 2.686817    Objective Loss 2.686817                                        LR 0.001000    Time 0.048550    
2024-04-05 15:10:27,634 - Epoch: [5][  200/  500]    Overall Loss 2.679701    Objective Loss 2.679701                                        LR 0.001000    Time 0.045836    
2024-04-05 15:10:31,963 - Epoch: [5][  300/  500]    Overall Loss 2.668413    Objective Loss 2.668413                                        LR 0.001000    Time 0.044969    
2024-04-05 15:10:36,001 - Epoch: [5][  400/  500]    Overall Loss 2.665171    Objective Loss 2.665171                                        LR 0.001000    Time 0.043811    
2024-04-05 15:10:40,329 - Epoch: [5][  500/  500]    Overall Loss 2.653180    Objective Loss 2.653180    Top1 33.000000    Top5 67.500000    LR 0.001000    Time 0.043695    
2024-04-05 15:10:40,606 - --- validate (epoch=5)-----------
2024-04-05 15:10:40,606 - 10000 samples (100 per mini-batch)
2024-04-05 15:10:42,095 - Epoch: [5][  100/  100]    Loss 2.606243    Top1 32.900000    Top5 64.830000    
2024-04-05 15:10:42,201 - ==> Top1: 32.900    Top5: 64.830    Loss: 2.606

2024-04-05 15:10:42,206 - ==> Best [Top1: 32.900   Top5: 64.830   Sparsity:0.00   Params: 314624 on epoch: 5]
2024-04-05 15:10:42,206 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:10:42,241 - 

2024-04-05 15:10:42,241 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:10:47,107 - Epoch: [6][  100/  500]    Overall Loss 2.554950    Objective Loss 2.554950                                        LR 0.001000    Time 0.048603    
2024-04-05 15:10:51,573 - Epoch: [6][  200/  500]    Overall Loss 2.556246    Objective Loss 2.556246                                        LR 0.001000    Time 0.046600    
2024-04-05 15:10:56,013 - Epoch: [6][  300/  500]    Overall Loss 2.543081    Objective Loss 2.543081                                        LR 0.001000    Time 0.045848    
2024-04-05 15:10:59,778 - Epoch: [6][  400/  500]    Overall Loss 2.537779    Objective Loss 2.537779                                        LR 0.001000    Time 0.043788    
2024-04-05 15:11:04,239 - Epoch: [6][  500/  500]    Overall Loss 2.528370    Objective Loss 2.528370    Top1 31.500000    Top5 61.000000    LR 0.001000    Time 0.043943    
2024-04-05 15:11:04,418 - --- validate (epoch=6)-----------
2024-04-05 15:11:04,419 - 10000 samples (100 per mini-batch)
2024-04-05 15:11:05,867 - Epoch: [6][  100/  100]    Loss 2.498349    Top1 34.690000    Top5 67.030000    
2024-04-05 15:11:06,033 - ==> Top1: 34.690    Top5: 67.030    Loss: 2.498

2024-04-05 15:11:06,039 - ==> Best [Top1: 34.690   Top5: 67.030   Sparsity:0.00   Params: 314624 on epoch: 6]
2024-04-05 15:11:06,039 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:11:06,327 - 

2024-04-05 15:11:06,327 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:11:10,909 - Epoch: [7][  100/  500]    Overall Loss 2.442503    Objective Loss 2.442503                                        LR 0.001000    Time 0.045767    
2024-04-05 15:11:14,177 - Epoch: [7][  200/  500]    Overall Loss 2.442171    Objective Loss 2.442171                                        LR 0.001000    Time 0.039202    
2024-04-05 15:11:17,286 - Epoch: [7][  300/  500]    Overall Loss 2.435138    Objective Loss 2.435138                                        LR 0.001000    Time 0.036484    
2024-04-05 15:11:20,794 - Epoch: [7][  400/  500]    Overall Loss 2.439120    Objective Loss 2.439120                                        LR 0.001000    Time 0.036124    
2024-04-05 15:11:25,087 - Epoch: [7][  500/  500]    Overall Loss 2.427722    Objective Loss 2.427722    Top1 32.500000    Top5 65.500000    LR 0.001000    Time 0.037475    
2024-04-05 15:11:25,206 - --- validate (epoch=7)-----------
2024-04-05 15:11:25,207 - 10000 samples (100 per mini-batch)
2024-04-05 15:11:26,389 - Epoch: [7][  100/  100]    Loss 2.390035    Top1 37.320000    Top5 69.950000    
2024-04-05 15:11:26,475 - ==> Top1: 37.320    Top5: 69.950    Loss: 2.390

2024-04-05 15:11:26,479 - ==> Best [Top1: 37.320   Top5: 69.950   Sparsity:0.00   Params: 314624 on epoch: 7]
2024-04-05 15:11:26,480 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:11:26,516 - 

2024-04-05 15:11:26,516 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:11:31,192 - Epoch: [8][  100/  500]    Overall Loss 2.326202    Objective Loss 2.326202                                        LR 0.001000    Time 0.046708    
2024-04-05 15:11:35,295 - Epoch: [8][  200/  500]    Overall Loss 2.343739    Objective Loss 2.343739                                        LR 0.001000    Time 0.043845    
2024-04-05 15:11:39,289 - Epoch: [8][  300/  500]    Overall Loss 2.336645    Objective Loss 2.336645                                        LR 0.001000    Time 0.042529    
2024-04-05 15:11:43,044 - Epoch: [8][  400/  500]    Overall Loss 2.341212    Objective Loss 2.341212                                        LR 0.001000    Time 0.041273    
2024-04-05 15:11:47,489 - Epoch: [8][  500/  500]    Overall Loss 2.337858    Objective Loss 2.337858    Top1 40.000000    Top5 70.500000    LR 0.001000    Time 0.041897    
2024-04-05 15:11:47,680 - --- validate (epoch=8)-----------
2024-04-05 15:11:47,680 - 10000 samples (100 per mini-batch)
2024-04-05 15:11:49,374 - Epoch: [8][  100/  100]    Loss 2.374813    Top1 37.340000    Top5 70.070000    
2024-04-05 15:11:49,574 - ==> Top1: 37.340    Top5: 70.070    Loss: 2.375

2024-04-05 15:11:49,580 - ==> Best [Top1: 37.340   Top5: 70.070   Sparsity:0.00   Params: 314624 on epoch: 8]
2024-04-05 15:11:49,580 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:11:49,618 - 

2024-04-05 15:11:49,619 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:11:54,518 - Epoch: [9][  100/  500]    Overall Loss 2.246976    Objective Loss 2.246976                                        LR 0.001000    Time 0.048945    
2024-04-05 15:11:59,033 - Epoch: [9][  200/  500]    Overall Loss 2.262861    Objective Loss 2.262861                                        LR 0.001000    Time 0.047020    
2024-04-05 15:12:03,404 - Epoch: [9][  300/  500]    Overall Loss 2.265340    Objective Loss 2.265340                                        LR 0.001000    Time 0.045901    
2024-04-05 15:12:07,501 - Epoch: [9][  400/  500]    Overall Loss 2.259280    Objective Loss 2.259280                                        LR 0.001000    Time 0.044656    
2024-04-05 15:12:11,926 - Epoch: [9][  500/  500]    Overall Loss 2.261503    Objective Loss 2.261503    Top1 39.500000    Top5 73.000000    LR 0.001000    Time 0.044565    
2024-04-05 15:12:12,109 - --- validate (epoch=9)-----------
2024-04-05 15:12:12,110 - 10000 samples (100 per mini-batch)
2024-04-05 15:12:13,643 - Epoch: [9][  100/  100]    Loss 2.259945    Top1 40.300000    Top5 72.510000    
2024-04-05 15:12:13,825 - ==> Top1: 40.300    Top5: 72.510    Loss: 2.260

2024-04-05 15:12:13,830 - ==> Best [Top1: 40.300   Top5: 72.510   Sparsity:0.00   Params: 314624 on epoch: 9]
2024-04-05 15:12:13,831 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:12:13,867 - 

2024-04-05 15:12:13,867 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:12:19,033 - Epoch: [10][  100/  500]    Overall Loss 2.207973    Objective Loss 2.207973                                        LR 0.001000    Time 0.051596    
2024-04-05 15:12:23,473 - Epoch: [10][  200/  500]    Overall Loss 2.206791    Objective Loss 2.206791                                        LR 0.001000    Time 0.047973    
2024-04-05 15:12:27,132 - Epoch: [10][  300/  500]    Overall Loss 2.201771    Objective Loss 2.201771                                        LR 0.001000    Time 0.044166    
2024-04-05 15:12:29,860 - Epoch: [10][  400/  500]    Overall Loss 2.195481    Objective Loss 2.195481                                        LR 0.001000    Time 0.039937    
2024-04-05 15:12:32,426 - Epoch: [10][  500/  500]    Overall Loss 2.196685    Objective Loss 2.196685    Top1 45.000000    Top5 75.000000    LR 0.001000    Time 0.037075    
2024-04-05 15:12:32,633 - --- validate (epoch=10)-----------
2024-04-05 15:12:32,634 - 10000 samples (100 per mini-batch)
2024-04-05 15:12:34,206 - Epoch: [10][  100/  100]    Loss 2.288552    Top1 39.960000    Top5 71.590000    
2024-04-05 15:12:34,397 - ==> Top1: 39.960    Top5: 71.590    Loss: 2.289

2024-04-05 15:12:34,402 - ==> Best [Top1: 40.300   Top5: 72.510   Sparsity:0.00   Params: 314624 on epoch: 9]
2024-04-05 15:12:34,402 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:12:34,432 - 

2024-04-05 15:12:34,432 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:12:39,373 - Epoch: [11][  100/  500]    Overall Loss 2.138690    Objective Loss 2.138690                                        LR 0.001000    Time 0.049354    
2024-04-05 15:12:43,851 - Epoch: [11][  200/  500]    Overall Loss 2.146869    Objective Loss 2.146869                                        LR 0.001000    Time 0.047037    
2024-04-05 15:12:48,293 - Epoch: [11][  300/  500]    Overall Loss 2.139949    Objective Loss 2.139949                                        LR 0.001000    Time 0.046151    
2024-04-05 15:12:52,348 - Epoch: [11][  400/  500]    Overall Loss 2.136081    Objective Loss 2.136081                                        LR 0.001000    Time 0.044739    
2024-04-05 15:12:56,746 - Epoch: [11][  500/  500]    Overall Loss 2.138539    Objective Loss 2.138539    Top1 40.500000    Top5 71.500000    LR 0.001000    Time 0.044577    
2024-04-05 15:12:56,938 - --- validate (epoch=11)-----------
2024-04-05 15:12:56,938 - 10000 samples (100 per mini-batch)
2024-04-05 15:12:58,487 - Epoch: [11][  100/  100]    Loss 2.209455    Top1 41.570000    Top5 72.650000    
2024-04-05 15:12:58,662 - ==> Top1: 41.570    Top5: 72.650    Loss: 2.209

2024-04-05 15:12:58,668 - ==> Best [Top1: 41.570   Top5: 72.650   Sparsity:0.00   Params: 314624 on epoch: 11]
2024-04-05 15:12:58,668 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:12:58,705 - 

2024-04-05 15:12:58,705 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:13:03,546 - Epoch: [12][  100/  500]    Overall Loss 2.104700    Objective Loss 2.104700                                        LR 0.001000    Time 0.048350    
2024-04-05 15:13:08,036 - Epoch: [12][  200/  500]    Overall Loss 2.106245    Objective Loss 2.106245                                        LR 0.001000    Time 0.046602    
2024-04-05 15:13:12,442 - Epoch: [12][  300/  500]    Overall Loss 2.096665    Objective Loss 2.096665                                        LR 0.001000    Time 0.045737    
2024-04-05 15:13:16,441 - Epoch: [12][  400/  500]    Overall Loss 2.092317    Objective Loss 2.092317                                        LR 0.001000    Time 0.044289    
2024-04-05 15:13:20,859 - Epoch: [12][  500/  500]    Overall Loss 2.091879    Objective Loss 2.091879    Top1 45.000000    Top5 80.000000    LR 0.001000    Time 0.044256    
2024-04-05 15:13:21,091 - --- validate (epoch=12)-----------
2024-04-05 15:13:21,092 - 10000 samples (100 per mini-batch)
2024-04-05 15:13:22,898 - Epoch: [12][  100/  100]    Loss 2.198807    Top1 41.530000    Top5 73.390000    
2024-04-05 15:13:23,081 - ==> Top1: 41.530    Top5: 73.390    Loss: 2.199

2024-04-05 15:13:23,087 - ==> Best [Top1: 41.570   Top5: 72.650   Sparsity:0.00   Params: 314624 on epoch: 11]
2024-04-05 15:13:23,087 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:13:23,118 - 

2024-04-05 15:13:23,118 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:13:27,997 - Epoch: [13][  100/  500]    Overall Loss 2.021437    Objective Loss 2.021437                                        LR 0.001000    Time 0.048733    
2024-04-05 15:13:32,468 - Epoch: [13][  200/  500]    Overall Loss 2.045432    Objective Loss 2.045432                                        LR 0.001000    Time 0.046697    
2024-04-05 15:13:36,478 - Epoch: [13][  300/  500]    Overall Loss 2.051113    Objective Loss 2.051113                                        LR 0.001000    Time 0.044482    
2024-04-05 15:13:40,923 - Epoch: [13][  400/  500]    Overall Loss 2.047331    Objective Loss 2.047331                                        LR 0.001000    Time 0.044462    
2024-04-05 15:13:45,361 - Epoch: [13][  500/  500]    Overall Loss 2.045550    Objective Loss 2.045550    Top1 46.500000    Top5 72.500000    LR 0.001000    Time 0.044435    
2024-04-05 15:13:45,558 - --- validate (epoch=13)-----------
2024-04-05 15:13:45,559 - 10000 samples (100 per mini-batch)
2024-04-05 15:13:47,052 - Epoch: [13][  100/  100]    Loss 2.109618    Top1 43.480000    Top5 75.320000    
2024-04-05 15:13:47,148 - ==> Top1: 43.480    Top5: 75.320    Loss: 2.110

2024-04-05 15:13:47,153 - ==> Best [Top1: 43.480   Top5: 75.320   Sparsity:0.00   Params: 314624 on epoch: 13]
2024-04-05 15:13:47,153 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:13:47,181 - 

2024-04-05 15:13:47,181 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:13:52,227 - Epoch: [14][  100/  500]    Overall Loss 1.969390    Objective Loss 1.969390                                        LR 0.001000    Time 0.050402    
2024-04-05 15:13:56,603 - Epoch: [14][  200/  500]    Overall Loss 1.992333    Objective Loss 1.992333                                        LR 0.001000    Time 0.047051    
2024-04-05 15:14:00,303 - Epoch: [14][  300/  500]    Overall Loss 2.002099    Objective Loss 2.002099                                        LR 0.001000    Time 0.043685    
2024-04-05 15:14:04,756 - Epoch: [14][  400/  500]    Overall Loss 2.003893    Objective Loss 2.003893                                        LR 0.001000    Time 0.043884    
2024-04-05 15:14:09,202 - Epoch: [14][  500/  500]    Overall Loss 2.002557    Objective Loss 2.002557    Top1 43.500000    Top5 75.500000    LR 0.001000    Time 0.043988    
2024-04-05 15:14:09,448 - --- validate (epoch=14)-----------
2024-04-05 15:14:09,449 - 10000 samples (100 per mini-batch)
2024-04-05 15:14:11,012 - Epoch: [14][  100/  100]    Loss 2.097086    Top1 43.740000    Top5 75.600000    
2024-04-05 15:14:11,207 - ==> Top1: 43.740    Top5: 75.600    Loss: 2.097

2024-04-05 15:14:11,212 - ==> Best [Top1: 43.740   Top5: 75.600   Sparsity:0.00   Params: 314624 on epoch: 14]
2024-04-05 15:14:11,212 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:14:11,249 - 

2024-04-05 15:14:11,249 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:14:15,791 - Epoch: [15][  100/  500]    Overall Loss 1.955844    Objective Loss 1.955844                                        LR 0.001000    Time 0.045354    
2024-04-05 15:14:20,268 - Epoch: [15][  200/  500]    Overall Loss 1.970277    Objective Loss 1.970277                                        LR 0.001000    Time 0.045034    
2024-04-05 15:14:23,917 - Epoch: [15][  300/  500]    Overall Loss 1.969525    Objective Loss 1.969525                                        LR 0.001000    Time 0.042171    
2024-04-05 15:14:28,336 - Epoch: [15][  400/  500]    Overall Loss 1.964125    Objective Loss 1.964125                                        LR 0.001000    Time 0.042663    
2024-04-05 15:14:32,812 - Epoch: [15][  500/  500]    Overall Loss 1.964038    Objective Loss 1.964038    Top1 45.500000    Top5 80.000000    LR 0.001000    Time 0.043073    
2024-04-05 15:14:33,018 - --- validate (epoch=15)-----------
2024-04-05 15:14:33,019 - 10000 samples (100 per mini-batch)
2024-04-05 15:14:34,532 - Epoch: [15][  100/  100]    Loss 2.056123    Top1 44.980000    Top5 75.820000    
2024-04-05 15:14:34,636 - ==> Top1: 44.980    Top5: 75.820    Loss: 2.056

2024-04-05 15:14:34,639 - ==> Best [Top1: 44.980   Top5: 75.820   Sparsity:0.00   Params: 314624 on epoch: 15]
2024-04-05 15:14:34,639 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:14:34,667 - 

2024-04-05 15:14:34,667 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:14:38,871 - Epoch: [16][  100/  500]    Overall Loss 1.895339    Objective Loss 1.895339                                        LR 0.001000    Time 0.041987    
2024-04-05 15:14:43,273 - Epoch: [16][  200/  500]    Overall Loss 1.917164    Objective Loss 1.917164                                        LR 0.001000    Time 0.042979    
2024-04-05 15:14:47,226 - Epoch: [16][  300/  500]    Overall Loss 1.921343    Objective Loss 1.921343                                        LR 0.001000    Time 0.041815    
2024-04-05 15:14:51,671 - Epoch: [16][  400/  500]    Overall Loss 1.921760    Objective Loss 1.921760                                        LR 0.001000    Time 0.042461    
2024-04-05 15:14:56,103 - Epoch: [16][  500/  500]    Overall Loss 1.922905    Objective Loss 1.922905    Top1 48.500000    Top5 82.000000    LR 0.001000    Time 0.042824    
2024-04-05 15:14:56,243 - --- validate (epoch=16)-----------
2024-04-05 15:14:56,244 - 10000 samples (100 per mini-batch)
2024-04-05 15:14:57,701 - Epoch: [16][  100/  100]    Loss 2.067205    Top1 44.890000    Top5 76.340000    
2024-04-05 15:14:57,828 - ==> Top1: 44.890    Top5: 76.340    Loss: 2.067

2024-04-05 15:14:57,831 - ==> Best [Top1: 44.980   Top5: 75.820   Sparsity:0.00   Params: 314624 on epoch: 15]
2024-04-05 15:14:57,831 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:14:57,852 - 

2024-04-05 15:14:57,852 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:15:02,940 - Epoch: [17][  100/  500]    Overall Loss 1.879062    Objective Loss 1.879062                                        LR 0.001000    Time 0.050824    
2024-04-05 15:15:07,224 - Epoch: [17][  200/  500]    Overall Loss 1.883450    Objective Loss 1.883450                                        LR 0.001000    Time 0.046806    
2024-04-05 15:15:11,042 - Epoch: [17][  300/  500]    Overall Loss 1.889469    Objective Loss 1.889469                                        LR 0.001000    Time 0.043916    
2024-04-05 15:15:15,463 - Epoch: [17][  400/  500]    Overall Loss 1.890771    Objective Loss 1.890771                                        LR 0.001000    Time 0.043976    
2024-04-05 15:15:19,868 - Epoch: [17][  500/  500]    Overall Loss 1.894885    Objective Loss 1.894885    Top1 49.000000    Top5 79.000000    LR 0.001000    Time 0.043982    
2024-04-05 15:15:20,097 - --- validate (epoch=17)-----------
2024-04-05 15:15:20,097 - 10000 samples (100 per mini-batch)
2024-04-05 15:15:21,594 - Epoch: [17][  100/  100]    Loss 2.064693    Top1 44.680000    Top5 75.920000    
2024-04-05 15:15:21,757 - ==> Top1: 44.680    Top5: 75.920    Loss: 2.065

2024-04-05 15:15:21,763 - ==> Best [Top1: 44.980   Top5: 75.820   Sparsity:0.00   Params: 314624 on epoch: 15]
2024-04-05 15:15:21,763 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:15:21,792 - 

2024-04-05 15:15:21,793 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:15:26,941 - Epoch: [18][  100/  500]    Overall Loss 1.839415    Objective Loss 1.839415                                        LR 0.001000    Time 0.051429    
2024-04-05 15:15:30,838 - Epoch: [18][  200/  500]    Overall Loss 1.844356    Objective Loss 1.844356                                        LR 0.001000    Time 0.045178    
2024-04-05 15:15:35,209 - Epoch: [18][  300/  500]    Overall Loss 1.855666    Objective Loss 1.855666                                        LR 0.001000    Time 0.044671    
2024-04-05 15:15:39,700 - Epoch: [18][  400/  500]    Overall Loss 1.857118    Objective Loss 1.857118                                        LR 0.001000    Time 0.044718    
2024-04-05 15:15:44,154 - Epoch: [18][  500/  500]    Overall Loss 1.860392    Objective Loss 1.860392    Top1 41.500000    Top5 73.000000    LR 0.001000    Time 0.044672    
2024-04-05 15:15:44,339 - --- validate (epoch=18)-----------
2024-04-05 15:15:44,340 - 10000 samples (100 per mini-batch)
2024-04-05 15:15:45,876 - Epoch: [18][  100/  100]    Loss 2.015164    Top1 45.220000    Top5 76.600000    
2024-04-05 15:15:46,025 - ==> Top1: 45.220    Top5: 76.600    Loss: 2.015

2024-04-05 15:15:46,030 - ==> Best [Top1: 45.220   Top5: 76.600   Sparsity:0.00   Params: 314624 on epoch: 18]
2024-04-05 15:15:46,031 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:15:46,069 - 

2024-04-05 15:15:46,070 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:15:50,821 - Epoch: [19][  100/  500]    Overall Loss 1.843147    Objective Loss 1.843147                                        LR 0.001000    Time 0.047462    
2024-04-05 15:15:55,108 - Epoch: [19][  200/  500]    Overall Loss 1.819674    Objective Loss 1.819674                                        LR 0.001000    Time 0.045138    
2024-04-05 15:15:59,414 - Epoch: [19][  300/  500]    Overall Loss 1.830811    Objective Loss 1.830811                                        LR 0.001000    Time 0.044431    
2024-04-05 15:16:03,846 - Epoch: [19][  400/  500]    Overall Loss 1.829557    Objective Loss 1.829557                                        LR 0.001000    Time 0.044392    
2024-04-05 15:16:08,272 - Epoch: [19][  500/  500]    Overall Loss 1.831494    Objective Loss 1.831494    Top1 47.500000    Top5 77.000000    LR 0.001000    Time 0.044356    
2024-04-05 15:16:08,442 - --- validate (epoch=19)-----------
2024-04-05 15:16:08,443 - 10000 samples (100 per mini-batch)
2024-04-05 15:16:09,824 - Epoch: [19][  100/  100]    Loss 2.006300    Top1 45.950000    Top5 77.050000    
2024-04-05 15:16:09,966 - ==> Top1: 45.950    Top5: 77.050    Loss: 2.006

2024-04-05 15:16:09,972 - ==> Best [Top1: 45.950   Top5: 77.050   Sparsity:0.00   Params: 314624 on epoch: 19]
2024-04-05 15:16:09,973 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:16:10,008 - 

2024-04-05 15:16:10,008 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:16:14,824 - Epoch: [20][  100/  500]    Overall Loss 1.799368    Objective Loss 1.799368                                        LR 0.001000    Time 0.048098    
2024-04-05 15:16:18,636 - Epoch: [20][  200/  500]    Overall Loss 1.797968    Objective Loss 1.797968                                        LR 0.001000    Time 0.043083    
2024-04-05 15:16:22,993 - Epoch: [20][  300/  500]    Overall Loss 1.796258    Objective Loss 1.796258                                        LR 0.001000    Time 0.043230    
2024-04-05 15:16:27,463 - Epoch: [20][  400/  500]    Overall Loss 1.804104    Objective Loss 1.804104                                        LR 0.001000    Time 0.043586    
2024-04-05 15:16:31,879 - Epoch: [20][  500/  500]    Overall Loss 1.805152    Objective Loss 1.805152    Top1 53.000000    Top5 83.500000    LR 0.001000    Time 0.043691    
2024-04-05 15:16:32,058 - --- validate (epoch=20)-----------
2024-04-05 15:16:32,059 - 10000 samples (100 per mini-batch)
2024-04-05 15:16:33,593 - Epoch: [20][  100/  100]    Loss 1.956568    Top1 47.240000    Top5 77.650000    
2024-04-05 15:16:33,734 - ==> Top1: 47.240    Top5: 77.650    Loss: 1.957

2024-04-05 15:16:33,740 - ==> Best [Top1: 47.240   Top5: 77.650   Sparsity:0.00   Params: 314624 on epoch: 20]
2024-04-05 15:16:33,740 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:16:33,779 - 

2024-04-05 15:16:33,779 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:16:38,604 - Epoch: [21][  100/  500]    Overall Loss 1.792797    Objective Loss 1.792797                                        LR 0.001000    Time 0.048198    
2024-04-05 15:16:43,021 - Epoch: [21][  200/  500]    Overall Loss 1.780461    Objective Loss 1.780461                                        LR 0.001000    Time 0.046161    
2024-04-05 15:16:47,365 - Epoch: [21][  300/  500]    Overall Loss 1.781355    Objective Loss 1.781355                                        LR 0.001000    Time 0.045239    
2024-04-05 15:16:51,781 - Epoch: [21][  400/  500]    Overall Loss 1.777463    Objective Loss 1.777463                                        LR 0.001000    Time 0.044954    
2024-04-05 15:16:56,162 - Epoch: [21][  500/  500]    Overall Loss 1.776004    Objective Loss 1.776004    Top1 49.000000    Top5 78.500000    LR 0.001000    Time 0.044717    
2024-04-05 15:16:56,431 - --- validate (epoch=21)-----------
2024-04-05 15:16:56,432 - 10000 samples (100 per mini-batch)
2024-04-05 15:16:57,958 - Epoch: [21][  100/  100]    Loss 1.968213    Top1 47.000000    Top5 77.760000    
2024-04-05 15:16:58,157 - ==> Top1: 47.000    Top5: 77.760    Loss: 1.968

2024-04-05 15:16:58,162 - ==> Best [Top1: 47.240   Top5: 77.650   Sparsity:0.00   Params: 314624 on epoch: 20]
2024-04-05 15:16:58,163 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:16:58,192 - 

2024-04-05 15:16:58,192 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:17:02,517 - Epoch: [22][  100/  500]    Overall Loss 1.737062    Objective Loss 1.737062                                        LR 0.001000    Time 0.043196    
2024-04-05 15:17:06,891 - Epoch: [22][  200/  500]    Overall Loss 1.733125    Objective Loss 1.733125                                        LR 0.001000    Time 0.043443    
2024-04-05 15:17:11,217 - Epoch: [22][  300/  500]    Overall Loss 1.737049    Objective Loss 1.737049                                        LR 0.001000    Time 0.043366    
2024-04-05 15:17:15,611 - Epoch: [22][  400/  500]    Overall Loss 1.747483    Objective Loss 1.747483                                        LR 0.001000    Time 0.043496    
2024-04-05 15:17:19,997 - Epoch: [22][  500/  500]    Overall Loss 1.753537    Objective Loss 1.753537    Top1 49.500000    Top5 82.500000    LR 0.001000    Time 0.043560    
2024-04-05 15:17:20,143 - --- validate (epoch=22)-----------
2024-04-05 15:17:20,143 - 10000 samples (100 per mini-batch)
2024-04-05 15:17:21,865 - Epoch: [22][  100/  100]    Loss 1.946675    Top1 47.450000    Top5 78.460000    
2024-04-05 15:17:21,995 - ==> Top1: 47.450    Top5: 78.460    Loss: 1.947

2024-04-05 15:17:22,000 - ==> Best [Top1: 47.450   Top5: 78.460   Sparsity:0.00   Params: 314624 on epoch: 22]
2024-04-05 15:17:22,001 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:17:22,036 - 

2024-04-05 15:17:22,036 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:17:25,964 - Epoch: [23][  100/  500]    Overall Loss 1.730246    Objective Loss 1.730246                                        LR 0.001000    Time 0.039238    
2024-04-05 15:17:30,359 - Epoch: [23][  200/  500]    Overall Loss 1.724108    Objective Loss 1.724108                                        LR 0.001000    Time 0.041568    
2024-04-05 15:17:34,790 - Epoch: [23][  300/  500]    Overall Loss 1.730115    Objective Loss 1.730115                                        LR 0.001000    Time 0.042466    
2024-04-05 15:17:39,234 - Epoch: [23][  400/  500]    Overall Loss 1.730162    Objective Loss 1.730162                                        LR 0.001000    Time 0.042946    
2024-04-05 15:17:43,652 - Epoch: [23][  500/  500]    Overall Loss 1.732843    Objective Loss 1.732843    Top1 50.500000    Top5 77.000000    LR 0.001000    Time 0.043183    
2024-04-05 15:17:43,834 - --- validate (epoch=23)-----------
2024-04-05 15:17:43,834 - 10000 samples (100 per mini-batch)
2024-04-05 15:17:45,380 - Epoch: [23][  100/  100]    Loss 1.969417    Top1 47.140000    Top5 77.900000    
2024-04-05 15:17:45,560 - ==> Top1: 47.140    Top5: 77.900    Loss: 1.969

2024-04-05 15:17:45,568 - ==> Best [Top1: 47.450   Top5: 78.460   Sparsity:0.00   Params: 314624 on epoch: 22]
2024-04-05 15:17:45,568 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:17:45,598 - 

2024-04-05 15:17:45,599 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:17:49,958 - Epoch: [24][  100/  500]    Overall Loss 1.668917    Objective Loss 1.668917                                        LR 0.001000    Time 0.043538    
2024-04-05 15:17:54,293 - Epoch: [24][  200/  500]    Overall Loss 1.681698    Objective Loss 1.681698                                        LR 0.001000    Time 0.043421    
2024-04-05 15:17:58,672 - Epoch: [24][  300/  500]    Overall Loss 1.682047    Objective Loss 1.682047                                        LR 0.001000    Time 0.043526    
2024-04-05 15:18:03,072 - Epoch: [24][  400/  500]    Overall Loss 1.690184    Objective Loss 1.690184                                        LR 0.001000    Time 0.043632    
2024-04-05 15:18:07,500 - Epoch: [24][  500/  500]    Overall Loss 1.696783    Objective Loss 1.696783    Top1 52.000000    Top5 85.500000    LR 0.001000    Time 0.043753    
2024-04-05 15:18:07,675 - --- validate (epoch=24)-----------
2024-04-05 15:18:07,675 - 10000 samples (100 per mini-batch)
2024-04-05 15:18:09,287 - Epoch: [24][  100/  100]    Loss 1.872103    Top1 49.100000    Top5 79.360000    
2024-04-05 15:18:09,438 - ==> Top1: 49.100    Top5: 79.360    Loss: 1.872

2024-04-05 15:18:09,441 - ==> Best [Top1: 49.100   Top5: 79.360   Sparsity:0.00   Params: 314624 on epoch: 24]
2024-04-05 15:18:09,441 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:18:09,472 - 

2024-04-05 15:18:09,472 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:18:14,168 - Epoch: [25][  100/  500]    Overall Loss 1.674028    Objective Loss 1.674028                                        LR 0.001000    Time 0.046910    
2024-04-05 15:18:18,583 - Epoch: [25][  200/  500]    Overall Loss 1.674558    Objective Loss 1.674558                                        LR 0.001000    Time 0.045500    
2024-04-05 15:18:23,022 - Epoch: [25][  300/  500]    Overall Loss 1.676901    Objective Loss 1.676901                                        LR 0.001000    Time 0.045115    
2024-04-05 15:18:27,414 - Epoch: [25][  400/  500]    Overall Loss 1.678981    Objective Loss 1.678981                                        LR 0.001000    Time 0.044805    
2024-04-05 15:18:31,835 - Epoch: [25][  500/  500]    Overall Loss 1.685959    Objective Loss 1.685959    Top1 54.000000    Top5 79.000000    LR 0.001000    Time 0.044677    
2024-04-05 15:18:32,029 - --- validate (epoch=25)-----------
2024-04-05 15:18:32,031 - 10000 samples (100 per mini-batch)
2024-04-05 15:18:33,611 - Epoch: [25][  100/  100]    Loss 1.900550    Top1 48.780000    Top5 79.270000    
2024-04-05 15:18:33,758 - ==> Top1: 48.780    Top5: 79.270    Loss: 1.901

2024-04-05 15:18:33,762 - ==> Best [Top1: 49.100   Top5: 79.360   Sparsity:0.00   Params: 314624 on epoch: 24]
2024-04-05 15:18:33,762 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:18:33,785 - 

2024-04-05 15:18:33,786 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:18:38,609 - Epoch: [26][  100/  500]    Overall Loss 1.623816    Objective Loss 1.623816                                        LR 0.001000    Time 0.048174    
2024-04-05 15:18:42,931 - Epoch: [26][  200/  500]    Overall Loss 1.632512    Objective Loss 1.632512                                        LR 0.001000    Time 0.045675    
2024-04-05 15:18:47,318 - Epoch: [26][  300/  500]    Overall Loss 1.653671    Objective Loss 1.653671                                        LR 0.001000    Time 0.045056    
2024-04-05 15:18:51,686 - Epoch: [26][  400/  500]    Overall Loss 1.665061    Objective Loss 1.665061                                        LR 0.001000    Time 0.044698    
2024-04-05 15:18:56,094 - Epoch: [26][  500/  500]    Overall Loss 1.666547    Objective Loss 1.666547    Top1 57.000000    Top5 85.500000    LR 0.001000    Time 0.044565    
2024-04-05 15:18:56,277 - --- validate (epoch=26)-----------
2024-04-05 15:18:56,278 - 10000 samples (100 per mini-batch)
2024-04-05 15:18:58,122 - Epoch: [26][  100/  100]    Loss 1.923293    Top1 47.920000    Top5 78.690000    
2024-04-05 15:18:58,321 - ==> Top1: 47.920    Top5: 78.690    Loss: 1.923

2024-04-05 15:18:58,327 - ==> Best [Top1: 49.100   Top5: 79.360   Sparsity:0.00   Params: 314624 on epoch: 24]
2024-04-05 15:18:58,327 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:18:58,357 - 

2024-04-05 15:18:58,357 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:19:03,408 - Epoch: [27][  100/  500]    Overall Loss 1.599827    Objective Loss 1.599827                                        LR 0.001000    Time 0.050449    
2024-04-05 15:19:07,863 - Epoch: [27][  200/  500]    Overall Loss 1.612192    Objective Loss 1.612192                                        LR 0.001000    Time 0.047475    
2024-04-05 15:19:12,283 - Epoch: [27][  300/  500]    Overall Loss 1.629206    Objective Loss 1.629206                                        LR 0.001000    Time 0.046364    
2024-04-05 15:19:16,692 - Epoch: [27][  400/  500]    Overall Loss 1.632420    Objective Loss 1.632420                                        LR 0.001000    Time 0.045783    
2024-04-05 15:19:20,872 - Epoch: [27][  500/  500]    Overall Loss 1.644723    Objective Loss 1.644723    Top1 53.000000    Top5 84.500000    LR 0.001000    Time 0.044977    
2024-04-05 15:19:21,070 - --- validate (epoch=27)-----------
2024-04-05 15:19:21,071 - 10000 samples (100 per mini-batch)
2024-04-05 15:19:22,830 - Epoch: [27][  100/  100]    Loss 1.908461    Top1 48.720000    Top5 79.070000    
2024-04-05 15:19:23,015 - ==> Top1: 48.720    Top5: 79.070    Loss: 1.908

2024-04-05 15:19:23,022 - ==> Best [Top1: 49.100   Top5: 79.360   Sparsity:0.00   Params: 314624 on epoch: 24]
2024-04-05 15:19:23,022 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:19:23,051 - 

2024-04-05 15:19:23,052 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:19:28,153 - Epoch: [28][  100/  500]    Overall Loss 1.622366    Objective Loss 1.622366                                        LR 0.001000    Time 0.050964    
2024-04-05 15:19:32,576 - Epoch: [28][  200/  500]    Overall Loss 1.621368    Objective Loss 1.621368                                        LR 0.001000    Time 0.047570    
2024-04-05 15:19:36,938 - Epoch: [28][  300/  500]    Overall Loss 1.619956    Objective Loss 1.619956                                        LR 0.001000    Time 0.046237    
2024-04-05 15:19:41,302 - Epoch: [28][  400/  500]    Overall Loss 1.621248    Objective Loss 1.621248                                        LR 0.001000    Time 0.045575    
2024-04-05 15:19:45,494 - Epoch: [28][  500/  500]    Overall Loss 1.621785    Objective Loss 1.621785    Top1 56.000000    Top5 83.500000    LR 0.001000    Time 0.044835    
2024-04-05 15:19:45,672 - --- validate (epoch=28)-----------
2024-04-05 15:19:45,673 - 10000 samples (100 per mini-batch)
2024-04-05 15:19:47,295 - Epoch: [28][  100/  100]    Loss 1.917518    Top1 48.530000    Top5 79.130000    
2024-04-05 15:19:47,405 - ==> Top1: 48.530    Top5: 79.130    Loss: 1.918

2024-04-05 15:19:47,411 - ==> Best [Top1: 49.100   Top5: 79.360   Sparsity:0.00   Params: 314624 on epoch: 24]
2024-04-05 15:19:47,411 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:19:47,443 - 

2024-04-05 15:19:47,443 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:19:52,351 - Epoch: [29][  100/  500]    Overall Loss 1.597751    Objective Loss 1.597751                                        LR 0.001000    Time 0.049022    
2024-04-05 15:19:56,820 - Epoch: [29][  200/  500]    Overall Loss 1.601746    Objective Loss 1.601746                                        LR 0.001000    Time 0.046831    
2024-04-05 15:20:01,235 - Epoch: [29][  300/  500]    Overall Loss 1.612793    Objective Loss 1.612793                                        LR 0.001000    Time 0.045922    
2024-04-05 15:20:05,657 - Epoch: [29][  400/  500]    Overall Loss 1.611721    Objective Loss 1.611721                                        LR 0.001000    Time 0.045483    
2024-04-05 15:20:09,512 - Epoch: [29][  500/  500]    Overall Loss 1.615059    Objective Loss 1.615059    Top1 57.000000    Top5 87.000000    LR 0.001000    Time 0.044087    
2024-04-05 15:20:09,772 - --- validate (epoch=29)-----------
2024-04-05 15:20:09,772 - 10000 samples (100 per mini-batch)
2024-04-05 15:20:11,315 - Epoch: [29][  100/  100]    Loss 1.867945    Top1 49.400000    Top5 79.310000    
2024-04-05 15:20:11,450 - ==> Top1: 49.400    Top5: 79.310    Loss: 1.868

2024-04-05 15:20:11,456 - ==> Best [Top1: 49.400   Top5: 79.310   Sparsity:0.00   Params: 314624 on epoch: 29]
2024-04-05 15:20:11,456 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:20:11,493 - 

2024-04-05 15:20:11,493 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:20:15,966 - Epoch: [30][  100/  500]    Overall Loss 1.549802    Objective Loss 1.549802                                        LR 0.001000    Time 0.044682    
2024-04-05 15:20:20,356 - Epoch: [30][  200/  500]    Overall Loss 1.561370    Objective Loss 1.561370                                        LR 0.001000    Time 0.044264    
2024-04-05 15:20:24,775 - Epoch: [30][  300/  500]    Overall Loss 1.579784    Objective Loss 1.579784                                        LR 0.001000    Time 0.044222    
2024-04-05 15:20:29,080 - Epoch: [30][  400/  500]    Overall Loss 1.587586    Objective Loss 1.587586                                        LR 0.001000    Time 0.043918    
2024-04-05 15:20:33,481 - Epoch: [30][  500/  500]    Overall Loss 1.594401    Objective Loss 1.594401    Top1 57.500000    Top5 81.000000    LR 0.001000    Time 0.043927    
2024-04-05 15:20:33,653 - --- validate (epoch=30)-----------
2024-04-05 15:20:33,654 - 10000 samples (100 per mini-batch)
2024-04-05 15:20:35,106 - Epoch: [30][  100/  100]    Loss 1.870286    Top1 49.090000    Top5 79.470000    
2024-04-05 15:20:35,221 - ==> Top1: 49.090    Top5: 79.470    Loss: 1.870

2024-04-05 15:20:35,228 - ==> Best [Top1: 49.400   Top5: 79.310   Sparsity:0.00   Params: 314624 on epoch: 29]
2024-04-05 15:20:35,228 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:20:35,259 - 

2024-04-05 15:20:35,260 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:20:40,431 - Epoch: [31][  100/  500]    Overall Loss 1.565584    Objective Loss 1.565584                                        LR 0.001000    Time 0.051661    
2024-04-05 15:20:44,860 - Epoch: [31][  200/  500]    Overall Loss 1.558084    Objective Loss 1.558084                                        LR 0.001000    Time 0.047948    
2024-04-05 15:20:49,282 - Epoch: [31][  300/  500]    Overall Loss 1.562780    Objective Loss 1.562780                                        LR 0.001000    Time 0.046688    
2024-04-05 15:20:53,336 - Epoch: [31][  400/  500]    Overall Loss 1.567404    Objective Loss 1.567404                                        LR 0.001000    Time 0.045139    
2024-04-05 15:20:57,687 - Epoch: [31][  500/  500]    Overall Loss 1.574152    Objective Loss 1.574152    Top1 57.500000    Top5 84.000000    LR 0.001000    Time 0.044804    
2024-04-05 15:20:57,881 - --- validate (epoch=31)-----------
2024-04-05 15:20:57,881 - 10000 samples (100 per mini-batch)
2024-04-05 15:20:59,389 - Epoch: [31][  100/  100]    Loss 1.884381    Top1 49.330000    Top5 79.330000    
2024-04-05 15:20:59,487 - ==> Top1: 49.330    Top5: 79.330    Loss: 1.884

2024-04-05 15:20:59,493 - ==> Best [Top1: 49.400   Top5: 79.310   Sparsity:0.00   Params: 314624 on epoch: 29]
2024-04-05 15:20:59,494 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:20:59,525 - 

2024-04-05 15:20:59,525 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:21:04,644 - Epoch: [32][  100/  500]    Overall Loss 1.543942    Objective Loss 1.543942                                        LR 0.001000    Time 0.051132    
2024-04-05 15:21:09,004 - Epoch: [32][  200/  500]    Overall Loss 1.550273    Objective Loss 1.550273                                        LR 0.001000    Time 0.047340    
2024-04-05 15:21:13,352 - Epoch: [32][  300/  500]    Overall Loss 1.564150    Objective Loss 1.564150                                        LR 0.001000    Time 0.046037    
2024-04-05 15:21:17,403 - Epoch: [32][  400/  500]    Overall Loss 1.557996    Objective Loss 1.557996                                        LR 0.001000    Time 0.044646    
2024-04-05 15:21:21,766 - Epoch: [32][  500/  500]    Overall Loss 1.559924    Objective Loss 1.559924    Top1 55.500000    Top5 88.000000    LR 0.001000    Time 0.044432    
2024-04-05 15:21:21,916 - --- validate (epoch=32)-----------
2024-04-05 15:21:21,917 - 10000 samples (100 per mini-batch)
2024-04-05 15:21:23,442 - Epoch: [32][  100/  100]    Loss 1.807766    Top1 51.510000    Top5 80.470000    
2024-04-05 15:21:23,621 - ==> Top1: 51.510    Top5: 80.470    Loss: 1.808

2024-04-05 15:21:23,627 - ==> Best [Top1: 51.510   Top5: 80.470   Sparsity:0.00   Params: 314624 on epoch: 32]
2024-04-05 15:21:23,627 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:21:23,664 - 

2024-04-05 15:21:23,665 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:21:28,592 - Epoch: [33][  100/  500]    Overall Loss 1.518515    Objective Loss 1.518515                                        LR 0.001000    Time 0.049216    
2024-04-05 15:21:32,996 - Epoch: [33][  200/  500]    Overall Loss 1.529727    Objective Loss 1.529727                                        LR 0.001000    Time 0.046600    
2024-04-05 15:21:37,436 - Epoch: [33][  300/  500]    Overall Loss 1.532778    Objective Loss 1.532778                                        LR 0.001000    Time 0.045850    
2024-04-05 15:21:41,437 - Epoch: [33][  400/  500]    Overall Loss 1.540962    Objective Loss 1.540962                                        LR 0.001000    Time 0.044379    
2024-04-05 15:21:45,898 - Epoch: [33][  500/  500]    Overall Loss 1.546899    Objective Loss 1.546899    Top1 53.500000    Top5 82.000000    LR 0.001000    Time 0.044415    
2024-04-05 15:21:46,087 - --- validate (epoch=33)-----------
2024-04-05 15:21:46,088 - 10000 samples (100 per mini-batch)
2024-04-05 15:21:47,607 - Epoch: [33][  100/  100]    Loss 1.851497    Top1 50.400000    Top5 79.530000    
2024-04-05 15:21:47,752 - ==> Top1: 50.400    Top5: 79.530    Loss: 1.851

2024-04-05 15:21:47,758 - ==> Best [Top1: 51.510   Top5: 80.470   Sparsity:0.00   Params: 314624 on epoch: 32]
2024-04-05 15:21:47,758 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:21:47,790 - 

2024-04-05 15:21:47,790 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:21:52,864 - Epoch: [34][  100/  500]    Overall Loss 1.485595    Objective Loss 1.485595                                        LR 0.001000    Time 0.050680    
2024-04-05 15:21:57,274 - Epoch: [34][  200/  500]    Overall Loss 1.507830    Objective Loss 1.507830                                        LR 0.001000    Time 0.047365    
2024-04-05 15:22:01,140 - Epoch: [34][  300/  500]    Overall Loss 1.513901    Objective Loss 1.513901                                        LR 0.001000    Time 0.044449    
2024-04-05 15:22:05,556 - Epoch: [34][  400/  500]    Overall Loss 1.517343    Objective Loss 1.517343                                        LR 0.001000    Time 0.044365    
2024-04-05 15:22:09,938 - Epoch: [34][  500/  500]    Overall Loss 1.527105    Objective Loss 1.527105    Top1 52.500000    Top5 84.000000    LR 0.001000    Time 0.044246    
2024-04-05 15:22:10,081 - --- validate (epoch=34)-----------
2024-04-05 15:22:10,081 - 10000 samples (100 per mini-batch)
2024-04-05 15:22:11,559 - Epoch: [34][  100/  100]    Loss 1.846003    Top1 49.890000    Top5 80.130000    
2024-04-05 15:22:11,672 - ==> Top1: 49.890    Top5: 80.130    Loss: 1.846

2024-04-05 15:22:11,678 - ==> Best [Top1: 51.510   Top5: 80.470   Sparsity:0.00   Params: 314624 on epoch: 32]
2024-04-05 15:22:11,678 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:22:11,709 - 

2024-04-05 15:22:11,709 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:22:16,599 - Epoch: [35][  100/  500]    Overall Loss 1.472716    Objective Loss 1.472716                                        LR 0.001000    Time 0.048838    
2024-04-05 15:22:21,055 - Epoch: [35][  200/  500]    Overall Loss 1.476506    Objective Loss 1.476506                                        LR 0.001000    Time 0.046678    
2024-04-05 15:22:25,073 - Epoch: [35][  300/  500]    Overall Loss 1.489034    Objective Loss 1.489034                                        LR 0.001000    Time 0.044495    
2024-04-05 15:22:29,510 - Epoch: [35][  400/  500]    Overall Loss 1.501013    Objective Loss 1.501013                                        LR 0.001000    Time 0.044451    
2024-04-05 15:22:33,906 - Epoch: [35][  500/  500]    Overall Loss 1.509898    Objective Loss 1.509898    Top1 53.500000    Top5 84.500000    LR 0.001000    Time 0.044342    
2024-04-05 15:22:34,093 - --- validate (epoch=35)-----------
2024-04-05 15:22:34,094 - 10000 samples (100 per mini-batch)
2024-04-05 15:22:35,592 - Epoch: [35][  100/  100]    Loss 1.795153    Top1 51.290000    Top5 80.520000    
2024-04-05 15:22:35,715 - ==> Top1: 51.290    Top5: 80.520    Loss: 1.795

2024-04-05 15:22:35,721 - ==> Best [Top1: 51.510   Top5: 80.470   Sparsity:0.00   Params: 314624 on epoch: 32]
2024-04-05 15:22:35,722 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:22:35,752 - 

2024-04-05 15:22:35,753 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:22:40,639 - Epoch: [36][  100/  500]    Overall Loss 1.466445    Objective Loss 1.466445                                        LR 0.001000    Time 0.048810    
2024-04-05 15:22:45,057 - Epoch: [36][  200/  500]    Overall Loss 1.476526    Objective Loss 1.476526                                        LR 0.001000    Time 0.046467    
2024-04-05 15:22:48,763 - Epoch: [36][  300/  500]    Overall Loss 1.495438    Objective Loss 1.495438                                        LR 0.001000    Time 0.043316    
2024-04-05 15:22:53,231 - Epoch: [36][  400/  500]    Overall Loss 1.496102    Objective Loss 1.496102                                        LR 0.001000    Time 0.043646    
2024-04-05 15:22:57,668 - Epoch: [36][  500/  500]    Overall Loss 1.499534    Objective Loss 1.499534    Top1 58.000000    Top5 86.000000    LR 0.001000    Time 0.043780    
2024-04-05 15:22:57,838 - --- validate (epoch=36)-----------
2024-04-05 15:22:57,839 - 10000 samples (100 per mini-batch)
2024-04-05 15:22:59,662 - Epoch: [36][  100/  100]    Loss 1.808885    Top1 51.290000    Top5 80.630000    
2024-04-05 15:22:59,841 - ==> Top1: 51.290    Top5: 80.630    Loss: 1.809

2024-04-05 15:22:59,846 - ==> Best [Top1: 51.510   Top5: 80.470   Sparsity:0.00   Params: 314624 on epoch: 32]
2024-04-05 15:22:59,846 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:22:59,876 - 

2024-04-05 15:22:59,877 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:23:04,771 - Epoch: [37][  100/  500]    Overall Loss 1.461406    Objective Loss 1.461406                                        LR 0.001000    Time 0.048887    
2024-04-05 15:23:08,761 - Epoch: [37][  200/  500]    Overall Loss 1.483372    Objective Loss 1.483372                                        LR 0.001000    Time 0.044371    
2024-04-05 15:23:12,850 - Epoch: [37][  300/  500]    Overall Loss 1.479730    Objective Loss 1.479730                                        LR 0.001000    Time 0.043197    
2024-04-05 15:23:17,316 - Epoch: [37][  400/  500]    Overall Loss 1.481428    Objective Loss 1.481428                                        LR 0.001000    Time 0.043549    
2024-04-05 15:23:21,762 - Epoch: [37][  500/  500]    Overall Loss 1.483735    Objective Loss 1.483735    Top1 55.000000    Top5 82.500000    LR 0.001000    Time 0.043720    
2024-04-05 15:23:21,962 - --- validate (epoch=37)-----------
2024-04-05 15:23:21,963 - 10000 samples (100 per mini-batch)
2024-04-05 15:23:23,497 - Epoch: [37][  100/  100]    Loss 1.842704    Top1 50.660000    Top5 80.240000    
2024-04-05 15:23:23,599 - ==> Top1: 50.660    Top5: 80.240    Loss: 1.843

2024-04-05 15:23:23,605 - ==> Best [Top1: 51.510   Top5: 80.470   Sparsity:0.00   Params: 314624 on epoch: 32]
2024-04-05 15:23:23,605 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:23:23,635 - 

2024-04-05 15:23:23,636 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:23:28,733 - Epoch: [38][  100/  500]    Overall Loss 1.441579    Objective Loss 1.441579                                        LR 0.001000    Time 0.050913    
2024-04-05 15:23:32,656 - Epoch: [38][  200/  500]    Overall Loss 1.457383    Objective Loss 1.457383                                        LR 0.001000    Time 0.045049    
2024-04-05 15:23:37,033 - Epoch: [38][  300/  500]    Overall Loss 1.462091    Objective Loss 1.462091                                        LR 0.001000    Time 0.044608    
2024-04-05 15:23:41,423 - Epoch: [38][  400/  500]    Overall Loss 1.464659    Objective Loss 1.464659                                        LR 0.001000    Time 0.044419    
2024-04-05 15:23:45,766 - Epoch: [38][  500/  500]    Overall Loss 1.469905    Objective Loss 1.469905    Top1 60.000000    Top5 87.000000    LR 0.001000    Time 0.044210    
2024-04-05 15:23:45,929 - --- validate (epoch=38)-----------
2024-04-05 15:23:45,930 - 10000 samples (100 per mini-batch)
2024-04-05 15:23:47,460 - Epoch: [38][  100/  100]    Loss 1.787596    Top1 51.910000    Top5 81.000000    
2024-04-05 15:23:47,561 - ==> Top1: 51.910    Top5: 81.000    Loss: 1.788

2024-04-05 15:23:47,567 - ==> Best [Top1: 51.910   Top5: 81.000   Sparsity:0.00   Params: 314624 on epoch: 38]
2024-04-05 15:23:47,567 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:23:47,605 - 

2024-04-05 15:23:47,605 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:23:52,588 - Epoch: [39][  100/  500]    Overall Loss 1.440048    Objective Loss 1.440048                                        LR 0.001000    Time 0.049768    
2024-04-05 15:23:56,701 - Epoch: [39][  200/  500]    Overall Loss 1.439826    Objective Loss 1.439826                                        LR 0.001000    Time 0.045427    
2024-04-05 15:24:01,091 - Epoch: [39][  300/  500]    Overall Loss 1.451414    Objective Loss 1.451414                                        LR 0.001000    Time 0.044898    
2024-04-05 15:24:05,528 - Epoch: [39][  400/  500]    Overall Loss 1.453293    Objective Loss 1.453293                                        LR 0.001000    Time 0.044755    
2024-04-05 15:24:09,982 - Epoch: [39][  500/  500]    Overall Loss 1.453637    Objective Loss 1.453637    Top1 61.500000    Top5 88.500000    LR 0.001000    Time 0.044702    
2024-04-05 15:24:10,153 - --- validate (epoch=39)-----------
2024-04-05 15:24:10,155 - 10000 samples (100 per mini-batch)
2024-04-05 15:24:11,670 - Epoch: [39][  100/  100]    Loss 1.791769    Top1 51.430000    Top5 80.860000    
2024-04-05 15:24:11,780 - ==> Top1: 51.430    Top5: 80.860    Loss: 1.792

2024-04-05 15:24:11,785 - ==> Best [Top1: 51.910   Top5: 81.000   Sparsity:0.00   Params: 314624 on epoch: 38]
2024-04-05 15:24:11,785 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:24:11,816 - 

2024-04-05 15:24:11,817 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:24:15,253 - Epoch: [40][  100/  500]    Overall Loss 1.400104    Objective Loss 1.400104                                        LR 0.001000    Time 0.034326    
2024-04-05 15:24:18,063 - Epoch: [40][  200/  500]    Overall Loss 1.418294    Objective Loss 1.418294                                        LR 0.001000    Time 0.031195    
2024-04-05 15:24:21,772 - Epoch: [40][  300/  500]    Overall Loss 1.430166    Objective Loss 1.430166                                        LR 0.001000    Time 0.033149    
2024-04-05 15:24:26,241 - Epoch: [40][  400/  500]    Overall Loss 1.434999    Objective Loss 1.434999                                        LR 0.001000    Time 0.036020    
2024-04-05 15:24:30,690 - Epoch: [40][  500/  500]    Overall Loss 1.438073    Objective Loss 1.438073    Top1 60.500000    Top5 87.500000    LR 0.001000    Time 0.037704    
2024-04-05 15:24:30,971 - --- validate (epoch=40)-----------
2024-04-05 15:24:30,971 - 10000 samples (100 per mini-batch)
2024-04-05 15:24:32,468 - Epoch: [40][  100/  100]    Loss 1.785963    Top1 51.580000    Top5 81.060000    
2024-04-05 15:24:32,600 - ==> Top1: 51.580    Top5: 81.060    Loss: 1.786

2024-04-05 15:24:32,607 - ==> Best [Top1: 51.910   Top5: 81.000   Sparsity:0.00   Params: 314624 on epoch: 38]
2024-04-05 15:24:32,607 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:24:32,637 - 

2024-04-05 15:24:32,637 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:24:37,733 - Epoch: [41][  100/  500]    Overall Loss 1.415993    Objective Loss 1.415993                                        LR 0.001000    Time 0.050902    
2024-04-05 15:24:41,587 - Epoch: [41][  200/  500]    Overall Loss 1.406655    Objective Loss 1.406655                                        LR 0.001000    Time 0.044701    
2024-04-05 15:24:45,840 - Epoch: [41][  300/  500]    Overall Loss 1.413118    Objective Loss 1.413118                                        LR 0.001000    Time 0.043963    
2024-04-05 15:24:50,304 - Epoch: [41][  400/  500]    Overall Loss 1.420251    Objective Loss 1.420251                                        LR 0.001000    Time 0.044119    
2024-04-05 15:24:54,751 - Epoch: [41][  500/  500]    Overall Loss 1.430882    Objective Loss 1.430882    Top1 62.000000    Top5 85.000000    LR 0.001000    Time 0.044179    
2024-04-05 15:24:54,928 - --- validate (epoch=41)-----------
2024-04-05 15:24:54,929 - 10000 samples (100 per mini-batch)
2024-04-05 15:24:56,373 - Epoch: [41][  100/  100]    Loss 1.832095    Top1 51.020000    Top5 80.130000    
2024-04-05 15:24:56,481 - ==> Top1: 51.020    Top5: 80.130    Loss: 1.832

2024-04-05 15:24:56,487 - ==> Best [Top1: 51.910   Top5: 81.000   Sparsity:0.00   Params: 314624 on epoch: 38]
2024-04-05 15:24:56,487 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:24:56,518 - 

2024-04-05 15:24:56,518 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:25:01,456 - Epoch: [42][  100/  500]    Overall Loss 1.414358    Objective Loss 1.414358                                        LR 0.001000    Time 0.049323    
2024-04-05 15:25:05,426 - Epoch: [42][  200/  500]    Overall Loss 1.403217    Objective Loss 1.403217                                        LR 0.001000    Time 0.044487    
2024-04-05 15:25:09,881 - Epoch: [42][  300/  500]    Overall Loss 1.397594    Objective Loss 1.397594                                        LR 0.001000    Time 0.044489    
2024-04-05 15:25:14,364 - Epoch: [42][  400/  500]    Overall Loss 1.416590    Objective Loss 1.416590                                        LR 0.001000    Time 0.044563    
2024-04-05 15:25:18,827 - Epoch: [42][  500/  500]    Overall Loss 1.421232    Objective Loss 1.421232    Top1 58.000000    Top5 88.500000    LR 0.001000    Time 0.044565    
2024-04-05 15:25:19,006 - --- validate (epoch=42)-----------
2024-04-05 15:25:19,007 - 10000 samples (100 per mini-batch)
2024-04-05 15:25:20,814 - Epoch: [42][  100/  100]    Loss 1.789114    Top1 51.710000    Top5 80.830000    
2024-04-05 15:25:20,993 - ==> Top1: 51.710    Top5: 80.830    Loss: 1.789

2024-04-05 15:25:20,998 - ==> Best [Top1: 51.910   Top5: 81.000   Sparsity:0.00   Params: 314624 on epoch: 38]
2024-04-05 15:25:20,998 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:25:21,029 - 

2024-04-05 15:25:21,029 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:25:25,894 - Epoch: [43][  100/  500]    Overall Loss 1.348844    Objective Loss 1.348844                                        LR 0.001000    Time 0.048585    
2024-04-05 15:25:30,027 - Epoch: [43][  200/  500]    Overall Loss 1.367418    Objective Loss 1.367418                                        LR 0.001000    Time 0.044933    
2024-04-05 15:25:34,445 - Epoch: [43][  300/  500]    Overall Loss 1.381185    Objective Loss 1.381185                                        LR 0.001000    Time 0.044668    
2024-04-05 15:25:38,877 - Epoch: [43][  400/  500]    Overall Loss 1.394346    Objective Loss 1.394346                                        LR 0.001000    Time 0.044568    
2024-04-05 15:25:43,281 - Epoch: [43][  500/  500]    Overall Loss 1.401384    Objective Loss 1.401384    Top1 57.000000    Top5 83.000000    LR 0.001000    Time 0.044452    
2024-04-05 15:25:43,464 - --- validate (epoch=43)-----------
2024-04-05 15:25:43,465 - 10000 samples (100 per mini-batch)
2024-04-05 15:25:45,037 - Epoch: [43][  100/  100]    Loss 1.830009    Top1 51.560000    Top5 80.400000    
2024-04-05 15:25:45,158 - ==> Top1: 51.560    Top5: 80.400    Loss: 1.830

2024-04-05 15:25:45,164 - ==> Best [Top1: 51.910   Top5: 81.000   Sparsity:0.00   Params: 314624 on epoch: 38]
2024-04-05 15:25:45,164 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:25:45,185 - 

2024-04-05 15:25:45,185 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:25:50,104 - Epoch: [44][  100/  500]    Overall Loss 1.384700    Objective Loss 1.384700                                        LR 0.001000    Time 0.049138    
2024-04-05 15:25:54,528 - Epoch: [44][  200/  500]    Overall Loss 1.389989    Objective Loss 1.389989                                        LR 0.001000    Time 0.046665    
2024-04-05 15:25:58,970 - Epoch: [44][  300/  500]    Overall Loss 1.388976    Objective Loss 1.388976                                        LR 0.001000    Time 0.045900    
2024-04-05 15:26:03,411 - Epoch: [44][  400/  500]    Overall Loss 1.387318    Objective Loss 1.387318                                        LR 0.001000    Time 0.045514    
2024-04-05 15:26:07,887 - Epoch: [44][  500/  500]    Overall Loss 1.391388    Objective Loss 1.391388    Top1 60.500000    Top5 85.000000    LR 0.001000    Time 0.045353    
2024-04-05 15:26:08,058 - --- validate (epoch=44)-----------
2024-04-05 15:26:08,058 - 10000 samples (100 per mini-batch)
2024-04-05 15:26:09,576 - Epoch: [44][  100/  100]    Loss 1.816437    Top1 51.590000    Top5 80.580000    
2024-04-05 15:26:09,776 - ==> Top1: 51.590    Top5: 80.580    Loss: 1.816

2024-04-05 15:26:09,781 - ==> Best [Top1: 51.910   Top5: 81.000   Sparsity:0.00   Params: 314624 on epoch: 38]
2024-04-05 15:26:09,782 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:26:09,813 - 

2024-04-05 15:26:09,813 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:26:14,446 - Epoch: [45][  100/  500]    Overall Loss 1.336777    Objective Loss 1.336777                                        LR 0.001000    Time 0.046279    
2024-04-05 15:26:18,936 - Epoch: [45][  200/  500]    Overall Loss 1.347734    Objective Loss 1.347734                                        LR 0.001000    Time 0.045562    
2024-04-05 15:26:23,319 - Epoch: [45][  300/  500]    Overall Loss 1.363498    Objective Loss 1.363498                                        LR 0.001000    Time 0.044970    
2024-04-05 15:26:27,794 - Epoch: [45][  400/  500]    Overall Loss 1.373227    Objective Loss 1.373227                                        LR 0.001000    Time 0.044902    
2024-04-05 15:26:32,262 - Epoch: [45][  500/  500]    Overall Loss 1.382649    Objective Loss 1.382649    Top1 61.500000    Top5 86.000000    LR 0.001000    Time 0.044847    
2024-04-05 15:26:32,454 - --- validate (epoch=45)-----------
2024-04-05 15:26:32,455 - 10000 samples (100 per mini-batch)
2024-04-05 15:26:34,004 - Epoch: [45][  100/  100]    Loss 1.765375    Top1 52.380000    Top5 81.520000    
2024-04-05 15:26:34,171 - ==> Top1: 52.380    Top5: 81.520    Loss: 1.765

2024-04-05 15:26:34,178 - ==> Best [Top1: 52.380   Top5: 81.520   Sparsity:0.00   Params: 314624 on epoch: 45]
2024-04-05 15:26:34,179 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:26:34,216 - 

2024-04-05 15:26:34,216 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:26:38,724 - Epoch: [46][  100/  500]    Overall Loss 1.319863    Objective Loss 1.319863                                        LR 0.001000    Time 0.045026    
2024-04-05 15:26:42,962 - Epoch: [46][  200/  500]    Overall Loss 1.342688    Objective Loss 1.342688                                        LR 0.001000    Time 0.043676    
2024-04-05 15:26:47,372 - Epoch: [46][  300/  500]    Overall Loss 1.350164    Objective Loss 1.350164                                        LR 0.001000    Time 0.043800    
2024-04-05 15:26:51,782 - Epoch: [46][  400/  500]    Overall Loss 1.358404    Objective Loss 1.358404                                        LR 0.001000    Time 0.043864    
2024-04-05 15:26:56,185 - Epoch: [46][  500/  500]    Overall Loss 1.366481    Objective Loss 1.366481    Top1 64.500000    Top5 94.500000    LR 0.001000    Time 0.043886    
2024-04-05 15:26:56,451 - --- validate (epoch=46)-----------
2024-04-05 15:26:56,452 - 10000 samples (100 per mini-batch)
2024-04-05 15:26:58,132 - Epoch: [46][  100/  100]    Loss 1.793955    Top1 51.890000    Top5 81.010000    
2024-04-05 15:26:58,281 - ==> Top1: 51.890    Top5: 81.010    Loss: 1.794

2024-04-05 15:26:58,286 - ==> Best [Top1: 52.380   Top5: 81.520   Sparsity:0.00   Params: 314624 on epoch: 45]
2024-04-05 15:26:58,287 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:26:58,318 - 

2024-04-05 15:26:58,318 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:27:03,489 - Epoch: [47][  100/  500]    Overall Loss 1.322549    Objective Loss 1.322549                                        LR 0.001000    Time 0.051656    
2024-04-05 15:27:07,935 - Epoch: [47][  200/  500]    Overall Loss 1.335817    Objective Loss 1.335817                                        LR 0.001000    Time 0.048035    
2024-04-05 15:27:12,370 - Epoch: [47][  300/  500]    Overall Loss 1.341510    Objective Loss 1.341510                                        LR 0.001000    Time 0.046787    
2024-04-05 15:27:16,801 - Epoch: [47][  400/  500]    Overall Loss 1.349276    Objective Loss 1.349276                                        LR 0.001000    Time 0.046155    
2024-04-05 15:27:21,230 - Epoch: [47][  500/  500]    Overall Loss 1.357021    Objective Loss 1.357021    Top1 62.500000    Top5 89.500000    LR 0.001000    Time 0.045772    
2024-04-05 15:27:21,371 - --- validate (epoch=47)-----------
2024-04-05 15:27:21,372 - 10000 samples (100 per mini-batch)
2024-04-05 15:27:23,042 - Epoch: [47][  100/  100]    Loss 1.753454    Top1 53.390000    Top5 81.550000    
2024-04-05 15:27:23,167 - ==> Top1: 53.390    Top5: 81.550    Loss: 1.753

2024-04-05 15:27:23,173 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:27:23,173 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:27:23,212 - 

2024-04-05 15:27:23,212 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:27:28,347 - Epoch: [48][  100/  500]    Overall Loss 1.341464    Objective Loss 1.341464                                        LR 0.001000    Time 0.051291    
2024-04-05 15:27:32,754 - Epoch: [48][  200/  500]    Overall Loss 1.333393    Objective Loss 1.333393                                        LR 0.001000    Time 0.047653    
2024-04-05 15:27:37,195 - Epoch: [48][  300/  500]    Overall Loss 1.341268    Objective Loss 1.341268                                        LR 0.001000    Time 0.046557    
2024-04-05 15:27:41,671 - Epoch: [48][  400/  500]    Overall Loss 1.340022    Objective Loss 1.340022                                        LR 0.001000    Time 0.046094    
2024-04-05 15:27:45,780 - Epoch: [48][  500/  500]    Overall Loss 1.346548    Objective Loss 1.346548    Top1 59.500000    Top5 86.500000    LR 0.001000    Time 0.045084    
2024-04-05 15:27:45,956 - --- validate (epoch=48)-----------
2024-04-05 15:27:45,957 - 10000 samples (100 per mini-batch)
2024-04-05 15:27:47,489 - Epoch: [48][  100/  100]    Loss 1.755982    Top1 52.900000    Top5 81.350000    
2024-04-05 15:27:47,589 - ==> Top1: 52.900    Top5: 81.350    Loss: 1.756

2024-04-05 15:27:47,594 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:27:47,595 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:27:47,624 - 

2024-04-05 15:27:47,624 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:27:52,560 - Epoch: [49][  100/  500]    Overall Loss 1.315420    Objective Loss 1.315420                                        LR 0.001000    Time 0.049290    
2024-04-05 15:27:57,006 - Epoch: [49][  200/  500]    Overall Loss 1.314484    Objective Loss 1.314484                                        LR 0.001000    Time 0.046849    
2024-04-05 15:28:01,414 - Epoch: [49][  300/  500]    Overall Loss 1.320626    Objective Loss 1.320626                                        LR 0.001000    Time 0.045909    
2024-04-05 15:28:05,785 - Epoch: [49][  400/  500]    Overall Loss 1.331863    Objective Loss 1.331863                                        LR 0.001000    Time 0.045346    
2024-04-05 15:28:09,411 - Epoch: [49][  500/  500]    Overall Loss 1.337022    Objective Loss 1.337022    Top1 61.000000    Top5 87.500000    LR 0.001000    Time 0.043520    
2024-04-05 15:28:09,646 - --- validate (epoch=49)-----------
2024-04-05 15:28:09,647 - 10000 samples (100 per mini-batch)
2024-04-05 15:28:11,204 - Epoch: [49][  100/  100]    Loss 1.746884    Top1 52.610000    Top5 81.480000    
2024-04-05 15:28:11,328 - ==> Top1: 52.610    Top5: 81.480    Loss: 1.747

2024-04-05 15:28:11,332 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:28:11,332 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:28:11,354 - 

2024-04-05 15:28:11,354 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:28:15,991 - Epoch: [50][  100/  500]    Overall Loss 1.316325    Objective Loss 1.316325                                        LR 0.001000    Time 0.046314    
2024-04-05 15:28:20,423 - Epoch: [50][  200/  500]    Overall Loss 1.307534    Objective Loss 1.307534                                        LR 0.001000    Time 0.045291    
2024-04-05 15:28:24,834 - Epoch: [50][  300/  500]    Overall Loss 1.323167    Objective Loss 1.323167                                        LR 0.001000    Time 0.044880    
2024-04-05 15:28:29,254 - Epoch: [50][  400/  500]    Overall Loss 1.323474    Objective Loss 1.323474                                        LR 0.001000    Time 0.044696    
2024-04-05 15:28:32,940 - Epoch: [50][  500/  500]    Overall Loss 1.330713    Objective Loss 1.330713    Top1 56.500000    Top5 88.500000    LR 0.001000    Time 0.043120    
2024-04-05 15:28:33,098 - --- validate (epoch=50)-----------
2024-04-05 15:28:33,099 - 10000 samples (100 per mini-batch)
2024-04-05 15:28:34,674 - Epoch: [50][  100/  100]    Loss 1.793812    Top1 52.190000    Top5 80.950000    
2024-04-05 15:28:34,865 - ==> Top1: 52.190    Top5: 80.950    Loss: 1.794

2024-04-05 15:28:34,871 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:28:34,872 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:28:34,901 - 

2024-04-05 15:28:34,901 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:28:39,951 - Epoch: [51][  100/  500]    Overall Loss 1.254087    Objective Loss 1.254087                                        LR 0.001000    Time 0.050444    
2024-04-05 15:28:44,341 - Epoch: [51][  200/  500]    Overall Loss 1.275034    Objective Loss 1.275034                                        LR 0.001000    Time 0.047145    
2024-04-05 15:28:48,708 - Epoch: [51][  300/  500]    Overall Loss 1.291563    Objective Loss 1.291563                                        LR 0.001000    Time 0.045970    
2024-04-05 15:28:52,951 - Epoch: [51][  400/  500]    Overall Loss 1.306300    Objective Loss 1.306300                                        LR 0.001000    Time 0.045074    
2024-04-05 15:28:56,989 - Epoch: [51][  500/  500]    Overall Loss 1.312458    Objective Loss 1.312458    Top1 60.500000    Top5 88.000000    LR 0.001000    Time 0.044125    
2024-04-05 15:28:57,151 - --- validate (epoch=51)-----------
2024-04-05 15:28:57,152 - 10000 samples (100 per mini-batch)
2024-04-05 15:28:58,646 - Epoch: [51][  100/  100]    Loss 1.797510    Top1 51.700000    Top5 80.840000    
2024-04-05 15:28:58,754 - ==> Top1: 51.700    Top5: 80.840    Loss: 1.798

2024-04-05 15:28:58,759 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:28:58,760 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:28:58,790 - 

2024-04-05 15:28:58,790 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:29:03,703 - Epoch: [52][  100/  500]    Overall Loss 1.265497    Objective Loss 1.265497                                        LR 0.001000    Time 0.049069    
2024-04-05 15:29:08,140 - Epoch: [52][  200/  500]    Overall Loss 1.274725    Objective Loss 1.274725                                        LR 0.001000    Time 0.046693    
2024-04-05 15:29:12,616 - Epoch: [52][  300/  500]    Overall Loss 1.278072    Objective Loss 1.278072                                        LR 0.001000    Time 0.046034    
2024-04-05 15:29:16,315 - Epoch: [52][  400/  500]    Overall Loss 1.292368    Objective Loss 1.292368                                        LR 0.001000    Time 0.043761    
2024-04-05 15:29:20,762 - Epoch: [52][  500/  500]    Overall Loss 1.301824    Objective Loss 1.301824    Top1 60.500000    Top5 88.500000    LR 0.001000    Time 0.043893    
2024-04-05 15:29:20,954 - --- validate (epoch=52)-----------
2024-04-05 15:29:20,955 - 10000 samples (100 per mini-batch)
2024-04-05 15:29:22,699 - Epoch: [52][  100/  100]    Loss 1.764524    Top1 52.820000    Top5 81.430000    
2024-04-05 15:29:22,843 - ==> Top1: 52.820    Top5: 81.430    Loss: 1.765

2024-04-05 15:29:22,849 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:29:22,849 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:29:22,879 - 

2024-04-05 15:29:22,879 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:29:27,078 - Epoch: [53][  100/  500]    Overall Loss 1.250883    Objective Loss 1.250883                                        LR 0.001000    Time 0.041939    
2024-04-05 15:29:31,522 - Epoch: [53][  200/  500]    Overall Loss 1.273960    Objective Loss 1.273960                                        LR 0.001000    Time 0.043164    
2024-04-05 15:29:35,918 - Epoch: [53][  300/  500]    Overall Loss 1.289347    Objective Loss 1.289347                                        LR 0.001000    Time 0.043414    
2024-04-05 15:29:39,654 - Epoch: [53][  400/  500]    Overall Loss 1.285431    Objective Loss 1.285431                                        LR 0.001000    Time 0.041890    
2024-04-05 15:29:44,057 - Epoch: [53][  500/  500]    Overall Loss 1.293598    Objective Loss 1.293598    Top1 60.000000    Top5 92.500000    LR 0.001000    Time 0.042307    
2024-04-05 15:29:44,243 - --- validate (epoch=53)-----------
2024-04-05 15:29:44,244 - 10000 samples (100 per mini-batch)
2024-04-05 15:29:45,846 - Epoch: [53][  100/  100]    Loss 1.764459    Top1 52.560000    Top5 81.850000    
2024-04-05 15:29:46,030 - ==> Top1: 52.560    Top5: 81.850    Loss: 1.764

2024-04-05 15:29:46,035 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:29:46,036 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:29:46,068 - 

2024-04-05 15:29:46,068 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:29:51,174 - Epoch: [54][  100/  500]    Overall Loss 1.247643    Objective Loss 1.247643                                        LR 0.001000    Time 0.051011    
2024-04-05 15:29:55,625 - Epoch: [54][  200/  500]    Overall Loss 1.266716    Objective Loss 1.266716                                        LR 0.001000    Time 0.047731    
2024-04-05 15:30:00,047 - Epoch: [54][  300/  500]    Overall Loss 1.275269    Objective Loss 1.275269                                        LR 0.001000    Time 0.046547    
2024-04-05 15:30:03,104 - Epoch: [54][  400/  500]    Overall Loss 1.282464    Objective Loss 1.282464                                        LR 0.001000    Time 0.042542    
2024-04-05 15:30:07,524 - Epoch: [54][  500/  500]    Overall Loss 1.287868    Objective Loss 1.287868    Top1 60.500000    Top5 88.500000    LR 0.001000    Time 0.042863    
2024-04-05 15:30:07,693 - --- validate (epoch=54)-----------
2024-04-05 15:30:07,695 - 10000 samples (100 per mini-batch)
2024-04-05 15:30:09,206 - Epoch: [54][  100/  100]    Loss 1.764673    Top1 53.200000    Top5 81.480000    
2024-04-05 15:30:09,408 - ==> Top1: 53.200    Top5: 81.480    Loss: 1.765

2024-04-05 15:30:09,414 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:30:09,414 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:30:09,444 - 

2024-04-05 15:30:09,445 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:30:14,312 - Epoch: [55][  100/  500]    Overall Loss 1.234159    Objective Loss 1.234159                                        LR 0.001000    Time 0.048624    
2024-04-05 15:30:18,770 - Epoch: [55][  200/  500]    Overall Loss 1.250560    Objective Loss 1.250560                                        LR 0.001000    Time 0.046572    
2024-04-05 15:30:23,173 - Epoch: [55][  300/  500]    Overall Loss 1.259975    Objective Loss 1.259975                                        LR 0.001000    Time 0.045709    
2024-04-05 15:30:26,895 - Epoch: [55][  400/  500]    Overall Loss 1.269365    Objective Loss 1.269365                                        LR 0.001000    Time 0.043575    
2024-04-05 15:30:31,302 - Epoch: [55][  500/  500]    Overall Loss 1.274551    Objective Loss 1.274551    Top1 63.000000    Top5 88.500000    LR 0.001000    Time 0.043665    
2024-04-05 15:30:31,494 - --- validate (epoch=55)-----------
2024-04-05 15:30:31,496 - 10000 samples (100 per mini-batch)
2024-04-05 15:30:33,084 - Epoch: [55][  100/  100]    Loss 1.744528    Top1 53.000000    Top5 81.770000    
2024-04-05 15:30:33,276 - ==> Top1: 53.000    Top5: 81.770    Loss: 1.745

2024-04-05 15:30:33,282 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:30:33,283 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:30:33,312 - 

2024-04-05 15:30:33,313 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:30:37,981 - Epoch: [56][  100/  500]    Overall Loss 1.230228    Objective Loss 1.230228                                        LR 0.001000    Time 0.046635    
2024-04-05 15:30:42,429 - Epoch: [56][  200/  500]    Overall Loss 1.240665    Objective Loss 1.240665                                        LR 0.001000    Time 0.045532    
2024-04-05 15:30:46,565 - Epoch: [56][  300/  500]    Overall Loss 1.244262    Objective Loss 1.244262                                        LR 0.001000    Time 0.044125    
2024-04-05 15:30:50,791 - Epoch: [56][  400/  500]    Overall Loss 1.250625    Objective Loss 1.250625                                        LR 0.001000    Time 0.043648    
2024-04-05 15:30:55,203 - Epoch: [56][  500/  500]    Overall Loss 1.259286    Objective Loss 1.259286    Top1 59.500000    Top5 91.500000    LR 0.001000    Time 0.043732    
2024-04-05 15:30:55,382 - --- validate (epoch=56)-----------
2024-04-05 15:30:55,383 - 10000 samples (100 per mini-batch)
2024-04-05 15:30:56,888 - Epoch: [56][  100/  100]    Loss 1.761944    Top1 53.090000    Top5 81.680000    
2024-04-05 15:30:57,047 - ==> Top1: 53.090    Top5: 81.680    Loss: 1.762

2024-04-05 15:30:57,054 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:30:57,054 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:30:57,084 - 

2024-04-05 15:30:57,085 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:31:02,122 - Epoch: [57][  100/  500]    Overall Loss 1.219571    Objective Loss 1.219571                                        LR 0.001000    Time 0.050323    
2024-04-05 15:31:06,550 - Epoch: [57][  200/  500]    Overall Loss 1.234914    Objective Loss 1.234914                                        LR 0.001000    Time 0.047275    
2024-04-05 15:31:10,327 - Epoch: [57][  300/  500]    Overall Loss 1.244836    Objective Loss 1.244836                                        LR 0.001000    Time 0.044094    
2024-04-05 15:31:14,648 - Epoch: [57][  400/  500]    Overall Loss 1.251759    Objective Loss 1.251759                                        LR 0.001000    Time 0.043861    
2024-04-05 15:31:18,966 - Epoch: [57][  500/  500]    Overall Loss 1.256098    Objective Loss 1.256098    Top1 65.000000    Top5 89.000000    LR 0.001000    Time 0.043716    
2024-04-05 15:31:19,167 - --- validate (epoch=57)-----------
2024-04-05 15:31:19,169 - 10000 samples (100 per mini-batch)
2024-04-05 15:31:20,577 - Epoch: [57][  100/  100]    Loss 1.760203    Top1 53.010000    Top5 81.930000    
2024-04-05 15:31:20,732 - ==> Top1: 53.010    Top5: 81.930    Loss: 1.760

2024-04-05 15:31:20,737 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:31:20,737 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:31:20,756 - 

2024-04-05 15:31:20,757 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:31:25,748 - Epoch: [58][  100/  500]    Overall Loss 1.240849    Objective Loss 1.240849                                        LR 0.001000    Time 0.049864    
2024-04-05 15:31:30,104 - Epoch: [58][  200/  500]    Overall Loss 1.232432    Objective Loss 1.232432                                        LR 0.001000    Time 0.046685    
2024-04-05 15:31:34,054 - Epoch: [58][  300/  500]    Overall Loss 1.235823    Objective Loss 1.235823                                        LR 0.001000    Time 0.044276    
2024-04-05 15:31:38,479 - Epoch: [58][  400/  500]    Overall Loss 1.245008    Objective Loss 1.245008                                        LR 0.001000    Time 0.044257    
2024-04-05 15:31:42,843 - Epoch: [58][  500/  500]    Overall Loss 1.250650    Objective Loss 1.250650    Top1 65.500000    Top5 89.500000    LR 0.001000    Time 0.044124    
2024-04-05 15:31:43,011 - --- validate (epoch=58)-----------
2024-04-05 15:31:43,011 - 10000 samples (100 per mini-batch)
2024-04-05 15:31:44,589 - Epoch: [58][  100/  100]    Loss 1.769426    Top1 52.870000    Top5 81.700000    
2024-04-05 15:31:44,747 - ==> Top1: 52.870    Top5: 81.700    Loss: 1.769

2024-04-05 15:31:44,753 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:31:44,754 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:31:44,783 - 

2024-04-05 15:31:44,784 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:31:49,225 - Epoch: [59][  100/  500]    Overall Loss 1.213736    Objective Loss 1.213736                                        LR 0.001000    Time 0.044359    
2024-04-05 15:31:53,573 - Epoch: [59][  200/  500]    Overall Loss 1.215508    Objective Loss 1.215508                                        LR 0.001000    Time 0.043899    
2024-04-05 15:31:57,552 - Epoch: [59][  300/  500]    Overall Loss 1.219542    Objective Loss 1.219542                                        LR 0.001000    Time 0.042511    
2024-04-05 15:32:02,015 - Epoch: [59][  400/  500]    Overall Loss 1.230078    Objective Loss 1.230078                                        LR 0.001000    Time 0.043029    
2024-04-05 15:32:06,472 - Epoch: [59][  500/  500]    Overall Loss 1.235000    Objective Loss 1.235000    Top1 64.500000    Top5 92.500000    LR 0.001000    Time 0.043327    
2024-04-05 15:32:06,691 - --- validate (epoch=59)-----------
2024-04-05 15:32:06,692 - 10000 samples (100 per mini-batch)
2024-04-05 15:32:08,277 - Epoch: [59][  100/  100]    Loss 1.768732    Top1 52.430000    Top5 81.480000    
2024-04-05 15:32:08,456 - ==> Top1: 52.430    Top5: 81.480    Loss: 1.769

2024-04-05 15:32:08,462 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:32:08,463 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:32:08,494 - 

2024-04-05 15:32:08,494 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:32:13,253 - Epoch: [60][  100/  500]    Overall Loss 1.192906    Objective Loss 1.192906                                        LR 0.001000    Time 0.047531    
2024-04-05 15:32:17,379 - Epoch: [60][  200/  500]    Overall Loss 1.200702    Objective Loss 1.200702                                        LR 0.001000    Time 0.044371    
2024-04-05 15:32:21,766 - Epoch: [60][  300/  500]    Overall Loss 1.207876    Objective Loss 1.207876                                        LR 0.001000    Time 0.044189    
2024-04-05 15:32:26,190 - Epoch: [60][  400/  500]    Overall Loss 1.217181    Objective Loss 1.217181                                        LR 0.001000    Time 0.044189    
2024-04-05 15:32:30,645 - Epoch: [60][  500/  500]    Overall Loss 1.231659    Objective Loss 1.231659    Top1 66.000000    Top5 93.000000    LR 0.001000    Time 0.044251    
2024-04-05 15:32:30,890 - --- validate (epoch=60)-----------
2024-04-05 15:32:30,891 - 10000 samples (100 per mini-batch)
2024-04-05 15:32:32,412 - Epoch: [60][  100/  100]    Loss 1.788098    Top1 52.260000    Top5 81.830000    
2024-04-05 15:32:32,594 - ==> Top1: 52.260    Top5: 81.830    Loss: 1.788

2024-04-05 15:32:32,601 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:32:32,601 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:32:32,633 - 

2024-04-05 15:32:32,633 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:32:37,820 - Epoch: [61][  100/  500]    Overall Loss 1.205066    Objective Loss 1.205066                                        LR 0.001000    Time 0.051815    
2024-04-05 15:32:41,814 - Epoch: [61][  200/  500]    Overall Loss 1.212495    Objective Loss 1.212495                                        LR 0.001000    Time 0.045850    
2024-04-05 15:32:46,037 - Epoch: [61][  300/  500]    Overall Loss 1.219878    Objective Loss 1.219878                                        LR 0.001000    Time 0.044626    
2024-04-05 15:32:50,445 - Epoch: [61][  400/  500]    Overall Loss 1.220795    Objective Loss 1.220795                                        LR 0.001000    Time 0.044476    
2024-04-05 15:32:54,818 - Epoch: [61][  500/  500]    Overall Loss 1.228583    Objective Loss 1.228583    Top1 64.500000    Top5 91.500000    LR 0.001000    Time 0.044318    
2024-04-05 15:32:55,076 - --- validate (epoch=61)-----------
2024-04-05 15:32:55,077 - 10000 samples (100 per mini-batch)
2024-04-05 15:32:56,602 - Epoch: [61][  100/  100]    Loss 1.764971    Top1 53.320000    Top5 81.650000    
2024-04-05 15:32:56,789 - ==> Top1: 53.320    Top5: 81.650    Loss: 1.765

2024-04-05 15:32:56,795 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:32:56,796 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:32:56,827 - 

2024-04-05 15:32:56,827 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:33:01,715 - Epoch: [62][  100/  500]    Overall Loss 1.174028    Objective Loss 1.174028                                        LR 0.001000    Time 0.048807    
2024-04-05 15:33:05,937 - Epoch: [62][  200/  500]    Overall Loss 1.183831    Objective Loss 1.183831                                        LR 0.001000    Time 0.045490    
2024-04-05 15:33:10,339 - Epoch: [62][  300/  500]    Overall Loss 1.197976    Objective Loss 1.197976                                        LR 0.001000    Time 0.044983    
2024-04-05 15:33:14,807 - Epoch: [62][  400/  500]    Overall Loss 1.205368    Objective Loss 1.205368                                        LR 0.001000    Time 0.044895    
2024-04-05 15:33:19,257 - Epoch: [62][  500/  500]    Overall Loss 1.211790    Objective Loss 1.211790    Top1 68.000000    Top5 91.000000    LR 0.001000    Time 0.044805    
2024-04-05 15:33:19,458 - --- validate (epoch=62)-----------
2024-04-05 15:33:19,458 - 10000 samples (100 per mini-batch)
2024-04-05 15:33:21,242 - Epoch: [62][  100/  100]    Loss 1.807151    Top1 52.450000    Top5 81.010000    
2024-04-05 15:33:21,364 - ==> Top1: 52.450    Top5: 81.010    Loss: 1.807

2024-04-05 15:33:21,370 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:33:21,371 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:33:21,401 - 

2024-04-05 15:33:21,401 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:33:25,684 - Epoch: [63][  100/  500]    Overall Loss 1.167740    Objective Loss 1.167740                                        LR 0.001000    Time 0.042783    
2024-04-05 15:33:30,100 - Epoch: [63][  200/  500]    Overall Loss 1.183083    Objective Loss 1.183083                                        LR 0.001000    Time 0.043441    
2024-04-05 15:33:34,493 - Epoch: [63][  300/  500]    Overall Loss 1.192131    Objective Loss 1.192131                                        LR 0.001000    Time 0.043587    
2024-04-05 15:33:38,890 - Epoch: [63][  400/  500]    Overall Loss 1.201813    Objective Loss 1.201813                                        LR 0.001000    Time 0.043669    
2024-04-05 15:33:43,233 - Epoch: [63][  500/  500]    Overall Loss 1.205021    Objective Loss 1.205021    Top1 59.500000    Top5 89.000000    LR 0.001000    Time 0.043611    
2024-04-05 15:33:43,427 - --- validate (epoch=63)-----------
2024-04-05 15:33:43,428 - 10000 samples (100 per mini-batch)
2024-04-05 15:33:44,883 - Epoch: [63][  100/  100]    Loss 1.773096    Top1 53.080000    Top5 81.620000    
2024-04-05 15:33:44,985 - ==> Top1: 53.080    Top5: 81.620    Loss: 1.773

2024-04-05 15:33:44,988 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:33:44,988 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:33:45,008 - 

2024-04-05 15:33:45,008 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:33:48,437 - Epoch: [64][  100/  500]    Overall Loss 1.150137    Objective Loss 1.150137                                        LR 0.001000    Time 0.034247    
2024-04-05 15:33:50,985 - Epoch: [64][  200/  500]    Overall Loss 1.176444    Objective Loss 1.176444                                        LR 0.001000    Time 0.029845    
2024-04-05 15:33:53,529 - Epoch: [64][  300/  500]    Overall Loss 1.176045    Objective Loss 1.176045                                        LR 0.001000    Time 0.028367    
2024-04-05 15:33:56,183 - Epoch: [64][  400/  500]    Overall Loss 1.180159    Objective Loss 1.180159                                        LR 0.001000    Time 0.027902    
2024-04-05 15:33:58,855 - Epoch: [64][  500/  500]    Overall Loss 1.185667    Objective Loss 1.185667    Top1 67.500000    Top5 92.500000    LR 0.001000    Time 0.027659    
2024-04-05 15:33:59,023 - --- validate (epoch=64)-----------
2024-04-05 15:33:59,023 - 10000 samples (100 per mini-batch)
2024-04-05 15:34:00,650 - Epoch: [64][  100/  100]    Loss 1.785786    Top1 52.940000    Top5 81.530000    
2024-04-05 15:34:00,767 - ==> Top1: 52.940    Top5: 81.530    Loss: 1.786

2024-04-05 15:34:00,772 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:34:00,772 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:34:00,799 - 

2024-04-05 15:34:00,799 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:34:05,650 - Epoch: [65][  100/  500]    Overall Loss 1.169956    Objective Loss 1.169956                                        LR 0.001000    Time 0.048458    
2024-04-05 15:34:08,327 - Epoch: [65][  200/  500]    Overall Loss 1.167764    Objective Loss 1.167764                                        LR 0.001000    Time 0.037596    
2024-04-05 15:34:11,445 - Epoch: [65][  300/  500]    Overall Loss 1.182568    Objective Loss 1.182568                                        LR 0.001000    Time 0.035444    
2024-04-05 15:34:14,639 - Epoch: [65][  400/  500]    Overall Loss 1.194823    Objective Loss 1.194823                                        LR 0.001000    Time 0.034558    
2024-04-05 15:34:17,469 - Epoch: [65][  500/  500]    Overall Loss 1.198103    Objective Loss 1.198103    Top1 67.500000    Top5 88.500000    LR 0.001000    Time 0.033301    
2024-04-05 15:34:17,720 - --- validate (epoch=65)-----------
2024-04-05 15:34:17,721 - 10000 samples (100 per mini-batch)
2024-04-05 15:34:19,252 - Epoch: [65][  100/  100]    Loss 1.773993    Top1 53.090000    Top5 81.720000    
2024-04-05 15:34:19,440 - ==> Top1: 53.090    Top5: 81.720    Loss: 1.774

2024-04-05 15:34:19,445 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:34:19,446 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:34:19,475 - 

2024-04-05 15:34:19,475 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:34:24,141 - Epoch: [66][  100/  500]    Overall Loss 1.169027    Objective Loss 1.169027                                        LR 0.001000    Time 0.046601    
2024-04-05 15:34:28,630 - Epoch: [66][  200/  500]    Overall Loss 1.158980    Objective Loss 1.158980                                        LR 0.001000    Time 0.045719    
2024-04-05 15:34:32,666 - Epoch: [66][  300/  500]    Overall Loss 1.163808    Objective Loss 1.163808                                        LR 0.001000    Time 0.043918    
2024-04-05 15:34:36,823 - Epoch: [66][  400/  500]    Overall Loss 1.170870    Objective Loss 1.170870                                        LR 0.001000    Time 0.043318    
2024-04-05 15:34:41,291 - Epoch: [66][  500/  500]    Overall Loss 1.174210    Objective Loss 1.174210    Top1 61.000000    Top5 89.500000    LR 0.001000    Time 0.043581    
2024-04-05 15:34:41,474 - --- validate (epoch=66)-----------
2024-04-05 15:34:41,475 - 10000 samples (100 per mini-batch)
2024-04-05 15:34:43,337 - Epoch: [66][  100/  100]    Loss 1.749540    Top1 53.350000    Top5 82.030000    
2024-04-05 15:34:43,500 - ==> Top1: 53.350    Top5: 82.030    Loss: 1.750

2024-04-05 15:34:43,506 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:34:43,506 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:34:43,537 - 

2024-04-05 15:34:43,538 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:34:48,399 - Epoch: [67][  100/  500]    Overall Loss 1.135493    Objective Loss 1.135493                                        LR 0.001000    Time 0.048555    
2024-04-05 15:34:52,821 - Epoch: [67][  200/  500]    Overall Loss 1.135222    Objective Loss 1.135222                                        LR 0.001000    Time 0.046363    
2024-04-05 15:34:56,665 - Epoch: [67][  300/  500]    Overall Loss 1.146854    Objective Loss 1.146854                                        LR 0.001000    Time 0.043706    
2024-04-05 15:35:01,135 - Epoch: [67][  400/  500]    Overall Loss 1.160394    Objective Loss 1.160394                                        LR 0.001000    Time 0.043941    
2024-04-05 15:35:05,621 - Epoch: [67][  500/  500]    Overall Loss 1.167941    Objective Loss 1.167941    Top1 68.500000    Top5 93.000000    LR 0.001000    Time 0.044114    
2024-04-05 15:35:05,781 - --- validate (epoch=67)-----------
2024-04-05 15:35:05,782 - 10000 samples (100 per mini-batch)
2024-04-05 15:35:07,337 - Epoch: [67][  100/  100]    Loss 1.772270    Top1 52.960000    Top5 81.370000    
2024-04-05 15:35:07,495 - ==> Top1: 52.960    Top5: 81.370    Loss: 1.772

2024-04-05 15:35:07,500 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:35:07,501 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:35:07,531 - 

2024-04-05 15:35:07,532 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:35:12,672 - Epoch: [68][  100/  500]    Overall Loss 1.141699    Objective Loss 1.141699                                        LR 0.001000    Time 0.051357    
2024-04-05 15:35:17,104 - Epoch: [68][  200/  500]    Overall Loss 1.151835    Objective Loss 1.151835                                        LR 0.001000    Time 0.047810    
2024-04-05 15:35:21,164 - Epoch: [68][  300/  500]    Overall Loss 1.160206    Objective Loss 1.160206                                        LR 0.001000    Time 0.045392    
2024-04-05 15:35:25,597 - Epoch: [68][  400/  500]    Overall Loss 1.156740    Objective Loss 1.156740                                        LR 0.001000    Time 0.045115    
2024-04-05 15:35:30,063 - Epoch: [68][  500/  500]    Overall Loss 1.164383    Objective Loss 1.164383    Top1 71.500000    Top5 94.000000    LR 0.001000    Time 0.045013    
2024-04-05 15:35:30,288 - --- validate (epoch=68)-----------
2024-04-05 15:35:30,289 - 10000 samples (100 per mini-batch)
2024-04-05 15:35:31,759 - Epoch: [68][  100/  100]    Loss 1.773406    Top1 53.240000    Top5 81.890000    
2024-04-05 15:35:31,948 - ==> Top1: 53.240    Top5: 81.890    Loss: 1.773

2024-04-05 15:35:31,954 - ==> Best [Top1: 53.390   Top5: 81.550   Sparsity:0.00   Params: 314624 on epoch: 47]
2024-04-05 15:35:31,955 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:35:31,985 - 

2024-04-05 15:35:31,985 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:35:36,902 - Epoch: [69][  100/  500]    Overall Loss 1.119924    Objective Loss 1.119924                                        LR 0.001000    Time 0.049111    
2024-04-05 15:35:40,878 - Epoch: [69][  200/  500]    Overall Loss 1.137095    Objective Loss 1.137095                                        LR 0.001000    Time 0.044413    
2024-04-05 15:35:44,219 - Epoch: [69][  300/  500]    Overall Loss 1.146372    Objective Loss 1.146372                                        LR 0.001000    Time 0.040734    
2024-04-05 15:35:48,691 - Epoch: [69][  400/  500]    Overall Loss 1.153154    Objective Loss 1.153154                                        LR 0.001000    Time 0.041717    
2024-04-05 15:35:53,101 - Epoch: [69][  500/  500]    Overall Loss 1.159805    Objective Loss 1.159805    Top1 67.000000    Top5 92.500000    LR 0.001000    Time 0.042184    
2024-04-05 15:35:53,266 - --- validate (epoch=69)-----------
2024-04-05 15:35:53,267 - 10000 samples (100 per mini-batch)
2024-04-05 15:35:54,829 - Epoch: [69][  100/  100]    Loss 1.750194    Top1 53.760000    Top5 82.090000    
2024-04-05 15:35:54,956 - ==> Top1: 53.760    Top5: 82.090    Loss: 1.750

2024-04-05 15:35:54,962 - ==> Best [Top1: 53.760   Top5: 82.090   Sparsity:0.00   Params: 314624 on epoch: 69]
2024-04-05 15:35:54,963 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:35:54,999 - 

2024-04-05 15:35:54,999 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:36:00,111 - Epoch: [70][  100/  500]    Overall Loss 1.114756    Objective Loss 1.114756                                        LR 0.001000    Time 0.051066    
2024-04-05 15:36:04,059 - Epoch: [70][  200/  500]    Overall Loss 1.119765    Objective Loss 1.119765                                        LR 0.001000    Time 0.045252    
2024-04-05 15:36:08,466 - Epoch: [70][  300/  500]    Overall Loss 1.133018    Objective Loss 1.133018                                        LR 0.001000    Time 0.044842    
2024-04-05 15:36:12,958 - Epoch: [70][  400/  500]    Overall Loss 1.148156    Objective Loss 1.148156                                        LR 0.001000    Time 0.044848    
2024-04-05 15:36:17,433 - Epoch: [70][  500/  500]    Overall Loss 1.147370    Objective Loss 1.147370    Top1 67.000000    Top5 91.000000    LR 0.001000    Time 0.044819    
2024-04-05 15:36:17,592 - --- validate (epoch=70)-----------
2024-04-05 15:36:17,592 - 10000 samples (100 per mini-batch)
2024-04-05 15:36:19,112 - Epoch: [70][  100/  100]    Loss 1.764336    Top1 53.250000    Top5 82.250000    
2024-04-05 15:36:19,213 - ==> Top1: 53.250    Top5: 82.250    Loss: 1.764

2024-04-05 15:36:19,219 - ==> Best [Top1: 53.760   Top5: 82.090   Sparsity:0.00   Params: 314624 on epoch: 69]
2024-04-05 15:36:19,219 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:36:19,250 - 

2024-04-05 15:36:19,251 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:36:24,095 - Epoch: [71][  100/  500]    Overall Loss 1.104548    Objective Loss 1.104548                                        LR 0.001000    Time 0.048376    
2024-04-05 15:36:27,980 - Epoch: [71][  200/  500]    Overall Loss 1.110245    Objective Loss 1.110245                                        LR 0.001000    Time 0.043589    
2024-04-05 15:36:32,421 - Epoch: [71][  300/  500]    Overall Loss 1.121102    Objective Loss 1.121102                                        LR 0.001000    Time 0.043846    
2024-04-05 15:36:36,881 - Epoch: [71][  400/  500]    Overall Loss 1.128839    Objective Loss 1.128839                                        LR 0.001000    Time 0.044020    
2024-04-05 15:36:41,304 - Epoch: [71][  500/  500]    Overall Loss 1.136978    Objective Loss 1.136978    Top1 70.500000    Top5 92.500000    LR 0.001000    Time 0.044054    
2024-04-05 15:36:41,506 - --- validate (epoch=71)-----------
2024-04-05 15:36:41,507 - 10000 samples (100 per mini-batch)
2024-04-05 15:36:42,986 - Epoch: [71][  100/  100]    Loss 1.810100    Top1 52.690000    Top5 81.110000    
2024-04-05 15:36:43,139 - ==> Top1: 52.690    Top5: 81.110    Loss: 1.810

2024-04-05 15:36:43,145 - ==> Best [Top1: 53.760   Top5: 82.090   Sparsity:0.00   Params: 314624 on epoch: 69]
2024-04-05 15:36:43,145 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:36:43,175 - 

2024-04-05 15:36:43,175 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:36:48,249 - Epoch: [72][  100/  500]    Overall Loss 1.110989    Objective Loss 1.110989                                        LR 0.001000    Time 0.050686    
2024-04-05 15:36:52,353 - Epoch: [72][  200/  500]    Overall Loss 1.105425    Objective Loss 1.105425                                        LR 0.001000    Time 0.045837    
2024-04-05 15:36:56,768 - Epoch: [72][  300/  500]    Overall Loss 1.111553    Objective Loss 1.111553                                        LR 0.001000    Time 0.045258    
2024-04-05 15:37:01,160 - Epoch: [72][  400/  500]    Overall Loss 1.129167    Objective Loss 1.129167                                        LR 0.001000    Time 0.044910    
2024-04-05 15:37:05,529 - Epoch: [72][  500/  500]    Overall Loss 1.133621    Objective Loss 1.133621    Top1 65.500000    Top5 89.500000    LR 0.001000    Time 0.044655    
2024-04-05 15:37:05,770 - --- validate (epoch=72)-----------
2024-04-05 15:37:05,770 - 10000 samples (100 per mini-batch)
2024-04-05 15:37:07,398 - Epoch: [72][  100/  100]    Loss 1.751209    Top1 53.730000    Top5 82.300000    
2024-04-05 15:37:07,576 - ==> Top1: 53.730    Top5: 82.300    Loss: 1.751

2024-04-05 15:37:07,582 - ==> Best [Top1: 53.760   Top5: 82.090   Sparsity:0.00   Params: 314624 on epoch: 69]
2024-04-05 15:37:07,583 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:37:07,615 - 

2024-04-05 15:37:07,615 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:37:12,049 - Epoch: [73][  100/  500]    Overall Loss 1.086002    Objective Loss 1.086002                                        LR 0.001000    Time 0.044287    
2024-04-05 15:37:16,193 - Epoch: [73][  200/  500]    Overall Loss 1.094421    Objective Loss 1.094421                                        LR 0.001000    Time 0.042843    
2024-04-05 15:37:20,621 - Epoch: [73][  300/  500]    Overall Loss 1.107887    Objective Loss 1.107887                                        LR 0.001000    Time 0.043304    
2024-04-05 15:37:24,991 - Epoch: [73][  400/  500]    Overall Loss 1.116766    Objective Loss 1.116766                                        LR 0.001000    Time 0.043392    
2024-04-05 15:37:29,383 - Epoch: [73][  500/  500]    Overall Loss 1.126846    Objective Loss 1.126846    Top1 71.000000    Top5 91.500000    LR 0.001000    Time 0.043486    
2024-04-05 15:37:29,567 - --- validate (epoch=73)-----------
2024-04-05 15:37:29,568 - 10000 samples (100 per mini-batch)
2024-04-05 15:37:31,127 - Epoch: [73][  100/  100]    Loss 1.773895    Top1 52.540000    Top5 82.070000    
2024-04-05 15:37:31,226 - ==> Top1: 52.540    Top5: 82.070    Loss: 1.774

2024-04-05 15:37:31,232 - ==> Best [Top1: 53.760   Top5: 82.090   Sparsity:0.00   Params: 314624 on epoch: 69]
2024-04-05 15:37:31,232 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:37:31,264 - 

2024-04-05 15:37:31,264 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:37:35,728 - Epoch: [74][  100/  500]    Overall Loss 1.093116    Objective Loss 1.093116                                        LR 0.001000    Time 0.044597    
2024-04-05 15:37:40,116 - Epoch: [74][  200/  500]    Overall Loss 1.095455    Objective Loss 1.095455                                        LR 0.001000    Time 0.044211    
2024-04-05 15:37:44,529 - Epoch: [74][  300/  500]    Overall Loss 1.112666    Objective Loss 1.112666                                        LR 0.001000    Time 0.044170    
2024-04-05 15:37:48,981 - Epoch: [74][  400/  500]    Overall Loss 1.118047    Objective Loss 1.118047                                        LR 0.001000    Time 0.044244    
2024-04-05 15:37:53,399 - Epoch: [74][  500/  500]    Overall Loss 1.120481    Objective Loss 1.120481    Top1 67.000000    Top5 93.000000    LR 0.001000    Time 0.044221    
2024-04-05 15:37:53,573 - --- validate (epoch=74)-----------
2024-04-05 15:37:53,574 - 10000 samples (100 per mini-batch)
2024-04-05 15:37:55,035 - Epoch: [74][  100/  100]    Loss 1.760283    Top1 53.340000    Top5 82.630000    
2024-04-05 15:37:55,182 - ==> Top1: 53.340    Top5: 82.630    Loss: 1.760

2024-04-05 15:37:55,187 - ==> Best [Top1: 53.760   Top5: 82.090   Sparsity:0.00   Params: 314624 on epoch: 69]
2024-04-05 15:37:55,188 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:37:55,218 - 

2024-04-05 15:37:55,218 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:37:59,683 - Epoch: [75][  100/  500]    Overall Loss 1.089277    Objective Loss 1.089277                                        LR 0.001000    Time 0.044604    
2024-04-05 15:38:04,046 - Epoch: [75][  200/  500]    Overall Loss 1.099679    Objective Loss 1.099679                                        LR 0.001000    Time 0.044093    
2024-04-05 15:38:08,440 - Epoch: [75][  300/  500]    Overall Loss 1.101825    Objective Loss 1.101825                                        LR 0.001000    Time 0.044023    
2024-04-05 15:38:12,916 - Epoch: [75][  400/  500]    Overall Loss 1.106342    Objective Loss 1.106342                                        LR 0.001000    Time 0.044194    
2024-04-05 15:38:17,369 - Epoch: [75][  500/  500]    Overall Loss 1.111721    Objective Loss 1.111721    Top1 60.500000    Top5 90.500000    LR 0.001000    Time 0.044252    
2024-04-05 15:38:17,625 - --- validate (epoch=75)-----------
2024-04-05 15:38:17,627 - 10000 samples (100 per mini-batch)
2024-04-05 15:38:19,195 - Epoch: [75][  100/  100]    Loss 1.825372    Top1 52.410000    Top5 81.030000    
2024-04-05 15:38:19,363 - ==> Top1: 52.410    Top5: 81.030    Loss: 1.825

2024-04-05 15:38:19,368 - ==> Best [Top1: 53.760   Top5: 82.090   Sparsity:0.00   Params: 314624 on epoch: 69]
2024-04-05 15:38:19,369 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:38:19,399 - 

2024-04-05 15:38:19,399 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:38:24,158 - Epoch: [76][  100/  500]    Overall Loss 1.062957    Objective Loss 1.062957                                        LR 0.001000    Time 0.047535    
2024-04-05 15:38:28,496 - Epoch: [76][  200/  500]    Overall Loss 1.091213    Objective Loss 1.091213                                        LR 0.001000    Time 0.045437    
2024-04-05 15:38:32,960 - Epoch: [76][  300/  500]    Overall Loss 1.092214    Objective Loss 1.092214                                        LR 0.001000    Time 0.045155    
2024-04-05 15:38:37,397 - Epoch: [76][  400/  500]    Overall Loss 1.104746    Objective Loss 1.104746                                        LR 0.001000    Time 0.044945    
2024-04-05 15:38:41,849 - Epoch: [76][  500/  500]    Overall Loss 1.112914    Objective Loss 1.112914    Top1 61.500000    Top5 92.000000    LR 0.001000    Time 0.044849    
2024-04-05 15:38:42,008 - --- validate (epoch=76)-----------
2024-04-05 15:38:42,010 - 10000 samples (100 per mini-batch)
2024-04-05 15:38:43,554 - Epoch: [76][  100/  100]    Loss 1.774249    Top1 53.070000    Top5 82.000000    
2024-04-05 15:38:43,742 - ==> Top1: 53.070    Top5: 82.000    Loss: 1.774

2024-04-05 15:38:43,749 - ==> Best [Top1: 53.760   Top5: 82.090   Sparsity:0.00   Params: 314624 on epoch: 69]
2024-04-05 15:38:43,749 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:38:43,789 - 

2024-04-05 15:38:43,789 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:38:48,514 - Epoch: [77][  100/  500]    Overall Loss 1.069376    Objective Loss 1.069376                                        LR 0.001000    Time 0.047178    
2024-04-05 15:38:52,935 - Epoch: [77][  200/  500]    Overall Loss 1.078874    Objective Loss 1.078874                                        LR 0.001000    Time 0.045669    
2024-04-05 15:38:57,382 - Epoch: [77][  300/  500]    Overall Loss 1.077196    Objective Loss 1.077196                                        LR 0.001000    Time 0.045246    
2024-04-05 15:39:01,841 - Epoch: [77][  400/  500]    Overall Loss 1.092822    Objective Loss 1.092822                                        LR 0.001000    Time 0.045070    
2024-04-05 15:39:06,284 - Epoch: [77][  500/  500]    Overall Loss 1.102396    Objective Loss 1.102396    Top1 68.500000    Top5 95.000000    LR 0.001000    Time 0.044932    
2024-04-05 15:39:06,445 - --- validate (epoch=77)-----------
2024-04-05 15:39:06,446 - 10000 samples (100 per mini-batch)
2024-04-05 15:39:08,081 - Epoch: [77][  100/  100]    Loss 1.769206    Top1 53.850000    Top5 82.160000    
2024-04-05 15:39:08,291 - ==> Top1: 53.850    Top5: 82.160    Loss: 1.769

2024-04-05 15:39:08,297 - ==> Best [Top1: 53.850   Top5: 82.160   Sparsity:0.00   Params: 314624 on epoch: 77]
2024-04-05 15:39:08,297 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:39:08,336 - 

2024-04-05 15:39:08,336 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:39:13,435 - Epoch: [78][  100/  500]    Overall Loss 1.058354    Objective Loss 1.058354                                        LR 0.001000    Time 0.050933    
2024-04-05 15:39:17,853 - Epoch: [78][  200/  500]    Overall Loss 1.084689    Objective Loss 1.084689                                        LR 0.001000    Time 0.047531    
2024-04-05 15:39:22,285 - Epoch: [78][  300/  500]    Overall Loss 1.084181    Objective Loss 1.084181                                        LR 0.001000    Time 0.046444    
2024-04-05 15:39:26,730 - Epoch: [78][  400/  500]    Overall Loss 1.090182    Objective Loss 1.090182                                        LR 0.001000    Time 0.045931    
2024-04-05 15:39:30,915 - Epoch: [78][  500/  500]    Overall Loss 1.092789    Objective Loss 1.092789    Top1 66.000000    Top5 92.000000    LR 0.001000    Time 0.045102    
2024-04-05 15:39:31,114 - --- validate (epoch=78)-----------
2024-04-05 15:39:31,115 - 10000 samples (100 per mini-batch)
2024-04-05 15:39:32,748 - Epoch: [78][  100/  100]    Loss 1.776443    Top1 53.650000    Top5 82.330000    
2024-04-05 15:39:32,861 - ==> Top1: 53.650    Top5: 82.330    Loss: 1.776

2024-04-05 15:39:32,867 - ==> Best [Top1: 53.850   Top5: 82.160   Sparsity:0.00   Params: 314624 on epoch: 77]
2024-04-05 15:39:32,867 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:39:32,898 - 

2024-04-05 15:39:32,899 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:39:37,749 - Epoch: [79][  100/  500]    Overall Loss 1.065377    Objective Loss 1.065377                                        LR 0.001000    Time 0.048446    
2024-04-05 15:39:42,183 - Epoch: [79][  200/  500]    Overall Loss 1.073399    Objective Loss 1.073399                                        LR 0.001000    Time 0.046370    
2024-04-05 15:39:46,517 - Epoch: [79][  300/  500]    Overall Loss 1.078403    Objective Loss 1.078403                                        LR 0.001000    Time 0.045343    
2024-04-05 15:39:50,893 - Epoch: [79][  400/  500]    Overall Loss 1.078242    Objective Loss 1.078242                                        LR 0.001000    Time 0.044934    
2024-04-05 15:39:54,600 - Epoch: [79][  500/  500]    Overall Loss 1.083751    Objective Loss 1.083751    Top1 64.000000    Top5 91.500000    LR 0.001000    Time 0.043353    
2024-04-05 15:39:54,774 - --- validate (epoch=79)-----------
2024-04-05 15:39:54,775 - 10000 samples (100 per mini-batch)
2024-04-05 15:39:56,425 - Epoch: [79][  100/  100]    Loss 1.755514    Top1 54.370000    Top5 82.320000    
2024-04-05 15:39:56,538 - ==> Top1: 54.370    Top5: 82.320    Loss: 1.756

2024-04-05 15:39:56,542 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:39:56,542 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:39:56,569 - 

2024-04-05 15:39:56,570 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:40:01,421 - Epoch: [80][  100/  500]    Overall Loss 1.050111    Objective Loss 1.050111                                        LR 0.001000    Time 0.048464    
2024-04-05 15:40:05,823 - Epoch: [80][  200/  500]    Overall Loss 1.048588    Objective Loss 1.048588                                        LR 0.001000    Time 0.046214    
2024-04-05 15:40:10,235 - Epoch: [80][  300/  500]    Overall Loss 1.059182    Objective Loss 1.059182                                        LR 0.001000    Time 0.045500    
2024-04-05 15:40:14,603 - Epoch: [80][  400/  500]    Overall Loss 1.070222    Objective Loss 1.070222                                        LR 0.001000    Time 0.045033    
2024-04-05 15:40:18,581 - Epoch: [80][  500/  500]    Overall Loss 1.080344    Objective Loss 1.080344    Top1 66.500000    Top5 91.000000    LR 0.001000    Time 0.043973    
2024-04-05 15:40:18,821 - --- validate (epoch=80)-----------
2024-04-05 15:40:18,822 - 10000 samples (100 per mini-batch)
2024-04-05 15:40:20,385 - Epoch: [80][  100/  100]    Loss 1.768568    Top1 53.650000    Top5 82.030000    
2024-04-05 15:40:20,514 - ==> Top1: 53.650    Top5: 82.030    Loss: 1.769

2024-04-05 15:40:20,517 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:40:20,517 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:40:20,539 - 

2024-04-05 15:40:20,539 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:40:25,591 - Epoch: [81][  100/  500]    Overall Loss 1.036342    Objective Loss 1.036342                                        LR 0.001000    Time 0.050464    
2024-04-05 15:40:30,006 - Epoch: [81][  200/  500]    Overall Loss 1.054676    Objective Loss 1.054676                                        LR 0.001000    Time 0.047281    
2024-04-05 15:40:34,415 - Epoch: [81][  300/  500]    Overall Loss 1.068411    Objective Loss 1.068411                                        LR 0.001000    Time 0.046201    
2024-04-05 15:40:38,712 - Epoch: [81][  400/  500]    Overall Loss 1.071048    Objective Loss 1.071048                                        LR 0.001000    Time 0.045380    
2024-04-05 15:40:43,041 - Epoch: [81][  500/  500]    Overall Loss 1.077325    Objective Loss 1.077325    Top1 66.500000    Top5 90.000000    LR 0.001000    Time 0.044952    
2024-04-05 15:40:43,207 - --- validate (epoch=81)-----------
2024-04-05 15:40:43,207 - 10000 samples (100 per mini-batch)
2024-04-05 15:40:44,709 - Epoch: [81][  100/  100]    Loss 1.804726    Top1 52.880000    Top5 81.940000    
2024-04-05 15:40:44,870 - ==> Top1: 52.880    Top5: 81.940    Loss: 1.805

2024-04-05 15:40:44,876 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:40:44,877 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:40:44,906 - 

2024-04-05 15:40:44,907 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:40:49,686 - Epoch: [82][  100/  500]    Overall Loss 1.052220    Objective Loss 1.052220                                        LR 0.001000    Time 0.047744    
2024-04-05 15:40:54,085 - Epoch: [82][  200/  500]    Overall Loss 1.053267    Objective Loss 1.053267                                        LR 0.001000    Time 0.045842    
2024-04-05 15:40:58,404 - Epoch: [82][  300/  500]    Overall Loss 1.058087    Objective Loss 1.058087                                        LR 0.001000    Time 0.044941    
2024-04-05 15:41:02,761 - Epoch: [82][  400/  500]    Overall Loss 1.058854    Objective Loss 1.058854                                        LR 0.001000    Time 0.044587    
2024-04-05 15:41:07,205 - Epoch: [82][  500/  500]    Overall Loss 1.063094    Objective Loss 1.063094    Top1 74.000000    Top5 90.000000    LR 0.001000    Time 0.044547    
2024-04-05 15:41:07,407 - --- validate (epoch=82)-----------
2024-04-05 15:41:07,408 - 10000 samples (100 per mini-batch)
2024-04-05 15:41:09,086 - Epoch: [82][  100/  100]    Loss 1.770456    Top1 53.520000    Top5 81.980000    
2024-04-05 15:41:09,253 - ==> Top1: 53.520    Top5: 81.980    Loss: 1.770

2024-04-05 15:41:09,259 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:41:09,260 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:41:09,290 - 

2024-04-05 15:41:09,290 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:41:14,149 - Epoch: [83][  100/  500]    Overall Loss 1.034547    Objective Loss 1.034547                                        LR 0.001000    Time 0.048535    
2024-04-05 15:41:18,589 - Epoch: [83][  200/  500]    Overall Loss 1.042190    Objective Loss 1.042190                                        LR 0.001000    Time 0.046442    
2024-04-05 15:41:22,547 - Epoch: [83][  300/  500]    Overall Loss 1.047144    Objective Loss 1.047144                                        LR 0.001000    Time 0.044142    
2024-04-05 15:41:26,881 - Epoch: [83][  400/  500]    Overall Loss 1.063062    Objective Loss 1.063062                                        LR 0.001000    Time 0.043928    
2024-04-05 15:41:31,271 - Epoch: [83][  500/  500]    Overall Loss 1.063766    Objective Loss 1.063766    Top1 71.500000    Top5 95.000000    LR 0.001000    Time 0.043914    
2024-04-05 15:41:31,452 - --- validate (epoch=83)-----------
2024-04-05 15:41:31,453 - 10000 samples (100 per mini-batch)
2024-04-05 15:41:32,957 - Epoch: [83][  100/  100]    Loss 1.782118    Top1 54.080000    Top5 81.710000    
2024-04-05 15:41:33,136 - ==> Top1: 54.080    Top5: 81.710    Loss: 1.782

2024-04-05 15:41:33,142 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:41:33,142 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:41:33,173 - 

2024-04-05 15:41:33,173 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:41:38,271 - Epoch: [84][  100/  500]    Overall Loss 0.997337    Objective Loss 0.997337                                        LR 0.001000    Time 0.050924    
2024-04-05 15:41:42,646 - Epoch: [84][  200/  500]    Overall Loss 1.022036    Objective Loss 1.022036                                        LR 0.001000    Time 0.047310    
2024-04-05 15:41:46,752 - Epoch: [84][  300/  500]    Overall Loss 1.030359    Objective Loss 1.030359                                        LR 0.001000    Time 0.045213    
2024-04-05 15:41:51,177 - Epoch: [84][  400/  500]    Overall Loss 1.037683    Objective Loss 1.037683                                        LR 0.001000    Time 0.044960    
2024-04-05 15:41:55,615 - Epoch: [84][  500/  500]    Overall Loss 1.048218    Objective Loss 1.048218    Top1 62.000000    Top5 92.500000    LR 0.001000    Time 0.044834    
2024-04-05 15:41:55,799 - --- validate (epoch=84)-----------
2024-04-05 15:41:55,799 - 10000 samples (100 per mini-batch)
2024-04-05 15:41:57,315 - Epoch: [84][  100/  100]    Loss 1.795766    Top1 53.650000    Top5 81.560000    
2024-04-05 15:41:57,420 - ==> Top1: 53.650    Top5: 81.560    Loss: 1.796

2024-04-05 15:41:57,425 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:41:57,426 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:41:57,458 - 

2024-04-05 15:41:57,458 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:42:02,324 - Epoch: [85][  100/  500]    Overall Loss 1.011087    Objective Loss 1.011087                                        LR 0.001000    Time 0.048612    
2024-04-05 15:42:06,533 - Epoch: [85][  200/  500]    Overall Loss 1.034501    Objective Loss 1.034501                                        LR 0.001000    Time 0.045324    
2024-04-05 15:42:10,507 - Epoch: [85][  300/  500]    Overall Loss 1.038724    Objective Loss 1.038724                                        LR 0.001000    Time 0.043448    
2024-04-05 15:42:14,962 - Epoch: [85][  400/  500]    Overall Loss 1.044553    Objective Loss 1.044553                                        LR 0.001000    Time 0.043712    
2024-04-05 15:42:19,435 - Epoch: [85][  500/  500]    Overall Loss 1.047447    Objective Loss 1.047447    Top1 74.500000    Top5 94.500000    LR 0.001000    Time 0.043904    
2024-04-05 15:42:19,628 - --- validate (epoch=85)-----------
2024-04-05 15:42:19,629 - 10000 samples (100 per mini-batch)
2024-04-05 15:42:21,168 - Epoch: [85][  100/  100]    Loss 1.777312    Top1 53.530000    Top5 82.170000    
2024-04-05 15:42:21,360 - ==> Top1: 53.530    Top5: 82.170    Loss: 1.777

2024-04-05 15:42:21,367 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:42:21,368 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:42:21,398 - 

2024-04-05 15:42:21,398 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:42:26,261 - Epoch: [86][  100/  500]    Overall Loss 1.016330    Objective Loss 1.016330                                        LR 0.001000    Time 0.048570    
2024-04-05 15:42:30,008 - Epoch: [86][  200/  500]    Overall Loss 1.013161    Objective Loss 1.013161                                        LR 0.001000    Time 0.042998    
2024-04-05 15:42:34,331 - Epoch: [86][  300/  500]    Overall Loss 1.027227    Objective Loss 1.027227                                        LR 0.001000    Time 0.043057    
2024-04-05 15:42:38,782 - Epoch: [86][  400/  500]    Overall Loss 1.035653    Objective Loss 1.035653                                        LR 0.001000    Time 0.043408    
2024-04-05 15:42:43,229 - Epoch: [86][  500/  500]    Overall Loss 1.041753    Objective Loss 1.041753    Top1 67.500000    Top5 92.500000    LR 0.001000    Time 0.043611    
2024-04-05 15:42:43,506 - --- validate (epoch=86)-----------
2024-04-05 15:42:43,506 - 10000 samples (100 per mini-batch)
2024-04-05 15:42:44,982 - Epoch: [86][  100/  100]    Loss 1.781614    Top1 53.520000    Top5 81.890000    
2024-04-05 15:42:45,083 - ==> Top1: 53.520    Top5: 81.890    Loss: 1.782

2024-04-05 15:42:45,089 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:42:45,089 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:42:45,118 - 

2024-04-05 15:42:45,118 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:42:48,641 - Epoch: [87][  100/  500]    Overall Loss 1.007017    Objective Loss 1.007017                                        LR 0.001000    Time 0.035191    
2024-04-05 15:42:51,319 - Epoch: [87][  200/  500]    Overall Loss 1.000996    Objective Loss 1.000996                                        LR 0.001000    Time 0.030967    
2024-04-05 15:42:53,924 - Epoch: [87][  300/  500]    Overall Loss 1.021876    Objective Loss 1.021876                                        LR 0.001000    Time 0.029319    
2024-04-05 15:42:56,461 - Epoch: [87][  400/  500]    Overall Loss 1.026721    Objective Loss 1.026721                                        LR 0.001000    Time 0.028323    
2024-04-05 15:43:00,817 - Epoch: [87][  500/  500]    Overall Loss 1.035487    Objective Loss 1.035487    Top1 66.000000    Top5 93.000000    LR 0.001000    Time 0.031360    
2024-04-05 15:43:00,992 - --- validate (epoch=87)-----------
2024-04-05 15:43:00,993 - 10000 samples (100 per mini-batch)
2024-04-05 15:43:02,431 - Epoch: [87][  100/  100]    Loss 1.810091    Top1 53.320000    Top5 81.750000    
2024-04-05 15:43:02,582 - ==> Top1: 53.320    Top5: 81.750    Loss: 1.810

2024-04-05 15:43:02,588 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:43:02,589 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:43:02,618 - 

2024-04-05 15:43:02,619 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:43:07,702 - Epoch: [88][  100/  500]    Overall Loss 1.009961    Objective Loss 1.009961                                        LR 0.001000    Time 0.050778    
2024-04-05 15:43:11,553 - Epoch: [88][  200/  500]    Overall Loss 1.033250    Objective Loss 1.033250                                        LR 0.001000    Time 0.044624    
2024-04-05 15:43:15,975 - Epoch: [88][  300/  500]    Overall Loss 1.024651    Objective Loss 1.024651                                        LR 0.001000    Time 0.044471    
2024-04-05 15:43:20,373 - Epoch: [88][  400/  500]    Overall Loss 1.028902    Objective Loss 1.028902                                        LR 0.001000    Time 0.044337    
2024-04-05 15:43:24,651 - Epoch: [88][  500/  500]    Overall Loss 1.031258    Objective Loss 1.031258    Top1 76.000000    Top5 97.500000    LR 0.001000    Time 0.044016    
2024-04-05 15:43:24,818 - --- validate (epoch=88)-----------
2024-04-05 15:43:24,819 - 10000 samples (100 per mini-batch)
2024-04-05 15:43:26,269 - Epoch: [88][  100/  100]    Loss 1.792616    Top1 53.890000    Top5 82.270000    
2024-04-05 15:43:26,408 - ==> Top1: 53.890    Top5: 82.270    Loss: 1.793

2024-04-05 15:43:26,414 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:43:26,414 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:43:26,446 - 

2024-04-05 15:43:26,446 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:43:29,829 - Epoch: [89][  100/  500]    Overall Loss 0.987536    Objective Loss 0.987536                                        LR 0.001000    Time 0.033793    
2024-04-05 15:43:32,426 - Epoch: [89][  200/  500]    Overall Loss 1.004418    Objective Loss 1.004418                                        LR 0.001000    Time 0.029865    
2024-04-05 15:43:35,011 - Epoch: [89][  300/  500]    Overall Loss 1.009623    Objective Loss 1.009623                                        LR 0.001000    Time 0.028515    
2024-04-05 15:43:37,577 - Epoch: [89][  400/  500]    Overall Loss 1.021149    Objective Loss 1.021149                                        LR 0.001000    Time 0.027793    
2024-04-05 15:43:41,207 - Epoch: [89][  500/  500]    Overall Loss 1.024816    Objective Loss 1.024816    Top1 73.000000    Top5 97.000000    LR 0.001000    Time 0.029488    
2024-04-05 15:43:41,395 - --- validate (epoch=89)-----------
2024-04-05 15:43:41,395 - 10000 samples (100 per mini-batch)
2024-04-05 15:43:42,969 - Epoch: [89][  100/  100]    Loss 1.785967    Top1 53.860000    Top5 82.260000    
2024-04-05 15:43:43,072 - ==> Top1: 53.860    Top5: 82.260    Loss: 1.786

2024-04-05 15:43:43,077 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:43:43,078 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:43:43,111 - 

2024-04-05 15:43:43,111 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:43:47,968 - Epoch: [90][  100/  500]    Overall Loss 0.992227    Objective Loss 0.992227                                        LR 0.001000    Time 0.048512    
2024-04-05 15:43:52,368 - Epoch: [90][  200/  500]    Overall Loss 0.999452    Objective Loss 0.999452                                        LR 0.001000    Time 0.046227    
2024-04-05 15:43:56,356 - Epoch: [90][  300/  500]    Overall Loss 1.008948    Objective Loss 1.008948                                        LR 0.001000    Time 0.044096    
2024-04-05 15:44:00,816 - Epoch: [90][  400/  500]    Overall Loss 1.013118    Objective Loss 1.013118                                        LR 0.001000    Time 0.044210    
2024-04-05 15:44:05,263 - Epoch: [90][  500/  500]    Overall Loss 1.020442    Objective Loss 1.020442    Top1 68.500000    Top5 93.000000    LR 0.001000    Time 0.044251    
2024-04-05 15:44:05,450 - --- validate (epoch=90)-----------
2024-04-05 15:44:05,450 - 10000 samples (100 per mini-batch)
2024-04-05 15:44:07,008 - Epoch: [90][  100/  100]    Loss 1.817156    Top1 53.060000    Top5 81.810000    
2024-04-05 15:44:07,181 - ==> Top1: 53.060    Top5: 81.810    Loss: 1.817

2024-04-05 15:44:07,188 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:44:07,188 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:44:07,217 - 

2024-04-05 15:44:07,218 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:44:12,284 - Epoch: [91][  100/  500]    Overall Loss 0.970218    Objective Loss 0.970218                                        LR 0.001000    Time 0.050613    
2024-04-05 15:44:16,760 - Epoch: [91][  200/  500]    Overall Loss 0.991148    Objective Loss 0.991148                                        LR 0.001000    Time 0.047659    
2024-04-05 15:44:20,414 - Epoch: [91][  300/  500]    Overall Loss 1.001774    Objective Loss 1.001774                                        LR 0.001000    Time 0.043936    
2024-04-05 15:44:24,913 - Epoch: [91][  400/  500]    Overall Loss 1.008426    Objective Loss 1.008426                                        LR 0.001000    Time 0.044186    
2024-04-05 15:44:29,370 - Epoch: [91][  500/  500]    Overall Loss 1.016169    Objective Loss 1.016169    Top1 67.500000    Top5 92.000000    LR 0.001000    Time 0.044254    
2024-04-05 15:44:29,559 - --- validate (epoch=91)-----------
2024-04-05 15:44:29,559 - 10000 samples (100 per mini-batch)
2024-04-05 15:44:31,086 - Epoch: [91][  100/  100]    Loss 1.793021    Top1 53.620000    Top5 82.200000    
2024-04-05 15:44:31,213 - ==> Top1: 53.620    Top5: 82.200    Loss: 1.793

2024-04-05 15:44:31,220 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:44:31,220 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:44:31,251 - 

2024-04-05 15:44:31,251 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:44:35,620 - Epoch: [92][  100/  500]    Overall Loss 0.969192    Objective Loss 0.969192                                        LR 0.001000    Time 0.043640    
2024-04-05 15:44:39,760 - Epoch: [92][  200/  500]    Overall Loss 0.986910    Objective Loss 0.986910                                        LR 0.001000    Time 0.042494    
2024-04-05 15:44:43,757 - Epoch: [92][  300/  500]    Overall Loss 0.997556    Objective Loss 0.997556                                        LR 0.001000    Time 0.041638    
2024-04-05 15:44:47,925 - Epoch: [92][  400/  500]    Overall Loss 1.004908    Objective Loss 1.004908                                        LR 0.001000    Time 0.041636    
2024-04-05 15:44:50,465 - Epoch: [92][  500/  500]    Overall Loss 1.012721    Objective Loss 1.012721    Top1 72.000000    Top5 91.000000    LR 0.001000    Time 0.038382    
2024-04-05 15:44:50,648 - --- validate (epoch=92)-----------
2024-04-05 15:44:50,649 - 10000 samples (100 per mini-batch)
2024-04-05 15:44:52,358 - Epoch: [92][  100/  100]    Loss 1.802353    Top1 53.930000    Top5 81.600000    
2024-04-05 15:44:52,459 - ==> Top1: 53.930    Top5: 81.600    Loss: 1.802

2024-04-05 15:44:52,462 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:44:52,462 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:44:52,482 - 

2024-04-05 15:44:52,483 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:44:57,365 - Epoch: [93][  100/  500]    Overall Loss 0.955806    Objective Loss 0.955806                                        LR 0.001000    Time 0.048766    
2024-04-05 15:45:01,179 - Epoch: [93][  200/  500]    Overall Loss 0.988977    Objective Loss 0.988977                                        LR 0.001000    Time 0.043430    
2024-04-05 15:45:04,264 - Epoch: [93][  300/  500]    Overall Loss 0.991881    Objective Loss 0.991881                                        LR 0.001000    Time 0.039225    
2024-04-05 15:45:08,714 - Epoch: [93][  400/  500]    Overall Loss 0.998347    Objective Loss 0.998347                                        LR 0.001000    Time 0.040530    
2024-04-05 15:45:13,146 - Epoch: [93][  500/  500]    Overall Loss 1.005475    Objective Loss 1.005475    Top1 68.500000    Top5 94.500000    LR 0.001000    Time 0.041279    
2024-04-05 15:45:13,320 - --- validate (epoch=93)-----------
2024-04-05 15:45:13,321 - 10000 samples (100 per mini-batch)
2024-04-05 15:45:14,890 - Epoch: [93][  100/  100]    Loss 1.811744    Top1 53.400000    Top5 81.880000    
2024-04-05 15:45:15,033 - ==> Top1: 53.400    Top5: 81.880    Loss: 1.812

2024-04-05 15:45:15,039 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:45:15,039 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:45:15,070 - 

2024-04-05 15:45:15,070 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:45:20,124 - Epoch: [94][  100/  500]    Overall Loss 0.965484    Objective Loss 0.965484                                        LR 0.001000    Time 0.050485    
2024-04-05 15:45:24,566 - Epoch: [94][  200/  500]    Overall Loss 0.976147    Objective Loss 0.976147                                        LR 0.001000    Time 0.047424    
2024-04-05 15:45:28,789 - Epoch: [94][  300/  500]    Overall Loss 0.976557    Objective Loss 0.976557                                        LR 0.001000    Time 0.045673    
2024-04-05 15:45:33,192 - Epoch: [94][  400/  500]    Overall Loss 0.988480    Objective Loss 0.988480                                        LR 0.001000    Time 0.045249    
2024-04-05 15:45:37,614 - Epoch: [94][  500/  500]    Overall Loss 0.997158    Objective Loss 0.997158    Top1 70.000000    Top5 94.500000    LR 0.001000    Time 0.045033    
2024-04-05 15:45:37,795 - --- validate (epoch=94)-----------
2024-04-05 15:45:37,796 - 10000 samples (100 per mini-batch)
2024-04-05 15:45:39,361 - Epoch: [94][  100/  100]    Loss 1.815975    Top1 53.500000    Top5 81.930000    
2024-04-05 15:45:39,530 - ==> Top1: 53.500    Top5: 81.930    Loss: 1.816

2024-04-05 15:45:39,536 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:45:39,536 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:45:39,565 - 

2024-04-05 15:45:39,566 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:45:44,432 - Epoch: [95][  100/  500]    Overall Loss 0.974948    Objective Loss 0.974948                                        LR 0.001000    Time 0.048600    
2024-04-05 15:45:48,350 - Epoch: [95][  200/  500]    Overall Loss 0.975339    Objective Loss 0.975339                                        LR 0.001000    Time 0.043868    
2024-04-05 15:45:50,836 - Epoch: [95][  300/  500]    Overall Loss 0.982051    Objective Loss 0.982051                                        LR 0.001000    Time 0.037521    
2024-04-05 15:45:54,650 - Epoch: [95][  400/  500]    Overall Loss 0.996662    Objective Loss 0.996662                                        LR 0.001000    Time 0.037665    
2024-04-05 15:45:59,089 - Epoch: [95][  500/  500]    Overall Loss 1.000206    Objective Loss 1.000206    Top1 69.500000    Top5 93.000000    LR 0.001000    Time 0.039000    
2024-04-05 15:45:59,247 - --- validate (epoch=95)-----------
2024-04-05 15:45:59,248 - 10000 samples (100 per mini-batch)
2024-04-05 15:46:00,744 - Epoch: [95][  100/  100]    Loss 1.866161    Top1 52.600000    Top5 80.820000    
2024-04-05 15:46:00,899 - ==> Top1: 52.600    Top5: 80.820    Loss: 1.866

2024-04-05 15:46:00,905 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:46:00,905 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:46:00,936 - 

2024-04-05 15:46:00,936 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:46:05,787 - Epoch: [96][  100/  500]    Overall Loss 0.976740    Objective Loss 0.976740                                        LR 0.001000    Time 0.048452    
2024-04-05 15:46:10,186 - Epoch: [96][  200/  500]    Overall Loss 0.973448    Objective Loss 0.973448                                        LR 0.001000    Time 0.046195    
2024-04-05 15:46:14,269 - Epoch: [96][  300/  500]    Overall Loss 0.979824    Objective Loss 0.979824                                        LR 0.001000    Time 0.044393    
2024-04-05 15:46:18,723 - Epoch: [96][  400/  500]    Overall Loss 0.987157    Objective Loss 0.987157                                        LR 0.001000    Time 0.044416    
2024-04-05 15:46:23,200 - Epoch: [96][  500/  500]    Overall Loss 0.989912    Objective Loss 0.989912    Top1 69.500000    Top5 92.500000    LR 0.001000    Time 0.044477    
2024-04-05 15:46:23,358 - --- validate (epoch=96)-----------
2024-04-05 15:46:23,359 - 10000 samples (100 per mini-batch)
2024-04-05 15:46:24,963 - Epoch: [96][  100/  100]    Loss 1.795957    Top1 54.190000    Top5 82.080000    
2024-04-05 15:46:25,120 - ==> Top1: 54.190    Top5: 82.080    Loss: 1.796

2024-04-05 15:46:25,126 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:46:25,126 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:46:25,157 - 

2024-04-05 15:46:25,157 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:46:30,338 - Epoch: [97][  100/  500]    Overall Loss 0.962689    Objective Loss 0.962689                                        LR 0.001000    Time 0.051753    
2024-04-05 15:46:34,489 - Epoch: [97][  200/  500]    Overall Loss 0.975521    Objective Loss 0.975521                                        LR 0.001000    Time 0.046610    
2024-04-05 15:46:38,850 - Epoch: [97][  300/  500]    Overall Loss 0.971868    Objective Loss 0.971868                                        LR 0.001000    Time 0.045592    
2024-04-05 15:46:43,324 - Epoch: [97][  400/  500]    Overall Loss 0.980200    Objective Loss 0.980200                                        LR 0.001000    Time 0.045368    
2024-04-05 15:46:47,718 - Epoch: [97][  500/  500]    Overall Loss 0.986126    Objective Loss 0.986126    Top1 65.500000    Top5 93.000000    LR 0.001000    Time 0.045072    
2024-04-05 15:46:47,971 - --- validate (epoch=97)-----------
2024-04-05 15:46:47,972 - 10000 samples (100 per mini-batch)
2024-04-05 15:46:49,421 - Epoch: [97][  100/  100]    Loss 1.797621    Top1 54.000000    Top5 82.230000    
2024-04-05 15:46:49,606 - ==> Top1: 54.000    Top5: 82.230    Loss: 1.798

2024-04-05 15:46:49,612 - ==> Best [Top1: 54.370   Top5: 82.320   Sparsity:0.00   Params: 314624 on epoch: 79]
2024-04-05 15:46:49,612 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:46:49,642 - 

2024-04-05 15:46:49,643 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:46:54,760 - Epoch: [98][  100/  500]    Overall Loss 0.949430    Objective Loss 0.949430                                        LR 0.001000    Time 0.051124    
2024-04-05 15:46:57,850 - Epoch: [98][  200/  500]    Overall Loss 0.964083    Objective Loss 0.964083                                        LR 0.001000    Time 0.040991    
2024-04-05 15:47:01,081 - Epoch: [98][  300/  500]    Overall Loss 0.971708    Objective Loss 0.971708                                        LR 0.001000    Time 0.038084    
2024-04-05 15:47:05,550 - Epoch: [98][  400/  500]    Overall Loss 0.974968    Objective Loss 0.974968                                        LR 0.001000    Time 0.039723    
2024-04-05 15:47:10,000 - Epoch: [98][  500/  500]    Overall Loss 0.980998    Objective Loss 0.980998    Top1 67.500000    Top5 92.500000    LR 0.001000    Time 0.040670    
2024-04-05 15:47:10,141 - --- validate (epoch=98)-----------
2024-04-05 15:47:10,142 - 10000 samples (100 per mini-batch)
2024-04-05 15:47:11,629 - Epoch: [98][  100/  100]    Loss 1.786753    Top1 54.600000    Top5 82.180000    
2024-04-05 15:47:11,737 - ==> Top1: 54.600    Top5: 82.180    Loss: 1.787

2024-04-05 15:47:11,743 - ==> Best [Top1: 54.600   Top5: 82.180   Sparsity:0.00   Params: 314624 on epoch: 98]
2024-04-05 15:47:11,743 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:47:11,780 - 

2024-04-05 15:47:11,781 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:47:16,693 - Epoch: [99][  100/  500]    Overall Loss 0.936295    Objective Loss 0.936295                                        LR 0.001000    Time 0.049072    
2024-04-05 15:47:20,775 - Epoch: [99][  200/  500]    Overall Loss 0.958190    Objective Loss 0.958190                                        LR 0.001000    Time 0.044923    
2024-04-05 15:47:25,139 - Epoch: [99][  300/  500]    Overall Loss 0.964459    Objective Loss 0.964459                                        LR 0.001000    Time 0.044479    
2024-04-05 15:47:28,017 - Epoch: [99][  400/  500]    Overall Loss 0.968400    Objective Loss 0.968400                                        LR 0.001000    Time 0.040544    
2024-04-05 15:47:30,720 - Epoch: [99][  500/  500]    Overall Loss 0.969732    Objective Loss 0.969732    Top1 68.500000    Top5 92.000000    LR 0.001000    Time 0.037835    
2024-04-05 15:47:30,899 - --- validate (epoch=99)-----------
2024-04-05 15:47:30,899 - 10000 samples (100 per mini-batch)
2024-04-05 15:47:32,384 - Epoch: [99][  100/  100]    Loss 1.794036    Top1 54.130000    Top5 82.140000    
2024-04-05 15:47:32,562 - ==> Top1: 54.130    Top5: 82.140    Loss: 1.794

2024-04-05 15:47:32,567 - ==> Best [Top1: 54.600   Top5: 82.180   Sparsity:0.00   Params: 314624 on epoch: 98]
2024-04-05 15:47:32,568 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:47:32,602 - 

2024-04-05 15:47:32,602 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:47:37,506 - Epoch: [100][  100/  500]    Overall Loss 0.903520    Objective Loss 0.903520                                        LR 0.000500    Time 0.048969    
2024-04-05 15:47:41,618 - Epoch: [100][  200/  500]    Overall Loss 0.900207    Objective Loss 0.900207                                        LR 0.000500    Time 0.045020    
2024-04-05 15:47:45,667 - Epoch: [100][  300/  500]    Overall Loss 0.891813    Objective Loss 0.891813                                        LR 0.000500    Time 0.043495    
2024-04-05 15:47:50,163 - Epoch: [100][  400/  500]    Overall Loss 0.893139    Objective Loss 0.893139                                        LR 0.000500    Time 0.043847    
2024-04-05 15:47:54,633 - Epoch: [100][  500/  500]    Overall Loss 0.894444    Objective Loss 0.894444    Top1 73.000000    Top5 93.500000    LR 0.000500    Time 0.044008    
2024-04-05 15:47:54,775 - --- validate (epoch=100)-----------
2024-04-05 15:47:54,776 - 10000 samples (100 per mini-batch)
2024-04-05 15:47:56,313 - Epoch: [100][  100/  100]    Loss 1.739008    Top1 55.480000    Top5 82.620000    
2024-04-05 15:47:56,431 - ==> Top1: 55.480    Top5: 82.620    Loss: 1.739

2024-04-05 15:47:56,436 - ==> Best [Top1: 55.480   Top5: 82.620   Sparsity:0.00   Params: 314624 on epoch: 100]
2024-04-05 15:47:56,437 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:47:56,474 - 

2024-04-05 15:47:56,474 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:48:01,560 - Epoch: [101][  100/  500]    Overall Loss 0.861810    Objective Loss 0.861810                                        LR 0.000500    Time 0.050814    
2024-04-05 15:48:05,258 - Epoch: [101][  200/  500]    Overall Loss 0.868029    Objective Loss 0.868029                                        LR 0.000500    Time 0.043871    
2024-04-05 15:48:09,542 - Epoch: [101][  300/  500]    Overall Loss 0.873449    Objective Loss 0.873449                                        LR 0.000500    Time 0.043512    
2024-04-05 15:48:13,979 - Epoch: [101][  400/  500]    Overall Loss 0.867341    Objective Loss 0.867341                                        LR 0.000500    Time 0.043713    
2024-04-05 15:48:18,382 - Epoch: [101][  500/  500]    Overall Loss 0.872629    Objective Loss 0.872629    Top1 72.500000    Top5 92.500000    LR 0.000500    Time 0.043767    
2024-04-05 15:48:18,669 - --- validate (epoch=101)-----------
2024-04-05 15:48:18,670 - 10000 samples (100 per mini-batch)
2024-04-05 15:48:20,236 - Epoch: [101][  100/  100]    Loss 1.757712    Top1 55.240000    Top5 82.640000    
2024-04-05 15:48:20,345 - ==> Top1: 55.240    Top5: 82.640    Loss: 1.758

2024-04-05 15:48:20,351 - ==> Best [Top1: 55.480   Top5: 82.620   Sparsity:0.00   Params: 314624 on epoch: 100]
2024-04-05 15:48:20,351 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:48:20,381 - 

2024-04-05 15:48:20,381 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:48:25,105 - Epoch: [102][  100/  500]    Overall Loss 0.857148    Objective Loss 0.857148                                        LR 0.000500    Time 0.047184    
2024-04-05 15:48:28,796 - Epoch: [102][  200/  500]    Overall Loss 0.859783    Objective Loss 0.859783                                        LR 0.000500    Time 0.042028    
2024-04-05 15:48:32,231 - Epoch: [102][  300/  500]    Overall Loss 0.862965    Objective Loss 0.862965                                        LR 0.000500    Time 0.039453    
2024-04-05 15:48:34,999 - Epoch: [102][  400/  500]    Overall Loss 0.864247    Objective Loss 0.864247                                        LR 0.000500    Time 0.036503    
2024-04-05 15:48:39,312 - Epoch: [102][  500/  500]    Overall Loss 0.865169    Objective Loss 0.865169    Top1 74.500000    Top5 96.500000    LR 0.000500    Time 0.037819    
2024-04-05 15:48:39,463 - --- validate (epoch=102)-----------
2024-04-05 15:48:39,464 - 10000 samples (100 per mini-batch)
2024-04-05 15:48:41,288 - Epoch: [102][  100/  100]    Loss 1.757629    Top1 55.090000    Top5 82.510000    
2024-04-05 15:48:41,455 - ==> Top1: 55.090    Top5: 82.510    Loss: 1.758

2024-04-05 15:48:41,461 - ==> Best [Top1: 55.480   Top5: 82.620   Sparsity:0.00   Params: 314624 on epoch: 100]
2024-04-05 15:48:41,461 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:48:41,491 - 

2024-04-05 15:48:41,491 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:48:46,262 - Epoch: [103][  100/  500]    Overall Loss 0.830830    Objective Loss 0.830830                                        LR 0.000500    Time 0.047655    
2024-04-05 15:48:50,085 - Epoch: [103][  200/  500]    Overall Loss 0.823521    Objective Loss 0.823521                                        LR 0.000500    Time 0.042920    
2024-04-05 15:48:54,505 - Epoch: [103][  300/  500]    Overall Loss 0.835446    Objective Loss 0.835446                                        LR 0.000500    Time 0.043331    
2024-04-05 15:48:58,957 - Epoch: [103][  400/  500]    Overall Loss 0.845600    Objective Loss 0.845600                                        LR 0.000500    Time 0.043616    
2024-04-05 15:49:03,356 - Epoch: [103][  500/  500]    Overall Loss 0.854226    Objective Loss 0.854226    Top1 77.000000    Top5 96.000000    LR 0.000500    Time 0.043680    
2024-04-05 15:49:03,551 - --- validate (epoch=103)-----------
2024-04-05 15:49:03,552 - 10000 samples (100 per mini-batch)
2024-04-05 15:49:05,121 - Epoch: [103][  100/  100]    Loss 1.748486    Top1 55.310000    Top5 82.720000    
2024-04-05 15:49:05,244 - ==> Top1: 55.310    Top5: 82.720    Loss: 1.748

2024-04-05 15:49:05,248 - ==> Best [Top1: 55.480   Top5: 82.620   Sparsity:0.00   Params: 314624 on epoch: 100]
2024-04-05 15:49:05,248 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:49:05,269 - 

2024-04-05 15:49:05,269 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:49:09,653 - Epoch: [104][  100/  500]    Overall Loss 0.800941    Objective Loss 0.800941                                        LR 0.000500    Time 0.043787    
2024-04-05 15:49:13,964 - Epoch: [104][  200/  500]    Overall Loss 0.816446    Objective Loss 0.816446                                        LR 0.000500    Time 0.043422    
2024-04-05 15:49:18,429 - Epoch: [104][  300/  500]    Overall Loss 0.825711    Objective Loss 0.825711                                        LR 0.000500    Time 0.043814    
2024-04-05 15:49:22,751 - Epoch: [104][  400/  500]    Overall Loss 0.832508    Objective Loss 0.832508                                        LR 0.000500    Time 0.043654    
2024-04-05 15:49:27,144 - Epoch: [104][  500/  500]    Overall Loss 0.840283    Objective Loss 0.840283    Top1 73.000000    Top5 93.500000    LR 0.000500    Time 0.043699    
2024-04-05 15:49:27,298 - --- validate (epoch=104)-----------
2024-04-05 15:49:27,298 - 10000 samples (100 per mini-batch)
2024-04-05 15:49:28,845 - Epoch: [104][  100/  100]    Loss 1.777716    Top1 54.740000    Top5 82.060000    
2024-04-05 15:49:28,998 - ==> Top1: 54.740    Top5: 82.060    Loss: 1.778

2024-04-05 15:49:29,004 - ==> Best [Top1: 55.480   Top5: 82.620   Sparsity:0.00   Params: 314624 on epoch: 100]
2024-04-05 15:49:29,004 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:49:29,035 - 

2024-04-05 15:49:29,035 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:49:33,274 - Epoch: [105][  100/  500]    Overall Loss 0.822114    Objective Loss 0.822114                                        LR 0.000500    Time 0.042338    
2024-04-05 15:49:37,692 - Epoch: [105][  200/  500]    Overall Loss 0.833525    Objective Loss 0.833525                                        LR 0.000500    Time 0.043235    
2024-04-05 15:49:42,135 - Epoch: [105][  300/  500]    Overall Loss 0.840030    Objective Loss 0.840030                                        LR 0.000500    Time 0.043615    
2024-04-05 15:49:46,536 - Epoch: [105][  400/  500]    Overall Loss 0.843821    Objective Loss 0.843821                                        LR 0.000500    Time 0.043702    
2024-04-05 15:49:50,998 - Epoch: [105][  500/  500]    Overall Loss 0.845362    Objective Loss 0.845362    Top1 71.000000    Top5 96.500000    LR 0.000500    Time 0.043875    
2024-04-05 15:49:51,285 - --- validate (epoch=105)-----------
2024-04-05 15:49:51,285 - 10000 samples (100 per mini-batch)
2024-04-05 15:49:52,764 - Epoch: [105][  100/  100]    Loss 1.768430    Top1 55.240000    Top5 82.240000    
2024-04-05 15:49:52,864 - ==> Top1: 55.240    Top5: 82.240    Loss: 1.768

2024-04-05 15:49:52,871 - ==> Best [Top1: 55.480   Top5: 82.620   Sparsity:0.00   Params: 314624 on epoch: 100]
2024-04-05 15:49:52,872 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:49:52,901 - 

2024-04-05 15:49:52,901 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:49:56,928 - Epoch: [106][  100/  500]    Overall Loss 0.830198    Objective Loss 0.830198                                        LR 0.000500    Time 0.040217    
2024-04-05 15:50:01,323 - Epoch: [106][  200/  500]    Overall Loss 0.837419    Objective Loss 0.837419                                        LR 0.000500    Time 0.042062    
2024-04-05 15:50:05,709 - Epoch: [106][  300/  500]    Overall Loss 0.845221    Objective Loss 0.845221                                        LR 0.000500    Time 0.042645    
2024-04-05 15:50:10,121 - Epoch: [106][  400/  500]    Overall Loss 0.845119    Objective Loss 0.845119                                        LR 0.000500    Time 0.043000    
2024-04-05 15:50:14,574 - Epoch: [106][  500/  500]    Overall Loss 0.845750    Objective Loss 0.845750    Top1 77.000000    Top5 96.500000    LR 0.000500    Time 0.043298    
2024-04-05 15:50:14,831 - --- validate (epoch=106)-----------
2024-04-05 15:50:14,831 - 10000 samples (100 per mini-batch)
2024-04-05 15:50:16,339 - Epoch: [106][  100/  100]    Loss 1.773945    Top1 55.080000    Top5 82.210000    
2024-04-05 15:50:16,458 - ==> Top1: 55.080    Top5: 82.210    Loss: 1.774

2024-04-05 15:50:16,464 - ==> Best [Top1: 55.480   Top5: 82.620   Sparsity:0.00   Params: 314624 on epoch: 100]
2024-04-05 15:50:16,464 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:50:16,495 - 

2024-04-05 15:50:16,495 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:50:21,494 - Epoch: [107][  100/  500]    Overall Loss 0.854365    Objective Loss 0.854365                                        LR 0.000500    Time 0.049939    
2024-04-05 15:50:25,913 - Epoch: [107][  200/  500]    Overall Loss 0.837929    Objective Loss 0.837929                                        LR 0.000500    Time 0.047039    
2024-04-05 15:50:30,334 - Epoch: [107][  300/  500]    Overall Loss 0.832989    Objective Loss 0.832989                                        LR 0.000500    Time 0.046081    
2024-04-05 15:50:34,785 - Epoch: [107][  400/  500]    Overall Loss 0.832420    Objective Loss 0.832420                                        LR 0.000500    Time 0.045673    
2024-04-05 15:50:39,182 - Epoch: [107][  500/  500]    Overall Loss 0.838786    Objective Loss 0.838786    Top1 70.000000    Top5 92.000000    LR 0.000500    Time 0.045324    
2024-04-05 15:50:39,364 - --- validate (epoch=107)-----------
2024-04-05 15:50:39,364 - 10000 samples (100 per mini-batch)
2024-04-05 15:50:41,167 - Epoch: [107][  100/  100]    Loss 1.782213    Top1 54.870000    Top5 82.360000    
2024-04-05 15:50:41,267 - ==> Top1: 54.870    Top5: 82.360    Loss: 1.782

2024-04-05 15:50:41,272 - ==> Best [Top1: 55.480   Top5: 82.620   Sparsity:0.00   Params: 314624 on epoch: 100]
2024-04-05 15:50:41,272 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:50:41,300 - 

2024-04-05 15:50:41,300 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:50:46,420 - Epoch: [108][  100/  500]    Overall Loss 0.816371    Objective Loss 0.816371                                        LR 0.000500    Time 0.051141    
2024-04-05 15:50:50,694 - Epoch: [108][  200/  500]    Overall Loss 0.812197    Objective Loss 0.812197                                        LR 0.000500    Time 0.046917    
2024-04-05 15:50:55,021 - Epoch: [108][  300/  500]    Overall Loss 0.821423    Objective Loss 0.821423                                        LR 0.000500    Time 0.045684    
2024-04-05 15:50:59,425 - Epoch: [108][  400/  500]    Overall Loss 0.829460    Objective Loss 0.829460                                        LR 0.000500    Time 0.045261    
2024-04-05 15:51:02,420 - Epoch: [108][  500/  500]    Overall Loss 0.834055    Objective Loss 0.834055    Top1 72.000000    Top5 96.000000    LR 0.000500    Time 0.042190    
2024-04-05 15:51:02,613 - --- validate (epoch=108)-----------
2024-04-05 15:51:02,613 - 10000 samples (100 per mini-batch)
2024-04-05 15:51:04,493 - Epoch: [108][  100/  100]    Loss 1.780163    Top1 54.950000    Top5 81.950000    
2024-04-05 15:51:04,660 - ==> Top1: 54.950    Top5: 81.950    Loss: 1.780

2024-04-05 15:51:04,667 - ==> Best [Top1: 55.480   Top5: 82.620   Sparsity:0.00   Params: 314624 on epoch: 100]
2024-04-05 15:51:04,668 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:51:04,700 - 

2024-04-05 15:51:04,700 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:51:09,058 - Epoch: [109][  100/  500]    Overall Loss 0.808867    Objective Loss 0.808867                                        LR 0.000500    Time 0.043528    
2024-04-05 15:51:13,349 - Epoch: [109][  200/  500]    Overall Loss 0.820250    Objective Loss 0.820250                                        LR 0.000500    Time 0.043194    
2024-04-05 15:51:17,769 - Epoch: [109][  300/  500]    Overall Loss 0.816800    Objective Loss 0.816800                                        LR 0.000500    Time 0.043514    
2024-04-05 15:51:22,204 - Epoch: [109][  400/  500]    Overall Loss 0.821519    Objective Loss 0.821519                                        LR 0.000500    Time 0.043711    
2024-04-05 15:51:26,655 - Epoch: [109][  500/  500]    Overall Loss 0.826947    Objective Loss 0.826947    Top1 68.000000    Top5 95.000000    LR 0.000500    Time 0.043860    
2024-04-05 15:51:26,883 - --- validate (epoch=109)-----------
2024-04-05 15:51:26,883 - 10000 samples (100 per mini-batch)
2024-04-05 15:51:28,699 - Epoch: [109][  100/  100]    Loss 1.781682    Top1 54.960000    Top5 82.280000    
2024-04-05 15:51:28,822 - ==> Top1: 54.960    Top5: 82.280    Loss: 1.782

2024-04-05 15:51:28,827 - ==> Best [Top1: 55.480   Top5: 82.620   Sparsity:0.00   Params: 314624 on epoch: 100]
2024-04-05 15:51:28,828 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:51:28,859 - 

2024-04-05 15:51:28,859 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:51:33,312 - Epoch: [110][  100/  500]    Overall Loss 0.793752    Objective Loss 0.793752                                        LR 0.000500    Time 0.044474    
2024-04-05 15:51:37,729 - Epoch: [110][  200/  500]    Overall Loss 0.805960    Objective Loss 0.805960                                        LR 0.000500    Time 0.044298    
2024-04-05 15:51:42,183 - Epoch: [110][  300/  500]    Overall Loss 0.819236    Objective Loss 0.819236                                        LR 0.000500    Time 0.044351    
2024-04-05 15:51:46,681 - Epoch: [110][  400/  500]    Overall Loss 0.820919    Objective Loss 0.820919                                        LR 0.000500    Time 0.044494    
2024-04-05 15:51:51,108 - Epoch: [110][  500/  500]    Overall Loss 0.823455    Objective Loss 0.823455    Top1 73.500000    Top5 93.000000    LR 0.000500    Time 0.044439    
2024-04-05 15:51:51,265 - --- validate (epoch=110)-----------
2024-04-05 15:51:51,265 - 10000 samples (100 per mini-batch)
2024-04-05 15:51:53,106 - Epoch: [110][  100/  100]    Loss 1.768647    Top1 55.370000    Top5 82.490000    
2024-04-05 15:51:53,248 - ==> Top1: 55.370    Top5: 82.490    Loss: 1.769

2024-04-05 15:51:53,256 - ==> Best [Top1: 55.480   Top5: 82.620   Sparsity:0.00   Params: 314624 on epoch: 100]
2024-04-05 15:51:53,256 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:51:53,287 - 

2024-04-05 15:51:53,287 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:51:57,704 - Epoch: [111][  100/  500]    Overall Loss 0.801159    Objective Loss 0.801159                                        LR 0.000500    Time 0.044119    
2024-04-05 15:52:02,116 - Epoch: [111][  200/  500]    Overall Loss 0.802393    Objective Loss 0.802393                                        LR 0.000500    Time 0.044094    
2024-04-05 15:52:06,558 - Epoch: [111][  300/  500]    Overall Loss 0.809498    Objective Loss 0.809498                                        LR 0.000500    Time 0.044186    
2024-04-05 15:52:10,945 - Epoch: [111][  400/  500]    Overall Loss 0.817600    Objective Loss 0.817600                                        LR 0.000500    Time 0.044093    
2024-04-05 15:52:14,348 - Epoch: [111][  500/  500]    Overall Loss 0.820294    Objective Loss 0.820294    Top1 78.500000    Top5 95.000000    LR 0.000500    Time 0.042072    
2024-04-05 15:52:14,610 - --- validate (epoch=111)-----------
2024-04-05 15:52:14,612 - 10000 samples (100 per mini-batch)
2024-04-05 15:52:16,141 - Epoch: [111][  100/  100]    Loss 1.765953    Top1 55.500000    Top5 82.530000    
2024-04-05 15:52:16,333 - ==> Top1: 55.500    Top5: 82.530    Loss: 1.766

2024-04-05 15:52:16,338 - ==> Best [Top1: 55.500   Top5: 82.530   Sparsity:0.00   Params: 314624 on epoch: 111]
2024-04-05 15:52:16,339 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:52:16,374 - 

2024-04-05 15:52:16,374 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:52:21,484 - Epoch: [112][  100/  500]    Overall Loss 0.795181    Objective Loss 0.795181                                        LR 0.000500    Time 0.051050    
2024-04-05 15:52:25,887 - Epoch: [112][  200/  500]    Overall Loss 0.801686    Objective Loss 0.801686                                        LR 0.000500    Time 0.047515    
2024-04-05 15:52:28,686 - Epoch: [112][  300/  500]    Overall Loss 0.802095    Objective Loss 0.802095                                        LR 0.000500    Time 0.040995    
2024-04-05 15:52:31,496 - Epoch: [112][  400/  500]    Overall Loss 0.807335    Objective Loss 0.807335                                        LR 0.000500    Time 0.037762    
2024-04-05 15:52:34,242 - Epoch: [112][  500/  500]    Overall Loss 0.815754    Objective Loss 0.815754    Top1 73.500000    Top5 96.000000    LR 0.000500    Time 0.035695    
2024-04-05 15:52:34,439 - --- validate (epoch=112)-----------
2024-04-05 15:52:34,440 - 10000 samples (100 per mini-batch)
2024-04-05 15:52:36,383 - Epoch: [112][  100/  100]    Loss 1.775936    Top1 55.450000    Top5 82.350000    
2024-04-05 15:52:36,549 - ==> Top1: 55.450    Top5: 82.350    Loss: 1.776

2024-04-05 15:52:36,557 - ==> Best [Top1: 55.500   Top5: 82.530   Sparsity:0.00   Params: 314624 on epoch: 111]
2024-04-05 15:52:36,557 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:52:36,587 - 

2024-04-05 15:52:36,587 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:52:40,971 - Epoch: [113][  100/  500]    Overall Loss 0.801977    Objective Loss 0.801977                                        LR 0.000500    Time 0.043791    
2024-04-05 15:52:45,129 - Epoch: [113][  200/  500]    Overall Loss 0.794999    Objective Loss 0.794999                                        LR 0.000500    Time 0.042662    
2024-04-05 15:52:49,560 - Epoch: [113][  300/  500]    Overall Loss 0.804321    Objective Loss 0.804321                                        LR 0.000500    Time 0.043194    
2024-04-05 15:52:54,017 - Epoch: [113][  400/  500]    Overall Loss 0.810010    Objective Loss 0.810010                                        LR 0.000500    Time 0.043526    
2024-04-05 15:52:58,341 - Epoch: [113][  500/  500]    Overall Loss 0.811977    Objective Loss 0.811977    Top1 72.500000    Top5 96.000000    LR 0.000500    Time 0.043457    
2024-04-05 15:52:58,512 - --- validate (epoch=113)-----------
2024-04-05 15:52:58,512 - 10000 samples (100 per mini-batch)
2024-04-05 15:53:00,286 - Epoch: [113][  100/  100]    Loss 1.793028    Top1 54.650000    Top5 82.540000    
2024-04-05 15:53:00,437 - ==> Top1: 54.650    Top5: 82.540    Loss: 1.793

2024-04-05 15:53:00,442 - ==> Best [Top1: 55.500   Top5: 82.530   Sparsity:0.00   Params: 314624 on epoch: 111]
2024-04-05 15:53:00,443 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:53:00,472 - 

2024-04-05 15:53:00,473 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:53:05,208 - Epoch: [114][  100/  500]    Overall Loss 0.801552    Objective Loss 0.801552                                        LR 0.000500    Time 0.047303    
2024-04-05 15:53:09,578 - Epoch: [114][  200/  500]    Overall Loss 0.800200    Objective Loss 0.800200                                        LR 0.000500    Time 0.045474    
2024-04-05 15:53:14,054 - Epoch: [114][  300/  500]    Overall Loss 0.798077    Objective Loss 0.798077                                        LR 0.000500    Time 0.045221    
2024-04-05 15:53:18,532 - Epoch: [114][  400/  500]    Overall Loss 0.805283    Objective Loss 0.805283                                        LR 0.000500    Time 0.045098    
2024-04-05 15:53:22,716 - Epoch: [114][  500/  500]    Overall Loss 0.812014    Objective Loss 0.812014    Top1 76.000000    Top5 94.500000    LR 0.000500    Time 0.044437    
2024-04-05 15:53:22,869 - --- validate (epoch=114)-----------
2024-04-05 15:53:22,870 - 10000 samples (100 per mini-batch)
2024-04-05 15:53:24,528 - Epoch: [114][  100/  100]    Loss 1.790991    Top1 55.280000    Top5 82.120000    
2024-04-05 15:53:24,661 - ==> Top1: 55.280    Top5: 82.120    Loss: 1.791

2024-04-05 15:53:24,667 - ==> Best [Top1: 55.500   Top5: 82.530   Sparsity:0.00   Params: 314624 on epoch: 111]
2024-04-05 15:53:24,668 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:53:24,888 - 

2024-04-05 15:53:24,888 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:53:29,599 - Epoch: [115][  100/  500]    Overall Loss 0.801431    Objective Loss 0.801431                                        LR 0.000500    Time 0.047054    
2024-04-05 15:53:34,117 - Epoch: [115][  200/  500]    Overall Loss 0.801783    Objective Loss 0.801783                                        LR 0.000500    Time 0.046093    
2024-04-05 15:53:38,563 - Epoch: [115][  300/  500]    Overall Loss 0.797259    Objective Loss 0.797259                                        LR 0.000500    Time 0.045531    
2024-04-05 15:53:43,061 - Epoch: [115][  400/  500]    Overall Loss 0.803658    Objective Loss 0.803658                                        LR 0.000500    Time 0.045381    
2024-04-05 15:53:46,831 - Epoch: [115][  500/  500]    Overall Loss 0.806374    Objective Loss 0.806374    Top1 72.000000    Top5 94.500000    LR 0.000500    Time 0.043833    
2024-04-05 15:53:47,029 - --- validate (epoch=115)-----------
2024-04-05 15:53:47,030 - 10000 samples (100 per mini-batch)
2024-04-05 15:53:48,592 - Epoch: [115][  100/  100]    Loss 1.781664    Top1 55.010000    Top5 82.450000    
2024-04-05 15:53:48,781 - ==> Top1: 55.010    Top5: 82.450    Loss: 1.782

2024-04-05 15:53:48,788 - ==> Best [Top1: 55.500   Top5: 82.530   Sparsity:0.00   Params: 314624 on epoch: 111]
2024-04-05 15:53:48,788 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:53:48,819 - 

2024-04-05 15:53:48,819 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:53:53,869 - Epoch: [116][  100/  500]    Overall Loss 0.784423    Objective Loss 0.784423                                        LR 0.000500    Time 0.050446    
2024-04-05 15:53:58,332 - Epoch: [116][  200/  500]    Overall Loss 0.792305    Objective Loss 0.792305                                        LR 0.000500    Time 0.047510    
2024-04-05 15:54:02,780 - Epoch: [116][  300/  500]    Overall Loss 0.795067    Objective Loss 0.795067                                        LR 0.000500    Time 0.046483    
2024-04-05 15:54:07,208 - Epoch: [116][  400/  500]    Overall Loss 0.795658    Objective Loss 0.795658                                        LR 0.000500    Time 0.045919    
2024-04-05 15:54:10,919 - Epoch: [116][  500/  500]    Overall Loss 0.802121    Objective Loss 0.802121    Top1 71.500000    Top5 95.500000    LR 0.000500    Time 0.044148    
2024-04-05 15:54:11,119 - --- validate (epoch=116)-----------
2024-04-05 15:54:11,120 - 10000 samples (100 per mini-batch)
2024-04-05 15:54:12,599 - Epoch: [116][  100/  100]    Loss 1.788437    Top1 55.540000    Top5 82.610000    
2024-04-05 15:54:12,704 - ==> Top1: 55.540    Top5: 82.610    Loss: 1.788

2024-04-05 15:54:12,710 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:54:12,710 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:54:12,746 - 

2024-04-05 15:54:12,746 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:54:17,569 - Epoch: [117][  100/  500]    Overall Loss 0.779946    Objective Loss 0.779946                                        LR 0.000500    Time 0.048178    
2024-04-05 15:54:21,961 - Epoch: [117][  200/  500]    Overall Loss 0.781388    Objective Loss 0.781388                                        LR 0.000500    Time 0.046025    
2024-04-05 15:54:26,384 - Epoch: [117][  300/  500]    Overall Loss 0.784509    Objective Loss 0.784509                                        LR 0.000500    Time 0.045411    
2024-04-05 15:54:30,735 - Epoch: [117][  400/  500]    Overall Loss 0.794969    Objective Loss 0.794969                                        LR 0.000500    Time 0.044923    
2024-04-05 15:54:34,601 - Epoch: [117][  500/  500]    Overall Loss 0.795869    Objective Loss 0.795869    Top1 72.500000    Top5 95.500000    LR 0.000500    Time 0.043661    
2024-04-05 15:54:34,864 - --- validate (epoch=117)-----------
2024-04-05 15:54:34,865 - 10000 samples (100 per mini-batch)
2024-04-05 15:54:36,329 - Epoch: [117][  100/  100]    Loss 1.789988    Top1 55.240000    Top5 82.400000    
2024-04-05 15:54:36,429 - ==> Top1: 55.240    Top5: 82.400    Loss: 1.790

2024-04-05 15:54:36,435 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:54:36,435 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:54:36,464 - 

2024-04-05 15:54:36,465 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:54:41,569 - Epoch: [118][  100/  500]    Overall Loss 0.762768    Objective Loss 0.762768                                        LR 0.000500    Time 0.050994    
2024-04-05 15:54:45,972 - Epoch: [118][  200/  500]    Overall Loss 0.763046    Objective Loss 0.763046                                        LR 0.000500    Time 0.047483    
2024-04-05 15:54:50,301 - Epoch: [118][  300/  500]    Overall Loss 0.774868    Objective Loss 0.774868                                        LR 0.000500    Time 0.046070    
2024-04-05 15:54:54,259 - Epoch: [118][  400/  500]    Overall Loss 0.782600    Objective Loss 0.782600                                        LR 0.000500    Time 0.044437    
2024-04-05 15:54:58,406 - Epoch: [118][  500/  500]    Overall Loss 0.793713    Objective Loss 0.793713    Top1 78.000000    Top5 95.500000    LR 0.000500    Time 0.043833    
2024-04-05 15:54:58,568 - --- validate (epoch=118)-----------
2024-04-05 15:54:58,569 - 10000 samples (100 per mini-batch)
2024-04-05 15:55:00,098 - Epoch: [118][  100/  100]    Loss 1.791500    Top1 55.090000    Top5 82.470000    
2024-04-05 15:55:00,215 - ==> Top1: 55.090    Top5: 82.470    Loss: 1.792

2024-04-05 15:55:00,222 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:55:00,222 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:55:00,253 - 

2024-04-05 15:55:00,253 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:55:05,112 - Epoch: [119][  100/  500]    Overall Loss 0.771850    Objective Loss 0.771850                                        LR 0.000500    Time 0.048534    
2024-04-05 15:55:09,584 - Epoch: [119][  200/  500]    Overall Loss 0.778382    Objective Loss 0.778382                                        LR 0.000500    Time 0.046600    
2024-04-05 15:55:14,009 - Epoch: [119][  300/  500]    Overall Loss 0.784975    Objective Loss 0.784975                                        LR 0.000500    Time 0.045797    
2024-04-05 15:55:17,933 - Epoch: [119][  400/  500]    Overall Loss 0.792366    Objective Loss 0.792366                                        LR 0.000500    Time 0.044148    
2024-04-05 15:55:22,333 - Epoch: [119][  500/  500]    Overall Loss 0.799187    Objective Loss 0.799187    Top1 76.500000    Top5 96.500000    LR 0.000500    Time 0.044108    
2024-04-05 15:55:22,587 - --- validate (epoch=119)-----------
2024-04-05 15:55:22,588 - 10000 samples (100 per mini-batch)
2024-04-05 15:55:24,044 - Epoch: [119][  100/  100]    Loss 1.806050    Top1 54.690000    Top5 81.960000    
2024-04-05 15:55:24,172 - ==> Top1: 54.690    Top5: 81.960    Loss: 1.806

2024-04-05 15:55:24,178 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:55:24,179 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:55:24,208 - 

2024-04-05 15:55:24,208 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:55:28,542 - Epoch: [120][  100/  500]    Overall Loss 0.743480    Objective Loss 0.743480                                        LR 0.000500    Time 0.043292    
2024-04-05 15:55:32,970 - Epoch: [120][  200/  500]    Overall Loss 0.763716    Objective Loss 0.763716                                        LR 0.000500    Time 0.043759    
2024-04-05 15:55:37,338 - Epoch: [120][  300/  500]    Overall Loss 0.771768    Objective Loss 0.771768                                        LR 0.000500    Time 0.043717    
2024-04-05 15:55:41,095 - Epoch: [120][  400/  500]    Overall Loss 0.781867    Objective Loss 0.781867                                        LR 0.000500    Time 0.042168    
2024-04-05 15:55:45,536 - Epoch: [120][  500/  500]    Overall Loss 0.788665    Objective Loss 0.788665    Top1 72.500000    Top5 91.500000    LR 0.000500    Time 0.042607    
2024-04-05 15:55:45,680 - --- validate (epoch=120)-----------
2024-04-05 15:55:45,681 - 10000 samples (100 per mini-batch)
2024-04-05 15:55:47,478 - Epoch: [120][  100/  100]    Loss 1.810948    Top1 54.830000    Top5 82.300000    
2024-04-05 15:55:47,602 - ==> Top1: 54.830    Top5: 82.300    Loss: 1.811

2024-04-05 15:55:47,607 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:55:47,607 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:55:47,638 - 

2024-04-05 15:55:47,639 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:55:52,484 - Epoch: [121][  100/  500]    Overall Loss 0.770512    Objective Loss 0.770512                                        LR 0.000500    Time 0.048403    
2024-04-05 15:55:56,961 - Epoch: [121][  200/  500]    Overall Loss 0.773936    Objective Loss 0.773936                                        LR 0.000500    Time 0.046561    
2024-04-05 15:56:01,383 - Epoch: [121][  300/  500]    Overall Loss 0.778493    Objective Loss 0.778493                                        LR 0.000500    Time 0.045765    
2024-04-05 15:56:05,347 - Epoch: [121][  400/  500]    Overall Loss 0.782885    Objective Loss 0.782885                                        LR 0.000500    Time 0.044222    
2024-04-05 15:56:09,762 - Epoch: [121][  500/  500]    Overall Loss 0.792701    Objective Loss 0.792701    Top1 78.500000    Top5 97.000000    LR 0.000500    Time 0.044197    
2024-04-05 15:56:09,954 - --- validate (epoch=121)-----------
2024-04-05 15:56:09,956 - 10000 samples (100 per mini-batch)
2024-04-05 15:56:11,480 - Epoch: [121][  100/  100]    Loss 1.808743    Top1 55.030000    Top5 82.190000    
2024-04-05 15:56:11,594 - ==> Top1: 55.030    Top5: 82.190    Loss: 1.809

2024-04-05 15:56:11,600 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:56:11,600 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:56:11,630 - 

2024-04-05 15:56:11,630 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:56:16,453 - Epoch: [122][  100/  500]    Overall Loss 0.767599    Objective Loss 0.767599                                        LR 0.000500    Time 0.048175    
2024-04-05 15:56:20,847 - Epoch: [122][  200/  500]    Overall Loss 0.772524    Objective Loss 0.772524                                        LR 0.000500    Time 0.046033    
2024-04-05 15:56:25,261 - Epoch: [122][  300/  500]    Overall Loss 0.773381    Objective Loss 0.773381                                        LR 0.000500    Time 0.045386    
2024-04-05 15:56:29,327 - Epoch: [122][  400/  500]    Overall Loss 0.778569    Objective Loss 0.778569                                        LR 0.000500    Time 0.044193    
2024-04-05 15:56:33,793 - Epoch: [122][  500/  500]    Overall Loss 0.786441    Objective Loss 0.786441    Top1 73.000000    Top5 96.500000    LR 0.000500    Time 0.044276    
2024-04-05 15:56:34,052 - --- validate (epoch=122)-----------
2024-04-05 15:56:34,053 - 10000 samples (100 per mini-batch)
2024-04-05 15:56:35,804 - Epoch: [122][  100/  100]    Loss 1.800418    Top1 55.050000    Top5 82.320000    
2024-04-05 15:56:35,928 - ==> Top1: 55.050    Top5: 82.320    Loss: 1.800

2024-04-05 15:56:35,933 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:56:35,933 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:56:35,963 - 

2024-04-05 15:56:35,963 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:56:40,823 - Epoch: [123][  100/  500]    Overall Loss 0.755858    Objective Loss 0.755858                                        LR 0.000500    Time 0.048547    
2024-04-05 15:56:45,297 - Epoch: [123][  200/  500]    Overall Loss 0.762968    Objective Loss 0.762968                                        LR 0.000500    Time 0.046616    
2024-04-05 15:56:49,094 - Epoch: [123][  300/  500]    Overall Loss 0.764633    Objective Loss 0.764633                                        LR 0.000500    Time 0.043720    
2024-04-05 15:56:53,559 - Epoch: [123][  400/  500]    Overall Loss 0.776272    Objective Loss 0.776272                                        LR 0.000500    Time 0.043935    
2024-04-05 15:56:57,995 - Epoch: [123][  500/  500]    Overall Loss 0.785414    Objective Loss 0.785414    Top1 75.000000    Top5 98.000000    LR 0.000500    Time 0.044010    
2024-04-05 15:56:58,231 - --- validate (epoch=123)-----------
2024-04-05 15:56:58,231 - 10000 samples (100 per mini-batch)
2024-04-05 15:56:59,722 - Epoch: [123][  100/  100]    Loss 1.816649    Top1 55.220000    Top5 81.850000    
2024-04-05 15:56:59,853 - ==> Top1: 55.220    Top5: 81.850    Loss: 1.817

2024-04-05 15:56:59,859 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:56:59,859 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:56:59,888 - 

2024-04-05 15:56:59,888 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:57:04,977 - Epoch: [124][  100/  500]    Overall Loss 0.745887    Objective Loss 0.745887                                        LR 0.000500    Time 0.050839    
2024-04-05 15:57:09,406 - Epoch: [124][  200/  500]    Overall Loss 0.771540    Objective Loss 0.771540                                        LR 0.000500    Time 0.047537    
2024-04-05 15:57:13,063 - Epoch: [124][  300/  500]    Overall Loss 0.777814    Objective Loss 0.777814                                        LR 0.000500    Time 0.043870    
2024-04-05 15:57:17,514 - Epoch: [124][  400/  500]    Overall Loss 0.782268    Objective Loss 0.782268                                        LR 0.000500    Time 0.044018    
2024-04-05 15:57:21,957 - Epoch: [124][  500/  500]    Overall Loss 0.783071    Objective Loss 0.783071    Top1 84.500000    Top5 97.000000    LR 0.000500    Time 0.044090    
2024-04-05 15:57:22,139 - --- validate (epoch=124)-----------
2024-04-05 15:57:22,140 - 10000 samples (100 per mini-batch)
2024-04-05 15:57:23,650 - Epoch: [124][  100/  100]    Loss 1.810663    Top1 54.660000    Top5 82.140000    
2024-04-05 15:57:23,767 - ==> Top1: 54.660    Top5: 82.140    Loss: 1.811

2024-04-05 15:57:23,773 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:57:23,774 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:57:23,804 - 

2024-04-05 15:57:23,805 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:57:28,680 - Epoch: [125][  100/  500]    Overall Loss 0.788491    Objective Loss 0.788491                                        LR 0.000500    Time 0.048702    
2024-04-05 15:57:33,089 - Epoch: [125][  200/  500]    Overall Loss 0.776153    Objective Loss 0.776153                                        LR 0.000500    Time 0.046372    
2024-04-05 15:57:37,232 - Epoch: [125][  300/  500]    Overall Loss 0.770115    Objective Loss 0.770115                                        LR 0.000500    Time 0.044708    
2024-04-05 15:57:41,680 - Epoch: [125][  400/  500]    Overall Loss 0.774388    Objective Loss 0.774388                                        LR 0.000500    Time 0.044637    
2024-04-05 15:57:46,105 - Epoch: [125][  500/  500]    Overall Loss 0.780108    Objective Loss 0.780108    Top1 77.000000    Top5 96.000000    LR 0.000500    Time 0.044550    
2024-04-05 15:57:46,309 - --- validate (epoch=125)-----------
2024-04-05 15:57:46,310 - 10000 samples (100 per mini-batch)
2024-04-05 15:57:47,840 - Epoch: [125][  100/  100]    Loss 1.828880    Top1 54.170000    Top5 81.750000    
2024-04-05 15:57:47,956 - ==> Top1: 54.170    Top5: 81.750    Loss: 1.829

2024-04-05 15:57:47,963 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:57:47,963 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:57:47,994 - 

2024-04-05 15:57:47,994 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:57:52,812 - Epoch: [126][  100/  500]    Overall Loss 0.756591    Objective Loss 0.756591                                        LR 0.000500    Time 0.048137    
2024-04-05 15:57:56,649 - Epoch: [126][  200/  500]    Overall Loss 0.767374    Objective Loss 0.767374                                        LR 0.000500    Time 0.043232    
2024-04-05 15:58:01,002 - Epoch: [126][  300/  500]    Overall Loss 0.773674    Objective Loss 0.773674                                        LR 0.000500    Time 0.043315    
2024-04-05 15:58:05,460 - Epoch: [126][  400/  500]    Overall Loss 0.775992    Objective Loss 0.775992                                        LR 0.000500    Time 0.043617    
2024-04-05 15:58:09,888 - Epoch: [126][  500/  500]    Overall Loss 0.775939    Objective Loss 0.775939    Top1 78.500000    Top5 96.500000    LR 0.000500    Time 0.043741    
2024-04-05 15:58:10,041 - --- validate (epoch=126)-----------
2024-04-05 15:58:10,042 - 10000 samples (100 per mini-batch)
2024-04-05 15:58:11,605 - Epoch: [126][  100/  100]    Loss 1.818767    Top1 54.490000    Top5 82.080000    
2024-04-05 15:58:11,759 - ==> Top1: 54.490    Top5: 82.080    Loss: 1.819

2024-04-05 15:58:11,765 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:58:11,765 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:58:11,795 - 

2024-04-05 15:58:11,796 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:58:16,675 - Epoch: [127][  100/  500]    Overall Loss 0.762452    Objective Loss 0.762452                                        LR 0.000500    Time 0.048739    
2024-04-05 15:58:20,421 - Epoch: [127][  200/  500]    Overall Loss 0.765227    Objective Loss 0.765227                                        LR 0.000500    Time 0.043075    
2024-04-05 15:58:24,830 - Epoch: [127][  300/  500]    Overall Loss 0.769449    Objective Loss 0.769449                                        LR 0.000500    Time 0.043399    
2024-04-05 15:58:29,273 - Epoch: [127][  400/  500]    Overall Loss 0.774985    Objective Loss 0.774985                                        LR 0.000500    Time 0.043644    
2024-04-05 15:58:33,632 - Epoch: [127][  500/  500]    Overall Loss 0.778033    Objective Loss 0.778033    Top1 77.500000    Top5 96.500000    LR 0.000500    Time 0.043625    
2024-04-05 15:58:33,795 - --- validate (epoch=127)-----------
2024-04-05 15:58:33,795 - 10000 samples (100 per mini-batch)
2024-04-05 15:58:35,232 - Epoch: [127][  100/  100]    Loss 1.812917    Top1 55.340000    Top5 82.050000    
2024-04-05 15:58:35,376 - ==> Top1: 55.340    Top5: 82.050    Loss: 1.813

2024-04-05 15:58:35,382 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:58:35,383 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:58:35,413 - 

2024-04-05 15:58:35,413 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:58:39,784 - Epoch: [128][  100/  500]    Overall Loss 0.741951    Objective Loss 0.741951                                        LR 0.000500    Time 0.043657    
2024-04-05 15:58:43,529 - Epoch: [128][  200/  500]    Overall Loss 0.754746    Objective Loss 0.754746                                        LR 0.000500    Time 0.040534    
2024-04-05 15:58:47,956 - Epoch: [128][  300/  500]    Overall Loss 0.767424    Objective Loss 0.767424                                        LR 0.000500    Time 0.041762    
2024-04-05 15:58:52,308 - Epoch: [128][  400/  500]    Overall Loss 0.771758    Objective Loss 0.771758                                        LR 0.000500    Time 0.042189    
2024-04-05 15:58:56,773 - Epoch: [128][  500/  500]    Overall Loss 0.773592    Objective Loss 0.773592    Top1 75.000000    Top5 96.000000    LR 0.000500    Time 0.042671    
2024-04-05 15:58:57,036 - --- validate (epoch=128)-----------
2024-04-05 15:58:57,037 - 10000 samples (100 per mini-batch)
2024-04-05 15:58:58,817 - Epoch: [128][  100/  100]    Loss 1.824152    Top1 54.750000    Top5 82.170000    
2024-04-05 15:58:58,927 - ==> Top1: 54.750    Top5: 82.170    Loss: 1.824

2024-04-05 15:58:58,932 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:58:58,932 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:58:58,962 - 

2024-04-05 15:58:58,962 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:59:02,799 - Epoch: [129][  100/  500]    Overall Loss 0.744462    Objective Loss 0.744462                                        LR 0.000500    Time 0.038307    
2024-04-05 15:59:05,609 - Epoch: [129][  200/  500]    Overall Loss 0.753745    Objective Loss 0.753745                                        LR 0.000500    Time 0.033185    
2024-04-05 15:59:08,222 - Epoch: [129][  300/  500]    Overall Loss 0.754837    Objective Loss 0.754837                                        LR 0.000500    Time 0.030823    
2024-04-05 15:59:10,925 - Epoch: [129][  400/  500]    Overall Loss 0.763943    Objective Loss 0.763943                                        LR 0.000500    Time 0.029868    
2024-04-05 15:59:14,276 - Epoch: [129][  500/  500]    Overall Loss 0.764141    Objective Loss 0.764141    Top1 76.000000    Top5 97.000000    LR 0.000500    Time 0.030588    
2024-04-05 15:59:14,462 - --- validate (epoch=129)-----------
2024-04-05 15:59:14,463 - 10000 samples (100 per mini-batch)
2024-04-05 15:59:16,016 - Epoch: [129][  100/  100]    Loss 1.810366    Top1 55.310000    Top5 82.350000    
2024-04-05 15:59:16,122 - ==> Top1: 55.310    Top5: 82.350    Loss: 1.810

2024-04-05 15:59:16,128 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:59:16,128 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:59:16,157 - 

2024-04-05 15:59:16,158 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:59:21,059 - Epoch: [130][  100/  500]    Overall Loss 0.778139    Objective Loss 0.778139                                        LR 0.000500    Time 0.048959    
2024-04-05 15:59:24,598 - Epoch: [130][  200/  500]    Overall Loss 0.755333    Objective Loss 0.755333                                        LR 0.000500    Time 0.042156    
2024-04-05 15:59:28,937 - Epoch: [130][  300/  500]    Overall Loss 0.756453    Objective Loss 0.756453                                        LR 0.000500    Time 0.042551    
2024-04-05 15:59:33,356 - Epoch: [130][  400/  500]    Overall Loss 0.759999    Objective Loss 0.759999                                        LR 0.000500    Time 0.042948    
2024-04-05 15:59:37,809 - Epoch: [130][  500/  500]    Overall Loss 0.764939    Objective Loss 0.764939    Top1 78.500000    Top5 96.000000    LR 0.000500    Time 0.043253    
2024-04-05 15:59:38,007 - --- validate (epoch=130)-----------
2024-04-05 15:59:38,007 - 10000 samples (100 per mini-batch)
2024-04-05 15:59:39,515 - Epoch: [130][  100/  100]    Loss 1.822245    Top1 55.040000    Top5 82.270000    
2024-04-05 15:59:39,626 - ==> Top1: 55.040    Top5: 82.270    Loss: 1.822

2024-04-05 15:59:39,633 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:59:39,633 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:59:39,663 - 

2024-04-05 15:59:39,664 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 15:59:44,561 - Epoch: [131][  100/  500]    Overall Loss 0.746880    Objective Loss 0.746880                                        LR 0.000500    Time 0.048916    
2024-04-05 15:59:47,881 - Epoch: [131][  200/  500]    Overall Loss 0.748485    Objective Loss 0.748485                                        LR 0.000500    Time 0.041038    
2024-04-05 15:59:51,180 - Epoch: [131][  300/  500]    Overall Loss 0.758074    Objective Loss 0.758074                                        LR 0.000500    Time 0.038342    
2024-04-05 15:59:53,795 - Epoch: [131][  400/  500]    Overall Loss 0.756589    Objective Loss 0.756589                                        LR 0.000500    Time 0.035286    
2024-04-05 15:59:56,440 - Epoch: [131][  500/  500]    Overall Loss 0.760816    Objective Loss 0.760816    Top1 78.000000    Top5 97.500000    LR 0.000500    Time 0.033511    
2024-04-05 15:59:56,657 - --- validate (epoch=131)-----------
2024-04-05 15:59:56,657 - 10000 samples (100 per mini-batch)
2024-04-05 15:59:58,171 - Epoch: [131][  100/  100]    Loss 1.831976    Top1 54.850000    Top5 82.250000    
2024-04-05 15:59:58,275 - ==> Top1: 54.850    Top5: 82.250    Loss: 1.832

2024-04-05 15:59:58,281 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 15:59:58,282 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 15:59:58,311 - 

2024-04-05 15:59:58,312 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:00:03,080 - Epoch: [132][  100/  500]    Overall Loss 0.756464    Objective Loss 0.756464                                        LR 0.000500    Time 0.047629    
2024-04-05 16:00:07,471 - Epoch: [132][  200/  500]    Overall Loss 0.754350    Objective Loss 0.754350                                        LR 0.000500    Time 0.045746    
2024-04-05 16:00:11,130 - Epoch: [132][  300/  500]    Overall Loss 0.753759    Objective Loss 0.753759                                        LR 0.000500    Time 0.042680    
2024-04-05 16:00:15,578 - Epoch: [132][  400/  500]    Overall Loss 0.757104    Objective Loss 0.757104                                        LR 0.000500    Time 0.043117    
2024-04-05 16:00:20,018 - Epoch: [132][  500/  500]    Overall Loss 0.760808    Objective Loss 0.760808    Top1 75.500000    Top5 95.500000    LR 0.000500    Time 0.043364    
2024-04-05 16:00:20,200 - --- validate (epoch=132)-----------
2024-04-05 16:00:20,200 - 10000 samples (100 per mini-batch)
2024-04-05 16:00:21,993 - Epoch: [132][  100/  100]    Loss 1.838626    Top1 54.370000    Top5 82.070000    
2024-04-05 16:00:22,125 - ==> Top1: 54.370    Top5: 82.070    Loss: 1.839

2024-04-05 16:00:22,130 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:00:22,131 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:00:22,161 - 

2024-04-05 16:00:22,161 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:00:26,990 - Epoch: [133][  100/  500]    Overall Loss 0.730742    Objective Loss 0.730742                                        LR 0.000500    Time 0.048235    
2024-04-05 16:00:31,084 - Epoch: [133][  200/  500]    Overall Loss 0.730435    Objective Loss 0.730435                                        LR 0.000500    Time 0.044567    
2024-04-05 16:00:35,459 - Epoch: [133][  300/  500]    Overall Loss 0.738699    Objective Loss 0.738699                                        LR 0.000500    Time 0.044277    
2024-04-05 16:00:39,878 - Epoch: [133][  400/  500]    Overall Loss 0.750874    Objective Loss 0.750874                                        LR 0.000500    Time 0.044243    
2024-04-05 16:00:44,319 - Epoch: [133][  500/  500]    Overall Loss 0.753034    Objective Loss 0.753034    Top1 75.500000    Top5 97.000000    LR 0.000500    Time 0.044266    
2024-04-05 16:00:44,588 - --- validate (epoch=133)-----------
2024-04-05 16:00:44,589 - 10000 samples (100 per mini-batch)
2024-04-05 16:00:46,133 - Epoch: [133][  100/  100]    Loss 1.843375    Top1 54.620000    Top5 82.040000    
2024-04-05 16:00:46,287 - ==> Top1: 54.620    Top5: 82.040    Loss: 1.843

2024-04-05 16:00:46,293 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:00:46,293 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:00:46,323 - 

2024-04-05 16:00:46,324 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:00:51,355 - Epoch: [134][  100/  500]    Overall Loss 0.735387    Objective Loss 0.735387                                        LR 0.000500    Time 0.050259    
2024-04-05 16:00:55,169 - Epoch: [134][  200/  500]    Overall Loss 0.740666    Objective Loss 0.740666                                        LR 0.000500    Time 0.044179    
2024-04-05 16:00:59,574 - Epoch: [134][  300/  500]    Overall Loss 0.749150    Objective Loss 0.749150                                        LR 0.000500    Time 0.044119    
2024-04-05 16:01:03,998 - Epoch: [134][  400/  500]    Overall Loss 0.747854    Objective Loss 0.747854                                        LR 0.000500    Time 0.044135    
2024-04-05 16:01:08,401 - Epoch: [134][  500/  500]    Overall Loss 0.754720    Objective Loss 0.754720    Top1 74.000000    Top5 95.500000    LR 0.000500    Time 0.044106    
2024-04-05 16:01:08,574 - --- validate (epoch=134)-----------
2024-04-05 16:01:08,575 - 10000 samples (100 per mini-batch)
2024-04-05 16:01:10,198 - Epoch: [134][  100/  100]    Loss 1.843191    Top1 54.490000    Top5 82.390000    
2024-04-05 16:01:10,303 - ==> Top1: 54.490    Top5: 82.390    Loss: 1.843

2024-04-05 16:01:10,310 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:01:10,310 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:01:10,346 - 

2024-04-05 16:01:10,346 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:01:15,176 - Epoch: [135][  100/  500]    Overall Loss 0.738395    Objective Loss 0.738395                                        LR 0.000500    Time 0.048240    
2024-04-05 16:01:19,021 - Epoch: [135][  200/  500]    Overall Loss 0.740927    Objective Loss 0.740927                                        LR 0.000500    Time 0.043324    
2024-04-05 16:01:23,426 - Epoch: [135][  300/  500]    Overall Loss 0.741731    Objective Loss 0.741731                                        LR 0.000500    Time 0.043548    
2024-04-05 16:01:27,813 - Epoch: [135][  400/  500]    Overall Loss 0.748145    Objective Loss 0.748145                                        LR 0.000500    Time 0.043618    
2024-04-05 16:01:32,247 - Epoch: [135][  500/  500]    Overall Loss 0.753486    Objective Loss 0.753486    Top1 71.500000    Top5 94.000000    LR 0.000500    Time 0.043753    
2024-04-05 16:01:32,432 - --- validate (epoch=135)-----------
2024-04-05 16:01:32,433 - 10000 samples (100 per mini-batch)
2024-04-05 16:01:33,971 - Epoch: [135][  100/  100]    Loss 1.837217    Top1 55.040000    Top5 82.320000    
2024-04-05 16:01:34,153 - ==> Top1: 55.040    Top5: 82.320    Loss: 1.837

2024-04-05 16:01:34,159 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:01:34,159 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:01:34,189 - 

2024-04-05 16:01:34,189 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:01:38,852 - Epoch: [136][  100/  500]    Overall Loss 0.720540    Objective Loss 0.720540                                        LR 0.000500    Time 0.046579    
2024-04-05 16:01:42,159 - Epoch: [136][  200/  500]    Overall Loss 0.720060    Objective Loss 0.720060                                        LR 0.000500    Time 0.039804    
2024-04-05 16:01:46,542 - Epoch: [136][  300/  500]    Overall Loss 0.734180    Objective Loss 0.734180                                        LR 0.000500    Time 0.041130    
2024-04-05 16:01:50,526 - Epoch: [136][  400/  500]    Overall Loss 0.742042    Objective Loss 0.742042                                        LR 0.000500    Time 0.040796    
2024-04-05 16:01:54,715 - Epoch: [136][  500/  500]    Overall Loss 0.748033    Objective Loss 0.748033    Top1 76.500000    Top5 95.000000    LR 0.000500    Time 0.041006    
2024-04-05 16:01:54,893 - --- validate (epoch=136)-----------
2024-04-05 16:01:54,893 - 10000 samples (100 per mini-batch)
2024-04-05 16:01:56,700 - Epoch: [136][  100/  100]    Loss 1.839945    Top1 54.990000    Top5 82.080000    
2024-04-05 16:01:56,826 - ==> Top1: 54.990    Top5: 82.080    Loss: 1.840

2024-04-05 16:01:56,834 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:01:56,834 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:01:56,864 - 

2024-04-05 16:01:56,864 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:02:01,390 - Epoch: [137][  100/  500]    Overall Loss 0.733753    Objective Loss 0.733753                                        LR 0.000500    Time 0.045208    
2024-04-05 16:02:05,419 - Epoch: [137][  200/  500]    Overall Loss 0.739475    Objective Loss 0.739475                                        LR 0.000500    Time 0.042723    
2024-04-05 16:02:09,823 - Epoch: [137][  300/  500]    Overall Loss 0.739931    Objective Loss 0.739931                                        LR 0.000500    Time 0.043147    
2024-04-05 16:02:14,240 - Epoch: [137][  400/  500]    Overall Loss 0.745268    Objective Loss 0.745268                                        LR 0.000500    Time 0.043389    
2024-04-05 16:02:18,640 - Epoch: [137][  500/  500]    Overall Loss 0.747741    Objective Loss 0.747741    Top1 74.500000    Top5 98.500000    LR 0.000500    Time 0.043501    
2024-04-05 16:02:18,794 - --- validate (epoch=137)-----------
2024-04-05 16:02:18,795 - 10000 samples (100 per mini-batch)
2024-04-05 16:02:20,308 - Epoch: [137][  100/  100]    Loss 1.842883    Top1 54.950000    Top5 82.420000    
2024-04-05 16:02:20,487 - ==> Top1: 54.950    Top5: 82.420    Loss: 1.843

2024-04-05 16:02:20,494 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:02:20,494 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:02:20,524 - 

2024-04-05 16:02:20,524 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:02:24,807 - Epoch: [138][  100/  500]    Overall Loss 0.751058    Objective Loss 0.751058                                        LR 0.000500    Time 0.042787    
2024-04-05 16:02:29,197 - Epoch: [138][  200/  500]    Overall Loss 0.752461    Objective Loss 0.752461                                        LR 0.000500    Time 0.043315    
2024-04-05 16:02:33,641 - Epoch: [138][  300/  500]    Overall Loss 0.747237    Objective Loss 0.747237                                        LR 0.000500    Time 0.043675    
2024-04-05 16:02:38,107 - Epoch: [138][  400/  500]    Overall Loss 0.747346    Objective Loss 0.747346                                        LR 0.000500    Time 0.043908    
2024-04-05 16:02:42,533 - Epoch: [138][  500/  500]    Overall Loss 0.750080    Objective Loss 0.750080    Top1 70.500000    Top5 92.500000    LR 0.000500    Time 0.043969    
2024-04-05 16:02:42,710 - --- validate (epoch=138)-----------
2024-04-05 16:02:42,711 - 10000 samples (100 per mini-batch)
2024-04-05 16:02:44,195 - Epoch: [138][  100/  100]    Loss 1.860219    Top1 54.600000    Top5 82.030000    
2024-04-05 16:02:44,307 - ==> Top1: 54.600    Top5: 82.030    Loss: 1.860

2024-04-05 16:02:44,313 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:02:44,313 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:02:44,343 - 

2024-04-05 16:02:44,344 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:02:48,253 - Epoch: [139][  100/  500]    Overall Loss 0.721266    Objective Loss 0.721266                                        LR 0.000500    Time 0.039051    
2024-04-05 16:02:52,675 - Epoch: [139][  200/  500]    Overall Loss 0.726059    Objective Loss 0.726059                                        LR 0.000500    Time 0.041610    
2024-04-05 16:02:57,083 - Epoch: [139][  300/  500]    Overall Loss 0.735537    Objective Loss 0.735537                                        LR 0.000500    Time 0.042416    
2024-04-05 16:03:01,483 - Epoch: [139][  400/  500]    Overall Loss 0.737932    Objective Loss 0.737932                                        LR 0.000500    Time 0.042796    
2024-04-05 16:03:05,906 - Epoch: [139][  500/  500]    Overall Loss 0.742532    Objective Loss 0.742532    Top1 82.000000    Top5 96.500000    LR 0.000500    Time 0.043075    
2024-04-05 16:03:06,109 - --- validate (epoch=139)-----------
2024-04-05 16:03:06,109 - 10000 samples (100 per mini-batch)
2024-04-05 16:03:07,620 - Epoch: [139][  100/  100]    Loss 1.840512    Top1 54.730000    Top5 82.160000    
2024-04-05 16:03:07,730 - ==> Top1: 54.730    Top5: 82.160    Loss: 1.841

2024-04-05 16:03:07,736 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:03:07,737 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:03:07,768 - 

2024-04-05 16:03:07,768 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:03:12,132 - Epoch: [140][  100/  500]    Overall Loss 0.710890    Objective Loss 0.710890                                        LR 0.000500    Time 0.043588    
2024-04-05 16:03:16,500 - Epoch: [140][  200/  500]    Overall Loss 0.724670    Objective Loss 0.724670                                        LR 0.000500    Time 0.043609    
2024-04-05 16:03:20,939 - Epoch: [140][  300/  500]    Overall Loss 0.729280    Objective Loss 0.729280                                        LR 0.000500    Time 0.043850    
2024-04-05 16:03:25,382 - Epoch: [140][  400/  500]    Overall Loss 0.733907    Objective Loss 0.733907                                        LR 0.000500    Time 0.043983    
2024-04-05 16:03:29,826 - Epoch: [140][  500/  500]    Overall Loss 0.740498    Objective Loss 0.740498    Top1 78.000000    Top5 97.500000    LR 0.000500    Time 0.044063    
2024-04-05 16:03:30,010 - --- validate (epoch=140)-----------
2024-04-05 16:03:30,011 - 10000 samples (100 per mini-batch)
2024-04-05 16:03:31,776 - Epoch: [140][  100/  100]    Loss 1.841076    Top1 54.890000    Top5 82.400000    
2024-04-05 16:03:32,009 - ==> Top1: 54.890    Top5: 82.400    Loss: 1.841

2024-04-05 16:03:32,014 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:03:32,015 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:03:32,044 - 

2024-04-05 16:03:32,044 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:03:36,782 - Epoch: [141][  100/  500]    Overall Loss 0.712492    Objective Loss 0.712492                                        LR 0.000500    Time 0.047320    
2024-04-05 16:03:41,246 - Epoch: [141][  200/  500]    Overall Loss 0.718736    Objective Loss 0.718736                                        LR 0.000500    Time 0.045953    
2024-04-05 16:03:45,626 - Epoch: [141][  300/  500]    Overall Loss 0.728738    Objective Loss 0.728738                                        LR 0.000500    Time 0.045218    
2024-04-05 16:03:50,085 - Epoch: [141][  400/  500]    Overall Loss 0.734170    Objective Loss 0.734170                                        LR 0.000500    Time 0.045049    
2024-04-05 16:03:54,547 - Epoch: [141][  500/  500]    Overall Loss 0.740863    Objective Loss 0.740863    Top1 71.500000    Top5 95.000000    LR 0.000500    Time 0.044953    
2024-04-05 16:03:54,798 - --- validate (epoch=141)-----------
2024-04-05 16:03:54,799 - 10000 samples (100 per mini-batch)
2024-04-05 16:03:56,619 - Epoch: [141][  100/  100]    Loss 1.868488    Top1 54.350000    Top5 81.550000    
2024-04-05 16:03:56,780 - ==> Top1: 54.350    Top5: 81.550    Loss: 1.868

2024-04-05 16:03:56,794 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:03:56,794 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:03:56,822 - 

2024-04-05 16:03:56,822 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:04:01,593 - Epoch: [142][  100/  500]    Overall Loss 0.727850    Objective Loss 0.727850                                        LR 0.000500    Time 0.047659    
2024-04-05 16:04:06,060 - Epoch: [142][  200/  500]    Overall Loss 0.727240    Objective Loss 0.727240                                        LR 0.000500    Time 0.046137    
2024-04-05 16:04:10,413 - Epoch: [142][  300/  500]    Overall Loss 0.731949    Objective Loss 0.731949                                        LR 0.000500    Time 0.045253    
2024-04-05 16:04:14,829 - Epoch: [142][  400/  500]    Overall Loss 0.738256    Objective Loss 0.738256                                        LR 0.000500    Time 0.044967    
2024-04-05 16:04:19,063 - Epoch: [142][  500/  500]    Overall Loss 0.739426    Objective Loss 0.739426    Top1 81.000000    Top5 98.000000    LR 0.000500    Time 0.044433    
2024-04-05 16:04:19,227 - --- validate (epoch=142)-----------
2024-04-05 16:04:19,228 - 10000 samples (100 per mini-batch)
2024-04-05 16:04:20,741 - Epoch: [142][  100/  100]    Loss 1.863313    Top1 54.530000    Top5 81.850000    
2024-04-05 16:04:20,867 - ==> Top1: 54.530    Top5: 81.850    Loss: 1.863

2024-04-05 16:04:20,873 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:04:20,874 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:04:20,904 - 

2024-04-05 16:04:20,905 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:04:25,806 - Epoch: [143][  100/  500]    Overall Loss 0.709606    Objective Loss 0.709606                                        LR 0.000500    Time 0.048961    
2024-04-05 16:04:30,222 - Epoch: [143][  200/  500]    Overall Loss 0.720181    Objective Loss 0.720181                                        LR 0.000500    Time 0.046530    
2024-04-05 16:04:34,590 - Epoch: [143][  300/  500]    Overall Loss 0.721777    Objective Loss 0.721777                                        LR 0.000500    Time 0.045567    
2024-04-05 16:04:39,006 - Epoch: [143][  400/  500]    Overall Loss 0.728626    Objective Loss 0.728626                                        LR 0.000500    Time 0.045202    
2024-04-05 16:04:43,036 - Epoch: [143][  500/  500]    Overall Loss 0.732956    Objective Loss 0.732956    Top1 73.500000    Top5 94.500000    LR 0.000500    Time 0.044213    
2024-04-05 16:04:43,273 - --- validate (epoch=143)-----------
2024-04-05 16:04:43,274 - 10000 samples (100 per mini-batch)
2024-04-05 16:04:44,765 - Epoch: [143][  100/  100]    Loss 1.867802    Top1 55.110000    Top5 81.840000    
2024-04-05 16:04:44,891 - ==> Top1: 55.110    Top5: 81.840    Loss: 1.868

2024-04-05 16:04:44,897 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:04:44,897 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:04:44,927 - 

2024-04-05 16:04:44,928 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:04:49,797 - Epoch: [144][  100/  500]    Overall Loss 0.709016    Objective Loss 0.709016                                        LR 0.000500    Time 0.048638    
2024-04-05 16:04:54,178 - Epoch: [144][  200/  500]    Overall Loss 0.715795    Objective Loss 0.715795                                        LR 0.000500    Time 0.046196    
2024-04-05 16:04:58,609 - Epoch: [144][  300/  500]    Overall Loss 0.720148    Objective Loss 0.720148                                        LR 0.000500    Time 0.045553    
2024-04-05 16:05:03,039 - Epoch: [144][  400/  500]    Overall Loss 0.725919    Objective Loss 0.725919                                        LR 0.000500    Time 0.045227    
2024-04-05 16:05:06,607 - Epoch: [144][  500/  500]    Overall Loss 0.731878    Objective Loss 0.731878    Top1 81.000000    Top5 98.500000    LR 0.000500    Time 0.043309    
2024-04-05 16:05:06,786 - --- validate (epoch=144)-----------
2024-04-05 16:05:06,787 - 10000 samples (100 per mini-batch)
2024-04-05 16:05:08,606 - Epoch: [144][  100/  100]    Loss 1.866690    Top1 54.800000    Top5 82.320000    
2024-04-05 16:05:08,717 - ==> Top1: 54.800    Top5: 82.320    Loss: 1.867

2024-04-05 16:05:08,721 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:05:08,721 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:05:08,742 - 

2024-04-05 16:05:08,743 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:05:13,567 - Epoch: [145][  100/  500]    Overall Loss 0.700761    Objective Loss 0.700761                                        LR 0.000500    Time 0.048191    
2024-04-05 16:05:18,005 - Epoch: [145][  200/  500]    Overall Loss 0.704546    Objective Loss 0.704546                                        LR 0.000500    Time 0.046257    
2024-04-05 16:05:22,346 - Epoch: [145][  300/  500]    Overall Loss 0.714183    Objective Loss 0.714183                                        LR 0.000500    Time 0.045292    
2024-04-05 16:05:26,790 - Epoch: [145][  400/  500]    Overall Loss 0.726719    Objective Loss 0.726719                                        LR 0.000500    Time 0.045067    
2024-04-05 16:05:30,454 - Epoch: [145][  500/  500]    Overall Loss 0.732843    Objective Loss 0.732843    Top1 79.500000    Top5 96.500000    LR 0.000500    Time 0.043372    
2024-04-05 16:05:30,631 - --- validate (epoch=145)-----------
2024-04-05 16:05:30,631 - 10000 samples (100 per mini-batch)
2024-04-05 16:05:32,194 - Epoch: [145][  100/  100]    Loss 1.862226    Top1 54.820000    Top5 82.110000    
2024-04-05 16:05:32,289 - ==> Top1: 54.820    Top5: 82.110    Loss: 1.862

2024-04-05 16:05:32,297 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:05:32,297 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:05:32,326 - 

2024-04-05 16:05:32,327 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:05:37,121 - Epoch: [146][  100/  500]    Overall Loss 0.720764    Objective Loss 0.720764                                        LR 0.000500    Time 0.047893    
2024-04-05 16:05:41,493 - Epoch: [146][  200/  500]    Overall Loss 0.717896    Objective Loss 0.717896                                        LR 0.000500    Time 0.045777    
2024-04-05 16:05:45,888 - Epoch: [146][  300/  500]    Overall Loss 0.718858    Objective Loss 0.718858                                        LR 0.000500    Time 0.045152    
2024-04-05 16:05:48,985 - Epoch: [146][  400/  500]    Overall Loss 0.721229    Objective Loss 0.721229                                        LR 0.000500    Time 0.041597    
2024-04-05 16:05:51,469 - Epoch: [146][  500/  500]    Overall Loss 0.725311    Objective Loss 0.725311    Top1 78.000000    Top5 96.500000    LR 0.000500    Time 0.038239    
2024-04-05 16:05:51,672 - --- validate (epoch=146)-----------
2024-04-05 16:05:51,673 - 10000 samples (100 per mini-batch)
2024-04-05 16:05:53,508 - Epoch: [146][  100/  100]    Loss 1.869855    Top1 54.770000    Top5 81.790000    
2024-04-05 16:05:53,701 - ==> Top1: 54.770    Top5: 81.790    Loss: 1.870

2024-04-05 16:05:53,707 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:05:53,707 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:05:53,737 - 

2024-04-05 16:05:53,737 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:05:58,388 - Epoch: [147][  100/  500]    Overall Loss 0.728827    Objective Loss 0.728827                                        LR 0.000500    Time 0.046453    
2024-04-05 16:06:02,665 - Epoch: [147][  200/  500]    Overall Loss 0.726585    Objective Loss 0.726585                                        LR 0.000500    Time 0.044587    
2024-04-05 16:06:07,069 - Epoch: [147][  300/  500]    Overall Loss 0.723900    Objective Loss 0.723900                                        LR 0.000500    Time 0.044390    
2024-04-05 16:06:11,512 - Epoch: [147][  400/  500]    Overall Loss 0.727191    Objective Loss 0.727191                                        LR 0.000500    Time 0.044389    
2024-04-05 16:06:15,232 - Epoch: [147][  500/  500]    Overall Loss 0.731521    Objective Loss 0.731521    Top1 80.500000    Top5 98.000000    LR 0.000500    Time 0.042941    
2024-04-05 16:06:15,472 - --- validate (epoch=147)-----------
2024-04-05 16:06:15,473 - 10000 samples (100 per mini-batch)
2024-04-05 16:06:17,009 - Epoch: [147][  100/  100]    Loss 1.869712    Top1 54.580000    Top5 81.990000    
2024-04-05 16:06:17,163 - ==> Top1: 54.580    Top5: 81.990    Loss: 1.870

2024-04-05 16:06:17,169 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:06:17,170 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:06:17,199 - 

2024-04-05 16:06:17,199 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:06:21,701 - Epoch: [148][  100/  500]    Overall Loss 0.699501    Objective Loss 0.699501                                        LR 0.000500    Time 0.044972    
2024-04-05 16:06:26,141 - Epoch: [148][  200/  500]    Overall Loss 0.713234    Objective Loss 0.713234                                        LR 0.000500    Time 0.044659    
2024-04-05 16:06:30,525 - Epoch: [148][  300/  500]    Overall Loss 0.716166    Objective Loss 0.716166                                        LR 0.000500    Time 0.044371    
2024-04-05 16:06:34,967 - Epoch: [148][  400/  500]    Overall Loss 0.718606    Objective Loss 0.718606                                        LR 0.000500    Time 0.044370    
2024-04-05 16:06:38,653 - Epoch: [148][  500/  500]    Overall Loss 0.721763    Objective Loss 0.721763    Top1 76.500000    Top5 96.500000    LR 0.000500    Time 0.042860    
2024-04-05 16:06:38,897 - --- validate (epoch=148)-----------
2024-04-05 16:06:38,898 - 10000 samples (100 per mini-batch)
2024-04-05 16:06:40,417 - Epoch: [148][  100/  100]    Loss 1.864543    Top1 54.620000    Top5 81.980000    
2024-04-05 16:06:40,529 - ==> Top1: 54.620    Top5: 81.980    Loss: 1.865

2024-04-05 16:06:40,535 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:06:40,536 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:06:40,567 - 

2024-04-05 16:06:40,568 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:06:45,479 - Epoch: [149][  100/  500]    Overall Loss 0.715770    Objective Loss 0.715770                                        LR 0.000500    Time 0.049063    
2024-04-05 16:06:49,906 - Epoch: [149][  200/  500]    Overall Loss 0.717598    Objective Loss 0.717598                                        LR 0.000500    Time 0.046636    
2024-04-05 16:06:54,328 - Epoch: [149][  300/  500]    Overall Loss 0.723741    Objective Loss 0.723741                                        LR 0.000500    Time 0.045815    
2024-04-05 16:06:58,722 - Epoch: [149][  400/  500]    Overall Loss 0.727129    Objective Loss 0.727129                                        LR 0.000500    Time 0.045334    
2024-04-05 16:07:02,696 - Epoch: [149][  500/  500]    Overall Loss 0.727157    Objective Loss 0.727157    Top1 78.000000    Top5 95.500000    LR 0.000500    Time 0.044207    
2024-04-05 16:07:02,955 - --- validate (epoch=149)-----------
2024-04-05 16:07:02,956 - 10000 samples (100 per mini-batch)
2024-04-05 16:07:04,589 - Epoch: [149][  100/  100]    Loss 1.870785    Top1 54.400000    Top5 82.060000    
2024-04-05 16:07:04,697 - ==> Top1: 54.400    Top5: 82.060    Loss: 1.871

2024-04-05 16:07:04,706 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:07:04,706 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:07:04,735 - 

2024-04-05 16:07:04,735 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:07:09,827 - Epoch: [150][  100/  500]    Overall Loss 0.697226    Objective Loss 0.697226                                        LR 0.000250    Time 0.050861    
2024-04-05 16:07:14,282 - Epoch: [150][  200/  500]    Overall Loss 0.680855    Objective Loss 0.680855                                        LR 0.000250    Time 0.047680    
2024-04-05 16:07:18,686 - Epoch: [150][  300/  500]    Overall Loss 0.683075    Objective Loss 0.683075                                        LR 0.000250    Time 0.046448    
2024-04-05 16:07:22,480 - Epoch: [150][  400/  500]    Overall Loss 0.687327    Objective Loss 0.687327                                        LR 0.000250    Time 0.044310    
2024-04-05 16:07:26,906 - Epoch: [150][  500/  500]    Overall Loss 0.690905    Objective Loss 0.690905    Top1 83.000000    Top5 98.000000    LR 0.000250    Time 0.044290    
2024-04-05 16:07:27,060 - --- validate (epoch=150)-----------
2024-04-05 16:07:27,061 - 10000 samples (100 per mini-batch)
2024-04-05 16:07:28,585 - Epoch: [150][  100/  100]    Loss 1.852225    Top1 54.950000    Top5 81.990000    
2024-04-05 16:07:28,711 - ==> Top1: 54.950    Top5: 81.990    Loss: 1.852

2024-04-05 16:07:28,717 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:07:28,717 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:07:28,749 - 

2024-04-05 16:07:28,749 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:07:33,659 - Epoch: [151][  100/  500]    Overall Loss 0.660047    Objective Loss 0.660047                                        LR 0.000250    Time 0.049021    
2024-04-05 16:07:38,152 - Epoch: [151][  200/  500]    Overall Loss 0.662905    Objective Loss 0.662905                                        LR 0.000250    Time 0.046946    
2024-04-05 16:07:42,554 - Epoch: [151][  300/  500]    Overall Loss 0.661901    Objective Loss 0.661901                                        LR 0.000250    Time 0.045955    
2024-04-05 16:07:46,390 - Epoch: [151][  400/  500]    Overall Loss 0.665323    Objective Loss 0.665323                                        LR 0.000250    Time 0.044043    
2024-04-05 16:07:50,835 - Epoch: [151][  500/  500]    Overall Loss 0.669683    Objective Loss 0.669683    Top1 86.000000    Top5 99.500000    LR 0.000250    Time 0.044114    
2024-04-05 16:07:51,011 - --- validate (epoch=151)-----------
2024-04-05 16:07:51,013 - 10000 samples (100 per mini-batch)
2024-04-05 16:07:52,514 - Epoch: [151][  100/  100]    Loss 1.856143    Top1 55.180000    Top5 82.250000    
2024-04-05 16:07:52,687 - ==> Top1: 55.180    Top5: 82.250    Loss: 1.856

2024-04-05 16:07:52,694 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:07:52,694 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:07:52,725 - 

2024-04-05 16:07:52,725 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:07:57,191 - Epoch: [152][  100/  500]    Overall Loss 0.651998    Objective Loss 0.651998                                        LR 0.000250    Time 0.044603    
2024-04-05 16:08:01,656 - Epoch: [152][  200/  500]    Overall Loss 0.661004    Objective Loss 0.661004                                        LR 0.000250    Time 0.044600    
2024-04-05 16:08:06,017 - Epoch: [152][  300/  500]    Overall Loss 0.668400    Objective Loss 0.668400                                        LR 0.000250    Time 0.044240    
2024-04-05 16:08:10,129 - Epoch: [152][  400/  500]    Overall Loss 0.669447    Objective Loss 0.669447                                        LR 0.000250    Time 0.043446    
2024-04-05 16:08:14,558 - Epoch: [152][  500/  500]    Overall Loss 0.673236    Objective Loss 0.673236    Top1 81.000000    Top5 98.500000    LR 0.000250    Time 0.043606    
2024-04-05 16:08:14,744 - --- validate (epoch=152)-----------
2024-04-05 16:08:14,744 - 10000 samples (100 per mini-batch)
2024-04-05 16:08:16,583 - Epoch: [152][  100/  100]    Loss 1.850039    Top1 54.940000    Top5 82.280000    
2024-04-05 16:08:16,683 - ==> Top1: 54.940    Top5: 82.280    Loss: 1.850

2024-04-05 16:08:16,690 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:08:16,690 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:08:16,722 - 

2024-04-05 16:08:16,722 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:08:20,965 - Epoch: [153][  100/  500]    Overall Loss 0.651471    Objective Loss 0.651471                                        LR 0.000250    Time 0.042385    
2024-04-05 16:08:25,342 - Epoch: [153][  200/  500]    Overall Loss 0.653890    Objective Loss 0.653890                                        LR 0.000250    Time 0.043051    
2024-04-05 16:08:29,780 - Epoch: [153][  300/  500]    Overall Loss 0.659948    Objective Loss 0.659948                                        LR 0.000250    Time 0.043477    
2024-04-05 16:08:33,550 - Epoch: [153][  400/  500]    Overall Loss 0.658351    Objective Loss 0.658351                                        LR 0.000250    Time 0.042022    
2024-04-05 16:08:37,995 - Epoch: [153][  500/  500]    Overall Loss 0.660464    Objective Loss 0.660464    Top1 84.500000    Top5 98.500000    LR 0.000250    Time 0.042496    
2024-04-05 16:08:38,174 - --- validate (epoch=153)-----------
2024-04-05 16:08:38,175 - 10000 samples (100 per mini-batch)
2024-04-05 16:08:39,714 - Epoch: [153][  100/  100]    Loss 1.861507    Top1 55.170000    Top5 82.290000    
2024-04-05 16:08:39,897 - ==> Top1: 55.170    Top5: 82.290    Loss: 1.862

2024-04-05 16:08:39,903 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:08:39,903 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:08:39,933 - 

2024-04-05 16:08:39,933 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:08:44,864 - Epoch: [154][  100/  500]    Overall Loss 0.632274    Objective Loss 0.632274                                        LR 0.000250    Time 0.049248    
2024-04-05 16:08:49,291 - Epoch: [154][  200/  500]    Overall Loss 0.645699    Objective Loss 0.645699                                        LR 0.000250    Time 0.046735    
2024-04-05 16:08:53,350 - Epoch: [154][  300/  500]    Overall Loss 0.653595    Objective Loss 0.653595                                        LR 0.000250    Time 0.044670    
2024-04-05 16:08:57,500 - Epoch: [154][  400/  500]    Overall Loss 0.657072    Objective Loss 0.657072                                        LR 0.000250    Time 0.043868    
2024-04-05 16:09:01,896 - Epoch: [154][  500/  500]    Overall Loss 0.661552    Objective Loss 0.661552    Top1 80.000000    Top5 97.000000    LR 0.000250    Time 0.043873    
2024-04-05 16:09:02,071 - --- validate (epoch=154)-----------
2024-04-05 16:09:02,072 - 10000 samples (100 per mini-batch)
2024-04-05 16:09:03,570 - Epoch: [154][  100/  100]    Loss 1.856877    Top1 54.900000    Top5 82.120000    
2024-04-05 16:09:03,684 - ==> Top1: 54.900    Top5: 82.120    Loss: 1.857

2024-04-05 16:09:03,690 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:09:03,690 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:09:03,722 - 

2024-04-05 16:09:03,722 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:09:08,604 - Epoch: [155][  100/  500]    Overall Loss 0.642000    Objective Loss 0.642000                                        LR 0.000250    Time 0.048762    
2024-04-05 16:09:12,963 - Epoch: [155][  200/  500]    Overall Loss 0.646789    Objective Loss 0.646789                                        LR 0.000250    Time 0.046151    
2024-04-05 16:09:16,818 - Epoch: [155][  300/  500]    Overall Loss 0.652694    Objective Loss 0.652694                                        LR 0.000250    Time 0.043602    
2024-04-05 16:09:21,255 - Epoch: [155][  400/  500]    Overall Loss 0.655412    Objective Loss 0.655412                                        LR 0.000250    Time 0.043784    
2024-04-05 16:09:25,698 - Epoch: [155][  500/  500]    Overall Loss 0.656829    Objective Loss 0.656829    Top1 83.000000    Top5 97.500000    LR 0.000250    Time 0.043903    
2024-04-05 16:09:25,954 - --- validate (epoch=155)-----------
2024-04-05 16:09:25,955 - 10000 samples (100 per mini-batch)
2024-04-05 16:09:27,454 - Epoch: [155][  100/  100]    Loss 1.848720    Top1 55.210000    Top5 82.210000    
2024-04-05 16:09:27,569 - ==> Top1: 55.210    Top5: 82.210    Loss: 1.849

2024-04-05 16:09:27,576 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:09:27,576 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:09:27,605 - 

2024-04-05 16:09:27,606 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:09:32,349 - Epoch: [156][  100/  500]    Overall Loss 0.637641    Objective Loss 0.637641                                        LR 0.000250    Time 0.047378    
2024-04-05 16:09:36,429 - Epoch: [156][  200/  500]    Overall Loss 0.648299    Objective Loss 0.648299                                        LR 0.000250    Time 0.044067    
2024-04-05 16:09:40,833 - Epoch: [156][  300/  500]    Overall Loss 0.651511    Objective Loss 0.651511                                        LR 0.000250    Time 0.044043    
2024-04-05 16:09:45,276 - Epoch: [156][  400/  500]    Overall Loss 0.655323    Objective Loss 0.655323                                        LR 0.000250    Time 0.044127    
2024-04-05 16:09:49,698 - Epoch: [156][  500/  500]    Overall Loss 0.654790    Objective Loss 0.654790    Top1 82.000000    Top5 97.000000    LR 0.000250    Time 0.044135    
2024-04-05 16:09:49,884 - --- validate (epoch=156)-----------
2024-04-05 16:09:49,885 - 10000 samples (100 per mini-batch)
2024-04-05 16:09:51,531 - Epoch: [156][  100/  100]    Loss 1.866552    Top1 54.800000    Top5 81.950000    
2024-04-05 16:09:51,689 - ==> Top1: 54.800    Top5: 81.950    Loss: 1.867

2024-04-05 16:09:51,696 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:09:51,696 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:09:51,726 - 

2024-04-05 16:09:51,726 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:09:56,549 - Epoch: [157][  100/  500]    Overall Loss 0.640907    Objective Loss 0.640907                                        LR 0.000250    Time 0.048181    
2024-04-05 16:10:00,352 - Epoch: [157][  200/  500]    Overall Loss 0.644163    Objective Loss 0.644163                                        LR 0.000250    Time 0.043080    
2024-04-05 16:10:04,723 - Epoch: [157][  300/  500]    Overall Loss 0.648078    Objective Loss 0.648078                                        LR 0.000250    Time 0.043273    
2024-04-05 16:10:09,176 - Epoch: [157][  400/  500]    Overall Loss 0.649728    Objective Loss 0.649728                                        LR 0.000250    Time 0.043575    
2024-04-05 16:10:13,631 - Epoch: [157][  500/  500]    Overall Loss 0.653281    Objective Loss 0.653281    Top1 84.000000    Top5 98.000000    LR 0.000250    Time 0.043759    
2024-04-05 16:10:13,908 - --- validate (epoch=157)-----------
2024-04-05 16:10:13,909 - 10000 samples (100 per mini-batch)
2024-04-05 16:10:15,406 - Epoch: [157][  100/  100]    Loss 1.860968    Top1 54.600000    Top5 82.260000    
2024-04-05 16:10:15,542 - ==> Top1: 54.600    Top5: 82.260    Loss: 1.861

2024-04-05 16:10:15,548 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:10:15,548 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:10:15,578 - 

2024-04-05 16:10:15,579 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:10:20,514 - Epoch: [158][  100/  500]    Overall Loss 0.646239    Objective Loss 0.646239                                        LR 0.000250    Time 0.049302    
2024-04-05 16:10:24,926 - Epoch: [158][  200/  500]    Overall Loss 0.652161    Objective Loss 0.652161                                        LR 0.000250    Time 0.046687    
2024-04-05 16:10:29,313 - Epoch: [158][  300/  500]    Overall Loss 0.653226    Objective Loss 0.653226                                        LR 0.000250    Time 0.045732    
2024-04-05 16:10:33,733 - Epoch: [158][  400/  500]    Overall Loss 0.652396    Objective Loss 0.652396                                        LR 0.000250    Time 0.045335    
2024-04-05 16:10:38,177 - Epoch: [158][  500/  500]    Overall Loss 0.653290    Objective Loss 0.653290    Top1 83.000000    Top5 96.500000    LR 0.000250    Time 0.045146    
2024-04-05 16:10:38,373 - --- validate (epoch=158)-----------
2024-04-05 16:10:38,374 - 10000 samples (100 per mini-batch)
2024-04-05 16:10:39,896 - Epoch: [158][  100/  100]    Loss 1.854488    Top1 55.160000    Top5 82.440000    
2024-04-05 16:10:40,003 - ==> Top1: 55.160    Top5: 82.440    Loss: 1.854

2024-04-05 16:10:40,011 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:10:40,011 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:10:40,042 - 

2024-04-05 16:10:40,042 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:10:44,300 - Epoch: [159][  100/  500]    Overall Loss 0.621733    Objective Loss 0.621733                                        LR 0.000250    Time 0.042527    
2024-04-05 16:10:48,771 - Epoch: [159][  200/  500]    Overall Loss 0.641559    Objective Loss 0.641559                                        LR 0.000250    Time 0.043594    
2024-04-05 16:10:53,123 - Epoch: [159][  300/  500]    Overall Loss 0.652452    Objective Loss 0.652452                                        LR 0.000250    Time 0.043554    
2024-04-05 16:10:57,603 - Epoch: [159][  400/  500]    Overall Loss 0.657192    Objective Loss 0.657192                                        LR 0.000250    Time 0.043853    
2024-04-05 16:11:02,008 - Epoch: [159][  500/  500]    Overall Loss 0.658397    Objective Loss 0.658397    Top1 79.000000    Top5 94.000000    LR 0.000250    Time 0.043882    
2024-04-05 16:11:02,171 - --- validate (epoch=159)-----------
2024-04-05 16:11:02,172 - 10000 samples (100 per mini-batch)
2024-04-05 16:11:03,685 - Epoch: [159][  100/  100]    Loss 1.868440    Top1 54.900000    Top5 82.060000    
2024-04-05 16:11:03,842 - ==> Top1: 54.900    Top5: 82.060    Loss: 1.868

2024-04-05 16:11:03,849 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:11:03,850 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:11:03,879 - 

2024-04-05 16:11:03,879 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:11:08,051 - Epoch: [160][  100/  500]    Overall Loss 0.641993    Objective Loss 0.641993                                        LR 0.000250    Time 0.041670    
2024-04-05 16:11:12,461 - Epoch: [160][  200/  500]    Overall Loss 0.638770    Objective Loss 0.638770                                        LR 0.000250    Time 0.042860    
2024-04-05 16:11:16,595 - Epoch: [160][  300/  500]    Overall Loss 0.644470    Objective Loss 0.644470                                        LR 0.000250    Time 0.042336    
2024-04-05 16:11:20,990 - Epoch: [160][  400/  500]    Overall Loss 0.643712    Objective Loss 0.643712                                        LR 0.000250    Time 0.042726    
2024-04-05 16:11:25,381 - Epoch: [160][  500/  500]    Overall Loss 0.643481    Objective Loss 0.643481    Top1 82.500000    Top5 99.500000    LR 0.000250    Time 0.042954    
2024-04-05 16:11:25,570 - --- validate (epoch=160)-----------
2024-04-05 16:11:25,571 - 10000 samples (100 per mini-batch)
2024-04-05 16:11:27,313 - Epoch: [160][  100/  100]    Loss 1.867425    Top1 54.920000    Top5 82.290000    
2024-04-05 16:11:27,436 - ==> Top1: 54.920    Top5: 82.290    Loss: 1.867

2024-04-05 16:11:27,442 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:11:27,443 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:11:27,473 - 

2024-04-05 16:11:27,473 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:11:32,042 - Epoch: [161][  100/  500]    Overall Loss 0.628218    Objective Loss 0.628218                                        LR 0.000250    Time 0.045632    
2024-04-05 16:11:36,530 - Epoch: [161][  200/  500]    Overall Loss 0.638601    Objective Loss 0.638601                                        LR 0.000250    Time 0.045230    
2024-04-05 16:11:40,898 - Epoch: [161][  300/  500]    Overall Loss 0.643026    Objective Loss 0.643026                                        LR 0.000250    Time 0.044697    
2024-04-05 16:11:45,297 - Epoch: [161][  400/  500]    Overall Loss 0.644530    Objective Loss 0.644530                                        LR 0.000250    Time 0.044509    
2024-04-05 16:11:49,711 - Epoch: [161][  500/  500]    Overall Loss 0.644438    Objective Loss 0.644438    Top1 81.500000    Top5 97.500000    LR 0.000250    Time 0.044426    
2024-04-05 16:11:49,900 - --- validate (epoch=161)-----------
2024-04-05 16:11:49,901 - 10000 samples (100 per mini-batch)
2024-04-05 16:11:51,397 - Epoch: [161][  100/  100]    Loss 1.868917    Top1 54.920000    Top5 82.450000    
2024-04-05 16:11:51,513 - ==> Top1: 54.920    Top5: 82.450    Loss: 1.869

2024-04-05 16:11:51,519 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:11:51,519 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:11:51,548 - 

2024-04-05 16:11:51,548 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:11:55,733 - Epoch: [162][  100/  500]    Overall Loss 0.632343    Objective Loss 0.632343                                        LR 0.000250    Time 0.041806    
2024-04-05 16:11:58,295 - Epoch: [162][  200/  500]    Overall Loss 0.645072    Objective Loss 0.645072                                        LR 0.000250    Time 0.033694    
2024-04-05 16:12:02,121 - Epoch: [162][  300/  500]    Overall Loss 0.643318    Objective Loss 0.643318                                        LR 0.000250    Time 0.035204    
2024-04-05 16:12:06,571 - Epoch: [162][  400/  500]    Overall Loss 0.645453    Objective Loss 0.645453                                        LR 0.000250    Time 0.037515    
2024-04-05 16:12:10,992 - Epoch: [162][  500/  500]    Overall Loss 0.644148    Objective Loss 0.644148    Top1 83.000000    Top5 98.000000    LR 0.000250    Time 0.038842    
2024-04-05 16:12:11,147 - --- validate (epoch=162)-----------
2024-04-05 16:12:11,148 - 10000 samples (100 per mini-batch)
2024-04-05 16:12:12,881 - Epoch: [162][  100/  100]    Loss 1.871169    Top1 55.140000    Top5 82.220000    
2024-04-05 16:12:13,045 - ==> Top1: 55.140    Top5: 82.220    Loss: 1.871

2024-04-05 16:12:13,051 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:12:13,051 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:12:13,082 - 

2024-04-05 16:12:13,082 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:12:17,963 - Epoch: [163][  100/  500]    Overall Loss 0.634867    Objective Loss 0.634867                                        LR 0.000250    Time 0.048750    
2024-04-05 16:12:22,247 - Epoch: [163][  200/  500]    Overall Loss 0.646192    Objective Loss 0.646192                                        LR 0.000250    Time 0.045773    
2024-04-05 16:12:26,696 - Epoch: [163][  300/  500]    Overall Loss 0.649654    Objective Loss 0.649654                                        LR 0.000250    Time 0.045326    
2024-04-05 16:12:31,133 - Epoch: [163][  400/  500]    Overall Loss 0.642660    Objective Loss 0.642660                                        LR 0.000250    Time 0.045074    
2024-04-05 16:12:35,588 - Epoch: [163][  500/  500]    Overall Loss 0.645238    Objective Loss 0.645238    Top1 83.500000    Top5 97.500000    LR 0.000250    Time 0.044959    
2024-04-05 16:12:35,782 - --- validate (epoch=163)-----------
2024-04-05 16:12:35,783 - 10000 samples (100 per mini-batch)
2024-04-05 16:12:37,304 - Epoch: [163][  100/  100]    Loss 1.876687    Top1 54.680000    Top5 81.880000    
2024-04-05 16:12:37,496 - ==> Top1: 54.680    Top5: 81.880    Loss: 1.877

2024-04-05 16:12:37,502 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:12:37,503 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:12:37,532 - 

2024-04-05 16:12:37,533 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:12:42,627 - Epoch: [164][  100/  500]    Overall Loss 0.634923    Objective Loss 0.634923                                        LR 0.000250    Time 0.050887    
2024-04-05 16:12:46,601 - Epoch: [164][  200/  500]    Overall Loss 0.635335    Objective Loss 0.635335                                        LR 0.000250    Time 0.045286    
2024-04-05 16:12:50,961 - Epoch: [164][  300/  500]    Overall Loss 0.641264    Objective Loss 0.641264                                        LR 0.000250    Time 0.044705    
2024-04-05 16:12:55,383 - Epoch: [164][  400/  500]    Overall Loss 0.642421    Objective Loss 0.642421                                        LR 0.000250    Time 0.044571    
2024-04-05 16:12:59,799 - Epoch: [164][  500/  500]    Overall Loss 0.645984    Objective Loss 0.645984    Top1 77.500000    Top5 95.500000    LR 0.000250    Time 0.044478    
2024-04-05 16:12:59,959 - --- validate (epoch=164)-----------
2024-04-05 16:12:59,960 - 10000 samples (100 per mini-batch)
2024-04-05 16:13:01,522 - Epoch: [164][  100/  100]    Loss 1.878717    Top1 55.250000    Top5 82.160000    
2024-04-05 16:13:01,644 - ==> Top1: 55.250    Top5: 82.160    Loss: 1.879

2024-04-05 16:13:01,654 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:13:01,654 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:13:01,684 - 

2024-04-05 16:13:01,684 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:13:06,449 - Epoch: [165][  100/  500]    Overall Loss 0.639307    Objective Loss 0.639307                                        LR 0.000250    Time 0.047598    
2024-04-05 16:13:10,589 - Epoch: [165][  200/  500]    Overall Loss 0.632105    Objective Loss 0.632105                                        LR 0.000250    Time 0.044474    
2024-04-05 16:13:15,036 - Epoch: [165][  300/  500]    Overall Loss 0.639119    Objective Loss 0.639119                                        LR 0.000250    Time 0.044457    
2024-04-05 16:13:19,487 - Epoch: [165][  400/  500]    Overall Loss 0.638560    Objective Loss 0.638560                                        LR 0.000250    Time 0.044456    
2024-04-05 16:13:23,886 - Epoch: [165][  500/  500]    Overall Loss 0.640343    Objective Loss 0.640343    Top1 77.500000    Top5 96.500000    LR 0.000250    Time 0.044354    
2024-04-05 16:13:24,161 - --- validate (epoch=165)-----------
2024-04-05 16:13:24,162 - 10000 samples (100 per mini-batch)
2024-04-05 16:13:25,648 - Epoch: [165][  100/  100]    Loss 1.871405    Top1 54.990000    Top5 82.120000    
2024-04-05 16:13:25,767 - ==> Top1: 54.990    Top5: 82.120    Loss: 1.871

2024-04-05 16:13:25,774 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:13:25,774 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:13:25,803 - 

2024-04-05 16:13:25,804 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:13:31,038 - Epoch: [166][  100/  500]    Overall Loss 0.634688    Objective Loss 0.634688                                        LR 0.000250    Time 0.052288    
2024-04-05 16:13:35,167 - Epoch: [166][  200/  500]    Overall Loss 0.627348    Objective Loss 0.627348                                        LR 0.000250    Time 0.046765    
2024-04-05 16:13:39,522 - Epoch: [166][  300/  500]    Overall Loss 0.636152    Objective Loss 0.636152                                        LR 0.000250    Time 0.045674    
2024-04-05 16:13:43,924 - Epoch: [166][  400/  500]    Overall Loss 0.637241    Objective Loss 0.637241                                        LR 0.000250    Time 0.045251    
2024-04-05 16:13:48,315 - Epoch: [166][  500/  500]    Overall Loss 0.638747    Objective Loss 0.638747    Top1 74.000000    Top5 98.000000    LR 0.000250    Time 0.044972    
2024-04-05 16:13:48,557 - --- validate (epoch=166)-----------
2024-04-05 16:13:48,557 - 10000 samples (100 per mini-batch)
2024-04-05 16:13:50,099 - Epoch: [166][  100/  100]    Loss 1.881305    Top1 54.990000    Top5 81.850000    
2024-04-05 16:13:50,201 - ==> Top1: 54.990    Top5: 81.850    Loss: 1.881

2024-04-05 16:13:50,207 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:13:50,208 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:13:50,239 - 

2024-04-05 16:13:50,239 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:13:55,114 - Epoch: [167][  100/  500]    Overall Loss 0.622780    Objective Loss 0.622780                                        LR 0.000250    Time 0.048698    
2024-04-05 16:13:59,283 - Epoch: [167][  200/  500]    Overall Loss 0.629048    Objective Loss 0.629048                                        LR 0.000250    Time 0.045167    
2024-04-05 16:14:03,661 - Epoch: [167][  300/  500]    Overall Loss 0.629802    Objective Loss 0.629802                                        LR 0.000250    Time 0.044687    
2024-04-05 16:14:08,016 - Epoch: [167][  400/  500]    Overall Loss 0.631581    Objective Loss 0.631581                                        LR 0.000250    Time 0.044391    
2024-04-05 16:14:12,418 - Epoch: [167][  500/  500]    Overall Loss 0.634765    Objective Loss 0.634765    Top1 76.000000    Top5 97.000000    LR 0.000250    Time 0.044307    
2024-04-05 16:14:12,595 - --- validate (epoch=167)-----------
2024-04-05 16:14:12,596 - 10000 samples (100 per mini-batch)
2024-04-05 16:14:14,144 - Epoch: [167][  100/  100]    Loss 1.869730    Top1 55.320000    Top5 82.130000    
2024-04-05 16:14:14,254 - ==> Top1: 55.320    Top5: 82.130    Loss: 1.870

2024-04-05 16:14:14,261 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:14:14,261 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:14:14,291 - 

2024-04-05 16:14:14,292 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:14:19,099 - Epoch: [168][  100/  500]    Overall Loss 0.623057    Objective Loss 0.623057                                        LR 0.000250    Time 0.048017    
2024-04-05 16:14:23,244 - Epoch: [168][  200/  500]    Overall Loss 0.633987    Objective Loss 0.633987                                        LR 0.000250    Time 0.044707    
2024-04-05 16:14:27,476 - Epoch: [168][  300/  500]    Overall Loss 0.637497    Objective Loss 0.637497                                        LR 0.000250    Time 0.043897    
2024-04-05 16:14:31,859 - Epoch: [168][  400/  500]    Overall Loss 0.638194    Objective Loss 0.638194                                        LR 0.000250    Time 0.043869    
2024-04-05 16:14:36,220 - Epoch: [168][  500/  500]    Overall Loss 0.638187    Objective Loss 0.638187    Top1 76.000000    Top5 97.000000    LR 0.000250    Time 0.043807    
2024-04-05 16:14:36,411 - --- validate (epoch=168)-----------
2024-04-05 16:14:36,413 - 10000 samples (100 per mini-batch)
2024-04-05 16:14:38,049 - Epoch: [168][  100/  100]    Loss 1.880724    Top1 54.880000    Top5 82.430000    
2024-04-05 16:14:38,146 - ==> Top1: 54.880    Top5: 82.430    Loss: 1.881

2024-04-05 16:14:38,152 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:14:38,153 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:14:38,182 - 

2024-04-05 16:14:38,183 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:14:42,874 - Epoch: [169][  100/  500]    Overall Loss 0.638859    Objective Loss 0.638859                                        LR 0.000250    Time 0.046863    
2024-04-05 16:14:46,412 - Epoch: [169][  200/  500]    Overall Loss 0.640022    Objective Loss 0.640022                                        LR 0.000250    Time 0.041104    
2024-04-05 16:14:50,813 - Epoch: [169][  300/  500]    Overall Loss 0.634874    Objective Loss 0.634874                                        LR 0.000250    Time 0.042056    
2024-04-05 16:14:55,307 - Epoch: [169][  400/  500]    Overall Loss 0.634512    Objective Loss 0.634512                                        LR 0.000250    Time 0.042765    
2024-04-05 16:14:59,754 - Epoch: [169][  500/  500]    Overall Loss 0.636247    Objective Loss 0.636247    Top1 73.500000    Top5 96.500000    LR 0.000250    Time 0.043094    
2024-04-05 16:15:00,002 - --- validate (epoch=169)-----------
2024-04-05 16:15:00,002 - 10000 samples (100 per mini-batch)
2024-04-05 16:15:01,584 - Epoch: [169][  100/  100]    Loss 1.880037    Top1 55.200000    Top5 81.940000    
2024-04-05 16:15:01,743 - ==> Top1: 55.200    Top5: 81.940    Loss: 1.880

2024-04-05 16:15:01,749 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:15:01,749 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:15:01,778 - 

2024-04-05 16:15:01,779 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:15:06,573 - Epoch: [170][  100/  500]    Overall Loss 0.612242    Objective Loss 0.612242                                        LR 0.000250    Time 0.047891    
2024-04-05 16:15:10,313 - Epoch: [170][  200/  500]    Overall Loss 0.622685    Objective Loss 0.622685                                        LR 0.000250    Time 0.042621    
2024-04-05 16:15:13,479 - Epoch: [170][  300/  500]    Overall Loss 0.628528    Objective Loss 0.628528                                        LR 0.000250    Time 0.038956    
2024-04-05 16:15:16,169 - Epoch: [170][  400/  500]    Overall Loss 0.633747    Objective Loss 0.633747                                        LR 0.000250    Time 0.035932    
2024-04-05 16:15:20,060 - Epoch: [170][  500/  500]    Overall Loss 0.637106    Objective Loss 0.637106    Top1 81.000000    Top5 96.500000    LR 0.000250    Time 0.036520    
2024-04-05 16:15:20,226 - --- validate (epoch=170)-----------
2024-04-05 16:15:20,227 - 10000 samples (100 per mini-batch)
2024-04-05 16:15:21,996 - Epoch: [170][  100/  100]    Loss 1.885227    Top1 55.190000    Top5 82.200000    
2024-04-05 16:15:22,125 - ==> Top1: 55.190    Top5: 82.200    Loss: 1.885

2024-04-05 16:15:22,131 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:15:22,132 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:15:22,162 - 

2024-04-05 16:15:22,162 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:15:26,934 - Epoch: [171][  100/  500]    Overall Loss 0.624289    Objective Loss 0.624289                                        LR 0.000250    Time 0.047662    
2024-04-05 16:15:31,236 - Epoch: [171][  200/  500]    Overall Loss 0.632198    Objective Loss 0.632198                                        LR 0.000250    Time 0.045319    
2024-04-05 16:15:35,482 - Epoch: [171][  300/  500]    Overall Loss 0.638415    Objective Loss 0.638415                                        LR 0.000250    Time 0.044349    
2024-04-05 16:15:39,860 - Epoch: [171][  400/  500]    Overall Loss 0.636311    Objective Loss 0.636311                                        LR 0.000250    Time 0.044194    
2024-04-05 16:15:44,323 - Epoch: [171][  500/  500]    Overall Loss 0.634640    Objective Loss 0.634640    Top1 84.500000    Top5 98.000000    LR 0.000250    Time 0.044271    
2024-04-05 16:15:44,457 - --- validate (epoch=171)-----------
2024-04-05 16:15:44,458 - 10000 samples (100 per mini-batch)
2024-04-05 16:15:46,022 - Epoch: [171][  100/  100]    Loss 1.891047    Top1 55.030000    Top5 81.620000    
2024-04-05 16:15:46,223 - ==> Top1: 55.030    Top5: 81.620    Loss: 1.891

2024-04-05 16:15:46,230 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:15:46,230 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:15:46,260 - 

2024-04-05 16:15:46,260 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:15:51,402 - Epoch: [172][  100/  500]    Overall Loss 0.620346    Objective Loss 0.620346                                        LR 0.000250    Time 0.051362    
2024-04-05 16:15:55,861 - Epoch: [172][  200/  500]    Overall Loss 0.617966    Objective Loss 0.617966                                        LR 0.000250    Time 0.047949    
2024-04-05 16:15:59,961 - Epoch: [172][  300/  500]    Overall Loss 0.621152    Objective Loss 0.621152                                        LR 0.000250    Time 0.045620    
2024-04-05 16:16:04,390 - Epoch: [172][  400/  500]    Overall Loss 0.629685    Objective Loss 0.629685                                        LR 0.000250    Time 0.045272    
2024-04-05 16:16:08,825 - Epoch: [172][  500/  500]    Overall Loss 0.631245    Objective Loss 0.631245    Top1 77.500000    Top5 97.000000    LR 0.000250    Time 0.045077    
2024-04-05 16:16:08,954 - --- validate (epoch=172)-----------
2024-04-05 16:16:08,954 - 10000 samples (100 per mini-batch)
2024-04-05 16:16:10,450 - Epoch: [172][  100/  100]    Loss 1.891500    Top1 54.970000    Top5 81.930000    
2024-04-05 16:16:10,630 - ==> Top1: 54.970    Top5: 81.930    Loss: 1.892

2024-04-05 16:16:10,636 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:16:10,636 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:16:10,666 - 

2024-04-05 16:16:10,666 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:16:15,508 - Epoch: [173][  100/  500]    Overall Loss 0.598918    Objective Loss 0.598918                                        LR 0.000250    Time 0.048367    
2024-04-05 16:16:19,902 - Epoch: [173][  200/  500]    Overall Loss 0.607986    Objective Loss 0.607986                                        LR 0.000250    Time 0.046129    
2024-04-05 16:16:24,138 - Epoch: [173][  300/  500]    Overall Loss 0.618978    Objective Loss 0.618978                                        LR 0.000250    Time 0.044856    
2024-04-05 16:16:28,586 - Epoch: [173][  400/  500]    Overall Loss 0.625646    Objective Loss 0.625646                                        LR 0.000250    Time 0.044749    
2024-04-05 16:16:33,040 - Epoch: [173][  500/  500]    Overall Loss 0.625566    Objective Loss 0.625566    Top1 84.000000    Top5 99.500000    LR 0.000250    Time 0.044698    
2024-04-05 16:16:33,227 - --- validate (epoch=173)-----------
2024-04-05 16:16:33,227 - 10000 samples (100 per mini-batch)
2024-04-05 16:16:34,730 - Epoch: [173][  100/  100]    Loss 1.890960    Top1 54.970000    Top5 81.710000    
2024-04-05 16:16:34,836 - ==> Top1: 54.970    Top5: 81.710    Loss: 1.891

2024-04-05 16:16:34,843 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:16:34,843 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:16:34,873 - 

2024-04-05 16:16:34,874 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:16:39,977 - Epoch: [174][  100/  500]    Overall Loss 0.615907    Objective Loss 0.615907                                        LR 0.000250    Time 0.050981    
2024-04-05 16:16:44,370 - Epoch: [174][  200/  500]    Overall Loss 0.629569    Objective Loss 0.629569                                        LR 0.000250    Time 0.047427    
2024-04-05 16:16:48,512 - Epoch: [174][  300/  500]    Overall Loss 0.626736    Objective Loss 0.626736                                        LR 0.000250    Time 0.045410    
2024-04-05 16:16:52,967 - Epoch: [174][  400/  500]    Overall Loss 0.626632    Objective Loss 0.626632                                        LR 0.000250    Time 0.045182    
2024-04-05 16:16:57,417 - Epoch: [174][  500/  500]    Overall Loss 0.626910    Objective Loss 0.626910    Top1 78.000000    Top5 96.500000    LR 0.000250    Time 0.045036    
2024-04-05 16:16:57,626 - --- validate (epoch=174)-----------
2024-04-05 16:16:57,627 - 10000 samples (100 per mini-batch)
2024-04-05 16:16:59,085 - Epoch: [174][  100/  100]    Loss 1.900484    Top1 55.010000    Top5 81.820000    
2024-04-05 16:16:59,188 - ==> Top1: 55.010    Top5: 81.820    Loss: 1.900

2024-04-05 16:16:59,194 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:16:59,194 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:16:59,226 - 

2024-04-05 16:16:59,226 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:17:04,059 - Epoch: [175][  100/  500]    Overall Loss 0.618522    Objective Loss 0.618522                                        LR 0.000250    Time 0.048265    
2024-04-05 16:17:08,406 - Epoch: [175][  200/  500]    Overall Loss 0.621172    Objective Loss 0.621172                                        LR 0.000250    Time 0.045844    
2024-04-05 16:17:12,448 - Epoch: [175][  300/  500]    Overall Loss 0.624155    Objective Loss 0.624155                                        LR 0.000250    Time 0.044019    
2024-04-05 16:17:16,884 - Epoch: [175][  400/  500]    Overall Loss 0.623689    Objective Loss 0.623689                                        LR 0.000250    Time 0.044092    
2024-04-05 16:17:21,334 - Epoch: [175][  500/  500]    Overall Loss 0.624612    Objective Loss 0.624612    Top1 79.000000    Top5 97.500000    LR 0.000250    Time 0.044164    
2024-04-05 16:17:21,570 - --- validate (epoch=175)-----------
2024-04-05 16:17:21,571 - 10000 samples (100 per mini-batch)
2024-04-05 16:17:23,124 - Epoch: [175][  100/  100]    Loss 1.886782    Top1 54.820000    Top5 81.910000    
2024-04-05 16:17:23,270 - ==> Top1: 54.820    Top5: 81.910    Loss: 1.887

2024-04-05 16:17:23,277 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:17:23,277 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:17:23,308 - 

2024-04-05 16:17:23,308 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:17:28,037 - Epoch: [176][  100/  500]    Overall Loss 0.628303    Objective Loss 0.628303                                        LR 0.000250    Time 0.047241    
2024-04-05 16:17:32,446 - Epoch: [176][  200/  500]    Overall Loss 0.627631    Objective Loss 0.627631                                        LR 0.000250    Time 0.045640    
2024-04-05 16:17:36,626 - Epoch: [176][  300/  500]    Overall Loss 0.629685    Objective Loss 0.629685                                        LR 0.000250    Time 0.044344    
2024-04-05 16:17:41,024 - Epoch: [176][  400/  500]    Overall Loss 0.628999    Objective Loss 0.628999                                        LR 0.000250    Time 0.044242    
2024-04-05 16:17:45,457 - Epoch: [176][  500/  500]    Overall Loss 0.631024    Objective Loss 0.631024    Top1 78.500000    Top5 94.000000    LR 0.000250    Time 0.044249    
2024-04-05 16:17:45,687 - --- validate (epoch=176)-----------
2024-04-05 16:17:45,687 - 10000 samples (100 per mini-batch)
2024-04-05 16:17:47,371 - Epoch: [176][  100/  100]    Loss 1.898540    Top1 54.830000    Top5 81.820000    
2024-04-05 16:17:47,490 - ==> Top1: 54.830    Top5: 81.820    Loss: 1.899

2024-04-05 16:17:47,496 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:17:47,497 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:17:47,528 - 

2024-04-05 16:17:47,528 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:17:52,340 - Epoch: [177][  100/  500]    Overall Loss 0.614143    Objective Loss 0.614143                                        LR 0.000250    Time 0.048065    
2024-04-05 16:17:56,795 - Epoch: [177][  200/  500]    Overall Loss 0.612618    Objective Loss 0.612618                                        LR 0.000250    Time 0.046283    
2024-04-05 16:18:01,006 - Epoch: [177][  300/  500]    Overall Loss 0.617459    Objective Loss 0.617459                                        LR 0.000250    Time 0.044876    
2024-04-05 16:18:05,184 - Epoch: [177][  400/  500]    Overall Loss 0.620284    Objective Loss 0.620284                                        LR 0.000250    Time 0.044090    
2024-04-05 16:18:09,633 - Epoch: [177][  500/  500]    Overall Loss 0.622729    Objective Loss 0.622729    Top1 79.500000    Top5 98.000000    LR 0.000250    Time 0.044160    
2024-04-05 16:18:09,816 - --- validate (epoch=177)-----------
2024-04-05 16:18:09,817 - 10000 samples (100 per mini-batch)
2024-04-05 16:18:11,306 - Epoch: [177][  100/  100]    Loss 1.900587    Top1 55.110000    Top5 81.780000    
2024-04-05 16:18:11,510 - ==> Top1: 55.110    Top5: 81.780    Loss: 1.901

2024-04-05 16:18:11,516 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:18:11,517 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:18:11,545 - 

2024-04-05 16:18:11,545 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:18:16,630 - Epoch: [178][  100/  500]    Overall Loss 0.596370    Objective Loss 0.596370                                        LR 0.000250    Time 0.050798    
2024-04-05 16:18:21,083 - Epoch: [178][  200/  500]    Overall Loss 0.607061    Objective Loss 0.607061                                        LR 0.000250    Time 0.047639    
2024-04-05 16:18:25,401 - Epoch: [178][  300/  500]    Overall Loss 0.612805    Objective Loss 0.612805                                        LR 0.000250    Time 0.046136    
2024-04-05 16:18:29,491 - Epoch: [178][  400/  500]    Overall Loss 0.618338    Objective Loss 0.618338                                        LR 0.000250    Time 0.044815    
2024-04-05 16:18:33,918 - Epoch: [178][  500/  500]    Overall Loss 0.622492    Objective Loss 0.622492    Top1 79.500000    Top5 97.000000    LR 0.000250    Time 0.044696    
2024-04-05 16:18:34,099 - --- validate (epoch=178)-----------
2024-04-05 16:18:34,100 - 10000 samples (100 per mini-batch)
2024-04-05 16:18:35,589 - Epoch: [178][  100/  100]    Loss 1.903051    Top1 54.780000    Top5 81.860000    
2024-04-05 16:18:35,778 - ==> Top1: 54.780    Top5: 81.860    Loss: 1.903

2024-04-05 16:18:35,784 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:18:35,784 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:18:35,814 - 

2024-04-05 16:18:35,814 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:18:40,673 - Epoch: [179][  100/  500]    Overall Loss 0.624044    Objective Loss 0.624044                                        LR 0.000250    Time 0.048534    
2024-04-05 16:18:45,112 - Epoch: [179][  200/  500]    Overall Loss 0.623148    Objective Loss 0.623148                                        LR 0.000250    Time 0.046435    
2024-04-05 16:18:49,531 - Epoch: [179][  300/  500]    Overall Loss 0.622419    Objective Loss 0.622419                                        LR 0.000250    Time 0.045671    
2024-04-05 16:18:53,596 - Epoch: [179][  400/  500]    Overall Loss 0.619761    Objective Loss 0.619761                                        LR 0.000250    Time 0.044402    
2024-04-05 16:18:57,985 - Epoch: [179][  500/  500]    Overall Loss 0.621640    Objective Loss 0.621640    Top1 83.000000    Top5 99.500000    LR 0.000250    Time 0.044291    
2024-04-05 16:18:58,261 - --- validate (epoch=179)-----------
2024-04-05 16:18:58,262 - 10000 samples (100 per mini-batch)
2024-04-05 16:18:59,646 - Epoch: [179][  100/  100]    Loss 1.904880    Top1 54.780000    Top5 81.950000    
2024-04-05 16:18:59,748 - ==> Top1: 54.780    Top5: 81.950    Loss: 1.905

2024-04-05 16:18:59,755 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:18:59,755 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:18:59,785 - 

2024-04-05 16:18:59,785 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:19:04,655 - Epoch: [180][  100/  500]    Overall Loss 0.621441    Objective Loss 0.621441                                        LR 0.000250    Time 0.048646    
2024-04-05 16:19:09,085 - Epoch: [180][  200/  500]    Overall Loss 0.622526    Objective Loss 0.622526                                        LR 0.000250    Time 0.046449    
2024-04-05 16:19:12,652 - Epoch: [180][  300/  500]    Overall Loss 0.620871    Objective Loss 0.620871                                        LR 0.000250    Time 0.042842    
2024-04-05 16:19:17,104 - Epoch: [180][  400/  500]    Overall Loss 0.621254    Objective Loss 0.621254                                        LR 0.000250    Time 0.043249    
2024-04-05 16:19:21,558 - Epoch: [180][  500/  500]    Overall Loss 0.624547    Objective Loss 0.624547    Top1 83.500000    Top5 98.500000    LR 0.000250    Time 0.043498    
2024-04-05 16:19:21,709 - --- validate (epoch=180)-----------
2024-04-05 16:19:21,710 - 10000 samples (100 per mini-batch)
2024-04-05 16:19:23,471 - Epoch: [180][  100/  100]    Loss 1.907458    Top1 54.810000    Top5 81.790000    
2024-04-05 16:19:23,636 - ==> Top1: 54.810    Top5: 81.790    Loss: 1.907

2024-04-05 16:19:23,642 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:19:23,643 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:19:23,672 - 

2024-04-05 16:19:23,673 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:19:28,573 - Epoch: [181][  100/  500]    Overall Loss 0.613343    Objective Loss 0.613343                                        LR 0.000250    Time 0.048951    
2024-04-05 16:19:32,970 - Epoch: [181][  200/  500]    Overall Loss 0.609288    Objective Loss 0.609288                                        LR 0.000250    Time 0.046436    
2024-04-05 16:19:37,120 - Epoch: [181][  300/  500]    Overall Loss 0.615266    Objective Loss 0.615266                                        LR 0.000250    Time 0.044774    
2024-04-05 16:19:41,625 - Epoch: [181][  400/  500]    Overall Loss 0.620006    Objective Loss 0.620006                                        LR 0.000250    Time 0.044831    
2024-04-05 16:19:46,111 - Epoch: [181][  500/  500]    Overall Loss 0.619584    Objective Loss 0.619584    Top1 86.500000    Top5 98.000000    LR 0.000250    Time 0.044827    
2024-04-05 16:19:46,278 - --- validate (epoch=181)-----------
2024-04-05 16:19:46,279 - 10000 samples (100 per mini-batch)
2024-04-05 16:19:47,736 - Epoch: [181][  100/  100]    Loss 1.905564    Top1 55.240000    Top5 81.800000    
2024-04-05 16:19:47,837 - ==> Top1: 55.240    Top5: 81.800    Loss: 1.906

2024-04-05 16:19:47,844 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:19:47,844 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:19:47,873 - 

2024-04-05 16:19:47,874 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:19:52,980 - Epoch: [182][  100/  500]    Overall Loss 0.612813    Objective Loss 0.612813                                        LR 0.000250    Time 0.051011    
2024-04-05 16:19:57,370 - Epoch: [182][  200/  500]    Overall Loss 0.609537    Objective Loss 0.609537                                        LR 0.000250    Time 0.047423    
2024-04-05 16:20:01,455 - Epoch: [182][  300/  500]    Overall Loss 0.612041    Objective Loss 0.612041                                        LR 0.000250    Time 0.045217    
2024-04-05 16:20:05,858 - Epoch: [182][  400/  500]    Overall Loss 0.613618    Objective Loss 0.613618                                        LR 0.000250    Time 0.044909    
2024-04-05 16:20:10,273 - Epoch: [182][  500/  500]    Overall Loss 0.616283    Objective Loss 0.616283    Top1 86.500000    Top5 98.000000    LR 0.000250    Time 0.044746    
2024-04-05 16:20:10,462 - --- validate (epoch=182)-----------
2024-04-05 16:20:10,462 - 10000 samples (100 per mini-batch)
2024-04-05 16:20:11,954 - Epoch: [182][  100/  100]    Loss 1.888323    Top1 55.030000    Top5 82.300000    
2024-04-05 16:20:12,059 - ==> Top1: 55.030    Top5: 82.300    Loss: 1.888

2024-04-05 16:20:12,065 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:20:12,066 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:20:12,095 - 

2024-04-05 16:20:12,095 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:20:16,956 - Epoch: [183][  100/  500]    Overall Loss 0.603197    Objective Loss 0.603197                                        LR 0.000250    Time 0.048560    
2024-04-05 16:20:21,316 - Epoch: [183][  200/  500]    Overall Loss 0.612875    Objective Loss 0.612875                                        LR 0.000250    Time 0.046048    
2024-04-05 16:20:25,593 - Epoch: [183][  300/  500]    Overall Loss 0.620547    Objective Loss 0.620547                                        LR 0.000250    Time 0.044940    
2024-04-05 16:20:29,893 - Epoch: [183][  400/  500]    Overall Loss 0.617200    Objective Loss 0.617200                                        LR 0.000250    Time 0.044443    
2024-04-05 16:20:34,268 - Epoch: [183][  500/  500]    Overall Loss 0.616994    Objective Loss 0.616994    Top1 78.500000    Top5 95.500000    LR 0.000250    Time 0.044295    
2024-04-05 16:20:34,401 - --- validate (epoch=183)-----------
2024-04-05 16:20:34,402 - 10000 samples (100 per mini-batch)
2024-04-05 16:20:35,970 - Epoch: [183][  100/  100]    Loss 1.891233    Top1 55.370000    Top5 82.230000    
2024-04-05 16:20:36,121 - ==> Top1: 55.370    Top5: 82.230    Loss: 1.891

2024-04-05 16:20:36,127 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:20:36,128 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:20:36,158 - 

2024-04-05 16:20:36,159 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:20:40,914 - Epoch: [184][  100/  500]    Overall Loss 0.614345    Objective Loss 0.614345                                        LR 0.000250    Time 0.047503    
2024-04-05 16:20:45,380 - Epoch: [184][  200/  500]    Overall Loss 0.614820    Objective Loss 0.614820                                        LR 0.000250    Time 0.046053    
2024-04-05 16:20:49,663 - Epoch: [184][  300/  500]    Overall Loss 0.615358    Objective Loss 0.615358                                        LR 0.000250    Time 0.044964    
2024-04-05 16:20:53,918 - Epoch: [184][  400/  500]    Overall Loss 0.621019    Objective Loss 0.621019                                        LR 0.000250    Time 0.044347    
2024-04-05 16:20:58,411 - Epoch: [184][  500/  500]    Overall Loss 0.623283    Objective Loss 0.623283    Top1 76.000000    Top5 97.000000    LR 0.000250    Time 0.044453    
2024-04-05 16:20:58,577 - --- validate (epoch=184)-----------
2024-04-05 16:20:58,578 - 10000 samples (100 per mini-batch)
2024-04-05 16:21:00,364 - Epoch: [184][  100/  100]    Loss 1.905120    Top1 54.940000    Top5 82.040000    
2024-04-05 16:21:00,517 - ==> Top1: 54.940    Top5: 82.040    Loss: 1.905

2024-04-05 16:21:00,523 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:21:00,524 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:21:00,555 - 

2024-04-05 16:21:00,555 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:21:05,467 - Epoch: [185][  100/  500]    Overall Loss 0.613983    Objective Loss 0.613983                                        LR 0.000250    Time 0.049060    
2024-04-05 16:21:09,922 - Epoch: [185][  200/  500]    Overall Loss 0.614075    Objective Loss 0.614075                                        LR 0.000250    Time 0.046780    
2024-04-05 16:21:14,325 - Epoch: [185][  300/  500]    Overall Loss 0.615579    Objective Loss 0.615579                                        LR 0.000250    Time 0.045847    
2024-04-05 16:21:18,479 - Epoch: [185][  400/  500]    Overall Loss 0.616018    Objective Loss 0.616018                                        LR 0.000250    Time 0.044758    
2024-04-05 16:21:22,908 - Epoch: [185][  500/  500]    Overall Loss 0.616882    Objective Loss 0.616882    Top1 83.000000    Top5 96.000000    LR 0.000250    Time 0.044655    
2024-04-05 16:21:23,061 - --- validate (epoch=185)-----------
2024-04-05 16:21:23,061 - 10000 samples (100 per mini-batch)
2024-04-05 16:21:24,560 - Epoch: [185][  100/  100]    Loss 1.900520    Top1 54.900000    Top5 82.000000    
2024-04-05 16:21:24,661 - ==> Top1: 54.900    Top5: 82.000    Loss: 1.901

2024-04-05 16:21:24,669 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:21:24,670 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:21:24,699 - 

2024-04-05 16:21:24,700 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:21:29,618 - Epoch: [186][  100/  500]    Overall Loss 0.606479    Objective Loss 0.606479                                        LR 0.000250    Time 0.049131    
2024-04-05 16:21:33,170 - Epoch: [186][  200/  500]    Overall Loss 0.617314    Objective Loss 0.617314                                        LR 0.000250    Time 0.042308    
2024-04-05 16:21:37,315 - Epoch: [186][  300/  500]    Overall Loss 0.616660    Objective Loss 0.616660                                        LR 0.000250    Time 0.042006    
2024-04-05 16:21:41,755 - Epoch: [186][  400/  500]    Overall Loss 0.618636    Objective Loss 0.618636                                        LR 0.000250    Time 0.042592    
2024-04-05 16:21:46,245 - Epoch: [186][  500/  500]    Overall Loss 0.619137    Objective Loss 0.619137    Top1 79.000000    Top5 96.000000    LR 0.000250    Time 0.043045    
2024-04-05 16:21:46,438 - --- validate (epoch=186)-----------
2024-04-05 16:21:46,439 - 10000 samples (100 per mini-batch)
2024-04-05 16:21:48,002 - Epoch: [186][  100/  100]    Loss 1.898888    Top1 55.180000    Top5 82.160000    
2024-04-05 16:21:48,113 - ==> Top1: 55.180    Top5: 82.160    Loss: 1.899

2024-04-05 16:21:48,119 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:21:48,120 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:21:48,149 - 

2024-04-05 16:21:48,150 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:21:52,289 - Epoch: [187][  100/  500]    Overall Loss 0.593323    Objective Loss 0.593323                                        LR 0.000250    Time 0.041351    
2024-04-05 16:21:56,553 - Epoch: [187][  200/  500]    Overall Loss 0.598536    Objective Loss 0.598536                                        LR 0.000250    Time 0.041972    
2024-04-05 16:22:00,935 - Epoch: [187][  300/  500]    Overall Loss 0.598870    Objective Loss 0.598870                                        LR 0.000250    Time 0.042572    
2024-04-05 16:22:05,361 - Epoch: [187][  400/  500]    Overall Loss 0.604290    Objective Loss 0.604290                                        LR 0.000250    Time 0.042982    
2024-04-05 16:22:09,715 - Epoch: [187][  500/  500]    Overall Loss 0.613468    Objective Loss 0.613468    Top1 81.500000    Top5 99.000000    LR 0.000250    Time 0.043082    
2024-04-05 16:22:09,883 - --- validate (epoch=187)-----------
2024-04-05 16:22:09,883 - 10000 samples (100 per mini-batch)
2024-04-05 16:22:11,320 - Epoch: [187][  100/  100]    Loss 1.906822    Top1 55.070000    Top5 82.010000    
2024-04-05 16:22:11,470 - ==> Top1: 55.070    Top5: 82.010    Loss: 1.907

2024-04-05 16:22:11,476 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:22:11,476 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:22:11,506 - 

2024-04-05 16:22:11,506 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:22:16,027 - Epoch: [188][  100/  500]    Overall Loss 0.593180    Objective Loss 0.593180                                        LR 0.000250    Time 0.045160    
2024-04-05 16:22:20,467 - Epoch: [188][  200/  500]    Overall Loss 0.603248    Objective Loss 0.603248                                        LR 0.000250    Time 0.044746    
2024-04-05 16:22:24,876 - Epoch: [188][  300/  500]    Overall Loss 0.604446    Objective Loss 0.604446                                        LR 0.000250    Time 0.044511    
2024-04-05 16:22:29,311 - Epoch: [188][  400/  500]    Overall Loss 0.605632    Objective Loss 0.605632                                        LR 0.000250    Time 0.044459    
2024-04-05 16:22:33,753 - Epoch: [188][  500/  500]    Overall Loss 0.607111    Objective Loss 0.607111    Top1 82.500000    Top5 98.000000    LR 0.000250    Time 0.044442    
2024-04-05 16:22:33,949 - --- validate (epoch=188)-----------
2024-04-05 16:22:33,950 - 10000 samples (100 per mini-batch)
2024-04-05 16:22:35,613 - Epoch: [188][  100/  100]    Loss 1.908659    Top1 54.550000    Top5 82.150000    
2024-04-05 16:22:35,731 - ==> Top1: 54.550    Top5: 82.150    Loss: 1.909

2024-04-05 16:22:35,737 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:22:35,738 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:22:35,767 - 

2024-04-05 16:22:35,768 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:22:40,491 - Epoch: [189][  100/  500]    Overall Loss 0.613048    Objective Loss 0.613048                                        LR 0.000250    Time 0.047184    
2024-04-05 16:22:44,876 - Epoch: [189][  200/  500]    Overall Loss 0.605898    Objective Loss 0.605898                                        LR 0.000250    Time 0.045493    
2024-04-05 16:22:49,292 - Epoch: [189][  300/  500]    Overall Loss 0.607838    Objective Loss 0.607838                                        LR 0.000250    Time 0.045030    
2024-04-05 16:22:53,715 - Epoch: [189][  400/  500]    Overall Loss 0.608921    Objective Loss 0.608921                                        LR 0.000250    Time 0.044816    
2024-04-05 16:22:58,129 - Epoch: [189][  500/  500]    Overall Loss 0.609910    Objective Loss 0.609910    Top1 81.500000    Top5 96.500000    LR 0.000250    Time 0.044671    
2024-04-05 16:22:58,314 - --- validate (epoch=189)-----------
2024-04-05 16:22:58,315 - 10000 samples (100 per mini-batch)
2024-04-05 16:22:59,836 - Epoch: [189][  100/  100]    Loss 1.912366    Top1 54.810000    Top5 82.140000    
2024-04-05 16:23:00,002 - ==> Top1: 54.810    Top5: 82.140    Loss: 1.912

2024-04-05 16:23:00,008 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:23:00,009 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:23:00,040 - 

2024-04-05 16:23:00,040 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:23:04,806 - Epoch: [190][  100/  500]    Overall Loss 0.597788    Objective Loss 0.597788                                        LR 0.000250    Time 0.047601    
2024-04-05 16:23:08,998 - Epoch: [190][  200/  500]    Overall Loss 0.602274    Objective Loss 0.602274                                        LR 0.000250    Time 0.044740    
2024-04-05 16:23:13,389 - Epoch: [190][  300/  500]    Overall Loss 0.599310    Objective Loss 0.599310                                        LR 0.000250    Time 0.044447    
2024-04-05 16:23:17,765 - Epoch: [190][  400/  500]    Overall Loss 0.604379    Objective Loss 0.604379                                        LR 0.000250    Time 0.044264    
2024-04-05 16:23:22,191 - Epoch: [190][  500/  500]    Overall Loss 0.610685    Objective Loss 0.610685    Top1 83.000000    Top5 98.500000    LR 0.000250    Time 0.044252    
2024-04-05 16:23:22,384 - --- validate (epoch=190)-----------
2024-04-05 16:23:22,385 - 10000 samples (100 per mini-batch)
2024-04-05 16:23:23,829 - Epoch: [190][  100/  100]    Loss 1.902092    Top1 55.310000    Top5 81.900000    
2024-04-05 16:23:23,941 - ==> Top1: 55.310    Top5: 81.900    Loss: 1.902

2024-04-05 16:23:23,948 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:23:23,948 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:23:23,978 - 

2024-04-05 16:23:23,978 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:23:28,824 - Epoch: [191][  100/  500]    Overall Loss 0.599680    Objective Loss 0.599680                                        LR 0.000250    Time 0.048404    
2024-04-05 16:23:33,125 - Epoch: [191][  200/  500]    Overall Loss 0.599685    Objective Loss 0.599685                                        LR 0.000250    Time 0.045681    
2024-04-05 16:23:37,500 - Epoch: [191][  300/  500]    Overall Loss 0.603340    Objective Loss 0.603340                                        LR 0.000250    Time 0.045022    
2024-04-05 16:23:41,910 - Epoch: [191][  400/  500]    Overall Loss 0.607037    Objective Loss 0.607037                                        LR 0.000250    Time 0.044780    
2024-04-05 16:23:46,312 - Epoch: [191][  500/  500]    Overall Loss 0.608168    Objective Loss 0.608168    Top1 82.000000    Top5 98.500000    LR 0.000250    Time 0.044618    
2024-04-05 16:23:46,494 - --- validate (epoch=191)-----------
2024-04-05 16:23:46,495 - 10000 samples (100 per mini-batch)
2024-04-05 16:23:47,953 - Epoch: [191][  100/  100]    Loss 1.906212    Top1 55.070000    Top5 82.130000    
2024-04-05 16:23:48,129 - ==> Top1: 55.070    Top5: 82.130    Loss: 1.906

2024-04-05 16:23:48,133 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:23:48,133 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:23:48,155 - 

2024-04-05 16:23:48,155 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:23:52,987 - Epoch: [192][  100/  500]    Overall Loss 0.587351    Objective Loss 0.587351                                        LR 0.000250    Time 0.048267    
2024-04-05 16:23:57,338 - Epoch: [192][  200/  500]    Overall Loss 0.595700    Objective Loss 0.595700                                        LR 0.000250    Time 0.045861    
2024-04-05 16:24:01,729 - Epoch: [192][  300/  500]    Overall Loss 0.597576    Objective Loss 0.597576                                        LR 0.000250    Time 0.045197    
2024-04-05 16:24:06,271 - Epoch: [192][  400/  500]    Overall Loss 0.603364    Objective Loss 0.603364                                        LR 0.000250    Time 0.045238    
2024-04-05 16:24:10,777 - Epoch: [192][  500/  500]    Overall Loss 0.605425    Objective Loss 0.605425    Top1 85.500000    Top5 98.500000    LR 0.000250    Time 0.045193    
2024-04-05 16:24:10,943 - --- validate (epoch=192)-----------
2024-04-05 16:24:10,944 - 10000 samples (100 per mini-batch)
2024-04-05 16:24:12,663 - Epoch: [192][  100/  100]    Loss 1.906777    Top1 55.140000    Top5 82.050000    
2024-04-05 16:24:12,795 - ==> Top1: 55.140    Top5: 82.050    Loss: 1.907

2024-04-05 16:24:12,800 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:24:12,800 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:24:12,821 - 

2024-04-05 16:24:12,821 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:24:17,221 - Epoch: [193][  100/  500]    Overall Loss 0.585171    Objective Loss 0.585171                                        LR 0.000250    Time 0.043942    
2024-04-05 16:24:21,419 - Epoch: [193][  200/  500]    Overall Loss 0.589817    Objective Loss 0.589817                                        LR 0.000250    Time 0.042938    
2024-04-05 16:24:25,788 - Epoch: [193][  300/  500]    Overall Loss 0.596929    Objective Loss 0.596929                                        LR 0.000250    Time 0.043172    
2024-04-05 16:24:30,210 - Epoch: [193][  400/  500]    Overall Loss 0.598551    Objective Loss 0.598551                                        LR 0.000250    Time 0.043421    
2024-04-05 16:24:34,567 - Epoch: [193][  500/  500]    Overall Loss 0.604147    Objective Loss 0.604147    Top1 83.500000    Top5 99.000000    LR 0.000250    Time 0.043442    
2024-04-05 16:24:34,805 - --- validate (epoch=193)-----------
2024-04-05 16:24:34,806 - 10000 samples (100 per mini-batch)
2024-04-05 16:24:36,346 - Epoch: [193][  100/  100]    Loss 1.912404    Top1 54.810000    Top5 81.980000    
2024-04-05 16:24:36,445 - ==> Top1: 54.810    Top5: 81.980    Loss: 1.912

2024-04-05 16:24:36,451 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:24:36,452 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:24:36,483 - 

2024-04-05 16:24:36,484 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:24:41,414 - Epoch: [194][  100/  500]    Overall Loss 0.596442    Objective Loss 0.596442                                        LR 0.000250    Time 0.049252    
2024-04-05 16:24:45,815 - Epoch: [194][  200/  500]    Overall Loss 0.602091    Objective Loss 0.602091                                        LR 0.000250    Time 0.046604    
2024-04-05 16:24:49,841 - Epoch: [194][  300/  500]    Overall Loss 0.602581    Objective Loss 0.602581                                        LR 0.000250    Time 0.044476    
2024-04-05 16:24:53,141 - Epoch: [194][  400/  500]    Overall Loss 0.606646    Objective Loss 0.606646                                        LR 0.000250    Time 0.041596    
2024-04-05 16:24:55,880 - Epoch: [194][  500/  500]    Overall Loss 0.609291    Objective Loss 0.609291    Top1 80.500000    Top5 97.000000    LR 0.000250    Time 0.038749    
2024-04-05 16:24:56,056 - --- validate (epoch=194)-----------
2024-04-05 16:24:56,056 - 10000 samples (100 per mini-batch)
2024-04-05 16:24:57,763 - Epoch: [194][  100/  100]    Loss 1.908314    Top1 55.100000    Top5 81.970000    
2024-04-05 16:24:57,935 - ==> Top1: 55.100    Top5: 81.970    Loss: 1.908

2024-04-05 16:24:57,941 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:24:57,941 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:24:57,972 - 

2024-04-05 16:24:57,972 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:25:03,013 - Epoch: [195][  100/  500]    Overall Loss 0.593377    Objective Loss 0.593377                                        LR 0.000250    Time 0.050347    
2024-04-05 16:25:07,523 - Epoch: [195][  200/  500]    Overall Loss 0.598015    Objective Loss 0.598015                                        LR 0.000250    Time 0.047699    
2024-04-05 16:25:11,609 - Epoch: [195][  300/  500]    Overall Loss 0.602138    Objective Loss 0.602138                                        LR 0.000250    Time 0.045403    
2024-04-05 16:25:16,000 - Epoch: [195][  400/  500]    Overall Loss 0.605876    Objective Loss 0.605876                                        LR 0.000250    Time 0.045018    
2024-04-05 16:25:20,421 - Epoch: [195][  500/  500]    Overall Loss 0.607641    Objective Loss 0.607641    Top1 79.500000    Top5 96.500000    LR 0.000250    Time 0.044846    
2024-04-05 16:25:20,578 - --- validate (epoch=195)-----------
2024-04-05 16:25:20,580 - 10000 samples (100 per mini-batch)
2024-04-05 16:25:21,977 - Epoch: [195][  100/  100]    Loss 1.911540    Top1 54.870000    Top5 81.870000    
2024-04-05 16:25:22,126 - ==> Top1: 54.870    Top5: 81.870    Loss: 1.912

2024-04-05 16:25:22,133 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:25:22,134 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:25:22,163 - 

2024-04-05 16:25:22,164 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:25:27,232 - Epoch: [196][  100/  500]    Overall Loss 0.607249    Objective Loss 0.607249                                        LR 0.000250    Time 0.050625    
2024-04-05 16:25:31,675 - Epoch: [196][  200/  500]    Overall Loss 0.602416    Objective Loss 0.602416                                        LR 0.000250    Time 0.047505    
2024-04-05 16:25:35,829 - Epoch: [196][  300/  500]    Overall Loss 0.602117    Objective Loss 0.602117                                        LR 0.000250    Time 0.045502    
2024-04-05 16:25:40,266 - Epoch: [196][  400/  500]    Overall Loss 0.605882    Objective Loss 0.605882                                        LR 0.000250    Time 0.045207    
2024-04-05 16:25:44,741 - Epoch: [196][  500/  500]    Overall Loss 0.607273    Objective Loss 0.607273    Top1 84.000000    Top5 100.000000    LR 0.000250    Time 0.045104    
2024-04-05 16:25:44,933 - --- validate (epoch=196)-----------
2024-04-05 16:25:44,934 - 10000 samples (100 per mini-batch)
2024-04-05 16:25:46,431 - Epoch: [196][  100/  100]    Loss 1.915684    Top1 54.990000    Top5 81.860000    
2024-04-05 16:25:46,543 - ==> Top1: 54.990    Top5: 81.860    Loss: 1.916

2024-04-05 16:25:46,549 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:25:46,550 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:25:46,581 - 

2024-04-05 16:25:46,581 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:25:51,498 - Epoch: [197][  100/  500]    Overall Loss 0.593673    Objective Loss 0.593673                                        LR 0.000250    Time 0.049106    
2024-04-05 16:25:55,905 - Epoch: [197][  200/  500]    Overall Loss 0.592898    Objective Loss 0.592898                                        LR 0.000250    Time 0.046567    
2024-04-05 16:26:00,112 - Epoch: [197][  300/  500]    Overall Loss 0.596038    Objective Loss 0.596038                                        LR 0.000250    Time 0.045052    
2024-04-05 16:26:04,605 - Epoch: [197][  400/  500]    Overall Loss 0.602563    Objective Loss 0.602563                                        LR 0.000250    Time 0.045008    
2024-04-05 16:26:09,006 - Epoch: [197][  500/  500]    Overall Loss 0.603426    Objective Loss 0.603426    Top1 79.500000    Top5 99.000000    LR 0.000250    Time 0.044799    
2024-04-05 16:26:09,154 - --- validate (epoch=197)-----------
2024-04-05 16:26:09,154 - 10000 samples (100 per mini-batch)
2024-04-05 16:26:10,721 - Epoch: [197][  100/  100]    Loss 1.922645    Top1 54.820000    Top5 82.080000    
2024-04-05 16:26:10,835 - ==> Top1: 54.820    Top5: 82.080    Loss: 1.923

2024-04-05 16:26:10,842 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:26:10,843 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:26:10,874 - 

2024-04-05 16:26:10,874 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:26:15,989 - Epoch: [198][  100/  500]    Overall Loss 0.583174    Objective Loss 0.583174                                        LR 0.000250    Time 0.051092    
2024-04-05 16:26:20,496 - Epoch: [198][  200/  500]    Overall Loss 0.585011    Objective Loss 0.585011                                        LR 0.000250    Time 0.048060    
2024-04-05 16:26:24,588 - Epoch: [198][  300/  500]    Overall Loss 0.592822    Objective Loss 0.592822                                        LR 0.000250    Time 0.045664    
2024-04-05 16:26:29,085 - Epoch: [198][  400/  500]    Overall Loss 0.600610    Objective Loss 0.600610                                        LR 0.000250    Time 0.045478    
2024-04-05 16:26:33,525 - Epoch: [198][  500/  500]    Overall Loss 0.606028    Objective Loss 0.606028    Top1 76.500000    Top5 96.000000    LR 0.000250    Time 0.045251    
2024-04-05 16:26:33,759 - --- validate (epoch=198)-----------
2024-04-05 16:26:33,760 - 10000 samples (100 per mini-batch)
2024-04-05 16:26:35,274 - Epoch: [198][  100/  100]    Loss 1.915669    Top1 54.830000    Top5 82.030000    
2024-04-05 16:26:35,407 - ==> Top1: 54.830    Top5: 82.030    Loss: 1.916

2024-04-05 16:26:35,414 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:26:35,415 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:26:35,445 - 

2024-04-05 16:26:35,446 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:26:40,374 - Epoch: [199][  100/  500]    Overall Loss 0.583755    Objective Loss 0.583755                                        LR 0.000250    Time 0.049220    
2024-04-05 16:26:44,804 - Epoch: [199][  200/  500]    Overall Loss 0.592482    Objective Loss 0.592482                                        LR 0.000250    Time 0.046736    
2024-04-05 16:26:48,951 - Epoch: [199][  300/  500]    Overall Loss 0.602597    Objective Loss 0.602597                                        LR 0.000250    Time 0.044965    
2024-04-05 16:26:53,320 - Epoch: [199][  400/  500]    Overall Loss 0.602468    Objective Loss 0.602468                                        LR 0.000250    Time 0.044635    
2024-04-05 16:26:57,729 - Epoch: [199][  500/  500]    Overall Loss 0.603827    Objective Loss 0.603827    Top1 83.500000    Top5 97.000000    LR 0.000250    Time 0.044516    
2024-04-05 16:26:57,999 - --- validate (epoch=199)-----------
2024-04-05 16:26:58,000 - 10000 samples (100 per mini-batch)
2024-04-05 16:26:59,548 - Epoch: [199][  100/  100]    Loss 1.928522    Top1 54.770000    Top5 81.870000    
2024-04-05 16:26:59,746 - ==> Top1: 54.770    Top5: 81.870    Loss: 1.929

2024-04-05 16:26:59,752 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:26:59,753 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:26:59,785 - 

2024-04-05 16:26:59,785 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:27:04,160 - Epoch: [200][  100/  500]    Overall Loss 0.582821    Objective Loss 0.582821                                        LR 0.000125    Time 0.043700    
2024-04-05 16:27:08,359 - Epoch: [200][  200/  500]    Overall Loss 0.580228    Objective Loss 0.580228                                        LR 0.000125    Time 0.042819    
2024-04-05 16:27:12,357 - Epoch: [200][  300/  500]    Overall Loss 0.578392    Objective Loss 0.578392                                        LR 0.000125    Time 0.041860    
2024-04-05 16:27:16,767 - Epoch: [200][  400/  500]    Overall Loss 0.578054    Objective Loss 0.578054                                        LR 0.000125    Time 0.042405    
2024-04-05 16:27:21,159 - Epoch: [200][  500/  500]    Overall Loss 0.579780    Objective Loss 0.579780    Top1 85.500000    Top5 96.500000    LR 0.000125    Time 0.042698    
2024-04-05 16:27:21,330 - --- validate (epoch=200)-----------
2024-04-05 16:27:21,332 - 10000 samples (100 per mini-batch)
2024-04-05 16:27:23,036 - Epoch: [200][  100/  100]    Loss 1.911288    Top1 55.350000    Top5 82.150000    
2024-04-05 16:27:23,207 - ==> Top1: 55.350    Top5: 82.150    Loss: 1.911

2024-04-05 16:27:23,213 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:27:23,213 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:27:23,243 - 

2024-04-05 16:27:23,243 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:27:28,134 - Epoch: [201][  100/  500]    Overall Loss 0.558676    Objective Loss 0.558676                                        LR 0.000125    Time 0.048848    
2024-04-05 16:27:32,646 - Epoch: [201][  200/  500]    Overall Loss 0.575273    Objective Loss 0.575273                                        LR 0.000125    Time 0.046958    
2024-04-05 16:27:36,791 - Epoch: [201][  300/  500]    Overall Loss 0.572238    Objective Loss 0.572238                                        LR 0.000125    Time 0.045106    
2024-04-05 16:27:41,301 - Epoch: [201][  400/  500]    Overall Loss 0.573321    Objective Loss 0.573321                                        LR 0.000125    Time 0.045090    
2024-04-05 16:27:45,786 - Epoch: [201][  500/  500]    Overall Loss 0.572724    Objective Loss 0.572724    Top1 78.500000    Top5 97.500000    LR 0.000125    Time 0.045033    
2024-04-05 16:27:45,946 - --- validate (epoch=201)-----------
2024-04-05 16:27:45,947 - 10000 samples (100 per mini-batch)
2024-04-05 16:27:47,500 - Epoch: [201][  100/  100]    Loss 1.915004    Top1 55.210000    Top5 82.180000    
2024-04-05 16:27:47,609 - ==> Top1: 55.210    Top5: 82.180    Loss: 1.915

2024-04-05 16:27:47,615 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:27:47,616 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:27:47,647 - 

2024-04-05 16:27:47,648 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:27:52,509 - Epoch: [202][  100/  500]    Overall Loss 0.575878    Objective Loss 0.575878                                        LR 0.000125    Time 0.048561    
2024-04-05 16:27:56,970 - Epoch: [202][  200/  500]    Overall Loss 0.570355    Objective Loss 0.570355                                        LR 0.000125    Time 0.046558    
2024-04-05 16:28:01,217 - Epoch: [202][  300/  500]    Overall Loss 0.570421    Objective Loss 0.570421                                        LR 0.000125    Time 0.045179    
2024-04-05 16:28:05,845 - Epoch: [202][  400/  500]    Overall Loss 0.572289    Objective Loss 0.572289                                        LR 0.000125    Time 0.045443    
2024-04-05 16:28:10,333 - Epoch: [202][  500/  500]    Overall Loss 0.575869    Objective Loss 0.575869    Top1 84.000000    Top5 99.000000    LR 0.000125    Time 0.045317    
2024-04-05 16:28:10,502 - --- validate (epoch=202)-----------
2024-04-05 16:28:10,503 - 10000 samples (100 per mini-batch)
2024-04-05 16:28:12,272 - Epoch: [202][  100/  100]    Loss 1.919079    Top1 55.310000    Top5 82.190000    
2024-04-05 16:28:12,383 - ==> Top1: 55.310    Top5: 82.190    Loss: 1.919

2024-04-05 16:28:12,389 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:28:12,390 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:28:12,420 - 

2024-04-05 16:28:12,420 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:28:16,830 - Epoch: [203][  100/  500]    Overall Loss 0.566841    Objective Loss 0.566841                                        LR 0.000125    Time 0.044047    
2024-04-05 16:28:21,164 - Epoch: [203][  200/  500]    Overall Loss 0.565217    Objective Loss 0.565217                                        LR 0.000125    Time 0.043671    
2024-04-05 16:28:25,336 - Epoch: [203][  300/  500]    Overall Loss 0.565040    Objective Loss 0.565040                                        LR 0.000125    Time 0.043005    
2024-04-05 16:28:29,477 - Epoch: [203][  400/  500]    Overall Loss 0.569102    Objective Loss 0.569102                                        LR 0.000125    Time 0.042596    
2024-04-05 16:28:33,876 - Epoch: [203][  500/  500]    Overall Loss 0.571247    Objective Loss 0.571247    Top1 81.500000    Top5 98.500000    LR 0.000125    Time 0.042865    
2024-04-05 16:28:34,007 - --- validate (epoch=203)-----------
2024-04-05 16:28:34,007 - 10000 samples (100 per mini-batch)
2024-04-05 16:28:35,543 - Epoch: [203][  100/  100]    Loss 1.909194    Top1 55.400000    Top5 82.530000    
2024-04-05 16:28:35,720 - ==> Top1: 55.400    Top5: 82.530    Loss: 1.909

2024-04-05 16:28:35,728 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:28:35,728 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:28:35,759 - 

2024-04-05 16:28:35,759 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:28:40,891 - Epoch: [204][  100/  500]    Overall Loss 0.571791    Objective Loss 0.571791                                        LR 0.000125    Time 0.051268    
2024-04-05 16:28:45,374 - Epoch: [204][  200/  500]    Overall Loss 0.574553    Objective Loss 0.574553                                        LR 0.000125    Time 0.048019    
2024-04-05 16:28:49,720 - Epoch: [204][  300/  500]    Overall Loss 0.570875    Objective Loss 0.570875                                        LR 0.000125    Time 0.046483    
2024-04-05 16:28:54,095 - Epoch: [204][  400/  500]    Overall Loss 0.573770    Objective Loss 0.573770                                        LR 0.000125    Time 0.045788    
2024-04-05 16:28:58,511 - Epoch: [204][  500/  500]    Overall Loss 0.571483    Objective Loss 0.571483    Top1 84.000000    Top5 99.000000    LR 0.000125    Time 0.045453    
2024-04-05 16:28:58,676 - --- validate (epoch=204)-----------
2024-04-05 16:28:58,678 - 10000 samples (100 per mini-batch)
2024-04-05 16:29:00,142 - Epoch: [204][  100/  100]    Loss 1.913283    Top1 54.900000    Top5 82.300000    
2024-04-05 16:29:00,239 - ==> Top1: 54.900    Top5: 82.300    Loss: 1.913

2024-04-05 16:29:00,245 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:29:00,245 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:29:00,276 - 

2024-04-05 16:29:00,276 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:29:05,195 - Epoch: [205][  100/  500]    Overall Loss 0.558743    Objective Loss 0.558743                                        LR 0.000125    Time 0.049137    
2024-04-05 16:29:09,628 - Epoch: [205][  200/  500]    Overall Loss 0.565456    Objective Loss 0.565456                                        LR 0.000125    Time 0.046706    
2024-04-05 16:29:13,848 - Epoch: [205][  300/  500]    Overall Loss 0.571460    Objective Loss 0.571460                                        LR 0.000125    Time 0.045188    
2024-04-05 16:29:18,002 - Epoch: [205][  400/  500]    Overall Loss 0.572798    Objective Loss 0.572798                                        LR 0.000125    Time 0.044264    
2024-04-05 16:29:22,449 - Epoch: [205][  500/  500]    Overall Loss 0.570288    Objective Loss 0.570288    Top1 84.500000    Top5 98.500000    LR 0.000125    Time 0.044294    
2024-04-05 16:29:22,609 - --- validate (epoch=205)-----------
2024-04-05 16:29:22,610 - 10000 samples (100 per mini-batch)
2024-04-05 16:29:24,188 - Epoch: [205][  100/  100]    Loss 1.912009    Top1 55.310000    Top5 82.210000    
2024-04-05 16:29:24,368 - ==> Top1: 55.310    Top5: 82.210    Loss: 1.912

2024-04-05 16:29:24,375 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:29:24,375 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:29:24,405 - 

2024-04-05 16:29:24,406 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:29:29,530 - Epoch: [206][  100/  500]    Overall Loss 0.565316    Objective Loss 0.565316                                        LR 0.000125    Time 0.051193    
2024-04-05 16:29:33,827 - Epoch: [206][  200/  500]    Overall Loss 0.560480    Objective Loss 0.560480                                        LR 0.000125    Time 0.047054    
2024-04-05 16:29:38,212 - Epoch: [206][  300/  500]    Overall Loss 0.562643    Objective Loss 0.562643                                        LR 0.000125    Time 0.045973    
2024-04-05 16:29:42,470 - Epoch: [206][  400/  500]    Overall Loss 0.566267    Objective Loss 0.566267                                        LR 0.000125    Time 0.045112    
2024-04-05 16:29:46,935 - Epoch: [206][  500/  500]    Overall Loss 0.566755    Objective Loss 0.566755    Top1 84.000000    Top5 98.000000    LR 0.000125    Time 0.045008    
2024-04-05 16:29:47,111 - --- validate (epoch=206)-----------
2024-04-05 16:29:47,111 - 10000 samples (100 per mini-batch)
2024-04-05 16:29:48,654 - Epoch: [206][  100/  100]    Loss 1.917667    Top1 55.090000    Top5 82.310000    
2024-04-05 16:29:48,756 - ==> Top1: 55.090    Top5: 82.310    Loss: 1.918

2024-04-05 16:29:48,759 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:29:48,760 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:29:48,783 - 

2024-04-05 16:29:48,783 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:29:53,638 - Epoch: [207][  100/  500]    Overall Loss 0.560562    Objective Loss 0.560562                                        LR 0.000125    Time 0.048486    
2024-04-05 16:29:58,149 - Epoch: [207][  200/  500]    Overall Loss 0.568421    Objective Loss 0.568421                                        LR 0.000125    Time 0.046772    
2024-04-05 16:30:02,406 - Epoch: [207][  300/  500]    Overall Loss 0.560714    Objective Loss 0.560714                                        LR 0.000125    Time 0.045359    
2024-04-05 16:30:06,675 - Epoch: [207][  400/  500]    Overall Loss 0.562914    Objective Loss 0.562914                                        LR 0.000125    Time 0.044678    
2024-04-05 16:30:11,096 - Epoch: [207][  500/  500]    Overall Loss 0.568701    Objective Loss 0.568701    Top1 82.500000    Top5 98.000000    LR 0.000125    Time 0.044575    
2024-04-05 16:30:11,269 - --- validate (epoch=207)-----------
2024-04-05 16:30:11,269 - 10000 samples (100 per mini-batch)
2024-04-05 16:30:12,880 - Epoch: [207][  100/  100]    Loss 1.915031    Top1 55.220000    Top5 82.130000    
2024-04-05 16:30:13,066 - ==> Top1: 55.220    Top5: 82.130    Loss: 1.915

2024-04-05 16:30:13,073 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:30:13,073 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:30:13,093 - 

2024-04-05 16:30:13,094 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:30:18,000 - Epoch: [208][  100/  500]    Overall Loss 0.559536    Objective Loss 0.559536                                        LR 0.000125    Time 0.049005    
2024-04-05 16:30:22,484 - Epoch: [208][  200/  500]    Overall Loss 0.564981    Objective Loss 0.564981                                        LR 0.000125    Time 0.046896    
2024-04-05 16:30:26,779 - Epoch: [208][  300/  500]    Overall Loss 0.566454    Objective Loss 0.566454                                        LR 0.000125    Time 0.045566    
2024-04-05 16:30:31,263 - Epoch: [208][  400/  500]    Overall Loss 0.565662    Objective Loss 0.565662                                        LR 0.000125    Time 0.045372    
2024-04-05 16:30:35,826 - Epoch: [208][  500/  500]    Overall Loss 0.568464    Objective Loss 0.568464    Top1 79.500000    Top5 98.000000    LR 0.000125    Time 0.045414    
2024-04-05 16:30:36,013 - --- validate (epoch=208)-----------
2024-04-05 16:30:36,014 - 10000 samples (100 per mini-batch)
2024-04-05 16:30:37,728 - Epoch: [208][  100/  100]    Loss 1.922756    Top1 55.270000    Top5 82.110000    
2024-04-05 16:30:37,895 - ==> Top1: 55.270    Top5: 82.110    Loss: 1.923

2024-04-05 16:30:37,901 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:30:37,901 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:30:37,931 - 

2024-04-05 16:30:37,931 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:30:43,005 - Epoch: [209][  100/  500]    Overall Loss 0.559290    Objective Loss 0.559290                                        LR 0.000125    Time 0.050677    
2024-04-05 16:30:47,619 - Epoch: [209][  200/  500]    Overall Loss 0.553277    Objective Loss 0.553277                                        LR 0.000125    Time 0.048383    
2024-04-05 16:30:52,020 - Epoch: [209][  300/  500]    Overall Loss 0.569419    Objective Loss 0.569419                                        LR 0.000125    Time 0.046906    
2024-04-05 16:30:56,387 - Epoch: [209][  400/  500]    Overall Loss 0.568412    Objective Loss 0.568412                                        LR 0.000125    Time 0.046084    
2024-04-05 16:31:00,869 - Epoch: [209][  500/  500]    Overall Loss 0.568705    Objective Loss 0.568705    Top1 77.500000    Top5 97.000000    LR 0.000125    Time 0.045823    
2024-04-05 16:31:01,122 - --- validate (epoch=209)-----------
2024-04-05 16:31:01,123 - 10000 samples (100 per mini-batch)
2024-04-05 16:31:02,593 - Epoch: [209][  100/  100]    Loss 1.921581    Top1 55.120000    Top5 81.910000    
2024-04-05 16:31:02,763 - ==> Top1: 55.120    Top5: 81.910    Loss: 1.922

2024-04-05 16:31:02,769 - ==> Best [Top1: 55.540   Top5: 82.610   Sparsity:0.00   Params: 314624 on epoch: 116]
2024-04-05 16:31:02,770 - Saving checkpoint to: logs/2024.04.05-150814/checkpoint.pth.tar
2024-04-05 16:31:02,799 - 

2024-04-05 16:31:02,799 - Initiating quantization aware training (QAT)...
2024-04-05 16:31:02,827 - 

2024-04-05 16:31:02,827 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:31:07,896 - Epoch: [210][  100/  500]    Overall Loss 1.956838    Objective Loss 1.956838                                        LR 0.000125    Time 0.050657    
2024-04-05 16:31:12,358 - Epoch: [210][  200/  500]    Overall Loss 1.596674    Objective Loss 1.596674                                        LR 0.000125    Time 0.047624    
2024-04-05 16:31:16,747 - Epoch: [210][  300/  500]    Overall Loss 1.451328    Objective Loss 1.451328                                        LR 0.000125    Time 0.046367    
2024-04-05 16:31:21,170 - Epoch: [210][  400/  500]    Overall Loss 1.368675    Objective Loss 1.368675                                        LR 0.000125    Time 0.045824    
2024-04-05 16:31:25,562 - Epoch: [210][  500/  500]    Overall Loss 1.316053    Objective Loss 1.316053    Top1 75.500000    Top5 94.500000    LR 0.000125    Time 0.045439    
2024-04-05 16:31:25,749 - --- validate (epoch=210)-----------
2024-04-05 16:31:25,750 - 10000 samples (100 per mini-batch)
2024-04-05 16:31:28,143 - Epoch: [210][  100/  100]    Loss 1.699710    Top1 54.020000    Top5 82.640000    
2024-04-05 16:31:28,315 - ==> Top1: 54.020    Top5: 82.640    Loss: 1.700

2024-04-05 16:31:28,322 - ==> Best [Top1: 54.020   Top5: 82.640   Sparsity:0.00   Params: 314624 on epoch: 210]
2024-04-05 16:31:28,322 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:31:28,355 - 

2024-04-05 16:31:28,355 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:31:33,262 - Epoch: [211][  100/  500]    Overall Loss 1.061812    Objective Loss 1.061812                                        LR 0.000125    Time 0.049037    
2024-04-05 16:31:37,671 - Epoch: [211][  200/  500]    Overall Loss 1.055596    Objective Loss 1.055596                                        LR 0.000125    Time 0.046544    
2024-04-05 16:31:41,912 - Epoch: [211][  300/  500]    Overall Loss 1.054364    Objective Loss 1.054364                                        LR 0.000125    Time 0.045158    
2024-04-05 16:31:46,300 - Epoch: [211][  400/  500]    Overall Loss 1.057606    Objective Loss 1.057606                                        LR 0.000125    Time 0.044831    
2024-04-05 16:31:50,711 - Epoch: [211][  500/  500]    Overall Loss 1.053721    Objective Loss 1.053721    Top1 78.500000    Top5 96.500000    LR 0.000125    Time 0.044680    
2024-04-05 16:31:50,961 - --- validate (epoch=211)-----------
2024-04-05 16:31:50,961 - 10000 samples (100 per mini-batch)
2024-04-05 16:31:53,308 - Epoch: [211][  100/  100]    Loss 1.661354    Top1 55.050000    Top5 83.260000    
2024-04-05 16:31:53,457 - ==> Top1: 55.050    Top5: 83.260    Loss: 1.661

2024-04-05 16:31:53,462 - ==> Best [Top1: 55.050   Top5: 83.260   Sparsity:0.00   Params: 314624 on epoch: 211]
2024-04-05 16:31:53,462 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:31:53,496 - 

2024-04-05 16:31:53,497 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:31:58,364 - Epoch: [212][  100/  500]    Overall Loss 1.018235    Objective Loss 1.018235                                        LR 0.000125    Time 0.048641    
2024-04-05 16:32:02,833 - Epoch: [212][  200/  500]    Overall Loss 1.011881    Objective Loss 1.011881                                        LR 0.000125    Time 0.046646    
2024-04-05 16:32:07,150 - Epoch: [212][  300/  500]    Overall Loss 1.016631    Objective Loss 1.016631                                        LR 0.000125    Time 0.045480    
2024-04-05 16:32:11,498 - Epoch: [212][  400/  500]    Overall Loss 1.015812    Objective Loss 1.015812                                        LR 0.000125    Time 0.044970    
2024-04-05 16:32:15,882 - Epoch: [212][  500/  500]    Overall Loss 1.012491    Objective Loss 1.012491    Top1 72.500000    Top5 95.500000    LR 0.000125    Time 0.044739    
2024-04-05 16:32:16,078 - --- validate (epoch=212)-----------
2024-04-05 16:32:16,078 - 10000 samples (100 per mini-batch)
2024-04-05 16:32:18,735 - Epoch: [212][  100/  100]    Loss 1.668491    Top1 55.140000    Top5 83.220000    
2024-04-05 16:32:18,924 - ==> Top1: 55.140    Top5: 83.220    Loss: 1.668

2024-04-05 16:32:18,929 - ==> Best [Top1: 55.140   Top5: 83.220   Sparsity:0.00   Params: 314624 on epoch: 212]
2024-04-05 16:32:18,929 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:32:18,967 - 

2024-04-05 16:32:18,967 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:32:23,925 - Epoch: [213][  100/  500]    Overall Loss 0.969164    Objective Loss 0.969164                                        LR 0.000125    Time 0.049545    
2024-04-05 16:32:28,357 - Epoch: [213][  200/  500]    Overall Loss 0.984017    Objective Loss 0.984017                                        LR 0.000125    Time 0.046912    
2024-04-05 16:32:32,620 - Epoch: [213][  300/  500]    Overall Loss 0.977838    Objective Loss 0.977838                                        LR 0.000125    Time 0.045477    
2024-04-05 16:32:37,110 - Epoch: [213][  400/  500]    Overall Loss 0.978991    Objective Loss 0.978991                                        LR 0.000125    Time 0.045325    
2024-04-05 16:32:41,588 - Epoch: [213][  500/  500]    Overall Loss 0.980253    Objective Loss 0.980253    Top1 70.000000    Top5 97.000000    LR 0.000125    Time 0.045208    
2024-04-05 16:32:41,762 - --- validate (epoch=213)-----------
2024-04-05 16:32:41,762 - 10000 samples (100 per mini-batch)
2024-04-05 16:32:44,211 - Epoch: [213][  100/  100]    Loss 1.647948    Top1 55.220000    Top5 83.270000    
2024-04-05 16:32:44,341 - ==> Top1: 55.220    Top5: 83.270    Loss: 1.648

2024-04-05 16:32:44,347 - ==> Best [Top1: 55.220   Top5: 83.270   Sparsity:0.00   Params: 314624 on epoch: 213]
2024-04-05 16:32:44,348 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:32:44,384 - 

2024-04-05 16:32:44,384 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:32:49,481 - Epoch: [214][  100/  500]    Overall Loss 0.941626    Objective Loss 0.941626                                        LR 0.000125    Time 0.050938    
2024-04-05 16:32:53,989 - Epoch: [214][  200/  500]    Overall Loss 0.950629    Objective Loss 0.950629                                        LR 0.000125    Time 0.047989    
2024-04-05 16:32:58,248 - Epoch: [214][  300/  500]    Overall Loss 0.954000    Objective Loss 0.954000                                        LR 0.000125    Time 0.046180    
2024-04-05 16:33:02,621 - Epoch: [214][  400/  500]    Overall Loss 0.954369    Objective Loss 0.954369                                        LR 0.000125    Time 0.045560    
2024-04-05 16:33:07,027 - Epoch: [214][  500/  500]    Overall Loss 0.956873    Objective Loss 0.956873    Top1 73.500000    Top5 96.000000    LR 0.000125    Time 0.045254    
2024-04-05 16:33:07,188 - --- validate (epoch=214)-----------
2024-04-05 16:33:07,189 - 10000 samples (100 per mini-batch)
2024-04-05 16:33:09,611 - Epoch: [214][  100/  100]    Loss 1.662251    Top1 55.110000    Top5 83.420000    
2024-04-05 16:33:09,772 - ==> Top1: 55.110    Top5: 83.420    Loss: 1.662

2024-04-05 16:33:09,778 - ==> Best [Top1: 55.220   Top5: 83.270   Sparsity:0.00   Params: 314624 on epoch: 213]
2024-04-05 16:33:09,778 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:33:09,806 - 

2024-04-05 16:33:09,807 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:33:14,753 - Epoch: [215][  100/  500]    Overall Loss 0.927317    Objective Loss 0.927317                                        LR 0.000125    Time 0.049423    
2024-04-05 16:33:19,071 - Epoch: [215][  200/  500]    Overall Loss 0.933710    Objective Loss 0.933710                                        LR 0.000125    Time 0.046288    
2024-04-05 16:33:23,400 - Epoch: [215][  300/  500]    Overall Loss 0.943320    Objective Loss 0.943320                                        LR 0.000125    Time 0.045276    
2024-04-05 16:33:27,796 - Epoch: [215][  400/  500]    Overall Loss 0.942073    Objective Loss 0.942073                                        LR 0.000125    Time 0.044940    
2024-04-05 16:33:32,234 - Epoch: [215][  500/  500]    Overall Loss 0.947075    Objective Loss 0.947075    Top1 72.500000    Top5 96.500000    LR 0.000125    Time 0.044823    
2024-04-05 16:33:32,434 - --- validate (epoch=215)-----------
2024-04-05 16:33:32,434 - 10000 samples (100 per mini-batch)
2024-04-05 16:33:34,908 - Epoch: [215][  100/  100]    Loss 1.677467    Top1 54.930000    Top5 82.740000    
2024-04-05 16:33:35,038 - ==> Top1: 54.930    Top5: 82.740    Loss: 1.677

2024-04-05 16:33:35,044 - ==> Best [Top1: 55.220   Top5: 83.270   Sparsity:0.00   Params: 314624 on epoch: 213]
2024-04-05 16:33:35,044 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:33:35,073 - 

2024-04-05 16:33:35,073 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:33:40,217 - Epoch: [216][  100/  500]    Overall Loss 0.942661    Objective Loss 0.942661                                        LR 0.000125    Time 0.051395    
2024-04-05 16:33:44,449 - Epoch: [216][  200/  500]    Overall Loss 0.933930    Objective Loss 0.933930                                        LR 0.000125    Time 0.046846    
2024-04-05 16:33:47,426 - Epoch: [216][  300/  500]    Overall Loss 0.928468    Objective Loss 0.928468                                        LR 0.000125    Time 0.041146    
2024-04-05 16:33:51,789 - Epoch: [216][  400/  500]    Overall Loss 0.926581    Objective Loss 0.926581                                        LR 0.000125    Time 0.041757    
2024-04-05 16:33:56,139 - Epoch: [216][  500/  500]    Overall Loss 0.929022    Objective Loss 0.929022    Top1 74.500000    Top5 98.500000    LR 0.000125    Time 0.042099    
2024-04-05 16:33:56,298 - --- validate (epoch=216)-----------
2024-04-05 16:33:56,299 - 10000 samples (100 per mini-batch)
2024-04-05 16:33:58,695 - Epoch: [216][  100/  100]    Loss 1.650428    Top1 55.420000    Top5 83.320000    
2024-04-05 16:33:58,874 - ==> Top1: 55.420    Top5: 83.320    Loss: 1.650

2024-04-05 16:33:58,879 - ==> Best [Top1: 55.420   Top5: 83.320   Sparsity:0.00   Params: 314624 on epoch: 216]
2024-04-05 16:33:58,879 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:33:58,914 - 

2024-04-05 16:33:58,915 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:34:03,965 - Epoch: [217][  100/  500]    Overall Loss 0.916215    Objective Loss 0.916215                                        LR 0.000125    Time 0.050468    
2024-04-05 16:34:08,188 - Epoch: [217][  200/  500]    Overall Loss 0.906101    Objective Loss 0.906101                                        LR 0.000125    Time 0.046332    
2024-04-05 16:34:12,572 - Epoch: [217][  300/  500]    Overall Loss 0.914782    Objective Loss 0.914782                                        LR 0.000125    Time 0.045493    
2024-04-05 16:34:17,055 - Epoch: [217][  400/  500]    Overall Loss 0.919669    Objective Loss 0.919669                                        LR 0.000125    Time 0.045318    
2024-04-05 16:34:21,563 - Epoch: [217][  500/  500]    Overall Loss 0.920578    Objective Loss 0.920578    Top1 75.500000    Top5 97.500000    LR 0.000125    Time 0.045264    
2024-04-05 16:34:21,751 - --- validate (epoch=217)-----------
2024-04-05 16:34:21,751 - 10000 samples (100 per mini-batch)
2024-04-05 16:34:24,051 - Epoch: [217][  100/  100]    Loss 1.669188    Top1 55.160000    Top5 82.540000    
2024-04-05 16:34:24,218 - ==> Top1: 55.160    Top5: 82.540    Loss: 1.669

2024-04-05 16:34:24,223 - ==> Best [Top1: 55.420   Top5: 83.320   Sparsity:0.00   Params: 314624 on epoch: 216]
2024-04-05 16:34:24,224 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:34:24,252 - 

2024-04-05 16:34:24,252 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:34:29,168 - Epoch: [218][  100/  500]    Overall Loss 0.910843    Objective Loss 0.910843                                        LR 0.000125    Time 0.049122    
2024-04-05 16:34:33,295 - Epoch: [218][  200/  500]    Overall Loss 0.901432    Objective Loss 0.901432                                        LR 0.000125    Time 0.045180    
2024-04-05 16:34:37,676 - Epoch: [218][  300/  500]    Overall Loss 0.902087    Objective Loss 0.902087                                        LR 0.000125    Time 0.044714    
2024-04-05 16:34:42,105 - Epoch: [218][  400/  500]    Overall Loss 0.911466    Objective Loss 0.911466                                        LR 0.000125    Time 0.044599    
2024-04-05 16:34:46,573 - Epoch: [218][  500/  500]    Overall Loss 0.912558    Objective Loss 0.912558    Top1 71.000000    Top5 94.500000    LR 0.000125    Time 0.044610    
2024-04-05 16:34:46,744 - --- validate (epoch=218)-----------
2024-04-05 16:34:46,745 - 10000 samples (100 per mini-batch)
2024-04-05 16:34:49,392 - Epoch: [218][  100/  100]    Loss 1.656948    Top1 55.450000    Top5 83.210000    
2024-04-05 16:34:49,533 - ==> Top1: 55.450    Top5: 83.210    Loss: 1.657

2024-04-05 16:34:49,539 - ==> Best [Top1: 55.450   Top5: 83.210   Sparsity:0.00   Params: 314624 on epoch: 218]
2024-04-05 16:34:49,539 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:34:49,577 - 

2024-04-05 16:34:49,577 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:34:54,553 - Epoch: [219][  100/  500]    Overall Loss 0.889743    Objective Loss 0.889743                                        LR 0.000125    Time 0.049727    
2024-04-05 16:34:58,701 - Epoch: [219][  200/  500]    Overall Loss 0.901124    Objective Loss 0.901124                                        LR 0.000125    Time 0.045585    
2024-04-05 16:35:03,141 - Epoch: [219][  300/  500]    Overall Loss 0.896630    Objective Loss 0.896630                                        LR 0.000125    Time 0.045182    
2024-04-05 16:35:07,611 - Epoch: [219][  400/  500]    Overall Loss 0.900930    Objective Loss 0.900930                                        LR 0.000125    Time 0.045052    
2024-04-05 16:35:12,093 - Epoch: [219][  500/  500]    Overall Loss 0.900852    Objective Loss 0.900852    Top1 73.500000    Top5 96.500000    LR 0.000125    Time 0.044999    
2024-04-05 16:35:12,262 - --- validate (epoch=219)-----------
2024-04-05 16:35:12,263 - 10000 samples (100 per mini-batch)
2024-04-05 16:35:14,669 - Epoch: [219][  100/  100]    Loss 1.657947    Top1 55.600000    Top5 83.050000    
2024-04-05 16:35:14,868 - ==> Top1: 55.600    Top5: 83.050    Loss: 1.658

2024-04-05 16:35:14,874 - ==> Best [Top1: 55.600   Top5: 83.050   Sparsity:0.00   Params: 314624 on epoch: 219]
2024-04-05 16:35:14,874 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:35:14,909 - 

2024-04-05 16:35:14,909 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:35:20,019 - Epoch: [220][  100/  500]    Overall Loss 0.888489    Objective Loss 0.888489                                        LR 0.000125    Time 0.051066    
2024-04-05 16:35:24,292 - Epoch: [220][  200/  500]    Overall Loss 0.896593    Objective Loss 0.896593                                        LR 0.000125    Time 0.046882    
2024-04-05 16:35:28,673 - Epoch: [220][  300/  500]    Overall Loss 0.892849    Objective Loss 0.892849                                        LR 0.000125    Time 0.045846    
2024-04-05 16:35:33,068 - Epoch: [220][  400/  500]    Overall Loss 0.897825    Objective Loss 0.897825                                        LR 0.000125    Time 0.045363    
2024-04-05 16:35:37,486 - Epoch: [220][  500/  500]    Overall Loss 0.902443    Objective Loss 0.902443    Top1 78.000000    Top5 97.000000    LR 0.000125    Time 0.045121    
2024-04-05 16:35:37,677 - --- validate (epoch=220)-----------
2024-04-05 16:35:37,677 - 10000 samples (100 per mini-batch)
2024-04-05 16:35:40,095 - Epoch: [220][  100/  100]    Loss 1.653866    Top1 55.380000    Top5 83.270000    
2024-04-05 16:35:40,191 - ==> Top1: 55.380    Top5: 83.270    Loss: 1.654

2024-04-05 16:35:40,197 - ==> Best [Top1: 55.600   Top5: 83.050   Sparsity:0.00   Params: 314624 on epoch: 219]
2024-04-05 16:35:40,198 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:35:40,227 - 

2024-04-05 16:35:40,227 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:35:45,003 - Epoch: [221][  100/  500]    Overall Loss 0.859564    Objective Loss 0.859564                                        LR 0.000125    Time 0.047721    
2024-04-05 16:35:49,289 - Epoch: [221][  200/  500]    Overall Loss 0.863250    Objective Loss 0.863250                                        LR 0.000125    Time 0.045273    
2024-04-05 16:35:53,789 - Epoch: [221][  300/  500]    Overall Loss 0.876322    Objective Loss 0.876322                                        LR 0.000125    Time 0.045170    
2024-04-05 16:35:58,232 - Epoch: [221][  400/  500]    Overall Loss 0.880099    Objective Loss 0.880099                                        LR 0.000125    Time 0.044978    
2024-04-05 16:36:02,656 - Epoch: [221][  500/  500]    Overall Loss 0.882836    Objective Loss 0.882836    Top1 77.500000    Top5 98.000000    LR 0.000125    Time 0.044823    
2024-04-05 16:36:02,819 - --- validate (epoch=221)-----------
2024-04-05 16:36:02,819 - 10000 samples (100 per mini-batch)
2024-04-05 16:36:05,208 - Epoch: [221][  100/  100]    Loss 1.660464    Top1 54.880000    Top5 83.240000    
2024-04-05 16:36:05,354 - ==> Top1: 54.880    Top5: 83.240    Loss: 1.660

2024-04-05 16:36:05,360 - ==> Best [Top1: 55.600   Top5: 83.050   Sparsity:0.00   Params: 314624 on epoch: 219]
2024-04-05 16:36:05,360 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:36:05,389 - 

2024-04-05 16:36:05,390 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:36:10,110 - Epoch: [222][  100/  500]    Overall Loss 0.855542    Objective Loss 0.855542                                        LR 0.000125    Time 0.047156    
2024-04-05 16:36:14,520 - Epoch: [222][  200/  500]    Overall Loss 0.868515    Objective Loss 0.868515                                        LR 0.000125    Time 0.045608    
2024-04-05 16:36:18,914 - Epoch: [222][  300/  500]    Overall Loss 0.872467    Objective Loss 0.872467                                        LR 0.000125    Time 0.045042    
2024-04-05 16:36:23,364 - Epoch: [222][  400/  500]    Overall Loss 0.874707    Objective Loss 0.874707                                        LR 0.000125    Time 0.044901    
2024-04-05 16:36:27,883 - Epoch: [222][  500/  500]    Overall Loss 0.876512    Objective Loss 0.876512    Top1 73.000000    Top5 96.000000    LR 0.000125    Time 0.044951    
2024-04-05 16:36:28,069 - --- validate (epoch=222)-----------
2024-04-05 16:36:28,070 - 10000 samples (100 per mini-batch)
2024-04-05 16:36:30,726 - Epoch: [222][  100/  100]    Loss 1.663586    Top1 55.460000    Top5 83.010000    
2024-04-05 16:36:30,858 - ==> Top1: 55.460    Top5: 83.010    Loss: 1.664

2024-04-05 16:36:30,863 - ==> Best [Top1: 55.600   Top5: 83.050   Sparsity:0.00   Params: 314624 on epoch: 219]
2024-04-05 16:36:30,863 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:36:30,892 - 

2024-04-05 16:36:30,893 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:36:35,495 - Epoch: [223][  100/  500]    Overall Loss 0.851009    Objective Loss 0.851009                                        LR 0.000125    Time 0.045985    
2024-04-05 16:36:39,922 - Epoch: [223][  200/  500]    Overall Loss 0.847306    Objective Loss 0.847306                                        LR 0.000125    Time 0.045112    
2024-04-05 16:36:44,278 - Epoch: [223][  300/  500]    Overall Loss 0.854197    Objective Loss 0.854197                                        LR 0.000125    Time 0.044586    
2024-04-05 16:36:48,654 - Epoch: [223][  400/  500]    Overall Loss 0.862720    Objective Loss 0.862720                                        LR 0.000125    Time 0.044370    
2024-04-05 16:36:53,034 - Epoch: [223][  500/  500]    Overall Loss 0.865625    Objective Loss 0.865625    Top1 73.000000    Top5 96.000000    LR 0.000125    Time 0.044248    
2024-04-05 16:36:53,231 - --- validate (epoch=223)-----------
2024-04-05 16:36:53,232 - 10000 samples (100 per mini-batch)
2024-04-05 16:36:55,764 - Epoch: [223][  100/  100]    Loss 1.664755    Top1 55.090000    Top5 83.230000    
2024-04-05 16:36:55,921 - ==> Top1: 55.090    Top5: 83.230    Loss: 1.665

2024-04-05 16:36:55,926 - ==> Best [Top1: 55.600   Top5: 83.050   Sparsity:0.00   Params: 314624 on epoch: 219]
2024-04-05 16:36:55,926 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:36:55,955 - 

2024-04-05 16:36:55,956 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:37:00,783 - Epoch: [224][  100/  500]    Overall Loss 0.845685    Objective Loss 0.845685                                        LR 0.000125    Time 0.048238    
2024-04-05 16:37:05,185 - Epoch: [224][  200/  500]    Overall Loss 0.845542    Objective Loss 0.845542                                        LR 0.000125    Time 0.046112    
2024-04-05 16:37:09,626 - Epoch: [224][  300/  500]    Overall Loss 0.850374    Objective Loss 0.850374                                        LR 0.000125    Time 0.045534    
2024-04-05 16:37:14,035 - Epoch: [224][  400/  500]    Overall Loss 0.852555    Objective Loss 0.852555                                        LR 0.000125    Time 0.045166    
2024-04-05 16:37:18,488 - Epoch: [224][  500/  500]    Overall Loss 0.857659    Objective Loss 0.857659    Top1 73.000000    Top5 94.000000    LR 0.000125    Time 0.045033    
2024-04-05 16:37:18,755 - --- validate (epoch=224)-----------
2024-04-05 16:37:18,755 - 10000 samples (100 per mini-batch)
2024-04-05 16:37:21,167 - Epoch: [224][  100/  100]    Loss 1.671563    Top1 55.060000    Top5 82.930000    
2024-04-05 16:37:21,323 - ==> Top1: 55.060    Top5: 82.930    Loss: 1.672

2024-04-05 16:37:21,328 - ==> Best [Top1: 55.600   Top5: 83.050   Sparsity:0.00   Params: 314624 on epoch: 219]
2024-04-05 16:37:21,329 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:37:21,358 - 

2024-04-05 16:37:21,358 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:37:26,133 - Epoch: [225][  100/  500]    Overall Loss 0.842714    Objective Loss 0.842714                                        LR 0.000125    Time 0.047712    
2024-04-05 16:37:30,745 - Epoch: [225][  200/  500]    Overall Loss 0.841072    Objective Loss 0.841072                                        LR 0.000125    Time 0.046898    
2024-04-05 16:37:35,411 - Epoch: [225][  300/  500]    Overall Loss 0.842562    Objective Loss 0.842562                                        LR 0.000125    Time 0.046805    
2024-04-05 16:37:40,062 - Epoch: [225][  400/  500]    Overall Loss 0.848481    Objective Loss 0.848481                                        LR 0.000125    Time 0.046720    
2024-04-05 16:37:44,732 - Epoch: [225][  500/  500]    Overall Loss 0.853938    Objective Loss 0.853938    Top1 75.000000    Top5 95.500000    LR 0.000125    Time 0.046709    
2024-04-05 16:37:44,889 - --- validate (epoch=225)-----------
2024-04-05 16:37:44,890 - 10000 samples (100 per mini-batch)
2024-04-05 16:37:47,356 - Epoch: [225][  100/  100]    Loss 1.684611    Top1 54.700000    Top5 82.830000    
2024-04-05 16:37:47,534 - ==> Top1: 54.700    Top5: 82.830    Loss: 1.685

2024-04-05 16:37:47,537 - ==> Best [Top1: 55.600   Top5: 83.050   Sparsity:0.00   Params: 314624 on epoch: 219]
2024-04-05 16:37:47,538 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:37:47,561 - 

2024-04-05 16:37:47,561 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:37:52,586 - Epoch: [226][  100/  500]    Overall Loss 0.828544    Objective Loss 0.828544                                        LR 0.000125    Time 0.050208    
2024-04-05 16:37:56,989 - Epoch: [226][  200/  500]    Overall Loss 0.851870    Objective Loss 0.851870                                        LR 0.000125    Time 0.047106    
2024-04-05 16:38:01,403 - Epoch: [226][  300/  500]    Overall Loss 0.855962    Objective Loss 0.855962                                        LR 0.000125    Time 0.046107    
2024-04-05 16:38:05,780 - Epoch: [226][  400/  500]    Overall Loss 0.853402    Objective Loss 0.853402                                        LR 0.000125    Time 0.045514    
2024-04-05 16:38:10,210 - Epoch: [226][  500/  500]    Overall Loss 0.856011    Objective Loss 0.856011    Top1 79.000000    Top5 98.000000    LR 0.000125    Time 0.045266    
2024-04-05 16:38:10,371 - --- validate (epoch=226)-----------
2024-04-05 16:38:10,372 - 10000 samples (100 per mini-batch)
2024-04-05 16:38:12,816 - Epoch: [226][  100/  100]    Loss 1.666198    Top1 55.450000    Top5 82.700000    
2024-04-05 16:38:12,988 - ==> Top1: 55.450    Top5: 82.700    Loss: 1.666

2024-04-05 16:38:12,992 - ==> Best [Top1: 55.600   Top5: 83.050   Sparsity:0.00   Params: 314624 on epoch: 219]
2024-04-05 16:38:12,992 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:38:13,020 - 

2024-04-05 16:38:13,021 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:38:18,024 - Epoch: [227][  100/  500]    Overall Loss 0.822418    Objective Loss 0.822418                                        LR 0.000125    Time 0.049992    
2024-04-05 16:38:22,525 - Epoch: [227][  200/  500]    Overall Loss 0.828202    Objective Loss 0.828202                                        LR 0.000125    Time 0.047484    
2024-04-05 16:38:27,021 - Epoch: [227][  300/  500]    Overall Loss 0.837764    Objective Loss 0.837764                                        LR 0.000125    Time 0.046628    
2024-04-05 16:38:31,514 - Epoch: [227][  400/  500]    Overall Loss 0.840488    Objective Loss 0.840488                                        LR 0.000125    Time 0.046195    
2024-04-05 16:38:36,013 - Epoch: [227][  500/  500]    Overall Loss 0.847582    Objective Loss 0.847582    Top1 80.000000    Top5 96.000000    LR 0.000125    Time 0.045948    
2024-04-05 16:38:36,193 - --- validate (epoch=227)-----------
2024-04-05 16:38:36,194 - 10000 samples (100 per mini-batch)
2024-04-05 16:38:38,708 - Epoch: [227][  100/  100]    Loss 1.694765    Top1 54.950000    Top5 82.340000    
2024-04-05 16:38:38,833 - ==> Top1: 54.950    Top5: 82.340    Loss: 1.695

2024-04-05 16:38:38,837 - ==> Best [Top1: 55.600   Top5: 83.050   Sparsity:0.00   Params: 314624 on epoch: 219]
2024-04-05 16:38:38,838 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:38:38,865 - 

2024-04-05 16:38:38,865 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:38:43,894 - Epoch: [228][  100/  500]    Overall Loss 0.820685    Objective Loss 0.820685                                        LR 0.000125    Time 0.050241    
2024-04-05 16:38:48,381 - Epoch: [228][  200/  500]    Overall Loss 0.824909    Objective Loss 0.824909                                        LR 0.000125    Time 0.047541    
2024-04-05 16:38:52,937 - Epoch: [228][  300/  500]    Overall Loss 0.828350    Objective Loss 0.828350                                        LR 0.000125    Time 0.046870    
2024-04-05 16:38:57,483 - Epoch: [228][  400/  500]    Overall Loss 0.838691    Objective Loss 0.838691                                        LR 0.000125    Time 0.046509    
2024-04-05 16:39:02,008 - Epoch: [228][  500/  500]    Overall Loss 0.841569    Objective Loss 0.841569    Top1 79.500000    Top5 94.000000    LR 0.000125    Time 0.046250    
2024-04-05 16:39:02,183 - --- validate (epoch=228)-----------
2024-04-05 16:39:02,184 - 10000 samples (100 per mini-batch)
2024-04-05 16:39:04,671 - Epoch: [228][  100/  100]    Loss 1.686774    Top1 55.460000    Top5 82.570000    
2024-04-05 16:39:04,789 - ==> Top1: 55.460    Top5: 82.570    Loss: 1.687

2024-04-05 16:39:04,794 - ==> Best [Top1: 55.600   Top5: 83.050   Sparsity:0.00   Params: 314624 on epoch: 219]
2024-04-05 16:39:04,794 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:39:04,822 - 

2024-04-05 16:39:04,822 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:39:10,028 - Epoch: [229][  100/  500]    Overall Loss 0.823066    Objective Loss 0.823066                                        LR 0.000125    Time 0.052021    
2024-04-05 16:39:14,478 - Epoch: [229][  200/  500]    Overall Loss 0.819080    Objective Loss 0.819080                                        LR 0.000125    Time 0.048246    
2024-04-05 16:39:18,917 - Epoch: [229][  300/  500]    Overall Loss 0.832563    Objective Loss 0.832563                                        LR 0.000125    Time 0.046949    
2024-04-05 16:39:23,331 - Epoch: [229][  400/  500]    Overall Loss 0.837824    Objective Loss 0.837824                                        LR 0.000125    Time 0.046239    
2024-04-05 16:39:27,734 - Epoch: [229][  500/  500]    Overall Loss 0.838682    Objective Loss 0.838682    Top1 76.000000    Top5 97.000000    LR 0.000125    Time 0.045790    
2024-04-05 16:39:27,910 - --- validate (epoch=229)-----------
2024-04-05 16:39:27,911 - 10000 samples (100 per mini-batch)
2024-04-05 16:39:30,406 - Epoch: [229][  100/  100]    Loss 1.677160    Top1 55.070000    Top5 82.480000    
2024-04-05 16:39:30,563 - ==> Top1: 55.070    Top5: 82.480    Loss: 1.677

2024-04-05 16:39:30,568 - ==> Best [Top1: 55.600   Top5: 83.050   Sparsity:0.00   Params: 314624 on epoch: 219]
2024-04-05 16:39:30,569 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:39:30,600 - 

2024-04-05 16:39:30,600 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:39:35,510 - Epoch: [230][  100/  500]    Overall Loss 0.816163    Objective Loss 0.816163                                        LR 0.000125    Time 0.049064    
2024-04-05 16:39:39,989 - Epoch: [230][  200/  500]    Overall Loss 0.821985    Objective Loss 0.821985                                        LR 0.000125    Time 0.046909    
2024-04-05 16:39:44,422 - Epoch: [230][  300/  500]    Overall Loss 0.824395    Objective Loss 0.824395                                        LR 0.000125    Time 0.046037    
2024-04-05 16:39:48,889 - Epoch: [230][  400/  500]    Overall Loss 0.992283    Objective Loss 0.992283                                        LR 0.000125    Time 0.045689    
2024-04-05 16:39:53,342 - Epoch: [230][  500/  500]    Overall Loss 1.090047    Objective Loss 1.090047    Top1 75.000000    Top5 93.500000    LR 0.000125    Time 0.045449    
2024-04-05 16:39:53,474 - --- validate (epoch=230)-----------
2024-04-05 16:39:53,474 - 10000 samples (100 per mini-batch)
2024-04-05 16:39:55,977 - Epoch: [230][  100/  100]    Loss 1.902224    Top1 55.770000    Top5 83.500000    
2024-04-05 16:39:56,087 - ==> Top1: 55.770    Top5: 83.500    Loss: 1.902

2024-04-05 16:39:56,093 - ==> Best [Top1: 55.770   Top5: 83.500   Sparsity:0.00   Params: 314624 on epoch: 230]
2024-04-05 16:39:56,093 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:39:56,132 - 

2024-04-05 16:39:56,133 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:40:01,087 - Epoch: [231][  100/  500]    Overall Loss 1.437864    Objective Loss 1.437864                                        LR 0.000125    Time 0.049510    
2024-04-05 16:40:05,528 - Epoch: [231][  200/  500]    Overall Loss 1.424607    Objective Loss 1.424607                                        LR 0.000125    Time 0.046942    
2024-04-05 16:40:09,958 - Epoch: [231][  300/  500]    Overall Loss 1.424980    Objective Loss 1.424980                                        LR 0.000125    Time 0.046051    
2024-04-05 16:40:14,405 - Epoch: [231][  400/  500]    Overall Loss 1.417233    Objective Loss 1.417233                                        LR 0.000125    Time 0.045648    
2024-04-05 16:40:18,773 - Epoch: [231][  500/  500]    Overall Loss 1.411123    Objective Loss 1.411123    Top1 78.500000    Top5 97.000000    LR 0.000125    Time 0.045247    
2024-04-05 16:40:18,968 - --- validate (epoch=231)-----------
2024-04-05 16:40:18,968 - 10000 samples (100 per mini-batch)
2024-04-05 16:40:21,449 - Epoch: [231][  100/  100]    Loss 1.847105    Top1 56.010000    Top5 83.410000    
2024-04-05 16:40:21,619 - ==> Top1: 56.010    Top5: 83.410    Loss: 1.847

2024-04-05 16:40:21,624 - ==> Best [Top1: 56.010   Top5: 83.410   Sparsity:0.00   Params: 314624 on epoch: 231]
2024-04-05 16:40:21,625 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:40:21,660 - 

2024-04-05 16:40:21,660 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:40:26,754 - Epoch: [232][  100/  500]    Overall Loss 1.378003    Objective Loss 1.378003                                        LR 0.000125    Time 0.050905    
2024-04-05 16:40:31,181 - Epoch: [232][  200/  500]    Overall Loss 1.369250    Objective Loss 1.369250                                        LR 0.000125    Time 0.047571    
2024-04-05 16:40:35,573 - Epoch: [232][  300/  500]    Overall Loss 1.370836    Objective Loss 1.370836                                        LR 0.000125    Time 0.046345    
2024-04-05 16:40:40,047 - Epoch: [232][  400/  500]    Overall Loss 1.365607    Objective Loss 1.365607                                        LR 0.000125    Time 0.045936    
2024-04-05 16:40:44,436 - Epoch: [232][  500/  500]    Overall Loss 1.366052    Objective Loss 1.366052    Top1 73.500000    Top5 96.500000    LR 0.000125    Time 0.045520    
2024-04-05 16:40:44,597 - --- validate (epoch=232)-----------
2024-04-05 16:40:44,597 - 10000 samples (100 per mini-batch)
2024-04-05 16:40:46,920 - Epoch: [232][  100/  100]    Loss 1.818494    Top1 55.700000    Top5 83.670000    
2024-04-05 16:40:47,019 - ==> Top1: 55.700    Top5: 83.670    Loss: 1.818

2024-04-05 16:40:47,024 - ==> Best [Top1: 56.010   Top5: 83.410   Sparsity:0.00   Params: 314624 on epoch: 231]
2024-04-05 16:40:47,024 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:40:47,055 - 

2024-04-05 16:40:47,056 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:40:52,026 - Epoch: [233][  100/  500]    Overall Loss 1.354137    Objective Loss 1.354137                                        LR 0.000125    Time 0.049661    
2024-04-05 16:40:56,454 - Epoch: [233][  200/  500]    Overall Loss 1.349446    Objective Loss 1.349446                                        LR 0.000125    Time 0.046949    
2024-04-05 16:41:00,927 - Epoch: [233][  300/  500]    Overall Loss 1.346887    Objective Loss 1.346887                                        LR 0.000125    Time 0.046197    
2024-04-05 16:41:05,395 - Epoch: [233][  400/  500]    Overall Loss 1.345727    Objective Loss 1.345727                                        LR 0.000125    Time 0.045811    
2024-04-05 16:41:09,719 - Epoch: [233][  500/  500]    Overall Loss 1.342871    Objective Loss 1.342871    Top1 64.000000    Top5 93.000000    LR 0.000125    Time 0.045289    
2024-04-05 16:41:09,915 - --- validate (epoch=233)-----------
2024-04-05 16:41:09,916 - 10000 samples (100 per mini-batch)
2024-04-05 16:41:12,291 - Epoch: [233][  100/  100]    Loss 1.793456    Top1 55.810000    Top5 83.400000    
2024-04-05 16:41:12,469 - ==> Top1: 55.810    Top5: 83.400    Loss: 1.793

2024-04-05 16:41:12,474 - ==> Best [Top1: 56.010   Top5: 83.410   Sparsity:0.00   Params: 314624 on epoch: 231]
2024-04-05 16:41:12,475 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:41:12,504 - 

2024-04-05 16:41:12,504 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:41:17,137 - Epoch: [234][  100/  500]    Overall Loss 1.324588    Objective Loss 1.324588                                        LR 0.000125    Time 0.046293    
2024-04-05 16:41:21,556 - Epoch: [234][  200/  500]    Overall Loss 1.326710    Objective Loss 1.326710                                        LR 0.000125    Time 0.045223    
2024-04-05 16:41:26,065 - Epoch: [234][  300/  500]    Overall Loss 1.321319    Objective Loss 1.321319                                        LR 0.000125    Time 0.045169    
2024-04-05 16:41:30,579 - Epoch: [234][  400/  500]    Overall Loss 1.322800    Objective Loss 1.322800                                        LR 0.000125    Time 0.045155    
2024-04-05 16:41:34,867 - Epoch: [234][  500/  500]    Overall Loss 1.320173    Objective Loss 1.320173    Top1 74.000000    Top5 93.500000    LR 0.000125    Time 0.044693    
2024-04-05 16:41:35,113 - --- validate (epoch=234)-----------
2024-04-05 16:41:35,114 - 10000 samples (100 per mini-batch)
2024-04-05 16:41:37,569 - Epoch: [234][  100/  100]    Loss 1.774035    Top1 55.460000    Top5 83.880000    
2024-04-05 16:41:37,747 - ==> Top1: 55.460    Top5: 83.880    Loss: 1.774

2024-04-05 16:41:37,753 - ==> Best [Top1: 56.010   Top5: 83.410   Sparsity:0.00   Params: 314624 on epoch: 231]
2024-04-05 16:41:37,753 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:41:37,783 - 

2024-04-05 16:41:37,784 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:41:42,632 - Epoch: [235][  100/  500]    Overall Loss 1.280163    Objective Loss 1.280163                                        LR 0.000125    Time 0.048449    
2024-04-05 16:41:47,052 - Epoch: [235][  200/  500]    Overall Loss 1.299245    Objective Loss 1.299245                                        LR 0.000125    Time 0.046305    
2024-04-05 16:41:51,396 - Epoch: [235][  300/  500]    Overall Loss 1.301224    Objective Loss 1.301224                                        LR 0.000125    Time 0.045342    
2024-04-05 16:41:55,731 - Epoch: [235][  400/  500]    Overall Loss 1.304028    Objective Loss 1.304028                                        LR 0.000125    Time 0.044835    
2024-04-05 16:41:59,846 - Epoch: [235][  500/  500]    Overall Loss 1.302901    Objective Loss 1.302901    Top1 70.500000    Top5 91.000000    LR 0.000125    Time 0.044092    
2024-04-05 16:42:00,016 - --- validate (epoch=235)-----------
2024-04-05 16:42:00,016 - 10000 samples (100 per mini-batch)
2024-04-05 16:42:02,442 - Epoch: [235][  100/  100]    Loss 1.784887    Top1 55.210000    Top5 83.250000    
2024-04-05 16:42:02,565 - ==> Top1: 55.210    Top5: 83.250    Loss: 1.785

2024-04-05 16:42:02,572 - ==> Best [Top1: 56.010   Top5: 83.410   Sparsity:0.00   Params: 314624 on epoch: 231]
2024-04-05 16:42:02,572 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:42:02,600 - 

2024-04-05 16:42:02,600 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:42:07,478 - Epoch: [236][  100/  500]    Overall Loss 1.290713    Objective Loss 1.290713                                        LR 0.000125    Time 0.048734    
2024-04-05 16:42:11,904 - Epoch: [236][  200/  500]    Overall Loss 1.291314    Objective Loss 1.291314                                        LR 0.000125    Time 0.046485    
2024-04-05 16:42:16,284 - Epoch: [236][  300/  500]    Overall Loss 1.286409    Objective Loss 1.286409                                        LR 0.000125    Time 0.045577    
2024-04-05 16:42:20,592 - Epoch: [236][  400/  500]    Overall Loss 1.285160    Objective Loss 1.285160                                        LR 0.000125    Time 0.044945    
2024-04-05 16:42:24,880 - Epoch: [236][  500/  500]    Overall Loss 1.285765    Objective Loss 1.285765    Top1 71.500000    Top5 94.000000    LR 0.000125    Time 0.044526    
2024-04-05 16:42:25,138 - --- validate (epoch=236)-----------
2024-04-05 16:42:25,139 - 10000 samples (100 per mini-batch)
2024-04-05 16:42:27,783 - Epoch: [236][  100/  100]    Loss 1.760402    Top1 55.490000    Top5 83.510000    
2024-04-05 16:42:27,962 - ==> Top1: 55.490    Top5: 83.510    Loss: 1.760

2024-04-05 16:42:27,967 - ==> Best [Top1: 56.010   Top5: 83.410   Sparsity:0.00   Params: 314624 on epoch: 231]
2024-04-05 16:42:27,967 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:42:27,997 - 

2024-04-05 16:42:27,997 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:42:32,873 - Epoch: [237][  100/  500]    Overall Loss 1.269372    Objective Loss 1.269372                                        LR 0.000125    Time 0.048721    
2024-04-05 16:42:37,052 - Epoch: [237][  200/  500]    Overall Loss 1.272289    Objective Loss 1.272289                                        LR 0.000125    Time 0.045240    
2024-04-05 16:42:40,687 - Epoch: [237][  300/  500]    Overall Loss 1.270418    Objective Loss 1.270418                                        LR 0.000125    Time 0.042270    
2024-04-05 16:42:45,074 - Epoch: [237][  400/  500]    Overall Loss 1.273713    Objective Loss 1.273713                                        LR 0.000125    Time 0.042662    
2024-04-05 16:42:49,500 - Epoch: [237][  500/  500]    Overall Loss 1.271208    Objective Loss 1.271208    Top1 68.000000    Top5 91.000000    LR 0.000125    Time 0.042976    
2024-04-05 16:42:49,715 - --- validate (epoch=237)-----------
2024-04-05 16:42:49,717 - 10000 samples (100 per mini-batch)
2024-04-05 16:42:52,118 - Epoch: [237][  100/  100]    Loss 1.746207    Top1 56.000000    Top5 83.630000    
2024-04-05 16:42:52,299 - ==> Top1: 56.000    Top5: 83.630    Loss: 1.746

2024-04-05 16:42:52,304 - ==> Best [Top1: 56.010   Top5: 83.410   Sparsity:0.00   Params: 314624 on epoch: 231]
2024-04-05 16:42:52,305 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:42:52,334 - 

2024-04-05 16:42:52,334 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:42:57,001 - Epoch: [238][  100/  500]    Overall Loss 1.228882    Objective Loss 1.228882                                        LR 0.000125    Time 0.046636    
2024-04-05 16:43:01,401 - Epoch: [238][  200/  500]    Overall Loss 1.236352    Objective Loss 1.236352                                        LR 0.000125    Time 0.045304    
2024-04-05 16:43:05,678 - Epoch: [238][  300/  500]    Overall Loss 1.247443    Objective Loss 1.247443                                        LR 0.000125    Time 0.044448    
2024-04-05 16:43:10,126 - Epoch: [238][  400/  500]    Overall Loss 1.248028    Objective Loss 1.248028                                        LR 0.000125    Time 0.044449    
2024-04-05 16:43:14,622 - Epoch: [238][  500/  500]    Overall Loss 1.255448    Objective Loss 1.255448    Top1 74.000000    Top5 93.500000    LR 0.000125    Time 0.044543    
2024-04-05 16:43:14,785 - --- validate (epoch=238)-----------
2024-04-05 16:43:14,786 - 10000 samples (100 per mini-batch)
2024-04-05 16:43:17,203 - Epoch: [238][  100/  100]    Loss 1.748213    Top1 55.580000    Top5 83.240000    
2024-04-05 16:43:17,353 - ==> Top1: 55.580    Top5: 83.240    Loss: 1.748

2024-04-05 16:43:17,359 - ==> Best [Top1: 56.010   Top5: 83.410   Sparsity:0.00   Params: 314624 on epoch: 231]
2024-04-05 16:43:17,359 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:43:17,389 - 

2024-04-05 16:43:17,390 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:43:22,382 - Epoch: [239][  100/  500]    Overall Loss 1.237208    Objective Loss 1.237208                                        LR 0.000125    Time 0.049883    
2024-04-05 16:43:26,892 - Epoch: [239][  200/  500]    Overall Loss 1.243646    Objective Loss 1.243646                                        LR 0.000125    Time 0.047477    
2024-04-05 16:43:31,171 - Epoch: [239][  300/  500]    Overall Loss 1.238841    Objective Loss 1.238841                                        LR 0.000125    Time 0.045904    
2024-04-05 16:43:35,610 - Epoch: [239][  400/  500]    Overall Loss 1.251836    Objective Loss 1.251836                                        LR 0.000125    Time 0.045518    
2024-04-05 16:43:40,008 - Epoch: [239][  500/  500]    Overall Loss 1.253017    Objective Loss 1.253017    Top1 68.500000    Top5 95.000000    LR 0.000125    Time 0.045203    
2024-04-05 16:43:40,166 - --- validate (epoch=239)-----------
2024-04-05 16:43:40,167 - 10000 samples (100 per mini-batch)
2024-04-05 16:43:42,635 - Epoch: [239][  100/  100]    Loss 1.741113    Top1 55.120000    Top5 83.520000    
2024-04-05 16:43:42,733 - ==> Top1: 55.120    Top5: 83.520    Loss: 1.741

2024-04-05 16:43:42,736 - ==> Best [Top1: 56.010   Top5: 83.410   Sparsity:0.00   Params: 314624 on epoch: 231]
2024-04-05 16:43:42,736 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:43:42,754 - 

2024-04-05 16:43:42,754 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:43:47,661 - Epoch: [240][  100/  500]    Overall Loss 1.225125    Objective Loss 1.225125                                        LR 0.000125    Time 0.049024    
2024-04-05 16:43:52,026 - Epoch: [240][  200/  500]    Overall Loss 1.236094    Objective Loss 1.236094                                        LR 0.000125    Time 0.046322    
2024-04-05 16:43:56,240 - Epoch: [240][  300/  500]    Overall Loss 1.242918    Objective Loss 1.242918                                        LR 0.000125    Time 0.044918    
2024-04-05 16:44:00,600 - Epoch: [240][  400/  500]    Overall Loss 1.240355    Objective Loss 1.240355                                        LR 0.000125    Time 0.044582    
2024-04-05 16:44:04,996 - Epoch: [240][  500/  500]    Overall Loss 1.233581    Objective Loss 1.233581    Top1 76.500000    Top5 98.500000    LR 0.000125    Time 0.044450    
2024-04-05 16:44:05,172 - --- validate (epoch=240)-----------
2024-04-05 16:44:05,173 - 10000 samples (100 per mini-batch)
2024-04-05 16:44:07,611 - Epoch: [240][  100/  100]    Loss 1.733145    Top1 55.740000    Top5 83.530000    
2024-04-05 16:44:07,775 - ==> Top1: 55.740    Top5: 83.530    Loss: 1.733

2024-04-05 16:44:07,780 - ==> Best [Top1: 56.010   Top5: 83.410   Sparsity:0.00   Params: 314624 on epoch: 231]
2024-04-05 16:44:07,780 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:44:07,809 - 

2024-04-05 16:44:07,810 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:44:12,997 - Epoch: [241][  100/  500]    Overall Loss 1.207342    Objective Loss 1.207342                                        LR 0.000125    Time 0.051837    
2024-04-05 16:44:17,339 - Epoch: [241][  200/  500]    Overall Loss 1.209182    Objective Loss 1.209182                                        LR 0.000125    Time 0.047611    
2024-04-05 16:44:21,593 - Epoch: [241][  300/  500]    Overall Loss 1.216805    Objective Loss 1.216805                                        LR 0.000125    Time 0.045911    
2024-04-05 16:44:25,988 - Epoch: [241][  400/  500]    Overall Loss 1.219505    Objective Loss 1.219505                                        LR 0.000125    Time 0.045413    
2024-04-05 16:44:30,387 - Epoch: [241][  500/  500]    Overall Loss 1.217735    Objective Loss 1.217735    Top1 70.000000    Top5 94.000000    LR 0.000125    Time 0.045122    
2024-04-05 16:44:30,572 - --- validate (epoch=241)-----------
2024-04-05 16:44:30,573 - 10000 samples (100 per mini-batch)
2024-04-05 16:44:33,073 - Epoch: [241][  100/  100]    Loss 1.747813    Top1 54.950000    Top5 82.880000    
2024-04-05 16:44:33,254 - ==> Top1: 54.950    Top5: 82.880    Loss: 1.748

2024-04-05 16:44:33,259 - ==> Best [Top1: 56.010   Top5: 83.410   Sparsity:0.00   Params: 314624 on epoch: 231]
2024-04-05 16:44:33,259 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:44:33,287 - 

2024-04-05 16:44:33,288 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:44:38,157 - Epoch: [242][  100/  500]    Overall Loss 1.203115    Objective Loss 1.203115                                        LR 0.000125    Time 0.048651    
2024-04-05 16:44:42,427 - Epoch: [242][  200/  500]    Overall Loss 1.200209    Objective Loss 1.200209                                        LR 0.000125    Time 0.045661    
2024-04-05 16:44:46,707 - Epoch: [242][  300/  500]    Overall Loss 1.195293    Objective Loss 1.195293                                        LR 0.000125    Time 0.044697    
2024-04-05 16:44:51,110 - Epoch: [242][  400/  500]    Overall Loss 1.203816    Objective Loss 1.203816                                        LR 0.000125    Time 0.044523    
2024-04-05 16:44:55,502 - Epoch: [242][  500/  500]    Overall Loss 1.202088    Objective Loss 1.202088    Top1 69.500000    Top5 91.500000    LR 0.000125    Time 0.044395    
2024-04-05 16:44:55,629 - --- validate (epoch=242)-----------
2024-04-05 16:44:55,630 - 10000 samples (100 per mini-batch)
2024-04-05 16:44:58,260 - Epoch: [242][  100/  100]    Loss 1.710001    Top1 55.900000    Top5 83.440000    
2024-04-05 16:44:58,385 - ==> Top1: 55.900    Top5: 83.440    Loss: 1.710

2024-04-05 16:44:58,391 - ==> Best [Top1: 56.010   Top5: 83.410   Sparsity:0.00   Params: 314624 on epoch: 231]
2024-04-05 16:44:58,392 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:44:58,421 - 

2024-04-05 16:44:58,421 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:45:03,334 - Epoch: [243][  100/  500]    Overall Loss 1.182967    Objective Loss 1.182967                                        LR 0.000125    Time 0.049095    
2024-04-05 16:45:07,611 - Epoch: [243][  200/  500]    Overall Loss 1.174635    Objective Loss 1.174635                                        LR 0.000125    Time 0.045916    
2024-04-05 16:45:11,896 - Epoch: [243][  300/  500]    Overall Loss 1.184024    Objective Loss 1.184024                                        LR 0.000125    Time 0.044885    
2024-04-05 16:45:16,259 - Epoch: [243][  400/  500]    Overall Loss 1.187312    Objective Loss 1.187312                                        LR 0.000125    Time 0.044562    
2024-04-05 16:45:20,651 - Epoch: [243][  500/  500]    Overall Loss 1.184341    Objective Loss 1.184341    Top1 70.500000    Top5 93.500000    LR 0.000125    Time 0.044428    
2024-04-05 16:45:20,819 - --- validate (epoch=243)-----------
2024-04-05 16:45:20,819 - 10000 samples (100 per mini-batch)
2024-04-05 16:45:23,167 - Epoch: [243][  100/  100]    Loss 1.702595    Top1 56.030000    Top5 83.510000    
2024-04-05 16:45:23,356 - ==> Top1: 56.030    Top5: 83.510    Loss: 1.703

2024-04-05 16:45:23,362 - ==> Best [Top1: 56.030   Top5: 83.510   Sparsity:0.00   Params: 314624 on epoch: 243]
2024-04-05 16:45:23,362 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:45:23,398 - 

2024-04-05 16:45:23,399 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:45:28,527 - Epoch: [244][  100/  500]    Overall Loss 1.164000    Objective Loss 1.164000                                        LR 0.000125    Time 0.051242    
2024-04-05 16:45:32,773 - Epoch: [244][  200/  500]    Overall Loss 1.170786    Objective Loss 1.170786                                        LR 0.000125    Time 0.046834    
2024-04-05 16:45:37,165 - Epoch: [244][  300/  500]    Overall Loss 1.172248    Objective Loss 1.172248                                        LR 0.000125    Time 0.045854    
2024-04-05 16:45:41,586 - Epoch: [244][  400/  500]    Overall Loss 1.173104    Objective Loss 1.173104                                        LR 0.000125    Time 0.045436    
2024-04-05 16:45:46,087 - Epoch: [244][  500/  500]    Overall Loss 1.177092    Objective Loss 1.177092    Top1 74.000000    Top5 94.500000    LR 0.000125    Time 0.045344    
2024-04-05 16:45:46,360 - --- validate (epoch=244)-----------
2024-04-05 16:45:46,360 - 10000 samples (100 per mini-batch)
2024-04-05 16:45:48,719 - Epoch: [244][  100/  100]    Loss 1.697958    Top1 55.880000    Top5 83.500000    
2024-04-05 16:45:48,848 - ==> Top1: 55.880    Top5: 83.500    Loss: 1.698

2024-04-05 16:45:48,854 - ==> Best [Top1: 56.030   Top5: 83.510   Sparsity:0.00   Params: 314624 on epoch: 243]
2024-04-05 16:45:48,854 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:45:48,883 - 

2024-04-05 16:45:48,884 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:45:53,411 - Epoch: [245][  100/  500]    Overall Loss 1.148389    Objective Loss 1.148389                                        LR 0.000125    Time 0.045239    
2024-04-05 16:45:57,433 - Epoch: [245][  200/  500]    Overall Loss 1.162551    Objective Loss 1.162551                                        LR 0.000125    Time 0.042713    
2024-04-05 16:46:01,853 - Epoch: [245][  300/  500]    Overall Loss 1.164096    Objective Loss 1.164096                                        LR 0.000125    Time 0.043199    
2024-04-05 16:46:06,277 - Epoch: [245][  400/  500]    Overall Loss 1.168766    Objective Loss 1.168766                                        LR 0.000125    Time 0.043451    
2024-04-05 16:46:10,696 - Epoch: [245][  500/  500]    Overall Loss 1.167951    Objective Loss 1.167951    Top1 77.500000    Top5 97.500000    LR 0.000125    Time 0.043592    
2024-04-05 16:46:10,862 - --- validate (epoch=245)-----------
2024-04-05 16:46:10,863 - 10000 samples (100 per mini-batch)
2024-04-05 16:46:13,226 - Epoch: [245][  100/  100]    Loss 1.693114    Top1 55.880000    Top5 83.350000    
2024-04-05 16:46:13,414 - ==> Top1: 55.880    Top5: 83.350    Loss: 1.693

2024-04-05 16:46:13,420 - ==> Best [Top1: 56.030   Top5: 83.510   Sparsity:0.00   Params: 314624 on epoch: 243]
2024-04-05 16:46:13,420 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:46:13,449 - 

2024-04-05 16:46:13,449 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:46:18,420 - Epoch: [246][  100/  500]    Overall Loss 1.161847    Objective Loss 1.161847                                        LR 0.000125    Time 0.049664    
2024-04-05 16:46:22,634 - Epoch: [246][  200/  500]    Overall Loss 1.157009    Objective Loss 1.157009                                        LR 0.000125    Time 0.045887    
2024-04-05 16:46:27,064 - Epoch: [246][  300/  500]    Overall Loss 1.158242    Objective Loss 1.158242                                        LR 0.000125    Time 0.045350    
2024-04-05 16:46:31,459 - Epoch: [246][  400/  500]    Overall Loss 1.158914    Objective Loss 1.158914                                        LR 0.000125    Time 0.044991    
2024-04-05 16:46:35,908 - Epoch: [246][  500/  500]    Overall Loss 1.157537    Objective Loss 1.157537    Top1 69.000000    Top5 94.000000    LR 0.000125    Time 0.044885    
2024-04-05 16:46:36,091 - --- validate (epoch=246)-----------
2024-04-05 16:46:36,092 - 10000 samples (100 per mini-batch)
2024-04-05 16:46:38,452 - Epoch: [246][  100/  100]    Loss 1.681502    Top1 56.130000    Top5 83.780000    
2024-04-05 16:46:38,601 - ==> Top1: 56.130    Top5: 83.780    Loss: 1.682

2024-04-05 16:46:38,607 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:46:38,607 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:46:38,642 - 

2024-04-05 16:46:38,642 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:46:43,852 - Epoch: [247][  100/  500]    Overall Loss 1.129001    Objective Loss 1.129001                                        LR 0.000125    Time 0.052058    
2024-04-05 16:46:47,935 - Epoch: [247][  200/  500]    Overall Loss 1.125544    Objective Loss 1.125544                                        LR 0.000125    Time 0.046431    
2024-04-05 16:46:52,394 - Epoch: [247][  300/  500]    Overall Loss 1.133645    Objective Loss 1.133645                                        LR 0.000125    Time 0.045807    
2024-04-05 16:46:56,845 - Epoch: [247][  400/  500]    Overall Loss 1.139160    Objective Loss 1.139160                                        LR 0.000125    Time 0.045475    
2024-04-05 16:47:01,278 - Epoch: [247][  500/  500]    Overall Loss 1.142862    Objective Loss 1.142862    Top1 75.000000    Top5 96.000000    LR 0.000125    Time 0.045239    
2024-04-05 16:47:01,433 - --- validate (epoch=247)-----------
2024-04-05 16:47:01,433 - 10000 samples (100 per mini-batch)
2024-04-05 16:47:03,864 - Epoch: [247][  100/  100]    Loss 1.707768    Top1 55.510000    Top5 83.220000    
2024-04-05 16:47:03,996 - ==> Top1: 55.510    Top5: 83.220    Loss: 1.708

2024-04-05 16:47:04,001 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:47:04,001 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:47:04,030 - 

2024-04-05 16:47:04,030 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:47:09,203 - Epoch: [248][  100/  500]    Overall Loss 1.103192    Objective Loss 1.103192                                        LR 0.000125    Time 0.051694    
2024-04-05 16:47:13,326 - Epoch: [248][  200/  500]    Overall Loss 1.124155    Objective Loss 1.124155                                        LR 0.000125    Time 0.046448    
2024-04-05 16:47:17,836 - Epoch: [248][  300/  500]    Overall Loss 1.131208    Objective Loss 1.131208                                        LR 0.000125    Time 0.045988    
2024-04-05 16:47:22,301 - Epoch: [248][  400/  500]    Overall Loss 1.134492    Objective Loss 1.134492                                        LR 0.000125    Time 0.045644    
2024-04-05 16:47:26,795 - Epoch: [248][  500/  500]    Overall Loss 1.137910    Objective Loss 1.137910    Top1 72.000000    Top5 97.500000    LR 0.000125    Time 0.045498    
2024-04-05 16:47:26,999 - --- validate (epoch=248)-----------
2024-04-05 16:47:26,999 - 10000 samples (100 per mini-batch)
2024-04-05 16:47:29,424 - Epoch: [248][  100/  100]    Loss 1.700172    Top1 55.290000    Top5 83.240000    
2024-04-05 16:47:29,553 - ==> Top1: 55.290    Top5: 83.240    Loss: 1.700

2024-04-05 16:47:29,559 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:47:29,560 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:47:29,590 - 

2024-04-05 16:47:29,591 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:47:34,384 - Epoch: [249][  100/  500]    Overall Loss 1.110728    Objective Loss 1.110728                                        LR 0.000125    Time 0.047888    
2024-04-05 16:47:38,442 - Epoch: [249][  200/  500]    Overall Loss 1.122890    Objective Loss 1.122890                                        LR 0.000125    Time 0.044219    
2024-04-05 16:47:42,919 - Epoch: [249][  300/  500]    Overall Loss 1.121132    Objective Loss 1.121132                                        LR 0.000125    Time 0.044393    
2024-04-05 16:47:47,416 - Epoch: [249][  400/  500]    Overall Loss 1.121627    Objective Loss 1.121627                                        LR 0.000125    Time 0.044528    
2024-04-05 16:47:51,894 - Epoch: [249][  500/  500]    Overall Loss 1.124916    Objective Loss 1.124916    Top1 73.500000    Top5 95.500000    LR 0.000125    Time 0.044573    
2024-04-05 16:47:52,050 - --- validate (epoch=249)-----------
2024-04-05 16:47:52,051 - 10000 samples (100 per mini-batch)
2024-04-05 16:47:54,620 - Epoch: [249][  100/  100]    Loss 1.684133    Top1 55.850000    Top5 83.340000    
2024-04-05 16:47:54,850 - ==> Top1: 55.850    Top5: 83.340    Loss: 1.684

2024-04-05 16:47:54,856 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:47:54,857 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:47:54,886 - 

2024-04-05 16:47:54,886 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:48:00,075 - Epoch: [250][  100/  500]    Overall Loss 1.098964    Objective Loss 1.098964                                        LR 0.000125    Time 0.051855    
2024-04-05 16:48:04,516 - Epoch: [250][  200/  500]    Overall Loss 1.112566    Objective Loss 1.112566                                        LR 0.000125    Time 0.048118    
2024-04-05 16:48:08,969 - Epoch: [250][  300/  500]    Overall Loss 1.114530    Objective Loss 1.114530                                        LR 0.000125    Time 0.046912    
2024-04-05 16:48:13,409 - Epoch: [250][  400/  500]    Overall Loss 1.115890    Objective Loss 1.115890                                        LR 0.000125    Time 0.046275    
2024-04-05 16:48:17,888 - Epoch: [250][  500/  500]    Overall Loss 1.117033    Objective Loss 1.117033    Top1 71.000000    Top5 93.500000    LR 0.000125    Time 0.045972    
2024-04-05 16:48:18,061 - --- validate (epoch=250)-----------
2024-04-05 16:48:18,061 - 10000 samples (100 per mini-batch)
2024-04-05 16:48:20,467 - Epoch: [250][  100/  100]    Loss 1.696122    Top1 55.490000    Top5 82.910000    
2024-04-05 16:48:20,650 - ==> Top1: 55.490    Top5: 82.910    Loss: 1.696

2024-04-05 16:48:20,656 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:48:20,656 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:48:20,685 - 

2024-04-05 16:48:20,685 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:48:25,614 - Epoch: [251][  100/  500]    Overall Loss 1.089619    Objective Loss 1.089619                                        LR 0.000125    Time 0.049250    
2024-04-05 16:48:30,009 - Epoch: [251][  200/  500]    Overall Loss 1.117214    Objective Loss 1.117214                                        LR 0.000125    Time 0.046583    
2024-04-05 16:48:34,470 - Epoch: [251][  300/  500]    Overall Loss 1.118809    Objective Loss 1.118809                                        LR 0.000125    Time 0.045915    
2024-04-05 16:48:38,905 - Epoch: [251][  400/  500]    Overall Loss 1.115853    Objective Loss 1.115853                                        LR 0.000125    Time 0.045514    
2024-04-05 16:48:43,317 - Epoch: [251][  500/  500]    Overall Loss 1.123796    Objective Loss 1.123796    Top1 78.000000    Top5 97.000000    LR 0.000125    Time 0.045230    
2024-04-05 16:48:43,517 - --- validate (epoch=251)-----------
2024-04-05 16:48:43,517 - 10000 samples (100 per mini-batch)
2024-04-05 16:48:45,907 - Epoch: [251][  100/  100]    Loss 1.680680    Top1 55.580000    Top5 83.470000    
2024-04-05 16:48:46,103 - ==> Top1: 55.580    Top5: 83.470    Loss: 1.681

2024-04-05 16:48:46,108 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:48:46,108 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:48:46,136 - 

2024-04-05 16:48:46,136 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:48:51,090 - Epoch: [252][  100/  500]    Overall Loss 1.098418    Objective Loss 1.098418                                        LR 0.000125    Time 0.049500    
2024-04-05 16:48:55,477 - Epoch: [252][  200/  500]    Overall Loss 1.091856    Objective Loss 1.091856                                        LR 0.000125    Time 0.046668    
2024-04-05 16:48:59,920 - Epoch: [252][  300/  500]    Overall Loss 1.096285    Objective Loss 1.096285                                        LR 0.000125    Time 0.045911    
2024-04-05 16:49:04,387 - Epoch: [252][  400/  500]    Overall Loss 1.098022    Objective Loss 1.098022                                        LR 0.000125    Time 0.045594    
2024-04-05 16:49:08,828 - Epoch: [252][  500/  500]    Overall Loss 1.100735    Objective Loss 1.100735    Top1 72.500000    Top5 93.500000    LR 0.000125    Time 0.045350    
2024-04-05 16:49:09,007 - --- validate (epoch=252)-----------
2024-04-05 16:49:09,008 - 10000 samples (100 per mini-batch)
2024-04-05 16:49:11,360 - Epoch: [252][  100/  100]    Loss 1.681586    Top1 55.690000    Top5 83.570000    
2024-04-05 16:49:11,510 - ==> Top1: 55.690    Top5: 83.570    Loss: 1.682

2024-04-05 16:49:11,513 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:49:11,514 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:49:11,534 - 

2024-04-05 16:49:11,535 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:49:16,651 - Epoch: [253][  100/  500]    Overall Loss 1.153728    Objective Loss 1.153728                                        LR 0.000125    Time 0.051127    
2024-04-05 16:49:21,121 - Epoch: [253][  200/  500]    Overall Loss 1.175998    Objective Loss 1.175998                                        LR 0.000125    Time 0.047893    
2024-04-05 16:49:25,521 - Epoch: [253][  300/  500]    Overall Loss 1.188131    Objective Loss 1.188131                                        LR 0.000125    Time 0.046587    
2024-04-05 16:49:29,933 - Epoch: [253][  400/  500]    Overall Loss 1.172482    Objective Loss 1.172482                                        LR 0.000125    Time 0.045962    
2024-04-05 16:49:34,400 - Epoch: [253][  500/  500]    Overall Loss 1.160660    Objective Loss 1.160660    Top1 65.000000    Top5 91.000000    LR 0.000125    Time 0.045696    
2024-04-05 16:49:34,566 - --- validate (epoch=253)-----------
2024-04-05 16:49:34,567 - 10000 samples (100 per mini-batch)
2024-04-05 16:49:36,896 - Epoch: [253][  100/  100]    Loss 1.687864    Top1 55.440000    Top5 83.290000    
2024-04-05 16:49:37,017 - ==> Top1: 55.440    Top5: 83.290    Loss: 1.688

2024-04-05 16:49:37,022 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:49:37,022 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:49:37,052 - 

2024-04-05 16:49:37,052 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:49:42,205 - Epoch: [254][  100/  500]    Overall Loss 1.081002    Objective Loss 1.081002                                        LR 0.000125    Time 0.051486    
2024-04-05 16:49:46,654 - Epoch: [254][  200/  500]    Overall Loss 1.087098    Objective Loss 1.087098                                        LR 0.000125    Time 0.047968    
2024-04-05 16:49:51,108 - Epoch: [254][  300/  500]    Overall Loss 1.085843    Objective Loss 1.085843                                        LR 0.000125    Time 0.046817    
2024-04-05 16:49:55,554 - Epoch: [254][  400/  500]    Overall Loss 1.088294    Objective Loss 1.088294                                        LR 0.000125    Time 0.046220    
2024-04-05 16:49:59,962 - Epoch: [254][  500/  500]    Overall Loss 1.093416    Objective Loss 1.093416    Top1 74.000000    Top5 95.000000    LR 0.000125    Time 0.045786    
2024-04-05 16:50:00,197 - --- validate (epoch=254)-----------
2024-04-05 16:50:00,197 - 10000 samples (100 per mini-batch)
2024-04-05 16:50:02,702 - Epoch: [254][  100/  100]    Loss 1.680008    Top1 56.100000    Top5 83.140000    
2024-04-05 16:50:02,815 - ==> Top1: 56.100    Top5: 83.140    Loss: 1.680

2024-04-05 16:50:02,820 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:50:02,820 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:50:02,848 - 

2024-04-05 16:50:02,848 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:50:07,314 - Epoch: [255][  100/  500]    Overall Loss 1.066236    Objective Loss 1.066236                                        LR 0.000125    Time 0.044618    
2024-04-05 16:50:11,580 - Epoch: [255][  200/  500]    Overall Loss 1.074621    Objective Loss 1.074621                                        LR 0.000125    Time 0.043628    
2024-04-05 16:50:16,055 - Epoch: [255][  300/  500]    Overall Loss 1.084185    Objective Loss 1.084185                                        LR 0.000125    Time 0.043990    
2024-04-05 16:50:20,511 - Epoch: [255][  400/  500]    Overall Loss 1.079897    Objective Loss 1.079897                                        LR 0.000125    Time 0.044124    
2024-04-05 16:50:24,938 - Epoch: [255][  500/  500]    Overall Loss 1.085004    Objective Loss 1.085004    Top1 71.000000    Top5 95.500000    LR 0.000125    Time 0.044148    
2024-04-05 16:50:25,079 - --- validate (epoch=255)-----------
2024-04-05 16:50:25,079 - 10000 samples (100 per mini-batch)
2024-04-05 16:50:27,502 - Epoch: [255][  100/  100]    Loss 1.675973    Top1 55.860000    Top5 83.210000    
2024-04-05 16:50:27,702 - ==> Top1: 55.860    Top5: 83.210    Loss: 1.676

2024-04-05 16:50:27,708 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:50:27,709 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:50:27,738 - 

2024-04-05 16:50:27,738 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:50:32,645 - Epoch: [256][  100/  500]    Overall Loss 1.067448    Objective Loss 1.067448                                        LR 0.000125    Time 0.049032    
2024-04-05 16:50:37,094 - Epoch: [256][  200/  500]    Overall Loss 1.067765    Objective Loss 1.067765                                        LR 0.000125    Time 0.046744    
2024-04-05 16:50:41,566 - Epoch: [256][  300/  500]    Overall Loss 1.073182    Objective Loss 1.073182                                        LR 0.000125    Time 0.046061    
2024-04-05 16:50:46,017 - Epoch: [256][  400/  500]    Overall Loss 1.074894    Objective Loss 1.074894                                        LR 0.000125    Time 0.045664    
2024-04-05 16:50:50,482 - Epoch: [256][  500/  500]    Overall Loss 1.075986    Objective Loss 1.075986    Top1 76.500000    Top5 93.000000    LR 0.000125    Time 0.045453    
2024-04-05 16:50:50,653 - --- validate (epoch=256)-----------
2024-04-05 16:50:50,654 - 10000 samples (100 per mini-batch)
2024-04-05 16:50:53,299 - Epoch: [256][  100/  100]    Loss 1.680534    Top1 56.060000    Top5 83.310000    
2024-04-05 16:50:53,468 - ==> Top1: 56.060    Top5: 83.310    Loss: 1.681

2024-04-05 16:50:53,473 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:50:53,474 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:50:53,502 - 

2024-04-05 16:50:53,502 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:50:58,380 - Epoch: [257][  100/  500]    Overall Loss 1.061007    Objective Loss 1.061007                                        LR 0.000125    Time 0.048743    
2024-04-05 16:51:02,818 - Epoch: [257][  200/  500]    Overall Loss 1.058571    Objective Loss 1.058571                                        LR 0.000125    Time 0.046542    
2024-04-05 16:51:07,244 - Epoch: [257][  300/  500]    Overall Loss 1.060379    Objective Loss 1.060379                                        LR 0.000125    Time 0.045773    
2024-04-05 16:51:11,678 - Epoch: [257][  400/  500]    Overall Loss 1.064732    Objective Loss 1.064732                                        LR 0.000125    Time 0.045405    
2024-04-05 16:51:16,164 - Epoch: [257][  500/  500]    Overall Loss 1.065468    Objective Loss 1.065468    Top1 79.500000    Top5 95.000000    LR 0.000125    Time 0.045290    
2024-04-05 16:51:16,305 - --- validate (epoch=257)-----------
2024-04-05 16:51:16,306 - 10000 samples (100 per mini-batch)
2024-04-05 16:51:18,714 - Epoch: [257][  100/  100]    Loss 1.666542    Top1 55.980000    Top5 83.560000    
2024-04-05 16:51:18,907 - ==> Top1: 55.980    Top5: 83.560    Loss: 1.667

2024-04-05 16:51:18,914 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:51:18,914 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:51:18,944 - 

2024-04-05 16:51:18,945 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:51:23,872 - Epoch: [258][  100/  500]    Overall Loss 1.056708    Objective Loss 1.056708                                        LR 0.000125    Time 0.049239    
2024-04-05 16:51:28,300 - Epoch: [258][  200/  500]    Overall Loss 1.057167    Objective Loss 1.057167                                        LR 0.000125    Time 0.046741    
2024-04-05 16:51:32,732 - Epoch: [258][  300/  500]    Overall Loss 1.061489    Objective Loss 1.061489                                        LR 0.000125    Time 0.045925    
2024-04-05 16:51:37,163 - Epoch: [258][  400/  500]    Overall Loss 1.062026    Objective Loss 1.062026                                        LR 0.000125    Time 0.045512    
2024-04-05 16:51:41,611 - Epoch: [258][  500/  500]    Overall Loss 1.067685    Objective Loss 1.067685    Top1 72.000000    Top5 96.500000    LR 0.000125    Time 0.045299    
2024-04-05 16:51:41,748 - --- validate (epoch=258)-----------
2024-04-05 16:51:41,748 - 10000 samples (100 per mini-batch)
2024-04-05 16:51:44,198 - Epoch: [258][  100/  100]    Loss 1.663901    Top1 55.920000    Top5 83.600000    
2024-04-05 16:51:44,333 - ==> Top1: 55.920    Top5: 83.600    Loss: 1.664

2024-04-05 16:51:44,339 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:51:44,340 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:51:44,368 - 

2024-04-05 16:51:44,369 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:51:49,485 - Epoch: [259][  100/  500]    Overall Loss 1.042479    Objective Loss 1.042479                                        LR 0.000125    Time 0.051122    
2024-04-05 16:51:53,931 - Epoch: [259][  200/  500]    Overall Loss 1.058572    Objective Loss 1.058572                                        LR 0.000125    Time 0.047778    
2024-04-05 16:51:58,346 - Epoch: [259][  300/  500]    Overall Loss 1.054553    Objective Loss 1.054553                                        LR 0.000125    Time 0.046558    
2024-04-05 16:52:02,759 - Epoch: [259][  400/  500]    Overall Loss 1.055600    Objective Loss 1.055600                                        LR 0.000125    Time 0.045944    
2024-04-05 16:52:07,218 - Epoch: [259][  500/  500]    Overall Loss 1.058395    Objective Loss 1.058395    Top1 75.000000    Top5 94.500000    LR 0.000125    Time 0.045666    
2024-04-05 16:52:07,413 - --- validate (epoch=259)-----------
2024-04-05 16:52:07,414 - 10000 samples (100 per mini-batch)
2024-04-05 16:52:09,855 - Epoch: [259][  100/  100]    Loss 1.671411    Top1 56.030000    Top5 83.290000    
2024-04-05 16:52:10,005 - ==> Top1: 56.030    Top5: 83.290    Loss: 1.671

2024-04-05 16:52:10,010 - ==> Best [Top1: 56.130   Top5: 83.780   Sparsity:0.00   Params: 314624 on epoch: 246]
2024-04-05 16:52:10,010 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:52:10,040 - 

2024-04-05 16:52:10,040 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:52:15,175 - Epoch: [260][  100/  500]    Overall Loss 1.034080    Objective Loss 1.034080                                        LR 0.000125    Time 0.051309    
2024-04-05 16:52:19,550 - Epoch: [260][  200/  500]    Overall Loss 1.043627    Objective Loss 1.043627                                        LR 0.000125    Time 0.047513    
2024-04-05 16:52:23,969 - Epoch: [260][  300/  500]    Overall Loss 1.046441    Objective Loss 1.046441                                        LR 0.000125    Time 0.046395    
2024-04-05 16:52:28,350 - Epoch: [260][  400/  500]    Overall Loss 1.050630    Objective Loss 1.050630                                        LR 0.000125    Time 0.045743    
2024-04-05 16:52:32,742 - Epoch: [260][  500/  500]    Overall Loss 1.050658    Objective Loss 1.050658    Top1 73.500000    Top5 97.000000    LR 0.000125    Time 0.045372    
2024-04-05 16:52:32,893 - --- validate (epoch=260)-----------
2024-04-05 16:52:32,894 - 10000 samples (100 per mini-batch)
2024-04-05 16:52:35,285 - Epoch: [260][  100/  100]    Loss 1.665074    Top1 56.190000    Top5 83.400000    
2024-04-05 16:52:35,397 - ==> Top1: 56.190    Top5: 83.400    Loss: 1.665

2024-04-05 16:52:35,403 - ==> Best [Top1: 56.190   Top5: 83.400   Sparsity:0.00   Params: 314624 on epoch: 260]
2024-04-05 16:52:35,403 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:52:35,438 - 

2024-04-05 16:52:35,439 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:52:40,364 - Epoch: [261][  100/  500]    Overall Loss 1.059550    Objective Loss 1.059550                                        LR 0.000125    Time 0.049219    
2024-04-05 16:52:44,770 - Epoch: [261][  200/  500]    Overall Loss 1.045067    Objective Loss 1.045067                                        LR 0.000125    Time 0.046624    
2024-04-05 16:52:49,211 - Epoch: [261][  300/  500]    Overall Loss 1.041524    Objective Loss 1.041524                                        LR 0.000125    Time 0.045877    
2024-04-05 16:52:53,657 - Epoch: [261][  400/  500]    Overall Loss 1.042901    Objective Loss 1.042901                                        LR 0.000125    Time 0.045515    
2024-04-05 16:52:58,068 - Epoch: [261][  500/  500]    Overall Loss 1.045127    Objective Loss 1.045127    Top1 69.000000    Top5 93.000000    LR 0.000125    Time 0.045227    
2024-04-05 16:52:58,213 - --- validate (epoch=261)-----------
2024-04-05 16:52:58,214 - 10000 samples (100 per mini-batch)
2024-04-05 16:53:00,516 - Epoch: [261][  100/  100]    Loss 1.666192    Top1 55.630000    Top5 83.260000    
2024-04-05 16:53:00,605 - ==> Top1: 55.630    Top5: 83.260    Loss: 1.666

2024-04-05 16:53:00,610 - ==> Best [Top1: 56.190   Top5: 83.400   Sparsity:0.00   Params: 314624 on epoch: 260]
2024-04-05 16:53:00,610 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:53:00,637 - 

2024-04-05 16:53:00,637 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:53:05,531 - Epoch: [262][  100/  500]    Overall Loss 1.043761    Objective Loss 1.043761                                        LR 0.000125    Time 0.048907    
2024-04-05 16:53:09,968 - Epoch: [262][  200/  500]    Overall Loss 1.036363    Objective Loss 1.036363                                        LR 0.000125    Time 0.046621    
2024-04-05 16:53:14,377 - Epoch: [262][  300/  500]    Overall Loss 1.039079    Objective Loss 1.039079                                        LR 0.000125    Time 0.045766    
2024-04-05 16:53:18,787 - Epoch: [262][  400/  500]    Overall Loss 1.039386    Objective Loss 1.039386                                        LR 0.000125    Time 0.045340    
2024-04-05 16:53:23,167 - Epoch: [262][  500/  500]    Overall Loss 1.041147    Objective Loss 1.041147    Top1 73.000000    Top5 94.500000    LR 0.000125    Time 0.045026    
2024-04-05 16:53:23,306 - --- validate (epoch=262)-----------
2024-04-05 16:53:23,307 - 10000 samples (100 per mini-batch)
2024-04-05 16:53:25,789 - Epoch: [262][  100/  100]    Loss 1.666956    Top1 56.070000    Top5 83.470000    
2024-04-05 16:53:25,898 - ==> Top1: 56.070    Top5: 83.470    Loss: 1.667

2024-04-05 16:53:25,904 - ==> Best [Top1: 56.190   Top5: 83.400   Sparsity:0.00   Params: 314624 on epoch: 260]
2024-04-05 16:53:25,904 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:53:25,933 - 

2024-04-05 16:53:25,934 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:53:30,853 - Epoch: [263][  100/  500]    Overall Loss 1.018261    Objective Loss 1.018261                                        LR 0.000125    Time 0.049159    
2024-04-05 16:53:35,253 - Epoch: [263][  200/  500]    Overall Loss 1.024578    Objective Loss 1.024578                                        LR 0.000125    Time 0.046564    
2024-04-05 16:53:39,698 - Epoch: [263][  300/  500]    Overall Loss 1.023923    Objective Loss 1.023923                                        LR 0.000125    Time 0.045847    
2024-04-05 16:53:44,149 - Epoch: [263][  400/  500]    Overall Loss 1.031118    Objective Loss 1.031118                                        LR 0.000125    Time 0.045506    
2024-04-05 16:53:48,584 - Epoch: [263][  500/  500]    Overall Loss 1.029639    Objective Loss 1.029639    Top1 82.000000    Top5 97.000000    LR 0.000125    Time 0.045267    
2024-04-05 16:53:48,748 - --- validate (epoch=263)-----------
2024-04-05 16:53:48,749 - 10000 samples (100 per mini-batch)
2024-04-05 16:53:51,189 - Epoch: [263][  100/  100]    Loss 1.675273    Top1 55.400000    Top5 83.100000    
2024-04-05 16:53:51,375 - ==> Top1: 55.400    Top5: 83.100    Loss: 1.675

2024-04-05 16:53:51,380 - ==> Best [Top1: 56.190   Top5: 83.400   Sparsity:0.00   Params: 314624 on epoch: 260]
2024-04-05 16:53:51,380 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:53:51,409 - 

2024-04-05 16:53:51,410 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:53:56,293 - Epoch: [264][  100/  500]    Overall Loss 1.025422    Objective Loss 1.025422                                        LR 0.000125    Time 0.048792    
2024-04-05 16:54:00,721 - Epoch: [264][  200/  500]    Overall Loss 1.011159    Objective Loss 1.011159                                        LR 0.000125    Time 0.046523    
2024-04-05 16:54:05,143 - Epoch: [264][  300/  500]    Overall Loss 1.024999    Objective Loss 1.024999                                        LR 0.000125    Time 0.045743    
2024-04-05 16:54:09,571 - Epoch: [264][  400/  500]    Overall Loss 1.027072    Objective Loss 1.027072                                        LR 0.000125    Time 0.045369    
2024-04-05 16:54:13,968 - Epoch: [264][  500/  500]    Overall Loss 1.029177    Objective Loss 1.029177    Top1 72.500000    Top5 94.500000    LR 0.000125    Time 0.045084    
2024-04-05 16:54:14,123 - --- validate (epoch=264)-----------
2024-04-05 16:54:14,123 - 10000 samples (100 per mini-batch)
2024-04-05 16:54:16,523 - Epoch: [264][  100/  100]    Loss 1.662881    Top1 56.030000    Top5 83.160000    
2024-04-05 16:54:16,723 - ==> Top1: 56.030    Top5: 83.160    Loss: 1.663

2024-04-05 16:54:16,730 - ==> Best [Top1: 56.190   Top5: 83.400   Sparsity:0.00   Params: 314624 on epoch: 260]
2024-04-05 16:54:16,730 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:54:16,759 - 

2024-04-05 16:54:16,760 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:54:21,887 - Epoch: [265][  100/  500]    Overall Loss 1.016931    Objective Loss 1.016931                                        LR 0.000125    Time 0.051233    
2024-04-05 16:54:26,306 - Epoch: [265][  200/  500]    Overall Loss 1.022056    Objective Loss 1.022056                                        LR 0.000125    Time 0.047696    
2024-04-05 16:54:30,749 - Epoch: [265][  300/  500]    Overall Loss 1.018501    Objective Loss 1.018501                                        LR 0.000125    Time 0.046596    
2024-04-05 16:54:35,161 - Epoch: [265][  400/  500]    Overall Loss 1.018624    Objective Loss 1.018624                                        LR 0.000125    Time 0.045971    
2024-04-05 16:54:39,596 - Epoch: [265][  500/  500]    Overall Loss 1.020219    Objective Loss 1.020219    Top1 76.500000    Top5 94.500000    LR 0.000125    Time 0.045640    
2024-04-05 16:54:39,757 - --- validate (epoch=265)-----------
2024-04-05 16:54:39,758 - 10000 samples (100 per mini-batch)
2024-04-05 16:54:42,115 - Epoch: [265][  100/  100]    Loss 1.666702    Top1 55.700000    Top5 83.400000    
2024-04-05 16:54:42,210 - ==> Top1: 55.700    Top5: 83.400    Loss: 1.667

2024-04-05 16:54:42,215 - ==> Best [Top1: 56.190   Top5: 83.400   Sparsity:0.00   Params: 314624 on epoch: 260]
2024-04-05 16:54:42,216 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:54:42,243 - 

2024-04-05 16:54:42,243 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:54:46,965 - Epoch: [266][  100/  500]    Overall Loss 0.996558    Objective Loss 0.996558                                        LR 0.000125    Time 0.047188    
2024-04-05 16:54:51,443 - Epoch: [266][  200/  500]    Overall Loss 0.998647    Objective Loss 0.998647                                        LR 0.000125    Time 0.045964    
2024-04-05 16:54:55,863 - Epoch: [266][  300/  500]    Overall Loss 1.003504    Objective Loss 1.003504                                        LR 0.000125    Time 0.045368    
2024-04-05 16:55:00,261 - Epoch: [266][  400/  500]    Overall Loss 1.011645    Objective Loss 1.011645                                        LR 0.000125    Time 0.045011    
2024-04-05 16:55:04,660 - Epoch: [266][  500/  500]    Overall Loss 1.013322    Objective Loss 1.013322    Top1 70.000000    Top5 93.500000    LR 0.000125    Time 0.044802    
2024-04-05 16:55:04,827 - --- validate (epoch=266)-----------
2024-04-05 16:55:04,828 - 10000 samples (100 per mini-batch)
2024-04-05 16:55:07,460 - Epoch: [266][  100/  100]    Loss 1.663085    Top1 55.980000    Top5 83.250000    
2024-04-05 16:55:07,625 - ==> Top1: 55.980    Top5: 83.250    Loss: 1.663

2024-04-05 16:55:07,630 - ==> Best [Top1: 56.190   Top5: 83.400   Sparsity:0.00   Params: 314624 on epoch: 260]
2024-04-05 16:55:07,630 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:55:07,659 - 

2024-04-05 16:55:07,660 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:55:12,620 - Epoch: [267][  100/  500]    Overall Loss 0.993257    Objective Loss 0.993257                                        LR 0.000125    Time 0.049562    
2024-04-05 16:55:17,041 - Epoch: [267][  200/  500]    Overall Loss 0.998396    Objective Loss 0.998396                                        LR 0.000125    Time 0.046874    
2024-04-05 16:55:21,483 - Epoch: [267][  300/  500]    Overall Loss 1.011797    Objective Loss 1.011797                                        LR 0.000125    Time 0.046044    
2024-04-05 16:55:25,899 - Epoch: [267][  400/  500]    Overall Loss 1.010839    Objective Loss 1.010839                                        LR 0.000125    Time 0.045565    
2024-04-05 16:55:30,313 - Epoch: [267][  500/  500]    Overall Loss 1.009356    Objective Loss 1.009356    Top1 74.500000    Top5 96.500000    LR 0.000125    Time 0.045274    
2024-04-05 16:55:30,468 - --- validate (epoch=267)-----------
2024-04-05 16:55:30,469 - 10000 samples (100 per mini-batch)
2024-04-05 16:55:32,887 - Epoch: [267][  100/  100]    Loss 1.656883    Top1 55.930000    Top5 83.270000    
2024-04-05 16:55:33,096 - ==> Top1: 55.930    Top5: 83.270    Loss: 1.657

2024-04-05 16:55:33,101 - ==> Best [Top1: 56.190   Top5: 83.400   Sparsity:0.00   Params: 314624 on epoch: 260]
2024-04-05 16:55:33,101 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:55:33,130 - 

2024-04-05 16:55:33,131 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:55:38,219 - Epoch: [268][  100/  500]    Overall Loss 0.981401    Objective Loss 0.981401                                        LR 0.000125    Time 0.050846    
2024-04-05 16:55:42,659 - Epoch: [268][  200/  500]    Overall Loss 0.996716    Objective Loss 0.996716                                        LR 0.000125    Time 0.047606    
2024-04-05 16:55:47,076 - Epoch: [268][  300/  500]    Overall Loss 1.004707    Objective Loss 1.004707                                        LR 0.000125    Time 0.046450    
2024-04-05 16:55:51,501 - Epoch: [268][  400/  500]    Overall Loss 1.003016    Objective Loss 1.003016                                        LR 0.000125    Time 0.045892    
2024-04-05 16:55:55,972 - Epoch: [268][  500/  500]    Overall Loss 1.002874    Objective Loss 1.002874    Top1 72.500000    Top5 93.000000    LR 0.000125    Time 0.045651    
2024-04-05 16:55:56,136 - --- validate (epoch=268)-----------
2024-04-05 16:55:56,137 - 10000 samples (100 per mini-batch)
2024-04-05 16:55:58,595 - Epoch: [268][  100/  100]    Loss 1.651622    Top1 56.000000    Top5 83.240000    
2024-04-05 16:55:58,705 - ==> Top1: 56.000    Top5: 83.240    Loss: 1.652

2024-04-05 16:55:58,712 - ==> Best [Top1: 56.190   Top5: 83.400   Sparsity:0.00   Params: 314624 on epoch: 260]
2024-04-05 16:55:58,712 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:55:58,741 - 

2024-04-05 16:55:58,741 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:56:03,665 - Epoch: [269][  100/  500]    Overall Loss 0.993452    Objective Loss 0.993452                                        LR 0.000125    Time 0.049207    
2024-04-05 16:56:08,095 - Epoch: [269][  200/  500]    Overall Loss 0.989621    Objective Loss 0.989621                                        LR 0.000125    Time 0.046733    
2024-04-05 16:56:12,518 - Epoch: [269][  300/  500]    Overall Loss 0.999970    Objective Loss 0.999970                                        LR 0.000125    Time 0.045889    
2024-04-05 16:56:16,964 - Epoch: [269][  400/  500]    Overall Loss 1.001998    Objective Loss 1.001998                                        LR 0.000125    Time 0.045521    
2024-04-05 16:56:21,401 - Epoch: [269][  500/  500]    Overall Loss 1.003467    Objective Loss 1.003467    Top1 73.000000    Top5 96.000000    LR 0.000125    Time 0.045285    
2024-04-05 16:56:21,647 - --- validate (epoch=269)-----------
2024-04-05 16:56:21,647 - 10000 samples (100 per mini-batch)
2024-04-05 16:56:24,115 - Epoch: [269][  100/  100]    Loss 1.651639    Top1 56.220000    Top5 83.630000    
2024-04-05 16:56:24,301 - ==> Top1: 56.220    Top5: 83.630    Loss: 1.652

2024-04-05 16:56:24,306 - ==> Best [Top1: 56.220   Top5: 83.630   Sparsity:0.00   Params: 314624 on epoch: 269]
2024-04-05 16:56:24,307 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:56:24,343 - 

2024-04-05 16:56:24,343 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:56:29,263 - Epoch: [270][  100/  500]    Overall Loss 0.974280    Objective Loss 0.974280                                        LR 0.000125    Time 0.049162    
2024-04-05 16:56:33,711 - Epoch: [270][  200/  500]    Overall Loss 0.988260    Objective Loss 0.988260                                        LR 0.000125    Time 0.046807    
2024-04-05 16:56:38,144 - Epoch: [270][  300/  500]    Overall Loss 0.988779    Objective Loss 0.988779                                        LR 0.000125    Time 0.045970    
2024-04-05 16:56:42,589 - Epoch: [270][  400/  500]    Overall Loss 0.992870    Objective Loss 0.992870                                        LR 0.000125    Time 0.045581    
2024-04-05 16:56:47,056 - Epoch: [270][  500/  500]    Overall Loss 0.991778    Objective Loss 0.991778    Top1 77.000000    Top5 96.000000    LR 0.000125    Time 0.045392    
2024-04-05 16:56:47,208 - --- validate (epoch=270)-----------
2024-04-05 16:56:47,209 - 10000 samples (100 per mini-batch)
2024-04-05 16:56:49,673 - Epoch: [270][  100/  100]    Loss 1.651873    Top1 55.970000    Top5 83.500000    
2024-04-05 16:56:49,857 - ==> Top1: 55.970    Top5: 83.500    Loss: 1.652

2024-04-05 16:56:49,863 - ==> Best [Top1: 56.220   Top5: 83.630   Sparsity:0.00   Params: 314624 on epoch: 269]
2024-04-05 16:56:49,863 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:56:49,891 - 

2024-04-05 16:56:49,891 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:56:55,029 - Epoch: [271][  100/  500]    Overall Loss 0.986179    Objective Loss 0.986179                                        LR 0.000125    Time 0.051337    
2024-04-05 16:56:59,411 - Epoch: [271][  200/  500]    Overall Loss 0.987641    Objective Loss 0.987641                                        LR 0.000125    Time 0.047564    
2024-04-05 16:57:03,831 - Epoch: [271][  300/  500]    Overall Loss 0.989750    Objective Loss 0.989750                                        LR 0.000125    Time 0.046431    
2024-04-05 16:57:08,271 - Epoch: [271][  400/  500]    Overall Loss 0.992531    Objective Loss 0.992531                                        LR 0.000125    Time 0.045917    
2024-04-05 16:57:12,711 - Epoch: [271][  500/  500]    Overall Loss 0.994656    Objective Loss 0.994656    Top1 74.000000    Top5 95.000000    LR 0.000125    Time 0.045606    
2024-04-05 16:57:12,853 - --- validate (epoch=271)-----------
2024-04-05 16:57:12,853 - 10000 samples (100 per mini-batch)
2024-04-05 16:57:15,338 - Epoch: [271][  100/  100]    Loss 1.648547    Top1 56.220000    Top5 83.300000    
2024-04-05 16:57:15,423 - ==> Top1: 56.220    Top5: 83.300    Loss: 1.649

2024-04-05 16:57:15,429 - ==> Best [Top1: 56.220   Top5: 83.630   Sparsity:0.00   Params: 314624 on epoch: 269]
2024-04-05 16:57:15,430 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:57:15,456 - 

2024-04-05 16:57:15,456 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:57:20,171 - Epoch: [272][  100/  500]    Overall Loss 0.976754    Objective Loss 0.976754                                        LR 0.000125    Time 0.047102    
2024-04-05 16:57:24,629 - Epoch: [272][  200/  500]    Overall Loss 0.977269    Objective Loss 0.977269                                        LR 0.000125    Time 0.045824    
2024-04-05 16:57:29,072 - Epoch: [272][  300/  500]    Overall Loss 0.982250    Objective Loss 0.982250                                        LR 0.000125    Time 0.045350    
2024-04-05 16:57:33,525 - Epoch: [272][  400/  500]    Overall Loss 0.980665    Objective Loss 0.980665                                        LR 0.000125    Time 0.045135    
2024-04-05 16:57:37,954 - Epoch: [272][  500/  500]    Overall Loss 0.982986    Objective Loss 0.982986    Top1 73.000000    Top5 94.500000    LR 0.000125    Time 0.044961    
2024-04-05 16:57:38,101 - --- validate (epoch=272)-----------
2024-04-05 16:57:38,102 - 10000 samples (100 per mini-batch)
2024-04-05 16:57:40,719 - Epoch: [272][  100/  100]    Loss 1.660214    Top1 56.060000    Top5 83.040000    
2024-04-05 16:57:40,916 - ==> Top1: 56.060    Top5: 83.040    Loss: 1.660

2024-04-05 16:57:40,922 - ==> Best [Top1: 56.220   Top5: 83.630   Sparsity:0.00   Params: 314624 on epoch: 269]
2024-04-05 16:57:40,922 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:57:40,951 - 

2024-04-05 16:57:40,951 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:57:45,858 - Epoch: [273][  100/  500]    Overall Loss 0.968090    Objective Loss 0.968090                                        LR 0.000125    Time 0.049029    
2024-04-05 16:57:50,288 - Epoch: [273][  200/  500]    Overall Loss 0.975769    Objective Loss 0.975769                                        LR 0.000125    Time 0.046650    
2024-04-05 16:57:54,710 - Epoch: [273][  300/  500]    Overall Loss 0.982477    Objective Loss 0.982477                                        LR 0.000125    Time 0.045831    
2024-04-05 16:57:59,117 - Epoch: [273][  400/  500]    Overall Loss 0.986509    Objective Loss 0.986509                                        LR 0.000125    Time 0.045384    
2024-04-05 16:58:03,517 - Epoch: [273][  500/  500]    Overall Loss 0.984181    Objective Loss 0.984181    Top1 76.500000    Top5 97.500000    LR 0.000125    Time 0.045101    
2024-04-05 16:58:03,677 - --- validate (epoch=273)-----------
2024-04-05 16:58:03,677 - 10000 samples (100 per mini-batch)
2024-04-05 16:58:06,100 - Epoch: [273][  100/  100]    Loss 1.665156    Top1 55.890000    Top5 82.840000    
2024-04-05 16:58:06,298 - ==> Top1: 55.890    Top5: 82.840    Loss: 1.665

2024-04-05 16:58:06,304 - ==> Best [Top1: 56.220   Top5: 83.630   Sparsity:0.00   Params: 314624 on epoch: 269]
2024-04-05 16:58:06,304 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:58:06,332 - 

2024-04-05 16:58:06,332 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:58:11,439 - Epoch: [274][  100/  500]    Overall Loss 0.983309    Objective Loss 0.983309                                        LR 0.000125    Time 0.051025    
2024-04-05 16:58:15,875 - Epoch: [274][  200/  500]    Overall Loss 0.972599    Objective Loss 0.972599                                        LR 0.000125    Time 0.047678    
2024-04-05 16:58:20,362 - Epoch: [274][  300/  500]    Overall Loss 0.973069    Objective Loss 0.973069                                        LR 0.000125    Time 0.046734    
2024-04-05 16:58:24,780 - Epoch: [274][  400/  500]    Overall Loss 0.978624    Objective Loss 0.978624                                        LR 0.000125    Time 0.046085    
2024-04-05 16:58:29,209 - Epoch: [274][  500/  500]    Overall Loss 0.979987    Objective Loss 0.979987    Top1 74.500000    Top5 97.000000    LR 0.000125    Time 0.045720    
2024-04-05 16:58:29,328 - --- validate (epoch=274)-----------
2024-04-05 16:58:29,328 - 10000 samples (100 per mini-batch)
2024-04-05 16:58:31,705 - Epoch: [274][  100/  100]    Loss 1.674450    Top1 55.170000    Top5 83.210000    
2024-04-05 16:58:31,823 - ==> Top1: 55.170    Top5: 83.210    Loss: 1.674

2024-04-05 16:58:31,829 - ==> Best [Top1: 56.220   Top5: 83.630   Sparsity:0.00   Params: 314624 on epoch: 269]
2024-04-05 16:58:31,830 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:58:31,858 - 

2024-04-05 16:58:31,858 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:58:36,739 - Epoch: [275][  100/  500]    Overall Loss 0.960300    Objective Loss 0.960300                                        LR 0.000125    Time 0.048763    
2024-04-05 16:58:41,189 - Epoch: [275][  200/  500]    Overall Loss 0.964034    Objective Loss 0.964034                                        LR 0.000125    Time 0.046617    
2024-04-05 16:58:45,553 - Epoch: [275][  300/  500]    Overall Loss 0.961651    Objective Loss 0.961651                                        LR 0.000125    Time 0.045615    
2024-04-05 16:58:49,997 - Epoch: [275][  400/  500]    Overall Loss 0.967085    Objective Loss 0.967085                                        LR 0.000125    Time 0.045314    
2024-04-05 16:58:54,399 - Epoch: [275][  500/  500]    Overall Loss 0.972356    Objective Loss 0.972356    Top1 70.000000    Top5 95.500000    LR 0.000125    Time 0.045048    
2024-04-05 16:58:54,582 - --- validate (epoch=275)-----------
2024-04-05 16:58:54,583 - 10000 samples (100 per mini-batch)
2024-04-05 16:58:56,983 - Epoch: [275][  100/  100]    Loss 1.672176    Top1 55.690000    Top5 82.840000    
2024-04-05 16:58:57,166 - ==> Top1: 55.690    Top5: 82.840    Loss: 1.672

2024-04-05 16:58:57,172 - ==> Best [Top1: 56.220   Top5: 83.630   Sparsity:0.00   Params: 314624 on epoch: 269]
2024-04-05 16:58:57,172 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:58:57,200 - 

2024-04-05 16:58:57,200 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:59:02,081 - Epoch: [276][  100/  500]    Overall Loss 0.954873    Objective Loss 0.954873                                        LR 0.000125    Time 0.048778    
2024-04-05 16:59:06,454 - Epoch: [276][  200/  500]    Overall Loss 0.962303    Objective Loss 0.962303                                        LR 0.000125    Time 0.046239    
2024-04-05 16:59:10,897 - Epoch: [276][  300/  500]    Overall Loss 0.961974    Objective Loss 0.961974                                        LR 0.000125    Time 0.045624    
2024-04-05 16:59:15,307 - Epoch: [276][  400/  500]    Overall Loss 0.963674    Objective Loss 0.963674                                        LR 0.000125    Time 0.045236    
2024-04-05 16:59:19,733 - Epoch: [276][  500/  500]    Overall Loss 0.967568    Objective Loss 0.967568    Top1 73.500000    Top5 96.000000    LR 0.000125    Time 0.045033    
2024-04-05 16:59:19,916 - --- validate (epoch=276)-----------
2024-04-05 16:59:19,916 - 10000 samples (100 per mini-batch)
2024-04-05 16:59:22,235 - Epoch: [276][  100/  100]    Loss 1.658675    Top1 55.780000    Top5 83.110000    
2024-04-05 16:59:22,432 - ==> Top1: 55.780    Top5: 83.110    Loss: 1.659

2024-04-05 16:59:22,438 - ==> Best [Top1: 56.220   Top5: 83.630   Sparsity:0.00   Params: 314624 on epoch: 269]
2024-04-05 16:59:22,438 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:59:22,468 - 

2024-04-05 16:59:22,468 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:59:27,533 - Epoch: [277][  100/  500]    Overall Loss 0.941063    Objective Loss 0.941063                                        LR 0.000125    Time 0.050613    
2024-04-05 16:59:31,792 - Epoch: [277][  200/  500]    Overall Loss 0.954672    Objective Loss 0.954672                                        LR 0.000125    Time 0.046581    
2024-04-05 16:59:36,125 - Epoch: [277][  300/  500]    Overall Loss 0.960171    Objective Loss 0.960171                                        LR 0.000125    Time 0.045484    
2024-04-05 16:59:40,558 - Epoch: [277][  400/  500]    Overall Loss 0.963248    Objective Loss 0.963248                                        LR 0.000125    Time 0.045189    
2024-04-05 16:59:45,008 - Epoch: [277][  500/  500]    Overall Loss 0.963685    Objective Loss 0.963685    Top1 80.500000    Top5 94.500000    LR 0.000125    Time 0.045045    
2024-04-05 16:59:45,220 - --- validate (epoch=277)-----------
2024-04-05 16:59:45,221 - 10000 samples (100 per mini-batch)
2024-04-05 16:59:47,591 - Epoch: [277][  100/  100]    Loss 1.653002    Top1 55.720000    Top5 83.400000    
2024-04-05 16:59:47,712 - ==> Top1: 55.720    Top5: 83.400    Loss: 1.653

2024-04-05 16:59:47,718 - ==> Best [Top1: 56.220   Top5: 83.630   Sparsity:0.00   Params: 314624 on epoch: 269]
2024-04-05 16:59:47,718 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 16:59:47,747 - 

2024-04-05 16:59:47,747 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 16:59:52,844 - Epoch: [278][  100/  500]    Overall Loss 0.951867    Objective Loss 0.951867                                        LR 0.000125    Time 0.050931    
2024-04-05 16:59:57,300 - Epoch: [278][  200/  500]    Overall Loss 0.948198    Objective Loss 0.948198                                        LR 0.000125    Time 0.047731    
2024-04-05 17:00:01,749 - Epoch: [278][  300/  500]    Overall Loss 0.952839    Objective Loss 0.952839                                        LR 0.000125    Time 0.046637    
2024-04-05 17:00:06,171 - Epoch: [278][  400/  500]    Overall Loss 0.952309    Objective Loss 0.952309                                        LR 0.000125    Time 0.046025    
2024-04-05 17:00:10,613 - Epoch: [278][  500/  500]    Overall Loss 0.957405    Objective Loss 0.957405    Top1 75.000000    Top5 95.500000    LR 0.000125    Time 0.045697    
2024-04-05 17:00:10,759 - --- validate (epoch=278)-----------
2024-04-05 17:00:10,759 - 10000 samples (100 per mini-batch)
2024-04-05 17:00:13,198 - Epoch: [278][  100/  100]    Loss 1.670002    Top1 55.830000    Top5 82.710000    
2024-04-05 17:00:13,324 - ==> Top1: 55.830    Top5: 82.710    Loss: 1.670

2024-04-05 17:00:13,330 - ==> Best [Top1: 56.220   Top5: 83.630   Sparsity:0.00   Params: 314624 on epoch: 269]
2024-04-05 17:00:13,330 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:00:13,358 - 

2024-04-05 17:00:13,358 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:00:18,351 - Epoch: [279][  100/  500]    Overall Loss 0.943023    Objective Loss 0.943023                                        LR 0.000125    Time 0.049887    
2024-04-05 17:00:22,787 - Epoch: [279][  200/  500]    Overall Loss 0.946936    Objective Loss 0.946936                                        LR 0.000125    Time 0.047103    
2024-04-05 17:00:27,165 - Epoch: [279][  300/  500]    Overall Loss 0.942457    Objective Loss 0.942457                                        LR 0.000125    Time 0.045986    
2024-04-05 17:00:31,562 - Epoch: [279][  400/  500]    Overall Loss 0.946176    Objective Loss 0.946176                                        LR 0.000125    Time 0.045475    
2024-04-05 17:00:36,026 - Epoch: [279][  500/  500]    Overall Loss 0.953374    Objective Loss 0.953374    Top1 76.000000    Top5 96.500000    LR 0.000125    Time 0.045301    
2024-04-05 17:00:36,187 - --- validate (epoch=279)-----------
2024-04-05 17:00:36,188 - 10000 samples (100 per mini-batch)
2024-04-05 17:00:38,539 - Epoch: [279][  100/  100]    Loss 1.664376    Top1 55.550000    Top5 83.280000    
2024-04-05 17:00:38,672 - ==> Top1: 55.550    Top5: 83.280    Loss: 1.664

2024-04-05 17:00:38,679 - ==> Best [Top1: 56.220   Top5: 83.630   Sparsity:0.00   Params: 314624 on epoch: 269]
2024-04-05 17:00:38,679 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:00:38,708 - 

2024-04-05 17:00:38,709 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:00:43,221 - Epoch: [280][  100/  500]    Overall Loss 0.949965    Objective Loss 0.949965                                        LR 0.000125    Time 0.045086    
2024-04-05 17:00:47,524 - Epoch: [280][  200/  500]    Overall Loss 0.944014    Objective Loss 0.944014                                        LR 0.000125    Time 0.044044    
2024-04-05 17:00:51,910 - Epoch: [280][  300/  500]    Overall Loss 0.950576    Objective Loss 0.950576                                        LR 0.000125    Time 0.043974    
2024-04-05 17:00:55,998 - Epoch: [280][  400/  500]    Overall Loss 0.952569    Objective Loss 0.952569                                        LR 0.000125    Time 0.043193    
2024-04-05 17:01:00,464 - Epoch: [280][  500/  500]    Overall Loss 0.953866    Objective Loss 0.953866    Top1 75.000000    Top5 93.500000    LR 0.000125    Time 0.043479    
2024-04-05 17:01:00,613 - --- validate (epoch=280)-----------
2024-04-05 17:01:00,614 - 10000 samples (100 per mini-batch)
2024-04-05 17:01:03,009 - Epoch: [280][  100/  100]    Loss 1.647835    Top1 56.040000    Top5 83.640000    
2024-04-05 17:01:03,203 - ==> Top1: 56.040    Top5: 83.640    Loss: 1.648

2024-04-05 17:01:03,208 - ==> Best [Top1: 56.220   Top5: 83.630   Sparsity:0.00   Params: 314624 on epoch: 269]
2024-04-05 17:01:03,209 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:01:03,237 - 

2024-04-05 17:01:03,238 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:01:08,168 - Epoch: [281][  100/  500]    Overall Loss 0.915763    Objective Loss 0.915763                                        LR 0.000125    Time 0.049261    
2024-04-05 17:01:12,592 - Epoch: [281][  200/  500]    Overall Loss 0.922415    Objective Loss 0.922415                                        LR 0.000125    Time 0.046734    
2024-04-05 17:01:16,996 - Epoch: [281][  300/  500]    Overall Loss 0.937042    Objective Loss 0.937042                                        LR 0.000125    Time 0.045826    
2024-04-05 17:01:21,411 - Epoch: [281][  400/  500]    Overall Loss 0.939203    Objective Loss 0.939203                                        LR 0.000125    Time 0.045400    
2024-04-05 17:01:25,818 - Epoch: [281][  500/  500]    Overall Loss 0.941968    Objective Loss 0.941968    Top1 74.500000    Top5 95.500000    LR 0.000125    Time 0.045127    
2024-04-05 17:01:25,983 - --- validate (epoch=281)-----------
2024-04-05 17:01:25,984 - 10000 samples (100 per mini-batch)
2024-04-05 17:01:28,364 - Epoch: [281][  100/  100]    Loss 1.647477    Top1 56.390000    Top5 83.460000    
2024-04-05 17:01:28,553 - ==> Top1: 56.390    Top5: 83.460    Loss: 1.647

2024-04-05 17:01:28,559 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:01:28,560 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:01:28,594 - 

2024-04-05 17:01:28,594 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:01:33,485 - Epoch: [282][  100/  500]    Overall Loss 0.925105    Objective Loss 0.925105                                        LR 0.000125    Time 0.048872    
2024-04-05 17:01:37,941 - Epoch: [282][  200/  500]    Overall Loss 0.938025    Objective Loss 0.938025                                        LR 0.000125    Time 0.046697    
2024-04-05 17:01:42,319 - Epoch: [282][  300/  500]    Overall Loss 0.933458    Objective Loss 0.933458                                        LR 0.000125    Time 0.045717    
2024-04-05 17:01:46,728 - Epoch: [282][  400/  500]    Overall Loss 0.938098    Objective Loss 0.938098                                        LR 0.000125    Time 0.045302    
2024-04-05 17:01:51,185 - Epoch: [282][  500/  500]    Overall Loss 0.940100    Objective Loss 0.940100    Top1 77.000000    Top5 95.000000    LR 0.000125    Time 0.045148    
2024-04-05 17:01:51,352 - --- validate (epoch=282)-----------
2024-04-05 17:01:51,352 - 10000 samples (100 per mini-batch)
2024-04-05 17:01:53,779 - Epoch: [282][  100/  100]    Loss 1.667027    Top1 56.050000    Top5 83.150000    
2024-04-05 17:01:53,899 - ==> Top1: 56.050    Top5: 83.150    Loss: 1.667

2024-04-05 17:01:53,904 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:01:53,904 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:01:53,932 - 

2024-04-05 17:01:53,932 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:01:58,738 - Epoch: [283][  100/  500]    Overall Loss 0.925752    Objective Loss 0.925752                                        LR 0.000125    Time 0.048027    
2024-04-05 17:02:03,194 - Epoch: [283][  200/  500]    Overall Loss 0.929179    Objective Loss 0.929179                                        LR 0.000125    Time 0.046276    
2024-04-05 17:02:07,591 - Epoch: [283][  300/  500]    Overall Loss 0.938453    Objective Loss 0.938453                                        LR 0.000125    Time 0.045499    
2024-04-05 17:02:12,021 - Epoch: [283][  400/  500]    Overall Loss 0.938740    Objective Loss 0.938740                                        LR 0.000125    Time 0.045191    
2024-04-05 17:02:16,474 - Epoch: [283][  500/  500]    Overall Loss 0.940059    Objective Loss 0.940059    Top1 76.000000    Top5 97.500000    LR 0.000125    Time 0.045054    
2024-04-05 17:02:16,623 - --- validate (epoch=283)-----------
2024-04-05 17:02:16,624 - 10000 samples (100 per mini-batch)
2024-04-05 17:02:19,007 - Epoch: [283][  100/  100]    Loss 1.642483    Top1 56.100000    Top5 83.520000    
2024-04-05 17:02:19,208 - ==> Top1: 56.100    Top5: 83.520    Loss: 1.642

2024-04-05 17:02:19,214 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:02:19,214 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:02:19,242 - 

2024-04-05 17:02:19,243 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:02:24,166 - Epoch: [284][  100/  500]    Overall Loss 0.913146    Objective Loss 0.913146                                        LR 0.000125    Time 0.049193    
2024-04-05 17:02:28,585 - Epoch: [284][  200/  500]    Overall Loss 0.922727    Objective Loss 0.922727                                        LR 0.000125    Time 0.046674    
2024-04-05 17:02:33,035 - Epoch: [284][  300/  500]    Overall Loss 0.930167    Objective Loss 0.930167                                        LR 0.000125    Time 0.045940    
2024-04-05 17:02:37,470 - Epoch: [284][  400/  500]    Overall Loss 0.933847    Objective Loss 0.933847                                        LR 0.000125    Time 0.045533    
2024-04-05 17:02:41,920 - Epoch: [284][  500/  500]    Overall Loss 0.935392    Objective Loss 0.935392    Top1 78.500000    Top5 95.500000    LR 0.000125    Time 0.045320    
2024-04-05 17:02:42,094 - --- validate (epoch=284)-----------
2024-04-05 17:02:42,095 - 10000 samples (100 per mini-batch)
2024-04-05 17:02:44,758 - Epoch: [284][  100/  100]    Loss 1.661877    Top1 55.580000    Top5 83.100000    
2024-04-05 17:02:44,878 - ==> Top1: 55.580    Top5: 83.100    Loss: 1.662

2024-04-05 17:02:44,882 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:02:44,882 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:02:44,908 - 

2024-04-05 17:02:44,908 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:02:49,868 - Epoch: [285][  100/  500]    Overall Loss 0.928700    Objective Loss 0.928700                                        LR 0.000125    Time 0.049558    
2024-04-05 17:02:54,294 - Epoch: [285][  200/  500]    Overall Loss 0.926212    Objective Loss 0.926212                                        LR 0.000125    Time 0.046895    
2024-04-05 17:02:58,714 - Epoch: [285][  300/  500]    Overall Loss 0.927793    Objective Loss 0.927793                                        LR 0.000125    Time 0.045986    
2024-04-05 17:03:03,137 - Epoch: [285][  400/  500]    Overall Loss 0.929572    Objective Loss 0.929572                                        LR 0.000125    Time 0.045538    
2024-04-05 17:03:07,564 - Epoch: [285][  500/  500]    Overall Loss 0.930185    Objective Loss 0.930185    Top1 82.500000    Top5 96.500000    LR 0.000125    Time 0.045278    
2024-04-05 17:03:07,724 - --- validate (epoch=285)-----------
2024-04-05 17:03:07,725 - 10000 samples (100 per mini-batch)
2024-04-05 17:03:10,135 - Epoch: [285][  100/  100]    Loss 1.658118    Top1 55.600000    Top5 83.030000    
2024-04-05 17:03:10,345 - ==> Top1: 55.600    Top5: 83.030    Loss: 1.658

2024-04-05 17:03:10,351 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:03:10,351 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:03:10,381 - 

2024-04-05 17:03:10,381 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:03:15,500 - Epoch: [286][  100/  500]    Overall Loss 0.925063    Objective Loss 0.925063                                        LR 0.000125    Time 0.051158    
2024-04-05 17:03:19,955 - Epoch: [286][  200/  500]    Overall Loss 0.918757    Objective Loss 0.918757                                        LR 0.000125    Time 0.047836    
2024-04-05 17:03:24,372 - Epoch: [286][  300/  500]    Overall Loss 0.923338    Objective Loss 0.923338                                        LR 0.000125    Time 0.046602    
2024-04-05 17:03:28,785 - Epoch: [286][  400/  500]    Overall Loss 0.928386    Objective Loss 0.928386                                        LR 0.000125    Time 0.045977    
2024-04-05 17:03:33,223 - Epoch: [286][  500/  500]    Overall Loss 0.929801    Objective Loss 0.929801    Top1 71.500000    Top5 95.000000    LR 0.000125    Time 0.045653    
2024-04-05 17:03:33,397 - --- validate (epoch=286)-----------
2024-04-05 17:03:33,397 - 10000 samples (100 per mini-batch)
2024-04-05 17:03:35,861 - Epoch: [286][  100/  100]    Loss 1.650954    Top1 55.730000    Top5 83.260000    
2024-04-05 17:03:36,017 - ==> Top1: 55.730    Top5: 83.260    Loss: 1.651

2024-04-05 17:03:36,022 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:03:36,023 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:03:36,051 - 

2024-04-05 17:03:36,051 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:03:40,916 - Epoch: [287][  100/  500]    Overall Loss 0.921778    Objective Loss 0.921778                                        LR 0.000125    Time 0.048616    
2024-04-05 17:03:45,304 - Epoch: [287][  200/  500]    Overall Loss 0.926135    Objective Loss 0.926135                                        LR 0.000125    Time 0.046227    
2024-04-05 17:03:49,666 - Epoch: [287][  300/  500]    Overall Loss 0.923285    Objective Loss 0.923285                                        LR 0.000125    Time 0.045350    
2024-04-05 17:03:53,992 - Epoch: [287][  400/  500]    Overall Loss 0.926396    Objective Loss 0.926396                                        LR 0.000125    Time 0.044819    
2024-04-05 17:03:58,399 - Epoch: [287][  500/  500]    Overall Loss 0.927803    Objective Loss 0.927803    Top1 76.000000    Top5 98.500000    LR 0.000125    Time 0.044664    
2024-04-05 17:03:58,572 - --- validate (epoch=287)-----------
2024-04-05 17:03:58,573 - 10000 samples (100 per mini-batch)
2024-04-05 17:04:00,954 - Epoch: [287][  100/  100]    Loss 1.664696    Top1 55.550000    Top5 83.230000    
2024-04-05 17:04:01,172 - ==> Top1: 55.550    Top5: 83.230    Loss: 1.665

2024-04-05 17:04:01,177 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:04:01,178 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:04:01,206 - 

2024-04-05 17:04:01,207 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:04:05,630 - Epoch: [288][  100/  500]    Overall Loss 0.897815    Objective Loss 0.897815                                        LR 0.000125    Time 0.044199    
2024-04-05 17:04:10,060 - Epoch: [288][  200/  500]    Overall Loss 0.906020    Objective Loss 0.906020                                        LR 0.000125    Time 0.044232    
2024-04-05 17:04:14,472 - Epoch: [288][  300/  500]    Overall Loss 0.915986    Objective Loss 0.915986                                        LR 0.000125    Time 0.044185    
2024-04-05 17:04:18,925 - Epoch: [288][  400/  500]    Overall Loss 0.917368    Objective Loss 0.917368                                        LR 0.000125    Time 0.044264    
2024-04-05 17:04:23,371 - Epoch: [288][  500/  500]    Overall Loss 0.917216    Objective Loss 0.917216    Top1 76.500000    Top5 95.000000    LR 0.000125    Time 0.044295    
2024-04-05 17:04:23,524 - --- validate (epoch=288)-----------
2024-04-05 17:04:23,524 - 10000 samples (100 per mini-batch)
2024-04-05 17:04:25,995 - Epoch: [288][  100/  100]    Loss 1.670377    Top1 55.570000    Top5 82.950000    
2024-04-05 17:04:26,171 - ==> Top1: 55.570    Top5: 82.950    Loss: 1.670

2024-04-05 17:04:26,177 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:04:26,177 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:04:26,205 - 

2024-04-05 17:04:26,205 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:04:31,342 - Epoch: [289][  100/  500]    Overall Loss 0.905026    Objective Loss 0.905026                                        LR 0.000125    Time 0.051327    
2024-04-05 17:04:35,801 - Epoch: [289][  200/  500]    Overall Loss 0.903209    Objective Loss 0.903209                                        LR 0.000125    Time 0.047943    
2024-04-05 17:04:40,199 - Epoch: [289][  300/  500]    Overall Loss 0.914980    Objective Loss 0.914980                                        LR 0.000125    Time 0.046613    
2024-04-05 17:04:44,602 - Epoch: [289][  400/  500]    Overall Loss 0.913703    Objective Loss 0.913703                                        LR 0.000125    Time 0.045959    
2024-04-05 17:04:49,003 - Epoch: [289][  500/  500]    Overall Loss 0.920628    Objective Loss 0.920628    Top1 74.500000    Top5 96.000000    LR 0.000125    Time 0.045563    
2024-04-05 17:04:49,160 - --- validate (epoch=289)-----------
2024-04-05 17:04:49,161 - 10000 samples (100 per mini-batch)
2024-04-05 17:04:51,660 - Epoch: [289][  100/  100]    Loss 1.676737    Top1 55.790000    Top5 82.430000    
2024-04-05 17:04:51,806 - ==> Top1: 55.790    Top5: 82.430    Loss: 1.677

2024-04-05 17:04:51,811 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:04:51,812 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:04:51,840 - 

2024-04-05 17:04:51,840 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:04:56,477 - Epoch: [290][  100/  500]    Overall Loss 0.914374    Objective Loss 0.914374                                        LR 0.000125    Time 0.046338    
2024-04-05 17:05:00,907 - Epoch: [290][  200/  500]    Overall Loss 0.915275    Objective Loss 0.915275                                        LR 0.000125    Time 0.045292    
2024-04-05 17:05:05,401 - Epoch: [290][  300/  500]    Overall Loss 0.913205    Objective Loss 0.913205                                        LR 0.000125    Time 0.045164    
2024-04-05 17:05:09,793 - Epoch: [290][  400/  500]    Overall Loss 0.918025    Objective Loss 0.918025                                        LR 0.000125    Time 0.044845    
2024-04-05 17:05:14,154 - Epoch: [290][  500/  500]    Overall Loss 0.916720    Objective Loss 0.916720    Top1 80.500000    Top5 97.000000    LR 0.000125    Time 0.044593    
2024-04-05 17:05:14,391 - --- validate (epoch=290)-----------
2024-04-05 17:05:14,392 - 10000 samples (100 per mini-batch)
2024-04-05 17:05:17,012 - Epoch: [290][  100/  100]    Loss 1.650838    Top1 56.150000    Top5 83.260000    
2024-04-05 17:05:17,138 - ==> Top1: 56.150    Top5: 83.260    Loss: 1.651

2024-04-05 17:05:17,144 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:05:17,144 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:05:17,171 - 

2024-04-05 17:05:17,172 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:05:22,043 - Epoch: [291][  100/  500]    Overall Loss 0.902816    Objective Loss 0.902816                                        LR 0.000125    Time 0.048681    
2024-04-05 17:05:26,453 - Epoch: [291][  200/  500]    Overall Loss 0.899806    Objective Loss 0.899806                                        LR 0.000125    Time 0.046372    
2024-04-05 17:05:30,840 - Epoch: [291][  300/  500]    Overall Loss 0.904735    Objective Loss 0.904735                                        LR 0.000125    Time 0.045528    
2024-04-05 17:05:35,257 - Epoch: [291][  400/  500]    Overall Loss 0.907864    Objective Loss 0.907864                                        LR 0.000125    Time 0.045182    
2024-04-05 17:05:39,687 - Epoch: [291][  500/  500]    Overall Loss 0.912860    Objective Loss 0.912860    Top1 70.000000    Top5 95.000000    LR 0.000125    Time 0.045000    
2024-04-05 17:05:39,866 - --- validate (epoch=291)-----------
2024-04-05 17:05:39,867 - 10000 samples (100 per mini-batch)
2024-04-05 17:05:42,413 - Epoch: [291][  100/  100]    Loss 1.664669    Top1 55.810000    Top5 83.090000    
2024-04-05 17:05:42,575 - ==> Top1: 55.810    Top5: 83.090    Loss: 1.665

2024-04-05 17:05:42,581 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:05:42,581 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:05:42,608 - 

2024-04-05 17:05:42,608 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:05:47,315 - Epoch: [292][  100/  500]    Overall Loss 0.929471    Objective Loss 0.929471                                        LR 0.000125    Time 0.047026    
2024-04-05 17:05:51,709 - Epoch: [292][  200/  500]    Overall Loss 0.918160    Objective Loss 0.918160                                        LR 0.000125    Time 0.045469    
2024-04-05 17:05:56,047 - Epoch: [292][  300/  500]    Overall Loss 0.918134    Objective Loss 0.918134                                        LR 0.000125    Time 0.044763    
2024-04-05 17:06:00,502 - Epoch: [292][  400/  500]    Overall Loss 0.918062    Objective Loss 0.918062                                        LR 0.000125    Time 0.044703    
2024-04-05 17:06:04,951 - Epoch: [292][  500/  500]    Overall Loss 0.914118    Objective Loss 0.914118    Top1 79.000000    Top5 97.000000    LR 0.000125    Time 0.044653    
2024-04-05 17:06:05,149 - --- validate (epoch=292)-----------
2024-04-05 17:06:05,150 - 10000 samples (100 per mini-batch)
2024-04-05 17:06:07,608 - Epoch: [292][  100/  100]    Loss 1.652351    Top1 55.970000    Top5 83.250000    
2024-04-05 17:06:07,790 - ==> Top1: 55.970    Top5: 83.250    Loss: 1.652

2024-04-05 17:06:07,796 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:06:07,796 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:06:07,824 - 

2024-04-05 17:06:07,825 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:06:12,819 - Epoch: [293][  100/  500]    Overall Loss 0.882922    Objective Loss 0.882922                                        LR 0.000125    Time 0.049899    
2024-04-05 17:06:17,212 - Epoch: [293][  200/  500]    Overall Loss 0.883819    Objective Loss 0.883819                                        LR 0.000125    Time 0.046900    
2024-04-05 17:06:21,658 - Epoch: [293][  300/  500]    Overall Loss 0.896185    Objective Loss 0.896185                                        LR 0.000125    Time 0.046076    
2024-04-05 17:06:26,107 - Epoch: [293][  400/  500]    Overall Loss 0.896975    Objective Loss 0.896975                                        LR 0.000125    Time 0.045670    
2024-04-05 17:06:30,535 - Epoch: [293][  500/  500]    Overall Loss 0.902189    Objective Loss 0.902189    Top1 81.500000    Top5 98.500000    LR 0.000125    Time 0.045386    
2024-04-05 17:06:30,694 - --- validate (epoch=293)-----------
2024-04-05 17:06:30,695 - 10000 samples (100 per mini-batch)
2024-04-05 17:06:33,129 - Epoch: [293][  100/  100]    Loss 1.657948    Top1 55.690000    Top5 83.330000    
2024-04-05 17:06:33,280 - ==> Top1: 55.690    Top5: 83.330    Loss: 1.658

2024-04-05 17:06:33,286 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:06:33,287 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:06:33,316 - 

2024-04-05 17:06:33,317 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:06:38,205 - Epoch: [294][  100/  500]    Overall Loss 0.890504    Objective Loss 0.890504                                        LR 0.000125    Time 0.048845    
2024-04-05 17:06:42,694 - Epoch: [294][  200/  500]    Overall Loss 0.891563    Objective Loss 0.891563                                        LR 0.000125    Time 0.046844    
2024-04-05 17:06:47,127 - Epoch: [294][  300/  500]    Overall Loss 0.892539    Objective Loss 0.892539                                        LR 0.000125    Time 0.045996    
2024-04-05 17:06:51,554 - Epoch: [294][  400/  500]    Overall Loss 0.893966    Objective Loss 0.893966                                        LR 0.000125    Time 0.045557    
2024-04-05 17:06:55,951 - Epoch: [294][  500/  500]    Overall Loss 0.896851    Objective Loss 0.896851    Top1 79.000000    Top5 96.000000    LR 0.000125    Time 0.045233    
2024-04-05 17:06:56,116 - --- validate (epoch=294)-----------
2024-04-05 17:06:56,117 - 10000 samples (100 per mini-batch)
2024-04-05 17:06:58,677 - Epoch: [294][  100/  100]    Loss 1.669391    Top1 55.920000    Top5 83.010000    
2024-04-05 17:06:58,859 - ==> Top1: 55.920    Top5: 83.010    Loss: 1.669

2024-04-05 17:06:58,865 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:06:58,865 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:06:58,894 - 

2024-04-05 17:06:58,895 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:07:04,007 - Epoch: [295][  100/  500]    Overall Loss 0.890515    Objective Loss 0.890515                                        LR 0.000125    Time 0.051081    
2024-04-05 17:07:08,403 - Epoch: [295][  200/  500]    Overall Loss 0.895832    Objective Loss 0.895832                                        LR 0.000125    Time 0.047507    
2024-04-05 17:07:12,817 - Epoch: [295][  300/  500]    Overall Loss 0.896495    Objective Loss 0.896495                                        LR 0.000125    Time 0.046373    
2024-04-05 17:07:17,288 - Epoch: [295][  400/  500]    Overall Loss 0.895898    Objective Loss 0.895898                                        LR 0.000125    Time 0.045949    
2024-04-05 17:07:21,705 - Epoch: [295][  500/  500]    Overall Loss 0.897950    Objective Loss 0.897950    Top1 77.500000    Top5 95.000000    LR 0.000125    Time 0.045588    
2024-04-05 17:07:21,946 - --- validate (epoch=295)-----------
2024-04-05 17:07:21,947 - 10000 samples (100 per mini-batch)
2024-04-05 17:07:24,431 - Epoch: [295][  100/  100]    Loss 1.698396    Top1 55.190000    Top5 82.480000    
2024-04-05 17:07:24,561 - ==> Top1: 55.190    Top5: 82.480    Loss: 1.698

2024-04-05 17:07:24,567 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:07:24,568 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:07:24,597 - 

2024-04-05 17:07:24,597 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:07:29,717 - Epoch: [296][  100/  500]    Overall Loss 0.887214    Objective Loss 0.887214                                        LR 0.000125    Time 0.051163    
2024-04-05 17:07:34,185 - Epoch: [296][  200/  500]    Overall Loss 0.891983    Objective Loss 0.891983                                        LR 0.000125    Time 0.047900    
2024-04-05 17:07:38,580 - Epoch: [296][  300/  500]    Overall Loss 0.898125    Objective Loss 0.898125                                        LR 0.000125    Time 0.046576    
2024-04-05 17:07:43,009 - Epoch: [296][  400/  500]    Overall Loss 0.896437    Objective Loss 0.896437                                        LR 0.000125    Time 0.045995    
2024-04-05 17:07:47,424 - Epoch: [296][  500/  500]    Overall Loss 0.895738    Objective Loss 0.895738    Top1 80.500000    Top5 99.000000    LR 0.000125    Time 0.045621    
2024-04-05 17:07:47,589 - --- validate (epoch=296)-----------
2024-04-05 17:07:47,589 - 10000 samples (100 per mini-batch)
2024-04-05 17:07:50,112 - Epoch: [296][  100/  100]    Loss 1.653247    Top1 56.090000    Top5 83.030000    
2024-04-05 17:07:50,300 - ==> Top1: 56.090    Top5: 83.030    Loss: 1.653

2024-04-05 17:07:50,306 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:07:50,307 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:07:50,337 - 

2024-04-05 17:07:50,337 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:07:55,257 - Epoch: [297][  100/  500]    Overall Loss 0.887268    Objective Loss 0.887268                                        LR 0.000125    Time 0.049159    
2024-04-05 17:07:59,643 - Epoch: [297][  200/  500]    Overall Loss 0.881507    Objective Loss 0.881507                                        LR 0.000125    Time 0.046495    
2024-04-05 17:08:04,058 - Epoch: [297][  300/  500]    Overall Loss 0.886900    Objective Loss 0.886900                                        LR 0.000125    Time 0.045702    
2024-04-05 17:08:08,435 - Epoch: [297][  400/  500]    Overall Loss 0.886122    Objective Loss 0.886122                                        LR 0.000125    Time 0.045212    
2024-04-05 17:08:12,818 - Epoch: [297][  500/  500]    Overall Loss 0.890052    Objective Loss 0.890052    Top1 78.500000    Top5 97.000000    LR 0.000125    Time 0.044928    
2024-04-05 17:08:12,971 - --- validate (epoch=297)-----------
2024-04-05 17:08:12,972 - 10000 samples (100 per mini-batch)
2024-04-05 17:08:15,424 - Epoch: [297][  100/  100]    Loss 1.670140    Top1 55.840000    Top5 82.870000    
2024-04-05 17:08:15,548 - ==> Top1: 55.840    Top5: 82.870    Loss: 1.670

2024-04-05 17:08:15,553 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:08:15,553 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:08:15,571 - 

2024-04-05 17:08:15,571 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:08:20,669 - Epoch: [298][  100/  500]    Overall Loss 0.876835    Objective Loss 0.876835                                        LR 0.000125    Time 0.050947    
2024-04-05 17:08:25,153 - Epoch: [298][  200/  500]    Overall Loss 0.872268    Objective Loss 0.872268                                        LR 0.000125    Time 0.047877    
2024-04-05 17:08:29,553 - Epoch: [298][  300/  500]    Overall Loss 0.878816    Objective Loss 0.878816                                        LR 0.000125    Time 0.046575    
2024-04-05 17:08:33,989 - Epoch: [298][  400/  500]    Overall Loss 0.881227    Objective Loss 0.881227                                        LR 0.000125    Time 0.046011    
2024-04-05 17:08:38,401 - Epoch: [298][  500/  500]    Overall Loss 0.885690    Objective Loss 0.885690    Top1 75.500000    Top5 96.500000    LR 0.000125    Time 0.045627    
2024-04-05 17:08:38,556 - --- validate (epoch=298)-----------
2024-04-05 17:08:38,556 - 10000 samples (100 per mini-batch)
2024-04-05 17:08:41,025 - Epoch: [298][  100/  100]    Loss 1.663217    Top1 55.780000    Top5 83.000000    
2024-04-05 17:08:41,148 - ==> Top1: 55.780    Top5: 83.000    Loss: 1.663

2024-04-05 17:08:41,154 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:08:41,154 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:08:41,183 - 

2024-04-05 17:08:41,183 - Training epoch: 50000 samples (100 per mini-batch)
2024-04-05 17:08:46,124 - Epoch: [299][  100/  500]    Overall Loss 0.863494    Objective Loss 0.863494                                        LR 0.000125    Time 0.049369    
2024-04-05 17:08:50,568 - Epoch: [299][  200/  500]    Overall Loss 0.873390    Objective Loss 0.873390                                        LR 0.000125    Time 0.046887    
2024-04-05 17:08:54,994 - Epoch: [299][  300/  500]    Overall Loss 0.877882    Objective Loss 0.877882                                        LR 0.000125    Time 0.046002    
2024-04-05 17:08:59,416 - Epoch: [299][  400/  500]    Overall Loss 0.882067    Objective Loss 0.882067                                        LR 0.000125    Time 0.045549    
2024-04-05 17:09:03,816 - Epoch: [299][  500/  500]    Overall Loss 0.883899    Objective Loss 0.883899    Top1 77.000000    Top5 94.500000    LR 0.000125    Time 0.045232    
2024-04-05 17:09:03,973 - --- validate (epoch=299)-----------
2024-04-05 17:09:03,974 - 10000 samples (100 per mini-batch)
2024-04-05 17:09:06,500 - Epoch: [299][  100/  100]    Loss 1.669205    Top1 55.610000    Top5 82.580000    
2024-04-05 17:09:06,629 - ==> Top1: 55.610    Top5: 82.580    Loss: 1.669

2024-04-05 17:09:06,633 - ==> Best [Top1: 56.390   Top5: 83.460   Sparsity:0.00   Params: 314624 on epoch: 281]
2024-04-05 17:09:06,633 - Saving checkpoint to: logs/2024.04.05-150814/qat_checkpoint.pth.tar
2024-04-05 17:09:06,661 - --- test ---------------------
2024-04-05 17:09:06,661 - 10000 samples (100 per mini-batch)
2024-04-05 17:09:09,051 - Test: [  100/  100]    Loss 1.669205    Top1 55.610000    Top5 82.580000    
2024-04-05 17:09:09,246 - ==> Top1: 55.610    Top5: 82.580    Loss: 1.669

2024-04-05 17:09:09,254 - 
2024-04-05 17:09:09,254 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.05-150814/2024.04.05-150814.log
