2024-04-04 16:57:33,540 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.04-165733/2024.04.04-165733.log
2024-04-04 16:57:36,986 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-04-04 16:57:36,986 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-04-04 17:01:00,889 - Dataset sizes:
	training=4428
	validation=1392
	test=1392
2024-04-04 17:01:00,889 - Reading compression schedule from: policies/schedule-camvid.yaml
2024-04-04 17:01:00,897 - 

2024-04-04 17:01:00,897 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:01:05,664 - Epoch: [0][   10/  139]    Overall Loss 1.277216    Objective Loss 1.277216                                        LR 0.001000    Time 0.476564    
2024-04-04 17:01:08,314 - Epoch: [0][   20/  139]    Overall Loss 1.231959    Objective Loss 1.231959                                        LR 0.001000    Time 0.370759    
2024-04-04 17:01:10,975 - Epoch: [0][   30/  139]    Overall Loss 1.208552    Objective Loss 1.208552                                        LR 0.001000    Time 0.335839    
2024-04-04 17:01:13,628 - Epoch: [0][   40/  139]    Overall Loss 1.195460    Objective Loss 1.195460                                        LR 0.001000    Time 0.318194    
2024-04-04 17:01:16,296 - Epoch: [0][   50/  139]    Overall Loss 1.186381    Objective Loss 1.186381                                        LR 0.001000    Time 0.307909    
2024-04-04 17:01:18,956 - Epoch: [0][   60/  139]    Overall Loss 1.177361    Objective Loss 1.177361                                        LR 0.001000    Time 0.300916    
2024-04-04 17:01:21,614 - Epoch: [0][   70/  139]    Overall Loss 1.171236    Objective Loss 1.171236                                        LR 0.001000    Time 0.295894    
2024-04-04 17:01:24,273 - Epoch: [0][   80/  139]    Overall Loss 1.164177    Objective Loss 1.164177                                        LR 0.001000    Time 0.292139    
2024-04-04 17:01:26,927 - Epoch: [0][   90/  139]    Overall Loss 1.159550    Objective Loss 1.159550                                        LR 0.001000    Time 0.289154    
2024-04-04 17:01:29,572 - Epoch: [0][  100/  139]    Overall Loss 1.155041    Objective Loss 1.155041                                        LR 0.001000    Time 0.286685    
2024-04-04 17:01:32,243 - Epoch: [0][  110/  139]    Overall Loss 1.151142    Objective Loss 1.151142                                        LR 0.001000    Time 0.284902    
2024-04-04 17:01:34,907 - Epoch: [0][  120/  139]    Overall Loss 1.147527    Objective Loss 1.147527                                        LR 0.001000    Time 0.283359    
2024-04-04 17:01:37,560 - Epoch: [0][  130/  139]    Overall Loss 1.144796    Objective Loss 1.144796                                        LR 0.001000    Time 0.281964    
2024-04-04 17:01:44,804 - Epoch: [0][  139/  139]    Overall Loss 1.142365    Objective Loss 1.142365    Top1 83.266334    LR 0.001000    Time 0.315818    
2024-04-04 17:01:44,977 - --- validate (epoch=0)-----------
2024-04-04 17:01:44,978 - 1392 samples (32 per mini-batch)
2024-04-04 17:02:17,669 - Epoch: [0][   10/   44]    Loss 1.123704    Top1 80.455365    
2024-04-04 17:02:49,852 - Epoch: [0][   20/   44]    Loss 1.124877    Top1 80.518172    
2024-04-04 17:03:21,238 - Epoch: [0][   30/   44]    Loss 1.126142    Top1 80.885151    
2024-04-04 17:03:52,712 - Epoch: [0][   40/   44]    Loss 1.127419    Top1 80.780991    
2024-04-04 17:04:03,700 - Epoch: [0][   44/   44]    Loss 1.128620    Top1 80.654569    
2024-04-04 17:04:03,969 - ==> Top1: 80.655    Loss: 1.129

2024-04-04 17:04:03,978 - ==> Best [Top1: 80.655   Sparsity:0.00   Params: 272800 on epoch: 0]
2024-04-04 17:04:03,979 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:04:04,023 - 

2024-04-04 17:04:04,023 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:04:07,342 - Epoch: [1][   10/  139]    Overall Loss 1.098001    Objective Loss 1.098001                                        LR 0.001000    Time 0.331748    
2024-04-04 17:04:09,996 - Epoch: [1][   20/  139]    Overall Loss 1.103078    Objective Loss 1.103078                                        LR 0.001000    Time 0.298534    
2024-04-04 17:04:12,653 - Epoch: [1][   30/  139]    Overall Loss 1.105908    Objective Loss 1.105908                                        LR 0.001000    Time 0.287595    
2024-04-04 17:04:15,309 - Epoch: [1][   40/  139]    Overall Loss 1.104956    Objective Loss 1.104956                                        LR 0.001000    Time 0.282079    
2024-04-04 17:04:17,959 - Epoch: [1][   50/  139]    Overall Loss 1.104303    Objective Loss 1.104303                                        LR 0.001000    Time 0.278657    
2024-04-04 17:04:20,610 - Epoch: [1][   60/  139]    Overall Loss 1.103508    Objective Loss 1.103508                                        LR 0.001000    Time 0.276391    
2024-04-04 17:04:23,268 - Epoch: [1][   70/  139]    Overall Loss 1.103009    Objective Loss 1.103009                                        LR 0.001000    Time 0.274861    
2024-04-04 17:04:25,917 - Epoch: [1][   80/  139]    Overall Loss 1.102184    Objective Loss 1.102184                                        LR 0.001000    Time 0.273609    
2024-04-04 17:04:28,565 - Epoch: [1][   90/  139]    Overall Loss 1.101941    Objective Loss 1.101941                                        LR 0.001000    Time 0.272624    
2024-04-04 17:04:31,214 - Epoch: [1][  100/  139]    Overall Loss 1.100586    Objective Loss 1.100586                                        LR 0.001000    Time 0.271845    
2024-04-04 17:04:33,867 - Epoch: [1][  110/  139]    Overall Loss 1.100120    Objective Loss 1.100120                                        LR 0.001000    Time 0.271245    
2024-04-04 17:04:36,518 - Epoch: [1][  120/  139]    Overall Loss 1.099576    Objective Loss 1.099576                                        LR 0.001000    Time 0.270729    
2024-04-04 17:04:39,171 - Epoch: [1][  130/  139]    Overall Loss 1.099635    Objective Loss 1.099635                                        LR 0.001000    Time 0.270311    
2024-04-04 17:04:46,068 - Epoch: [1][  139/  139]    Overall Loss 1.099416    Objective Loss 1.099416    Top1 87.494259    LR 0.001000    Time 0.302424    
2024-04-04 17:04:46,262 - --- validate (epoch=1)-----------
2024-04-04 17:04:46,263 - 1392 samples (32 per mini-batch)
2024-04-04 17:05:18,776 - Epoch: [1][   10/   44]    Loss 1.101172    Top1 85.053910    
2024-04-04 17:05:50,804 - Epoch: [1][   20/   44]    Loss 1.097632    Top1 85.476011    
2024-04-04 17:06:22,636 - Epoch: [1][   30/   44]    Loss 1.097433    Top1 85.098713    
2024-04-04 17:06:55,083 - Epoch: [1][   40/   44]    Loss 1.095358    Top1 85.263625    
2024-04-04 17:07:06,291 - Epoch: [1][   44/   44]    Loss 1.096920    Top1 85.115391    
2024-04-04 17:07:06,558 - ==> Top1: 85.115    Loss: 1.097

2024-04-04 17:07:06,566 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 272800 on epoch: 1]
2024-04-04 17:07:06,566 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:07:06,607 - 

2024-04-04 17:07:06,607 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:07:09,914 - Epoch: [2][   10/  139]    Overall Loss 1.100167    Objective Loss 1.100167                                        LR 0.001000    Time 0.330591    
2024-04-04 17:07:12,578 - Epoch: [2][   20/  139]    Overall Loss 1.100498    Objective Loss 1.100498                                        LR 0.001000    Time 0.298448    
2024-04-04 17:07:15,232 - Epoch: [2][   30/  139]    Overall Loss 1.097908    Objective Loss 1.097908                                        LR 0.001000    Time 0.287414    
2024-04-04 17:07:17,889 - Epoch: [2][   40/  139]    Overall Loss 1.096562    Objective Loss 1.096562                                        LR 0.001000    Time 0.281969    
2024-04-04 17:07:20,551 - Epoch: [2][   50/  139]    Overall Loss 1.096090    Objective Loss 1.096090                                        LR 0.001000    Time 0.278801    
2024-04-04 17:07:23,203 - Epoch: [2][   60/  139]    Overall Loss 1.095119    Objective Loss 1.095119                                        LR 0.001000    Time 0.276511    
2024-04-04 17:07:25,872 - Epoch: [2][   70/  139]    Overall Loss 1.094026    Objective Loss 1.094026                                        LR 0.001000    Time 0.275120    
2024-04-04 17:07:28,529 - Epoch: [2][   80/  139]    Overall Loss 1.093712    Objective Loss 1.093712                                        LR 0.001000    Time 0.273942    
2024-04-04 17:07:31,185 - Epoch: [2][   90/  139]    Overall Loss 1.092891    Objective Loss 1.092891                                        LR 0.001000    Time 0.273007    
2024-04-04 17:07:33,847 - Epoch: [2][  100/  139]    Overall Loss 1.092479    Objective Loss 1.092479                                        LR 0.001000    Time 0.272314    
2024-04-04 17:07:36,505 - Epoch: [2][  110/  139]    Overall Loss 1.092285    Objective Loss 1.092285                                        LR 0.001000    Time 0.271721    
2024-04-04 17:07:39,171 - Epoch: [2][  120/  139]    Overall Loss 1.092147    Objective Loss 1.092147                                        LR 0.001000    Time 0.271289    
2024-04-04 17:07:41,830 - Epoch: [2][  130/  139]    Overall Loss 1.091914    Objective Loss 1.091914                                        LR 0.001000    Time 0.270862    
2024-04-04 17:07:49,146 - Epoch: [2][  139/  139]    Overall Loss 1.091731    Objective Loss 1.091731    Top1 87.203509    LR 0.001000    Time 0.305953    
2024-04-04 17:07:49,415 - --- validate (epoch=2)-----------
2024-04-04 17:07:49,417 - 1392 samples (32 per mini-batch)
2024-04-04 17:08:21,544 - Epoch: [2][   10/   44]    Loss 1.116897    Top1 80.441521    
2024-04-04 17:08:53,512 - Epoch: [2][   20/   44]    Loss 1.106793    Top1 81.451927    
2024-04-04 17:09:24,700 - Epoch: [2][   30/   44]    Loss 1.107147    Top1 81.186135    
2024-04-04 17:09:56,441 - Epoch: [2][   40/   44]    Loss 1.103219    Top1 81.428791    
2024-04-04 17:10:07,560 - Epoch: [2][   44/   44]    Loss 1.103487    Top1 81.379613    
2024-04-04 17:10:07,841 - ==> Top1: 81.380    Loss: 1.103

2024-04-04 17:10:07,848 - ==> Best [Top1: 85.115   Sparsity:0.00   Params: 272800 on epoch: 1]
2024-04-04 17:10:07,848 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:10:07,885 - 

2024-04-04 17:10:07,885 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:10:11,154 - Epoch: [3][   10/  139]    Overall Loss 1.083119    Objective Loss 1.083119                                        LR 0.001000    Time 0.326804    
2024-04-04 17:10:13,807 - Epoch: [3][   20/  139]    Overall Loss 1.086626    Objective Loss 1.086626                                        LR 0.001000    Time 0.296039    
2024-04-04 17:10:16,459 - Epoch: [3][   30/  139]    Overall Loss 1.085854    Objective Loss 1.085854                                        LR 0.001000    Time 0.285738    
2024-04-04 17:10:19,108 - Epoch: [3][   40/  139]    Overall Loss 1.086762    Objective Loss 1.086762                                        LR 0.001000    Time 0.280519    
2024-04-04 17:10:21,760 - Epoch: [3][   50/  139]    Overall Loss 1.087251    Objective Loss 1.087251                                        LR 0.001000    Time 0.277441    
2024-04-04 17:10:24,424 - Epoch: [3][   60/  139]    Overall Loss 1.087905    Objective Loss 1.087905                                        LR 0.001000    Time 0.275598    
2024-04-04 17:10:27,079 - Epoch: [3][   70/  139]    Overall Loss 1.086684    Objective Loss 1.086684                                        LR 0.001000    Time 0.274139    
2024-04-04 17:10:29,733 - Epoch: [3][   80/  139]    Overall Loss 1.085223    Objective Loss 1.085223                                        LR 0.001000    Time 0.273040    
2024-04-04 17:10:32,393 - Epoch: [3][   90/  139]    Overall Loss 1.084604    Objective Loss 1.084604                                        LR 0.001000    Time 0.272259    
2024-04-04 17:10:35,052 - Epoch: [3][  100/  139]    Overall Loss 1.083934    Objective Loss 1.083934                                        LR 0.001000    Time 0.271616    
2024-04-04 17:10:37,712 - Epoch: [3][  110/  139]    Overall Loss 1.084461    Objective Loss 1.084461                                        LR 0.001000    Time 0.271097    
2024-04-04 17:10:40,366 - Epoch: [3][  120/  139]    Overall Loss 1.084757    Objective Loss 1.084757                                        LR 0.001000    Time 0.270625    
2024-04-04 17:10:43,026 - Epoch: [3][  130/  139]    Overall Loss 1.084814    Objective Loss 1.084814                                        LR 0.001000    Time 0.270262    
2024-04-04 17:10:50,476 - Epoch: [3][  139/  139]    Overall Loss 1.084988    Objective Loss 1.084988    Top1 89.093848    LR 0.001000    Time 0.306354    
2024-04-04 17:10:50,655 - --- validate (epoch=3)-----------
2024-04-04 17:10:50,656 - 1392 samples (32 per mini-batch)
2024-04-04 17:11:22,582 - Epoch: [3][   10/   44]    Loss 1.083415    Top1 86.637697    
2024-04-04 17:11:53,504 - Epoch: [3][   20/   44]    Loss 1.077567    Top1 86.648706    
2024-04-04 17:12:25,022 - Epoch: [3][   30/   44]    Loss 1.079103    Top1 86.444714    
2024-04-04 17:12:56,756 - Epoch: [3][   40/   44]    Loss 1.079615    Top1 86.143876    
2024-04-04 17:13:08,442 - Epoch: [3][   44/   44]    Loss 1.078945    Top1 86.265330    
2024-04-04 17:13:08,631 - ==> Top1: 86.265    Loss: 1.079

2024-04-04 17:13:08,638 - ==> Best [Top1: 86.265   Sparsity:0.00   Params: 272800 on epoch: 3]
2024-04-04 17:13:08,638 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:13:08,681 - 

2024-04-04 17:13:08,681 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:13:12,016 - Epoch: [4][   10/  139]    Overall Loss 1.097251    Objective Loss 1.097251                                        LR 0.001000    Time 0.333228    
2024-04-04 17:13:14,662 - Epoch: [4][   20/  139]    Overall Loss 1.091013    Objective Loss 1.091013                                        LR 0.001000    Time 0.298879    
2024-04-04 17:13:17,314 - Epoch: [4][   30/  139]    Overall Loss 1.088825    Objective Loss 1.088825                                        LR 0.001000    Time 0.287630    
2024-04-04 17:13:19,965 - Epoch: [4][   40/  139]    Overall Loss 1.084595    Objective Loss 1.084595                                        LR 0.001000    Time 0.281980    
2024-04-04 17:13:22,610 - Epoch: [4][   50/  139]    Overall Loss 1.083037    Objective Loss 1.083037                                        LR 0.001000    Time 0.278479    
2024-04-04 17:13:25,268 - Epoch: [4][   60/  139]    Overall Loss 1.082032    Objective Loss 1.082032                                        LR 0.001000    Time 0.276363    
2024-04-04 17:13:27,924 - Epoch: [4][   70/  139]    Overall Loss 1.082118    Objective Loss 1.082118                                        LR 0.001000    Time 0.274813    
2024-04-04 17:13:30,574 - Epoch: [4][   80/  139]    Overall Loss 1.082472    Objective Loss 1.082472                                        LR 0.001000    Time 0.273577    
2024-04-04 17:13:33,228 - Epoch: [4][   90/  139]    Overall Loss 1.082899    Objective Loss 1.082899                                        LR 0.001000    Time 0.272662    
2024-04-04 17:13:35,879 - Epoch: [4][  100/  139]    Overall Loss 1.082887    Objective Loss 1.082887                                        LR 0.001000    Time 0.271902    
2024-04-04 17:13:38,532 - Epoch: [4][  110/  139]    Overall Loss 1.082600    Objective Loss 1.082600                                        LR 0.001000    Time 0.271300    
2024-04-04 17:13:41,192 - Epoch: [4][  120/  139]    Overall Loss 1.082243    Objective Loss 1.082243                                        LR 0.001000    Time 0.270855    
2024-04-04 17:13:43,846 - Epoch: [4][  130/  139]    Overall Loss 1.081939    Objective Loss 1.081939                                        LR 0.001000    Time 0.270431    
2024-04-04 17:13:50,740 - Epoch: [4][  139/  139]    Overall Loss 1.081782    Objective Loss 1.081782    Top1 88.045602    LR 0.001000    Time 0.302514    
2024-04-04 17:13:51,009 - --- validate (epoch=4)-----------
2024-04-04 17:13:51,010 - 1392 samples (32 per mini-batch)
2024-04-04 17:14:23,602 - Epoch: [4][   10/   44]    Loss 1.077214    Top1 85.798955    
2024-04-04 17:14:57,085 - Epoch: [4][   20/   44]    Loss 1.078761    Top1 85.449301    
2024-04-04 17:15:28,760 - Epoch: [4][   30/   44]    Loss 1.077422    Top1 85.251961    
2024-04-04 17:15:59,822 - Epoch: [4][   40/   44]    Loss 1.073883    Top1 85.624006    
2024-04-04 17:16:10,856 - Epoch: [4][   44/   44]    Loss 1.074127    Top1 85.592068    
2024-04-04 17:16:11,130 - ==> Top1: 85.592    Loss: 1.074

2024-04-04 17:16:11,137 - ==> Best [Top1: 86.265   Sparsity:0.00   Params: 272800 on epoch: 3]
2024-04-04 17:16:11,137 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:16:11,173 - 

2024-04-04 17:16:11,173 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:16:14,412 - Epoch: [5][   10/  139]    Overall Loss 1.078721    Objective Loss 1.078721                                        LR 0.001000    Time 0.323774    
2024-04-04 17:16:17,066 - Epoch: [5][   20/  139]    Overall Loss 1.080626    Objective Loss 1.080626                                        LR 0.001000    Time 0.294558    
2024-04-04 17:16:19,722 - Epoch: [5][   30/  139]    Overall Loss 1.082233    Objective Loss 1.082233                                        LR 0.001000    Time 0.284889    
2024-04-04 17:16:22,381 - Epoch: [5][   40/  139]    Overall Loss 1.082171    Objective Loss 1.082171                                        LR 0.001000    Time 0.280117    
2024-04-04 17:16:25,027 - Epoch: [5][   50/  139]    Overall Loss 1.079217    Objective Loss 1.079217                                        LR 0.001000    Time 0.276998    
2024-04-04 17:16:27,684 - Epoch: [5][   60/  139]    Overall Loss 1.079052    Objective Loss 1.079052                                        LR 0.001000    Time 0.275114    
2024-04-04 17:16:30,343 - Epoch: [5][   70/  139]    Overall Loss 1.078654    Objective Loss 1.078654                                        LR 0.001000    Time 0.273792    
2024-04-04 17:16:33,000 - Epoch: [5][   80/  139]    Overall Loss 1.078187    Objective Loss 1.078187                                        LR 0.001000    Time 0.272769    
2024-04-04 17:16:35,654 - Epoch: [5][   90/  139]    Overall Loss 1.077882    Objective Loss 1.077882                                        LR 0.001000    Time 0.271952    
2024-04-04 17:16:38,309 - Epoch: [5][  100/  139]    Overall Loss 1.078627    Objective Loss 1.078627                                        LR 0.001000    Time 0.271296    
2024-04-04 17:16:40,962 - Epoch: [5][  110/  139]    Overall Loss 1.078539    Objective Loss 1.078539                                        LR 0.001000    Time 0.270753    
2024-04-04 17:16:43,619 - Epoch: [5][  120/  139]    Overall Loss 1.078568    Objective Loss 1.078568                                        LR 0.001000    Time 0.270324    
2024-04-04 17:16:46,271 - Epoch: [5][  130/  139]    Overall Loss 1.078336    Objective Loss 1.078336                                        LR 0.001000    Time 0.269928    
2024-04-04 17:16:53,167 - Epoch: [5][  139/  139]    Overall Loss 1.079226    Objective Loss 1.079226    Top1 87.169576    LR 0.001000    Time 0.302060    
2024-04-04 17:16:53,462 - --- validate (epoch=5)-----------
2024-04-04 17:16:53,463 - 1392 samples (32 per mini-batch)
2024-04-04 17:17:25,826 - Epoch: [5][   10/   44]    Loss 1.078734    Top1 86.537077    
2024-04-04 17:17:58,220 - Epoch: [5][   20/   44]    Loss 1.075767    Top1 86.629081    
2024-04-04 17:18:29,885 - Epoch: [5][   30/   44]    Loss 1.078453    Top1 86.560818    
2024-04-04 17:19:01,699 - Epoch: [5][   40/   44]    Loss 1.075138    Top1 86.928873    
2024-04-04 17:19:12,247 - Epoch: [5][   44/   44]    Loss 1.073503    Top1 86.925429    
2024-04-04 17:19:12,524 - ==> Top1: 86.925    Loss: 1.074

2024-04-04 17:19:12,533 - ==> Best [Top1: 86.925   Sparsity:0.00   Params: 272800 on epoch: 5]
2024-04-04 17:19:12,534 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:19:12,574 - 

2024-04-04 17:19:12,574 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:19:15,873 - Epoch: [6][   10/  139]    Overall Loss 1.077543    Objective Loss 1.077543                                        LR 0.001000    Time 0.329791    
2024-04-04 17:19:18,525 - Epoch: [6][   20/  139]    Overall Loss 1.079103    Objective Loss 1.079103                                        LR 0.001000    Time 0.297473    
2024-04-04 17:19:21,176 - Epoch: [6][   30/  139]    Overall Loss 1.078126    Objective Loss 1.078126                                        LR 0.001000    Time 0.286650    
2024-04-04 17:19:23,823 - Epoch: [6][   40/  139]    Overall Loss 1.077670    Objective Loss 1.077670                                        LR 0.001000    Time 0.281162    
2024-04-04 17:19:26,472 - Epoch: [6][   50/  139]    Overall Loss 1.076651    Objective Loss 1.076651                                        LR 0.001000    Time 0.277892    
2024-04-04 17:19:29,126 - Epoch: [6][   60/  139]    Overall Loss 1.075015    Objective Loss 1.075015                                        LR 0.001000    Time 0.275809    
2024-04-04 17:19:31,780 - Epoch: [6][   70/  139]    Overall Loss 1.075445    Objective Loss 1.075445                                        LR 0.001000    Time 0.274319    
2024-04-04 17:19:34,435 - Epoch: [6][   80/  139]    Overall Loss 1.075418    Objective Loss 1.075418                                        LR 0.001000    Time 0.273210    
2024-04-04 17:19:37,084 - Epoch: [6][   90/  139]    Overall Loss 1.074803    Objective Loss 1.074803                                        LR 0.001000    Time 0.272284    
2024-04-04 17:19:39,734 - Epoch: [6][  100/  139]    Overall Loss 1.074953    Objective Loss 1.074953                                        LR 0.001000    Time 0.271542    
2024-04-04 17:19:42,385 - Epoch: [6][  110/  139]    Overall Loss 1.074481    Objective Loss 1.074481                                        LR 0.001000    Time 0.270960    
2024-04-04 17:19:45,036 - Epoch: [6][  120/  139]    Overall Loss 1.074618    Objective Loss 1.074618                                        LR 0.001000    Time 0.270460    
2024-04-04 17:19:47,688 - Epoch: [6][  130/  139]    Overall Loss 1.075230    Objective Loss 1.075230                                        LR 0.001000    Time 0.270052    
2024-04-04 17:19:55,078 - Epoch: [6][  139/  139]    Overall Loss 1.075627    Objective Loss 1.075627    Top1 86.538919    LR 0.001000    Time 0.305728    
2024-04-04 17:19:55,361 - --- validate (epoch=6)-----------
2024-04-04 17:19:55,361 - 1392 samples (32 per mini-batch)
2024-04-04 17:20:27,620 - Epoch: [6][   10/   44]    Loss 1.101177    Top1 85.130540    
2024-04-04 17:20:58,469 - Epoch: [6][   20/   44]    Loss 1.099970    Top1 84.658487    
2024-04-04 17:21:30,761 - Epoch: [6][   30/   44]    Loss 1.099968    Top1 84.583443    
2024-04-04 17:22:02,564 - Epoch: [6][   40/   44]    Loss 1.097578    Top1 84.836740    
2024-04-04 17:22:13,672 - Epoch: [6][   44/   44]    Loss 1.097224    Top1 84.843608    
2024-04-04 17:22:13,904 - ==> Top1: 84.844    Loss: 1.097

2024-04-04 17:22:13,911 - ==> Best [Top1: 86.925   Sparsity:0.00   Params: 272800 on epoch: 5]
2024-04-04 17:22:13,911 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:22:13,946 - 

2024-04-04 17:22:13,946 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:22:17,209 - Epoch: [7][   10/  139]    Overall Loss 1.070466    Objective Loss 1.070466                                        LR 0.001000    Time 0.326235    
2024-04-04 17:22:19,861 - Epoch: [7][   20/  139]    Overall Loss 1.075911    Objective Loss 1.075911                                        LR 0.001000    Time 0.295658    
2024-04-04 17:22:22,514 - Epoch: [7][   30/  139]    Overall Loss 1.075707    Objective Loss 1.075707                                        LR 0.001000    Time 0.285528    
2024-04-04 17:22:25,167 - Epoch: [7][   40/  139]    Overall Loss 1.077442    Objective Loss 1.077442                                        LR 0.001000    Time 0.280467    
2024-04-04 17:22:27,820 - Epoch: [7][   50/  139]    Overall Loss 1.077053    Objective Loss 1.077053                                        LR 0.001000    Time 0.277408    
2024-04-04 17:22:30,473 - Epoch: [7][   60/  139]    Overall Loss 1.076039    Objective Loss 1.076039                                        LR 0.001000    Time 0.275390    
2024-04-04 17:22:33,124 - Epoch: [7][   70/  139]    Overall Loss 1.076660    Objective Loss 1.076660                                        LR 0.001000    Time 0.273917    
2024-04-04 17:22:35,780 - Epoch: [7][   80/  139]    Overall Loss 1.076330    Objective Loss 1.076330                                        LR 0.001000    Time 0.272865    
2024-04-04 17:22:38,433 - Epoch: [7][   90/  139]    Overall Loss 1.077219    Objective Loss 1.077219                                        LR 0.001000    Time 0.272025    
2024-04-04 17:22:41,091 - Epoch: [7][  100/  139]    Overall Loss 1.076301    Objective Loss 1.076301                                        LR 0.001000    Time 0.271395    
2024-04-04 17:22:43,751 - Epoch: [7][  110/  139]    Overall Loss 1.076821    Objective Loss 1.076821                                        LR 0.001000    Time 0.270899    
2024-04-04 17:22:46,403 - Epoch: [7][  120/  139]    Overall Loss 1.076694    Objective Loss 1.076694                                        LR 0.001000    Time 0.270419    
2024-04-04 17:22:49,056 - Epoch: [7][  130/  139]    Overall Loss 1.076573    Objective Loss 1.076573                                        LR 0.001000    Time 0.270025    
2024-04-04 17:22:55,602 - Epoch: [7][  139/  139]    Overall Loss 1.076712    Objective Loss 1.076712    Top1 87.873456    LR 0.001000    Time 0.299628    
2024-04-04 17:22:55,879 - --- validate (epoch=7)-----------
2024-04-04 17:22:55,880 - 1392 samples (32 per mini-batch)
2024-04-04 17:23:28,830 - Epoch: [7][   10/   44]    Loss 1.079668    Top1 85.896634    
2024-04-04 17:24:01,375 - Epoch: [7][   20/   44]    Loss 1.077705    Top1 86.692876    
2024-04-04 17:24:33,437 - Epoch: [7][   30/   44]    Loss 1.074856    Top1 86.948029    
2024-04-04 17:25:04,502 - Epoch: [7][   40/   44]    Loss 1.074308    Top1 86.926603    
2024-04-04 17:25:15,743 - Epoch: [7][   44/   44]    Loss 1.075230    Top1 86.890698    
2024-04-04 17:25:15,962 - ==> Top1: 86.891    Loss: 1.075

2024-04-04 17:25:15,969 - ==> Best [Top1: 86.925   Sparsity:0.00   Params: 272800 on epoch: 5]
2024-04-04 17:25:15,969 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:25:16,006 - 

2024-04-04 17:25:16,006 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:25:19,298 - Epoch: [8][   10/  139]    Overall Loss 1.074892    Objective Loss 1.074892                                        LR 0.001000    Time 0.329020    
2024-04-04 17:25:21,947 - Epoch: [8][   20/  139]    Overall Loss 1.075428    Objective Loss 1.075428                                        LR 0.001000    Time 0.296946    
2024-04-04 17:25:24,596 - Epoch: [8][   30/  139]    Overall Loss 1.078276    Objective Loss 1.078276                                        LR 0.001000    Time 0.286223    
2024-04-04 17:25:27,250 - Epoch: [8][   40/  139]    Overall Loss 1.078631    Objective Loss 1.078631                                        LR 0.001000    Time 0.280999    
2024-04-04 17:25:29,903 - Epoch: [8][   50/  139]    Overall Loss 1.076717    Objective Loss 1.076717                                        LR 0.001000    Time 0.277863    
2024-04-04 17:25:32,553 - Epoch: [8][   60/  139]    Overall Loss 1.077177    Objective Loss 1.077177                                        LR 0.001000    Time 0.275707    
2024-04-04 17:25:35,204 - Epoch: [8][   70/  139]    Overall Loss 1.076386    Objective Loss 1.076386                                        LR 0.001000    Time 0.274191    
2024-04-04 17:25:37,861 - Epoch: [8][   80/  139]    Overall Loss 1.075253    Objective Loss 1.075253                                        LR 0.001000    Time 0.273123    
2024-04-04 17:25:40,514 - Epoch: [8][   90/  139]    Overall Loss 1.073919    Objective Loss 1.073919                                        LR 0.001000    Time 0.272247    
2024-04-04 17:25:43,170 - Epoch: [8][  100/  139]    Overall Loss 1.073329    Objective Loss 1.073329                                        LR 0.001000    Time 0.271568    
2024-04-04 17:25:45,820 - Epoch: [8][  110/  139]    Overall Loss 1.072802    Objective Loss 1.072802                                        LR 0.001000    Time 0.270975    
2024-04-04 17:25:48,471 - Epoch: [8][  120/  139]    Overall Loss 1.073697    Objective Loss 1.073697                                        LR 0.001000    Time 0.270477    
2024-04-04 17:25:51,121 - Epoch: [8][  130/  139]    Overall Loss 1.073861    Objective Loss 1.073861                                        LR 0.001000    Time 0.270050    
2024-04-04 17:25:58,639 - Epoch: [8][  139/  139]    Overall Loss 1.074005    Objective Loss 1.074005    Top1 89.906133    LR 0.001000    Time 0.306651    
2024-04-04 17:25:58,909 - --- validate (epoch=8)-----------
2024-04-04 17:25:58,911 - 1392 samples (32 per mini-batch)
2024-04-04 17:26:31,077 - Epoch: [8][   10/   44]    Loss 1.083723    Top1 86.942487    
2024-04-04 17:27:03,329 - Epoch: [8][   20/   44]    Loss 1.078285    Top1 87.310148    
2024-04-04 17:27:34,794 - Epoch: [8][   30/   44]    Loss 1.076677    Top1 87.321676    
2024-04-04 17:28:06,900 - Epoch: [8][   40/   44]    Loss 1.077925    Top1 86.850987    
2024-04-04 17:28:18,281 - Epoch: [8][   44/   44]    Loss 1.076818    Top1 86.978746    
2024-04-04 17:28:18,495 - ==> Top1: 86.979    Loss: 1.077

2024-04-04 17:28:18,503 - ==> Best [Top1: 86.979   Sparsity:0.00   Params: 272800 on epoch: 8]
2024-04-04 17:28:18,503 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:28:18,542 - 

2024-04-04 17:28:18,542 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:28:21,897 - Epoch: [9][   10/  139]    Overall Loss 1.076735    Objective Loss 1.076735                                        LR 0.001000    Time 0.335328    
2024-04-04 17:28:24,549 - Epoch: [9][   20/  139]    Overall Loss 1.071025    Objective Loss 1.071025                                        LR 0.001000    Time 0.300260    
2024-04-04 17:28:27,206 - Epoch: [9][   30/  139]    Overall Loss 1.075015    Objective Loss 1.075015                                        LR 0.001000    Time 0.288718    
2024-04-04 17:28:29,860 - Epoch: [9][   40/  139]    Overall Loss 1.074563    Objective Loss 1.074563                                        LR 0.001000    Time 0.282879    
2024-04-04 17:28:32,520 - Epoch: [9][   50/  139]    Overall Loss 1.075046    Objective Loss 1.075046                                        LR 0.001000    Time 0.279494    
2024-04-04 17:28:35,178 - Epoch: [9][   60/  139]    Overall Loss 1.074137    Objective Loss 1.074137                                        LR 0.001000    Time 0.277208    
2024-04-04 17:28:37,837 - Epoch: [9][   70/  139]    Overall Loss 1.075399    Objective Loss 1.075399                                        LR 0.001000    Time 0.275581    
2024-04-04 17:28:40,498 - Epoch: [9][   80/  139]    Overall Loss 1.075811    Objective Loss 1.075811                                        LR 0.001000    Time 0.274391    
2024-04-04 17:28:43,160 - Epoch: [9][   90/  139]    Overall Loss 1.075080    Objective Loss 1.075080                                        LR 0.001000    Time 0.273469    
2024-04-04 17:28:45,816 - Epoch: [9][  100/  139]    Overall Loss 1.074205    Objective Loss 1.074205                                        LR 0.001000    Time 0.272686    
2024-04-04 17:28:48,468 - Epoch: [9][  110/  139]    Overall Loss 1.073438    Objective Loss 1.073438                                        LR 0.001000    Time 0.271993    
2024-04-04 17:28:51,134 - Epoch: [9][  120/  139]    Overall Loss 1.073255    Objective Loss 1.073255                                        LR 0.001000    Time 0.271546    
2024-04-04 17:28:53,786 - Epoch: [9][  130/  139]    Overall Loss 1.073493    Objective Loss 1.073493                                        LR 0.001000    Time 0.271047    
2024-04-04 17:29:00,539 - Epoch: [9][  139/  139]    Overall Loss 1.073438    Objective Loss 1.073438    Top1 90.623202    LR 0.001000    Time 0.302080    
2024-04-04 17:29:00,726 - --- validate (epoch=9)-----------
2024-04-04 17:29:00,726 - 1392 samples (32 per mini-batch)
2024-04-04 17:29:34,371 - Epoch: [9][   10/   44]    Loss 1.064476    Top1 89.935101    
2024-04-04 17:30:06,041 - Epoch: [9][   20/   44]    Loss 1.068923    Top1 90.047127    
2024-04-04 17:30:37,599 - Epoch: [9][   30/   44]    Loss 1.073753    Top1 89.645815    
2024-04-04 17:31:10,504 - Epoch: [9][   40/   44]    Loss 1.072536    Top1 89.450232    
2024-04-04 17:31:22,216 - Epoch: [9][   44/   44]    Loss 1.071922    Top1 89.343610    
2024-04-04 17:31:22,510 - ==> Top1: 89.344    Loss: 1.072

2024-04-04 17:31:22,517 - ==> Best [Top1: 89.344   Sparsity:0.00   Params: 272800 on epoch: 9]
2024-04-04 17:31:22,517 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:31:22,553 - 

2024-04-04 17:31:22,553 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:31:25,981 - Epoch: [10][   10/  139]    Overall Loss 1.068921    Objective Loss 1.068921                                        LR 0.001000    Time 0.342667    
2024-04-04 17:31:28,631 - Epoch: [10][   20/  139]    Overall Loss 1.071760    Objective Loss 1.071760                                        LR 0.001000    Time 0.303787    
2024-04-04 17:31:31,271 - Epoch: [10][   30/  139]    Overall Loss 1.068208    Objective Loss 1.068208                                        LR 0.001000    Time 0.290512    
2024-04-04 17:31:33,938 - Epoch: [10][   40/  139]    Overall Loss 1.066944    Objective Loss 1.066944                                        LR 0.001000    Time 0.284555    
2024-04-04 17:31:36,587 - Epoch: [10][   50/  139]    Overall Loss 1.067558    Objective Loss 1.067558                                        LR 0.001000    Time 0.280610    
2024-04-04 17:31:39,235 - Epoch: [10][   60/  139]    Overall Loss 1.069054    Objective Loss 1.069054                                        LR 0.001000    Time 0.277969    
2024-04-04 17:31:41,884 - Epoch: [10][   70/  139]    Overall Loss 1.069657    Objective Loss 1.069657                                        LR 0.001000    Time 0.276100    
2024-04-04 17:31:44,534 - Epoch: [10][   80/  139]    Overall Loss 1.068927    Objective Loss 1.068927                                        LR 0.001000    Time 0.274699    
2024-04-04 17:31:47,184 - Epoch: [10][   90/  139]    Overall Loss 1.069112    Objective Loss 1.069112                                        LR 0.001000    Time 0.273619    
2024-04-04 17:31:49,832 - Epoch: [10][  100/  139]    Overall Loss 1.069085    Objective Loss 1.069085                                        LR 0.001000    Time 0.272737    
2024-04-04 17:31:52,482 - Epoch: [10][  110/  139]    Overall Loss 1.069768    Objective Loss 1.069768                                        LR 0.001000    Time 0.272028    
2024-04-04 17:31:55,130 - Epoch: [10][  120/  139]    Overall Loss 1.070482    Objective Loss 1.070482                                        LR 0.001000    Time 0.271417    
2024-04-04 17:31:57,778 - Epoch: [10][  130/  139]    Overall Loss 1.070488    Objective Loss 1.070488                                        LR 0.001000    Time 0.270908    
2024-04-04 17:32:04,828 - Epoch: [10][  139/  139]    Overall Loss 1.070703    Objective Loss 1.070703    Top1 91.186927    LR 0.001000    Time 0.304084    
2024-04-04 17:32:05,103 - --- validate (epoch=10)-----------
2024-04-04 17:32:05,104 - 1392 samples (32 per mini-batch)
2024-04-04 17:32:38,203 - Epoch: [10][   10/   44]    Loss 1.067881    Top1 89.028409    
2024-04-04 17:33:10,821 - Epoch: [10][   20/   44]    Loss 1.073706    Top1 88.570780    
2024-04-04 17:33:44,790 - Epoch: [10][   30/   44]    Loss 1.073599    Top1 88.648986    
2024-04-04 17:34:17,214 - Epoch: [10][   40/   44]    Loss 1.073240    Top1 88.585645    
2024-04-04 17:34:27,785 - Epoch: [10][   44/   44]    Loss 1.072517    Top1 88.685615    
2024-04-04 17:34:28,083 - ==> Top1: 88.686    Loss: 1.073

2024-04-04 17:34:28,090 - ==> Best [Top1: 89.344   Sparsity:0.00   Params: 272800 on epoch: 9]
2024-04-04 17:34:28,090 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:34:28,128 - 

2024-04-04 17:34:28,128 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:34:31,535 - Epoch: [11][   10/  139]    Overall Loss 1.059345    Objective Loss 1.059345                                        LR 0.001000    Time 0.340561    
2024-04-04 17:34:34,175 - Epoch: [11][   20/  139]    Overall Loss 1.066366    Objective Loss 1.066366                                        LR 0.001000    Time 0.302249    
2024-04-04 17:34:36,821 - Epoch: [11][   30/  139]    Overall Loss 1.065463    Objective Loss 1.065463                                        LR 0.001000    Time 0.289667    
2024-04-04 17:34:39,462 - Epoch: [11][   40/  139]    Overall Loss 1.067190    Objective Loss 1.067190                                        LR 0.001000    Time 0.283277    
2024-04-04 17:34:42,111 - Epoch: [11][   50/  139]    Overall Loss 1.067950    Objective Loss 1.067950                                        LR 0.001000    Time 0.279588    
2024-04-04 17:34:44,769 - Epoch: [11][   60/  139]    Overall Loss 1.066907    Objective Loss 1.066907                                        LR 0.001000    Time 0.277281    
2024-04-04 17:34:47,418 - Epoch: [11][   70/  139]    Overall Loss 1.067402    Objective Loss 1.067402                                        LR 0.001000    Time 0.275511    
2024-04-04 17:34:50,067 - Epoch: [11][   80/  139]    Overall Loss 1.068564    Objective Loss 1.068564                                        LR 0.001000    Time 0.274175    
2024-04-04 17:34:52,718 - Epoch: [11][   90/  139]    Overall Loss 1.068664    Objective Loss 1.068664                                        LR 0.001000    Time 0.273163    
2024-04-04 17:34:55,362 - Epoch: [11][  100/  139]    Overall Loss 1.069128    Objective Loss 1.069128                                        LR 0.001000    Time 0.272278    
2024-04-04 17:34:58,012 - Epoch: [11][  110/  139]    Overall Loss 1.069363    Objective Loss 1.069363                                        LR 0.001000    Time 0.271618    
2024-04-04 17:35:00,658 - Epoch: [11][  120/  139]    Overall Loss 1.069800    Objective Loss 1.069800                                        LR 0.001000    Time 0.271025    
2024-04-04 17:35:03,306 - Epoch: [11][  130/  139]    Overall Loss 1.070012    Objective Loss 1.070012                                        LR 0.001000    Time 0.270541    
2024-04-04 17:35:09,836 - Epoch: [11][  139/  139]    Overall Loss 1.070241    Objective Loss 1.070241    Top1 86.896912    LR 0.001000    Time 0.300003    
2024-04-04 17:35:10,146 - --- validate (epoch=11)-----------
2024-04-04 17:35:10,146 - 1392 samples (32 per mini-batch)
2024-04-04 17:35:42,443 - Epoch: [11][   10/   44]    Loss 1.114736    Top1 80.386812    
2024-04-04 17:36:14,282 - Epoch: [11][   20/   44]    Loss 1.108987    Top1 80.750064    
2024-04-04 17:36:45,888 - Epoch: [11][   30/   44]    Loss 1.114465    Top1 80.146511    
2024-04-04 17:37:17,666 - Epoch: [11][   40/   44]    Loss 1.111073    Top1 80.165601    
2024-04-04 17:37:29,256 - Epoch: [11][   44/   44]    Loss 1.112669    Top1 80.279342    
2024-04-04 17:37:29,595 - ==> Top1: 80.279    Loss: 1.113

2024-04-04 17:37:29,602 - ==> Best [Top1: 89.344   Sparsity:0.00   Params: 272800 on epoch: 9]
2024-04-04 17:37:29,602 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:37:29,640 - 

2024-04-04 17:37:29,640 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:37:32,982 - Epoch: [12][   10/  139]    Overall Loss 1.078808    Objective Loss 1.078808                                        LR 0.001000    Time 0.334028    
2024-04-04 17:37:35,631 - Epoch: [12][   20/  139]    Overall Loss 1.073839    Objective Loss 1.073839                                        LR 0.001000    Time 0.299437    
2024-04-04 17:37:38,286 - Epoch: [12][   30/  139]    Overall Loss 1.074096    Objective Loss 1.074096                                        LR 0.001000    Time 0.288134    
2024-04-04 17:37:40,934 - Epoch: [12][   40/  139]    Overall Loss 1.076664    Objective Loss 1.076664                                        LR 0.001000    Time 0.282275    
2024-04-04 17:37:43,589 - Epoch: [12][   50/  139]    Overall Loss 1.075077    Objective Loss 1.075077                                        LR 0.001000    Time 0.278915    
2024-04-04 17:37:46,245 - Epoch: [12][   60/  139]    Overall Loss 1.074320    Objective Loss 1.074320                                        LR 0.001000    Time 0.276682    
2024-04-04 17:37:48,911 - Epoch: [12][   70/  139]    Overall Loss 1.074154    Objective Loss 1.074154                                        LR 0.001000    Time 0.275242    
2024-04-04 17:37:51,561 - Epoch: [12][   80/  139]    Overall Loss 1.072629    Objective Loss 1.072629                                        LR 0.001000    Time 0.273957    
2024-04-04 17:37:54,219 - Epoch: [12][   90/  139]    Overall Loss 1.072506    Objective Loss 1.072506                                        LR 0.001000    Time 0.273046    
2024-04-04 17:37:56,874 - Epoch: [12][  100/  139]    Overall Loss 1.072081    Objective Loss 1.072081                                        LR 0.001000    Time 0.272280    
2024-04-04 17:37:59,528 - Epoch: [12][  110/  139]    Overall Loss 1.071824    Objective Loss 1.071824                                        LR 0.001000    Time 0.271652    
2024-04-04 17:38:02,182 - Epoch: [12][  120/  139]    Overall Loss 1.071094    Objective Loss 1.071094                                        LR 0.001000    Time 0.271129    
2024-04-04 17:38:04,837 - Epoch: [12][  130/  139]    Overall Loss 1.070858    Objective Loss 1.070858                                        LR 0.001000    Time 0.270692    
2024-04-04 17:38:11,528 - Epoch: [12][  139/  139]    Overall Loss 1.070388    Objective Loss 1.070388    Top1 88.886025    LR 0.001000    Time 0.301298    
2024-04-04 17:38:11,734 - --- validate (epoch=12)-----------
2024-04-04 17:38:11,735 - 1392 samples (32 per mini-batch)
2024-04-04 17:38:43,804 - Epoch: [12][   10/   44]    Loss 1.065690    Top1 88.931804    
2024-04-04 17:39:15,746 - Epoch: [12][   20/   44]    Loss 1.062486    Top1 89.390429    
2024-04-04 17:39:45,966 - Epoch: [12][   30/   44]    Loss 1.061677    Top1 89.331515    
2024-04-04 17:40:17,331 - Epoch: [12][   40/   44]    Loss 1.065070    Top1 89.285704    
2024-04-04 17:40:28,494 - Epoch: [12][   44/   44]    Loss 1.065827    Top1 89.358124    
2024-04-04 17:40:28,723 - ==> Top1: 89.358    Loss: 1.066

2024-04-04 17:40:28,730 - ==> Best [Top1: 89.358   Sparsity:0.00   Params: 272800 on epoch: 12]
2024-04-04 17:40:28,731 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:40:28,769 - 

2024-04-04 17:40:28,769 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:40:32,047 - Epoch: [13][   10/  139]    Overall Loss 1.068789    Objective Loss 1.068789                                        LR 0.001000    Time 0.327649    
2024-04-04 17:40:34,690 - Epoch: [13][   20/  139]    Overall Loss 1.066456    Objective Loss 1.066456                                        LR 0.001000    Time 0.295916    
2024-04-04 17:40:37,351 - Epoch: [13][   30/  139]    Overall Loss 1.063539    Objective Loss 1.063539                                        LR 0.001000    Time 0.285979    
2024-04-04 17:40:40,005 - Epoch: [13][   40/  139]    Overall Loss 1.064810    Objective Loss 1.064810                                        LR 0.001000    Time 0.280819    
2024-04-04 17:40:42,652 - Epoch: [13][   50/  139]    Overall Loss 1.066199    Objective Loss 1.066199                                        LR 0.001000    Time 0.277589    
2024-04-04 17:40:45,316 - Epoch: [13][   60/  139]    Overall Loss 1.067578    Objective Loss 1.067578                                        LR 0.001000    Time 0.275712    
2024-04-04 17:40:47,973 - Epoch: [13][   70/  139]    Overall Loss 1.066937    Objective Loss 1.066937                                        LR 0.001000    Time 0.274276    
2024-04-04 17:40:50,625 - Epoch: [13][   80/  139]    Overall Loss 1.068199    Objective Loss 1.068199                                        LR 0.001000    Time 0.273133    
2024-04-04 17:40:53,287 - Epoch: [13][   90/  139]    Overall Loss 1.068403    Objective Loss 1.068403                                        LR 0.001000    Time 0.272355    
2024-04-04 17:40:55,943 - Epoch: [13][  100/  139]    Overall Loss 1.068013    Objective Loss 1.068013                                        LR 0.001000    Time 0.271677    
2024-04-04 17:40:58,604 - Epoch: [13][  110/  139]    Overall Loss 1.067927    Objective Loss 1.067927                                        LR 0.001000    Time 0.271167    
2024-04-04 17:41:01,262 - Epoch: [13][  120/  139]    Overall Loss 1.068146    Objective Loss 1.068146                                        LR 0.001000    Time 0.270712    
2024-04-04 17:41:03,920 - Epoch: [13][  130/  139]    Overall Loss 1.068624    Objective Loss 1.068624                                        LR 0.001000    Time 0.270335    
2024-04-04 17:41:10,677 - Epoch: [13][  139/  139]    Overall Loss 1.068217    Objective Loss 1.068217    Top1 90.636006    LR 0.001000    Time 0.301436    
2024-04-04 17:41:11,048 - --- validate (epoch=13)-----------
2024-04-04 17:41:11,049 - 1392 samples (32 per mini-batch)
2024-04-04 17:41:44,431 - Epoch: [13][   10/   44]    Loss 1.056438    Top1 89.118650    
2024-04-04 17:42:15,631 - Epoch: [13][   20/   44]    Loss 1.061147    Top1 89.308477    
2024-04-04 17:42:47,758 - Epoch: [13][   30/   44]    Loss 1.060743    Top1 89.619602    
2024-04-04 17:43:20,773 - Epoch: [13][   40/   44]    Loss 1.062927    Top1 89.738841    
2024-04-04 17:43:32,039 - Epoch: [13][   44/   44]    Loss 1.062688    Top1 89.802384    
2024-04-04 17:43:32,279 - ==> Top1: 89.802    Loss: 1.063

2024-04-04 17:43:32,286 - ==> Best [Top1: 89.802   Sparsity:0.00   Params: 272800 on epoch: 13]
2024-04-04 17:43:32,287 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:43:32,324 - 

2024-04-04 17:43:32,325 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:43:35,697 - Epoch: [14][   10/  139]    Overall Loss 1.065648    Objective Loss 1.065648                                        LR 0.001000    Time 0.337080    
2024-04-04 17:43:38,410 - Epoch: [14][   20/  139]    Overall Loss 1.062940    Objective Loss 1.062940                                        LR 0.001000    Time 0.304182    
2024-04-04 17:43:41,080 - Epoch: [14][   30/  139]    Overall Loss 1.063273    Objective Loss 1.063273                                        LR 0.001000    Time 0.291780    
2024-04-04 17:43:43,733 - Epoch: [14][   40/  139]    Overall Loss 1.064745    Objective Loss 1.064745                                        LR 0.001000    Time 0.285146    
2024-04-04 17:43:46,390 - Epoch: [14][   50/  139]    Overall Loss 1.065815    Objective Loss 1.065815                                        LR 0.001000    Time 0.281230    
2024-04-04 17:43:49,049 - Epoch: [14][   60/  139]    Overall Loss 1.065399    Objective Loss 1.065399                                        LR 0.001000    Time 0.278681    
2024-04-04 17:43:51,705 - Epoch: [14][   70/  139]    Overall Loss 1.065209    Objective Loss 1.065209                                        LR 0.001000    Time 0.276794    
2024-04-04 17:43:54,359 - Epoch: [14][   80/  139]    Overall Loss 1.065372    Objective Loss 1.065372                                        LR 0.001000    Time 0.275368    
2024-04-04 17:43:57,019 - Epoch: [14][   90/  139]    Overall Loss 1.065657    Objective Loss 1.065657                                        LR 0.001000    Time 0.274328    
2024-04-04 17:43:59,673 - Epoch: [14][  100/  139]    Overall Loss 1.066636    Objective Loss 1.066636                                        LR 0.001000    Time 0.273430    
2024-04-04 17:44:02,331 - Epoch: [14][  110/  139]    Overall Loss 1.067461    Objective Loss 1.067461                                        LR 0.001000    Time 0.272725    
2024-04-04 17:44:04,984 - Epoch: [14][  120/  139]    Overall Loss 1.067727    Objective Loss 1.067727                                        LR 0.001000    Time 0.272102    
2024-04-04 17:44:07,639 - Epoch: [14][  130/  139]    Overall Loss 1.067812    Objective Loss 1.067812                                        LR 0.001000    Time 0.271591    
2024-04-04 17:44:15,194 - Epoch: [14][  139/  139]    Overall Loss 1.067719    Objective Loss 1.067719    Top1 91.489287    LR 0.001000    Time 0.308352    
2024-04-04 17:44:15,385 - --- validate (epoch=14)-----------
2024-04-04 17:44:15,387 - 1392 samples (32 per mini-batch)
2024-04-04 17:44:47,725 - Epoch: [14][   10/   44]    Loss 1.083229    Top1 85.687054    
2024-04-04 17:45:18,896 - Epoch: [14][   20/   44]    Loss 1.080766    Top1 86.523092    
2024-04-04 17:45:50,290 - Epoch: [14][   30/   44]    Loss 1.077493    Top1 87.050405    
2024-04-04 17:46:22,293 - Epoch: [14][   40/   44]    Loss 1.078393    Top1 87.212338    
2024-04-04 17:46:33,314 - Epoch: [14][   44/   44]    Loss 1.078908    Top1 87.135813    
2024-04-04 17:46:33,618 - ==> Top1: 87.136    Loss: 1.079

2024-04-04 17:46:33,625 - ==> Best [Top1: 89.802   Sparsity:0.00   Params: 272800 on epoch: 13]
2024-04-04 17:46:33,626 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:46:33,661 - 

2024-04-04 17:46:33,661 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:46:36,915 - Epoch: [15][   10/  139]    Overall Loss 1.072310    Objective Loss 1.072310                                        LR 0.001000    Time 0.325202    
2024-04-04 17:46:39,564 - Epoch: [15][   20/  139]    Overall Loss 1.065767    Objective Loss 1.065767                                        LR 0.001000    Time 0.295032    
2024-04-04 17:46:42,212 - Epoch: [15][   30/  139]    Overall Loss 1.067117    Objective Loss 1.067117                                        LR 0.001000    Time 0.284956    
2024-04-04 17:46:44,864 - Epoch: [15][   40/  139]    Overall Loss 1.068050    Objective Loss 1.068050                                        LR 0.001000    Time 0.280006    
2024-04-04 17:46:47,515 - Epoch: [15][   50/  139]    Overall Loss 1.068847    Objective Loss 1.068847                                        LR 0.001000    Time 0.277005    
2024-04-04 17:46:50,165 - Epoch: [15][   60/  139]    Overall Loss 1.067659    Objective Loss 1.067659                                        LR 0.001000    Time 0.275006    
2024-04-04 17:46:52,816 - Epoch: [15][   70/  139]    Overall Loss 1.067797    Objective Loss 1.067797                                        LR 0.001000    Time 0.273578    
2024-04-04 17:46:55,489 - Epoch: [15][   80/  139]    Overall Loss 1.067615    Objective Loss 1.067615                                        LR 0.001000    Time 0.272795    
2024-04-04 17:46:58,144 - Epoch: [15][   90/  139]    Overall Loss 1.066944    Objective Loss 1.066944                                        LR 0.001000    Time 0.271969    
2024-04-04 17:47:00,801 - Epoch: [15][  100/  139]    Overall Loss 1.067214    Objective Loss 1.067214                                        LR 0.001000    Time 0.271338    
2024-04-04 17:47:03,458 - Epoch: [15][  110/  139]    Overall Loss 1.067426    Objective Loss 1.067426                                        LR 0.001000    Time 0.270825    
2024-04-04 17:47:06,107 - Epoch: [15][  120/  139]    Overall Loss 1.067874    Objective Loss 1.067874                                        LR 0.001000    Time 0.270324    
2024-04-04 17:47:08,768 - Epoch: [15][  130/  139]    Overall Loss 1.067690    Objective Loss 1.067690                                        LR 0.001000    Time 0.269996    
2024-04-04 17:47:15,207 - Epoch: [15][  139/  139]    Overall Loss 1.067541    Objective Loss 1.067541    Top1 93.726173    LR 0.001000    Time 0.298827    
2024-04-04 17:47:15,531 - --- validate (epoch=15)-----------
2024-04-04 17:47:15,532 - 1392 samples (32 per mini-batch)
2024-04-04 17:47:49,182 - Epoch: [15][   10/   44]    Loss 1.064405    Top1 89.975243    
2024-04-04 17:48:21,537 - Epoch: [15][   20/   44]    Loss 1.069083    Top1 89.345192    
2024-04-04 17:48:52,859 - Epoch: [15][   30/   44]    Loss 1.068484    Top1 89.477081    
2024-04-04 17:49:25,159 - Epoch: [15][   40/   44]    Loss 1.065986    Top1 89.443723    
2024-04-04 17:49:36,664 - Epoch: [15][   44/   44]    Loss 1.066314    Top1 89.496884    
2024-04-04 17:49:36,936 - ==> Top1: 89.497    Loss: 1.066

2024-04-04 17:49:36,945 - ==> Best [Top1: 89.802   Sparsity:0.00   Params: 272800 on epoch: 13]
2024-04-04 17:49:36,945 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:49:36,981 - 

2024-04-04 17:49:36,981 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:49:40,258 - Epoch: [16][   10/  139]    Overall Loss 1.063779    Objective Loss 1.063779                                        LR 0.001000    Time 0.327546    
2024-04-04 17:49:42,908 - Epoch: [16][   20/  139]    Overall Loss 1.064648    Objective Loss 1.064648                                        LR 0.001000    Time 0.296253    
2024-04-04 17:49:45,558 - Epoch: [16][   30/  139]    Overall Loss 1.063755    Objective Loss 1.063755                                        LR 0.001000    Time 0.285839    
2024-04-04 17:49:48,212 - Epoch: [16][   40/  139]    Overall Loss 1.063955    Objective Loss 1.063955                                        LR 0.001000    Time 0.280697    
2024-04-04 17:49:50,870 - Epoch: [16][   50/  139]    Overall Loss 1.065568    Objective Loss 1.065568                                        LR 0.001000    Time 0.277707    
2024-04-04 17:49:53,527 - Epoch: [16][   60/  139]    Overall Loss 1.064304    Objective Loss 1.064304                                        LR 0.001000    Time 0.275704    
2024-04-04 17:49:56,185 - Epoch: [16][   70/  139]    Overall Loss 1.064612    Objective Loss 1.064612                                        LR 0.001000    Time 0.274286    
2024-04-04 17:49:58,855 - Epoch: [16][   80/  139]    Overall Loss 1.064929    Objective Loss 1.064929                                        LR 0.001000    Time 0.273370    
2024-04-04 17:50:01,516 - Epoch: [16][   90/  139]    Overall Loss 1.064766    Objective Loss 1.064766                                        LR 0.001000    Time 0.272546    
2024-04-04 17:50:04,172 - Epoch: [16][  100/  139]    Overall Loss 1.065827    Objective Loss 1.065827                                        LR 0.001000    Time 0.271854    
2024-04-04 17:50:06,829 - Epoch: [16][  110/  139]    Overall Loss 1.065695    Objective Loss 1.065695                                        LR 0.001000    Time 0.271288    
2024-04-04 17:50:09,482 - Epoch: [16][  120/  139]    Overall Loss 1.065327    Objective Loss 1.065327                                        LR 0.001000    Time 0.270787    
2024-04-04 17:50:12,137 - Epoch: [16][  130/  139]    Overall Loss 1.065680    Objective Loss 1.065680                                        LR 0.001000    Time 0.270374    
2024-04-04 17:50:18,835 - Epoch: [16][  139/  139]    Overall Loss 1.066378    Objective Loss 1.066378    Top1 89.069122    LR 0.001000    Time 0.301054    
2024-04-04 17:50:19,075 - --- validate (epoch=16)-----------
2024-04-04 17:50:19,076 - 1392 samples (32 per mini-batch)
2024-04-04 17:50:52,277 - Epoch: [16][   10/   44]    Loss 1.098178    Top1 85.720560    
2024-04-04 17:51:24,580 - Epoch: [16][   20/   44]    Loss 1.088295    Top1 86.867671    
2024-04-04 17:51:56,091 - Epoch: [16][   30/   44]    Loss 1.087323    Top1 86.780170    
2024-04-04 17:52:28,760 - Epoch: [16][   40/   44]    Loss 1.086727    Top1 86.867407    
2024-04-04 17:52:39,983 - Epoch: [16][   44/   44]    Loss 1.085647    Top1 86.967837    
2024-04-04 17:52:40,269 - ==> Top1: 86.968    Loss: 1.086

2024-04-04 17:52:40,276 - ==> Best [Top1: 89.802   Sparsity:0.00   Params: 272800 on epoch: 13]
2024-04-04 17:52:40,276 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:52:40,312 - 

2024-04-04 17:52:40,312 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:52:43,713 - Epoch: [17][   10/  139]    Overall Loss 1.061639    Objective Loss 1.061639                                        LR 0.001000    Time 0.339995    
2024-04-04 17:52:46,362 - Epoch: [17][   20/  139]    Overall Loss 1.062620    Objective Loss 1.062620                                        LR 0.001000    Time 0.302420    
2024-04-04 17:52:49,013 - Epoch: [17][   30/  139]    Overall Loss 1.063515    Objective Loss 1.063515                                        LR 0.001000    Time 0.289955    
2024-04-04 17:52:51,665 - Epoch: [17][   40/  139]    Overall Loss 1.065648    Objective Loss 1.065648                                        LR 0.001000    Time 0.283757    
2024-04-04 17:52:54,318 - Epoch: [17][   50/  139]    Overall Loss 1.066114    Objective Loss 1.066114                                        LR 0.001000    Time 0.280048    
2024-04-04 17:52:56,967 - Epoch: [17][   60/  139]    Overall Loss 1.064776    Objective Loss 1.064776                                        LR 0.001000    Time 0.277510    
2024-04-04 17:52:59,618 - Epoch: [17][   70/  139]    Overall Loss 1.064928    Objective Loss 1.064928                                        LR 0.001000    Time 0.275739    
2024-04-04 17:53:02,274 - Epoch: [17][   80/  139]    Overall Loss 1.063848    Objective Loss 1.063848                                        LR 0.001000    Time 0.274458    
2024-04-04 17:53:04,929 - Epoch: [17][   90/  139]    Overall Loss 1.065134    Objective Loss 1.065134                                        LR 0.001000    Time 0.273465    
2024-04-04 17:53:07,592 - Epoch: [17][  100/  139]    Overall Loss 1.065715    Objective Loss 1.065715                                        LR 0.001000    Time 0.272740    
2024-04-04 17:53:10,245 - Epoch: [17][  110/  139]    Overall Loss 1.064918    Objective Loss 1.064918                                        LR 0.001000    Time 0.272062    
2024-04-04 17:53:12,904 - Epoch: [17][  120/  139]    Overall Loss 1.065189    Objective Loss 1.065189                                        LR 0.001000    Time 0.271545    
2024-04-04 17:53:15,552 - Epoch: [17][  130/  139]    Overall Loss 1.065044    Objective Loss 1.065044                                        LR 0.001000    Time 0.271016    
2024-04-04 17:53:23,129 - Epoch: [17][  139/  139]    Overall Loss 1.065511    Objective Loss 1.065511    Top1 94.675515    LR 0.001000    Time 0.307982    
2024-04-04 17:53:23,495 - --- validate (epoch=17)-----------
2024-04-04 17:53:23,497 - 1392 samples (32 per mini-batch)
2024-04-04 17:53:57,360 - Epoch: [17][   10/   44]    Loss 1.089637    Top1 88.075264    
2024-04-04 17:54:30,768 - Epoch: [17][   20/   44]    Loss 1.081122    Top1 87.734168    
2024-04-04 17:55:02,667 - Epoch: [17][   30/   44]    Loss 1.079780    Top1 87.688997    
2024-04-04 17:55:33,962 - Epoch: [17][   40/   44]    Loss 1.081092    Top1 87.550702    
2024-04-04 17:55:44,977 - Epoch: [17][   44/   44]    Loss 1.079357    Top1 87.706500    
2024-04-04 17:55:45,273 - ==> Top1: 87.706    Loss: 1.079

2024-04-04 17:55:45,281 - ==> Best [Top1: 89.802   Sparsity:0.00   Params: 272800 on epoch: 13]
2024-04-04 17:55:45,281 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:55:45,318 - 

2024-04-04 17:55:45,318 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:55:48,647 - Epoch: [18][   10/  139]    Overall Loss 1.073878    Objective Loss 1.073878                                        LR 0.001000    Time 0.332807    
2024-04-04 17:55:51,299 - Epoch: [18][   20/  139]    Overall Loss 1.065000    Objective Loss 1.065000                                        LR 0.001000    Time 0.298931    
2024-04-04 17:55:53,965 - Epoch: [18][   30/  139]    Overall Loss 1.065083    Objective Loss 1.065083                                        LR 0.001000    Time 0.288147    
2024-04-04 17:55:56,595 - Epoch: [18][   40/  139]    Overall Loss 1.066083    Objective Loss 1.066083                                        LR 0.001000    Time 0.281857    
2024-04-04 17:55:59,253 - Epoch: [18][   50/  139]    Overall Loss 1.066004    Objective Loss 1.066004                                        LR 0.001000    Time 0.278629    
2024-04-04 17:56:01,906 - Epoch: [18][   60/  139]    Overall Loss 1.066012    Objective Loss 1.066012                                        LR 0.001000    Time 0.276391    
2024-04-04 17:56:04,556 - Epoch: [18][   70/  139]    Overall Loss 1.065127    Objective Loss 1.065127                                        LR 0.001000    Time 0.274765    
2024-04-04 17:56:07,213 - Epoch: [18][   80/  139]    Overall Loss 1.066636    Objective Loss 1.066636                                        LR 0.001000    Time 0.273625    
2024-04-04 17:56:09,869 - Epoch: [18][   90/  139]    Overall Loss 1.065938    Objective Loss 1.065938                                        LR 0.001000    Time 0.272728    
2024-04-04 17:56:12,521 - Epoch: [18][  100/  139]    Overall Loss 1.065979    Objective Loss 1.065979                                        LR 0.001000    Time 0.271966    
2024-04-04 17:56:15,178 - Epoch: [18][  110/  139]    Overall Loss 1.066081    Objective Loss 1.066081                                        LR 0.001000    Time 0.271390    
2024-04-04 17:56:17,832 - Epoch: [18][  120/  139]    Overall Loss 1.065608    Objective Loss 1.065608                                        LR 0.001000    Time 0.270885    
2024-04-04 17:56:20,485 - Epoch: [18][  130/  139]    Overall Loss 1.065514    Objective Loss 1.065514                                        LR 0.001000    Time 0.270454    
2024-04-04 17:56:27,439 - Epoch: [18][  139/  139]    Overall Loss 1.065140    Objective Loss 1.065140    Top1 91.530650    LR 0.001000    Time 0.302966    
2024-04-04 17:56:27,747 - --- validate (epoch=18)-----------
2024-04-04 17:56:27,747 - 1392 samples (32 per mini-batch)
2024-04-04 17:57:00,350 - Epoch: [18][   10/   44]    Loss 1.073321    Top1 88.528737    
2024-04-04 17:57:33,315 - Epoch: [18][   20/   44]    Loss 1.070627    Top1 89.090485    
2024-04-04 17:58:05,917 - Epoch: [18][   30/   44]    Loss 1.071316    Top1 89.241624    
2024-04-04 17:58:37,487 - Epoch: [18][   40/   44]    Loss 1.073351    Top1 89.180529    
2024-04-04 17:58:48,599 - Epoch: [18][   44/   44]    Loss 1.073236    Top1 89.108793    
2024-04-04 17:58:48,945 - ==> Top1: 89.109    Loss: 1.073

2024-04-04 17:58:48,952 - ==> Best [Top1: 89.802   Sparsity:0.00   Params: 272800 on epoch: 13]
2024-04-04 17:58:48,953 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 17:58:48,989 - 

2024-04-04 17:58:48,989 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 17:58:52,299 - Epoch: [19][   10/  139]    Overall Loss 1.058547    Objective Loss 1.058547                                        LR 0.001000    Time 0.330869    
2024-04-04 17:58:54,951 - Epoch: [19][   20/  139]    Overall Loss 1.065406    Objective Loss 1.065406                                        LR 0.001000    Time 0.298035    
2024-04-04 17:58:57,601 - Epoch: [19][   30/  139]    Overall Loss 1.065058    Objective Loss 1.065058                                        LR 0.001000    Time 0.287003    
2024-04-04 17:59:00,252 - Epoch: [19][   40/  139]    Overall Loss 1.065031    Objective Loss 1.065031                                        LR 0.001000    Time 0.281514    
2024-04-04 17:59:02,898 - Epoch: [19][   50/  139]    Overall Loss 1.065492    Objective Loss 1.065492                                        LR 0.001000    Time 0.278120    
2024-04-04 17:59:05,551 - Epoch: [19][   60/  139]    Overall Loss 1.064601    Objective Loss 1.064601                                        LR 0.001000    Time 0.275974    
2024-04-04 17:59:08,210 - Epoch: [19][   70/  139]    Overall Loss 1.065137    Objective Loss 1.065137                                        LR 0.001000    Time 0.274531    
2024-04-04 17:59:10,853 - Epoch: [19][   80/  139]    Overall Loss 1.064891    Objective Loss 1.064891                                        LR 0.001000    Time 0.273251    
2024-04-04 17:59:13,507 - Epoch: [19][   90/  139]    Overall Loss 1.064981    Objective Loss 1.064981                                        LR 0.001000    Time 0.272373    
2024-04-04 17:59:16,160 - Epoch: [19][  100/  139]    Overall Loss 1.064626    Objective Loss 1.064626                                        LR 0.001000    Time 0.271661    
2024-04-04 17:59:18,818 - Epoch: [19][  110/  139]    Overall Loss 1.064483    Objective Loss 1.064483                                        LR 0.001000    Time 0.271117    
2024-04-04 17:59:21,473 - Epoch: [19][  120/  139]    Overall Loss 1.063736    Objective Loss 1.063736                                        LR 0.001000    Time 0.270644    
2024-04-04 17:59:24,131 - Epoch: [19][  130/  139]    Overall Loss 1.063883    Objective Loss 1.063883                                        LR 0.001000    Time 0.270269    
2024-04-04 17:59:31,160 - Epoch: [19][  139/  139]    Overall Loss 1.064214    Objective Loss 1.064214    Top1 90.144845    LR 0.001000    Time 0.303333    
2024-04-04 17:59:31,454 - --- validate (epoch=19)-----------
2024-04-04 17:59:31,454 - 1392 samples (32 per mini-batch)
2024-04-04 18:00:04,491 - Epoch: [19][   10/   44]    Loss 1.082434    Top1 89.530841    
2024-04-04 18:00:35,730 - Epoch: [19][   20/   44]    Loss 1.082028    Top1 89.149916    
2024-04-04 18:01:08,109 - Epoch: [19][   30/   44]    Loss 1.082195    Top1 89.374676    
2024-04-04 18:01:39,569 - Epoch: [19][   40/   44]    Loss 1.080352    Top1 89.412368    
2024-04-04 18:01:50,558 - Epoch: [19][   44/   44]    Loss 1.079804    Top1 89.339728    
2024-04-04 18:01:50,880 - ==> Top1: 89.340    Loss: 1.080

2024-04-04 18:01:50,887 - ==> Best [Top1: 89.802   Sparsity:0.00   Params: 272800 on epoch: 13]
2024-04-04 18:01:50,888 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:01:50,924 - 

2024-04-04 18:01:50,924 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:01:54,198 - Epoch: [20][   10/  139]    Overall Loss 1.058054    Objective Loss 1.058054                                        LR 0.000500    Time 0.327278    
2024-04-04 18:01:56,849 - Epoch: [20][   20/  139]    Overall Loss 1.056165    Objective Loss 1.056165                                        LR 0.000500    Time 0.296151    
2024-04-04 18:01:59,504 - Epoch: [20][   30/  139]    Overall Loss 1.060375    Objective Loss 1.060375                                        LR 0.000500    Time 0.285936    
2024-04-04 18:02:02,173 - Epoch: [20][   40/  139]    Overall Loss 1.061158    Objective Loss 1.061158                                        LR 0.000500    Time 0.281169    
2024-04-04 18:02:04,822 - Epoch: [20][   50/  139]    Overall Loss 1.060274    Objective Loss 1.060274                                        LR 0.000500    Time 0.277902    
2024-04-04 18:02:07,473 - Epoch: [20][   60/  139]    Overall Loss 1.061430    Objective Loss 1.061430                                        LR 0.000500    Time 0.275753    
2024-04-04 18:02:10,121 - Epoch: [20][   70/  139]    Overall Loss 1.061207    Objective Loss 1.061207                                        LR 0.000500    Time 0.274188    
2024-04-04 18:02:12,760 - Epoch: [20][   80/  139]    Overall Loss 1.060477    Objective Loss 1.060477                                        LR 0.000500    Time 0.272901    
2024-04-04 18:02:15,399 - Epoch: [20][   90/  139]    Overall Loss 1.060571    Objective Loss 1.060571                                        LR 0.000500    Time 0.271892    
2024-04-04 18:02:18,048 - Epoch: [20][  100/  139]    Overall Loss 1.061149    Objective Loss 1.061149                                        LR 0.000500    Time 0.271185    
2024-04-04 18:02:20,701 - Epoch: [20][  110/  139]    Overall Loss 1.061106    Objective Loss 1.061106                                        LR 0.000500    Time 0.270651    
2024-04-04 18:02:23,358 - Epoch: [20][  120/  139]    Overall Loss 1.061323    Objective Loss 1.061323                                        LR 0.000500    Time 0.270233    
2024-04-04 18:02:26,012 - Epoch: [20][  130/  139]    Overall Loss 1.061897    Objective Loss 1.061897                                        LR 0.000500    Time 0.269855    
2024-04-04 18:02:33,571 - Epoch: [20][  139/  139]    Overall Loss 1.061898    Objective Loss 1.061898    Top1 93.168960    LR 0.000500    Time 0.306761    
2024-04-04 18:02:33,884 - --- validate (epoch=20)-----------
2024-04-04 18:02:33,884 - 1392 samples (32 per mini-batch)
2024-04-04 18:03:06,175 - Epoch: [20][   10/   44]    Loss 1.063987    Top1 90.767686    
2024-04-04 18:03:38,126 - Epoch: [20][   20/   44]    Loss 1.070155    Top1 90.073879    
2024-04-04 18:04:10,224 - Epoch: [20][   30/   44]    Loss 1.066316    Top1 90.100129    
2024-04-04 18:04:42,482 - Epoch: [20][   40/   44]    Loss 1.063677    Top1 90.124572    
2024-04-04 18:04:53,680 - Epoch: [20][   44/   44]    Loss 1.063255    Top1 90.162390    
2024-04-04 18:04:53,910 - ==> Top1: 90.162    Loss: 1.063

2024-04-04 18:04:53,918 - ==> Best [Top1: 90.162   Sparsity:0.00   Params: 272800 on epoch: 20]
2024-04-04 18:04:53,918 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:04:53,957 - 

2024-04-04 18:04:53,957 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:04:57,283 - Epoch: [21][   10/  139]    Overall Loss 1.061230    Objective Loss 1.061230                                        LR 0.000500    Time 0.332476    
2024-04-04 18:04:59,936 - Epoch: [21][   20/  139]    Overall Loss 1.060477    Objective Loss 1.060477                                        LR 0.000500    Time 0.298832    
2024-04-04 18:05:02,590 - Epoch: [21][   30/  139]    Overall Loss 1.061594    Objective Loss 1.061594                                        LR 0.000500    Time 0.287686    
2024-04-04 18:05:05,238 - Epoch: [21][   40/  139]    Overall Loss 1.061780    Objective Loss 1.061780                                        LR 0.000500    Time 0.281944    
2024-04-04 18:05:07,884 - Epoch: [21][   50/  139]    Overall Loss 1.059906    Objective Loss 1.059906                                        LR 0.000500    Time 0.278472    
2024-04-04 18:05:10,535 - Epoch: [21][   60/  139]    Overall Loss 1.059177    Objective Loss 1.059177                                        LR 0.000500    Time 0.276235    
2024-04-04 18:05:13,178 - Epoch: [21][   70/  139]    Overall Loss 1.059792    Objective Loss 1.059792                                        LR 0.000500    Time 0.274528    
2024-04-04 18:05:15,822 - Epoch: [21][   80/  139]    Overall Loss 1.059468    Objective Loss 1.059468                                        LR 0.000500    Time 0.273249    
2024-04-04 18:05:18,472 - Epoch: [21][   90/  139]    Overall Loss 1.059448    Objective Loss 1.059448                                        LR 0.000500    Time 0.272331    
2024-04-04 18:05:21,129 - Epoch: [21][  100/  139]    Overall Loss 1.060229    Objective Loss 1.060229                                        LR 0.000500    Time 0.271655    
2024-04-04 18:05:23,781 - Epoch: [21][  110/  139]    Overall Loss 1.060173    Objective Loss 1.060173                                        LR 0.000500    Time 0.271066    
2024-04-04 18:05:26,428 - Epoch: [21][  120/  139]    Overall Loss 1.060064    Objective Loss 1.060064                                        LR 0.000500    Time 0.270536    
2024-04-04 18:05:29,078 - Epoch: [21][  130/  139]    Overall Loss 1.059853    Objective Loss 1.059853                                        LR 0.000500    Time 0.270104    
2024-04-04 18:05:36,733 - Epoch: [21][  139/  139]    Overall Loss 1.059827    Objective Loss 1.059827    Top1 93.803340    LR 0.000500    Time 0.307687    
2024-04-04 18:05:37,102 - --- validate (epoch=21)-----------
2024-04-04 18:05:37,103 - 1392 samples (32 per mini-batch)
2024-04-04 18:06:10,273 - Epoch: [21][   10/   44]    Loss 1.062736    Top1 90.513109    
2024-04-04 18:06:43,606 - Epoch: [21][   20/   44]    Loss 1.068648    Top1 90.210412    
2024-04-04 18:07:15,575 - Epoch: [21][   30/   44]    Loss 1.067391    Top1 89.969701    
2024-04-04 18:07:47,712 - Epoch: [21][   40/   44]    Loss 1.064186    Top1 90.148008    
2024-04-04 18:07:58,915 - Epoch: [21][   44/   44]    Loss 1.064805    Top1 90.010643    
2024-04-04 18:07:59,284 - ==> Top1: 90.011    Loss: 1.065

2024-04-04 18:07:59,291 - ==> Best [Top1: 90.162   Sparsity:0.00   Params: 272800 on epoch: 20]
2024-04-04 18:07:59,292 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:07:59,329 - 

2024-04-04 18:07:59,329 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:08:02,598 - Epoch: [22][   10/  139]    Overall Loss 1.054904    Objective Loss 1.054904                                        LR 0.000500    Time 0.326739    
2024-04-04 18:08:05,245 - Epoch: [22][   20/  139]    Overall Loss 1.057019    Objective Loss 1.057019                                        LR 0.000500    Time 0.295696    
2024-04-04 18:08:07,895 - Epoch: [22][   30/  139]    Overall Loss 1.059626    Objective Loss 1.059626                                        LR 0.000500    Time 0.285431    
2024-04-04 18:08:10,544 - Epoch: [22][   40/  139]    Overall Loss 1.061974    Objective Loss 1.061974                                        LR 0.000500    Time 0.280298    
2024-04-04 18:08:13,191 - Epoch: [22][   50/  139]    Overall Loss 1.061030    Objective Loss 1.061030                                        LR 0.000500    Time 0.277169    
2024-04-04 18:08:15,837 - Epoch: [22][   60/  139]    Overall Loss 1.060371    Objective Loss 1.060371                                        LR 0.000500    Time 0.275065    
2024-04-04 18:08:18,491 - Epoch: [22][   70/  139]    Overall Loss 1.060273    Objective Loss 1.060273                                        LR 0.000500    Time 0.273682    
2024-04-04 18:08:21,139 - Epoch: [22][   80/  139]    Overall Loss 1.059790    Objective Loss 1.059790                                        LR 0.000500    Time 0.272556    
2024-04-04 18:08:23,793 - Epoch: [22][   90/  139]    Overall Loss 1.059957    Objective Loss 1.059957                                        LR 0.000500    Time 0.271763    
2024-04-04 18:08:26,444 - Epoch: [22][  100/  139]    Overall Loss 1.059418    Objective Loss 1.059418                                        LR 0.000500    Time 0.271087    
2024-04-04 18:08:29,098 - Epoch: [22][  110/  139]    Overall Loss 1.058723    Objective Loss 1.058723                                        LR 0.000500    Time 0.270570    
2024-04-04 18:08:31,753 - Epoch: [22][  120/  139]    Overall Loss 1.058980    Objective Loss 1.058980                                        LR 0.000500    Time 0.270142    
2024-04-04 18:08:34,412 - Epoch: [22][  130/  139]    Overall Loss 1.058986    Objective Loss 1.058986                                        LR 0.000500    Time 0.269811    
2024-04-04 18:08:41,099 - Epoch: [22][  139/  139]    Overall Loss 1.059906    Objective Loss 1.059906    Top1 93.674428    LR 0.000500    Time 0.300442    
2024-04-04 18:08:41,390 - --- validate (epoch=22)-----------
2024-04-04 18:08:41,390 - 1392 samples (32 per mini-batch)
2024-04-04 18:09:14,531 - Epoch: [22][   10/   44]    Loss 1.061987    Top1 89.217991    
2024-04-04 18:09:46,493 - Epoch: [22][   20/   44]    Loss 1.065580    Top1 89.610979    
2024-04-04 18:10:19,054 - Epoch: [22][   30/   44]    Loss 1.068629    Top1 90.023451    
2024-04-04 18:10:51,092 - Epoch: [22][   40/   44]    Loss 1.067562    Top1 90.216298    
2024-04-04 18:11:02,619 - Epoch: [22][   44/   44]    Loss 1.066760    Top1 90.234578    
2024-04-04 18:11:02,938 - ==> Top1: 90.235    Loss: 1.067

2024-04-04 18:11:02,946 - ==> Best [Top1: 90.235   Sparsity:0.00   Params: 272800 on epoch: 22]
2024-04-04 18:11:02,946 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:11:02,986 - 

2024-04-04 18:11:02,986 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:11:06,241 - Epoch: [23][   10/  139]    Overall Loss 1.062856    Objective Loss 1.062856                                        LR 0.000500    Time 0.325409    
2024-04-04 18:11:08,895 - Epoch: [23][   20/  139]    Overall Loss 1.060404    Objective Loss 1.060404                                        LR 0.000500    Time 0.295370    
2024-04-04 18:11:11,550 - Epoch: [23][   30/  139]    Overall Loss 1.060103    Objective Loss 1.060103                                        LR 0.000500    Time 0.285381    
2024-04-04 18:11:14,206 - Epoch: [23][   40/  139]    Overall Loss 1.058607    Objective Loss 1.058607                                        LR 0.000500    Time 0.280426    
2024-04-04 18:11:16,867 - Epoch: [23][   50/  139]    Overall Loss 1.060006    Objective Loss 1.060006                                        LR 0.000500    Time 0.277566    
2024-04-04 18:11:19,522 - Epoch: [23][   60/  139]    Overall Loss 1.059669    Objective Loss 1.059669                                        LR 0.000500    Time 0.275540    
2024-04-04 18:11:22,190 - Epoch: [23][   70/  139]    Overall Loss 1.061188    Objective Loss 1.061188                                        LR 0.000500    Time 0.274280    
2024-04-04 18:11:24,850 - Epoch: [23][   80/  139]    Overall Loss 1.062121    Objective Loss 1.062121                                        LR 0.000500    Time 0.273248    
2024-04-04 18:11:27,515 - Epoch: [23][   90/  139]    Overall Loss 1.060971    Objective Loss 1.060971                                        LR 0.000500    Time 0.272483    
2024-04-04 18:11:30,178 - Epoch: [23][  100/  139]    Overall Loss 1.060167    Objective Loss 1.060167                                        LR 0.000500    Time 0.271860    
2024-04-04 18:11:32,838 - Epoch: [23][  110/  139]    Overall Loss 1.060412    Objective Loss 1.060412                                        LR 0.000500    Time 0.271326    
2024-04-04 18:11:35,500 - Epoch: [23][  120/  139]    Overall Loss 1.060473    Objective Loss 1.060473                                        LR 0.000500    Time 0.270892    
2024-04-04 18:11:38,165 - Epoch: [23][  130/  139]    Overall Loss 1.060109    Objective Loss 1.060109                                        LR 0.000500    Time 0.270553    
2024-04-04 18:11:45,176 - Epoch: [23][  139/  139]    Overall Loss 1.059804    Objective Loss 1.059804    Top1 92.806564    LR 0.000500    Time 0.303473    
2024-04-04 18:11:45,427 - --- validate (epoch=23)-----------
2024-04-04 18:11:45,429 - 1392 samples (32 per mini-batch)
2024-04-04 18:12:18,423 - Epoch: [23][   10/   44]    Loss 1.062929    Top1 90.340117    
2024-04-04 18:12:49,265 - Epoch: [23][   20/   44]    Loss 1.065597    Top1 90.358898    
2024-04-04 18:13:21,046 - Epoch: [23][   30/   44]    Loss 1.067474    Top1 90.462905    
2024-04-04 18:13:53,586 - Epoch: [23][   40/   44]    Loss 1.066798    Top1 90.372589    
2024-04-04 18:14:04,877 - Epoch: [23][   44/   44]    Loss 1.067667    Top1 90.361206    
2024-04-04 18:14:05,171 - ==> Top1: 90.361    Loss: 1.068

2024-04-04 18:14:05,178 - ==> Best [Top1: 90.361   Sparsity:0.00   Params: 272800 on epoch: 23]
2024-04-04 18:14:05,179 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:14:05,219 - 

2024-04-04 18:14:05,219 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:14:08,500 - Epoch: [24][   10/  139]    Overall Loss 1.054907    Objective Loss 1.054907                                        LR 0.000500    Time 0.327934    
2024-04-04 18:14:11,147 - Epoch: [24][   20/  139]    Overall Loss 1.058430    Objective Loss 1.058430                                        LR 0.000500    Time 0.296321    
2024-04-04 18:14:13,796 - Epoch: [24][   30/  139]    Overall Loss 1.060593    Objective Loss 1.060593                                        LR 0.000500    Time 0.285831    
2024-04-04 18:14:16,446 - Epoch: [24][   40/  139]    Overall Loss 1.058789    Objective Loss 1.058789                                        LR 0.000500    Time 0.280605    
2024-04-04 18:14:19,102 - Epoch: [24][   50/  139]    Overall Loss 1.059489    Objective Loss 1.059489                                        LR 0.000500    Time 0.277589    
2024-04-04 18:14:21,753 - Epoch: [24][   60/  139]    Overall Loss 1.058945    Objective Loss 1.058945                                        LR 0.000500    Time 0.275308    
2024-04-04 18:14:24,410 - Epoch: [24][   70/  139]    Overall Loss 1.059780    Objective Loss 1.059780                                        LR 0.000500    Time 0.273929    
2024-04-04 18:14:27,071 - Epoch: [24][   80/  139]    Overall Loss 1.059760    Objective Loss 1.059760                                        LR 0.000500    Time 0.272934    
2024-04-04 18:14:29,731 - Epoch: [24][   90/  139]    Overall Loss 1.059946    Objective Loss 1.059946                                        LR 0.000500    Time 0.272150    
2024-04-04 18:14:32,388 - Epoch: [24][  100/  139]    Overall Loss 1.059842    Objective Loss 1.059842                                        LR 0.000500    Time 0.271503    
2024-04-04 18:14:35,050 - Epoch: [24][  110/  139]    Overall Loss 1.060433    Objective Loss 1.060433                                        LR 0.000500    Time 0.271015    
2024-04-04 18:14:37,704 - Epoch: [24][  120/  139]    Overall Loss 1.060072    Objective Loss 1.060072                                        LR 0.000500    Time 0.270542    
2024-04-04 18:14:40,361 - Epoch: [24][  130/  139]    Overall Loss 1.059850    Objective Loss 1.059850                                        LR 0.000500    Time 0.270171    
2024-04-04 18:14:47,680 - Epoch: [24][  139/  139]    Overall Loss 1.060111    Objective Loss 1.060111    Top1 93.120040    LR 0.000500    Time 0.305327    
2024-04-04 18:14:47,968 - --- validate (epoch=24)-----------
2024-04-04 18:14:47,969 - 1392 samples (32 per mini-batch)
2024-04-04 18:15:21,220 - Epoch: [24][   10/   44]    Loss 1.063604    Top1 91.492564    
2024-04-04 18:15:52,661 - Epoch: [24][   20/   44]    Loss 1.059224    Top1 91.089533    
2024-04-04 18:16:24,273 - Epoch: [24][   30/   44]    Loss 1.064185    Top1 90.755962    
2024-04-04 18:16:55,582 - Epoch: [24][   40/   44]    Loss 1.065412    Top1 90.523153    
2024-04-04 18:17:06,545 - Epoch: [24][   44/   44]    Loss 1.063724    Top1 90.570537    
2024-04-04 18:17:06,835 - ==> Top1: 90.571    Loss: 1.064

2024-04-04 18:17:06,843 - ==> Best [Top1: 90.571   Sparsity:0.00   Params: 272800 on epoch: 24]
2024-04-04 18:17:06,843 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:17:06,884 - 

2024-04-04 18:17:06,884 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:17:10,229 - Epoch: [25][   10/  139]    Overall Loss 1.067670    Objective Loss 1.067670                                        LR 0.000500    Time 0.334440    
2024-04-04 18:17:12,888 - Epoch: [25][   20/  139]    Overall Loss 1.060085    Objective Loss 1.060085                                        LR 0.000500    Time 0.300137    
2024-04-04 18:17:15,543 - Epoch: [25][   30/  139]    Overall Loss 1.060112    Objective Loss 1.060112                                        LR 0.000500    Time 0.288561    
2024-04-04 18:17:18,196 - Epoch: [25][   40/  139]    Overall Loss 1.058258    Objective Loss 1.058258                                        LR 0.000500    Time 0.282744    
2024-04-04 18:17:20,859 - Epoch: [25][   50/  139]    Overall Loss 1.058052    Objective Loss 1.058052                                        LR 0.000500    Time 0.279442    
2024-04-04 18:17:23,519 - Epoch: [25][   60/  139]    Overall Loss 1.058805    Objective Loss 1.058805                                        LR 0.000500    Time 0.277186    
2024-04-04 18:17:26,183 - Epoch: [25][   70/  139]    Overall Loss 1.058034    Objective Loss 1.058034                                        LR 0.000500    Time 0.275643    
2024-04-04 18:17:28,840 - Epoch: [25][   80/  139]    Overall Loss 1.057849    Objective Loss 1.057849                                        LR 0.000500    Time 0.274391    
2024-04-04 18:17:31,500 - Epoch: [25][   90/  139]    Overall Loss 1.057526    Objective Loss 1.057526                                        LR 0.000500    Time 0.273456    
2024-04-04 18:17:34,161 - Epoch: [25][  100/  139]    Overall Loss 1.058060    Objective Loss 1.058060                                        LR 0.000500    Time 0.272717    
2024-04-04 18:17:36,823 - Epoch: [25][  110/  139]    Overall Loss 1.058619    Objective Loss 1.058619                                        LR 0.000500    Time 0.272116    
2024-04-04 18:17:39,486 - Epoch: [25][  120/  139]    Overall Loss 1.058874    Objective Loss 1.058874                                        LR 0.000500    Time 0.271626    
2024-04-04 18:17:42,146 - Epoch: [25][  130/  139]    Overall Loss 1.058503    Objective Loss 1.058503                                        LR 0.000500    Time 0.271192    
2024-04-04 18:17:50,017 - Epoch: [25][  139/  139]    Overall Loss 1.059433    Objective Loss 1.059433    Top1 92.635501    LR 0.000500    Time 0.310257    
2024-04-04 18:17:50,366 - --- validate (epoch=25)-----------
2024-04-04 18:17:50,368 - 1392 samples (32 per mini-batch)
2024-04-04 18:18:23,177 - Epoch: [25][   10/   44]    Loss 1.075356    Top1 89.420494    
2024-04-04 18:18:54,305 - Epoch: [25][   20/   44]    Loss 1.079024    Top1 89.390561    
2024-04-04 18:19:26,354 - Epoch: [25][   30/   44]    Loss 1.071908    Top1 89.391973    
2024-04-04 18:19:58,055 - Epoch: [25][   40/   44]    Loss 1.067371    Top1 89.299442    
2024-04-04 18:20:09,214 - Epoch: [25][   44/   44]    Loss 1.067800    Top1 89.363778    
2024-04-04 18:20:09,564 - ==> Top1: 89.364    Loss: 1.068

2024-04-04 18:20:09,570 - ==> Best [Top1: 90.571   Sparsity:0.00   Params: 272800 on epoch: 24]
2024-04-04 18:20:09,571 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:20:09,609 - 

2024-04-04 18:20:09,609 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:20:12,934 - Epoch: [26][   10/  139]    Overall Loss 1.061483    Objective Loss 1.061483                                        LR 0.000500    Time 0.332402    
2024-04-04 18:20:15,585 - Epoch: [26][   20/  139]    Overall Loss 1.061147    Objective Loss 1.061147                                        LR 0.000500    Time 0.298714    
2024-04-04 18:20:18,244 - Epoch: [26][   30/  139]    Overall Loss 1.062044    Objective Loss 1.062044                                        LR 0.000500    Time 0.287773    
2024-04-04 18:20:20,898 - Epoch: [26][   40/  139]    Overall Loss 1.059862    Objective Loss 1.059862                                        LR 0.000500    Time 0.282151    
2024-04-04 18:20:23,555 - Epoch: [26][   50/  139]    Overall Loss 1.057970    Objective Loss 1.057970                                        LR 0.000500    Time 0.278856    
2024-04-04 18:20:26,208 - Epoch: [26][   60/  139]    Overall Loss 1.058650    Objective Loss 1.058650                                        LR 0.000500    Time 0.276593    
2024-04-04 18:20:28,864 - Epoch: [26][   70/  139]    Overall Loss 1.058254    Objective Loss 1.058254                                        LR 0.000500    Time 0.275011    
2024-04-04 18:20:31,522 - Epoch: [26][   80/  139]    Overall Loss 1.058943    Objective Loss 1.058943                                        LR 0.000500    Time 0.273851    
2024-04-04 18:20:34,184 - Epoch: [26][   90/  139]    Overall Loss 1.060208    Objective Loss 1.060208                                        LR 0.000500    Time 0.272999    
2024-04-04 18:20:36,840 - Epoch: [26][  100/  139]    Overall Loss 1.059440    Objective Loss 1.059440                                        LR 0.000500    Time 0.272258    
2024-04-04 18:20:39,498 - Epoch: [26][  110/  139]    Overall Loss 1.059964    Objective Loss 1.059964                                        LR 0.000500    Time 0.271668    
2024-04-04 18:20:42,151 - Epoch: [26][  120/  139]    Overall Loss 1.060605    Objective Loss 1.060605                                        LR 0.000500    Time 0.271133    
2024-04-04 18:20:44,821 - Epoch: [26][  130/  139]    Overall Loss 1.060229    Objective Loss 1.060229                                        LR 0.000500    Time 0.270812    
2024-04-04 18:20:52,384 - Epoch: [26][  139/  139]    Overall Loss 1.060195    Objective Loss 1.060195    Top1 93.094727    LR 0.000500    Time 0.307680    
2024-04-04 18:20:52,765 - --- validate (epoch=26)-----------
2024-04-04 18:20:52,766 - 1392 samples (32 per mini-batch)
2024-04-04 18:21:25,610 - Epoch: [26][   10/   44]    Loss 1.069879    Top1 88.181109    
2024-04-04 18:21:57,719 - Epoch: [26][   20/   44]    Loss 1.069693    Top1 89.319715    
2024-04-04 18:22:29,804 - Epoch: [26][   30/   44]    Loss 1.070352    Top1 89.445892    
2024-04-04 18:23:02,619 - Epoch: [26][   40/   44]    Loss 1.069846    Top1 89.168314    
2024-04-04 18:23:13,935 - Epoch: [26][   44/   44]    Loss 1.070261    Top1 89.150969    
2024-04-04 18:23:14,230 - ==> Top1: 89.151    Loss: 1.070

2024-04-04 18:23:14,236 - ==> Best [Top1: 90.571   Sparsity:0.00   Params: 272800 on epoch: 24]
2024-04-04 18:23:14,237 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:23:14,272 - 

2024-04-04 18:23:14,272 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:23:17,489 - Epoch: [27][   10/  139]    Overall Loss 1.063524    Objective Loss 1.063524                                        LR 0.000500    Time 0.321558    
2024-04-04 18:23:20,144 - Epoch: [27][   20/  139]    Overall Loss 1.059580    Objective Loss 1.059580                                        LR 0.000500    Time 0.293497    
2024-04-04 18:23:22,804 - Epoch: [27][   30/  139]    Overall Loss 1.059479    Objective Loss 1.059479                                        LR 0.000500    Time 0.284334    
2024-04-04 18:23:25,455 - Epoch: [27][   40/  139]    Overall Loss 1.061618    Objective Loss 1.061618                                        LR 0.000500    Time 0.279501    
2024-04-04 18:23:28,111 - Epoch: [27][   50/  139]    Overall Loss 1.061862    Objective Loss 1.061862                                        LR 0.000500    Time 0.276720    
2024-04-04 18:23:30,774 - Epoch: [27][   60/  139]    Overall Loss 1.061796    Objective Loss 1.061796                                        LR 0.000500    Time 0.274982    
2024-04-04 18:23:33,443 - Epoch: [27][   70/  139]    Overall Loss 1.060803    Objective Loss 1.060803                                        LR 0.000500    Time 0.273817    
2024-04-04 18:23:36,105 - Epoch: [27][   80/  139]    Overall Loss 1.059498    Objective Loss 1.059498                                        LR 0.000500    Time 0.272858    
2024-04-04 18:23:38,767 - Epoch: [27][   90/  139]    Overall Loss 1.058683    Objective Loss 1.058683                                        LR 0.000500    Time 0.272115    
2024-04-04 18:23:41,432 - Epoch: [27][  100/  139]    Overall Loss 1.058729    Objective Loss 1.058729                                        LR 0.000500    Time 0.271550    
2024-04-04 18:23:44,092 - Epoch: [27][  110/  139]    Overall Loss 1.058304    Objective Loss 1.058304                                        LR 0.000500    Time 0.271040    
2024-04-04 18:23:46,758 - Epoch: [27][  120/  139]    Overall Loss 1.058712    Objective Loss 1.058712                                        LR 0.000500    Time 0.270664    
2024-04-04 18:23:49,418 - Epoch: [27][  130/  139]    Overall Loss 1.058866    Objective Loss 1.058866                                        LR 0.000500    Time 0.270305    
2024-04-04 18:23:56,990 - Epoch: [27][  139/  139]    Overall Loss 1.059022    Objective Loss 1.059022    Top1 93.229821    LR 0.000500    Time 0.307270    
2024-04-04 18:23:57,234 - --- validate (epoch=27)-----------
2024-04-04 18:23:57,234 - 1392 samples (32 per mini-batch)
2024-04-04 18:24:30,354 - Epoch: [27][   10/   44]    Loss 1.050122    Top1 90.655056    
2024-04-04 18:25:02,968 - Epoch: [27][   20/   44]    Loss 1.056047    Top1 90.686064    
2024-04-04 18:25:34,878 - Epoch: [27][   30/   44]    Loss 1.059214    Top1 90.650390    
2024-04-04 18:26:07,470 - Epoch: [27][   40/   44]    Loss 1.061543    Top1 90.561678    
2024-04-04 18:26:19,249 - Epoch: [27][   44/   44]    Loss 1.062135    Top1 90.498493    
2024-04-04 18:26:19,550 - ==> Top1: 90.498    Loss: 1.062

2024-04-04 18:26:19,557 - ==> Best [Top1: 90.571   Sparsity:0.00   Params: 272800 on epoch: 24]
2024-04-04 18:26:19,558 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:26:19,595 - 

2024-04-04 18:26:19,595 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:26:23,060 - Epoch: [28][   10/  139]    Overall Loss 1.059594    Objective Loss 1.059594                                        LR 0.000500    Time 0.346327    
2024-04-04 18:26:25,755 - Epoch: [28][   20/  139]    Overall Loss 1.062718    Objective Loss 1.062718                                        LR 0.000500    Time 0.307906    
2024-04-04 18:26:28,409 - Epoch: [28][   30/  139]    Overall Loss 1.062333    Objective Loss 1.062333                                        LR 0.000500    Time 0.293709    
2024-04-04 18:26:31,068 - Epoch: [28][   40/  139]    Overall Loss 1.060524    Objective Loss 1.060524                                        LR 0.000500    Time 0.286750    
2024-04-04 18:26:33,724 - Epoch: [28][   50/  139]    Overall Loss 1.059270    Objective Loss 1.059270                                        LR 0.000500    Time 0.282513    
2024-04-04 18:26:36,381 - Epoch: [28][   60/  139]    Overall Loss 1.058317    Objective Loss 1.058317                                        LR 0.000500    Time 0.279696    
2024-04-04 18:26:39,035 - Epoch: [28][   70/  139]    Overall Loss 1.058349    Objective Loss 1.058349                                        LR 0.000500    Time 0.277644    
2024-04-04 18:26:41,694 - Epoch: [28][   80/  139]    Overall Loss 1.057885    Objective Loss 1.057885                                        LR 0.000500    Time 0.276175    
2024-04-04 18:26:44,355 - Epoch: [28][   90/  139]    Overall Loss 1.058600    Objective Loss 1.058600                                        LR 0.000500    Time 0.275048    
2024-04-04 18:26:47,012 - Epoch: [28][  100/  139]    Overall Loss 1.058538    Objective Loss 1.058538                                        LR 0.000500    Time 0.274113    
2024-04-04 18:26:49,671 - Epoch: [28][  110/  139]    Overall Loss 1.058499    Objective Loss 1.058499                                        LR 0.000500    Time 0.273355    
2024-04-04 18:26:52,326 - Epoch: [28][  120/  139]    Overall Loss 1.057965    Objective Loss 1.057965                                        LR 0.000500    Time 0.272700    
2024-04-04 18:26:54,983 - Epoch: [28][  130/  139]    Overall Loss 1.057891    Objective Loss 1.057891                                        LR 0.000500    Time 0.272158    
2024-04-04 18:27:01,687 - Epoch: [28][  139/  139]    Overall Loss 1.058259    Objective Loss 1.058259    Top1 94.491245    LR 0.000500    Time 0.302761    
2024-04-04 18:27:02,051 - --- validate (epoch=28)-----------
2024-04-04 18:27:02,052 - 1392 samples (32 per mini-batch)
2024-04-04 18:27:34,877 - Epoch: [28][   10/   44]    Loss 1.071677    Top1 90.217411    
2024-04-04 18:28:06,353 - Epoch: [28][   20/   44]    Loss 1.065655    Top1 90.571450    
2024-04-04 18:28:37,443 - Epoch: [28][   30/   44]    Loss 1.064157    Top1 90.514852    
2024-04-04 18:29:08,891 - Epoch: [28][   40/   44]    Loss 1.063411    Top1 90.599903    
2024-04-04 18:29:20,192 - Epoch: [28][   44/   44]    Loss 1.064261    Top1 90.591230    
2024-04-04 18:29:20,435 - ==> Top1: 90.591    Loss: 1.064

2024-04-04 18:29:20,441 - ==> Best [Top1: 90.591   Sparsity:0.00   Params: 272800 on epoch: 28]
2024-04-04 18:29:20,442 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:29:20,481 - 

2024-04-04 18:29:20,481 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:29:23,722 - Epoch: [29][   10/  139]    Overall Loss 1.051659    Objective Loss 1.051659                                        LR 0.000500    Time 0.323950    
2024-04-04 18:29:26,375 - Epoch: [29][   20/  139]    Overall Loss 1.053470    Objective Loss 1.053470                                        LR 0.000500    Time 0.294587    
2024-04-04 18:29:29,030 - Epoch: [29][   30/  139]    Overall Loss 1.055369    Objective Loss 1.055369                                        LR 0.000500    Time 0.284896    
2024-04-04 18:29:31,689 - Epoch: [29][   40/  139]    Overall Loss 1.058039    Objective Loss 1.058039                                        LR 0.000500    Time 0.280120    
2024-04-04 18:29:34,342 - Epoch: [29][   50/  139]    Overall Loss 1.057374    Objective Loss 1.057374                                        LR 0.000500    Time 0.277153    
2024-04-04 18:29:37,004 - Epoch: [29][   60/  139]    Overall Loss 1.057002    Objective Loss 1.057002                                        LR 0.000500    Time 0.275328    
2024-04-04 18:29:39,669 - Epoch: [29][   70/  139]    Overall Loss 1.057657    Objective Loss 1.057657                                        LR 0.000500    Time 0.274047    
2024-04-04 18:29:42,320 - Epoch: [29][   80/  139]    Overall Loss 1.058149    Objective Loss 1.058149                                        LR 0.000500    Time 0.272927    
2024-04-04 18:29:44,984 - Epoch: [29][   90/  139]    Overall Loss 1.058150    Objective Loss 1.058150                                        LR 0.000500    Time 0.272193    
2024-04-04 18:29:47,643 - Epoch: [29][  100/  139]    Overall Loss 1.058682    Objective Loss 1.058682                                        LR 0.000500    Time 0.271563    
2024-04-04 18:29:50,305 - Epoch: [29][  110/  139]    Overall Loss 1.058278    Objective Loss 1.058278                                        LR 0.000500    Time 0.271075    
2024-04-04 18:29:52,963 - Epoch: [29][  120/  139]    Overall Loss 1.058987    Objective Loss 1.058987                                        LR 0.000500    Time 0.270624    
2024-04-04 18:29:55,622 - Epoch: [29][  130/  139]    Overall Loss 1.058822    Objective Loss 1.058822                                        LR 0.000500    Time 0.270259    
2024-04-04 18:30:02,568 - Epoch: [29][  139/  139]    Overall Loss 1.059017    Objective Loss 1.059017    Top1 93.132091    LR 0.000500    Time 0.302731    
2024-04-04 18:30:02,929 - --- validate (epoch=29)-----------
2024-04-04 18:30:02,930 - 1392 samples (32 per mini-batch)
2024-04-04 18:30:35,685 - Epoch: [29][   10/   44]    Loss 1.069510    Top1 91.917122    
2024-04-04 18:31:07,158 - Epoch: [29][   20/   44]    Loss 1.065539    Top1 91.228987    
2024-04-04 18:31:40,241 - Epoch: [29][   30/   44]    Loss 1.066773    Top1 91.149205    
2024-04-04 18:32:12,109 - Epoch: [29][   40/   44]    Loss 1.067143    Top1 91.020251    
2024-04-04 18:32:23,256 - Epoch: [29][   44/   44]    Loss 1.065667    Top1 91.077187    
2024-04-04 18:32:23,588 - ==> Top1: 91.077    Loss: 1.066

2024-04-04 18:32:23,595 - ==> Best [Top1: 91.077   Sparsity:0.00   Params: 272800 on epoch: 29]
2024-04-04 18:32:23,595 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:32:23,635 - 

2024-04-04 18:32:23,635 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:32:27,085 - Epoch: [30][   10/  139]    Overall Loss 1.053031    Objective Loss 1.053031                                        LR 0.000500    Time 0.344871    
2024-04-04 18:32:29,739 - Epoch: [30][   20/  139]    Overall Loss 1.054040    Objective Loss 1.054040                                        LR 0.000500    Time 0.305111    
2024-04-04 18:32:32,398 - Epoch: [30][   30/  139]    Overall Loss 1.055405    Objective Loss 1.055405                                        LR 0.000500    Time 0.292044    
2024-04-04 18:32:35,050 - Epoch: [30][   40/  139]    Overall Loss 1.056374    Objective Loss 1.056374                                        LR 0.000500    Time 0.285300    
2024-04-04 18:32:37,716 - Epoch: [30][   50/  139]    Overall Loss 1.058098    Objective Loss 1.058098                                        LR 0.000500    Time 0.281555    
2024-04-04 18:32:40,380 - Epoch: [30][   60/  139]    Overall Loss 1.058497    Objective Loss 1.058497                                        LR 0.000500    Time 0.279026    
2024-04-04 18:32:43,038 - Epoch: [30][   70/  139]    Overall Loss 1.059059    Objective Loss 1.059059                                        LR 0.000500    Time 0.277123    
2024-04-04 18:32:45,699 - Epoch: [30][   80/  139]    Overall Loss 1.057266    Objective Loss 1.057266                                        LR 0.000500    Time 0.275743    
2024-04-04 18:32:48,361 - Epoch: [30][   90/  139]    Overall Loss 1.057830    Objective Loss 1.057830                                        LR 0.000500    Time 0.274673    
2024-04-04 18:32:51,021 - Epoch: [30][  100/  139]    Overall Loss 1.057268    Objective Loss 1.057268                                        LR 0.000500    Time 0.273799    
2024-04-04 18:32:53,681 - Epoch: [30][  110/  139]    Overall Loss 1.057697    Objective Loss 1.057697                                        LR 0.000500    Time 0.273087    
2024-04-04 18:32:56,344 - Epoch: [30][  120/  139]    Overall Loss 1.057589    Objective Loss 1.057589                                        LR 0.000500    Time 0.272522    
2024-04-04 18:32:58,998 - Epoch: [30][  130/  139]    Overall Loss 1.058038    Objective Loss 1.058038                                        LR 0.000500    Time 0.271965    
2024-04-04 18:33:05,982 - Epoch: [30][  139/  139]    Overall Loss 1.058506    Objective Loss 1.058506    Top1 92.669288    LR 0.000500    Time 0.304601    
2024-04-04 18:33:06,279 - --- validate (epoch=30)-----------
2024-04-04 18:33:06,280 - 1392 samples (32 per mini-batch)
2024-04-04 18:33:39,894 - Epoch: [30][   10/   44]    Loss 1.058628    Top1 90.102025    
2024-04-04 18:34:11,747 - Epoch: [30][   20/   44]    Loss 1.061718    Top1 90.032489    
2024-04-04 18:34:44,041 - Epoch: [30][   30/   44]    Loss 1.063906    Top1 89.741922    
2024-04-04 18:35:16,212 - Epoch: [30][   40/   44]    Loss 1.063443    Top1 89.705032    
2024-04-04 18:35:27,118 - Epoch: [30][   44/   44]    Loss 1.062397    Top1 89.789598    
2024-04-04 18:35:27,368 - ==> Top1: 89.790    Loss: 1.062

2024-04-04 18:35:27,375 - ==> Best [Top1: 91.077   Sparsity:0.00   Params: 272800 on epoch: 29]
2024-04-04 18:35:27,375 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:35:27,412 - 

2024-04-04 18:35:27,412 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:35:30,869 - Epoch: [31][   10/  139]    Overall Loss 1.060680    Objective Loss 1.060680                                        LR 0.000500    Time 0.345617    
2024-04-04 18:35:33,525 - Epoch: [31][   20/  139]    Overall Loss 1.057774    Objective Loss 1.057774                                        LR 0.000500    Time 0.305576    
2024-04-04 18:35:36,183 - Epoch: [31][   30/  139]    Overall Loss 1.057514    Objective Loss 1.057514                                        LR 0.000500    Time 0.292282    
2024-04-04 18:35:38,836 - Epoch: [31][   40/  139]    Overall Loss 1.058132    Objective Loss 1.058132                                        LR 0.000500    Time 0.285528    
2024-04-04 18:35:41,494 - Epoch: [31][   50/  139]    Overall Loss 1.058377    Objective Loss 1.058377                                        LR 0.000500    Time 0.281575    
2024-04-04 18:35:44,152 - Epoch: [31][   60/  139]    Overall Loss 1.057819    Objective Loss 1.057819                                        LR 0.000500    Time 0.278935    
2024-04-04 18:35:46,810 - Epoch: [31][   70/  139]    Overall Loss 1.057496    Objective Loss 1.057496                                        LR 0.000500    Time 0.277058    
2024-04-04 18:35:49,468 - Epoch: [31][   80/  139]    Overall Loss 1.058517    Objective Loss 1.058517                                        LR 0.000500    Time 0.275645    
2024-04-04 18:35:52,129 - Epoch: [31][   90/  139]    Overall Loss 1.058367    Objective Loss 1.058367                                        LR 0.000500    Time 0.274571    
2024-04-04 18:35:54,794 - Epoch: [31][  100/  139]    Overall Loss 1.058720    Objective Loss 1.058720                                        LR 0.000500    Time 0.273762    
2024-04-04 18:35:57,454 - Epoch: [31][  110/  139]    Overall Loss 1.059145    Objective Loss 1.059145                                        LR 0.000500    Time 0.273058    
2024-04-04 18:36:00,114 - Epoch: [31][  120/  139]    Overall Loss 1.058340    Objective Loss 1.058340                                        LR 0.000500    Time 0.272465    
2024-04-04 18:36:02,771 - Epoch: [31][  130/  139]    Overall Loss 1.058244    Objective Loss 1.058244                                        LR 0.000500    Time 0.271935    
2024-04-04 18:36:09,363 - Epoch: [31][  139/  139]    Overall Loss 1.057820    Objective Loss 1.057820    Top1 94.752792    LR 0.000500    Time 0.301753    
2024-04-04 18:36:09,627 - --- validate (epoch=31)-----------
2024-04-04 18:36:09,628 - 1392 samples (32 per mini-batch)
2024-04-04 18:36:42,588 - Epoch: [31][   10/   44]    Loss 1.065570    Top1 89.890460    
2024-04-04 18:37:14,945 - Epoch: [31][   20/   44]    Loss 1.066604    Top1 90.523994    
2024-04-04 18:37:46,916 - Epoch: [31][   30/   44]    Loss 1.069130    Top1 90.657117    
2024-04-04 18:38:18,360 - Epoch: [31][   40/   44]    Loss 1.068855    Top1 90.591677    
2024-04-04 18:38:29,853 - Epoch: [31][   44/   44]    Loss 1.067883    Top1 90.627739    
2024-04-04 18:38:30,123 - ==> Top1: 90.628    Loss: 1.068

2024-04-04 18:38:30,130 - ==> Best [Top1: 91.077   Sparsity:0.00   Params: 272800 on epoch: 29]
2024-04-04 18:38:30,131 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:38:30,167 - 

2024-04-04 18:38:30,167 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:38:33,438 - Epoch: [32][   10/  139]    Overall Loss 1.052409    Objective Loss 1.052409                                        LR 0.000500    Time 0.326938    
2024-04-04 18:38:36,095 - Epoch: [32][   20/  139]    Overall Loss 1.053007    Objective Loss 1.053007                                        LR 0.000500    Time 0.296274    
2024-04-04 18:38:38,762 - Epoch: [32][   30/  139]    Overall Loss 1.055233    Objective Loss 1.055233                                        LR 0.000500    Time 0.286421    
2024-04-04 18:38:41,421 - Epoch: [32][   40/  139]    Overall Loss 1.053440    Objective Loss 1.053440                                        LR 0.000500    Time 0.281273    
2024-04-04 18:38:44,085 - Epoch: [32][   50/  139]    Overall Loss 1.056389    Objective Loss 1.056389                                        LR 0.000500    Time 0.278285    
2024-04-04 18:38:46,743 - Epoch: [32][   60/  139]    Overall Loss 1.056975    Objective Loss 1.056975                                        LR 0.000500    Time 0.276199    
2024-04-04 18:38:49,408 - Epoch: [32][   70/  139]    Overall Loss 1.057572    Objective Loss 1.057572                                        LR 0.000500    Time 0.274812    
2024-04-04 18:38:52,070 - Epoch: [32][   80/  139]    Overall Loss 1.057335    Objective Loss 1.057335                                        LR 0.000500    Time 0.273729    
2024-04-04 18:38:54,729 - Epoch: [32][   90/  139]    Overall Loss 1.056459    Objective Loss 1.056459                                        LR 0.000500    Time 0.272854    
2024-04-04 18:38:57,392 - Epoch: [32][  100/  139]    Overall Loss 1.056873    Objective Loss 1.056873                                        LR 0.000500    Time 0.272197    
2024-04-04 18:39:00,056 - Epoch: [32][  110/  139]    Overall Loss 1.057330    Objective Loss 1.057330                                        LR 0.000500    Time 0.271658    
2024-04-04 18:39:02,715 - Epoch: [32][  120/  139]    Overall Loss 1.057248    Objective Loss 1.057248                                        LR 0.000500    Time 0.271178    
2024-04-04 18:39:05,375 - Epoch: [32][  130/  139]    Overall Loss 1.057956    Objective Loss 1.057956                                        LR 0.000500    Time 0.270779    
2024-04-04 18:39:12,257 - Epoch: [32][  139/  139]    Overall Loss 1.057943    Objective Loss 1.057943    Top1 92.473095    LR 0.000500    Time 0.302753    
2024-04-04 18:39:12,506 - --- validate (epoch=32)-----------
2024-04-04 18:39:12,507 - 1392 samples (32 per mini-batch)
2024-04-04 18:39:45,326 - Epoch: [32][   10/   44]    Loss 1.075889    Top1 89.571064    
2024-04-04 18:40:17,431 - Epoch: [32][   20/   44]    Loss 1.077420    Top1 89.323427    
2024-04-04 18:40:48,478 - Epoch: [32][   30/   44]    Loss 1.076187    Top1 88.824554    
2024-04-04 18:41:19,979 - Epoch: [32][   40/   44]    Loss 1.076967    Top1 88.755986    
2024-04-04 18:41:31,178 - Epoch: [32][   44/   44]    Loss 1.076083    Top1 88.767912    
2024-04-04 18:41:31,455 - ==> Top1: 88.768    Loss: 1.076

2024-04-04 18:41:31,462 - ==> Best [Top1: 91.077   Sparsity:0.00   Params: 272800 on epoch: 29]
2024-04-04 18:41:31,463 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:41:31,497 - 

2024-04-04 18:41:31,497 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:41:34,855 - Epoch: [33][   10/  139]    Overall Loss 1.064141    Objective Loss 1.064141                                        LR 0.000500    Time 0.335646    
2024-04-04 18:41:37,508 - Epoch: [33][   20/  139]    Overall Loss 1.066407    Objective Loss 1.066407                                        LR 0.000500    Time 0.300431    
2024-04-04 18:41:40,167 - Epoch: [33][   30/  139]    Overall Loss 1.061224    Objective Loss 1.061224                                        LR 0.000500    Time 0.288911    
2024-04-04 18:41:42,822 - Epoch: [33][   40/  139]    Overall Loss 1.058607    Objective Loss 1.058607                                        LR 0.000500    Time 0.283051    
2024-04-04 18:41:45,484 - Epoch: [33][   50/  139]    Overall Loss 1.057208    Objective Loss 1.057208                                        LR 0.000500    Time 0.279669    
2024-04-04 18:41:48,142 - Epoch: [33][   60/  139]    Overall Loss 1.057134    Objective Loss 1.057134                                        LR 0.000500    Time 0.277348    
2024-04-04 18:41:50,811 - Epoch: [33][   70/  139]    Overall Loss 1.057477    Objective Loss 1.057477                                        LR 0.000500    Time 0.275846    
2024-04-04 18:41:53,468 - Epoch: [33][   80/  139]    Overall Loss 1.057477    Objective Loss 1.057477                                        LR 0.000500    Time 0.274577    
2024-04-04 18:41:56,133 - Epoch: [33][   90/  139]    Overall Loss 1.056747    Objective Loss 1.056747                                        LR 0.000500    Time 0.273673    
2024-04-04 18:41:58,798 - Epoch: [33][  100/  139]    Overall Loss 1.057389    Objective Loss 1.057389                                        LR 0.000500    Time 0.272952    
2024-04-04 18:42:01,465 - Epoch: [33][  110/  139]    Overall Loss 1.057099    Objective Loss 1.057099                                        LR 0.000500    Time 0.272373    
2024-04-04 18:42:04,132 - Epoch: [33][  120/  139]    Overall Loss 1.056848    Objective Loss 1.056848                                        LR 0.000500    Time 0.271901    
2024-04-04 18:42:06,791 - Epoch: [33][  130/  139]    Overall Loss 1.057385    Objective Loss 1.057385                                        LR 0.000500    Time 0.271432    
2024-04-04 18:42:14,542 - Epoch: [33][  139/  139]    Overall Loss 1.057391    Objective Loss 1.057391    Top1 93.934068    LR 0.000500    Time 0.309622    
2024-04-04 18:42:14,831 - --- validate (epoch=33)-----------
2024-04-04 18:42:14,832 - 1392 samples (32 per mini-batch)
2024-04-04 18:42:49,047 - Epoch: [33][   10/   44]    Loss 1.080045    Top1 88.245872    
2024-04-04 18:43:21,954 - Epoch: [33][   20/   44]    Loss 1.081394    Top1 88.304790    
2024-04-04 18:43:54,047 - Epoch: [33][   30/   44]    Loss 1.080780    Top1 88.453282    
2024-04-04 18:44:25,417 - Epoch: [33][   40/   44]    Loss 1.079054    Top1 88.709978    
2024-04-04 18:44:36,223 - Epoch: [33][   44/   44]    Loss 1.078152    Top1 88.544851    
2024-04-04 18:44:36,613 - ==> Top1: 88.545    Loss: 1.078

2024-04-04 18:44:36,620 - ==> Best [Top1: 91.077   Sparsity:0.00   Params: 272800 on epoch: 29]
2024-04-04 18:44:36,620 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:44:36,656 - 

2024-04-04 18:44:36,656 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:44:39,997 - Epoch: [34][   10/  139]    Overall Loss 1.053916    Objective Loss 1.053916                                        LR 0.000500    Time 0.333954    
2024-04-04 18:44:42,651 - Epoch: [34][   20/  139]    Overall Loss 1.059515    Objective Loss 1.059515                                        LR 0.000500    Time 0.299660    
2024-04-04 18:44:45,305 - Epoch: [34][   30/  139]    Overall Loss 1.060912    Objective Loss 1.060912                                        LR 0.000500    Time 0.288202    
2024-04-04 18:44:47,956 - Epoch: [34][   40/  139]    Overall Loss 1.061017    Objective Loss 1.061017                                        LR 0.000500    Time 0.282434    
2024-04-04 18:44:50,614 - Epoch: [34][   50/  139]    Overall Loss 1.060320    Objective Loss 1.060320                                        LR 0.000500    Time 0.279089    
2024-04-04 18:44:53,268 - Epoch: [34][   60/  139]    Overall Loss 1.060060    Objective Loss 1.060060                                        LR 0.000500    Time 0.276793    
2024-04-04 18:44:55,921 - Epoch: [34][   70/  139]    Overall Loss 1.059080    Objective Loss 1.059080                                        LR 0.000500    Time 0.275147    
2024-04-04 18:44:58,576 - Epoch: [34][   80/  139]    Overall Loss 1.056840    Objective Loss 1.056840                                        LR 0.000500    Time 0.273937    
2024-04-04 18:45:01,229 - Epoch: [34][   90/  139]    Overall Loss 1.058202    Objective Loss 1.058202                                        LR 0.000500    Time 0.272972    
2024-04-04 18:45:03,888 - Epoch: [34][  100/  139]    Overall Loss 1.058201    Objective Loss 1.058201                                        LR 0.000500    Time 0.272255    
2024-04-04 18:45:06,565 - Epoch: [34][  110/  139]    Overall Loss 1.057782    Objective Loss 1.057782                                        LR 0.000500    Time 0.271838    
2024-04-04 18:45:09,194 - Epoch: [34][  120/  139]    Overall Loss 1.058400    Objective Loss 1.058400                                        LR 0.000500    Time 0.271086    
2024-04-04 18:45:11,845 - Epoch: [34][  130/  139]    Overall Loss 1.057734    Objective Loss 1.057734                                        LR 0.000500    Time 0.270626    
2024-04-04 18:45:19,552 - Epoch: [34][  139/  139]    Overall Loss 1.058182    Objective Loss 1.058182    Top1 94.726269    LR 0.000500    Time 0.308542    
2024-04-04 18:45:19,871 - --- validate (epoch=34)-----------
2024-04-04 18:45:19,871 - 1392 samples (32 per mini-batch)
2024-04-04 18:45:53,267 - Epoch: [34][   10/   44]    Loss 1.069457    Top1 90.029176    
2024-04-04 18:46:25,324 - Epoch: [34][   20/   44]    Loss 1.071187    Top1 90.118037    
2024-04-04 18:46:57,700 - Epoch: [34][   30/   44]    Loss 1.069785    Top1 89.952097    
2024-04-04 18:47:29,789 - Epoch: [34][   40/   44]    Loss 1.067430    Top1 90.005914    
2024-04-04 18:47:40,915 - Epoch: [34][   44/   44]    Loss 1.067568    Top1 89.995417    
2024-04-04 18:47:41,159 - ==> Top1: 89.995    Loss: 1.068

2024-04-04 18:47:41,166 - ==> Best [Top1: 91.077   Sparsity:0.00   Params: 272800 on epoch: 29]
2024-04-04 18:47:41,167 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:47:41,201 - 

2024-04-04 18:47:41,201 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:47:44,520 - Epoch: [35][   10/  139]    Overall Loss 1.061200    Objective Loss 1.061200                                        LR 0.000500    Time 0.331763    
2024-04-04 18:47:47,182 - Epoch: [35][   20/  139]    Overall Loss 1.059055    Objective Loss 1.059055                                        LR 0.000500    Time 0.298973    
2024-04-04 18:47:49,838 - Epoch: [35][   30/  139]    Overall Loss 1.059548    Objective Loss 1.059548                                        LR 0.000500    Time 0.287830    
2024-04-04 18:47:52,495 - Epoch: [35][   40/  139]    Overall Loss 1.059264    Objective Loss 1.059264                                        LR 0.000500    Time 0.282271    
2024-04-04 18:47:55,155 - Epoch: [35][   50/  139]    Overall Loss 1.058645    Objective Loss 1.058645                                        LR 0.000500    Time 0.279021    
2024-04-04 18:47:57,810 - Epoch: [35][   60/  139]    Overall Loss 1.057495    Objective Loss 1.057495                                        LR 0.000500    Time 0.276756    
2024-04-04 18:48:00,469 - Epoch: [35][   70/  139]    Overall Loss 1.057374    Objective Loss 1.057374                                        LR 0.000500    Time 0.275196    
2024-04-04 18:48:03,131 - Epoch: [35][   80/  139]    Overall Loss 1.056905    Objective Loss 1.056905                                        LR 0.000500    Time 0.274064    
2024-04-04 18:48:05,792 - Epoch: [35][   90/  139]    Overall Loss 1.057338    Objective Loss 1.057338                                        LR 0.000500    Time 0.273173    
2024-04-04 18:48:08,456 - Epoch: [35][  100/  139]    Overall Loss 1.057359    Objective Loss 1.057359                                        LR 0.000500    Time 0.272488    
2024-04-04 18:48:11,116 - Epoch: [35][  110/  139]    Overall Loss 1.057534    Objective Loss 1.057534                                        LR 0.000500    Time 0.271895    
2024-04-04 18:48:13,776 - Epoch: [35][  120/  139]    Overall Loss 1.057737    Objective Loss 1.057737                                        LR 0.000500    Time 0.271400    
2024-04-04 18:48:16,433 - Epoch: [35][  130/  139]    Overall Loss 1.057951    Objective Loss 1.057951                                        LR 0.000500    Time 0.270957    
2024-04-04 18:48:24,135 - Epoch: [35][  139/  139]    Overall Loss 1.057984    Objective Loss 1.057984    Top1 94.039961    LR 0.000500    Time 0.308822    
2024-04-04 18:48:24,511 - --- validate (epoch=35)-----------
2024-04-04 18:48:24,512 - 1392 samples (32 per mini-batch)
2024-04-04 18:48:57,712 - Epoch: [35][   10/   44]    Loss 1.066098    Top1 91.037199    
2024-04-04 18:49:30,269 - Epoch: [35][   20/   44]    Loss 1.064173    Top1 90.411615    
2024-04-04 18:50:02,556 - Epoch: [35][   30/   44]    Loss 1.063246    Top1 90.323894    
2024-04-04 18:50:34,469 - Epoch: [35][   40/   44]    Loss 1.064006    Top1 90.599075    
2024-04-04 18:50:46,257 - Epoch: [35][   44/   44]    Loss 1.063345    Top1 90.479328    
2024-04-04 18:50:46,569 - ==> Top1: 90.479    Loss: 1.063

2024-04-04 18:50:46,576 - ==> Best [Top1: 91.077   Sparsity:0.00   Params: 272800 on epoch: 29]
2024-04-04 18:50:46,576 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:50:46,613 - 

2024-04-04 18:50:46,613 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:50:49,901 - Epoch: [36][   10/  139]    Overall Loss 1.057024    Objective Loss 1.057024                                        LR 0.000500    Time 0.328698    
2024-04-04 18:50:52,551 - Epoch: [36][   20/  139]    Overall Loss 1.057756    Objective Loss 1.057756                                        LR 0.000500    Time 0.296795    
2024-04-04 18:50:55,208 - Epoch: [36][   30/  139]    Overall Loss 1.056348    Objective Loss 1.056348                                        LR 0.000500    Time 0.286429    
2024-04-04 18:50:57,862 - Epoch: [36][   40/  139]    Overall Loss 1.056098    Objective Loss 1.056098                                        LR 0.000500    Time 0.281144    
2024-04-04 18:51:00,522 - Epoch: [36][   50/  139]    Overall Loss 1.055762    Objective Loss 1.055762                                        LR 0.000500    Time 0.278104    
2024-04-04 18:51:03,180 - Epoch: [36][   60/  139]    Overall Loss 1.055684    Objective Loss 1.055684                                        LR 0.000500    Time 0.276047    
2024-04-04 18:51:05,828 - Epoch: [36][   70/  139]    Overall Loss 1.055643    Objective Loss 1.055643                                        LR 0.000500    Time 0.274436    
2024-04-04 18:51:08,475 - Epoch: [36][   80/  139]    Overall Loss 1.055766    Objective Loss 1.055766                                        LR 0.000500    Time 0.273217    
2024-04-04 18:51:11,121 - Epoch: [36][   90/  139]    Overall Loss 1.054643    Objective Loss 1.054643                                        LR 0.000500    Time 0.272251    
2024-04-04 18:51:13,769 - Epoch: [36][  100/  139]    Overall Loss 1.056048    Objective Loss 1.056048                                        LR 0.000500    Time 0.271503    
2024-04-04 18:51:16,414 - Epoch: [36][  110/  139]    Overall Loss 1.055829    Objective Loss 1.055829                                        LR 0.000500    Time 0.270859    
2024-04-04 18:51:19,065 - Epoch: [36][  120/  139]    Overall Loss 1.056077    Objective Loss 1.056077                                        LR 0.000500    Time 0.270377    
2024-04-04 18:51:21,710 - Epoch: [36][  130/  139]    Overall Loss 1.056527    Objective Loss 1.056527                                        LR 0.000500    Time 0.269920    
2024-04-04 18:51:28,511 - Epoch: [36][  139/  139]    Overall Loss 1.056896    Objective Loss 1.056896    Top1 94.093631    LR 0.000500    Time 0.301372    
2024-04-04 18:51:28,899 - --- validate (epoch=36)-----------
2024-04-04 18:51:28,900 - 1392 samples (32 per mini-batch)
2024-04-04 18:52:01,879 - Epoch: [36][   10/   44]    Loss 1.085949    Top1 89.436030    
2024-04-04 18:52:34,456 - Epoch: [36][   20/   44]    Loss 1.080081    Top1 89.718267    
2024-04-04 18:53:05,867 - Epoch: [36][   30/   44]    Loss 1.077505    Top1 89.502846    
2024-04-04 18:53:36,716 - Epoch: [36][   40/   44]    Loss 1.076139    Top1 89.184458    
2024-04-04 18:53:47,407 - Epoch: [36][   44/   44]    Loss 1.075882    Top1 89.238484    
2024-04-04 18:53:47,698 - ==> Top1: 89.238    Loss: 1.076

2024-04-04 18:53:47,705 - ==> Best [Top1: 91.077   Sparsity:0.00   Params: 272800 on epoch: 29]
2024-04-04 18:53:47,705 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:53:47,741 - 

2024-04-04 18:53:47,741 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:53:51,150 - Epoch: [37][   10/  139]    Overall Loss 1.054256    Objective Loss 1.054256                                        LR 0.000500    Time 0.340848    
2024-04-04 18:53:53,804 - Epoch: [37][   20/  139]    Overall Loss 1.054933    Objective Loss 1.054933                                        LR 0.000500    Time 0.303088    
2024-04-04 18:53:56,457 - Epoch: [37][   30/  139]    Overall Loss 1.055417    Objective Loss 1.055417                                        LR 0.000500    Time 0.290474    
2024-04-04 18:53:59,114 - Epoch: [37][   40/  139]    Overall Loss 1.053069    Objective Loss 1.053069                                        LR 0.000500    Time 0.284258    
2024-04-04 18:54:01,764 - Epoch: [37][   50/  139]    Overall Loss 1.053392    Objective Loss 1.053392                                        LR 0.000500    Time 0.280399    
2024-04-04 18:54:04,419 - Epoch: [37][   60/  139]    Overall Loss 1.053835    Objective Loss 1.053835                                        LR 0.000500    Time 0.277903    
2024-04-04 18:54:07,124 - Epoch: [37][   70/  139]    Overall Loss 1.053997    Objective Loss 1.053997                                        LR 0.000500    Time 0.276846    
2024-04-04 18:54:09,768 - Epoch: [37][   80/  139]    Overall Loss 1.054138    Objective Loss 1.054138                                        LR 0.000500    Time 0.275285    
2024-04-04 18:54:12,421 - Epoch: [37][   90/  139]    Overall Loss 1.055285    Objective Loss 1.055285                                        LR 0.000500    Time 0.274163    
2024-04-04 18:54:15,084 - Epoch: [37][  100/  139]    Overall Loss 1.056010    Objective Loss 1.056010                                        LR 0.000500    Time 0.273374    
2024-04-04 18:54:17,731 - Epoch: [37][  110/  139]    Overall Loss 1.055436    Objective Loss 1.055436                                        LR 0.000500    Time 0.272578    
2024-04-04 18:54:20,388 - Epoch: [37][  120/  139]    Overall Loss 1.054921    Objective Loss 1.054921                                        LR 0.000500    Time 0.272000    
2024-04-04 18:54:23,040 - Epoch: [37][  130/  139]    Overall Loss 1.055327    Objective Loss 1.055327                                        LR 0.000500    Time 0.271479    
2024-04-04 18:54:30,285 - Epoch: [37][  139/  139]    Overall Loss 1.055931    Objective Loss 1.055931    Top1 93.935683    LR 0.000500    Time 0.306018    
2024-04-04 18:54:30,528 - --- validate (epoch=37)-----------
2024-04-04 18:54:30,530 - 1392 samples (32 per mini-batch)
2024-04-04 18:55:03,253 - Epoch: [37][   10/   44]    Loss 1.068498    Top1 90.747502    
2024-04-04 18:55:36,132 - Epoch: [37][   20/   44]    Loss 1.070868    Top1 90.672494    
2024-04-04 18:56:07,898 - Epoch: [37][   30/   44]    Loss 1.066512    Top1 90.849749    
2024-04-04 18:56:39,786 - Epoch: [37][   40/   44]    Loss 1.065915    Top1 90.724511    
2024-04-04 18:56:51,083 - Epoch: [37][   44/   44]    Loss 1.064272    Top1 90.789099    
2024-04-04 18:56:51,414 - ==> Top1: 90.789    Loss: 1.064

2024-04-04 18:56:51,422 - ==> Best [Top1: 91.077   Sparsity:0.00   Params: 272800 on epoch: 29]
2024-04-04 18:56:51,422 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:56:51,457 - 

2024-04-04 18:56:51,458 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:56:54,791 - Epoch: [38][   10/  139]    Overall Loss 1.049873    Objective Loss 1.049873                                        LR 0.000500    Time 0.333226    
2024-04-04 18:56:57,445 - Epoch: [38][   20/  139]    Overall Loss 1.050368    Objective Loss 1.050368                                        LR 0.000500    Time 0.299264    
2024-04-04 18:57:00,102 - Epoch: [38][   30/  139]    Overall Loss 1.053173    Objective Loss 1.053173                                        LR 0.000500    Time 0.288058    
2024-04-04 18:57:02,759 - Epoch: [38][   40/  139]    Overall Loss 1.052216    Objective Loss 1.052216                                        LR 0.000500    Time 0.282472    
2024-04-04 18:57:05,413 - Epoch: [38][   50/  139]    Overall Loss 1.054437    Objective Loss 1.054437                                        LR 0.000500    Time 0.279047    
2024-04-04 18:57:08,075 - Epoch: [38][   60/  139]    Overall Loss 1.054956    Objective Loss 1.054956                                        LR 0.000500    Time 0.276893    
2024-04-04 18:57:10,733 - Epoch: [38][   70/  139]    Overall Loss 1.055368    Objective Loss 1.055368                                        LR 0.000500    Time 0.275298    
2024-04-04 18:57:13,392 - Epoch: [38][   80/  139]    Overall Loss 1.055823    Objective Loss 1.055823                                        LR 0.000500    Time 0.274128    
2024-04-04 18:57:16,051 - Epoch: [38][   90/  139]    Overall Loss 1.055555    Objective Loss 1.055555                                        LR 0.000500    Time 0.273208    
2024-04-04 18:57:18,713 - Epoch: [38][  100/  139]    Overall Loss 1.056165    Objective Loss 1.056165                                        LR 0.000500    Time 0.272499    
2024-04-04 18:57:21,374 - Epoch: [38][  110/  139]    Overall Loss 1.055899    Objective Loss 1.055899                                        LR 0.000500    Time 0.271913    
2024-04-04 18:57:24,034 - Epoch: [38][  120/  139]    Overall Loss 1.056454    Objective Loss 1.056454                                        LR 0.000500    Time 0.271417    
2024-04-04 18:57:26,693 - Epoch: [38][  130/  139]    Overall Loss 1.055948    Objective Loss 1.055948                                        LR 0.000500    Time 0.270987    
2024-04-04 18:57:33,147 - Epoch: [38][  139/  139]    Overall Loss 1.056396    Objective Loss 1.056396    Top1 93.329311    LR 0.000500    Time 0.299872    
2024-04-04 18:57:33,517 - --- validate (epoch=38)-----------
2024-04-04 18:57:33,518 - 1392 samples (32 per mini-batch)
2024-04-04 18:58:06,237 - Epoch: [38][   10/   44]    Loss 1.061148    Top1 89.685250    
2024-04-04 18:58:38,722 - Epoch: [38][   20/   44]    Loss 1.065714    Top1 89.527956    
2024-04-04 18:59:10,584 - Epoch: [38][   30/   44]    Loss 1.066077    Top1 89.551419    
2024-04-04 18:59:43,251 - Epoch: [38][   40/   44]    Loss 1.065087    Top1 89.582373    
2024-04-04 18:59:54,353 - Epoch: [38][   44/   44]    Loss 1.064843    Top1 89.586968    
2024-04-04 18:59:54,582 - ==> Top1: 89.587    Loss: 1.065

2024-04-04 18:59:54,589 - ==> Best [Top1: 91.077   Sparsity:0.00   Params: 272800 on epoch: 29]
2024-04-04 18:59:54,590 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 18:59:54,625 - 

2024-04-04 18:59:54,625 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 18:59:57,981 - Epoch: [39][   10/  139]    Overall Loss 1.057738    Objective Loss 1.057738                                        LR 0.000500    Time 0.335471    
2024-04-04 19:00:00,671 - Epoch: [39][   20/  139]    Overall Loss 1.057525    Objective Loss 1.057525                                        LR 0.000500    Time 0.302228    
2024-04-04 19:00:03,328 - Epoch: [39][   30/  139]    Overall Loss 1.056184    Objective Loss 1.056184                                        LR 0.000500    Time 0.290020    
2024-04-04 19:00:05,999 - Epoch: [39][   40/  139]    Overall Loss 1.055738    Objective Loss 1.055738                                        LR 0.000500    Time 0.284276    
2024-04-04 19:00:08,656 - Epoch: [39][   50/  139]    Overall Loss 1.056920    Objective Loss 1.056920                                        LR 0.000500    Time 0.280549    
2024-04-04 19:00:11,317 - Epoch: [39][   60/  139]    Overall Loss 1.056039    Objective Loss 1.056039                                        LR 0.000500    Time 0.278135    
2024-04-04 19:00:13,981 - Epoch: [39][   70/  139]    Overall Loss 1.056107    Objective Loss 1.056107                                        LR 0.000500    Time 0.276459    
2024-04-04 19:00:16,642 - Epoch: [39][   80/  139]    Overall Loss 1.056438    Objective Loss 1.056438                                        LR 0.000500    Time 0.275147    
2024-04-04 19:00:19,302 - Epoch: [39][   90/  139]    Overall Loss 1.056437    Objective Loss 1.056437                                        LR 0.000500    Time 0.274126    
2024-04-04 19:00:21,966 - Epoch: [39][  100/  139]    Overall Loss 1.056356    Objective Loss 1.056356                                        LR 0.000500    Time 0.273357    
2024-04-04 19:00:24,634 - Epoch: [39][  110/  139]    Overall Loss 1.056297    Objective Loss 1.056297                                        LR 0.000500    Time 0.272749    
2024-04-04 19:00:27,293 - Epoch: [39][  120/  139]    Overall Loss 1.055702    Objective Loss 1.055702                                        LR 0.000500    Time 0.272177    
2024-04-04 19:00:29,952 - Epoch: [39][  130/  139]    Overall Loss 1.056408    Objective Loss 1.056408                                        LR 0.000500    Time 0.271695    
2024-04-04 19:00:37,613 - Epoch: [39][  139/  139]    Overall Loss 1.056837    Objective Loss 1.056837    Top1 94.716309    LR 0.000500    Time 0.309212    
2024-04-04 19:00:37,920 - --- validate (epoch=39)-----------
2024-04-04 19:00:37,920 - 1392 samples (32 per mini-batch)
2024-04-04 19:01:11,393 - Epoch: [39][   10/   44]    Loss 1.072765    Top1 89.084228    
2024-04-04 19:01:43,029 - Epoch: [39][   20/   44]    Loss 1.075356    Top1 89.304929    
2024-04-04 19:02:14,750 - Epoch: [39][   30/   44]    Loss 1.075703    Top1 89.361655    
2024-04-04 19:02:47,019 - Epoch: [39][   40/   44]    Loss 1.076621    Top1 89.434473    
2024-04-04 19:02:58,934 - Epoch: [39][   44/   44]    Loss 1.075715    Top1 89.423114    
2024-04-04 19:02:59,142 - ==> Top1: 89.423    Loss: 1.076

2024-04-04 19:02:59,150 - ==> Best [Top1: 91.077   Sparsity:0.00   Params: 272800 on epoch: 29]
2024-04-04 19:02:59,150 - Saving checkpoint to: logs/2024.04.04-165733/checkpoint.pth.tar
2024-04-04 19:02:59,185 - 

2024-04-04 19:02:59,185 - Initiating quantization aware training (QAT)...
2024-04-04 19:02:59,215 - 

2024-04-04 19:02:59,215 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:03:02,554 - Epoch: [40][   10/  139]    Overall Loss 0.971739    Objective Loss 0.971739                                        LR 0.000500    Time 0.333855    
2024-04-04 19:03:05,167 - Epoch: [40][   20/  139]    Overall Loss 0.840046    Objective Loss 0.840046                                        LR 0.000500    Time 0.297514    
2024-04-04 19:03:07,720 - Epoch: [40][   30/  139]    Overall Loss 0.768955    Objective Loss 0.768955                                        LR 0.000500    Time 0.283439    
2024-04-04 19:03:10,336 - Epoch: [40][   40/  139]    Overall Loss 0.729555    Objective Loss 0.729555                                        LR 0.000500    Time 0.277968    
2024-04-04 19:03:12,972 - Epoch: [40][   50/  139]    Overall Loss 0.698317    Objective Loss 0.698317                                        LR 0.000500    Time 0.275083    
2024-04-04 19:03:15,601 - Epoch: [40][   60/  139]    Overall Loss 0.679432    Objective Loss 0.679432                                        LR 0.000500    Time 0.273049    
2024-04-04 19:03:18,204 - Epoch: [40][   70/  139]    Overall Loss 0.663105    Objective Loss 0.663105                                        LR 0.000500    Time 0.271208    
2024-04-04 19:03:20,813 - Epoch: [40][   80/  139]    Overall Loss 0.648337    Objective Loss 0.648337                                        LR 0.000500    Time 0.269924    
2024-04-04 19:03:23,405 - Epoch: [40][   90/  139]    Overall Loss 0.633771    Objective Loss 0.633771                                        LR 0.000500    Time 0.268724    
2024-04-04 19:03:26,015 - Epoch: [40][  100/  139]    Overall Loss 0.620674    Objective Loss 0.620674                                        LR 0.000500    Time 0.267950    
2024-04-04 19:03:28,618 - Epoch: [40][  110/  139]    Overall Loss 0.610785    Objective Loss 0.610785                                        LR 0.000500    Time 0.267250    
2024-04-04 19:03:31,221 - Epoch: [40][  120/  139]    Overall Loss 0.600701    Objective Loss 0.600701                                        LR 0.000500    Time 0.266666    
2024-04-04 19:03:33,837 - Epoch: [40][  130/  139]    Overall Loss 0.592447    Objective Loss 0.592447                                        LR 0.000500    Time 0.266269    
2024-04-04 19:03:40,242 - Epoch: [40][  139/  139]    Overall Loss 0.584679    Objective Loss 0.584679    Top1 92.955452    LR 0.000500    Time 0.295109    
2024-04-04 19:03:40,572 - --- validate (epoch=40)-----------
2024-04-04 19:03:40,573 - 1392 samples (32 per mini-batch)
2024-04-04 19:04:13,288 - Epoch: [40][   10/   44]    Loss 0.524170    Top1 89.186389    
2024-04-04 19:04:45,803 - Epoch: [40][   20/   44]    Loss 0.526487    Top1 89.004624    
2024-04-04 19:05:18,204 - Epoch: [40][   30/   44]    Loss 0.527985    Top1 88.964604    
2024-04-04 19:05:51,021 - Epoch: [40][   40/   44]    Loss 0.533793    Top1 88.599921    
2024-04-04 19:06:02,445 - Epoch: [40][   44/   44]    Loss 0.534346    Top1 88.550675    
2024-04-04 19:06:02,763 - ==> Top1: 88.551    Loss: 0.534

2024-04-04 19:06:02,768 - ==> Best [Top1: 88.551   Sparsity:0.00   Params: 272800 on epoch: 40]
2024-04-04 19:06:02,769 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:06:02,799 - 

2024-04-04 19:06:02,799 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:06:06,071 - Epoch: [41][   10/  139]    Overall Loss 0.482247    Objective Loss 0.482247                                        LR 0.000500    Time 0.327095    
2024-04-04 19:06:08,681 - Epoch: [41][   20/  139]    Overall Loss 0.479958    Objective Loss 0.479958                                        LR 0.000500    Time 0.294022    
2024-04-04 19:06:11,281 - Epoch: [41][   30/  139]    Overall Loss 0.479193    Objective Loss 0.479193                                        LR 0.000500    Time 0.282661    
2024-04-04 19:06:13,896 - Epoch: [41][   40/  139]    Overall Loss 0.475647    Objective Loss 0.475647                                        LR 0.000500    Time 0.277372    
2024-04-04 19:06:16,502 - Epoch: [41][   50/  139]    Overall Loss 0.471538    Objective Loss 0.471538                                        LR 0.000500    Time 0.273993    
2024-04-04 19:06:19,096 - Epoch: [41][   60/  139]    Overall Loss 0.468471    Objective Loss 0.468471                                        LR 0.000500    Time 0.271569    
2024-04-04 19:06:21,692 - Epoch: [41][   70/  139]    Overall Loss 0.468655    Objective Loss 0.468655                                        LR 0.000500    Time 0.269842    
2024-04-04 19:06:24,284 - Epoch: [41][   80/  139]    Overall Loss 0.466959    Objective Loss 0.466959                                        LR 0.000500    Time 0.268507    
2024-04-04 19:06:26,890 - Epoch: [41][   90/  139]    Overall Loss 0.466398    Objective Loss 0.466398                                        LR 0.000500    Time 0.267630    
2024-04-04 19:06:29,483 - Epoch: [41][  100/  139]    Overall Loss 0.465104    Objective Loss 0.465104                                        LR 0.000500    Time 0.266789    
2024-04-04 19:06:32,110 - Epoch: [41][  110/  139]    Overall Loss 0.464034    Objective Loss 0.464034                                        LR 0.000500    Time 0.266412    
2024-04-04 19:06:34,713 - Epoch: [41][  120/  139]    Overall Loss 0.463435    Objective Loss 0.463435                                        LR 0.000500    Time 0.265902    
2024-04-04 19:06:37,308 - Epoch: [41][  130/  139]    Overall Loss 0.461767    Objective Loss 0.461767                                        LR 0.000500    Time 0.265407    
2024-04-04 19:06:43,887 - Epoch: [41][  139/  139]    Overall Loss 0.461058    Objective Loss 0.461058    Top1 92.555160    LR 0.000500    Time 0.295547    
2024-04-04 19:06:44,192 - --- validate (epoch=41)-----------
2024-04-04 19:06:44,193 - 1392 samples (32 per mini-batch)
2024-04-04 19:07:17,818 - Epoch: [41][   10/   44]    Loss 0.507640    Top1 90.204745    
2024-04-04 19:07:50,496 - Epoch: [41][   20/   44]    Loss 0.509255    Top1 90.126561    
2024-04-04 19:08:22,258 - Epoch: [41][   30/   44]    Loss 0.509116    Top1 90.156285    
2024-04-04 19:08:54,379 - Epoch: [41][   40/   44]    Loss 0.511806    Top1 89.997500    
2024-04-04 19:09:05,866 - Epoch: [41][   44/   44]    Loss 0.512468    Top1 89.966997    
2024-04-04 19:09:06,148 - ==> Top1: 89.967    Loss: 0.512

2024-04-04 19:09:06,155 - ==> Best [Top1: 89.967   Sparsity:0.00   Params: 272800 on epoch: 41]
2024-04-04 19:09:06,155 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:09:06,195 - 

2024-04-04 19:09:06,195 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:09:09,486 - Epoch: [42][   10/  139]    Overall Loss 0.453435    Objective Loss 0.453435                                        LR 0.000500    Time 0.328949    
2024-04-04 19:09:12,055 - Epoch: [42][   20/  139]    Overall Loss 0.453659    Objective Loss 0.453659                                        LR 0.000500    Time 0.292906    
2024-04-04 19:09:14,625 - Epoch: [42][   30/  139]    Overall Loss 0.454626    Objective Loss 0.454626                                        LR 0.000500    Time 0.280928    
2024-04-04 19:09:17,240 - Epoch: [42][   40/  139]    Overall Loss 0.453448    Objective Loss 0.453448                                        LR 0.000500    Time 0.276066    
2024-04-04 19:09:19,793 - Epoch: [42][   50/  139]    Overall Loss 0.453758    Objective Loss 0.453758                                        LR 0.000500    Time 0.271889    
2024-04-04 19:09:22,411 - Epoch: [42][   60/  139]    Overall Loss 0.451596    Objective Loss 0.451596                                        LR 0.000500    Time 0.270197    
2024-04-04 19:09:25,022 - Epoch: [42][   70/  139]    Overall Loss 0.451424    Objective Loss 0.451424                                        LR 0.000500    Time 0.268895    
2024-04-04 19:09:27,624 - Epoch: [42][   80/  139]    Overall Loss 0.449536    Objective Loss 0.449536                                        LR 0.000500    Time 0.267805    
2024-04-04 19:09:30,257 - Epoch: [42][   90/  139]    Overall Loss 0.447958    Objective Loss 0.447958                                        LR 0.000500    Time 0.267297    
2024-04-04 19:09:32,900 - Epoch: [42][  100/  139]    Overall Loss 0.447286    Objective Loss 0.447286                                        LR 0.000500    Time 0.266990    
2024-04-04 19:09:35,528 - Epoch: [42][  110/  139]    Overall Loss 0.446526    Objective Loss 0.446526                                        LR 0.000500    Time 0.266605    
2024-04-04 19:09:38,139 - Epoch: [42][  120/  139]    Overall Loss 0.444839    Objective Loss 0.444839                                        LR 0.000500    Time 0.266140    
2024-04-04 19:09:40,787 - Epoch: [42][  130/  139]    Overall Loss 0.445401    Objective Loss 0.445401                                        LR 0.000500    Time 0.266032    
2024-04-04 19:09:48,142 - Epoch: [42][  139/  139]    Overall Loss 0.445591    Objective Loss 0.445591    Top1 95.402471    LR 0.000500    Time 0.301719    
2024-04-04 19:09:48,426 - --- validate (epoch=42)-----------
2024-04-04 19:09:48,426 - 1392 samples (32 per mini-batch)
2024-04-04 19:10:21,625 - Epoch: [42][   10/   44]    Loss 0.510909    Top1 89.782165    
2024-04-04 19:10:53,906 - Epoch: [42][   20/   44]    Loss 0.513192    Top1 89.665222    
2024-04-04 19:11:25,862 - Epoch: [42][   30/   44]    Loss 0.508315    Top1 89.957718    
2024-04-04 19:11:58,664 - Epoch: [42][   40/   44]    Loss 0.508946    Top1 89.912543    
2024-04-04 19:12:09,956 - Epoch: [42][   44/   44]    Loss 0.508625    Top1 89.955725    
2024-04-04 19:12:10,323 - ==> Top1: 89.956    Loss: 0.509

2024-04-04 19:12:10,330 - ==> Best [Top1: 89.967   Sparsity:0.00   Params: 272800 on epoch: 41]
2024-04-04 19:12:10,330 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:12:10,366 - 

2024-04-04 19:12:10,366 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:12:13,693 - Epoch: [43][   10/  139]    Overall Loss 0.436734    Objective Loss 0.436734                                        LR 0.000500    Time 0.332606    
2024-04-04 19:12:16,321 - Epoch: [43][   20/  139]    Overall Loss 0.439228    Objective Loss 0.439228                                        LR 0.000500    Time 0.297661    
2024-04-04 19:12:18,919 - Epoch: [43][   30/  139]    Overall Loss 0.439814    Objective Loss 0.439814                                        LR 0.000500    Time 0.285013    
2024-04-04 19:12:21,492 - Epoch: [43][   40/  139]    Overall Loss 0.438672    Objective Loss 0.438672                                        LR 0.000500    Time 0.278060    
2024-04-04 19:12:24,110 - Epoch: [43][   50/  139]    Overall Loss 0.437859    Objective Loss 0.437859                                        LR 0.000500    Time 0.274802    
2024-04-04 19:12:26,716 - Epoch: [43][   60/  139]    Overall Loss 0.437473    Objective Loss 0.437473                                        LR 0.000500    Time 0.272437    
2024-04-04 19:12:29,318 - Epoch: [43][   70/  139]    Overall Loss 0.436477    Objective Loss 0.436477                                        LR 0.000500    Time 0.270682    
2024-04-04 19:12:31,916 - Epoch: [43][   80/  139]    Overall Loss 0.439514    Objective Loss 0.439514                                        LR 0.000500    Time 0.269312    
2024-04-04 19:12:34,502 - Epoch: [43][   90/  139]    Overall Loss 0.440404    Objective Loss 0.440404                                        LR 0.000500    Time 0.268116    
2024-04-04 19:12:37,104 - Epoch: [43][  100/  139]    Overall Loss 0.441064    Objective Loss 0.441064                                        LR 0.000500    Time 0.267324    
2024-04-04 19:12:39,687 - Epoch: [43][  110/  139]    Overall Loss 0.441220    Objective Loss 0.441220                                        LR 0.000500    Time 0.266494    
2024-04-04 19:12:42,291 - Epoch: [43][  120/  139]    Overall Loss 0.440531    Objective Loss 0.440531                                        LR 0.000500    Time 0.265980    
2024-04-04 19:12:44,887 - Epoch: [43][  130/  139]    Overall Loss 0.440367    Objective Loss 0.440367                                        LR 0.000500    Time 0.265491    
2024-04-04 19:12:51,297 - Epoch: [43][  139/  139]    Overall Loss 0.439713    Objective Loss 0.439713    Top1 94.058743    LR 0.000500    Time 0.294412    
2024-04-04 19:12:51,651 - --- validate (epoch=43)-----------
2024-04-04 19:12:51,652 - 1392 samples (32 per mini-batch)
2024-04-04 19:13:24,185 - Epoch: [43][   10/   44]    Loss 0.534581    Top1 88.714095    
2024-04-04 19:13:56,426 - Epoch: [43][   20/   44]    Loss 0.533851    Top1 88.740533    
2024-04-04 19:14:28,602 - Epoch: [43][   30/   44]    Loss 0.534948    Top1 88.692123    
2024-04-04 19:15:00,543 - Epoch: [43][   40/   44]    Loss 0.536793    Top1 88.583309    
2024-04-04 19:15:12,031 - Epoch: [43][   44/   44]    Loss 0.534540    Top1 88.680782    
2024-04-04 19:15:12,332 - ==> Top1: 88.681    Loss: 0.535

2024-04-04 19:15:12,338 - ==> Best [Top1: 89.967   Sparsity:0.00   Params: 272800 on epoch: 41]
2024-04-04 19:15:12,339 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:15:12,375 - 

2024-04-04 19:15:12,375 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:15:15,738 - Epoch: [44][   10/  139]    Overall Loss 0.438416    Objective Loss 0.438416                                        LR 0.000500    Time 0.336162    
2024-04-04 19:15:18,358 - Epoch: [44][   20/  139]    Overall Loss 0.430856    Objective Loss 0.430856                                        LR 0.000500    Time 0.299033    
2024-04-04 19:15:20,997 - Epoch: [44][   30/  139]    Overall Loss 0.431718    Objective Loss 0.431718                                        LR 0.000500    Time 0.287331    
2024-04-04 19:15:23,578 - Epoch: [44][   40/  139]    Overall Loss 0.431908    Objective Loss 0.431908                                        LR 0.000500    Time 0.279996    
2024-04-04 19:15:26,150 - Epoch: [44][   50/  139]    Overall Loss 0.431443    Objective Loss 0.431443                                        LR 0.000500    Time 0.275424    
2024-04-04 19:15:28,724 - Epoch: [44][   60/  139]    Overall Loss 0.430683    Objective Loss 0.430683                                        LR 0.000500    Time 0.272411    
2024-04-04 19:15:31,312 - Epoch: [44][   70/  139]    Overall Loss 0.430207    Objective Loss 0.430207                                        LR 0.000500    Time 0.270457    
2024-04-04 19:15:33,923 - Epoch: [44][   80/  139]    Overall Loss 0.431121    Objective Loss 0.431121                                        LR 0.000500    Time 0.269284    
2024-04-04 19:15:36,553 - Epoch: [44][   90/  139]    Overall Loss 0.431006    Objective Loss 0.431006                                        LR 0.000500    Time 0.268577    
2024-04-04 19:15:39,157 - Epoch: [44][  100/  139]    Overall Loss 0.431280    Objective Loss 0.431280                                        LR 0.000500    Time 0.267758    
2024-04-04 19:15:41,776 - Epoch: [44][  110/  139]    Overall Loss 0.431433    Objective Loss 0.431433                                        LR 0.000500    Time 0.267225    
2024-04-04 19:15:44,421 - Epoch: [44][  120/  139]    Overall Loss 0.432321    Objective Loss 0.432321                                        LR 0.000500    Time 0.266989    
2024-04-04 19:15:47,037 - Epoch: [44][  130/  139]    Overall Loss 0.433316    Objective Loss 0.433316                                        LR 0.000500    Time 0.266568    
2024-04-04 19:15:54,685 - Epoch: [44][  139/  139]    Overall Loss 0.434054    Objective Loss 0.434054    Top1 92.992540    LR 0.000500    Time 0.304327    
2024-04-04 19:15:54,991 - --- validate (epoch=44)-----------
2024-04-04 19:15:54,992 - 1392 samples (32 per mini-batch)
2024-04-04 19:16:29,195 - Epoch: [44][   10/   44]    Loss 0.509902    Top1 90.081820    
2024-04-04 19:17:01,102 - Epoch: [44][   20/   44]    Loss 0.512724    Top1 89.948993    
2024-04-04 19:17:33,016 - Epoch: [44][   30/   44]    Loss 0.510878    Top1 90.038899    
2024-04-04 19:18:04,708 - Epoch: [44][   40/   44]    Loss 0.511464    Top1 89.998337    
2024-04-04 19:18:16,227 - Epoch: [44][   44/   44]    Loss 0.510097    Top1 90.028707    
2024-04-04 19:18:16,528 - ==> Top1: 90.029    Loss: 0.510

2024-04-04 19:18:16,535 - ==> Best [Top1: 90.029   Sparsity:0.00   Params: 272800 on epoch: 44]
2024-04-04 19:18:16,536 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:18:16,576 - 

2024-04-04 19:18:16,576 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:18:19,988 - Epoch: [45][   10/  139]    Overall Loss 0.431036    Objective Loss 0.431036                                        LR 0.000500    Time 0.341150    
2024-04-04 19:18:22,563 - Epoch: [45][   20/  139]    Overall Loss 0.439485    Objective Loss 0.439485                                        LR 0.000500    Time 0.299284    
2024-04-04 19:18:25,194 - Epoch: [45][   30/  139]    Overall Loss 0.438957    Objective Loss 0.438957                                        LR 0.000500    Time 0.287195    
2024-04-04 19:18:27,818 - Epoch: [45][   40/  139]    Overall Loss 0.437878    Objective Loss 0.437878                                        LR 0.000500    Time 0.280993    
2024-04-04 19:18:30,413 - Epoch: [45][   50/  139]    Overall Loss 0.435260    Objective Loss 0.435260                                        LR 0.000500    Time 0.276680    
2024-04-04 19:18:33,009 - Epoch: [45][   60/  139]    Overall Loss 0.435431    Objective Loss 0.435431                                        LR 0.000500    Time 0.273816    
2024-04-04 19:18:35,575 - Epoch: [45][   70/  139]    Overall Loss 0.436063    Objective Loss 0.436063                                        LR 0.000500    Time 0.271352    
2024-04-04 19:18:38,137 - Epoch: [45][   80/  139]    Overall Loss 0.435998    Objective Loss 0.435998                                        LR 0.000500    Time 0.269454    
2024-04-04 19:18:40,677 - Epoch: [45][   90/  139]    Overall Loss 0.435105    Objective Loss 0.435105                                        LR 0.000500    Time 0.267738    
2024-04-04 19:18:43,268 - Epoch: [45][  100/  139]    Overall Loss 0.434381    Objective Loss 0.434381                                        LR 0.000500    Time 0.266864    
2024-04-04 19:18:45,827 - Epoch: [45][  110/  139]    Overall Loss 0.433108    Objective Loss 0.433108                                        LR 0.000500    Time 0.265866    
2024-04-04 19:18:48,406 - Epoch: [45][  120/  139]    Overall Loss 0.432426    Objective Loss 0.432426                                        LR 0.000500    Time 0.265193    
2024-04-04 19:18:50,955 - Epoch: [45][  130/  139]    Overall Loss 0.431319    Objective Loss 0.431319                                        LR 0.000500    Time 0.264400    
2024-04-04 19:18:57,774 - Epoch: [45][  139/  139]    Overall Loss 0.431225    Objective Loss 0.431225    Top1 94.215812    LR 0.000500    Time 0.296337    
2024-04-04 19:18:58,018 - --- validate (epoch=45)-----------
2024-04-04 19:18:58,019 - 1392 samples (32 per mini-batch)
2024-04-04 19:19:31,118 - Epoch: [45][   10/   44]    Loss 0.514060    Top1 89.783560    
2024-04-04 19:20:03,230 - Epoch: [45][   20/   44]    Loss 0.506647    Top1 90.209794    
2024-04-04 19:20:35,477 - Epoch: [45][   30/   44]    Loss 0.509333    Top1 90.026478    
2024-04-04 19:21:07,951 - Epoch: [45][   40/   44]    Loss 0.505764    Top1 90.246643    
2024-04-04 19:21:19,939 - Epoch: [45][   44/   44]    Loss 0.505272    Top1 90.277005    
2024-04-04 19:21:20,209 - ==> Top1: 90.277    Loss: 0.505

2024-04-04 19:21:20,216 - ==> Best [Top1: 90.277   Sparsity:0.00   Params: 272800 on epoch: 45]
2024-04-04 19:21:20,216 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:21:20,254 - 

2024-04-04 19:21:20,254 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:21:23,644 - Epoch: [46][   10/  139]    Overall Loss 0.424042    Objective Loss 0.424042                                        LR 0.000500    Time 0.338865    
2024-04-04 19:21:26,206 - Epoch: [46][   20/  139]    Overall Loss 0.424481    Objective Loss 0.424481                                        LR 0.000500    Time 0.297480    
2024-04-04 19:21:28,822 - Epoch: [46][   30/  139]    Overall Loss 0.425949    Objective Loss 0.425949                                        LR 0.000500    Time 0.285512    
2024-04-04 19:21:31,431 - Epoch: [46][   40/  139]    Overall Loss 0.425370    Objective Loss 0.425370                                        LR 0.000500    Time 0.279351    
2024-04-04 19:21:34,029 - Epoch: [46][   50/  139]    Overall Loss 0.425862    Objective Loss 0.425862                                        LR 0.000500    Time 0.275428    
2024-04-04 19:21:36,651 - Epoch: [46][   60/  139]    Overall Loss 0.424719    Objective Loss 0.424719                                        LR 0.000500    Time 0.273216    
2024-04-04 19:21:39,228 - Epoch: [46][   70/  139]    Overall Loss 0.425607    Objective Loss 0.425607                                        LR 0.000500    Time 0.270996    
2024-04-04 19:21:41,849 - Epoch: [46][   80/  139]    Overall Loss 0.425562    Objective Loss 0.425562                                        LR 0.000500    Time 0.269867    
2024-04-04 19:21:44,481 - Epoch: [46][   90/  139]    Overall Loss 0.425203    Objective Loss 0.425203                                        LR 0.000500    Time 0.269123    
2024-04-04 19:21:47,105 - Epoch: [46][  100/  139]    Overall Loss 0.425861    Objective Loss 0.425861                                        LR 0.000500    Time 0.268445    
2024-04-04 19:21:49,739 - Epoch: [46][  110/  139]    Overall Loss 0.425039    Objective Loss 0.425039                                        LR 0.000500    Time 0.267980    
2024-04-04 19:21:52,355 - Epoch: [46][  120/  139]    Overall Loss 0.426027    Objective Loss 0.426027                                        LR 0.000500    Time 0.267444    
2024-04-04 19:21:54,989 - Epoch: [46][  130/  139]    Overall Loss 0.425861    Objective Loss 0.425861                                        LR 0.000500    Time 0.267125    
2024-04-04 19:22:02,229 - Epoch: [46][  139/  139]    Overall Loss 0.426239    Objective Loss 0.426239    Top1 94.858575    LR 0.000500    Time 0.301919    
2024-04-04 19:22:02,503 - --- validate (epoch=46)-----------
2024-04-04 19:22:02,504 - 1392 samples (32 per mini-batch)
2024-04-04 19:22:35,187 - Epoch: [46][   10/   44]    Loss 0.502704    Top1 90.473842    
2024-04-04 19:23:08,187 - Epoch: [46][   20/   44]    Loss 0.495341    Top1 90.925400    
2024-04-04 19:23:39,924 - Epoch: [46][   30/   44]    Loss 0.495419    Top1 90.917252    
2024-04-04 19:24:11,481 - Epoch: [46][   40/   44]    Loss 0.496563    Top1 90.842562    
2024-04-04 19:24:23,272 - Epoch: [46][   44/   44]    Loss 0.497151    Top1 90.810862    
2024-04-04 19:24:23,516 - ==> Top1: 90.811    Loss: 0.497

2024-04-04 19:24:23,523 - ==> Best [Top1: 90.811   Sparsity:0.00   Params: 272800 on epoch: 46]
2024-04-04 19:24:23,523 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:24:23,561 - 

2024-04-04 19:24:23,562 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:24:26,958 - Epoch: [47][   10/  139]    Overall Loss 0.426117    Objective Loss 0.426117                                        LR 0.000500    Time 0.339507    
2024-04-04 19:24:29,560 - Epoch: [47][   20/  139]    Overall Loss 0.425554    Objective Loss 0.425554                                        LR 0.000500    Time 0.299845    
2024-04-04 19:24:32,119 - Epoch: [47][   30/  139]    Overall Loss 0.423701    Objective Loss 0.423701                                        LR 0.000500    Time 0.285159    
2024-04-04 19:24:34,708 - Epoch: [47][   40/  139]    Overall Loss 0.425363    Objective Loss 0.425363                                        LR 0.000500    Time 0.278592    
2024-04-04 19:24:37,303 - Epoch: [47][   50/  139]    Overall Loss 0.425113    Objective Loss 0.425113                                        LR 0.000500    Time 0.274766    
2024-04-04 19:24:39,877 - Epoch: [47][   60/  139]    Overall Loss 0.425596    Objective Loss 0.425596                                        LR 0.000500    Time 0.271858    
2024-04-04 19:24:42,447 - Epoch: [47][   70/  139]    Overall Loss 0.424590    Objective Loss 0.424590                                        LR 0.000500    Time 0.269728    
2024-04-04 19:24:45,023 - Epoch: [47][   80/  139]    Overall Loss 0.424734    Objective Loss 0.424734                                        LR 0.000500    Time 0.268203    
2024-04-04 19:24:47,644 - Epoch: [47][   90/  139]    Overall Loss 0.424766    Objective Loss 0.424766                                        LR 0.000500    Time 0.267528    
2024-04-04 19:24:50,263 - Epoch: [47][  100/  139]    Overall Loss 0.424979    Objective Loss 0.424979                                        LR 0.000500    Time 0.266957    
2024-04-04 19:24:52,902 - Epoch: [47][  110/  139]    Overall Loss 0.425623    Objective Loss 0.425623                                        LR 0.000500    Time 0.266675    
2024-04-04 19:24:55,540 - Epoch: [47][  120/  139]    Overall Loss 0.426646    Objective Loss 0.426646                                        LR 0.000500    Time 0.266435    
2024-04-04 19:24:58,163 - Epoch: [47][  130/  139]    Overall Loss 0.427419    Objective Loss 0.427419                                        LR 0.000500    Time 0.266109    
2024-04-04 19:25:05,716 - Epoch: [47][  139/  139]    Overall Loss 0.427141    Objective Loss 0.427141    Top1 94.651321    LR 0.000500    Time 0.303212    
2024-04-04 19:25:06,023 - --- validate (epoch=47)-----------
2024-04-04 19:25:06,024 - 1392 samples (32 per mini-batch)
2024-04-04 19:25:39,129 - Epoch: [47][   10/   44]    Loss 0.541732    Top1 88.489549    
2024-04-04 19:26:11,389 - Epoch: [47][   20/   44]    Loss 0.537079    Top1 88.778287    
2024-04-04 19:26:43,326 - Epoch: [47][   30/   44]    Loss 0.532198    Top1 89.012012    
2024-04-04 19:27:15,963 - Epoch: [47][   40/   44]    Loss 0.531584    Top1 89.073772    
2024-04-04 19:27:27,195 - Epoch: [47][   44/   44]    Loss 0.530588    Top1 89.159634    
2024-04-04 19:27:27,449 - ==> Top1: 89.160    Loss: 0.531

2024-04-04 19:27:27,456 - ==> Best [Top1: 90.811   Sparsity:0.00   Params: 272800 on epoch: 46]
2024-04-04 19:27:27,456 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:27:27,490 - 

2024-04-04 19:27:27,490 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:27:30,761 - Epoch: [48][   10/  139]    Overall Loss 0.432937    Objective Loss 0.432937                                        LR 0.000500    Time 0.326944    
2024-04-04 19:27:33,332 - Epoch: [48][   20/  139]    Overall Loss 0.426424    Objective Loss 0.426424                                        LR 0.000500    Time 0.291968    
2024-04-04 19:27:35,912 - Epoch: [48][   30/  139]    Overall Loss 0.425550    Objective Loss 0.425550                                        LR 0.000500    Time 0.280634    
2024-04-04 19:27:38,485 - Epoch: [48][   40/  139]    Overall Loss 0.424243    Objective Loss 0.424243                                        LR 0.000500    Time 0.274798    
2024-04-04 19:27:41,072 - Epoch: [48][   50/  139]    Overall Loss 0.423925    Objective Loss 0.423925                                        LR 0.000500    Time 0.271567    
2024-04-04 19:27:43,645 - Epoch: [48][   60/  139]    Overall Loss 0.423748    Objective Loss 0.423748                                        LR 0.000500    Time 0.269177    
2024-04-04 19:27:46,250 - Epoch: [48][   70/  139]    Overall Loss 0.423907    Objective Loss 0.423907                                        LR 0.000500    Time 0.267930    
2024-04-04 19:27:48,848 - Epoch: [48][   80/  139]    Overall Loss 0.424989    Objective Loss 0.424989                                        LR 0.000500    Time 0.266910    
2024-04-04 19:27:51,430 - Epoch: [48][   90/  139]    Overall Loss 0.425824    Objective Loss 0.425824                                        LR 0.000500    Time 0.265934    
2024-04-04 19:27:54,055 - Epoch: [48][  100/  139]    Overall Loss 0.425784    Objective Loss 0.425784                                        LR 0.000500    Time 0.265593    
2024-04-04 19:27:56,645 - Epoch: [48][  110/  139]    Overall Loss 0.426277    Objective Loss 0.426277                                        LR 0.000500    Time 0.264982    
2024-04-04 19:27:59,240 - Epoch: [48][  120/  139]    Overall Loss 0.427162    Objective Loss 0.427162                                        LR 0.000500    Time 0.264525    
2024-04-04 19:28:01,852 - Epoch: [48][  130/  139]    Overall Loss 0.427810    Objective Loss 0.427810                                        LR 0.000500    Time 0.264265    
2024-04-04 19:28:09,277 - Epoch: [48][  139/  139]    Overall Loss 0.427383    Objective Loss 0.427383    Top1 95.893723    LR 0.000500    Time 0.300567    
2024-04-04 19:28:09,613 - --- validate (epoch=48)-----------
2024-04-04 19:28:09,614 - 1392 samples (32 per mini-batch)
2024-04-04 19:28:42,174 - Epoch: [48][   10/   44]    Loss 0.497017    Top1 90.728497    
2024-04-04 19:29:13,992 - Epoch: [48][   20/   44]    Loss 0.499318    Top1 90.608466    
2024-04-04 19:29:46,900 - Epoch: [48][   30/   44]    Loss 0.497463    Top1 90.740430    
2024-04-04 19:30:18,869 - Epoch: [48][   40/   44]    Loss 0.493794    Top1 90.948442    
2024-04-04 19:30:30,670 - Epoch: [48][   44/   44]    Loss 0.494176    Top1 90.911080    
2024-04-04 19:30:30,907 - ==> Top1: 90.911    Loss: 0.494

2024-04-04 19:30:30,913 - ==> Best [Top1: 90.911   Sparsity:0.00   Params: 272800 on epoch: 48]
2024-04-04 19:30:30,914 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:30:30,952 - 

2024-04-04 19:30:30,952 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:30:34,249 - Epoch: [49][   10/  139]    Overall Loss 0.420253    Objective Loss 0.420253                                        LR 0.000500    Time 0.329513    
2024-04-04 19:30:36,801 - Epoch: [49][   20/  139]    Overall Loss 0.424400    Objective Loss 0.424400                                        LR 0.000500    Time 0.292357    
2024-04-04 19:30:39,353 - Epoch: [49][   30/  139]    Overall Loss 0.426118    Objective Loss 0.426118                                        LR 0.000500    Time 0.279959    
2024-04-04 19:30:41,917 - Epoch: [49][   40/  139]    Overall Loss 0.424428    Objective Loss 0.424428                                        LR 0.000500    Time 0.274057    
2024-04-04 19:30:44,520 - Epoch: [49][   50/  139]    Overall Loss 0.424355    Objective Loss 0.424355                                        LR 0.000500    Time 0.271291    
2024-04-04 19:30:47,104 - Epoch: [49][   60/  139]    Overall Loss 0.423638    Objective Loss 0.423638                                        LR 0.000500    Time 0.269128    
2024-04-04 19:30:49,677 - Epoch: [49][   70/  139]    Overall Loss 0.424119    Objective Loss 0.424119                                        LR 0.000500    Time 0.267435    
2024-04-04 19:30:52,234 - Epoch: [49][   80/  139]    Overall Loss 0.424180    Objective Loss 0.424180                                        LR 0.000500    Time 0.265957    
2024-04-04 19:30:54,860 - Epoch: [49][   90/  139]    Overall Loss 0.424455    Objective Loss 0.424455                                        LR 0.000500    Time 0.265587    
2024-04-04 19:30:57,487 - Epoch: [49][  100/  139]    Overall Loss 0.423443    Objective Loss 0.423443                                        LR 0.000500    Time 0.265288    
2024-04-04 19:31:00,129 - Epoch: [49][  110/  139]    Overall Loss 0.423108    Objective Loss 0.423108                                        LR 0.000500    Time 0.265183    
2024-04-04 19:31:02,760 - Epoch: [49][  120/  139]    Overall Loss 0.423681    Objective Loss 0.423681                                        LR 0.000500    Time 0.265004    
2024-04-04 19:31:05,389 - Epoch: [49][  130/  139]    Overall Loss 0.424214    Objective Loss 0.424214                                        LR 0.000500    Time 0.264840    
2024-04-04 19:31:13,143 - Epoch: [49][  139/  139]    Overall Loss 0.424645    Objective Loss 0.424645    Top1 92.923224    LR 0.000500    Time 0.303476    
2024-04-04 19:31:13,436 - --- validate (epoch=49)-----------
2024-04-04 19:31:13,438 - 1392 samples (32 per mini-batch)
2024-04-04 19:31:46,142 - Epoch: [49][   10/   44]    Loss 0.475318    Top1 92.076794    
2024-04-04 19:32:18,688 - Epoch: [49][   20/   44]    Loss 0.484860    Top1 91.522175    
2024-04-04 19:32:50,814 - Epoch: [49][   30/   44]    Loss 0.489527    Top1 91.237662    
2024-04-04 19:33:23,275 - Epoch: [49][   40/   44]    Loss 0.493794    Top1 90.992027    
2024-04-04 19:33:34,165 - Epoch: [49][   44/   44]    Loss 0.493935    Top1 91.002667    
2024-04-04 19:33:34,540 - ==> Top1: 91.003    Loss: 0.494

2024-04-04 19:33:34,547 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 19:33:34,547 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:33:34,586 - 

2024-04-04 19:33:34,587 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:33:38,022 - Epoch: [50][   10/  139]    Overall Loss 0.425831    Objective Loss 0.425831                                        LR 0.000500    Time 0.343416    
2024-04-04 19:33:40,591 - Epoch: [50][   20/  139]    Overall Loss 0.425310    Objective Loss 0.425310                                        LR 0.000500    Time 0.300123    
2024-04-04 19:33:43,182 - Epoch: [50][   30/  139]    Overall Loss 0.424021    Objective Loss 0.424021                                        LR 0.000500    Time 0.286453    
2024-04-04 19:33:45,781 - Epoch: [50][   40/  139]    Overall Loss 0.422758    Objective Loss 0.422758                                        LR 0.000500    Time 0.279790    
2024-04-04 19:33:48,396 - Epoch: [50][   50/  139]    Overall Loss 0.420996    Objective Loss 0.420996                                        LR 0.000500    Time 0.276110    
2024-04-04 19:33:51,011 - Epoch: [50][   60/  139]    Overall Loss 0.421465    Objective Loss 0.421465                                        LR 0.000500    Time 0.273673    
2024-04-04 19:33:53,597 - Epoch: [50][   70/  139]    Overall Loss 0.420666    Objective Loss 0.420666                                        LR 0.000500    Time 0.271511    
2024-04-04 19:33:56,220 - Epoch: [50][   80/  139]    Overall Loss 0.420673    Objective Loss 0.420673                                        LR 0.000500    Time 0.270350    
2024-04-04 19:33:58,830 - Epoch: [50][   90/  139]    Overall Loss 0.420363    Objective Loss 0.420363                                        LR 0.000500    Time 0.269306    
2024-04-04 19:34:01,473 - Epoch: [50][  100/  139]    Overall Loss 0.420244    Objective Loss 0.420244                                        LR 0.000500    Time 0.268798    
2024-04-04 19:34:04,095 - Epoch: [50][  110/  139]    Overall Loss 0.420627    Objective Loss 0.420627                                        LR 0.000500    Time 0.268193    
2024-04-04 19:34:06,746 - Epoch: [50][  120/  139]    Overall Loss 0.421091    Objective Loss 0.421091                                        LR 0.000500    Time 0.267930    
2024-04-04 19:34:09,361 - Epoch: [50][  130/  139]    Overall Loss 0.422058    Objective Loss 0.422058                                        LR 0.000500    Time 0.267430    
2024-04-04 19:34:16,528 - Epoch: [50][  139/  139]    Overall Loss 0.421565    Objective Loss 0.421565    Top1 96.085771    LR 0.000500    Time 0.301669    
2024-04-04 19:34:16,856 - --- validate (epoch=50)-----------
2024-04-04 19:34:16,857 - 1392 samples (32 per mini-batch)
2024-04-04 19:34:49,423 - Epoch: [50][   10/   44]    Loss 0.496859    Top1 90.796625    
2024-04-04 19:35:21,728 - Epoch: [50][   20/   44]    Loss 0.494979    Top1 90.866020    
2024-04-04 19:35:53,441 - Epoch: [50][   30/   44]    Loss 0.496725    Top1 90.747928    
2024-04-04 19:36:24,993 - Epoch: [50][   40/   44]    Loss 0.494667    Top1 90.863951    
2024-04-04 19:36:35,990 - Epoch: [50][   44/   44]    Loss 0.495392    Top1 90.822012    
2024-04-04 19:36:36,310 - ==> Top1: 90.822    Loss: 0.495

2024-04-04 19:36:36,317 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 19:36:36,317 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:36:36,353 - 

2024-04-04 19:36:36,353 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:36:39,684 - Epoch: [51][   10/  139]    Overall Loss 0.415809    Objective Loss 0.415809                                        LR 0.000500    Time 0.333015    
2024-04-04 19:36:42,285 - Epoch: [51][   20/  139]    Overall Loss 0.414450    Objective Loss 0.414450                                        LR 0.000500    Time 0.296521    
2024-04-04 19:36:44,884 - Epoch: [51][   30/  139]    Overall Loss 0.414116    Objective Loss 0.414116                                        LR 0.000500    Time 0.284280    
2024-04-04 19:36:47,451 - Epoch: [51][   40/  139]    Overall Loss 0.414408    Objective Loss 0.414408                                        LR 0.000500    Time 0.277365    
2024-04-04 19:36:50,059 - Epoch: [51][   50/  139]    Overall Loss 0.416027    Objective Loss 0.416027                                        LR 0.000500    Time 0.274051    
2024-04-04 19:36:52,675 - Epoch: [51][   60/  139]    Overall Loss 0.416833    Objective Loss 0.416833                                        LR 0.000500    Time 0.271970    
2024-04-04 19:36:55,301 - Epoch: [51][   70/  139]    Overall Loss 0.417859    Objective Loss 0.417859                                        LR 0.000500    Time 0.270616    
2024-04-04 19:36:57,932 - Epoch: [51][   80/  139]    Overall Loss 0.417535    Objective Loss 0.417535                                        LR 0.000500    Time 0.269681    
2024-04-04 19:37:00,562 - Epoch: [51][   90/  139]    Overall Loss 0.417851    Objective Loss 0.417851                                        LR 0.000500    Time 0.268933    
2024-04-04 19:37:03,157 - Epoch: [51][  100/  139]    Overall Loss 0.417882    Objective Loss 0.417882                                        LR 0.000500    Time 0.267985    
2024-04-04 19:37:05,782 - Epoch: [51][  110/  139]    Overall Loss 0.418984    Objective Loss 0.418984                                        LR 0.000500    Time 0.267475    
2024-04-04 19:37:08,428 - Epoch: [51][  120/  139]    Overall Loss 0.421211    Objective Loss 0.421211                                        LR 0.000500    Time 0.267238    
2024-04-04 19:37:11,053 - Epoch: [51][  130/  139]    Overall Loss 0.422107    Objective Loss 0.422107                                        LR 0.000500    Time 0.266862    
2024-04-04 19:37:18,663 - Epoch: [51][  139/  139]    Overall Loss 0.423217    Objective Loss 0.423217    Top1 94.901606    LR 0.000500    Time 0.304330    
2024-04-04 19:37:18,964 - --- validate (epoch=51)-----------
2024-04-04 19:37:18,965 - 1392 samples (32 per mini-batch)
2024-04-04 19:37:51,054 - Epoch: [51][   10/   44]    Loss 0.501591    Top1 90.571357    
2024-04-04 19:38:22,682 - Epoch: [51][   20/   44]    Loss 0.500973    Top1 90.563872    
2024-04-04 19:38:54,341 - Epoch: [51][   30/   44]    Loss 0.503163    Top1 90.456704    
2024-04-04 19:39:25,370 - Epoch: [51][   40/   44]    Loss 0.502000    Top1 90.496565    
2024-04-04 19:39:36,484 - Epoch: [51][   44/   44]    Loss 0.504703    Top1 90.370633    
2024-04-04 19:39:36,808 - ==> Top1: 90.371    Loss: 0.505

2024-04-04 19:39:36,815 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 19:39:36,816 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:39:36,850 - 

2024-04-04 19:39:36,850 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:39:40,211 - Epoch: [52][   10/  139]    Overall Loss 0.426162    Objective Loss 0.426162                                        LR 0.000500    Time 0.336005    
2024-04-04 19:39:42,801 - Epoch: [52][   20/  139]    Overall Loss 0.428648    Objective Loss 0.428648                                        LR 0.000500    Time 0.297450    
2024-04-04 19:39:45,408 - Epoch: [52][   30/  139]    Overall Loss 0.426730    Objective Loss 0.426730                                        LR 0.000500    Time 0.285190    
2024-04-04 19:39:48,026 - Epoch: [52][   40/  139]    Overall Loss 0.426930    Objective Loss 0.426930                                        LR 0.000500    Time 0.279321    
2024-04-04 19:39:50,623 - Epoch: [52][   50/  139]    Overall Loss 0.427100    Objective Loss 0.427100                                        LR 0.000500    Time 0.275396    
2024-04-04 19:39:53,229 - Epoch: [52][   60/  139]    Overall Loss 0.425734    Objective Loss 0.425734                                        LR 0.000500    Time 0.272920    
2024-04-04 19:39:55,817 - Epoch: [52][   70/  139]    Overall Loss 0.426177    Objective Loss 0.426177                                        LR 0.000500    Time 0.270899    
2024-04-04 19:39:58,429 - Epoch: [52][   80/  139]    Overall Loss 0.425812    Objective Loss 0.425812                                        LR 0.000500    Time 0.269684    
2024-04-04 19:40:01,020 - Epoch: [52][   90/  139]    Overall Loss 0.424672    Objective Loss 0.424672                                        LR 0.000500    Time 0.268493    
2024-04-04 19:40:03,582 - Epoch: [52][  100/  139]    Overall Loss 0.424833    Objective Loss 0.424833                                        LR 0.000500    Time 0.267266    
2024-04-04 19:40:06,208 - Epoch: [52][  110/  139]    Overall Loss 0.424540    Objective Loss 0.424540                                        LR 0.000500    Time 0.266831    
2024-04-04 19:40:08,821 - Epoch: [52][  120/  139]    Overall Loss 0.423920    Objective Loss 0.423920                                        LR 0.000500    Time 0.266371    
2024-04-04 19:40:11,429 - Epoch: [52][  130/  139]    Overall Loss 0.423001    Objective Loss 0.423001                                        LR 0.000500    Time 0.265940    
2024-04-04 19:40:17,924 - Epoch: [52][  139/  139]    Overall Loss 0.423092    Objective Loss 0.423092    Top1 95.346562    LR 0.000500    Time 0.295444    
2024-04-04 19:40:18,221 - --- validate (epoch=52)-----------
2024-04-04 19:40:18,221 - 1392 samples (32 per mini-batch)
2024-04-04 19:40:51,898 - Epoch: [52][   10/   44]    Loss 0.499626    Top1 90.677258    
2024-04-04 19:41:24,177 - Epoch: [52][   20/   44]    Loss 0.500392    Top1 90.662867    
2024-04-04 19:41:56,910 - Epoch: [52][   30/   44]    Loss 0.500427    Top1 90.643108    
2024-04-04 19:42:28,047 - Epoch: [52][   40/   44]    Loss 0.501529    Top1 90.571164    
2024-04-04 19:42:39,385 - Epoch: [52][   44/   44]    Loss 0.499300    Top1 90.683837    
2024-04-04 19:42:39,691 - ==> Top1: 90.684    Loss: 0.499

2024-04-04 19:42:39,697 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 19:42:39,698 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:42:39,732 - 

2024-04-04 19:42:39,732 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:42:43,031 - Epoch: [53][   10/  139]    Overall Loss 0.410067    Objective Loss 0.410067                                        LR 0.000500    Time 0.329755    
2024-04-04 19:42:45,631 - Epoch: [53][   20/  139]    Overall Loss 0.416618    Objective Loss 0.416618                                        LR 0.000500    Time 0.294832    
2024-04-04 19:42:48,226 - Epoch: [53][   30/  139]    Overall Loss 0.415773    Objective Loss 0.415773                                        LR 0.000500    Time 0.283039    
2024-04-04 19:42:50,811 - Epoch: [53][   40/  139]    Overall Loss 0.416384    Objective Loss 0.416384                                        LR 0.000500    Time 0.276888    
2024-04-04 19:42:53,393 - Epoch: [53][   50/  139]    Overall Loss 0.416082    Objective Loss 0.416082                                        LR 0.000500    Time 0.273145    
2024-04-04 19:42:55,968 - Epoch: [53][   60/  139]    Overall Loss 0.416591    Objective Loss 0.416591                                        LR 0.000500    Time 0.270533    
2024-04-04 19:42:58,557 - Epoch: [53][   70/  139]    Overall Loss 0.417621    Objective Loss 0.417621                                        LR 0.000500    Time 0.268865    
2024-04-04 19:43:01,158 - Epoch: [53][   80/  139]    Overall Loss 0.417278    Objective Loss 0.417278                                        LR 0.000500    Time 0.267766    
2024-04-04 19:43:03,726 - Epoch: [53][   90/  139]    Overall Loss 0.417681    Objective Loss 0.417681                                        LR 0.000500    Time 0.266543    
2024-04-04 19:43:06,313 - Epoch: [53][  100/  139]    Overall Loss 0.417917    Objective Loss 0.417917                                        LR 0.000500    Time 0.265752    
2024-04-04 19:43:08,893 - Epoch: [53][  110/  139]    Overall Loss 0.418712    Objective Loss 0.418712                                        LR 0.000500    Time 0.265038    
2024-04-04 19:43:11,449 - Epoch: [53][  120/  139]    Overall Loss 0.418767    Objective Loss 0.418767                                        LR 0.000500    Time 0.264252    
2024-04-04 19:43:14,029 - Epoch: [53][  130/  139]    Overall Loss 0.420339    Objective Loss 0.420339                                        LR 0.000500    Time 0.263767    
2024-04-04 19:43:20,753 - Epoch: [53][  139/  139]    Overall Loss 0.421683    Objective Loss 0.421683    Top1 93.276099    LR 0.000500    Time 0.295058    
2024-04-04 19:43:20,966 - --- validate (epoch=53)-----------
2024-04-04 19:43:20,967 - 1392 samples (32 per mini-batch)
2024-04-04 19:43:54,096 - Epoch: [53][   10/   44]    Loss 0.500467    Top1 90.367580    
2024-04-04 19:44:26,703 - Epoch: [53][   20/   44]    Loss 0.508236    Top1 89.881582    
2024-04-04 19:44:59,811 - Epoch: [53][   30/   44]    Loss 0.508687    Top1 89.807530    
2024-04-04 19:45:31,917 - Epoch: [53][   40/   44]    Loss 0.505112    Top1 89.998618    
2024-04-04 19:45:42,975 - Epoch: [53][   44/   44]    Loss 0.506175    Top1 89.919645    
2024-04-04 19:45:43,357 - ==> Top1: 89.920    Loss: 0.506

2024-04-04 19:45:43,364 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 19:45:43,365 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:45:43,394 - 

2024-04-04 19:45:43,394 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:45:46,917 - Epoch: [54][   10/  139]    Overall Loss 0.434484    Objective Loss 0.434484                                        LR 0.000500    Time 0.352235    
2024-04-04 19:45:49,494 - Epoch: [54][   20/  139]    Overall Loss 0.425102    Objective Loss 0.425102                                        LR 0.000500    Time 0.304927    
2024-04-04 19:45:52,116 - Epoch: [54][   30/  139]    Overall Loss 0.422901    Objective Loss 0.422901                                        LR 0.000500    Time 0.290670    
2024-04-04 19:45:54,732 - Epoch: [54][   40/  139]    Overall Loss 0.423470    Objective Loss 0.423470                                        LR 0.000500    Time 0.283373    
2024-04-04 19:45:57,344 - Epoch: [54][   50/  139]    Overall Loss 0.422756    Objective Loss 0.422756                                        LR 0.000500    Time 0.278930    
2024-04-04 19:45:59,951 - Epoch: [54][   60/  139]    Overall Loss 0.421265    Objective Loss 0.421265                                        LR 0.000500    Time 0.275885    
2024-04-04 19:46:02,559 - Epoch: [54][   70/  139]    Overall Loss 0.421370    Objective Loss 0.421370                                        LR 0.000500    Time 0.273724    
2024-04-04 19:46:05,157 - Epoch: [54][   80/  139]    Overall Loss 0.421437    Objective Loss 0.421437                                        LR 0.000500    Time 0.271971    
2024-04-04 19:46:07,741 - Epoch: [54][   90/  139]    Overall Loss 0.421090    Objective Loss 0.421090                                        LR 0.000500    Time 0.270461    
2024-04-04 19:46:10,335 - Epoch: [54][  100/  139]    Overall Loss 0.419913    Objective Loss 0.419913                                        LR 0.000500    Time 0.269355    
2024-04-04 19:46:12,966 - Epoch: [54][  110/  139]    Overall Loss 0.419139    Objective Loss 0.419139                                        LR 0.000500    Time 0.268778    
2024-04-04 19:46:15,588 - Epoch: [54][  120/  139]    Overall Loss 0.418984    Objective Loss 0.418984                                        LR 0.000500    Time 0.268229    
2024-04-04 19:46:18,180 - Epoch: [54][  130/  139]    Overall Loss 0.419167    Objective Loss 0.419167                                        LR 0.000500    Time 0.267524    
2024-04-04 19:46:24,825 - Epoch: [54][  139/  139]    Overall Loss 0.418931    Objective Loss 0.418931    Top1 94.903166    LR 0.000500    Time 0.298005    
2024-04-04 19:46:25,146 - --- validate (epoch=54)-----------
2024-04-04 19:46:25,147 - 1392 samples (32 per mini-batch)
2024-04-04 19:46:58,425 - Epoch: [54][   10/   44]    Loss 0.502719    Top1 90.577947    
2024-04-04 19:47:30,624 - Epoch: [54][   20/   44]    Loss 0.501955    Top1 90.606589    
2024-04-04 19:48:03,493 - Epoch: [54][   30/   44]    Loss 0.500405    Top1 90.695563    
2024-04-04 19:48:35,285 - Epoch: [54][   40/   44]    Loss 0.497832    Top1 90.826975    
2024-04-04 19:48:46,122 - Epoch: [54][   44/   44]    Loss 0.497442    Top1 90.849781    
2024-04-04 19:48:46,409 - ==> Top1: 90.850    Loss: 0.497

2024-04-04 19:48:46,416 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 19:48:46,416 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:48:46,451 - 

2024-04-04 19:48:46,451 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:48:49,875 - Epoch: [55][   10/  139]    Overall Loss 0.416635    Objective Loss 0.416635                                        LR 0.000500    Time 0.342230    
2024-04-04 19:48:52,489 - Epoch: [55][   20/  139]    Overall Loss 0.417378    Objective Loss 0.417378                                        LR 0.000500    Time 0.301807    
2024-04-04 19:48:55,122 - Epoch: [55][   30/  139]    Overall Loss 0.418163    Objective Loss 0.418163                                        LR 0.000500    Time 0.288955    
2024-04-04 19:48:57,690 - Epoch: [55][   40/  139]    Overall Loss 0.419195    Objective Loss 0.419195                                        LR 0.000500    Time 0.280918    
2024-04-04 19:49:00,296 - Epoch: [55][   50/  139]    Overall Loss 0.420575    Objective Loss 0.420575                                        LR 0.000500    Time 0.276828    
2024-04-04 19:49:02,878 - Epoch: [55][   60/  139]    Overall Loss 0.418646    Objective Loss 0.418646                                        LR 0.000500    Time 0.273718    
2024-04-04 19:49:05,447 - Epoch: [55][   70/  139]    Overall Loss 0.417996    Objective Loss 0.417996                                        LR 0.000500    Time 0.271320    
2024-04-04 19:49:08,036 - Epoch: [55][   80/  139]    Overall Loss 0.417470    Objective Loss 0.417470                                        LR 0.000500    Time 0.269750    
2024-04-04 19:49:10,665 - Epoch: [55][   90/  139]    Overall Loss 0.417358    Objective Loss 0.417358                                        LR 0.000500    Time 0.268987    
2024-04-04 19:49:13,280 - Epoch: [55][  100/  139]    Overall Loss 0.417288    Objective Loss 0.417288                                        LR 0.000500    Time 0.268231    
2024-04-04 19:49:15,908 - Epoch: [55][  110/  139]    Overall Loss 0.417519    Objective Loss 0.417519                                        LR 0.000500    Time 0.267734    
2024-04-04 19:49:18,546 - Epoch: [55][  120/  139]    Overall Loss 0.417693    Objective Loss 0.417693                                        LR 0.000500    Time 0.267400    
2024-04-04 19:49:21,148 - Epoch: [55][  130/  139]    Overall Loss 0.417705    Objective Loss 0.417705                                        LR 0.000500    Time 0.266846    
2024-04-04 19:49:28,407 - Epoch: [55][  139/  139]    Overall Loss 0.418139    Objective Loss 0.418139    Top1 94.650220    LR 0.000500    Time 0.301787    
2024-04-04 19:49:28,671 - --- validate (epoch=55)-----------
2024-04-04 19:49:28,671 - 1392 samples (32 per mini-batch)
2024-04-04 19:50:02,576 - Epoch: [55][   10/   44]    Loss 0.509064    Top1 90.258703    
2024-04-04 19:50:33,937 - Epoch: [55][   20/   44]    Loss 0.501996    Top1 90.646529    
2024-04-04 19:51:06,945 - Epoch: [55][   30/   44]    Loss 0.499414    Top1 90.782791    
2024-04-04 19:51:39,261 - Epoch: [55][   40/   44]    Loss 0.498642    Top1 90.784788    
2024-04-04 19:51:50,646 - Epoch: [55][   44/   44]    Loss 0.499690    Top1 90.749702    
2024-04-04 19:51:50,879 - ==> Top1: 90.750    Loss: 0.500

2024-04-04 19:51:50,886 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 19:51:50,887 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:51:50,923 - 

2024-04-04 19:51:50,923 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:51:54,301 - Epoch: [56][   10/  139]    Overall Loss 0.425153    Objective Loss 0.425153                                        LR 0.000500    Time 0.337702    
2024-04-04 19:51:56,888 - Epoch: [56][   20/  139]    Overall Loss 0.422219    Objective Loss 0.422219                                        LR 0.000500    Time 0.298150    
2024-04-04 19:51:59,473 - Epoch: [56][   30/  139]    Overall Loss 0.420012    Objective Loss 0.420012                                        LR 0.000500    Time 0.284908    
2024-04-04 19:52:02,083 - Epoch: [56][   40/  139]    Overall Loss 0.417787    Objective Loss 0.417787                                        LR 0.000500    Time 0.278938    
2024-04-04 19:52:04,692 - Epoch: [56][   50/  139]    Overall Loss 0.418118    Objective Loss 0.418118                                        LR 0.000500    Time 0.275323    
2024-04-04 19:52:07,334 - Epoch: [56][   60/  139]    Overall Loss 0.417196    Objective Loss 0.417196                                        LR 0.000500    Time 0.273457    
2024-04-04 19:52:09,953 - Epoch: [56][   70/  139]    Overall Loss 0.417612    Objective Loss 0.417612                                        LR 0.000500    Time 0.271789    
2024-04-04 19:52:12,559 - Epoch: [56][   80/  139]    Overall Loss 0.417307    Objective Loss 0.417307                                        LR 0.000500    Time 0.270391    
2024-04-04 19:52:15,183 - Epoch: [56][   90/  139]    Overall Loss 0.416512    Objective Loss 0.416512                                        LR 0.000500    Time 0.269491    
2024-04-04 19:52:17,814 - Epoch: [56][  100/  139]    Overall Loss 0.416965    Objective Loss 0.416965                                        LR 0.000500    Time 0.268848    
2024-04-04 19:52:20,451 - Epoch: [56][  110/  139]    Overall Loss 0.417781    Objective Loss 0.417781                                        LR 0.000500    Time 0.268374    
2024-04-04 19:52:23,090 - Epoch: [56][  120/  139]    Overall Loss 0.417599    Objective Loss 0.417599                                        LR 0.000500    Time 0.268000    
2024-04-04 19:52:25,716 - Epoch: [56][  130/  139]    Overall Loss 0.417383    Objective Loss 0.417383                                        LR 0.000500    Time 0.267582    
2024-04-04 19:52:33,046 - Epoch: [56][  139/  139]    Overall Loss 0.417762    Objective Loss 0.417762    Top1 95.511646    LR 0.000500    Time 0.302981    
2024-04-04 19:52:33,413 - --- validate (epoch=56)-----------
2024-04-04 19:52:33,413 - 1392 samples (32 per mini-batch)
2024-04-04 19:53:07,144 - Epoch: [56][   10/   44]    Loss 0.514236    Top1 89.743493    
2024-04-04 19:53:39,297 - Epoch: [56][   20/   44]    Loss 0.516487    Top1 89.549810    
2024-04-04 19:54:11,131 - Epoch: [56][   30/   44]    Loss 0.515876    Top1 89.593653    
2024-04-04 19:54:42,751 - Epoch: [56][   40/   44]    Loss 0.515442    Top1 89.647782    
2024-04-04 19:54:53,768 - Epoch: [56][   44/   44]    Loss 0.517652    Top1 89.537110    
2024-04-04 19:54:54,093 - ==> Top1: 89.537    Loss: 0.518

2024-04-04 19:54:54,101 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 19:54:54,101 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:54:54,142 - 

2024-04-04 19:54:54,142 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:54:57,515 - Epoch: [57][   10/  139]    Overall Loss 0.422612    Objective Loss 0.422612                                        LR 0.000500    Time 0.336999    
2024-04-04 19:55:00,093 - Epoch: [57][   20/  139]    Overall Loss 0.417731    Objective Loss 0.417731                                        LR 0.000500    Time 0.297387    
2024-04-04 19:55:02,674 - Epoch: [57][   30/  139]    Overall Loss 0.417523    Objective Loss 0.417523                                        LR 0.000500    Time 0.284270    
2024-04-04 19:55:05,247 - Epoch: [57][   40/  139]    Overall Loss 0.417546    Objective Loss 0.417546                                        LR 0.000500    Time 0.277519    
2024-04-04 19:55:07,840 - Epoch: [57][   50/  139]    Overall Loss 0.416787    Objective Loss 0.416787                                        LR 0.000500    Time 0.273871    
2024-04-04 19:55:10,431 - Epoch: [57][   60/  139]    Overall Loss 0.416190    Objective Loss 0.416190                                        LR 0.000500    Time 0.271395    
2024-04-04 19:55:12,979 - Epoch: [57][   70/  139]    Overall Loss 0.416374    Objective Loss 0.416374                                        LR 0.000500    Time 0.269012    
2024-04-04 19:55:15,577 - Epoch: [57][   80/  139]    Overall Loss 0.416753    Objective Loss 0.416753                                        LR 0.000500    Time 0.267863    
2024-04-04 19:55:18,205 - Epoch: [57][   90/  139]    Overall Loss 0.417256    Objective Loss 0.417256                                        LR 0.000500    Time 0.267298    
2024-04-04 19:55:20,828 - Epoch: [57][  100/  139]    Overall Loss 0.416702    Objective Loss 0.416702                                        LR 0.000500    Time 0.266791    
2024-04-04 19:55:23,442 - Epoch: [57][  110/  139]    Overall Loss 0.416392    Objective Loss 0.416392                                        LR 0.000500    Time 0.266291    
2024-04-04 19:55:26,040 - Epoch: [57][  120/  139]    Overall Loss 0.416397    Objective Loss 0.416397                                        LR 0.000500    Time 0.265747    
2024-04-04 19:55:28,642 - Epoch: [57][  130/  139]    Overall Loss 0.416521    Objective Loss 0.416521                                        LR 0.000500    Time 0.265320    
2024-04-04 19:55:35,224 - Epoch: [57][  139/  139]    Overall Loss 0.417041    Objective Loss 0.417041    Top1 95.820316    LR 0.000500    Time 0.295491    
2024-04-04 19:55:35,565 - --- validate (epoch=57)-----------
2024-04-04 19:55:35,566 - 1392 samples (32 per mini-batch)
2024-04-04 19:56:07,348 - Epoch: [57][   10/   44]    Loss 0.511325    Top1 89.966231    
2024-04-04 19:56:38,634 - Epoch: [57][   20/   44]    Loss 0.504095    Top1 90.375704    
2024-04-04 19:57:09,864 - Epoch: [57][   30/   44]    Loss 0.510829    Top1 89.977023    
2024-04-04 19:57:41,771 - Epoch: [57][   40/   44]    Loss 0.509214    Top1 90.060787    
2024-04-04 19:57:53,434 - Epoch: [57][   44/   44]    Loss 0.507764    Top1 90.153339    
2024-04-04 19:57:53,816 - ==> Top1: 90.153    Loss: 0.508

2024-04-04 19:57:53,823 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 19:57:53,823 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 19:57:53,858 - 

2024-04-04 19:57:53,858 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 19:57:57,278 - Epoch: [58][   10/  139]    Overall Loss 0.417316    Objective Loss 0.417316                                        LR 0.000500    Time 0.341859    
2024-04-04 19:57:59,857 - Epoch: [58][   20/  139]    Overall Loss 0.416271    Objective Loss 0.416271                                        LR 0.000500    Time 0.299841    
2024-04-04 19:58:02,369 - Epoch: [58][   30/  139]    Overall Loss 0.416956    Objective Loss 0.416956                                        LR 0.000500    Time 0.283610    
2024-04-04 19:58:04,952 - Epoch: [58][   40/  139]    Overall Loss 0.416678    Objective Loss 0.416678                                        LR 0.000500    Time 0.277277    
2024-04-04 19:58:07,548 - Epoch: [58][   50/  139]    Overall Loss 0.416354    Objective Loss 0.416354                                        LR 0.000500    Time 0.273739    
2024-04-04 19:58:10,170 - Epoch: [58][   60/  139]    Overall Loss 0.417296    Objective Loss 0.417296                                        LR 0.000500    Time 0.271805    
2024-04-04 19:58:12,767 - Epoch: [58][   70/  139]    Overall Loss 0.415928    Objective Loss 0.415928                                        LR 0.000500    Time 0.270067    
2024-04-04 19:58:15,390 - Epoch: [58][   80/  139]    Overall Loss 0.415022    Objective Loss 0.415022                                        LR 0.000500    Time 0.269084    
2024-04-04 19:58:18,009 - Epoch: [58][   90/  139]    Overall Loss 0.415041    Objective Loss 0.415041                                        LR 0.000500    Time 0.268284    
2024-04-04 19:58:20,618 - Epoch: [58][  100/  139]    Overall Loss 0.415008    Objective Loss 0.415008                                        LR 0.000500    Time 0.267536    
2024-04-04 19:58:23,240 - Epoch: [58][  110/  139]    Overall Loss 0.415222    Objective Loss 0.415222                                        LR 0.000500    Time 0.267045    
2024-04-04 19:58:25,856 - Epoch: [58][  120/  139]    Overall Loss 0.415404    Objective Loss 0.415404                                        LR 0.000500    Time 0.266587    
2024-04-04 19:58:28,482 - Epoch: [58][  130/  139]    Overall Loss 0.415776    Objective Loss 0.415776                                        LR 0.000500    Time 0.266279    
2024-04-04 19:58:35,386 - Epoch: [58][  139/  139]    Overall Loss 0.415817    Objective Loss 0.415817    Top1 95.812887    LR 0.000500    Time 0.298702    
2024-04-04 19:58:35,692 - --- validate (epoch=58)-----------
2024-04-04 19:58:35,693 - 1392 samples (32 per mini-batch)
2024-04-04 19:59:08,438 - Epoch: [58][   10/   44]    Loss 0.503182    Top1 90.489631    
2024-04-04 19:59:40,523 - Epoch: [58][   20/   44]    Loss 0.504879    Top1 90.392773    
2024-04-04 20:00:12,495 - Epoch: [58][   30/   44]    Loss 0.497853    Top1 90.802228    
2024-04-04 20:00:44,391 - Epoch: [58][   40/   44]    Loss 0.496120    Top1 90.883160    
2024-04-04 20:00:56,357 - Epoch: [58][   44/   44]    Loss 0.495896    Top1 90.896143    
2024-04-04 20:00:56,726 - ==> Top1: 90.896    Loss: 0.496

2024-04-04 20:00:56,733 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 20:00:56,734 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:00:56,769 - 

2024-04-04 20:00:56,770 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:01:00,061 - Epoch: [59][   10/  139]    Overall Loss 0.413532    Objective Loss 0.413532                                        LR 0.000500    Time 0.329014    
2024-04-04 20:01:02,650 - Epoch: [59][   20/  139]    Overall Loss 0.413786    Objective Loss 0.413786                                        LR 0.000500    Time 0.293952    
2024-04-04 20:01:05,205 - Epoch: [59][   30/  139]    Overall Loss 0.415672    Objective Loss 0.415672                                        LR 0.000500    Time 0.281116    
2024-04-04 20:01:07,821 - Epoch: [59][   40/  139]    Overall Loss 0.414030    Objective Loss 0.414030                                        LR 0.000500    Time 0.276223    
2024-04-04 20:01:10,429 - Epoch: [59][   50/  139]    Overall Loss 0.413904    Objective Loss 0.413904                                        LR 0.000500    Time 0.273122    
2024-04-04 20:01:13,056 - Epoch: [59][   60/  139]    Overall Loss 0.415076    Objective Loss 0.415076                                        LR 0.000500    Time 0.271369    
2024-04-04 20:01:15,654 - Epoch: [59][   70/  139]    Overall Loss 0.416700    Objective Loss 0.416700                                        LR 0.000500    Time 0.269708    
2024-04-04 20:01:18,242 - Epoch: [59][   80/  139]    Overall Loss 0.416821    Objective Loss 0.416821                                        LR 0.000500    Time 0.268343    
2024-04-04 20:01:20,835 - Epoch: [59][   90/  139]    Overall Loss 0.417129    Objective Loss 0.417129                                        LR 0.000500    Time 0.267333    
2024-04-04 20:01:23,440 - Epoch: [59][  100/  139]    Overall Loss 0.418175    Objective Loss 0.418175                                        LR 0.000500    Time 0.266649    
2024-04-04 20:01:26,027 - Epoch: [59][  110/  139]    Overall Loss 0.418567    Objective Loss 0.418567                                        LR 0.000500    Time 0.265924    
2024-04-04 20:01:28,638 - Epoch: [59][  120/  139]    Overall Loss 0.419158    Objective Loss 0.419158                                        LR 0.000500    Time 0.265511    
2024-04-04 20:01:31,223 - Epoch: [59][  130/  139]    Overall Loss 0.418831    Objective Loss 0.418831                                        LR 0.000500    Time 0.264973    
2024-04-04 20:01:37,713 - Epoch: [59][  139/  139]    Overall Loss 0.418452    Objective Loss 0.418452    Top1 95.801955    LR 0.000500    Time 0.294502    
2024-04-04 20:01:37,999 - --- validate (epoch=59)-----------
2024-04-04 20:01:37,999 - 1392 samples (32 per mini-batch)
2024-04-04 20:02:11,489 - Epoch: [59][   10/   44]    Loss 0.512130    Top1 90.051267    
2024-04-04 20:02:44,558 - Epoch: [59][   20/   44]    Loss 0.516195    Top1 89.850464    
2024-04-04 20:03:16,247 - Epoch: [59][   30/   44]    Loss 0.514055    Top1 89.979446    
2024-04-04 20:03:48,931 - Epoch: [59][   40/   44]    Loss 0.515348    Top1 89.902047    
2024-04-04 20:03:59,626 - Epoch: [59][   44/   44]    Loss 0.515198    Top1 89.889560    
2024-04-04 20:03:59,920 - ==> Top1: 89.890    Loss: 0.515

2024-04-04 20:03:59,927 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 20:03:59,927 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:03:59,963 - 

2024-04-04 20:03:59,963 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:04:03,338 - Epoch: [60][   10/  139]    Overall Loss 0.424372    Objective Loss 0.424372                                        LR 0.000500    Time 0.337352    
2024-04-04 20:04:05,994 - Epoch: [60][   20/  139]    Overall Loss 0.420653    Objective Loss 0.420653                                        LR 0.000500    Time 0.301477    
2024-04-04 20:04:08,582 - Epoch: [60][   30/  139]    Overall Loss 0.422743    Objective Loss 0.422743                                        LR 0.000500    Time 0.287211    
2024-04-04 20:04:11,160 - Epoch: [60][   40/  139]    Overall Loss 0.421123    Objective Loss 0.421123                                        LR 0.000500    Time 0.279867    
2024-04-04 20:04:13,740 - Epoch: [60][   50/  139]    Overall Loss 0.420128    Objective Loss 0.420128                                        LR 0.000500    Time 0.275480    
2024-04-04 20:04:16,325 - Epoch: [60][   60/  139]    Overall Loss 0.418305    Objective Loss 0.418305                                        LR 0.000500    Time 0.272646    
2024-04-04 20:04:18,898 - Epoch: [60][   70/  139]    Overall Loss 0.417391    Objective Loss 0.417391                                        LR 0.000500    Time 0.270437    
2024-04-04 20:04:21,511 - Epoch: [60][   80/  139]    Overall Loss 0.417732    Objective Loss 0.417732                                        LR 0.000500    Time 0.269295    
2024-04-04 20:04:24,144 - Epoch: [60][   90/  139]    Overall Loss 0.417499    Objective Loss 0.417499                                        LR 0.000500    Time 0.268613    
2024-04-04 20:04:26,749 - Epoch: [60][  100/  139]    Overall Loss 0.417329    Objective Loss 0.417329                                        LR 0.000500    Time 0.267794    
2024-04-04 20:04:29,378 - Epoch: [60][  110/  139]    Overall Loss 0.417009    Objective Loss 0.417009                                        LR 0.000500    Time 0.267342    
2024-04-04 20:04:32,016 - Epoch: [60][  120/  139]    Overall Loss 0.416812    Objective Loss 0.416812                                        LR 0.000500    Time 0.267042    
2024-04-04 20:04:34,634 - Epoch: [60][  130/  139]    Overall Loss 0.416093    Objective Loss 0.416093                                        LR 0.000500    Time 0.266635    
2024-04-04 20:04:41,626 - Epoch: [60][  139/  139]    Overall Loss 0.415593    Objective Loss 0.415593    Top1 95.087693    LR 0.000500    Time 0.299670    
2024-04-04 20:04:41,970 - --- validate (epoch=60)-----------
2024-04-04 20:04:41,972 - 1392 samples (32 per mini-batch)
2024-04-04 20:05:15,416 - Epoch: [60][   10/   44]    Loss 0.507732    Top1 90.210549    
2024-04-04 20:05:47,353 - Epoch: [60][   20/   44]    Loss 0.500619    Top1 90.611851    
2024-04-04 20:06:18,362 - Epoch: [60][   30/   44]    Loss 0.508617    Top1 90.194673    
2024-04-04 20:06:51,296 - Epoch: [60][   40/   44]    Loss 0.509404    Top1 90.136787    
2024-04-04 20:07:02,409 - Epoch: [60][   44/   44]    Loss 0.509986    Top1 90.177064    
2024-04-04 20:07:02,771 - ==> Top1: 90.177    Loss: 0.510

2024-04-04 20:07:02,778 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 20:07:02,778 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:07:02,807 - 

2024-04-04 20:07:02,807 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:07:06,229 - Epoch: [61][   10/  139]    Overall Loss 0.415979    Objective Loss 0.415979                                        LR 0.000500    Time 0.342077    
2024-04-04 20:07:08,823 - Epoch: [61][   20/  139]    Overall Loss 0.411490    Objective Loss 0.411490                                        LR 0.000500    Time 0.300678    
2024-04-04 20:07:11,429 - Epoch: [61][   30/  139]    Overall Loss 0.413017    Objective Loss 0.413017                                        LR 0.000500    Time 0.287300    
2024-04-04 20:07:14,008 - Epoch: [61][   40/  139]    Overall Loss 0.414671    Objective Loss 0.414671                                        LR 0.000500    Time 0.279957    
2024-04-04 20:07:16,620 - Epoch: [61][   50/  139]    Overall Loss 0.414556    Objective Loss 0.414556                                        LR 0.000500    Time 0.276187    
2024-04-04 20:07:19,211 - Epoch: [61][   60/  139]    Overall Loss 0.414665    Objective Loss 0.414665                                        LR 0.000500    Time 0.273335    
2024-04-04 20:07:21,817 - Epoch: [61][   70/  139]    Overall Loss 0.413330    Objective Loss 0.413330                                        LR 0.000500    Time 0.271511    
2024-04-04 20:07:24,434 - Epoch: [61][   80/  139]    Overall Loss 0.414532    Objective Loss 0.414532                                        LR 0.000500    Time 0.270272    
2024-04-04 20:07:26,990 - Epoch: [61][   90/  139]    Overall Loss 0.415139    Objective Loss 0.415139                                        LR 0.000500    Time 0.268643    
2024-04-04 20:07:29,600 - Epoch: [61][  100/  139]    Overall Loss 0.415321    Objective Loss 0.415321                                        LR 0.000500    Time 0.267867    
2024-04-04 20:07:32,215 - Epoch: [61][  110/  139]    Overall Loss 0.414673    Objective Loss 0.414673                                        LR 0.000500    Time 0.267287    
2024-04-04 20:07:34,840 - Epoch: [61][  120/  139]    Overall Loss 0.414892    Objective Loss 0.414892                                        LR 0.000500    Time 0.266879    
2024-04-04 20:07:37,459 - Epoch: [61][  130/  139]    Overall Loss 0.414565    Objective Loss 0.414565                                        LR 0.000500    Time 0.266494    
2024-04-04 20:07:43,774 - Epoch: [61][  139/  139]    Overall Loss 0.414510    Objective Loss 0.414510    Top1 96.294749    LR 0.000500    Time 0.294669    
2024-04-04 20:07:44,088 - --- validate (epoch=61)-----------
2024-04-04 20:07:44,089 - 1392 samples (32 per mini-batch)
2024-04-04 20:08:17,366 - Epoch: [61][   10/   44]    Loss 0.492742    Top1 91.155938    
2024-04-04 20:08:49,622 - Epoch: [61][   20/   44]    Loss 0.497034    Top1 90.899630    
2024-04-04 20:09:22,546 - Epoch: [61][   30/   44]    Loss 0.500553    Top1 90.714070    
2024-04-04 20:09:54,217 - Epoch: [61][   40/   44]    Loss 0.497234    Top1 90.903504    
2024-04-04 20:10:04,943 - Epoch: [61][   44/   44]    Loss 0.496836    Top1 90.914848    
2024-04-04 20:10:05,252 - ==> Top1: 90.915    Loss: 0.497

2024-04-04 20:10:05,259 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 20:10:05,259 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:10:05,288 - 

2024-04-04 20:10:05,288 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:10:08,698 - Epoch: [62][   10/  139]    Overall Loss 0.413368    Objective Loss 0.413368                                        LR 0.000500    Time 0.340869    
2024-04-04 20:10:11,300 - Epoch: [62][   20/  139]    Overall Loss 0.410561    Objective Loss 0.410561                                        LR 0.000500    Time 0.300486    
2024-04-04 20:10:13,924 - Epoch: [62][   30/  139]    Overall Loss 0.409506    Objective Loss 0.409506                                        LR 0.000500    Time 0.287791    
2024-04-04 20:10:16,521 - Epoch: [62][   40/  139]    Overall Loss 0.409780    Objective Loss 0.409780                                        LR 0.000500    Time 0.280748    
2024-04-04 20:10:19,157 - Epoch: [62][   50/  139]    Overall Loss 0.409272    Objective Loss 0.409272                                        LR 0.000500    Time 0.277315    
2024-04-04 20:10:21,792 - Epoch: [62][   60/  139]    Overall Loss 0.410339    Objective Loss 0.410339                                        LR 0.000500    Time 0.274999    
2024-04-04 20:10:24,417 - Epoch: [62][   70/  139]    Overall Loss 0.410503    Objective Loss 0.410503                                        LR 0.000500    Time 0.273203    
2024-04-04 20:10:27,015 - Epoch: [62][   80/  139]    Overall Loss 0.410925    Objective Loss 0.410925                                        LR 0.000500    Time 0.271521    
2024-04-04 20:10:29,645 - Epoch: [62][   90/  139]    Overall Loss 0.411270    Objective Loss 0.411270                                        LR 0.000500    Time 0.270570    
2024-04-04 20:10:32,299 - Epoch: [62][  100/  139]    Overall Loss 0.411823    Objective Loss 0.411823                                        LR 0.000500    Time 0.270042    
2024-04-04 20:10:34,936 - Epoch: [62][  110/  139]    Overall Loss 0.412453    Objective Loss 0.412453                                        LR 0.000500    Time 0.269464    
2024-04-04 20:10:37,551 - Epoch: [62][  120/  139]    Overall Loss 0.412636    Objective Loss 0.412636                                        LR 0.000500    Time 0.268793    
2024-04-04 20:10:40,163 - Epoch: [62][  130/  139]    Overall Loss 0.412835    Objective Loss 0.412835                                        LR 0.000500    Time 0.268211    
2024-04-04 20:10:47,199 - Epoch: [62][  139/  139]    Overall Loss 0.412980    Objective Loss 0.412980    Top1 96.567687    LR 0.000500    Time 0.301455    
2024-04-04 20:10:47,542 - --- validate (epoch=62)-----------
2024-04-04 20:10:47,542 - 1392 samples (32 per mini-batch)
2024-04-04 20:11:21,392 - Epoch: [62][   10/   44]    Loss 0.512999    Top1 89.910979    
2024-04-04 20:11:55,106 - Epoch: [62][   20/   44]    Loss 0.504563    Top1 90.397413    
2024-04-04 20:12:26,501 - Epoch: [62][   30/   44]    Loss 0.509873    Top1 90.097565    
2024-04-04 20:12:58,183 - Epoch: [62][   40/   44]    Loss 0.506464    Top1 90.279293    
2024-04-04 20:13:09,067 - Epoch: [62][   44/   44]    Loss 0.511082    Top1 90.038726    
2024-04-04 20:13:09,310 - ==> Top1: 90.039    Loss: 0.511

2024-04-04 20:13:09,318 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 20:13:09,318 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:13:09,347 - 

2024-04-04 20:13:09,348 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:13:12,802 - Epoch: [63][   10/  139]    Overall Loss 0.408634    Objective Loss 0.408634                                        LR 0.000500    Time 0.345305    
2024-04-04 20:13:15,397 - Epoch: [63][   20/  139]    Overall Loss 0.408725    Objective Loss 0.408725                                        LR 0.000500    Time 0.302381    
2024-04-04 20:13:17,960 - Epoch: [63][   30/  139]    Overall Loss 0.409085    Objective Loss 0.409085                                        LR 0.000500    Time 0.286999    
2024-04-04 20:13:20,567 - Epoch: [63][   40/  139]    Overall Loss 0.411832    Objective Loss 0.411832                                        LR 0.000500    Time 0.280406    
2024-04-04 20:13:23,194 - Epoch: [63][   50/  139]    Overall Loss 0.411947    Objective Loss 0.411947                                        LR 0.000500    Time 0.276853    
2024-04-04 20:13:25,816 - Epoch: [63][   60/  139]    Overall Loss 0.411811    Objective Loss 0.411811                                        LR 0.000500    Time 0.274405    
2024-04-04 20:13:28,409 - Epoch: [63][   70/  139]    Overall Loss 0.411055    Objective Loss 0.411055                                        LR 0.000500    Time 0.272239    
2024-04-04 20:13:31,069 - Epoch: [63][   80/  139]    Overall Loss 0.412227    Objective Loss 0.412227                                        LR 0.000500    Time 0.271447    
2024-04-04 20:13:33,739 - Epoch: [63][   90/  139]    Overall Loss 0.412911    Objective Loss 0.412911                                        LR 0.000500    Time 0.270950    
2024-04-04 20:13:36,364 - Epoch: [63][  100/  139]    Overall Loss 0.412823    Objective Loss 0.412823                                        LR 0.000500    Time 0.270100    
2024-04-04 20:13:38,990 - Epoch: [63][  110/  139]    Overall Loss 0.412724    Objective Loss 0.412724                                        LR 0.000500    Time 0.269411    
2024-04-04 20:13:41,607 - Epoch: [63][  120/  139]    Overall Loss 0.413779    Objective Loss 0.413779                                        LR 0.000500    Time 0.268768    
2024-04-04 20:13:44,210 - Epoch: [63][  130/  139]    Overall Loss 0.413309    Objective Loss 0.413309                                        LR 0.000500    Time 0.268110    
2024-04-04 20:13:50,973 - Epoch: [63][  139/  139]    Overall Loss 0.413345    Objective Loss 0.413345    Top1 95.943524    LR 0.000500    Time 0.299400    
2024-04-04 20:13:51,313 - --- validate (epoch=63)-----------
2024-04-04 20:13:51,314 - 1392 samples (32 per mini-batch)
2024-04-04 20:14:24,121 - Epoch: [63][   10/   44]    Loss 0.473376    Top1 92.291900    
2024-04-04 20:14:57,157 - Epoch: [63][   20/   44]    Loss 0.494065    Top1 91.130630    
2024-04-04 20:15:28,927 - Epoch: [63][   30/   44]    Loss 0.498533    Top1 90.880733    
2024-04-04 20:16:02,016 - Epoch: [63][   40/   44]    Loss 0.500896    Top1 90.750971    
2024-04-04 20:16:13,426 - Epoch: [63][   44/   44]    Loss 0.500656    Top1 90.780199    
2024-04-04 20:16:13,745 - ==> Top1: 90.780    Loss: 0.501

2024-04-04 20:16:13,752 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 20:16:13,752 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:16:13,789 - 

2024-04-04 20:16:13,789 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:16:17,119 - Epoch: [64][   10/  139]    Overall Loss 0.410375    Objective Loss 0.410375                                        LR 0.000500    Time 0.332800    
2024-04-04 20:16:19,689 - Epoch: [64][   20/  139]    Overall Loss 0.412138    Objective Loss 0.412138                                        LR 0.000500    Time 0.294863    
2024-04-04 20:16:22,282 - Epoch: [64][   30/  139]    Overall Loss 0.414433    Objective Loss 0.414433                                        LR 0.000500    Time 0.283025    
2024-04-04 20:16:24,866 - Epoch: [64][   40/  139]    Overall Loss 0.413788    Objective Loss 0.413788                                        LR 0.000500    Time 0.276842    
2024-04-04 20:16:27,446 - Epoch: [64][   50/  139]    Overall Loss 0.415098    Objective Loss 0.415098                                        LR 0.000500    Time 0.273067    
2024-04-04 20:16:30,093 - Epoch: [64][   60/  139]    Overall Loss 0.415354    Objective Loss 0.415354                                        LR 0.000500    Time 0.271655    
2024-04-04 20:16:32,674 - Epoch: [64][   70/  139]    Overall Loss 0.415024    Objective Loss 0.415024                                        LR 0.000500    Time 0.269717    
2024-04-04 20:16:35,317 - Epoch: [64][   80/  139]    Overall Loss 0.415002    Objective Loss 0.415002                                        LR 0.000500    Time 0.269027    
2024-04-04 20:16:37,941 - Epoch: [64][   90/  139]    Overall Loss 0.414375    Objective Loss 0.414375                                        LR 0.000500    Time 0.268295    
2024-04-04 20:16:40,563 - Epoch: [64][  100/  139]    Overall Loss 0.414082    Objective Loss 0.414082                                        LR 0.000500    Time 0.267671    
2024-04-04 20:16:43,194 - Epoch: [64][  110/  139]    Overall Loss 0.414109    Objective Loss 0.414109                                        LR 0.000500    Time 0.267256    
2024-04-04 20:16:45,824 - Epoch: [64][  120/  139]    Overall Loss 0.414313    Objective Loss 0.414313                                        LR 0.000500    Time 0.266893    
2024-04-04 20:16:48,439 - Epoch: [64][  130/  139]    Overall Loss 0.414429    Objective Loss 0.414429                                        LR 0.000500    Time 0.266480    
2024-04-04 20:16:55,586 - Epoch: [64][  139/  139]    Overall Loss 0.414349    Objective Loss 0.414349    Top1 95.858927    LR 0.000500    Time 0.300639    
2024-04-04 20:16:55,921 - --- validate (epoch=64)-----------
2024-04-04 20:16:55,921 - 1392 samples (32 per mini-batch)
2024-04-04 20:17:29,479 - Epoch: [64][   10/   44]    Loss 0.515622    Top1 89.691974    
2024-04-04 20:18:01,864 - Epoch: [64][   20/   44]    Loss 0.511165    Top1 89.996623    
2024-04-04 20:18:34,549 - Epoch: [64][   30/   44]    Loss 0.506339    Top1 90.262180    
2024-04-04 20:19:07,043 - Epoch: [64][   40/   44]    Loss 0.505663    Top1 90.295092    
2024-04-04 20:19:17,710 - Epoch: [64][   44/   44]    Loss 0.503538    Top1 90.379101    
2024-04-04 20:19:18,105 - ==> Top1: 90.379    Loss: 0.504

2024-04-04 20:19:18,112 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 20:19:18,112 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:19:18,149 - 

2024-04-04 20:19:18,149 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:19:21,524 - Epoch: [65][   10/  139]    Overall Loss 0.413381    Objective Loss 0.413381                                        LR 0.000500    Time 0.337303    
2024-04-04 20:19:24,153 - Epoch: [65][   20/  139]    Overall Loss 0.413292    Objective Loss 0.413292                                        LR 0.000500    Time 0.300075    
2024-04-04 20:19:26,766 - Epoch: [65][   30/  139]    Overall Loss 0.414496    Objective Loss 0.414496                                        LR 0.000500    Time 0.287125    
2024-04-04 20:19:29,385 - Epoch: [65][   40/  139]    Overall Loss 0.413839    Objective Loss 0.413839                                        LR 0.000500    Time 0.280807    
2024-04-04 20:19:32,004 - Epoch: [65][   50/  139]    Overall Loss 0.412839    Objective Loss 0.412839                                        LR 0.000500    Time 0.277009    
2024-04-04 20:19:34,597 - Epoch: [65][   60/  139]    Overall Loss 0.411963    Objective Loss 0.411963                                        LR 0.000500    Time 0.274045    
2024-04-04 20:19:37,176 - Epoch: [65][   70/  139]    Overall Loss 0.412337    Objective Loss 0.412337                                        LR 0.000500    Time 0.271738    
2024-04-04 20:19:39,737 - Epoch: [65][   80/  139]    Overall Loss 0.412505    Objective Loss 0.412505                                        LR 0.000500    Time 0.269778    
2024-04-04 20:19:42,286 - Epoch: [65][   90/  139]    Overall Loss 0.412540    Objective Loss 0.412540                                        LR 0.000500    Time 0.268121    
2024-04-04 20:19:44,864 - Epoch: [65][  100/  139]    Overall Loss 0.412270    Objective Loss 0.412270                                        LR 0.000500    Time 0.267087    
2024-04-04 20:19:47,505 - Epoch: [65][  110/  139]    Overall Loss 0.412312    Objective Loss 0.412312                                        LR 0.000500    Time 0.266810    
2024-04-04 20:19:50,118 - Epoch: [65][  120/  139]    Overall Loss 0.412260    Objective Loss 0.412260                                        LR 0.000500    Time 0.266346    
2024-04-04 20:19:52,727 - Epoch: [65][  130/  139]    Overall Loss 0.412400    Objective Loss 0.412400                                        LR 0.000500    Time 0.265920    
2024-04-04 20:19:59,940 - Epoch: [65][  139/  139]    Overall Loss 0.412622    Objective Loss 0.412622    Top1 95.820775    LR 0.000500    Time 0.300590    
2024-04-04 20:20:00,201 - --- validate (epoch=65)-----------
2024-04-04 20:20:00,203 - 1392 samples (32 per mini-batch)
2024-04-04 20:20:33,332 - Epoch: [65][   10/   44]    Loss 0.498635    Top1 90.750712    
2024-04-04 20:21:06,437 - Epoch: [65][   20/   44]    Loss 0.494840    Top1 90.959761    
2024-04-04 20:21:37,381 - Epoch: [65][   30/   44]    Loss 0.496590    Top1 90.855795    
2024-04-04 20:22:10,048 - Epoch: [65][   40/   44]    Loss 0.500308    Top1 90.651498    
2024-04-04 20:22:21,268 - Epoch: [65][   44/   44]    Loss 0.499653    Top1 90.669407    
2024-04-04 20:22:21,525 - ==> Top1: 90.669    Loss: 0.500

2024-04-04 20:22:21,533 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 20:22:21,533 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:22:21,569 - 

2024-04-04 20:22:21,569 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:22:24,881 - Epoch: [66][   10/  139]    Overall Loss 0.415172    Objective Loss 0.415172                                        LR 0.000500    Time 0.331100    
2024-04-04 20:22:27,472 - Epoch: [66][   20/  139]    Overall Loss 0.414012    Objective Loss 0.414012                                        LR 0.000500    Time 0.295035    
2024-04-04 20:22:30,061 - Epoch: [66][   30/  139]    Overall Loss 0.412720    Objective Loss 0.412720                                        LR 0.000500    Time 0.282964    
2024-04-04 20:22:32,636 - Epoch: [66][   40/  139]    Overall Loss 0.410843    Objective Loss 0.410843                                        LR 0.000500    Time 0.276588    
2024-04-04 20:22:35,217 - Epoch: [66][   50/  139]    Overall Loss 0.411655    Objective Loss 0.411655                                        LR 0.000500    Time 0.272879    
2024-04-04 20:22:37,850 - Epoch: [66][   60/  139]    Overall Loss 0.412961    Objective Loss 0.412961                                        LR 0.000500    Time 0.271282    
2024-04-04 20:22:40,469 - Epoch: [66][   70/  139]    Overall Loss 0.414767    Objective Loss 0.414767                                        LR 0.000500    Time 0.269931    
2024-04-04 20:22:43,087 - Epoch: [66][   80/  139]    Overall Loss 0.414992    Objective Loss 0.414992                                        LR 0.000500    Time 0.268914    
2024-04-04 20:22:45,740 - Epoch: [66][   90/  139]    Overall Loss 0.414991    Objective Loss 0.414991                                        LR 0.000500    Time 0.268498    
2024-04-04 20:22:48,352 - Epoch: [66][  100/  139]    Overall Loss 0.415148    Objective Loss 0.415148                                        LR 0.000500    Time 0.267766    
2024-04-04 20:22:50,976 - Epoch: [66][  110/  139]    Overall Loss 0.414822    Objective Loss 0.414822                                        LR 0.000500    Time 0.267268    
2024-04-04 20:22:53,605 - Epoch: [66][  120/  139]    Overall Loss 0.414885    Objective Loss 0.414885                                        LR 0.000500    Time 0.266896    
2024-04-04 20:22:56,230 - Epoch: [66][  130/  139]    Overall Loss 0.414465    Objective Loss 0.414465                                        LR 0.000500    Time 0.266555    
2024-04-04 20:23:04,104 - Epoch: [66][  139/  139]    Overall Loss 0.413879    Objective Loss 0.413879    Top1 96.364616    LR 0.000500    Time 0.305940    
2024-04-04 20:23:04,382 - --- validate (epoch=66)-----------
2024-04-04 20:23:04,382 - 1392 samples (32 per mini-batch)
2024-04-04 20:23:36,932 - Epoch: [66][   10/   44]    Loss 0.500833    Top1 90.691223    
2024-04-04 20:24:08,425 - Epoch: [66][   20/   44]    Loss 0.500858    Top1 90.612476    
2024-04-04 20:24:40,364 - Epoch: [66][   30/   44]    Loss 0.498336    Top1 90.761710    
2024-04-04 20:25:13,450 - Epoch: [66][   40/   44]    Loss 0.498180    Top1 90.763935    
2024-04-04 20:25:24,788 - Epoch: [66][   44/   44]    Loss 0.498075    Top1 90.788693    
2024-04-04 20:25:25,094 - ==> Top1: 90.789    Loss: 0.498

2024-04-04 20:25:25,101 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 20:25:25,101 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:25:25,135 - 

2024-04-04 20:25:25,135 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:25:28,453 - Epoch: [67][   10/  139]    Overall Loss 0.417821    Objective Loss 0.417821                                        LR 0.000500    Time 0.331685    
2024-04-04 20:25:31,022 - Epoch: [67][   20/  139]    Overall Loss 0.412337    Objective Loss 0.412337                                        LR 0.000500    Time 0.294284    
2024-04-04 20:25:33,610 - Epoch: [67][   30/  139]    Overall Loss 0.408714    Objective Loss 0.408714                                        LR 0.000500    Time 0.282435    
2024-04-04 20:25:36,179 - Epoch: [67][   40/  139]    Overall Loss 0.409155    Objective Loss 0.409155                                        LR 0.000500    Time 0.276024    
2024-04-04 20:25:38,806 - Epoch: [67][   50/  139]    Overall Loss 0.409164    Objective Loss 0.409164                                        LR 0.000500    Time 0.273351    
2024-04-04 20:25:41,423 - Epoch: [67][   60/  139]    Overall Loss 0.409854    Objective Loss 0.409854                                        LR 0.000500    Time 0.271408    
2024-04-04 20:25:44,039 - Epoch: [67][   70/  139]    Overall Loss 0.410529    Objective Loss 0.410529                                        LR 0.000500    Time 0.270000    
2024-04-04 20:25:46,667 - Epoch: [67][   80/  139]    Overall Loss 0.410310    Objective Loss 0.410310                                        LR 0.000500    Time 0.269093    
2024-04-04 20:25:49,269 - Epoch: [67][   90/  139]    Overall Loss 0.410372    Objective Loss 0.410372                                        LR 0.000500    Time 0.268096    
2024-04-04 20:25:51,913 - Epoch: [67][  100/  139]    Overall Loss 0.410864    Objective Loss 0.410864                                        LR 0.000500    Time 0.267717    
2024-04-04 20:25:54,543 - Epoch: [67][  110/  139]    Overall Loss 0.411492    Objective Loss 0.411492                                        LR 0.000500    Time 0.267283    
2024-04-04 20:25:57,158 - Epoch: [67][  120/  139]    Overall Loss 0.411280    Objective Loss 0.411280                                        LR 0.000500    Time 0.266799    
2024-04-04 20:25:59,776 - Epoch: [67][  130/  139]    Overall Loss 0.411254    Objective Loss 0.411254                                        LR 0.000500    Time 0.266404    
2024-04-04 20:26:07,010 - Epoch: [67][  139/  139]    Overall Loss 0.411563    Objective Loss 0.411563    Top1 94.896397    LR 0.000500    Time 0.301193    
2024-04-04 20:26:07,260 - --- validate (epoch=67)-----------
2024-04-04 20:26:07,263 - 1392 samples (32 per mini-batch)
2024-04-04 20:26:40,467 - Epoch: [67][   10/   44]    Loss 0.512124    Top1 90.218952    
2024-04-04 20:27:12,925 - Epoch: [67][   20/   44]    Loss 0.498579    Top1 90.970927    
2024-04-04 20:27:44,751 - Epoch: [67][   30/   44]    Loss 0.502555    Top1 90.762171    
2024-04-04 20:28:17,307 - Epoch: [67][   40/   44]    Loss 0.505201    Top1 90.608359    
2024-04-04 20:28:28,435 - Epoch: [67][   44/   44]    Loss 0.503255    Top1 90.744050    
2024-04-04 20:28:28,757 - ==> Top1: 90.744    Loss: 0.503

2024-04-04 20:28:28,763 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 20:28:28,764 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:28:28,799 - 

2024-04-04 20:28:28,799 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:28:32,290 - Epoch: [68][   10/  139]    Overall Loss 0.414333    Objective Loss 0.414333                                        LR 0.000500    Time 0.348940    
2024-04-04 20:28:34,829 - Epoch: [68][   20/  139]    Overall Loss 0.411725    Objective Loss 0.411725                                        LR 0.000500    Time 0.301399    
2024-04-04 20:28:37,440 - Epoch: [68][   30/  139]    Overall Loss 0.413361    Objective Loss 0.413361                                        LR 0.000500    Time 0.287954    
2024-04-04 20:28:40,089 - Epoch: [68][   40/  139]    Overall Loss 0.412663    Objective Loss 0.412663                                        LR 0.000500    Time 0.282157    
2024-04-04 20:28:42,727 - Epoch: [68][   50/  139]    Overall Loss 0.412948    Objective Loss 0.412948                                        LR 0.000500    Time 0.278480    
2024-04-04 20:28:45,367 - Epoch: [68][   60/  139]    Overall Loss 0.412130    Objective Loss 0.412130                                        LR 0.000500    Time 0.276068    
2024-04-04 20:28:47,986 - Epoch: [68][   70/  139]    Overall Loss 0.411786    Objective Loss 0.411786                                        LR 0.000500    Time 0.274032    
2024-04-04 20:28:50,603 - Epoch: [68][   80/  139]    Overall Loss 0.412090    Objective Loss 0.412090                                        LR 0.000500    Time 0.272486    
2024-04-04 20:28:53,227 - Epoch: [68][   90/  139]    Overall Loss 0.413568    Objective Loss 0.413568                                        LR 0.000500    Time 0.271362    
2024-04-04 20:28:55,867 - Epoch: [68][  100/  139]    Overall Loss 0.413711    Objective Loss 0.413711                                        LR 0.000500    Time 0.270616    
2024-04-04 20:28:58,501 - Epoch: [68][  110/  139]    Overall Loss 0.414100    Objective Loss 0.414100                                        LR 0.000500    Time 0.269958    
2024-04-04 20:29:01,133 - Epoch: [68][  120/  139]    Overall Loss 0.414238    Objective Loss 0.414238                                        LR 0.000500    Time 0.269391    
2024-04-04 20:29:03,758 - Epoch: [68][  130/  139]    Overall Loss 0.414195    Objective Loss 0.414195                                        LR 0.000500    Time 0.268856    
2024-04-04 20:29:11,288 - Epoch: [68][  139/  139]    Overall Loss 0.413845    Objective Loss 0.413845    Top1 95.894916    LR 0.000500    Time 0.305615    
2024-04-04 20:29:11,642 - --- validate (epoch=68)-----------
2024-04-04 20:29:11,643 - 1392 samples (32 per mini-batch)
2024-04-04 20:29:45,649 - Epoch: [68][   10/   44]    Loss 0.519010    Top1 89.815982    
2024-04-04 20:30:18,137 - Epoch: [68][   20/   44]    Loss 0.506475    Top1 90.485396    
2024-04-04 20:30:50,630 - Epoch: [68][   30/   44]    Loss 0.504539    Top1 90.577987    
2024-04-04 20:31:23,225 - Epoch: [68][   40/   44]    Loss 0.500108    Top1 90.824640    
2024-04-04 20:31:34,145 - Epoch: [68][   44/   44]    Loss 0.500113    Top1 90.805779    
2024-04-04 20:31:34,454 - ==> Top1: 90.806    Loss: 0.500

2024-04-04 20:31:34,461 - ==> Best [Top1: 91.003   Sparsity:0.00   Params: 272800 on epoch: 49]
2024-04-04 20:31:34,461 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:31:34,496 - 

2024-04-04 20:31:34,496 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:31:37,792 - Epoch: [69][   10/  139]    Overall Loss 0.409369    Objective Loss 0.409369                                        LR 0.000500    Time 0.329440    
2024-04-04 20:31:40,363 - Epoch: [69][   20/  139]    Overall Loss 0.407230    Objective Loss 0.407230                                        LR 0.000500    Time 0.293207    
2024-04-04 20:31:42,979 - Epoch: [69][   30/  139]    Overall Loss 0.404676    Objective Loss 0.404676                                        LR 0.000500    Time 0.282651    
2024-04-04 20:31:45,563 - Epoch: [69][   40/  139]    Overall Loss 0.405623    Objective Loss 0.405623                                        LR 0.000500    Time 0.276596    
2024-04-04 20:31:48,169 - Epoch: [69][   50/  139]    Overall Loss 0.406255    Objective Loss 0.406255                                        LR 0.000500    Time 0.273375    
2024-04-04 20:31:50,746 - Epoch: [69][   60/  139]    Overall Loss 0.406748    Objective Loss 0.406748                                        LR 0.000500    Time 0.270748    
2024-04-04 20:31:53,311 - Epoch: [69][   70/  139]    Overall Loss 0.407748    Objective Loss 0.407748                                        LR 0.000500    Time 0.268717    
2024-04-04 20:31:55,894 - Epoch: [69][   80/  139]    Overall Loss 0.408124    Objective Loss 0.408124                                        LR 0.000500    Time 0.267405    
2024-04-04 20:31:58,494 - Epoch: [69][   90/  139]    Overall Loss 0.408284    Objective Loss 0.408284                                        LR 0.000500    Time 0.266574    
2024-04-04 20:32:01,030 - Epoch: [69][  100/  139]    Overall Loss 0.409088    Objective Loss 0.409088                                        LR 0.000500    Time 0.265268    
2024-04-04 20:32:03,609 - Epoch: [69][  110/  139]    Overall Loss 0.408952    Objective Loss 0.408952                                        LR 0.000500    Time 0.264599    
2024-04-04 20:32:06,155 - Epoch: [69][  120/  139]    Overall Loss 0.408828    Objective Loss 0.408828                                        LR 0.000500    Time 0.263760    
2024-04-04 20:32:08,709 - Epoch: [69][  130/  139]    Overall Loss 0.408911    Objective Loss 0.408911                                        LR 0.000500    Time 0.263108    
2024-04-04 20:32:15,548 - Epoch: [69][  139/  139]    Overall Loss 0.408740    Objective Loss 0.408740    Top1 96.855740    LR 0.000500    Time 0.295273    
2024-04-04 20:32:15,920 - --- validate (epoch=69)-----------
2024-04-04 20:32:15,920 - 1392 samples (32 per mini-batch)
2024-04-04 20:32:49,588 - Epoch: [69][   10/   44]    Loss 0.494719    Top1 91.051840    
2024-04-04 20:33:22,403 - Epoch: [69][   20/   44]    Loss 0.497086    Top1 90.941471    
2024-04-04 20:33:54,392 - Epoch: [69][   30/   44]    Loss 0.497270    Top1 90.906467    
2024-04-04 20:34:26,113 - Epoch: [69][   40/   44]    Loss 0.493691    Top1 91.124586    
2024-04-04 20:34:37,222 - Epoch: [69][   44/   44]    Loss 0.494814    Top1 91.082928    
2024-04-04 20:34:37,487 - ==> Top1: 91.083    Loss: 0.495

2024-04-04 20:34:37,493 - ==> Best [Top1: 91.083   Sparsity:0.00   Params: 272800 on epoch: 69]
2024-04-04 20:34:37,494 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:34:37,532 - 

2024-04-04 20:34:37,532 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:34:40,927 - Epoch: [70][   10/  139]    Overall Loss 0.405235    Objective Loss 0.405235                                        LR 0.000500    Time 0.339337    
2024-04-04 20:34:43,522 - Epoch: [70][   20/  139]    Overall Loss 0.407187    Objective Loss 0.407187                                        LR 0.000500    Time 0.299366    
2024-04-04 20:34:46,070 - Epoch: [70][   30/  139]    Overall Loss 0.405640    Objective Loss 0.405640                                        LR 0.000500    Time 0.284506    
2024-04-04 20:34:48,674 - Epoch: [70][   40/  139]    Overall Loss 0.405391    Objective Loss 0.405391                                        LR 0.000500    Time 0.278451    
2024-04-04 20:34:51,300 - Epoch: [70][   50/  139]    Overall Loss 0.405252    Objective Loss 0.405252                                        LR 0.000500    Time 0.275287    
2024-04-04 20:34:53,910 - Epoch: [70][   60/  139]    Overall Loss 0.405865    Objective Loss 0.405865                                        LR 0.000500    Time 0.272897    
2024-04-04 20:34:56,539 - Epoch: [70][   70/  139]    Overall Loss 0.406136    Objective Loss 0.406136                                        LR 0.000500    Time 0.271460    
2024-04-04 20:34:59,158 - Epoch: [70][   80/  139]    Overall Loss 0.406140    Objective Loss 0.406140                                        LR 0.000500    Time 0.270253    
2024-04-04 20:35:01,800 - Epoch: [70][   90/  139]    Overall Loss 0.407232    Objective Loss 0.407232                                        LR 0.000500    Time 0.269577    
2024-04-04 20:35:04,426 - Epoch: [70][  100/  139]    Overall Loss 0.407818    Objective Loss 0.407818                                        LR 0.000500    Time 0.268874    
2024-04-04 20:35:07,076 - Epoch: [70][  110/  139]    Overall Loss 0.407915    Objective Loss 0.407915                                        LR 0.000500    Time 0.268522    
2024-04-04 20:35:09,715 - Epoch: [70][  120/  139]    Overall Loss 0.407493    Objective Loss 0.407493                                        LR 0.000500    Time 0.268130    
2024-04-04 20:35:12,349 - Epoch: [70][  130/  139]    Overall Loss 0.407654    Objective Loss 0.407654                                        LR 0.000500    Time 0.267758    
2024-04-04 20:35:18,999 - Epoch: [70][  139/  139]    Overall Loss 0.408100    Objective Loss 0.408100    Top1 96.101619    LR 0.000500    Time 0.298261    
2024-04-04 20:35:19,238 - --- validate (epoch=70)-----------
2024-04-04 20:35:19,238 - 1392 samples (32 per mini-batch)
2024-04-04 20:35:52,308 - Epoch: [70][   10/   44]    Loss 0.515998    Top1 89.718815    
2024-04-04 20:36:24,584 - Epoch: [70][   20/   44]    Loss 0.511786    Top1 89.923325    
2024-04-04 20:36:56,098 - Epoch: [70][   30/   44]    Loss 0.512300    Top1 89.879546    
2024-04-04 20:37:28,935 - Epoch: [70][   40/   44]    Loss 0.516872    Top1 89.614253    
2024-04-04 20:37:40,334 - Epoch: [70][   44/   44]    Loss 0.518817    Top1 89.547336    
2024-04-04 20:37:40,624 - ==> Top1: 89.547    Loss: 0.519

2024-04-04 20:37:40,631 - ==> Best [Top1: 91.083   Sparsity:0.00   Params: 272800 on epoch: 69]
2024-04-04 20:37:40,631 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:37:40,665 - 

2024-04-04 20:37:40,666 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:37:44,108 - Epoch: [71][   10/  139]    Overall Loss 0.417324    Objective Loss 0.417324                                        LR 0.000500    Time 0.344086    
2024-04-04 20:37:46,709 - Epoch: [71][   20/  139]    Overall Loss 0.411303    Objective Loss 0.411303                                        LR 0.000500    Time 0.302094    
2024-04-04 20:37:49,280 - Epoch: [71][   30/  139]    Overall Loss 0.408992    Objective Loss 0.408992                                        LR 0.000500    Time 0.287067    
2024-04-04 20:37:51,871 - Epoch: [71][   40/  139]    Overall Loss 0.409371    Objective Loss 0.409371                                        LR 0.000500    Time 0.280074    
2024-04-04 20:37:54,445 - Epoch: [71][   50/  139]    Overall Loss 0.407542    Objective Loss 0.407542                                        LR 0.000500    Time 0.275521    
2024-04-04 20:37:57,024 - Epoch: [71][   60/  139]    Overall Loss 0.407294    Objective Loss 0.407294                                        LR 0.000500    Time 0.272579    
2024-04-04 20:37:59,586 - Epoch: [71][   70/  139]    Overall Loss 0.408249    Objective Loss 0.408249                                        LR 0.000500    Time 0.270225    
2024-04-04 20:38:02,169 - Epoch: [71][   80/  139]    Overall Loss 0.408780    Objective Loss 0.408780                                        LR 0.000500    Time 0.268729    
2024-04-04 20:38:04,770 - Epoch: [71][   90/  139]    Overall Loss 0.408652    Objective Loss 0.408652                                        LR 0.000500    Time 0.267763    
2024-04-04 20:38:07,396 - Epoch: [71][  100/  139]    Overall Loss 0.408353    Objective Loss 0.408353                                        LR 0.000500    Time 0.267245    
2024-04-04 20:38:10,028 - Epoch: [71][  110/  139]    Overall Loss 0.408009    Objective Loss 0.408009                                        LR 0.000500    Time 0.266877    
2024-04-04 20:38:12,684 - Epoch: [71][  120/  139]    Overall Loss 0.408193    Objective Loss 0.408193                                        LR 0.000500    Time 0.266765    
2024-04-04 20:38:15,303 - Epoch: [71][  130/  139]    Overall Loss 0.408576    Objective Loss 0.408576                                        LR 0.000500    Time 0.266386    
2024-04-04 20:38:22,563 - Epoch: [71][  139/  139]    Overall Loss 0.409010    Objective Loss 0.409010    Top1 95.481069    LR 0.000500    Time 0.301366    
2024-04-04 20:38:22,810 - --- validate (epoch=71)-----------
2024-04-04 20:38:22,811 - 1392 samples (32 per mini-batch)
2024-04-04 20:38:56,416 - Epoch: [71][   10/   44]    Loss 0.510747    Top1 90.244073    
2024-04-04 20:39:28,694 - Epoch: [71][   20/   44]    Loss 0.510603    Top1 90.235570    
2024-04-04 20:40:00,321 - Epoch: [71][   30/   44]    Loss 0.508220    Top1 90.393730    
2024-04-04 20:40:32,074 - Epoch: [71][   40/   44]    Loss 0.505959    Top1 90.518951    
2024-04-04 20:40:43,646 - Epoch: [71][   44/   44]    Loss 0.503539    Top1 90.616039    
2024-04-04 20:40:43,922 - ==> Top1: 90.616    Loss: 0.504

2024-04-04 20:40:43,930 - ==> Best [Top1: 91.083   Sparsity:0.00   Params: 272800 on epoch: 69]
2024-04-04 20:40:43,930 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:40:43,964 - 

2024-04-04 20:40:43,964 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:40:47,274 - Epoch: [72][   10/  139]    Overall Loss 0.407472    Objective Loss 0.407472                                        LR 0.000500    Time 0.330865    
2024-04-04 20:40:49,819 - Epoch: [72][   20/  139]    Overall Loss 0.412406    Objective Loss 0.412406                                        LR 0.000500    Time 0.292625    
2024-04-04 20:40:52,429 - Epoch: [72][   30/  139]    Overall Loss 0.411593    Objective Loss 0.411593                                        LR 0.000500    Time 0.282062    
2024-04-04 20:40:55,030 - Epoch: [72][   40/  139]    Overall Loss 0.412353    Objective Loss 0.412353                                        LR 0.000500    Time 0.276555    
2024-04-04 20:40:57,638 - Epoch: [72][   50/  139]    Overall Loss 0.411934    Objective Loss 0.411934                                        LR 0.000500    Time 0.273395    
2024-04-04 20:41:00,244 - Epoch: [72][   60/  139]    Overall Loss 0.411583    Objective Loss 0.411583                                        LR 0.000500    Time 0.271260    
2024-04-04 20:41:02,840 - Epoch: [72][   70/  139]    Overall Loss 0.411262    Objective Loss 0.411262                                        LR 0.000500    Time 0.269589    
2024-04-04 20:41:05,448 - Epoch: [72][   80/  139]    Overall Loss 0.410719    Objective Loss 0.410719                                        LR 0.000500    Time 0.268481    
2024-04-04 20:41:08,036 - Epoch: [72][   90/  139]    Overall Loss 0.410855    Objective Loss 0.410855                                        LR 0.000500    Time 0.267396    
2024-04-04 20:41:10,637 - Epoch: [72][  100/  139]    Overall Loss 0.410735    Objective Loss 0.410735                                        LR 0.000500    Time 0.266668    
2024-04-04 20:41:13,214 - Epoch: [72][  110/  139]    Overall Loss 0.410739    Objective Loss 0.410739                                        LR 0.000500    Time 0.265847    
2024-04-04 20:41:15,810 - Epoch: [72][  120/  139]    Overall Loss 0.410785    Objective Loss 0.410785                                        LR 0.000500    Time 0.265321    
2024-04-04 20:41:18,411 - Epoch: [72][  130/  139]    Overall Loss 0.410625    Objective Loss 0.410625                                        LR 0.000500    Time 0.264918    
2024-04-04 20:41:24,892 - Epoch: [72][  139/  139]    Overall Loss 0.410409    Objective Loss 0.410409    Top1 96.294308    LR 0.000500    Time 0.294384    
2024-04-04 20:41:25,205 - --- validate (epoch=72)-----------
2024-04-04 20:41:25,206 - 1392 samples (32 per mini-batch)
2024-04-04 20:41:58,570 - Epoch: [72][   10/   44]    Loss 0.484016    Top1 91.655304    
2024-04-04 20:42:30,074 - Epoch: [72][   20/   44]    Loss 0.495251    Top1 91.024827    
2024-04-04 20:43:02,106 - Epoch: [72][   30/   44]    Loss 0.493741    Top1 91.110322    
2024-04-04 20:43:34,646 - Epoch: [72][   40/   44]    Loss 0.493549    Top1 91.130759    
2024-04-04 20:43:46,200 - Epoch: [72][   44/   44]    Loss 0.493470    Top1 91.128057    
2024-04-04 20:43:46,573 - ==> Top1: 91.128    Loss: 0.493

2024-04-04 20:43:46,581 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 20:43:46,581 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:43:46,620 - 

2024-04-04 20:43:46,620 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:43:50,029 - Epoch: [73][   10/  139]    Overall Loss 0.409258    Objective Loss 0.409258                                        LR 0.000500    Time 0.340793    
2024-04-04 20:43:52,606 - Epoch: [73][   20/  139]    Overall Loss 0.410232    Objective Loss 0.410232                                        LR 0.000500    Time 0.299198    
2024-04-04 20:43:55,165 - Epoch: [73][   30/  139]    Overall Loss 0.409571    Objective Loss 0.409571                                        LR 0.000500    Time 0.284764    
2024-04-04 20:43:57,764 - Epoch: [73][   40/  139]    Overall Loss 0.408290    Objective Loss 0.408290                                        LR 0.000500    Time 0.278533    
2024-04-04 20:44:00,345 - Epoch: [73][   50/  139]    Overall Loss 0.408466    Objective Loss 0.408466                                        LR 0.000500    Time 0.274429    
2024-04-04 20:44:02,923 - Epoch: [73][   60/  139]    Overall Loss 0.409381    Objective Loss 0.409381                                        LR 0.000500    Time 0.271652    
2024-04-04 20:44:05,510 - Epoch: [73][   70/  139]    Overall Loss 0.408470    Objective Loss 0.408470                                        LR 0.000500    Time 0.269793    
2024-04-04 20:44:08,089 - Epoch: [73][   80/  139]    Overall Loss 0.408607    Objective Loss 0.408607                                        LR 0.000500    Time 0.268298    
2024-04-04 20:44:10,683 - Epoch: [73][   90/  139]    Overall Loss 0.408378    Objective Loss 0.408378                                        LR 0.000500    Time 0.267308    
2024-04-04 20:44:13,248 - Epoch: [73][  100/  139]    Overall Loss 0.409006    Objective Loss 0.409006                                        LR 0.000500    Time 0.266222    
2024-04-04 20:44:15,847 - Epoch: [73][  110/  139]    Overall Loss 0.408501    Objective Loss 0.408501                                        LR 0.000500    Time 0.265644    
2024-04-04 20:44:18,426 - Epoch: [73][  120/  139]    Overall Loss 0.408459    Objective Loss 0.408459                                        LR 0.000500    Time 0.264991    
2024-04-04 20:44:21,009 - Epoch: [73][  130/  139]    Overall Loss 0.408237    Objective Loss 0.408237                                        LR 0.000500    Time 0.264477    
2024-04-04 20:44:27,559 - Epoch: [73][  139/  139]    Overall Loss 0.408536    Objective Loss 0.408536    Top1 94.909109    LR 0.000500    Time 0.294468    
2024-04-04 20:44:27,819 - --- validate (epoch=73)-----------
2024-04-04 20:44:27,820 - 1392 samples (32 per mini-batch)
2024-04-04 20:44:59,822 - Epoch: [73][   10/   44]    Loss 0.507793    Top1 90.256335    
2024-04-04 20:45:32,116 - Epoch: [73][   20/   44]    Loss 0.495885    Top1 90.993791    
2024-04-04 20:46:04,461 - Epoch: [73][   30/   44]    Loss 0.498580    Top1 90.835884    
2024-04-04 20:46:36,856 - Epoch: [73][   40/   44]    Loss 0.496619    Top1 90.980506    
2024-04-04 20:46:47,811 - Epoch: [73][   44/   44]    Loss 0.498518    Top1 90.895101    
2024-04-04 20:46:48,202 - ==> Top1: 90.895    Loss: 0.499

2024-04-04 20:46:48,210 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 20:46:48,210 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:46:48,246 - 

2024-04-04 20:46:48,246 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:46:51,577 - Epoch: [74][   10/  139]    Overall Loss 0.406747    Objective Loss 0.406747                                        LR 0.000500    Time 0.333028    
2024-04-04 20:46:54,207 - Epoch: [74][   20/  139]    Overall Loss 0.407296    Objective Loss 0.407296                                        LR 0.000500    Time 0.297958    
2024-04-04 20:46:56,823 - Epoch: [74][   30/  139]    Overall Loss 0.407949    Objective Loss 0.407949                                        LR 0.000500    Time 0.285839    
2024-04-04 20:46:59,378 - Epoch: [74][   40/  139]    Overall Loss 0.408476    Objective Loss 0.408476                                        LR 0.000500    Time 0.278244    
2024-04-04 20:47:01,960 - Epoch: [74][   50/  139]    Overall Loss 0.408943    Objective Loss 0.408943                                        LR 0.000500    Time 0.274219    
2024-04-04 20:47:04,600 - Epoch: [74][   60/  139]    Overall Loss 0.408798    Objective Loss 0.408798                                        LR 0.000500    Time 0.272498    
2024-04-04 20:47:07,235 - Epoch: [74][   70/  139]    Overall Loss 0.407782    Objective Loss 0.407782                                        LR 0.000500    Time 0.271203    
2024-04-04 20:47:09,873 - Epoch: [74][   80/  139]    Overall Loss 0.406904    Objective Loss 0.406904                                        LR 0.000500    Time 0.270271    
2024-04-04 20:47:12,494 - Epoch: [74][   90/  139]    Overall Loss 0.406883    Objective Loss 0.406883                                        LR 0.000500    Time 0.269356    
2024-04-04 20:47:15,087 - Epoch: [74][  100/  139]    Overall Loss 0.407222    Objective Loss 0.407222                                        LR 0.000500    Time 0.268346    
2024-04-04 20:47:17,714 - Epoch: [74][  110/  139]    Overall Loss 0.407310    Objective Loss 0.407310                                        LR 0.000500    Time 0.267829    
2024-04-04 20:47:20,361 - Epoch: [74][  120/  139]    Overall Loss 0.407758    Objective Loss 0.407758                                        LR 0.000500    Time 0.267559    
2024-04-04 20:47:23,008 - Epoch: [74][  130/  139]    Overall Loss 0.407579    Objective Loss 0.407579                                        LR 0.000500    Time 0.267337    
2024-04-04 20:47:30,553 - Epoch: [74][  139/  139]    Overall Loss 0.407442    Objective Loss 0.407442    Top1 95.986060    LR 0.000500    Time 0.304302    
2024-04-04 20:47:30,852 - --- validate (epoch=74)-----------
2024-04-04 20:47:30,853 - 1392 samples (32 per mini-batch)
2024-04-04 20:48:05,131 - Epoch: [74][   10/   44]    Loss 0.511896    Top1 90.187459    
2024-04-04 20:48:37,051 - Epoch: [74][   20/   44]    Loss 0.500662    Top1 90.832386    
2024-04-04 20:49:09,440 - Epoch: [74][   30/   44]    Loss 0.500382    Top1 90.867125    
2024-04-04 20:49:40,746 - Epoch: [74][   40/   44]    Loss 0.499091    Top1 90.934340    
2024-04-04 20:49:52,046 - Epoch: [74][   44/   44]    Loss 0.498608    Top1 90.968045    
2024-04-04 20:49:52,407 - ==> Top1: 90.968    Loss: 0.499

2024-04-04 20:49:52,414 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 20:49:52,414 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:49:52,448 - 

2024-04-04 20:49:52,448 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:49:55,803 - Epoch: [75][   10/  139]    Overall Loss 0.406213    Objective Loss 0.406213                                        LR 0.000500    Time 0.335376    
2024-04-04 20:49:58,421 - Epoch: [75][   20/  139]    Overall Loss 0.404289    Objective Loss 0.404289                                        LR 0.000500    Time 0.298577    
2024-04-04 20:50:01,039 - Epoch: [75][   30/  139]    Overall Loss 0.403165    Objective Loss 0.403165                                        LR 0.000500    Time 0.286282    
2024-04-04 20:50:03,659 - Epoch: [75][   40/  139]    Overall Loss 0.408574    Objective Loss 0.408574                                        LR 0.000500    Time 0.280195    
2024-04-04 20:50:06,284 - Epoch: [75][   50/  139]    Overall Loss 0.410569    Objective Loss 0.410569                                        LR 0.000500    Time 0.276654    
2024-04-04 20:50:08,897 - Epoch: [75][   60/  139]    Overall Loss 0.411065    Objective Loss 0.411065                                        LR 0.000500    Time 0.274079    
2024-04-04 20:50:11,474 - Epoch: [75][   70/  139]    Overall Loss 0.411744    Objective Loss 0.411744                                        LR 0.000500    Time 0.271741    
2024-04-04 20:50:14,040 - Epoch: [75][   80/  139]    Overall Loss 0.411012    Objective Loss 0.411012                                        LR 0.000500    Time 0.269842    
2024-04-04 20:50:16,598 - Epoch: [75][   90/  139]    Overall Loss 0.410864    Objective Loss 0.410864                                        LR 0.000500    Time 0.268278    
2024-04-04 20:50:19,140 - Epoch: [75][  100/  139]    Overall Loss 0.410658    Objective Loss 0.410658                                        LR 0.000500    Time 0.266864    
2024-04-04 20:50:21,728 - Epoch: [75][  110/  139]    Overall Loss 0.410077    Objective Loss 0.410077                                        LR 0.000500    Time 0.266122    
2024-04-04 20:50:24,312 - Epoch: [75][  120/  139]    Overall Loss 0.409760    Objective Loss 0.409760                                        LR 0.000500    Time 0.265475    
2024-04-04 20:50:26,899 - Epoch: [75][  130/  139]    Overall Loss 0.409722    Objective Loss 0.409722                                        LR 0.000500    Time 0.264956    
2024-04-04 20:50:34,365 - Epoch: [75][  139/  139]    Overall Loss 0.409546    Objective Loss 0.409546    Top1 96.278589    LR 0.000500    Time 0.301505    
2024-04-04 20:50:34,670 - --- validate (epoch=75)-----------
2024-04-04 20:50:34,671 - 1392 samples (32 per mini-batch)
2024-04-04 20:51:08,074 - Epoch: [75][   10/   44]    Loss 0.498798    Top1 90.821866    
2024-04-04 20:51:40,377 - Epoch: [75][   20/   44]    Loss 0.502298    Top1 90.678715    
2024-04-04 20:52:12,412 - Epoch: [75][   30/   44]    Loss 0.503029    Top1 90.641095    
2024-04-04 20:52:44,612 - Epoch: [75][   40/   44]    Loss 0.502759    Top1 90.663597    
2024-04-04 20:52:55,818 - Epoch: [75][   44/   44]    Loss 0.501163    Top1 90.706146    
2024-04-04 20:52:56,087 - ==> Top1: 90.706    Loss: 0.501

2024-04-04 20:52:56,094 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 20:52:56,094 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:52:56,130 - 

2024-04-04 20:52:56,130 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:52:59,538 - Epoch: [76][   10/  139]    Overall Loss 0.407287    Objective Loss 0.407287                                        LR 0.000500    Time 0.340691    
2024-04-04 20:53:02,162 - Epoch: [76][   20/  139]    Overall Loss 0.405636    Objective Loss 0.405636                                        LR 0.000500    Time 0.301480    
2024-04-04 20:53:04,768 - Epoch: [76][   30/  139]    Overall Loss 0.403508    Objective Loss 0.403508                                        LR 0.000500    Time 0.287842    
2024-04-04 20:53:07,411 - Epoch: [76][   40/  139]    Overall Loss 0.402845    Objective Loss 0.402845                                        LR 0.000500    Time 0.281938    
2024-04-04 20:53:09,992 - Epoch: [76][   50/  139]    Overall Loss 0.404160    Objective Loss 0.404160                                        LR 0.000500    Time 0.277158    
2024-04-04 20:53:12,591 - Epoch: [76][   60/  139]    Overall Loss 0.405423    Objective Loss 0.405423                                        LR 0.000500    Time 0.274270    
2024-04-04 20:53:15,154 - Epoch: [76][   70/  139]    Overall Loss 0.405686    Objective Loss 0.405686                                        LR 0.000500    Time 0.271699    
2024-04-04 20:53:17,765 - Epoch: [76][   80/  139]    Overall Loss 0.405491    Objective Loss 0.405491                                        LR 0.000500    Time 0.270369    
2024-04-04 20:53:20,396 - Epoch: [76][   90/  139]    Overall Loss 0.406104    Objective Loss 0.406104                                        LR 0.000500    Time 0.269555    
2024-04-04 20:53:23,040 - Epoch: [76][  100/  139]    Overall Loss 0.406359    Objective Loss 0.406359                                        LR 0.000500    Time 0.269025    
2024-04-04 20:53:25,687 - Epoch: [76][  110/  139]    Overall Loss 0.406632    Objective Loss 0.406632                                        LR 0.000500    Time 0.268630    
2024-04-04 20:53:28,316 - Epoch: [76][  120/  139]    Overall Loss 0.407182    Objective Loss 0.407182                                        LR 0.000500    Time 0.268143    
2024-04-04 20:53:30,932 - Epoch: [76][  130/  139]    Overall Loss 0.406880    Objective Loss 0.406880                                        LR 0.000500    Time 0.267641    
2024-04-04 20:53:38,466 - Epoch: [76][  139/  139]    Overall Loss 0.407303    Objective Loss 0.407303    Top1 96.057138    LR 0.000500    Time 0.304510    
2024-04-04 20:53:38,726 - --- validate (epoch=76)-----------
2024-04-04 20:53:38,726 - 1392 samples (32 per mini-batch)
2024-04-04 20:54:11,751 - Epoch: [76][   10/   44]    Loss 0.486286    Top1 91.583900    
2024-04-04 20:54:44,881 - Epoch: [76][   20/   44]    Loss 0.488341    Top1 91.484439    
2024-04-04 20:55:16,829 - Epoch: [76][   30/   44]    Loss 0.489754    Top1 91.427243    
2024-04-04 20:55:49,247 - Epoch: [76][   40/   44]    Loss 0.496529    Top1 91.056667    
2024-04-04 20:56:00,330 - Epoch: [76][   44/   44]    Loss 0.497009    Top1 91.037326    
2024-04-04 20:56:00,614 - ==> Top1: 91.037    Loss: 0.497

2024-04-04 20:56:00,620 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 20:56:00,621 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:56:00,656 - 

2024-04-04 20:56:00,656 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:56:03,979 - Epoch: [77][   10/  139]    Overall Loss 0.409573    Objective Loss 0.409573                                        LR 0.000500    Time 0.332212    
2024-04-04 20:56:06,562 - Epoch: [77][   20/  139]    Overall Loss 0.412904    Objective Loss 0.412904                                        LR 0.000500    Time 0.295199    
2024-04-04 20:56:09,161 - Epoch: [77][   30/  139]    Overall Loss 0.412714    Objective Loss 0.412714                                        LR 0.000500    Time 0.283429    
2024-04-04 20:56:11,756 - Epoch: [77][   40/  139]    Overall Loss 0.411276    Objective Loss 0.411276                                        LR 0.000500    Time 0.277443    
2024-04-04 20:56:14,344 - Epoch: [77][   50/  139]    Overall Loss 0.410756    Objective Loss 0.410756                                        LR 0.000500    Time 0.273692    
2024-04-04 20:56:16,936 - Epoch: [77][   60/  139]    Overall Loss 0.409715    Objective Loss 0.409715                                        LR 0.000500    Time 0.271268    
2024-04-04 20:56:19,514 - Epoch: [77][   70/  139]    Overall Loss 0.408561    Objective Loss 0.408561                                        LR 0.000500    Time 0.269341    
2024-04-04 20:56:22,102 - Epoch: [77][   80/  139]    Overall Loss 0.407325    Objective Loss 0.407325                                        LR 0.000500    Time 0.268019    
2024-04-04 20:56:24,661 - Epoch: [77][   90/  139]    Overall Loss 0.407200    Objective Loss 0.407200                                        LR 0.000500    Time 0.266667    
2024-04-04 20:56:27,270 - Epoch: [77][  100/  139]    Overall Loss 0.406933    Objective Loss 0.406933                                        LR 0.000500    Time 0.266090    
2024-04-04 20:56:29,878 - Epoch: [77][  110/  139]    Overall Loss 0.407012    Objective Loss 0.407012                                        LR 0.000500    Time 0.265601    
2024-04-04 20:56:32,478 - Epoch: [77][  120/  139]    Overall Loss 0.406686    Objective Loss 0.406686                                        LR 0.000500    Time 0.265133    
2024-04-04 20:56:35,087 - Epoch: [77][  130/  139]    Overall Loss 0.406860    Objective Loss 0.406860                                        LR 0.000500    Time 0.264800    
2024-04-04 20:56:41,525 - Epoch: [77][  139/  139]    Overall Loss 0.407488    Objective Loss 0.407488    Top1 95.711379    LR 0.000500    Time 0.293968    
2024-04-04 20:56:41,864 - --- validate (epoch=77)-----------
2024-04-04 20:56:41,865 - 1392 samples (32 per mini-batch)
2024-04-04 20:57:15,320 - Epoch: [77][   10/   44]    Loss 0.520628    Top1 89.681402    
2024-04-04 20:57:47,477 - Epoch: [77][   20/   44]    Loss 0.516688    Top1 89.882203    
2024-04-04 20:58:20,015 - Epoch: [77][   30/   44]    Loss 0.510809    Top1 90.200894    
2024-04-04 20:58:52,517 - Epoch: [77][   40/   44]    Loss 0.511166    Top1 90.177533    
2024-04-04 20:59:03,657 - Epoch: [77][   44/   44]    Loss 0.512226    Top1 90.138422    
2024-04-04 20:59:03,897 - ==> Top1: 90.138    Loss: 0.512

2024-04-04 20:59:03,904 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 20:59:03,905 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 20:59:03,939 - 

2024-04-04 20:59:03,939 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 20:59:07,231 - Epoch: [78][   10/  139]    Overall Loss 0.406227    Objective Loss 0.406227                                        LR 0.000500    Time 0.329016    
2024-04-04 20:59:09,811 - Epoch: [78][   20/  139]    Overall Loss 0.403877    Objective Loss 0.403877                                        LR 0.000500    Time 0.293506    
2024-04-04 20:59:12,400 - Epoch: [78][   30/  139]    Overall Loss 0.402962    Objective Loss 0.402962                                        LR 0.000500    Time 0.281947    
2024-04-04 20:59:14,965 - Epoch: [78][   40/  139]    Overall Loss 0.405025    Objective Loss 0.405025                                        LR 0.000500    Time 0.275575    
2024-04-04 20:59:17,558 - Epoch: [78][   50/  139]    Overall Loss 0.404496    Objective Loss 0.404496                                        LR 0.000500    Time 0.272304    
2024-04-04 20:59:20,202 - Epoch: [78][   60/  139]    Overall Loss 0.404266    Objective Loss 0.404266                                        LR 0.000500    Time 0.270988    
2024-04-04 20:59:22,842 - Epoch: [78][   70/  139]    Overall Loss 0.404848    Objective Loss 0.404848                                        LR 0.000500    Time 0.269983    
2024-04-04 20:59:25,466 - Epoch: [78][   80/  139]    Overall Loss 0.405379    Objective Loss 0.405379                                        LR 0.000500    Time 0.269019    
2024-04-04 20:59:28,112 - Epoch: [78][   90/  139]    Overall Loss 0.405675    Objective Loss 0.405675                                        LR 0.000500    Time 0.268521    
2024-04-04 20:59:30,752 - Epoch: [78][  100/  139]    Overall Loss 0.405701    Objective Loss 0.405701                                        LR 0.000500    Time 0.268070    
2024-04-04 20:59:33,385 - Epoch: [78][  110/  139]    Overall Loss 0.406592    Objective Loss 0.406592                                        LR 0.000500    Time 0.267628    
2024-04-04 20:59:35,998 - Epoch: [78][  120/  139]    Overall Loss 0.407910    Objective Loss 0.407910                                        LR 0.000500    Time 0.267093    
2024-04-04 20:59:38,645 - Epoch: [78][  130/  139]    Overall Loss 0.408551    Objective Loss 0.408551                                        LR 0.000500    Time 0.266904    
2024-04-04 20:59:45,602 - Epoch: [78][  139/  139]    Overall Loss 0.408792    Objective Loss 0.408792    Top1 95.976137    LR 0.000500    Time 0.299672    
2024-04-04 20:59:45,912 - --- validate (epoch=78)-----------
2024-04-04 20:59:45,913 - 1392 samples (32 per mini-batch)
2024-04-04 21:00:18,969 - Epoch: [78][   10/   44]    Loss 0.507313    Top1 90.204783    
2024-04-04 21:00:50,574 - Epoch: [78][   20/   44]    Loss 0.505125    Top1 90.334806    
2024-04-04 21:01:23,290 - Epoch: [78][   30/   44]    Loss 0.502348    Top1 90.519266    
2024-04-04 21:01:55,219 - Epoch: [78][   40/   44]    Loss 0.504883    Top1 90.341193    
2024-04-04 21:02:06,873 - Epoch: [78][   44/   44]    Loss 0.504638    Top1 90.317561    
2024-04-04 21:02:07,248 - ==> Top1: 90.318    Loss: 0.505

2024-04-04 21:02:07,255 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:02:07,255 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:02:07,291 - 

2024-04-04 21:02:07,291 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:02:10,739 - Epoch: [79][   10/  139]    Overall Loss 0.407154    Objective Loss 0.407154                                        LR 0.000500    Time 0.344677    
2024-04-04 21:02:13,366 - Epoch: [79][   20/  139]    Overall Loss 0.405675    Objective Loss 0.405675                                        LR 0.000500    Time 0.303629    
2024-04-04 21:02:16,001 - Epoch: [79][   30/  139]    Overall Loss 0.404844    Objective Loss 0.404844                                        LR 0.000500    Time 0.290271    
2024-04-04 21:02:18,637 - Epoch: [79][   40/  139]    Overall Loss 0.404297    Objective Loss 0.404297                                        LR 0.000500    Time 0.283581    
2024-04-04 21:02:21,295 - Epoch: [79][   50/  139]    Overall Loss 0.404877    Objective Loss 0.404877                                        LR 0.000500    Time 0.280019    
2024-04-04 21:02:23,882 - Epoch: [79][   60/  139]    Overall Loss 0.405779    Objective Loss 0.405779                                        LR 0.000500    Time 0.276455    
2024-04-04 21:02:26,474 - Epoch: [79][   70/  139]    Overall Loss 0.405256    Objective Loss 0.405256                                        LR 0.000500    Time 0.273991    
2024-04-04 21:02:29,050 - Epoch: [79][   80/  139]    Overall Loss 0.405116    Objective Loss 0.405116                                        LR 0.000500    Time 0.271925    
2024-04-04 21:02:31,631 - Epoch: [79][   90/  139]    Overall Loss 0.405519    Objective Loss 0.405519                                        LR 0.000500    Time 0.270383    
2024-04-04 21:02:34,157 - Epoch: [79][  100/  139]    Overall Loss 0.405406    Objective Loss 0.405406                                        LR 0.000500    Time 0.268598    
2024-04-04 21:02:36,746 - Epoch: [79][  110/  139]    Overall Loss 0.405419    Objective Loss 0.405419                                        LR 0.000500    Time 0.267715    
2024-04-04 21:02:39,316 - Epoch: [79][  120/  139]    Overall Loss 0.405724    Objective Loss 0.405724                                        LR 0.000500    Time 0.266822    
2024-04-04 21:02:41,925 - Epoch: [79][  130/  139]    Overall Loss 0.405988    Objective Loss 0.405988                                        LR 0.000500    Time 0.266357    
2024-04-04 21:02:48,808 - Epoch: [79][  139/  139]    Overall Loss 0.405554    Objective Loss 0.405554    Top1 96.183225    LR 0.000500    Time 0.298632    
2024-04-04 21:02:49,179 - --- validate (epoch=79)-----------
2024-04-04 21:02:49,180 - 1392 samples (32 per mini-batch)
2024-04-04 21:03:21,928 - Epoch: [79][   10/   44]    Loss 0.502346    Top1 90.727375    
2024-04-04 21:03:52,912 - Epoch: [79][   20/   44]    Loss 0.504550    Top1 90.614693    
2024-04-04 21:04:26,072 - Epoch: [79][   30/   44]    Loss 0.508360    Top1 90.400673    
2024-04-04 21:04:58,030 - Epoch: [79][   40/   44]    Loss 0.502202    Top1 90.736394    
2024-04-04 21:05:09,411 - Epoch: [79][   44/   44]    Loss 0.500147    Top1 90.850051    
2024-04-04 21:05:09,802 - ==> Top1: 90.850    Loss: 0.500

2024-04-04 21:05:09,810 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:05:09,810 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:05:09,846 - 

2024-04-04 21:05:09,846 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:05:13,148 - Epoch: [80][   10/  139]    Overall Loss 0.403477    Objective Loss 0.403477                                        LR 0.000500    Time 0.330029    
2024-04-04 21:05:15,727 - Epoch: [80][   20/  139]    Overall Loss 0.408116    Objective Loss 0.408116                                        LR 0.000500    Time 0.293936    
2024-04-04 21:05:18,321 - Epoch: [80][   30/  139]    Overall Loss 0.406720    Objective Loss 0.406720                                        LR 0.000500    Time 0.282421    
2024-04-04 21:05:20,881 - Epoch: [80][   40/  139]    Overall Loss 0.404932    Objective Loss 0.404932                                        LR 0.000500    Time 0.275789    
2024-04-04 21:05:23,436 - Epoch: [80][   50/  139]    Overall Loss 0.402885    Objective Loss 0.402885                                        LR 0.000500    Time 0.271728    
2024-04-04 21:05:26,050 - Epoch: [80][   60/  139]    Overall Loss 0.401830    Objective Loss 0.401830                                        LR 0.000500    Time 0.270002    
2024-04-04 21:05:28,673 - Epoch: [80][   70/  139]    Overall Loss 0.401668    Objective Loss 0.401668                                        LR 0.000500    Time 0.268887    
2024-04-04 21:05:31,285 - Epoch: [80][   80/  139]    Overall Loss 0.401705    Objective Loss 0.401705                                        LR 0.000500    Time 0.267918    
2024-04-04 21:05:33,916 - Epoch: [80][   90/  139]    Overall Loss 0.402104    Objective Loss 0.402104                                        LR 0.000500    Time 0.267383    
2024-04-04 21:05:36,536 - Epoch: [80][  100/  139]    Overall Loss 0.402019    Objective Loss 0.402019                                        LR 0.000500    Time 0.266833    
2024-04-04 21:05:39,171 - Epoch: [80][  110/  139]    Overall Loss 0.402955    Objective Loss 0.402955                                        LR 0.000500    Time 0.266531    
2024-04-04 21:05:41,775 - Epoch: [80][  120/  139]    Overall Loss 0.403217    Objective Loss 0.403217                                        LR 0.000500    Time 0.266010    
2024-04-04 21:05:44,384 - Epoch: [80][  130/  139]    Overall Loss 0.403705    Objective Loss 0.403705                                        LR 0.000500    Time 0.265615    
2024-04-04 21:05:51,496 - Epoch: [80][  139/  139]    Overall Loss 0.404464    Objective Loss 0.404464    Top1 95.559300    LR 0.000500    Time 0.299577    
2024-04-04 21:05:51,806 - --- validate (epoch=80)-----------
2024-04-04 21:05:51,807 - 1392 samples (32 per mini-batch)
2024-04-04 21:06:24,806 - Epoch: [80][   10/   44]    Loss 0.519414    Top1 89.485247    
2024-04-04 21:06:56,700 - Epoch: [80][   20/   44]    Loss 0.507557    Top1 90.181179    
2024-04-04 21:07:28,807 - Epoch: [80][   30/   44]    Loss 0.511255    Top1 89.956849    
2024-04-04 21:08:01,267 - Epoch: [80][   40/   44]    Loss 0.510806    Top1 89.987297    
2024-04-04 21:08:12,252 - Epoch: [80][   44/   44]    Loss 0.510801    Top1 89.974068    
2024-04-04 21:08:12,528 - ==> Top1: 89.974    Loss: 0.511

2024-04-04 21:08:12,535 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:08:12,535 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:08:12,570 - 

2024-04-04 21:08:12,570 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:08:16,066 - Epoch: [81][   10/  139]    Overall Loss 0.404753    Objective Loss 0.404753                                        LR 0.000500    Time 0.349494    
2024-04-04 21:08:18,636 - Epoch: [81][   20/  139]    Overall Loss 0.407408    Objective Loss 0.407408                                        LR 0.000500    Time 0.303214    
2024-04-04 21:08:21,230 - Epoch: [81][   30/  139]    Overall Loss 0.406380    Objective Loss 0.406380                                        LR 0.000500    Time 0.288573    
2024-04-04 21:08:23,805 - Epoch: [81][   40/  139]    Overall Loss 0.407834    Objective Loss 0.407834                                        LR 0.000500    Time 0.280813    
2024-04-04 21:08:26,368 - Epoch: [81][   50/  139]    Overall Loss 0.407916    Objective Loss 0.407916                                        LR 0.000500    Time 0.275890    
2024-04-04 21:08:29,007 - Epoch: [81][   60/  139]    Overall Loss 0.408801    Objective Loss 0.408801                                        LR 0.000500    Time 0.273886    
2024-04-04 21:08:31,671 - Epoch: [81][   70/  139]    Overall Loss 0.410530    Objective Loss 0.410530                                        LR 0.000500    Time 0.272806    
2024-04-04 21:08:34,313 - Epoch: [81][   80/  139]    Overall Loss 0.411581    Objective Loss 0.411581                                        LR 0.000500    Time 0.271724    
2024-04-04 21:08:36,943 - Epoch: [81][   90/  139]    Overall Loss 0.411883    Objective Loss 0.411883                                        LR 0.000500    Time 0.270742    
2024-04-04 21:08:39,585 - Epoch: [81][  100/  139]    Overall Loss 0.411438    Objective Loss 0.411438                                        LR 0.000500    Time 0.270083    
2024-04-04 21:08:42,192 - Epoch: [81][  110/  139]    Overall Loss 0.411185    Objective Loss 0.411185                                        LR 0.000500    Time 0.269222    
2024-04-04 21:08:44,775 - Epoch: [81][  120/  139]    Overall Loss 0.410691    Objective Loss 0.410691                                        LR 0.000500    Time 0.268308    
2024-04-04 21:08:47,420 - Epoch: [81][  130/  139]    Overall Loss 0.410180    Objective Loss 0.410180                                        LR 0.000500    Time 0.268010    
2024-04-04 21:08:54,897 - Epoch: [81][  139/  139]    Overall Loss 0.409677    Objective Loss 0.409677    Top1 96.311807    LR 0.000500    Time 0.304447    
2024-04-04 21:08:55,152 - --- validate (epoch=81)-----------
2024-04-04 21:08:55,152 - 1392 samples (32 per mini-batch)
2024-04-04 21:09:28,255 - Epoch: [81][   10/   44]    Loss 0.505065    Top1 90.565824    
2024-04-04 21:09:59,645 - Epoch: [81][   20/   44]    Loss 0.518237    Top1 89.856735    
2024-04-04 21:10:31,720 - Epoch: [81][   30/   44]    Loss 0.516981    Top1 89.879076    
2024-04-04 21:11:03,701 - Epoch: [81][   40/   44]    Loss 0.514931    Top1 89.975211    
2024-04-04 21:11:15,050 - Epoch: [81][   44/   44]    Loss 0.515188    Top1 89.984286    
2024-04-04 21:11:15,327 - ==> Top1: 89.984    Loss: 0.515

2024-04-04 21:11:15,335 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:11:15,335 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:11:15,370 - 

2024-04-04 21:11:15,370 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:11:18,710 - Epoch: [82][   10/  139]    Overall Loss 0.407197    Objective Loss 0.407197                                        LR 0.000500    Time 0.333867    
2024-04-04 21:11:21,337 - Epoch: [82][   20/  139]    Overall Loss 0.405720    Objective Loss 0.405720                                        LR 0.000500    Time 0.298233    
2024-04-04 21:11:23,963 - Epoch: [82][   30/  139]    Overall Loss 0.403946    Objective Loss 0.403946                                        LR 0.000500    Time 0.286341    
2024-04-04 21:11:26,577 - Epoch: [82][   40/  139]    Overall Loss 0.404097    Objective Loss 0.404097                                        LR 0.000500    Time 0.280087    
2024-04-04 21:11:29,184 - Epoch: [82][   50/  139]    Overall Loss 0.403983    Objective Loss 0.403983                                        LR 0.000500    Time 0.276196    
2024-04-04 21:11:31,817 - Epoch: [82][   60/  139]    Overall Loss 0.405321    Objective Loss 0.405321                                        LR 0.000500    Time 0.274036    
2024-04-04 21:11:34,432 - Epoch: [82][   70/  139]    Overall Loss 0.405772    Objective Loss 0.405772                                        LR 0.000500    Time 0.272243    
2024-04-04 21:11:37,061 - Epoch: [82][   80/  139]    Overall Loss 0.405600    Objective Loss 0.405600                                        LR 0.000500    Time 0.271076    
2024-04-04 21:11:39,705 - Epoch: [82][   90/  139]    Overall Loss 0.406012    Objective Loss 0.406012                                        LR 0.000500    Time 0.270322    
2024-04-04 21:11:42,293 - Epoch: [82][  100/  139]    Overall Loss 0.405343    Objective Loss 0.405343                                        LR 0.000500    Time 0.269164    
2024-04-04 21:11:44,931 - Epoch: [82][  110/  139]    Overall Loss 0.405491    Objective Loss 0.405491                                        LR 0.000500    Time 0.268678    
2024-04-04 21:11:47,588 - Epoch: [82][  120/  139]    Overall Loss 0.404981    Objective Loss 0.404981                                        LR 0.000500    Time 0.268425    
2024-04-04 21:11:50,240 - Epoch: [82][  130/  139]    Overall Loss 0.405150    Objective Loss 0.405150                                        LR 0.000500    Time 0.268169    
2024-04-04 21:11:57,758 - Epoch: [82][  139/  139]    Overall Loss 0.405061    Objective Loss 0.405061    Top1 95.501759    LR 0.000500    Time 0.304888    
2024-04-04 21:11:58,116 - --- validate (epoch=82)-----------
2024-04-04 21:11:58,117 - 1392 samples (32 per mini-batch)
2024-04-04 21:12:31,541 - Epoch: [82][   10/   44]    Loss 0.517017    Top1 89.806718    
2024-04-04 21:13:03,918 - Epoch: [82][   20/   44]    Loss 0.504811    Top1 90.476716    
2024-04-04 21:13:35,980 - Epoch: [82][   30/   44]    Loss 0.500267    Top1 90.750263    
2024-04-04 21:14:09,484 - Epoch: [82][   40/   44]    Loss 0.499606    Top1 90.784665    
2024-04-04 21:14:20,795 - Epoch: [82][   44/   44]    Loss 0.498888    Top1 90.793894    
2024-04-04 21:14:21,048 - ==> Top1: 90.794    Loss: 0.499

2024-04-04 21:14:21,055 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:14:21,055 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:14:21,092 - 

2024-04-04 21:14:21,092 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:14:24,529 - Epoch: [83][   10/  139]    Overall Loss 0.407680    Objective Loss 0.407680                                        LR 0.000500    Time 0.343562    
2024-04-04 21:14:27,122 - Epoch: [83][   20/  139]    Overall Loss 0.405661    Objective Loss 0.405661                                        LR 0.000500    Time 0.301403    
2024-04-04 21:14:29,760 - Epoch: [83][   30/  139]    Overall Loss 0.403729    Objective Loss 0.403729                                        LR 0.000500    Time 0.288838    
2024-04-04 21:14:32,372 - Epoch: [83][   40/  139]    Overall Loss 0.404092    Objective Loss 0.404092                                        LR 0.000500    Time 0.281923    
2024-04-04 21:14:34,991 - Epoch: [83][   50/  139]    Overall Loss 0.403004    Objective Loss 0.403004                                        LR 0.000500    Time 0.277923    
2024-04-04 21:14:37,592 - Epoch: [83][   60/  139]    Overall Loss 0.403300    Objective Loss 0.403300                                        LR 0.000500    Time 0.274934    
2024-04-04 21:14:40,214 - Epoch: [83][   70/  139]    Overall Loss 0.402828    Objective Loss 0.402828                                        LR 0.000500    Time 0.273112    
2024-04-04 21:14:42,809 - Epoch: [83][   80/  139]    Overall Loss 0.403110    Objective Loss 0.403110                                        LR 0.000500    Time 0.271397    
2024-04-04 21:14:45,424 - Epoch: [83][   90/  139]    Overall Loss 0.402869    Objective Loss 0.402869                                        LR 0.000500    Time 0.270290    
2024-04-04 21:14:48,040 - Epoch: [83][  100/  139]    Overall Loss 0.402613    Objective Loss 0.402613                                        LR 0.000500    Time 0.269417    
2024-04-04 21:14:50,646 - Epoch: [83][  110/  139]    Overall Loss 0.402881    Objective Loss 0.402881                                        LR 0.000500    Time 0.268611    
2024-04-04 21:14:53,247 - Epoch: [83][  120/  139]    Overall Loss 0.402632    Objective Loss 0.402632                                        LR 0.000500    Time 0.267899    
2024-04-04 21:14:55,885 - Epoch: [83][  130/  139]    Overall Loss 0.402401    Objective Loss 0.402401                                        LR 0.000500    Time 0.267577    
2024-04-04 21:15:02,813 - Epoch: [83][  139/  139]    Overall Loss 0.402170    Objective Loss 0.402170    Top1 96.790624    LR 0.000500    Time 0.300090    
2024-04-04 21:15:03,197 - --- validate (epoch=83)-----------
2024-04-04 21:15:03,198 - 1392 samples (32 per mini-batch)
2024-04-04 21:15:36,049 - Epoch: [83][   10/   44]    Loss 0.510096    Top1 90.197784    
2024-04-04 21:16:07,716 - Epoch: [83][   20/   44]    Loss 0.505109    Top1 90.484388    
2024-04-04 21:16:39,171 - Epoch: [83][   30/   44]    Loss 0.504751    Top1 90.525071    
2024-04-04 21:17:11,397 - Epoch: [83][   40/   44]    Loss 0.503838    Top1 90.575744    
2024-04-04 21:17:22,697 - Epoch: [83][   44/   44]    Loss 0.503837    Top1 90.611601    
2024-04-04 21:17:23,009 - ==> Top1: 90.612    Loss: 0.504

2024-04-04 21:17:23,016 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:17:23,016 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:17:23,051 - 

2024-04-04 21:17:23,051 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:17:26,370 - Epoch: [84][   10/  139]    Overall Loss 0.396266    Objective Loss 0.396266                                        LR 0.000500    Time 0.331751    
2024-04-04 21:17:28,952 - Epoch: [84][   20/  139]    Overall Loss 0.400522    Objective Loss 0.400522                                        LR 0.000500    Time 0.294983    
2024-04-04 21:17:31,523 - Epoch: [84][   30/  139]    Overall Loss 0.400566    Objective Loss 0.400566                                        LR 0.000500    Time 0.282314    
2024-04-04 21:17:34,124 - Epoch: [84][   40/  139]    Overall Loss 0.400788    Objective Loss 0.400788                                        LR 0.000500    Time 0.276747    
2024-04-04 21:17:36,716 - Epoch: [84][   50/  139]    Overall Loss 0.401632    Objective Loss 0.401632                                        LR 0.000500    Time 0.273238    
2024-04-04 21:17:39,297 - Epoch: [84][   60/  139]    Overall Loss 0.402431    Objective Loss 0.402431                                        LR 0.000500    Time 0.270699    
2024-04-04 21:17:41,895 - Epoch: [84][   70/  139]    Overall Loss 0.402756    Objective Loss 0.402756                                        LR 0.000500    Time 0.269143    
2024-04-04 21:17:44,519 - Epoch: [84][   80/  139]    Overall Loss 0.403075    Objective Loss 0.403075                                        LR 0.000500    Time 0.268294    
2024-04-04 21:17:47,092 - Epoch: [84][   90/  139]    Overall Loss 0.403417    Objective Loss 0.403417                                        LR 0.000500    Time 0.267060    
2024-04-04 21:17:49,737 - Epoch: [84][  100/  139]    Overall Loss 0.404025    Objective Loss 0.404025                                        LR 0.000500    Time 0.266804    
2024-04-04 21:17:52,356 - Epoch: [84][  110/  139]    Overall Loss 0.404263    Objective Loss 0.404263                                        LR 0.000500    Time 0.266349    
2024-04-04 21:17:54,983 - Epoch: [84][  120/  139]    Overall Loss 0.404235    Objective Loss 0.404235                                        LR 0.000500    Time 0.266044    
2024-04-04 21:17:57,632 - Epoch: [84][  130/  139]    Overall Loss 0.404280    Objective Loss 0.404280                                        LR 0.000500    Time 0.265953    
2024-04-04 21:18:04,153 - Epoch: [84][  139/  139]    Overall Loss 0.404610    Objective Loss 0.404610    Top1 95.733684    LR 0.000500    Time 0.295646    
2024-04-04 21:18:04,510 - --- validate (epoch=84)-----------
2024-04-04 21:18:04,511 - 1392 samples (32 per mini-batch)
2024-04-04 21:18:37,269 - Epoch: [84][   10/   44]    Loss 0.514775    Top1 90.051378    
2024-04-04 21:19:08,779 - Epoch: [84][   20/   44]    Loss 0.518504    Top1 89.844718    
2024-04-04 21:19:41,395 - Epoch: [84][   30/   44]    Loss 0.516747    Top1 89.935079    
2024-04-04 21:20:13,844 - Epoch: [84][   40/   44]    Loss 0.511016    Top1 90.237289    
2024-04-04 21:20:24,710 - Epoch: [84][   44/   44]    Loss 0.509910    Top1 90.273896    
2024-04-04 21:20:24,946 - ==> Top1: 90.274    Loss: 0.510

2024-04-04 21:20:24,953 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:20:24,953 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:20:24,988 - 

2024-04-04 21:20:24,988 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:20:28,275 - Epoch: [85][   10/  139]    Overall Loss 0.400578    Objective Loss 0.400578                                        LR 0.000500    Time 0.328616    
2024-04-04 21:20:30,872 - Epoch: [85][   20/  139]    Overall Loss 0.404662    Objective Loss 0.404662                                        LR 0.000500    Time 0.294123    
2024-04-04 21:20:33,469 - Epoch: [85][   30/  139]    Overall Loss 0.402551    Objective Loss 0.402551                                        LR 0.000500    Time 0.282614    
2024-04-04 21:20:36,066 - Epoch: [85][   40/  139]    Overall Loss 0.403602    Objective Loss 0.403602                                        LR 0.000500    Time 0.276883    
2024-04-04 21:20:38,642 - Epoch: [85][   50/  139]    Overall Loss 0.404459    Objective Loss 0.404459                                        LR 0.000500    Time 0.273020    
2024-04-04 21:20:41,223 - Epoch: [85][   60/  139]    Overall Loss 0.403660    Objective Loss 0.403660                                        LR 0.000500    Time 0.270525    
2024-04-04 21:20:43,872 - Epoch: [85][   70/  139]    Overall Loss 0.404150    Objective Loss 0.404150                                        LR 0.000500    Time 0.269711    
2024-04-04 21:20:46,498 - Epoch: [85][   80/  139]    Overall Loss 0.404015    Objective Loss 0.404015                                        LR 0.000500    Time 0.268813    
2024-04-04 21:20:49,131 - Epoch: [85][   90/  139]    Overall Loss 0.403725    Objective Loss 0.403725                                        LR 0.000500    Time 0.268199    
2024-04-04 21:20:51,775 - Epoch: [85][  100/  139]    Overall Loss 0.403452    Objective Loss 0.403452                                        LR 0.000500    Time 0.267816    
2024-04-04 21:20:54,422 - Epoch: [85][  110/  139]    Overall Loss 0.403691    Objective Loss 0.403691                                        LR 0.000500    Time 0.267523    
2024-04-04 21:20:57,063 - Epoch: [85][  120/  139]    Overall Loss 0.403694    Objective Loss 0.403694                                        LR 0.000500    Time 0.267235    
2024-04-04 21:20:59,683 - Epoch: [85][  130/  139]    Overall Loss 0.403254    Objective Loss 0.403254                                        LR 0.000500    Time 0.266830    
2024-04-04 21:21:06,498 - Epoch: [85][  139/  139]    Overall Loss 0.403332    Objective Loss 0.403332    Top1 96.483403    LR 0.000500    Time 0.298578    
2024-04-04 21:21:06,807 - --- validate (epoch=85)-----------
2024-04-04 21:21:06,808 - 1392 samples (32 per mini-batch)
2024-04-04 21:21:40,632 - Epoch: [85][   10/   44]    Loss 0.500005    Top1 90.831324    
2024-04-04 21:22:12,722 - Epoch: [85][   20/   44]    Loss 0.505952    Top1 90.509628    
2024-04-04 21:22:44,471 - Epoch: [85][   30/   44]    Loss 0.500983    Top1 90.788591    
2024-04-04 21:23:16,662 - Epoch: [85][   40/   44]    Loss 0.499660    Top1 90.862076    
2024-04-04 21:23:28,187 - Epoch: [85][   44/   44]    Loss 0.498444    Top1 90.928479    
2024-04-04 21:23:28,433 - ==> Top1: 90.928    Loss: 0.498

2024-04-04 21:23:28,439 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:23:28,440 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:23:28,474 - 

2024-04-04 21:23:28,474 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:23:31,789 - Epoch: [86][   10/  139]    Overall Loss 0.403869    Objective Loss 0.403869                                        LR 0.000500    Time 0.331299    
2024-04-04 21:23:34,399 - Epoch: [86][   20/  139]    Overall Loss 0.404869    Objective Loss 0.404869                                        LR 0.000500    Time 0.296133    
2024-04-04 21:23:36,996 - Epoch: [86][   30/  139]    Overall Loss 0.404267    Objective Loss 0.404267                                        LR 0.000500    Time 0.283986    
2024-04-04 21:23:39,584 - Epoch: [86][   40/  139]    Overall Loss 0.403545    Objective Loss 0.403545                                        LR 0.000500    Time 0.277687    
2024-04-04 21:23:42,187 - Epoch: [86][   50/  139]    Overall Loss 0.404032    Objective Loss 0.404032                                        LR 0.000500    Time 0.274205    
2024-04-04 21:23:44,790 - Epoch: [86][   60/  139]    Overall Loss 0.403786    Objective Loss 0.403786                                        LR 0.000500    Time 0.271883    
2024-04-04 21:23:47,399 - Epoch: [86][   70/  139]    Overall Loss 0.402994    Objective Loss 0.402994                                        LR 0.000500    Time 0.270309    
2024-04-04 21:23:50,013 - Epoch: [86][   80/  139]    Overall Loss 0.403741    Objective Loss 0.403741                                        LR 0.000500    Time 0.269193    
2024-04-04 21:23:52,685 - Epoch: [86][   90/  139]    Overall Loss 0.403895    Objective Loss 0.403895                                        LR 0.000500    Time 0.268965    
2024-04-04 21:23:55,338 - Epoch: [86][  100/  139]    Overall Loss 0.403910    Objective Loss 0.403910                                        LR 0.000500    Time 0.268588    
2024-04-04 21:23:57,973 - Epoch: [86][  110/  139]    Overall Loss 0.404540    Objective Loss 0.404540                                        LR 0.000500    Time 0.268119    
2024-04-04 21:24:00,597 - Epoch: [86][  120/  139]    Overall Loss 0.405079    Objective Loss 0.405079                                        LR 0.000500    Time 0.267644    
2024-04-04 21:24:03,247 - Epoch: [86][  130/  139]    Overall Loss 0.405458    Objective Loss 0.405458                                        LR 0.000500    Time 0.267436    
2024-04-04 21:24:10,510 - Epoch: [86][  139/  139]    Overall Loss 0.405195    Objective Loss 0.405195    Top1 96.675964    LR 0.000500    Time 0.302367    
2024-04-04 21:24:10,903 - --- validate (epoch=86)-----------
2024-04-04 21:24:10,904 - 1392 samples (32 per mini-batch)
2024-04-04 21:24:44,304 - Epoch: [86][   10/   44]    Loss 0.512361    Top1 90.278880    
2024-04-04 21:25:17,449 - Epoch: [86][   20/   44]    Loss 0.502887    Top1 90.768424    
2024-04-04 21:25:49,730 - Epoch: [86][   30/   44]    Loss 0.504573    Top1 90.661634    
2024-04-04 21:26:21,794 - Epoch: [86][   40/   44]    Loss 0.502862    Top1 90.741767    
2024-04-04 21:26:32,608 - Epoch: [86][   44/   44]    Loss 0.503674    Top1 90.670818    
2024-04-04 21:26:32,998 - ==> Top1: 90.671    Loss: 0.504

2024-04-04 21:26:33,005 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:26:33,005 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:26:33,041 - 

2024-04-04 21:26:33,041 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:26:36,455 - Epoch: [87][   10/  139]    Overall Loss 0.408583    Objective Loss 0.408583                                        LR 0.000500    Time 0.341329    
2024-04-04 21:26:39,079 - Epoch: [87][   20/  139]    Overall Loss 0.408425    Objective Loss 0.408425                                        LR 0.000500    Time 0.301826    
2024-04-04 21:26:41,691 - Epoch: [87][   30/  139]    Overall Loss 0.406589    Objective Loss 0.406589                                        LR 0.000500    Time 0.288259    
2024-04-04 21:26:44,319 - Epoch: [87][   40/  139]    Overall Loss 0.406066    Objective Loss 0.406066                                        LR 0.000500    Time 0.281870    
2024-04-04 21:26:46,890 - Epoch: [87][   50/  139]    Overall Loss 0.405575    Objective Loss 0.405575                                        LR 0.000500    Time 0.276924    
2024-04-04 21:26:49,474 - Epoch: [87][   60/  139]    Overall Loss 0.405243    Objective Loss 0.405243                                        LR 0.000500    Time 0.273819    
2024-04-04 21:26:52,047 - Epoch: [87][   70/  139]    Overall Loss 0.405024    Objective Loss 0.405024                                        LR 0.000500    Time 0.271456    
2024-04-04 21:26:54,648 - Epoch: [87][   80/  139]    Overall Loss 0.404972    Objective Loss 0.404972                                        LR 0.000500    Time 0.270027    
2024-04-04 21:26:57,279 - Epoch: [87][   90/  139]    Overall Loss 0.404239    Objective Loss 0.404239                                        LR 0.000500    Time 0.269255    
2024-04-04 21:26:59,895 - Epoch: [87][  100/  139]    Overall Loss 0.403344    Objective Loss 0.403344                                        LR 0.000500    Time 0.268482    
2024-04-04 21:27:02,518 - Epoch: [87][  110/  139]    Overall Loss 0.403501    Objective Loss 0.403501                                        LR 0.000500    Time 0.267917    
2024-04-04 21:27:05,156 - Epoch: [87][  120/  139]    Overall Loss 0.403914    Objective Loss 0.403914                                        LR 0.000500    Time 0.267567    
2024-04-04 21:27:07,758 - Epoch: [87][  130/  139]    Overall Loss 0.404506    Objective Loss 0.404506                                        LR 0.000500    Time 0.266999    
2024-04-04 21:27:15,016 - Epoch: [87][  139/  139]    Overall Loss 0.404142    Objective Loss 0.404142    Top1 96.657383    LR 0.000500    Time 0.301921    
2024-04-04 21:27:15,227 - --- validate (epoch=87)-----------
2024-04-04 21:27:15,228 - 1392 samples (32 per mini-batch)
2024-04-04 21:27:47,080 - Epoch: [87][   10/   44]    Loss 0.528637    Top1 89.230922    
2024-04-04 21:28:19,834 - Epoch: [87][   20/   44]    Loss 0.528035    Top1 89.290058    
2024-04-04 21:28:52,619 - Epoch: [87][   30/   44]    Loss 0.529765    Top1 89.199361    
2024-04-04 21:29:25,139 - Epoch: [87][   40/   44]    Loss 0.526678    Top1 89.354714    
2024-04-04 21:29:36,734 - Epoch: [87][   44/   44]    Loss 0.525625    Top1 89.397735    
2024-04-04 21:29:36,984 - ==> Top1: 89.398    Loss: 0.526

2024-04-04 21:29:36,991 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:29:36,991 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:29:37,026 - 

2024-04-04 21:29:37,026 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:29:40,328 - Epoch: [88][   10/  139]    Overall Loss 0.402490    Objective Loss 0.402490                                        LR 0.000500    Time 0.330034    
2024-04-04 21:29:42,865 - Epoch: [88][   20/  139]    Overall Loss 0.402090    Objective Loss 0.402090                                        LR 0.000500    Time 0.291844    
2024-04-04 21:29:45,493 - Epoch: [88][   30/  139]    Overall Loss 0.401413    Objective Loss 0.401413                                        LR 0.000500    Time 0.282143    
2024-04-04 21:29:48,127 - Epoch: [88][   40/  139]    Overall Loss 0.400702    Objective Loss 0.400702                                        LR 0.000500    Time 0.277440    
2024-04-04 21:29:50,744 - Epoch: [88][   50/  139]    Overall Loss 0.401820    Objective Loss 0.401820                                        LR 0.000500    Time 0.274269    
2024-04-04 21:29:53,364 - Epoch: [88][   60/  139]    Overall Loss 0.401861    Objective Loss 0.401861                                        LR 0.000500    Time 0.272222    
2024-04-04 21:29:55,988 - Epoch: [88][   70/  139]    Overall Loss 0.402892    Objective Loss 0.402892                                        LR 0.000500    Time 0.270809    
2024-04-04 21:29:58,629 - Epoch: [88][   80/  139]    Overall Loss 0.405108    Objective Loss 0.405108                                        LR 0.000500    Time 0.269964    
2024-04-04 21:30:01,272 - Epoch: [88][   90/  139]    Overall Loss 0.406161    Objective Loss 0.406161                                        LR 0.000500    Time 0.269334    
2024-04-04 21:30:03,924 - Epoch: [88][  100/  139]    Overall Loss 0.406781    Objective Loss 0.406781                                        LR 0.000500    Time 0.268914    
2024-04-04 21:30:06,567 - Epoch: [88][  110/  139]    Overall Loss 0.406415    Objective Loss 0.406415                                        LR 0.000500    Time 0.268490    
2024-04-04 21:30:09,203 - Epoch: [88][  120/  139]    Overall Loss 0.406199    Objective Loss 0.406199                                        LR 0.000500    Time 0.268076    
2024-04-04 21:30:11,843 - Epoch: [88][  130/  139]    Overall Loss 0.406026    Objective Loss 0.406026                                        LR 0.000500    Time 0.267763    
2024-04-04 21:30:19,338 - Epoch: [88][  139/  139]    Overall Loss 0.406202    Objective Loss 0.406202    Top1 96.190141    LR 0.000500    Time 0.304338    
2024-04-04 21:30:19,683 - --- validate (epoch=88)-----------
2024-04-04 21:30:19,684 - 1392 samples (32 per mini-batch)
2024-04-04 21:30:52,338 - Epoch: [88][   10/   44]    Loss 0.514827    Top1 90.053731    
2024-04-04 21:31:24,610 - Epoch: [88][   20/   44]    Loss 0.514592    Top1 90.059822    
2024-04-04 21:31:57,053 - Epoch: [88][   30/   44]    Loss 0.515988    Top1 89.961747    
2024-04-04 21:32:29,365 - Epoch: [88][   40/   44]    Loss 0.516687    Top1 89.907302    
2024-04-04 21:32:40,633 - Epoch: [88][   44/   44]    Loss 0.516204    Top1 89.911449    
2024-04-04 21:32:41,037 - ==> Top1: 89.911    Loss: 0.516

2024-04-04 21:32:41,044 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:32:41,045 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:32:41,079 - 

2024-04-04 21:32:41,079 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:32:44,542 - Epoch: [89][   10/  139]    Overall Loss 0.401523    Objective Loss 0.401523                                        LR 0.000500    Time 0.346162    
2024-04-04 21:32:47,184 - Epoch: [89][   20/  139]    Overall Loss 0.397913    Objective Loss 0.397913                                        LR 0.000500    Time 0.305127    
2024-04-04 21:32:49,829 - Epoch: [89][   30/  139]    Overall Loss 0.397604    Objective Loss 0.397604                                        LR 0.000500    Time 0.291578    
2024-04-04 21:32:52,473 - Epoch: [89][   40/  139]    Overall Loss 0.397789    Objective Loss 0.397789                                        LR 0.000500    Time 0.284765    
2024-04-04 21:32:55,111 - Epoch: [89][   50/  139]    Overall Loss 0.398488    Objective Loss 0.398488                                        LR 0.000500    Time 0.280572    
2024-04-04 21:32:57,753 - Epoch: [89][   60/  139]    Overall Loss 0.399732    Objective Loss 0.399732                                        LR 0.000500    Time 0.277829    
2024-04-04 21:33:00,377 - Epoch: [89][   70/  139]    Overall Loss 0.400914    Objective Loss 0.400914                                        LR 0.000500    Time 0.275626    
2024-04-04 21:33:02,971 - Epoch: [89][   80/  139]    Overall Loss 0.401002    Objective Loss 0.401002                                        LR 0.000500    Time 0.273590    
2024-04-04 21:33:05,597 - Epoch: [89][   90/  139]    Overall Loss 0.400755    Objective Loss 0.400755                                        LR 0.000500    Time 0.272357    
2024-04-04 21:33:08,204 - Epoch: [89][  100/  139]    Overall Loss 0.400762    Objective Loss 0.400762                                        LR 0.000500    Time 0.271177    
2024-04-04 21:33:10,823 - Epoch: [89][  110/  139]    Overall Loss 0.400463    Objective Loss 0.400463                                        LR 0.000500    Time 0.270332    
2024-04-04 21:33:13,461 - Epoch: [89][  120/  139]    Overall Loss 0.400645    Objective Loss 0.400645                                        LR 0.000500    Time 0.269784    
2024-04-04 21:33:16,103 - Epoch: [89][  130/  139]    Overall Loss 0.400889    Objective Loss 0.400889                                        LR 0.000500    Time 0.269347    
2024-04-04 21:33:23,066 - Epoch: [89][  139/  139]    Overall Loss 0.401246    Objective Loss 0.401246    Top1 95.112253    LR 0.000500    Time 0.301999    
2024-04-04 21:33:23,473 - --- validate (epoch=89)-----------
2024-04-04 21:33:23,473 - 1392 samples (32 per mini-batch)
2024-04-04 21:33:57,134 - Epoch: [89][   10/   44]    Loss 0.517966    Top1 89.430133    
2024-04-04 21:34:29,013 - Epoch: [89][   20/   44]    Loss 0.528688    Top1 88.789735    
2024-04-04 21:35:00,881 - Epoch: [89][   30/   44]    Loss 0.529783    Top1 88.720706    
2024-04-04 21:35:32,854 - Epoch: [89][   40/   44]    Loss 0.528119    Top1 88.829340    
2024-04-04 21:35:44,655 - Epoch: [89][   44/   44]    Loss 0.527229    Top1 88.887562    
2024-04-04 21:35:44,963 - ==> Top1: 88.888    Loss: 0.527

2024-04-04 21:35:44,973 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:35:44,974 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:35:45,007 - 

2024-04-04 21:35:45,007 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:35:48,312 - Epoch: [90][   10/  139]    Overall Loss 0.409104    Objective Loss 0.409104                                        LR 0.000500    Time 0.330439    
2024-04-04 21:35:50,931 - Epoch: [90][   20/  139]    Overall Loss 0.408675    Objective Loss 0.408675                                        LR 0.000500    Time 0.296090    
2024-04-04 21:35:53,545 - Epoch: [90][   30/  139]    Overall Loss 0.407509    Objective Loss 0.407509                                        LR 0.000500    Time 0.284519    
2024-04-04 21:35:56,165 - Epoch: [90][   40/  139]    Overall Loss 0.406301    Objective Loss 0.406301                                        LR 0.000500    Time 0.278873    
2024-04-04 21:35:58,765 - Epoch: [90][   50/  139]    Overall Loss 0.406321    Objective Loss 0.406321                                        LR 0.000500    Time 0.275092    
2024-04-04 21:36:01,357 - Epoch: [90][   60/  139]    Overall Loss 0.406149    Objective Loss 0.406149                                        LR 0.000500    Time 0.272442    
2024-04-04 21:36:03,940 - Epoch: [90][   70/  139]    Overall Loss 0.407096    Objective Loss 0.407096                                        LR 0.000500    Time 0.270415    
2024-04-04 21:36:06,499 - Epoch: [90][   80/  139]    Overall Loss 0.406873    Objective Loss 0.406873                                        LR 0.000500    Time 0.268594    
2024-04-04 21:36:09,055 - Epoch: [90][   90/  139]    Overall Loss 0.407165    Objective Loss 0.407165                                        LR 0.000500    Time 0.267146    
2024-04-04 21:36:11,638 - Epoch: [90][  100/  139]    Overall Loss 0.406824    Objective Loss 0.406824                                        LR 0.000500    Time 0.266252    
2024-04-04 21:36:14,208 - Epoch: [90][  110/  139]    Overall Loss 0.406380    Objective Loss 0.406380                                        LR 0.000500    Time 0.265402    
2024-04-04 21:36:16,769 - Epoch: [90][  120/  139]    Overall Loss 0.405888    Objective Loss 0.405888                                        LR 0.000500    Time 0.264628    
2024-04-04 21:36:19,344 - Epoch: [90][  130/  139]    Overall Loss 0.405172    Objective Loss 0.405172                                        LR 0.000500    Time 0.264076    
2024-04-04 21:36:25,736 - Epoch: [90][  139/  139]    Overall Loss 0.404713    Objective Loss 0.404713    Top1 97.025025    LR 0.000500    Time 0.292959    
2024-04-04 21:36:26,098 - --- validate (epoch=90)-----------
2024-04-04 21:36:26,099 - 1392 samples (32 per mini-batch)
2024-04-04 21:36:59,620 - Epoch: [90][   10/   44]    Loss 0.504159    Top1 90.574288    
2024-04-04 21:37:31,856 - Epoch: [90][   20/   44]    Loss 0.500484    Top1 90.757902    
2024-04-04 21:38:04,188 - Epoch: [90][   30/   44]    Loss 0.500118    Top1 90.778878    
2024-04-04 21:38:36,495 - Epoch: [90][   40/   44]    Loss 0.499566    Top1 90.830944    
2024-04-04 21:38:47,714 - Epoch: [90][   44/   44]    Loss 0.500675    Top1 90.837203    
2024-04-04 21:38:48,025 - ==> Top1: 90.837    Loss: 0.501

2024-04-04 21:38:48,033 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:38:48,033 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:38:48,067 - 

2024-04-04 21:38:48,067 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:38:51,504 - Epoch: [91][   10/  139]    Overall Loss 0.396633    Objective Loss 0.396633                                        LR 0.000500    Time 0.343526    
2024-04-04 21:38:54,083 - Epoch: [91][   20/  139]    Overall Loss 0.398187    Objective Loss 0.398187                                        LR 0.000500    Time 0.300687    
2024-04-04 21:38:56,686 - Epoch: [91][   30/  139]    Overall Loss 0.399632    Objective Loss 0.399632                                        LR 0.000500    Time 0.287221    
2024-04-04 21:38:59,259 - Epoch: [91][   40/  139]    Overall Loss 0.399086    Objective Loss 0.399086                                        LR 0.000500    Time 0.279717    
2024-04-04 21:39:01,852 - Epoch: [91][   50/  139]    Overall Loss 0.400027    Objective Loss 0.400027                                        LR 0.000500    Time 0.275638    
2024-04-04 21:39:04,441 - Epoch: [91][   60/  139]    Overall Loss 0.400012    Objective Loss 0.400012                                        LR 0.000500    Time 0.272836    
2024-04-04 21:39:07,001 - Epoch: [91][   70/  139]    Overall Loss 0.400076    Objective Loss 0.400076                                        LR 0.000500    Time 0.270417    
2024-04-04 21:39:09,581 - Epoch: [91][   80/  139]    Overall Loss 0.400466    Objective Loss 0.400466                                        LR 0.000500    Time 0.268859    
2024-04-04 21:39:12,163 - Epoch: [91][   90/  139]    Overall Loss 0.400588    Objective Loss 0.400588                                        LR 0.000500    Time 0.267674    
2024-04-04 21:39:14,750 - Epoch: [91][  100/  139]    Overall Loss 0.400638    Objective Loss 0.400638                                        LR 0.000500    Time 0.266771    
2024-04-04 21:39:17,348 - Epoch: [91][  110/  139]    Overall Loss 0.400602    Objective Loss 0.400602                                        LR 0.000500    Time 0.266132    
2024-04-04 21:39:19,884 - Epoch: [91][  120/  139]    Overall Loss 0.400641    Objective Loss 0.400641                                        LR 0.000500    Time 0.265086    
2024-04-04 21:39:22,475 - Epoch: [91][  130/  139]    Overall Loss 0.400888    Objective Loss 0.400888                                        LR 0.000500    Time 0.264622    
2024-04-04 21:39:28,704 - Epoch: [91][  139/  139]    Overall Loss 0.400905    Objective Loss 0.400905    Top1 96.541145    LR 0.000500    Time 0.292296    
2024-04-04 21:39:29,009 - --- validate (epoch=91)-----------
2024-04-04 21:39:29,010 - 1392 samples (32 per mini-batch)
2024-04-04 21:40:01,293 - Epoch: [91][   10/   44]    Loss 0.516966    Top1 89.814917    
2024-04-04 21:40:33,886 - Epoch: [91][   20/   44]    Loss 0.516792    Top1 89.759784    
2024-04-04 21:41:05,605 - Epoch: [91][   30/   44]    Loss 0.515780    Top1 89.832936    
2024-04-04 21:41:37,354 - Epoch: [91][   40/   44]    Loss 0.515734    Top1 89.826514    
2024-04-04 21:41:48,946 - Epoch: [91][   44/   44]    Loss 0.515662    Top1 89.839362    
2024-04-04 21:41:49,236 - ==> Top1: 89.839    Loss: 0.516

2024-04-04 21:41:49,243 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:41:49,243 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:41:49,278 - 

2024-04-04 21:41:49,279 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:41:52,617 - Epoch: [92][   10/  139]    Overall Loss 0.405170    Objective Loss 0.405170                                        LR 0.000500    Time 0.333684    
2024-04-04 21:41:55,245 - Epoch: [92][   20/  139]    Overall Loss 0.401763    Objective Loss 0.401763                                        LR 0.000500    Time 0.298205    
2024-04-04 21:41:57,868 - Epoch: [92][   30/  139]    Overall Loss 0.402111    Objective Loss 0.402111                                        LR 0.000500    Time 0.286220    
2024-04-04 21:42:00,480 - Epoch: [92][   40/  139]    Overall Loss 0.402349    Objective Loss 0.402349                                        LR 0.000500    Time 0.279951    
2024-04-04 21:42:03,112 - Epoch: [92][   50/  139]    Overall Loss 0.400541    Objective Loss 0.400541                                        LR 0.000500    Time 0.276598    
2024-04-04 21:42:05,780 - Epoch: [92][   60/  139]    Overall Loss 0.399773    Objective Loss 0.399773                                        LR 0.000500    Time 0.274960    
2024-04-04 21:42:08,409 - Epoch: [92][   70/  139]    Overall Loss 0.399665    Objective Loss 0.399665                                        LR 0.000500    Time 0.273232    
2024-04-04 21:42:11,024 - Epoch: [92][   80/  139]    Overall Loss 0.399830    Objective Loss 0.399830                                        LR 0.000500    Time 0.271750    
2024-04-04 21:42:13,653 - Epoch: [92][   90/  139]    Overall Loss 0.399522    Objective Loss 0.399522                                        LR 0.000500    Time 0.270763    
2024-04-04 21:42:16,313 - Epoch: [92][  100/  139]    Overall Loss 0.399467    Objective Loss 0.399467                                        LR 0.000500    Time 0.270275    
2024-04-04 21:42:18,937 - Epoch: [92][  110/  139]    Overall Loss 0.399349    Objective Loss 0.399349                                        LR 0.000500    Time 0.269553    
2024-04-04 21:42:21,552 - Epoch: [92][  120/  139]    Overall Loss 0.399805    Objective Loss 0.399805                                        LR 0.000500    Time 0.268880    
2024-04-04 21:42:24,148 - Epoch: [92][  130/  139]    Overall Loss 0.400228    Objective Loss 0.400228                                        LR 0.000500    Time 0.268159    
2024-04-04 21:42:31,184 - Epoch: [92][  139/  139]    Overall Loss 0.400123    Objective Loss 0.400123    Top1 96.380262    LR 0.000500    Time 0.301412    
2024-04-04 21:42:31,611 - --- validate (epoch=92)-----------
2024-04-04 21:42:31,613 - 1392 samples (32 per mini-batch)
2024-04-04 21:43:05,416 - Epoch: [92][   10/   44]    Loss 0.519181    Top1 89.797444    
2024-04-04 21:43:36,364 - Epoch: [92][   20/   44]    Loss 0.515509    Top1 89.966828    
2024-04-04 21:44:08,678 - Epoch: [92][   30/   44]    Loss 0.510754    Top1 90.209388    
2024-04-04 21:44:41,590 - Epoch: [92][   40/   44]    Loss 0.508689    Top1 90.341654    
2024-04-04 21:44:52,968 - Epoch: [92][   44/   44]    Loss 0.509216    Top1 90.321231    
2024-04-04 21:44:53,275 - ==> Top1: 90.321    Loss: 0.509

2024-04-04 21:44:53,282 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:44:53,282 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:44:53,316 - 

2024-04-04 21:44:53,316 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:44:56,635 - Epoch: [93][   10/  139]    Overall Loss 0.402217    Objective Loss 0.402217                                        LR 0.000500    Time 0.331778    
2024-04-04 21:44:59,208 - Epoch: [93][   20/  139]    Overall Loss 0.400149    Objective Loss 0.400149                                        LR 0.000500    Time 0.294503    
2024-04-04 21:45:01,799 - Epoch: [93][   30/  139]    Overall Loss 0.400518    Objective Loss 0.400518                                        LR 0.000500    Time 0.282697    
2024-04-04 21:45:04,403 - Epoch: [93][   40/  139]    Overall Loss 0.400524    Objective Loss 0.400524                                        LR 0.000500    Time 0.277093    
2024-04-04 21:45:07,009 - Epoch: [93][   50/  139]    Overall Loss 0.399909    Objective Loss 0.399909                                        LR 0.000500    Time 0.273796    
2024-04-04 21:45:09,614 - Epoch: [93][   60/  139]    Overall Loss 0.400177    Objective Loss 0.400177                                        LR 0.000500    Time 0.271571    
2024-04-04 21:45:12,215 - Epoch: [93][   70/  139]    Overall Loss 0.400074    Objective Loss 0.400074                                        LR 0.000500    Time 0.269918    
2024-04-04 21:45:14,842 - Epoch: [93][   80/  139]    Overall Loss 0.399762    Objective Loss 0.399762                                        LR 0.000500    Time 0.269008    
2024-04-04 21:45:17,488 - Epoch: [93][   90/  139]    Overall Loss 0.399553    Objective Loss 0.399553                                        LR 0.000500    Time 0.268515    
2024-04-04 21:45:20,091 - Epoch: [93][  100/  139]    Overall Loss 0.401276    Objective Loss 0.401276                                        LR 0.000500    Time 0.267688    
2024-04-04 21:45:22,723 - Epoch: [93][  110/  139]    Overall Loss 0.402294    Objective Loss 0.402294                                        LR 0.000500    Time 0.267280    
2024-04-04 21:45:25,328 - Epoch: [93][  120/  139]    Overall Loss 0.402736    Objective Loss 0.402736                                        LR 0.000500    Time 0.266710    
2024-04-04 21:45:27,942 - Epoch: [93][  130/  139]    Overall Loss 0.402534    Objective Loss 0.402534                                        LR 0.000500    Time 0.266293    
2024-04-04 21:45:34,577 - Epoch: [93][  139/  139]    Overall Loss 0.402634    Objective Loss 0.402634    Top1 96.568017    LR 0.000500    Time 0.296786    
2024-04-04 21:45:34,985 - --- validate (epoch=93)-----------
2024-04-04 21:45:34,986 - 1392 samples (32 per mini-batch)
2024-04-04 21:46:08,442 - Epoch: [93][   10/   44]    Loss 0.502110    Top1 90.775210    
2024-04-04 21:46:39,688 - Epoch: [93][   20/   44]    Loss 0.503197    Top1 90.737334    
2024-04-04 21:47:12,033 - Epoch: [93][   30/   44]    Loss 0.506148    Top1 90.571662    
2024-04-04 21:47:43,738 - Epoch: [93][   40/   44]    Loss 0.504657    Top1 90.651568    
2024-04-04 21:47:54,800 - Epoch: [93][   44/   44]    Loss 0.505552    Top1 90.613095    
2024-04-04 21:47:55,131 - ==> Top1: 90.613    Loss: 0.506

2024-04-04 21:47:55,139 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:47:55,139 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:47:55,173 - 

2024-04-04 21:47:55,173 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:47:58,549 - Epoch: [94][   10/  139]    Overall Loss 0.404698    Objective Loss 0.404698                                        LR 0.000500    Time 0.337465    
2024-04-04 21:48:01,175 - Epoch: [94][   20/  139]    Overall Loss 0.402861    Objective Loss 0.402861                                        LR 0.000500    Time 0.300035    
2024-04-04 21:48:03,794 - Epoch: [94][   30/  139]    Overall Loss 0.401796    Objective Loss 0.401796                                        LR 0.000500    Time 0.287306    
2024-04-04 21:48:06,399 - Epoch: [94][   40/  139]    Overall Loss 0.400765    Objective Loss 0.400765                                        LR 0.000500    Time 0.280572    
2024-04-04 21:48:09,008 - Epoch: [94][   50/  139]    Overall Loss 0.400899    Objective Loss 0.400899                                        LR 0.000500    Time 0.276643    
2024-04-04 21:48:11,595 - Epoch: [94][   60/  139]    Overall Loss 0.400118    Objective Loss 0.400118                                        LR 0.000500    Time 0.273637    
2024-04-04 21:48:14,179 - Epoch: [94][   70/  139]    Overall Loss 0.400045    Objective Loss 0.400045                                        LR 0.000500    Time 0.271450    
2024-04-04 21:48:16,810 - Epoch: [94][   80/  139]    Overall Loss 0.400476    Objective Loss 0.400476                                        LR 0.000500    Time 0.270392    
2024-04-04 21:48:19,437 - Epoch: [94][   90/  139]    Overall Loss 0.401178    Objective Loss 0.401178                                        LR 0.000500    Time 0.269534    
2024-04-04 21:48:22,068 - Epoch: [94][  100/  139]    Overall Loss 0.401063    Objective Loss 0.401063                                        LR 0.000500    Time 0.268889    
2024-04-04 21:48:24,687 - Epoch: [94][  110/  139]    Overall Loss 0.401259    Objective Loss 0.401259                                        LR 0.000500    Time 0.268242    
2024-04-04 21:48:27,303 - Epoch: [94][  120/  139]    Overall Loss 0.400939    Objective Loss 0.400939                                        LR 0.000500    Time 0.267687    
2024-04-04 21:48:29,940 - Epoch: [94][  130/  139]    Overall Loss 0.400858    Objective Loss 0.400858                                        LR 0.000500    Time 0.267379    
2024-04-04 21:48:36,959 - Epoch: [94][  139/  139]    Overall Loss 0.400409    Objective Loss 0.400409    Top1 97.403635    LR 0.000500    Time 0.300555    
2024-04-04 21:48:37,277 - --- validate (epoch=94)-----------
2024-04-04 21:48:37,277 - 1392 samples (32 per mini-batch)
2024-04-04 21:49:11,463 - Epoch: [94][   10/   44]    Loss 0.511175    Top1 90.193219    
2024-04-04 21:49:43,279 - Epoch: [94][   20/   44]    Loss 0.510112    Top1 90.241347    
2024-04-04 21:50:15,630 - Epoch: [94][   30/   44]    Loss 0.509745    Top1 90.268626    
2024-04-04 21:50:48,142 - Epoch: [94][   40/   44]    Loss 0.509833    Top1 90.282958    
2024-04-04 21:50:59,745 - Epoch: [94][   44/   44]    Loss 0.507100    Top1 90.393582    
2024-04-04 21:51:00,157 - ==> Top1: 90.394    Loss: 0.507

2024-04-04 21:51:00,164 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:51:00,165 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:51:00,199 - 

2024-04-04 21:51:00,199 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:51:03,551 - Epoch: [95][   10/  139]    Overall Loss 0.398212    Objective Loss 0.398212                                        LR 0.000500    Time 0.335073    
2024-04-04 21:51:06,170 - Epoch: [95][   20/  139]    Overall Loss 0.398760    Objective Loss 0.398760                                        LR 0.000500    Time 0.298476    
2024-04-04 21:51:08,790 - Epoch: [95][   30/  139]    Overall Loss 0.397304    Objective Loss 0.397304                                        LR 0.000500    Time 0.286269    
2024-04-04 21:51:11,356 - Epoch: [95][   40/  139]    Overall Loss 0.397591    Objective Loss 0.397591                                        LR 0.000500    Time 0.278862    
2024-04-04 21:51:13,916 - Epoch: [95][   50/  139]    Overall Loss 0.397373    Objective Loss 0.397373                                        LR 0.000500    Time 0.274268    
2024-04-04 21:51:16,531 - Epoch: [95][   60/  139]    Overall Loss 0.398181    Objective Loss 0.398181                                        LR 0.000500    Time 0.272142    
2024-04-04 21:51:19,123 - Epoch: [95][   70/  139]    Overall Loss 0.398342    Objective Loss 0.398342                                        LR 0.000500    Time 0.270278    
2024-04-04 21:51:21,678 - Epoch: [95][   80/  139]    Overall Loss 0.398419    Objective Loss 0.398419                                        LR 0.000500    Time 0.268424    
2024-04-04 21:51:24,239 - Epoch: [95][   90/  139]    Overall Loss 0.398533    Objective Loss 0.398533                                        LR 0.000500    Time 0.267046    
2024-04-04 21:51:26,790 - Epoch: [95][  100/  139]    Overall Loss 0.398812    Objective Loss 0.398812                                        LR 0.000500    Time 0.265846    
2024-04-04 21:51:29,324 - Epoch: [95][  110/  139]    Overall Loss 0.398562    Objective Loss 0.398562                                        LR 0.000500    Time 0.264717    
2024-04-04 21:51:31,872 - Epoch: [95][  120/  139]    Overall Loss 0.399154    Objective Loss 0.399154                                        LR 0.000500    Time 0.263883    
2024-04-04 21:51:34,428 - Epoch: [95][  130/  139]    Overall Loss 0.398889    Objective Loss 0.398889                                        LR 0.000500    Time 0.263242    
2024-04-04 21:51:41,198 - Epoch: [95][  139/  139]    Overall Loss 0.398564    Objective Loss 0.398564    Top1 96.724297    LR 0.000500    Time 0.294903    
2024-04-04 21:51:41,579 - --- validate (epoch=95)-----------
2024-04-04 21:51:41,580 - 1392 samples (32 per mini-batch)
2024-04-04 21:52:14,677 - Epoch: [95][   10/   44]    Loss 0.522348    Top1 89.647461    
2024-04-04 21:52:46,284 - Epoch: [95][   20/   44]    Loss 0.517742    Top1 89.897209    
2024-04-04 21:53:18,394 - Epoch: [95][   30/   44]    Loss 0.513783    Top1 90.156954    
2024-04-04 21:53:51,259 - Epoch: [95][   40/   44]    Loss 0.512291    Top1 90.235225    
2024-04-04 21:54:02,727 - Epoch: [95][   44/   44]    Loss 0.509699    Top1 90.342559    
2024-04-04 21:54:03,023 - ==> Top1: 90.343    Loss: 0.510

2024-04-04 21:54:03,033 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:54:03,034 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:54:03,066 - 

2024-04-04 21:54:03,067 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:54:06,530 - Epoch: [96][   10/  139]    Overall Loss 0.397299    Objective Loss 0.397299                                        LR 0.000500    Time 0.346178    
2024-04-04 21:54:09,159 - Epoch: [96][   20/  139]    Overall Loss 0.398180    Objective Loss 0.398180                                        LR 0.000500    Time 0.304544    
2024-04-04 21:54:11,787 - Epoch: [96][   30/  139]    Overall Loss 0.398735    Objective Loss 0.398735                                        LR 0.000500    Time 0.290587    
2024-04-04 21:54:14,386 - Epoch: [96][   40/  139]    Overall Loss 0.399804    Objective Loss 0.399804                                        LR 0.000500    Time 0.282905    
2024-04-04 21:54:16,988 - Epoch: [96][   50/  139]    Overall Loss 0.400081    Objective Loss 0.400081                                        LR 0.000500    Time 0.278355    
2024-04-04 21:54:19,604 - Epoch: [96][   60/  139]    Overall Loss 0.400830    Objective Loss 0.400830                                        LR 0.000500    Time 0.275566    
2024-04-04 21:54:22,214 - Epoch: [96][   70/  139]    Overall Loss 0.400893    Objective Loss 0.400893                                        LR 0.000500    Time 0.273474    
2024-04-04 21:54:24,814 - Epoch: [96][   80/  139]    Overall Loss 0.400682    Objective Loss 0.400682                                        LR 0.000500    Time 0.271790    
2024-04-04 21:54:27,445 - Epoch: [96][   90/  139]    Overall Loss 0.399816    Objective Loss 0.399816                                        LR 0.000500    Time 0.270817    
2024-04-04 21:54:30,075 - Epoch: [96][  100/  139]    Overall Loss 0.399400    Objective Loss 0.399400                                        LR 0.000500    Time 0.270028    
2024-04-04 21:54:32,708 - Epoch: [96][  110/  139]    Overall Loss 0.399231    Objective Loss 0.399231                                        LR 0.000500    Time 0.269408    
2024-04-04 21:54:35,364 - Epoch: [96][  120/  139]    Overall Loss 0.399448    Objective Loss 0.399448                                        LR 0.000500    Time 0.269076    
2024-04-04 21:54:38,001 - Epoch: [96][  130/  139]    Overall Loss 0.399742    Objective Loss 0.399742                                        LR 0.000500    Time 0.268657    
2024-04-04 21:54:45,714 - Epoch: [96][  139/  139]    Overall Loss 0.400338    Objective Loss 0.400338    Top1 96.196377    LR 0.000500    Time 0.306752    
2024-04-04 21:54:45,965 - --- validate (epoch=96)-----------
2024-04-04 21:54:45,967 - 1392 samples (32 per mini-batch)
2024-04-04 21:55:17,902 - Epoch: [96][   10/   44]    Loss 0.523896    Top1 89.468069    
2024-04-04 21:55:50,085 - Epoch: [96][   20/   44]    Loss 0.515475    Top1 89.886982    
2024-04-04 21:56:21,477 - Epoch: [96][   30/   44]    Loss 0.519224    Top1 89.684408    
2024-04-04 21:56:53,376 - Epoch: [96][   40/   44]    Loss 0.519708    Top1 89.670940    
2024-04-04 21:57:04,586 - Epoch: [96][   44/   44]    Loss 0.518739    Top1 89.688788    
2024-04-04 21:57:04,864 - ==> Top1: 89.689    Loss: 0.519

2024-04-04 21:57:04,871 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 21:57:04,872 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 21:57:04,907 - 

2024-04-04 21:57:04,907 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 21:57:08,313 - Epoch: [97][   10/  139]    Overall Loss 0.400239    Objective Loss 0.400239                                        LR 0.000500    Time 0.340509    
2024-04-04 21:57:10,931 - Epoch: [97][   20/  139]    Overall Loss 0.402192    Objective Loss 0.402192                                        LR 0.000500    Time 0.301093    
2024-04-04 21:57:13,546 - Epoch: [97][   30/  139]    Overall Loss 0.403271    Objective Loss 0.403271                                        LR 0.000500    Time 0.287896    
2024-04-04 21:57:16,178 - Epoch: [97][   40/  139]    Overall Loss 0.402626    Objective Loss 0.402626                                        LR 0.000500    Time 0.281707    
2024-04-04 21:57:18,721 - Epoch: [97][   50/  139]    Overall Loss 0.401815    Objective Loss 0.401815                                        LR 0.000500    Time 0.276218    
2024-04-04 21:57:21,324 - Epoch: [97][   60/  139]    Overall Loss 0.401501    Objective Loss 0.401501                                        LR 0.000500    Time 0.273546    
2024-04-04 21:57:23,932 - Epoch: [97][   70/  139]    Overall Loss 0.401143    Objective Loss 0.401143                                        LR 0.000500    Time 0.271721    
2024-04-04 21:57:26,533 - Epoch: [97][   80/  139]    Overall Loss 0.400756    Objective Loss 0.400756                                        LR 0.000500    Time 0.270260    
2024-04-04 21:57:29,163 - Epoch: [97][   90/  139]    Overall Loss 0.400902    Objective Loss 0.400902                                        LR 0.000500    Time 0.269448    
2024-04-04 21:57:31,762 - Epoch: [97][  100/  139]    Overall Loss 0.401103    Objective Loss 0.401103                                        LR 0.000500    Time 0.268494    
2024-04-04 21:57:34,359 - Epoch: [97][  110/  139]    Overall Loss 0.401095    Objective Loss 0.401095                                        LR 0.000500    Time 0.267686    
2024-04-04 21:57:36,946 - Epoch: [97][  120/  139]    Overall Loss 0.400290    Objective Loss 0.400290                                        LR 0.000500    Time 0.266932    
2024-04-04 21:57:39,542 - Epoch: [97][  130/  139]    Overall Loss 0.400117    Objective Loss 0.400117                                        LR 0.000500    Time 0.266367    
2024-04-04 21:57:46,293 - Epoch: [97][  139/  139]    Overall Loss 0.399862    Objective Loss 0.399862    Top1 96.642635    LR 0.000500    Time 0.297685    
2024-04-04 21:57:46,698 - --- validate (epoch=97)-----------
2024-04-04 21:57:46,700 - 1392 samples (32 per mini-batch)
2024-04-04 21:58:19,746 - Epoch: [97][   10/   44]    Loss 0.512441    Top1 90.067968    
2024-04-04 21:58:51,962 - Epoch: [97][   20/   44]    Loss 0.513384    Top1 90.037810    
2024-04-04 21:59:24,456 - Epoch: [97][   30/   44]    Loss 0.513272    Top1 90.052369    
2024-04-04 21:59:57,030 - Epoch: [97][   40/   44]    Loss 0.514079    Top1 90.039098    
2024-04-04 22:00:08,713 - Epoch: [97][   44/   44]    Loss 0.513130    Top1 90.054795    
2024-04-04 22:00:08,962 - ==> Top1: 90.055    Loss: 0.513

2024-04-04 22:00:08,969 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 22:00:08,970 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 22:00:08,998 - 

2024-04-04 22:00:08,998 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 22:00:12,439 - Epoch: [98][   10/  139]    Overall Loss 0.399317    Objective Loss 0.399317                                        LR 0.000500    Time 0.343936    
2024-04-04 22:00:14,997 - Epoch: [98][   20/  139]    Overall Loss 0.400304    Objective Loss 0.400304                                        LR 0.000500    Time 0.299859    
2024-04-04 22:00:17,564 - Epoch: [98][   30/  139]    Overall Loss 0.399133    Objective Loss 0.399133                                        LR 0.000500    Time 0.285452    
2024-04-04 22:00:20,133 - Epoch: [98][   40/  139]    Overall Loss 0.400820    Objective Loss 0.400820                                        LR 0.000500    Time 0.278282    
2024-04-04 22:00:22,699 - Epoch: [98][   50/  139]    Overall Loss 0.401732    Objective Loss 0.401732                                        LR 0.000500    Time 0.273949    
2024-04-04 22:00:25,298 - Epoch: [98][   60/  139]    Overall Loss 0.401872    Objective Loss 0.401872                                        LR 0.000500    Time 0.271596    
2024-04-04 22:00:27,844 - Epoch: [98][   70/  139]    Overall Loss 0.401517    Objective Loss 0.401517                                        LR 0.000500    Time 0.269164    
2024-04-04 22:00:30,413 - Epoch: [98][   80/  139]    Overall Loss 0.401803    Objective Loss 0.401803                                        LR 0.000500    Time 0.267621    
2024-04-04 22:00:33,000 - Epoch: [98][   90/  139]    Overall Loss 0.402104    Objective Loss 0.402104                                        LR 0.000500    Time 0.266624    
2024-04-04 22:00:35,625 - Epoch: [98][  100/  139]    Overall Loss 0.402245    Objective Loss 0.402245                                        LR 0.000500    Time 0.266209    
2024-04-04 22:00:38,237 - Epoch: [98][  110/  139]    Overall Loss 0.401732    Objective Loss 0.401732                                        LR 0.000500    Time 0.265746    
2024-04-04 22:00:40,859 - Epoch: [98][  120/  139]    Overall Loss 0.400968    Objective Loss 0.400968                                        LR 0.000500    Time 0.265446    
2024-04-04 22:00:43,475 - Epoch: [98][  130/  139]    Overall Loss 0.400720    Objective Loss 0.400720                                        LR 0.000500    Time 0.265147    
2024-04-04 22:00:50,449 - Epoch: [98][  139/  139]    Overall Loss 0.400840    Objective Loss 0.400840    Top1 96.466252    LR 0.000500    Time 0.298152    
2024-04-04 22:00:50,825 - --- validate (epoch=98)-----------
2024-04-04 22:00:50,827 - 1392 samples (32 per mini-batch)
2024-04-04 22:01:24,554 - Epoch: [98][   10/   44]    Loss 0.501840    Top1 90.658590    
2024-04-04 22:01:56,650 - Epoch: [98][   20/   44]    Loss 0.507638    Top1 90.364399    
2024-04-04 22:02:28,772 - Epoch: [98][   30/   44]    Loss 0.507789    Top1 90.340030    
2024-04-04 22:03:00,732 - Epoch: [98][   40/   44]    Loss 0.503436    Top1 90.597012    
2024-04-04 22:03:12,058 - Epoch: [98][   44/   44]    Loss 0.502773    Top1 90.671806    
2024-04-04 22:03:12,334 - ==> Top1: 90.672    Loss: 0.503

2024-04-04 22:03:12,341 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 22:03:12,342 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 22:03:12,378 - 

2024-04-04 22:03:12,378 - Training epoch: 4428 samples (32 per mini-batch)
2024-04-04 22:03:15,698 - Epoch: [99][   10/  139]    Overall Loss 0.399128    Objective Loss 0.399128                                        LR 0.000500    Time 0.331842    
2024-04-04 22:03:18,249 - Epoch: [99][   20/  139]    Overall Loss 0.397298    Objective Loss 0.397298                                        LR 0.000500    Time 0.293424    
2024-04-04 22:03:20,855 - Epoch: [99][   30/  139]    Overall Loss 0.398006    Objective Loss 0.398006                                        LR 0.000500    Time 0.282476    
2024-04-04 22:03:23,459 - Epoch: [99][   40/  139]    Overall Loss 0.397898    Objective Loss 0.397898                                        LR 0.000500    Time 0.276930    
2024-04-04 22:03:26,072 - Epoch: [99][   50/  139]    Overall Loss 0.398134    Objective Loss 0.398134                                        LR 0.000500    Time 0.273799    
2024-04-04 22:03:28,712 - Epoch: [99][   60/  139]    Overall Loss 0.397628    Objective Loss 0.397628                                        LR 0.000500    Time 0.272159    
2024-04-04 22:03:31,347 - Epoch: [99][   70/  139]    Overall Loss 0.397387    Objective Loss 0.397387                                        LR 0.000500    Time 0.270916    
2024-04-04 22:03:33,981 - Epoch: [99][   80/  139]    Overall Loss 0.397096    Objective Loss 0.397096                                        LR 0.000500    Time 0.269970    
2024-04-04 22:03:36,608 - Epoch: [99][   90/  139]    Overall Loss 0.396678    Objective Loss 0.396678                                        LR 0.000500    Time 0.269148    
2024-04-04 22:03:39,252 - Epoch: [99][  100/  139]    Overall Loss 0.396690    Objective Loss 0.396690                                        LR 0.000500    Time 0.268670    
2024-04-04 22:03:41,876 - Epoch: [99][  110/  139]    Overall Loss 0.396826    Objective Loss 0.396826                                        LR 0.000500    Time 0.268098    
2024-04-04 22:03:44,522 - Epoch: [99][  120/  139]    Overall Loss 0.396695    Objective Loss 0.396695                                        LR 0.000500    Time 0.267799    
2024-04-04 22:03:47,137 - Epoch: [99][  130/  139]    Overall Loss 0.397328    Objective Loss 0.397328                                        LR 0.000500    Time 0.267314    
2024-04-04 22:03:54,574 - Epoch: [99][  139/  139]    Overall Loss 0.397256    Objective Loss 0.397256    Top1 96.755388    LR 0.000500    Time 0.303500    
2024-04-04 22:03:54,883 - --- validate (epoch=99)-----------
2024-04-04 22:03:54,884 - 1392 samples (32 per mini-batch)
2024-04-04 22:04:28,126 - Epoch: [99][   10/   44]    Loss 0.498470    Top1 91.020298    
2024-04-04 22:05:00,196 - Epoch: [99][   20/   44]    Loss 0.509206    Top1 90.393537    
2024-04-04 22:05:32,706 - Epoch: [99][   30/   44]    Loss 0.510439    Top1 90.328404    
2024-04-04 22:06:04,948 - Epoch: [99][   40/   44]    Loss 0.507958    Top1 90.459563    
2024-04-04 22:06:16,014 - Epoch: [99][   44/   44]    Loss 0.505912    Top1 90.550461    
2024-04-04 22:06:16,254 - ==> Top1: 90.550    Loss: 0.506

2024-04-04 22:06:16,261 - ==> Best [Top1: 91.128   Sparsity:0.00   Params: 272800 on epoch: 72]
2024-04-04 22:06:16,262 - Saving checkpoint to: logs/2024.04.04-165733/qat_checkpoint.pth.tar
2024-04-04 22:06:16,297 - --- test ---------------------
2024-04-04 22:06:16,297 - 1392 samples (32 per mini-batch)
2024-04-04 22:06:49,458 - Test: [   10/   44]    Loss 0.505462    Top1 90.599986    
2024-04-04 22:07:20,819 - Test: [   20/   44]    Loss 0.504611    Top1 90.662926    
2024-04-04 22:07:51,945 - Test: [   30/   44]    Loss 0.499251    Top1 90.944722    
2024-04-04 22:08:24,986 - Test: [   40/   44]    Loss 0.504028    Top1 90.674297    
2024-04-04 22:08:36,251 - Test: [   44/   44]    Loss 0.506606    Top1 90.550461    
2024-04-04 22:08:36,489 - ==> Top1: 90.550    Loss: 0.507

2024-04-04 22:08:36,534 - 
2024-04-04 22:08:36,535 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.04.04-165733/2024.04.04-165733.log
