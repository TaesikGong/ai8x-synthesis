2024-02-26 16:31:17,723 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.02.26-163117/2024.02.26-163117.log
2024-02-26 16:31:20,890 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-02-26 16:31:20,890 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-02-26 16:34:58,257 - Dataset sizes:
	training=4428
	validation=1392
	test=1392
2024-02-26 16:34:58,257 - Reading compression schedule from: policies/schedule-camvid.yaml
2024-02-26 16:34:58,264 - 

2024-02-26 16:34:58,264 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:35:09,178 - Epoch: [0][   10/  139]    Overall Loss 1.255882    Objective Loss 1.255882                                        LR 0.001000    Time 1.091255    
2024-02-26 16:35:18,523 - Epoch: [0][   20/  139]    Overall Loss 1.223661    Objective Loss 1.223661                                        LR 0.001000    Time 1.012848    
2024-02-26 16:35:27,875 - Epoch: [0][   30/  139]    Overall Loss 1.206230    Objective Loss 1.206230                                        LR 0.001000    Time 0.986921    
2024-02-26 16:35:37,219 - Epoch: [0][   40/  139]    Overall Loss 1.196350    Objective Loss 1.196350                                        LR 0.001000    Time 0.973802    
2024-02-26 16:35:46,563 - Epoch: [0][   50/  139]    Overall Loss 1.190315    Objective Loss 1.190315                                        LR 0.001000    Time 0.965900    
2024-02-26 16:35:55,909 - Epoch: [0][   60/  139]    Overall Loss 1.184264    Objective Loss 1.184264                                        LR 0.001000    Time 0.960686    
2024-02-26 16:36:05,262 - Epoch: [0][   70/  139]    Overall Loss 1.180146    Objective Loss 1.180146                                        LR 0.001000    Time 0.957050    
2024-02-26 16:36:14,609 - Epoch: [0][   80/  139]    Overall Loss 1.175651    Objective Loss 1.175651                                        LR 0.001000    Time 0.954245    
2024-02-26 16:36:23,963 - Epoch: [0][   90/  139]    Overall Loss 1.172955    Objective Loss 1.172955                                        LR 0.001000    Time 0.952149    
2024-02-26 16:36:33,326 - Epoch: [0][  100/  139]    Overall Loss 1.169796    Objective Loss 1.169796                                        LR 0.001000    Time 0.950552    
2024-02-26 16:36:42,712 - Epoch: [0][  110/  139]    Overall Loss 1.166576    Objective Loss 1.166576                                        LR 0.001000    Time 0.949456    
2024-02-26 16:36:52,073 - Epoch: [0][  120/  139]    Overall Loss 1.163883    Objective Loss 1.163883                                        LR 0.001000    Time 0.948343    
2024-02-26 16:37:01,422 - Epoch: [0][  130/  139]    Overall Loss 1.161756    Objective Loss 1.161756                                        LR 0.001000    Time 0.947299    
2024-02-26 16:37:15,009 - Epoch: [0][  139/  139]    Overall Loss 1.159553    Objective Loss 1.159553    Top1 77.403400    LR 0.001000    Time 0.983713    
2024-02-26 16:37:15,215 - --- validate (epoch=0)-----------
2024-02-26 16:37:15,215 - 1392 samples (32 per mini-batch)
2024-02-26 16:37:53,246 - Epoch: [0][   10/   44]    Loss 1.170735    Top1 72.180658    
2024-02-26 16:38:29,132 - Epoch: [0][   20/   44]    Loss 1.171950    Top1 72.648474    
2024-02-26 16:39:03,407 - Epoch: [0][   30/   44]    Loss 1.176019    Top1 72.367846    
2024-02-26 16:39:37,442 - Epoch: [0][   40/   44]    Loss 1.177349    Top1 72.254369    
2024-02-26 16:39:49,550 - Epoch: [0][   44/   44]    Loss 1.179597    Top1 71.999333    
2024-02-26 16:39:49,713 - ==> Top1: 71.999    Loss: 1.180

2024-02-26 16:39:49,720 - ==> Best [Top1: 71.999   Sparsity:0.00   Params: 271456 on epoch: 0]
2024-02-26 16:39:49,721 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 16:39:49,759 - 

2024-02-26 16:39:49,759 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:39:59,314 - Epoch: [1][   10/  139]    Overall Loss 1.123137    Objective Loss 1.123137                                        LR 0.001000    Time 0.955292    
2024-02-26 16:40:08,647 - Epoch: [1][   20/  139]    Overall Loss 1.126492    Objective Loss 1.126492                                        LR 0.001000    Time 0.944289    
2024-02-26 16:40:17,972 - Epoch: [1][   30/  139]    Overall Loss 1.128523    Objective Loss 1.128523                                        LR 0.001000    Time 0.940314    
2024-02-26 16:40:27,317 - Epoch: [1][   40/  139]    Overall Loss 1.127715    Objective Loss 1.127715                                        LR 0.001000    Time 0.938844    
2024-02-26 16:40:36,648 - Epoch: [1][   50/  139]    Overall Loss 1.126648    Objective Loss 1.126648                                        LR 0.001000    Time 0.937691    
2024-02-26 16:40:46,004 - Epoch: [1][   60/  139]    Overall Loss 1.125515    Objective Loss 1.125515                                        LR 0.001000    Time 0.937335    
2024-02-26 16:40:55,370 - Epoch: [1][   70/  139]    Overall Loss 1.125077    Objective Loss 1.125077                                        LR 0.001000    Time 0.937223    
2024-02-26 16:41:04,725 - Epoch: [1][   80/  139]    Overall Loss 1.124312    Objective Loss 1.124312                                        LR 0.001000    Time 0.936999    
2024-02-26 16:41:14,067 - Epoch: [1][   90/  139]    Overall Loss 1.123843    Objective Loss 1.123843                                        LR 0.001000    Time 0.936684    
2024-02-26 16:41:23,423 - Epoch: [1][  100/  139]    Overall Loss 1.122195    Objective Loss 1.122195                                        LR 0.001000    Time 0.936570    
2024-02-26 16:41:32,770 - Epoch: [1][  110/  139]    Overall Loss 1.121706    Objective Loss 1.121706                                        LR 0.001000    Time 0.936393    
2024-02-26 16:41:42,116 - Epoch: [1][  120/  139]    Overall Loss 1.120938    Objective Loss 1.120938                                        LR 0.001000    Time 0.936239    
2024-02-26 16:41:51,469 - Epoch: [1][  130/  139]    Overall Loss 1.120647    Objective Loss 1.120647                                        LR 0.001000    Time 0.936167    
2024-02-26 16:42:03,774 - Epoch: [1][  139/  139]    Overall Loss 1.120291    Objective Loss 1.120291    Top1 82.941229    LR 0.001000    Time 0.964073    
2024-02-26 16:42:04,031 - --- validate (epoch=1)-----------
2024-02-26 16:42:04,032 - 1392 samples (32 per mini-batch)
2024-02-26 16:42:38,178 - Epoch: [1][   10/   44]    Loss 1.105660    Top1 80.900400    
2024-02-26 16:43:11,135 - Epoch: [1][   20/   44]    Loss 1.105265    Top1 81.043298    
2024-02-26 16:43:42,482 - Epoch: [1][   30/   44]    Loss 1.106168    Top1 80.470188    
2024-02-26 16:44:14,284 - Epoch: [1][   40/   44]    Loss 1.104417    Top1 80.559369    
2024-02-26 16:44:25,882 - Epoch: [1][   44/   44]    Loss 1.107599    Top1 80.307749    
2024-02-26 16:44:26,078 - ==> Top1: 80.308    Loss: 1.108

2024-02-26 16:44:26,085 - ==> Best [Top1: 80.308   Sparsity:0.00   Params: 271456 on epoch: 1]
2024-02-26 16:44:26,085 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 16:44:26,122 - 

2024-02-26 16:44:26,122 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:44:35,804 - Epoch: [2][   10/  139]    Overall Loss 1.115813    Objective Loss 1.115813                                        LR 0.001000    Time 0.968058    
2024-02-26 16:44:45,143 - Epoch: [2][   20/  139]    Overall Loss 1.112821    Objective Loss 1.112821                                        LR 0.001000    Time 0.950947    
2024-02-26 16:44:54,484 - Epoch: [2][   30/  139]    Overall Loss 1.113173    Objective Loss 1.113173                                        LR 0.001000    Time 0.945309    
2024-02-26 16:45:03,829 - Epoch: [2][   40/  139]    Overall Loss 1.112112    Objective Loss 1.112112                                        LR 0.001000    Time 0.942601    
2024-02-26 16:45:13,173 - Epoch: [2][   50/  139]    Overall Loss 1.111463    Objective Loss 1.111463                                        LR 0.001000    Time 0.940950    
2024-02-26 16:45:22,526 - Epoch: [2][   60/  139]    Overall Loss 1.109842    Objective Loss 1.109842                                        LR 0.001000    Time 0.939988    
2024-02-26 16:45:31,874 - Epoch: [2][   70/  139]    Overall Loss 1.108692    Objective Loss 1.108692                                        LR 0.001000    Time 0.939242    
2024-02-26 16:45:41,223 - Epoch: [2][   80/  139]    Overall Loss 1.108395    Objective Loss 1.108395                                        LR 0.001000    Time 0.938696    
2024-02-26 16:45:50,589 - Epoch: [2][   90/  139]    Overall Loss 1.107567    Objective Loss 1.107567                                        LR 0.001000    Time 0.938452    
2024-02-26 16:45:59,937 - Epoch: [2][  100/  139]    Overall Loss 1.107209    Objective Loss 1.107209                                        LR 0.001000    Time 0.938090    
2024-02-26 16:46:09,290 - Epoch: [2][  110/  139]    Overall Loss 1.107206    Objective Loss 1.107206                                        LR 0.001000    Time 0.937826    
2024-02-26 16:46:18,644 - Epoch: [2][  120/  139]    Overall Loss 1.107205    Objective Loss 1.107205                                        LR 0.001000    Time 0.937621    
2024-02-26 16:46:28,000 - Epoch: [2][  130/  139]    Overall Loss 1.107229    Objective Loss 1.107229                                        LR 0.001000    Time 0.937465    
2024-02-26 16:46:40,938 - Epoch: [2][  139/  139]    Overall Loss 1.107088    Objective Loss 1.107088    Top1 81.914921    LR 0.001000    Time 0.969839    
2024-02-26 16:46:41,280 - --- validate (epoch=2)-----------
2024-02-26 16:46:41,281 - 1392 samples (32 per mini-batch)
2024-02-26 16:47:15,917 - Epoch: [2][   10/   44]    Loss 1.154715    Top1 72.062746    
2024-02-26 16:47:49,732 - Epoch: [2][   20/   44]    Loss 1.145065    Top1 73.563021    
2024-02-26 16:48:20,837 - Epoch: [2][   30/   44]    Loss 1.146263    Top1 73.214844    
2024-02-26 16:48:51,808 - Epoch: [2][   40/   44]    Loss 1.142456    Top1 73.729798    
2024-02-26 16:49:02,427 - Epoch: [2][   44/   44]    Loss 1.143432    Top1 73.542204    
2024-02-26 16:49:02,771 - ==> Top1: 73.542    Loss: 1.143

2024-02-26 16:49:02,775 - ==> Best [Top1: 80.308   Sparsity:0.00   Params: 271456 on epoch: 1]
2024-02-26 16:49:02,775 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 16:49:02,805 - 

2024-02-26 16:49:02,805 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:49:12,355 - Epoch: [3][   10/  139]    Overall Loss 1.097782    Objective Loss 1.097782                                        LR 0.001000    Time 0.954683    
2024-02-26 16:49:21,713 - Epoch: [3][   20/  139]    Overall Loss 1.102300    Objective Loss 1.102300                                        LR 0.001000    Time 0.945230    
2024-02-26 16:49:31,059 - Epoch: [3][   30/  139]    Overall Loss 1.102318    Objective Loss 1.102318                                        LR 0.001000    Time 0.941653    
2024-02-26 16:49:40,424 - Epoch: [3][   40/  139]    Overall Loss 1.104566    Objective Loss 1.104566                                        LR 0.001000    Time 0.940347    
2024-02-26 16:49:49,776 - Epoch: [3][   50/  139]    Overall Loss 1.104177    Objective Loss 1.104177                                        LR 0.001000    Time 0.939314    
2024-02-26 16:49:59,115 - Epoch: [3][   60/  139]    Overall Loss 1.104200    Objective Loss 1.104200                                        LR 0.001000    Time 0.938407    
2024-02-26 16:50:08,469 - Epoch: [3][   70/  139]    Overall Loss 1.102639    Objective Loss 1.102639                                        LR 0.001000    Time 0.937967    
2024-02-26 16:50:17,812 - Epoch: [3][   80/  139]    Overall Loss 1.101181    Objective Loss 1.101181                                        LR 0.001000    Time 0.937500    
2024-02-26 16:50:27,166 - Epoch: [3][   90/  139]    Overall Loss 1.100688    Objective Loss 1.100688                                        LR 0.001000    Time 0.937267    
2024-02-26 16:50:36,509 - Epoch: [3][  100/  139]    Overall Loss 1.100324    Objective Loss 1.100324                                        LR 0.001000    Time 0.936957    
2024-02-26 16:50:45,873 - Epoch: [3][  110/  139]    Overall Loss 1.101022    Objective Loss 1.101022                                        LR 0.001000    Time 0.936907    
2024-02-26 16:50:55,214 - Epoch: [3][  120/  139]    Overall Loss 1.101152    Objective Loss 1.101152                                        LR 0.001000    Time 0.936669    
2024-02-26 16:51:04,586 - Epoch: [3][  130/  139]    Overall Loss 1.100949    Objective Loss 1.100949                                        LR 0.001000    Time 0.936704    
2024-02-26 16:51:17,237 - Epoch: [3][  139/  139]    Overall Loss 1.101073    Objective Loss 1.101073    Top1 86.042879    LR 0.001000    Time 0.967065    
2024-02-26 16:51:17,610 - --- validate (epoch=3)-----------
2024-02-26 16:51:17,611 - 1392 samples (32 per mini-batch)
2024-02-26 16:51:50,234 - Epoch: [3][   10/   44]    Loss 1.096225    Top1 83.885796    
2024-02-26 16:52:20,922 - Epoch: [3][   20/   44]    Loss 1.088983    Top1 83.976717    
2024-02-26 16:52:52,925 - Epoch: [3][   30/   44]    Loss 1.091053    Top1 83.605438    
2024-02-26 16:53:23,212 - Epoch: [3][   40/   44]    Loss 1.092592    Top1 83.196945    
2024-02-26 16:53:33,338 - Epoch: [3][   44/   44]    Loss 1.091508    Top1 83.357717    
2024-02-26 16:53:33,666 - ==> Top1: 83.358    Loss: 1.092

2024-02-26 16:53:33,672 - ==> Best [Top1: 83.358   Sparsity:0.00   Params: 271456 on epoch: 3]
2024-02-26 16:53:33,672 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 16:53:33,721 - 

2024-02-26 16:53:33,722 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:53:43,253 - Epoch: [4][   10/  139]    Overall Loss 1.115448    Objective Loss 1.115448                                        LR 0.001000    Time 0.952895    
2024-02-26 16:53:52,586 - Epoch: [4][   20/  139]    Overall Loss 1.110202    Objective Loss 1.110202                                        LR 0.001000    Time 0.943078    
2024-02-26 16:54:01,930 - Epoch: [4][   30/  139]    Overall Loss 1.107073    Objective Loss 1.107073                                        LR 0.001000    Time 0.940184    
2024-02-26 16:54:11,269 - Epoch: [4][   40/  139]    Overall Loss 1.103174    Objective Loss 1.103174                                        LR 0.001000    Time 0.938588    
2024-02-26 16:54:20,617 - Epoch: [4][   50/  139]    Overall Loss 1.101686    Objective Loss 1.101686                                        LR 0.001000    Time 0.937835    
2024-02-26 16:54:29,971 - Epoch: [4][   60/  139]    Overall Loss 1.100311    Objective Loss 1.100311                                        LR 0.001000    Time 0.937410    
2024-02-26 16:54:39,339 - Epoch: [4][   70/  139]    Overall Loss 1.100067    Objective Loss 1.100067                                        LR 0.001000    Time 0.937313    
2024-02-26 16:54:48,692 - Epoch: [4][   80/  139]    Overall Loss 1.100110    Objective Loss 1.100110                                        LR 0.001000    Time 0.937065    
2024-02-26 16:54:58,052 - Epoch: [4][   90/  139]    Overall Loss 1.100321    Objective Loss 1.100321                                        LR 0.001000    Time 0.936938    
2024-02-26 16:55:07,403 - Epoch: [4][  100/  139]    Overall Loss 1.099940    Objective Loss 1.099940                                        LR 0.001000    Time 0.936748    
2024-02-26 16:55:16,750 - Epoch: [4][  110/  139]    Overall Loss 1.099334    Objective Loss 1.099334                                        LR 0.001000    Time 0.936561    
2024-02-26 16:55:26,097 - Epoch: [4][  120/  139]    Overall Loss 1.098889    Objective Loss 1.098889                                        LR 0.001000    Time 0.936396    
2024-02-26 16:55:35,446 - Epoch: [4][  130/  139]    Overall Loss 1.098331    Objective Loss 1.098331                                        LR 0.001000    Time 0.936284    
2024-02-26 16:55:47,963 - Epoch: [4][  139/  139]    Overall Loss 1.097927    Objective Loss 1.097927    Top1 84.456772    LR 0.001000    Time 0.965706    
2024-02-26 16:55:48,235 - --- validate (epoch=4)-----------
2024-02-26 16:55:48,236 - 1392 samples (32 per mini-batch)
2024-02-26 16:56:24,744 - Epoch: [4][   10/   44]    Loss 1.111487    Top1 81.313012    
2024-02-26 16:56:57,421 - Epoch: [4][   20/   44]    Loss 1.110550    Top1 81.389979    
2024-02-26 16:57:30,381 - Epoch: [4][   30/   44]    Loss 1.109334    Top1 81.419230    
2024-02-26 16:58:02,081 - Epoch: [4][   40/   44]    Loss 1.106972    Top1 81.723678    
2024-02-26 16:58:12,776 - Epoch: [4][   44/   44]    Loss 1.106814    Top1 81.793875    
2024-02-26 16:58:13,148 - ==> Top1: 81.794    Loss: 1.107

2024-02-26 16:58:13,156 - ==> Best [Top1: 83.358   Sparsity:0.00   Params: 271456 on epoch: 3]
2024-02-26 16:58:13,156 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 16:58:13,187 - 

2024-02-26 16:58:13,187 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 16:58:22,852 - Epoch: [5][   10/  139]    Overall Loss 1.095518    Objective Loss 1.095518                                        LR 0.001000    Time 0.966262    
2024-02-26 16:58:32,181 - Epoch: [5][   20/  139]    Overall Loss 1.097252    Objective Loss 1.097252                                        LR 0.001000    Time 0.949575    
2024-02-26 16:58:41,505 - Epoch: [5][   30/  139]    Overall Loss 1.098124    Objective Loss 1.098124                                        LR 0.001000    Time 0.943840    
2024-02-26 16:58:50,871 - Epoch: [5][   40/  139]    Overall Loss 1.097866    Objective Loss 1.097866                                        LR 0.001000    Time 0.941997    
2024-02-26 16:59:00,221 - Epoch: [5][   50/  139]    Overall Loss 1.095117    Objective Loss 1.095117                                        LR 0.001000    Time 0.940581    
2024-02-26 16:59:09,573 - Epoch: [5][   60/  139]    Overall Loss 1.095095    Objective Loss 1.095095                                        LR 0.001000    Time 0.939677    
2024-02-26 16:59:18,923 - Epoch: [5][   70/  139]    Overall Loss 1.094785    Objective Loss 1.094785                                        LR 0.001000    Time 0.939006    
2024-02-26 16:59:28,284 - Epoch: [5][   80/  139]    Overall Loss 1.093952    Objective Loss 1.093952                                        LR 0.001000    Time 0.938627    
2024-02-26 16:59:37,652 - Epoch: [5][   90/  139]    Overall Loss 1.093253    Objective Loss 1.093253                                        LR 0.001000    Time 0.938420    
2024-02-26 16:59:47,041 - Epoch: [5][  100/  139]    Overall Loss 1.093915    Objective Loss 1.093915                                        LR 0.001000    Time 0.938457    
2024-02-26 16:59:56,394 - Epoch: [5][  110/  139]    Overall Loss 1.093943    Objective Loss 1.093943                                        LR 0.001000    Time 0.938157    
2024-02-26 17:00:05,748 - Epoch: [5][  120/  139]    Overall Loss 1.093987    Objective Loss 1.093987                                        LR 0.001000    Time 0.937920    
2024-02-26 17:00:15,104 - Epoch: [5][  130/  139]    Overall Loss 1.093762    Objective Loss 1.093762                                        LR 0.001000    Time 0.937742    
2024-02-26 17:00:28,097 - Epoch: [5][  139/  139]    Overall Loss 1.094632    Objective Loss 1.094632    Top1 83.414506    LR 0.001000    Time 0.970490    
2024-02-26 17:00:28,341 - --- validate (epoch=5)-----------
2024-02-26 17:00:28,341 - 1392 samples (32 per mini-batch)
2024-02-26 17:01:03,578 - Epoch: [5][   10/   44]    Loss 1.103000    Top1 82.495571    
2024-02-26 17:01:36,641 - Epoch: [5][   20/   44]    Loss 1.100337    Top1 82.604753    
2024-02-26 17:02:09,551 - Epoch: [5][   30/   44]    Loss 1.103928    Top1 82.335226    
2024-02-26 17:02:43,397 - Epoch: [5][   40/   44]    Loss 1.100303    Top1 82.784115    
2024-02-26 17:02:54,865 - Epoch: [5][   44/   44]    Loss 1.098510    Top1 82.795982    
2024-02-26 17:02:55,119 - ==> Top1: 82.796    Loss: 1.099

2024-02-26 17:02:55,127 - ==> Best [Top1: 83.358   Sparsity:0.00   Params: 271456 on epoch: 3]
2024-02-26 17:02:55,127 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:02:55,161 - 

2024-02-26 17:02:55,161 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:03:04,759 - Epoch: [6][   10/  139]    Overall Loss 1.091470    Objective Loss 1.091470                                        LR 0.001000    Time 0.959684    
2024-02-26 17:03:14,102 - Epoch: [6][   20/  139]    Overall Loss 1.093911    Objective Loss 1.093911                                        LR 0.001000    Time 0.946958    
2024-02-26 17:03:23,434 - Epoch: [6][   30/  139]    Overall Loss 1.092851    Objective Loss 1.092851                                        LR 0.001000    Time 0.942343    
2024-02-26 17:03:32,787 - Epoch: [6][   40/  139]    Overall Loss 1.091941    Objective Loss 1.091941                                        LR 0.001000    Time 0.940566    
2024-02-26 17:03:42,145 - Epoch: [6][   50/  139]    Overall Loss 1.091072    Objective Loss 1.091072                                        LR 0.001000    Time 0.939599    
2024-02-26 17:03:51,489 - Epoch: [6][   60/  139]    Overall Loss 1.089562    Objective Loss 1.089562                                        LR 0.001000    Time 0.938725    
2024-02-26 17:04:00,844 - Epoch: [6][   70/  139]    Overall Loss 1.089979    Objective Loss 1.089979                                        LR 0.001000    Time 0.938257    
2024-02-26 17:04:10,190 - Epoch: [6][   80/  139]    Overall Loss 1.090108    Objective Loss 1.090108                                        LR 0.001000    Time 0.937790    
2024-02-26 17:04:19,541 - Epoch: [6][   90/  139]    Overall Loss 1.089627    Objective Loss 1.089627                                        LR 0.001000    Time 0.937493    
2024-02-26 17:04:28,899 - Epoch: [6][  100/  139]    Overall Loss 1.089839    Objective Loss 1.089839                                        LR 0.001000    Time 0.937319    
2024-02-26 17:04:38,254 - Epoch: [6][  110/  139]    Overall Loss 1.089694    Objective Loss 1.089694                                        LR 0.001000    Time 0.937146    
2024-02-26 17:04:47,620 - Epoch: [6][  120/  139]    Overall Loss 1.089918    Objective Loss 1.089918                                        LR 0.001000    Time 0.937096    
2024-02-26 17:04:56,983 - Epoch: [6][  130/  139]    Overall Loss 1.090527    Objective Loss 1.090527                                        LR 0.001000    Time 0.937027    
2024-02-26 17:05:09,747 - Epoch: [6][  139/  139]    Overall Loss 1.090873    Objective Loss 1.090873    Top1 82.970412    LR 0.001000    Time 0.968182    
2024-02-26 17:05:10,178 - --- validate (epoch=6)-----------
2024-02-26 17:05:10,179 - 1392 samples (32 per mini-batch)
2024-02-26 17:05:44,353 - Epoch: [6][   10/   44]    Loss 1.100761    Top1 81.923213    
2024-02-26 17:06:13,185 - Epoch: [6][   20/   44]    Loss 1.100217    Top1 81.309609    
2024-02-26 17:06:40,729 - Epoch: [6][   30/   44]    Loss 1.097999    Top1 81.505227    
2024-02-26 17:07:07,439 - Epoch: [6][   40/   44]    Loss 1.095351    Top1 81.706074    
2024-02-26 17:07:18,277 - Epoch: [6][   44/   44]    Loss 1.094869    Top1 81.752792    
2024-02-26 17:07:18,713 - ==> Top1: 81.753    Loss: 1.095

2024-02-26 17:07:18,719 - ==> Best [Top1: 83.358   Sparsity:0.00   Params: 271456 on epoch: 3]
2024-02-26 17:07:18,720 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:07:18,757 - 

2024-02-26 17:07:18,758 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:07:28,847 - Epoch: [7][   10/  139]    Overall Loss 1.084584    Objective Loss 1.084584                                        LR 0.001000    Time 1.008689    
2024-02-26 17:07:38,194 - Epoch: [7][   20/  139]    Overall Loss 1.087435    Objective Loss 1.087435                                        LR 0.001000    Time 0.971633    
2024-02-26 17:07:47,536 - Epoch: [7][   30/  139]    Overall Loss 1.087239    Objective Loss 1.087239                                        LR 0.001000    Time 0.959158    
2024-02-26 17:07:56,885 - Epoch: [7][   40/  139]    Overall Loss 1.089715    Objective Loss 1.089715                                        LR 0.001000    Time 0.953070    
2024-02-26 17:08:06,217 - Epoch: [7][   50/  139]    Overall Loss 1.090045    Objective Loss 1.090045                                        LR 0.001000    Time 0.949074    
2024-02-26 17:08:15,601 - Epoch: [7][   60/  139]    Overall Loss 1.088884    Objective Loss 1.088884                                        LR 0.001000    Time 0.947291    
2024-02-26 17:08:24,930 - Epoch: [7][   70/  139]    Overall Loss 1.089135    Objective Loss 1.089135                                        LR 0.001000    Time 0.945228    
2024-02-26 17:08:34,273 - Epoch: [7][   80/  139]    Overall Loss 1.088897    Objective Loss 1.088897                                        LR 0.001000    Time 0.943858    
2024-02-26 17:08:43,638 - Epoch: [7][   90/  139]    Overall Loss 1.090017    Objective Loss 1.090017                                        LR 0.001000    Time 0.943033    
2024-02-26 17:08:52,996 - Epoch: [7][  100/  139]    Overall Loss 1.089199    Objective Loss 1.089199                                        LR 0.001000    Time 0.942296    
2024-02-26 17:09:02,351 - Epoch: [7][  110/  139]    Overall Loss 1.089875    Objective Loss 1.089875                                        LR 0.001000    Time 0.941673    
2024-02-26 17:09:11,706 - Epoch: [7][  120/  139]    Overall Loss 1.089597    Objective Loss 1.089597                                        LR 0.001000    Time 0.941155    
2024-02-26 17:09:21,062 - Epoch: [7][  130/  139]    Overall Loss 1.089279    Objective Loss 1.089279                                        LR 0.001000    Time 0.940725    
2024-02-26 17:09:33,709 - Epoch: [7][  139/  139]    Overall Loss 1.089483    Objective Loss 1.089483    Top1 84.739065    LR 0.001000    Time 0.970801    
2024-02-26 17:09:34,047 - --- validate (epoch=7)-----------
2024-02-26 17:09:34,048 - 1392 samples (32 per mini-batch)
2024-02-26 17:10:08,891 - Epoch: [7][   10/   44]    Loss 1.101839    Top1 82.626905    
2024-02-26 17:10:40,483 - Epoch: [7][   20/   44]    Loss 1.100871    Top1 83.159761    
2024-02-26 17:11:11,868 - Epoch: [7][   30/   44]    Loss 1.097459    Top1 83.597043    
2024-02-26 17:11:41,314 - Epoch: [7][   40/   44]    Loss 1.096665    Top1 83.589927    
2024-02-26 17:11:51,311 - Epoch: [7][   44/   44]    Loss 1.097432    Top1 83.593530    
2024-02-26 17:11:51,566 - ==> Top1: 83.594    Loss: 1.097

2024-02-26 17:11:51,573 - ==> Best [Top1: 83.594   Sparsity:0.00   Params: 271456 on epoch: 7]
2024-02-26 17:11:51,573 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:11:51,608 - 

2024-02-26 17:11:51,609 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:12:01,193 - Epoch: [8][   10/  139]    Overall Loss 1.090872    Objective Loss 1.090872                                        LR 0.001000    Time 0.958323    
2024-02-26 17:12:10,563 - Epoch: [8][   20/  139]    Overall Loss 1.089877    Objective Loss 1.089877                                        LR 0.001000    Time 0.947606    
2024-02-26 17:12:19,918 - Epoch: [8][   30/  139]    Overall Loss 1.091851    Objective Loss 1.091851                                        LR 0.001000    Time 0.943565    
2024-02-26 17:12:29,261 - Epoch: [8][   40/  139]    Overall Loss 1.091807    Objective Loss 1.091807                                        LR 0.001000    Time 0.941250    
2024-02-26 17:12:38,607 - Epoch: [8][   50/  139]    Overall Loss 1.089919    Objective Loss 1.089919                                        LR 0.001000    Time 0.939895    
2024-02-26 17:12:47,946 - Epoch: [8][   60/  139]    Overall Loss 1.090205    Objective Loss 1.090205                                        LR 0.001000    Time 0.938889    
2024-02-26 17:12:57,311 - Epoch: [8][   70/  139]    Overall Loss 1.089160    Objective Loss 1.089160                                        LR 0.001000    Time 0.938548    
2024-02-26 17:13:06,655 - Epoch: [8][   80/  139]    Overall Loss 1.088175    Objective Loss 1.088175                                        LR 0.001000    Time 0.938014    
2024-02-26 17:13:15,999 - Epoch: [8][   90/  139]    Overall Loss 1.086903    Objective Loss 1.086903                                        LR 0.001000    Time 0.937611    
2024-02-26 17:13:25,344 - Epoch: [8][  100/  139]    Overall Loss 1.086391    Objective Loss 1.086391                                        LR 0.001000    Time 0.937289    
2024-02-26 17:13:34,691 - Epoch: [8][  110/  139]    Overall Loss 1.085952    Objective Loss 1.085952                                        LR 0.001000    Time 0.937054    
2024-02-26 17:13:44,038 - Epoch: [8][  120/  139]    Overall Loss 1.086939    Objective Loss 1.086939                                        LR 0.001000    Time 0.936853    
2024-02-26 17:13:53,386 - Epoch: [8][  130/  139]    Overall Loss 1.087036    Objective Loss 1.087036                                        LR 0.001000    Time 0.936689    
2024-02-26 17:14:05,659 - Epoch: [8][  139/  139]    Overall Loss 1.087206    Objective Loss 1.087206    Top1 84.464237    LR 0.001000    Time 0.964336    
2024-02-26 17:14:06,008 - --- validate (epoch=8)-----------
2024-02-26 17:14:06,008 - 1392 samples (32 per mini-batch)
2024-02-26 17:14:40,423 - Epoch: [8][   10/   44]    Loss 1.096076    Top1 83.481471    
2024-02-26 17:15:13,685 - Epoch: [8][   20/   44]    Loss 1.091013    Top1 83.930342    
2024-02-26 17:15:45,819 - Epoch: [8][   30/   44]    Loss 1.090341    Top1 83.920081    
2024-02-26 17:16:15,872 - Epoch: [8][   40/   44]    Loss 1.092193    Top1 83.479211    
2024-02-26 17:16:25,687 - Epoch: [8][   44/   44]    Loss 1.091107    Top1 83.567304    
2024-02-26 17:16:26,096 - ==> Top1: 83.567    Loss: 1.091

2024-02-26 17:16:26,099 - ==> Best [Top1: 83.594   Sparsity:0.00   Params: 271456 on epoch: 7]
2024-02-26 17:16:26,099 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:16:26,123 - 

2024-02-26 17:16:26,124 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:16:35,634 - Epoch: [9][   10/  139]    Overall Loss 1.089871    Objective Loss 1.089871                                        LR 0.001000    Time 0.950802    
2024-02-26 17:16:44,981 - Epoch: [9][   20/  139]    Overall Loss 1.084561    Objective Loss 1.084561                                        LR 0.001000    Time 0.942705    
2024-02-26 17:16:54,312 - Epoch: [9][   30/  139]    Overall Loss 1.090293    Objective Loss 1.090293                                        LR 0.001000    Time 0.939484    
2024-02-26 17:17:03,681 - Epoch: [9][   40/  139]    Overall Loss 1.090361    Objective Loss 1.090361                                        LR 0.001000    Time 0.938818    
2024-02-26 17:17:13,040 - Epoch: [9][   50/  139]    Overall Loss 1.091315    Objective Loss 1.091315                                        LR 0.001000    Time 0.938219    
2024-02-26 17:17:22,377 - Epoch: [9][   60/  139]    Overall Loss 1.090411    Objective Loss 1.090411                                        LR 0.001000    Time 0.937463    
2024-02-26 17:17:31,723 - Epoch: [9][   70/  139]    Overall Loss 1.091505    Objective Loss 1.091505                                        LR 0.001000    Time 0.937044    
2024-02-26 17:17:41,067 - Epoch: [9][   80/  139]    Overall Loss 1.091937    Objective Loss 1.091937                                        LR 0.001000    Time 0.936704    
2024-02-26 17:17:50,410 - Epoch: [9][   90/  139]    Overall Loss 1.090982    Objective Loss 1.090982                                        LR 0.001000    Time 0.936437    
2024-02-26 17:17:59,752 - Epoch: [9][  100/  139]    Overall Loss 1.089926    Objective Loss 1.089926                                        LR 0.001000    Time 0.936208    
2024-02-26 17:18:09,101 - Epoch: [9][  110/  139]    Overall Loss 1.089046    Objective Loss 1.089046                                        LR 0.001000    Time 0.936087    
2024-02-26 17:18:18,449 - Epoch: [9][  120/  139]    Overall Loss 1.088649    Objective Loss 1.088649                                        LR 0.001000    Time 0.935978    
2024-02-26 17:18:27,789 - Epoch: [9][  130/  139]    Overall Loss 1.088669    Objective Loss 1.088669                                        LR 0.001000    Time 0.935823    
2024-02-26 17:18:40,321 - Epoch: [9][  139/  139]    Overall Loss 1.088440    Objective Loss 1.088440    Top1 86.519475    LR 0.001000    Time 0.965379    
2024-02-26 17:18:40,656 - --- validate (epoch=9)-----------
2024-02-26 17:18:40,657 - 1392 samples (32 per mini-batch)
2024-02-26 17:19:15,052 - Epoch: [9][   10/   44]    Loss 1.068129    Top1 87.114490    
2024-02-26 17:19:48,785 - Epoch: [9][   20/   44]    Loss 1.074801    Top1 86.662657    
2024-02-26 17:20:23,149 - Epoch: [9][   30/   44]    Loss 1.081067    Top1 85.957000    
2024-02-26 17:20:55,177 - Epoch: [9][   40/   44]    Loss 1.080318    Top1 85.676471    
2024-02-26 17:21:07,034 - Epoch: [9][   44/   44]    Loss 1.080105    Top1 85.484485    
2024-02-26 17:21:07,285 - ==> Top1: 85.484    Loss: 1.080

2024-02-26 17:21:07,293 - ==> Best [Top1: 85.484   Sparsity:0.00   Params: 271456 on epoch: 9]
2024-02-26 17:21:07,293 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:21:07,331 - 

2024-02-26 17:21:07,331 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:21:16,985 - Epoch: [10][   10/  139]    Overall Loss 1.083769    Objective Loss 1.083769                                        LR 0.001000    Time 0.965191    
2024-02-26 17:21:26,313 - Epoch: [10][   20/  139]    Overall Loss 1.086530    Objective Loss 1.086530                                        LR 0.001000    Time 0.948977    
2024-02-26 17:21:35,648 - Epoch: [10][   30/  139]    Overall Loss 1.082711    Objective Loss 1.082711                                        LR 0.001000    Time 0.943805    
2024-02-26 17:21:44,987 - Epoch: [10][   40/  139]    Overall Loss 1.081286    Objective Loss 1.081286                                        LR 0.001000    Time 0.941313    
2024-02-26 17:21:54,324 - Epoch: [10][   50/  139]    Overall Loss 1.081856    Objective Loss 1.081856                                        LR 0.001000    Time 0.939782    
2024-02-26 17:22:03,676 - Epoch: [10][   60/  139]    Overall Loss 1.083067    Objective Loss 1.083067                                        LR 0.001000    Time 0.939007    
2024-02-26 17:22:13,041 - Epoch: [10][   70/  139]    Overall Loss 1.083436    Objective Loss 1.083436                                        LR 0.001000    Time 0.938645    
2024-02-26 17:22:22,419 - Epoch: [10][   80/  139]    Overall Loss 1.082727    Objective Loss 1.082727                                        LR 0.001000    Time 0.938526    
2024-02-26 17:22:31,762 - Epoch: [10][   90/  139]    Overall Loss 1.082843    Objective Loss 1.082843                                        LR 0.001000    Time 0.938054    
2024-02-26 17:22:41,108 - Epoch: [10][  100/  139]    Overall Loss 1.082703    Objective Loss 1.082703                                        LR 0.001000    Time 0.937703    
2024-02-26 17:22:50,452 - Epoch: [10][  110/  139]    Overall Loss 1.083534    Objective Loss 1.083534                                        LR 0.001000    Time 0.937402    
2024-02-26 17:22:59,800 - Epoch: [10][  120/  139]    Overall Loss 1.084391    Objective Loss 1.084391                                        LR 0.001000    Time 0.937175    
2024-02-26 17:23:09,143 - Epoch: [10][  130/  139]    Overall Loss 1.084427    Objective Loss 1.084427                                        LR 0.001000    Time 0.936948    
2024-02-26 17:23:21,352 - Epoch: [10][  139/  139]    Overall Loss 1.084633    Objective Loss 1.084633    Top1 88.357445    LR 0.001000    Time 0.964118    
2024-02-26 17:23:21,697 - --- validate (epoch=10)-----------
2024-02-26 17:23:21,698 - 1392 samples (32 per mini-batch)
2024-02-26 17:23:56,719 - Epoch: [10][   10/   44]    Loss 1.078512    Top1 85.679178    
2024-02-26 17:24:30,738 - Epoch: [10][   20/   44]    Loss 1.081994    Top1 85.473672    
2024-02-26 17:25:04,833 - Epoch: [10][   30/   44]    Loss 1.080804    Top1 85.696248    
2024-02-26 17:25:40,703 - Epoch: [10][   40/   44]    Loss 1.080343    Top1 85.723671    
2024-02-26 17:25:52,375 - Epoch: [10][   44/   44]    Loss 1.080440    Top1 85.671295    
2024-02-26 17:25:52,633 - ==> Top1: 85.671    Loss: 1.080

2024-02-26 17:25:52,641 - ==> Best [Top1: 85.671   Sparsity:0.00   Params: 271456 on epoch: 10]
2024-02-26 17:25:52,642 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:25:52,679 - 

2024-02-26 17:25:52,679 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:26:02,371 - Epoch: [11][   10/  139]    Overall Loss 1.072249    Objective Loss 1.072249                                        LR 0.001000    Time 0.969059    
2024-02-26 17:26:11,701 - Epoch: [11][   20/  139]    Overall Loss 1.078898    Objective Loss 1.078898                                        LR 0.001000    Time 0.951018    
2024-02-26 17:26:21,033 - Epoch: [11][   30/  139]    Overall Loss 1.078161    Objective Loss 1.078161                                        LR 0.001000    Time 0.945053    
2024-02-26 17:26:30,356 - Epoch: [11][   40/  139]    Overall Loss 1.079995    Objective Loss 1.079995                                        LR 0.001000    Time 0.941866    
2024-02-26 17:26:39,700 - Epoch: [11][   50/  139]    Overall Loss 1.081024    Objective Loss 1.081024                                        LR 0.001000    Time 0.940366    
2024-02-26 17:26:49,037 - Epoch: [11][   60/  139]    Overall Loss 1.080388    Objective Loss 1.080388                                        LR 0.001000    Time 0.939244    
2024-02-26 17:26:58,379 - Epoch: [11][   70/  139]    Overall Loss 1.081037    Objective Loss 1.081037                                        LR 0.001000    Time 0.938519    
2024-02-26 17:27:07,728 - Epoch: [11][   80/  139]    Overall Loss 1.082479    Objective Loss 1.082479                                        LR 0.001000    Time 0.938054    
2024-02-26 17:27:17,069 - Epoch: [11][   90/  139]    Overall Loss 1.082574    Objective Loss 1.082574                                        LR 0.001000    Time 0.937617    
2024-02-26 17:27:26,417 - Epoch: [11][  100/  139]    Overall Loss 1.082688    Objective Loss 1.082688                                        LR 0.001000    Time 0.937330    
2024-02-26 17:27:35,787 - Epoch: [11][  110/  139]    Overall Loss 1.082789    Objective Loss 1.082789                                        LR 0.001000    Time 0.937292    
2024-02-26 17:27:45,148 - Epoch: [11][  120/  139]    Overall Loss 1.083112    Objective Loss 1.083112                                        LR 0.001000    Time 0.937186    
2024-02-26 17:27:54,499 - Epoch: [11][  130/  139]    Overall Loss 1.083232    Objective Loss 1.083232                                        LR 0.001000    Time 0.937021    
2024-02-26 17:28:06,895 - Epoch: [11][  139/  139]    Overall Loss 1.083711    Objective Loss 1.083711    Top1 81.470845    LR 0.001000    Time 0.965529    
2024-02-26 17:28:07,235 - --- validate (epoch=11)-----------
2024-02-26 17:28:07,235 - 1392 samples (32 per mini-batch)
2024-02-26 17:28:40,372 - Epoch: [11][   10/   44]    Loss 1.103618    Top1 81.781430    
2024-02-26 17:29:14,932 - Epoch: [11][   20/   44]    Loss 1.098358    Top1 82.218857    
2024-02-26 17:29:47,440 - Epoch: [11][   30/   44]    Loss 1.104128    Top1 81.488030    
2024-02-26 17:30:20,135 - Epoch: [11][   40/   44]    Loss 1.100541    Top1 81.502921    
2024-02-26 17:30:32,169 - Epoch: [11][   44/   44]    Loss 1.102527    Top1 81.545823    
2024-02-26 17:30:32,394 - ==> Top1: 81.546    Loss: 1.103

2024-02-26 17:30:32,401 - ==> Best [Top1: 85.671   Sparsity:0.00   Params: 271456 on epoch: 10]
2024-02-26 17:30:32,401 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:30:32,435 - 

2024-02-26 17:30:32,436 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:30:42,051 - Epoch: [12][   10/  139]    Overall Loss 1.091639    Objective Loss 1.091639                                        LR 0.001000    Time 0.961178    
2024-02-26 17:30:51,388 - Epoch: [12][   20/  139]    Overall Loss 1.087167    Objective Loss 1.087167                                        LR 0.001000    Time 0.947426    
2024-02-26 17:31:00,733 - Epoch: [12][   30/  139]    Overall Loss 1.087608    Objective Loss 1.087608                                        LR 0.001000    Time 0.943091    
2024-02-26 17:31:10,070 - Epoch: [12][   40/  139]    Overall Loss 1.090634    Objective Loss 1.090634                                        LR 0.001000    Time 0.940736    
2024-02-26 17:31:19,405 - Epoch: [12][   50/  139]    Overall Loss 1.089237    Objective Loss 1.089237                                        LR 0.001000    Time 0.939274    
2024-02-26 17:31:28,753 - Epoch: [12][   60/  139]    Overall Loss 1.088420    Objective Loss 1.088420                                        LR 0.001000    Time 0.938517    
2024-02-26 17:31:38,098 - Epoch: [12][   70/  139]    Overall Loss 1.088034    Objective Loss 1.088034                                        LR 0.001000    Time 0.937943    
2024-02-26 17:31:47,445 - Epoch: [12][   80/  139]    Overall Loss 1.086431    Objective Loss 1.086431                                        LR 0.001000    Time 0.937520    
2024-02-26 17:31:56,798 - Epoch: [12][   90/  139]    Overall Loss 1.086064    Objective Loss 1.086064                                        LR 0.001000    Time 0.937277    
2024-02-26 17:32:06,142 - Epoch: [12][  100/  139]    Overall Loss 1.085558    Objective Loss 1.085558                                        LR 0.001000    Time 0.936978    
2024-02-26 17:32:15,499 - Epoch: [12][  110/  139]    Overall Loss 1.085364    Objective Loss 1.085364                                        LR 0.001000    Time 0.936860    
2024-02-26 17:32:24,840 - Epoch: [12][  120/  139]    Overall Loss 1.084635    Objective Loss 1.084635                                        LR 0.001000    Time 0.936621    
2024-02-26 17:32:34,180 - Epoch: [12][  130/  139]    Overall Loss 1.084339    Objective Loss 1.084339                                        LR 0.001000    Time 0.936421    
2024-02-26 17:32:46,473 - Epoch: [12][  139/  139]    Overall Loss 1.083775    Objective Loss 1.083775    Top1 86.073419    LR 0.001000    Time 0.964221    
2024-02-26 17:32:47,451 - --- validate (epoch=12)-----------
2024-02-26 17:32:47,452 - 1392 samples (32 per mini-batch)
2024-02-26 17:33:22,625 - Epoch: [12][   10/   44]    Loss 1.081700    Top1 85.844003    
2024-02-26 17:33:56,563 - Epoch: [12][   20/   44]    Loss 1.079628    Top1 86.397289    
2024-02-26 17:34:29,330 - Epoch: [12][   30/   44]    Loss 1.077678    Top1 86.407910    
2024-02-26 17:35:01,797 - Epoch: [12][   40/   44]    Loss 1.081208    Top1 86.286312    
2024-02-26 17:35:13,793 - Epoch: [12][   44/   44]    Loss 1.082046    Top1 86.329437    
2024-02-26 17:35:14,143 - ==> Top1: 86.329    Loss: 1.082

2024-02-26 17:35:14,150 - ==> Best [Top1: 86.329   Sparsity:0.00   Params: 271456 on epoch: 12]
2024-02-26 17:35:14,151 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:35:14,196 - 

2024-02-26 17:35:14,196 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:35:23,918 - Epoch: [13][   10/  139]    Overall Loss 1.080860    Objective Loss 1.080860                                        LR 0.001000    Time 0.972022    
2024-02-26 17:35:33,250 - Epoch: [13][   20/  139]    Overall Loss 1.078076    Objective Loss 1.078076                                        LR 0.001000    Time 0.952554    
2024-02-26 17:35:42,586 - Epoch: [13][   30/  139]    Overall Loss 1.075902    Objective Loss 1.075902                                        LR 0.001000    Time 0.946233    
2024-02-26 17:35:51,928 - Epoch: [13][   40/  139]    Overall Loss 1.077312    Objective Loss 1.077312                                        LR 0.001000    Time 0.943214    
2024-02-26 17:36:01,281 - Epoch: [13][   50/  139]    Overall Loss 1.078947    Objective Loss 1.078947                                        LR 0.001000    Time 0.941619    
2024-02-26 17:36:10,626 - Epoch: [13][   60/  139]    Overall Loss 1.080516    Objective Loss 1.080516                                        LR 0.001000    Time 0.940419    
2024-02-26 17:36:19,975 - Epoch: [13][   70/  139]    Overall Loss 1.079635    Objective Loss 1.079635                                        LR 0.001000    Time 0.939627    
2024-02-26 17:36:29,326 - Epoch: [13][   80/  139]    Overall Loss 1.080822    Objective Loss 1.080822                                        LR 0.001000    Time 0.939056    
2024-02-26 17:36:38,692 - Epoch: [13][   90/  139]    Overall Loss 1.081768    Objective Loss 1.081768                                        LR 0.001000    Time 0.938770    
2024-02-26 17:36:48,026 - Epoch: [13][  100/  139]    Overall Loss 1.081520    Objective Loss 1.081520                                        LR 0.001000    Time 0.938235    
2024-02-26 17:36:57,382 - Epoch: [13][  110/  139]    Overall Loss 1.081564    Objective Loss 1.081564                                        LR 0.001000    Time 0.937990    
2024-02-26 17:37:06,748 - Epoch: [13][  120/  139]    Overall Loss 1.081831    Objective Loss 1.081831                                        LR 0.001000    Time 0.937871    
2024-02-26 17:37:16,100 - Epoch: [13][  130/  139]    Overall Loss 1.082524    Objective Loss 1.082524                                        LR 0.001000    Time 0.937655    
2024-02-26 17:37:29,077 - Epoch: [13][  139/  139]    Overall Loss 1.082138    Objective Loss 1.082138    Top1 87.292526    LR 0.001000    Time 0.970301    
2024-02-26 17:37:29,308 - --- validate (epoch=13)-----------
2024-02-26 17:37:29,308 - 1392 samples (32 per mini-batch)
2024-02-26 17:38:05,994 - Epoch: [13][   10/   44]    Loss 1.128022    Top1 76.120134    
2024-02-26 17:38:43,242 - Epoch: [13][   20/   44]    Loss 1.127955    Top1 77.163216    
2024-02-26 17:39:14,749 - Epoch: [13][   30/   44]    Loss 1.127898    Top1 77.409613    
2024-02-26 17:39:47,618 - Epoch: [13][   40/   44]    Loss 1.130044    Top1 77.503427    
2024-02-26 17:39:58,262 - Epoch: [13][   44/   44]    Loss 1.129300    Top1 77.687661    
2024-02-26 17:39:58,520 - ==> Top1: 77.688    Loss: 1.129

2024-02-26 17:39:58,527 - ==> Best [Top1: 86.329   Sparsity:0.00   Params: 271456 on epoch: 12]
2024-02-26 17:39:58,527 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:39:58,558 - 

2024-02-26 17:39:58,558 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:40:08,301 - Epoch: [14][   10/  139]    Overall Loss 1.078638    Objective Loss 1.078638                                        LR 0.001000    Time 0.974121    
2024-02-26 17:40:17,633 - Epoch: [14][   20/  139]    Overall Loss 1.075887    Objective Loss 1.075887                                        LR 0.001000    Time 0.953657    
2024-02-26 17:40:27,000 - Epoch: [14][   30/  139]    Overall Loss 1.076584    Objective Loss 1.076584                                        LR 0.001000    Time 0.947974    
2024-02-26 17:40:36,357 - Epoch: [14][   40/  139]    Overall Loss 1.078876    Objective Loss 1.078876                                        LR 0.001000    Time 0.944874    
2024-02-26 17:40:45,704 - Epoch: [14][   50/  139]    Overall Loss 1.079580    Objective Loss 1.079580                                        LR 0.001000    Time 0.942840    
2024-02-26 17:40:55,037 - Epoch: [14][   60/  139]    Overall Loss 1.079005    Objective Loss 1.079005                                        LR 0.001000    Time 0.941231    
2024-02-26 17:41:04,391 - Epoch: [14][   70/  139]    Overall Loss 1.078670    Objective Loss 1.078670                                        LR 0.001000    Time 0.940403    
2024-02-26 17:41:13,744 - Epoch: [14][   80/  139]    Overall Loss 1.078578    Objective Loss 1.078578                                        LR 0.001000    Time 0.939759    
2024-02-26 17:41:23,081 - Epoch: [14][   90/  139]    Overall Loss 1.078833    Objective Loss 1.078833                                        LR 0.001000    Time 0.939076    
2024-02-26 17:41:32,425 - Epoch: [14][  100/  139]    Overall Loss 1.080137    Objective Loss 1.080137                                        LR 0.001000    Time 0.938602    
2024-02-26 17:41:41,776 - Epoch: [14][  110/  139]    Overall Loss 1.081132    Objective Loss 1.081132                                        LR 0.001000    Time 0.938283    
2024-02-26 17:41:51,120 - Epoch: [14][  120/  139]    Overall Loss 1.081420    Objective Loss 1.081420                                        LR 0.001000    Time 0.937954    
2024-02-26 17:42:00,463 - Epoch: [14][  130/  139]    Overall Loss 1.081268    Objective Loss 1.081268                                        LR 0.001000    Time 0.937664    
2024-02-26 17:42:12,994 - Epoch: [14][  139/  139]    Overall Loss 1.081129    Objective Loss 1.081129    Top1 88.552629    LR 0.001000    Time 0.967099    
2024-02-26 17:42:13,298 - --- validate (epoch=14)-----------
2024-02-26 17:42:13,300 - 1392 samples (32 per mini-batch)
2024-02-26 17:42:46,970 - Epoch: [14][   10/   44]    Loss 1.090992    Top1 83.662909    
2024-02-26 17:43:21,353 - Epoch: [14][   20/   44]    Loss 1.088832    Top1 84.377009    
2024-02-26 17:43:54,643 - Epoch: [14][   30/   44]    Loss 1.085713    Top1 84.937789    
2024-02-26 17:44:25,259 - Epoch: [14][   40/   44]    Loss 1.086406    Top1 85.140440    
2024-02-26 17:44:34,607 - Epoch: [14][   44/   44]    Loss 1.087402    Top1 85.007192    
2024-02-26 17:44:34,831 - ==> Top1: 85.007    Loss: 1.087

2024-02-26 17:44:34,834 - ==> Best [Top1: 86.329   Sparsity:0.00   Params: 271456 on epoch: 12]
2024-02-26 17:44:34,835 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:44:34,867 - 

2024-02-26 17:44:34,867 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:44:44,419 - Epoch: [15][   10/  139]    Overall Loss 1.083363    Objective Loss 1.083363                                        LR 0.001000    Time 0.954936    
2024-02-26 17:44:53,765 - Epoch: [15][   20/  139]    Overall Loss 1.076818    Objective Loss 1.076818                                        LR 0.001000    Time 0.944727    
2024-02-26 17:45:03,102 - Epoch: [15][   30/  139]    Overall Loss 1.078264    Objective Loss 1.078264                                        LR 0.001000    Time 0.941041    
2024-02-26 17:45:12,447 - Epoch: [15][   40/  139]    Overall Loss 1.079527    Objective Loss 1.079527                                        LR 0.001000    Time 0.939379    
2024-02-26 17:45:21,820 - Epoch: [15][   50/  139]    Overall Loss 1.080609    Objective Loss 1.080609                                        LR 0.001000    Time 0.938943    
2024-02-26 17:45:31,198 - Epoch: [15][   60/  139]    Overall Loss 1.079959    Objective Loss 1.079959                                        LR 0.001000    Time 0.938702    
2024-02-26 17:45:40,556 - Epoch: [15][   70/  139]    Overall Loss 1.080032    Objective Loss 1.080032                                        LR 0.001000    Time 0.938282    
2024-02-26 17:45:49,894 - Epoch: [15][   80/  139]    Overall Loss 1.080326    Objective Loss 1.080326                                        LR 0.001000    Time 0.937708    
2024-02-26 17:45:59,246 - Epoch: [15][   90/  139]    Overall Loss 1.079460    Objective Loss 1.079460                                        LR 0.001000    Time 0.937423    
2024-02-26 17:46:08,591 - Epoch: [15][  100/  139]    Overall Loss 1.079765    Objective Loss 1.079765                                        LR 0.001000    Time 0.937129    
2024-02-26 17:46:17,937 - Epoch: [15][  110/  139]    Overall Loss 1.080112    Objective Loss 1.080112                                        LR 0.001000    Time 0.936892    
2024-02-26 17:46:27,283 - Epoch: [15][  120/  139]    Overall Loss 1.080834    Objective Loss 1.080834                                        LR 0.001000    Time 0.936700    
2024-02-26 17:46:36,631 - Epoch: [15][  130/  139]    Overall Loss 1.080463    Objective Loss 1.080463                                        LR 0.001000    Time 0.936555    
2024-02-26 17:46:48,906 - Epoch: [15][  139/  139]    Overall Loss 1.080306    Objective Loss 1.080306    Top1 91.101469    LR 0.001000    Time 0.964216    
2024-02-26 17:46:49,079 - --- validate (epoch=15)-----------
2024-02-26 17:46:49,080 - 1392 samples (32 per mini-batch)
2024-02-26 17:47:20,723 - Epoch: [15][   10/   44]    Loss 1.102310    Top1 84.320255    
2024-02-26 17:47:49,812 - Epoch: [15][   20/   44]    Loss 1.101669    Top1 84.490934    
2024-02-26 17:48:24,401 - Epoch: [15][   30/   44]    Loss 1.100891    Top1 84.655338    
2024-02-26 17:48:57,350 - Epoch: [15][   40/   44]    Loss 1.099337    Top1 84.544654    
2024-02-26 17:49:08,941 - Epoch: [15][   44/   44]    Loss 1.098746    Top1 84.680500    
2024-02-26 17:49:09,189 - ==> Top1: 84.680    Loss: 1.099

2024-02-26 17:49:09,197 - ==> Best [Top1: 86.329   Sparsity:0.00   Params: 271456 on epoch: 12]
2024-02-26 17:49:09,197 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:49:09,229 - 

2024-02-26 17:49:09,229 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:49:18,881 - Epoch: [16][   10/  139]    Overall Loss 1.077687    Objective Loss 1.077687                                        LR 0.001000    Time 0.965018    
2024-02-26 17:49:28,221 - Epoch: [16][   20/  139]    Overall Loss 1.079148    Objective Loss 1.079148                                        LR 0.001000    Time 0.949480    
2024-02-26 17:49:37,571 - Epoch: [16][   30/  139]    Overall Loss 1.077474    Objective Loss 1.077474                                        LR 0.001000    Time 0.944619    
2024-02-26 17:49:46,904 - Epoch: [16][   40/  139]    Overall Loss 1.077275    Objective Loss 1.077275                                        LR 0.001000    Time 0.941760    
2024-02-26 17:49:56,240 - Epoch: [16][   50/  139]    Overall Loss 1.079174    Objective Loss 1.079174                                        LR 0.001000    Time 0.940121    
2024-02-26 17:50:05,581 - Epoch: [16][   60/  139]    Overall Loss 1.077921    Objective Loss 1.077921                                        LR 0.001000    Time 0.939112    
2024-02-26 17:50:14,910 - Epoch: [16][   70/  139]    Overall Loss 1.078059    Objective Loss 1.078059                                        LR 0.001000    Time 0.938216    
2024-02-26 17:50:24,274 - Epoch: [16][   80/  139]    Overall Loss 1.078561    Objective Loss 1.078561                                        LR 0.001000    Time 0.937970    
2024-02-26 17:50:33,636 - Epoch: [16][   90/  139]    Overall Loss 1.077994    Objective Loss 1.077994                                        LR 0.001000    Time 0.937773    
2024-02-26 17:50:42,997 - Epoch: [16][  100/  139]    Overall Loss 1.078755    Objective Loss 1.078755                                        LR 0.001000    Time 0.937599    
2024-02-26 17:50:52,340 - Epoch: [16][  110/  139]    Overall Loss 1.078561    Objective Loss 1.078561                                        LR 0.001000    Time 0.937294    
2024-02-26 17:51:01,690 - Epoch: [16][  120/  139]    Overall Loss 1.078238    Objective Loss 1.078238                                        LR 0.001000    Time 0.937093    
2024-02-26 17:51:11,038 - Epoch: [16][  130/  139]    Overall Loss 1.078510    Objective Loss 1.078510                                        LR 0.001000    Time 0.936919    
2024-02-26 17:51:23,514 - Epoch: [16][  139/  139]    Overall Loss 1.079258    Objective Loss 1.079258    Top1 87.900530    LR 0.001000    Time 0.966007    
2024-02-26 17:51:23,784 - --- validate (epoch=16)-----------
2024-02-26 17:51:23,785 - 1392 samples (32 per mini-batch)
2024-02-26 17:51:55,535 - Epoch: [16][   10/   44]    Loss 1.092236    Top1 85.846653    
2024-02-26 17:52:22,133 - Epoch: [16][   20/   44]    Loss 1.083084    Top1 86.653273    
2024-02-26 17:52:53,657 - Epoch: [16][   30/   44]    Loss 1.081648    Top1 86.622994    
2024-02-26 17:53:25,775 - Epoch: [16][   40/   44]    Loss 1.081284    Top1 86.620174    
2024-02-26 17:53:36,521 - Epoch: [16][   44/   44]    Loss 1.080234    Top1 86.716920    
2024-02-26 17:53:36,782 - ==> Top1: 86.717    Loss: 1.080

2024-02-26 17:53:36,789 - ==> Best [Top1: 86.717   Sparsity:0.00   Params: 271456 on epoch: 16]
2024-02-26 17:53:36,790 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:53:36,832 - 

2024-02-26 17:53:36,832 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:53:46,569 - Epoch: [17][   10/  139]    Overall Loss 1.075673    Objective Loss 1.075673                                        LR 0.001000    Time 0.973344    
2024-02-26 17:53:55,901 - Epoch: [17][   20/  139]    Overall Loss 1.075478    Objective Loss 1.075478                                        LR 0.001000    Time 0.953276    
2024-02-26 17:54:05,240 - Epoch: [17][   30/  139]    Overall Loss 1.075815    Objective Loss 1.075815                                        LR 0.001000    Time 0.946798    
2024-02-26 17:54:14,587 - Epoch: [17][   40/  139]    Overall Loss 1.078843    Objective Loss 1.078843                                        LR 0.001000    Time 0.943764    
2024-02-26 17:54:23,942 - Epoch: [17][   50/  139]    Overall Loss 1.079257    Objective Loss 1.079257                                        LR 0.001000    Time 0.942102    
2024-02-26 17:54:33,280 - Epoch: [17][   60/  139]    Overall Loss 1.077900    Objective Loss 1.077900                                        LR 0.001000    Time 0.940710    
2024-02-26 17:54:42,624 - Epoch: [17][   70/  139]    Overall Loss 1.077661    Objective Loss 1.077661                                        LR 0.001000    Time 0.939800    
2024-02-26 17:54:51,965 - Epoch: [17][   80/  139]    Overall Loss 1.076457    Objective Loss 1.076457                                        LR 0.001000    Time 0.939084    
2024-02-26 17:55:01,314 - Epoch: [17][   90/  139]    Overall Loss 1.077888    Objective Loss 1.077888                                        LR 0.001000    Time 0.938607    
2024-02-26 17:55:10,655 - Epoch: [17][  100/  139]    Overall Loss 1.078634    Objective Loss 1.078634                                        LR 0.001000    Time 0.938158    
2024-02-26 17:55:20,037 - Epoch: [17][  110/  139]    Overall Loss 1.078005    Objective Loss 1.078005                                        LR 0.001000    Time 0.938152    
2024-02-26 17:55:29,395 - Epoch: [17][  120/  139]    Overall Loss 1.078092    Objective Loss 1.078092                                        LR 0.001000    Time 0.937950    
2024-02-26 17:55:38,750 - Epoch: [17][  130/  139]    Overall Loss 1.078054    Objective Loss 1.078054                                        LR 0.001000    Time 0.937756    
2024-02-26 17:55:51,290 - Epoch: [17][  139/  139]    Overall Loss 1.078653    Objective Loss 1.078653    Top1 91.830112    LR 0.001000    Time 0.967246    
2024-02-26 17:55:51,533 - --- validate (epoch=17)-----------
2024-02-26 17:55:51,534 - 1392 samples (32 per mini-batch)
2024-02-26 17:56:24,556 - Epoch: [17][   10/   44]    Loss 1.105297    Top1 84.605239    
2024-02-26 17:56:53,328 - Epoch: [17][   20/   44]    Loss 1.098176    Top1 84.279693    
2024-02-26 17:57:23,106 - Epoch: [17][   30/   44]    Loss 1.100261    Top1 83.729399    
2024-02-26 17:57:55,307 - Epoch: [17][   40/   44]    Loss 1.101399    Top1 83.605910    
2024-02-26 17:58:07,220 - Epoch: [17][   44/   44]    Loss 1.099368    Top1 83.828663    
2024-02-26 17:58:07,535 - ==> Top1: 83.829    Loss: 1.099

2024-02-26 17:58:07,540 - ==> Best [Top1: 86.717   Sparsity:0.00   Params: 271456 on epoch: 16]
2024-02-26 17:58:07,541 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 17:58:07,585 - 

2024-02-26 17:58:07,586 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 17:58:17,165 - Epoch: [18][   10/  139]    Overall Loss 1.088800    Objective Loss 1.088800                                        LR 0.001000    Time 0.957610    
2024-02-26 17:58:26,512 - Epoch: [18][   20/  139]    Overall Loss 1.079999    Objective Loss 1.079999                                        LR 0.001000    Time 0.946135    
2024-02-26 17:58:35,853 - Epoch: [18][   30/  139]    Overall Loss 1.079119    Objective Loss 1.079119                                        LR 0.001000    Time 0.942104    
2024-02-26 17:58:45,200 - Epoch: [18][   40/  139]    Overall Loss 1.080224    Objective Loss 1.080224                                        LR 0.001000    Time 0.940241    
2024-02-26 17:58:54,544 - Epoch: [18][   50/  139]    Overall Loss 1.079672    Objective Loss 1.079672                                        LR 0.001000    Time 0.939050    
2024-02-26 17:59:03,889 - Epoch: [18][   60/  139]    Overall Loss 1.079494    Objective Loss 1.079494                                        LR 0.001000    Time 0.938285    
2024-02-26 17:59:13,235 - Epoch: [18][   70/  139]    Overall Loss 1.078399    Objective Loss 1.078399                                        LR 0.001000    Time 0.937755    
2024-02-26 17:59:22,582 - Epoch: [18][   80/  139]    Overall Loss 1.080109    Objective Loss 1.080109                                        LR 0.001000    Time 0.937363    
2024-02-26 17:59:31,925 - Epoch: [18][   90/  139]    Overall Loss 1.079441    Objective Loss 1.079441                                        LR 0.001000    Time 0.937027    
2024-02-26 17:59:41,298 - Epoch: [18][  100/  139]    Overall Loss 1.079453    Objective Loss 1.079453                                        LR 0.001000    Time 0.937040    
2024-02-26 17:59:50,626 - Epoch: [18][  110/  139]    Overall Loss 1.079422    Objective Loss 1.079422                                        LR 0.001000    Time 0.936655    
2024-02-26 17:59:59,990 - Epoch: [18][  120/  139]    Overall Loss 1.078745    Objective Loss 1.078745                                        LR 0.001000    Time 0.936625    
2024-02-26 18:00:09,325 - Epoch: [18][  130/  139]    Overall Loss 1.078510    Objective Loss 1.078510                                        LR 0.001000    Time 0.936383    
2024-02-26 18:00:21,624 - Epoch: [18][  139/  139]    Overall Loss 1.078149    Objective Loss 1.078149    Top1 88.266264    LR 0.001000    Time 0.964225    
2024-02-26 18:00:21,949 - --- validate (epoch=18)-----------
2024-02-26 18:00:21,949 - 1392 samples (32 per mini-batch)
2024-02-26 18:00:58,123 - Epoch: [18][   10/   44]    Loss 1.087649    Top1 84.646811    
2024-02-26 18:01:31,970 - Epoch: [18][   20/   44]    Loss 1.085552    Top1 85.189967    
2024-02-26 18:02:04,654 - Epoch: [18][   30/   44]    Loss 1.086763    Top1 85.277522    
2024-02-26 18:02:37,258 - Epoch: [18][   40/   44]    Loss 1.088205    Top1 85.276936    
2024-02-26 18:02:48,352 - Epoch: [18][   44/   44]    Loss 1.088838    Top1 85.154598    
2024-02-26 18:02:48,641 - ==> Top1: 85.155    Loss: 1.089

2024-02-26 18:02:48,648 - ==> Best [Top1: 86.717   Sparsity:0.00   Params: 271456 on epoch: 16]
2024-02-26 18:02:48,648 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:02:48,681 - 

2024-02-26 18:02:48,682 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:02:58,302 - Epoch: [19][   10/  139]    Overall Loss 1.072417    Objective Loss 1.072417                                        LR 0.001000    Time 0.961924    
2024-02-26 18:03:07,632 - Epoch: [19][   20/  139]    Overall Loss 1.079097    Objective Loss 1.079097                                        LR 0.001000    Time 0.947402    
2024-02-26 18:03:16,966 - Epoch: [19][   30/  139]    Overall Loss 1.078753    Objective Loss 1.078753                                        LR 0.001000    Time 0.942716    
2024-02-26 18:03:26,309 - Epoch: [19][   40/  139]    Overall Loss 1.078665    Objective Loss 1.078665                                        LR 0.001000    Time 0.940618    
2024-02-26 18:03:35,655 - Epoch: [19][   50/  139]    Overall Loss 1.078785    Objective Loss 1.078785                                        LR 0.001000    Time 0.939395    
2024-02-26 18:03:44,999 - Epoch: [19][   60/  139]    Overall Loss 1.077989    Objective Loss 1.077989                                        LR 0.001000    Time 0.938558    
2024-02-26 18:03:54,365 - Epoch: [19][   70/  139]    Overall Loss 1.078285    Objective Loss 1.078285                                        LR 0.001000    Time 0.938274    
2024-02-26 18:04:03,705 - Epoch: [19][   80/  139]    Overall Loss 1.077884    Objective Loss 1.077884                                        LR 0.001000    Time 0.937729    
2024-02-26 18:04:13,049 - Epoch: [19][   90/  139]    Overall Loss 1.077703    Objective Loss 1.077703                                        LR 0.001000    Time 0.937351    
2024-02-26 18:04:22,396 - Epoch: [19][  100/  139]    Overall Loss 1.077071    Objective Loss 1.077071                                        LR 0.001000    Time 0.937086    
2024-02-26 18:04:31,737 - Epoch: [19][  110/  139]    Overall Loss 1.077000    Objective Loss 1.077000                                        LR 0.001000    Time 0.936812    
2024-02-26 18:04:41,083 - Epoch: [19][  120/  139]    Overall Loss 1.076137    Objective Loss 1.076137                                        LR 0.001000    Time 0.936622    
2024-02-26 18:04:50,438 - Epoch: [19][  130/  139]    Overall Loss 1.076283    Objective Loss 1.076283                                        LR 0.001000    Time 0.936532    
2024-02-26 18:05:03,341 - Epoch: [19][  139/  139]    Overall Loss 1.076660    Objective Loss 1.076660    Top1 87.356671    LR 0.001000    Time 0.968715    
2024-02-26 18:05:03,879 - --- validate (epoch=19)-----------
2024-02-26 18:05:03,884 - 1392 samples (32 per mini-batch)
2024-02-26 18:05:39,018 - Epoch: [19][   10/   44]    Loss 1.082776    Top1 86.781889    
2024-02-26 18:06:12,967 - Epoch: [19][   20/   44]    Loss 1.081815    Top1 86.402309    
2024-02-26 18:06:45,118 - Epoch: [19][   30/   44]    Loss 1.082408    Top1 86.646459    
2024-02-26 18:07:16,107 - Epoch: [19][   40/   44]    Loss 1.079404    Top1 86.850193    
2024-02-26 18:07:27,467 - Epoch: [19][   44/   44]    Loss 1.078936    Top1 86.773519    
2024-02-26 18:07:27,752 - ==> Top1: 86.774    Loss: 1.079

2024-02-26 18:07:27,760 - ==> Best [Top1: 86.774   Sparsity:0.00   Params: 271456 on epoch: 19]
2024-02-26 18:07:27,760 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:07:27,802 - 

2024-02-26 18:07:27,803 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:07:37,505 - Epoch: [20][   10/  139]    Overall Loss 1.070223    Objective Loss 1.070223                                        LR 0.000500    Time 0.969960    
2024-02-26 18:07:46,839 - Epoch: [20][   20/  139]    Overall Loss 1.068636    Objective Loss 1.068636                                        LR 0.000500    Time 0.951677    
2024-02-26 18:07:56,187 - Epoch: [20][   30/  139]    Overall Loss 1.072711    Objective Loss 1.072711                                        LR 0.000500    Time 0.946020    
2024-02-26 18:08:05,540 - Epoch: [20][   40/  139]    Overall Loss 1.073574    Objective Loss 1.073574                                        LR 0.000500    Time 0.943321    
2024-02-26 18:08:14,888 - Epoch: [20][   50/  139]    Overall Loss 1.072600    Objective Loss 1.072600                                        LR 0.000500    Time 0.941608    
2024-02-26 18:08:24,223 - Epoch: [20][   60/  139]    Overall Loss 1.073820    Objective Loss 1.073820                                        LR 0.000500    Time 0.940253    
2024-02-26 18:08:33,563 - Epoch: [20][   70/  139]    Overall Loss 1.073397    Objective Loss 1.073397                                        LR 0.000500    Time 0.939349    
2024-02-26 18:08:42,903 - Epoch: [20][   80/  139]    Overall Loss 1.072785    Objective Loss 1.072785                                        LR 0.000500    Time 0.938676    
2024-02-26 18:08:52,250 - Epoch: [20][   90/  139]    Overall Loss 1.072994    Objective Loss 1.072994                                        LR 0.000500    Time 0.938228    
2024-02-26 18:09:01,608 - Epoch: [20][  100/  139]    Overall Loss 1.073496    Objective Loss 1.073496                                        LR 0.000500    Time 0.937975    
2024-02-26 18:09:10,960 - Epoch: [20][  110/  139]    Overall Loss 1.073486    Objective Loss 1.073486                                        LR 0.000500    Time 0.937716    
2024-02-26 18:09:20,312 - Epoch: [20][  120/  139]    Overall Loss 1.073788    Objective Loss 1.073788                                        LR 0.000500    Time 0.937505    
2024-02-26 18:09:29,654 - Epoch: [20][  130/  139]    Overall Loss 1.074449    Objective Loss 1.074449                                        LR 0.000500    Time 0.937249    
2024-02-26 18:09:42,419 - Epoch: [20][  139/  139]    Overall Loss 1.074534    Objective Loss 1.074534    Top1 87.935271    LR 0.000500    Time 0.968393    
2024-02-26 18:09:42,674 - --- validate (epoch=20)-----------
2024-02-26 18:09:42,675 - 1392 samples (32 per mini-batch)
2024-02-26 18:10:17,771 - Epoch: [20][   10/   44]    Loss 1.088267    Top1 84.631368    
2024-02-26 18:10:51,827 - Epoch: [20][   20/   44]    Loss 1.094322    Top1 83.880383    
2024-02-26 18:11:25,835 - Epoch: [20][   30/   44]    Loss 1.089847    Top1 84.108549    
2024-02-26 18:11:59,782 - Epoch: [20][   40/   44]    Loss 1.086754    Top1 84.211078    
2024-02-26 18:12:11,297 - Epoch: [20][   44/   44]    Loss 1.086420    Top1 84.196903    
2024-02-26 18:12:11,642 - ==> Top1: 84.197    Loss: 1.086

2024-02-26 18:12:11,648 - ==> Best [Top1: 86.774   Sparsity:0.00   Params: 271456 on epoch: 19]
2024-02-26 18:12:11,648 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:12:11,684 - 

2024-02-26 18:12:11,685 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:12:21,273 - Epoch: [21][   10/  139]    Overall Loss 1.074848    Objective Loss 1.074848                                        LR 0.000500    Time 0.958427    
2024-02-26 18:12:30,612 - Epoch: [21][   20/  139]    Overall Loss 1.073476    Objective Loss 1.073476                                        LR 0.000500    Time 0.946155    
2024-02-26 18:12:39,950 - Epoch: [21][   30/  139]    Overall Loss 1.074309    Objective Loss 1.074309                                        LR 0.000500    Time 0.942003    
2024-02-26 18:12:49,288 - Epoch: [21][   40/  139]    Overall Loss 1.074313    Objective Loss 1.074313                                        LR 0.000500    Time 0.939946    
2024-02-26 18:12:58,631 - Epoch: [21][   50/  139]    Overall Loss 1.072143    Objective Loss 1.072143                                        LR 0.000500    Time 0.938797    
2024-02-26 18:13:07,967 - Epoch: [21][   60/  139]    Overall Loss 1.071284    Objective Loss 1.071284                                        LR 0.000500    Time 0.937923    
2024-02-26 18:13:17,335 - Epoch: [21][   70/  139]    Overall Loss 1.072054    Objective Loss 1.072054                                        LR 0.000500    Time 0.937760    
2024-02-26 18:13:26,686 - Epoch: [21][   80/  139]    Overall Loss 1.071744    Objective Loss 1.071744                                        LR 0.000500    Time 0.937425    
2024-02-26 18:13:36,042 - Epoch: [21][   90/  139]    Overall Loss 1.071785    Objective Loss 1.071785                                        LR 0.000500    Time 0.937211    
2024-02-26 18:13:45,397 - Epoch: [21][  100/  139]    Overall Loss 1.072588    Objective Loss 1.072588                                        LR 0.000500    Time 0.937031    
2024-02-26 18:13:54,743 - Epoch: [21][  110/  139]    Overall Loss 1.072650    Objective Loss 1.072650                                        LR 0.000500    Time 0.936802    
2024-02-26 18:14:04,079 - Epoch: [21][  120/  139]    Overall Loss 1.072552    Objective Loss 1.072552                                        LR 0.000500    Time 0.936533    
2024-02-26 18:14:13,424 - Epoch: [21][  130/  139]    Overall Loss 1.072353    Objective Loss 1.072353                                        LR 0.000500    Time 0.936377    
2024-02-26 18:14:26,112 - Epoch: [21][  139/  139]    Overall Loss 1.072469    Objective Loss 1.072469    Top1 90.904450    LR 0.000500    Time 0.967022    
2024-02-26 18:14:26,315 - --- validate (epoch=21)-----------
2024-02-26 18:14:26,316 - 1392 samples (32 per mini-batch)
2024-02-26 18:15:02,506 - Epoch: [21][   10/   44]    Loss 1.072823    Top1 87.997618    
2024-02-26 18:15:34,111 - Epoch: [21][   20/   44]    Loss 1.080200    Top1 87.403068    
2024-02-26 18:16:08,328 - Epoch: [21][   30/   44]    Loss 1.079050    Top1 87.235030    
2024-02-26 18:16:39,807 - Epoch: [21][   40/   44]    Loss 1.075077    Top1 87.615791    
2024-02-26 18:16:50,833 - Epoch: [21][   44/   44]    Loss 1.075819    Top1 87.472952    
2024-02-26 18:16:51,159 - ==> Top1: 87.473    Loss: 1.076

2024-02-26 18:16:51,165 - ==> Best [Top1: 87.473   Sparsity:0.00   Params: 271456 on epoch: 21]
2024-02-26 18:16:51,166 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:16:51,207 - 

2024-02-26 18:16:51,208 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:17:00,872 - Epoch: [22][   10/  139]    Overall Loss 1.069222    Objective Loss 1.069222                                        LR 0.000500    Time 0.966189    
2024-02-26 18:17:10,189 - Epoch: [22][   20/  139]    Overall Loss 1.070510    Objective Loss 1.070510                                        LR 0.000500    Time 0.948877    
2024-02-26 18:17:19,528 - Epoch: [22][   30/  139]    Overall Loss 1.072525    Objective Loss 1.072525                                        LR 0.000500    Time 0.943869    
2024-02-26 18:17:28,870 - Epoch: [22][   40/  139]    Overall Loss 1.074397    Objective Loss 1.074397                                        LR 0.000500    Time 0.941428    
2024-02-26 18:17:38,211 - Epoch: [22][   50/  139]    Overall Loss 1.073218    Objective Loss 1.073218                                        LR 0.000500    Time 0.939963    
2024-02-26 18:17:47,557 - Epoch: [22][   60/  139]    Overall Loss 1.072563    Objective Loss 1.072563                                        LR 0.000500    Time 0.939064    
2024-02-26 18:17:56,895 - Epoch: [22][   70/  139]    Overall Loss 1.072368    Objective Loss 1.072368                                        LR 0.000500    Time 0.938295    
2024-02-26 18:18:06,237 - Epoch: [22][   80/  139]    Overall Loss 1.071954    Objective Loss 1.071954                                        LR 0.000500    Time 0.937784    
2024-02-26 18:18:15,598 - Epoch: [22][   90/  139]    Overall Loss 1.072092    Objective Loss 1.072092                                        LR 0.000500    Time 0.937584    
2024-02-26 18:18:24,952 - Epoch: [22][  100/  139]    Overall Loss 1.071539    Objective Loss 1.071539                                        LR 0.000500    Time 0.937362    
2024-02-26 18:18:34,294 - Epoch: [22][  110/  139]    Overall Loss 1.070968    Objective Loss 1.070968                                        LR 0.000500    Time 0.937071    
2024-02-26 18:18:43,636 - Epoch: [22][  120/  139]    Overall Loss 1.071242    Objective Loss 1.071242                                        LR 0.000500    Time 0.936823    
2024-02-26 18:18:52,982 - Epoch: [22][  130/  139]    Overall Loss 1.071236    Objective Loss 1.071236                                        LR 0.000500    Time 0.936654    
2024-02-26 18:19:05,435 - Epoch: [22][  139/  139]    Overall Loss 1.072161    Objective Loss 1.072161    Top1 90.747254    LR 0.000500    Time 0.965588    
2024-02-26 18:19:05,790 - --- validate (epoch=22)-----------
2024-02-26 18:19:05,791 - 1392 samples (32 per mini-batch)
2024-02-26 18:19:39,599 - Epoch: [22][   10/   44]    Loss 1.072776    Top1 86.424735    
2024-02-26 18:20:12,065 - Epoch: [22][   20/   44]    Loss 1.073602    Top1 87.175577    
2024-02-26 18:20:44,248 - Epoch: [22][   30/   44]    Loss 1.076851    Top1 87.547485    
2024-02-26 18:21:18,492 - Epoch: [22][   40/   44]    Loss 1.075623    Top1 87.738059    
2024-02-26 18:21:31,012 - Epoch: [22][   44/   44]    Loss 1.074801    Top1 87.818486    
2024-02-26 18:21:31,266 - ==> Top1: 87.818    Loss: 1.075

2024-02-26 18:21:31,274 - ==> Best [Top1: 87.818   Sparsity:0.00   Params: 271456 on epoch: 22]
2024-02-26 18:21:31,274 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:21:31,310 - 

2024-02-26 18:21:31,310 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:21:41,004 - Epoch: [23][   10/  139]    Overall Loss 1.076229    Objective Loss 1.076229                                        LR 0.000500    Time 0.969300    
2024-02-26 18:21:50,328 - Epoch: [23][   20/  139]    Overall Loss 1.073266    Objective Loss 1.073266                                        LR 0.000500    Time 0.950801    
2024-02-26 18:21:59,660 - Epoch: [23][   30/  139]    Overall Loss 1.072628    Objective Loss 1.072628                                        LR 0.000500    Time 0.944906    
2024-02-26 18:22:09,002 - Epoch: [23][   40/  139]    Overall Loss 1.070900    Objective Loss 1.070900                                        LR 0.000500    Time 0.942214    
2024-02-26 18:22:18,340 - Epoch: [23][   50/  139]    Overall Loss 1.071974    Objective Loss 1.071974                                        LR 0.000500    Time 0.940527    
2024-02-26 18:22:27,684 - Epoch: [23][   60/  139]    Overall Loss 1.071611    Objective Loss 1.071611                                        LR 0.000500    Time 0.939499    
2024-02-26 18:22:37,034 - Epoch: [23][   70/  139]    Overall Loss 1.073127    Objective Loss 1.073127                                        LR 0.000500    Time 0.938849    
2024-02-26 18:22:46,380 - Epoch: [23][   80/  139]    Overall Loss 1.074118    Objective Loss 1.074118                                        LR 0.000500    Time 0.938313    
2024-02-26 18:22:55,724 - Epoch: [23][   90/  139]    Overall Loss 1.073139    Objective Loss 1.073139                                        LR 0.000500    Time 0.937872    
2024-02-26 18:23:05,071 - Epoch: [23][  100/  139]    Overall Loss 1.072734    Objective Loss 1.072734                                        LR 0.000500    Time 0.937553    
2024-02-26 18:23:14,423 - Epoch: [23][  110/  139]    Overall Loss 1.072976    Objective Loss 1.072976                                        LR 0.000500    Time 0.937329    
2024-02-26 18:23:23,762 - Epoch: [23][  120/  139]    Overall Loss 1.073052    Objective Loss 1.073052                                        LR 0.000500    Time 0.937046    
2024-02-26 18:23:33,136 - Epoch: [23][  130/  139]    Overall Loss 1.072677    Objective Loss 1.072677                                        LR 0.000500    Time 0.937067    
2024-02-26 18:23:45,469 - Epoch: [23][  139/  139]    Overall Loss 1.072318    Objective Loss 1.072318    Top1 90.108856    LR 0.000500    Time 0.965107    
2024-02-26 18:23:45,751 - --- validate (epoch=23)-----------
2024-02-26 18:23:45,752 - 1392 samples (32 per mini-batch)
2024-02-26 18:24:18,567 - Epoch: [23][   10/   44]    Loss 1.073469    Top1 88.056411    
2024-02-26 18:24:47,145 - Epoch: [23][   20/   44]    Loss 1.076318    Top1 87.954177    
2024-02-26 18:25:16,082 - Epoch: [23][   30/   44]    Loss 1.078206    Top1 88.025666    
2024-02-26 18:25:43,865 - Epoch: [23][   40/   44]    Loss 1.077801    Top1 87.934463    
2024-02-26 18:25:56,471 - Epoch: [23][   44/   44]    Loss 1.078518    Top1 87.932181    
2024-02-26 18:25:56,718 - ==> Top1: 87.932    Loss: 1.079

2024-02-26 18:25:56,726 - ==> Best [Top1: 87.932   Sparsity:0.00   Params: 271456 on epoch: 23]
2024-02-26 18:25:56,726 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:25:56,769 - 

2024-02-26 18:25:56,769 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:26:06,528 - Epoch: [24][   10/  139]    Overall Loss 1.067918    Objective Loss 1.067918                                        LR 0.000500    Time 0.975776    
2024-02-26 18:26:15,874 - Epoch: [24][   20/  139]    Overall Loss 1.069914    Objective Loss 1.069914                                        LR 0.000500    Time 0.955142    
2024-02-26 18:26:25,208 - Epoch: [24][   30/  139]    Overall Loss 1.072398    Objective Loss 1.072398                                        LR 0.000500    Time 0.947868    
2024-02-26 18:26:34,521 - Epoch: [24][   40/  139]    Overall Loss 1.070536    Objective Loss 1.070536                                        LR 0.000500    Time 0.943721    
2024-02-26 18:26:43,891 - Epoch: [24][   50/  139]    Overall Loss 1.071190    Objective Loss 1.071190                                        LR 0.000500    Time 0.942360    
2024-02-26 18:26:53,223 - Epoch: [24][   60/  139]    Overall Loss 1.070724    Objective Loss 1.070724                                        LR 0.000500    Time 0.940826    
2024-02-26 18:27:02,568 - Epoch: [24][   70/  139]    Overall Loss 1.071657    Objective Loss 1.071657                                        LR 0.000500    Time 0.939916    
2024-02-26 18:27:11,911 - Epoch: [24][   80/  139]    Overall Loss 1.071656    Objective Loss 1.071656                                        LR 0.000500    Time 0.939201    
2024-02-26 18:27:21,266 - Epoch: [24][   90/  139]    Overall Loss 1.071876    Objective Loss 1.071876                                        LR 0.000500    Time 0.938787    
2024-02-26 18:27:30,621 - Epoch: [24][  100/  139]    Overall Loss 1.071813    Objective Loss 1.071813                                        LR 0.000500    Time 0.938452    
2024-02-26 18:27:39,962 - Epoch: [24][  110/  139]    Overall Loss 1.072501    Objective Loss 1.072501                                        LR 0.000500    Time 0.938051    
2024-02-26 18:27:49,312 - Epoch: [24][  120/  139]    Overall Loss 1.072095    Objective Loss 1.072095                                        LR 0.000500    Time 0.937797    
2024-02-26 18:27:58,670 - Epoch: [24][  130/  139]    Overall Loss 1.071914    Objective Loss 1.071914                                        LR 0.000500    Time 0.937638    
2024-02-26 18:28:11,070 - Epoch: [24][  139/  139]    Overall Loss 1.072263    Objective Loss 1.072263    Top1 89.985300    LR 0.000500    Time 0.966132    
2024-02-26 18:28:11,368 - --- validate (epoch=24)-----------
2024-02-26 18:28:11,369 - 1392 samples (32 per mini-batch)
2024-02-26 18:28:44,786 - Epoch: [24][   10/   44]    Loss 1.078681    Top1 88.764290    
2024-02-26 18:29:14,535 - Epoch: [24][   20/   44]    Loss 1.073937    Top1 88.310945    
2024-02-26 18:29:43,942 - Epoch: [24][   30/   44]    Loss 1.078412    Top1 88.066876    
2024-02-26 18:30:12,138 - Epoch: [24][   40/   44]    Loss 1.079487    Top1 87.860345    
2024-02-26 18:30:21,584 - Epoch: [24][   44/   44]    Loss 1.077840    Top1 87.917244    
2024-02-26 18:30:21,748 - ==> Top1: 87.917    Loss: 1.078

2024-02-26 18:30:21,755 - ==> Best [Top1: 87.932   Sparsity:0.00   Params: 271456 on epoch: 23]
2024-02-26 18:30:21,756 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:30:21,788 - 

2024-02-26 18:30:21,788 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:30:31,404 - Epoch: [25][   10/  139]    Overall Loss 1.081973    Objective Loss 1.081973                                        LR 0.000500    Time 0.961355    
2024-02-26 18:30:40,753 - Epoch: [25][   20/  139]    Overall Loss 1.073627    Objective Loss 1.073627                                        LR 0.000500    Time 0.948094    
2024-02-26 18:30:50,113 - Epoch: [25][   30/  139]    Overall Loss 1.072844    Objective Loss 1.072844                                        LR 0.000500    Time 0.944032    
2024-02-26 18:30:59,443 - Epoch: [25][   40/  139]    Overall Loss 1.070708    Objective Loss 1.070708                                        LR 0.000500    Time 0.941253    
2024-02-26 18:31:08,796 - Epoch: [25][   50/  139]    Overall Loss 1.070580    Objective Loss 1.070580                                        LR 0.000500    Time 0.940055    
2024-02-26 18:31:18,152 - Epoch: [25][   60/  139]    Overall Loss 1.071199    Objective Loss 1.071199                                        LR 0.000500    Time 0.939298    
2024-02-26 18:31:27,492 - Epoch: [25][   70/  139]    Overall Loss 1.070381    Objective Loss 1.070381                                        LR 0.000500    Time 0.938538    
2024-02-26 18:31:36,846 - Epoch: [25][   80/  139]    Overall Loss 1.070042    Objective Loss 1.070042                                        LR 0.000500    Time 0.938140    
2024-02-26 18:31:46,198 - Epoch: [25][   90/  139]    Overall Loss 1.069810    Objective Loss 1.069810                                        LR 0.000500    Time 0.937808    
2024-02-26 18:31:55,547 - Epoch: [25][  100/  139]    Overall Loss 1.070506    Objective Loss 1.070506                                        LR 0.000500    Time 0.937510    
2024-02-26 18:32:04,900 - Epoch: [25][  110/  139]    Overall Loss 1.071269    Objective Loss 1.071269                                        LR 0.000500    Time 0.937308    
2024-02-26 18:32:14,252 - Epoch: [25][  120/  139]    Overall Loss 1.071629    Objective Loss 1.071629                                        LR 0.000500    Time 0.937127    
2024-02-26 18:32:23,605 - Epoch: [25][  130/  139]    Overall Loss 1.071173    Objective Loss 1.071173                                        LR 0.000500    Time 0.936984    
2024-02-26 18:32:36,317 - Epoch: [25][  139/  139]    Overall Loss 1.072110    Objective Loss 1.072110    Top1 90.312533    LR 0.000500    Time 0.967764    
2024-02-26 18:32:36,615 - --- validate (epoch=25)-----------
2024-02-26 18:32:36,616 - 1392 samples (32 per mini-batch)
2024-02-26 18:33:07,788 - Epoch: [25][   10/   44]    Loss 1.087093    Top1 87.044413    
2024-02-26 18:33:42,570 - Epoch: [25][   20/   44]    Loss 1.087935    Top1 87.496579    
2024-02-26 18:34:16,442 - Epoch: [25][   30/   44]    Loss 1.079462    Top1 87.702302    
2024-02-26 18:34:46,338 - Epoch: [25][   40/   44]    Loss 1.074304    Top1 87.626778    
2024-02-26 18:34:55,813 - Epoch: [25][   44/   44]    Loss 1.074740    Top1 87.706158    
2024-02-26 18:34:56,037 - ==> Top1: 87.706    Loss: 1.075

2024-02-26 18:34:56,044 - ==> Best [Top1: 87.932   Sparsity:0.00   Params: 271456 on epoch: 23]
2024-02-26 18:34:56,044 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:34:56,076 - 

2024-02-26 18:34:56,077 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:35:05,604 - Epoch: [26][   10/  139]    Overall Loss 1.074571    Objective Loss 1.074571                                        LR 0.000500    Time 0.952488    
2024-02-26 18:35:14,936 - Epoch: [26][   20/  139]    Overall Loss 1.074305    Objective Loss 1.074305                                        LR 0.000500    Time 0.942784    
2024-02-26 18:35:24,269 - Epoch: [26][   30/  139]    Overall Loss 1.074915    Objective Loss 1.074915                                        LR 0.000500    Time 0.939624    
2024-02-26 18:35:33,615 - Epoch: [26][   40/  139]    Overall Loss 1.072116    Objective Loss 1.072116                                        LR 0.000500    Time 0.938345    
2024-02-26 18:35:42,971 - Epoch: [26][   50/  139]    Overall Loss 1.069956    Objective Loss 1.069956                                        LR 0.000500    Time 0.937787    
2024-02-26 18:35:52,329 - Epoch: [26][   60/  139]    Overall Loss 1.070655    Objective Loss 1.070655                                        LR 0.000500    Time 0.937447    
2024-02-26 18:36:01,709 - Epoch: [26][   70/  139]    Overall Loss 1.070186    Objective Loss 1.070186                                        LR 0.000500    Time 0.937511    
2024-02-26 18:36:11,055 - Epoch: [26][   80/  139]    Overall Loss 1.070814    Objective Loss 1.070814                                        LR 0.000500    Time 0.937147    
2024-02-26 18:36:20,399 - Epoch: [26][   90/  139]    Overall Loss 1.072223    Objective Loss 1.072223                                        LR 0.000500    Time 0.936833    
2024-02-26 18:36:29,740 - Epoch: [26][  100/  139]    Overall Loss 1.071446    Objective Loss 1.071446                                        LR 0.000500    Time 0.936559    
2024-02-26 18:36:39,089 - Epoch: [26][  110/  139]    Overall Loss 1.071842    Objective Loss 1.071842                                        LR 0.000500    Time 0.936398    
2024-02-26 18:36:48,435 - Epoch: [26][  120/  139]    Overall Loss 1.072486    Objective Loss 1.072486                                        LR 0.000500    Time 0.936245    
2024-02-26 18:36:57,777 - Epoch: [26][  130/  139]    Overall Loss 1.072109    Objective Loss 1.072109                                        LR 0.000500    Time 0.936090    
2024-02-26 18:37:10,554 - Epoch: [26][  139/  139]    Overall Loss 1.072094    Objective Loss 1.072094    Top1 90.194847    LR 0.000500    Time 0.967397    
2024-02-26 18:37:10,815 - --- validate (epoch=26)-----------
2024-02-26 18:37:10,817 - 1392 samples (32 per mini-batch)
2024-02-26 18:37:45,507 - Epoch: [26][   10/   44]    Loss 1.079276    Top1 84.743077    
2024-02-26 18:38:17,084 - Epoch: [26][   20/   44]    Loss 1.081293    Top1 85.464412    
2024-02-26 18:38:52,242 - Epoch: [26][   30/   44]    Loss 1.082051    Top1 85.715530    
2024-02-26 18:39:27,611 - Epoch: [26][   40/   44]    Loss 1.080676    Top1 85.575287    
2024-02-26 18:39:39,270 - Epoch: [26][   44/   44]    Loss 1.081191    Top1 85.528235    
2024-02-26 18:39:39,578 - ==> Top1: 85.528    Loss: 1.081

2024-02-26 18:39:39,583 - ==> Best [Top1: 87.932   Sparsity:0.00   Params: 271456 on epoch: 23]
2024-02-26 18:39:39,583 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:39:39,616 - 

2024-02-26 18:39:39,616 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:39:49,323 - Epoch: [27][   10/  139]    Overall Loss 1.074993    Objective Loss 1.074993                                        LR 0.000500    Time 0.970463    
2024-02-26 18:39:58,648 - Epoch: [27][   20/  139]    Overall Loss 1.071747    Objective Loss 1.071747                                        LR 0.000500    Time 0.951415    
2024-02-26 18:40:07,984 - Epoch: [27][   30/  139]    Overall Loss 1.071583    Objective Loss 1.071583                                        LR 0.000500    Time 0.945483    
2024-02-26 18:40:17,320 - Epoch: [27][   40/  139]    Overall Loss 1.073565    Objective Loss 1.073565                                        LR 0.000500    Time 0.942505    
2024-02-26 18:40:26,659 - Epoch: [27][   50/  139]    Overall Loss 1.073526    Objective Loss 1.073526                                        LR 0.000500    Time 0.940770    
2024-02-26 18:40:36,002 - Epoch: [27][   60/  139]    Overall Loss 1.073329    Objective Loss 1.073329                                        LR 0.000500    Time 0.939673    
2024-02-26 18:40:45,345 - Epoch: [27][   70/  139]    Overall Loss 1.072479    Objective Loss 1.072479                                        LR 0.000500    Time 0.938901    
2024-02-26 18:40:54,688 - Epoch: [27][   80/  139]    Overall Loss 1.071164    Objective Loss 1.071164                                        LR 0.000500    Time 0.938328    
2024-02-26 18:41:04,045 - Epoch: [27][   90/  139]    Overall Loss 1.070489    Objective Loss 1.070489                                        LR 0.000500    Time 0.938025    
2024-02-26 18:41:13,391 - Epoch: [27][  100/  139]    Overall Loss 1.070558    Objective Loss 1.070558                                        LR 0.000500    Time 0.937682    
2024-02-26 18:41:22,747 - Epoch: [27][  110/  139]    Overall Loss 1.070104    Objective Loss 1.070104                                        LR 0.000500    Time 0.937488    
2024-02-26 18:41:32,100 - Epoch: [27][  120/  139]    Overall Loss 1.070471    Objective Loss 1.070471                                        LR 0.000500    Time 0.937295    
2024-02-26 18:41:41,437 - Epoch: [27][  130/  139]    Overall Loss 1.070648    Objective Loss 1.070648                                        LR 0.000500    Time 0.937015    
2024-02-26 18:41:54,427 - Epoch: [27][  139/  139]    Overall Loss 1.070905    Objective Loss 1.070905    Top1 89.381130    LR 0.000500    Time 0.969795    
2024-02-26 18:41:54,733 - --- validate (epoch=27)-----------
2024-02-26 18:41:54,734 - 1392 samples (32 per mini-batch)
2024-02-26 18:42:33,272 - Epoch: [27][   10/   44]    Loss 1.062828    Top1 87.647511    
2024-02-26 18:43:08,526 - Epoch: [27][   20/   44]    Loss 1.070303    Top1 87.421628    
2024-02-26 18:43:42,592 - Epoch: [27][   30/   44]    Loss 1.073947    Top1 87.367019    
2024-02-26 18:44:18,184 - Epoch: [27][   40/   44]    Loss 1.075791    Top1 87.285200    
2024-02-26 18:44:29,456 - Epoch: [27][   44/   44]    Loss 1.076550    Top1 87.235780    
2024-02-26 18:44:29,796 - ==> Top1: 87.236    Loss: 1.077

2024-02-26 18:44:29,803 - ==> Best [Top1: 87.932   Sparsity:0.00   Params: 271456 on epoch: 23]
2024-02-26 18:44:29,804 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:44:29,845 - 

2024-02-26 18:44:29,845 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:44:39,394 - Epoch: [28][   10/  139]    Overall Loss 1.071846    Objective Loss 1.071846                                        LR 0.000500    Time 0.954840    
2024-02-26 18:44:48,729 - Epoch: [28][   20/  139]    Overall Loss 1.074604    Objective Loss 1.074604                                        LR 0.000500    Time 0.944150    
2024-02-26 18:44:58,063 - Epoch: [28][   30/  139]    Overall Loss 1.073712    Objective Loss 1.073712                                        LR 0.000500    Time 0.940541    
2024-02-26 18:45:07,410 - Epoch: [28][   40/  139]    Overall Loss 1.071882    Objective Loss 1.071882                                        LR 0.000500    Time 0.939063    
2024-02-26 18:45:16,745 - Epoch: [28][   50/  139]    Overall Loss 1.070526    Objective Loss 1.070526                                        LR 0.000500    Time 0.937943    
2024-02-26 18:45:26,090 - Epoch: [28][   60/  139]    Overall Loss 1.069614    Objective Loss 1.069614                                        LR 0.000500    Time 0.937366    
2024-02-26 18:45:35,446 - Epoch: [28][   70/  139]    Overall Loss 1.070044    Objective Loss 1.070044                                        LR 0.000500    Time 0.937109    
2024-02-26 18:45:44,788 - Epoch: [28][   80/  139]    Overall Loss 1.069774    Objective Loss 1.069774                                        LR 0.000500    Time 0.936737    
2024-02-26 18:45:54,144 - Epoch: [28][   90/  139]    Overall Loss 1.070558    Objective Loss 1.070558                                        LR 0.000500    Time 0.936600    
2024-02-26 18:46:03,499 - Epoch: [28][  100/  139]    Overall Loss 1.070549    Objective Loss 1.070549                                        LR 0.000500    Time 0.936490    
2024-02-26 18:46:12,852 - Epoch: [28][  110/  139]    Overall Loss 1.070386    Objective Loss 1.070386                                        LR 0.000500    Time 0.936378    
2024-02-26 18:46:22,214 - Epoch: [28][  120/  139]    Overall Loss 1.069764    Objective Loss 1.069764                                        LR 0.000500    Time 0.936360    
2024-02-26 18:46:31,581 - Epoch: [28][  130/  139]    Overall Loss 1.069749    Objective Loss 1.069749                                        LR 0.000500    Time 0.936381    
2024-02-26 18:46:44,238 - Epoch: [28][  139/  139]    Overall Loss 1.070277    Objective Loss 1.070277    Top1 91.227116    LR 0.000500    Time 0.966799    
2024-02-26 18:46:44,548 - --- validate (epoch=28)-----------
2024-02-26 18:46:44,548 - 1392 samples (32 per mini-batch)
2024-02-26 18:47:21,874 - Epoch: [28][   10/   44]    Loss 1.082099    Top1 87.033633    
2024-02-26 18:47:55,975 - Epoch: [28][   20/   44]    Loss 1.076309    Top1 87.370322    
2024-02-26 18:48:28,412 - Epoch: [28][   30/   44]    Loss 1.075178    Top1 87.283190    
2024-02-26 18:48:56,616 - Epoch: [28][   40/   44]    Loss 1.074231    Top1 87.418190    
2024-02-26 18:49:08,938 - Epoch: [28][   44/   44]    Loss 1.074845    Top1 87.417966    
2024-02-26 18:49:09,242 - ==> Top1: 87.418    Loss: 1.075

2024-02-26 18:49:09,249 - ==> Best [Top1: 87.932   Sparsity:0.00   Params: 271456 on epoch: 23]
2024-02-26 18:49:09,250 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:49:09,284 - 

2024-02-26 18:49:09,284 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:49:19,296 - Epoch: [29][   10/  139]    Overall Loss 1.063506    Objective Loss 1.063506                                        LR 0.000500    Time 1.001067    
2024-02-26 18:49:28,630 - Epoch: [29][   20/  139]    Overall Loss 1.065815    Objective Loss 1.065815                                        LR 0.000500    Time 0.967187    
2024-02-26 18:49:37,966 - Epoch: [29][   30/  139]    Overall Loss 1.067850    Objective Loss 1.067850                                        LR 0.000500    Time 0.955966    
2024-02-26 18:49:47,301 - Epoch: [29][   40/  139]    Overall Loss 1.070657    Objective Loss 1.070657                                        LR 0.000500    Time 0.950354    
2024-02-26 18:49:56,636 - Epoch: [29][   50/  139]    Overall Loss 1.070078    Objective Loss 1.070078                                        LR 0.000500    Time 0.946962    
2024-02-26 18:50:05,979 - Epoch: [29][   60/  139]    Overall Loss 1.069540    Objective Loss 1.069540                                        LR 0.000500    Time 0.944853    
2024-02-26 18:50:15,326 - Epoch: [29][   70/  139]    Overall Loss 1.070085    Objective Loss 1.070085                                        LR 0.000500    Time 0.943385    
2024-02-26 18:50:24,668 - Epoch: [29][   80/  139]    Overall Loss 1.070557    Objective Loss 1.070557                                        LR 0.000500    Time 0.942233    
2024-02-26 18:50:34,009 - Epoch: [29][   90/  139]    Overall Loss 1.070445    Objective Loss 1.070445                                        LR 0.000500    Time 0.941324    
2024-02-26 18:50:43,355 - Epoch: [29][  100/  139]    Overall Loss 1.070995    Objective Loss 1.070995                                        LR 0.000500    Time 0.940649    
2024-02-26 18:50:52,703 - Epoch: [29][  110/  139]    Overall Loss 1.070493    Objective Loss 1.070493                                        LR 0.000500    Time 0.940115    
2024-02-26 18:51:02,048 - Epoch: [29][  120/  139]    Overall Loss 1.071211    Objective Loss 1.071211                                        LR 0.000500    Time 0.939638    
2024-02-26 18:51:11,391 - Epoch: [29][  130/  139]    Overall Loss 1.071094    Objective Loss 1.071094                                        LR 0.000500    Time 0.939222    
2024-02-26 18:51:23,902 - Epoch: [29][  139/  139]    Overall Loss 1.071290    Objective Loss 1.071290    Top1 89.606543    LR 0.000500    Time 0.968419    
2024-02-26 18:51:24,159 - --- validate (epoch=29)-----------
2024-02-26 18:51:24,162 - 1392 samples (32 per mini-batch)
2024-02-26 18:51:59,706 - Epoch: [29][   10/   44]    Loss 1.092544    Top1 87.083914    
2024-02-26 18:52:29,541 - Epoch: [29][   20/   44]    Loss 1.085287    Top1 86.883884    
2024-02-26 18:52:59,400 - Epoch: [29][   30/   44]    Loss 1.087332    Top1 86.613165    
2024-02-26 18:53:25,935 - Epoch: [29][   40/   44]    Loss 1.087454    Top1 86.496110    
2024-02-26 18:53:34,917 - Epoch: [29][   44/   44]    Loss 1.085603    Top1 86.581036    
2024-02-26 18:53:35,149 - ==> Top1: 86.581    Loss: 1.086

2024-02-26 18:53:35,156 - ==> Best [Top1: 87.932   Sparsity:0.00   Params: 271456 on epoch: 23]
2024-02-26 18:53:35,156 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:53:35,188 - 

2024-02-26 18:53:35,189 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:53:44,784 - Epoch: [30][   10/  139]    Overall Loss 1.067247    Objective Loss 1.067247                                        LR 0.000500    Time 0.959279    
2024-02-26 18:53:54,130 - Epoch: [30][   20/  139]    Overall Loss 1.066535    Objective Loss 1.066535                                        LR 0.000500    Time 0.946858    
2024-02-26 18:54:03,491 - Epoch: [30][   30/  139]    Overall Loss 1.068641    Objective Loss 1.068641                                        LR 0.000500    Time 0.943244    
2024-02-26 18:54:12,838 - Epoch: [30][   40/  139]    Overall Loss 1.069669    Objective Loss 1.069669                                        LR 0.000500    Time 0.941090    
2024-02-26 18:54:22,181 - Epoch: [30][   50/  139]    Overall Loss 1.071457    Objective Loss 1.071457                                        LR 0.000500    Time 0.939727    
2024-02-26 18:54:31,532 - Epoch: [30][   60/  139]    Overall Loss 1.071652    Objective Loss 1.071652                                        LR 0.000500    Time 0.938941    
2024-02-26 18:54:40,877 - Epoch: [30][   70/  139]    Overall Loss 1.071993    Objective Loss 1.071993                                        LR 0.000500    Time 0.938293    
2024-02-26 18:54:50,222 - Epoch: [30][   80/  139]    Overall Loss 1.070075    Objective Loss 1.070075                                        LR 0.000500    Time 0.937815    
2024-02-26 18:54:59,571 - Epoch: [30][   90/  139]    Overall Loss 1.070450    Objective Loss 1.070450                                        LR 0.000500    Time 0.937481    
2024-02-26 18:55:08,922 - Epoch: [30][  100/  139]    Overall Loss 1.069746    Objective Loss 1.069746                                        LR 0.000500    Time 0.937242    
2024-02-26 18:55:18,269 - Epoch: [30][  110/  139]    Overall Loss 1.070196    Objective Loss 1.070196                                        LR 0.000500    Time 0.937002    
2024-02-26 18:55:27,623 - Epoch: [30][  120/  139]    Overall Loss 1.070117    Objective Loss 1.070117                                        LR 0.000500    Time 0.936862    
2024-02-26 18:55:36,982 - Epoch: [30][  130/  139]    Overall Loss 1.070423    Objective Loss 1.070423                                        LR 0.000500    Time 0.936779    
2024-02-26 18:55:49,505 - Epoch: [30][  139/  139]    Overall Loss 1.070800    Objective Loss 1.070800    Top1 90.677937    LR 0.000500    Time 0.966216    
2024-02-26 18:55:49,731 - --- validate (epoch=30)-----------
2024-02-26 18:55:49,731 - 1392 samples (32 per mini-batch)
2024-02-26 18:56:23,683 - Epoch: [30][   10/   44]    Loss 1.069880    Top1 87.859938    
2024-02-26 18:56:57,115 - Epoch: [30][   20/   44]    Loss 1.073392    Top1 87.707562    
2024-02-26 18:57:30,050 - Epoch: [30][   30/   44]    Loss 1.076226    Top1 87.263984    
2024-02-26 18:57:58,565 - Epoch: [30][   40/   44]    Loss 1.075796    Top1 87.212861    
2024-02-26 18:58:08,137 - Epoch: [30][   44/   44]    Loss 1.074725    Top1 87.316896    
2024-02-26 18:58:08,368 - ==> Top1: 87.317    Loss: 1.075

2024-02-26 18:58:08,377 - ==> Best [Top1: 87.932   Sparsity:0.00   Params: 271456 on epoch: 23]
2024-02-26 18:58:08,377 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 18:58:08,409 - 

2024-02-26 18:58:08,410 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 18:58:18,089 - Epoch: [31][   10/  139]    Overall Loss 1.072278    Objective Loss 1.072278                                        LR 0.000500    Time 0.967711    
2024-02-26 18:58:27,426 - Epoch: [31][   20/  139]    Overall Loss 1.069570    Objective Loss 1.069570                                        LR 0.000500    Time 0.950656    
2024-02-26 18:58:36,780 - Epoch: [31][   30/  139]    Overall Loss 1.069550    Objective Loss 1.069550                                        LR 0.000500    Time 0.945523    
2024-02-26 18:58:46,120 - Epoch: [31][   40/  139]    Overall Loss 1.069389    Objective Loss 1.069389                                        LR 0.000500    Time 0.942622    
2024-02-26 18:58:55,479 - Epoch: [31][   50/  139]    Overall Loss 1.069692    Objective Loss 1.069692                                        LR 0.000500    Time 0.941259    
2024-02-26 18:59:04,859 - Epoch: [31][   60/  139]    Overall Loss 1.069288    Objective Loss 1.069288                                        LR 0.000500    Time 0.940697    
2024-02-26 18:59:14,211 - Epoch: [31][   70/  139]    Overall Loss 1.069063    Objective Loss 1.069063                                        LR 0.000500    Time 0.939895    
2024-02-26 18:59:23,556 - Epoch: [31][   80/  139]    Overall Loss 1.070305    Objective Loss 1.070305                                        LR 0.000500    Time 0.939218    
2024-02-26 18:59:32,902 - Epoch: [31][   90/  139]    Overall Loss 1.070123    Objective Loss 1.070123                                        LR 0.000500    Time 0.938702    
2024-02-26 18:59:42,254 - Epoch: [31][  100/  139]    Overall Loss 1.070593    Objective Loss 1.070593                                        LR 0.000500    Time 0.938342    
2024-02-26 18:59:51,601 - Epoch: [31][  110/  139]    Overall Loss 1.071050    Objective Loss 1.071050                                        LR 0.000500    Time 0.938010    
2024-02-26 19:00:00,962 - Epoch: [31][  120/  139]    Overall Loss 1.070216    Objective Loss 1.070216                                        LR 0.000500    Time 0.937847    
2024-02-26 19:00:10,299 - Epoch: [31][  130/  139]    Overall Loss 1.070138    Objective Loss 1.070138                                        LR 0.000500    Time 0.937524    
2024-02-26 19:00:23,072 - Epoch: [31][  139/  139]    Overall Loss 1.069667    Objective Loss 1.069667    Top1 92.620937    LR 0.000500    Time 0.968705    
2024-02-26 19:00:23,312 - --- validate (epoch=31)-----------
2024-02-26 19:00:23,313 - 1392 samples (32 per mini-batch)
2024-02-26 19:00:55,794 - Epoch: [31][   10/   44]    Loss 1.074883    Top1 87.925695    
2024-02-26 19:01:25,776 - Epoch: [31][   20/   44]    Loss 1.076963    Top1 88.259764    
2024-02-26 19:01:57,872 - Epoch: [31][   30/   44]    Loss 1.079696    Top1 88.243704    
2024-02-26 19:02:25,728 - Epoch: [31][   40/   44]    Loss 1.079642    Top1 88.131087    
2024-02-26 19:02:35,764 - Epoch: [31][   44/   44]    Loss 1.078904    Top1 88.133211    
2024-02-26 19:02:36,009 - ==> Top1: 88.133    Loss: 1.079

2024-02-26 19:02:36,018 - ==> Best [Top1: 88.133   Sparsity:0.00   Params: 271456 on epoch: 31]
2024-02-26 19:02:36,018 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 19:02:36,061 - 

2024-02-26 19:02:36,062 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:02:45,649 - Epoch: [32][   10/  139]    Overall Loss 1.065952    Objective Loss 1.065952                                        LR 0.000500    Time 0.958441    
2024-02-26 19:02:54,989 - Epoch: [32][   20/  139]    Overall Loss 1.065376    Objective Loss 1.065376                                        LR 0.000500    Time 0.946155    
2024-02-26 19:03:04,331 - Epoch: [32][   30/  139]    Overall Loss 1.067017    Objective Loss 1.067017                                        LR 0.000500    Time 0.942150    
2024-02-26 19:03:13,685 - Epoch: [32][   40/  139]    Overall Loss 1.065436    Objective Loss 1.065436                                        LR 0.000500    Time 0.940434    
2024-02-26 19:03:23,031 - Epoch: [32][   50/  139]    Overall Loss 1.068614    Objective Loss 1.068614                                        LR 0.000500    Time 0.939255    
2024-02-26 19:03:32,374 - Epoch: [32][   60/  139]    Overall Loss 1.069165    Objective Loss 1.069165                                        LR 0.000500    Time 0.938423    
2024-02-26 19:03:41,718 - Epoch: [32][   70/  139]    Overall Loss 1.069831    Objective Loss 1.069831                                        LR 0.000500    Time 0.937844    
2024-02-26 19:03:51,077 - Epoch: [32][   80/  139]    Overall Loss 1.069533    Objective Loss 1.069533                                        LR 0.000500    Time 0.937591    
2024-02-26 19:04:00,454 - Epoch: [32][   90/  139]    Overall Loss 1.068817    Objective Loss 1.068817                                        LR 0.000500    Time 0.937593    
2024-02-26 19:04:09,815 - Epoch: [32][  100/  139]    Overall Loss 1.069286    Objective Loss 1.069286                                        LR 0.000500    Time 0.937442    
2024-02-26 19:04:19,157 - Epoch: [32][  110/  139]    Overall Loss 1.069944    Objective Loss 1.069944                                        LR 0.000500    Time 0.937146    
2024-02-26 19:04:28,511 - Epoch: [32][  120/  139]    Overall Loss 1.069774    Objective Loss 1.069774                                        LR 0.000500    Time 0.936996    
2024-02-26 19:04:37,868 - Epoch: [32][  130/  139]    Overall Loss 1.070296    Objective Loss 1.070296                                        LR 0.000500    Time 0.936887    
2024-02-26 19:04:50,239 - Epoch: [32][  139/  139]    Overall Loss 1.070287    Objective Loss 1.070287    Top1 89.880289    LR 0.000500    Time 0.965224    
2024-02-26 19:04:50,471 - --- validate (epoch=32)-----------
2024-02-26 19:04:50,472 - 1392 samples (32 per mini-batch)
2024-02-26 19:05:19,517 - Epoch: [32][   10/   44]    Loss 1.079859    Top1 88.861846    
2024-02-26 19:05:46,804 - Epoch: [32][   20/   44]    Loss 1.082195    Top1 88.557217    
2024-02-26 19:06:15,690 - Epoch: [32][   30/   44]    Loss 1.078863    Top1 88.466314    
2024-02-26 19:06:48,146 - Epoch: [32][   40/   44]    Loss 1.079121    Top1 88.405852    
2024-02-26 19:06:57,980 - Epoch: [32][   44/   44]    Loss 1.078461    Top1 88.412159    
2024-02-26 19:06:58,200 - ==> Top1: 88.412    Loss: 1.078

2024-02-26 19:06:58,209 - ==> Best [Top1: 88.412   Sparsity:0.00   Params: 271456 on epoch: 32]
2024-02-26 19:06:58,209 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 19:06:58,249 - 

2024-02-26 19:06:58,249 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:07:07,817 - Epoch: [33][   10/  139]    Overall Loss 1.076528    Objective Loss 1.076528                                        LR 0.000500    Time 0.956735    
2024-02-26 19:07:17,141 - Epoch: [33][   20/  139]    Overall Loss 1.077584    Objective Loss 1.077584                                        LR 0.000500    Time 0.944497    
2024-02-26 19:07:26,471 - Epoch: [33][   30/  139]    Overall Loss 1.072289    Objective Loss 1.072289                                        LR 0.000500    Time 0.940667    
2024-02-26 19:07:35,811 - Epoch: [33][   40/  139]    Overall Loss 1.069880    Objective Loss 1.069880                                        LR 0.000500    Time 0.938984    
2024-02-26 19:07:45,152 - Epoch: [33][   50/  139]    Overall Loss 1.068416    Objective Loss 1.068416                                        LR 0.000500    Time 0.938005    
2024-02-26 19:07:54,489 - Epoch: [33][   60/  139]    Overall Loss 1.068567    Objective Loss 1.068567                                        LR 0.000500    Time 0.937278    
2024-02-26 19:08:03,836 - Epoch: [33][   70/  139]    Overall Loss 1.068888    Objective Loss 1.068888                                        LR 0.000500    Time 0.936897    
2024-02-26 19:08:13,191 - Epoch: [33][   80/  139]    Overall Loss 1.068882    Objective Loss 1.068882                                        LR 0.000500    Time 0.936725    
2024-02-26 19:08:22,535 - Epoch: [33][   90/  139]    Overall Loss 1.068307    Objective Loss 1.068307                                        LR 0.000500    Time 0.936457    
2024-02-26 19:08:31,894 - Epoch: [33][  100/  139]    Overall Loss 1.068847    Objective Loss 1.068847                                        LR 0.000500    Time 0.936393    
2024-02-26 19:08:41,241 - Epoch: [33][  110/  139]    Overall Loss 1.068362    Objective Loss 1.068362                                        LR 0.000500    Time 0.936235    
2024-02-26 19:08:50,639 - Epoch: [33][  120/  139]    Overall Loss 1.068227    Objective Loss 1.068227                                        LR 0.000500    Time 0.936526    
2024-02-26 19:08:59,998 - Epoch: [33][  130/  139]    Overall Loss 1.068787    Objective Loss 1.068787                                        LR 0.000500    Time 0.936473    
2024-02-26 19:09:12,241 - Epoch: [33][  139/  139]    Overall Loss 1.069005    Objective Loss 1.069005    Top1 90.474242    LR 0.000500    Time 0.963915    
2024-02-26 19:09:12,478 - --- validate (epoch=33)-----------
2024-02-26 19:09:12,479 - 1392 samples (32 per mini-batch)
2024-02-26 19:09:44,411 - Epoch: [33][   10/   44]    Loss 1.079619    Top1 87.464378    
2024-02-26 19:10:11,818 - Epoch: [33][   20/   44]    Loss 1.080482    Top1 87.440653    
2024-02-26 19:10:38,595 - Epoch: [33][   30/   44]    Loss 1.079392    Top1 87.686614    
2024-02-26 19:11:06,469 - Epoch: [33][   40/   44]    Loss 1.077172    Top1 88.017101    
2024-02-26 19:11:18,669 - Epoch: [33][   44/   44]    Loss 1.075724    Top1 87.935517    
2024-02-26 19:11:18,894 - ==> Top1: 87.936    Loss: 1.076

2024-02-26 19:11:18,905 - ==> Best [Top1: 88.412   Sparsity:0.00   Params: 271456 on epoch: 32]
2024-02-26 19:11:18,905 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 19:11:18,935 - 

2024-02-26 19:11:18,935 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:11:28,479 - Epoch: [34][   10/  139]    Overall Loss 1.068627    Objective Loss 1.068627                                        LR 0.000500    Time 0.954263    
2024-02-26 19:11:37,824 - Epoch: [34][   20/  139]    Overall Loss 1.073459    Objective Loss 1.073459                                        LR 0.000500    Time 0.944360    
2024-02-26 19:11:47,159 - Epoch: [34][   30/  139]    Overall Loss 1.074413    Objective Loss 1.074413                                        LR 0.000500    Time 0.940725    
2024-02-26 19:11:56,501 - Epoch: [34][   40/  139]    Overall Loss 1.074234    Objective Loss 1.074234                                        LR 0.000500    Time 0.939059    
2024-02-26 19:12:05,845 - Epoch: [34][   50/  139]    Overall Loss 1.073546    Objective Loss 1.073546                                        LR 0.000500    Time 0.938132    
2024-02-26 19:12:15,197 - Epoch: [34][   60/  139]    Overall Loss 1.073061    Objective Loss 1.073061                                        LR 0.000500    Time 0.937622    
2024-02-26 19:12:24,549 - Epoch: [34][   70/  139]    Overall Loss 1.071961    Objective Loss 1.071961                                        LR 0.000500    Time 0.937270    
2024-02-26 19:12:33,908 - Epoch: [34][   80/  139]    Overall Loss 1.069493    Objective Loss 1.069493                                        LR 0.000500    Time 0.937093    
2024-02-26 19:12:43,254 - Epoch: [34][   90/  139]    Overall Loss 1.070732    Objective Loss 1.070732                                        LR 0.000500    Time 0.936815    
2024-02-26 19:12:52,609 - Epoch: [34][  100/  139]    Overall Loss 1.070822    Objective Loss 1.070822                                        LR 0.000500    Time 0.936681    
2024-02-26 19:13:01,964 - Epoch: [34][  110/  139]    Overall Loss 1.070491    Objective Loss 1.070491                                        LR 0.000500    Time 0.936563    
2024-02-26 19:13:11,320 - Epoch: [34][  120/  139]    Overall Loss 1.070929    Objective Loss 1.070929                                        LR 0.000500    Time 0.936479    
2024-02-26 19:13:20,662 - Epoch: [34][  130/  139]    Overall Loss 1.070251    Objective Loss 1.070251                                        LR 0.000500    Time 0.936303    
2024-02-26 19:13:33,395 - Epoch: [34][  139/  139]    Overall Loss 1.070747    Objective Loss 1.070747    Top1 91.947083    LR 0.000500    Time 0.967283    
2024-02-26 19:13:33,659 - --- validate (epoch=34)-----------
2024-02-26 19:13:33,660 - 1392 samples (32 per mini-batch)
2024-02-26 19:14:09,942 - Epoch: [34][   10/   44]    Loss 1.073338    Top1 87.283134    
2024-02-26 19:14:44,635 - Epoch: [34][   20/   44]    Loss 1.074066    Top1 87.560233    
2024-02-26 19:15:19,249 - Epoch: [34][   30/   44]    Loss 1.071851    Top1 87.528464    
2024-02-26 19:15:53,432 - Epoch: [34][   40/   44]    Loss 1.068486    Top1 87.773444    
2024-02-26 19:16:04,805 - Epoch: [34][   44/   44]    Loss 1.068737    Top1 87.722368    
2024-02-26 19:16:05,040 - ==> Top1: 87.722    Loss: 1.069

2024-02-26 19:16:05,048 - ==> Best [Top1: 88.412   Sparsity:0.00   Params: 271456 on epoch: 32]
2024-02-26 19:16:05,048 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 19:16:05,085 - 

2024-02-26 19:16:05,085 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:16:14,738 - Epoch: [35][   10/  139]    Overall Loss 1.071545    Objective Loss 1.071545                                        LR 0.000500    Time 0.964985    
2024-02-26 19:16:24,097 - Epoch: [35][   20/  139]    Overall Loss 1.069506    Objective Loss 1.069506                                        LR 0.000500    Time 0.950422    
2024-02-26 19:16:33,442 - Epoch: [35][   30/  139]    Overall Loss 1.070218    Objective Loss 1.070218                                        LR 0.000500    Time 0.945070    
2024-02-26 19:16:42,776 - Epoch: [35][   40/  139]    Overall Loss 1.070218    Objective Loss 1.070218                                        LR 0.000500    Time 0.942145    
2024-02-26 19:16:52,124 - Epoch: [35][   50/  139]    Overall Loss 1.069611    Objective Loss 1.069611                                        LR 0.000500    Time 0.940664    
2024-02-26 19:17:01,472 - Epoch: [35][   60/  139]    Overall Loss 1.068799    Objective Loss 1.068799                                        LR 0.000500    Time 0.939683    
2024-02-26 19:17:10,815 - Epoch: [35][   70/  139]    Overall Loss 1.068941    Objective Loss 1.068941                                        LR 0.000500    Time 0.938906    
2024-02-26 19:17:20,161 - Epoch: [35][   80/  139]    Overall Loss 1.068721    Objective Loss 1.068721                                        LR 0.000500    Time 0.938372    
2024-02-26 19:17:29,513 - Epoch: [35][   90/  139]    Overall Loss 1.068933    Objective Loss 1.068933                                        LR 0.000500    Time 0.938008    
2024-02-26 19:17:38,861 - Epoch: [35][  100/  139]    Overall Loss 1.068970    Objective Loss 1.068970                                        LR 0.000500    Time 0.937687    
2024-02-26 19:17:48,216 - Epoch: [35][  110/  139]    Overall Loss 1.068982    Objective Loss 1.068982                                        LR 0.000500    Time 0.937480    
2024-02-26 19:17:57,572 - Epoch: [35][  120/  139]    Overall Loss 1.069204    Objective Loss 1.069204                                        LR 0.000500    Time 0.937326    
2024-02-26 19:18:06,922 - Epoch: [35][  130/  139]    Overall Loss 1.069544    Objective Loss 1.069544                                        LR 0.000500    Time 0.937136    
2024-02-26 19:18:19,628 - Epoch: [35][  139/  139]    Overall Loss 1.069709    Objective Loss 1.069709    Top1 90.695876    LR 0.000500    Time 0.967870    
2024-02-26 19:18:19,912 - --- validate (epoch=35)-----------
2024-02-26 19:18:19,912 - 1392 samples (32 per mini-batch)
2024-02-26 19:18:55,900 - Epoch: [35][   10/   44]    Loss 1.080052    Top1 89.191040    
2024-02-26 19:19:29,672 - Epoch: [35][   20/   44]    Loss 1.079160    Top1 88.408404    
2024-02-26 19:20:03,517 - Epoch: [35][   30/   44]    Loss 1.079062    Top1 88.240150    
2024-02-26 19:20:35,869 - Epoch: [35][   40/   44]    Loss 1.080449    Top1 88.457028    
2024-02-26 19:20:46,954 - Epoch: [35][   44/   44]    Loss 1.079854    Top1 88.316400    
2024-02-26 19:20:47,142 - ==> Top1: 88.316    Loss: 1.080

2024-02-26 19:20:47,145 - ==> Best [Top1: 88.412   Sparsity:0.00   Params: 271456 on epoch: 32]
2024-02-26 19:20:47,145 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 19:20:47,169 - 

2024-02-26 19:20:47,170 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:20:56,670 - Epoch: [36][   10/  139]    Overall Loss 1.070144    Objective Loss 1.070144                                        LR 0.000500    Time 0.949935    
2024-02-26 19:21:06,007 - Epoch: [36][   20/  139]    Overall Loss 1.070321    Objective Loss 1.070321                                        LR 0.000500    Time 0.941747    
2024-02-26 19:21:15,355 - Epoch: [36][   30/  139]    Overall Loss 1.068706    Objective Loss 1.068706                                        LR 0.000500    Time 0.939409    
2024-02-26 19:21:24,717 - Epoch: [36][   40/  139]    Overall Loss 1.068338    Objective Loss 1.068338                                        LR 0.000500    Time 0.938603    
2024-02-26 19:21:34,091 - Epoch: [36][   50/  139]    Overall Loss 1.067871    Objective Loss 1.067871                                        LR 0.000500    Time 0.938326    
2024-02-26 19:21:43,458 - Epoch: [36][   60/  139]    Overall Loss 1.067850    Objective Loss 1.067850                                        LR 0.000500    Time 0.938034    
2024-02-26 19:21:52,810 - Epoch: [36][   70/  139]    Overall Loss 1.067694    Objective Loss 1.067694                                        LR 0.000500    Time 0.937618    
2024-02-26 19:22:02,153 - Epoch: [36][   80/  139]    Overall Loss 1.067714    Objective Loss 1.067714                                        LR 0.000500    Time 0.937196    
2024-02-26 19:22:11,486 - Epoch: [36][   90/  139]    Overall Loss 1.066538    Objective Loss 1.066538                                        LR 0.000500    Time 0.936759    
2024-02-26 19:22:20,835 - Epoch: [36][  100/  139]    Overall Loss 1.067939    Objective Loss 1.067939                                        LR 0.000500    Time 0.936575    
2024-02-26 19:22:30,180 - Epoch: [36][  110/  139]    Overall Loss 1.067785    Objective Loss 1.067785                                        LR 0.000500    Time 0.936379    
2024-02-26 19:22:39,530 - Epoch: [36][  120/  139]    Overall Loss 1.068028    Objective Loss 1.068028                                        LR 0.000500    Time 0.936263    
2024-02-26 19:22:48,870 - Epoch: [36][  130/  139]    Overall Loss 1.068468    Objective Loss 1.068468                                        LR 0.000500    Time 0.936085    
2024-02-26 19:23:01,524 - Epoch: [36][  139/  139]    Overall Loss 1.068828    Objective Loss 1.068828    Top1 91.404801    LR 0.000500    Time 0.966502    
2024-02-26 19:23:01,765 - --- validate (epoch=36)-----------
2024-02-26 19:23:01,766 - 1392 samples (32 per mini-batch)
2024-02-26 19:23:33,642 - Epoch: [36][   10/   44]    Loss 1.082568    Top1 87.736120    
2024-02-26 19:24:03,675 - Epoch: [36][   20/   44]    Loss 1.076581    Top1 88.007849    
2024-02-26 19:24:40,124 - Epoch: [36][   30/   44]    Loss 1.074198    Top1 87.835244    
2024-02-26 19:25:12,715 - Epoch: [36][   40/   44]    Loss 1.072650    Top1 87.543631    
2024-02-26 19:25:23,379 - Epoch: [36][   44/   44]    Loss 1.072682    Top1 87.532095    
2024-02-26 19:25:23,645 - ==> Top1: 87.532    Loss: 1.073

2024-02-26 19:25:23,656 - ==> Best [Top1: 88.412   Sparsity:0.00   Params: 271456 on epoch: 32]
2024-02-26 19:25:23,656 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 19:25:23,688 - 

2024-02-26 19:25:23,688 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:25:33,393 - Epoch: [37][   10/  139]    Overall Loss 1.067395    Objective Loss 1.067395                                        LR 0.000500    Time 0.970325    
2024-02-26 19:25:42,724 - Epoch: [37][   20/  139]    Overall Loss 1.067164    Objective Loss 1.067164                                        LR 0.000500    Time 0.951686    
2024-02-26 19:25:52,063 - Epoch: [37][   30/  139]    Overall Loss 1.067403    Objective Loss 1.067403                                        LR 0.000500    Time 0.945725    
2024-02-26 19:26:01,411 - Epoch: [37][   40/  139]    Overall Loss 1.064657    Objective Loss 1.064657                                        LR 0.000500    Time 0.942969    
2024-02-26 19:26:10,755 - Epoch: [37][   50/  139]    Overall Loss 1.064613    Objective Loss 1.064613                                        LR 0.000500    Time 0.941245    
2024-02-26 19:26:20,100 - Epoch: [37][   60/  139]    Overall Loss 1.065034    Objective Loss 1.065034                                        LR 0.000500    Time 0.940122    
2024-02-26 19:26:29,452 - Epoch: [37][   70/  139]    Overall Loss 1.065175    Objective Loss 1.065175                                        LR 0.000500    Time 0.939405    
2024-02-26 19:26:38,818 - Epoch: [37][   80/  139]    Overall Loss 1.065183    Objective Loss 1.065183                                        LR 0.000500    Time 0.939043    
2024-02-26 19:26:48,174 - Epoch: [37][   90/  139]    Overall Loss 1.066312    Objective Loss 1.066312                                        LR 0.000500    Time 0.938655    
2024-02-26 19:26:57,529 - Epoch: [37][  100/  139]    Overall Loss 1.067305    Objective Loss 1.067305                                        LR 0.000500    Time 0.938325    
2024-02-26 19:27:06,882 - Epoch: [37][  110/  139]    Overall Loss 1.066751    Objective Loss 1.066751                                        LR 0.000500    Time 0.938036    
2024-02-26 19:27:16,223 - Epoch: [37][  120/  139]    Overall Loss 1.066242    Objective Loss 1.066242                                        LR 0.000500    Time 0.937699    
2024-02-26 19:27:25,573 - Epoch: [37][  130/  139]    Overall Loss 1.066644    Objective Loss 1.066644                                        LR 0.000500    Time 0.937489    
2024-02-26 19:27:38,230 - Epoch: [37][  139/  139]    Overall Loss 1.067290    Objective Loss 1.067290    Top1 90.919088    LR 0.000500    Time 0.967840    
2024-02-26 19:27:38,431 - --- validate (epoch=37)-----------
2024-02-26 19:27:38,432 - 1392 samples (32 per mini-batch)
2024-02-26 19:28:13,595 - Epoch: [37][   10/   44]    Loss 1.081605    Top1 87.121824    
2024-02-26 19:28:46,058 - Epoch: [37][   20/   44]    Loss 1.083519    Top1 87.177205    
2024-02-26 19:29:18,902 - Epoch: [37][   30/   44]    Loss 1.079431    Top1 87.330535    
2024-02-26 19:29:53,539 - Epoch: [37][   40/   44]    Loss 1.079185    Top1 87.104318    
2024-02-26 19:30:05,362 - Epoch: [37][   44/   44]    Loss 1.077553    Top1 87.163019    
2024-02-26 19:30:05,612 - ==> Top1: 87.163    Loss: 1.078

2024-02-26 19:30:05,621 - ==> Best [Top1: 88.412   Sparsity:0.00   Params: 271456 on epoch: 32]
2024-02-26 19:30:05,621 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 19:30:05,660 - 

2024-02-26 19:30:05,661 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:30:15,346 - Epoch: [38][   10/  139]    Overall Loss 1.061815    Objective Loss 1.061815                                        LR 0.000500    Time 0.968258    
2024-02-26 19:30:24,688 - Epoch: [38][   20/  139]    Overall Loss 1.061101    Objective Loss 1.061101                                        LR 0.000500    Time 0.951191    
2024-02-26 19:30:34,024 - Epoch: [38][   30/  139]    Overall Loss 1.065172    Objective Loss 1.065172                                        LR 0.000500    Time 0.945303    
2024-02-26 19:30:43,379 - Epoch: [38][   40/  139]    Overall Loss 1.063947    Objective Loss 1.063947                                        LR 0.000500    Time 0.942844    
2024-02-26 19:30:52,731 - Epoch: [38][   50/  139]    Overall Loss 1.066058    Objective Loss 1.066058                                        LR 0.000500    Time 0.941301    
2024-02-26 19:31:02,109 - Epoch: [38][   60/  139]    Overall Loss 1.066548    Objective Loss 1.066548                                        LR 0.000500    Time 0.940709    
2024-02-26 19:31:11,435 - Epoch: [38][   70/  139]    Overall Loss 1.067032    Objective Loss 1.067032                                        LR 0.000500    Time 0.939546    
2024-02-26 19:31:20,790 - Epoch: [38][   80/  139]    Overall Loss 1.067496    Objective Loss 1.067496                                        LR 0.000500    Time 0.939030    
2024-02-26 19:31:30,152 - Epoch: [38][   90/  139]    Overall Loss 1.067125    Objective Loss 1.067125                                        LR 0.000500    Time 0.938709    
2024-02-26 19:31:39,506 - Epoch: [38][  100/  139]    Overall Loss 1.067659    Objective Loss 1.067659                                        LR 0.000500    Time 0.938375    
2024-02-26 19:31:48,883 - Epoch: [38][  110/  139]    Overall Loss 1.067458    Objective Loss 1.067458                                        LR 0.000500    Time 0.938309    
2024-02-26 19:31:58,260 - Epoch: [38][  120/  139]    Overall Loss 1.068038    Objective Loss 1.068038                                        LR 0.000500    Time 0.938252    
2024-02-26 19:32:07,625 - Epoch: [38][  130/  139]    Overall Loss 1.067645    Objective Loss 1.067645                                        LR 0.000500    Time 0.938109    
2024-02-26 19:32:20,599 - Epoch: [38][  139/  139]    Overall Loss 1.068122    Objective Loss 1.068122    Top1 90.208842    LR 0.000500    Time 0.970701    
2024-02-26 19:32:20,877 - --- validate (epoch=38)-----------
2024-02-26 19:32:20,878 - 1392 samples (32 per mini-batch)
2024-02-26 19:32:56,130 - Epoch: [38][   10/   44]    Loss 1.062970    Top1 88.432607    
2024-02-26 19:33:28,568 - Epoch: [38][   20/   44]    Loss 1.067441    Top1 88.170037    
2024-02-26 19:34:00,026 - Epoch: [38][   30/   44]    Loss 1.067716    Top1 88.206508    
2024-02-26 19:34:33,804 - Epoch: [38][   40/   44]    Loss 1.066295    Top1 88.336070    
2024-02-26 19:34:45,480 - Epoch: [38][   44/   44]    Loss 1.065907    Top1 88.350098    
2024-02-26 19:34:45,777 - ==> Top1: 88.350    Loss: 1.066

2024-02-26 19:34:45,786 - ==> Best [Top1: 88.412   Sparsity:0.00   Params: 271456 on epoch: 32]
2024-02-26 19:34:45,786 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 19:34:45,825 - 

2024-02-26 19:34:45,826 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:34:55,464 - Epoch: [39][   10/  139]    Overall Loss 1.069699    Objective Loss 1.069699                                        LR 0.000500    Time 0.963545    
2024-02-26 19:35:04,805 - Epoch: [39][   20/  139]    Overall Loss 1.069387    Objective Loss 1.069387                                        LR 0.000500    Time 0.948807    
2024-02-26 19:35:14,153 - Epoch: [39][   30/  139]    Overall Loss 1.067906    Objective Loss 1.067906                                        LR 0.000500    Time 0.944107    
2024-02-26 19:35:23,488 - Epoch: [39][   40/  139]    Overall Loss 1.067563    Objective Loss 1.067563                                        LR 0.000500    Time 0.941444    
2024-02-26 19:35:32,840 - Epoch: [39][   50/  139]    Overall Loss 1.068987    Objective Loss 1.068987                                        LR 0.000500    Time 0.940186    
2024-02-26 19:35:42,201 - Epoch: [39][   60/  139]    Overall Loss 1.068164    Objective Loss 1.068164                                        LR 0.000500    Time 0.939482    
2024-02-26 19:35:51,543 - Epoch: [39][   70/  139]    Overall Loss 1.068317    Objective Loss 1.068317                                        LR 0.000500    Time 0.938720    
2024-02-26 19:36:00,889 - Epoch: [39][   80/  139]    Overall Loss 1.068734    Objective Loss 1.068734                                        LR 0.000500    Time 0.938208    
2024-02-26 19:36:10,240 - Epoch: [39][   90/  139]    Overall Loss 1.068917    Objective Loss 1.068917                                        LR 0.000500    Time 0.937849    
2024-02-26 19:36:19,590 - Epoch: [39][  100/  139]    Overall Loss 1.068641    Objective Loss 1.068641                                        LR 0.000500    Time 0.937567    
2024-02-26 19:36:28,930 - Epoch: [39][  110/  139]    Overall Loss 1.068499    Objective Loss 1.068499                                        LR 0.000500    Time 0.937232    
2024-02-26 19:36:38,281 - Epoch: [39][  120/  139]    Overall Loss 1.067833    Objective Loss 1.067833                                        LR 0.000500    Time 0.937055    
2024-02-26 19:36:47,638 - Epoch: [39][  130/  139]    Overall Loss 1.068408    Objective Loss 1.068408                                        LR 0.000500    Time 0.936945    
2024-02-26 19:37:00,134 - Epoch: [39][  139/  139]    Overall Loss 1.068833    Objective Loss 1.068833    Top1 92.279378    LR 0.000500    Time 0.966173    
2024-02-26 19:37:00,367 - --- validate (epoch=39)-----------
2024-02-26 19:37:00,367 - 1392 samples (32 per mini-batch)
2024-02-26 19:37:36,544 - Epoch: [39][   10/   44]    Loss 1.070003    Top1 88.330613    
2024-02-26 19:38:11,319 - Epoch: [39][   20/   44]    Loss 1.073579    Top1 88.420966    
2024-02-26 19:38:41,021 - Epoch: [39][   30/   44]    Loss 1.075213    Top1 88.191761    
2024-02-26 19:39:07,796 - Epoch: [39][   40/   44]    Loss 1.076162    Top1 88.208886    
2024-02-26 19:39:16,960 - Epoch: [39][   44/   44]    Loss 1.075566    Top1 88.157808    
2024-02-26 19:39:17,188 - ==> Top1: 88.158    Loss: 1.076

2024-02-26 19:39:17,198 - ==> Best [Top1: 88.412   Sparsity:0.00   Params: 271456 on epoch: 32]
2024-02-26 19:39:17,198 - Saving checkpoint to: logs/2024.02.26-163117/checkpoint.pth.tar
2024-02-26 19:39:17,233 - 

2024-02-26 19:39:17,233 - Initiating quantization aware training (QAT)...
2024-02-26 19:39:17,266 - 

2024-02-26 19:39:17,266 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:39:26,097 - Epoch: [40][   10/  139]    Overall Loss 1.020599    Objective Loss 1.020599                                        LR 0.000500    Time 0.882912    
2024-02-26 19:39:34,528 - Epoch: [40][   20/  139]    Overall Loss 0.977945    Objective Loss 0.977945                                        LR 0.000500    Time 0.862984    
2024-02-26 19:39:42,935 - Epoch: [40][   30/  139]    Overall Loss 0.970297    Objective Loss 0.970297                                        LR 0.000500    Time 0.855543    
2024-02-26 19:39:51,334 - Epoch: [40][   40/  139]    Overall Loss 0.951290    Objective Loss 0.951290                                        LR 0.000500    Time 0.851617    
2024-02-26 19:39:59,735 - Epoch: [40][   50/  139]    Overall Loss 0.938300    Objective Loss 0.938300                                        LR 0.000500    Time 0.849295    
2024-02-26 19:40:08,156 - Epoch: [40][   60/  139]    Overall Loss 0.936288    Objective Loss 0.936288                                        LR 0.000500    Time 0.848088    
2024-02-26 19:40:16,590 - Epoch: [40][   70/  139]    Overall Loss 0.926176    Objective Loss 0.926176                                        LR 0.000500    Time 0.847406    
2024-02-26 19:40:25,015 - Epoch: [40][   80/  139]    Overall Loss 0.917023    Objective Loss 0.917023                                        LR 0.000500    Time 0.846786    
2024-02-26 19:40:33,461 - Epoch: [40][   90/  139]    Overall Loss 0.909137    Objective Loss 0.909137                                        LR 0.000500    Time 0.846542    
2024-02-26 19:40:41,883 - Epoch: [40][  100/  139]    Overall Loss 0.897824    Objective Loss 0.897824                                        LR 0.000500    Time 0.846104    
2024-02-26 19:40:50,312 - Epoch: [40][  110/  139]    Overall Loss 0.890339    Objective Loss 0.890339                                        LR 0.000500    Time 0.845806    
2024-02-26 19:40:58,718 - Epoch: [40][  120/  139]    Overall Loss 0.879869    Objective Loss 0.879869                                        LR 0.000500    Time 0.845372    
2024-02-26 19:41:07,108 - Epoch: [40][  130/  139]    Overall Loss 0.872811    Objective Loss 0.872811                                        LR 0.000500    Time 0.844875    
2024-02-26 19:41:19,003 - Epoch: [40][  139/  139]    Overall Loss 0.866718    Objective Loss 0.866718    Top1 71.886739    LR 0.000500    Time 0.875740    
2024-02-26 19:41:19,320 - --- validate (epoch=40)-----------
2024-02-26 19:41:19,321 - 1392 samples (32 per mini-batch)
2024-02-26 19:41:50,208 - Epoch: [40][   10/   44]    Loss 0.804507    Top1 67.966710    
2024-02-26 19:42:20,889 - Epoch: [40][   20/   44]    Loss 0.795305    Top1 68.497876    
2024-02-26 19:42:49,330 - Epoch: [40][   30/   44]    Loss 0.795086    Top1 68.767573    
2024-02-26 19:43:17,575 - Epoch: [40][   40/   44]    Loss 0.799979    Top1 68.590459    
2024-02-26 19:43:26,523 - Epoch: [40][   44/   44]    Loss 0.801338    Top1 68.246602    
2024-02-26 19:43:26,701 - ==> Top1: 68.247    Loss: 0.801

2024-02-26 19:43:26,707 - ==> Best [Top1: 68.247   Sparsity:0.00   Params: 271456 on epoch: 40]
2024-02-26 19:43:26,708 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 19:43:26,740 - 

2024-02-26 19:43:26,740 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:43:35,584 - Epoch: [41][   10/  139]    Overall Loss 0.790184    Objective Loss 0.790184                                        LR 0.000500    Time 0.884267    
2024-02-26 19:43:43,965 - Epoch: [41][   20/  139]    Overall Loss 0.774913    Objective Loss 0.774913                                        LR 0.000500    Time 0.861139    
2024-02-26 19:43:52,369 - Epoch: [41][   30/  139]    Overall Loss 0.767581    Objective Loss 0.767581                                        LR 0.000500    Time 0.854214    
2024-02-26 19:44:00,767 - Epoch: [41][   40/  139]    Overall Loss 0.756071    Objective Loss 0.756071                                        LR 0.000500    Time 0.850606    
2024-02-26 19:44:09,174 - Epoch: [41][   50/  139]    Overall Loss 0.746195    Objective Loss 0.746195                                        LR 0.000500    Time 0.848605    
2024-02-26 19:44:17,631 - Epoch: [41][   60/  139]    Overall Loss 0.736802    Objective Loss 0.736802                                        LR 0.000500    Time 0.848105    
2024-02-26 19:44:26,058 - Epoch: [41][   70/  139]    Overall Loss 0.730512    Objective Loss 0.730512                                        LR 0.000500    Time 0.847324    
2024-02-26 19:44:34,464 - Epoch: [41][   80/  139]    Overall Loss 0.724492    Objective Loss 0.724492                                        LR 0.000500    Time 0.846477    
2024-02-26 19:44:42,880 - Epoch: [41][   90/  139]    Overall Loss 0.720832    Objective Loss 0.720832                                        LR 0.000500    Time 0.845935    
2024-02-26 19:44:51,276 - Epoch: [41][  100/  139]    Overall Loss 0.717984    Objective Loss 0.717984                                        LR 0.000500    Time 0.845291    
2024-02-26 19:44:59,685 - Epoch: [41][  110/  139]    Overall Loss 0.714761    Objective Loss 0.714761                                        LR 0.000500    Time 0.844896    
2024-02-26 19:45:08,067 - Epoch: [41][  120/  139]    Overall Loss 0.711098    Objective Loss 0.711098                                        LR 0.000500    Time 0.844329    
2024-02-26 19:45:16,464 - Epoch: [41][  130/  139]    Overall Loss 0.707002    Objective Loss 0.707002                                        LR 0.000500    Time 0.843970    
2024-02-26 19:45:28,081 - Epoch: [41][  139/  139]    Overall Loss 0.703874    Objective Loss 0.703874    Top1 76.986710    LR 0.000500    Time 0.872899    
2024-02-26 19:45:28,343 - --- validate (epoch=41)-----------
2024-02-26 19:45:28,344 - 1392 samples (32 per mini-batch)
2024-02-26 19:46:00,054 - Epoch: [41][   10/   44]    Loss 0.736786    Top1 75.088027    
2024-02-26 19:46:30,642 - Epoch: [41][   20/   44]    Loss 0.732538    Top1 75.021748    
2024-02-26 19:47:04,002 - Epoch: [41][   30/   44]    Loss 0.740702    Top1 74.017844    
2024-02-26 19:47:35,421 - Epoch: [41][   40/   44]    Loss 0.747130    Top1 73.475341    
2024-02-26 19:47:46,211 - Epoch: [41][   44/   44]    Loss 0.747745    Top1 73.389177    
2024-02-26 19:47:46,606 - ==> Top1: 73.389    Loss: 0.748

2024-02-26 19:47:46,613 - ==> Best [Top1: 73.389   Sparsity:0.00   Params: 271456 on epoch: 41]
2024-02-26 19:47:46,613 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 19:47:46,649 - 

2024-02-26 19:47:46,650 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:47:55,516 - Epoch: [42][   10/  139]    Overall Loss 0.661257    Objective Loss 0.661257                                        LR 0.000500    Time 0.886527    
2024-02-26 19:48:03,932 - Epoch: [42][   20/  139]    Overall Loss 0.651672    Objective Loss 0.651672                                        LR 0.000500    Time 0.864027    
2024-02-26 19:48:12,330 - Epoch: [42][   30/  139]    Overall Loss 0.652470    Objective Loss 0.652470                                        LR 0.000500    Time 0.855924    
2024-02-26 19:48:20,738 - Epoch: [42][   40/  139]    Overall Loss 0.647680    Objective Loss 0.647680                                        LR 0.000500    Time 0.852147    
2024-02-26 19:48:29,157 - Epoch: [42][   50/  139]    Overall Loss 0.645598    Objective Loss 0.645598                                        LR 0.000500    Time 0.850082    
2024-02-26 19:48:37,558 - Epoch: [42][   60/  139]    Overall Loss 0.641064    Objective Loss 0.641064                                        LR 0.000500    Time 0.848414    
2024-02-26 19:48:45,976 - Epoch: [42][   70/  139]    Overall Loss 0.638884    Objective Loss 0.638884                                        LR 0.000500    Time 0.847458    
2024-02-26 19:48:54,386 - Epoch: [42][   80/  139]    Overall Loss 0.634428    Objective Loss 0.634428                                        LR 0.000500    Time 0.846650    
2024-02-26 19:49:02,793 - Epoch: [42][   90/  139]    Overall Loss 0.631357    Objective Loss 0.631357                                        LR 0.000500    Time 0.845980    
2024-02-26 19:49:11,210 - Epoch: [42][  100/  139]    Overall Loss 0.627780    Objective Loss 0.627780                                        LR 0.000500    Time 0.845550    
2024-02-26 19:49:19,648 - Epoch: [42][  110/  139]    Overall Loss 0.625070    Objective Loss 0.625070                                        LR 0.000500    Time 0.845383    
2024-02-26 19:49:28,079 - Epoch: [42][  120/  139]    Overall Loss 0.620585    Objective Loss 0.620585                                        LR 0.000500    Time 0.845189    
2024-02-26 19:49:36,528 - Epoch: [42][  130/  139]    Overall Loss 0.619372    Objective Loss 0.619372                                        LR 0.000500    Time 0.845159    
2024-02-26 19:49:47,917 - Epoch: [42][  139/  139]    Overall Loss 0.617635    Objective Loss 0.617635    Top1 83.489857    LR 0.000500    Time 0.872371    
2024-02-26 19:49:48,168 - --- validate (epoch=42)-----------
2024-02-26 19:49:48,168 - 1392 samples (32 per mini-batch)
2024-02-26 19:50:21,131 - Epoch: [42][   10/   44]    Loss 0.631456    Top1 82.695711    
2024-02-26 19:50:54,389 - Epoch: [42][   20/   44]    Loss 0.631143    Top1 82.411693    
2024-02-26 19:51:24,893 - Epoch: [42][   30/   44]    Loss 0.628016    Top1 82.539559    
2024-02-26 19:51:56,983 - Epoch: [42][   40/   44]    Loss 0.626057    Top1 82.672198    
2024-02-26 19:52:09,801 - Epoch: [42][   44/   44]    Loss 0.626717    Top1 82.626014    
2024-02-26 19:52:10,084 - ==> Top1: 82.626    Loss: 0.627

2024-02-26 19:52:10,092 - ==> Best [Top1: 82.626   Sparsity:0.00   Params: 271456 on epoch: 42]
2024-02-26 19:52:10,092 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 19:52:10,126 - 

2024-02-26 19:52:10,127 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:52:19,004 - Epoch: [43][   10/  139]    Overall Loss 0.586586    Objective Loss 0.586586                                        LR 0.000500    Time 0.887611    
2024-02-26 19:52:27,410 - Epoch: [43][   20/  139]    Overall Loss 0.588475    Objective Loss 0.588475                                        LR 0.000500    Time 0.864081    
2024-02-26 19:52:35,820 - Epoch: [43][   30/  139]    Overall Loss 0.582110    Objective Loss 0.582110                                        LR 0.000500    Time 0.856364    
2024-02-26 19:52:44,225 - Epoch: [43][   40/  139]    Overall Loss 0.576903    Objective Loss 0.576903                                        LR 0.000500    Time 0.852379    
2024-02-26 19:52:52,620 - Epoch: [43][   50/  139]    Overall Loss 0.574063    Objective Loss 0.574063                                        LR 0.000500    Time 0.849801    
2024-02-26 19:53:01,032 - Epoch: [43][   60/  139]    Overall Loss 0.572243    Objective Loss 0.572243                                        LR 0.000500    Time 0.848356    
2024-02-26 19:53:09,434 - Epoch: [43][   70/  139]    Overall Loss 0.571334    Objective Loss 0.571334                                        LR 0.000500    Time 0.847178    
2024-02-26 19:53:17,852 - Epoch: [43][   80/  139]    Overall Loss 0.574766    Objective Loss 0.574766                                        LR 0.000500    Time 0.846505    
2024-02-26 19:53:26,250 - Epoch: [43][   90/  139]    Overall Loss 0.573166    Objective Loss 0.573166                                        LR 0.000500    Time 0.845750    
2024-02-26 19:53:34,658 - Epoch: [43][  100/  139]    Overall Loss 0.571030    Objective Loss 0.571030                                        LR 0.000500    Time 0.845258    
2024-02-26 19:53:43,054 - Epoch: [43][  110/  139]    Overall Loss 0.568993    Objective Loss 0.568993                                        LR 0.000500    Time 0.844736    
2024-02-26 19:53:51,483 - Epoch: [43][  120/  139]    Overall Loss 0.567020    Objective Loss 0.567020                                        LR 0.000500    Time 0.844578    
2024-02-26 19:53:59,875 - Epoch: [43][  130/  139]    Overall Loss 0.567154    Objective Loss 0.567154                                        LR 0.000500    Time 0.844166    
2024-02-26 19:54:11,540 - Epoch: [43][  139/  139]    Overall Loss 0.566104    Objective Loss 0.566104    Top1 83.461903    LR 0.000500    Time 0.873422    
2024-02-26 19:54:11,774 - --- validate (epoch=43)-----------
2024-02-26 19:54:11,775 - 1392 samples (32 per mini-batch)
2024-02-26 19:54:47,858 - Epoch: [43][   10/   44]    Loss 0.615683    Top1 83.574711    
2024-02-26 19:55:22,836 - Epoch: [43][   20/   44]    Loss 0.612430    Top1 83.686444    
2024-02-26 19:55:55,196 - Epoch: [43][   30/   44]    Loss 0.612594    Top1 83.680333    
2024-02-26 19:56:26,779 - Epoch: [43][   40/   44]    Loss 0.610339    Top1 83.854810    
2024-02-26 19:56:38,121 - Epoch: [43][   44/   44]    Loss 0.607601    Top1 83.981722    
2024-02-26 19:56:38,413 - ==> Top1: 83.982    Loss: 0.608

2024-02-26 19:56:38,420 - ==> Best [Top1: 83.982   Sparsity:0.00   Params: 271456 on epoch: 43]
2024-02-26 19:56:38,421 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 19:56:38,456 - 

2024-02-26 19:56:38,457 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 19:56:47,364 - Epoch: [44][   10/  139]    Overall Loss 0.571549    Objective Loss 0.571549                                        LR 0.000500    Time 0.890573    
2024-02-26 19:56:55,768 - Epoch: [44][   20/  139]    Overall Loss 0.559796    Objective Loss 0.559796                                        LR 0.000500    Time 0.865498    
2024-02-26 19:57:04,197 - Epoch: [44][   30/  139]    Overall Loss 0.563214    Objective Loss 0.563214                                        LR 0.000500    Time 0.857938    
2024-02-26 19:57:12,616 - Epoch: [44][   40/  139]    Overall Loss 0.563462    Objective Loss 0.563462                                        LR 0.000500    Time 0.853908    
2024-02-26 19:57:21,025 - Epoch: [44][   50/  139]    Overall Loss 0.558339    Objective Loss 0.558339                                        LR 0.000500    Time 0.851300    
2024-02-26 19:57:29,445 - Epoch: [44][   60/  139]    Overall Loss 0.553462    Objective Loss 0.553462                                        LR 0.000500    Time 0.849744    
2024-02-26 19:57:37,835 - Epoch: [44][   70/  139]    Overall Loss 0.550618    Objective Loss 0.550618                                        LR 0.000500    Time 0.848201    
2024-02-26 19:57:46,286 - Epoch: [44][   80/  139]    Overall Loss 0.549636    Objective Loss 0.549636                                        LR 0.000500    Time 0.847807    
2024-02-26 19:57:54,704 - Epoch: [44][   90/  139]    Overall Loss 0.548609    Objective Loss 0.548609                                        LR 0.000500    Time 0.847134    
2024-02-26 19:58:03,109 - Epoch: [44][  100/  139]    Overall Loss 0.547866    Objective Loss 0.547866                                        LR 0.000500    Time 0.846462    
2024-02-26 19:58:11,517 - Epoch: [44][  110/  139]    Overall Loss 0.545796    Objective Loss 0.545796                                        LR 0.000500    Time 0.845941    
2024-02-26 19:58:19,931 - Epoch: [44][  120/  139]    Overall Loss 0.545883    Objective Loss 0.545883                                        LR 0.000500    Time 0.845565    
2024-02-26 19:58:28,344 - Epoch: [44][  130/  139]    Overall Loss 0.547658    Objective Loss 0.547658                                        LR 0.000500    Time 0.845227    
2024-02-26 19:58:40,236 - Epoch: [44][  139/  139]    Overall Loss 0.548232    Objective Loss 0.548232    Top1 85.296094    LR 0.000500    Time 0.876050    
2024-02-26 19:58:40,541 - --- validate (epoch=44)-----------
2024-02-26 19:58:40,543 - 1392 samples (32 per mini-batch)
2024-02-26 19:59:14,276 - Epoch: [44][   10/   44]    Loss 0.575273    Top1 85.391715    
2024-02-26 19:59:48,923 - Epoch: [44][   20/   44]    Loss 0.577980    Top1 85.266435    
2024-02-26 20:00:22,396 - Epoch: [44][   30/   44]    Loss 0.575207    Top1 85.467227    
2024-02-26 20:00:55,666 - Epoch: [44][   40/   44]    Loss 0.575310    Top1 85.445869    
2024-02-26 20:01:06,620 - Epoch: [44][   44/   44]    Loss 0.574568    Top1 85.445230    
2024-02-26 20:01:06,849 - ==> Top1: 85.445    Loss: 0.575

2024-02-26 20:01:06,857 - ==> Best [Top1: 85.445   Sparsity:0.00   Params: 271456 on epoch: 44]
2024-02-26 20:01:06,857 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:01:06,895 - 

2024-02-26 20:01:06,895 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:01:15,681 - Epoch: [45][   10/  139]    Overall Loss 0.563679    Objective Loss 0.563679                                        LR 0.000500    Time 0.878431    
2024-02-26 20:01:24,069 - Epoch: [45][   20/  139]    Overall Loss 0.563964    Objective Loss 0.563964                                        LR 0.000500    Time 0.858611    
2024-02-26 20:01:32,470 - Epoch: [45][   30/  139]    Overall Loss 0.554318    Objective Loss 0.554318                                        LR 0.000500    Time 0.852410    
2024-02-26 20:01:40,862 - Epoch: [45][   40/  139]    Overall Loss 0.551804    Objective Loss 0.551804                                        LR 0.000500    Time 0.849094    
2024-02-26 20:01:49,268 - Epoch: [45][   50/  139]    Overall Loss 0.546764    Objective Loss 0.546764                                        LR 0.000500    Time 0.847394    
2024-02-26 20:01:57,664 - Epoch: [45][   60/  139]    Overall Loss 0.544589    Objective Loss 0.544589                                        LR 0.000500    Time 0.846074    
2024-02-26 20:02:06,066 - Epoch: [45][   70/  139]    Overall Loss 0.542958    Objective Loss 0.542958                                        LR 0.000500    Time 0.845237    
2024-02-26 20:02:14,468 - Epoch: [45][   80/  139]    Overall Loss 0.541229    Objective Loss 0.541229                                        LR 0.000500    Time 0.844602    
2024-02-26 20:02:22,872 - Epoch: [45][   90/  139]    Overall Loss 0.539943    Objective Loss 0.539943                                        LR 0.000500    Time 0.844119    
2024-02-26 20:02:31,282 - Epoch: [45][  100/  139]    Overall Loss 0.538074    Objective Loss 0.538074                                        LR 0.000500    Time 0.843810    
2024-02-26 20:02:39,694 - Epoch: [45][  110/  139]    Overall Loss 0.535435    Objective Loss 0.535435                                        LR 0.000500    Time 0.843563    
2024-02-26 20:02:48,099 - Epoch: [45][  120/  139]    Overall Loss 0.534223    Objective Loss 0.534223                                        LR 0.000500    Time 0.843303    
2024-02-26 20:02:56,551 - Epoch: [45][  130/  139]    Overall Loss 0.533289    Objective Loss 0.533289                                        LR 0.000500    Time 0.843450    
2024-02-26 20:03:08,421 - Epoch: [45][  139/  139]    Overall Loss 0.533568    Objective Loss 0.533568    Top1 87.754413    LR 0.000500    Time 0.874225    
2024-02-26 20:03:08,694 - --- validate (epoch=45)-----------
2024-02-26 20:03:08,695 - 1392 samples (32 per mini-batch)
2024-02-26 20:03:41,695 - Epoch: [45][   10/   44]    Loss 0.572595    Top1 85.441564    
2024-02-26 20:04:12,656 - Epoch: [45][   20/   44]    Loss 0.566051    Top1 85.885648    
2024-02-26 20:04:42,589 - Epoch: [45][   30/   44]    Loss 0.568840    Top1 85.673239    
2024-02-26 20:05:14,331 - Epoch: [45][   40/   44]    Loss 0.565686    Top1 85.837390    
2024-02-26 20:05:24,952 - Epoch: [45][   44/   44]    Loss 0.565535    Top1 85.858042    
2024-02-26 20:05:25,311 - ==> Top1: 85.858    Loss: 0.566

2024-02-26 20:05:25,318 - ==> Best [Top1: 85.858   Sparsity:0.00   Params: 271456 on epoch: 45]
2024-02-26 20:05:25,319 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:05:25,359 - 

2024-02-26 20:05:25,359 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:05:34,224 - Epoch: [46][   10/  139]    Overall Loss 0.515920    Objective Loss 0.515920                                        LR 0.000500    Time 0.886339    
2024-02-26 20:05:42,656 - Epoch: [46][   20/  139]    Overall Loss 0.517033    Objective Loss 0.517033                                        LR 0.000500    Time 0.864734    
2024-02-26 20:05:51,040 - Epoch: [46][   30/  139]    Overall Loss 0.517102    Objective Loss 0.517102                                        LR 0.000500    Time 0.855941    
2024-02-26 20:05:59,442 - Epoch: [46][   40/  139]    Overall Loss 0.516490    Objective Loss 0.516490                                        LR 0.000500    Time 0.852006    
2024-02-26 20:06:07,847 - Epoch: [46][   50/  139]    Overall Loss 0.518156    Objective Loss 0.518156                                        LR 0.000500    Time 0.849685    
2024-02-26 20:06:16,249 - Epoch: [46][   60/  139]    Overall Loss 0.517306    Objective Loss 0.517306                                        LR 0.000500    Time 0.848110    
2024-02-26 20:06:24,701 - Epoch: [46][   70/  139]    Overall Loss 0.517594    Objective Loss 0.517594                                        LR 0.000500    Time 0.847678    
2024-02-26 20:06:33,114 - Epoch: [46][   80/  139]    Overall Loss 0.517637    Objective Loss 0.517637                                        LR 0.000500    Time 0.846880    
2024-02-26 20:06:41,518 - Epoch: [46][   90/  139]    Overall Loss 0.518797    Objective Loss 0.518797                                        LR 0.000500    Time 0.846157    
2024-02-26 20:06:49,926 - Epoch: [46][  100/  139]    Overall Loss 0.521073    Objective Loss 0.521073                                        LR 0.000500    Time 0.845611    
2024-02-26 20:06:58,327 - Epoch: [46][  110/  139]    Overall Loss 0.519433    Objective Loss 0.519433                                        LR 0.000500    Time 0.845108    
2024-02-26 20:07:06,755 - Epoch: [46][  120/  139]    Overall Loss 0.520121    Objective Loss 0.520121                                        LR 0.000500    Time 0.844909    
2024-02-26 20:07:15,184 - Epoch: [46][  130/  139]    Overall Loss 0.519128    Objective Loss 0.519128                                        LR 0.000500    Time 0.844754    
2024-02-26 20:07:26,939 - Epoch: [46][  139/  139]    Overall Loss 0.519523    Objective Loss 0.519523    Top1 89.106981    LR 0.000500    Time 0.874617    
2024-02-26 20:07:27,161 - --- validate (epoch=46)-----------
2024-02-26 20:07:27,161 - 1392 samples (32 per mini-batch)
2024-02-26 20:08:01,189 - Epoch: [46][   10/   44]    Loss 0.560928    Top1 86.058070    
2024-02-26 20:08:31,817 - Epoch: [46][   20/   44]    Loss 0.551985    Top1 86.722102    
2024-02-26 20:08:59,510 - Epoch: [46][   30/   44]    Loss 0.552988    Top1 86.682620    
2024-02-26 20:09:28,824 - Epoch: [46][   40/   44]    Loss 0.554121    Top1 86.639883    
2024-02-26 20:09:41,490 - Epoch: [46][   44/   44]    Loss 0.556782    Top1 86.526879    
2024-02-26 20:09:41,915 - ==> Top1: 86.527    Loss: 0.557

2024-02-26 20:09:41,922 - ==> Best [Top1: 86.527   Sparsity:0.00   Params: 271456 on epoch: 46]
2024-02-26 20:09:41,922 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:09:41,958 - 

2024-02-26 20:09:41,958 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:09:50,908 - Epoch: [47][   10/  139]    Overall Loss 0.503034    Objective Loss 0.503034                                        LR 0.000500    Time 0.894834    
2024-02-26 20:09:59,308 - Epoch: [47][   20/  139]    Overall Loss 0.507458    Objective Loss 0.507458                                        LR 0.000500    Time 0.867406    
2024-02-26 20:10:07,716 - Epoch: [47][   30/  139]    Overall Loss 0.509140    Objective Loss 0.509140                                        LR 0.000500    Time 0.858491    
2024-02-26 20:10:16,095 - Epoch: [47][   40/  139]    Overall Loss 0.509255    Objective Loss 0.509255                                        LR 0.000500    Time 0.853352    
2024-02-26 20:10:24,496 - Epoch: [47][   50/  139]    Overall Loss 0.508052    Objective Loss 0.508052                                        LR 0.000500    Time 0.850693    
2024-02-26 20:10:32,911 - Epoch: [47][   60/  139]    Overall Loss 0.508376    Objective Loss 0.508376                                        LR 0.000500    Time 0.849140    
2024-02-26 20:10:41,303 - Epoch: [47][   70/  139]    Overall Loss 0.506654    Objective Loss 0.506654                                        LR 0.000500    Time 0.847714    
2024-02-26 20:10:49,701 - Epoch: [47][   80/  139]    Overall Loss 0.507266    Objective Loss 0.507266                                        LR 0.000500    Time 0.846721    
2024-02-26 20:10:58,105 - Epoch: [47][   90/  139]    Overall Loss 0.509217    Objective Loss 0.509217                                        LR 0.000500    Time 0.846013    
2024-02-26 20:11:06,504 - Epoch: [47][  100/  139]    Overall Loss 0.509981    Objective Loss 0.509981                                        LR 0.000500    Time 0.845400    
2024-02-26 20:11:14,967 - Epoch: [47][  110/  139]    Overall Loss 0.512285    Objective Loss 0.512285                                        LR 0.000500    Time 0.845477    
2024-02-26 20:11:23,368 - Epoch: [47][  120/  139]    Overall Loss 0.512613    Objective Loss 0.512613                                        LR 0.000500    Time 0.845023    
2024-02-26 20:11:31,758 - Epoch: [47][  130/  139]    Overall Loss 0.514045    Objective Loss 0.514045                                        LR 0.000500    Time 0.844554    
2024-02-26 20:11:42,823 - Epoch: [47][  139/  139]    Overall Loss 0.514196    Objective Loss 0.514196    Top1 89.233343    LR 0.000500    Time 0.869478    
2024-02-26 20:11:43,072 - --- validate (epoch=47)-----------
2024-02-26 20:11:43,073 - 1392 samples (32 per mini-batch)
2024-02-26 20:12:18,541 - Epoch: [47][   10/   44]    Loss 0.569091    Top1 86.154114    
2024-02-26 20:12:50,129 - Epoch: [47][   20/   44]    Loss 0.568270    Top1 86.234178    
2024-02-26 20:13:18,954 - Epoch: [47][   30/   44]    Loss 0.562799    Top1 86.501066    
2024-02-26 20:13:49,390 - Epoch: [47][   40/   44]    Loss 0.565658    Top1 86.340405    
2024-02-26 20:13:59,478 - Epoch: [47][   44/   44]    Loss 0.565362    Top1 86.386360    
2024-02-26 20:13:59,699 - ==> Top1: 86.386    Loss: 0.565

2024-02-26 20:13:59,705 - ==> Best [Top1: 86.527   Sparsity:0.00   Params: 271456 on epoch: 46]
2024-02-26 20:13:59,706 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:13:59,734 - 

2024-02-26 20:13:59,735 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:14:08,483 - Epoch: [48][   10/  139]    Overall Loss 0.521274    Objective Loss 0.521274                                        LR 0.000500    Time 0.874728    
2024-02-26 20:14:16,881 - Epoch: [48][   20/  139]    Overall Loss 0.510752    Objective Loss 0.510752                                        LR 0.000500    Time 0.857241    
2024-02-26 20:14:25,334 - Epoch: [48][   30/  139]    Overall Loss 0.510717    Objective Loss 0.510717                                        LR 0.000500    Time 0.853215    
2024-02-26 20:14:33,753 - Epoch: [48][   40/  139]    Overall Loss 0.508493    Objective Loss 0.508493                                        LR 0.000500    Time 0.850366    
2024-02-26 20:14:42,172 - Epoch: [48][   50/  139]    Overall Loss 0.506800    Objective Loss 0.506800                                        LR 0.000500    Time 0.848663    
2024-02-26 20:14:50,601 - Epoch: [48][   60/  139]    Overall Loss 0.506673    Objective Loss 0.506673                                        LR 0.000500    Time 0.847701    
2024-02-26 20:14:59,020 - Epoch: [48][   70/  139]    Overall Loss 0.508156    Objective Loss 0.508156                                        LR 0.000500    Time 0.846867    
2024-02-26 20:15:07,422 - Epoch: [48][   80/  139]    Overall Loss 0.509487    Objective Loss 0.509487                                        LR 0.000500    Time 0.846025    
2024-02-26 20:15:15,864 - Epoch: [48][   90/  139]    Overall Loss 0.509018    Objective Loss 0.509018                                        LR 0.000500    Time 0.845821    
2024-02-26 20:15:24,266 - Epoch: [48][  100/  139]    Overall Loss 0.507756    Objective Loss 0.507756                                        LR 0.000500    Time 0.845251    
2024-02-26 20:15:32,682 - Epoch: [48][  110/  139]    Overall Loss 0.507138    Objective Loss 0.507138                                        LR 0.000500    Time 0.844919    
2024-02-26 20:15:41,060 - Epoch: [48][  120/  139]    Overall Loss 0.508692    Objective Loss 0.508692                                        LR 0.000500    Time 0.844316    
2024-02-26 20:15:49,459 - Epoch: [48][  130/  139]    Overall Loss 0.509666    Objective Loss 0.509666                                        LR 0.000500    Time 0.843973    
2024-02-26 20:16:01,397 - Epoch: [48][  139/  139]    Overall Loss 0.508823    Objective Loss 0.508823    Top1 90.504507    LR 0.000500    Time 0.875209    
2024-02-26 20:16:01,686 - --- validate (epoch=48)-----------
2024-02-26 20:16:01,687 - 1392 samples (32 per mini-batch)
2024-02-26 20:16:33,606 - Epoch: [48][   10/   44]    Loss 0.551382    Top1 86.814636    
2024-02-26 20:17:06,113 - Epoch: [48][   20/   44]    Loss 0.554102    Top1 86.775160    
2024-02-26 20:17:41,354 - Epoch: [48][   30/   44]    Loss 0.552065    Top1 86.942964    
2024-02-26 20:18:15,043 - Epoch: [48][   40/   44]    Loss 0.548070    Top1 87.172941    
2024-02-26 20:18:25,660 - Epoch: [48][   44/   44]    Loss 0.547679    Top1 87.171021    
2024-02-26 20:18:25,956 - ==> Top1: 87.171    Loss: 0.548

2024-02-26 20:18:25,964 - ==> Best [Top1: 87.171   Sparsity:0.00   Params: 271456 on epoch: 48]
2024-02-26 20:18:25,965 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:18:26,001 - 

2024-02-26 20:18:26,001 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:18:34,844 - Epoch: [49][   10/  139]    Overall Loss 0.503145    Objective Loss 0.503145                                        LR 0.000500    Time 0.884184    
2024-02-26 20:18:43,238 - Epoch: [49][   20/  139]    Overall Loss 0.504199    Objective Loss 0.504199                                        LR 0.000500    Time 0.861780    
2024-02-26 20:18:51,647 - Epoch: [49][   30/  139]    Overall Loss 0.506714    Objective Loss 0.506714                                        LR 0.000500    Time 0.854806    
2024-02-26 20:19:00,037 - Epoch: [49][   40/  139]    Overall Loss 0.504221    Objective Loss 0.504221                                        LR 0.000500    Time 0.850827    
2024-02-26 20:19:08,455 - Epoch: [49][   50/  139]    Overall Loss 0.504449    Objective Loss 0.504449                                        LR 0.000500    Time 0.849015    
2024-02-26 20:19:16,883 - Epoch: [49][   60/  139]    Overall Loss 0.502646    Objective Loss 0.502646                                        LR 0.000500    Time 0.847976    
2024-02-26 20:19:25,273 - Epoch: [49][   70/  139]    Overall Loss 0.502388    Objective Loss 0.502388                                        LR 0.000500    Time 0.846682    
2024-02-26 20:19:33,685 - Epoch: [49][   80/  139]    Overall Loss 0.500893    Objective Loss 0.500893                                        LR 0.000500    Time 0.845984    
2024-02-26 20:19:42,081 - Epoch: [49][   90/  139]    Overall Loss 0.501227    Objective Loss 0.501227                                        LR 0.000500    Time 0.845271    
2024-02-26 20:19:50,489 - Epoch: [49][  100/  139]    Overall Loss 0.500037    Objective Loss 0.500037                                        LR 0.000500    Time 0.844822    
2024-02-26 20:19:58,875 - Epoch: [49][  110/  139]    Overall Loss 0.500045    Objective Loss 0.500045                                        LR 0.000500    Time 0.844254    
2024-02-26 20:20:07,278 - Epoch: [49][  120/  139]    Overall Loss 0.501314    Objective Loss 0.501314                                        LR 0.000500    Time 0.843917    
2024-02-26 20:20:15,672 - Epoch: [49][  130/  139]    Overall Loss 0.501928    Objective Loss 0.501928                                        LR 0.000500    Time 0.843568    
2024-02-26 20:20:27,124 - Epoch: [49][  139/  139]    Overall Loss 0.501199    Objective Loss 0.501199    Top1 89.490306    LR 0.000500    Time 0.871334    
2024-02-26 20:20:27,330 - --- validate (epoch=49)-----------
2024-02-26 20:20:27,330 - 1392 samples (32 per mini-batch)
2024-02-26 20:21:01,591 - Epoch: [49][   10/   44]    Loss 0.526002    Top1 88.719190    
2024-02-26 20:21:33,011 - Epoch: [49][   20/   44]    Loss 0.533457    Top1 88.212607    
2024-02-26 20:22:07,524 - Epoch: [49][   30/   44]    Loss 0.537385    Top1 87.956170    
2024-02-26 20:22:42,036 - Epoch: [49][   40/   44]    Loss 0.540136    Top1 87.792570    
2024-02-26 20:22:52,388 - Epoch: [49][   44/   44]    Loss 0.542021    Top1 87.731804    
2024-02-26 20:22:52,613 - ==> Top1: 87.732    Loss: 0.542

2024-02-26 20:22:52,620 - ==> Best [Top1: 87.732   Sparsity:0.00   Params: 271456 on epoch: 49]
2024-02-26 20:22:52,620 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:22:52,660 - 

2024-02-26 20:22:52,661 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:23:01,447 - Epoch: [50][   10/  139]    Overall Loss 0.498009    Objective Loss 0.498009                                        LR 0.000500    Time 0.878353    
2024-02-26 20:23:09,841 - Epoch: [50][   20/  139]    Overall Loss 0.495435    Objective Loss 0.495435                                        LR 0.000500    Time 0.858865    
2024-02-26 20:23:18,242 - Epoch: [50][   30/  139]    Overall Loss 0.498433    Objective Loss 0.498433                                        LR 0.000500    Time 0.852606    
2024-02-26 20:23:26,641 - Epoch: [50][   40/  139]    Overall Loss 0.502359    Objective Loss 0.502359                                        LR 0.000500    Time 0.849410    
2024-02-26 20:23:35,035 - Epoch: [50][   50/  139]    Overall Loss 0.498493    Objective Loss 0.498493                                        LR 0.000500    Time 0.847386    
2024-02-26 20:23:43,438 - Epoch: [50][   60/  139]    Overall Loss 0.498042    Objective Loss 0.498042                                        LR 0.000500    Time 0.846206    
2024-02-26 20:23:51,830 - Epoch: [50][   70/  139]    Overall Loss 0.496411    Objective Loss 0.496411                                        LR 0.000500    Time 0.845189    
2024-02-26 20:24:00,242 - Epoch: [50][   80/  139]    Overall Loss 0.496528    Objective Loss 0.496528                                        LR 0.000500    Time 0.844689    
2024-02-26 20:24:08,671 - Epoch: [50][   90/  139]    Overall Loss 0.496106    Objective Loss 0.496106                                        LR 0.000500    Time 0.844487    
2024-02-26 20:24:17,084 - Epoch: [50][  100/  139]    Overall Loss 0.495521    Objective Loss 0.495521                                        LR 0.000500    Time 0.844157    
2024-02-26 20:24:25,493 - Epoch: [50][  110/  139]    Overall Loss 0.496598    Objective Loss 0.496598                                        LR 0.000500    Time 0.843859    
2024-02-26 20:24:33,913 - Epoch: [50][  120/  139]    Overall Loss 0.496365    Objective Loss 0.496365                                        LR 0.000500    Time 0.843700    
2024-02-26 20:24:42,330 - Epoch: [50][  130/  139]    Overall Loss 0.497411    Objective Loss 0.497411                                        LR 0.000500    Time 0.843537    
2024-02-26 20:24:53,875 - Epoch: [50][  139/  139]    Overall Loss 0.496898    Objective Loss 0.496898    Top1 91.110988    LR 0.000500    Time 0.871972    
2024-02-26 20:24:54,197 - --- validate (epoch=50)-----------
2024-02-26 20:24:54,198 - 1392 samples (32 per mini-batch)
2024-02-26 20:25:25,731 - Epoch: [50][   10/   44]    Loss 0.532749    Top1 88.182928    
2024-02-26 20:25:54,702 - Epoch: [50][   20/   44]    Loss 0.532662    Top1 88.174898    
2024-02-26 20:26:23,660 - Epoch: [50][   30/   44]    Loss 0.532841    Top1 88.122624    
2024-02-26 20:26:54,955 - Epoch: [50][   40/   44]    Loss 0.531950    Top1 88.179329    
2024-02-26 20:27:07,383 - Epoch: [50][   44/   44]    Loss 0.532716    Top1 88.146171    
2024-02-26 20:27:07,655 - ==> Top1: 88.146    Loss: 0.533

2024-02-26 20:27:07,663 - ==> Best [Top1: 88.146   Sparsity:0.00   Params: 271456 on epoch: 50]
2024-02-26 20:27:07,663 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:27:07,704 - 

2024-02-26 20:27:07,705 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:27:16,588 - Epoch: [51][   10/  139]    Overall Loss 0.491547    Objective Loss 0.491547                                        LR 0.000500    Time 0.888218    
2024-02-26 20:27:24,983 - Epoch: [51][   20/  139]    Overall Loss 0.487718    Objective Loss 0.487718                                        LR 0.000500    Time 0.863807    
2024-02-26 20:27:33,376 - Epoch: [51][   30/  139]    Overall Loss 0.485496    Objective Loss 0.485496                                        LR 0.000500    Time 0.855623    
2024-02-26 20:27:41,775 - Epoch: [51][   40/  139]    Overall Loss 0.485655    Objective Loss 0.485655                                        LR 0.000500    Time 0.851681    
2024-02-26 20:27:50,174 - Epoch: [51][   50/  139]    Overall Loss 0.487589    Objective Loss 0.487589                                        LR 0.000500    Time 0.849315    
2024-02-26 20:27:58,571 - Epoch: [51][   60/  139]    Overall Loss 0.488570    Objective Loss 0.488570                                        LR 0.000500    Time 0.847701    
2024-02-26 20:28:06,982 - Epoch: [51][   70/  139]    Overall Loss 0.488968    Objective Loss 0.488968                                        LR 0.000500    Time 0.846757    
2024-02-26 20:28:15,387 - Epoch: [51][   80/  139]    Overall Loss 0.488478    Objective Loss 0.488478                                        LR 0.000500    Time 0.845960    
2024-02-26 20:28:23,782 - Epoch: [51][   90/  139]    Overall Loss 0.488400    Objective Loss 0.488400                                        LR 0.000500    Time 0.845245    
2024-02-26 20:28:32,189 - Epoch: [51][  100/  139]    Overall Loss 0.488476    Objective Loss 0.488476                                        LR 0.000500    Time 0.844778    
2024-02-26 20:28:40,599 - Epoch: [51][  110/  139]    Overall Loss 0.489210    Objective Loss 0.489210                                        LR 0.000500    Time 0.844430    
2024-02-26 20:28:49,012 - Epoch: [51][  120/  139]    Overall Loss 0.490544    Objective Loss 0.490544                                        LR 0.000500    Time 0.844172    
2024-02-26 20:28:57,414 - Epoch: [51][  130/  139]    Overall Loss 0.490754    Objective Loss 0.490754                                        LR 0.000500    Time 0.843859    
2024-02-26 20:29:08,910 - Epoch: [51][  139/  139]    Overall Loss 0.491471    Objective Loss 0.491471    Top1 92.090302    LR 0.000500    Time 0.871926    
2024-02-26 20:29:09,190 - --- validate (epoch=51)-----------
2024-02-26 20:29:09,191 - 1392 samples (32 per mini-batch)
2024-02-26 20:29:45,556 - Epoch: [51][   10/   44]    Loss 0.546855    Top1 87.287179    
2024-02-26 20:30:17,643 - Epoch: [51][   20/   44]    Loss 0.547721    Top1 87.163255    
2024-02-26 20:30:48,746 - Epoch: [51][   30/   44]    Loss 0.544218    Top1 87.372461    
2024-02-26 20:31:22,022 - Epoch: [51][   40/   44]    Loss 0.544973    Top1 87.285637    
2024-02-26 20:31:33,951 - Epoch: [51][   44/   44]    Loss 0.547013    Top1 87.208925    
2024-02-26 20:31:34,178 - ==> Top1: 87.209    Loss: 0.547

2024-02-26 20:31:34,185 - ==> Best [Top1: 88.146   Sparsity:0.00   Params: 271456 on epoch: 50]
2024-02-26 20:31:34,185 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:31:34,220 - 

2024-02-26 20:31:34,220 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:31:42,919 - Epoch: [52][   10/  139]    Overall Loss 0.486800    Objective Loss 0.486800                                        LR 0.000500    Time 0.869837    
2024-02-26 20:31:51,325 - Epoch: [52][   20/  139]    Overall Loss 0.493554    Objective Loss 0.493554                                        LR 0.000500    Time 0.855184    
2024-02-26 20:31:59,741 - Epoch: [52][   30/  139]    Overall Loss 0.490481    Objective Loss 0.490481                                        LR 0.000500    Time 0.850630    
2024-02-26 20:32:08,130 - Epoch: [52][   40/  139]    Overall Loss 0.496138    Objective Loss 0.496138                                        LR 0.000500    Time 0.847679    
2024-02-26 20:32:16,524 - Epoch: [52][   50/  139]    Overall Loss 0.497136    Objective Loss 0.497136                                        LR 0.000500    Time 0.846023    
2024-02-26 20:32:24,927 - Epoch: [52][   60/  139]    Overall Loss 0.493560    Objective Loss 0.493560                                        LR 0.000500    Time 0.845066    
2024-02-26 20:32:33,327 - Epoch: [52][   70/  139]    Overall Loss 0.494990    Objective Loss 0.494990                                        LR 0.000500    Time 0.844335    
2024-02-26 20:32:41,732 - Epoch: [52][   80/  139]    Overall Loss 0.495750    Objective Loss 0.495750                                        LR 0.000500    Time 0.843841    
2024-02-26 20:32:50,131 - Epoch: [52][   90/  139]    Overall Loss 0.496305    Objective Loss 0.496305                                        LR 0.000500    Time 0.843408    
2024-02-26 20:32:58,564 - Epoch: [52][  100/  139]    Overall Loss 0.497316    Objective Loss 0.497316                                        LR 0.000500    Time 0.843385    
2024-02-26 20:33:06,966 - Epoch: [52][  110/  139]    Overall Loss 0.496893    Objective Loss 0.496893                                        LR 0.000500    Time 0.843089    
2024-02-26 20:33:15,360 - Epoch: [52][  120/  139]    Overall Loss 0.495640    Objective Loss 0.495640                                        LR 0.000500    Time 0.842778    
2024-02-26 20:33:23,779 - Epoch: [52][  130/  139]    Overall Loss 0.494398    Objective Loss 0.494398                                        LR 0.000500    Time 0.842706    
2024-02-26 20:33:35,126 - Epoch: [52][  139/  139]    Overall Loss 0.494366    Objective Loss 0.494366    Top1 90.780252    LR 0.000500    Time 0.869769    
2024-02-26 20:33:35,406 - --- validate (epoch=52)-----------
2024-02-26 20:33:35,407 - 1392 samples (32 per mini-batch)
2024-02-26 20:34:08,717 - Epoch: [52][   10/   44]    Loss 0.573243    Top1 85.485794    
2024-02-26 20:34:42,820 - Epoch: [52][   20/   44]    Loss 0.569866    Top1 85.872839    
2024-02-26 20:35:14,905 - Epoch: [52][   30/   44]    Loss 0.571084    Top1 85.807771    
2024-02-26 20:35:45,205 - Epoch: [52][   40/   44]    Loss 0.574045    Top1 85.617744    
2024-02-26 20:35:55,691 - Epoch: [52][   44/   44]    Loss 0.570450    Top1 85.763725    
2024-02-26 20:35:55,934 - ==> Top1: 85.764    Loss: 0.570

2024-02-26 20:35:55,943 - ==> Best [Top1: 88.146   Sparsity:0.00   Params: 271456 on epoch: 50]
2024-02-26 20:35:55,943 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:35:55,975 - 

2024-02-26 20:35:55,975 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:36:04,926 - Epoch: [53][   10/  139]    Overall Loss 0.473244    Objective Loss 0.473244                                        LR 0.000500    Time 0.894897    
2024-02-26 20:36:13,352 - Epoch: [53][   20/  139]    Overall Loss 0.481482    Objective Loss 0.481482                                        LR 0.000500    Time 0.868687    
2024-02-26 20:36:21,752 - Epoch: [53][   30/  139]    Overall Loss 0.480993    Objective Loss 0.480993                                        LR 0.000500    Time 0.859112    
2024-02-26 20:36:30,148 - Epoch: [53][   40/  139]    Overall Loss 0.482565    Objective Loss 0.482565                                        LR 0.000500    Time 0.854230    
2024-02-26 20:36:38,575 - Epoch: [53][   50/  139]    Overall Loss 0.483052    Objective Loss 0.483052                                        LR 0.000500    Time 0.851913    
2024-02-26 20:36:46,974 - Epoch: [53][   60/  139]    Overall Loss 0.484227    Objective Loss 0.484227                                        LR 0.000500    Time 0.849900    
2024-02-26 20:36:55,435 - Epoch: [53][   70/  139]    Overall Loss 0.485811    Objective Loss 0.485811                                        LR 0.000500    Time 0.849338    
2024-02-26 20:37:03,886 - Epoch: [53][   80/  139]    Overall Loss 0.485390    Objective Loss 0.485390                                        LR 0.000500    Time 0.848800    
2024-02-26 20:37:12,321 - Epoch: [53][   90/  139]    Overall Loss 0.488219    Objective Loss 0.488219                                        LR 0.000500    Time 0.848209    
2024-02-26 20:37:20,722 - Epoch: [53][  100/  139]    Overall Loss 0.489649    Objective Loss 0.489649                                        LR 0.000500    Time 0.847394    
2024-02-26 20:37:29,129 - Epoch: [53][  110/  139]    Overall Loss 0.490804    Objective Loss 0.490804                                        LR 0.000500    Time 0.846775    
2024-02-26 20:37:37,536 - Epoch: [53][  120/  139]    Overall Loss 0.489997    Objective Loss 0.489997                                        LR 0.000500    Time 0.846264    
2024-02-26 20:37:45,935 - Epoch: [53][  130/  139]    Overall Loss 0.489813    Objective Loss 0.489813                                        LR 0.000500    Time 0.845774    
2024-02-26 20:37:57,262 - Epoch: [53][  139/  139]    Overall Loss 0.490284    Objective Loss 0.490284    Top1 89.732447    LR 0.000500    Time 0.872496    
2024-02-26 20:37:57,513 - --- validate (epoch=53)-----------
2024-02-26 20:37:57,514 - 1392 samples (32 per mini-batch)
2024-02-26 20:38:29,333 - Epoch: [53][   10/   44]    Loss 0.549302    Top1 87.209737    
2024-02-26 20:38:58,456 - Epoch: [53][   20/   44]    Loss 0.549391    Top1 87.066626    
2024-02-26 20:39:30,947 - Epoch: [53][   30/   44]    Loss 0.549705    Top1 87.010409    
2024-02-26 20:40:06,966 - Epoch: [53][   40/   44]    Loss 0.546633    Top1 87.185727    
2024-02-26 20:40:18,829 - Epoch: [53][   44/   44]    Loss 0.548156    Top1 87.069050    
2024-02-26 20:40:19,121 - ==> Top1: 87.069    Loss: 0.548

2024-02-26 20:40:19,128 - ==> Best [Top1: 88.146   Sparsity:0.00   Params: 271456 on epoch: 50]
2024-02-26 20:40:19,129 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:40:19,158 - 

2024-02-26 20:40:19,158 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:40:28,124 - Epoch: [54][   10/  139]    Overall Loss 0.497135    Objective Loss 0.497135                                        LR 0.000500    Time 0.896419    
2024-02-26 20:40:36,538 - Epoch: [54][   20/  139]    Overall Loss 0.489272    Objective Loss 0.489272                                        LR 0.000500    Time 0.868871    
2024-02-26 20:40:44,931 - Epoch: [54][   30/  139]    Overall Loss 0.494606    Objective Loss 0.494606                                        LR 0.000500    Time 0.859009    
2024-02-26 20:40:53,352 - Epoch: [54][   40/  139]    Overall Loss 0.499676    Objective Loss 0.499676                                        LR 0.000500    Time 0.854768    
2024-02-26 20:41:01,750 - Epoch: [54][   50/  139]    Overall Loss 0.498580    Objective Loss 0.498580                                        LR 0.000500    Time 0.851761    
2024-02-26 20:41:10,247 - Epoch: [54][   60/  139]    Overall Loss 0.496091    Objective Loss 0.496091                                        LR 0.000500    Time 0.851408    
2024-02-26 20:41:18,656 - Epoch: [54][   70/  139]    Overall Loss 0.495891    Objective Loss 0.495891                                        LR 0.000500    Time 0.849906    
2024-02-26 20:41:27,059 - Epoch: [54][   80/  139]    Overall Loss 0.496406    Objective Loss 0.496406                                        LR 0.000500    Time 0.848700    
2024-02-26 20:41:35,468 - Epoch: [54][   90/  139]    Overall Loss 0.495635    Objective Loss 0.495635                                        LR 0.000500    Time 0.847827    
2024-02-26 20:41:43,894 - Epoch: [54][  100/  139]    Overall Loss 0.493733    Objective Loss 0.493733                                        LR 0.000500    Time 0.847298    
2024-02-26 20:41:52,293 - Epoch: [54][  110/  139]    Overall Loss 0.492756    Objective Loss 0.492756                                        LR 0.000500    Time 0.846618    
2024-02-26 20:42:00,699 - Epoch: [54][  120/  139]    Overall Loss 0.492512    Objective Loss 0.492512                                        LR 0.000500    Time 0.846118    
2024-02-26 20:42:09,116 - Epoch: [54][  130/  139]    Overall Loss 0.492462    Objective Loss 0.492462                                        LR 0.000500    Time 0.845771    
2024-02-26 20:42:20,612 - Epoch: [54][  139/  139]    Overall Loss 0.491331    Objective Loss 0.491331    Top1 91.125387    LR 0.000500    Time 0.873713    
2024-02-26 20:42:20,860 - --- validate (epoch=54)-----------
2024-02-26 20:42:20,861 - 1392 samples (32 per mini-batch)
2024-02-26 20:42:57,171 - Epoch: [54][   10/   44]    Loss 0.544443    Top1 87.672893    
2024-02-26 20:43:29,594 - Epoch: [54][   20/   44]    Loss 0.544141    Top1 87.645227    
2024-02-26 20:44:02,915 - Epoch: [54][   30/   44]    Loss 0.542641    Top1 87.698596    
2024-02-26 20:44:35,580 - Epoch: [54][   40/   44]    Loss 0.538984    Top1 87.921453    
2024-02-26 20:44:48,199 - Epoch: [54][   44/   44]    Loss 0.538919    Top1 87.963223    
2024-02-26 20:44:48,512 - ==> Top1: 87.963    Loss: 0.539

2024-02-26 20:44:48,518 - ==> Best [Top1: 88.146   Sparsity:0.00   Params: 271456 on epoch: 50]
2024-02-26 20:44:48,518 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:44:48,551 - 

2024-02-26 20:44:48,552 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:44:57,446 - Epoch: [55][   10/  139]    Overall Loss 0.477969    Objective Loss 0.477969                                        LR 0.000500    Time 0.889126    
2024-02-26 20:45:05,850 - Epoch: [55][   20/  139]    Overall Loss 0.481253    Objective Loss 0.481253                                        LR 0.000500    Time 0.864701    
2024-02-26 20:45:14,270 - Epoch: [55][   30/  139]    Overall Loss 0.482062    Objective Loss 0.482062                                        LR 0.000500    Time 0.857121    
2024-02-26 20:45:22,670 - Epoch: [55][   40/  139]    Overall Loss 0.483916    Objective Loss 0.483916                                        LR 0.000500    Time 0.852837    
2024-02-26 20:45:31,098 - Epoch: [55][   50/  139]    Overall Loss 0.486112    Objective Loss 0.486112                                        LR 0.000500    Time 0.850808    
2024-02-26 20:45:39,497 - Epoch: [55][   60/  139]    Overall Loss 0.484324    Objective Loss 0.484324                                        LR 0.000500    Time 0.848981    
2024-02-26 20:45:47,974 - Epoch: [55][   70/  139]    Overall Loss 0.483950    Objective Loss 0.483950                                        LR 0.000500    Time 0.848801    
2024-02-26 20:45:56,408 - Epoch: [55][   80/  139]    Overall Loss 0.482903    Objective Loss 0.482903                                        LR 0.000500    Time 0.848123    
2024-02-26 20:46:04,835 - Epoch: [55][   90/  139]    Overall Loss 0.482154    Objective Loss 0.482154                                        LR 0.000500    Time 0.847506    
2024-02-26 20:46:13,229 - Epoch: [55][  100/  139]    Overall Loss 0.482384    Objective Loss 0.482384                                        LR 0.000500    Time 0.846699    
2024-02-26 20:46:21,628 - Epoch: [55][  110/  139]    Overall Loss 0.483814    Objective Loss 0.483814                                        LR 0.000500    Time 0.846077    
2024-02-26 20:46:30,043 - Epoch: [55][  120/  139]    Overall Loss 0.484363    Objective Loss 0.484363                                        LR 0.000500    Time 0.845685    
2024-02-26 20:46:38,462 - Epoch: [55][  130/  139]    Overall Loss 0.485014    Objective Loss 0.485014                                        LR 0.000500    Time 0.845395    
2024-02-26 20:46:50,479 - Epoch: [55][  139/  139]    Overall Loss 0.486024    Objective Loss 0.486024    Top1 89.573673    LR 0.000500    Time 0.877105    
2024-02-26 20:46:50,905 - --- validate (epoch=55)-----------
2024-02-26 20:46:50,905 - 1392 samples (32 per mini-batch)
2024-02-26 20:47:27,562 - Epoch: [55][   10/   44]    Loss 0.546691    Top1 87.465659    
2024-02-26 20:48:01,971 - Epoch: [55][   20/   44]    Loss 0.541158    Top1 87.840137    
2024-02-26 20:48:35,821 - Epoch: [55][   30/   44]    Loss 0.542134    Top1 87.750816    
2024-02-26 20:49:09,147 - Epoch: [55][   40/   44]    Loss 0.543150    Top1 87.641542    
2024-02-26 20:49:20,684 - Epoch: [55][   44/   44]    Loss 0.544582    Top1 87.614029    
2024-02-26 20:49:20,922 - ==> Top1: 87.614    Loss: 0.545

2024-02-26 20:49:20,929 - ==> Best [Top1: 88.146   Sparsity:0.00   Params: 271456 on epoch: 50]
2024-02-26 20:49:20,929 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:49:20,959 - 

2024-02-26 20:49:20,959 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:49:29,739 - Epoch: [56][   10/  139]    Overall Loss 0.485808    Objective Loss 0.485808                                        LR 0.000500    Time 0.877848    
2024-02-26 20:49:38,130 - Epoch: [56][   20/  139]    Overall Loss 0.485028    Objective Loss 0.485028                                        LR 0.000500    Time 0.858452    
2024-02-26 20:49:46,516 - Epoch: [56][   30/  139]    Overall Loss 0.482189    Objective Loss 0.482189                                        LR 0.000500    Time 0.851838    
2024-02-26 20:49:54,897 - Epoch: [56][   40/  139]    Overall Loss 0.480749    Objective Loss 0.480749                                        LR 0.000500    Time 0.848368    
2024-02-26 20:50:03,278 - Epoch: [56][   50/  139]    Overall Loss 0.484704    Objective Loss 0.484704                                        LR 0.000500    Time 0.846320    
2024-02-26 20:50:11,661 - Epoch: [56][   60/  139]    Overall Loss 0.483760    Objective Loss 0.483760                                        LR 0.000500    Time 0.844974    
2024-02-26 20:50:20,047 - Epoch: [56][   70/  139]    Overall Loss 0.483849    Objective Loss 0.483849                                        LR 0.000500    Time 0.844053    
2024-02-26 20:50:28,446 - Epoch: [56][   80/  139]    Overall Loss 0.482546    Objective Loss 0.482546                                        LR 0.000500    Time 0.843521    
2024-02-26 20:50:36,909 - Epoch: [56][   90/  139]    Overall Loss 0.480618    Objective Loss 0.480618                                        LR 0.000500    Time 0.843828    
2024-02-26 20:50:45,366 - Epoch: [56][  100/  139]    Overall Loss 0.481061    Objective Loss 0.481061                                        LR 0.000500    Time 0.844007    
2024-02-26 20:50:53,826 - Epoch: [56][  110/  139]    Overall Loss 0.481466    Objective Loss 0.481466                                        LR 0.000500    Time 0.844185    
2024-02-26 20:51:02,284 - Epoch: [56][  120/  139]    Overall Loss 0.481264    Objective Loss 0.481264                                        LR 0.000500    Time 0.844309    
2024-02-26 20:51:10,754 - Epoch: [56][  130/  139]    Overall Loss 0.481620    Objective Loss 0.481620                                        LR 0.000500    Time 0.844510    
2024-02-26 20:51:22,840 - Epoch: [56][  139/  139]    Overall Loss 0.482341    Objective Loss 0.482341    Top1 90.861840    LR 0.000500    Time 0.876776    
2024-02-26 20:51:23,123 - --- validate (epoch=56)-----------
2024-02-26 20:51:23,125 - 1392 samples (32 per mini-batch)
2024-02-26 20:51:58,994 - Epoch: [56][   10/   44]    Loss 0.569156    Top1 85.807679    
2024-02-26 20:52:33,939 - Epoch: [56][   20/   44]    Loss 0.565442    Top1 85.947881    
2024-02-26 20:53:08,750 - Epoch: [56][   30/   44]    Loss 0.564649    Top1 86.004530    
2024-02-26 20:53:43,255 - Epoch: [56][   40/   44]    Loss 0.562504    Top1 86.189783    
2024-02-26 20:53:55,406 - Epoch: [56][   44/   44]    Loss 0.564318    Top1 86.146406    
2024-02-26 20:53:55,703 - ==> Top1: 86.146    Loss: 0.564

2024-02-26 20:53:55,710 - ==> Best [Top1: 88.146   Sparsity:0.00   Params: 271456 on epoch: 50]
2024-02-26 20:53:55,710 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:53:55,745 - 

2024-02-26 20:53:55,745 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:54:04,462 - Epoch: [57][   10/  139]    Overall Loss 0.488119    Objective Loss 0.488119                                        LR 0.000500    Time 0.871581    
2024-02-26 20:54:12,841 - Epoch: [57][   20/  139]    Overall Loss 0.481707    Objective Loss 0.481707                                        LR 0.000500    Time 0.854718    
2024-02-26 20:54:21,219 - Epoch: [57][   30/  139]    Overall Loss 0.479263    Objective Loss 0.479263                                        LR 0.000500    Time 0.849046    
2024-02-26 20:54:29,598 - Epoch: [57][   40/  139]    Overall Loss 0.480917    Objective Loss 0.480917                                        LR 0.000500    Time 0.846246    
2024-02-26 20:54:37,981 - Epoch: [57][   50/  139]    Overall Loss 0.479013    Objective Loss 0.479013                                        LR 0.000500    Time 0.844638    
2024-02-26 20:54:46,364 - Epoch: [57][   60/  139]    Overall Loss 0.478078    Objective Loss 0.478078                                        LR 0.000500    Time 0.843579    
2024-02-26 20:54:54,749 - Epoch: [57][   70/  139]    Overall Loss 0.477867    Objective Loss 0.477867                                        LR 0.000500    Time 0.842846    
2024-02-26 20:55:03,136 - Epoch: [57][   80/  139]    Overall Loss 0.478848    Objective Loss 0.478848                                        LR 0.000500    Time 0.842326    
2024-02-26 20:55:11,521 - Epoch: [57][   90/  139]    Overall Loss 0.480021    Objective Loss 0.480021                                        LR 0.000500    Time 0.841888    
2024-02-26 20:55:19,903 - Epoch: [57][  100/  139]    Overall Loss 0.479438    Objective Loss 0.479438                                        LR 0.000500    Time 0.841519    
2024-02-26 20:55:28,292 - Epoch: [57][  110/  139]    Overall Loss 0.478982    Objective Loss 0.478982                                        LR 0.000500    Time 0.841275    
2024-02-26 20:55:36,678 - Epoch: [57][  120/  139]    Overall Loss 0.478528    Objective Loss 0.478528                                        LR 0.000500    Time 0.841046    
2024-02-26 20:55:45,062 - Epoch: [57][  130/  139]    Overall Loss 0.478314    Objective Loss 0.478314                                        LR 0.000500    Time 0.840842    
2024-02-26 20:55:56,923 - Epoch: [57][  139/  139]    Overall Loss 0.478855    Objective Loss 0.478855    Top1 92.331013    LR 0.000500    Time 0.871728    
2024-02-26 20:55:57,270 - --- validate (epoch=57)-----------
2024-02-26 20:55:57,271 - 1392 samples (32 per mini-batch)
2024-02-26 20:56:33,523 - Epoch: [57][   10/   44]    Loss 0.542435    Top1 87.699678    
2024-02-26 20:57:08,768 - Epoch: [57][   20/   44]    Loss 0.535188    Top1 88.136848    
2024-02-26 20:57:44,034 - Epoch: [57][   30/   44]    Loss 0.543493    Top1 87.645534    
2024-02-26 20:58:19,118 - Epoch: [57][   40/   44]    Loss 0.542763    Top1 87.689498    
2024-02-26 20:58:31,482 - Epoch: [57][   44/   44]    Loss 0.540016    Top1 87.834787    
2024-02-26 20:58:31,776 - ==> Top1: 87.835    Loss: 0.540

2024-02-26 20:58:31,783 - ==> Best [Top1: 88.146   Sparsity:0.00   Params: 271456 on epoch: 50]
2024-02-26 20:58:31,784 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 20:58:31,819 - 

2024-02-26 20:58:31,819 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 20:58:40,589 - Epoch: [58][   10/  139]    Overall Loss 0.477037    Objective Loss 0.477037                                        LR 0.000500    Time 0.876881    
2024-02-26 20:58:48,967 - Epoch: [58][   20/  139]    Overall Loss 0.475130    Objective Loss 0.475130                                        LR 0.000500    Time 0.857282    
2024-02-26 20:58:57,347 - Epoch: [58][   30/  139]    Overall Loss 0.478579    Objective Loss 0.478579                                        LR 0.000500    Time 0.850855    
2024-02-26 20:59:05,733 - Epoch: [58][   40/  139]    Overall Loss 0.477674    Objective Loss 0.477674                                        LR 0.000500    Time 0.847769    
2024-02-26 20:59:14,117 - Epoch: [58][   50/  139]    Overall Loss 0.476625    Objective Loss 0.476625                                        LR 0.000500    Time 0.845901    
2024-02-26 20:59:22,501 - Epoch: [58][   60/  139]    Overall Loss 0.476542    Objective Loss 0.476542                                        LR 0.000500    Time 0.844641    
2024-02-26 20:59:30,888 - Epoch: [58][   70/  139]    Overall Loss 0.475661    Objective Loss 0.475661                                        LR 0.000500    Time 0.843784    
2024-02-26 20:59:39,276 - Epoch: [58][   80/  139]    Overall Loss 0.475045    Objective Loss 0.475045                                        LR 0.000500    Time 0.843147    
2024-02-26 20:59:47,664 - Epoch: [58][   90/  139]    Overall Loss 0.475214    Objective Loss 0.475214                                        LR 0.000500    Time 0.842666    
2024-02-26 20:59:56,107 - Epoch: [58][  100/  139]    Overall Loss 0.475496    Objective Loss 0.475496                                        LR 0.000500    Time 0.842824    
2024-02-26 21:00:04,576 - Epoch: [58][  110/  139]    Overall Loss 0.476192    Objective Loss 0.476192                                        LR 0.000500    Time 0.843187    
2024-02-26 21:00:13,041 - Epoch: [58][  120/  139]    Overall Loss 0.477021    Objective Loss 0.477021                                        LR 0.000500    Time 0.843458    
2024-02-26 21:00:21,512 - Epoch: [58][  130/  139]    Overall Loss 0.477635    Objective Loss 0.477635                                        LR 0.000500    Time 0.843731    
2024-02-26 21:00:33,719 - Epoch: [58][  139/  139]    Overall Loss 0.477297    Objective Loss 0.477297    Top1 92.065228    LR 0.000500    Time 0.876916    
2024-02-26 21:00:33,967 - --- validate (epoch=58)-----------
2024-02-26 21:00:33,968 - 1392 samples (32 per mini-batch)
2024-02-26 21:01:10,100 - Epoch: [58][   10/   44]    Loss 0.540651    Top1 87.645634    
2024-02-26 21:01:43,887 - Epoch: [58][   20/   44]    Loss 0.542027    Top1 87.513024    
2024-02-26 21:02:18,977 - Epoch: [58][   30/   44]    Loss 0.533364    Top1 88.049760    
2024-02-26 21:02:53,393 - Epoch: [58][   40/   44]    Loss 0.532848    Top1 88.064925    
2024-02-26 21:03:05,511 - Epoch: [58][   44/   44]    Loss 0.533642    Top1 88.037972    
2024-02-26 21:03:05,823 - ==> Top1: 88.038    Loss: 0.534

2024-02-26 21:03:05,831 - ==> Best [Top1: 88.146   Sparsity:0.00   Params: 271456 on epoch: 50]
2024-02-26 21:03:05,831 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:03:05,862 - 

2024-02-26 21:03:05,862 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:03:14,597 - Epoch: [59][   10/  139]    Overall Loss 0.467296    Objective Loss 0.467296                                        LR 0.000500    Time 0.873409    
2024-02-26 21:03:22,976 - Epoch: [59][   20/  139]    Overall Loss 0.471409    Objective Loss 0.471409                                        LR 0.000500    Time 0.855581    
2024-02-26 21:03:31,350 - Epoch: [59][   30/  139]    Overall Loss 0.474433    Objective Loss 0.474433                                        LR 0.000500    Time 0.849530    
2024-02-26 21:03:39,726 - Epoch: [59][   40/  139]    Overall Loss 0.473778    Objective Loss 0.473778                                        LR 0.000500    Time 0.846530    
2024-02-26 21:03:48,107 - Epoch: [59][   50/  139]    Overall Loss 0.474333    Objective Loss 0.474333                                        LR 0.000500    Time 0.844844    
2024-02-26 21:03:56,489 - Epoch: [59][   60/  139]    Overall Loss 0.475405    Objective Loss 0.475405                                        LR 0.000500    Time 0.843714    
2024-02-26 21:04:04,871 - Epoch: [59][   70/  139]    Overall Loss 0.476199    Objective Loss 0.476199                                        LR 0.000500    Time 0.842928    
2024-02-26 21:04:13,255 - Epoch: [59][   80/  139]    Overall Loss 0.475607    Objective Loss 0.475607                                        LR 0.000500    Time 0.842362    
2024-02-26 21:04:21,647 - Epoch: [59][   90/  139]    Overall Loss 0.475807    Objective Loss 0.475807                                        LR 0.000500    Time 0.841999    
2024-02-26 21:04:30,087 - Epoch: [59][  100/  139]    Overall Loss 0.478360    Objective Loss 0.478360                                        LR 0.000500    Time 0.842190    
2024-02-26 21:04:38,550 - Epoch: [59][  110/  139]    Overall Loss 0.479586    Objective Loss 0.479586                                        LR 0.000500    Time 0.842564    
2024-02-26 21:04:47,009 - Epoch: [59][  120/  139]    Overall Loss 0.479847    Objective Loss 0.479847                                        LR 0.000500    Time 0.842830    
2024-02-26 21:04:55,471 - Epoch: [59][  130/  139]    Overall Loss 0.480050    Objective Loss 0.480050                                        LR 0.000500    Time 0.843088    
2024-02-26 21:05:07,565 - Epoch: [59][  139/  139]    Overall Loss 0.479551    Objective Loss 0.479551    Top1 91.380295    LR 0.000500    Time 0.875505    
2024-02-26 21:05:07,857 - --- validate (epoch=59)-----------
2024-02-26 21:05:07,857 - 1392 samples (32 per mini-batch)
2024-02-26 21:05:43,589 - Epoch: [59][   10/   44]    Loss 0.550189    Top1 86.985350    
2024-02-26 21:06:18,600 - Epoch: [59][   20/   44]    Loss 0.553446    Top1 86.868706    
2024-02-26 21:06:53,272 - Epoch: [59][   30/   44]    Loss 0.552335    Top1 86.975099    
2024-02-26 21:07:28,779 - Epoch: [59][   40/   44]    Loss 0.552912    Top1 86.950739    
2024-02-26 21:07:41,076 - Epoch: [59][   44/   44]    Loss 0.553211    Top1 86.922714    
2024-02-26 21:07:41,428 - ==> Top1: 86.923    Loss: 0.553

2024-02-26 21:07:41,436 - ==> Best [Top1: 88.146   Sparsity:0.00   Params: 271456 on epoch: 50]
2024-02-26 21:07:41,436 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:07:41,467 - 

2024-02-26 21:07:41,468 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:07:50,201 - Epoch: [60][   10/  139]    Overall Loss 0.487886    Objective Loss 0.487886                                        LR 0.000500    Time 0.873210    
2024-02-26 21:07:58,582 - Epoch: [60][   20/  139]    Overall Loss 0.482613    Objective Loss 0.482613                                        LR 0.000500    Time 0.855607    
2024-02-26 21:08:06,971 - Epoch: [60][   30/  139]    Overall Loss 0.483354    Objective Loss 0.483354                                        LR 0.000500    Time 0.850032    
2024-02-26 21:08:15,349 - Epoch: [60][   40/  139]    Overall Loss 0.482087    Objective Loss 0.482087                                        LR 0.000500    Time 0.846954    
2024-02-26 21:08:23,736 - Epoch: [60][   50/  139]    Overall Loss 0.482012    Objective Loss 0.482012                                        LR 0.000500    Time 0.845288    
2024-02-26 21:08:32,127 - Epoch: [60][   60/  139]    Overall Loss 0.479515    Objective Loss 0.479515                                        LR 0.000500    Time 0.844253    
2024-02-26 21:08:40,514 - Epoch: [60][   70/  139]    Overall Loss 0.479613    Objective Loss 0.479613                                        LR 0.000500    Time 0.843453    
2024-02-26 21:08:48,901 - Epoch: [60][   80/  139]    Overall Loss 0.479289    Objective Loss 0.479289                                        LR 0.000500    Time 0.842858    
2024-02-26 21:08:57,289 - Epoch: [60][   90/  139]    Overall Loss 0.480624    Objective Loss 0.480624                                        LR 0.000500    Time 0.842397    
2024-02-26 21:09:05,685 - Epoch: [60][  100/  139]    Overall Loss 0.481536    Objective Loss 0.481536                                        LR 0.000500    Time 0.842117    
2024-02-26 21:09:14,147 - Epoch: [60][  110/  139]    Overall Loss 0.481437    Objective Loss 0.481437                                        LR 0.000500    Time 0.842475    
2024-02-26 21:09:22,611 - Epoch: [60][  120/  139]    Overall Loss 0.481172    Objective Loss 0.481172                                        LR 0.000500    Time 0.842804    
2024-02-26 21:09:31,081 - Epoch: [60][  130/  139]    Overall Loss 0.479995    Objective Loss 0.479995                                        LR 0.000500    Time 0.843119    
2024-02-26 21:09:42,966 - Epoch: [60][  139/  139]    Overall Loss 0.479731    Objective Loss 0.479731    Top1 90.628228    LR 0.000500    Time 0.874024    
2024-02-26 21:09:43,248 - --- validate (epoch=60)-----------
2024-02-26 21:09:43,249 - 1392 samples (32 per mini-batch)
2024-02-26 21:10:20,162 - Epoch: [60][   10/   44]    Loss 0.569255    Top1 85.975493    
2024-02-26 21:10:56,017 - Epoch: [60][   20/   44]    Loss 0.562982    Top1 86.322145    
2024-02-26 21:11:30,820 - Epoch: [60][   30/   44]    Loss 0.571741    Top1 85.809877    
2024-02-26 21:12:06,618 - Epoch: [60][   40/   44]    Loss 0.573751    Top1 85.646377    
2024-02-26 21:12:18,772 - Epoch: [60][   44/   44]    Loss 0.573362    Top1 85.737313    
2024-02-26 21:12:19,040 - ==> Top1: 85.737    Loss: 0.573

2024-02-26 21:12:19,047 - ==> Best [Top1: 88.146   Sparsity:0.00   Params: 271456 on epoch: 50]
2024-02-26 21:12:19,047 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:12:19,077 - 

2024-02-26 21:12:19,077 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:12:27,810 - Epoch: [61][   10/  139]    Overall Loss 0.484050    Objective Loss 0.484050                                        LR 0.000500    Time 0.873245    
2024-02-26 21:12:36,191 - Epoch: [61][   20/  139]    Overall Loss 0.476055    Objective Loss 0.476055                                        LR 0.000500    Time 0.855634    
2024-02-26 21:12:44,567 - Epoch: [61][   30/  139]    Overall Loss 0.477053    Objective Loss 0.477053                                        LR 0.000500    Time 0.849599    
2024-02-26 21:12:52,944 - Epoch: [61][   40/  139]    Overall Loss 0.477264    Objective Loss 0.477264                                        LR 0.000500    Time 0.846602    
2024-02-26 21:13:01,329 - Epoch: [61][   50/  139]    Overall Loss 0.476205    Objective Loss 0.476205                                        LR 0.000500    Time 0.844974    
2024-02-26 21:13:09,716 - Epoch: [61][   60/  139]    Overall Loss 0.476988    Objective Loss 0.476988                                        LR 0.000500    Time 0.843927    
2024-02-26 21:13:18,100 - Epoch: [61][   70/  139]    Overall Loss 0.474953    Objective Loss 0.474953                                        LR 0.000500    Time 0.843132    
2024-02-26 21:13:26,484 - Epoch: [61][   80/  139]    Overall Loss 0.476206    Objective Loss 0.476206                                        LR 0.000500    Time 0.842532    
2024-02-26 21:13:34,867 - Epoch: [61][   90/  139]    Overall Loss 0.475646    Objective Loss 0.475646                                        LR 0.000500    Time 0.842050    
2024-02-26 21:13:43,253 - Epoch: [61][  100/  139]    Overall Loss 0.475297    Objective Loss 0.475297                                        LR 0.000500    Time 0.841701    
2024-02-26 21:13:51,643 - Epoch: [61][  110/  139]    Overall Loss 0.474534    Objective Loss 0.474534                                        LR 0.000500    Time 0.841458    
2024-02-26 21:14:00,029 - Epoch: [61][  120/  139]    Overall Loss 0.474661    Objective Loss 0.474661                                        LR 0.000500    Time 0.841215    
2024-02-26 21:14:08,468 - Epoch: [61][  130/  139]    Overall Loss 0.474527    Objective Loss 0.474527                                        LR 0.000500    Time 0.841419    
2024-02-26 21:14:21,049 - Epoch: [61][  139/  139]    Overall Loss 0.474219    Objective Loss 0.474219    Top1 92.768026    LR 0.000500    Time 0.877440    
2024-02-26 21:14:21,393 - --- validate (epoch=61)-----------
2024-02-26 21:14:21,393 - 1392 samples (32 per mini-batch)
2024-02-26 21:14:58,078 - Epoch: [61][   10/   44]    Loss 0.527167    Top1 88.506258    
2024-02-26 21:15:33,527 - Epoch: [61][   20/   44]    Loss 0.530506    Top1 88.275578    
2024-02-26 21:16:08,171 - Epoch: [61][   30/   44]    Loss 0.530903    Top1 88.262328    
2024-02-26 21:16:42,778 - Epoch: [61][   40/   44]    Loss 0.527472    Top1 88.452450    
2024-02-26 21:16:55,538 - Epoch: [61][   44/   44]    Loss 0.527913    Top1 88.444431    
2024-02-26 21:16:55,750 - ==> Top1: 88.444    Loss: 0.528

2024-02-26 21:16:55,757 - ==> Best [Top1: 88.444   Sparsity:0.00   Params: 271456 on epoch: 61]
2024-02-26 21:16:55,757 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:16:55,791 - 

2024-02-26 21:16:55,791 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:17:04,629 - Epoch: [62][   10/  139]    Overall Loss 0.476225    Objective Loss 0.476225                                        LR 0.000500    Time 0.883638    
2024-02-26 21:17:13,010 - Epoch: [62][   20/  139]    Overall Loss 0.470663    Objective Loss 0.470663                                        LR 0.000500    Time 0.860852    
2024-02-26 21:17:21,430 - Epoch: [62][   30/  139]    Overall Loss 0.468641    Objective Loss 0.468641                                        LR 0.000500    Time 0.854559    
2024-02-26 21:17:29,882 - Epoch: [62][   40/  139]    Overall Loss 0.471767    Objective Loss 0.471767                                        LR 0.000500    Time 0.852182    
2024-02-26 21:17:38,332 - Epoch: [62][   50/  139]    Overall Loss 0.471518    Objective Loss 0.471518                                        LR 0.000500    Time 0.850730    
2024-02-26 21:17:46,786 - Epoch: [62][   60/  139]    Overall Loss 0.472446    Objective Loss 0.472446                                        LR 0.000500    Time 0.849830    
2024-02-26 21:17:55,238 - Epoch: [62][   70/  139]    Overall Loss 0.472400    Objective Loss 0.472400                                        LR 0.000500    Time 0.849158    
2024-02-26 21:18:03,693 - Epoch: [62][   80/  139]    Overall Loss 0.473185    Objective Loss 0.473185                                        LR 0.000500    Time 0.848696    
2024-02-26 21:18:12,146 - Epoch: [62][   90/  139]    Overall Loss 0.473836    Objective Loss 0.473836                                        LR 0.000500    Time 0.848316    
2024-02-26 21:18:20,601 - Epoch: [62][  100/  139]    Overall Loss 0.474162    Objective Loss 0.474162                                        LR 0.000500    Time 0.848021    
2024-02-26 21:18:29,056 - Epoch: [62][  110/  139]    Overall Loss 0.473956    Objective Loss 0.473956                                        LR 0.000500    Time 0.847784    
2024-02-26 21:18:37,521 - Epoch: [62][  120/  139]    Overall Loss 0.473867    Objective Loss 0.473867                                        LR 0.000500    Time 0.847671    
2024-02-26 21:18:45,981 - Epoch: [62][  130/  139]    Overall Loss 0.474681    Objective Loss 0.474681                                        LR 0.000500    Time 0.847531    
2024-02-26 21:18:58,540 - Epoch: [62][  139/  139]    Overall Loss 0.475574    Objective Loss 0.475574    Top1 90.842819    LR 0.000500    Time 0.883006    
2024-02-26 21:18:58,756 - --- validate (epoch=62)-----------
2024-02-26 21:18:58,756 - 1392 samples (32 per mini-batch)
2024-02-26 21:19:35,457 - Epoch: [62][   10/   44]    Loss 0.536801    Top1 87.627271    
2024-02-26 21:20:11,427 - Epoch: [62][   20/   44]    Loss 0.525776    Top1 88.441578    
2024-02-26 21:20:46,003 - Epoch: [62][   30/   44]    Loss 0.531818    Top1 88.151512    
2024-02-26 21:21:20,432 - Epoch: [62][   40/   44]    Loss 0.527105    Top1 88.419846    
2024-02-26 21:21:32,866 - Epoch: [62][   44/   44]    Loss 0.530204    Top1 88.217643    
2024-02-26 21:21:33,095 - ==> Top1: 88.218    Loss: 0.530

2024-02-26 21:21:33,102 - ==> Best [Top1: 88.444   Sparsity:0.00   Params: 271456 on epoch: 61]
2024-02-26 21:21:33,102 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:21:33,137 - 

2024-02-26 21:21:33,137 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:21:42,002 - Epoch: [63][   10/  139]    Overall Loss 0.480098    Objective Loss 0.480098                                        LR 0.000500    Time 0.886437    
2024-02-26 21:21:50,388 - Epoch: [63][   20/  139]    Overall Loss 0.480993    Objective Loss 0.480993                                        LR 0.000500    Time 0.862456    
2024-02-26 21:21:58,767 - Epoch: [63][   30/  139]    Overall Loss 0.480790    Objective Loss 0.480790                                        LR 0.000500    Time 0.854269    
2024-02-26 21:22:07,152 - Epoch: [63][   40/  139]    Overall Loss 0.481584    Objective Loss 0.481584                                        LR 0.000500    Time 0.850310    
2024-02-26 21:22:15,538 - Epoch: [63][   50/  139]    Overall Loss 0.481392    Objective Loss 0.481392                                        LR 0.000500    Time 0.847947    
2024-02-26 21:22:23,924 - Epoch: [63][   60/  139]    Overall Loss 0.479921    Objective Loss 0.479921                                        LR 0.000500    Time 0.846395    
2024-02-26 21:22:32,307 - Epoch: [63][   70/  139]    Overall Loss 0.476869    Objective Loss 0.476869                                        LR 0.000500    Time 0.845226    
2024-02-26 21:22:40,696 - Epoch: [63][   80/  139]    Overall Loss 0.477108    Objective Loss 0.477108                                        LR 0.000500    Time 0.844425    
2024-02-26 21:22:49,084 - Epoch: [63][   90/  139]    Overall Loss 0.477013    Objective Loss 0.477013                                        LR 0.000500    Time 0.843792    
2024-02-26 21:22:57,476 - Epoch: [63][  100/  139]    Overall Loss 0.475803    Objective Loss 0.475803                                        LR 0.000500    Time 0.843332    
2024-02-26 21:23:05,865 - Epoch: [63][  110/  139]    Overall Loss 0.475358    Objective Loss 0.475358                                        LR 0.000500    Time 0.842921    
2024-02-26 21:23:14,253 - Epoch: [63][  120/  139]    Overall Loss 0.476060    Objective Loss 0.476060                                        LR 0.000500    Time 0.842576    
2024-02-26 21:23:22,649 - Epoch: [63][  130/  139]    Overall Loss 0.474428    Objective Loss 0.474428                                        LR 0.000500    Time 0.842342    
2024-02-26 21:23:34,482 - Epoch: [63][  139/  139]    Overall Loss 0.474165    Objective Loss 0.474165    Top1 92.663785    LR 0.000500    Time 0.872928    
2024-02-26 21:23:34,748 - --- validate (epoch=63)-----------
2024-02-26 21:23:34,749 - 1392 samples (32 per mini-batch)
2024-02-26 21:24:11,598 - Epoch: [63][   10/   44]    Loss 0.518354    Top1 89.074374    
2024-02-26 21:24:47,084 - Epoch: [63][   20/   44]    Loss 0.531823    Top1 88.322889    
2024-02-26 21:25:22,895 - Epoch: [63][   30/   44]    Loss 0.537913    Top1 87.940451    
2024-02-26 21:25:57,955 - Epoch: [63][   40/   44]    Loss 0.539638    Top1 87.836381    
2024-02-26 21:26:10,051 - Epoch: [63][   44/   44]    Loss 0.540534    Top1 87.826079    
2024-02-26 21:26:10,400 - ==> Top1: 87.826    Loss: 0.541

2024-02-26 21:26:10,407 - ==> Best [Top1: 88.444   Sparsity:0.00   Params: 271456 on epoch: 61]
2024-02-26 21:26:10,408 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:26:10,442 - 

2024-02-26 21:26:10,442 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:26:19,191 - Epoch: [64][   10/  139]    Overall Loss 0.467575    Objective Loss 0.467575                                        LR 0.000500    Time 0.874810    
2024-02-26 21:26:27,579 - Epoch: [64][   20/  139]    Overall Loss 0.469318    Objective Loss 0.469318                                        LR 0.000500    Time 0.856758    
2024-02-26 21:26:35,977 - Epoch: [64][   30/  139]    Overall Loss 0.475987    Objective Loss 0.475987                                        LR 0.000500    Time 0.851071    
2024-02-26 21:26:44,419 - Epoch: [64][   40/  139]    Overall Loss 0.474421    Objective Loss 0.474421                                        LR 0.000500    Time 0.849340    
2024-02-26 21:26:52,862 - Epoch: [64][   50/  139]    Overall Loss 0.475970    Objective Loss 0.475970                                        LR 0.000500    Time 0.848304    
2024-02-26 21:27:01,312 - Epoch: [64][   60/  139]    Overall Loss 0.478886    Objective Loss 0.478886                                        LR 0.000500    Time 0.847751    
2024-02-26 21:27:09,764 - Epoch: [64][   70/  139]    Overall Loss 0.480859    Objective Loss 0.480859                                        LR 0.000500    Time 0.847380    
2024-02-26 21:27:18,209 - Epoch: [64][   80/  139]    Overall Loss 0.480182    Objective Loss 0.480182                                        LR 0.000500    Time 0.847002    
2024-02-26 21:27:26,655 - Epoch: [64][   90/  139]    Overall Loss 0.478924    Objective Loss 0.478924                                        LR 0.000500    Time 0.846733    
2024-02-26 21:27:35,104 - Epoch: [64][  100/  139]    Overall Loss 0.478329    Objective Loss 0.478329                                        LR 0.000500    Time 0.846540    
2024-02-26 21:27:43,553 - Epoch: [64][  110/  139]    Overall Loss 0.477610    Objective Loss 0.477610                                        LR 0.000500    Time 0.846385    
2024-02-26 21:27:52,006 - Epoch: [64][  120/  139]    Overall Loss 0.477746    Objective Loss 0.477746                                        LR 0.000500    Time 0.846295    
2024-02-26 21:28:00,457 - Epoch: [64][  130/  139]    Overall Loss 0.477399    Objective Loss 0.477399                                        LR 0.000500    Time 0.846196    
2024-02-26 21:28:12,746 - Epoch: [64][  139/  139]    Overall Loss 0.477245    Objective Loss 0.477245    Top1 91.971974    LR 0.000500    Time 0.879812    
2024-02-26 21:28:12,922 - --- validate (epoch=64)-----------
2024-02-26 21:28:12,923 - 1392 samples (32 per mini-batch)
2024-02-26 21:28:48,911 - Epoch: [64][   10/   44]    Loss 0.534145    Top1 88.050252    
2024-02-26 21:29:23,979 - Epoch: [64][   20/   44]    Loss 0.532115    Top1 88.238290    
2024-02-26 21:29:58,830 - Epoch: [64][   30/   44]    Loss 0.529306    Top1 88.402584    
2024-02-26 21:30:32,990 - Epoch: [64][   40/   44]    Loss 0.530037    Top1 88.337057    
2024-02-26 21:30:45,108 - Epoch: [64][   44/   44]    Loss 0.527997    Top1 88.434409    
2024-02-26 21:30:45,369 - ==> Top1: 88.434    Loss: 0.528

2024-02-26 21:30:45,376 - ==> Best [Top1: 88.444   Sparsity:0.00   Params: 271456 on epoch: 61]
2024-02-26 21:30:45,376 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:30:45,407 - 

2024-02-26 21:30:45,408 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:30:54,216 - Epoch: [65][   10/  139]    Overall Loss 0.473208    Objective Loss 0.473208                                        LR 0.000500    Time 0.880680    
2024-02-26 21:31:02,640 - Epoch: [65][   20/  139]    Overall Loss 0.472210    Objective Loss 0.472210                                        LR 0.000500    Time 0.861518    
2024-02-26 21:31:11,118 - Epoch: [65][   30/  139]    Overall Loss 0.472103    Objective Loss 0.472103                                        LR 0.000500    Time 0.856904    
2024-02-26 21:31:19,594 - Epoch: [65][   40/  139]    Overall Loss 0.469931    Objective Loss 0.469931                                        LR 0.000500    Time 0.854536    
2024-02-26 21:31:28,063 - Epoch: [65][   50/  139]    Overall Loss 0.467395    Objective Loss 0.467395                                        LR 0.000500    Time 0.852998    
2024-02-26 21:31:36,535 - Epoch: [65][   60/  139]    Overall Loss 0.467151    Objective Loss 0.467151                                        LR 0.000500    Time 0.852020    
2024-02-26 21:31:45,009 - Epoch: [65][   70/  139]    Overall Loss 0.468083    Objective Loss 0.468083                                        LR 0.000500    Time 0.851356    
2024-02-26 21:31:53,495 - Epoch: [65][   80/  139]    Overall Loss 0.468443    Objective Loss 0.468443                                        LR 0.000500    Time 0.850996    
2024-02-26 21:32:01,960 - Epoch: [65][   90/  139]    Overall Loss 0.469201    Objective Loss 0.469201                                        LR 0.000500    Time 0.850490    
2024-02-26 21:32:10,435 - Epoch: [65][  100/  139]    Overall Loss 0.470251    Objective Loss 0.470251                                        LR 0.000500    Time 0.850181    
2024-02-26 21:32:18,905 - Epoch: [65][  110/  139]    Overall Loss 0.471178    Objective Loss 0.471178                                        LR 0.000500    Time 0.849878    
2024-02-26 21:32:27,405 - Epoch: [65][  120/  139]    Overall Loss 0.471445    Objective Loss 0.471445                                        LR 0.000500    Time 0.849887    
2024-02-26 21:32:35,871 - Epoch: [65][  130/  139]    Overall Loss 0.471944    Objective Loss 0.471944                                        LR 0.000500    Time 0.849627    
2024-02-26 21:32:48,695 - Epoch: [65][  139/  139]    Overall Loss 0.471622    Objective Loss 0.471622    Top1 91.776386    LR 0.000500    Time 0.886871    
2024-02-26 21:32:49,088 - --- validate (epoch=65)-----------
2024-02-26 21:32:49,089 - 1392 samples (32 per mini-batch)
2024-02-26 21:33:25,492 - Epoch: [65][   10/   44]    Loss 0.536403    Top1 88.108127    
2024-02-26 21:34:00,887 - Epoch: [65][   20/   44]    Loss 0.537919    Top1 87.986431    
2024-02-26 21:34:35,811 - Epoch: [65][   30/   44]    Loss 0.537182    Top1 88.041339    
2024-02-26 21:35:11,291 - Epoch: [65][   40/   44]    Loss 0.544116    Top1 87.597601    
2024-02-26 21:35:23,264 - Epoch: [65][   44/   44]    Loss 0.543514    Top1 87.627714    
2024-02-26 21:35:23,558 - ==> Top1: 87.628    Loss: 0.544

2024-02-26 21:35:23,565 - ==> Best [Top1: 88.444   Sparsity:0.00   Params: 271456 on epoch: 61]
2024-02-26 21:35:23,565 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:35:23,595 - 

2024-02-26 21:35:23,595 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:35:32,372 - Epoch: [66][   10/  139]    Overall Loss 0.476964    Objective Loss 0.476964                                        LR 0.000500    Time 0.877591    
2024-02-26 21:35:40,759 - Epoch: [66][   20/  139]    Overall Loss 0.474407    Objective Loss 0.474407                                        LR 0.000500    Time 0.858119    
2024-02-26 21:35:49,134 - Epoch: [66][   30/  139]    Overall Loss 0.471897    Objective Loss 0.471897                                        LR 0.000500    Time 0.851232    
2024-02-26 21:35:57,517 - Epoch: [66][   40/  139]    Overall Loss 0.467992    Objective Loss 0.467992                                        LR 0.000500    Time 0.847977    
2024-02-26 21:36:05,898 - Epoch: [66][   50/  139]    Overall Loss 0.470758    Objective Loss 0.470758                                        LR 0.000500    Time 0.845997    
2024-02-26 21:36:14,331 - Epoch: [66][   60/  139]    Overall Loss 0.472022    Objective Loss 0.472022                                        LR 0.000500    Time 0.845542    
2024-02-26 21:36:22,799 - Epoch: [66][   70/  139]    Overall Loss 0.472745    Objective Loss 0.472745                                        LR 0.000500    Time 0.845706    
2024-02-26 21:36:31,264 - Epoch: [66][   80/  139]    Overall Loss 0.471363    Objective Loss 0.471363                                        LR 0.000500    Time 0.845802    
2024-02-26 21:36:39,730 - Epoch: [66][   90/  139]    Overall Loss 0.471013    Objective Loss 0.471013                                        LR 0.000500    Time 0.845884    
2024-02-26 21:36:48,196 - Epoch: [66][  100/  139]    Overall Loss 0.470657    Objective Loss 0.470657                                        LR 0.000500    Time 0.845950    
2024-02-26 21:36:56,670 - Epoch: [66][  110/  139]    Overall Loss 0.470476    Objective Loss 0.470476                                        LR 0.000500    Time 0.846072    
2024-02-26 21:37:05,133 - Epoch: [66][  120/  139]    Overall Loss 0.470589    Objective Loss 0.470589                                        LR 0.000500    Time 0.846083    
2024-02-26 21:37:13,602 - Epoch: [66][  130/  139]    Overall Loss 0.469846    Objective Loss 0.469846                                        LR 0.000500    Time 0.846140    
2024-02-26 21:37:25,856 - Epoch: [66][  139/  139]    Overall Loss 0.468815    Objective Loss 0.468815    Top1 92.614664    LR 0.000500    Time 0.879511    
2024-02-26 21:37:26,089 - --- validate (epoch=66)-----------
2024-02-26 21:37:26,090 - 1392 samples (32 per mini-batch)
2024-02-26 21:38:01,933 - Epoch: [66][   10/   44]    Loss 0.532754    Top1 88.325574    
2024-02-26 21:38:35,531 - Epoch: [66][   20/   44]    Loss 0.534899    Top1 88.174870    
2024-02-26 21:39:10,323 - Epoch: [66][   30/   44]    Loss 0.531607    Top1 88.374311    
2024-02-26 21:39:45,800 - Epoch: [66][   40/   44]    Loss 0.532934    Top1 88.264623    
2024-02-26 21:39:58,304 - Epoch: [66][   44/   44]    Loss 0.532615    Top1 88.302616    
2024-02-26 21:39:58,595 - ==> Top1: 88.303    Loss: 0.533

2024-02-26 21:39:58,602 - ==> Best [Top1: 88.444   Sparsity:0.00   Params: 271456 on epoch: 61]
2024-02-26 21:39:58,602 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:39:58,631 - 

2024-02-26 21:39:58,631 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:40:07,411 - Epoch: [67][   10/  139]    Overall Loss 0.482279    Objective Loss 0.482279                                        LR 0.000500    Time 0.877825    
2024-02-26 21:40:15,790 - Epoch: [67][   20/  139]    Overall Loss 0.471318    Objective Loss 0.471318                                        LR 0.000500    Time 0.857850    
2024-02-26 21:40:24,163 - Epoch: [67][   30/  139]    Overall Loss 0.464718    Objective Loss 0.464718                                        LR 0.000500    Time 0.850995    
2024-02-26 21:40:32,546 - Epoch: [67][   40/  139]    Overall Loss 0.465795    Objective Loss 0.465795                                        LR 0.000500    Time 0.847806    
2024-02-26 21:40:40,928 - Epoch: [67][   50/  139]    Overall Loss 0.465953    Objective Loss 0.465953                                        LR 0.000500    Time 0.845871    
2024-02-26 21:40:49,312 - Epoch: [67][   60/  139]    Overall Loss 0.467693    Objective Loss 0.467693                                        LR 0.000500    Time 0.844627    
2024-02-26 21:40:57,697 - Epoch: [67][   70/  139]    Overall Loss 0.469112    Objective Loss 0.469112                                        LR 0.000500    Time 0.843738    
2024-02-26 21:41:06,084 - Epoch: [67][   80/  139]    Overall Loss 0.468722    Objective Loss 0.468722                                        LR 0.000500    Time 0.843101    
2024-02-26 21:41:14,466 - Epoch: [67][   90/  139]    Overall Loss 0.469001    Objective Loss 0.469001                                        LR 0.000500    Time 0.842558    
2024-02-26 21:41:22,850 - Epoch: [67][  100/  139]    Overall Loss 0.469712    Objective Loss 0.469712                                        LR 0.000500    Time 0.842136    
2024-02-26 21:41:31,237 - Epoch: [67][  110/  139]    Overall Loss 0.470243    Objective Loss 0.470243                                        LR 0.000500    Time 0.841817    
2024-02-26 21:41:39,624 - Epoch: [67][  120/  139]    Overall Loss 0.469411    Objective Loss 0.469411                                        LR 0.000500    Time 0.841551    
2024-02-26 21:41:48,011 - Epoch: [67][  130/  139]    Overall Loss 0.469466    Objective Loss 0.469466                                        LR 0.000500    Time 0.841332    
2024-02-26 21:41:59,914 - Epoch: [67][  139/  139]    Overall Loss 0.469513    Objective Loss 0.469513    Top1 90.852816    LR 0.000500    Time 0.872482    
2024-02-26 21:42:00,220 - --- validate (epoch=67)-----------
2024-02-26 21:42:00,221 - 1392 samples (32 per mini-batch)
2024-02-26 21:42:36,432 - Epoch: [67][   10/   44]    Loss 0.528005    Top1 88.837384    
2024-02-26 21:43:12,079 - Epoch: [67][   20/   44]    Loss 0.520816    Top1 89.204991    
2024-02-26 21:43:47,182 - Epoch: [67][   30/   44]    Loss 0.524821    Top1 88.954747    
2024-02-26 21:44:22,387 - Epoch: [67][   40/   44]    Loss 0.527567    Top1 88.774946    
2024-02-26 21:44:34,397 - Epoch: [67][   44/   44]    Loss 0.526032    Top1 88.903536    
2024-02-26 21:44:34,617 - ==> Top1: 88.904    Loss: 0.526

2024-02-26 21:44:34,625 - ==> Best [Top1: 88.904   Sparsity:0.00   Params: 271456 on epoch: 67]
2024-02-26 21:44:34,625 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:44:34,660 - 

2024-02-26 21:44:34,660 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:44:43,443 - Epoch: [68][   10/  139]    Overall Loss 0.471150    Objective Loss 0.471150                                        LR 0.000500    Time 0.878179    
2024-02-26 21:44:51,818 - Epoch: [68][   20/  139]    Overall Loss 0.470140    Objective Loss 0.470140                                        LR 0.000500    Time 0.857805    
2024-02-26 21:45:00,195 - Epoch: [68][   30/  139]    Overall Loss 0.471725    Objective Loss 0.471725                                        LR 0.000500    Time 0.851086    
2024-02-26 21:45:08,578 - Epoch: [68][   40/  139]    Overall Loss 0.469155    Objective Loss 0.469155                                        LR 0.000500    Time 0.847878    
2024-02-26 21:45:16,960 - Epoch: [68][   50/  139]    Overall Loss 0.468675    Objective Loss 0.468675                                        LR 0.000500    Time 0.845944    
2024-02-26 21:45:25,340 - Epoch: [68][   60/  139]    Overall Loss 0.467471    Objective Loss 0.467471                                        LR 0.000500    Time 0.844603    
2024-02-26 21:45:33,752 - Epoch: [68][   70/  139]    Overall Loss 0.466415    Objective Loss 0.466415                                        LR 0.000500    Time 0.844119    
2024-02-26 21:45:42,223 - Epoch: [68][   80/  139]    Overall Loss 0.466380    Objective Loss 0.466380                                        LR 0.000500    Time 0.844476    
2024-02-26 21:45:50,693 - Epoch: [68][   90/  139]    Overall Loss 0.467522    Objective Loss 0.467522                                        LR 0.000500    Time 0.844747    
2024-02-26 21:45:59,153 - Epoch: [68][  100/  139]    Overall Loss 0.466848    Objective Loss 0.466848                                        LR 0.000500    Time 0.844867    
2024-02-26 21:46:07,623 - Epoch: [68][  110/  139]    Overall Loss 0.467039    Objective Loss 0.467039                                        LR 0.000500    Time 0.845060    
2024-02-26 21:46:16,098 - Epoch: [68][  120/  139]    Overall Loss 0.467136    Objective Loss 0.467136                                        LR 0.000500    Time 0.845250    
2024-02-26 21:46:24,565 - Epoch: [68][  130/  139]    Overall Loss 0.467740    Objective Loss 0.467740                                        LR 0.000500    Time 0.845358    
2024-02-26 21:46:37,316 - Epoch: [68][  139/  139]    Overall Loss 0.467590    Objective Loss 0.467590    Top1 92.686493    LR 0.000500    Time 0.882355    
2024-02-26 21:46:37,542 - --- validate (epoch=68)-----------
2024-02-26 21:46:37,543 - 1392 samples (32 per mini-batch)
2024-02-26 21:47:13,813 - Epoch: [68][   10/   44]    Loss 0.540471    Top1 87.924721    
2024-02-26 21:47:48,677 - Epoch: [68][   20/   44]    Loss 0.527715    Top1 88.650557    
2024-02-26 21:48:23,793 - Epoch: [68][   30/   44]    Loss 0.527786    Top1 88.639320    
2024-02-26 21:48:59,930 - Epoch: [68][   40/   44]    Loss 0.525129    Top1 88.767860    
2024-02-26 21:49:11,913 - Epoch: [68][   44/   44]    Loss 0.524768    Top1 88.788885    
2024-02-26 21:49:12,190 - ==> Top1: 88.789    Loss: 0.525

2024-02-26 21:49:12,197 - ==> Best [Top1: 88.904   Sparsity:0.00   Params: 271456 on epoch: 67]
2024-02-26 21:49:12,198 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:49:12,233 - 

2024-02-26 21:49:12,233 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:49:20,965 - Epoch: [69][   10/  139]    Overall Loss 0.464889    Objective Loss 0.464889                                        LR 0.000500    Time 0.873048    
2024-02-26 21:49:29,354 - Epoch: [69][   20/  139]    Overall Loss 0.463546    Objective Loss 0.463546                                        LR 0.000500    Time 0.855932    
2024-02-26 21:49:37,812 - Epoch: [69][   30/  139]    Overall Loss 0.459570    Objective Loss 0.459570                                        LR 0.000500    Time 0.852545    
2024-02-26 21:49:46,269 - Epoch: [69][   40/  139]    Overall Loss 0.462350    Objective Loss 0.462350                                        LR 0.000500    Time 0.850807    
2024-02-26 21:49:54,729 - Epoch: [69][   50/  139]    Overall Loss 0.464956    Objective Loss 0.464956                                        LR 0.000500    Time 0.849832    
2024-02-26 21:50:03,191 - Epoch: [69][   60/  139]    Overall Loss 0.466196    Objective Loss 0.466196                                        LR 0.000500    Time 0.849206    
2024-02-26 21:50:11,656 - Epoch: [69][   70/  139]    Overall Loss 0.469016    Objective Loss 0.469016                                        LR 0.000500    Time 0.848814    
2024-02-26 21:50:20,119 - Epoch: [69][   80/  139]    Overall Loss 0.469307    Objective Loss 0.469307                                        LR 0.000500    Time 0.848497    
2024-02-26 21:50:28,585 - Epoch: [69][   90/  139]    Overall Loss 0.469544    Objective Loss 0.469544                                        LR 0.000500    Time 0.848276    
2024-02-26 21:50:37,047 - Epoch: [69][  100/  139]    Overall Loss 0.469801    Objective Loss 0.469801                                        LR 0.000500    Time 0.848057    
2024-02-26 21:50:45,513 - Epoch: [69][  110/  139]    Overall Loss 0.469319    Objective Loss 0.469319                                        LR 0.000500    Time 0.847924    
2024-02-26 21:50:53,979 - Epoch: [69][  120/  139]    Overall Loss 0.468348    Objective Loss 0.468348                                        LR 0.000500    Time 0.847802    
2024-02-26 21:51:02,442 - Epoch: [69][  130/  139]    Overall Loss 0.467844    Objective Loss 0.467844                                        LR 0.000500    Time 0.847683    
2024-02-26 21:51:15,037 - Epoch: [69][  139/  139]    Overall Loss 0.467838    Objective Loss 0.467838    Top1 93.474457    LR 0.000500    Time 0.883410    
2024-02-26 21:51:15,358 - --- validate (epoch=69)-----------
2024-02-26 21:51:15,359 - 1392 samples (32 per mini-batch)
2024-02-26 21:51:51,539 - Epoch: [69][   10/   44]    Loss 0.548370    Top1 87.501841    
2024-02-26 21:52:27,272 - Epoch: [69][   20/   44]    Loss 0.550363    Top1 87.391465    
2024-02-26 21:53:02,297 - Epoch: [69][   30/   44]    Loss 0.549120    Top1 87.486303    
2024-02-26 21:53:36,915 - Epoch: [69][   40/   44]    Loss 0.544032    Top1 87.809303    
2024-02-26 21:53:49,200 - Epoch: [69][   44/   44]    Loss 0.543363    Top1 87.846314    
2024-02-26 21:53:49,521 - ==> Top1: 87.846    Loss: 0.543

2024-02-26 21:53:49,528 - ==> Best [Top1: 88.904   Sparsity:0.00   Params: 271456 on epoch: 67]
2024-02-26 21:53:49,529 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:53:49,563 - 

2024-02-26 21:53:49,563 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:53:58,405 - Epoch: [70][   10/  139]    Overall Loss 0.460514    Objective Loss 0.460514                                        LR 0.000500    Time 0.884050    
2024-02-26 21:54:06,781 - Epoch: [70][   20/  139]    Overall Loss 0.463210    Objective Loss 0.463210                                        LR 0.000500    Time 0.860790    
2024-02-26 21:54:15,158 - Epoch: [70][   30/  139]    Overall Loss 0.460365    Objective Loss 0.460365                                        LR 0.000500    Time 0.853095    
2024-02-26 21:54:23,537 - Epoch: [70][   40/  139]    Overall Loss 0.460803    Objective Loss 0.460803                                        LR 0.000500    Time 0.849271    
2024-02-26 21:54:31,916 - Epoch: [70][   50/  139]    Overall Loss 0.459798    Objective Loss 0.459798                                        LR 0.000500    Time 0.847003    
2024-02-26 21:54:40,308 - Epoch: [70][   60/  139]    Overall Loss 0.461648    Objective Loss 0.461648                                        LR 0.000500    Time 0.845683    
2024-02-26 21:54:48,691 - Epoch: [70][   70/  139]    Overall Loss 0.461820    Objective Loss 0.461820                                        LR 0.000500    Time 0.844618    
2024-02-26 21:54:57,074 - Epoch: [70][   80/  139]    Overall Loss 0.461690    Objective Loss 0.461690                                        LR 0.000500    Time 0.843822    
2024-02-26 21:55:05,462 - Epoch: [70][   90/  139]    Overall Loss 0.462742    Objective Loss 0.462742                                        LR 0.000500    Time 0.843261    
2024-02-26 21:55:13,847 - Epoch: [70][  100/  139]    Overall Loss 0.463584    Objective Loss 0.463584                                        LR 0.000500    Time 0.842785    
2024-02-26 21:55:22,237 - Epoch: [70][  110/  139]    Overall Loss 0.463879    Objective Loss 0.463879                                        LR 0.000500    Time 0.842435    
2024-02-26 21:55:30,620 - Epoch: [70][  120/  139]    Overall Loss 0.463370    Objective Loss 0.463370                                        LR 0.000500    Time 0.842085    
2024-02-26 21:55:39,009 - Epoch: [70][  130/  139]    Overall Loss 0.463529    Objective Loss 0.463529                                        LR 0.000500    Time 0.841839    
2024-02-26 21:55:50,674 - Epoch: [70][  139/  139]    Overall Loss 0.463995    Objective Loss 0.463995    Top1 92.372742    LR 0.000500    Time 0.871249    
2024-02-26 21:55:50,972 - --- validate (epoch=70)-----------
2024-02-26 21:55:50,973 - 1392 samples (32 per mini-batch)
2024-02-26 21:56:27,276 - Epoch: [70][   10/   44]    Loss 0.538225    Top1 88.107544    
2024-02-26 21:57:03,092 - Epoch: [70][   20/   44]    Loss 0.527877    Top1 88.648383    
2024-02-26 21:57:37,352 - Epoch: [70][   30/   44]    Loss 0.525529    Top1 88.813061    
2024-02-26 21:58:11,469 - Epoch: [70][   40/   44]    Loss 0.528613    Top1 88.608358    
2024-02-26 21:58:23,664 - Epoch: [70][   44/   44]    Loss 0.529980    Top1 88.539573    
2024-02-26 21:58:23,953 - ==> Top1: 88.540    Loss: 0.530

2024-02-26 21:58:23,960 - ==> Best [Top1: 88.904   Sparsity:0.00   Params: 271456 on epoch: 67]
2024-02-26 21:58:23,961 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 21:58:23,992 - 

2024-02-26 21:58:23,992 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 21:58:32,872 - Epoch: [71][   10/  139]    Overall Loss 0.468221    Objective Loss 0.468221                                        LR 0.000500    Time 0.887893    
2024-02-26 21:58:41,249 - Epoch: [71][   20/  139]    Overall Loss 0.464380    Objective Loss 0.464380                                        LR 0.000500    Time 0.862772    
2024-02-26 21:58:49,630 - Epoch: [71][   30/  139]    Overall Loss 0.464915    Objective Loss 0.464915                                        LR 0.000500    Time 0.854527    
2024-02-26 21:58:58,012 - Epoch: [71][   40/  139]    Overall Loss 0.466319    Objective Loss 0.466319                                        LR 0.000500    Time 0.850434    
2024-02-26 21:59:06,391 - Epoch: [71][   50/  139]    Overall Loss 0.463654    Objective Loss 0.463654                                        LR 0.000500    Time 0.847923    
2024-02-26 21:59:14,776 - Epoch: [71][   60/  139]    Overall Loss 0.462707    Objective Loss 0.462707                                        LR 0.000500    Time 0.846333    
2024-02-26 21:59:23,157 - Epoch: [71][   70/  139]    Overall Loss 0.463404    Objective Loss 0.463404                                        LR 0.000500    Time 0.845159    
2024-02-26 21:59:31,542 - Epoch: [71][   80/  139]    Overall Loss 0.464428    Objective Loss 0.464428                                        LR 0.000500    Time 0.844325    
2024-02-26 21:59:39,935 - Epoch: [71][   90/  139]    Overall Loss 0.464143    Objective Loss 0.464143                                        LR 0.000500    Time 0.843758    
2024-02-26 21:59:48,316 - Epoch: [71][  100/  139]    Overall Loss 0.464017    Objective Loss 0.464017                                        LR 0.000500    Time 0.843187    
2024-02-26 21:59:56,705 - Epoch: [71][  110/  139]    Overall Loss 0.463474    Objective Loss 0.463474                                        LR 0.000500    Time 0.842789    
2024-02-26 22:00:05,089 - Epoch: [71][  120/  139]    Overall Loss 0.463782    Objective Loss 0.463782                                        LR 0.000500    Time 0.842421    
2024-02-26 22:00:13,475 - Epoch: [71][  130/  139]    Overall Loss 0.464065    Objective Loss 0.464065                                        LR 0.000500    Time 0.842124    
2024-02-26 22:00:25,827 - Epoch: [71][  139/  139]    Overall Loss 0.464144    Objective Loss 0.464144    Top1 92.538413    LR 0.000500    Time 0.876455    
2024-02-26 22:00:26,096 - --- validate (epoch=71)-----------
2024-02-26 22:00:26,096 - 1392 samples (32 per mini-batch)
2024-02-26 22:01:02,364 - Epoch: [71][   10/   44]    Loss 0.524702    Top1 88.826049    
2024-02-26 22:01:37,433 - Epoch: [71][   20/   44]    Loss 0.523383    Top1 88.910115    
2024-02-26 22:02:12,256 - Epoch: [71][   30/   44]    Loss 0.523161    Top1 88.964845    
2024-02-26 22:02:47,175 - Epoch: [71][   40/   44]    Loss 0.521050    Top1 89.098907    
2024-02-26 22:02:59,123 - Epoch: [71][   44/   44]    Loss 0.518551    Top1 89.214026    
2024-02-26 22:02:59,454 - ==> Top1: 89.214    Loss: 0.519

2024-02-26 22:02:59,461 - ==> Best [Top1: 89.214   Sparsity:0.00   Params: 271456 on epoch: 71]
2024-02-26 22:02:59,461 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:02:59,495 - 

2024-02-26 22:02:59,495 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:03:08,253 - Epoch: [72][   10/  139]    Overall Loss 0.443765    Objective Loss 0.443765                                        LR 0.000500    Time 0.875663    
2024-02-26 22:03:16,633 - Epoch: [72][   20/  139]    Overall Loss 0.452637    Objective Loss 0.452637                                        LR 0.000500    Time 0.856818    
2024-02-26 22:03:25,077 - Epoch: [72][   30/  139]    Overall Loss 0.456170    Objective Loss 0.456170                                        LR 0.000500    Time 0.852653    
2024-02-26 22:03:33,521 - Epoch: [72][   40/  139]    Overall Loss 0.458835    Objective Loss 0.458835                                        LR 0.000500    Time 0.850568    
2024-02-26 22:03:41,966 - Epoch: [72][   50/  139]    Overall Loss 0.460022    Objective Loss 0.460022                                        LR 0.000500    Time 0.849342    
2024-02-26 22:03:50,416 - Epoch: [72][   60/  139]    Overall Loss 0.460654    Objective Loss 0.460654                                        LR 0.000500    Time 0.848611    
2024-02-26 22:03:58,865 - Epoch: [72][   70/  139]    Overall Loss 0.461283    Objective Loss 0.461283                                        LR 0.000500    Time 0.848071    
2024-02-26 22:04:07,323 - Epoch: [72][   80/  139]    Overall Loss 0.460605    Objective Loss 0.460605                                        LR 0.000500    Time 0.847769    
2024-02-26 22:04:15,777 - Epoch: [72][   90/  139]    Overall Loss 0.461232    Objective Loss 0.461232                                        LR 0.000500    Time 0.847501    
2024-02-26 22:04:24,229 - Epoch: [72][  100/  139]    Overall Loss 0.461862    Objective Loss 0.461862                                        LR 0.000500    Time 0.847269    
2024-02-26 22:04:32,680 - Epoch: [72][  110/  139]    Overall Loss 0.462086    Objective Loss 0.462086                                        LR 0.000500    Time 0.847064    
2024-02-26 22:04:41,131 - Epoch: [72][  120/  139]    Overall Loss 0.462466    Objective Loss 0.462466                                        LR 0.000500    Time 0.846894    
2024-02-26 22:04:49,583 - Epoch: [72][  130/  139]    Overall Loss 0.462398    Objective Loss 0.462398                                        LR 0.000500    Time 0.846757    
2024-02-26 22:05:01,779 - Epoch: [72][  139/  139]    Overall Loss 0.462627    Objective Loss 0.462627    Top1 92.672058    LR 0.000500    Time 0.879671    
2024-02-26 22:05:01,991 - --- validate (epoch=72)-----------
2024-02-26 22:05:01,992 - 1392 samples (32 per mini-batch)
2024-02-26 22:05:38,868 - Epoch: [72][   10/   44]    Loss 0.512164    Top1 89.580661    
2024-02-26 22:06:13,800 - Epoch: [72][   20/   44]    Loss 0.516449    Top1 89.288858    
2024-02-26 22:06:48,317 - Epoch: [72][   30/   44]    Loss 0.518441    Top1 89.167774    
2024-02-26 22:07:23,254 - Epoch: [72][   40/   44]    Loss 0.517728    Top1 89.202827    
2024-02-26 22:07:35,242 - Epoch: [72][   44/   44]    Loss 0.516591    Top1 89.252894    
2024-02-26 22:07:35,525 - ==> Top1: 89.253    Loss: 0.517

2024-02-26 22:07:35,533 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 22:07:35,534 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:07:35,568 - 

2024-02-26 22:07:35,569 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:07:44,447 - Epoch: [73][   10/  139]    Overall Loss 0.472093    Objective Loss 0.472093                                        LR 0.000500    Time 0.887726    
2024-02-26 22:07:52,855 - Epoch: [73][   20/  139]    Overall Loss 0.469132    Objective Loss 0.469132                                        LR 0.000500    Time 0.864209    
2024-02-26 22:08:01,311 - Epoch: [73][   30/  139]    Overall Loss 0.468125    Objective Loss 0.468125                                        LR 0.000500    Time 0.857991    
2024-02-26 22:08:09,756 - Epoch: [73][   40/  139]    Overall Loss 0.464362    Objective Loss 0.464362                                        LR 0.000500    Time 0.854603    
2024-02-26 22:08:18,220 - Epoch: [73][   50/  139]    Overall Loss 0.464313    Objective Loss 0.464313                                        LR 0.000500    Time 0.852927    
2024-02-26 22:08:26,675 - Epoch: [73][   60/  139]    Overall Loss 0.466315    Objective Loss 0.466315                                        LR 0.000500    Time 0.851686    
2024-02-26 22:08:35,130 - Epoch: [73][   70/  139]    Overall Loss 0.466590    Objective Loss 0.466590                                        LR 0.000500    Time 0.850783    
2024-02-26 22:08:43,585 - Epoch: [73][   80/  139]    Overall Loss 0.465914    Objective Loss 0.465914                                        LR 0.000500    Time 0.850120    
2024-02-26 22:08:52,035 - Epoch: [73][   90/  139]    Overall Loss 0.466790    Objective Loss 0.466790                                        LR 0.000500    Time 0.849541    
2024-02-26 22:09:00,499 - Epoch: [73][  100/  139]    Overall Loss 0.467694    Objective Loss 0.467694                                        LR 0.000500    Time 0.849223    
2024-02-26 22:09:08,958 - Epoch: [73][  110/  139]    Overall Loss 0.466439    Objective Loss 0.466439                                        LR 0.000500    Time 0.848914    
2024-02-26 22:09:17,412 - Epoch: [73][  120/  139]    Overall Loss 0.466782    Objective Loss 0.466782                                        LR 0.000500    Time 0.848613    
2024-02-26 22:09:25,861 - Epoch: [73][  130/  139]    Overall Loss 0.467176    Objective Loss 0.467176                                        LR 0.000500    Time 0.848319    
2024-02-26 22:09:37,882 - Epoch: [73][  139/  139]    Overall Loss 0.468100    Objective Loss 0.468100    Top1 91.108109    LR 0.000500    Time 0.879874    
2024-02-26 22:09:38,116 - --- validate (epoch=73)-----------
2024-02-26 22:09:38,117 - 1392 samples (32 per mini-batch)
2024-02-26 22:10:15,072 - Epoch: [73][   10/   44]    Loss 0.563603    Top1 86.181527    
2024-02-26 22:10:49,902 - Epoch: [73][   20/   44]    Loss 0.544313    Top1 87.386313    
2024-02-26 22:11:26,398 - Epoch: [73][   30/   44]    Loss 0.546629    Top1 87.206659    
2024-02-26 22:12:02,264 - Epoch: [73][   40/   44]    Loss 0.544450    Top1 87.356411    
2024-02-26 22:12:14,683 - Epoch: [73][   44/   44]    Loss 0.546123    Top1 87.253102    
2024-02-26 22:12:14,906 - ==> Top1: 87.253    Loss: 0.546

2024-02-26 22:12:14,913 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 22:12:14,913 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:12:14,943 - 

2024-02-26 22:12:14,943 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:12:23,723 - Epoch: [74][   10/  139]    Overall Loss 0.475251    Objective Loss 0.475251                                        LR 0.000500    Time 0.877782    
2024-02-26 22:12:32,105 - Epoch: [74][   20/  139]    Overall Loss 0.469506    Objective Loss 0.469506                                        LR 0.000500    Time 0.858007    
2024-02-26 22:12:40,485 - Epoch: [74][   30/  139]    Overall Loss 0.468633    Objective Loss 0.468633                                        LR 0.000500    Time 0.851316    
2024-02-26 22:12:48,904 - Epoch: [74][   40/  139]    Overall Loss 0.466782    Objective Loss 0.466782                                        LR 0.000500    Time 0.848948    
2024-02-26 22:12:57,354 - Epoch: [74][   50/  139]    Overall Loss 0.465302    Objective Loss 0.465302                                        LR 0.000500    Time 0.848143    
2024-02-26 22:13:05,802 - Epoch: [74][   60/  139]    Overall Loss 0.464061    Objective Loss 0.464061                                        LR 0.000500    Time 0.847575    
2024-02-26 22:13:14,258 - Epoch: [74][   70/  139]    Overall Loss 0.462610    Objective Loss 0.462610                                        LR 0.000500    Time 0.847282    
2024-02-26 22:13:22,711 - Epoch: [74][   80/  139]    Overall Loss 0.461080    Objective Loss 0.461080                                        LR 0.000500    Time 0.847027    
2024-02-26 22:13:31,168 - Epoch: [74][   90/  139]    Overall Loss 0.461443    Objective Loss 0.461443                                        LR 0.000500    Time 0.846864    
2024-02-26 22:13:39,625 - Epoch: [74][  100/  139]    Overall Loss 0.461278    Objective Loss 0.461278                                        LR 0.000500    Time 0.846741    
2024-02-26 22:13:48,081 - Epoch: [74][  110/  139]    Overall Loss 0.460730    Objective Loss 0.460730                                        LR 0.000500    Time 0.846638    
2024-02-26 22:13:56,536 - Epoch: [74][  120/  139]    Overall Loss 0.460785    Objective Loss 0.460785                                        LR 0.000500    Time 0.846533    
2024-02-26 22:14:04,989 - Epoch: [74][  130/  139]    Overall Loss 0.460679    Objective Loss 0.460679                                        LR 0.000500    Time 0.846435    
2024-02-26 22:14:17,294 - Epoch: [74][  139/  139]    Overall Loss 0.460588    Objective Loss 0.460588    Top1 93.461378    LR 0.000500    Time 0.880151    
2024-02-26 22:14:17,576 - --- validate (epoch=74)-----------
2024-02-26 22:14:17,577 - 1392 samples (32 per mini-batch)
2024-02-26 22:14:53,929 - Epoch: [74][   10/   44]    Loss 0.538336    Top1 88.012436    
2024-02-26 22:15:28,155 - Epoch: [74][   20/   44]    Loss 0.524189    Top1 88.791699    
2024-02-26 22:16:02,716 - Epoch: [74][   30/   44]    Loss 0.523679    Top1 88.807878    
2024-02-26 22:16:37,655 - Epoch: [74][   40/   44]    Loss 0.523202    Top1 88.841931    
2024-02-26 22:16:49,916 - Epoch: [74][   44/   44]    Loss 0.523794    Top1 88.809579    
2024-02-26 22:16:50,165 - ==> Top1: 88.810    Loss: 0.524

2024-02-26 22:16:50,173 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 22:16:50,173 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:16:50,208 - 

2024-02-26 22:16:50,208 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:16:58,991 - Epoch: [75][   10/  139]    Overall Loss 0.459873    Objective Loss 0.459873                                        LR 0.000500    Time 0.878165    
2024-02-26 22:17:07,376 - Epoch: [75][   20/  139]    Overall Loss 0.454559    Objective Loss 0.454559                                        LR 0.000500    Time 0.858299    
2024-02-26 22:17:15,755 - Epoch: [75][   30/  139]    Overall Loss 0.452818    Objective Loss 0.452818                                        LR 0.000500    Time 0.851494    
2024-02-26 22:17:24,140 - Epoch: [75][   40/  139]    Overall Loss 0.458177    Objective Loss 0.458177                                        LR 0.000500    Time 0.848235    
2024-02-26 22:17:32,523 - Epoch: [75][   50/  139]    Overall Loss 0.458263    Objective Loss 0.458263                                        LR 0.000500    Time 0.846235    
2024-02-26 22:17:40,903 - Epoch: [75][   60/  139]    Overall Loss 0.459627    Objective Loss 0.459627                                        LR 0.000500    Time 0.844851    
2024-02-26 22:17:49,297 - Epoch: [75][   70/  139]    Overall Loss 0.461084    Objective Loss 0.461084                                        LR 0.000500    Time 0.844073    
2024-02-26 22:17:57,739 - Epoch: [75][   80/  139]    Overall Loss 0.459992    Objective Loss 0.459992                                        LR 0.000500    Time 0.844083    
2024-02-26 22:18:06,195 - Epoch: [75][   90/  139]    Overall Loss 0.460870    Objective Loss 0.460870                                        LR 0.000500    Time 0.844239    
2024-02-26 22:18:14,650 - Epoch: [75][  100/  139]    Overall Loss 0.460983    Objective Loss 0.460983                                        LR 0.000500    Time 0.844357    
2024-02-26 22:18:23,105 - Epoch: [75][  110/  139]    Overall Loss 0.460567    Objective Loss 0.460567                                        LR 0.000500    Time 0.844455    
2024-02-26 22:18:31,570 - Epoch: [75][  120/  139]    Overall Loss 0.460578    Objective Loss 0.460578                                        LR 0.000500    Time 0.844618    
2024-02-26 22:18:40,028 - Epoch: [75][  130/  139]    Overall Loss 0.461657    Objective Loss 0.461657                                        LR 0.000500    Time 0.844705    
2024-02-26 22:18:52,142 - Epoch: [75][  139/  139]    Overall Loss 0.461770    Objective Loss 0.461770    Top1 92.527976    LR 0.000500    Time 0.877158    
2024-02-26 22:18:52,438 - --- validate (epoch=75)-----------
2024-02-26 22:18:52,439 - 1392 samples (32 per mini-batch)
2024-02-26 22:19:28,615 - Epoch: [75][   10/   44]    Loss 0.522554    Top1 88.876711    
2024-02-26 22:20:04,240 - Epoch: [75][   20/   44]    Loss 0.527517    Top1 88.572149    
2024-02-26 22:20:39,795 - Epoch: [75][   30/   44]    Loss 0.526962    Top1 88.651627    
2024-02-26 22:21:15,739 - Epoch: [75][   40/   44]    Loss 0.525126    Top1 88.793093    
2024-02-26 22:21:28,277 - Epoch: [75][   44/   44]    Loss 0.523862    Top1 88.833559    
2024-02-26 22:21:28,507 - ==> Top1: 88.834    Loss: 0.524

2024-02-26 22:21:28,515 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 22:21:28,515 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:21:28,549 - 

2024-02-26 22:21:28,550 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:21:37,318 - Epoch: [76][   10/  139]    Overall Loss 0.464750    Objective Loss 0.464750                                        LR 0.000500    Time 0.876724    
2024-02-26 22:21:45,702 - Epoch: [76][   20/  139]    Overall Loss 0.462087    Objective Loss 0.462087                                        LR 0.000500    Time 0.857521    
2024-02-26 22:21:54,082 - Epoch: [76][   30/  139]    Overall Loss 0.457167    Objective Loss 0.457167                                        LR 0.000500    Time 0.850993    
2024-02-26 22:22:02,461 - Epoch: [76][   40/  139]    Overall Loss 0.457207    Objective Loss 0.457207                                        LR 0.000500    Time 0.847731    
2024-02-26 22:22:10,846 - Epoch: [76][   50/  139]    Overall Loss 0.458906    Objective Loss 0.458906                                        LR 0.000500    Time 0.845859    
2024-02-26 22:22:19,232 - Epoch: [76][   60/  139]    Overall Loss 0.460534    Objective Loss 0.460534                                        LR 0.000500    Time 0.844654    
2024-02-26 22:22:27,616 - Epoch: [76][   70/  139]    Overall Loss 0.460587    Objective Loss 0.460587                                        LR 0.000500    Time 0.843754    
2024-02-26 22:22:35,996 - Epoch: [76][   80/  139]    Overall Loss 0.459576    Objective Loss 0.459576                                        LR 0.000500    Time 0.843025    
2024-02-26 22:22:44,377 - Epoch: [76][   90/  139]    Overall Loss 0.459234    Objective Loss 0.459234                                        LR 0.000500    Time 0.842472    
2024-02-26 22:22:52,761 - Epoch: [76][  100/  139]    Overall Loss 0.459398    Objective Loss 0.459398                                        LR 0.000500    Time 0.842062    
2024-02-26 22:23:01,159 - Epoch: [76][  110/  139]    Overall Loss 0.459887    Objective Loss 0.459887                                        LR 0.000500    Time 0.841854    
2024-02-26 22:23:09,546 - Epoch: [76][  120/  139]    Overall Loss 0.460495    Objective Loss 0.460495                                        LR 0.000500    Time 0.841585    
2024-02-26 22:23:17,933 - Epoch: [76][  130/  139]    Overall Loss 0.459881    Objective Loss 0.459881                                        LR 0.000500    Time 0.841355    
2024-02-26 22:23:29,688 - Epoch: [76][  139/  139]    Overall Loss 0.460341    Objective Loss 0.460341    Top1 91.549873    LR 0.000500    Time 0.871448    
2024-02-26 22:23:29,974 - --- validate (epoch=76)-----------
2024-02-26 22:23:29,975 - 1392 samples (32 per mini-batch)
2024-02-26 22:24:06,107 - Epoch: [76][   10/   44]    Loss 0.529407    Top1 88.478515    
2024-02-26 22:24:41,464 - Epoch: [76][   20/   44]    Loss 0.529904    Top1 88.473575    
2024-02-26 22:25:16,495 - Epoch: [76][   30/   44]    Loss 0.528286    Top1 88.589394    
2024-02-26 22:25:51,320 - Epoch: [76][   40/   44]    Loss 0.535622    Top1 88.184390    
2024-02-26 22:26:04,166 - Epoch: [76][   44/   44]    Loss 0.534872    Top1 88.206206    
2024-02-26 22:26:04,491 - ==> Top1: 88.206    Loss: 0.535

2024-02-26 22:26:04,498 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 22:26:04,498 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:26:04,528 - 

2024-02-26 22:26:04,529 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:26:13,362 - Epoch: [77][   10/  139]    Overall Loss 0.453376    Objective Loss 0.453376                                        LR 0.000500    Time 0.883268    
2024-02-26 22:26:21,738 - Epoch: [77][   20/  139]    Overall Loss 0.459706    Objective Loss 0.459706                                        LR 0.000500    Time 0.860390    
2024-02-26 22:26:30,115 - Epoch: [77][   30/  139]    Overall Loss 0.458278    Objective Loss 0.458278                                        LR 0.000500    Time 0.852809    
2024-02-26 22:26:38,571 - Epoch: [77][   40/  139]    Overall Loss 0.457938    Objective Loss 0.457938                                        LR 0.000500    Time 0.850995    
2024-02-26 22:26:47,038 - Epoch: [77][   50/  139]    Overall Loss 0.458932    Objective Loss 0.458932                                        LR 0.000500    Time 0.850106    
2024-02-26 22:26:55,508 - Epoch: [77][   60/  139]    Overall Loss 0.458694    Objective Loss 0.458694                                        LR 0.000500    Time 0.849567    
2024-02-26 22:27:03,980 - Epoch: [77][   70/  139]    Overall Loss 0.457829    Objective Loss 0.457829                                        LR 0.000500    Time 0.849209    
2024-02-26 22:27:12,452 - Epoch: [77][   80/  139]    Overall Loss 0.457412    Objective Loss 0.457412                                        LR 0.000500    Time 0.848952    
2024-02-26 22:27:20,931 - Epoch: [77][   90/  139]    Overall Loss 0.457762    Objective Loss 0.457762                                        LR 0.000500    Time 0.848817    
2024-02-26 22:27:29,403 - Epoch: [77][  100/  139]    Overall Loss 0.458063    Objective Loss 0.458063                                        LR 0.000500    Time 0.848647    
2024-02-26 22:27:37,876 - Epoch: [77][  110/  139]    Overall Loss 0.458394    Objective Loss 0.458394                                        LR 0.000500    Time 0.848519    
2024-02-26 22:27:46,353 - Epoch: [77][  120/  139]    Overall Loss 0.457990    Objective Loss 0.457990                                        LR 0.000500    Time 0.848443    
2024-02-26 22:27:54,821 - Epoch: [77][  130/  139]    Overall Loss 0.457713    Objective Loss 0.457713                                        LR 0.000500    Time 0.848315    
2024-02-26 22:28:07,429 - Epoch: [77][  139/  139]    Overall Loss 0.458860    Objective Loss 0.458860    Top1 92.463667    LR 0.000500    Time 0.884088    
2024-02-26 22:28:07,668 - --- validate (epoch=77)-----------
2024-02-26 22:28:07,668 - 1392 samples (32 per mini-batch)
2024-02-26 22:28:43,838 - Epoch: [77][   10/   44]    Loss 0.547937    Top1 87.813103    
2024-02-26 22:29:20,586 - Epoch: [77][   20/   44]    Loss 0.543186    Top1 88.105073    
2024-02-26 22:29:55,415 - Epoch: [77][   30/   44]    Loss 0.542039    Top1 88.157251    
2024-02-26 22:30:30,986 - Epoch: [77][   40/   44]    Loss 0.541512    Top1 88.197990    
2024-02-26 22:30:42,813 - Epoch: [77][   44/   44]    Loss 0.542188    Top1 88.176585    
2024-02-26 22:30:43,050 - ==> Top1: 88.177    Loss: 0.542

2024-02-26 22:30:43,058 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 22:30:43,058 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:30:43,088 - 

2024-02-26 22:30:43,088 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:30:51,809 - Epoch: [78][   10/  139]    Overall Loss 0.466760    Objective Loss 0.466760                                        LR 0.000500    Time 0.871961    
2024-02-26 22:31:00,188 - Epoch: [78][   20/  139]    Overall Loss 0.463554    Objective Loss 0.463554                                        LR 0.000500    Time 0.854888    
2024-02-26 22:31:08,563 - Epoch: [78][   30/  139]    Overall Loss 0.462739    Objective Loss 0.462739                                        LR 0.000500    Time 0.849085    
2024-02-26 22:31:16,942 - Epoch: [78][   40/  139]    Overall Loss 0.465323    Objective Loss 0.465323                                        LR 0.000500    Time 0.846278    
2024-02-26 22:31:25,324 - Epoch: [78][   50/  139]    Overall Loss 0.464063    Objective Loss 0.464063                                        LR 0.000500    Time 0.844654    
2024-02-26 22:31:33,710 - Epoch: [78][   60/  139]    Overall Loss 0.462250    Objective Loss 0.462250                                        LR 0.000500    Time 0.843633    
2024-02-26 22:31:42,094 - Epoch: [78][   70/  139]    Overall Loss 0.462026    Objective Loss 0.462026                                        LR 0.000500    Time 0.842876    
2024-02-26 22:31:50,475 - Epoch: [78][   80/  139]    Overall Loss 0.461615    Objective Loss 0.461615                                        LR 0.000500    Time 0.842274    
2024-02-26 22:31:58,867 - Epoch: [78][   90/  139]    Overall Loss 0.461138    Objective Loss 0.461138                                        LR 0.000500    Time 0.841931    
2024-02-26 22:32:07,250 - Epoch: [78][  100/  139]    Overall Loss 0.460538    Objective Loss 0.460538                                        LR 0.000500    Time 0.841561    
2024-02-26 22:32:15,641 - Epoch: [78][  110/  139]    Overall Loss 0.460002    Objective Loss 0.460002                                        LR 0.000500    Time 0.841329    
2024-02-26 22:32:24,093 - Epoch: [78][  120/  139]    Overall Loss 0.459833    Objective Loss 0.459833                                        LR 0.000500    Time 0.841646    
2024-02-26 22:32:32,558 - Epoch: [78][  130/  139]    Overall Loss 0.460004    Objective Loss 0.460004                                        LR 0.000500    Time 0.842012    
2024-02-26 22:32:44,764 - Epoch: [78][  139/  139]    Overall Loss 0.460022    Objective Loss 0.460022    Top1 93.252291    LR 0.000500    Time 0.875303    
2024-02-26 22:32:45,111 - --- validate (epoch=78)-----------
2024-02-26 22:32:45,111 - 1392 samples (32 per mini-batch)
2024-02-26 22:33:21,085 - Epoch: [78][   10/   44]    Loss 0.550327    Top1 86.893490    
2024-02-26 22:33:55,905 - Epoch: [78][   20/   44]    Loss 0.550886    Top1 86.820888    
2024-02-26 22:34:30,346 - Epoch: [78][   30/   44]    Loss 0.545125    Top1 87.196241    
2024-02-26 22:35:04,877 - Epoch: [78][   40/   44]    Loss 0.551757    Top1 86.783096    
2024-02-26 22:35:16,933 - Epoch: [78][   44/   44]    Loss 0.552220    Top1 86.726819    
2024-02-26 22:35:17,200 - ==> Top1: 86.727    Loss: 0.552

2024-02-26 22:35:17,207 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 22:35:17,208 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:35:17,237 - 

2024-02-26 22:35:17,238 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:35:26,079 - Epoch: [79][   10/  139]    Overall Loss 0.458786    Objective Loss 0.458786                                        LR 0.000500    Time 0.884009    
2024-02-26 22:35:34,455 - Epoch: [79][   20/  139]    Overall Loss 0.459557    Objective Loss 0.459557                                        LR 0.000500    Time 0.860773    
2024-02-26 22:35:42,836 - Epoch: [79][   30/  139]    Overall Loss 0.458824    Objective Loss 0.458824                                        LR 0.000500    Time 0.853188    
2024-02-26 22:35:51,210 - Epoch: [79][   40/  139]    Overall Loss 0.455826    Objective Loss 0.455826                                        LR 0.000500    Time 0.849243    
2024-02-26 22:35:59,594 - Epoch: [79][   50/  139]    Overall Loss 0.457101    Objective Loss 0.457101                                        LR 0.000500    Time 0.847064    
2024-02-26 22:36:07,975 - Epoch: [79][   60/  139]    Overall Loss 0.458417    Objective Loss 0.458417                                        LR 0.000500    Time 0.845552    
2024-02-26 22:36:16,364 - Epoch: [79][   70/  139]    Overall Loss 0.457263    Objective Loss 0.457263                                        LR 0.000500    Time 0.844607    
2024-02-26 22:36:24,752 - Epoch: [79][   80/  139]    Overall Loss 0.456545    Objective Loss 0.456545                                        LR 0.000500    Time 0.843865    
2024-02-26 22:36:33,133 - Epoch: [79][   90/  139]    Overall Loss 0.456893    Objective Loss 0.456893                                        LR 0.000500    Time 0.843230    
2024-02-26 22:36:41,520 - Epoch: [79][  100/  139]    Overall Loss 0.456903    Objective Loss 0.456903                                        LR 0.000500    Time 0.842766    
2024-02-26 22:36:49,911 - Epoch: [79][  110/  139]    Overall Loss 0.457117    Objective Loss 0.457117                                        LR 0.000500    Time 0.842427    
2024-02-26 22:36:58,295 - Epoch: [79][  120/  139]    Overall Loss 0.457598    Objective Loss 0.457598                                        LR 0.000500    Time 0.842091    
2024-02-26 22:37:06,685 - Epoch: [79][  130/  139]    Overall Loss 0.457969    Objective Loss 0.457969                                        LR 0.000500    Time 0.841850    
2024-02-26 22:37:18,206 - Epoch: [79][  139/  139]    Overall Loss 0.457583    Objective Loss 0.457583    Top1 92.426468    LR 0.000500    Time 0.870223    
2024-02-26 22:37:18,500 - --- validate (epoch=79)-----------
2024-02-26 22:37:18,500 - 1392 samples (32 per mini-batch)
2024-02-26 22:37:54,904 - Epoch: [79][   10/   44]    Loss 0.537020    Top1 88.237032    
2024-02-26 22:38:30,602 - Epoch: [79][   20/   44]    Loss 0.538881    Top1 88.014307    
2024-02-26 22:39:05,725 - Epoch: [79][   30/   44]    Loss 0.543857    Top1 87.706212    
2024-02-26 22:39:41,478 - Epoch: [79][   40/   44]    Loss 0.536865    Top1 88.113509    
2024-02-26 22:39:53,749 - Epoch: [79][   44/   44]    Loss 0.533651    Top1 88.287802    
2024-02-26 22:39:54,098 - ==> Top1: 88.288    Loss: 0.534

2024-02-26 22:39:54,105 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 22:39:54,105 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:39:54,135 - 

2024-02-26 22:39:54,135 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:40:02,988 - Epoch: [80][   10/  139]    Overall Loss 0.455556    Objective Loss 0.455556                                        LR 0.000500    Time 0.885161    
2024-02-26 22:40:11,369 - Epoch: [80][   20/  139]    Overall Loss 0.462864    Objective Loss 0.462864                                        LR 0.000500    Time 0.861600    
2024-02-26 22:40:19,752 - Epoch: [80][   30/  139]    Overall Loss 0.462052    Objective Loss 0.462052                                        LR 0.000500    Time 0.853835    
2024-02-26 22:40:28,140 - Epoch: [80][   40/  139]    Overall Loss 0.459754    Objective Loss 0.459754                                        LR 0.000500    Time 0.850056    
2024-02-26 22:40:36,521 - Epoch: [80][   50/  139]    Overall Loss 0.457084    Objective Loss 0.457084                                        LR 0.000500    Time 0.847664    
2024-02-26 22:40:44,902 - Epoch: [80][   60/  139]    Overall Loss 0.455876    Objective Loss 0.455876                                        LR 0.000500    Time 0.846050    
2024-02-26 22:40:53,291 - Epoch: [80][   70/  139]    Overall Loss 0.455473    Objective Loss 0.455473                                        LR 0.000500    Time 0.845027    
2024-02-26 22:41:01,755 - Epoch: [80][   80/  139]    Overall Loss 0.455297    Objective Loss 0.455297                                        LR 0.000500    Time 0.845179    
2024-02-26 22:41:10,209 - Epoch: [80][   90/  139]    Overall Loss 0.455885    Objective Loss 0.455885                                        LR 0.000500    Time 0.845188    
2024-02-26 22:41:18,664 - Epoch: [80][  100/  139]    Overall Loss 0.456117    Objective Loss 0.456117                                        LR 0.000500    Time 0.845212    
2024-02-26 22:41:27,118 - Epoch: [80][  110/  139]    Overall Loss 0.457071    Objective Loss 0.457071                                        LR 0.000500    Time 0.845222    
2024-02-26 22:41:35,572 - Epoch: [80][  120/  139]    Overall Loss 0.457060    Objective Loss 0.457060                                        LR 0.000500    Time 0.845230    
2024-02-26 22:41:44,026 - Epoch: [80][  130/  139]    Overall Loss 0.457306    Objective Loss 0.457306                                        LR 0.000500    Time 0.845242    
2024-02-26 22:41:56,494 - Epoch: [80][  139/  139]    Overall Loss 0.456710    Objective Loss 0.456710    Top1 93.669274    LR 0.000500    Time 0.880201    
2024-02-26 22:41:56,761 - --- validate (epoch=80)-----------
2024-02-26 22:41:56,762 - 1392 samples (32 per mini-batch)
2024-02-26 22:42:33,051 - Epoch: [80][   10/   44]    Loss 0.541866    Top1 87.652421    
2024-02-26 22:43:07,051 - Epoch: [80][   20/   44]    Loss 0.526543    Top1 88.590592    
2024-02-26 22:43:43,495 - Epoch: [80][   30/   44]    Loss 0.531412    Top1 88.253441    
2024-02-26 22:44:19,228 - Epoch: [80][   40/   44]    Loss 0.529606    Top1 88.371794    
2024-02-26 22:44:31,555 - Epoch: [80][   44/   44]    Loss 0.529962    Top1 88.337807    
2024-02-26 22:44:31,807 - ==> Top1: 88.338    Loss: 0.530

2024-02-26 22:44:31,814 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 22:44:31,815 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:44:31,851 - 

2024-02-26 22:44:31,851 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:44:40,856 - Epoch: [81][   10/  139]    Overall Loss 0.449641    Objective Loss 0.449641                                        LR 0.000500    Time 0.900316    
2024-02-26 22:44:49,239 - Epoch: [81][   20/  139]    Overall Loss 0.452089    Objective Loss 0.452089                                        LR 0.000500    Time 0.869314    
2024-02-26 22:44:57,619 - Epoch: [81][   30/  139]    Overall Loss 0.452600    Objective Loss 0.452600                                        LR 0.000500    Time 0.858856    
2024-02-26 22:45:06,037 - Epoch: [81][   40/  139]    Overall Loss 0.456411    Objective Loss 0.456411                                        LR 0.000500    Time 0.854572    
2024-02-26 22:45:14,487 - Epoch: [81][   50/  139]    Overall Loss 0.458500    Objective Loss 0.458500                                        LR 0.000500    Time 0.852636    
2024-02-26 22:45:22,938 - Epoch: [81][   60/  139]    Overall Loss 0.459930    Objective Loss 0.459930                                        LR 0.000500    Time 0.851378    
2024-02-26 22:45:31,390 - Epoch: [81][   70/  139]    Overall Loss 0.460706    Objective Loss 0.460706                                        LR 0.000500    Time 0.850482    
2024-02-26 22:45:39,850 - Epoch: [81][   80/  139]    Overall Loss 0.460242    Objective Loss 0.460242                                        LR 0.000500    Time 0.849908    
2024-02-26 22:45:48,310 - Epoch: [81][   90/  139]    Overall Loss 0.460075    Objective Loss 0.460075                                        LR 0.000500    Time 0.849465    
2024-02-26 22:45:56,774 - Epoch: [81][  100/  139]    Overall Loss 0.459842    Objective Loss 0.459842                                        LR 0.000500    Time 0.849147    
2024-02-26 22:46:05,239 - Epoch: [81][  110/  139]    Overall Loss 0.460723    Objective Loss 0.460723                                        LR 0.000500    Time 0.848896    
2024-02-26 22:46:13,701 - Epoch: [81][  120/  139]    Overall Loss 0.460949    Objective Loss 0.460949                                        LR 0.000500    Time 0.848663    
2024-02-26 22:46:22,161 - Epoch: [81][  130/  139]    Overall Loss 0.460807    Objective Loss 0.460807                                        LR 0.000500    Time 0.848452    
2024-02-26 22:46:34,383 - Epoch: [81][  139/  139]    Overall Loss 0.460961    Objective Loss 0.460961    Top1 92.778940    LR 0.000500    Time 0.881442    
2024-02-26 22:46:34,641 - --- validate (epoch=81)-----------
2024-02-26 22:46:34,642 - 1392 samples (32 per mini-batch)
2024-02-26 22:47:10,090 - Epoch: [81][   10/   44]    Loss 0.528748    Top1 88.829257    
2024-02-26 22:47:44,812 - Epoch: [81][   20/   44]    Loss 0.544216    Top1 87.949656    
2024-02-26 22:48:19,831 - Epoch: [81][   30/   44]    Loss 0.545744    Top1 87.854496    
2024-02-26 22:48:54,794 - Epoch: [81][   40/   44]    Loss 0.543990    Top1 87.951776    
2024-02-26 22:49:07,234 - Epoch: [81][   44/   44]    Loss 0.545185    Top1 87.921475    
2024-02-26 22:49:07,579 - ==> Top1: 87.921    Loss: 0.545

2024-02-26 22:49:07,587 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 22:49:07,588 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:49:07,622 - 

2024-02-26 22:49:07,623 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:49:16,387 - Epoch: [82][   10/  139]    Overall Loss 0.461413    Objective Loss 0.461413                                        LR 0.000500    Time 0.876315    
2024-02-26 22:49:24,780 - Epoch: [82][   20/  139]    Overall Loss 0.461721    Objective Loss 0.461721                                        LR 0.000500    Time 0.857789    
2024-02-26 22:49:33,226 - Epoch: [82][   30/  139]    Overall Loss 0.459447    Objective Loss 0.459447                                        LR 0.000500    Time 0.853351    
2024-02-26 22:49:41,683 - Epoch: [82][   40/  139]    Overall Loss 0.457674    Objective Loss 0.457674                                        LR 0.000500    Time 0.851433    
2024-02-26 22:49:50,134 - Epoch: [82][   50/  139]    Overall Loss 0.457891    Objective Loss 0.457891                                        LR 0.000500    Time 0.850150    
2024-02-26 22:49:58,588 - Epoch: [82][   60/  139]    Overall Loss 0.458769    Objective Loss 0.458769                                        LR 0.000500    Time 0.849345    
2024-02-26 22:50:07,043 - Epoch: [82][   70/  139]    Overall Loss 0.458385    Objective Loss 0.458385                                        LR 0.000500    Time 0.848786    
2024-02-26 22:50:15,496 - Epoch: [82][   80/  139]    Overall Loss 0.458416    Objective Loss 0.458416                                        LR 0.000500    Time 0.848333    
2024-02-26 22:50:23,951 - Epoch: [82][   90/  139]    Overall Loss 0.458716    Objective Loss 0.458716                                        LR 0.000500    Time 0.848015    
2024-02-26 22:50:32,407 - Epoch: [82][  100/  139]    Overall Loss 0.457946    Objective Loss 0.457946                                        LR 0.000500    Time 0.847761    
2024-02-26 22:50:40,858 - Epoch: [82][  110/  139]    Overall Loss 0.458897    Objective Loss 0.458897                                        LR 0.000500    Time 0.847516    
2024-02-26 22:50:49,315 - Epoch: [82][  120/  139]    Overall Loss 0.458367    Objective Loss 0.458367                                        LR 0.000500    Time 0.847361    
2024-02-26 22:50:57,773 - Epoch: [82][  130/  139]    Overall Loss 0.459059    Objective Loss 0.459059                                        LR 0.000500    Time 0.847232    
2024-02-26 22:51:10,352 - Epoch: [82][  139/  139]    Overall Loss 0.459790    Objective Loss 0.459790    Top1 92.043639    LR 0.000500    Time 0.882870    
2024-02-26 22:51:10,652 - --- validate (epoch=82)-----------
2024-02-26 22:51:10,653 - 1392 samples (32 per mini-batch)
2024-02-26 22:51:47,480 - Epoch: [82][   10/   44]    Loss 0.563294    Top1 86.680537    
2024-02-26 22:52:22,051 - Epoch: [82][   20/   44]    Loss 0.552658    Top1 87.233334    
2024-02-26 22:52:57,707 - Epoch: [82][   30/   44]    Loss 0.543121    Top1 87.766675    
2024-02-26 22:53:32,594 - Epoch: [82][   40/   44]    Loss 0.543485    Top1 87.753029    
2024-02-26 22:53:45,016 - Epoch: [82][   44/   44]    Loss 0.542650    Top1 87.769375    
2024-02-26 22:53:45,275 - ==> Top1: 87.769    Loss: 0.543

2024-02-26 22:53:45,283 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 22:53:45,283 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:53:45,312 - 

2024-02-26 22:53:45,312 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:53:54,147 - Epoch: [83][   10/  139]    Overall Loss 0.471738    Objective Loss 0.471738                                        LR 0.000500    Time 0.883339    
2024-02-26 22:54:02,560 - Epoch: [83][   20/  139]    Overall Loss 0.466400    Objective Loss 0.466400                                        LR 0.000500    Time 0.862293    
2024-02-26 22:54:11,013 - Epoch: [83][   30/  139]    Overall Loss 0.464005    Objective Loss 0.464005                                        LR 0.000500    Time 0.856595    
2024-02-26 22:54:19,456 - Epoch: [83][   40/  139]    Overall Loss 0.468282    Objective Loss 0.468282                                        LR 0.000500    Time 0.853501    
2024-02-26 22:54:27,914 - Epoch: [83][   50/  139]    Overall Loss 0.465940    Objective Loss 0.465940                                        LR 0.000500    Time 0.851951    
2024-02-26 22:54:36,375 - Epoch: [83][   60/  139]    Overall Loss 0.466184    Objective Loss 0.466184                                        LR 0.000500    Time 0.850964    
2024-02-26 22:54:44,833 - Epoch: [83][   70/  139]    Overall Loss 0.464090    Objective Loss 0.464090                                        LR 0.000500    Time 0.850211    
2024-02-26 22:54:53,291 - Epoch: [83][   80/  139]    Overall Loss 0.464393    Objective Loss 0.464393                                        LR 0.000500    Time 0.849657    
2024-02-26 22:55:01,749 - Epoch: [83][   90/  139]    Overall Loss 0.463429    Objective Loss 0.463429                                        LR 0.000500    Time 0.849216    
2024-02-26 22:55:10,206 - Epoch: [83][  100/  139]    Overall Loss 0.462723    Objective Loss 0.462723                                        LR 0.000500    Time 0.848861    
2024-02-26 22:55:18,665 - Epoch: [83][  110/  139]    Overall Loss 0.462397    Objective Loss 0.462397                                        LR 0.000500    Time 0.848582    
2024-02-26 22:55:27,121 - Epoch: [83][  120/  139]    Overall Loss 0.461757    Objective Loss 0.461757                                        LR 0.000500    Time 0.848324    
2024-02-26 22:55:35,583 - Epoch: [83][  130/  139]    Overall Loss 0.460535    Objective Loss 0.460535                                        LR 0.000500    Time 0.848158    
2024-02-26 22:55:47,944 - Epoch: [83][  139/  139]    Overall Loss 0.459870    Objective Loss 0.459870    Top1 94.523234    LR 0.000500    Time 0.882166    
2024-02-26 22:55:48,217 - --- validate (epoch=83)-----------
2024-02-26 22:55:48,218 - 1392 samples (32 per mini-batch)
2024-02-26 22:56:24,225 - Epoch: [83][   10/   44]    Loss 0.535493    Top1 88.266428    
2024-02-26 22:56:57,523 - Epoch: [83][   20/   44]    Loss 0.528954    Top1 88.637051    
2024-02-26 22:57:32,050 - Epoch: [83][   30/   44]    Loss 0.530127    Top1 88.564599    
2024-02-26 22:58:07,536 - Epoch: [83][   40/   44]    Loss 0.529389    Top1 88.600053    
2024-02-26 22:58:19,678 - Epoch: [83][   44/   44]    Loss 0.529684    Top1 88.618123    
2024-02-26 22:58:19,947 - ==> Top1: 88.618    Loss: 0.530

2024-02-26 22:58:19,955 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 22:58:19,955 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 22:58:19,984 - 

2024-02-26 22:58:19,984 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 22:58:28,742 - Epoch: [84][   10/  139]    Overall Loss 0.447613    Objective Loss 0.447613                                        LR 0.000500    Time 0.875696    
2024-02-26 22:58:37,128 - Epoch: [84][   20/  139]    Overall Loss 0.450769    Objective Loss 0.450769                                        LR 0.000500    Time 0.857113    
2024-02-26 22:58:45,508 - Epoch: [84][   30/  139]    Overall Loss 0.449859    Objective Loss 0.449859                                        LR 0.000500    Time 0.850721    
2024-02-26 22:58:53,923 - Epoch: [84][   40/  139]    Overall Loss 0.452483    Objective Loss 0.452483                                        LR 0.000500    Time 0.848410    
2024-02-26 22:59:02,375 - Epoch: [84][   50/  139]    Overall Loss 0.454373    Objective Loss 0.454373                                        LR 0.000500    Time 0.847756    
2024-02-26 22:59:10,822 - Epoch: [84][   60/  139]    Overall Loss 0.455523    Objective Loss 0.455523                                        LR 0.000500    Time 0.847231    
2024-02-26 22:59:19,273 - Epoch: [84][   70/  139]    Overall Loss 0.455061    Objective Loss 0.455061                                        LR 0.000500    Time 0.846923    
2024-02-26 22:59:27,724 - Epoch: [84][   80/  139]    Overall Loss 0.456141    Objective Loss 0.456141                                        LR 0.000500    Time 0.846683    
2024-02-26 22:59:36,181 - Epoch: [84][   90/  139]    Overall Loss 0.456396    Objective Loss 0.456396                                        LR 0.000500    Time 0.846566    
2024-02-26 22:59:44,640 - Epoch: [84][  100/  139]    Overall Loss 0.457255    Objective Loss 0.457255                                        LR 0.000500    Time 0.846491    
2024-02-26 22:59:53,098 - Epoch: [84][  110/  139]    Overall Loss 0.457408    Objective Loss 0.457408                                        LR 0.000500    Time 0.846422    
2024-02-26 23:00:01,548 - Epoch: [84][  120/  139]    Overall Loss 0.458226    Objective Loss 0.458226                                        LR 0.000500    Time 0.846301    
2024-02-26 23:00:10,002 - Epoch: [84][  130/  139]    Overall Loss 0.458807    Objective Loss 0.458807                                        LR 0.000500    Time 0.846222    
2024-02-26 23:00:22,515 - Epoch: [84][  139/  139]    Overall Loss 0.459438    Objective Loss 0.459438    Top1 91.821436    LR 0.000500    Time 0.881450    
2024-02-26 23:00:22,796 - --- validate (epoch=84)-----------
2024-02-26 23:00:22,796 - 1392 samples (32 per mini-batch)
2024-02-26 23:00:59,508 - Epoch: [84][   10/   44]    Loss 0.544336    Top1 87.753097    
2024-02-26 23:01:35,229 - Epoch: [84][   20/   44]    Loss 0.543972    Top1 87.772712    
2024-02-26 23:02:10,486 - Epoch: [84][   30/   44]    Loss 0.544656    Top1 87.713807    
2024-02-26 23:02:45,313 - Epoch: [84][   40/   44]    Loss 0.540524    Top1 87.964578    
2024-02-26 23:02:57,408 - Epoch: [84][   44/   44]    Loss 0.539847    Top1 87.993957    
2024-02-26 23:02:57,683 - ==> Top1: 87.994    Loss: 0.540

2024-02-26 23:02:57,690 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:02:57,691 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:02:57,719 - 

2024-02-26 23:02:57,719 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:03:06,455 - Epoch: [85][   10/  139]    Overall Loss 0.461131    Objective Loss 0.461131                                        LR 0.000500    Time 0.873493    
2024-02-26 23:03:14,829 - Epoch: [85][   20/  139]    Overall Loss 0.464731    Objective Loss 0.464731                                        LR 0.000500    Time 0.855410    
2024-02-26 23:03:23,205 - Epoch: [85][   30/  139]    Overall Loss 0.459237    Objective Loss 0.459237                                        LR 0.000500    Time 0.849451    
2024-02-26 23:03:31,586 - Epoch: [85][   40/  139]    Overall Loss 0.459934    Objective Loss 0.459934                                        LR 0.000500    Time 0.846604    
2024-02-26 23:03:39,968 - Epoch: [85][   50/  139]    Overall Loss 0.459661    Objective Loss 0.459661                                        LR 0.000500    Time 0.844906    
2024-02-26 23:03:48,351 - Epoch: [85][   60/  139]    Overall Loss 0.457236    Objective Loss 0.457236                                        LR 0.000500    Time 0.843795    
2024-02-26 23:03:56,733 - Epoch: [85][   70/  139]    Overall Loss 0.457859    Objective Loss 0.457859                                        LR 0.000500    Time 0.842988    
2024-02-26 23:04:05,112 - Epoch: [85][   80/  139]    Overall Loss 0.457235    Objective Loss 0.457235                                        LR 0.000500    Time 0.842356    
2024-02-26 23:04:13,498 - Epoch: [85][   90/  139]    Overall Loss 0.456408    Objective Loss 0.456408                                        LR 0.000500    Time 0.841934    
2024-02-26 23:04:21,883 - Epoch: [85][  100/  139]    Overall Loss 0.455583    Objective Loss 0.455583                                        LR 0.000500    Time 0.841582    
2024-02-26 23:04:30,267 - Epoch: [85][  110/  139]    Overall Loss 0.456122    Objective Loss 0.456122                                        LR 0.000500    Time 0.841289    
2024-02-26 23:04:38,655 - Epoch: [85][  120/  139]    Overall Loss 0.455339    Objective Loss 0.455339                                        LR 0.000500    Time 0.841079    
2024-02-26 23:04:47,040 - Epoch: [85][  130/  139]    Overall Loss 0.454746    Objective Loss 0.454746                                        LR 0.000500    Time 0.840872    
2024-02-26 23:04:59,200 - Epoch: [85][  139/  139]    Overall Loss 0.454913    Objective Loss 0.454913    Top1 93.178113    LR 0.000500    Time 0.873908    
2024-02-26 23:04:59,525 - --- validate (epoch=85)-----------
2024-02-26 23:04:59,526 - 1392 samples (32 per mini-batch)
2024-02-26 23:05:35,156 - Epoch: [85][   10/   44]    Loss 0.520834    Top1 88.999447    
2024-02-26 23:06:10,011 - Epoch: [85][   20/   44]    Loss 0.522979    Top1 88.922465    
2024-02-26 23:06:44,956 - Epoch: [85][   30/   44]    Loss 0.520117    Top1 89.069096    
2024-02-26 23:07:19,407 - Epoch: [85][   40/   44]    Loss 0.519786    Top1 89.111391    
2024-02-26 23:07:31,515 - Epoch: [85][   44/   44]    Loss 0.518627    Top1 89.159939    
2024-02-26 23:07:31,780 - ==> Top1: 89.160    Loss: 0.519

2024-02-26 23:07:31,787 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:07:31,788 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:07:31,816 - 

2024-02-26 23:07:31,816 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:07:40,662 - Epoch: [86][   10/  139]    Overall Loss 0.448177    Objective Loss 0.448177                                        LR 0.000500    Time 0.884454    
2024-02-26 23:07:49,095 - Epoch: [86][   20/  139]    Overall Loss 0.452860    Objective Loss 0.452860                                        LR 0.000500    Time 0.863825    
2024-02-26 23:07:57,540 - Epoch: [86][   30/  139]    Overall Loss 0.454367    Objective Loss 0.454367                                        LR 0.000500    Time 0.857352    
2024-02-26 23:08:05,989 - Epoch: [86][   40/  139]    Overall Loss 0.454167    Objective Loss 0.454167                                        LR 0.000500    Time 0.854239    
2024-02-26 23:08:14,445 - Epoch: [86][   50/  139]    Overall Loss 0.455080    Objective Loss 0.455080                                        LR 0.000500    Time 0.852492    
2024-02-26 23:08:22,898 - Epoch: [86][   60/  139]    Overall Loss 0.455292    Objective Loss 0.455292                                        LR 0.000500    Time 0.851275    
2024-02-26 23:08:31,347 - Epoch: [86][   70/  139]    Overall Loss 0.454246    Objective Loss 0.454246                                        LR 0.000500    Time 0.850359    
2024-02-26 23:08:39,801 - Epoch: [86][   80/  139]    Overall Loss 0.455091    Objective Loss 0.455091                                        LR 0.000500    Time 0.849736    
2024-02-26 23:08:48,254 - Epoch: [86][   90/  139]    Overall Loss 0.455487    Objective Loss 0.455487                                        LR 0.000500    Time 0.849235    
2024-02-26 23:08:56,708 - Epoch: [86][  100/  139]    Overall Loss 0.454894    Objective Loss 0.454894                                        LR 0.000500    Time 0.848842    
2024-02-26 23:09:05,164 - Epoch: [86][  110/  139]    Overall Loss 0.454759    Objective Loss 0.454759                                        LR 0.000500    Time 0.848539    
2024-02-26 23:09:13,616 - Epoch: [86][  120/  139]    Overall Loss 0.454569    Objective Loss 0.454569                                        LR 0.000500    Time 0.848258    
2024-02-26 23:09:22,070 - Epoch: [86][  130/  139]    Overall Loss 0.454628    Objective Loss 0.454628                                        LR 0.000500    Time 0.848032    
2024-02-26 23:09:34,159 - Epoch: [86][  139/  139]    Overall Loss 0.453905    Objective Loss 0.453905    Top1 93.709499    LR 0.000500    Time 0.880088    
2024-02-26 23:09:34,881 - --- validate (epoch=86)-----------
2024-02-26 23:09:34,881 - 1392 samples (32 per mini-batch)
2024-02-26 23:10:10,498 - Epoch: [86][   10/   44]    Loss 0.532282    Top1 88.521401    
2024-02-26 23:10:46,667 - Epoch: [86][   20/   44]    Loss 0.524653    Top1 88.993629    
2024-02-26 23:11:22,014 - Epoch: [86][   30/   44]    Loss 0.524446    Top1 89.026265    
2024-02-26 23:11:56,498 - Epoch: [86][   40/   44]    Loss 0.521884    Top1 89.160456    
2024-02-26 23:12:09,138 - Epoch: [86][   44/   44]    Loss 0.522893    Top1 89.074869    
2024-02-26 23:12:09,369 - ==> Top1: 89.075    Loss: 0.523

2024-02-26 23:12:09,376 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:12:09,376 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:12:09,407 - 

2024-02-26 23:12:09,407 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:12:18,236 - Epoch: [87][   10/  139]    Overall Loss 0.453970    Objective Loss 0.453970                                        LR 0.000500    Time 0.882804    
2024-02-26 23:12:26,618 - Epoch: [87][   20/  139]    Overall Loss 0.456434    Objective Loss 0.456434                                        LR 0.000500    Time 0.860488    
2024-02-26 23:12:34,995 - Epoch: [87][   30/  139]    Overall Loss 0.453711    Objective Loss 0.453711                                        LR 0.000500    Time 0.852880    
2024-02-26 23:12:43,378 - Epoch: [87][   40/  139]    Overall Loss 0.452391    Objective Loss 0.452391                                        LR 0.000500    Time 0.849217    
2024-02-26 23:12:51,762 - Epoch: [87][   50/  139]    Overall Loss 0.451110    Objective Loss 0.451110                                        LR 0.000500    Time 0.847039    
2024-02-26 23:13:00,147 - Epoch: [87][   60/  139]    Overall Loss 0.451987    Objective Loss 0.451987                                        LR 0.000500    Time 0.845602    
2024-02-26 23:13:08,533 - Epoch: [87][   70/  139]    Overall Loss 0.451429    Objective Loss 0.451429                                        LR 0.000500    Time 0.844595    
2024-02-26 23:13:16,916 - Epoch: [87][   80/  139]    Overall Loss 0.452409    Objective Loss 0.452409                                        LR 0.000500    Time 0.843801    
2024-02-26 23:13:25,300 - Epoch: [87][   90/  139]    Overall Loss 0.452312    Objective Loss 0.452312                                        LR 0.000500    Time 0.843196    
2024-02-26 23:13:33,684 - Epoch: [87][  100/  139]    Overall Loss 0.452557    Objective Loss 0.452557                                        LR 0.000500    Time 0.842721    
2024-02-26 23:13:42,081 - Epoch: [87][  110/  139]    Overall Loss 0.453624    Objective Loss 0.453624                                        LR 0.000500    Time 0.842441    
2024-02-26 23:13:50,466 - Epoch: [87][  120/  139]    Overall Loss 0.454805    Objective Loss 0.454805                                        LR 0.000500    Time 0.842106    
2024-02-26 23:13:58,857 - Epoch: [87][  130/  139]    Overall Loss 0.455858    Objective Loss 0.455858                                        LR 0.000500    Time 0.841874    
2024-02-26 23:14:11,497 - Epoch: [87][  139/  139]    Overall Loss 0.455476    Objective Loss 0.455476    Top1 92.778280    LR 0.000500    Time 0.878295    
2024-02-26 23:14:11,741 - --- validate (epoch=87)-----------
2024-02-26 23:14:11,742 - 1392 samples (32 per mini-batch)
2024-02-26 23:14:48,165 - Epoch: [87][   10/   44]    Loss 0.537558    Top1 88.111968    
2024-02-26 23:15:24,559 - Epoch: [87][   20/   44]    Loss 0.534570    Top1 88.340985    
2024-02-26 23:15:59,383 - Epoch: [87][   30/   44]    Loss 0.538544    Top1 88.112936    
2024-02-26 23:16:34,740 - Epoch: [87][   40/   44]    Loss 0.537301    Top1 88.189935    
2024-02-26 23:16:47,069 - Epoch: [87][   44/   44]    Loss 0.536752    Top1 88.215176    
2024-02-26 23:16:47,346 - ==> Top1: 88.215    Loss: 0.537

2024-02-26 23:16:47,354 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:16:47,354 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:16:47,384 - 

2024-02-26 23:16:47,384 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:16:56,233 - Epoch: [88][   10/  139]    Overall Loss 0.445940    Objective Loss 0.445940                                        LR 0.000500    Time 0.884760    
2024-02-26 23:17:04,620 - Epoch: [88][   20/  139]    Overall Loss 0.447927    Objective Loss 0.447927                                        LR 0.000500    Time 0.861677    
2024-02-26 23:17:13,068 - Epoch: [88][   30/  139]    Overall Loss 0.446546    Objective Loss 0.446546                                        LR 0.000500    Time 0.856038    
2024-02-26 23:17:21,539 - Epoch: [88][   40/  139]    Overall Loss 0.447535    Objective Loss 0.447535                                        LR 0.000500    Time 0.853781    
2024-02-26 23:17:30,022 - Epoch: [88][   50/  139]    Overall Loss 0.450095    Objective Loss 0.450095                                        LR 0.000500    Time 0.852641    
2024-02-26 23:17:38,484 - Epoch: [88][   60/  139]    Overall Loss 0.451049    Objective Loss 0.451049                                        LR 0.000500    Time 0.851549    
2024-02-26 23:17:46,962 - Epoch: [88][   70/  139]    Overall Loss 0.453686    Objective Loss 0.453686                                        LR 0.000500    Time 0.851007    
2024-02-26 23:17:55,425 - Epoch: [88][   80/  139]    Overall Loss 0.459750    Objective Loss 0.459750                                        LR 0.000500    Time 0.850410    
2024-02-26 23:18:03,888 - Epoch: [88][   90/  139]    Overall Loss 0.461871    Objective Loss 0.461871                                        LR 0.000500    Time 0.849935    
2024-02-26 23:18:12,357 - Epoch: [88][  100/  139]    Overall Loss 0.463391    Objective Loss 0.463391                                        LR 0.000500    Time 0.849621    
2024-02-26 23:18:20,801 - Epoch: [88][  110/  139]    Overall Loss 0.463538    Objective Loss 0.463538                                        LR 0.000500    Time 0.849137    
2024-02-26 23:18:29,257 - Epoch: [88][  120/  139]    Overall Loss 0.464251    Objective Loss 0.464251                                        LR 0.000500    Time 0.848837    
2024-02-26 23:18:37,719 - Epoch: [88][  130/  139]    Overall Loss 0.463992    Objective Loss 0.463992                                        LR 0.000500    Time 0.848634    
2024-02-26 23:18:49,687 - Epoch: [88][  139/  139]    Overall Loss 0.464506    Objective Loss 0.464506    Top1 92.718831    LR 0.000500    Time 0.879776    
2024-02-26 23:18:49,984 - --- validate (epoch=88)-----------
2024-02-26 23:18:49,984 - 1392 samples (32 per mini-batch)
2024-02-26 23:19:26,977 - Epoch: [88][   10/   44]    Loss 0.532104    Top1 88.611153    
2024-02-26 23:20:01,570 - Epoch: [88][   20/   44]    Loss 0.528442    Top1 88.769855    
2024-02-26 23:20:36,540 - Epoch: [88][   30/   44]    Loss 0.529122    Top1 88.738825    
2024-02-26 23:21:10,998 - Epoch: [88][   40/   44]    Loss 0.530877    Top1 88.606813    
2024-02-26 23:21:23,167 - Epoch: [88][   44/   44]    Loss 0.530198    Top1 88.621771    
2024-02-26 23:21:23,450 - ==> Top1: 88.622    Loss: 0.530

2024-02-26 23:21:23,457 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:21:23,458 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:21:23,488 - 

2024-02-26 23:21:23,488 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:21:32,387 - Epoch: [89][   10/  139]    Overall Loss 0.456096    Objective Loss 0.456096                                        LR 0.000500    Time 0.889797    
2024-02-26 23:21:40,778 - Epoch: [89][   20/  139]    Overall Loss 0.451697    Objective Loss 0.451697                                        LR 0.000500    Time 0.864371    
2024-02-26 23:21:49,219 - Epoch: [89][   30/  139]    Overall Loss 0.450447    Objective Loss 0.450447                                        LR 0.000500    Time 0.857596    
2024-02-26 23:21:57,667 - Epoch: [89][   40/  139]    Overall Loss 0.451217    Objective Loss 0.451217                                        LR 0.000500    Time 0.854391    
2024-02-26 23:22:06,121 - Epoch: [89][   50/  139]    Overall Loss 0.452229    Objective Loss 0.452229                                        LR 0.000500    Time 0.852581    
2024-02-26 23:22:14,570 - Epoch: [89][   60/  139]    Overall Loss 0.453679    Objective Loss 0.453679                                        LR 0.000500    Time 0.851279    
2024-02-26 23:22:23,026 - Epoch: [89][   70/  139]    Overall Loss 0.454733    Objective Loss 0.454733                                        LR 0.000500    Time 0.850463    
2024-02-26 23:22:31,480 - Epoch: [89][   80/  139]    Overall Loss 0.454218    Objective Loss 0.454218                                        LR 0.000500    Time 0.849821    
2024-02-26 23:22:39,936 - Epoch: [89][   90/  139]    Overall Loss 0.453453    Objective Loss 0.453453                                        LR 0.000500    Time 0.849335    
2024-02-26 23:22:48,389 - Epoch: [89][  100/  139]    Overall Loss 0.453153    Objective Loss 0.453153                                        LR 0.000500    Time 0.848927    
2024-02-26 23:22:56,858 - Epoch: [89][  110/  139]    Overall Loss 0.452079    Objective Loss 0.452079                                        LR 0.000500    Time 0.848739    
2024-02-26 23:23:05,309 - Epoch: [89][  120/  139]    Overall Loss 0.453027    Objective Loss 0.453027                                        LR 0.000500    Time 0.848431    
2024-02-26 23:23:13,765 - Epoch: [89][  130/  139]    Overall Loss 0.453431    Objective Loss 0.453431                                        LR 0.000500    Time 0.848203    
2024-02-26 23:23:26,078 - Epoch: [89][  139/  139]    Overall Loss 0.453876    Objective Loss 0.453876    Top1 91.033509    LR 0.000500    Time 0.881866    
2024-02-26 23:23:26,380 - --- validate (epoch=89)-----------
2024-02-26 23:23:26,381 - 1392 samples (32 per mini-batch)
2024-02-26 23:24:01,268 - Epoch: [89][   10/   44]    Loss 0.522488    Top1 89.105250    
2024-02-26 23:24:36,980 - Epoch: [89][   20/   44]    Loss 0.528320    Top1 88.776103    
2024-02-26 23:25:11,639 - Epoch: [89][   30/   44]    Loss 0.527815    Top1 88.807402    
2024-02-26 23:25:45,545 - Epoch: [89][   40/   44]    Loss 0.527301    Top1 88.833380    
2024-02-26 23:25:57,440 - Epoch: [89][   44/   44]    Loss 0.528232    Top1 88.817998    
2024-02-26 23:25:57,701 - ==> Top1: 88.818    Loss: 0.528

2024-02-26 23:25:57,709 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:25:57,710 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:25:57,745 - 

2024-02-26 23:25:57,745 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:26:06,501 - Epoch: [90][   10/  139]    Overall Loss 0.461628    Objective Loss 0.461628                                        LR 0.000500    Time 0.875403    
2024-02-26 23:26:14,885 - Epoch: [90][   20/  139]    Overall Loss 0.462019    Objective Loss 0.462019                                        LR 0.000500    Time 0.856913    
2024-02-26 23:26:23,266 - Epoch: [90][   30/  139]    Overall Loss 0.459536    Objective Loss 0.459536                                        LR 0.000500    Time 0.850618    
2024-02-26 23:26:31,652 - Epoch: [90][   40/  139]    Overall Loss 0.456947    Objective Loss 0.456947                                        LR 0.000500    Time 0.847592    
2024-02-26 23:26:40,033 - Epoch: [90][   50/  139]    Overall Loss 0.457102    Objective Loss 0.457102                                        LR 0.000500    Time 0.845700    
2024-02-26 23:26:48,424 - Epoch: [90][   60/  139]    Overall Loss 0.456268    Objective Loss 0.456268                                        LR 0.000500    Time 0.844582    
2024-02-26 23:26:56,810 - Epoch: [90][   70/  139]    Overall Loss 0.457737    Objective Loss 0.457737                                        LR 0.000500    Time 0.843716    
2024-02-26 23:27:05,194 - Epoch: [90][   80/  139]    Overall Loss 0.456101    Objective Loss 0.456101                                        LR 0.000500    Time 0.843048    
2024-02-26 23:27:13,582 - Epoch: [90][   90/  139]    Overall Loss 0.455719    Objective Loss 0.455719                                        LR 0.000500    Time 0.842571    
2024-02-26 23:27:22,001 - Epoch: [90][  100/  139]    Overall Loss 0.455071    Objective Loss 0.455071                                        LR 0.000500    Time 0.842498    
2024-02-26 23:27:30,461 - Epoch: [90][  110/  139]    Overall Loss 0.454389    Objective Loss 0.454389                                        LR 0.000500    Time 0.842809    
2024-02-26 23:27:38,924 - Epoch: [90][  120/  139]    Overall Loss 0.454400    Objective Loss 0.454400                                        LR 0.000500    Time 0.843091    
2024-02-26 23:27:47,375 - Epoch: [90][  130/  139]    Overall Loss 0.454160    Objective Loss 0.454160                                        LR 0.000500    Time 0.843246    
2024-02-26 23:27:59,827 - Epoch: [90][  139/  139]    Overall Loss 0.453616    Objective Loss 0.453616    Top1 94.250039    LR 0.000500    Time 0.878227    
2024-02-26 23:28:00,072 - --- validate (epoch=90)-----------
2024-02-26 23:28:00,073 - 1392 samples (32 per mini-batch)
2024-02-26 23:28:36,190 - Epoch: [90][   10/   44]    Loss 0.526890    Top1 88.757662    
2024-02-26 23:29:11,920 - Epoch: [90][   20/   44]    Loss 0.530493    Top1 88.525522    
2024-02-26 23:29:46,991 - Epoch: [90][   30/   44]    Loss 0.527459    Top1 88.700268    
2024-02-26 23:30:22,000 - Epoch: [90][   40/   44]    Loss 0.527912    Top1 88.713608    
2024-02-26 23:30:34,502 - Epoch: [90][   44/   44]    Loss 0.529090    Top1 88.710350    
2024-02-26 23:30:34,795 - ==> Top1: 88.710    Loss: 0.529

2024-02-26 23:30:34,802 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:30:34,803 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:30:34,839 - 

2024-02-26 23:30:34,839 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:30:43,579 - Epoch: [91][   10/  139]    Overall Loss 0.442942    Objective Loss 0.442942                                        LR 0.000500    Time 0.873845    
2024-02-26 23:30:52,017 - Epoch: [91][   20/  139]    Overall Loss 0.447787    Objective Loss 0.447787                                        LR 0.000500    Time 0.858786    
2024-02-26 23:31:00,482 - Epoch: [91][   30/  139]    Overall Loss 0.449033    Objective Loss 0.449033                                        LR 0.000500    Time 0.854667    
2024-02-26 23:31:08,957 - Epoch: [91][   40/  139]    Overall Loss 0.451974    Objective Loss 0.451974                                        LR 0.000500    Time 0.852850    
2024-02-26 23:31:17,421 - Epoch: [91][   50/  139]    Overall Loss 0.453841    Objective Loss 0.453841                                        LR 0.000500    Time 0.851544    
2024-02-26 23:31:25,890 - Epoch: [91][   60/  139]    Overall Loss 0.455569    Objective Loss 0.455569                                        LR 0.000500    Time 0.850755    
2024-02-26 23:31:34,356 - Epoch: [91][   70/  139]    Overall Loss 0.455010    Objective Loss 0.455010                                        LR 0.000500    Time 0.850150    
2024-02-26 23:31:42,828 - Epoch: [91][   80/  139]    Overall Loss 0.454226    Objective Loss 0.454226                                        LR 0.000500    Time 0.849783    
2024-02-26 23:31:51,305 - Epoch: [91][   90/  139]    Overall Loss 0.454122    Objective Loss 0.454122                                        LR 0.000500    Time 0.849541    
2024-02-26 23:31:59,773 - Epoch: [91][  100/  139]    Overall Loss 0.455237    Objective Loss 0.455237                                        LR 0.000500    Time 0.849255    
2024-02-26 23:32:08,238 - Epoch: [91][  110/  139]    Overall Loss 0.455677    Objective Loss 0.455677                                        LR 0.000500    Time 0.848994    
2024-02-26 23:32:16,707 - Epoch: [91][  120/  139]    Overall Loss 0.456022    Objective Loss 0.456022                                        LR 0.000500    Time 0.848821    
2024-02-26 23:32:25,174 - Epoch: [91][  130/  139]    Overall Loss 0.456378    Objective Loss 0.456378                                        LR 0.000500    Time 0.848650    
2024-02-26 23:32:38,022 - Epoch: [91][  139/  139]    Overall Loss 0.455982    Objective Loss 0.455982    Top1 93.931225    LR 0.000500    Time 0.886128    
2024-02-26 23:32:38,257 - --- validate (epoch=91)-----------
2024-02-26 23:32:38,258 - 1392 samples (32 per mini-batch)
2024-02-26 23:33:13,925 - Epoch: [91][   10/   44]    Loss 0.547851    Top1 87.672803    
2024-02-26 23:33:48,544 - Epoch: [91][   20/   44]    Loss 0.546379    Top1 87.678279    
2024-02-26 23:34:24,424 - Epoch: [91][   30/   44]    Loss 0.542805    Top1 87.866787    
2024-02-26 23:35:00,215 - Epoch: [91][   40/   44]    Loss 0.543086    Top1 87.828713    
2024-02-26 23:35:12,565 - Epoch: [91][   44/   44]    Loss 0.543537    Top1 87.818059    
2024-02-26 23:35:12,859 - ==> Top1: 87.818    Loss: 0.544

2024-02-26 23:35:12,866 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:35:12,866 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:35:12,897 - 

2024-02-26 23:35:12,897 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:35:21,770 - Epoch: [92][   10/  139]    Overall Loss 0.461681    Objective Loss 0.461681                                        LR 0.000500    Time 0.887204    
2024-02-26 23:35:30,147 - Epoch: [92][   20/  139]    Overall Loss 0.456424    Objective Loss 0.456424                                        LR 0.000500    Time 0.862404    
2024-02-26 23:35:38,522 - Epoch: [92][   30/  139]    Overall Loss 0.457713    Objective Loss 0.457713                                        LR 0.000500    Time 0.854102    
2024-02-26 23:35:46,935 - Epoch: [92][   40/  139]    Overall Loss 0.458032    Objective Loss 0.458032                                        LR 0.000500    Time 0.850875    
2024-02-26 23:35:55,381 - Epoch: [92][   50/  139]    Overall Loss 0.454573    Objective Loss 0.454573                                        LR 0.000500    Time 0.849615    
2024-02-26 23:36:03,834 - Epoch: [92][   60/  139]    Overall Loss 0.453762    Objective Loss 0.453762                                        LR 0.000500    Time 0.848879    
2024-02-26 23:36:12,292 - Epoch: [92][   70/  139]    Overall Loss 0.453209    Objective Loss 0.453209                                        LR 0.000500    Time 0.848432    
2024-02-26 23:36:20,745 - Epoch: [92][   80/  139]    Overall Loss 0.452963    Objective Loss 0.452963                                        LR 0.000500    Time 0.848028    
2024-02-26 23:36:29,202 - Epoch: [92][   90/  139]    Overall Loss 0.452153    Objective Loss 0.452153                                        LR 0.000500    Time 0.847769    
2024-02-26 23:36:37,655 - Epoch: [92][  100/  139]    Overall Loss 0.452586    Objective Loss 0.452586                                        LR 0.000500    Time 0.847508    
2024-02-26 23:36:46,113 - Epoch: [92][  110/  139]    Overall Loss 0.452821    Objective Loss 0.452821                                        LR 0.000500    Time 0.847348    
2024-02-26 23:36:54,570 - Epoch: [92][  120/  139]    Overall Loss 0.454888    Objective Loss 0.454888                                        LR 0.000500    Time 0.847201    
2024-02-26 23:37:03,024 - Epoch: [92][  130/  139]    Overall Loss 0.454419    Objective Loss 0.454419                                        LR 0.000500    Time 0.847059    
2024-02-26 23:37:15,974 - Epoch: [92][  139/  139]    Overall Loss 0.453681    Objective Loss 0.453681    Top1 93.348608    LR 0.000500    Time 0.885372    
2024-02-26 23:37:16,247 - --- validate (epoch=92)-----------
2024-02-26 23:37:16,248 - 1392 samples (32 per mini-batch)
2024-02-26 23:37:52,329 - Epoch: [92][   10/   44]    Loss 0.540116    Top1 87.853182    
2024-02-26 23:38:27,411 - Epoch: [92][   20/   44]    Loss 0.539480    Top1 87.920950    
2024-02-26 23:39:02,523 - Epoch: [92][   30/   44]    Loss 0.536321    Top1 88.120976    
2024-02-26 23:39:38,369 - Epoch: [92][   40/   44]    Loss 0.532381    Top1 88.391369    
2024-02-26 23:39:51,110 - Epoch: [92][   44/   44]    Loss 0.532980    Top1 88.373080    
2024-02-26 23:39:51,361 - ==> Top1: 88.373    Loss: 0.533

2024-02-26 23:39:51,368 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:39:51,368 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:39:51,399 - 

2024-02-26 23:39:51,399 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:40:00,184 - Epoch: [93][   10/  139]    Overall Loss 0.465764    Objective Loss 0.465764                                        LR 0.000500    Time 0.878391    
2024-02-26 23:40:08,567 - Epoch: [93][   20/  139]    Overall Loss 0.464317    Objective Loss 0.464317                                        LR 0.000500    Time 0.858313    
2024-02-26 23:40:16,980 - Epoch: [93][   30/  139]    Overall Loss 0.462425    Objective Loss 0.462425                                        LR 0.000500    Time 0.852619    
2024-02-26 23:40:25,431 - Epoch: [93][   40/  139]    Overall Loss 0.459694    Objective Loss 0.459694                                        LR 0.000500    Time 0.850732    
2024-02-26 23:40:33,883 - Epoch: [93][   50/  139]    Overall Loss 0.459159    Objective Loss 0.459159                                        LR 0.000500    Time 0.849621    
2024-02-26 23:40:42,349 - Epoch: [93][   60/  139]    Overall Loss 0.459402    Objective Loss 0.459402                                        LR 0.000500    Time 0.849102    
2024-02-26 23:40:50,801 - Epoch: [93][   70/  139]    Overall Loss 0.458552    Objective Loss 0.458552                                        LR 0.000500    Time 0.848525    
2024-02-26 23:40:59,254 - Epoch: [93][   80/  139]    Overall Loss 0.457661    Objective Loss 0.457661                                        LR 0.000500    Time 0.848115    
2024-02-26 23:41:07,715 - Epoch: [93][   90/  139]    Overall Loss 0.456908    Objective Loss 0.456908                                        LR 0.000500    Time 0.847883    
2024-02-26 23:41:16,172 - Epoch: [93][  100/  139]    Overall Loss 0.456499    Objective Loss 0.456499                                        LR 0.000500    Time 0.847658    
2024-02-26 23:41:24,627 - Epoch: [93][  110/  139]    Overall Loss 0.456035    Objective Loss 0.456035                                        LR 0.000500    Time 0.847455    
2024-02-26 23:41:33,079 - Epoch: [93][  120/  139]    Overall Loss 0.456070    Objective Loss 0.456070                                        LR 0.000500    Time 0.847268    
2024-02-26 23:41:41,531 - Epoch: [93][  130/  139]    Overall Loss 0.455562    Objective Loss 0.455562                                        LR 0.000500    Time 0.847103    
2024-02-26 23:41:53,781 - Epoch: [93][  139/  139]    Overall Loss 0.455055    Objective Loss 0.455055    Top1 92.836683    LR 0.000500    Time 0.880376    
2024-02-26 23:41:54,002 - --- validate (epoch=93)-----------
2024-02-26 23:41:54,003 - 1392 samples (32 per mini-batch)
2024-02-26 23:42:29,423 - Epoch: [93][   10/   44]    Loss 0.527505    Top1 88.954463    
2024-02-26 23:43:04,394 - Epoch: [93][   20/   44]    Loss 0.526669    Top1 89.054360    
2024-02-26 23:43:40,018 - Epoch: [93][   30/   44]    Loss 0.528964    Top1 88.926475    
2024-02-26 23:44:16,605 - Epoch: [93][   40/   44]    Loss 0.527445    Top1 89.010755    
2024-02-26 23:44:28,402 - Epoch: [93][   44/   44]    Loss 0.528159    Top1 88.958567    
2024-02-26 23:44:28,695 - ==> Top1: 88.959    Loss: 0.528

2024-02-26 23:44:28,702 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:44:28,703 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:44:28,733 - 

2024-02-26 23:44:28,733 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:44:37,543 - Epoch: [94][   10/  139]    Overall Loss 0.458902    Objective Loss 0.458902                                        LR 0.000500    Time 0.880854    
2024-02-26 23:44:45,922 - Epoch: [94][   20/  139]    Overall Loss 0.454470    Objective Loss 0.454470                                        LR 0.000500    Time 0.859359    
2024-02-26 23:44:54,368 - Epoch: [94][   30/  139]    Overall Loss 0.456150    Objective Loss 0.456150                                        LR 0.000500    Time 0.854425    
2024-02-26 23:45:02,814 - Epoch: [94][   40/  139]    Overall Loss 0.457634    Objective Loss 0.457634                                        LR 0.000500    Time 0.851936    
2024-02-26 23:45:11,265 - Epoch: [94][   50/  139]    Overall Loss 0.457882    Objective Loss 0.457882                                        LR 0.000500    Time 0.850565    
2024-02-26 23:45:19,716 - Epoch: [94][   60/  139]    Overall Loss 0.456226    Objective Loss 0.456226                                        LR 0.000500    Time 0.849637    
2024-02-26 23:45:28,178 - Epoch: [94][   70/  139]    Overall Loss 0.456137    Objective Loss 0.456137                                        LR 0.000500    Time 0.849126    
2024-02-26 23:45:36,635 - Epoch: [94][   80/  139]    Overall Loss 0.455540    Objective Loss 0.455540                                        LR 0.000500    Time 0.848695    
2024-02-26 23:45:45,100 - Epoch: [94][   90/  139]    Overall Loss 0.455513    Objective Loss 0.455513                                        LR 0.000500    Time 0.848438    
2024-02-26 23:45:53,567 - Epoch: [94][  100/  139]    Overall Loss 0.454255    Objective Loss 0.454255                                        LR 0.000500    Time 0.848256    
2024-02-26 23:46:02,019 - Epoch: [94][  110/  139]    Overall Loss 0.454806    Objective Loss 0.454806                                        LR 0.000500    Time 0.847970    
2024-02-26 23:46:10,472 - Epoch: [94][  120/  139]    Overall Loss 0.454658    Objective Loss 0.454658                                        LR 0.000500    Time 0.847746    
2024-02-26 23:46:18,930 - Epoch: [94][  130/  139]    Overall Loss 0.455020    Objective Loss 0.455020                                        LR 0.000500    Time 0.847590    
2024-02-26 23:46:31,835 - Epoch: [94][  139/  139]    Overall Loss 0.454104    Objective Loss 0.454104    Top1 94.864041    LR 0.000500    Time 0.885548    
2024-02-26 23:46:32,077 - --- validate (epoch=94)-----------
2024-02-26 23:46:32,079 - 1392 samples (32 per mini-batch)
2024-02-26 23:47:08,395 - Epoch: [94][   10/   44]    Loss 0.536773    Top1 88.139288    
2024-02-26 23:47:43,573 - Epoch: [94][   20/   44]    Loss 0.536747    Top1 88.168244    
2024-02-26 23:48:19,139 - Epoch: [94][   30/   44]    Loss 0.532712    Top1 88.393065    
2024-02-26 23:48:54,192 - Epoch: [94][   40/   44]    Loss 0.530026    Top1 88.571214    
2024-02-26 23:49:06,137 - Epoch: [94][   44/   44]    Loss 0.526272    Top1 88.746758    
2024-02-26 23:49:06,352 - ==> Top1: 88.747    Loss: 0.526

2024-02-26 23:49:06,359 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:49:06,359 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:49:06,388 - 

2024-02-26 23:49:06,388 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:49:15,143 - Epoch: [95][   10/  139]    Overall Loss 0.453391    Objective Loss 0.453391                                        LR 0.000500    Time 0.875362    
2024-02-26 23:49:23,547 - Epoch: [95][   20/  139]    Overall Loss 0.453622    Objective Loss 0.453622                                        LR 0.000500    Time 0.857873    
2024-02-26 23:49:31,991 - Epoch: [95][   30/  139]    Overall Loss 0.450270    Objective Loss 0.450270                                        LR 0.000500    Time 0.853339    
2024-02-26 23:49:40,438 - Epoch: [95][   40/  139]    Overall Loss 0.450027    Objective Loss 0.450027                                        LR 0.000500    Time 0.851171    
2024-02-26 23:49:48,890 - Epoch: [95][   50/  139]    Overall Loss 0.450996    Objective Loss 0.450996                                        LR 0.000500    Time 0.849957    
2024-02-26 23:49:57,345 - Epoch: [95][   60/  139]    Overall Loss 0.452423    Objective Loss 0.452423                                        LR 0.000500    Time 0.849205    
2024-02-26 23:50:05,802 - Epoch: [95][   70/  139]    Overall Loss 0.452280    Objective Loss 0.452280                                        LR 0.000500    Time 0.848689    
2024-02-26 23:50:14,257 - Epoch: [95][   80/  139]    Overall Loss 0.452807    Objective Loss 0.452807                                        LR 0.000500    Time 0.848287    
2024-02-26 23:50:22,719 - Epoch: [95][   90/  139]    Overall Loss 0.452371    Objective Loss 0.452371                                        LR 0.000500    Time 0.848039    
2024-02-26 23:50:31,175 - Epoch: [95][  100/  139]    Overall Loss 0.452447    Objective Loss 0.452447                                        LR 0.000500    Time 0.847791    
2024-02-26 23:50:39,629 - Epoch: [95][  110/  139]    Overall Loss 0.451692    Objective Loss 0.451692                                        LR 0.000500    Time 0.847563    
2024-02-26 23:50:48,087 - Epoch: [95][  120/  139]    Overall Loss 0.453161    Objective Loss 0.453161                                        LR 0.000500    Time 0.847413    
2024-02-26 23:50:56,545 - Epoch: [95][  130/  139]    Overall Loss 0.452339    Objective Loss 0.452339                                        LR 0.000500    Time 0.847287    
2024-02-26 23:51:09,046 - Epoch: [95][  139/  139]    Overall Loss 0.451596    Objective Loss 0.451596    Top1 94.166506    LR 0.000500    Time 0.882359    
2024-02-26 23:51:09,383 - --- validate (epoch=95)-----------
2024-02-26 23:51:09,384 - 1392 samples (32 per mini-batch)
2024-02-26 23:51:45,284 - Epoch: [95][   10/   44]    Loss 0.587389    Top1 85.482289    
2024-02-26 23:52:20,689 - Epoch: [95][   20/   44]    Loss 0.574757    Top1 86.195177    
2024-02-26 23:52:55,429 - Epoch: [95][   30/   44]    Loss 0.565967    Top1 86.685800    
2024-02-26 23:53:31,403 - Epoch: [95][   40/   44]    Loss 0.565056    Top1 86.719617    
2024-02-26 23:53:42,928 - Epoch: [95][   44/   44]    Loss 0.562933    Top1 86.805092    
2024-02-26 23:53:43,160 - ==> Top1: 86.805    Loss: 0.563

2024-02-26 23:53:43,167 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:53:43,167 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:53:43,201 - 

2024-02-26 23:53:43,202 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:53:52,015 - Epoch: [96][   10/  139]    Overall Loss 0.454062    Objective Loss 0.454062                                        LR 0.000500    Time 0.881197    
2024-02-26 23:54:00,396 - Epoch: [96][   20/  139]    Overall Loss 0.454901    Objective Loss 0.454901                                        LR 0.000500    Time 0.859658    
2024-02-26 23:54:08,841 - Epoch: [96][   30/  139]    Overall Loss 0.453226    Objective Loss 0.453226                                        LR 0.000500    Time 0.854583    
2024-02-26 23:54:17,283 - Epoch: [96][   40/  139]    Overall Loss 0.451437    Objective Loss 0.451437                                        LR 0.000500    Time 0.851973    
2024-02-26 23:54:25,732 - Epoch: [96][   50/  139]    Overall Loss 0.451077    Objective Loss 0.451077                                        LR 0.000500    Time 0.850534    
2024-02-26 23:54:34,180 - Epoch: [96][   60/  139]    Overall Loss 0.451604    Objective Loss 0.451604                                        LR 0.000500    Time 0.849577    
2024-02-26 23:54:42,645 - Epoch: [96][   70/  139]    Overall Loss 0.451879    Objective Loss 0.451879                                        LR 0.000500    Time 0.849115    
2024-02-26 23:54:51,113 - Epoch: [96][   80/  139]    Overall Loss 0.451727    Objective Loss 0.451727                                        LR 0.000500    Time 0.848819    
2024-02-26 23:54:59,562 - Epoch: [96][   90/  139]    Overall Loss 0.450221    Objective Loss 0.450221                                        LR 0.000500    Time 0.848380    
2024-02-26 23:55:08,009 - Epoch: [96][  100/  139]    Overall Loss 0.449595    Objective Loss 0.449595                                        LR 0.000500    Time 0.848006    
2024-02-26 23:55:16,463 - Epoch: [96][  110/  139]    Overall Loss 0.449755    Objective Loss 0.449755                                        LR 0.000500    Time 0.847756    
2024-02-26 23:55:24,920 - Epoch: [96][  120/  139]    Overall Loss 0.449570    Objective Loss 0.449570                                        LR 0.000500    Time 0.847579    
2024-02-26 23:55:33,372 - Epoch: [96][  130/  139]    Overall Loss 0.449941    Objective Loss 0.449941                                        LR 0.000500    Time 0.847396    
2024-02-26 23:55:45,598 - Epoch: [96][  139/  139]    Overall Loss 0.449927    Objective Loss 0.449927    Top1 93.364988    LR 0.000500    Time 0.880476    
2024-02-26 23:55:45,895 - --- validate (epoch=96)-----------
2024-02-26 23:55:45,895 - 1392 samples (32 per mini-batch)
2024-02-26 23:56:22,608 - Epoch: [96][   10/   44]    Loss 0.545403    Top1 87.585767    
2024-02-26 23:56:57,153 - Epoch: [96][   20/   44]    Loss 0.541793    Top1 87.872180    
2024-02-26 23:57:33,039 - Epoch: [96][   30/   44]    Loss 0.545901    Top1 87.656786    
2024-02-26 23:58:08,525 - Epoch: [96][   40/   44]    Loss 0.545229    Top1 87.731496    
2024-02-26 23:58:21,094 - Epoch: [96][   44/   44]    Loss 0.545375    Top1 87.690543    
2024-02-26 23:58:21,313 - ==> Top1: 87.691    Loss: 0.545

2024-02-26 23:58:21,321 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-26 23:58:21,321 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-26 23:58:21,355 - 

2024-02-26 23:58:21,356 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-26 23:58:30,148 - Epoch: [97][   10/  139]    Overall Loss 0.439694    Objective Loss 0.439694                                        LR 0.000500    Time 0.879113    
2024-02-26 23:58:38,535 - Epoch: [97][   20/  139]    Overall Loss 0.445131    Objective Loss 0.445131                                        LR 0.000500    Time 0.858858    
2024-02-26 23:58:46,916 - Epoch: [97][   30/  139]    Overall Loss 0.449437    Objective Loss 0.449437                                        LR 0.000500    Time 0.851939    
2024-02-26 23:58:55,296 - Epoch: [97][   40/  139]    Overall Loss 0.448130    Objective Loss 0.448130                                        LR 0.000500    Time 0.848425    
2024-02-26 23:59:03,678 - Epoch: [97][   50/  139]    Overall Loss 0.448385    Objective Loss 0.448385                                        LR 0.000500    Time 0.846379    
2024-02-26 23:59:12,097 - Epoch: [97][   60/  139]    Overall Loss 0.449042    Objective Loss 0.449042                                        LR 0.000500    Time 0.845619    
2024-02-26 23:59:20,560 - Epoch: [97][   70/  139]    Overall Loss 0.449586    Objective Loss 0.449586                                        LR 0.000500    Time 0.845711    
2024-02-26 23:59:29,034 - Epoch: [97][   80/  139]    Overall Loss 0.450829    Objective Loss 0.450829                                        LR 0.000500    Time 0.845908    
2024-02-26 23:59:37,503 - Epoch: [97][   90/  139]    Overall Loss 0.451463    Objective Loss 0.451463                                        LR 0.000500    Time 0.846013    
2024-02-26 23:59:45,968 - Epoch: [97][  100/  139]    Overall Loss 0.452757    Objective Loss 0.452757                                        LR 0.000500    Time 0.846058    
2024-02-26 23:59:54,426 - Epoch: [97][  110/  139]    Overall Loss 0.453313    Objective Loss 0.453313                                        LR 0.000500    Time 0.846033    
2024-02-27 00:00:02,896 - Epoch: [97][  120/  139]    Overall Loss 0.452868    Objective Loss 0.452868                                        LR 0.000500    Time 0.846106    
2024-02-27 00:00:11,358 - Epoch: [97][  130/  139]    Overall Loss 0.452256    Objective Loss 0.452256                                        LR 0.000500    Time 0.846105    
2024-02-27 00:00:23,815 - Epoch: [97][  139/  139]    Overall Loss 0.451793    Objective Loss 0.451793    Top1 93.702382    LR 0.000500    Time 0.880934    
2024-02-27 00:00:24,163 - --- validate (epoch=97)-----------
2024-02-27 00:00:24,165 - 1392 samples (32 per mini-batch)
2024-02-27 00:01:00,313 - Epoch: [97][   10/   44]    Loss 0.530344    Top1 88.665015    
2024-02-27 00:01:35,475 - Epoch: [97][   20/   44]    Loss 0.529563    Top1 88.699647    
2024-02-27 00:02:11,107 - Epoch: [97][   30/   44]    Loss 0.529940    Top1 88.702966    
2024-02-27 00:02:46,861 - Epoch: [97][   40/   44]    Loss 0.530070    Top1 88.699008    
2024-02-27 00:02:59,128 - Epoch: [97][   44/   44]    Loss 0.529982    Top1 88.658841    
2024-02-27 00:02:59,466 - ==> Top1: 88.659    Loss: 0.530

2024-02-27 00:02:59,473 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-27 00:02:59,474 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-27 00:02:59,504 - 

2024-02-27 00:02:59,504 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-27 00:03:08,336 - Epoch: [98][   10/  139]    Overall Loss 0.444281    Objective Loss 0.444281                                        LR 0.000500    Time 0.883112    
2024-02-27 00:03:16,719 - Epoch: [98][   20/  139]    Overall Loss 0.444765    Objective Loss 0.444765                                        LR 0.000500    Time 0.860650    
2024-02-27 00:03:25,102 - Epoch: [98][   30/  139]    Overall Loss 0.442777    Objective Loss 0.442777                                        LR 0.000500    Time 0.853198    
2024-02-27 00:03:33,562 - Epoch: [98][   40/  139]    Overall Loss 0.446932    Objective Loss 0.446932                                        LR 0.000500    Time 0.851372    
2024-02-27 00:03:42,020 - Epoch: [98][   50/  139]    Overall Loss 0.449059    Objective Loss 0.449059                                        LR 0.000500    Time 0.850245    
2024-02-27 00:03:50,481 - Epoch: [98][   60/  139]    Overall Loss 0.451827    Objective Loss 0.451827                                        LR 0.000500    Time 0.849537    
2024-02-27 00:03:58,943 - Epoch: [98][   70/  139]    Overall Loss 0.450982    Objective Loss 0.450982                                        LR 0.000500    Time 0.849059    
2024-02-27 00:04:07,416 - Epoch: [98][   80/  139]    Overall Loss 0.451356    Objective Loss 0.451356                                        LR 0.000500    Time 0.848830    
2024-02-27 00:04:15,883 - Epoch: [98][   90/  139]    Overall Loss 0.451482    Objective Loss 0.451482                                        LR 0.000500    Time 0.848581    
2024-02-27 00:04:24,347 - Epoch: [98][  100/  139]    Overall Loss 0.451535    Objective Loss 0.451535                                        LR 0.000500    Time 0.848365    
2024-02-27 00:04:32,813 - Epoch: [98][  110/  139]    Overall Loss 0.451044    Objective Loss 0.451044                                        LR 0.000500    Time 0.848194    
2024-02-27 00:04:41,278 - Epoch: [98][  120/  139]    Overall Loss 0.450889    Objective Loss 0.450889                                        LR 0.000500    Time 0.848049    
2024-02-27 00:04:49,751 - Epoch: [98][  130/  139]    Overall Loss 0.450697    Objective Loss 0.450697                                        LR 0.000500    Time 0.847986    
2024-02-27 00:05:01,896 - Epoch: [98][  139/  139]    Overall Loss 0.451354    Objective Loss 0.451354    Top1 93.576900    LR 0.000500    Time 0.880451    
2024-02-27 00:05:02,168 - --- validate (epoch=98)-----------
2024-02-27 00:05:02,169 - 1392 samples (32 per mini-batch)
2024-02-27 00:05:38,187 - Epoch: [98][   10/   44]    Loss 0.527466    Top1 88.683555    
2024-02-27 00:06:12,386 - Epoch: [98][   20/   44]    Loss 0.534186    Top1 88.339100    
2024-02-27 00:06:48,411 - Epoch: [98][   30/   44]    Loss 0.536871    Top1 88.219940    
2024-02-27 00:07:23,320 - Epoch: [98][   40/   44]    Loss 0.532341    Top1 88.520829    
2024-02-27 00:07:35,430 - Epoch: [98][   44/   44]    Loss 0.532153    Top1 88.588682    
2024-02-27 00:07:35,719 - ==> Top1: 88.589    Loss: 0.532

2024-02-27 00:07:35,727 - ==> Best [Top1: 89.253   Sparsity:0.00   Params: 271456 on epoch: 72]
2024-02-27 00:07:35,727 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-27 00:07:35,758 - 

2024-02-27 00:07:35,759 - Training epoch: 4428 samples (32 per mini-batch)
2024-02-27 00:07:44,533 - Epoch: [99][   10/  139]    Overall Loss 0.457904    Objective Loss 0.457904                                        LR 0.000500    Time 0.877281    
2024-02-27 00:07:52,920 - Epoch: [99][   20/  139]    Overall Loss 0.454975    Objective Loss 0.454975                                        LR 0.000500    Time 0.857999    
2024-02-27 00:08:01,351 - Epoch: [99][   30/  139]    Overall Loss 0.456499    Objective Loss 0.456499                                        LR 0.000500    Time 0.853001    
2024-02-27 00:08:09,807 - Epoch: [99][   40/  139]    Overall Loss 0.457216    Objective Loss 0.457216                                        LR 0.000500    Time 0.851137    
2024-02-27 00:08:18,270 - Epoch: [99][   50/  139]    Overall Loss 0.455868    Objective Loss 0.455868                                        LR 0.000500    Time 0.850153    
2024-02-27 00:08:26,731 - Epoch: [99][   60/  139]    Overall Loss 0.453263    Objective Loss 0.453263                                        LR 0.000500    Time 0.849476    
2024-02-27 00:08:35,198 - Epoch: [99][   70/  139]    Overall Loss 0.451383    Objective Loss 0.451383                                        LR 0.000500    Time 0.849067    
2024-02-27 00:08:43,683 - Epoch: [99][   80/  139]    Overall Loss 0.451390    Objective Loss 0.451390                                        LR 0.000500    Time 0.848984    
2024-02-27 00:08:52,148 - Epoch: [99][   90/  139]    Overall Loss 0.450955    Objective Loss 0.450955                                        LR 0.000500    Time 0.848702    
2024-02-27 00:09:00,613 - Epoch: [99][  100/  139]    Overall Loss 0.450880    Objective Loss 0.450880                                        LR 0.000500    Time 0.848473    
2024-02-27 00:09:09,078 - Epoch: [99][  110/  139]    Overall Loss 0.450887    Objective Loss 0.450887                                        LR 0.000500    Time 0.848290    
2024-02-27 00:09:17,546 - Epoch: [99][  120/  139]    Overall Loss 0.450530    Objective Loss 0.450530                                        LR 0.000500    Time 0.848159    
2024-02-27 00:09:26,016 - Epoch: [99][  130/  139]    Overall Loss 0.451390    Objective Loss 0.451390                                        LR 0.000500    Time 0.848070    
2024-02-27 00:09:38,907 - Epoch: [99][  139/  139]    Overall Loss 0.451371    Objective Loss 0.451371    Top1 93.874767    LR 0.000500    Time 0.885890    
2024-02-27 00:09:39,174 - --- validate (epoch=99)-----------
2024-02-27 00:09:39,175 - 1392 samples (32 per mini-batch)
2024-02-27 00:10:15,156 - Epoch: [99][   10/   44]    Loss 0.511752    Top1 89.622972    
2024-02-27 00:10:50,152 - Epoch: [99][   20/   44]    Loss 0.520137    Top1 89.161760    
2024-02-27 00:11:25,733 - Epoch: [99][   30/   44]    Loss 0.521635    Top1 89.066044    
2024-02-27 00:11:59,907 - Epoch: [99][   40/   44]    Loss 0.519195    Top1 89.209147    
2024-02-27 00:12:12,523 - Epoch: [99][   44/   44]    Loss 0.516869    Top1 89.306841    
2024-02-27 00:12:12,785 - ==> Top1: 89.307    Loss: 0.517

2024-02-27 00:12:12,792 - ==> Best [Top1: 89.307   Sparsity:0.00   Params: 271456 on epoch: 99]
2024-02-27 00:12:12,792 - Saving checkpoint to: logs/2024.02.26-163117/qat_checkpoint.pth.tar
2024-02-27 00:12:12,827 - --- test ---------------------
2024-02-27 00:12:12,827 - 1392 samples (32 per mini-batch)
2024-02-27 00:12:48,752 - Test: [   10/   44]    Loss 0.517467    Top1 89.315042    
2024-02-27 00:13:23,097 - Test: [   20/   44]    Loss 0.514164    Top1 89.501513    
2024-02-27 00:13:58,655 - Test: [   30/   44]    Loss 0.510629    Top1 89.720941    
2024-02-27 00:14:33,695 - Test: [   40/   44]    Loss 0.515130    Top1 89.442252    
2024-02-27 00:14:46,098 - Test: [   44/   44]    Loss 0.517951    Top1 89.306841    
2024-02-27 00:14:46,323 - ==> Top1: 89.307    Loss: 0.518

2024-02-27 00:14:46,363 - 
2024-02-27 00:14:46,363 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.02.26-163117/2024.02.26-163117.log
