2024-02-17 11:02:26,314 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.02.17-110226/2024.02.17-110226.log
2024-02-17 11:02:29,906 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-02-17 11:02:29,906 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-02-17 11:02:32,317 - Dataset sizes:
	training=50000
	validation=10000
	test=10000
2024-02-17 11:02:32,318 - Reading compression schedule from: policies/schedule-cifar100-effnet2.yaml
2024-02-17 11:02:32,327 - 

2024-02-17 11:02:32,328 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:02:40,725 - Epoch: [0][  100/  500]    Overall Loss 4.275056    Objective Loss 4.275056                                        LR 0.001000    Time 0.083920    
2024-02-17 11:02:47,856 - Epoch: [0][  200/  500]    Overall Loss 4.121238    Objective Loss 4.121238                                        LR 0.001000    Time 0.077589    
2024-02-17 11:02:55,005 - Epoch: [0][  300/  500]    Overall Loss 4.013989    Objective Loss 4.013989                                        LR 0.001000    Time 0.075543    
2024-02-17 11:03:02,059 - Epoch: [0][  400/  500]    Overall Loss 3.929156    Objective Loss 3.929156                                        LR 0.001000    Time 0.074275    
2024-02-17 11:03:09,111 - Epoch: [0][  500/  500]    Overall Loss 3.866253    Objective Loss 3.866253    Top1 11.500000    Top5 46.000000    LR 0.001000    Time 0.073517    
2024-02-17 11:03:09,231 - --- validate (epoch=0)-----------
2024-02-17 11:03:09,233 - 10000 samples (100 per mini-batch)
2024-02-17 11:03:12,779 - Epoch: [0][  100/  100]    Loss 6.616838    Top1 1.510000    Top5 6.210000    
2024-02-17 11:03:12,895 - ==> Top1: 1.510    Top5: 6.210    Loss: 6.617

2024-02-17 11:03:12,905 - ==> Best [Top1: 1.510   Top5: 6.210   Sparsity:0.00   Params: 753952 on epoch: 0]
2024-02-17 11:03:12,905 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:03:12,971 - 

2024-02-17 11:03:12,971 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:03:20,754 - Epoch: [1][  100/  500]    Overall Loss 3.500466    Objective Loss 3.500466                                        LR 0.001000    Time 0.077777    
2024-02-17 11:03:28,192 - Epoch: [1][  200/  500]    Overall Loss 3.457511    Objective Loss 3.457511                                        LR 0.001000    Time 0.076059    
2024-02-17 11:03:35,589 - Epoch: [1][  300/  500]    Overall Loss 3.418027    Objective Loss 3.418027                                        LR 0.001000    Time 0.075347    
2024-02-17 11:03:42,943 - Epoch: [1][  400/  500]    Overall Loss 3.380266    Objective Loss 3.380266                                        LR 0.001000    Time 0.074885    
2024-02-17 11:03:50,337 - Epoch: [1][  500/  500]    Overall Loss 3.341529    Objective Loss 3.341529    Top1 16.000000    Top5 45.000000    LR 0.001000    Time 0.074688    
2024-02-17 11:03:50,451 - --- validate (epoch=1)-----------
2024-02-17 11:03:50,452 - 10000 samples (100 per mini-batch)
2024-02-17 11:03:53,685 - Epoch: [1][  100/  100]    Loss 3.431657    Top1 17.000000    Top5 44.840000    
2024-02-17 11:03:53,791 - ==> Top1: 17.000    Top5: 44.840    Loss: 3.432

2024-02-17 11:03:53,803 - ==> Best [Top1: 17.000   Top5: 44.840   Sparsity:0.00   Params: 753952 on epoch: 1]
2024-02-17 11:03:53,804 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:03:53,879 - 

2024-02-17 11:03:53,880 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:04:01,687 - Epoch: [2][  100/  500]    Overall Loss 3.099394    Objective Loss 3.099394                                        LR 0.001000    Time 0.078024    
2024-02-17 11:04:09,098 - Epoch: [2][  200/  500]    Overall Loss 3.083873    Objective Loss 3.083873                                        LR 0.001000    Time 0.076044    
2024-02-17 11:04:16,544 - Epoch: [2][  300/  500]    Overall Loss 3.067328    Objective Loss 3.067328                                        LR 0.001000    Time 0.075501    
2024-02-17 11:04:23,477 - Epoch: [2][  400/  500]    Overall Loss 3.046143    Objective Loss 3.046143                                        LR 0.001000    Time 0.073949    
2024-02-17 11:04:30,680 - Epoch: [2][  500/  500]    Overall Loss 3.019589    Objective Loss 3.019589    Top1 23.000000    Top5 60.000000    LR 0.001000    Time 0.073558    
2024-02-17 11:04:30,801 - --- validate (epoch=2)-----------
2024-02-17 11:04:30,803 - 10000 samples (100 per mini-batch)
2024-02-17 11:04:34,275 - Epoch: [2][  100/  100]    Loss 3.225702    Top1 22.180000    Top5 51.550000    
2024-02-17 11:04:34,449 - ==> Top1: 22.180    Top5: 51.550    Loss: 3.226

2024-02-17 11:04:34,459 - ==> Best [Top1: 22.180   Top5: 51.550   Sparsity:0.00   Params: 753952 on epoch: 2]
2024-02-17 11:04:34,460 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:04:34,537 - 

2024-02-17 11:04:34,538 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:04:42,304 - Epoch: [3][  100/  500]    Overall Loss 2.865246    Objective Loss 2.865246                                        LR 0.001000    Time 0.077607    
2024-02-17 11:04:49,475 - Epoch: [3][  200/  500]    Overall Loss 2.844952    Objective Loss 2.844952                                        LR 0.001000    Time 0.074641    
2024-02-17 11:04:56,653 - Epoch: [3][  300/  500]    Overall Loss 2.833951    Objective Loss 2.833951                                        LR 0.001000    Time 0.073674    
2024-02-17 11:05:03,968 - Epoch: [3][  400/  500]    Overall Loss 2.819812    Objective Loss 2.819812                                        LR 0.001000    Time 0.073532    
2024-02-17 11:05:11,196 - Epoch: [3][  500/  500]    Overall Loss 2.805881    Objective Loss 2.805881    Top1 25.000000    Top5 62.000000    LR 0.001000    Time 0.073274    
2024-02-17 11:05:11,363 - --- validate (epoch=3)-----------
2024-02-17 11:05:11,364 - 10000 samples (100 per mini-batch)
2024-02-17 11:05:14,539 - Epoch: [3][  100/  100]    Loss 3.079837    Top1 24.790000    Top5 56.140000    
2024-02-17 11:05:14,726 - ==> Top1: 24.790    Top5: 56.140    Loss: 3.080

2024-02-17 11:05:14,736 - ==> Best [Top1: 24.790   Top5: 56.140   Sparsity:0.00   Params: 753952 on epoch: 3]
2024-02-17 11:05:14,737 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:05:14,814 - 

2024-02-17 11:05:14,815 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:05:22,863 - Epoch: [4][  100/  500]    Overall Loss 2.697732    Objective Loss 2.697732                                        LR 0.001000    Time 0.080435    
2024-02-17 11:05:30,121 - Epoch: [4][  200/  500]    Overall Loss 2.681969    Objective Loss 2.681969                                        LR 0.001000    Time 0.076483    
2024-02-17 11:05:37,357 - Epoch: [4][  300/  500]    Overall Loss 2.668564    Objective Loss 2.668564                                        LR 0.001000    Time 0.075096    
2024-02-17 11:05:44,732 - Epoch: [4][  400/  500]    Overall Loss 2.648206    Objective Loss 2.648206                                        LR 0.001000    Time 0.074748    
2024-02-17 11:05:52,075 - Epoch: [4][  500/  500]    Overall Loss 2.628857    Objective Loss 2.628857    Top1 30.000000    Top5 64.500000    LR 0.001000    Time 0.074476    
2024-02-17 11:05:52,209 - --- validate (epoch=4)-----------
2024-02-17 11:05:52,210 - 10000 samples (100 per mini-batch)
2024-02-17 11:05:55,231 - Epoch: [4][  100/  100]    Loss 2.708755    Top1 30.410000    Top5 63.190000    
2024-02-17 11:05:55,361 - ==> Top1: 30.410    Top5: 63.190    Loss: 2.709

2024-02-17 11:05:55,375 - ==> Best [Top1: 30.410   Top5: 63.190   Sparsity:0.00   Params: 753952 on epoch: 4]
2024-02-17 11:05:55,376 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:05:55,452 - 

2024-02-17 11:05:55,452 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:06:03,208 - Epoch: [5][  100/  500]    Overall Loss 2.506355    Objective Loss 2.506355                                        LR 0.001000    Time 0.077499    
2024-02-17 11:06:10,748 - Epoch: [5][  200/  500]    Overall Loss 2.506461    Objective Loss 2.506461                                        LR 0.001000    Time 0.076431    
2024-02-17 11:06:18,195 - Epoch: [5][  300/  500]    Overall Loss 2.498337    Objective Loss 2.498337                                        LR 0.001000    Time 0.075765    
2024-02-17 11:06:25,609 - Epoch: [5][  400/  500]    Overall Loss 2.493585    Objective Loss 2.493585                                        LR 0.001000    Time 0.075347    
2024-02-17 11:06:33,043 - Epoch: [5][  500/  500]    Overall Loss 2.480782    Objective Loss 2.480782    Top1 38.000000    Top5 68.500000    LR 0.001000    Time 0.075138    
2024-02-17 11:06:33,173 - --- validate (epoch=5)-----------
2024-02-17 11:06:33,174 - 10000 samples (100 per mini-batch)
2024-02-17 11:06:36,253 - Epoch: [5][  100/  100]    Loss 2.529645    Top1 34.250000    Top5 67.130000    
2024-02-17 11:06:36,372 - ==> Top1: 34.250    Top5: 67.130    Loss: 2.530

2024-02-17 11:06:36,380 - ==> Best [Top1: 34.250   Top5: 67.130   Sparsity:0.00   Params: 753952 on epoch: 5]
2024-02-17 11:06:36,380 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:06:36,465 - 

2024-02-17 11:06:36,466 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:06:44,121 - Epoch: [6][  100/  500]    Overall Loss 2.366514    Objective Loss 2.366514                                        LR 0.001000    Time 0.076501    
2024-02-17 11:06:51,624 - Epoch: [6][  200/  500]    Overall Loss 2.383490    Objective Loss 2.383490                                        LR 0.001000    Time 0.075746    
2024-02-17 11:06:59,099 - Epoch: [6][  300/  500]    Overall Loss 2.374303    Objective Loss 2.374303                                        LR 0.001000    Time 0.075403    
2024-02-17 11:07:06,416 - Epoch: [6][  400/  500]    Overall Loss 2.364162    Objective Loss 2.364162                                        LR 0.001000    Time 0.074834    
2024-02-17 11:07:13,714 - Epoch: [6][  500/  500]    Overall Loss 2.355942    Objective Loss 2.355942    Top1 34.500000    Top5 65.000000    LR 0.001000    Time 0.074455    
2024-02-17 11:07:13,867 - --- validate (epoch=6)-----------
2024-02-17 11:07:13,868 - 10000 samples (100 per mini-batch)
2024-02-17 11:07:17,227 - Epoch: [6][  100/  100]    Loss 2.720212    Top1 32.220000    Top5 64.090000    
2024-02-17 11:07:17,393 - ==> Top1: 32.220    Top5: 64.090    Loss: 2.720

2024-02-17 11:07:17,404 - ==> Best [Top1: 34.250   Top5: 67.130   Sparsity:0.00   Params: 753952 on epoch: 5]
2024-02-17 11:07:17,405 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:07:17,469 - 

2024-02-17 11:07:17,469 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:07:25,262 - Epoch: [7][  100/  500]    Overall Loss 2.270916    Objective Loss 2.270916                                        LR 0.001000    Time 0.077867    
2024-02-17 11:07:32,604 - Epoch: [7][  200/  500]    Overall Loss 2.274110    Objective Loss 2.274110                                        LR 0.001000    Time 0.075625    
2024-02-17 11:07:40,032 - Epoch: [7][  300/  500]    Overall Loss 2.270804    Objective Loss 2.270804                                        LR 0.001000    Time 0.075164    
2024-02-17 11:07:47,403 - Epoch: [7][  400/  500]    Overall Loss 2.270610    Objective Loss 2.270610                                        LR 0.001000    Time 0.074790    
2024-02-17 11:07:54,768 - Epoch: [7][  500/  500]    Overall Loss 2.261209    Objective Loss 2.261209    Top1 35.000000    Top5 70.500000    LR 0.001000    Time 0.074553    
2024-02-17 11:07:54,932 - --- validate (epoch=7)-----------
2024-02-17 11:07:54,933 - 10000 samples (100 per mini-batch)
2024-02-17 11:07:58,049 - Epoch: [7][  100/  100]    Loss 2.439252    Top1 37.610000    Top5 69.580000    
2024-02-17 11:07:58,246 - ==> Top1: 37.610    Top5: 69.580    Loss: 2.439

2024-02-17 11:07:58,256 - ==> Best [Top1: 37.610   Top5: 69.580   Sparsity:0.00   Params: 753952 on epoch: 7]
2024-02-17 11:07:58,257 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:07:58,329 - 

2024-02-17 11:07:58,330 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:08:06,206 - Epoch: [8][  100/  500]    Overall Loss 2.151179    Objective Loss 2.151179                                        LR 0.001000    Time 0.078709    
2024-02-17 11:08:13,489 - Epoch: [8][  200/  500]    Overall Loss 2.173651    Objective Loss 2.173651                                        LR 0.001000    Time 0.075753    
2024-02-17 11:08:20,769 - Epoch: [8][  300/  500]    Overall Loss 2.162682    Objective Loss 2.162682                                        LR 0.001000    Time 0.074755    
2024-02-17 11:08:28,185 - Epoch: [8][  400/  500]    Overall Loss 2.168870    Objective Loss 2.168870                                        LR 0.001000    Time 0.074597    
2024-02-17 11:08:35,528 - Epoch: [8][  500/  500]    Overall Loss 2.163665    Objective Loss 2.163665    Top1 41.000000    Top5 75.500000    LR 0.001000    Time 0.074354    
2024-02-17 11:08:35,651 - --- validate (epoch=8)-----------
2024-02-17 11:08:35,652 - 10000 samples (100 per mini-batch)
2024-02-17 11:08:38,622 - Epoch: [8][  100/  100]    Loss 2.393116    Top1 38.040000    Top5 70.480000    
2024-02-17 11:08:38,740 - ==> Top1: 38.040    Top5: 70.480    Loss: 2.393

2024-02-17 11:08:38,747 - ==> Best [Top1: 38.040   Top5: 70.480   Sparsity:0.00   Params: 753952 on epoch: 8]
2024-02-17 11:08:38,747 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:08:38,816 - 

2024-02-17 11:08:38,816 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:08:46,802 - Epoch: [9][  100/  500]    Overall Loss 2.059027    Objective Loss 2.059027                                        LR 0.001000    Time 0.079811    
2024-02-17 11:08:54,185 - Epoch: [9][  200/  500]    Overall Loss 2.077117    Objective Loss 2.077117                                        LR 0.001000    Time 0.076798    
2024-02-17 11:09:01,114 - Epoch: [9][  300/  500]    Overall Loss 2.086387    Objective Loss 2.086387                                        LR 0.001000    Time 0.074285    
2024-02-17 11:09:08,410 - Epoch: [9][  400/  500]    Overall Loss 2.082988    Objective Loss 2.082988                                        LR 0.001000    Time 0.073942    
2024-02-17 11:09:15,732 - Epoch: [9][  500/  500]    Overall Loss 2.083254    Objective Loss 2.083254    Top1 47.000000    Top5 78.000000    LR 0.001000    Time 0.073790    
2024-02-17 11:09:15,846 - --- validate (epoch=9)-----------
2024-02-17 11:09:15,846 - 10000 samples (100 per mini-batch)
2024-02-17 11:09:18,982 - Epoch: [9][  100/  100]    Loss 2.423922    Top1 39.470000    Top5 70.630000    
2024-02-17 11:09:19,091 - ==> Top1: 39.470    Top5: 70.630    Loss: 2.424

2024-02-17 11:09:19,101 - ==> Best [Top1: 39.470   Top5: 70.630   Sparsity:0.00   Params: 753952 on epoch: 9]
2024-02-17 11:09:19,102 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:09:19,186 - 

2024-02-17 11:09:19,187 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:09:27,243 - Epoch: [10][  100/  500]    Overall Loss 2.034494    Objective Loss 2.034494                                        LR 0.001000    Time 0.080509    
2024-02-17 11:09:34,543 - Epoch: [10][  200/  500]    Overall Loss 2.030089    Objective Loss 2.030089                                        LR 0.001000    Time 0.076734    
2024-02-17 11:09:41,941 - Epoch: [10][  300/  500]    Overall Loss 2.026545    Objective Loss 2.026545                                        LR 0.001000    Time 0.075805    
2024-02-17 11:09:49,303 - Epoch: [10][  400/  500]    Overall Loss 2.018472    Objective Loss 2.018472                                        LR 0.001000    Time 0.075247    
2024-02-17 11:09:56,602 - Epoch: [10][  500/  500]    Overall Loss 2.021649    Objective Loss 2.021649    Top1 43.000000    Top5 74.500000    LR 0.001000    Time 0.074787    
2024-02-17 11:09:56,778 - --- validate (epoch=10)-----------
2024-02-17 11:09:56,779 - 10000 samples (100 per mini-batch)
2024-02-17 11:09:59,982 - Epoch: [10][  100/  100]    Loss 2.272644    Top1 40.380000    Top5 72.820000    
2024-02-17 11:10:00,117 - ==> Top1: 40.380    Top5: 72.820    Loss: 2.273

2024-02-17 11:10:00,127 - ==> Best [Top1: 40.380   Top5: 72.820   Sparsity:0.00   Params: 753952 on epoch: 10]
2024-02-17 11:10:00,127 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:10:00,216 - 

2024-02-17 11:10:00,217 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:10:07,935 - Epoch: [11][  100/  500]    Overall Loss 1.962647    Objective Loss 1.962647                                        LR 0.001000    Time 0.077125    
2024-02-17 11:10:15,286 - Epoch: [11][  200/  500]    Overall Loss 1.956996    Objective Loss 1.956996                                        LR 0.001000    Time 0.075298    
2024-02-17 11:10:22,598 - Epoch: [11][  300/  500]    Overall Loss 1.955405    Objective Loss 1.955405                                        LR 0.001000    Time 0.074558    
2024-02-17 11:10:29,816 - Epoch: [11][  400/  500]    Overall Loss 1.954840    Objective Loss 1.954840                                        LR 0.001000    Time 0.073954    
2024-02-17 11:10:36,929 - Epoch: [11][  500/  500]    Overall Loss 1.954866    Objective Loss 1.954866    Top1 53.000000    Top5 78.500000    LR 0.001000    Time 0.073382    
2024-02-17 11:10:37,036 - --- validate (epoch=11)-----------
2024-02-17 11:10:37,037 - 10000 samples (100 per mini-batch)
2024-02-17 11:10:40,154 - Epoch: [11][  100/  100]    Loss 2.191544    Top1 42.860000    Top5 74.630000    
2024-02-17 11:10:40,292 - ==> Top1: 42.860    Top5: 74.630    Loss: 2.192

2024-02-17 11:10:40,299 - ==> Best [Top1: 42.860   Top5: 74.630   Sparsity:0.00   Params: 753952 on epoch: 11]
2024-02-17 11:10:40,299 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:10:40,377 - 

2024-02-17 11:10:40,377 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:10:48,421 - Epoch: [12][  100/  500]    Overall Loss 1.905880    Objective Loss 1.905880                                        LR 0.001000    Time 0.080375    
2024-02-17 11:10:55,724 - Epoch: [12][  200/  500]    Overall Loss 1.911123    Objective Loss 1.911123                                        LR 0.001000    Time 0.076686    
2024-02-17 11:11:03,068 - Epoch: [12][  300/  500]    Overall Loss 1.905539    Objective Loss 1.905539                                        LR 0.001000    Time 0.075588    
2024-02-17 11:11:10,316 - Epoch: [12][  400/  500]    Overall Loss 1.901324    Objective Loss 1.901324                                        LR 0.001000    Time 0.074803    
2024-02-17 11:11:17,580 - Epoch: [12][  500/  500]    Overall Loss 1.901744    Objective Loss 1.901744    Top1 49.000000    Top5 80.000000    LR 0.001000    Time 0.074362    
2024-02-17 11:11:17,732 - --- validate (epoch=12)-----------
2024-02-17 11:11:17,732 - 10000 samples (100 per mini-batch)
2024-02-17 11:11:20,829 - Epoch: [12][  100/  100]    Loss 2.092381    Top1 45.170000    Top5 76.320000    
2024-02-17 11:11:20,954 - ==> Top1: 45.170    Top5: 76.320    Loss: 2.092

2024-02-17 11:11:20,961 - ==> Best [Top1: 45.170   Top5: 76.320   Sparsity:0.00   Params: 753952 on epoch: 12]
2024-02-17 11:11:20,961 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:11:21,036 - 

2024-02-17 11:11:21,037 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:11:28,901 - Epoch: [13][  100/  500]    Overall Loss 1.821593    Objective Loss 1.821593                                        LR 0.001000    Time 0.078587    
2024-02-17 11:11:36,319 - Epoch: [13][  200/  500]    Overall Loss 1.839496    Objective Loss 1.839496                                        LR 0.001000    Time 0.076364    
2024-02-17 11:11:43,637 - Epoch: [13][  300/  500]    Overall Loss 1.848061    Objective Loss 1.848061                                        LR 0.001000    Time 0.075286    
2024-02-17 11:11:50,839 - Epoch: [13][  400/  500]    Overall Loss 1.847638    Objective Loss 1.847638                                        LR 0.001000    Time 0.074460    
2024-02-17 11:11:58,039 - Epoch: [13][  500/  500]    Overall Loss 1.848399    Objective Loss 1.848399    Top1 49.000000    Top5 80.000000    LR 0.001000    Time 0.073959    
2024-02-17 11:11:58,192 - --- validate (epoch=13)-----------
2024-02-17 11:11:58,193 - 10000 samples (100 per mini-batch)
2024-02-17 11:12:01,254 - Epoch: [13][  100/  100]    Loss 2.009546    Top1 46.370000    Top5 77.500000    
2024-02-17 11:12:01,373 - ==> Top1: 46.370    Top5: 77.500    Loss: 2.010

2024-02-17 11:12:01,385 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-17 11:12:01,385 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:12:01,469 - 

2024-02-17 11:12:01,469 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:12:09,263 - Epoch: [14][  100/  500]    Overall Loss 1.775488    Objective Loss 1.775488                                        LR 0.001000    Time 0.077881    
2024-02-17 11:12:16,660 - Epoch: [14][  200/  500]    Overall Loss 1.784257    Objective Loss 1.784257                                        LR 0.001000    Time 0.075902    
2024-02-17 11:12:24,069 - Epoch: [14][  300/  500]    Overall Loss 1.796584    Objective Loss 1.796584                                        LR 0.001000    Time 0.075282    
2024-02-17 11:12:31,460 - Epoch: [14][  400/  500]    Overall Loss 1.795666    Objective Loss 1.795666                                        LR 0.001000    Time 0.074929    
2024-02-17 11:12:38,834 - Epoch: [14][  500/  500]    Overall Loss 1.796371    Objective Loss 1.796371    Top1 48.000000    Top5 74.500000    LR 0.001000    Time 0.074683    
2024-02-17 11:12:38,962 - --- validate (epoch=14)-----------
2024-02-17 11:12:38,962 - 10000 samples (100 per mini-batch)
2024-02-17 11:12:42,043 - Epoch: [14][  100/  100]    Loss 2.156361    Top1 43.530000    Top5 76.080000    
2024-02-17 11:12:42,157 - ==> Top1: 43.530    Top5: 76.080    Loss: 2.156

2024-02-17 11:12:42,418 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-17 11:12:42,418 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:12:42,474 - 

2024-02-17 11:12:42,474 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:12:50,325 - Epoch: [15][  100/  500]    Overall Loss 1.753944    Objective Loss 1.753944                                        LR 0.001000    Time 0.078455    
2024-02-17 11:12:57,591 - Epoch: [15][  200/  500]    Overall Loss 1.765189    Objective Loss 1.765189                                        LR 0.001000    Time 0.075535    
2024-02-17 11:13:04,928 - Epoch: [15][  300/  500]    Overall Loss 1.756644    Objective Loss 1.756644                                        LR 0.001000    Time 0.074798    
2024-02-17 11:13:12,278 - Epoch: [15][  400/  500]    Overall Loss 1.757607    Objective Loss 1.757607                                        LR 0.001000    Time 0.074463    
2024-02-17 11:13:19,570 - Epoch: [15][  500/  500]    Overall Loss 1.759161    Objective Loss 1.759161    Top1 54.000000    Top5 80.000000    LR 0.001000    Time 0.074147    
2024-02-17 11:13:19,697 - --- validate (epoch=15)-----------
2024-02-17 11:13:19,697 - 10000 samples (100 per mini-batch)
2024-02-17 11:13:22,779 - Epoch: [15][  100/  100]    Loss 2.198651    Top1 44.390000    Top5 74.910000    
2024-02-17 11:13:22,899 - ==> Top1: 44.390    Top5: 74.910    Loss: 2.199

2024-02-17 11:13:22,905 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-17 11:13:22,905 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:13:22,963 - 

2024-02-17 11:13:22,964 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:13:30,202 - Epoch: [16][  100/  500]    Overall Loss 1.711494    Objective Loss 1.711494                                        LR 0.001000    Time 0.072333    
2024-02-17 11:13:37,128 - Epoch: [16][  200/  500]    Overall Loss 1.725115    Objective Loss 1.725115                                        LR 0.001000    Time 0.070779    
2024-02-17 11:13:44,490 - Epoch: [16][  300/  500]    Overall Loss 1.719435    Objective Loss 1.719435                                        LR 0.001000    Time 0.071716    
2024-02-17 11:13:52,041 - Epoch: [16][  400/  500]    Overall Loss 1.718150    Objective Loss 1.718150                                        LR 0.001000    Time 0.072655    
2024-02-17 11:13:59,681 - Epoch: [16][  500/  500]    Overall Loss 1.720831    Objective Loss 1.720831    Top1 49.500000    Top5 82.500000    LR 0.001000    Time 0.073395    
2024-02-17 11:13:59,860 - --- validate (epoch=16)-----------
2024-02-17 11:13:59,861 - 10000 samples (100 per mini-batch)
2024-02-17 11:14:03,187 - Epoch: [16][  100/  100]    Loss 2.099510    Top1 45.580000    Top5 77.060000    
2024-02-17 11:14:03,360 - ==> Top1: 45.580    Top5: 77.060    Loss: 2.100

2024-02-17 11:14:03,371 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-17 11:14:03,371 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:14:03,435 - 

2024-02-17 11:14:03,435 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:14:11,256 - Epoch: [17][  100/  500]    Overall Loss 1.660831    Objective Loss 1.660831                                        LR 0.001000    Time 0.078157    
2024-02-17 11:14:18,622 - Epoch: [17][  200/  500]    Overall Loss 1.676588    Objective Loss 1.676588                                        LR 0.001000    Time 0.075885    
2024-02-17 11:14:26,011 - Epoch: [17][  300/  500]    Overall Loss 1.675820    Objective Loss 1.675820                                        LR 0.001000    Time 0.075209    
2024-02-17 11:14:33,255 - Epoch: [17][  400/  500]    Overall Loss 1.679714    Objective Loss 1.679714                                        LR 0.001000    Time 0.074505    
2024-02-17 11:14:40,039 - Epoch: [17][  500/  500]    Overall Loss 1.685002    Objective Loss 1.685002    Top1 53.500000    Top5 84.500000    LR 0.001000    Time 0.073167    
2024-02-17 11:14:40,210 - --- validate (epoch=17)-----------
2024-02-17 11:14:40,211 - 10000 samples (100 per mini-batch)
2024-02-17 11:14:43,219 - Epoch: [17][  100/  100]    Loss 2.105406    Top1 45.680000    Top5 77.190000    
2024-02-17 11:14:43,353 - ==> Top1: 45.680    Top5: 77.190    Loss: 2.105

2024-02-17 11:14:43,362 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-17 11:14:43,362 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:14:43,422 - 

2024-02-17 11:14:43,422 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:14:51,538 - Epoch: [18][  100/  500]    Overall Loss 1.621041    Objective Loss 1.621041                                        LR 0.001000    Time 0.081104    
2024-02-17 11:14:58,807 - Epoch: [18][  200/  500]    Overall Loss 1.613933    Objective Loss 1.613933                                        LR 0.001000    Time 0.076877    
2024-02-17 11:15:06,016 - Epoch: [18][  300/  500]    Overall Loss 1.632973    Objective Loss 1.632973                                        LR 0.001000    Time 0.075268    
2024-02-17 11:15:13,239 - Epoch: [18][  400/  500]    Overall Loss 1.638953    Objective Loss 1.638953                                        LR 0.001000    Time 0.074498    
2024-02-17 11:15:20,580 - Epoch: [18][  500/  500]    Overall Loss 1.642707    Objective Loss 1.642707    Top1 50.500000    Top5 84.000000    LR 0.001000    Time 0.074274    
2024-02-17 11:15:20,689 - --- validate (epoch=18)-----------
2024-02-17 11:15:20,689 - 10000 samples (100 per mini-batch)
2024-02-17 11:15:23,766 - Epoch: [18][  100/  100]    Loss 1.904714    Top1 49.260000    Top5 79.860000    
2024-02-17 11:15:23,929 - ==> Top1: 49.260    Top5: 79.860    Loss: 1.905

2024-02-17 11:15:23,940 - ==> Best [Top1: 49.260   Top5: 79.860   Sparsity:0.00   Params: 753952 on epoch: 18]
2024-02-17 11:15:23,940 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:15:24,017 - 

2024-02-17 11:15:24,018 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:15:31,948 - Epoch: [19][  100/  500]    Overall Loss 1.607954    Objective Loss 1.607954                                        LR 0.001000    Time 0.079249    
2024-02-17 11:15:39,327 - Epoch: [19][  200/  500]    Overall Loss 1.585529    Objective Loss 1.585529                                        LR 0.001000    Time 0.076498    
2024-02-17 11:15:46,646 - Epoch: [19][  300/  500]    Overall Loss 1.596851    Objective Loss 1.596851                                        LR 0.001000    Time 0.075379    
2024-02-17 11:15:53,878 - Epoch: [19][  400/  500]    Overall Loss 1.601803    Objective Loss 1.601803                                        LR 0.001000    Time 0.074606    
2024-02-17 11:16:01,287 - Epoch: [19][  500/  500]    Overall Loss 1.603009    Objective Loss 1.603009    Top1 52.500000    Top5 87.000000    LR 0.001000    Time 0.074494    
2024-02-17 11:16:01,397 - --- validate (epoch=19)-----------
2024-02-17 11:16:01,397 - 10000 samples (100 per mini-batch)
2024-02-17 11:16:04,434 - Epoch: [19][  100/  100]    Loss 1.988589    Top1 48.330000    Top5 79.250000    
2024-02-17 11:16:04,599 - ==> Top1: 48.330    Top5: 79.250    Loss: 1.989

2024-02-17 11:16:04,609 - ==> Best [Top1: 49.260   Top5: 79.860   Sparsity:0.00   Params: 753952 on epoch: 18]
2024-02-17 11:16:04,610 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:16:04,671 - 

2024-02-17 11:16:04,671 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:16:12,683 - Epoch: [20][  100/  500]    Overall Loss 1.564594    Objective Loss 1.564594                                        LR 0.001000    Time 0.080064    
2024-02-17 11:16:20,053 - Epoch: [20][  200/  500]    Overall Loss 1.562131    Objective Loss 1.562131                                        LR 0.001000    Time 0.076850    
2024-02-17 11:16:27,456 - Epoch: [20][  300/  500]    Overall Loss 1.562905    Objective Loss 1.562905                                        LR 0.001000    Time 0.075896    
2024-02-17 11:16:34,741 - Epoch: [20][  400/  500]    Overall Loss 1.571484    Objective Loss 1.571484                                        LR 0.001000    Time 0.075124    
2024-02-17 11:16:42,077 - Epoch: [20][  500/  500]    Overall Loss 1.575743    Objective Loss 1.575743    Top1 57.000000    Top5 87.500000    LR 0.001000    Time 0.074764    
2024-02-17 11:16:42,198 - --- validate (epoch=20)-----------
2024-02-17 11:16:42,198 - 10000 samples (100 per mini-batch)
2024-02-17 11:16:45,243 - Epoch: [20][  100/  100]    Loss 1.934092    Top1 49.540000    Top5 80.070000    
2024-02-17 11:16:45,365 - ==> Top1: 49.540    Top5: 80.070    Loss: 1.934

2024-02-17 11:16:45,372 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-17 11:16:45,373 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:16:45,457 - 

2024-02-17 11:16:45,458 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:16:53,248 - Epoch: [21][  100/  500]    Overall Loss 1.538992    Objective Loss 1.538992                                        LR 0.001000    Time 0.077825    
2024-02-17 11:17:00,652 - Epoch: [21][  200/  500]    Overall Loss 1.546913    Objective Loss 1.546913                                        LR 0.001000    Time 0.075910    
2024-02-17 11:17:07,919 - Epoch: [21][  300/  500]    Overall Loss 1.546955    Objective Loss 1.546955                                        LR 0.001000    Time 0.074815    
2024-02-17 11:17:15,249 - Epoch: [21][  400/  500]    Overall Loss 1.549520    Objective Loss 1.549520                                        LR 0.001000    Time 0.074425    
2024-02-17 11:17:22,635 - Epoch: [21][  500/  500]    Overall Loss 1.548122    Objective Loss 1.548122    Top1 51.500000    Top5 83.000000    LR 0.001000    Time 0.074303    
2024-02-17 11:17:22,769 - --- validate (epoch=21)-----------
2024-02-17 11:17:22,770 - 10000 samples (100 per mini-batch)
2024-02-17 11:17:25,723 - Epoch: [21][  100/  100]    Loss 2.062266    Top1 47.660000    Top5 77.650000    
2024-02-17 11:17:25,894 - ==> Top1: 47.660    Top5: 77.650    Loss: 2.062

2024-02-17 11:17:25,911 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-17 11:17:25,912 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:17:25,994 - 

2024-02-17 11:17:25,994 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:17:34,259 - Epoch: [22][  100/  500]    Overall Loss 1.496551    Objective Loss 1.496551                                        LR 0.001000    Time 0.082589    
2024-02-17 11:17:41,576 - Epoch: [22][  200/  500]    Overall Loss 1.495316    Objective Loss 1.495316                                        LR 0.001000    Time 0.077860    
2024-02-17 11:17:48,712 - Epoch: [22][  300/  500]    Overall Loss 1.502963    Objective Loss 1.502963                                        LR 0.001000    Time 0.075680    
2024-02-17 11:17:55,818 - Epoch: [22][  400/  500]    Overall Loss 1.511468    Objective Loss 1.511468                                        LR 0.001000    Time 0.074517    
2024-02-17 11:18:03,005 - Epoch: [22][  500/  500]    Overall Loss 1.516580    Objective Loss 1.516580    Top1 61.000000    Top5 85.500000    LR 0.001000    Time 0.073981    
2024-02-17 11:18:03,131 - --- validate (epoch=22)-----------
2024-02-17 11:18:03,132 - 10000 samples (100 per mini-batch)
2024-02-17 11:18:06,119 - Epoch: [22][  100/  100]    Loss 2.009924    Top1 49.130000    Top5 79.100000    
2024-02-17 11:18:06,240 - ==> Top1: 49.130    Top5: 79.100    Loss: 2.010

2024-02-17 11:18:06,252 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-17 11:18:06,252 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:18:06,324 - 

2024-02-17 11:18:06,324 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:18:13,983 - Epoch: [23][  100/  500]    Overall Loss 1.491574    Objective Loss 1.491574                                        LR 0.001000    Time 0.076541    
2024-02-17 11:18:20,747 - Epoch: [23][  200/  500]    Overall Loss 1.483728    Objective Loss 1.483728                                        LR 0.001000    Time 0.072074    
2024-02-17 11:18:27,741 - Epoch: [23][  300/  500]    Overall Loss 1.485817    Objective Loss 1.485817                                        LR 0.001000    Time 0.071351    
2024-02-17 11:18:34,978 - Epoch: [23][  400/  500]    Overall Loss 1.494041    Objective Loss 1.494041                                        LR 0.001000    Time 0.071596    
2024-02-17 11:18:42,272 - Epoch: [23][  500/  500]    Overall Loss 1.495390    Objective Loss 1.495390    Top1 51.500000    Top5 80.000000    LR 0.001000    Time 0.071855    
2024-02-17 11:18:42,399 - --- validate (epoch=23)-----------
2024-02-17 11:18:42,400 - 10000 samples (100 per mini-batch)
2024-02-17 11:18:45,372 - Epoch: [23][  100/  100]    Loss 1.921122    Top1 49.480000    Top5 80.280000    
2024-02-17 11:18:45,487 - ==> Top1: 49.480    Top5: 80.280    Loss: 1.921

2024-02-17 11:18:45,498 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-17 11:18:45,498 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:18:45,562 - 

2024-02-17 11:18:45,562 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:18:53,684 - Epoch: [24][  100/  500]    Overall Loss 1.432018    Objective Loss 1.432018                                        LR 0.001000    Time 0.081160    
2024-02-17 11:19:01,061 - Epoch: [24][  200/  500]    Overall Loss 1.439184    Objective Loss 1.439184                                        LR 0.001000    Time 0.077447    
2024-02-17 11:19:08,270 - Epoch: [24][  300/  500]    Overall Loss 1.446274    Objective Loss 1.446274                                        LR 0.001000    Time 0.075648    
2024-02-17 11:19:15,508 - Epoch: [24][  400/  500]    Overall Loss 1.455156    Objective Loss 1.455156                                        LR 0.001000    Time 0.074820    
2024-02-17 11:19:23,068 - Epoch: [24][  500/  500]    Overall Loss 1.462438    Objective Loss 1.462438    Top1 54.500000    Top5 88.000000    LR 0.001000    Time 0.074967    
2024-02-17 11:19:23,191 - --- validate (epoch=24)-----------
2024-02-17 11:19:23,191 - 10000 samples (100 per mini-batch)
2024-02-17 11:19:26,205 - Epoch: [24][  100/  100]    Loss 2.288580    Top1 45.180000    Top5 76.230000    
2024-02-17 11:19:26,313 - ==> Top1: 45.180    Top5: 76.230    Loss: 2.289

2024-02-17 11:19:26,323 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-17 11:19:26,324 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:19:26,386 - 

2024-02-17 11:19:26,386 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:19:34,291 - Epoch: [25][  100/  500]    Overall Loss 1.423045    Objective Loss 1.423045                                        LR 0.001000    Time 0.078995    
2024-02-17 11:19:41,629 - Epoch: [25][  200/  500]    Overall Loss 1.432119    Objective Loss 1.432119                                        LR 0.001000    Time 0.076164    
2024-02-17 11:19:48,765 - Epoch: [25][  300/  500]    Overall Loss 1.435971    Objective Loss 1.435971                                        LR 0.001000    Time 0.074548    
2024-02-17 11:19:55,883 - Epoch: [25][  400/  500]    Overall Loss 1.439155    Objective Loss 1.439155                                        LR 0.001000    Time 0.073696    
2024-02-17 11:20:03,164 - Epoch: [25][  500/  500]    Overall Loss 1.446353    Objective Loss 1.446353    Top1 59.000000    Top5 88.000000    LR 0.001000    Time 0.073511    
2024-02-17 11:20:03,300 - --- validate (epoch=25)-----------
2024-02-17 11:20:03,301 - 10000 samples (100 per mini-batch)
2024-02-17 11:20:06,282 - Epoch: [25][  100/  100]    Loss 1.934736    Top1 50.320000    Top5 80.460000    
2024-02-17 11:20:06,448 - ==> Top1: 50.320    Top5: 80.460    Loss: 1.935

2024-02-17 11:20:06,456 - ==> Best [Top1: 50.320   Top5: 80.460   Sparsity:0.00   Params: 753952 on epoch: 25]
2024-02-17 11:20:06,456 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:20:06,534 - 

2024-02-17 11:20:06,534 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:20:13,871 - Epoch: [26][  100/  500]    Overall Loss 1.370702    Objective Loss 1.370702                                        LR 0.001000    Time 0.073317    
2024-02-17 11:20:20,731 - Epoch: [26][  200/  500]    Overall Loss 1.381659    Objective Loss 1.381659                                        LR 0.001000    Time 0.070944    
2024-02-17 11:20:28,003 - Epoch: [26][  300/  500]    Overall Loss 1.401317    Objective Loss 1.401317                                        LR 0.001000    Time 0.071520    
2024-02-17 11:20:35,296 - Epoch: [26][  400/  500]    Overall Loss 1.416794    Objective Loss 1.416794                                        LR 0.001000    Time 0.071864    
2024-02-17 11:20:42,680 - Epoch: [26][  500/  500]    Overall Loss 1.416493    Objective Loss 1.416493    Top1 64.500000    Top5 84.500000    LR 0.001000    Time 0.072249    
2024-02-17 11:20:42,823 - --- validate (epoch=26)-----------
2024-02-17 11:20:42,823 - 10000 samples (100 per mini-batch)
2024-02-17 11:20:46,122 - Epoch: [26][  100/  100]    Loss 1.971634    Top1 49.450000    Top5 79.280000    
2024-02-17 11:20:46,220 - ==> Top1: 49.450    Top5: 79.280    Loss: 1.972

2024-02-17 11:20:46,231 - ==> Best [Top1: 50.320   Top5: 80.460   Sparsity:0.00   Params: 753952 on epoch: 25]
2024-02-17 11:20:46,232 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:20:46,295 - 

2024-02-17 11:20:46,295 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:20:54,089 - Epoch: [27][  100/  500]    Overall Loss 1.348677    Objective Loss 1.348677                                        LR 0.001000    Time 0.077889    
2024-02-17 11:21:01,399 - Epoch: [27][  200/  500]    Overall Loss 1.366492    Objective Loss 1.366492                                        LR 0.001000    Time 0.075472    
2024-02-17 11:21:08,893 - Epoch: [27][  300/  500]    Overall Loss 1.378561    Objective Loss 1.378561                                        LR 0.001000    Time 0.075279    
2024-02-17 11:21:16,464 - Epoch: [27][  400/  500]    Overall Loss 1.381536    Objective Loss 1.381536                                        LR 0.001000    Time 0.075378    
2024-02-17 11:21:23,999 - Epoch: [27][  500/  500]    Overall Loss 1.394964    Objective Loss 1.394964    Top1 60.500000    Top5 88.000000    LR 0.001000    Time 0.075364    
2024-02-17 11:21:24,171 - --- validate (epoch=27)-----------
2024-02-17 11:21:24,172 - 10000 samples (100 per mini-batch)
2024-02-17 11:21:27,274 - Epoch: [27][  100/  100]    Loss 2.050875    Top1 49.450000    Top5 78.590000    
2024-02-17 11:21:27,401 - ==> Top1: 49.450    Top5: 78.590    Loss: 2.051

2024-02-17 11:21:27,407 - ==> Best [Top1: 50.320   Top5: 80.460   Sparsity:0.00   Params: 753952 on epoch: 25]
2024-02-17 11:21:27,408 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:21:27,468 - 

2024-02-17 11:21:27,468 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:21:35,500 - Epoch: [28][  100/  500]    Overall Loss 1.328535    Objective Loss 1.328535                                        LR 0.001000    Time 0.080263    
2024-02-17 11:21:42,593 - Epoch: [28][  200/  500]    Overall Loss 1.350845    Objective Loss 1.350845                                        LR 0.001000    Time 0.075581    
2024-02-17 11:21:50,112 - Epoch: [28][  300/  500]    Overall Loss 1.362088    Objective Loss 1.362088                                        LR 0.001000    Time 0.075438    
2024-02-17 11:21:57,578 - Epoch: [28][  400/  500]    Overall Loss 1.363851    Objective Loss 1.363851                                        LR 0.001000    Time 0.075232    
2024-02-17 11:22:05,085 - Epoch: [28][  500/  500]    Overall Loss 1.367499    Objective Loss 1.367499    Top1 62.000000    Top5 87.500000    LR 0.001000    Time 0.075191    
2024-02-17 11:22:05,254 - --- validate (epoch=28)-----------
2024-02-17 11:22:05,256 - 10000 samples (100 per mini-batch)
2024-02-17 11:22:08,280 - Epoch: [28][  100/  100]    Loss 1.873124    Top1 51.380000    Top5 81.140000    
2024-02-17 11:22:08,392 - ==> Top1: 51.380    Top5: 81.140    Loss: 1.873

2024-02-17 11:22:08,403 - ==> Best [Top1: 51.380   Top5: 81.140   Sparsity:0.00   Params: 753952 on epoch: 28]
2024-02-17 11:22:08,403 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:22:08,486 - 

2024-02-17 11:22:08,486 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:22:16,243 - Epoch: [29][  100/  500]    Overall Loss 1.325078    Objective Loss 1.325078                                        LR 0.001000    Time 0.077511    
2024-02-17 11:22:23,753 - Epoch: [29][  200/  500]    Overall Loss 1.337117    Objective Loss 1.337117                                        LR 0.001000    Time 0.076285    
2024-02-17 11:22:31,115 - Epoch: [29][  300/  500]    Overall Loss 1.347000    Objective Loss 1.347000                                        LR 0.001000    Time 0.075380    
2024-02-17 11:22:38,455 - Epoch: [29][  400/  500]    Overall Loss 1.351536    Objective Loss 1.351536                                        LR 0.001000    Time 0.074875    
2024-02-17 11:22:45,873 - Epoch: [29][  500/  500]    Overall Loss 1.354046    Objective Loss 1.354046    Top1 63.000000    Top5 88.500000    LR 0.001000    Time 0.074726    
2024-02-17 11:22:46,008 - --- validate (epoch=29)-----------
2024-02-17 11:22:46,008 - 10000 samples (100 per mini-batch)
2024-02-17 11:22:49,105 - Epoch: [29][  100/  100]    Loss 1.797290    Top1 53.410000    Top5 81.720000    
2024-02-17 11:22:49,230 - ==> Top1: 53.410    Top5: 81.720    Loss: 1.797

2024-02-17 11:22:49,237 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:22:49,237 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:22:49,306 - 

2024-02-17 11:22:49,306 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:22:57,116 - Epoch: [30][  100/  500]    Overall Loss 1.287730    Objective Loss 1.287730                                        LR 0.001000    Time 0.078040    
2024-02-17 11:23:04,427 - Epoch: [30][  200/  500]    Overall Loss 1.299301    Objective Loss 1.299301                                        LR 0.001000    Time 0.075553    
2024-02-17 11:23:11,518 - Epoch: [30][  300/  500]    Overall Loss 1.313185    Objective Loss 1.313185                                        LR 0.001000    Time 0.073993    
2024-02-17 11:23:18,766 - Epoch: [30][  400/  500]    Overall Loss 1.322461    Objective Loss 1.322461                                        LR 0.001000    Time 0.073605    
2024-02-17 11:23:26,157 - Epoch: [30][  500/  500]    Overall Loss 1.331671    Objective Loss 1.331671    Top1 67.000000    Top5 89.000000    LR 0.001000    Time 0.073658    
2024-02-17 11:23:26,312 - --- validate (epoch=30)-----------
2024-02-17 11:23:26,313 - 10000 samples (100 per mini-batch)
2024-02-17 11:23:29,812 - Epoch: [30][  100/  100]    Loss 1.824264    Top1 52.090000    Top5 80.960000    
2024-02-17 11:23:29,926 - ==> Top1: 52.090    Top5: 80.960    Loss: 1.824

2024-02-17 11:23:29,937 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:23:29,937 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:23:29,999 - 

2024-02-17 11:23:29,999 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:23:37,817 - Epoch: [31][  100/  500]    Overall Loss 1.285199    Objective Loss 1.285199                                        LR 0.001000    Time 0.078127    
2024-02-17 11:23:45,128 - Epoch: [31][  200/  500]    Overall Loss 1.281403    Objective Loss 1.281403                                        LR 0.001000    Time 0.075597    
2024-02-17 11:23:52,466 - Epoch: [31][  300/  500]    Overall Loss 1.289112    Objective Loss 1.289112                                        LR 0.001000    Time 0.074839    
2024-02-17 11:23:59,454 - Epoch: [31][  400/  500]    Overall Loss 1.297153    Objective Loss 1.297153                                        LR 0.001000    Time 0.073590    
2024-02-17 11:24:06,856 - Epoch: [31][  500/  500]    Overall Loss 1.304195    Objective Loss 1.304195    Top1 65.000000    Top5 88.000000    LR 0.001000    Time 0.073667    
2024-02-17 11:24:06,979 - --- validate (epoch=31)-----------
2024-02-17 11:24:06,980 - 10000 samples (100 per mini-batch)
2024-02-17 11:24:10,162 - Epoch: [31][  100/  100]    Loss 1.831615    Top1 52.490000    Top5 81.970000    
2024-02-17 11:24:10,291 - ==> Top1: 52.490    Top5: 81.970    Loss: 1.832

2024-02-17 11:24:10,303 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:24:10,303 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:24:10,367 - 

2024-02-17 11:24:10,368 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:24:18,401 - Epoch: [32][  100/  500]    Overall Loss 1.256892    Objective Loss 1.256892                                        LR 0.001000    Time 0.080278    
2024-02-17 11:24:25,693 - Epoch: [32][  200/  500]    Overall Loss 1.268618    Objective Loss 1.268618                                        LR 0.001000    Time 0.076577    
2024-02-17 11:24:33,059 - Epoch: [32][  300/  500]    Overall Loss 1.278748    Objective Loss 1.278748                                        LR 0.001000    Time 0.075591    
2024-02-17 11:24:40,450 - Epoch: [32][  400/  500]    Overall Loss 1.282109    Objective Loss 1.282109                                        LR 0.001000    Time 0.075159    
2024-02-17 11:24:47,732 - Epoch: [32][  500/  500]    Overall Loss 1.286492    Objective Loss 1.286492    Top1 62.000000    Top5 92.000000    LR 0.001000    Time 0.074684    
2024-02-17 11:24:47,909 - --- validate (epoch=32)-----------
2024-02-17 11:24:47,910 - 10000 samples (100 per mini-batch)
2024-02-17 11:24:51,091 - Epoch: [32][  100/  100]    Loss 1.907953    Top1 51.330000    Top5 81.220000    
2024-02-17 11:24:51,184 - ==> Top1: 51.330    Top5: 81.220    Loss: 1.908

2024-02-17 11:24:51,198 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:24:51,198 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:24:51,267 - 

2024-02-17 11:24:51,268 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:24:59,099 - Epoch: [33][  100/  500]    Overall Loss 1.234660    Objective Loss 1.234660                                        LR 0.001000    Time 0.078252    
2024-02-17 11:25:06,476 - Epoch: [33][  200/  500]    Overall Loss 1.252759    Objective Loss 1.252759                                        LR 0.001000    Time 0.075991    
2024-02-17 11:25:13,769 - Epoch: [33][  300/  500]    Overall Loss 1.261966    Objective Loss 1.261966                                        LR 0.001000    Time 0.074957    
2024-02-17 11:25:21,153 - Epoch: [33][  400/  500]    Overall Loss 1.266817    Objective Loss 1.266817                                        LR 0.001000    Time 0.074667    
2024-02-17 11:25:28,706 - Epoch: [33][  500/  500]    Overall Loss 1.273002    Objective Loss 1.273002    Top1 59.500000    Top5 85.000000    LR 0.001000    Time 0.074832    
2024-02-17 11:25:28,858 - --- validate (epoch=33)-----------
2024-02-17 11:25:28,859 - 10000 samples (100 per mini-batch)
2024-02-17 11:25:31,942 - Epoch: [33][  100/  100]    Loss 1.876940    Top1 51.540000    Top5 81.710000    
2024-02-17 11:25:32,078 - ==> Top1: 51.540    Top5: 81.710    Loss: 1.877

2024-02-17 11:25:32,089 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:25:32,089 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:25:32,153 - 

2024-02-17 11:25:32,153 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:25:39,846 - Epoch: [34][  100/  500]    Overall Loss 1.218805    Objective Loss 1.218805                                        LR 0.001000    Time 0.076877    
2024-02-17 11:25:47,185 - Epoch: [34][  200/  500]    Overall Loss 1.223326    Objective Loss 1.223326                                        LR 0.001000    Time 0.075107    
2024-02-17 11:25:54,496 - Epoch: [34][  300/  500]    Overall Loss 1.228984    Objective Loss 1.228984                                        LR 0.001000    Time 0.074428    
2024-02-17 11:26:01,760 - Epoch: [34][  400/  500]    Overall Loss 1.236273    Objective Loss 1.236273                                        LR 0.001000    Time 0.073972    
2024-02-17 11:26:08,653 - Epoch: [34][  500/  500]    Overall Loss 1.248150    Objective Loss 1.248150    Top1 64.000000    Top5 90.500000    LR 0.001000    Time 0.072957    
2024-02-17 11:26:08,777 - --- validate (epoch=34)-----------
2024-02-17 11:26:08,778 - 10000 samples (100 per mini-batch)
2024-02-17 11:26:12,179 - Epoch: [34][  100/  100]    Loss 1.937653    Top1 52.230000    Top5 80.870000    
2024-02-17 11:26:12,290 - ==> Top1: 52.230    Top5: 80.870    Loss: 1.938

2024-02-17 11:26:12,296 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:26:12,296 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:26:12,354 - 

2024-02-17 11:26:12,354 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:26:20,145 - Epoch: [35][  100/  500]    Overall Loss 1.183362    Objective Loss 1.183362                                        LR 0.001000    Time 0.077850    
2024-02-17 11:26:27,527 - Epoch: [35][  200/  500]    Overall Loss 1.197224    Objective Loss 1.197224                                        LR 0.001000    Time 0.075816    
2024-02-17 11:26:34,892 - Epoch: [35][  300/  500]    Overall Loss 1.205798    Objective Loss 1.205798                                        LR 0.001000    Time 0.075079    
2024-02-17 11:26:42,211 - Epoch: [35][  400/  500]    Overall Loss 1.225171    Objective Loss 1.225171                                        LR 0.001000    Time 0.074596    
2024-02-17 11:26:49,545 - Epoch: [35][  500/  500]    Overall Loss 1.231215    Objective Loss 1.231215    Top1 63.000000    Top5 90.000000    LR 0.001000    Time 0.074338    
2024-02-17 11:26:49,673 - --- validate (epoch=35)-----------
2024-02-17 11:26:49,674 - 10000 samples (100 per mini-batch)
2024-02-17 11:26:52,671 - Epoch: [35][  100/  100]    Loss 1.796121    Top1 53.010000    Top5 82.540000    
2024-02-17 11:26:52,780 - ==> Top1: 53.010    Top5: 82.540    Loss: 1.796

2024-02-17 11:26:52,787 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:26:52,787 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:26:52,844 - 

2024-02-17 11:26:52,844 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:27:00,844 - Epoch: [36][  100/  500]    Overall Loss 1.157656    Objective Loss 1.157656                                        LR 0.001000    Time 0.079942    
2024-02-17 11:27:08,130 - Epoch: [36][  200/  500]    Overall Loss 1.183921    Objective Loss 1.183921                                        LR 0.001000    Time 0.076383    
2024-02-17 11:27:15,569 - Epoch: [36][  300/  500]    Overall Loss 1.203144    Objective Loss 1.203144                                        LR 0.001000    Time 0.075706    
2024-02-17 11:27:23,020 - Epoch: [36][  400/  500]    Overall Loss 1.207459    Objective Loss 1.207459                                        LR 0.001000    Time 0.075397    
2024-02-17 11:27:30,265 - Epoch: [36][  500/  500]    Overall Loss 1.211898    Objective Loss 1.211898    Top1 68.000000    Top5 90.500000    LR 0.001000    Time 0.074801    
2024-02-17 11:27:30,431 - --- validate (epoch=36)-----------
2024-02-17 11:27:30,431 - 10000 samples (100 per mini-batch)
2024-02-17 11:27:33,353 - Epoch: [36][  100/  100]    Loss 1.850014    Top1 52.670000    Top5 81.390000    
2024-02-17 11:27:33,471 - ==> Top1: 52.670    Top5: 81.390    Loss: 1.850

2024-02-17 11:27:33,483 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:27:33,483 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:27:33,548 - 

2024-02-17 11:27:33,548 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:27:41,258 - Epoch: [37][  100/  500]    Overall Loss 1.168624    Objective Loss 1.168624                                        LR 0.001000    Time 0.077045    
2024-02-17 11:27:48,751 - Epoch: [37][  200/  500]    Overall Loss 1.180387    Objective Loss 1.180387                                        LR 0.001000    Time 0.075968    
2024-02-17 11:27:56,145 - Epoch: [37][  300/  500]    Overall Loss 1.177521    Objective Loss 1.177521                                        LR 0.001000    Time 0.075279    
2024-02-17 11:28:03,483 - Epoch: [37][  400/  500]    Overall Loss 1.183165    Objective Loss 1.183165                                        LR 0.001000    Time 0.074792    
2024-02-17 11:28:10,932 - Epoch: [37][  500/  500]    Overall Loss 1.195524    Objective Loss 1.195524    Top1 57.000000    Top5 86.000000    LR 0.001000    Time 0.074725    
2024-02-17 11:28:11,084 - --- validate (epoch=37)-----------
2024-02-17 11:28:11,086 - 10000 samples (100 per mini-batch)
2024-02-17 11:28:14,268 - Epoch: [37][  100/  100]    Loss 1.863734    Top1 52.960000    Top5 81.110000    
2024-02-17 11:28:14,396 - ==> Top1: 52.960    Top5: 81.110    Loss: 1.864

2024-02-17 11:28:14,405 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:28:14,405 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:28:14,470 - 

2024-02-17 11:28:14,470 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:28:22,713 - Epoch: [38][  100/  500]    Overall Loss 1.126354    Objective Loss 1.126354                                        LR 0.001000    Time 0.082364    
2024-02-17 11:28:30,028 - Epoch: [38][  200/  500]    Overall Loss 1.148542    Objective Loss 1.148542                                        LR 0.001000    Time 0.077739    
2024-02-17 11:28:37,313 - Epoch: [38][  300/  500]    Overall Loss 1.159107    Objective Loss 1.159107                                        LR 0.001000    Time 0.076093    
2024-02-17 11:28:44,661 - Epoch: [38][  400/  500]    Overall Loss 1.166049    Objective Loss 1.166049                                        LR 0.001000    Time 0.075429    
2024-02-17 11:28:52,009 - Epoch: [38][  500/  500]    Overall Loss 1.173457    Objective Loss 1.173457    Top1 60.000000    Top5 89.500000    LR 0.001000    Time 0.075032    
2024-02-17 11:28:52,142 - --- validate (epoch=38)-----------
2024-02-17 11:28:52,143 - 10000 samples (100 per mini-batch)
2024-02-17 11:28:55,101 - Epoch: [38][  100/  100]    Loss 1.933706    Top1 51.900000    Top5 81.390000    
2024-02-17 11:28:55,209 - ==> Top1: 51.900    Top5: 81.390    Loss: 1.934

2024-02-17 11:28:55,219 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:28:55,219 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:28:55,284 - 

2024-02-17 11:28:55,284 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:29:02,737 - Epoch: [39][  100/  500]    Overall Loss 1.136036    Objective Loss 1.136036                                        LR 0.001000    Time 0.074481    
2024-02-17 11:29:09,606 - Epoch: [39][  200/  500]    Overall Loss 1.146980    Objective Loss 1.146980                                        LR 0.001000    Time 0.071567    
2024-02-17 11:29:16,957 - Epoch: [39][  300/  500]    Overall Loss 1.155615    Objective Loss 1.155615                                        LR 0.001000    Time 0.072201    
2024-02-17 11:29:24,396 - Epoch: [39][  400/  500]    Overall Loss 1.160542    Objective Loss 1.160542                                        LR 0.001000    Time 0.072736    
2024-02-17 11:29:31,642 - Epoch: [39][  500/  500]    Overall Loss 1.164606    Objective Loss 1.164606    Top1 64.500000    Top5 92.500000    LR 0.001000    Time 0.072674    
2024-02-17 11:29:31,792 - --- validate (epoch=39)-----------
2024-02-17 11:29:31,793 - 10000 samples (100 per mini-batch)
2024-02-17 11:29:34,753 - Epoch: [39][  100/  100]    Loss 1.959881    Top1 52.020000    Top5 80.500000    
2024-02-17 11:29:34,921 - ==> Top1: 52.020    Top5: 80.500    Loss: 1.960

2024-02-17 11:29:34,932 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:29:34,933 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:29:34,997 - 

2024-02-17 11:29:34,997 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:29:42,732 - Epoch: [40][  100/  500]    Overall Loss 1.099555    Objective Loss 1.099555                                        LR 0.001000    Time 0.077288    
2024-02-17 11:29:50,210 - Epoch: [40][  200/  500]    Overall Loss 1.107798    Objective Loss 1.107798                                        LR 0.001000    Time 0.076011    
2024-02-17 11:29:57,697 - Epoch: [40][  300/  500]    Overall Loss 1.119186    Objective Loss 1.119186                                        LR 0.001000    Time 0.075619    
2024-02-17 11:30:05,182 - Epoch: [40][  400/  500]    Overall Loss 1.135157    Objective Loss 1.135157                                        LR 0.001000    Time 0.075416    
2024-02-17 11:30:12,584 - Epoch: [40][  500/  500]    Overall Loss 1.139456    Objective Loss 1.139456    Top1 67.500000    Top5 91.000000    LR 0.001000    Time 0.075128    
2024-02-17 11:30:12,747 - --- validate (epoch=40)-----------
2024-02-17 11:30:12,747 - 10000 samples (100 per mini-batch)
2024-02-17 11:30:16,162 - Epoch: [40][  100/  100]    Loss 1.839705    Top1 53.910000    Top5 82.340000    
2024-02-17 11:30:16,266 - ==> Top1: 53.910    Top5: 82.340    Loss: 1.840

2024-02-17 11:30:16,272 - ==> Best [Top1: 53.910   Top5: 82.340   Sparsity:0.00   Params: 753952 on epoch: 40]
2024-02-17 11:30:16,272 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:30:16,344 - 

2024-02-17 11:30:16,344 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:30:24,221 - Epoch: [41][  100/  500]    Overall Loss 1.098113    Objective Loss 1.098113                                        LR 0.001000    Time 0.078714    
2024-02-17 11:30:31,573 - Epoch: [41][  200/  500]    Overall Loss 1.099937    Objective Loss 1.099937                                        LR 0.001000    Time 0.076093    
2024-02-17 11:30:38,779 - Epoch: [41][  300/  500]    Overall Loss 1.105861    Objective Loss 1.105861                                        LR 0.001000    Time 0.074737    
2024-02-17 11:30:46,013 - Epoch: [41][  400/  500]    Overall Loss 1.114760    Objective Loss 1.114760                                        LR 0.001000    Time 0.074126    
2024-02-17 11:30:53,320 - Epoch: [41][  500/  500]    Overall Loss 1.122951    Objective Loss 1.122951    Top1 68.000000    Top5 91.500000    LR 0.001000    Time 0.073906    
2024-02-17 11:30:53,447 - --- validate (epoch=41)-----------
2024-02-17 11:30:53,448 - 10000 samples (100 per mini-batch)
2024-02-17 11:30:56,595 - Epoch: [41][  100/  100]    Loss 1.782460    Top1 54.690000    Top5 82.720000    
2024-02-17 11:30:56,693 - ==> Top1: 54.690    Top5: 82.720    Loss: 1.782

2024-02-17 11:30:56,706 - ==> Best [Top1: 54.690   Top5: 82.720   Sparsity:0.00   Params: 753952 on epoch: 41]
2024-02-17 11:30:56,706 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:30:56,788 - 

2024-02-17 11:30:56,788 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:31:04,945 - Epoch: [42][  100/  500]    Overall Loss 1.089304    Objective Loss 1.089304                                        LR 0.001000    Time 0.081512    
2024-02-17 11:31:12,345 - Epoch: [42][  200/  500]    Overall Loss 1.088567    Objective Loss 1.088567                                        LR 0.001000    Time 0.077735    
2024-02-17 11:31:19,743 - Epoch: [42][  300/  500]    Overall Loss 1.090409    Objective Loss 1.090409                                        LR 0.001000    Time 0.076467    
2024-02-17 11:31:27,054 - Epoch: [42][  400/  500]    Overall Loss 1.103778    Objective Loss 1.103778                                        LR 0.001000    Time 0.075618    
2024-02-17 11:31:34,381 - Epoch: [42][  500/  500]    Overall Loss 1.108860    Objective Loss 1.108860    Top1 71.500000    Top5 90.000000    LR 0.001000    Time 0.075140    
2024-02-17 11:31:34,501 - --- validate (epoch=42)-----------
2024-02-17 11:31:34,501 - 10000 samples (100 per mini-batch)
2024-02-17 11:31:37,596 - Epoch: [42][  100/  100]    Loss 1.801879    Top1 54.520000    Top5 82.590000    
2024-02-17 11:31:37,708 - ==> Top1: 54.520    Top5: 82.590    Loss: 1.802

2024-02-17 11:31:37,719 - ==> Best [Top1: 54.690   Top5: 82.720   Sparsity:0.00   Params: 753952 on epoch: 41]
2024-02-17 11:31:37,719 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:31:37,780 - 

2024-02-17 11:31:37,780 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:31:45,644 - Epoch: [43][  100/  500]    Overall Loss 1.059019    Objective Loss 1.059019                                        LR 0.001000    Time 0.078583    
2024-02-17 11:31:52,997 - Epoch: [43][  200/  500]    Overall Loss 1.070833    Objective Loss 1.070833                                        LR 0.001000    Time 0.076034    
2024-02-17 11:32:00,383 - Epoch: [43][  300/  500]    Overall Loss 1.076827    Objective Loss 1.076827                                        LR 0.001000    Time 0.075293    
2024-02-17 11:32:07,687 - Epoch: [43][  400/  500]    Overall Loss 1.089423    Objective Loss 1.089423                                        LR 0.001000    Time 0.074721    
2024-02-17 11:32:15,032 - Epoch: [43][  500/  500]    Overall Loss 1.100200    Objective Loss 1.100200    Top1 63.000000    Top5 89.000000    LR 0.001000    Time 0.074458    
2024-02-17 11:32:15,193 - --- validate (epoch=43)-----------
2024-02-17 11:32:15,194 - 10000 samples (100 per mini-batch)
2024-02-17 11:32:18,151 - Epoch: [43][  100/  100]    Loss 1.852823    Top1 53.770000    Top5 83.190000    
2024-02-17 11:32:18,289 - ==> Top1: 53.770    Top5: 83.190    Loss: 1.853

2024-02-17 11:32:18,299 - ==> Best [Top1: 54.690   Top5: 82.720   Sparsity:0.00   Params: 753952 on epoch: 41]
2024-02-17 11:32:18,300 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:32:18,359 - 

2024-02-17 11:32:18,360 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:32:26,444 - Epoch: [44][  100/  500]    Overall Loss 1.047904    Objective Loss 1.047904                                        LR 0.001000    Time 0.080786    
2024-02-17 11:32:33,647 - Epoch: [44][  200/  500]    Overall Loss 1.062250    Objective Loss 1.062250                                        LR 0.001000    Time 0.076388    
2024-02-17 11:32:40,950 - Epoch: [44][  300/  500]    Overall Loss 1.065268    Objective Loss 1.065268                                        LR 0.001000    Time 0.075255    
2024-02-17 11:32:48,221 - Epoch: [44][  400/  500]    Overall Loss 1.066647    Objective Loss 1.066647                                        LR 0.001000    Time 0.074609    
2024-02-17 11:32:55,483 - Epoch: [44][  500/  500]    Overall Loss 1.078985    Objective Loss 1.078985    Top1 67.000000    Top5 87.500000    LR 0.001000    Time 0.074204    
2024-02-17 11:32:55,650 - --- validate (epoch=44)-----------
2024-02-17 11:32:55,651 - 10000 samples (100 per mini-batch)
2024-02-17 11:32:58,627 - Epoch: [44][  100/  100]    Loss 1.821990    Top1 54.740000    Top5 82.280000    
2024-02-17 11:32:58,731 - ==> Top1: 54.740    Top5: 82.280    Loss: 1.822

2024-02-17 11:32:58,742 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-17 11:32:58,743 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:32:58,821 - 

2024-02-17 11:32:58,822 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:33:06,607 - Epoch: [45][  100/  500]    Overall Loss 1.003887    Objective Loss 1.003887                                        LR 0.001000    Time 0.077792    
2024-02-17 11:33:13,835 - Epoch: [45][  200/  500]    Overall Loss 1.031504    Objective Loss 1.031504                                        LR 0.001000    Time 0.075014    
2024-02-17 11:33:20,756 - Epoch: [45][  300/  500]    Overall Loss 1.046354    Objective Loss 1.046354                                        LR 0.001000    Time 0.073066    
2024-02-17 11:33:28,137 - Epoch: [45][  400/  500]    Overall Loss 1.056035    Objective Loss 1.056035                                        LR 0.001000    Time 0.073243    
2024-02-17 11:33:35,505 - Epoch: [45][  500/  500]    Overall Loss 1.068227    Objective Loss 1.068227    Top1 66.000000    Top5 89.000000    LR 0.001000    Time 0.073323    
2024-02-17 11:33:35,620 - --- validate (epoch=45)-----------
2024-02-17 11:33:35,621 - 10000 samples (100 per mini-batch)
2024-02-17 11:33:38,581 - Epoch: [45][  100/  100]    Loss 1.828801    Top1 54.110000    Top5 82.480000    
2024-02-17 11:33:38,708 - ==> Top1: 54.110    Top5: 82.480    Loss: 1.829

2024-02-17 11:33:38,720 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-17 11:33:38,720 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:33:38,782 - 

2024-02-17 11:33:38,783 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:33:46,528 - Epoch: [46][  100/  500]    Overall Loss 1.009476    Objective Loss 1.009476                                        LR 0.001000    Time 0.077397    
2024-02-17 11:33:53,932 - Epoch: [46][  200/  500]    Overall Loss 1.027685    Objective Loss 1.027685                                        LR 0.001000    Time 0.075700    
2024-02-17 11:34:01,415 - Epoch: [46][  300/  500]    Overall Loss 1.036520    Objective Loss 1.036520                                        LR 0.001000    Time 0.075394    
2024-02-17 11:34:08,847 - Epoch: [46][  400/  500]    Overall Loss 1.042552    Objective Loss 1.042552                                        LR 0.001000    Time 0.075117    
2024-02-17 11:34:16,307 - Epoch: [46][  500/  500]    Overall Loss 1.052531    Objective Loss 1.052531    Top1 73.000000    Top5 96.000000    LR 0.001000    Time 0.075004    
2024-02-17 11:34:16,483 - --- validate (epoch=46)-----------
2024-02-17 11:34:16,483 - 10000 samples (100 per mini-batch)
2024-02-17 11:34:19,706 - Epoch: [46][  100/  100]    Loss 1.830720    Top1 53.730000    Top5 82.630000    
2024-02-17 11:34:19,832 - ==> Top1: 53.730    Top5: 82.630    Loss: 1.831

2024-02-17 11:34:19,842 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-17 11:34:19,843 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:34:19,908 - 

2024-02-17 11:34:19,908 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:34:27,790 - Epoch: [47][  100/  500]    Overall Loss 0.999660    Objective Loss 0.999660                                        LR 0.001000    Time 0.078761    
2024-02-17 11:34:35,191 - Epoch: [47][  200/  500]    Overall Loss 1.003852    Objective Loss 1.003852                                        LR 0.001000    Time 0.076362    
2024-02-17 11:34:42,236 - Epoch: [47][  300/  500]    Overall Loss 1.014563    Objective Loss 1.014563                                        LR 0.001000    Time 0.074379    
2024-02-17 11:34:49,553 - Epoch: [47][  400/  500]    Overall Loss 1.020945    Objective Loss 1.020945                                        LR 0.001000    Time 0.074065    
2024-02-17 11:34:56,463 - Epoch: [47][  500/  500]    Overall Loss 1.030677    Objective Loss 1.030677    Top1 70.000000    Top5 95.000000    LR 0.001000    Time 0.073066    
2024-02-17 11:34:56,593 - --- validate (epoch=47)-----------
2024-02-17 11:34:56,594 - 10000 samples (100 per mini-batch)
2024-02-17 11:34:59,579 - Epoch: [47][  100/  100]    Loss 1.896644    Top1 54.310000    Top5 82.350000    
2024-02-17 11:34:59,762 - ==> Top1: 54.310    Top5: 82.350    Loss: 1.897

2024-02-17 11:34:59,775 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-17 11:34:59,776 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:34:59,839 - 

2024-02-17 11:34:59,839 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:35:07,686 - Epoch: [48][  100/  500]    Overall Loss 1.005949    Objective Loss 1.005949                                        LR 0.001000    Time 0.078416    
2024-02-17 11:35:14,987 - Epoch: [48][  200/  500]    Overall Loss 1.002851    Objective Loss 1.002851                                        LR 0.001000    Time 0.075689    
2024-02-17 11:35:22,377 - Epoch: [48][  300/  500]    Overall Loss 1.013319    Objective Loss 1.013319                                        LR 0.001000    Time 0.075079    
2024-02-17 11:35:29,710 - Epoch: [48][  400/  500]    Overall Loss 1.015516    Objective Loss 1.015516                                        LR 0.001000    Time 0.074631    
2024-02-17 11:35:37,110 - Epoch: [48][  500/  500]    Overall Loss 1.024054    Objective Loss 1.024054    Top1 69.000000    Top5 93.000000    LR 0.001000    Time 0.074497    
2024-02-17 11:35:37,271 - --- validate (epoch=48)-----------
2024-02-17 11:35:37,272 - 10000 samples (100 per mini-batch)
2024-02-17 11:35:40,224 - Epoch: [48][  100/  100]    Loss 1.873272    Top1 54.180000    Top5 82.180000    
2024-02-17 11:35:40,340 - ==> Top1: 54.180    Top5: 82.180    Loss: 1.873

2024-02-17 11:35:40,352 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-17 11:35:40,353 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:35:40,415 - 

2024-02-17 11:35:40,416 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:35:48,157 - Epoch: [49][  100/  500]    Overall Loss 0.991793    Objective Loss 0.991793                                        LR 0.001000    Time 0.077360    
2024-02-17 11:35:55,501 - Epoch: [49][  200/  500]    Overall Loss 0.981546    Objective Loss 0.981546                                        LR 0.001000    Time 0.075379    
2024-02-17 11:36:02,884 - Epoch: [49][  300/  500]    Overall Loss 0.990645    Objective Loss 0.990645                                        LR 0.001000    Time 0.074849    
2024-02-17 11:36:10,145 - Epoch: [49][  400/  500]    Overall Loss 1.000108    Objective Loss 1.000108                                        LR 0.001000    Time 0.074279    
2024-02-17 11:36:17,397 - Epoch: [49][  500/  500]    Overall Loss 1.004350    Objective Loss 1.004350    Top1 66.000000    Top5 91.000000    LR 0.001000    Time 0.073918    
2024-02-17 11:36:17,512 - --- validate (epoch=49)-----------
2024-02-17 11:36:17,512 - 10000 samples (100 per mini-batch)
2024-02-17 11:36:20,386 - Epoch: [49][  100/  100]    Loss 1.923390    Top1 53.300000    Top5 82.380000    
2024-02-17 11:36:20,478 - ==> Top1: 53.300    Top5: 82.380    Loss: 1.923

2024-02-17 11:36:20,484 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-17 11:36:20,484 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:36:20,541 - 

2024-02-17 11:36:20,541 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:36:28,467 - Epoch: [50][  100/  500]    Overall Loss 0.891832    Objective Loss 0.891832                                        LR 0.000500    Time 0.079208    
2024-02-17 11:36:35,830 - Epoch: [50][  200/  500]    Overall Loss 0.875344    Objective Loss 0.875344                                        LR 0.000500    Time 0.076397    
2024-02-17 11:36:43,183 - Epoch: [50][  300/  500]    Overall Loss 0.871916    Objective Loss 0.871916                                        LR 0.000500    Time 0.075426    
2024-02-17 11:36:50,452 - Epoch: [50][  400/  500]    Overall Loss 0.872488    Objective Loss 0.872488                                        LR 0.000500    Time 0.074733    
2024-02-17 11:36:57,940 - Epoch: [50][  500/  500]    Overall Loss 0.877727    Objective Loss 0.877727    Top1 69.000000    Top5 92.500000    LR 0.000500    Time 0.074753    
2024-02-17 11:36:58,093 - --- validate (epoch=50)-----------
2024-02-17 11:36:58,094 - 10000 samples (100 per mini-batch)
2024-02-17 11:37:01,027 - Epoch: [50][  100/  100]    Loss 1.586217    Top1 58.580000    Top5 85.530000    
2024-02-17 11:37:01,135 - ==> Top1: 58.580    Top5: 85.530    Loss: 1.586

2024-02-17 11:37:01,147 - ==> Best [Top1: 58.580   Top5: 85.530   Sparsity:0.00   Params: 753952 on epoch: 50]
2024-02-17 11:37:01,147 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:37:01,227 - 

2024-02-17 11:37:01,227 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:37:08,867 - Epoch: [51][  100/  500]    Overall Loss 0.807896    Objective Loss 0.807896                                        LR 0.000500    Time 0.076348    
2024-02-17 11:37:16,209 - Epoch: [51][  200/  500]    Overall Loss 0.833882    Objective Loss 0.833882                                        LR 0.000500    Time 0.074861    
2024-02-17 11:37:23,583 - Epoch: [51][  300/  500]    Overall Loss 0.841966    Objective Loss 0.841966                                        LR 0.000500    Time 0.074474    
2024-02-17 11:37:30,930 - Epoch: [51][  400/  500]    Overall Loss 0.849738    Objective Loss 0.849738                                        LR 0.000500    Time 0.074212    
2024-02-17 11:37:38,292 - Epoch: [51][  500/  500]    Overall Loss 0.849891    Objective Loss 0.849891    Top1 72.000000    Top5 95.500000    LR 0.000500    Time 0.074086    
2024-02-17 11:37:38,481 - --- validate (epoch=51)-----------
2024-02-17 11:37:38,482 - 10000 samples (100 per mini-batch)
2024-02-17 11:37:41,361 - Epoch: [51][  100/  100]    Loss 1.623510    Top1 58.210000    Top5 85.200000    
2024-02-17 11:37:41,461 - ==> Top1: 58.210    Top5: 85.200    Loss: 1.624

2024-02-17 11:37:41,472 - ==> Best [Top1: 58.580   Top5: 85.530   Sparsity:0.00   Params: 753952 on epoch: 50]
2024-02-17 11:37:41,472 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:37:41,534 - 

2024-02-17 11:37:41,535 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:37:49,475 - Epoch: [52][  100/  500]    Overall Loss 0.800980    Objective Loss 0.800980                                        LR 0.000500    Time 0.079348    
2024-02-17 11:37:56,791 - Epoch: [52][  200/  500]    Overall Loss 0.809246    Objective Loss 0.809246                                        LR 0.000500    Time 0.076233    
2024-02-17 11:38:04,018 - Epoch: [52][  300/  500]    Overall Loss 0.815269    Objective Loss 0.815269                                        LR 0.000500    Time 0.074900    
2024-02-17 11:38:11,286 - Epoch: [52][  400/  500]    Overall Loss 0.828829    Objective Loss 0.828829                                        LR 0.000500    Time 0.074336    
2024-02-17 11:38:18,489 - Epoch: [52][  500/  500]    Overall Loss 0.833809    Objective Loss 0.833809    Top1 72.000000    Top5 93.000000    LR 0.000500    Time 0.073867    
2024-02-17 11:38:18,624 - --- validate (epoch=52)-----------
2024-02-17 11:38:18,625 - 10000 samples (100 per mini-batch)
2024-02-17 11:38:21,550 - Epoch: [52][  100/  100]    Loss 1.649348    Top1 58.060000    Top5 85.130000    
2024-02-17 11:38:21,726 - ==> Top1: 58.060    Top5: 85.130    Loss: 1.649

2024-02-17 11:38:21,739 - ==> Best [Top1: 58.580   Top5: 85.530   Sparsity:0.00   Params: 753952 on epoch: 50]
2024-02-17 11:38:21,739 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:38:21,802 - 

2024-02-17 11:38:21,803 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:38:29,623 - Epoch: [53][  100/  500]    Overall Loss 0.789713    Objective Loss 0.789713                                        LR 0.000500    Time 0.078151    
2024-02-17 11:38:36,935 - Epoch: [53][  200/  500]    Overall Loss 0.799589    Objective Loss 0.799589                                        LR 0.000500    Time 0.075611    
2024-02-17 11:38:44,230 - Epoch: [53][  300/  500]    Overall Loss 0.810559    Objective Loss 0.810559                                        LR 0.000500    Time 0.074711    
2024-02-17 11:38:51,580 - Epoch: [53][  400/  500]    Overall Loss 0.815939    Objective Loss 0.815939                                        LR 0.000500    Time 0.074399    
2024-02-17 11:38:58,868 - Epoch: [53][  500/  500]    Overall Loss 0.820874    Objective Loss 0.820874    Top1 70.000000    Top5 95.000000    LR 0.000500    Time 0.074086    
2024-02-17 11:38:59,069 - --- validate (epoch=53)-----------
2024-02-17 11:38:59,070 - 10000 samples (100 per mini-batch)
2024-02-17 11:39:01,925 - Epoch: [53][  100/  100]    Loss 1.603811    Top1 58.960000    Top5 85.370000    
2024-02-17 11:39:02,094 - ==> Top1: 58.960    Top5: 85.370    Loss: 1.604

2024-02-17 11:39:02,106 - ==> Best [Top1: 58.960   Top5: 85.370   Sparsity:0.00   Params: 753952 on epoch: 53]
2024-02-17 11:39:02,106 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:39:02,182 - 

2024-02-17 11:39:02,183 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:39:10,158 - Epoch: [54][  100/  500]    Overall Loss 0.796024    Objective Loss 0.796024                                        LR 0.000500    Time 0.079702    
2024-02-17 11:39:17,405 - Epoch: [54][  200/  500]    Overall Loss 0.797079    Objective Loss 0.797079                                        LR 0.000500    Time 0.076063    
2024-02-17 11:39:24,782 - Epoch: [54][  300/  500]    Overall Loss 0.806079    Objective Loss 0.806079                                        LR 0.000500    Time 0.075286    
2024-02-17 11:39:32,072 - Epoch: [54][  400/  500]    Overall Loss 0.813309    Objective Loss 0.813309                                        LR 0.000500    Time 0.074680    
2024-02-17 11:39:39,332 - Epoch: [54][  500/  500]    Overall Loss 0.818176    Objective Loss 0.818176    Top1 76.500000    Top5 96.000000    LR 0.000500    Time 0.074255    
2024-02-17 11:39:39,506 - --- validate (epoch=54)-----------
2024-02-17 11:39:39,507 - 10000 samples (100 per mini-batch)
2024-02-17 11:39:42,388 - Epoch: [54][  100/  100]    Loss 1.654874    Top1 58.370000    Top5 84.970000    
2024-02-17 11:39:42,549 - ==> Top1: 58.370    Top5: 84.970    Loss: 1.655

2024-02-17 11:39:42,560 - ==> Best [Top1: 58.960   Top5: 85.370   Sparsity:0.00   Params: 753952 on epoch: 53]
2024-02-17 11:39:42,561 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:39:42,623 - 

2024-02-17 11:39:42,623 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:39:50,335 - Epoch: [55][  100/  500]    Overall Loss 0.769146    Objective Loss 0.769146                                        LR 0.000500    Time 0.077061    
2024-02-17 11:39:57,737 - Epoch: [55][  200/  500]    Overall Loss 0.780171    Objective Loss 0.780171                                        LR 0.000500    Time 0.075518    
2024-02-17 11:40:04,986 - Epoch: [55][  300/  500]    Overall Loss 0.789821    Objective Loss 0.789821                                        LR 0.000500    Time 0.074497    
2024-02-17 11:40:12,345 - Epoch: [55][  400/  500]    Overall Loss 0.797652    Objective Loss 0.797652                                        LR 0.000500    Time 0.074259    
2024-02-17 11:40:19,680 - Epoch: [55][  500/  500]    Overall Loss 0.802727    Objective Loss 0.802727    Top1 80.000000    Top5 95.500000    LR 0.000500    Time 0.074071    
2024-02-17 11:40:19,796 - --- validate (epoch=55)-----------
2024-02-17 11:40:19,797 - 10000 samples (100 per mini-batch)
2024-02-17 11:40:22,790 - Epoch: [55][  100/  100]    Loss 1.577737    Top1 59.690000    Top5 85.980000    
2024-02-17 11:40:22,927 - ==> Top1: 59.690    Top5: 85.980    Loss: 1.578

2024-02-17 11:40:22,934 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:40:22,934 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:40:23,027 - 

2024-02-17 11:40:23,027 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:40:31,162 - Epoch: [56][  100/  500]    Overall Loss 0.767662    Objective Loss 0.767662                                        LR 0.000500    Time 0.081301    
2024-02-17 11:40:38,507 - Epoch: [56][  200/  500]    Overall Loss 0.775037    Objective Loss 0.775037                                        LR 0.000500    Time 0.077352    
2024-02-17 11:40:45,777 - Epoch: [56][  300/  500]    Overall Loss 0.782996    Objective Loss 0.782996                                        LR 0.000500    Time 0.075788    
2024-02-17 11:40:53,104 - Epoch: [56][  400/  500]    Overall Loss 0.793193    Objective Loss 0.793193                                        LR 0.000500    Time 0.075149    
2024-02-17 11:41:00,476 - Epoch: [56][  500/  500]    Overall Loss 0.798635    Objective Loss 0.798635    Top1 76.500000    Top5 95.500000    LR 0.000500    Time 0.074856    
2024-02-17 11:41:00,621 - --- validate (epoch=56)-----------
2024-02-17 11:41:00,622 - 10000 samples (100 per mini-batch)
2024-02-17 11:41:03,577 - Epoch: [56][  100/  100]    Loss 1.677374    Top1 57.960000    Top5 85.060000    
2024-02-17 11:41:03,750 - ==> Top1: 57.960    Top5: 85.060    Loss: 1.677

2024-02-17 11:41:03,761 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:41:03,762 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:41:03,825 - 

2024-02-17 11:41:03,825 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:41:11,630 - Epoch: [57][  100/  500]    Overall Loss 0.748854    Objective Loss 0.748854                                        LR 0.000500    Time 0.077984    
2024-02-17 11:41:18,891 - Epoch: [57][  200/  500]    Overall Loss 0.757948    Objective Loss 0.757948                                        LR 0.000500    Time 0.075276    
2024-02-17 11:41:26,170 - Epoch: [57][  300/  500]    Overall Loss 0.768813    Objective Loss 0.768813                                        LR 0.000500    Time 0.074435    
2024-02-17 11:41:33,347 - Epoch: [57][  400/  500]    Overall Loss 0.777358    Objective Loss 0.777358                                        LR 0.000500    Time 0.073760    
2024-02-17 11:41:40,508 - Epoch: [57][  500/  500]    Overall Loss 0.782456    Objective Loss 0.782456    Top1 78.000000    Top5 95.000000    LR 0.000500    Time 0.073322    
2024-02-17 11:41:40,685 - --- validate (epoch=57)-----------
2024-02-17 11:41:40,686 - 10000 samples (100 per mini-batch)
2024-02-17 11:41:43,672 - Epoch: [57][  100/  100]    Loss 1.637951    Top1 58.710000    Top5 85.710000    
2024-02-17 11:41:43,856 - ==> Top1: 58.710    Top5: 85.710    Loss: 1.638

2024-02-17 11:41:43,868 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:41:43,869 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:41:43,930 - 

2024-02-17 11:41:43,931 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:41:51,701 - Epoch: [58][  100/  500]    Overall Loss 0.757408    Objective Loss 0.757408                                        LR 0.000500    Time 0.077650    
2024-02-17 11:41:58,989 - Epoch: [58][  200/  500]    Overall Loss 0.752679    Objective Loss 0.752679                                        LR 0.000500    Time 0.075246    
2024-02-17 11:42:06,568 - Epoch: [58][  300/  500]    Overall Loss 0.761102    Objective Loss 0.761102                                        LR 0.000500    Time 0.075413    
2024-02-17 11:42:13,927 - Epoch: [58][  400/  500]    Overall Loss 0.769629    Objective Loss 0.769629                                        LR 0.000500    Time 0.074948    
2024-02-17 11:42:21,187 - Epoch: [58][  500/  500]    Overall Loss 0.776744    Objective Loss 0.776744    Top1 75.500000    Top5 94.500000    LR 0.000500    Time 0.074470    
2024-02-17 11:42:21,346 - --- validate (epoch=58)-----------
2024-02-17 11:42:21,347 - 10000 samples (100 per mini-batch)
2024-02-17 11:42:24,357 - Epoch: [58][  100/  100]    Loss 1.693725    Top1 58.040000    Top5 84.660000    
2024-02-17 11:42:24,468 - ==> Top1: 58.040    Top5: 84.660    Loss: 1.694

2024-02-17 11:42:24,726 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:42:24,726 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:42:24,788 - 

2024-02-17 11:42:24,788 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:42:32,693 - Epoch: [59][  100/  500]    Overall Loss 0.725762    Objective Loss 0.725762                                        LR 0.000500    Time 0.078974    
2024-02-17 11:42:39,898 - Epoch: [59][  200/  500]    Overall Loss 0.742909    Objective Loss 0.742909                                        LR 0.000500    Time 0.075495    
2024-02-17 11:42:47,257 - Epoch: [59][  300/  500]    Overall Loss 0.745777    Objective Loss 0.745777                                        LR 0.000500    Time 0.074841    
2024-02-17 11:42:54,574 - Epoch: [59][  400/  500]    Overall Loss 0.756595    Objective Loss 0.756595                                        LR 0.000500    Time 0.074414    
2024-02-17 11:43:01,938 - Epoch: [59][  500/  500]    Overall Loss 0.762398    Objective Loss 0.762398    Top1 74.500000    Top5 96.000000    LR 0.000500    Time 0.074251    
2024-02-17 11:43:02,082 - --- validate (epoch=59)-----------
2024-02-17 11:43:02,083 - 10000 samples (100 per mini-batch)
2024-02-17 11:43:05,086 - Epoch: [59][  100/  100]    Loss 1.658248    Top1 58.860000    Top5 85.150000    
2024-02-17 11:43:05,207 - ==> Top1: 58.860    Top5: 85.150    Loss: 1.658

2024-02-17 11:43:05,216 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:43:05,217 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:43:05,286 - 

2024-02-17 11:43:05,286 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:43:13,032 - Epoch: [60][  100/  500]    Overall Loss 0.717924    Objective Loss 0.717924                                        LR 0.000500    Time 0.077410    
2024-02-17 11:43:20,347 - Epoch: [60][  200/  500]    Overall Loss 0.740746    Objective Loss 0.740746                                        LR 0.000500    Time 0.075254    
2024-02-17 11:43:27,613 - Epoch: [60][  300/  500]    Overall Loss 0.746455    Objective Loss 0.746455                                        LR 0.000500    Time 0.074378    
2024-02-17 11:43:34,667 - Epoch: [60][  400/  500]    Overall Loss 0.755625    Objective Loss 0.755625                                        LR 0.000500    Time 0.073409    
2024-02-17 11:43:41,831 - Epoch: [60][  500/  500]    Overall Loss 0.761782    Objective Loss 0.761782    Top1 77.000000    Top5 96.000000    LR 0.000500    Time 0.073046    
2024-02-17 11:43:41,947 - --- validate (epoch=60)-----------
2024-02-17 11:43:41,947 - 10000 samples (100 per mini-batch)
2024-02-17 11:43:45,174 - Epoch: [60][  100/  100]    Loss 1.683339    Top1 57.680000    Top5 85.160000    
2024-02-17 11:43:45,323 - ==> Top1: 57.680    Top5: 85.160    Loss: 1.683

2024-02-17 11:43:45,338 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:43:45,338 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:43:45,403 - 

2024-02-17 11:43:45,403 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:43:53,207 - Epoch: [61][  100/  500]    Overall Loss 0.723786    Objective Loss 0.723786                                        LR 0.000500    Time 0.077977    
2024-02-17 11:44:00,512 - Epoch: [61][  200/  500]    Overall Loss 0.725941    Objective Loss 0.725941                                        LR 0.000500    Time 0.075494    
2024-02-17 11:44:07,858 - Epoch: [61][  300/  500]    Overall Loss 0.736931    Objective Loss 0.736931                                        LR 0.000500    Time 0.074801    
2024-02-17 11:44:15,129 - Epoch: [61][  400/  500]    Overall Loss 0.743888    Objective Loss 0.743888                                        LR 0.000500    Time 0.074268    
2024-02-17 11:44:22,438 - Epoch: [61][  500/  500]    Overall Loss 0.750233    Objective Loss 0.750233    Top1 76.500000    Top5 97.000000    LR 0.000500    Time 0.074025    
2024-02-17 11:44:22,658 - --- validate (epoch=61)-----------
2024-02-17 11:44:22,659 - 10000 samples (100 per mini-batch)
2024-02-17 11:44:25,737 - Epoch: [61][  100/  100]    Loss 1.703892    Top1 58.030000    Top5 84.660000    
2024-02-17 11:44:25,854 - ==> Top1: 58.030    Top5: 84.660    Loss: 1.704

2024-02-17 11:44:25,865 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:44:25,865 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:44:25,929 - 

2024-02-17 11:44:25,929 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:44:33,889 - Epoch: [62][  100/  500]    Overall Loss 0.716316    Objective Loss 0.716316                                        LR 0.000500    Time 0.079552    
2024-02-17 11:44:41,161 - Epoch: [62][  200/  500]    Overall Loss 0.725154    Objective Loss 0.725154                                        LR 0.000500    Time 0.076114    
2024-02-17 11:44:48,508 - Epoch: [62][  300/  500]    Overall Loss 0.726598    Objective Loss 0.726598                                        LR 0.000500    Time 0.075220    
2024-02-17 11:44:55,804 - Epoch: [62][  400/  500]    Overall Loss 0.732765    Objective Loss 0.732765                                        LR 0.000500    Time 0.074643    
2024-02-17 11:45:03,112 - Epoch: [62][  500/  500]    Overall Loss 0.735718    Objective Loss 0.735718    Top1 77.500000    Top5 97.000000    LR 0.000500    Time 0.074322    
2024-02-17 11:45:03,225 - --- validate (epoch=62)-----------
2024-02-17 11:45:03,226 - 10000 samples (100 per mini-batch)
2024-02-17 11:45:06,211 - Epoch: [62][  100/  100]    Loss 1.695187    Top1 58.080000    Top5 84.730000    
2024-02-17 11:45:06,369 - ==> Top1: 58.080    Top5: 84.730    Loss: 1.695

2024-02-17 11:45:06,380 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:45:06,381 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:45:06,443 - 

2024-02-17 11:45:06,444 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:45:14,123 - Epoch: [63][  100/  500]    Overall Loss 0.708055    Objective Loss 0.708055                                        LR 0.000500    Time 0.076738    
2024-02-17 11:45:21,416 - Epoch: [63][  200/  500]    Overall Loss 0.707810    Objective Loss 0.707810                                        LR 0.000500    Time 0.074813    
2024-02-17 11:45:28,773 - Epoch: [63][  300/  500]    Overall Loss 0.714700    Objective Loss 0.714700                                        LR 0.000500    Time 0.074383    
2024-02-17 11:45:36,108 - Epoch: [63][  400/  500]    Overall Loss 0.722657    Objective Loss 0.722657                                        LR 0.000500    Time 0.074114    
2024-02-17 11:45:43,415 - Epoch: [63][  500/  500]    Overall Loss 0.728273    Objective Loss 0.728273    Top1 78.000000    Top5 94.500000    LR 0.000500    Time 0.073896    
2024-02-17 11:45:43,538 - --- validate (epoch=63)-----------
2024-02-17 11:45:43,538 - 10000 samples (100 per mini-batch)
2024-02-17 11:45:46,532 - Epoch: [63][  100/  100]    Loss 1.712738    Top1 58.530000    Top5 85.230000    
2024-02-17 11:45:46,674 - ==> Top1: 58.530    Top5: 85.230    Loss: 1.713

2024-02-17 11:45:46,686 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:45:46,687 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:45:46,749 - 

2024-02-17 11:45:46,749 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:45:54,778 - Epoch: [64][  100/  500]    Overall Loss 0.699875    Objective Loss 0.699875                                        LR 0.000500    Time 0.080238    
2024-02-17 11:46:02,011 - Epoch: [64][  200/  500]    Overall Loss 0.711025    Objective Loss 0.711025                                        LR 0.000500    Time 0.076263    
2024-02-17 11:46:09,358 - Epoch: [64][  300/  500]    Overall Loss 0.711866    Objective Loss 0.711866                                        LR 0.000500    Time 0.075317    
2024-02-17 11:46:16,658 - Epoch: [64][  400/  500]    Overall Loss 0.718434    Objective Loss 0.718434                                        LR 0.000500    Time 0.074728    
2024-02-17 11:46:24,027 - Epoch: [64][  500/  500]    Overall Loss 0.721861    Objective Loss 0.721861    Top1 80.000000    Top5 97.500000    LR 0.000500    Time 0.074512    
2024-02-17 11:46:24,154 - --- validate (epoch=64)-----------
2024-02-17 11:46:24,155 - 10000 samples (100 per mini-batch)
2024-02-17 11:46:27,203 - Epoch: [64][  100/  100]    Loss 1.672986    Top1 58.580000    Top5 85.230000    
2024-02-17 11:46:27,319 - ==> Top1: 58.580    Top5: 85.230    Loss: 1.673

2024-02-17 11:46:27,330 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:46:27,330 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:46:27,392 - 

2024-02-17 11:46:27,393 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:46:35,071 - Epoch: [65][  100/  500]    Overall Loss 0.685307    Objective Loss 0.685307                                        LR 0.000500    Time 0.076732    
2024-02-17 11:46:42,368 - Epoch: [65][  200/  500]    Overall Loss 0.691732    Objective Loss 0.691732                                        LR 0.000500    Time 0.074822    
2024-02-17 11:46:49,695 - Epoch: [65][  300/  500]    Overall Loss 0.702046    Objective Loss 0.702046                                        LR 0.000500    Time 0.074293    
2024-02-17 11:46:56,971 - Epoch: [65][  400/  500]    Overall Loss 0.707181    Objective Loss 0.707181                                        LR 0.000500    Time 0.073897    
2024-02-17 11:47:04,430 - Epoch: [65][  500/  500]    Overall Loss 0.714602    Objective Loss 0.714602    Top1 77.000000    Top5 96.000000    LR 0.000500    Time 0.074028    
2024-02-17 11:47:04,617 - --- validate (epoch=65)-----------
2024-02-17 11:47:04,618 - 10000 samples (100 per mini-batch)
2024-02-17 11:47:07,564 - Epoch: [65][  100/  100]    Loss 1.658163    Top1 58.720000    Top5 85.510000    
2024-02-17 11:47:07,676 - ==> Top1: 58.720    Top5: 85.510    Loss: 1.658

2024-02-17 11:47:07,682 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:47:07,683 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:47:07,745 - 

2024-02-17 11:47:07,745 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:47:15,861 - Epoch: [66][  100/  500]    Overall Loss 0.674366    Objective Loss 0.674366                                        LR 0.000500    Time 0.081103    
2024-02-17 11:47:23,071 - Epoch: [66][  200/  500]    Overall Loss 0.684975    Objective Loss 0.684975                                        LR 0.000500    Time 0.076582    
2024-02-17 11:47:30,374 - Epoch: [66][  300/  500]    Overall Loss 0.694046    Objective Loss 0.694046                                        LR 0.000500    Time 0.075384    
2024-02-17 11:47:37,693 - Epoch: [66][  400/  500]    Overall Loss 0.699602    Objective Loss 0.699602                                        LR 0.000500    Time 0.074824    
2024-02-17 11:47:45,028 - Epoch: [66][  500/  500]    Overall Loss 0.704723    Objective Loss 0.704723    Top1 74.000000    Top5 93.000000    LR 0.000500    Time 0.074522    
2024-02-17 11:47:45,141 - --- validate (epoch=66)-----------
2024-02-17 11:47:45,142 - 10000 samples (100 per mini-batch)
2024-02-17 11:47:48,116 - Epoch: [66][  100/  100]    Loss 1.779810    Top1 57.320000    Top5 84.590000    
2024-02-17 11:47:48,225 - ==> Top1: 57.320    Top5: 84.590    Loss: 1.780

2024-02-17 11:47:48,237 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:47:48,237 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:47:48,314 - 

2024-02-17 11:47:48,314 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:47:56,174 - Epoch: [67][  100/  500]    Overall Loss 0.667879    Objective Loss 0.667879                                        LR 0.000500    Time 0.078541    
2024-02-17 11:48:03,439 - Epoch: [67][  200/  500]    Overall Loss 0.670391    Objective Loss 0.670391                                        LR 0.000500    Time 0.075575    
2024-02-17 11:48:10,809 - Epoch: [67][  300/  500]    Overall Loss 0.682634    Objective Loss 0.682634                                        LR 0.000500    Time 0.074934    
2024-02-17 11:48:18,147 - Epoch: [67][  400/  500]    Overall Loss 0.693407    Objective Loss 0.693407                                        LR 0.000500    Time 0.074535    
2024-02-17 11:48:25,509 - Epoch: [67][  500/  500]    Overall Loss 0.701100    Objective Loss 0.701100    Top1 82.000000    Top5 97.500000    LR 0.000500    Time 0.074344    
2024-02-17 11:48:25,647 - --- validate (epoch=67)-----------
2024-02-17 11:48:25,647 - 10000 samples (100 per mini-batch)
2024-02-17 11:48:28,501 - Epoch: [67][  100/  100]    Loss 1.624452    Top1 59.700000    Top5 85.970000    
2024-02-17 11:48:28,600 - ==> Top1: 59.700    Top5: 85.970    Loss: 1.624

2024-02-17 11:48:28,606 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:48:28,607 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:48:28,681 - 

2024-02-17 11:48:28,682 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:48:36,830 - Epoch: [68][  100/  500]    Overall Loss 0.666309    Objective Loss 0.666309                                        LR 0.000500    Time 0.081429    
2024-02-17 11:48:44,173 - Epoch: [68][  200/  500]    Overall Loss 0.671433    Objective Loss 0.671433                                        LR 0.000500    Time 0.077407    
2024-02-17 11:48:51,529 - Epoch: [68][  300/  500]    Overall Loss 0.681416    Objective Loss 0.681416                                        LR 0.000500    Time 0.076110    
2024-02-17 11:48:58,826 - Epoch: [68][  400/  500]    Overall Loss 0.681536    Objective Loss 0.681536                                        LR 0.000500    Time 0.075314    
2024-02-17 11:49:06,162 - Epoch: [68][  500/  500]    Overall Loss 0.689015    Objective Loss 0.689015    Top1 81.000000    Top5 96.500000    LR 0.000500    Time 0.074915    
2024-02-17 11:49:06,331 - --- validate (epoch=68)-----------
2024-02-17 11:49:06,331 - 10000 samples (100 per mini-batch)
2024-02-17 11:49:09,312 - Epoch: [68][  100/  100]    Loss 1.762042    Top1 57.330000    Top5 84.180000    
2024-02-17 11:49:09,403 - ==> Top1: 57.330    Top5: 84.180    Loss: 1.762

2024-02-17 11:49:09,414 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:49:09,415 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:49:09,478 - 

2024-02-17 11:49:09,479 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:49:17,302 - Epoch: [69][  100/  500]    Overall Loss 0.670748    Objective Loss 0.670748                                        LR 0.000500    Time 0.078180    
2024-02-17 11:49:24,564 - Epoch: [69][  200/  500]    Overall Loss 0.678400    Objective Loss 0.678400                                        LR 0.000500    Time 0.075379    
2024-02-17 11:49:31,836 - Epoch: [69][  300/  500]    Overall Loss 0.680186    Objective Loss 0.680186                                        LR 0.000500    Time 0.074479    
2024-02-17 11:49:39,077 - Epoch: [69][  400/  500]    Overall Loss 0.683780    Objective Loss 0.683780                                        LR 0.000500    Time 0.073952    
2024-02-17 11:49:46,340 - Epoch: [69][  500/  500]    Overall Loss 0.688127    Objective Loss 0.688127    Top1 75.000000    Top5 95.500000    LR 0.000500    Time 0.073679    
2024-02-17 11:49:46,570 - --- validate (epoch=69)-----------
2024-02-17 11:49:46,570 - 10000 samples (100 per mini-batch)
2024-02-17 11:49:49,505 - Epoch: [69][  100/  100]    Loss 1.698582    Top1 58.650000    Top5 85.260000    
2024-02-17 11:49:49,617 - ==> Top1: 58.650    Top5: 85.260    Loss: 1.699

2024-02-17 11:49:49,623 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:49:49,623 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:49:49,680 - 

2024-02-17 11:49:49,680 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:49:57,619 - Epoch: [70][  100/  500]    Overall Loss 0.654303    Objective Loss 0.654303                                        LR 0.000500    Time 0.079335    
2024-02-17 11:50:04,877 - Epoch: [70][  200/  500]    Overall Loss 0.663836    Objective Loss 0.663836                                        LR 0.000500    Time 0.075933    
2024-02-17 11:50:12,350 - Epoch: [70][  300/  500]    Overall Loss 0.670636    Objective Loss 0.670636                                        LR 0.000500    Time 0.075519    
2024-02-17 11:50:19,824 - Epoch: [70][  400/  500]    Overall Loss 0.675985    Objective Loss 0.675985                                        LR 0.000500    Time 0.075312    
2024-02-17 11:50:27,297 - Epoch: [70][  500/  500]    Overall Loss 0.682836    Objective Loss 0.682836    Top1 80.000000    Top5 96.500000    LR 0.000500    Time 0.075189    
2024-02-17 11:50:27,411 - --- validate (epoch=70)-----------
2024-02-17 11:50:27,412 - 10000 samples (100 per mini-batch)
2024-02-17 11:50:30,702 - Epoch: [70][  100/  100]    Loss 1.732679    Top1 58.640000    Top5 84.830000    
2024-02-17 11:50:30,831 - ==> Top1: 58.640    Top5: 84.830    Loss: 1.733

2024-02-17 11:50:30,843 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:50:30,844 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:50:30,906 - 

2024-02-17 11:50:30,906 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:50:38,864 - Epoch: [71][  100/  500]    Overall Loss 0.640584    Objective Loss 0.640584                                        LR 0.000500    Time 0.079524    
2024-02-17 11:50:46,185 - Epoch: [71][  200/  500]    Overall Loss 0.644814    Objective Loss 0.644814                                        LR 0.000500    Time 0.076341    
2024-02-17 11:50:53,464 - Epoch: [71][  300/  500]    Overall Loss 0.658395    Objective Loss 0.658395                                        LR 0.000500    Time 0.075142    
2024-02-17 11:51:00,748 - Epoch: [71][  400/  500]    Overall Loss 0.664975    Objective Loss 0.664975                                        LR 0.000500    Time 0.074558    
2024-02-17 11:51:08,084 - Epoch: [71][  500/  500]    Overall Loss 0.673418    Objective Loss 0.673418    Top1 76.500000    Top5 97.500000    LR 0.000500    Time 0.074310    
2024-02-17 11:51:08,219 - --- validate (epoch=71)-----------
2024-02-17 11:51:08,220 - 10000 samples (100 per mini-batch)
2024-02-17 11:51:11,274 - Epoch: [71][  100/  100]    Loss 1.694343    Top1 59.110000    Top5 85.550000    
2024-02-17 11:51:11,457 - ==> Top1: 59.110    Top5: 85.550    Loss: 1.694

2024-02-17 11:51:11,465 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:51:11,465 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:51:11,526 - 

2024-02-17 11:51:11,526 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:51:19,620 - Epoch: [72][  100/  500]    Overall Loss 0.634068    Objective Loss 0.634068                                        LR 0.000500    Time 0.080881    
2024-02-17 11:51:26,942 - Epoch: [72][  200/  500]    Overall Loss 0.639392    Objective Loss 0.639392                                        LR 0.000500    Time 0.077033    
2024-02-17 11:51:33,817 - Epoch: [72][  300/  500]    Overall Loss 0.649119    Objective Loss 0.649119                                        LR 0.000500    Time 0.074259    
2024-02-17 11:51:40,915 - Epoch: [72][  400/  500]    Overall Loss 0.660243    Objective Loss 0.660243                                        LR 0.000500    Time 0.073431    
2024-02-17 11:51:48,223 - Epoch: [72][  500/  500]    Overall Loss 0.662036    Objective Loss 0.662036    Top1 75.500000    Top5 97.000000    LR 0.000500    Time 0.073352    
2024-02-17 11:51:48,382 - --- validate (epoch=72)-----------
2024-02-17 11:51:48,383 - 10000 samples (100 per mini-batch)
2024-02-17 11:51:51,421 - Epoch: [72][  100/  100]    Loss 1.789423    Top1 58.120000    Top5 84.880000    
2024-02-17 11:51:51,528 - ==> Top1: 58.120    Top5: 84.880    Loss: 1.789

2024-02-17 11:51:51,534 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:51:51,535 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:51:51,627 - 

2024-02-17 11:51:51,628 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:51:59,549 - Epoch: [73][  100/  500]    Overall Loss 0.635874    Objective Loss 0.635874                                        LR 0.000500    Time 0.079158    
2024-02-17 11:52:06,928 - Epoch: [73][  200/  500]    Overall Loss 0.634746    Objective Loss 0.634746                                        LR 0.000500    Time 0.076453    
2024-02-17 11:52:14,298 - Epoch: [73][  300/  500]    Overall Loss 0.643160    Objective Loss 0.643160                                        LR 0.000500    Time 0.075518    
2024-02-17 11:52:21,476 - Epoch: [73][  400/  500]    Overall Loss 0.652762    Objective Loss 0.652762                                        LR 0.000500    Time 0.074576    
2024-02-17 11:52:28,738 - Epoch: [73][  500/  500]    Overall Loss 0.657868    Objective Loss 0.657868    Top1 81.000000    Top5 97.000000    LR 0.000500    Time 0.074178    
2024-02-17 11:52:28,859 - --- validate (epoch=73)-----------
2024-02-17 11:52:28,860 - 10000 samples (100 per mini-batch)
2024-02-17 11:52:31,895 - Epoch: [73][  100/  100]    Loss 1.707734    Top1 58.790000    Top5 85.400000    
2024-02-17 11:52:32,010 - ==> Top1: 58.790    Top5: 85.400    Loss: 1.708

2024-02-17 11:52:32,022 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:52:32,022 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:52:32,085 - 

2024-02-17 11:52:32,086 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:52:39,564 - Epoch: [74][  100/  500]    Overall Loss 0.609792    Objective Loss 0.609792                                        LR 0.000500    Time 0.074730    
2024-02-17 11:52:46,798 - Epoch: [74][  200/  500]    Overall Loss 0.622190    Objective Loss 0.622190                                        LR 0.000500    Time 0.073517    
2024-02-17 11:52:54,125 - Epoch: [74][  300/  500]    Overall Loss 0.634530    Objective Loss 0.634530                                        LR 0.000500    Time 0.073421    
2024-02-17 11:53:01,450 - Epoch: [74][  400/  500]    Overall Loss 0.644153    Objective Loss 0.644153                                        LR 0.000500    Time 0.073369    
2024-02-17 11:53:08,747 - Epoch: [74][  500/  500]    Overall Loss 0.649697    Objective Loss 0.649697    Top1 84.000000    Top5 98.000000    LR 0.000500    Time 0.073282    
2024-02-17 11:53:08,888 - --- validate (epoch=74)-----------
2024-02-17 11:53:08,889 - 10000 samples (100 per mini-batch)
2024-02-17 11:53:12,139 - Epoch: [74][  100/  100]    Loss 1.735290    Top1 58.450000    Top5 85.140000    
2024-02-17 11:53:12,287 - ==> Top1: 58.450    Top5: 85.140    Loss: 1.735

2024-02-17 11:53:12,294 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:53:12,295 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:53:12,365 - 

2024-02-17 11:53:12,365 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:53:19,629 - Epoch: [75][  100/  500]    Overall Loss 0.620486    Objective Loss 0.620486                                        LR 0.000500    Time 0.072590    
2024-02-17 11:53:26,494 - Epoch: [75][  200/  500]    Overall Loss 0.633876    Objective Loss 0.633876                                        LR 0.000500    Time 0.070607    
2024-02-17 11:53:33,621 - Epoch: [75][  300/  500]    Overall Loss 0.637861    Objective Loss 0.637861                                        LR 0.000500    Time 0.070814    
2024-02-17 11:53:40,986 - Epoch: [75][  400/  500]    Overall Loss 0.641115    Objective Loss 0.641115                                        LR 0.000500    Time 0.071514    
2024-02-17 11:53:48,270 - Epoch: [75][  500/  500]    Overall Loss 0.644184    Objective Loss 0.644184    Top1 79.500000    Top5 97.000000    LR 0.000500    Time 0.071771    
2024-02-17 11:53:48,400 - --- validate (epoch=75)-----------
2024-02-17 11:53:48,400 - 10000 samples (100 per mini-batch)
2024-02-17 11:53:51,375 - Epoch: [75][  100/  100]    Loss 1.705996    Top1 59.100000    Top5 85.270000    
2024-02-17 11:53:51,492 - ==> Top1: 59.100    Top5: 85.270    Loss: 1.706

2024-02-17 11:53:51,502 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:53:51,503 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:53:51,565 - 

2024-02-17 11:53:51,565 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:53:59,673 - Epoch: [76][  100/  500]    Overall Loss 0.610907    Objective Loss 0.610907                                        LR 0.000500    Time 0.081019    
2024-02-17 11:54:07,107 - Epoch: [76][  200/  500]    Overall Loss 0.624727    Objective Loss 0.624727                                        LR 0.000500    Time 0.077659    
2024-02-17 11:54:14,373 - Epoch: [76][  300/  500]    Overall Loss 0.624320    Objective Loss 0.624320                                        LR 0.000500    Time 0.075979    
2024-02-17 11:54:21,874 - Epoch: [76][  400/  500]    Overall Loss 0.631084    Objective Loss 0.631084                                        LR 0.000500    Time 0.075726    
2024-02-17 11:54:29,392 - Epoch: [76][  500/  500]    Overall Loss 0.636151    Objective Loss 0.636151    Top1 77.500000    Top5 98.500000    LR 0.000500    Time 0.075609    
2024-02-17 11:54:29,501 - --- validate (epoch=76)-----------
2024-02-17 11:54:29,502 - 10000 samples (100 per mini-batch)
2024-02-17 11:54:32,643 - Epoch: [76][  100/  100]    Loss 1.739712    Top1 58.250000    Top5 85.250000    
2024-02-17 11:54:32,755 - ==> Top1: 58.250    Top5: 85.250    Loss: 1.740

2024-02-17 11:54:32,770 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:54:32,770 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:54:32,835 - 

2024-02-17 11:54:32,835 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:54:40,618 - Epoch: [77][  100/  500]    Overall Loss 0.597206    Objective Loss 0.597206                                        LR 0.000500    Time 0.077769    
2024-02-17 11:54:47,929 - Epoch: [77][  200/  500]    Overall Loss 0.601952    Objective Loss 0.601952                                        LR 0.000500    Time 0.075421    
2024-02-17 11:54:55,175 - Epoch: [77][  300/  500]    Overall Loss 0.609414    Objective Loss 0.609414                                        LR 0.000500    Time 0.074419    
2024-02-17 11:55:02,455 - Epoch: [77][  400/  500]    Overall Loss 0.621360    Objective Loss 0.621360                                        LR 0.000500    Time 0.074005    
2024-02-17 11:55:09,777 - Epoch: [77][  500/  500]    Overall Loss 0.630023    Objective Loss 0.630023    Top1 84.000000    Top5 99.000000    LR 0.000500    Time 0.073840    
2024-02-17 11:55:09,900 - --- validate (epoch=77)-----------
2024-02-17 11:55:09,901 - 10000 samples (100 per mini-batch)
2024-02-17 11:55:12,959 - Epoch: [77][  100/  100]    Loss 1.715761    Top1 58.450000    Top5 85.800000    
2024-02-17 11:55:13,071 - ==> Top1: 58.450    Top5: 85.800    Loss: 1.716

2024-02-17 11:55:13,082 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:55:13,083 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:55:13,146 - 

2024-02-17 11:55:13,146 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:55:21,474 - Epoch: [78][  100/  500]    Overall Loss 0.602155    Objective Loss 0.602155                                        LR 0.000500    Time 0.083227    
2024-02-17 11:55:28,691 - Epoch: [78][  200/  500]    Overall Loss 0.619924    Objective Loss 0.619924                                        LR 0.000500    Time 0.077678    
2024-02-17 11:55:36,114 - Epoch: [78][  300/  500]    Overall Loss 0.618334    Objective Loss 0.618334                                        LR 0.000500    Time 0.076514    
2024-02-17 11:55:43,423 - Epoch: [78][  400/  500]    Overall Loss 0.623308    Objective Loss 0.623308                                        LR 0.000500    Time 0.075648    
2024-02-17 11:55:50,765 - Epoch: [78][  500/  500]    Overall Loss 0.626740    Objective Loss 0.626740    Top1 73.500000    Top5 97.500000    LR 0.000500    Time 0.075193    
2024-02-17 11:55:50,919 - --- validate (epoch=78)-----------
2024-02-17 11:55:50,920 - 10000 samples (100 per mini-batch)
2024-02-17 11:55:54,117 - Epoch: [78][  100/  100]    Loss 1.753041    Top1 57.960000    Top5 85.190000    
2024-02-17 11:55:54,282 - ==> Top1: 57.960    Top5: 85.190    Loss: 1.753

2024-02-17 11:55:54,294 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:55:54,295 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:55:54,358 - 

2024-02-17 11:55:54,358 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:56:02,337 - Epoch: [79][  100/  500]    Overall Loss 0.591097    Objective Loss 0.591097                                        LR 0.000500    Time 0.079732    
2024-02-17 11:56:09,639 - Epoch: [79][  200/  500]    Overall Loss 0.602335    Objective Loss 0.602335                                        LR 0.000500    Time 0.076354    
2024-02-17 11:56:16,945 - Epoch: [79][  300/  500]    Overall Loss 0.608733    Objective Loss 0.608733                                        LR 0.000500    Time 0.075243    
2024-02-17 11:56:24,155 - Epoch: [79][  400/  500]    Overall Loss 0.613700    Objective Loss 0.613700                                        LR 0.000500    Time 0.074448    
2024-02-17 11:56:31,377 - Epoch: [79][  500/  500]    Overall Loss 0.619532    Objective Loss 0.619532    Top1 76.000000    Top5 97.000000    LR 0.000500    Time 0.073993    
2024-02-17 11:56:31,529 - --- validate (epoch=79)-----------
2024-02-17 11:56:31,530 - 10000 samples (100 per mini-batch)
2024-02-17 11:56:34,619 - Epoch: [79][  100/  100]    Loss 1.748150    Top1 58.340000    Top5 85.160000    
2024-02-17 11:56:34,761 - ==> Top1: 58.340    Top5: 85.160    Loss: 1.748

2024-02-17 11:56:34,772 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:56:34,772 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:56:34,834 - 

2024-02-17 11:56:34,834 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:56:42,828 - Epoch: [80][  100/  500]    Overall Loss 0.586069    Objective Loss 0.586069                                        LR 0.000500    Time 0.079882    
2024-02-17 11:56:50,239 - Epoch: [80][  200/  500]    Overall Loss 0.584702    Objective Loss 0.584702                                        LR 0.000500    Time 0.076974    
2024-02-17 11:56:57,705 - Epoch: [80][  300/  500]    Overall Loss 0.597921    Objective Loss 0.597921                                        LR 0.000500    Time 0.076190    
2024-02-17 11:57:05,346 - Epoch: [80][  400/  500]    Overall Loss 0.604512    Objective Loss 0.604512                                        LR 0.000500    Time 0.076236    
2024-02-17 11:57:12,872 - Epoch: [80][  500/  500]    Overall Loss 0.610524    Objective Loss 0.610524    Top1 83.500000    Top5 97.500000    LR 0.000500    Time 0.076032    
2024-02-17 11:57:13,070 - --- validate (epoch=80)-----------
2024-02-17 11:57:13,071 - 10000 samples (100 per mini-batch)
2024-02-17 11:57:16,026 - Epoch: [80][  100/  100]    Loss 1.771340    Top1 58.120000    Top5 84.990000    
2024-02-17 11:57:16,200 - ==> Top1: 58.120    Top5: 84.990    Loss: 1.771

2024-02-17 11:57:16,213 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:57:16,213 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:57:16,278 - 

2024-02-17 11:57:16,279 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:57:23,973 - Epoch: [81][  100/  500]    Overall Loss 0.581604    Objective Loss 0.581604                                        LR 0.000500    Time 0.076889    
2024-02-17 11:57:31,274 - Epoch: [81][  200/  500]    Overall Loss 0.582514    Objective Loss 0.582514                                        LR 0.000500    Time 0.074930    
2024-02-17 11:57:38,520 - Epoch: [81][  300/  500]    Overall Loss 0.598248    Objective Loss 0.598248                                        LR 0.000500    Time 0.074093    
2024-02-17 11:57:45,793 - Epoch: [81][  400/  500]    Overall Loss 0.606046    Objective Loss 0.606046                                        LR 0.000500    Time 0.073744    
2024-02-17 11:57:53,222 - Epoch: [81][  500/  500]    Overall Loss 0.609403    Objective Loss 0.609403    Top1 82.000000    Top5 97.000000    LR 0.000500    Time 0.073844    
2024-02-17 11:57:53,370 - --- validate (epoch=81)-----------
2024-02-17 11:57:53,371 - 10000 samples (100 per mini-batch)
2024-02-17 11:57:56,346 - Epoch: [81][  100/  100]    Loss 1.777510    Top1 58.730000    Top5 84.850000    
2024-02-17 11:57:56,463 - ==> Top1: 58.730    Top5: 84.850    Loss: 1.778

2024-02-17 11:57:56,475 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:57:56,475 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:57:56,538 - 

2024-02-17 11:57:56,538 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:58:04,249 - Epoch: [82][  100/  500]    Overall Loss 0.580655    Objective Loss 0.580655                                        LR 0.000500    Time 0.077046    
2024-02-17 11:58:11,712 - Epoch: [82][  200/  500]    Overall Loss 0.586616    Objective Loss 0.586616                                        LR 0.000500    Time 0.075819    
2024-02-17 11:58:19,069 - Epoch: [82][  300/  500]    Overall Loss 0.591215    Objective Loss 0.591215                                        LR 0.000500    Time 0.075056    
2024-02-17 11:58:26,397 - Epoch: [82][  400/  500]    Overall Loss 0.591351    Objective Loss 0.591351                                        LR 0.000500    Time 0.074601    
2024-02-17 11:58:33,786 - Epoch: [82][  500/  500]    Overall Loss 0.597625    Objective Loss 0.597625    Top1 83.500000    Top5 99.000000    LR 0.000500    Time 0.074450    
2024-02-17 11:58:33,938 - --- validate (epoch=82)-----------
2024-02-17 11:58:33,938 - 10000 samples (100 per mini-batch)
2024-02-17 11:58:37,063 - Epoch: [82][  100/  100]    Loss 1.825459    Top1 57.690000    Top5 84.730000    
2024-02-17 11:58:37,232 - ==> Top1: 57.690    Top5: 84.730    Loss: 1.825

2024-02-17 11:58:37,471 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:58:37,471 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:58:37,524 - 

2024-02-17 11:58:37,525 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:58:45,290 - Epoch: [83][  100/  500]    Overall Loss 0.563809    Objective Loss 0.563809                                        LR 0.000500    Time 0.077599    
2024-02-17 11:58:52,593 - Epoch: [83][  200/  500]    Overall Loss 0.573816    Objective Loss 0.573816                                        LR 0.000500    Time 0.075295    
2024-02-17 11:58:59,840 - Epoch: [83][  300/  500]    Overall Loss 0.576394    Objective Loss 0.576394                                        LR 0.000500    Time 0.074340    
2024-02-17 11:59:07,037 - Epoch: [83][  400/  500]    Overall Loss 0.585076    Objective Loss 0.585076                                        LR 0.000500    Time 0.073736    
2024-02-17 11:59:14,417 - Epoch: [83][  500/  500]    Overall Loss 0.590422    Objective Loss 0.590422    Top1 83.000000    Top5 97.000000    LR 0.000500    Time 0.073740    
2024-02-17 11:59:14,595 - --- validate (epoch=83)-----------
2024-02-17 11:59:14,596 - 10000 samples (100 per mini-batch)
2024-02-17 11:59:17,770 - Epoch: [83][  100/  100]    Loss 1.793144    Top1 58.300000    Top5 85.080000    
2024-02-17 11:59:17,957 - ==> Top1: 58.300    Top5: 85.080    Loss: 1.793

2024-02-17 11:59:17,968 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:59:17,968 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:59:18,032 - 

2024-02-17 11:59:18,032 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:59:25,780 - Epoch: [84][  100/  500]    Overall Loss 0.537897    Objective Loss 0.537897                                        LR 0.000500    Time 0.077429    
2024-02-17 11:59:33,025 - Epoch: [84][  200/  500]    Overall Loss 0.562149    Objective Loss 0.562149                                        LR 0.000500    Time 0.074918    
2024-02-17 11:59:40,353 - Epoch: [84][  300/  500]    Overall Loss 0.570473    Objective Loss 0.570473                                        LR 0.000500    Time 0.074358    
2024-02-17 11:59:47,602 - Epoch: [84][  400/  500]    Overall Loss 0.577448    Objective Loss 0.577448                                        LR 0.000500    Time 0.073881    
2024-02-17 11:59:55,009 - Epoch: [84][  500/  500]    Overall Loss 0.587891    Objective Loss 0.587891    Top1 81.000000    Top5 97.000000    LR 0.000500    Time 0.073910    
2024-02-17 11:59:55,135 - --- validate (epoch=84)-----------
2024-02-17 11:59:55,136 - 10000 samples (100 per mini-batch)
2024-02-17 11:59:58,498 - Epoch: [84][  100/  100]    Loss 1.739641    Top1 58.970000    Top5 85.100000    
2024-02-17 11:59:58,625 - ==> Top1: 58.970    Top5: 85.100    Loss: 1.740

2024-02-17 11:59:58,637 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:59:58,637 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 11:59:58,700 - 

2024-02-17 11:59:58,701 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:00:06,415 - Epoch: [85][  100/  500]    Overall Loss 0.554587    Objective Loss 0.554587                                        LR 0.000500    Time 0.077088    
2024-02-17 12:00:13,608 - Epoch: [85][  200/  500]    Overall Loss 0.572589    Objective Loss 0.572589                                        LR 0.000500    Time 0.074485    
2024-02-17 12:00:20,932 - Epoch: [85][  300/  500]    Overall Loss 0.576759    Objective Loss 0.576759                                        LR 0.000500    Time 0.074058    
2024-02-17 12:00:28,321 - Epoch: [85][  400/  500]    Overall Loss 0.583177    Objective Loss 0.583177                                        LR 0.000500    Time 0.074005    
2024-02-17 12:00:35,670 - Epoch: [85][  500/  500]    Overall Loss 0.589292    Objective Loss 0.589292    Top1 81.000000    Top5 97.000000    LR 0.000500    Time 0.073894    
2024-02-17 12:00:35,855 - --- validate (epoch=85)-----------
2024-02-17 12:00:35,856 - 10000 samples (100 per mini-batch)
2024-02-17 12:00:38,884 - Epoch: [85][  100/  100]    Loss 1.771237    Top1 58.690000    Top5 85.650000    
2024-02-17 12:00:39,025 - ==> Top1: 58.690    Top5: 85.650    Loss: 1.771

2024-02-17 12:00:39,036 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:00:39,037 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:00:39,099 - 

2024-02-17 12:00:39,099 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:00:47,154 - Epoch: [86][  100/  500]    Overall Loss 0.539606    Objective Loss 0.539606                                        LR 0.000500    Time 0.080496    
2024-02-17 12:00:54,220 - Epoch: [86][  200/  500]    Overall Loss 0.546295    Objective Loss 0.546295                                        LR 0.000500    Time 0.075557    
2024-02-17 12:01:00,987 - Epoch: [86][  300/  500]    Overall Loss 0.558972    Objective Loss 0.558972                                        LR 0.000500    Time 0.072916    
2024-02-17 12:01:07,748 - Epoch: [86][  400/  500]    Overall Loss 0.567789    Objective Loss 0.567789                                        LR 0.000500    Time 0.071583    
2024-02-17 12:01:14,568 - Epoch: [86][  500/  500]    Overall Loss 0.574149    Objective Loss 0.574149    Top1 82.000000    Top5 97.000000    LR 0.000500    Time 0.070899    
2024-02-17 12:01:14,739 - --- validate (epoch=86)-----------
2024-02-17 12:01:14,740 - 10000 samples (100 per mini-batch)
2024-02-17 12:01:17,859 - Epoch: [86][  100/  100]    Loss 1.823585    Top1 57.930000    Top5 84.860000    
2024-02-17 12:01:17,981 - ==> Top1: 57.930    Top5: 84.860    Loss: 1.824

2024-02-17 12:01:17,994 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:01:17,995 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:01:18,058 - 

2024-02-17 12:01:18,059 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:01:25,920 - Epoch: [87][  100/  500]    Overall Loss 0.556764    Objective Loss 0.556764                                        LR 0.000500    Time 0.078553    
2024-02-17 12:01:33,292 - Epoch: [87][  200/  500]    Overall Loss 0.549502    Objective Loss 0.549502                                        LR 0.000500    Time 0.076117    
2024-02-17 12:01:40,579 - Epoch: [87][  300/  500]    Overall Loss 0.558405    Objective Loss 0.558405                                        LR 0.000500    Time 0.075020    
2024-02-17 12:01:47,895 - Epoch: [87][  400/  500]    Overall Loss 0.566278    Objective Loss 0.566278                                        LR 0.000500    Time 0.074545    
2024-02-17 12:01:54,923 - Epoch: [87][  500/  500]    Overall Loss 0.571798    Objective Loss 0.571798    Top1 79.000000    Top5 97.500000    LR 0.000500    Time 0.073683    
2024-02-17 12:01:55,077 - --- validate (epoch=87)-----------
2024-02-17 12:01:55,078 - 10000 samples (100 per mini-batch)
2024-02-17 12:01:58,206 - Epoch: [87][  100/  100]    Loss 1.827984    Top1 58.240000    Top5 84.840000    
2024-02-17 12:01:58,319 - ==> Top1: 58.240    Top5: 84.840    Loss: 1.828

2024-02-17 12:01:58,334 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:01:58,334 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:01:58,402 - 

2024-02-17 12:01:58,402 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:02:05,921 - Epoch: [88][  100/  500]    Overall Loss 0.547444    Objective Loss 0.547444                                        LR 0.000500    Time 0.075122    
2024-02-17 12:02:13,180 - Epoch: [88][  200/  500]    Overall Loss 0.558846    Objective Loss 0.558846                                        LR 0.000500    Time 0.073837    
2024-02-17 12:02:20,444 - Epoch: [88][  300/  500]    Overall Loss 0.563672    Objective Loss 0.563672                                        LR 0.000500    Time 0.073425    
2024-02-17 12:02:27,671 - Epoch: [88][  400/  500]    Overall Loss 0.568608    Objective Loss 0.568608                                        LR 0.000500    Time 0.073128    
2024-02-17 12:02:35,026 - Epoch: [88][  500/  500]    Overall Loss 0.572333    Objective Loss 0.572333    Top1 87.000000    Top5 98.000000    LR 0.000500    Time 0.073204    
2024-02-17 12:02:35,145 - --- validate (epoch=88)-----------
2024-02-17 12:02:35,146 - 10000 samples (100 per mini-batch)
2024-02-17 12:02:38,446 - Epoch: [88][  100/  100]    Loss 1.751668    Top1 58.800000    Top5 85.800000    
2024-02-17 12:02:38,580 - ==> Top1: 58.800    Top5: 85.800    Loss: 1.752

2024-02-17 12:02:38,592 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:02:38,592 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:02:38,656 - 

2024-02-17 12:02:38,656 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:02:46,555 - Epoch: [89][  100/  500]    Overall Loss 0.537153    Objective Loss 0.537153                                        LR 0.000500    Time 0.078934    
2024-02-17 12:02:53,769 - Epoch: [89][  200/  500]    Overall Loss 0.542063    Objective Loss 0.542063                                        LR 0.000500    Time 0.075514    
2024-02-17 12:03:01,099 - Epoch: [89][  300/  500]    Overall Loss 0.545037    Objective Loss 0.545037                                        LR 0.000500    Time 0.074761    
2024-02-17 12:03:08,333 - Epoch: [89][  400/  500]    Overall Loss 0.550915    Objective Loss 0.550915                                        LR 0.000500    Time 0.074146    
2024-02-17 12:03:15,673 - Epoch: [89][  500/  500]    Overall Loss 0.556556    Objective Loss 0.556556    Top1 87.000000    Top5 97.000000    LR 0.000500    Time 0.073990    
2024-02-17 12:03:15,853 - --- validate (epoch=89)-----------
2024-02-17 12:03:15,854 - 10000 samples (100 per mini-batch)
2024-02-17 12:03:18,866 - Epoch: [89][  100/  100]    Loss 1.848719    Top1 57.640000    Top5 84.930000    
2024-02-17 12:03:19,040 - ==> Top1: 57.640    Top5: 84.930    Loss: 1.849

2024-02-17 12:03:19,055 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:03:19,055 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:03:19,129 - 

2024-02-17 12:03:19,130 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:03:27,333 - Epoch: [90][  100/  500]    Overall Loss 0.529408    Objective Loss 0.529408                                        LR 0.000500    Time 0.081963    
2024-02-17 12:03:34,646 - Epoch: [90][  200/  500]    Overall Loss 0.539266    Objective Loss 0.539266                                        LR 0.000500    Time 0.077521    
2024-02-17 12:03:41,877 - Epoch: [90][  300/  500]    Overall Loss 0.540605    Objective Loss 0.540605                                        LR 0.000500    Time 0.075772    
2024-02-17 12:03:49,170 - Epoch: [90][  400/  500]    Overall Loss 0.546338    Objective Loss 0.546338                                        LR 0.000500    Time 0.075051    
2024-02-17 12:03:55,980 - Epoch: [90][  500/  500]    Overall Loss 0.556061    Objective Loss 0.556061    Top1 83.000000    Top5 97.500000    LR 0.000500    Time 0.073655    
2024-02-17 12:03:56,160 - --- validate (epoch=90)-----------
2024-02-17 12:03:56,161 - 10000 samples (100 per mini-batch)
2024-02-17 12:03:59,141 - Epoch: [90][  100/  100]    Loss 1.862603    Top1 57.940000    Top5 84.360000    
2024-02-17 12:03:59,293 - ==> Top1: 57.940    Top5: 84.360    Loss: 1.863

2024-02-17 12:03:59,306 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:03:59,306 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:03:59,369 - 

2024-02-17 12:03:59,370 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:04:07,177 - Epoch: [91][  100/  500]    Overall Loss 0.518050    Objective Loss 0.518050                                        LR 0.000500    Time 0.078018    
2024-02-17 12:04:14,478 - Epoch: [91][  200/  500]    Overall Loss 0.528958    Objective Loss 0.528958                                        LR 0.000500    Time 0.075495    
2024-02-17 12:04:22,042 - Epoch: [91][  300/  500]    Overall Loss 0.539271    Objective Loss 0.539271                                        LR 0.000500    Time 0.075528    
2024-02-17 12:04:29,189 - Epoch: [91][  400/  500]    Overall Loss 0.544243    Objective Loss 0.544243                                        LR 0.000500    Time 0.074506    
2024-02-17 12:04:36,351 - Epoch: [91][  500/  500]    Overall Loss 0.549738    Objective Loss 0.549738    Top1 87.000000    Top5 99.000000    LR 0.000500    Time 0.073919    
2024-02-17 12:04:36,463 - --- validate (epoch=91)-----------
2024-02-17 12:04:36,464 - 10000 samples (100 per mini-batch)
2024-02-17 12:04:39,369 - Epoch: [91][  100/  100]    Loss 1.888735    Top1 57.300000    Top5 84.190000    
2024-02-17 12:04:39,521 - ==> Top1: 57.300    Top5: 84.190    Loss: 1.889

2024-02-17 12:04:39,533 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:04:39,533 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:04:39,596 - 

2024-02-17 12:04:39,596 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:04:47,660 - Epoch: [92][  100/  500]    Overall Loss 0.512143    Objective Loss 0.512143                                        LR 0.000500    Time 0.080582    
2024-02-17 12:04:54,746 - Epoch: [92][  200/  500]    Overall Loss 0.524299    Objective Loss 0.524299                                        LR 0.000500    Time 0.075703    
2024-02-17 12:05:01,542 - Epoch: [92][  300/  500]    Overall Loss 0.532035    Objective Loss 0.532035                                        LR 0.000500    Time 0.073111    
2024-02-17 12:05:08,756 - Epoch: [92][  400/  500]    Overall Loss 0.539652    Objective Loss 0.539652                                        LR 0.000500    Time 0.072858    
2024-02-17 12:05:15,999 - Epoch: [92][  500/  500]    Overall Loss 0.544782    Objective Loss 0.544782    Top1 77.500000    Top5 96.500000    LR 0.000500    Time 0.072765    
2024-02-17 12:05:16,178 - --- validate (epoch=92)-----------
2024-02-17 12:05:16,179 - 10000 samples (100 per mini-batch)
2024-02-17 12:05:19,124 - Epoch: [92][  100/  100]    Loss 1.756985    Top1 59.200000    Top5 85.740000    
2024-02-17 12:05:19,256 - ==> Top1: 59.200    Top5: 85.740    Loss: 1.757

2024-02-17 12:05:19,268 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:05:19,268 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:05:19,331 - 

2024-02-17 12:05:19,331 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:05:27,107 - Epoch: [93][  100/  500]    Overall Loss 0.506487    Objective Loss 0.506487                                        LR 0.000500    Time 0.077704    
2024-02-17 12:05:34,235 - Epoch: [93][  200/  500]    Overall Loss 0.517290    Objective Loss 0.517290                                        LR 0.000500    Time 0.074473    
2024-02-17 12:05:41,537 - Epoch: [93][  300/  500]    Overall Loss 0.525091    Objective Loss 0.525091                                        LR 0.000500    Time 0.073976    
2024-02-17 12:05:48,906 - Epoch: [93][  400/  500]    Overall Loss 0.529492    Objective Loss 0.529492                                        LR 0.000500    Time 0.073893    
2024-02-17 12:05:56,283 - Epoch: [93][  500/  500]    Overall Loss 0.537910    Objective Loss 0.537910    Top1 83.000000    Top5 99.000000    LR 0.000500    Time 0.073860    
2024-02-17 12:05:56,448 - --- validate (epoch=93)-----------
2024-02-17 12:05:56,449 - 10000 samples (100 per mini-batch)
2024-02-17 12:05:59,331 - Epoch: [93][  100/  100]    Loss 1.832554    Top1 58.650000    Top5 84.650000    
2024-02-17 12:05:59,450 - ==> Top1: 58.650    Top5: 84.650    Loss: 1.833

2024-02-17 12:05:59,459 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:05:59,459 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:05:59,519 - 

2024-02-17 12:05:59,519 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:06:07,500 - Epoch: [94][  100/  500]    Overall Loss 0.500161    Objective Loss 0.500161                                        LR 0.000500    Time 0.079754    
2024-02-17 12:06:14,723 - Epoch: [94][  200/  500]    Overall Loss 0.509390    Objective Loss 0.509390                                        LR 0.000500    Time 0.075969    
2024-02-17 12:06:21,565 - Epoch: [94][  300/  500]    Overall Loss 0.520344    Objective Loss 0.520344                                        LR 0.000500    Time 0.073444    
2024-02-17 12:06:28,325 - Epoch: [94][  400/  500]    Overall Loss 0.527340    Objective Loss 0.527340                                        LR 0.000500    Time 0.071973    
2024-02-17 12:06:35,607 - Epoch: [94][  500/  500]    Overall Loss 0.534484    Objective Loss 0.534484    Top1 84.000000    Top5 98.000000    LR 0.000500    Time 0.072134    
2024-02-17 12:06:35,780 - --- validate (epoch=94)-----------
2024-02-17 12:06:35,781 - 10000 samples (100 per mini-batch)
2024-02-17 12:06:38,649 - Epoch: [94][  100/  100]    Loss 1.857067    Top1 57.960000    Top5 84.550000    
2024-02-17 12:06:38,760 - ==> Top1: 57.960    Top5: 84.550    Loss: 1.857

2024-02-17 12:06:38,773 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:06:38,773 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:06:38,836 - 

2024-02-17 12:06:38,836 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:06:46,088 - Epoch: [95][  100/  500]    Overall Loss 0.505093    Objective Loss 0.505093                                        LR 0.000500    Time 0.072478    
2024-02-17 12:06:52,838 - Epoch: [95][  200/  500]    Overall Loss 0.510239    Objective Loss 0.510239                                        LR 0.000500    Time 0.069971    
2024-02-17 12:07:00,065 - Epoch: [95][  300/  500]    Overall Loss 0.512875    Objective Loss 0.512875                                        LR 0.000500    Time 0.070724    
2024-02-17 12:07:07,476 - Epoch: [95][  400/  500]    Overall Loss 0.522760    Objective Loss 0.522760                                        LR 0.000500    Time 0.071560    
2024-02-17 12:07:14,739 - Epoch: [95][  500/  500]    Overall Loss 0.532060    Objective Loss 0.532060    Top1 84.000000    Top5 97.000000    LR 0.000500    Time 0.071768    
2024-02-17 12:07:14,912 - --- validate (epoch=95)-----------
2024-02-17 12:07:14,913 - 10000 samples (100 per mini-batch)
2024-02-17 12:07:17,740 - Epoch: [95][  100/  100]    Loss 1.794046    Top1 58.590000    Top5 85.450000    
2024-02-17 12:07:17,862 - ==> Top1: 58.590    Top5: 85.450    Loss: 1.794

2024-02-17 12:07:17,873 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:07:17,873 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:07:17,937 - 

2024-02-17 12:07:17,937 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:07:26,040 - Epoch: [96][  100/  500]    Overall Loss 0.506437    Objective Loss 0.506437                                        LR 0.000500    Time 0.080973    
2024-02-17 12:07:33,329 - Epoch: [96][  200/  500]    Overall Loss 0.510144    Objective Loss 0.510144                                        LR 0.000500    Time 0.076912    
2024-02-17 12:07:40,432 - Epoch: [96][  300/  500]    Overall Loss 0.513762    Objective Loss 0.513762                                        LR 0.000500    Time 0.074938    
2024-02-17 12:07:47,756 - Epoch: [96][  400/  500]    Overall Loss 0.521659    Objective Loss 0.521659                                        LR 0.000500    Time 0.074505    
2024-02-17 12:07:55,060 - Epoch: [96][  500/  500]    Overall Loss 0.523922    Objective Loss 0.523922    Top1 86.000000    Top5 98.500000    LR 0.000500    Time 0.074203    
2024-02-17 12:07:55,174 - --- validate (epoch=96)-----------
2024-02-17 12:07:55,174 - 10000 samples (100 per mini-batch)
2024-02-17 12:07:58,155 - Epoch: [96][  100/  100]    Loss 1.863796    Top1 57.850000    Top5 84.610000    
2024-02-17 12:07:58,262 - ==> Top1: 57.850    Top5: 84.610    Loss: 1.864

2024-02-17 12:07:58,275 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:07:58,275 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:07:58,340 - 

2024-02-17 12:07:58,340 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:08:06,175 - Epoch: [97][  100/  500]    Overall Loss 0.492927    Objective Loss 0.492927                                        LR 0.000500    Time 0.078297    
2024-02-17 12:08:13,478 - Epoch: [97][  200/  500]    Overall Loss 0.510134    Objective Loss 0.510134                                        LR 0.000500    Time 0.075640    
2024-02-17 12:08:20,803 - Epoch: [97][  300/  500]    Overall Loss 0.511359    Objective Loss 0.511359                                        LR 0.000500    Time 0.074828    
2024-02-17 12:08:28,140 - Epoch: [97][  400/  500]    Overall Loss 0.517971    Objective Loss 0.517971                                        LR 0.000500    Time 0.074454    
2024-02-17 12:08:35,447 - Epoch: [97][  500/  500]    Overall Loss 0.522544    Objective Loss 0.522544    Top1 80.000000    Top5 96.500000    LR 0.000500    Time 0.074169    
2024-02-17 12:08:35,611 - --- validate (epoch=97)-----------
2024-02-17 12:08:35,612 - 10000 samples (100 per mini-batch)
2024-02-17 12:08:38,542 - Epoch: [97][  100/  100]    Loss 1.799315    Top1 58.500000    Top5 85.210000    
2024-02-17 12:08:38,668 - ==> Top1: 58.500    Top5: 85.210    Loss: 1.799

2024-02-17 12:08:38,679 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:08:38,679 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:08:38,752 - 

2024-02-17 12:08:38,752 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:08:46,428 - Epoch: [98][  100/  500]    Overall Loss 0.492416    Objective Loss 0.492416                                        LR 0.000500    Time 0.076711    
2024-02-17 12:08:53,698 - Epoch: [98][  200/  500]    Overall Loss 0.509689    Objective Loss 0.509689                                        LR 0.000500    Time 0.074684    
2024-02-17 12:09:00,853 - Epoch: [98][  300/  500]    Overall Loss 0.514820    Objective Loss 0.514820                                        LR 0.000500    Time 0.073625    
2024-02-17 12:09:08,053 - Epoch: [98][  400/  500]    Overall Loss 0.519473    Objective Loss 0.519473                                        LR 0.000500    Time 0.073210    
2024-02-17 12:09:15,174 - Epoch: [98][  500/  500]    Overall Loss 0.520509    Objective Loss 0.520509    Top1 78.500000    Top5 96.000000    LR 0.000500    Time 0.072803    
2024-02-17 12:09:15,340 - --- validate (epoch=98)-----------
2024-02-17 12:09:15,341 - 10000 samples (100 per mini-batch)
2024-02-17 12:09:18,528 - Epoch: [98][  100/  100]    Loss 1.888811    Top1 57.210000    Top5 84.670000    
2024-02-17 12:09:18,684 - ==> Top1: 57.210    Top5: 84.670    Loss: 1.889

2024-02-17 12:09:18,697 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:09:18,697 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:09:18,760 - 

2024-02-17 12:09:18,761 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:09:26,462 - Epoch: [99][  100/  500]    Overall Loss 0.491538    Objective Loss 0.491538                                        LR 0.000500    Time 0.076960    
2024-02-17 12:09:33,739 - Epoch: [99][  200/  500]    Overall Loss 0.495809    Objective Loss 0.495809                                        LR 0.000500    Time 0.074843    
2024-02-17 12:09:41,059 - Epoch: [99][  300/  500]    Overall Loss 0.503789    Objective Loss 0.503789                                        LR 0.000500    Time 0.074282    
2024-02-17 12:09:48,366 - Epoch: [99][  400/  500]    Overall Loss 0.509748    Objective Loss 0.509748                                        LR 0.000500    Time 0.073969    
2024-02-17 12:09:55,573 - Epoch: [99][  500/  500]    Overall Loss 0.509678    Objective Loss 0.509678    Top1 83.000000    Top5 98.000000    LR 0.000500    Time 0.073581    
2024-02-17 12:09:55,730 - --- validate (epoch=99)-----------
2024-02-17 12:09:55,731 - 10000 samples (100 per mini-batch)
2024-02-17 12:09:58,658 - Epoch: [99][  100/  100]    Loss 1.846241    Top1 58.420000    Top5 85.290000    
2024-02-17 12:09:58,756 - ==> Top1: 58.420    Top5: 85.290    Loss: 1.846

2024-02-17 12:09:58,768 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:09:58,769 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:09:58,830 - 

2024-02-17 12:09:58,830 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:10:06,548 - Epoch: [100][  100/  500]    Overall Loss 0.451988    Objective Loss 0.451988                                        LR 0.000250    Time 0.077133    
2024-02-17 12:10:13,283 - Epoch: [100][  200/  500]    Overall Loss 0.452809    Objective Loss 0.452809                                        LR 0.000250    Time 0.072226    
2024-02-17 12:10:20,608 - Epoch: [100][  300/  500]    Overall Loss 0.448110    Objective Loss 0.448110                                        LR 0.000250    Time 0.072553    
2024-02-17 12:10:27,896 - Epoch: [100][  400/  500]    Overall Loss 0.446328    Objective Loss 0.446328                                        LR 0.000250    Time 0.072626    
2024-02-17 12:10:35,200 - Epoch: [100][  500/  500]    Overall Loss 0.444304    Objective Loss 0.444304    Top1 86.000000    Top5 99.500000    LR 0.000250    Time 0.072700    
2024-02-17 12:10:35,319 - --- validate (epoch=100)-----------
2024-02-17 12:10:35,320 - 10000 samples (100 per mini-batch)
2024-02-17 12:10:38,201 - Epoch: [100][  100/  100]    Loss 1.728898    Top1 59.900000    Top5 85.980000    
2024-02-17 12:10:38,312 - ==> Top1: 59.900    Top5: 85.980    Loss: 1.729

2024-02-17 12:10:38,327 - ==> Best [Top1: 59.900   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 100]
2024-02-17 12:10:38,328 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:10:38,418 - 

2024-02-17 12:10:38,418 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:10:46,035 - Epoch: [101][  100/  500]    Overall Loss 0.418033    Objective Loss 0.418033                                        LR 0.000250    Time 0.076118    
2024-02-17 12:10:53,300 - Epoch: [101][  200/  500]    Overall Loss 0.421524    Objective Loss 0.421524                                        LR 0.000250    Time 0.074365    
2024-02-17 12:11:00,406 - Epoch: [101][  300/  500]    Overall Loss 0.426896    Objective Loss 0.426896                                        LR 0.000250    Time 0.073248    
2024-02-17 12:11:07,552 - Epoch: [101][  400/  500]    Overall Loss 0.427725    Objective Loss 0.427725                                        LR 0.000250    Time 0.072793    
2024-02-17 12:11:14,922 - Epoch: [101][  500/  500]    Overall Loss 0.429468    Objective Loss 0.429468    Top1 86.000000    Top5 98.500000    LR 0.000250    Time 0.072966    
2024-02-17 12:11:15,052 - --- validate (epoch=101)-----------
2024-02-17 12:11:15,053 - 10000 samples (100 per mini-batch)
2024-02-17 12:11:17,967 - Epoch: [101][  100/  100]    Loss 1.757559    Top1 59.600000    Top5 86.150000    
2024-02-17 12:11:18,070 - ==> Top1: 59.600    Top5: 86.150    Loss: 1.758

2024-02-17 12:11:18,083 - ==> Best [Top1: 59.900   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 100]
2024-02-17 12:11:18,084 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:11:18,146 - 

2024-02-17 12:11:18,146 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:11:26,137 - Epoch: [102][  100/  500]    Overall Loss 0.416229    Objective Loss 0.416229                                        LR 0.000250    Time 0.079854    
2024-02-17 12:11:33,365 - Epoch: [102][  200/  500]    Overall Loss 0.413444    Objective Loss 0.413444                                        LR 0.000250    Time 0.076044    
2024-02-17 12:11:40,667 - Epoch: [102][  300/  500]    Overall Loss 0.420871    Objective Loss 0.420871                                        LR 0.000250    Time 0.075022    
2024-02-17 12:11:47,845 - Epoch: [102][  400/  500]    Overall Loss 0.427168    Objective Loss 0.427168                                        LR 0.000250    Time 0.074200    
2024-02-17 12:11:54,634 - Epoch: [102][  500/  500]    Overall Loss 0.427152    Objective Loss 0.427152    Top1 89.000000    Top5 99.500000    LR 0.000250    Time 0.072933    
2024-02-17 12:11:54,783 - --- validate (epoch=102)-----------
2024-02-17 12:11:54,784 - 10000 samples (100 per mini-batch)
2024-02-17 12:11:57,711 - Epoch: [102][  100/  100]    Loss 1.739574    Top1 60.070000    Top5 86.210000    
2024-02-17 12:11:57,831 - ==> Top1: 60.070    Top5: 86.210    Loss: 1.740

2024-02-17 12:11:57,842 - ==> Best [Top1: 60.070   Top5: 86.210   Sparsity:0.00   Params: 753952 on epoch: 102]
2024-02-17 12:11:57,843 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:11:57,921 - 

2024-02-17 12:11:57,921 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:12:05,706 - Epoch: [103][  100/  500]    Overall Loss 0.403438    Objective Loss 0.403438                                        LR 0.000250    Time 0.077797    
2024-02-17 12:12:13,084 - Epoch: [103][  200/  500]    Overall Loss 0.401079    Objective Loss 0.401079                                        LR 0.000250    Time 0.075767    
2024-02-17 12:12:20,401 - Epoch: [103][  300/  500]    Overall Loss 0.409565    Objective Loss 0.409565                                        LR 0.000250    Time 0.074886    
2024-02-17 12:12:27,622 - Epoch: [103][  400/  500]    Overall Loss 0.415376    Objective Loss 0.415376                                        LR 0.000250    Time 0.074208    
2024-02-17 12:12:34,525 - Epoch: [103][  500/  500]    Overall Loss 0.418406    Objective Loss 0.418406    Top1 89.000000    Top5 99.500000    LR 0.000250    Time 0.073165    
2024-02-17 12:12:34,691 - --- validate (epoch=103)-----------
2024-02-17 12:12:34,692 - 10000 samples (100 per mini-batch)
2024-02-17 12:12:37,658 - Epoch: [103][  100/  100]    Loss 1.754008    Top1 59.800000    Top5 85.760000    
2024-02-17 12:12:37,762 - ==> Top1: 59.800    Top5: 85.760    Loss: 1.754

2024-02-17 12:12:37,773 - ==> Best [Top1: 60.070   Top5: 86.210   Sparsity:0.00   Params: 753952 on epoch: 102]
2024-02-17 12:12:37,773 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:12:37,836 - 

2024-02-17 12:12:37,836 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:12:45,879 - Epoch: [104][  100/  500]    Overall Loss 0.394743    Objective Loss 0.394743                                        LR 0.000250    Time 0.080375    
2024-02-17 12:12:53,223 - Epoch: [104][  200/  500]    Overall Loss 0.400930    Objective Loss 0.400930                                        LR 0.000250    Time 0.076885    
2024-02-17 12:13:00,172 - Epoch: [104][  300/  500]    Overall Loss 0.403892    Objective Loss 0.403892                                        LR 0.000250    Time 0.074409    
2024-02-17 12:13:07,460 - Epoch: [104][  400/  500]    Overall Loss 0.407532    Objective Loss 0.407532                                        LR 0.000250    Time 0.074018    
2024-02-17 12:13:14,680 - Epoch: [104][  500/  500]    Overall Loss 0.412013    Objective Loss 0.412013    Top1 87.000000    Top5 99.000000    LR 0.000250    Time 0.073646    
2024-02-17 12:13:14,833 - --- validate (epoch=104)-----------
2024-02-17 12:13:14,834 - 10000 samples (100 per mini-batch)
2024-02-17 12:13:17,847 - Epoch: [104][  100/  100]    Loss 1.762275    Top1 60.200000    Top5 86.020000    
2024-02-17 12:13:17,980 - ==> Top1: 60.200    Top5: 86.020    Loss: 1.762

2024-02-17 12:13:17,993 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:13:17,994 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:13:18,084 - 

2024-02-17 12:13:18,085 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:13:25,810 - Epoch: [105][  100/  500]    Overall Loss 0.393309    Objective Loss 0.393309                                        LR 0.000250    Time 0.077191    
2024-02-17 12:13:33,003 - Epoch: [105][  200/  500]    Overall Loss 0.400789    Objective Loss 0.400789                                        LR 0.000250    Time 0.074540    
2024-02-17 12:13:40,159 - Epoch: [105][  300/  500]    Overall Loss 0.402713    Objective Loss 0.402713                                        LR 0.000250    Time 0.073532    
2024-02-17 12:13:47,369 - Epoch: [105][  400/  500]    Overall Loss 0.410494    Objective Loss 0.410494                                        LR 0.000250    Time 0.073164    
2024-02-17 12:13:54,820 - Epoch: [105][  500/  500]    Overall Loss 0.411551    Objective Loss 0.411551    Top1 88.500000    Top5 99.500000    LR 0.000250    Time 0.073424    
2024-02-17 12:13:54,974 - --- validate (epoch=105)-----------
2024-02-17 12:13:54,975 - 10000 samples (100 per mini-batch)
2024-02-17 12:13:58,049 - Epoch: [105][  100/  100]    Loss 1.748009    Top1 59.960000    Top5 86.130000    
2024-02-17 12:13:58,184 - ==> Top1: 59.960    Top5: 86.130    Loss: 1.748

2024-02-17 12:13:58,192 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:13:58,192 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:13:58,253 - 

2024-02-17 12:13:58,253 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:14:05,987 - Epoch: [106][  100/  500]    Overall Loss 0.394131    Objective Loss 0.394131                                        LR 0.000250    Time 0.077274    
2024-02-17 12:14:13,247 - Epoch: [106][  200/  500]    Overall Loss 0.396050    Objective Loss 0.396050                                        LR 0.000250    Time 0.074915    
2024-02-17 12:14:20,568 - Epoch: [106][  300/  500]    Overall Loss 0.398229    Objective Loss 0.398229                                        LR 0.000250    Time 0.074333    
2024-02-17 12:14:27,709 - Epoch: [106][  400/  500]    Overall Loss 0.399904    Objective Loss 0.399904                                        LR 0.000250    Time 0.073592    
2024-02-17 12:14:35,094 - Epoch: [106][  500/  500]    Overall Loss 0.403155    Objective Loss 0.403155    Top1 86.500000    Top5 99.500000    LR 0.000250    Time 0.073634    
2024-02-17 12:14:35,190 - --- validate (epoch=106)-----------
2024-02-17 12:14:35,191 - 10000 samples (100 per mini-batch)
2024-02-17 12:14:38,549 - Epoch: [106][  100/  100]    Loss 1.801233    Top1 59.730000    Top5 85.940000    
2024-02-17 12:14:38,699 - ==> Top1: 59.730    Top5: 85.940    Loss: 1.801

2024-02-17 12:14:38,705 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:14:38,705 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:14:38,763 - 

2024-02-17 12:14:38,763 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:14:46,574 - Epoch: [107][  100/  500]    Overall Loss 0.401932    Objective Loss 0.401932                                        LR 0.000250    Time 0.078048    
2024-02-17 12:14:53,948 - Epoch: [107][  200/  500]    Overall Loss 0.399534    Objective Loss 0.399534                                        LR 0.000250    Time 0.075871    
2024-02-17 12:15:01,313 - Epoch: [107][  300/  500]    Overall Loss 0.402269    Objective Loss 0.402269                                        LR 0.000250    Time 0.075116    
2024-02-17 12:15:08,615 - Epoch: [107][  400/  500]    Overall Loss 0.400546    Objective Loss 0.400546                                        LR 0.000250    Time 0.074583    
2024-02-17 12:15:15,970 - Epoch: [107][  500/  500]    Overall Loss 0.405310    Objective Loss 0.405310    Top1 87.000000    Top5 100.000000    LR 0.000250    Time 0.074368    
2024-02-17 12:15:16,139 - --- validate (epoch=107)-----------
2024-02-17 12:15:16,140 - 10000 samples (100 per mini-batch)
2024-02-17 12:15:19,218 - Epoch: [107][  100/  100]    Loss 1.785273    Top1 59.360000    Top5 86.040000    
2024-02-17 12:15:19,334 - ==> Top1: 59.360    Top5: 86.040    Loss: 1.785

2024-02-17 12:15:19,342 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:15:19,342 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:15:19,406 - 

2024-02-17 12:15:19,407 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:15:27,404 - Epoch: [108][  100/  500]    Overall Loss 0.384186    Objective Loss 0.384186                                        LR 0.000250    Time 0.079910    
2024-02-17 12:15:34,784 - Epoch: [108][  200/  500]    Overall Loss 0.387768    Objective Loss 0.387768                                        LR 0.000250    Time 0.076836    
2024-02-17 12:15:42,019 - Epoch: [108][  300/  500]    Overall Loss 0.390102    Objective Loss 0.390102                                        LR 0.000250    Time 0.075329    
2024-02-17 12:15:49,372 - Epoch: [108][  400/  500]    Overall Loss 0.397599    Objective Loss 0.397599                                        LR 0.000250    Time 0.074868    
2024-02-17 12:15:56,755 - Epoch: [108][  500/  500]    Overall Loss 0.399284    Objective Loss 0.399284    Top1 87.000000    Top5 98.500000    LR 0.000250    Time 0.074653    
2024-02-17 12:15:56,887 - --- validate (epoch=108)-----------
2024-02-17 12:15:56,888 - 10000 samples (100 per mini-batch)
2024-02-17 12:16:00,338 - Epoch: [108][  100/  100]    Loss 1.784492    Top1 60.080000    Top5 85.660000    
2024-02-17 12:16:00,441 - ==> Top1: 60.080    Top5: 85.660    Loss: 1.784

2024-02-17 12:16:00,452 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:16:00,453 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:16:00,514 - 

2024-02-17 12:16:00,515 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:16:08,334 - Epoch: [109][  100/  500]    Overall Loss 0.383582    Objective Loss 0.383582                                        LR 0.000250    Time 0.078110    
2024-02-17 12:16:15,668 - Epoch: [109][  200/  500]    Overall Loss 0.395178    Objective Loss 0.395178                                        LR 0.000250    Time 0.075705    
2024-02-17 12:16:22,926 - Epoch: [109][  300/  500]    Overall Loss 0.394470    Objective Loss 0.394470                                        LR 0.000250    Time 0.074650    
2024-02-17 12:16:30,271 - Epoch: [109][  400/  500]    Overall Loss 0.396336    Objective Loss 0.396336                                        LR 0.000250    Time 0.074339    
2024-02-17 12:16:37,477 - Epoch: [109][  500/  500]    Overall Loss 0.397936    Objective Loss 0.397936    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.073876    
2024-02-17 12:16:37,611 - --- validate (epoch=109)-----------
2024-02-17 12:16:37,611 - 10000 samples (100 per mini-batch)
2024-02-17 12:16:40,801 - Epoch: [109][  100/  100]    Loss 1.760970    Top1 60.100000    Top5 86.090000    
2024-02-17 12:16:40,923 - ==> Top1: 60.100    Top5: 86.090    Loss: 1.761

2024-02-17 12:16:40,935 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:16:40,936 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:16:40,999 - 

2024-02-17 12:16:41,000 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:16:48,995 - Epoch: [110][  100/  500]    Overall Loss 0.375902    Objective Loss 0.375902                                        LR 0.000250    Time 0.079895    
2024-02-17 12:16:56,542 - Epoch: [110][  200/  500]    Overall Loss 0.385555    Objective Loss 0.385555                                        LR 0.000250    Time 0.077663    
2024-02-17 12:17:03,782 - Epoch: [110][  300/  500]    Overall Loss 0.391136    Objective Loss 0.391136                                        LR 0.000250    Time 0.075897    
2024-02-17 12:17:11,099 - Epoch: [110][  400/  500]    Overall Loss 0.393006    Objective Loss 0.393006                                        LR 0.000250    Time 0.075204    
2024-02-17 12:17:18,433 - Epoch: [110][  500/  500]    Overall Loss 0.395539    Objective Loss 0.395539    Top1 88.000000    Top5 98.500000    LR 0.000250    Time 0.074823    
2024-02-17 12:17:18,559 - --- validate (epoch=110)-----------
2024-02-17 12:17:18,560 - 10000 samples (100 per mini-batch)
2024-02-17 12:17:21,629 - Epoch: [110][  100/  100]    Loss 1.768408    Top1 59.650000    Top5 85.850000    
2024-02-17 12:17:21,773 - ==> Top1: 59.650    Top5: 85.850    Loss: 1.768

2024-02-17 12:17:21,787 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:17:21,787 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:17:21,851 - 

2024-02-17 12:17:21,851 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:17:29,647 - Epoch: [111][  100/  500]    Overall Loss 0.376204    Objective Loss 0.376204                                        LR 0.000250    Time 0.077904    
2024-02-17 12:17:37,031 - Epoch: [111][  200/  500]    Overall Loss 0.375309    Objective Loss 0.375309                                        LR 0.000250    Time 0.075849    
2024-02-17 12:17:44,316 - Epoch: [111][  300/  500]    Overall Loss 0.379431    Objective Loss 0.379431                                        LR 0.000250    Time 0.074836    
2024-02-17 12:17:51,407 - Epoch: [111][  400/  500]    Overall Loss 0.384439    Objective Loss 0.384439                                        LR 0.000250    Time 0.073845    
2024-02-17 12:17:58,703 - Epoch: [111][  500/  500]    Overall Loss 0.384868    Objective Loss 0.384868    Top1 91.500000    Top5 99.500000    LR 0.000250    Time 0.073660    
2024-02-17 12:17:58,850 - --- validate (epoch=111)-----------
2024-02-17 12:17:58,851 - 10000 samples (100 per mini-batch)
2024-02-17 12:18:02,020 - Epoch: [111][  100/  100]    Loss 1.789759    Top1 59.550000    Top5 85.860000    
2024-02-17 12:18:02,127 - ==> Top1: 59.550    Top5: 85.860    Loss: 1.790

2024-02-17 12:18:02,136 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:18:02,136 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:18:02,198 - 

2024-02-17 12:18:02,198 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:18:09,920 - Epoch: [112][  100/  500]    Overall Loss 0.372916    Objective Loss 0.372916                                        LR 0.000250    Time 0.077164    
2024-02-17 12:18:17,154 - Epoch: [112][  200/  500]    Overall Loss 0.377291    Objective Loss 0.377291                                        LR 0.000250    Time 0.074734    
2024-02-17 12:18:24,441 - Epoch: [112][  300/  500]    Overall Loss 0.377563    Objective Loss 0.377563                                        LR 0.000250    Time 0.074101    
2024-02-17 12:18:31,773 - Epoch: [112][  400/  500]    Overall Loss 0.383397    Objective Loss 0.383397                                        LR 0.000250    Time 0.073894    
2024-02-17 12:18:38,922 - Epoch: [112][  500/  500]    Overall Loss 0.386634    Objective Loss 0.386634    Top1 85.500000    Top5 99.500000    LR 0.000250    Time 0.073404    
2024-02-17 12:18:39,038 - --- validate (epoch=112)-----------
2024-02-17 12:18:39,039 - 10000 samples (100 per mini-batch)
2024-02-17 12:18:42,419 - Epoch: [112][  100/  100]    Loss 1.808364    Top1 59.860000    Top5 86.170000    
2024-02-17 12:18:42,571 - ==> Top1: 59.860    Top5: 86.170    Loss: 1.808

2024-02-17 12:18:42,579 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:18:42,579 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:18:42,644 - 

2024-02-17 12:18:42,645 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:18:50,517 - Epoch: [113][  100/  500]    Overall Loss 0.379976    Objective Loss 0.379976                                        LR 0.000250    Time 0.078665    
2024-02-17 12:18:57,983 - Epoch: [113][  200/  500]    Overall Loss 0.376639    Objective Loss 0.376639                                        LR 0.000250    Time 0.076643    
2024-02-17 12:19:05,333 - Epoch: [113][  300/  500]    Overall Loss 0.377383    Objective Loss 0.377383                                        LR 0.000250    Time 0.075583    
2024-02-17 12:19:12,744 - Epoch: [113][  400/  500]    Overall Loss 0.382346    Objective Loss 0.382346                                        LR 0.000250    Time 0.075204    
2024-02-17 12:19:19,892 - Epoch: [113][  500/  500]    Overall Loss 0.384519    Objective Loss 0.384519    Top1 86.000000    Top5 99.500000    LR 0.000250    Time 0.074452    
2024-02-17 12:19:20,046 - --- validate (epoch=113)-----------
2024-02-17 12:19:20,047 - 10000 samples (100 per mini-batch)
2024-02-17 12:19:23,182 - Epoch: [113][  100/  100]    Loss 1.799925    Top1 59.570000    Top5 85.930000    
2024-02-17 12:19:23,368 - ==> Top1: 59.570    Top5: 85.930    Loss: 1.800

2024-02-17 12:19:23,380 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:19:23,380 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:19:23,441 - 

2024-02-17 12:19:23,441 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:19:31,369 - Epoch: [114][  100/  500]    Overall Loss 0.362519    Objective Loss 0.362519                                        LR 0.000250    Time 0.079226    
2024-02-17 12:19:38,637 - Epoch: [114][  200/  500]    Overall Loss 0.368233    Objective Loss 0.368233                                        LR 0.000250    Time 0.075932    
2024-02-17 12:19:45,923 - Epoch: [114][  300/  500]    Overall Loss 0.368697    Objective Loss 0.368697                                        LR 0.000250    Time 0.074895    
2024-02-17 12:19:53,382 - Epoch: [114][  400/  500]    Overall Loss 0.373663    Objective Loss 0.373663                                        LR 0.000250    Time 0.074808    
2024-02-17 12:20:00,791 - Epoch: [114][  500/  500]    Overall Loss 0.380259    Objective Loss 0.380259    Top1 90.000000    Top5 99.000000    LR 0.000250    Time 0.074656    
2024-02-17 12:20:00,986 - --- validate (epoch=114)-----------
2024-02-17 12:20:00,987 - 10000 samples (100 per mini-batch)
2024-02-17 12:20:03,949 - Epoch: [114][  100/  100]    Loss 1.824426    Top1 59.310000    Top5 85.840000    
2024-02-17 12:20:04,110 - ==> Top1: 59.310    Top5: 85.840    Loss: 1.824

2024-02-17 12:20:04,122 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:20:04,123 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:20:04,185 - 

2024-02-17 12:20:04,185 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:20:11,950 - Epoch: [115][  100/  500]    Overall Loss 0.372828    Objective Loss 0.372828                                        LR 0.000250    Time 0.077588    
2024-02-17 12:20:19,324 - Epoch: [115][  200/  500]    Overall Loss 0.373907    Objective Loss 0.373907                                        LR 0.000250    Time 0.075646    
2024-02-17 12:20:26,645 - Epoch: [115][  300/  500]    Overall Loss 0.372180    Objective Loss 0.372180                                        LR 0.000250    Time 0.074818    
2024-02-17 12:20:33,986 - Epoch: [115][  400/  500]    Overall Loss 0.377547    Objective Loss 0.377547                                        LR 0.000250    Time 0.074457    
2024-02-17 12:20:41,238 - Epoch: [115][  500/  500]    Overall Loss 0.378982    Objective Loss 0.378982    Top1 85.000000    Top5 98.500000    LR 0.000250    Time 0.074061    
2024-02-17 12:20:41,399 - --- validate (epoch=115)-----------
2024-02-17 12:20:41,399 - 10000 samples (100 per mini-batch)
2024-02-17 12:20:44,316 - Epoch: [115][  100/  100]    Loss 1.803950    Top1 59.830000    Top5 85.820000    
2024-02-17 12:20:44,430 - ==> Top1: 59.830    Top5: 85.820    Loss: 1.804

2024-02-17 12:20:44,441 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:20:44,442 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:20:44,503 - 

2024-02-17 12:20:44,503 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:20:52,786 - Epoch: [116][  100/  500]    Overall Loss 0.370018    Objective Loss 0.370018                                        LR 0.000250    Time 0.082772    
2024-02-17 12:21:00,346 - Epoch: [116][  200/  500]    Overall Loss 0.365850    Objective Loss 0.365850                                        LR 0.000250    Time 0.079163    
2024-02-17 12:21:07,586 - Epoch: [116][  300/  500]    Overall Loss 0.368996    Objective Loss 0.368996                                        LR 0.000250    Time 0.076896    
2024-02-17 12:21:14,830 - Epoch: [116][  400/  500]    Overall Loss 0.370000    Objective Loss 0.370000                                        LR 0.000250    Time 0.075775    
2024-02-17 12:21:22,166 - Epoch: [116][  500/  500]    Overall Loss 0.374056    Objective Loss 0.374056    Top1 85.000000    Top5 99.500000    LR 0.000250    Time 0.075282    
2024-02-17 12:21:22,296 - --- validate (epoch=116)-----------
2024-02-17 12:21:22,297 - 10000 samples (100 per mini-batch)
2024-02-17 12:21:25,206 - Epoch: [116][  100/  100]    Loss 1.815954    Top1 59.720000    Top5 85.730000    
2024-02-17 12:21:25,390 - ==> Top1: 59.720    Top5: 85.730    Loss: 1.816

2024-02-17 12:21:25,401 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:21:25,402 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:21:25,462 - 

2024-02-17 12:21:25,462 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:21:33,233 - Epoch: [117][  100/  500]    Overall Loss 0.357760    Objective Loss 0.357760                                        LR 0.000250    Time 0.077650    
2024-02-17 12:21:40,568 - Epoch: [117][  200/  500]    Overall Loss 0.356955    Objective Loss 0.356955                                        LR 0.000250    Time 0.075482    
2024-02-17 12:21:47,850 - Epoch: [117][  300/  500]    Overall Loss 0.364442    Objective Loss 0.364442                                        LR 0.000250    Time 0.074580    
2024-02-17 12:21:55,113 - Epoch: [117][  400/  500]    Overall Loss 0.370243    Objective Loss 0.370243                                        LR 0.000250    Time 0.074082    
2024-02-17 12:22:02,508 - Epoch: [117][  500/  500]    Overall Loss 0.372194    Objective Loss 0.372194    Top1 89.500000    Top5 99.500000    LR 0.000250    Time 0.074047    
2024-02-17 12:22:02,647 - --- validate (epoch=117)-----------
2024-02-17 12:22:02,648 - 10000 samples (100 per mini-batch)
2024-02-17 12:22:05,711 - Epoch: [117][  100/  100]    Loss 1.813385    Top1 60.020000    Top5 85.900000    
2024-02-17 12:22:05,901 - ==> Top1: 60.020    Top5: 85.900    Loss: 1.813

2024-02-17 12:22:05,913 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:22:05,913 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:22:05,980 - 

2024-02-17 12:22:05,981 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:22:13,988 - Epoch: [118][  100/  500]    Overall Loss 0.357653    Objective Loss 0.357653                                        LR 0.000250    Time 0.080017    
2024-02-17 12:22:21,266 - Epoch: [118][  200/  500]    Overall Loss 0.353822    Objective Loss 0.353822                                        LR 0.000250    Time 0.076377    
2024-02-17 12:22:28,539 - Epoch: [118][  300/  500]    Overall Loss 0.354413    Objective Loss 0.354413                                        LR 0.000250    Time 0.075150    
2024-02-17 12:22:35,780 - Epoch: [118][  400/  500]    Overall Loss 0.362473    Objective Loss 0.362473                                        LR 0.000250    Time 0.074454    
2024-02-17 12:22:43,147 - Epoch: [118][  500/  500]    Overall Loss 0.368500    Objective Loss 0.368500    Top1 89.000000    Top5 99.500000    LR 0.000250    Time 0.074289    
2024-02-17 12:22:43,271 - --- validate (epoch=118)-----------
2024-02-17 12:22:43,272 - 10000 samples (100 per mini-batch)
2024-02-17 12:22:46,237 - Epoch: [118][  100/  100]    Loss 1.849383    Top1 59.390000    Top5 85.570000    
2024-02-17 12:22:46,334 - ==> Top1: 59.390    Top5: 85.570    Loss: 1.849

2024-02-17 12:22:46,345 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:22:46,345 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:22:46,408 - 

2024-02-17 12:22:46,408 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:22:54,176 - Epoch: [119][  100/  500]    Overall Loss 0.345665    Objective Loss 0.345665                                        LR 0.000250    Time 0.077626    
2024-02-17 12:23:01,404 - Epoch: [119][  200/  500]    Overall Loss 0.359003    Objective Loss 0.359003                                        LR 0.000250    Time 0.074932    
2024-02-17 12:23:08,675 - Epoch: [119][  300/  500]    Overall Loss 0.360961    Objective Loss 0.360961                                        LR 0.000250    Time 0.074179    
2024-02-17 12:23:15,957 - Epoch: [119][  400/  500]    Overall Loss 0.365260    Objective Loss 0.365260                                        LR 0.000250    Time 0.073828    
2024-02-17 12:23:23,250 - Epoch: [119][  500/  500]    Overall Loss 0.368261    Objective Loss 0.368261    Top1 88.000000    Top5 99.500000    LR 0.000250    Time 0.073638    
2024-02-17 12:23:23,414 - --- validate (epoch=119)-----------
2024-02-17 12:23:23,415 - 10000 samples (100 per mini-batch)
2024-02-17 12:23:26,402 - Epoch: [119][  100/  100]    Loss 1.855645    Top1 59.090000    Top5 85.700000    
2024-02-17 12:23:26,587 - ==> Top1: 59.090    Top5: 85.700    Loss: 1.856

2024-02-17 12:23:26,598 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:23:26,598 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:23:26,662 - 

2024-02-17 12:23:26,662 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:23:34,784 - Epoch: [120][  100/  500]    Overall Loss 0.339139    Objective Loss 0.339139                                        LR 0.000250    Time 0.081162    
2024-02-17 12:23:42,047 - Epoch: [120][  200/  500]    Overall Loss 0.346002    Objective Loss 0.346002                                        LR 0.000250    Time 0.076877    
2024-02-17 12:23:49,347 - Epoch: [120][  300/  500]    Overall Loss 0.356069    Objective Loss 0.356069                                        LR 0.000250    Time 0.075570    
2024-02-17 12:23:56,645 - Epoch: [120][  400/  500]    Overall Loss 0.359483    Objective Loss 0.359483                                        LR 0.000250    Time 0.074912    
2024-02-17 12:24:04,050 - Epoch: [120][  500/  500]    Overall Loss 0.365972    Objective Loss 0.365972    Top1 89.000000    Top5 98.500000    LR 0.000250    Time 0.074730    
2024-02-17 12:24:04,172 - --- validate (epoch=120)-----------
2024-02-17 12:24:04,173 - 10000 samples (100 per mini-batch)
2024-02-17 12:24:07,233 - Epoch: [120][  100/  100]    Loss 1.849578    Top1 59.150000    Top5 85.530000    
2024-02-17 12:24:07,330 - ==> Top1: 59.150    Top5: 85.530    Loss: 1.850

2024-02-17 12:24:07,341 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:24:07,342 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:24:07,404 - 

2024-02-17 12:24:07,404 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:24:15,082 - Epoch: [121][  100/  500]    Overall Loss 0.353543    Objective Loss 0.353543                                        LR 0.000250    Time 0.076720    
2024-02-17 12:24:22,294 - Epoch: [121][  200/  500]    Overall Loss 0.355225    Objective Loss 0.355225                                        LR 0.000250    Time 0.074403    
2024-02-17 12:24:29,603 - Epoch: [121][  300/  500]    Overall Loss 0.357259    Objective Loss 0.357259                                        LR 0.000250    Time 0.073950    
2024-02-17 12:24:36,808 - Epoch: [121][  400/  500]    Overall Loss 0.362525    Objective Loss 0.362525                                        LR 0.000250    Time 0.073465    
2024-02-17 12:24:44,079 - Epoch: [121][  500/  500]    Overall Loss 0.365523    Objective Loss 0.365523    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.073306    
2024-02-17 12:24:44,238 - --- validate (epoch=121)-----------
2024-02-17 12:24:44,239 - 10000 samples (100 per mini-batch)
2024-02-17 12:24:47,370 - Epoch: [121][  100/  100]    Loss 1.824821    Top1 59.830000    Top5 86.040000    
2024-02-17 12:24:47,508 - ==> Top1: 59.830    Top5: 86.040    Loss: 1.825

2024-02-17 12:24:47,520 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:24:47,520 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:24:47,594 - 

2024-02-17 12:24:47,595 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:24:55,189 - Epoch: [122][  100/  500]    Overall Loss 0.342752    Objective Loss 0.342752                                        LR 0.000250    Time 0.075899    
2024-02-17 12:25:02,150 - Epoch: [122][  200/  500]    Overall Loss 0.351260    Objective Loss 0.351260                                        LR 0.000250    Time 0.072738    
2024-02-17 12:25:08,939 - Epoch: [122][  300/  500]    Overall Loss 0.356273    Objective Loss 0.356273                                        LR 0.000250    Time 0.071111    
2024-02-17 12:25:15,858 - Epoch: [122][  400/  500]    Overall Loss 0.360148    Objective Loss 0.360148                                        LR 0.000250    Time 0.070622    
2024-02-17 12:25:23,144 - Epoch: [122][  500/  500]    Overall Loss 0.361480    Objective Loss 0.361480    Top1 86.500000    Top5 99.500000    LR 0.000250    Time 0.071061    
2024-02-17 12:25:23,264 - --- validate (epoch=122)-----------
2024-02-17 12:25:23,264 - 10000 samples (100 per mini-batch)
2024-02-17 12:25:26,496 - Epoch: [122][  100/  100]    Loss 1.836520    Top1 59.600000    Top5 85.500000    
2024-02-17 12:25:26,609 - ==> Top1: 59.600    Top5: 85.500    Loss: 1.837

2024-02-17 12:25:26,620 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:25:26,621 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:25:26,686 - 

2024-02-17 12:25:26,686 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:25:34,323 - Epoch: [123][  100/  500]    Overall Loss 0.335022    Objective Loss 0.335022                                        LR 0.000250    Time 0.076314    
2024-02-17 12:25:41,575 - Epoch: [123][  200/  500]    Overall Loss 0.342234    Objective Loss 0.342234                                        LR 0.000250    Time 0.074396    
2024-02-17 12:25:48,878 - Epoch: [123][  300/  500]    Overall Loss 0.348723    Objective Loss 0.348723                                        LR 0.000250    Time 0.073926    
2024-02-17 12:25:56,145 - Epoch: [123][  400/  500]    Overall Loss 0.351100    Objective Loss 0.351100                                        LR 0.000250    Time 0.073604    
2024-02-17 12:26:03,487 - Epoch: [123][  500/  500]    Overall Loss 0.353314    Objective Loss 0.353314    Top1 84.500000    Top5 100.000000    LR 0.000250    Time 0.073558    
2024-02-17 12:26:03,663 - --- validate (epoch=123)-----------
2024-02-17 12:26:03,664 - 10000 samples (100 per mini-batch)
2024-02-17 12:26:06,934 - Epoch: [123][  100/  100]    Loss 1.858697    Top1 59.060000    Top5 85.740000    
2024-02-17 12:26:07,041 - ==> Top1: 59.060    Top5: 85.740    Loss: 1.859

2024-02-17 12:26:07,055 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:26:07,055 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:26:07,120 - 

2024-02-17 12:26:07,120 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:26:15,219 - Epoch: [124][  100/  500]    Overall Loss 0.339974    Objective Loss 0.339974                                        LR 0.000250    Time 0.080935    
2024-02-17 12:26:22,490 - Epoch: [124][  200/  500]    Overall Loss 0.345771    Objective Loss 0.345771                                        LR 0.000250    Time 0.076802    
2024-02-17 12:26:29,857 - Epoch: [124][  300/  500]    Overall Loss 0.345579    Objective Loss 0.345579                                        LR 0.000250    Time 0.075743    
2024-02-17 12:26:36,978 - Epoch: [124][  400/  500]    Overall Loss 0.349166    Objective Loss 0.349166                                        LR 0.000250    Time 0.074601    
2024-02-17 12:26:44,317 - Epoch: [124][  500/  500]    Overall Loss 0.353267    Objective Loss 0.353267    Top1 87.000000    Top5 99.000000    LR 0.000250    Time 0.074349    
2024-02-17 12:26:44,437 - --- validate (epoch=124)-----------
2024-02-17 12:26:44,438 - 10000 samples (100 per mini-batch)
2024-02-17 12:26:47,663 - Epoch: [124][  100/  100]    Loss 1.852374    Top1 59.910000    Top5 85.740000    
2024-02-17 12:26:47,775 - ==> Top1: 59.910    Top5: 85.740    Loss: 1.852

2024-02-17 12:26:47,788 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:26:47,789 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:26:47,870 - 

2024-02-17 12:26:47,871 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:26:55,716 - Epoch: [125][  100/  500]    Overall Loss 0.342641    Objective Loss 0.342641                                        LR 0.000250    Time 0.078392    
2024-02-17 12:27:03,113 - Epoch: [125][  200/  500]    Overall Loss 0.339652    Objective Loss 0.339652                                        LR 0.000250    Time 0.076163    
2024-02-17 12:27:10,406 - Epoch: [125][  300/  500]    Overall Loss 0.342186    Objective Loss 0.342186                                        LR 0.000250    Time 0.075072    
2024-02-17 12:27:17,722 - Epoch: [125][  400/  500]    Overall Loss 0.347361    Objective Loss 0.347361                                        LR 0.000250    Time 0.074581    
2024-02-17 12:27:25,114 - Epoch: [125][  500/  500]    Overall Loss 0.349484    Objective Loss 0.349484    Top1 92.500000    Top5 100.000000    LR 0.000250    Time 0.074441    
2024-02-17 12:27:25,245 - --- validate (epoch=125)-----------
2024-02-17 12:27:25,245 - 10000 samples (100 per mini-batch)
2024-02-17 12:27:28,322 - Epoch: [125][  100/  100]    Loss 1.864347    Top1 59.370000    Top5 85.530000    
2024-02-17 12:27:28,426 - ==> Top1: 59.370    Top5: 85.530    Loss: 1.864

2024-02-17 12:27:28,440 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:27:28,440 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:27:28,507 - 

2024-02-17 12:27:28,508 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:27:36,666 - Epoch: [126][  100/  500]    Overall Loss 0.328410    Objective Loss 0.328410                                        LR 0.000250    Time 0.081530    
2024-02-17 12:27:44,107 - Epoch: [126][  200/  500]    Overall Loss 0.342120    Objective Loss 0.342120                                        LR 0.000250    Time 0.077944    
2024-02-17 12:27:51,586 - Epoch: [126][  300/  500]    Overall Loss 0.346524    Objective Loss 0.346524                                        LR 0.000250    Time 0.076879    
2024-02-17 12:27:59,007 - Epoch: [126][  400/  500]    Overall Loss 0.350320    Objective Loss 0.350320                                        LR 0.000250    Time 0.076204    
2024-02-17 12:28:06,233 - Epoch: [126][  500/  500]    Overall Loss 0.349495    Objective Loss 0.349495    Top1 89.500000    Top5 98.500000    LR 0.000250    Time 0.075407    
2024-02-17 12:28:06,344 - --- validate (epoch=126)-----------
2024-02-17 12:28:06,344 - 10000 samples (100 per mini-batch)
2024-02-17 12:28:09,396 - Epoch: [126][  100/  100]    Loss 1.874391    Top1 58.960000    Top5 85.670000    
2024-02-17 12:28:09,507 - ==> Top1: 58.960    Top5: 85.670    Loss: 1.874

2024-02-17 12:28:09,520 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:28:09,521 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:28:09,587 - 

2024-02-17 12:28:09,587 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:28:17,519 - Epoch: [127][  100/  500]    Overall Loss 0.337505    Objective Loss 0.337505                                        LR 0.000250    Time 0.079258    
2024-02-17 12:28:24,630 - Epoch: [127][  200/  500]    Overall Loss 0.341469    Objective Loss 0.341469                                        LR 0.000250    Time 0.075166    
2024-02-17 12:28:31,864 - Epoch: [127][  300/  500]    Overall Loss 0.342730    Objective Loss 0.342730                                        LR 0.000250    Time 0.074210    
2024-02-17 12:28:39,168 - Epoch: [127][  400/  500]    Overall Loss 0.347414    Objective Loss 0.347414                                        LR 0.000250    Time 0.073907    
2024-02-17 12:28:46,511 - Epoch: [127][  500/  500]    Overall Loss 0.350394    Objective Loss 0.350394    Top1 87.500000    Top5 99.000000    LR 0.000250    Time 0.073802    
2024-02-17 12:28:46,661 - --- validate (epoch=127)-----------
2024-02-17 12:28:46,662 - 10000 samples (100 per mini-batch)
2024-02-17 12:28:49,578 - Epoch: [127][  100/  100]    Loss 1.868177    Top1 59.330000    Top5 85.890000    
2024-02-17 12:28:49,709 - ==> Top1: 59.330    Top5: 85.890    Loss: 1.868

2024-02-17 12:28:49,723 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:28:49,723 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:28:49,789 - 

2024-02-17 12:28:49,790 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:28:57,827 - Epoch: [128][  100/  500]    Overall Loss 0.321977    Objective Loss 0.321977                                        LR 0.000250    Time 0.080314    
2024-02-17 12:29:04,974 - Epoch: [128][  200/  500]    Overall Loss 0.328395    Objective Loss 0.328395                                        LR 0.000250    Time 0.075874    
2024-02-17 12:29:11,718 - Epoch: [128][  300/  500]    Overall Loss 0.335899    Objective Loss 0.335899                                        LR 0.000250    Time 0.073054    
2024-02-17 12:29:18,464 - Epoch: [128][  400/  500]    Overall Loss 0.340811    Objective Loss 0.340811                                        LR 0.000250    Time 0.071648    
2024-02-17 12:29:25,605 - Epoch: [128][  500/  500]    Overall Loss 0.344051    Objective Loss 0.344051    Top1 90.000000    Top5 100.000000    LR 0.000250    Time 0.071592    
2024-02-17 12:29:25,715 - --- validate (epoch=128)-----------
2024-02-17 12:29:25,716 - 10000 samples (100 per mini-batch)
2024-02-17 12:29:28,765 - Epoch: [128][  100/  100]    Loss 1.862338    Top1 59.780000    Top5 86.150000    
2024-02-17 12:29:28,887 - ==> Top1: 59.780    Top5: 86.150    Loss: 1.862

2024-02-17 12:29:28,899 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:29:28,900 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:29:28,971 - 

2024-02-17 12:29:28,971 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:29:36,761 - Epoch: [129][  100/  500]    Overall Loss 0.327128    Objective Loss 0.327128                                        LR 0.000250    Time 0.077843    
2024-02-17 12:29:44,036 - Epoch: [129][  200/  500]    Overall Loss 0.330816    Objective Loss 0.330816                                        LR 0.000250    Time 0.075275    
2024-02-17 12:29:51,332 - Epoch: [129][  300/  500]    Overall Loss 0.334286    Objective Loss 0.334286                                        LR 0.000250    Time 0.074492    
2024-02-17 12:29:58,624 - Epoch: [129][  400/  500]    Overall Loss 0.336386    Objective Loss 0.336386                                        LR 0.000250    Time 0.074086    
2024-02-17 12:30:06,121 - Epoch: [129][  500/  500]    Overall Loss 0.339072    Objective Loss 0.339072    Top1 89.500000    Top5 100.000000    LR 0.000250    Time 0.074255    
2024-02-17 12:30:06,242 - --- validate (epoch=129)-----------
2024-02-17 12:30:06,243 - 10000 samples (100 per mini-batch)
2024-02-17 12:30:09,339 - Epoch: [129][  100/  100]    Loss 1.913295    Top1 59.320000    Top5 85.110000    
2024-02-17 12:30:09,454 - ==> Top1: 59.320    Top5: 85.110    Loss: 1.913

2024-02-17 12:30:09,465 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:30:09,465 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:30:09,528 - 

2024-02-17 12:30:09,528 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:30:17,644 - Epoch: [130][  100/  500]    Overall Loss 0.334636    Objective Loss 0.334636                                        LR 0.000250    Time 0.081105    
2024-02-17 12:30:24,952 - Epoch: [130][  200/  500]    Overall Loss 0.330480    Objective Loss 0.330480                                        LR 0.000250    Time 0.077072    
2024-02-17 12:30:32,268 - Epoch: [130][  300/  500]    Overall Loss 0.327833    Objective Loss 0.327833                                        LR 0.000250    Time 0.075751    
2024-02-17 12:30:39,643 - Epoch: [130][  400/  500]    Overall Loss 0.331335    Objective Loss 0.331335                                        LR 0.000250    Time 0.075242    
2024-02-17 12:30:47,066 - Epoch: [130][  500/  500]    Overall Loss 0.335437    Objective Loss 0.335437    Top1 90.000000    Top5 98.500000    LR 0.000250    Time 0.075030    
2024-02-17 12:30:47,172 - --- validate (epoch=130)-----------
2024-02-17 12:30:47,173 - 10000 samples (100 per mini-batch)
2024-02-17 12:30:50,203 - Epoch: [130][  100/  100]    Loss 1.907367    Top1 59.130000    Top5 85.190000    
2024-02-17 12:30:50,333 - ==> Top1: 59.130    Top5: 85.190    Loss: 1.907

2024-02-17 12:30:50,344 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:30:50,344 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:30:50,407 - 

2024-02-17 12:30:50,408 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:30:58,242 - Epoch: [131][  100/  500]    Overall Loss 0.317695    Objective Loss 0.317695                                        LR 0.000250    Time 0.078287    
2024-02-17 12:31:05,573 - Epoch: [131][  200/  500]    Overall Loss 0.322430    Objective Loss 0.322430                                        LR 0.000250    Time 0.075773    
2024-02-17 12:31:12,787 - Epoch: [131][  300/  500]    Overall Loss 0.333403    Objective Loss 0.333403                                        LR 0.000250    Time 0.074552    
2024-02-17 12:31:20,007 - Epoch: [131][  400/  500]    Overall Loss 0.334155    Objective Loss 0.334155                                        LR 0.000250    Time 0.073953    
2024-02-17 12:31:27,287 - Epoch: [131][  500/  500]    Overall Loss 0.337027    Objective Loss 0.337027    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.073714    
2024-02-17 12:31:27,462 - --- validate (epoch=131)-----------
2024-02-17 12:31:27,463 - 10000 samples (100 per mini-batch)
2024-02-17 12:31:30,556 - Epoch: [131][  100/  100]    Loss 1.899934    Top1 59.270000    Top5 85.610000    
2024-02-17 12:31:30,660 - ==> Top1: 59.270    Top5: 85.610    Loss: 1.900

2024-02-17 12:31:30,671 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:31:30,671 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:31:30,734 - 

2024-02-17 12:31:30,735 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:31:38,735 - Epoch: [132][  100/  500]    Overall Loss 0.324536    Objective Loss 0.324536                                        LR 0.000250    Time 0.079946    
2024-02-17 12:31:46,064 - Epoch: [132][  200/  500]    Overall Loss 0.326878    Objective Loss 0.326878                                        LR 0.000250    Time 0.076600    
2024-02-17 12:31:52,901 - Epoch: [132][  300/  500]    Overall Loss 0.329249    Objective Loss 0.329249                                        LR 0.000250    Time 0.073844    
2024-02-17 12:31:59,955 - Epoch: [132][  400/  500]    Overall Loss 0.333414    Objective Loss 0.333414                                        LR 0.000250    Time 0.073010    
2024-02-17 12:32:07,442 - Epoch: [132][  500/  500]    Overall Loss 0.336415    Objective Loss 0.336415    Top1 88.000000    Top5 99.500000    LR 0.000250    Time 0.073374    
2024-02-17 12:32:07,572 - --- validate (epoch=132)-----------
2024-02-17 12:32:07,574 - 10000 samples (100 per mini-batch)
2024-02-17 12:32:10,826 - Epoch: [132][  100/  100]    Loss 1.892687    Top1 59.240000    Top5 85.570000    
2024-02-17 12:32:11,006 - ==> Top1: 59.240    Top5: 85.570    Loss: 1.893

2024-02-17 12:32:11,017 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:32:11,018 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:32:11,081 - 

2024-02-17 12:32:11,081 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:32:18,947 - Epoch: [133][  100/  500]    Overall Loss 0.314647    Objective Loss 0.314647                                        LR 0.000250    Time 0.078602    
2024-02-17 12:32:26,303 - Epoch: [133][  200/  500]    Overall Loss 0.318626    Objective Loss 0.318626                                        LR 0.000250    Time 0.076061    
2024-02-17 12:32:33,546 - Epoch: [133][  300/  500]    Overall Loss 0.325949    Objective Loss 0.325949                                        LR 0.000250    Time 0.074835    
2024-02-17 12:32:40,859 - Epoch: [133][  400/  500]    Overall Loss 0.330286    Objective Loss 0.330286                                        LR 0.000250    Time 0.074400    
2024-02-17 12:32:48,357 - Epoch: [133][  500/  500]    Overall Loss 0.332519    Objective Loss 0.332519    Top1 92.500000    Top5 100.000000    LR 0.000250    Time 0.074508    
2024-02-17 12:32:48,492 - --- validate (epoch=133)-----------
2024-02-17 12:32:48,492 - 10000 samples (100 per mini-batch)
2024-02-17 12:32:51,665 - Epoch: [133][  100/  100]    Loss 1.894338    Top1 59.280000    Top5 85.410000    
2024-02-17 12:32:51,853 - ==> Top1: 59.280    Top5: 85.410    Loss: 1.894

2024-02-17 12:32:51,861 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:32:51,861 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:32:51,919 - 

2024-02-17 12:32:51,919 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:33:00,034 - Epoch: [134][  100/  500]    Overall Loss 0.323956    Objective Loss 0.323956                                        LR 0.000250    Time 0.081085    
2024-02-17 12:33:07,437 - Epoch: [134][  200/  500]    Overall Loss 0.318200    Objective Loss 0.318200                                        LR 0.000250    Time 0.077538    
2024-02-17 12:33:14,833 - Epoch: [134][  300/  500]    Overall Loss 0.323282    Objective Loss 0.323282                                        LR 0.000250    Time 0.076332    
2024-02-17 12:33:22,145 - Epoch: [134][  400/  500]    Overall Loss 0.326481    Objective Loss 0.326481                                        LR 0.000250    Time 0.075517    
2024-02-17 12:33:29,578 - Epoch: [134][  500/  500]    Overall Loss 0.330671    Objective Loss 0.330671    Top1 89.500000    Top5 99.000000    LR 0.000250    Time 0.075271    
2024-02-17 12:33:29,703 - --- validate (epoch=134)-----------
2024-02-17 12:33:29,704 - 10000 samples (100 per mini-batch)
2024-02-17 12:33:32,963 - Epoch: [134][  100/  100]    Loss 1.921497    Top1 59.110000    Top5 85.390000    
2024-02-17 12:33:33,156 - ==> Top1: 59.110    Top5: 85.390    Loss: 1.921

2024-02-17 12:33:33,167 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:33:33,167 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:33:33,242 - 

2024-02-17 12:33:33,242 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:33:41,119 - Epoch: [135][  100/  500]    Overall Loss 0.319096    Objective Loss 0.319096                                        LR 0.000250    Time 0.078708    
2024-02-17 12:33:48,657 - Epoch: [135][  200/  500]    Overall Loss 0.320444    Objective Loss 0.320444                                        LR 0.000250    Time 0.077023    
2024-02-17 12:33:56,044 - Epoch: [135][  300/  500]    Overall Loss 0.323427    Objective Loss 0.323427                                        LR 0.000250    Time 0.075957    
2024-02-17 12:34:03,397 - Epoch: [135][  400/  500]    Overall Loss 0.329200    Objective Loss 0.329200                                        LR 0.000250    Time 0.075340    
2024-02-17 12:34:10,759 - Epoch: [135][  500/  500]    Overall Loss 0.330982    Objective Loss 0.330982    Top1 90.000000    Top5 99.500000    LR 0.000250    Time 0.074987    
2024-02-17 12:34:10,942 - --- validate (epoch=135)-----------
2024-02-17 12:34:10,943 - 10000 samples (100 per mini-batch)
2024-02-17 12:34:14,237 - Epoch: [135][  100/  100]    Loss 1.874001    Top1 59.550000    Top5 85.790000    
2024-02-17 12:34:14,419 - ==> Top1: 59.550    Top5: 85.790    Loss: 1.874

2024-02-17 12:34:14,431 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:34:14,431 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:34:14,492 - 

2024-02-17 12:34:14,493 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:34:22,617 - Epoch: [136][  100/  500]    Overall Loss 0.312774    Objective Loss 0.312774                                        LR 0.000250    Time 0.081184    
2024-02-17 12:34:29,976 - Epoch: [136][  200/  500]    Overall Loss 0.318205    Objective Loss 0.318205                                        LR 0.000250    Time 0.077365    
2024-02-17 12:34:37,255 - Epoch: [136][  300/  500]    Overall Loss 0.322399    Objective Loss 0.322399                                        LR 0.000250    Time 0.075824    
2024-02-17 12:34:44,542 - Epoch: [136][  400/  500]    Overall Loss 0.329251    Objective Loss 0.329251                                        LR 0.000250    Time 0.075075    
2024-02-17 12:34:51,882 - Epoch: [136][  500/  500]    Overall Loss 0.331625    Objective Loss 0.331625    Top1 91.000000    Top5 99.500000    LR 0.000250    Time 0.074731    
2024-02-17 12:34:52,025 - --- validate (epoch=136)-----------
2024-02-17 12:34:52,026 - 10000 samples (100 per mini-batch)
2024-02-17 12:34:55,260 - Epoch: [136][  100/  100]    Loss 1.928612    Top1 58.880000    Top5 85.260000    
2024-02-17 12:34:55,423 - ==> Top1: 58.880    Top5: 85.260    Loss: 1.929

2024-02-17 12:34:55,434 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:34:55,434 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:34:55,501 - 

2024-02-17 12:34:55,501 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:35:03,268 - Epoch: [137][  100/  500]    Overall Loss 0.320526    Objective Loss 0.320526                                        LR 0.000250    Time 0.077608    
2024-02-17 12:35:10,864 - Epoch: [137][  200/  500]    Overall Loss 0.319600    Objective Loss 0.319600                                        LR 0.000250    Time 0.076766    
2024-02-17 12:35:18,213 - Epoch: [137][  300/  500]    Overall Loss 0.321798    Objective Loss 0.321798                                        LR 0.000250    Time 0.075659    
2024-02-17 12:35:25,647 - Epoch: [137][  400/  500]    Overall Loss 0.324250    Objective Loss 0.324250                                        LR 0.000250    Time 0.075318    
2024-02-17 12:35:33,194 - Epoch: [137][  500/  500]    Overall Loss 0.326408    Objective Loss 0.326408    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.075341    
2024-02-17 12:35:33,320 - --- validate (epoch=137)-----------
2024-02-17 12:35:33,321 - 10000 samples (100 per mini-batch)
2024-02-17 12:35:36,488 - Epoch: [137][  100/  100]    Loss 1.924970    Top1 59.600000    Top5 85.320000    
2024-02-17 12:35:36,681 - ==> Top1: 59.600    Top5: 85.320    Loss: 1.925

2024-02-17 12:35:36,687 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:35:36,687 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:35:36,744 - 

2024-02-17 12:35:36,745 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:35:44,766 - Epoch: [138][  100/  500]    Overall Loss 0.312813    Objective Loss 0.312813                                        LR 0.000250    Time 0.080156    
2024-02-17 12:35:52,121 - Epoch: [138][  200/  500]    Overall Loss 0.319293    Objective Loss 0.319293                                        LR 0.000250    Time 0.076831    
2024-02-17 12:35:59,518 - Epoch: [138][  300/  500]    Overall Loss 0.317928    Objective Loss 0.317928                                        LR 0.000250    Time 0.075862    
2024-02-17 12:36:07,030 - Epoch: [138][  400/  500]    Overall Loss 0.321298    Objective Loss 0.321298                                        LR 0.000250    Time 0.075666    
2024-02-17 12:36:14,455 - Epoch: [138][  500/  500]    Overall Loss 0.325568    Objective Loss 0.325568    Top1 89.500000    Top5 99.500000    LR 0.000250    Time 0.075374    
2024-02-17 12:36:14,577 - --- validate (epoch=138)-----------
2024-02-17 12:36:14,578 - 10000 samples (100 per mini-batch)
2024-02-17 12:36:17,788 - Epoch: [138][  100/  100]    Loss 1.897192    Top1 59.600000    Top5 85.370000    
2024-02-17 12:36:17,910 - ==> Top1: 59.600    Top5: 85.370    Loss: 1.897

2024-02-17 12:36:17,924 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:36:17,924 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:36:17,987 - 

2024-02-17 12:36:17,988 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:36:25,763 - Epoch: [139][  100/  500]    Overall Loss 0.313691    Objective Loss 0.313691                                        LR 0.000250    Time 0.077697    
2024-02-17 12:36:33,200 - Epoch: [139][  200/  500]    Overall Loss 0.316112    Objective Loss 0.316112                                        LR 0.000250    Time 0.076011    
2024-02-17 12:36:40,447 - Epoch: [139][  300/  500]    Overall Loss 0.321306    Objective Loss 0.321306                                        LR 0.000250    Time 0.074818    
2024-02-17 12:36:47,799 - Epoch: [139][  400/  500]    Overall Loss 0.322199    Objective Loss 0.322199                                        LR 0.000250    Time 0.074483    
2024-02-17 12:36:55,170 - Epoch: [139][  500/  500]    Overall Loss 0.323036    Objective Loss 0.323036    Top1 88.500000    Top5 99.000000    LR 0.000250    Time 0.074320    
2024-02-17 12:36:55,339 - --- validate (epoch=139)-----------
2024-02-17 12:36:55,340 - 10000 samples (100 per mini-batch)
2024-02-17 12:36:58,518 - Epoch: [139][  100/  100]    Loss 1.915504    Top1 59.400000    Top5 85.500000    
2024-02-17 12:36:58,682 - ==> Top1: 59.400    Top5: 85.500    Loss: 1.916

2024-02-17 12:36:58,694 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:36:58,694 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:36:58,757 - 

2024-02-17 12:36:58,757 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:37:06,903 - Epoch: [140][  100/  500]    Overall Loss 0.308380    Objective Loss 0.308380                                        LR 0.000250    Time 0.081404    
2024-02-17 12:37:14,280 - Epoch: [140][  200/  500]    Overall Loss 0.316878    Objective Loss 0.316878                                        LR 0.000250    Time 0.077563    
2024-02-17 12:37:21,461 - Epoch: [140][  300/  500]    Overall Loss 0.317922    Objective Loss 0.317922                                        LR 0.000250    Time 0.075634    
2024-02-17 12:37:28,423 - Epoch: [140][  400/  500]    Overall Loss 0.319950    Objective Loss 0.319950                                        LR 0.000250    Time 0.074122    
2024-02-17 12:37:35,617 - Epoch: [140][  500/  500]    Overall Loss 0.322267    Objective Loss 0.322267    Top1 92.000000    Top5 99.500000    LR 0.000250    Time 0.073677    
2024-02-17 12:37:35,800 - --- validate (epoch=140)-----------
2024-02-17 12:37:35,801 - 10000 samples (100 per mini-batch)
2024-02-17 12:37:38,780 - Epoch: [140][  100/  100]    Loss 1.888656    Top1 59.530000    Top5 85.440000    
2024-02-17 12:37:38,896 - ==> Top1: 59.530    Top5: 85.440    Loss: 1.889

2024-02-17 12:37:38,905 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:37:38,906 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:37:38,972 - 

2024-02-17 12:37:38,973 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:37:46,689 - Epoch: [141][  100/  500]    Overall Loss 0.303841    Objective Loss 0.303841                                        LR 0.000250    Time 0.077094    
2024-02-17 12:37:54,029 - Epoch: [141][  200/  500]    Overall Loss 0.305617    Objective Loss 0.305617                                        LR 0.000250    Time 0.075224    
2024-02-17 12:38:01,312 - Epoch: [141][  300/  500]    Overall Loss 0.307391    Objective Loss 0.307391                                        LR 0.000250    Time 0.074413    
2024-02-17 12:38:08,509 - Epoch: [141][  400/  500]    Overall Loss 0.311601    Objective Loss 0.311601                                        LR 0.000250    Time 0.073793    
2024-02-17 12:38:15,859 - Epoch: [141][  500/  500]    Overall Loss 0.314979    Objective Loss 0.314979    Top1 92.000000    Top5 99.500000    LR 0.000250    Time 0.073725    
2024-02-17 12:38:16,010 - --- validate (epoch=141)-----------
2024-02-17 12:38:16,011 - 10000 samples (100 per mini-batch)
2024-02-17 12:38:18,958 - Epoch: [141][  100/  100]    Loss 1.918699    Top1 59.460000    Top5 85.740000    
2024-02-17 12:38:19,108 - ==> Top1: 59.460    Top5: 85.740    Loss: 1.919

2024-02-17 12:38:19,119 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:38:19,120 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:38:19,208 - 

2024-02-17 12:38:19,208 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:38:27,398 - Epoch: [142][  100/  500]    Overall Loss 0.301498    Objective Loss 0.301498                                        LR 0.000250    Time 0.081833    
2024-02-17 12:38:34,769 - Epoch: [142][  200/  500]    Overall Loss 0.307584    Objective Loss 0.307584                                        LR 0.000250    Time 0.077752    
2024-02-17 12:38:42,159 - Epoch: [142][  300/  500]    Overall Loss 0.312257    Objective Loss 0.312257                                        LR 0.000250    Time 0.076454    
2024-02-17 12:38:49,524 - Epoch: [142][  400/  500]    Overall Loss 0.315166    Objective Loss 0.315166                                        LR 0.000250    Time 0.075741    
2024-02-17 12:38:56,904 - Epoch: [142][  500/  500]    Overall Loss 0.318074    Objective Loss 0.318074    Top1 90.000000    Top5 100.000000    LR 0.000250    Time 0.075345    
2024-02-17 12:38:57,067 - --- validate (epoch=142)-----------
2024-02-17 12:38:57,068 - 10000 samples (100 per mini-batch)
2024-02-17 12:39:00,167 - Epoch: [142][  100/  100]    Loss 1.891356    Top1 59.630000    Top5 85.490000    
2024-02-17 12:39:00,272 - ==> Top1: 59.630    Top5: 85.490    Loss: 1.891

2024-02-17 12:39:00,284 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:39:00,285 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:39:00,351 - 

2024-02-17 12:39:00,352 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:39:08,075 - Epoch: [143][  100/  500]    Overall Loss 0.305017    Objective Loss 0.305017                                        LR 0.000250    Time 0.077173    
2024-02-17 12:39:15,223 - Epoch: [143][  200/  500]    Overall Loss 0.305078    Objective Loss 0.305078                                        LR 0.000250    Time 0.074309    
2024-02-17 12:39:22,581 - Epoch: [143][  300/  500]    Overall Loss 0.305630    Objective Loss 0.305630                                        LR 0.000250    Time 0.074054    
2024-02-17 12:39:29,837 - Epoch: [143][  400/  500]    Overall Loss 0.308593    Objective Loss 0.308593                                        LR 0.000250    Time 0.073671    
2024-02-17 12:39:37,266 - Epoch: [143][  500/  500]    Overall Loss 0.310301    Objective Loss 0.310301    Top1 92.000000    Top5 99.500000    LR 0.000250    Time 0.073785    
2024-02-17 12:39:37,441 - --- validate (epoch=143)-----------
2024-02-17 12:39:37,441 - 10000 samples (100 per mini-batch)
2024-02-17 12:39:40,419 - Epoch: [143][  100/  100]    Loss 1.907204    Top1 60.080000    Top5 85.530000    
2024-02-17 12:39:40,581 - ==> Top1: 60.080    Top5: 85.530    Loss: 1.907

2024-02-17 12:39:40,593 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:39:40,593 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:39:40,655 - 

2024-02-17 12:39:40,655 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:39:48,599 - Epoch: [144][  100/  500]    Overall Loss 0.296074    Objective Loss 0.296074                                        LR 0.000250    Time 0.079384    
2024-02-17 12:39:55,907 - Epoch: [144][  200/  500]    Overall Loss 0.292306    Objective Loss 0.292306                                        LR 0.000250    Time 0.076211    
2024-02-17 12:40:03,209 - Epoch: [144][  300/  500]    Overall Loss 0.299635    Objective Loss 0.299635                                        LR 0.000250    Time 0.075134    
2024-02-17 12:40:10,560 - Epoch: [144][  400/  500]    Overall Loss 0.302514    Objective Loss 0.302514                                        LR 0.000250    Time 0.074716    
2024-02-17 12:40:17,866 - Epoch: [144][  500/  500]    Overall Loss 0.306938    Objective Loss 0.306938    Top1 91.000000    Top5 100.000000    LR 0.000250    Time 0.074378    
2024-02-17 12:40:17,980 - --- validate (epoch=144)-----------
2024-02-17 12:40:17,981 - 10000 samples (100 per mini-batch)
2024-02-17 12:40:20,953 - Epoch: [144][  100/  100]    Loss 1.907192    Top1 59.280000    Top5 85.520000    
2024-02-17 12:40:21,101 - ==> Top1: 59.280    Top5: 85.520    Loss: 1.907

2024-02-17 12:40:21,113 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:40:21,113 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:40:21,176 - 

2024-02-17 12:40:21,177 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:40:28,941 - Epoch: [145][  100/  500]    Overall Loss 0.282330    Objective Loss 0.282330                                        LR 0.000250    Time 0.077589    
2024-02-17 12:40:36,443 - Epoch: [145][  200/  500]    Overall Loss 0.292444    Objective Loss 0.292444                                        LR 0.000250    Time 0.076286    
2024-02-17 12:40:43,774 - Epoch: [145][  300/  500]    Overall Loss 0.299170    Objective Loss 0.299170                                        LR 0.000250    Time 0.075281    
2024-02-17 12:40:51,054 - Epoch: [145][  400/  500]    Overall Loss 0.304370    Objective Loss 0.304370                                        LR 0.000250    Time 0.074650    
2024-02-17 12:40:58,300 - Epoch: [145][  500/  500]    Overall Loss 0.308219    Objective Loss 0.308219    Top1 92.500000    Top5 98.500000    LR 0.000250    Time 0.074203    
2024-02-17 12:40:58,428 - --- validate (epoch=145)-----------
2024-02-17 12:40:58,428 - 10000 samples (100 per mini-batch)
2024-02-17 12:41:01,503 - Epoch: [145][  100/  100]    Loss 1.923322    Top1 59.140000    Top5 85.370000    
2024-02-17 12:41:01,670 - ==> Top1: 59.140    Top5: 85.370    Loss: 1.923

2024-02-17 12:41:01,677 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:41:01,677 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:41:01,740 - 

2024-02-17 12:41:01,741 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:41:09,506 - Epoch: [146][  100/  500]    Overall Loss 0.295699    Objective Loss 0.295699                                        LR 0.000250    Time 0.077596    
2024-02-17 12:41:16,940 - Epoch: [146][  200/  500]    Overall Loss 0.296993    Objective Loss 0.296993                                        LR 0.000250    Time 0.075945    
2024-02-17 12:41:24,250 - Epoch: [146][  300/  500]    Overall Loss 0.299033    Objective Loss 0.299033                                        LR 0.000250    Time 0.074982    
2024-02-17 12:41:31,508 - Epoch: [146][  400/  500]    Overall Loss 0.301379    Objective Loss 0.301379                                        LR 0.000250    Time 0.074371    
2024-02-17 12:41:38,867 - Epoch: [146][  500/  500]    Overall Loss 0.305143    Objective Loss 0.305143    Top1 88.500000    Top5 99.500000    LR 0.000250    Time 0.074206    
2024-02-17 12:41:38,988 - --- validate (epoch=146)-----------
2024-02-17 12:41:38,989 - 10000 samples (100 per mini-batch)
2024-02-17 12:41:42,156 - Epoch: [146][  100/  100]    Loss 1.971627    Top1 58.810000    Top5 85.000000    
2024-02-17 12:41:42,309 - ==> Top1: 58.810    Top5: 85.000    Loss: 1.972

2024-02-17 12:41:42,559 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:41:42,559 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:41:42,613 - 

2024-02-17 12:41:42,613 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:41:50,397 - Epoch: [147][  100/  500]    Overall Loss 0.309138    Objective Loss 0.309138                                        LR 0.000250    Time 0.077778    
2024-02-17 12:41:57,742 - Epoch: [147][  200/  500]    Overall Loss 0.306801    Objective Loss 0.306801                                        LR 0.000250    Time 0.075584    
2024-02-17 12:42:05,054 - Epoch: [147][  300/  500]    Overall Loss 0.305706    Objective Loss 0.305706                                        LR 0.000250    Time 0.074750    
2024-02-17 12:42:12,378 - Epoch: [147][  400/  500]    Overall Loss 0.307134    Objective Loss 0.307134                                        LR 0.000250    Time 0.074362    
2024-02-17 12:42:19,724 - Epoch: [147][  500/  500]    Overall Loss 0.307280    Objective Loss 0.307280    Top1 94.000000    Top5 99.500000    LR 0.000250    Time 0.074173    
2024-02-17 12:42:19,895 - --- validate (epoch=147)-----------
2024-02-17 12:42:19,896 - 10000 samples (100 per mini-batch)
2024-02-17 12:42:22,995 - Epoch: [147][  100/  100]    Loss 1.915154    Top1 59.680000    Top5 85.160000    
2024-02-17 12:42:23,099 - ==> Top1: 59.680    Top5: 85.160    Loss: 1.915

2024-02-17 12:42:23,112 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:42:23,112 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:42:23,176 - 

2024-02-17 12:42:23,177 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:42:31,080 - Epoch: [148][  100/  500]    Overall Loss 0.302657    Objective Loss 0.302657                                        LR 0.000250    Time 0.078972    
2024-02-17 12:42:38,464 - Epoch: [148][  200/  500]    Overall Loss 0.302141    Objective Loss 0.302141                                        LR 0.000250    Time 0.076386    
2024-02-17 12:42:45,768 - Epoch: [148][  300/  500]    Overall Loss 0.303867    Objective Loss 0.303867                                        LR 0.000250    Time 0.075256    
2024-02-17 12:42:52,693 - Epoch: [148][  400/  500]    Overall Loss 0.304256    Objective Loss 0.304256                                        LR 0.000250    Time 0.073746    
2024-02-17 12:42:59,490 - Epoch: [148][  500/  500]    Overall Loss 0.306868    Objective Loss 0.306868    Top1 88.000000    Top5 100.000000    LR 0.000250    Time 0.072583    
2024-02-17 12:42:59,663 - --- validate (epoch=148)-----------
2024-02-17 12:42:59,663 - 10000 samples (100 per mini-batch)
2024-02-17 12:43:02,997 - Epoch: [148][  100/  100]    Loss 1.888129    Top1 60.240000    Top5 85.950000    
2024-02-17 12:43:03,118 - ==> Top1: 60.240    Top5: 85.950    Loss: 1.888

2024-02-17 12:43:03,131 - ==> Best [Top1: 60.240   Top5: 85.950   Sparsity:0.00   Params: 753952 on epoch: 148]
2024-02-17 12:43:03,131 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:43:03,207 - 

2024-02-17 12:43:03,207 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:43:10,903 - Epoch: [149][  100/  500]    Overall Loss 0.288324    Objective Loss 0.288324                                        LR 0.000250    Time 0.076896    
2024-02-17 12:43:18,258 - Epoch: [149][  200/  500]    Overall Loss 0.292148    Objective Loss 0.292148                                        LR 0.000250    Time 0.075205    
2024-02-17 12:43:25,575 - Epoch: [149][  300/  500]    Overall Loss 0.299755    Objective Loss 0.299755                                        LR 0.000250    Time 0.074512    
2024-02-17 12:43:32,845 - Epoch: [149][  400/  500]    Overall Loss 0.303344    Objective Loss 0.303344                                        LR 0.000250    Time 0.074048    
2024-02-17 12:43:40,181 - Epoch: [149][  500/  500]    Overall Loss 0.304277    Objective Loss 0.304277    Top1 90.000000    Top5 99.000000    LR 0.000250    Time 0.073902    
2024-02-17 12:43:40,335 - --- validate (epoch=149)-----------
2024-02-17 12:43:40,336 - 10000 samples (100 per mini-batch)
2024-02-17 12:43:43,460 - Epoch: [149][  100/  100]    Loss 1.935919    Top1 59.500000    Top5 85.440000    
2024-02-17 12:43:43,641 - ==> Top1: 59.500    Top5: 85.440    Loss: 1.936

2024-02-17 12:43:43,649 - ==> Best [Top1: 60.240   Top5: 85.950   Sparsity:0.00   Params: 753952 on epoch: 148]
2024-02-17 12:43:43,650 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:43:43,726 - 

2024-02-17 12:43:43,727 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:43:51,908 - Epoch: [150][  100/  500]    Overall Loss 0.273165    Objective Loss 0.273165                                        LR 0.000125    Time 0.081759    
2024-02-17 12:43:59,103 - Epoch: [150][  200/  500]    Overall Loss 0.268597    Objective Loss 0.268597                                        LR 0.000125    Time 0.076833    
2024-02-17 12:44:06,243 - Epoch: [150][  300/  500]    Overall Loss 0.272199    Objective Loss 0.272199                                        LR 0.000125    Time 0.075009    
2024-02-17 12:44:13,522 - Epoch: [150][  400/  500]    Overall Loss 0.273386    Objective Loss 0.273386                                        LR 0.000125    Time 0.074443    
2024-02-17 12:44:20,795 - Epoch: [150][  500/  500]    Overall Loss 0.273813    Objective Loss 0.273813    Top1 90.500000    Top5 99.500000    LR 0.000125    Time 0.074094    
2024-02-17 12:44:20,934 - --- validate (epoch=150)-----------
2024-02-17 12:44:20,935 - 10000 samples (100 per mini-batch)
2024-02-17 12:44:24,237 - Epoch: [150][  100/  100]    Loss 1.883507    Top1 60.170000    Top5 85.790000    
2024-02-17 12:44:24,361 - ==> Top1: 60.170    Top5: 85.790    Loss: 1.884

2024-02-17 12:44:24,371 - ==> Best [Top1: 60.240   Top5: 85.950   Sparsity:0.00   Params: 753952 on epoch: 148]
2024-02-17 12:44:24,371 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:44:24,457 - 

2024-02-17 12:44:24,458 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:44:32,440 - Epoch: [151][  100/  500]    Overall Loss 0.265116    Objective Loss 0.265116                                        LR 0.000125    Time 0.079747    
2024-02-17 12:44:39,767 - Epoch: [151][  200/  500]    Overall Loss 0.262215    Objective Loss 0.262215                                        LR 0.000125    Time 0.076487    
2024-02-17 12:44:47,112 - Epoch: [151][  300/  500]    Overall Loss 0.262135    Objective Loss 0.262135                                        LR 0.000125    Time 0.075458    
2024-02-17 12:44:54,246 - Epoch: [151][  400/  500]    Overall Loss 0.263139    Objective Loss 0.263139                                        LR 0.000125    Time 0.074420    
2024-02-17 12:45:01,641 - Epoch: [151][  500/  500]    Overall Loss 0.265369    Objective Loss 0.265369    Top1 94.500000    Top5 100.000000    LR 0.000125    Time 0.074316    
2024-02-17 12:45:01,795 - --- validate (epoch=151)-----------
2024-02-17 12:45:01,796 - 10000 samples (100 per mini-batch)
2024-02-17 12:45:05,021 - Epoch: [151][  100/  100]    Loss 1.877078    Top1 60.580000    Top5 85.860000    
2024-02-17 12:45:05,159 - ==> Top1: 60.580    Top5: 85.860    Loss: 1.877

2024-02-17 12:45:05,165 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:45:05,165 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:45:05,241 - 

2024-02-17 12:45:05,241 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:45:13,402 - Epoch: [152][  100/  500]    Overall Loss 0.258555    Objective Loss 0.258555                                        LR 0.000125    Time 0.081535    
2024-02-17 12:45:20,233 - Epoch: [152][  200/  500]    Overall Loss 0.261813    Objective Loss 0.261813                                        LR 0.000125    Time 0.074901    
2024-02-17 12:45:27,168 - Epoch: [152][  300/  500]    Overall Loss 0.261460    Objective Loss 0.261460                                        LR 0.000125    Time 0.073041    
2024-02-17 12:45:34,485 - Epoch: [152][  400/  500]    Overall Loss 0.264246    Objective Loss 0.264246                                        LR 0.000125    Time 0.073061    
2024-02-17 12:45:41,790 - Epoch: [152][  500/  500]    Overall Loss 0.264172    Objective Loss 0.264172    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.073051    
2024-02-17 12:45:41,898 - --- validate (epoch=152)-----------
2024-02-17 12:45:41,899 - 10000 samples (100 per mini-batch)
2024-02-17 12:45:45,054 - Epoch: [152][  100/  100]    Loss 1.897309    Top1 60.000000    Top5 86.000000    
2024-02-17 12:45:45,189 - ==> Top1: 60.000    Top5: 86.000    Loss: 1.897

2024-02-17 12:45:45,199 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:45:45,199 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:45:45,277 - 

2024-02-17 12:45:45,278 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:45:53,036 - Epoch: [153][  100/  500]    Overall Loss 0.254941    Objective Loss 0.254941                                        LR 0.000125    Time 0.077508    
2024-02-17 12:46:00,271 - Epoch: [153][  200/  500]    Overall Loss 0.253205    Objective Loss 0.253205                                        LR 0.000125    Time 0.074909    
2024-02-17 12:46:07,643 - Epoch: [153][  300/  500]    Overall Loss 0.257455    Objective Loss 0.257455                                        LR 0.000125    Time 0.074497    
2024-02-17 12:46:14,976 - Epoch: [153][  400/  500]    Overall Loss 0.258693    Objective Loss 0.258693                                        LR 0.000125    Time 0.074194    
2024-02-17 12:46:22,141 - Epoch: [153][  500/  500]    Overall Loss 0.261254    Objective Loss 0.261254    Top1 95.500000    Top5 100.000000    LR 0.000125    Time 0.073678    
2024-02-17 12:46:22,261 - --- validate (epoch=153)-----------
2024-02-17 12:46:22,262 - 10000 samples (100 per mini-batch)
2024-02-17 12:46:25,427 - Epoch: [153][  100/  100]    Loss 1.893290    Top1 60.220000    Top5 85.750000    
2024-02-17 12:46:25,553 - ==> Top1: 60.220    Top5: 85.750    Loss: 1.893

2024-02-17 12:46:25,563 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:46:25,563 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:46:25,627 - 

2024-02-17 12:46:25,627 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:46:33,385 - Epoch: [154][  100/  500]    Overall Loss 0.248995    Objective Loss 0.248995                                        LR 0.000125    Time 0.077529    
2024-02-17 12:46:40,733 - Epoch: [154][  200/  500]    Overall Loss 0.251812    Objective Loss 0.251812                                        LR 0.000125    Time 0.075478    
2024-02-17 12:46:48,054 - Epoch: [154][  300/  500]    Overall Loss 0.256797    Objective Loss 0.256797                                        LR 0.000125    Time 0.074711    
2024-02-17 12:46:55,307 - Epoch: [154][  400/  500]    Overall Loss 0.259046    Objective Loss 0.259046                                        LR 0.000125    Time 0.074155    
2024-02-17 12:47:02,438 - Epoch: [154][  500/  500]    Overall Loss 0.261252    Objective Loss 0.261252    Top1 89.500000    Top5 100.000000    LR 0.000125    Time 0.073579    
2024-02-17 12:47:02,587 - --- validate (epoch=154)-----------
2024-02-17 12:47:02,587 - 10000 samples (100 per mini-batch)
2024-02-17 12:47:06,065 - Epoch: [154][  100/  100]    Loss 1.909400    Top1 59.950000    Top5 85.850000    
2024-02-17 12:47:06,215 - ==> Top1: 59.950    Top5: 85.850    Loss: 1.909

2024-02-17 12:47:06,227 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:47:06,227 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:47:06,293 - 

2024-02-17 12:47:06,294 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:47:14,170 - Epoch: [155][  100/  500]    Overall Loss 0.246360    Objective Loss 0.246360                                        LR 0.000125    Time 0.078702    
2024-02-17 12:47:21,407 - Epoch: [155][  200/  500]    Overall Loss 0.251740    Objective Loss 0.251740                                        LR 0.000125    Time 0.075516    
2024-02-17 12:47:28,644 - Epoch: [155][  300/  500]    Overall Loss 0.255473    Objective Loss 0.255473                                        LR 0.000125    Time 0.074452    
2024-02-17 12:47:35,948 - Epoch: [155][  400/  500]    Overall Loss 0.254105    Objective Loss 0.254105                                        LR 0.000125    Time 0.074091    
2024-02-17 12:47:43,158 - Epoch: [155][  500/  500]    Overall Loss 0.255617    Objective Loss 0.255617    Top1 95.500000    Top5 100.000000    LR 0.000125    Time 0.073683    
2024-02-17 12:47:43,301 - --- validate (epoch=155)-----------
2024-02-17 12:47:43,302 - 10000 samples (100 per mini-batch)
2024-02-17 12:47:46,238 - Epoch: [155][  100/  100]    Loss 1.907299    Top1 59.790000    Top5 85.910000    
2024-02-17 12:47:46,436 - ==> Top1: 59.790    Top5: 85.910    Loss: 1.907

2024-02-17 12:47:46,447 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:47:46,447 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:47:46,515 - 

2024-02-17 12:47:46,515 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:47:54,632 - Epoch: [156][  100/  500]    Overall Loss 0.252096    Objective Loss 0.252096                                        LR 0.000125    Time 0.081110    
2024-02-17 12:48:01,703 - Epoch: [156][  200/  500]    Overall Loss 0.250345    Objective Loss 0.250345                                        LR 0.000125    Time 0.075889    
2024-02-17 12:48:08,962 - Epoch: [156][  300/  500]    Overall Loss 0.254333    Objective Loss 0.254333                                        LR 0.000125    Time 0.074777    
2024-02-17 12:48:16,200 - Epoch: [156][  400/  500]    Overall Loss 0.256664    Objective Loss 0.256664                                        LR 0.000125    Time 0.074167    
2024-02-17 12:48:22,986 - Epoch: [156][  500/  500]    Overall Loss 0.256761    Objective Loss 0.256761    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.072899    
2024-02-17 12:48:23,107 - --- validate (epoch=156)-----------
2024-02-17 12:48:23,108 - 10000 samples (100 per mini-batch)
2024-02-17 12:48:26,137 - Epoch: [156][  100/  100]    Loss 1.902428    Top1 60.500000    Top5 85.740000    
2024-02-17 12:48:26,236 - ==> Top1: 60.500    Top5: 85.740    Loss: 1.902

2024-02-17 12:48:26,257 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:48:26,257 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:48:26,330 - 

2024-02-17 12:48:26,331 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:48:34,162 - Epoch: [157][  100/  500]    Overall Loss 0.245394    Objective Loss 0.245394                                        LR 0.000125    Time 0.078256    
2024-02-17 12:48:41,507 - Epoch: [157][  200/  500]    Overall Loss 0.251643    Objective Loss 0.251643                                        LR 0.000125    Time 0.075832    
2024-02-17 12:48:48,881 - Epoch: [157][  300/  500]    Overall Loss 0.251384    Objective Loss 0.251384                                        LR 0.000125    Time 0.075120    
2024-02-17 12:48:56,123 - Epoch: [157][  400/  500]    Overall Loss 0.255264    Objective Loss 0.255264                                        LR 0.000125    Time 0.074436    
2024-02-17 12:49:03,390 - Epoch: [157][  500/  500]    Overall Loss 0.256547    Objective Loss 0.256547    Top1 95.500000    Top5 99.500000    LR 0.000125    Time 0.074075    
2024-02-17 12:49:03,551 - --- validate (epoch=157)-----------
2024-02-17 12:49:03,552 - 10000 samples (100 per mini-batch)
2024-02-17 12:49:06,567 - Epoch: [157][  100/  100]    Loss 1.920516    Top1 59.920000    Top5 85.730000    
2024-02-17 12:49:06,673 - ==> Top1: 59.920    Top5: 85.730    Loss: 1.921

2024-02-17 12:49:06,680 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:49:06,680 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:49:06,757 - 

2024-02-17 12:49:06,757 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:49:14,619 - Epoch: [158][  100/  500]    Overall Loss 0.243929    Objective Loss 0.243929                                        LR 0.000125    Time 0.078562    
2024-02-17 12:49:21,855 - Epoch: [158][  200/  500]    Overall Loss 0.251566    Objective Loss 0.251566                                        LR 0.000125    Time 0.075438    
2024-02-17 12:49:29,247 - Epoch: [158][  300/  500]    Overall Loss 0.253808    Objective Loss 0.253808                                        LR 0.000125    Time 0.074920    
2024-02-17 12:49:36,608 - Epoch: [158][  400/  500]    Overall Loss 0.257415    Objective Loss 0.257415                                        LR 0.000125    Time 0.074583    
2024-02-17 12:49:43,694 - Epoch: [158][  500/  500]    Overall Loss 0.258460    Objective Loss 0.258460    Top1 89.500000    Top5 100.000000    LR 0.000125    Time 0.073829    
2024-02-17 12:49:43,870 - --- validate (epoch=158)-----------
2024-02-17 12:49:43,871 - 10000 samples (100 per mini-batch)
2024-02-17 12:49:46,832 - Epoch: [158][  100/  100]    Loss 1.905086    Top1 60.190000    Top5 85.770000    
2024-02-17 12:49:47,004 - ==> Top1: 60.190    Top5: 85.770    Loss: 1.905

2024-02-17 12:49:47,238 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:49:47,238 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:49:47,292 - 

2024-02-17 12:49:47,293 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:49:55,012 - Epoch: [159][  100/  500]    Overall Loss 0.240422    Objective Loss 0.240422                                        LR 0.000125    Time 0.077140    
2024-02-17 12:50:02,300 - Epoch: [159][  200/  500]    Overall Loss 0.247656    Objective Loss 0.247656                                        LR 0.000125    Time 0.074986    
2024-02-17 12:50:09,614 - Epoch: [159][  300/  500]    Overall Loss 0.253079    Objective Loss 0.253079                                        LR 0.000125    Time 0.074359    
2024-02-17 12:50:16,715 - Epoch: [159][  400/  500]    Overall Loss 0.255299    Objective Loss 0.255299                                        LR 0.000125    Time 0.073513    
2024-02-17 12:50:23,840 - Epoch: [159][  500/  500]    Overall Loss 0.253614    Objective Loss 0.253614    Top1 92.500000    Top5 99.500000    LR 0.000125    Time 0.073054    
2024-02-17 12:50:24,028 - --- validate (epoch=159)-----------
2024-02-17 12:50:24,029 - 10000 samples (100 per mini-batch)
2024-02-17 12:50:27,024 - Epoch: [159][  100/  100]    Loss 1.922087    Top1 59.890000    Top5 85.770000    
2024-02-17 12:50:27,214 - ==> Top1: 59.890    Top5: 85.770    Loss: 1.922

2024-02-17 12:50:27,225 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:50:27,226 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:50:27,289 - 

2024-02-17 12:50:27,289 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:50:35,049 - Epoch: [160][  100/  500]    Overall Loss 0.250435    Objective Loss 0.250435                                        LR 0.000125    Time 0.077545    
2024-02-17 12:50:42,488 - Epoch: [160][  200/  500]    Overall Loss 0.255699    Objective Loss 0.255699                                        LR 0.000125    Time 0.075946    
2024-02-17 12:50:49,831 - Epoch: [160][  300/  500]    Overall Loss 0.255090    Objective Loss 0.255090                                        LR 0.000125    Time 0.075094    
2024-02-17 12:50:57,212 - Epoch: [160][  400/  500]    Overall Loss 0.253042    Objective Loss 0.253042                                        LR 0.000125    Time 0.074760    
2024-02-17 12:51:04,547 - Epoch: [160][  500/  500]    Overall Loss 0.252557    Objective Loss 0.252557    Top1 94.500000    Top5 100.000000    LR 0.000125    Time 0.074471    
2024-02-17 12:51:04,724 - --- validate (epoch=160)-----------
2024-02-17 12:51:04,725 - 10000 samples (100 per mini-batch)
2024-02-17 12:51:07,932 - Epoch: [160][  100/  100]    Loss 1.924850    Top1 60.170000    Top5 85.660000    
2024-02-17 12:51:08,041 - ==> Top1: 60.170    Top5: 85.660    Loss: 1.925

2024-02-17 12:51:08,050 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:51:08,050 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:51:08,119 - 

2024-02-17 12:51:08,119 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:51:15,945 - Epoch: [161][  100/  500]    Overall Loss 0.242642    Objective Loss 0.242642                                        LR 0.000125    Time 0.078199    
2024-02-17 12:51:23,141 - Epoch: [161][  200/  500]    Overall Loss 0.249146    Objective Loss 0.249146                                        LR 0.000125    Time 0.075058    
2024-02-17 12:51:30,273 - Epoch: [161][  300/  500]    Overall Loss 0.249139    Objective Loss 0.249139                                        LR 0.000125    Time 0.073798    
2024-02-17 12:51:37,606 - Epoch: [161][  400/  500]    Overall Loss 0.250134    Objective Loss 0.250134                                        LR 0.000125    Time 0.073671    
2024-02-17 12:51:44,748 - Epoch: [161][  500/  500]    Overall Loss 0.251034    Objective Loss 0.251034    Top1 93.500000    Top5 100.000000    LR 0.000125    Time 0.073213    
2024-02-17 12:51:44,882 - --- validate (epoch=161)-----------
2024-02-17 12:51:44,883 - 10000 samples (100 per mini-batch)
2024-02-17 12:51:47,839 - Epoch: [161][  100/  100]    Loss 1.905843    Top1 60.080000    Top5 85.760000    
2024-02-17 12:51:48,019 - ==> Top1: 60.080    Top5: 85.760    Loss: 1.906

2024-02-17 12:51:48,030 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:51:48,031 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:51:48,093 - 

2024-02-17 12:51:48,093 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:51:56,148 - Epoch: [162][  100/  500]    Overall Loss 0.234019    Objective Loss 0.234019                                        LR 0.000125    Time 0.080498    
2024-02-17 12:52:03,419 - Epoch: [162][  200/  500]    Overall Loss 0.244368    Objective Loss 0.244368                                        LR 0.000125    Time 0.076579    
2024-02-17 12:52:10,724 - Epoch: [162][  300/  500]    Overall Loss 0.245240    Objective Loss 0.245240                                        LR 0.000125    Time 0.075389    
2024-02-17 12:52:18,027 - Epoch: [162][  400/  500]    Overall Loss 0.245359    Objective Loss 0.245359                                        LR 0.000125    Time 0.074789    
2024-02-17 12:52:25,308 - Epoch: [162][  500/  500]    Overall Loss 0.247341    Objective Loss 0.247341    Top1 91.000000    Top5 99.500000    LR 0.000125    Time 0.074385    
2024-02-17 12:52:25,462 - --- validate (epoch=162)-----------
2024-02-17 12:52:25,463 - 10000 samples (100 per mini-batch)
2024-02-17 12:52:28,467 - Epoch: [162][  100/  100]    Loss 1.919250    Top1 60.410000    Top5 85.600000    
2024-02-17 12:52:28,562 - ==> Top1: 60.410    Top5: 85.600    Loss: 1.919

2024-02-17 12:52:28,574 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:52:28,575 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:52:28,638 - 

2024-02-17 12:52:28,638 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:52:36,492 - Epoch: [163][  100/  500]    Overall Loss 0.238383    Objective Loss 0.238383                                        LR 0.000125    Time 0.078486    
2024-02-17 12:52:43,775 - Epoch: [163][  200/  500]    Overall Loss 0.246432    Objective Loss 0.246432                                        LR 0.000125    Time 0.075631    
2024-02-17 12:52:51,065 - Epoch: [163][  300/  500]    Overall Loss 0.249270    Objective Loss 0.249270                                        LR 0.000125    Time 0.074710    
2024-02-17 12:52:58,100 - Epoch: [163][  400/  500]    Overall Loss 0.248447    Objective Loss 0.248447                                        LR 0.000125    Time 0.073612    
2024-02-17 12:53:05,170 - Epoch: [163][  500/  500]    Overall Loss 0.248890    Objective Loss 0.248890    Top1 93.500000    Top5 99.500000    LR 0.000125    Time 0.073022    
2024-02-17 12:53:05,281 - --- validate (epoch=163)-----------
2024-02-17 12:53:05,281 - 10000 samples (100 per mini-batch)
2024-02-17 12:53:08,194 - Epoch: [163][  100/  100]    Loss 1.931699    Top1 59.970000    Top5 85.960000    
2024-02-17 12:53:08,305 - ==> Top1: 59.970    Top5: 85.960    Loss: 1.932

2024-02-17 12:53:08,313 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:53:08,313 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:53:08,376 - 

2024-02-17 12:53:08,376 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:53:16,495 - Epoch: [164][  100/  500]    Overall Loss 0.241553    Objective Loss 0.241553                                        LR 0.000125    Time 0.081140    
2024-02-17 12:53:23,818 - Epoch: [164][  200/  500]    Overall Loss 0.247464    Objective Loss 0.247464                                        LR 0.000125    Time 0.077163    
2024-02-17 12:53:31,131 - Epoch: [164][  300/  500]    Overall Loss 0.247544    Objective Loss 0.247544                                        LR 0.000125    Time 0.075804    
2024-02-17 12:53:38,420 - Epoch: [164][  400/  500]    Overall Loss 0.249057    Objective Loss 0.249057                                        LR 0.000125    Time 0.075063    
2024-02-17 12:53:45,734 - Epoch: [164][  500/  500]    Overall Loss 0.249866    Objective Loss 0.249866    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.074670    
2024-02-17 12:53:45,896 - --- validate (epoch=164)-----------
2024-02-17 12:53:45,897 - 10000 samples (100 per mini-batch)
2024-02-17 12:53:48,794 - Epoch: [164][  100/  100]    Loss 1.929833    Top1 59.980000    Top5 85.800000    
2024-02-17 12:53:48,898 - ==> Top1: 59.980    Top5: 85.800    Loss: 1.930

2024-02-17 12:53:48,909 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:53:48,909 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:53:48,971 - 

2024-02-17 12:53:48,972 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:53:56,801 - Epoch: [165][  100/  500]    Overall Loss 0.238838    Objective Loss 0.238838                                        LR 0.000125    Time 0.078228    
2024-02-17 12:54:04,088 - Epoch: [165][  200/  500]    Overall Loss 0.240462    Objective Loss 0.240462                                        LR 0.000125    Time 0.075529    
2024-02-17 12:54:11,383 - Epoch: [165][  300/  500]    Overall Loss 0.243240    Objective Loss 0.243240                                        LR 0.000125    Time 0.074653    
2024-02-17 12:54:18,439 - Epoch: [165][  400/  500]    Overall Loss 0.244188    Objective Loss 0.244188                                        LR 0.000125    Time 0.073621    
2024-02-17 12:54:25,694 - Epoch: [165][  500/  500]    Overall Loss 0.244595    Objective Loss 0.244595    Top1 92.500000    Top5 100.000000    LR 0.000125    Time 0.073400    
2024-02-17 12:54:25,824 - --- validate (epoch=165)-----------
2024-02-17 12:54:25,825 - 10000 samples (100 per mini-batch)
2024-02-17 12:54:28,753 - Epoch: [165][  100/  100]    Loss 1.920215    Top1 60.150000    Top5 85.790000    
2024-02-17 12:54:28,886 - ==> Top1: 60.150    Top5: 85.790    Loss: 1.920

2024-02-17 12:54:28,897 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:54:28,898 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:54:28,960 - 

2024-02-17 12:54:28,961 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:54:37,100 - Epoch: [166][  100/  500]    Overall Loss 0.245896    Objective Loss 0.245896                                        LR 0.000125    Time 0.081334    
2024-02-17 12:54:44,342 - Epoch: [166][  200/  500]    Overall Loss 0.247981    Objective Loss 0.247981                                        LR 0.000125    Time 0.076857    
2024-02-17 12:54:51,598 - Epoch: [166][  300/  500]    Overall Loss 0.246354    Objective Loss 0.246354                                        LR 0.000125    Time 0.075410    
2024-02-17 12:54:58,907 - Epoch: [166][  400/  500]    Overall Loss 0.246137    Objective Loss 0.246137                                        LR 0.000125    Time 0.074818    
2024-02-17 12:55:06,231 - Epoch: [166][  500/  500]    Overall Loss 0.246829    Objective Loss 0.246829    Top1 91.000000    Top5 100.000000    LR 0.000125    Time 0.074494    
2024-02-17 12:55:06,407 - --- validate (epoch=166)-----------
2024-02-17 12:55:06,407 - 10000 samples (100 per mini-batch)
2024-02-17 12:55:09,626 - Epoch: [166][  100/  100]    Loss 1.935571    Top1 59.970000    Top5 85.610000    
2024-02-17 12:55:09,774 - ==> Top1: 59.970    Top5: 85.610    Loss: 1.936

2024-02-17 12:55:09,785 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:55:09,786 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:55:09,861 - 

2024-02-17 12:55:09,862 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:55:17,639 - Epoch: [167][  100/  500]    Overall Loss 0.236638    Objective Loss 0.236638                                        LR 0.000125    Time 0.077700    
2024-02-17 12:55:24,992 - Epoch: [167][  200/  500]    Overall Loss 0.237886    Objective Loss 0.237886                                        LR 0.000125    Time 0.075591    
2024-02-17 12:55:32,329 - Epoch: [167][  300/  500]    Overall Loss 0.240551    Objective Loss 0.240551                                        LR 0.000125    Time 0.074837    
2024-02-17 12:55:39,573 - Epoch: [167][  400/  500]    Overall Loss 0.241208    Objective Loss 0.241208                                        LR 0.000125    Time 0.074227    
2024-02-17 12:55:46,429 - Epoch: [167][  500/  500]    Overall Loss 0.244225    Objective Loss 0.244225    Top1 88.500000    Top5 100.000000    LR 0.000125    Time 0.073087    
2024-02-17 12:55:46,597 - --- validate (epoch=167)-----------
2024-02-17 12:55:46,597 - 10000 samples (100 per mini-batch)
2024-02-17 12:55:49,619 - Epoch: [167][  100/  100]    Loss 1.930874    Top1 60.170000    Top5 85.860000    
2024-02-17 12:55:49,803 - ==> Top1: 60.170    Top5: 85.860    Loss: 1.931

2024-02-17 12:55:49,817 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:55:49,817 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:55:49,881 - 

2024-02-17 12:55:49,881 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:55:57,998 - Epoch: [168][  100/  500]    Overall Loss 0.232428    Objective Loss 0.232428                                        LR 0.000125    Time 0.081113    
2024-02-17 12:56:05,239 - Epoch: [168][  200/  500]    Overall Loss 0.237562    Objective Loss 0.237562                                        LR 0.000125    Time 0.076738    
2024-02-17 12:56:12,546 - Epoch: [168][  300/  500]    Overall Loss 0.240998    Objective Loss 0.240998                                        LR 0.000125    Time 0.075500    
2024-02-17 12:56:19,834 - Epoch: [168][  400/  500]    Overall Loss 0.243139    Objective Loss 0.243139                                        LR 0.000125    Time 0.074835    
2024-02-17 12:56:27,095 - Epoch: [168][  500/  500]    Overall Loss 0.242613    Objective Loss 0.242613    Top1 94.000000    Top5 99.500000    LR 0.000125    Time 0.074380    
2024-02-17 12:56:27,217 - --- validate (epoch=168)-----------
2024-02-17 12:56:27,218 - 10000 samples (100 per mini-batch)
2024-02-17 12:56:30,161 - Epoch: [168][  100/  100]    Loss 1.940044    Top1 60.110000    Top5 85.750000    
2024-02-17 12:56:30,278 - ==> Top1: 60.110    Top5: 85.750    Loss: 1.940

2024-02-17 12:56:30,289 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:56:30,290 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:56:30,362 - 

2024-02-17 12:56:30,362 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:56:38,109 - Epoch: [169][  100/  500]    Overall Loss 0.233130    Objective Loss 0.233130                                        LR 0.000125    Time 0.077410    
2024-02-17 12:56:45,308 - Epoch: [169][  200/  500]    Overall Loss 0.239286    Objective Loss 0.239286                                        LR 0.000125    Time 0.074679    
2024-02-17 12:56:52,621 - Epoch: [169][  300/  500]    Overall Loss 0.239623    Objective Loss 0.239623                                        LR 0.000125    Time 0.074148    
2024-02-17 12:57:00,018 - Epoch: [169][  400/  500]    Overall Loss 0.240834    Objective Loss 0.240834                                        LR 0.000125    Time 0.074094    
2024-02-17 12:57:07,501 - Epoch: [169][  500/  500]    Overall Loss 0.241750    Objective Loss 0.241750    Top1 90.500000    Top5 100.000000    LR 0.000125    Time 0.074234    
2024-02-17 12:57:07,696 - --- validate (epoch=169)-----------
2024-02-17 12:57:07,697 - 10000 samples (100 per mini-batch)
2024-02-17 12:57:10,657 - Epoch: [169][  100/  100]    Loss 1.938254    Top1 60.110000    Top5 85.580000    
2024-02-17 12:57:10,755 - ==> Top1: 60.110    Top5: 85.580    Loss: 1.938

2024-02-17 12:57:10,767 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:57:10,767 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:57:10,829 - 

2024-02-17 12:57:10,829 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:57:18,800 - Epoch: [170][  100/  500]    Overall Loss 0.229916    Objective Loss 0.229916                                        LR 0.000125    Time 0.079653    
2024-02-17 12:57:26,082 - Epoch: [170][  200/  500]    Overall Loss 0.236218    Objective Loss 0.236218                                        LR 0.000125    Time 0.076219    
2024-02-17 12:57:33,395 - Epoch: [170][  300/  500]    Overall Loss 0.237610    Objective Loss 0.237610                                        LR 0.000125    Time 0.075175    
2024-02-17 12:57:40,716 - Epoch: [170][  400/  500]    Overall Loss 0.239643    Objective Loss 0.239643                                        LR 0.000125    Time 0.074672    
2024-02-17 12:57:48,077 - Epoch: [170][  500/  500]    Overall Loss 0.242543    Objective Loss 0.242543    Top1 94.000000    Top5 100.000000    LR 0.000125    Time 0.074452    
2024-02-17 12:57:48,228 - --- validate (epoch=170)-----------
2024-02-17 12:57:48,229 - 10000 samples (100 per mini-batch)
2024-02-17 12:57:51,073 - Epoch: [170][  100/  100]    Loss 1.934659    Top1 60.060000    Top5 85.940000    
2024-02-17 12:57:51,235 - ==> Top1: 60.060    Top5: 85.940    Loss: 1.935

2024-02-17 12:57:51,246 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:57:51,246 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:57:51,309 - 

2024-02-17 12:57:51,309 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:57:58,959 - Epoch: [171][  100/  500]    Overall Loss 0.222846    Objective Loss 0.222846                                        LR 0.000125    Time 0.076446    
2024-02-17 12:58:06,415 - Epoch: [171][  200/  500]    Overall Loss 0.231142    Objective Loss 0.231142                                        LR 0.000125    Time 0.075481    
2024-02-17 12:58:13,674 - Epoch: [171][  300/  500]    Overall Loss 0.233896    Objective Loss 0.233896                                        LR 0.000125    Time 0.074505    
2024-02-17 12:58:20,983 - Epoch: [171][  400/  500]    Overall Loss 0.235802    Objective Loss 0.235802                                        LR 0.000125    Time 0.074140    
2024-02-17 12:58:28,368 - Epoch: [171][  500/  500]    Overall Loss 0.236756    Objective Loss 0.236756    Top1 92.000000    Top5 99.500000    LR 0.000125    Time 0.074073    
2024-02-17 12:58:28,514 - --- validate (epoch=171)-----------
2024-02-17 12:58:28,514 - 10000 samples (100 per mini-batch)
2024-02-17 12:58:31,463 - Epoch: [171][  100/  100]    Loss 1.950507    Top1 59.930000    Top5 85.490000    
2024-02-17 12:58:31,582 - ==> Top1: 59.930    Top5: 85.490    Loss: 1.951

2024-02-17 12:58:31,594 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:58:31,595 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:58:31,659 - 

2024-02-17 12:58:31,659 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:58:39,430 - Epoch: [172][  100/  500]    Overall Loss 0.233213    Objective Loss 0.233213                                        LR 0.000125    Time 0.077653    
2024-02-17 12:58:46,711 - Epoch: [172][  200/  500]    Overall Loss 0.233640    Objective Loss 0.233640                                        LR 0.000125    Time 0.075208    
2024-02-17 12:58:53,930 - Epoch: [172][  300/  500]    Overall Loss 0.234297    Objective Loss 0.234297                                        LR 0.000125    Time 0.074188    
2024-02-17 12:59:01,208 - Epoch: [172][  400/  500]    Overall Loss 0.237797    Objective Loss 0.237797                                        LR 0.000125    Time 0.073827    
2024-02-17 12:59:08,095 - Epoch: [172][  500/  500]    Overall Loss 0.237228    Objective Loss 0.237228    Top1 94.500000    Top5 100.000000    LR 0.000125    Time 0.072828    
2024-02-17 12:59:08,261 - --- validate (epoch=172)-----------
2024-02-17 12:59:08,263 - 10000 samples (100 per mini-batch)
2024-02-17 12:59:11,190 - Epoch: [172][  100/  100]    Loss 1.936042    Top1 59.900000    Top5 85.730000    
2024-02-17 12:59:11,355 - ==> Top1: 59.900    Top5: 85.730    Loss: 1.936

2024-02-17 12:59:11,367 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:59:11,367 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:59:11,430 - 

2024-02-17 12:59:11,430 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:59:19,514 - Epoch: [173][  100/  500]    Overall Loss 0.222833    Objective Loss 0.222833                                        LR 0.000125    Time 0.080785    
2024-02-17 12:59:26,799 - Epoch: [173][  200/  500]    Overall Loss 0.226368    Objective Loss 0.226368                                        LR 0.000125    Time 0.076794    
2024-02-17 12:59:34,089 - Epoch: [173][  300/  500]    Overall Loss 0.233803    Objective Loss 0.233803                                        LR 0.000125    Time 0.075482    
2024-02-17 12:59:41,400 - Epoch: [173][  400/  500]    Overall Loss 0.236299    Objective Loss 0.236299                                        LR 0.000125    Time 0.074880    
2024-02-17 12:59:48,504 - Epoch: [173][  500/  500]    Overall Loss 0.237052    Objective Loss 0.237052    Top1 94.000000    Top5 100.000000    LR 0.000125    Time 0.074103    
2024-02-17 12:59:48,682 - --- validate (epoch=173)-----------
2024-02-17 12:59:48,683 - 10000 samples (100 per mini-batch)
2024-02-17 12:59:51,526 - Epoch: [173][  100/  100]    Loss 1.957766    Top1 59.780000    Top5 85.580000    
2024-02-17 12:59:51,634 - ==> Top1: 59.780    Top5: 85.580    Loss: 1.958

2024-02-17 12:59:51,645 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:59:51,645 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 12:59:51,714 - 

2024-02-17 12:59:51,714 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:59:59,732 - Epoch: [174][  100/  500]    Overall Loss 0.225888    Objective Loss 0.225888                                        LR 0.000125    Time 0.080125    
2024-02-17 13:00:06,989 - Epoch: [174][  200/  500]    Overall Loss 0.232191    Objective Loss 0.232191                                        LR 0.000125    Time 0.076330    
2024-02-17 13:00:14,192 - Epoch: [174][  300/  500]    Overall Loss 0.234775    Objective Loss 0.234775                                        LR 0.000125    Time 0.074880    
2024-02-17 13:00:21,560 - Epoch: [174][  400/  500]    Overall Loss 0.236206    Objective Loss 0.236206                                        LR 0.000125    Time 0.074571    
2024-02-17 13:00:28,874 - Epoch: [174][  500/  500]    Overall Loss 0.237734    Objective Loss 0.237734    Top1 92.500000    Top5 99.500000    LR 0.000125    Time 0.074277    
2024-02-17 13:00:29,043 - --- validate (epoch=174)-----------
2024-02-17 13:00:29,043 - 10000 samples (100 per mini-batch)
2024-02-17 13:00:32,046 - Epoch: [174][  100/  100]    Loss 1.943706    Top1 59.710000    Top5 85.770000    
2024-02-17 13:00:32,219 - ==> Top1: 59.710    Top5: 85.770    Loss: 1.944

2024-02-17 13:00:32,230 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:00:32,230 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:00:32,293 - 

2024-02-17 13:00:32,293 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:00:40,145 - Epoch: [175][  100/  500]    Overall Loss 0.225993    Objective Loss 0.225993                                        LR 0.000125    Time 0.078462    
2024-02-17 13:00:47,547 - Epoch: [175][  200/  500]    Overall Loss 0.233519    Objective Loss 0.233519                                        LR 0.000125    Time 0.076218    
2024-02-17 13:00:54,853 - Epoch: [175][  300/  500]    Overall Loss 0.234766    Objective Loss 0.234766                                        LR 0.000125    Time 0.075152    
2024-02-17 13:01:02,196 - Epoch: [175][  400/  500]    Overall Loss 0.235085    Objective Loss 0.235085                                        LR 0.000125    Time 0.074711    
2024-02-17 13:01:09,519 - Epoch: [175][  500/  500]    Overall Loss 0.236514    Objective Loss 0.236514    Top1 94.000000    Top5 100.000000    LR 0.000125    Time 0.074406    
2024-02-17 13:01:09,686 - --- validate (epoch=175)-----------
2024-02-17 13:01:09,686 - 10000 samples (100 per mini-batch)
2024-02-17 13:01:12,690 - Epoch: [175][  100/  100]    Loss 1.950114    Top1 59.730000    Top5 85.760000    
2024-02-17 13:01:12,864 - ==> Top1: 59.730    Top5: 85.760    Loss: 1.950

2024-02-17 13:01:12,876 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:01:12,877 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:01:12,940 - 

2024-02-17 13:01:12,940 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:01:20,697 - Epoch: [176][  100/  500]    Overall Loss 0.237072    Objective Loss 0.237072                                        LR 0.000125    Time 0.077514    
2024-02-17 13:01:28,019 - Epoch: [176][  200/  500]    Overall Loss 0.234331    Objective Loss 0.234331                                        LR 0.000125    Time 0.075343    
2024-02-17 13:01:35,274 - Epoch: [176][  300/  500]    Overall Loss 0.234554    Objective Loss 0.234554                                        LR 0.000125    Time 0.074397    
2024-02-17 13:01:42,495 - Epoch: [176][  400/  500]    Overall Loss 0.234573    Objective Loss 0.234573                                        LR 0.000125    Time 0.073841    
2024-02-17 13:01:49,871 - Epoch: [176][  500/  500]    Overall Loss 0.234733    Objective Loss 0.234733    Top1 96.500000    Top5 100.000000    LR 0.000125    Time 0.073817    
2024-02-17 13:01:50,029 - --- validate (epoch=176)-----------
2024-02-17 13:01:50,030 - 10000 samples (100 per mini-batch)
2024-02-17 13:01:53,316 - Epoch: [176][  100/  100]    Loss 1.951452    Top1 59.990000    Top5 85.820000    
2024-02-17 13:01:53,418 - ==> Top1: 59.990    Top5: 85.820    Loss: 1.951

2024-02-17 13:01:53,425 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:01:53,426 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:01:53,486 - 

2024-02-17 13:01:53,486 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:02:01,308 - Epoch: [177][  100/  500]    Overall Loss 0.229778    Objective Loss 0.229778                                        LR 0.000125    Time 0.078164    
2024-02-17 13:02:08,493 - Epoch: [177][  200/  500]    Overall Loss 0.233496    Objective Loss 0.233496                                        LR 0.000125    Time 0.074990    
2024-02-17 13:02:15,831 - Epoch: [177][  300/  500]    Overall Loss 0.234882    Objective Loss 0.234882                                        LR 0.000125    Time 0.074437    
2024-02-17 13:02:23,136 - Epoch: [177][  400/  500]    Overall Loss 0.234475    Objective Loss 0.234475                                        LR 0.000125    Time 0.074081    
2024-02-17 13:02:30,480 - Epoch: [177][  500/  500]    Overall Loss 0.233947    Objective Loss 0.233947    Top1 97.000000    Top5 100.000000    LR 0.000125    Time 0.073943    
2024-02-17 13:02:30,610 - --- validate (epoch=177)-----------
2024-02-17 13:02:30,611 - 10000 samples (100 per mini-batch)
2024-02-17 13:02:33,589 - Epoch: [177][  100/  100]    Loss 1.948968    Top1 59.860000    Top5 85.470000    
2024-02-17 13:02:33,715 - ==> Top1: 59.860    Top5: 85.470    Loss: 1.949

2024-02-17 13:02:33,726 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:02:33,726 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:02:33,790 - 

2024-02-17 13:02:33,790 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:02:41,879 - Epoch: [178][  100/  500]    Overall Loss 0.229757    Objective Loss 0.229757                                        LR 0.000125    Time 0.080834    
2024-02-17 13:02:49,112 - Epoch: [178][  200/  500]    Overall Loss 0.227889    Objective Loss 0.227889                                        LR 0.000125    Time 0.076559    
2024-02-17 13:02:56,415 - Epoch: [178][  300/  500]    Overall Loss 0.233380    Objective Loss 0.233380                                        LR 0.000125    Time 0.075369    
2024-02-17 13:03:03,719 - Epoch: [178][  400/  500]    Overall Loss 0.233113    Objective Loss 0.233113                                        LR 0.000125    Time 0.074775    
2024-02-17 13:03:11,053 - Epoch: [178][  500/  500]    Overall Loss 0.232737    Objective Loss 0.232737    Top1 91.000000    Top5 100.000000    LR 0.000125    Time 0.074480    
2024-02-17 13:03:11,191 - --- validate (epoch=178)-----------
2024-02-17 13:03:11,192 - 10000 samples (100 per mini-batch)
2024-02-17 13:03:14,173 - Epoch: [178][  100/  100]    Loss 1.957101    Top1 60.500000    Top5 85.740000    
2024-02-17 13:03:14,297 - ==> Top1: 60.500    Top5: 85.740    Loss: 1.957

2024-02-17 13:03:14,308 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:03:14,309 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:03:14,371 - 

2024-02-17 13:03:14,372 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:03:22,098 - Epoch: [179][  100/  500]    Overall Loss 0.225508    Objective Loss 0.225508                                        LR 0.000125    Time 0.077206    
2024-02-17 13:03:29,409 - Epoch: [179][  200/  500]    Overall Loss 0.226666    Objective Loss 0.226666                                        LR 0.000125    Time 0.075136    
2024-02-17 13:03:36,725 - Epoch: [179][  300/  500]    Overall Loss 0.228379    Objective Loss 0.228379                                        LR 0.000125    Time 0.074466    
2024-02-17 13:03:44,060 - Epoch: [179][  400/  500]    Overall Loss 0.229011    Objective Loss 0.229011                                        LR 0.000125    Time 0.074175    
2024-02-17 13:03:51,413 - Epoch: [179][  500/  500]    Overall Loss 0.229008    Objective Loss 0.229008    Top1 94.000000    Top5 100.000000    LR 0.000125    Time 0.074038    
2024-02-17 13:03:51,526 - --- validate (epoch=179)-----------
2024-02-17 13:03:51,527 - 10000 samples (100 per mini-batch)
2024-02-17 13:03:54,430 - Epoch: [179][  100/  100]    Loss 1.946505    Top1 60.290000    Top5 85.820000    
2024-02-17 13:03:54,610 - ==> Top1: 60.290    Top5: 85.820    Loss: 1.947

2024-02-17 13:03:54,621 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:03:54,621 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:03:54,684 - 

2024-02-17 13:03:54,685 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:04:02,744 - Epoch: [180][  100/  500]    Overall Loss 0.226473    Objective Loss 0.226473                                        LR 0.000125    Time 0.080534    
2024-02-17 13:04:10,051 - Epoch: [180][  200/  500]    Overall Loss 0.226837    Objective Loss 0.226837                                        LR 0.000125    Time 0.076776    
2024-02-17 13:04:17,259 - Epoch: [180][  300/  500]    Overall Loss 0.230913    Objective Loss 0.230913                                        LR 0.000125    Time 0.075199    
2024-02-17 13:04:24,586 - Epoch: [180][  400/  500]    Overall Loss 0.231669    Objective Loss 0.231669                                        LR 0.000125    Time 0.074703    
2024-02-17 13:04:31,745 - Epoch: [180][  500/  500]    Overall Loss 0.230858    Objective Loss 0.230858    Top1 91.000000    Top5 100.000000    LR 0.000125    Time 0.074074    
2024-02-17 13:04:31,894 - --- validate (epoch=180)-----------
2024-02-17 13:04:31,895 - 10000 samples (100 per mini-batch)
2024-02-17 13:04:34,779 - Epoch: [180][  100/  100]    Loss 1.952863    Top1 60.010000    Top5 85.820000    
2024-02-17 13:04:34,906 - ==> Top1: 60.010    Top5: 85.820    Loss: 1.953

2024-02-17 13:04:34,919 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:04:34,920 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:04:34,982 - 

2024-02-17 13:04:34,983 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:04:42,746 - Epoch: [181][  100/  500]    Overall Loss 0.221967    Objective Loss 0.221967                                        LR 0.000125    Time 0.077582    
2024-02-17 13:04:50,095 - Epoch: [181][  200/  500]    Overall Loss 0.225882    Objective Loss 0.225882                                        LR 0.000125    Time 0.075512    
2024-02-17 13:04:57,458 - Epoch: [181][  300/  500]    Overall Loss 0.229935    Objective Loss 0.229935                                        LR 0.000125    Time 0.074872    
2024-02-17 13:05:04,761 - Epoch: [181][  400/  500]    Overall Loss 0.229989    Objective Loss 0.229989                                        LR 0.000125    Time 0.074401    
2024-02-17 13:05:12,082 - Epoch: [181][  500/  500]    Overall Loss 0.229479    Objective Loss 0.229479    Top1 94.500000    Top5 100.000000    LR 0.000125    Time 0.074154    
2024-02-17 13:05:12,268 - --- validate (epoch=181)-----------
2024-02-17 13:05:12,269 - 10000 samples (100 per mini-batch)
2024-02-17 13:05:15,190 - Epoch: [181][  100/  100]    Loss 1.967669    Top1 59.920000    Top5 85.520000    
2024-02-17 13:05:15,297 - ==> Top1: 59.920    Top5: 85.520    Loss: 1.968

2024-02-17 13:05:15,309 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:05:15,309 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:05:15,371 - 

2024-02-17 13:05:15,371 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:05:23,225 - Epoch: [182][  100/  500]    Overall Loss 0.228324    Objective Loss 0.228324                                        LR 0.000125    Time 0.078479    
2024-02-17 13:05:30,575 - Epoch: [182][  200/  500]    Overall Loss 0.222645    Objective Loss 0.222645                                        LR 0.000125    Time 0.075967    
2024-02-17 13:05:37,905 - Epoch: [182][  300/  500]    Overall Loss 0.223732    Objective Loss 0.223732                                        LR 0.000125    Time 0.075064    
2024-02-17 13:05:45,319 - Epoch: [182][  400/  500]    Overall Loss 0.227632    Objective Loss 0.227632                                        LR 0.000125    Time 0.074822    
2024-02-17 13:05:52,758 - Epoch: [182][  500/  500]    Overall Loss 0.229066    Objective Loss 0.229066    Top1 92.500000    Top5 99.500000    LR 0.000125    Time 0.074726    
2024-02-17 13:05:52,894 - --- validate (epoch=182)-----------
2024-02-17 13:05:52,894 - 10000 samples (100 per mini-batch)
2024-02-17 13:05:55,899 - Epoch: [182][  100/  100]    Loss 1.974157    Top1 59.970000    Top5 85.750000    
2024-02-17 13:05:56,052 - ==> Top1: 59.970    Top5: 85.750    Loss: 1.974

2024-02-17 13:05:56,309 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:05:56,309 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:05:56,363 - 

2024-02-17 13:05:56,363 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:06:04,015 - Epoch: [183][  100/  500]    Overall Loss 0.215227    Objective Loss 0.215227                                        LR 0.000125    Time 0.076467    
2024-02-17 13:06:11,332 - Epoch: [183][  200/  500]    Overall Loss 0.222679    Objective Loss 0.222679                                        LR 0.000125    Time 0.074798    
2024-02-17 13:06:18,533 - Epoch: [183][  300/  500]    Overall Loss 0.226788    Objective Loss 0.226788                                        LR 0.000125    Time 0.073853    
2024-02-17 13:06:25,903 - Epoch: [183][  400/  500]    Overall Loss 0.227187    Objective Loss 0.227187                                        LR 0.000125    Time 0.073806    
2024-02-17 13:06:33,258 - Epoch: [183][  500/  500]    Overall Loss 0.227088    Objective Loss 0.227088    Top1 94.000000    Top5 99.000000    LR 0.000125    Time 0.073745    
2024-02-17 13:06:33,389 - --- validate (epoch=183)-----------
2024-02-17 13:06:33,389 - 10000 samples (100 per mini-batch)
2024-02-17 13:06:36,390 - Epoch: [183][  100/  100]    Loss 1.957040    Top1 59.830000    Top5 85.790000    
2024-02-17 13:06:36,598 - ==> Top1: 59.830    Top5: 85.790    Loss: 1.957

2024-02-17 13:06:36,609 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:06:36,609 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:06:36,676 - 

2024-02-17 13:06:36,676 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:06:44,436 - Epoch: [184][  100/  500]    Overall Loss 0.219644    Objective Loss 0.219644                                        LR 0.000125    Time 0.077546    
2024-02-17 13:06:51,619 - Epoch: [184][  200/  500]    Overall Loss 0.224112    Objective Loss 0.224112                                        LR 0.000125    Time 0.074673    
2024-02-17 13:06:58,618 - Epoch: [184][  300/  500]    Overall Loss 0.224402    Objective Loss 0.224402                                        LR 0.000125    Time 0.073102    
2024-02-17 13:07:05,886 - Epoch: [184][  400/  500]    Overall Loss 0.227515    Objective Loss 0.227515                                        LR 0.000125    Time 0.072986    
2024-02-17 13:07:13,246 - Epoch: [184][  500/  500]    Overall Loss 0.229596    Objective Loss 0.229596    Top1 93.500000    Top5 99.500000    LR 0.000125    Time 0.073101    
2024-02-17 13:07:13,366 - --- validate (epoch=184)-----------
2024-02-17 13:07:13,367 - 10000 samples (100 per mini-batch)
2024-02-17 13:07:16,617 - Epoch: [184][  100/  100]    Loss 1.966017    Top1 60.000000    Top5 85.630000    
2024-02-17 13:07:16,743 - ==> Top1: 60.000    Top5: 85.630    Loss: 1.966

2024-02-17 13:07:16,751 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:07:16,751 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:07:16,813 - 

2024-02-17 13:07:16,813 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:07:24,484 - Epoch: [185][  100/  500]    Overall Loss 0.227796    Objective Loss 0.227796                                        LR 0.000125    Time 0.076659    
2024-02-17 13:07:31,705 - Epoch: [185][  200/  500]    Overall Loss 0.223938    Objective Loss 0.223938                                        LR 0.000125    Time 0.074410    
2024-02-17 13:07:39,083 - Epoch: [185][  300/  500]    Overall Loss 0.226002    Objective Loss 0.226002                                        LR 0.000125    Time 0.074186    
2024-02-17 13:07:46,364 - Epoch: [185][  400/  500]    Overall Loss 0.225594    Objective Loss 0.225594                                        LR 0.000125    Time 0.073834    
2024-02-17 13:07:53,685 - Epoch: [185][  500/  500]    Overall Loss 0.225943    Objective Loss 0.225943    Top1 93.500000    Top5 100.000000    LR 0.000125    Time 0.073699    
2024-02-17 13:07:53,860 - --- validate (epoch=185)-----------
2024-02-17 13:07:53,861 - 10000 samples (100 per mini-batch)
2024-02-17 13:07:57,282 - Epoch: [185][  100/  100]    Loss 1.967303    Top1 59.800000    Top5 85.760000    
2024-02-17 13:07:57,418 - ==> Top1: 59.800    Top5: 85.760    Loss: 1.967

2024-02-17 13:07:57,425 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:07:57,425 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:07:57,486 - 

2024-02-17 13:07:57,487 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:08:05,647 - Epoch: [186][  100/  500]    Overall Loss 0.210687    Objective Loss 0.210687                                        LR 0.000125    Time 0.081555    
2024-02-17 13:08:12,956 - Epoch: [186][  200/  500]    Overall Loss 0.218706    Objective Loss 0.218706                                        LR 0.000125    Time 0.077301    
2024-02-17 13:08:20,269 - Epoch: [186][  300/  500]    Overall Loss 0.220617    Objective Loss 0.220617                                        LR 0.000125    Time 0.075894    
2024-02-17 13:08:27,503 - Epoch: [186][  400/  500]    Overall Loss 0.221219    Objective Loss 0.221219                                        LR 0.000125    Time 0.074995    
2024-02-17 13:08:34,912 - Epoch: [186][  500/  500]    Overall Loss 0.224767    Objective Loss 0.224767    Top1 93.000000    Top5 99.500000    LR 0.000125    Time 0.074806    
2024-02-17 13:08:35,051 - --- validate (epoch=186)-----------
2024-02-17 13:08:35,051 - 10000 samples (100 per mini-batch)
2024-02-17 13:08:38,339 - Epoch: [186][  100/  100]    Loss 1.972442    Top1 59.790000    Top5 85.870000    
2024-02-17 13:08:38,447 - ==> Top1: 59.790    Top5: 85.870    Loss: 1.972

2024-02-17 13:08:38,458 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:08:38,458 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:08:38,516 - 

2024-02-17 13:08:38,517 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:08:46,365 - Epoch: [187][  100/  500]    Overall Loss 0.222190    Objective Loss 0.222190                                        LR 0.000125    Time 0.078427    
2024-02-17 13:08:53,694 - Epoch: [187][  200/  500]    Overall Loss 0.221114    Objective Loss 0.221114                                        LR 0.000125    Time 0.075833    
2024-02-17 13:09:00,652 - Epoch: [187][  300/  500]    Overall Loss 0.221460    Objective Loss 0.221460                                        LR 0.000125    Time 0.073738    
2024-02-17 13:09:08,045 - Epoch: [187][  400/  500]    Overall Loss 0.224399    Objective Loss 0.224399                                        LR 0.000125    Time 0.073775    
2024-02-17 13:09:15,378 - Epoch: [187][  500/  500]    Overall Loss 0.226769    Objective Loss 0.226769    Top1 93.000000    Top5 100.000000    LR 0.000125    Time 0.073677    
2024-02-17 13:09:15,502 - --- validate (epoch=187)-----------
2024-02-17 13:09:15,502 - 10000 samples (100 per mini-batch)
2024-02-17 13:09:18,943 - Epoch: [187][  100/  100]    Loss 1.984545    Top1 59.840000    Top5 85.680000    
2024-02-17 13:09:19,036 - ==> Top1: 59.840    Top5: 85.680    Loss: 1.985

2024-02-17 13:09:19,046 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:09:19,047 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:09:19,120 - 

2024-02-17 13:09:19,120 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:09:27,168 - Epoch: [188][  100/  500]    Overall Loss 0.213649    Objective Loss 0.213649                                        LR 0.000125    Time 0.080416    
2024-02-17 13:09:34,386 - Epoch: [188][  200/  500]    Overall Loss 0.218540    Objective Loss 0.218540                                        LR 0.000125    Time 0.076277    
2024-02-17 13:09:41,653 - Epoch: [188][  300/  500]    Overall Loss 0.218849    Objective Loss 0.218849                                        LR 0.000125    Time 0.075063    
2024-02-17 13:09:48,951 - Epoch: [188][  400/  500]    Overall Loss 0.223136    Objective Loss 0.223136                                        LR 0.000125    Time 0.074530    
2024-02-17 13:09:56,251 - Epoch: [188][  500/  500]    Overall Loss 0.225520    Objective Loss 0.225520    Top1 90.000000    Top5 100.000000    LR 0.000125    Time 0.074216    
2024-02-17 13:09:56,388 - --- validate (epoch=188)-----------
2024-02-17 13:09:56,389 - 10000 samples (100 per mini-batch)
2024-02-17 13:09:59,418 - Epoch: [188][  100/  100]    Loss 1.987643    Top1 59.360000    Top5 85.380000    
2024-02-17 13:09:59,540 - ==> Top1: 59.360    Top5: 85.380    Loss: 1.988

2024-02-17 13:09:59,552 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:09:59,552 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:09:59,616 - 

2024-02-17 13:09:59,616 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:10:07,391 - Epoch: [189][  100/  500]    Overall Loss 0.225949    Objective Loss 0.225949                                        LR 0.000125    Time 0.077687    
2024-02-17 13:10:14,744 - Epoch: [189][  200/  500]    Overall Loss 0.222795    Objective Loss 0.222795                                        LR 0.000125    Time 0.075587    
2024-02-17 13:10:21,676 - Epoch: [189][  300/  500]    Overall Loss 0.224683    Objective Loss 0.224683                                        LR 0.000125    Time 0.073490    
2024-02-17 13:10:28,986 - Epoch: [189][  400/  500]    Overall Loss 0.223539    Objective Loss 0.223539                                        LR 0.000125    Time 0.073382    
2024-02-17 13:10:36,189 - Epoch: [189][  500/  500]    Overall Loss 0.226418    Objective Loss 0.226418    Top1 93.000000    Top5 98.500000    LR 0.000125    Time 0.073103    
2024-02-17 13:10:36,331 - --- validate (epoch=189)-----------
2024-02-17 13:10:36,332 - 10000 samples (100 per mini-batch)
2024-02-17 13:10:39,399 - Epoch: [189][  100/  100]    Loss 1.986064    Top1 60.010000    Top5 85.360000    
2024-02-17 13:10:39,585 - ==> Top1: 60.010    Top5: 85.360    Loss: 1.986

2024-02-17 13:10:39,599 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:10:39,599 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:10:39,668 - 

2024-02-17 13:10:39,669 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:10:47,655 - Epoch: [190][  100/  500]    Overall Loss 0.211893    Objective Loss 0.211893                                        LR 0.000125    Time 0.079808    
2024-02-17 13:10:54,912 - Epoch: [190][  200/  500]    Overall Loss 0.216724    Objective Loss 0.216724                                        LR 0.000125    Time 0.076168    
2024-02-17 13:11:02,153 - Epoch: [190][  300/  500]    Overall Loss 0.217644    Objective Loss 0.217644                                        LR 0.000125    Time 0.074902    
2024-02-17 13:11:09,557 - Epoch: [190][  400/  500]    Overall Loss 0.220819    Objective Loss 0.220819                                        LR 0.000125    Time 0.074676    
2024-02-17 13:11:16,762 - Epoch: [190][  500/  500]    Overall Loss 0.222200    Objective Loss 0.222200    Top1 94.500000    Top5 99.500000    LR 0.000125    Time 0.074144    
2024-02-17 13:11:16,934 - --- validate (epoch=190)-----------
2024-02-17 13:11:16,935 - 10000 samples (100 per mini-batch)
2024-02-17 13:11:20,085 - Epoch: [190][  100/  100]    Loss 1.970894    Top1 59.700000    Top5 85.680000    
2024-02-17 13:11:20,196 - ==> Top1: 59.700    Top5: 85.680    Loss: 1.971

2024-02-17 13:11:20,207 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:11:20,207 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:11:20,275 - 

2024-02-17 13:11:20,276 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:11:28,378 - Epoch: [191][  100/  500]    Overall Loss 0.219249    Objective Loss 0.219249                                        LR 0.000125    Time 0.080969    
2024-02-17 13:11:35,823 - Epoch: [191][  200/  500]    Overall Loss 0.219000    Objective Loss 0.219000                                        LR 0.000125    Time 0.077686    
2024-02-17 13:11:43,149 - Epoch: [191][  300/  500]    Overall Loss 0.219732    Objective Loss 0.219732                                        LR 0.000125    Time 0.076197    
2024-02-17 13:11:50,273 - Epoch: [191][  400/  500]    Overall Loss 0.221630    Objective Loss 0.221630                                        LR 0.000125    Time 0.074947    
2024-02-17 13:11:57,214 - Epoch: [191][  500/  500]    Overall Loss 0.222612    Objective Loss 0.222612    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.073833    
2024-02-17 13:11:57,336 - --- validate (epoch=191)-----------
2024-02-17 13:11:57,336 - 10000 samples (100 per mini-batch)
2024-02-17 13:12:00,282 - Epoch: [191][  100/  100]    Loss 1.991651    Top1 59.920000    Top5 85.580000    
2024-02-17 13:12:00,401 - ==> Top1: 59.920    Top5: 85.580    Loss: 1.992

2024-02-17 13:12:00,413 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:12:00,413 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:12:00,474 - 

2024-02-17 13:12:00,475 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:12:08,399 - Epoch: [192][  100/  500]    Overall Loss 0.218386    Objective Loss 0.218386                                        LR 0.000125    Time 0.079194    
2024-02-17 13:12:15,546 - Epoch: [192][  200/  500]    Overall Loss 0.217557    Objective Loss 0.217557                                        LR 0.000125    Time 0.075311    
2024-02-17 13:12:22,856 - Epoch: [192][  300/  500]    Overall Loss 0.215115    Objective Loss 0.215115                                        LR 0.000125    Time 0.074561    
2024-02-17 13:12:30,191 - Epoch: [192][  400/  500]    Overall Loss 0.217083    Objective Loss 0.217083                                        LR 0.000125    Time 0.074249    
2024-02-17 13:12:37,474 - Epoch: [192][  500/  500]    Overall Loss 0.219166    Objective Loss 0.219166    Top1 97.000000    Top5 100.000000    LR 0.000125    Time 0.073956    
2024-02-17 13:12:37,617 - --- validate (epoch=192)-----------
2024-02-17 13:12:37,617 - 10000 samples (100 per mini-batch)
2024-02-17 13:12:40,663 - Epoch: [192][  100/  100]    Loss 1.972215    Top1 59.890000    Top5 85.600000    
2024-02-17 13:12:40,839 - ==> Top1: 59.890    Top5: 85.600    Loss: 1.972

2024-02-17 13:12:40,851 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:12:40,851 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:12:40,914 - 

2024-02-17 13:12:40,915 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:12:48,704 - Epoch: [193][  100/  500]    Overall Loss 0.213690    Objective Loss 0.213690                                        LR 0.000125    Time 0.077838    
2024-02-17 13:12:55,968 - Epoch: [193][  200/  500]    Overall Loss 0.216133    Objective Loss 0.216133                                        LR 0.000125    Time 0.075219    
2024-02-17 13:13:03,266 - Epoch: [193][  300/  500]    Overall Loss 0.217282    Objective Loss 0.217282                                        LR 0.000125    Time 0.074458    
2024-02-17 13:13:10,480 - Epoch: [193][  400/  500]    Overall Loss 0.218157    Objective Loss 0.218157                                        LR 0.000125    Time 0.073868    
2024-02-17 13:13:17,739 - Epoch: [193][  500/  500]    Overall Loss 0.217944    Objective Loss 0.217944    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.073606    
2024-02-17 13:13:17,891 - --- validate (epoch=193)-----------
2024-02-17 13:13:17,892 - 10000 samples (100 per mini-batch)
2024-02-17 13:13:20,812 - Epoch: [193][  100/  100]    Loss 1.982611    Top1 59.880000    Top5 85.910000    
2024-02-17 13:13:20,989 - ==> Top1: 59.880    Top5: 85.910    Loss: 1.983

2024-02-17 13:13:21,003 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:13:21,003 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:13:21,064 - 

2024-02-17 13:13:21,064 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:13:29,079 - Epoch: [194][  100/  500]    Overall Loss 0.203038    Objective Loss 0.203038                                        LR 0.000125    Time 0.080100    
2024-02-17 13:13:36,341 - Epoch: [194][  200/  500]    Overall Loss 0.209588    Objective Loss 0.209588                                        LR 0.000125    Time 0.076338    
2024-02-17 13:13:43,193 - Epoch: [194][  300/  500]    Overall Loss 0.212824    Objective Loss 0.212824                                        LR 0.000125    Time 0.073721    
2024-02-17 13:13:50,003 - Epoch: [194][  400/  500]    Overall Loss 0.214587    Objective Loss 0.214587                                        LR 0.000125    Time 0.072307    
2024-02-17 13:13:57,516 - Epoch: [194][  500/  500]    Overall Loss 0.216752    Objective Loss 0.216752    Top1 92.000000    Top5 99.500000    LR 0.000125    Time 0.072863    
2024-02-17 13:13:57,653 - --- validate (epoch=194)-----------
2024-02-17 13:13:57,654 - 10000 samples (100 per mini-batch)
2024-02-17 13:14:00,789 - Epoch: [194][  100/  100]    Loss 2.009548    Top1 59.420000    Top5 85.450000    
2024-02-17 13:14:00,915 - ==> Top1: 59.420    Top5: 85.450    Loss: 2.010

2024-02-17 13:14:00,926 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:14:00,927 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:14:00,993 - 

2024-02-17 13:14:00,993 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:14:08,801 - Epoch: [195][  100/  500]    Overall Loss 0.218217    Objective Loss 0.218217                                        LR 0.000125    Time 0.078027    
2024-02-17 13:14:16,035 - Epoch: [195][  200/  500]    Overall Loss 0.218245    Objective Loss 0.218245                                        LR 0.000125    Time 0.075163    
2024-02-17 13:14:23,291 - Epoch: [195][  300/  500]    Overall Loss 0.219620    Objective Loss 0.219620                                        LR 0.000125    Time 0.074282    
2024-02-17 13:14:30,596 - Epoch: [195][  400/  500]    Overall Loss 0.220032    Objective Loss 0.220032                                        LR 0.000125    Time 0.073962    
2024-02-17 13:14:37,901 - Epoch: [195][  500/  500]    Overall Loss 0.220848    Objective Loss 0.220848    Top1 93.000000    Top5 100.000000    LR 0.000125    Time 0.073771    
2024-02-17 13:14:38,070 - --- validate (epoch=195)-----------
2024-02-17 13:14:38,070 - 10000 samples (100 per mini-batch)
2024-02-17 13:14:40,992 - Epoch: [195][  100/  100]    Loss 1.998598    Top1 59.870000    Top5 85.750000    
2024-02-17 13:14:41,103 - ==> Top1: 59.870    Top5: 85.750    Loss: 1.999

2024-02-17 13:14:41,116 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:14:41,117 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:14:41,178 - 

2024-02-17 13:14:41,178 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:14:49,006 - Epoch: [196][  100/  500]    Overall Loss 0.215504    Objective Loss 0.215504                                        LR 0.000125    Time 0.078224    
2024-02-17 13:14:56,248 - Epoch: [196][  200/  500]    Overall Loss 0.215083    Objective Loss 0.215083                                        LR 0.000125    Time 0.075298    
2024-02-17 13:15:03,208 - Epoch: [196][  300/  500]    Overall Loss 0.214971    Objective Loss 0.214971                                        LR 0.000125    Time 0.073390    
2024-02-17 13:15:10,500 - Epoch: [196][  400/  500]    Overall Loss 0.215812    Objective Loss 0.215812                                        LR 0.000125    Time 0.073261    
2024-02-17 13:15:17,793 - Epoch: [196][  500/  500]    Overall Loss 0.216520    Objective Loss 0.216520    Top1 95.500000    Top5 100.000000    LR 0.000125    Time 0.073188    
2024-02-17 13:15:17,922 - --- validate (epoch=196)-----------
2024-02-17 13:15:17,923 - 10000 samples (100 per mini-batch)
2024-02-17 13:15:20,855 - Epoch: [196][  100/  100]    Loss 2.017509    Top1 59.410000    Top5 85.360000    
2024-02-17 13:15:20,956 - ==> Top1: 59.410    Top5: 85.360    Loss: 2.018

2024-02-17 13:15:20,967 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:15:20,968 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:15:21,031 - 

2024-02-17 13:15:21,031 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:15:28,911 - Epoch: [197][  100/  500]    Overall Loss 0.199093    Objective Loss 0.199093                                        LR 0.000125    Time 0.078746    
2024-02-17 13:15:36,178 - Epoch: [197][  200/  500]    Overall Loss 0.210532    Objective Loss 0.210532                                        LR 0.000125    Time 0.075690    
2024-02-17 13:15:43,479 - Epoch: [197][  300/  500]    Overall Loss 0.213149    Objective Loss 0.213149                                        LR 0.000125    Time 0.074780    
2024-02-17 13:15:50,776 - Epoch: [197][  400/  500]    Overall Loss 0.213956    Objective Loss 0.213956                                        LR 0.000125    Time 0.074317    
2024-02-17 13:15:58,024 - Epoch: [197][  500/  500]    Overall Loss 0.215248    Objective Loss 0.215248    Top1 93.000000    Top5 100.000000    LR 0.000125    Time 0.073942    
2024-02-17 13:15:58,196 - --- validate (epoch=197)-----------
2024-02-17 13:15:58,196 - 10000 samples (100 per mini-batch)
2024-02-17 13:16:01,221 - Epoch: [197][  100/  100]    Loss 1.980144    Top1 60.340000    Top5 85.590000    
2024-02-17 13:16:01,330 - ==> Top1: 60.340    Top5: 85.590    Loss: 1.980

2024-02-17 13:16:01,342 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:16:01,342 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:16:01,405 - 

2024-02-17 13:16:01,405 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:16:09,285 - Epoch: [198][  100/  500]    Overall Loss 0.212729    Objective Loss 0.212729                                        LR 0.000125    Time 0.078745    
2024-02-17 13:16:16,466 - Epoch: [198][  200/  500]    Overall Loss 0.210995    Objective Loss 0.210995                                        LR 0.000125    Time 0.075261    
2024-02-17 13:16:23,746 - Epoch: [198][  300/  500]    Overall Loss 0.211916    Objective Loss 0.211916                                        LR 0.000125    Time 0.074426    
2024-02-17 13:16:30,971 - Epoch: [198][  400/  500]    Overall Loss 0.213681    Objective Loss 0.213681                                        LR 0.000125    Time 0.073872    
2024-02-17 13:16:38,086 - Epoch: [198][  500/  500]    Overall Loss 0.216552    Objective Loss 0.216552    Top1 91.500000    Top5 100.000000    LR 0.000125    Time 0.073320    
2024-02-17 13:16:38,197 - --- validate (epoch=198)-----------
2024-02-17 13:16:38,197 - 10000 samples (100 per mini-batch)
2024-02-17 13:16:41,170 - Epoch: [198][  100/  100]    Loss 2.016967    Top1 59.390000    Top5 85.560000    
2024-02-17 13:16:41,295 - ==> Top1: 59.390    Top5: 85.560    Loss: 2.017

2024-02-17 13:16:41,307 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:16:41,307 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:16:41,370 - 

2024-02-17 13:16:41,371 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:16:49,180 - Epoch: [199][  100/  500]    Overall Loss 0.208800    Objective Loss 0.208800                                        LR 0.000125    Time 0.078035    
2024-02-17 13:16:56,157 - Epoch: [199][  200/  500]    Overall Loss 0.209824    Objective Loss 0.209824                                        LR 0.000125    Time 0.073886    
2024-02-17 13:17:03,272 - Epoch: [199][  300/  500]    Overall Loss 0.211934    Objective Loss 0.211934                                        LR 0.000125    Time 0.072961    
2024-02-17 13:17:10,346 - Epoch: [199][  400/  500]    Overall Loss 0.214977    Objective Loss 0.214977                                        LR 0.000125    Time 0.072397    
2024-02-17 13:17:17,622 - Epoch: [199][  500/  500]    Overall Loss 0.216143    Objective Loss 0.216143    Top1 93.500000    Top5 100.000000    LR 0.000125    Time 0.072462    
2024-02-17 13:17:17,753 - --- validate (epoch=199)-----------
2024-02-17 13:17:17,754 - 10000 samples (100 per mini-batch)
2024-02-17 13:17:20,957 - Epoch: [199][  100/  100]    Loss 1.993669    Top1 59.600000    Top5 85.480000    
2024-02-17 13:17:21,149 - ==> Top1: 59.600    Top5: 85.480    Loss: 1.994

2024-02-17 13:17:21,158 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:17:21,158 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:17:21,218 - 

2024-02-17 13:17:21,218 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:17:29,320 - Epoch: [200][  100/  500]    Overall Loss 0.203186    Objective Loss 0.203186                                        LR 0.000063    Time 0.080960    
2024-02-17 13:17:36,660 - Epoch: [200][  200/  500]    Overall Loss 0.200658    Objective Loss 0.200658                                        LR 0.000063    Time 0.077160    
2024-02-17 13:17:44,009 - Epoch: [200][  300/  500]    Overall Loss 0.199368    Objective Loss 0.199368                                        LR 0.000063    Time 0.075922    
2024-02-17 13:17:51,354 - Epoch: [200][  400/  500]    Overall Loss 0.198770    Objective Loss 0.198770                                        LR 0.000063    Time 0.075293    
2024-02-17 13:17:58,656 - Epoch: [200][  500/  500]    Overall Loss 0.200164    Objective Loss 0.200164    Top1 94.500000    Top5 100.000000    LR 0.000063    Time 0.074830    
2024-02-17 13:17:58,779 - --- validate (epoch=200)-----------
2024-02-17 13:17:58,780 - 10000 samples (100 per mini-batch)
2024-02-17 13:18:01,923 - Epoch: [200][  100/  100]    Loss 1.965052    Top1 59.960000    Top5 85.850000    
2024-02-17 13:18:02,023 - ==> Top1: 59.960    Top5: 85.850    Loss: 1.965

2024-02-17 13:18:02,034 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:18:02,035 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:18:02,099 - 

2024-02-17 13:18:02,099 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:18:09,700 - Epoch: [201][  100/  500]    Overall Loss 0.194777    Objective Loss 0.194777                                        LR 0.000063    Time 0.075960    
2024-02-17 13:18:16,920 - Epoch: [201][  200/  500]    Overall Loss 0.195865    Objective Loss 0.195865                                        LR 0.000063    Time 0.074061    
2024-02-17 13:18:24,046 - Epoch: [201][  300/  500]    Overall Loss 0.197402    Objective Loss 0.197402                                        LR 0.000063    Time 0.073115    
2024-02-17 13:18:31,327 - Epoch: [201][  400/  500]    Overall Loss 0.197737    Objective Loss 0.197737                                        LR 0.000063    Time 0.073029    
2024-02-17 13:18:38,660 - Epoch: [201][  500/  500]    Overall Loss 0.198817    Objective Loss 0.198817    Top1 92.000000    Top5 99.500000    LR 0.000063    Time 0.073081    
2024-02-17 13:18:38,764 - --- validate (epoch=201)-----------
2024-02-17 13:18:38,765 - 10000 samples (100 per mini-batch)
2024-02-17 13:18:41,931 - Epoch: [201][  100/  100]    Loss 1.979687    Top1 60.100000    Top5 85.590000    
2024-02-17 13:18:42,045 - ==> Top1: 60.100    Top5: 85.590    Loss: 1.980

2024-02-17 13:18:42,056 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:18:42,057 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:18:42,121 - 

2024-02-17 13:18:42,121 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:18:50,213 - Epoch: [202][  100/  500]    Overall Loss 0.196987    Objective Loss 0.196987                                        LR 0.000063    Time 0.080864    
2024-02-17 13:18:57,478 - Epoch: [202][  200/  500]    Overall Loss 0.198782    Objective Loss 0.198782                                        LR 0.000063    Time 0.076736    
2024-02-17 13:19:04,488 - Epoch: [202][  300/  500]    Overall Loss 0.199579    Objective Loss 0.199579                                        LR 0.000063    Time 0.074515    
2024-02-17 13:19:11,685 - Epoch: [202][  400/  500]    Overall Loss 0.202158    Objective Loss 0.202158                                        LR 0.000063    Time 0.073868    
2024-02-17 13:19:18,967 - Epoch: [202][  500/  500]    Overall Loss 0.202946    Objective Loss 0.202946    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.073651    
2024-02-17 13:19:19,088 - --- validate (epoch=202)-----------
2024-02-17 13:19:19,089 - 10000 samples (100 per mini-batch)
2024-02-17 13:19:22,057 - Epoch: [202][  100/  100]    Loss 1.980951    Top1 60.160000    Top5 85.550000    
2024-02-17 13:19:22,154 - ==> Top1: 60.160    Top5: 85.550    Loss: 1.981

2024-02-17 13:19:22,166 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:19:22,166 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:19:22,229 - 

2024-02-17 13:19:22,229 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:19:29,953 - Epoch: [203][  100/  500]    Overall Loss 0.198696    Objective Loss 0.198696                                        LR 0.000063    Time 0.077191    
2024-02-17 13:19:37,285 - Epoch: [203][  200/  500]    Overall Loss 0.202378    Objective Loss 0.202378                                        LR 0.000063    Time 0.075233    
2024-02-17 13:19:44,234 - Epoch: [203][  300/  500]    Overall Loss 0.199438    Objective Loss 0.199438                                        LR 0.000063    Time 0.073310    
2024-02-17 13:19:51,308 - Epoch: [203][  400/  500]    Overall Loss 0.200565    Objective Loss 0.200565                                        LR 0.000063    Time 0.072658    
2024-02-17 13:19:58,510 - Epoch: [203][  500/  500]    Overall Loss 0.198712    Objective Loss 0.198712    Top1 93.500000    Top5 100.000000    LR 0.000063    Time 0.072523    
2024-02-17 13:19:58,695 - --- validate (epoch=203)-----------
2024-02-17 13:19:58,695 - 10000 samples (100 per mini-batch)
2024-02-17 13:20:01,615 - Epoch: [203][  100/  100]    Loss 1.983417    Top1 60.080000    Top5 85.490000    
2024-02-17 13:20:01,794 - ==> Top1: 60.080    Top5: 85.490    Loss: 1.983

2024-02-17 13:20:01,807 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:20:01,808 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:20:01,871 - 

2024-02-17 13:20:01,871 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:20:09,919 - Epoch: [204][  100/  500]    Overall Loss 0.194937    Objective Loss 0.194937                                        LR 0.000063    Time 0.080425    
2024-02-17 13:20:17,192 - Epoch: [204][  200/  500]    Overall Loss 0.194596    Objective Loss 0.194596                                        LR 0.000063    Time 0.076559    
2024-02-17 13:20:24,535 - Epoch: [204][  300/  500]    Overall Loss 0.192799    Objective Loss 0.192799                                        LR 0.000063    Time 0.075501    
2024-02-17 13:20:31,933 - Epoch: [204][  400/  500]    Overall Loss 0.195310    Objective Loss 0.195310                                        LR 0.000063    Time 0.075111    
2024-02-17 13:20:39,299 - Epoch: [204][  500/  500]    Overall Loss 0.196354    Objective Loss 0.196354    Top1 93.500000    Top5 99.500000    LR 0.000063    Time 0.074812    
2024-02-17 13:20:39,430 - --- validate (epoch=204)-----------
2024-02-17 13:20:39,431 - 10000 samples (100 per mini-batch)
2024-02-17 13:20:42,457 - Epoch: [204][  100/  100]    Loss 1.986956    Top1 60.240000    Top5 85.410000    
2024-02-17 13:20:42,558 - ==> Top1: 60.240    Top5: 85.410    Loss: 1.987

2024-02-17 13:20:42,570 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:20:42,570 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:20:42,632 - 

2024-02-17 13:20:42,632 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:20:50,408 - Epoch: [205][  100/  500]    Overall Loss 0.195522    Objective Loss 0.195522                                        LR 0.000063    Time 0.077708    
2024-02-17 13:20:57,475 - Epoch: [205][  200/  500]    Overall Loss 0.197703    Objective Loss 0.197703                                        LR 0.000063    Time 0.074169    
2024-02-17 13:21:04,600 - Epoch: [205][  300/  500]    Overall Loss 0.197991    Objective Loss 0.197991                                        LR 0.000063    Time 0.073184    
2024-02-17 13:21:11,837 - Epoch: [205][  400/  500]    Overall Loss 0.197787    Objective Loss 0.197787                                        LR 0.000063    Time 0.072970    
2024-02-17 13:21:18,990 - Epoch: [205][  500/  500]    Overall Loss 0.198011    Objective Loss 0.198011    Top1 96.000000    Top5 100.000000    LR 0.000063    Time 0.072676    
2024-02-17 13:21:19,114 - --- validate (epoch=205)-----------
2024-02-17 13:21:19,114 - 10000 samples (100 per mini-batch)
2024-02-17 13:21:22,201 - Epoch: [205][  100/  100]    Loss 1.993326    Top1 59.860000    Top5 85.530000    
2024-02-17 13:21:22,364 - ==> Top1: 59.860    Top5: 85.530    Loss: 1.993

2024-02-17 13:21:22,376 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:21:22,376 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:21:22,442 - 

2024-02-17 13:21:22,442 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:21:30,275 - Epoch: [206][  100/  500]    Overall Loss 0.187737    Objective Loss 0.187737                                        LR 0.000063    Time 0.078274    
2024-02-17 13:21:37,470 - Epoch: [206][  200/  500]    Overall Loss 0.190697    Objective Loss 0.190697                                        LR 0.000063    Time 0.075095    
2024-02-17 13:21:44,795 - Epoch: [206][  300/  500]    Overall Loss 0.191348    Objective Loss 0.191348                                        LR 0.000063    Time 0.074464    
2024-02-17 13:21:52,084 - Epoch: [206][  400/  500]    Overall Loss 0.193628    Objective Loss 0.193628                                        LR 0.000063    Time 0.074063    
2024-02-17 13:21:59,440 - Epoch: [206][  500/  500]    Overall Loss 0.194200    Objective Loss 0.194200    Top1 91.000000    Top5 100.000000    LR 0.000063    Time 0.073953    
2024-02-17 13:21:59,594 - --- validate (epoch=206)-----------
2024-02-17 13:21:59,595 - 10000 samples (100 per mini-batch)
2024-02-17 13:22:02,579 - Epoch: [206][  100/  100]    Loss 1.985267    Top1 59.780000    Top5 85.580000    
2024-02-17 13:22:02,757 - ==> Top1: 59.780    Top5: 85.580    Loss: 1.985

2024-02-17 13:22:02,768 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:22:02,768 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:22:02,832 - 

2024-02-17 13:22:02,832 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:22:10,655 - Epoch: [207][  100/  500]    Overall Loss 0.194213    Objective Loss 0.194213                                        LR 0.000063    Time 0.078171    
2024-02-17 13:22:17,901 - Epoch: [207][  200/  500]    Overall Loss 0.199908    Objective Loss 0.199908                                        LR 0.000063    Time 0.075296    
2024-02-17 13:22:25,181 - Epoch: [207][  300/  500]    Overall Loss 0.195590    Objective Loss 0.195590                                        LR 0.000063    Time 0.074453    
2024-02-17 13:22:32,297 - Epoch: [207][  400/  500]    Overall Loss 0.196481    Objective Loss 0.196481                                        LR 0.000063    Time 0.073620    
2024-02-17 13:22:39,429 - Epoch: [207][  500/  500]    Overall Loss 0.196540    Objective Loss 0.196540    Top1 96.500000    Top5 100.000000    LR 0.000063    Time 0.073152    
2024-02-17 13:22:39,551 - --- validate (epoch=207)-----------
2024-02-17 13:22:39,552 - 10000 samples (100 per mini-batch)
2024-02-17 13:22:42,605 - Epoch: [207][  100/  100]    Loss 1.995921    Top1 60.050000    Top5 85.430000    
2024-02-17 13:22:42,702 - ==> Top1: 60.050    Top5: 85.430    Loss: 1.996

2024-02-17 13:22:42,709 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:22:42,709 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:22:42,767 - 

2024-02-17 13:22:42,767 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:22:50,468 - Epoch: [208][  100/  500]    Overall Loss 0.186295    Objective Loss 0.186295                                        LR 0.000063    Time 0.076953    
2024-02-17 13:22:57,639 - Epoch: [208][  200/  500]    Overall Loss 0.191939    Objective Loss 0.191939                                        LR 0.000063    Time 0.074313    
2024-02-17 13:23:04,883 - Epoch: [208][  300/  500]    Overall Loss 0.191132    Objective Loss 0.191132                                        LR 0.000063    Time 0.073676    
2024-02-17 13:23:12,059 - Epoch: [208][  400/  500]    Overall Loss 0.191322    Objective Loss 0.191322                                        LR 0.000063    Time 0.073187    
2024-02-17 13:23:19,208 - Epoch: [208][  500/  500]    Overall Loss 0.191751    Objective Loss 0.191751    Top1 94.500000    Top5 99.500000    LR 0.000063    Time 0.072841    
2024-02-17 13:23:19,386 - --- validate (epoch=208)-----------
2024-02-17 13:23:19,387 - 10000 samples (100 per mini-batch)
2024-02-17 13:23:22,655 - Epoch: [208][  100/  100]    Loss 1.989587    Top1 59.850000    Top5 85.630000    
2024-02-17 13:23:22,818 - ==> Top1: 59.850    Top5: 85.630    Loss: 1.990

2024-02-17 13:23:22,830 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:23:22,831 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:23:22,896 - 

2024-02-17 13:23:22,897 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:23:30,954 - Epoch: [209][  100/  500]    Overall Loss 0.182289    Objective Loss 0.182289                                        LR 0.000063    Time 0.080515    
2024-02-17 13:23:38,350 - Epoch: [209][  200/  500]    Overall Loss 0.184634    Objective Loss 0.184634                                        LR 0.000063    Time 0.077219    
2024-02-17 13:23:45,713 - Epoch: [209][  300/  500]    Overall Loss 0.189662    Objective Loss 0.189662                                        LR 0.000063    Time 0.076009    
2024-02-17 13:23:52,899 - Epoch: [209][  400/  500]    Overall Loss 0.189371    Objective Loss 0.189371                                        LR 0.000063    Time 0.074961    
2024-02-17 13:24:00,210 - Epoch: [209][  500/  500]    Overall Loss 0.191692    Objective Loss 0.191692    Top1 97.500000    Top5 100.000000    LR 0.000063    Time 0.074583    
2024-02-17 13:24:00,322 - --- validate (epoch=209)-----------
2024-02-17 13:24:00,323 - 10000 samples (100 per mini-batch)
2024-02-17 13:24:03,283 - Epoch: [209][  100/  100]    Loss 1.987464    Top1 60.260000    Top5 85.570000    
2024-02-17 13:24:03,466 - ==> Top1: 60.260    Top5: 85.570    Loss: 1.987

2024-02-17 13:24:03,478 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:24:03,478 - Saving checkpoint to: logs/2024.02.17-110226/checkpoint.pth.tar
2024-02-17 13:24:03,538 - 

2024-02-17 13:24:03,539 - Initiating quantization aware training (QAT)...
2024-02-17 13:24:03,603 - 

2024-02-17 13:24:03,603 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:24:13,266 - Epoch: [210][  100/  500]    Overall Loss 5.444752    Objective Loss 5.444752                                        LR 0.000063    Time 0.096581    
2024-02-17 13:24:21,925 - Epoch: [210][  200/  500]    Overall Loss 5.227063    Objective Loss 5.227063                                        LR 0.000063    Time 0.091570    
2024-02-17 13:24:30,419 - Epoch: [210][  300/  500]    Overall Loss 5.105260    Objective Loss 5.105260                                        LR 0.000063    Time 0.089351    
2024-02-17 13:24:39,400 - Epoch: [210][  400/  500]    Overall Loss 5.035809    Objective Loss 5.035809                                        LR 0.000063    Time 0.089456    
2024-02-17 13:24:48,547 - Epoch: [210][  500/  500]    Overall Loss 4.989016    Objective Loss 4.989016    Top1 1.000000    Top5 5.000000    LR 0.000063    Time 0.089850    
2024-02-17 13:24:48,723 - --- validate (epoch=210)-----------
2024-02-17 13:24:48,724 - 10000 samples (100 per mini-batch)
2024-02-17 13:24:54,083 - Epoch: [210][  100/  100]    Loss 4.767465    Top1 1.000000    Top5 5.000000    
2024-02-17 13:24:54,235 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.767

2024-02-17 13:24:54,246 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 210]
2024-02-17 13:24:54,247 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:24:54,304 - 

2024-02-17 13:24:54,304 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:25:03,622 - Epoch: [211][  100/  500]    Overall Loss 4.754490    Objective Loss 4.754490                                        LR 0.000063    Time 0.093131    
2024-02-17 13:25:12,863 - Epoch: [211][  200/  500]    Overall Loss 4.743237    Objective Loss 4.743237                                        LR 0.000063    Time 0.092748    
2024-02-17 13:25:21,959 - Epoch: [211][  300/  500]    Overall Loss 4.736369    Objective Loss 4.736369                                        LR 0.000063    Time 0.092141    
2024-02-17 13:25:30,996 - Epoch: [211][  400/  500]    Overall Loss 4.725453    Objective Loss 4.725453                                        LR 0.000063    Time 0.091690    
2024-02-17 13:25:39,754 - Epoch: [211][  500/  500]    Overall Loss 4.713034    Objective Loss 4.713034    Top1 1.000000    Top5 4.000000    LR 0.000063    Time 0.090860    
2024-02-17 13:25:39,867 - --- validate (epoch=211)-----------
2024-02-17 13:25:39,867 - 10000 samples (100 per mini-batch)
2024-02-17 13:25:45,671 - Epoch: [211][  100/  100]    Loss 4.658339    Top1 1.000000    Top5 5.000000    
2024-02-17 13:25:45,788 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.658

2024-02-17 13:25:45,798 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 211]
2024-02-17 13:25:45,798 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:25:45,863 - 

2024-02-17 13:25:45,863 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:25:55,339 - Epoch: [212][  100/  500]    Overall Loss 4.654815    Objective Loss 4.654815                                        LR 0.000063    Time 0.094706    
2024-02-17 13:26:04,429 - Epoch: [212][  200/  500]    Overall Loss 4.651801    Objective Loss 4.651801                                        LR 0.000063    Time 0.092785    
2024-02-17 13:26:13,564 - Epoch: [212][  300/  500]    Overall Loss 4.650704    Objective Loss 4.650704                                        LR 0.000063    Time 0.092292    
2024-02-17 13:26:22,593 - Epoch: [212][  400/  500]    Overall Loss 4.650395    Objective Loss 4.650395                                        LR 0.000063    Time 0.091783    
2024-02-17 13:26:31,850 - Epoch: [212][  500/  500]    Overall Loss 4.648938    Objective Loss 4.648938    Top1 1.000000    Top5 4.500000    LR 0.000063    Time 0.091932    
2024-02-17 13:26:31,995 - --- validate (epoch=212)-----------
2024-02-17 13:26:31,996 - 10000 samples (100 per mini-batch)
2024-02-17 13:26:38,398 - Epoch: [212][  100/  100]    Loss 4.637719    Top1 1.000000    Top5 5.000000    
2024-02-17 13:26:38,500 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.638

2024-02-17 13:26:38,511 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 212]
2024-02-17 13:26:38,511 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:26:38,579 - 

2024-02-17 13:26:38,579 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:26:48,027 - Epoch: [213][  100/  500]    Overall Loss 4.634920    Objective Loss 4.634920                                        LR 0.000063    Time 0.094425    
2024-02-17 13:26:57,061 - Epoch: [213][  200/  500]    Overall Loss 4.633433    Objective Loss 4.633433                                        LR 0.000063    Time 0.092364    
2024-02-17 13:27:06,269 - Epoch: [213][  300/  500]    Overall Loss 4.633693    Objective Loss 4.633693                                        LR 0.000063    Time 0.092259    
2024-02-17 13:27:15,564 - Epoch: [213][  400/  500]    Overall Loss 4.634453    Objective Loss 4.634453                                        LR 0.000063    Time 0.092420    
2024-02-17 13:27:24,775 - Epoch: [213][  500/  500]    Overall Loss 4.633700    Objective Loss 4.633700    Top1 0.500000    Top5 5.500000    LR 0.000063    Time 0.092351    
2024-02-17 13:27:24,946 - --- validate (epoch=213)-----------
2024-02-17 13:27:24,947 - 10000 samples (100 per mini-batch)
2024-02-17 13:27:30,459 - Epoch: [213][  100/  100]    Loss 4.634576    Top1 1.000000    Top5 5.000000    
2024-02-17 13:27:30,641 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.635

2024-02-17 13:27:30,651 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 213]
2024-02-17 13:27:30,651 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:27:30,720 - 

2024-02-17 13:27:30,720 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:27:40,743 - Epoch: [214][  100/  500]    Overall Loss 4.630026    Objective Loss 4.630026                                        LR 0.000063    Time 0.100171    
2024-02-17 13:27:49,768 - Epoch: [214][  200/  500]    Overall Loss 4.629296    Objective Loss 4.629296                                        LR 0.000063    Time 0.095189    
2024-02-17 13:27:58,590 - Epoch: [214][  300/  500]    Overall Loss 4.628845    Objective Loss 4.628845                                        LR 0.000063    Time 0.092855    
2024-02-17 13:28:07,472 - Epoch: [214][  400/  500]    Overall Loss 4.628663    Objective Loss 4.628663                                        LR 0.000063    Time 0.091838    
2024-02-17 13:28:16,648 - Epoch: [214][  500/  500]    Overall Loss 4.627583    Objective Loss 4.627583    Top1 1.000000    Top5 5.000000    LR 0.000063    Time 0.091814    
2024-02-17 13:28:16,800 - --- validate (epoch=214)-----------
2024-02-17 13:28:16,801 - 10000 samples (100 per mini-batch)
2024-02-17 13:28:21,837 - Epoch: [214][  100/  100]    Loss 4.623987    Top1 1.000000    Top5 5.000000    
2024-02-17 13:28:21,932 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.624

2024-02-17 13:28:21,941 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 214]
2024-02-17 13:28:21,941 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:28:21,993 - 

2024-02-17 13:28:21,993 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:28:30,858 - Epoch: [215][  100/  500]    Overall Loss 4.626857    Objective Loss 4.626857                                        LR 0.000063    Time 0.088610    
2024-02-17 13:28:39,343 - Epoch: [215][  200/  500]    Overall Loss 4.624124    Objective Loss 4.624124                                        LR 0.000063    Time 0.086712    
2024-02-17 13:28:48,425 - Epoch: [215][  300/  500]    Overall Loss 4.624562    Objective Loss 4.624562                                        LR 0.000063    Time 0.088068    
2024-02-17 13:28:57,692 - Epoch: [215][  400/  500]    Overall Loss 4.624870    Objective Loss 4.624870                                        LR 0.000063    Time 0.089208    
2024-02-17 13:29:06,807 - Epoch: [215][  500/  500]    Overall Loss 4.624732    Objective Loss 4.624732    Top1 0.500000    Top5 4.500000    LR 0.000063    Time 0.089590    
2024-02-17 13:29:07,011 - --- validate (epoch=215)-----------
2024-02-17 13:29:07,012 - 10000 samples (100 per mini-batch)
2024-02-17 13:29:11,944 - Epoch: [215][  100/  100]    Loss 4.620592    Top1 1.000000    Top5 5.000000    
2024-02-17 13:29:12,037 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.621

2024-02-17 13:29:12,042 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 215]
2024-02-17 13:29:12,042 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:29:12,122 - 

2024-02-17 13:29:12,122 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:29:21,313 - Epoch: [216][  100/  500]    Overall Loss 4.619829    Objective Loss 4.619829                                        LR 0.000063    Time 0.091845    
2024-02-17 13:29:30,223 - Epoch: [216][  200/  500]    Overall Loss 4.622614    Objective Loss 4.622614                                        LR 0.000063    Time 0.090453    
2024-02-17 13:29:39,470 - Epoch: [216][  300/  500]    Overall Loss 4.623785    Objective Loss 4.623785                                        LR 0.000063    Time 0.091114    
2024-02-17 13:29:48,641 - Epoch: [216][  400/  500]    Overall Loss 4.624750    Objective Loss 4.624750                                        LR 0.000063    Time 0.091251    
2024-02-17 13:29:57,722 - Epoch: [216][  500/  500]    Overall Loss 4.624482    Objective Loss 4.624482    Top1 1.500000    Top5 6.000000    LR 0.000063    Time 0.091156    
2024-02-17 13:29:57,836 - --- validate (epoch=216)-----------
2024-02-17 13:29:57,837 - 10000 samples (100 per mini-batch)
2024-02-17 13:30:03,286 - Epoch: [216][  100/  100]    Loss 4.620479    Top1 1.000000    Top5 5.000000    
2024-02-17 13:30:03,417 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.620

2024-02-17 13:30:03,427 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 216]
2024-02-17 13:30:03,428 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:30:03,491 - 

2024-02-17 13:30:03,491 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:30:13,054 - Epoch: [217][  100/  500]    Overall Loss 4.624911    Objective Loss 4.624911                                        LR 0.000063    Time 0.095572    
2024-02-17 13:30:22,134 - Epoch: [217][  200/  500]    Overall Loss 4.623965    Objective Loss 4.623965                                        LR 0.000063    Time 0.093165    
2024-02-17 13:30:31,555 - Epoch: [217][  300/  500]    Overall Loss 4.623370    Objective Loss 4.623370                                        LR 0.000063    Time 0.093502    
2024-02-17 13:30:40,860 - Epoch: [217][  400/  500]    Overall Loss 4.622505    Objective Loss 4.622505                                        LR 0.000063    Time 0.093378    
2024-02-17 13:30:49,995 - Epoch: [217][  500/  500]    Overall Loss 4.622867    Objective Loss 4.622867    Top1 0.500000    Top5 3.500000    LR 0.000063    Time 0.092965    
2024-02-17 13:30:50,099 - --- validate (epoch=217)-----------
2024-02-17 13:30:50,100 - 10000 samples (100 per mini-batch)
2024-02-17 13:30:55,514 - Epoch: [217][  100/  100]    Loss 4.648580    Top1 1.000000    Top5 5.000000    
2024-02-17 13:30:55,634 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.649

2024-02-17 13:30:55,643 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 217]
2024-02-17 13:30:55,644 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:30:55,709 - 

2024-02-17 13:30:55,709 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:31:05,185 - Epoch: [218][  100/  500]    Overall Loss 4.618400    Objective Loss 4.618400                                        LR 0.000063    Time 0.094705    
2024-02-17 13:31:14,148 - Epoch: [218][  200/  500]    Overall Loss 4.621321    Objective Loss 4.621321                                        LR 0.000063    Time 0.092149    
2024-02-17 13:31:23,361 - Epoch: [218][  300/  500]    Overall Loss 4.619404    Objective Loss 4.619404                                        LR 0.000063    Time 0.092131    
2024-02-17 13:31:32,576 - Epoch: [218][  400/  500]    Overall Loss 4.620066    Objective Loss 4.620066                                        LR 0.000063    Time 0.092122    
2024-02-17 13:31:41,798 - Epoch: [218][  500/  500]    Overall Loss 4.620519    Objective Loss 4.620519    Top1 1.000000    Top5 8.000000    LR 0.000063    Time 0.092135    
2024-02-17 13:31:41,934 - --- validate (epoch=218)-----------
2024-02-17 13:31:41,935 - 10000 samples (100 per mini-batch)
2024-02-17 13:31:48,656 - Epoch: [218][  100/  100]    Loss 4.615341    Top1 1.000000    Top5 5.000000    
2024-02-17 13:31:48,779 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.615

2024-02-17 13:31:48,789 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 218]
2024-02-17 13:31:48,789 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:31:48,856 - 

2024-02-17 13:31:48,856 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:31:58,490 - Epoch: [219][  100/  500]    Overall Loss 4.617027    Objective Loss 4.617027                                        LR 0.000063    Time 0.096269    
2024-02-17 13:32:07,517 - Epoch: [219][  200/  500]    Overall Loss 4.616177    Objective Loss 4.616177                                        LR 0.000063    Time 0.093252    
2024-02-17 13:32:16,715 - Epoch: [219][  300/  500]    Overall Loss 4.615849    Objective Loss 4.615849                                        LR 0.000063    Time 0.092817    
2024-02-17 13:32:25,868 - Epoch: [219][  400/  500]    Overall Loss 4.615923    Objective Loss 4.615923                                        LR 0.000063    Time 0.092484    
2024-02-17 13:32:35,036 - Epoch: [219][  500/  500]    Overall Loss 4.616100    Objective Loss 4.616100    Top1 1.000000    Top5 4.000000    LR 0.000063    Time 0.092316    
2024-02-17 13:32:35,147 - --- validate (epoch=219)-----------
2024-02-17 13:32:35,147 - 10000 samples (100 per mini-batch)
2024-02-17 13:32:40,908 - Epoch: [219][  100/  100]    Loss 4.615734    Top1 1.000000    Top5 5.000000    
2024-02-17 13:32:41,013 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.616

2024-02-17 13:32:41,021 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 219]
2024-02-17 13:32:41,022 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:32:41,093 - 

2024-02-17 13:32:41,093 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:32:50,797 - Epoch: [220][  100/  500]    Overall Loss 4.620548    Objective Loss 4.620548                                        LR 0.000063    Time 0.096987    
2024-02-17 13:32:59,823 - Epoch: [220][  200/  500]    Overall Loss 4.619840    Objective Loss 4.619840                                        LR 0.000063    Time 0.093605    
2024-02-17 13:33:09,010 - Epoch: [220][  300/  500]    Overall Loss 4.618631    Objective Loss 4.618631                                        LR 0.000063    Time 0.093013    
2024-02-17 13:33:18,272 - Epoch: [220][  400/  500]    Overall Loss 4.619344    Objective Loss 4.619344                                        LR 0.000063    Time 0.092904    
2024-02-17 13:33:27,462 - Epoch: [220][  500/  500]    Overall Loss 4.619008    Objective Loss 4.619008    Top1 1.000000    Top5 6.000000    LR 0.000063    Time 0.092696    
2024-02-17 13:33:27,577 - --- validate (epoch=220)-----------
2024-02-17 13:33:27,578 - 10000 samples (100 per mini-batch)
2024-02-17 13:33:32,957 - Epoch: [220][  100/  100]    Loss 4.620998    Top1 1.000000    Top5 5.000000    
2024-02-17 13:33:33,077 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.621

2024-02-17 13:33:33,086 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 220]
2024-02-17 13:33:33,087 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:33:33,152 - 

2024-02-17 13:33:33,152 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:33:42,687 - Epoch: [221][  100/  500]    Overall Loss 4.616433    Objective Loss 4.616433                                        LR 0.000063    Time 0.095298    
2024-02-17 13:33:51,860 - Epoch: [221][  200/  500]    Overall Loss 4.617953    Objective Loss 4.617953                                        LR 0.000063    Time 0.093493    
2024-02-17 13:34:01,214 - Epoch: [221][  300/  500]    Overall Loss 4.618721    Objective Loss 4.618721                                        LR 0.000063    Time 0.093493    
2024-02-17 13:34:10,447 - Epoch: [221][  400/  500]    Overall Loss 4.619469    Objective Loss 4.619469                                        LR 0.000063    Time 0.093194    
2024-02-17 13:34:19,084 - Epoch: [221][  500/  500]    Overall Loss 4.618773    Objective Loss 4.618773    Top1 0.500000    Top5 8.000000    LR 0.000063    Time 0.091822    
2024-02-17 13:34:19,176 - --- validate (epoch=221)-----------
2024-02-17 13:34:19,177 - 10000 samples (100 per mini-batch)
2024-02-17 13:34:24,463 - Epoch: [221][  100/  100]    Loss 4.619521    Top1 1.000000    Top5 5.000000    
2024-02-17 13:34:24,616 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.620

2024-02-17 13:34:24,627 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 221]
2024-02-17 13:34:24,628 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:34:24,692 - 

2024-02-17 13:34:24,692 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:34:34,514 - Epoch: [222][  100/  500]    Overall Loss 4.617930    Objective Loss 4.617930                                        LR 0.000063    Time 0.098165    
2024-02-17 13:34:43,636 - Epoch: [222][  200/  500]    Overall Loss 4.617419    Objective Loss 4.617419                                        LR 0.000063    Time 0.094674    
2024-02-17 13:34:53,040 - Epoch: [222][  300/  500]    Overall Loss 4.616896    Objective Loss 4.616896                                        LR 0.000063    Time 0.094450    
2024-02-17 13:35:02,210 - Epoch: [222][  400/  500]    Overall Loss 4.617841    Objective Loss 4.617841                                        LR 0.000063    Time 0.093751    
2024-02-17 13:35:11,220 - Epoch: [222][  500/  500]    Overall Loss 4.618187    Objective Loss 4.618187    Top1 0.000000    Top5 4.000000    LR 0.000063    Time 0.093014    
2024-02-17 13:35:11,344 - --- validate (epoch=222)-----------
2024-02-17 13:35:11,344 - 10000 samples (100 per mini-batch)
2024-02-17 13:35:16,978 - Epoch: [222][  100/  100]    Loss 4.624555    Top1 1.000000    Top5 5.000000    
2024-02-17 13:35:17,112 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.625

2024-02-17 13:35:17,122 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 222]
2024-02-17 13:35:17,123 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:35:17,184 - 

2024-02-17 13:35:17,185 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:35:26,636 - Epoch: [223][  100/  500]    Overall Loss 4.619978    Objective Loss 4.619978                                        LR 0.000063    Time 0.094460    
2024-02-17 13:35:35,720 - Epoch: [223][  200/  500]    Overall Loss 4.620590    Objective Loss 4.620590                                        LR 0.000063    Time 0.092631    
2024-02-17 13:35:44,946 - Epoch: [223][  300/  500]    Overall Loss 4.621026    Objective Loss 4.621026                                        LR 0.000063    Time 0.092495    
2024-02-17 13:35:54,082 - Epoch: [223][  400/  500]    Overall Loss 4.620998    Objective Loss 4.620998                                        LR 0.000063    Time 0.092201    
2024-02-17 13:36:03,173 - Epoch: [223][  500/  500]    Overall Loss 4.620814    Objective Loss 4.620814    Top1 2.000000    Top5 6.500000    LR 0.000063    Time 0.091935    
2024-02-17 13:36:03,317 - --- validate (epoch=223)-----------
2024-02-17 13:36:03,318 - 10000 samples (100 per mini-batch)
2024-02-17 13:36:09,186 - Epoch: [223][  100/  100]    Loss 4.620372    Top1 1.000000    Top5 5.000000    
2024-02-17 13:36:09,307 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.620

2024-02-17 13:36:09,317 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 223]
2024-02-17 13:36:09,318 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:36:09,402 - 

2024-02-17 13:36:09,403 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:36:19,057 - Epoch: [224][  100/  500]    Overall Loss 4.622783    Objective Loss 4.622783                                        LR 0.000063    Time 0.096468    
2024-02-17 13:36:28,263 - Epoch: [224][  200/  500]    Overall Loss 4.621219    Objective Loss 4.621219                                        LR 0.000063    Time 0.094241    
2024-02-17 13:36:37,522 - Epoch: [224][  300/  500]    Overall Loss 4.619966    Objective Loss 4.619966                                        LR 0.000063    Time 0.093679    
2024-02-17 13:36:46,577 - Epoch: [224][  400/  500]    Overall Loss 4.619673    Objective Loss 4.619673                                        LR 0.000063    Time 0.092886    
2024-02-17 13:36:55,265 - Epoch: [224][  500/  500]    Overall Loss 4.619508    Objective Loss 4.619508    Top1 1.000000    Top5 4.500000    LR 0.000063    Time 0.091679    
2024-02-17 13:36:55,455 - --- validate (epoch=224)-----------
2024-02-17 13:36:55,456 - 10000 samples (100 per mini-batch)
2024-02-17 13:37:01,182 - Epoch: [224][  100/  100]    Loss 4.616920    Top1 1.000000    Top5 5.000000    
2024-02-17 13:37:01,298 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.617

2024-02-17 13:37:01,308 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 224]
2024-02-17 13:37:01,309 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:37:01,374 - 

2024-02-17 13:37:01,374 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:37:10,922 - Epoch: [225][  100/  500]    Overall Loss 4.618667    Objective Loss 4.618667                                        LR 0.000063    Time 0.095428    
2024-02-17 13:37:20,000 - Epoch: [225][  200/  500]    Overall Loss 4.617093    Objective Loss 4.617093                                        LR 0.000063    Time 0.093085    
2024-02-17 13:37:29,114 - Epoch: [225][  300/  500]    Overall Loss 4.617094    Objective Loss 4.617094                                        LR 0.000063    Time 0.092423    
2024-02-17 13:37:38,026 - Epoch: [225][  400/  500]    Overall Loss 4.616344    Objective Loss 4.616344                                        LR 0.000063    Time 0.091589    
2024-02-17 13:37:47,264 - Epoch: [225][  500/  500]    Overall Loss 4.616322    Objective Loss 4.616322    Top1 2.000000    Top5 6.000000    LR 0.000063    Time 0.091739    
2024-02-17 13:37:47,378 - --- validate (epoch=225)-----------
2024-02-17 13:37:47,378 - 10000 samples (100 per mini-batch)
2024-02-17 13:37:52,778 - Epoch: [225][  100/  100]    Loss 4.614939    Top1 1.000000    Top5 5.000000    
2024-02-17 13:37:52,911 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.615

2024-02-17 13:37:52,922 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 225]
2024-02-17 13:37:52,923 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:37:52,991 - 

2024-02-17 13:37:52,991 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:38:02,924 - Epoch: [226][  100/  500]    Overall Loss 4.614178    Objective Loss 4.614178                                        LR 0.000063    Time 0.099277    
2024-02-17 13:38:12,164 - Epoch: [226][  200/  500]    Overall Loss 4.614001    Objective Loss 4.614001                                        LR 0.000063    Time 0.095820    
2024-02-17 13:38:21,174 - Epoch: [226][  300/  500]    Overall Loss 4.613960    Objective Loss 4.613960                                        LR 0.000063    Time 0.093899    
2024-02-17 13:38:30,323 - Epoch: [226][  400/  500]    Overall Loss 4.613748    Objective Loss 4.613748                                        LR 0.000063    Time 0.093287    
2024-02-17 13:38:39,299 - Epoch: [226][  500/  500]    Overall Loss 4.614374    Objective Loss 4.614374    Top1 0.000000    Top5 2.500000    LR 0.000063    Time 0.092574    
2024-02-17 13:38:39,431 - --- validate (epoch=226)-----------
2024-02-17 13:38:39,431 - 10000 samples (100 per mini-batch)
2024-02-17 13:38:45,188 - Epoch: [226][  100/  100]    Loss 4.616166    Top1 1.000000    Top5 5.000000    
2024-02-17 13:38:45,315 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.616

2024-02-17 13:38:45,325 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 226]
2024-02-17 13:38:45,326 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:38:45,392 - 

2024-02-17 13:38:45,392 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:38:54,952 - Epoch: [227][  100/  500]    Overall Loss 4.613437    Objective Loss 4.613437                                        LR 0.000063    Time 0.095543    
2024-02-17 13:39:04,034 - Epoch: [227][  200/  500]    Overall Loss 4.615406    Objective Loss 4.615406                                        LR 0.000063    Time 0.093165    
2024-02-17 13:39:12,813 - Epoch: [227][  300/  500]    Overall Loss 4.615242    Objective Loss 4.615242                                        LR 0.000063    Time 0.091360    
2024-02-17 13:39:21,910 - Epoch: [227][  400/  500]    Overall Loss 4.615235    Objective Loss 4.615235                                        LR 0.000063    Time 0.091254    
2024-02-17 13:39:31,072 - Epoch: [227][  500/  500]    Overall Loss 4.615056    Objective Loss 4.615056    Top1 0.000000    Top5 6.500000    LR 0.000063    Time 0.091319    
2024-02-17 13:39:31,247 - --- validate (epoch=227)-----------
2024-02-17 13:39:31,248 - 10000 samples (100 per mini-batch)
2024-02-17 13:39:37,505 - Epoch: [227][  100/  100]    Loss 4.615161    Top1 1.000000    Top5 5.000000    
2024-02-17 13:39:37,624 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.615

2024-02-17 13:39:37,630 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 227]
2024-02-17 13:39:37,630 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:39:37,691 - 

2024-02-17 13:39:37,692 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:39:47,600 - Epoch: [228][  100/  500]    Overall Loss 4.616103    Objective Loss 4.616103                                        LR 0.000063    Time 0.099027    
2024-02-17 13:39:56,787 - Epoch: [228][  200/  500]    Overall Loss 4.615205    Objective Loss 4.615205                                        LR 0.000063    Time 0.095429    
2024-02-17 13:40:05,921 - Epoch: [228][  300/  500]    Overall Loss 4.614283    Objective Loss 4.614283                                        LR 0.000063    Time 0.094051    
2024-02-17 13:40:15,085 - Epoch: [228][  400/  500]    Overall Loss 4.614301    Objective Loss 4.614301                                        LR 0.000063    Time 0.093440    
2024-02-17 13:40:24,437 - Epoch: [228][  500/  500]    Overall Loss 4.614027    Objective Loss 4.614027    Top1 0.000000    Top5 3.000000    LR 0.000063    Time 0.093447    
2024-02-17 13:40:24,558 - --- validate (epoch=228)-----------
2024-02-17 13:40:24,559 - 10000 samples (100 per mini-batch)
2024-02-17 13:40:30,205 - Epoch: [228][  100/  100]    Loss 4.613386    Top1 1.000000    Top5 5.000000    
2024-02-17 13:40:30,309 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.613

2024-02-17 13:40:30,319 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 228]
2024-02-17 13:40:30,320 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:40:30,385 - 

2024-02-17 13:40:30,385 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:40:40,029 - Epoch: [229][  100/  500]    Overall Loss 4.612126    Objective Loss 4.612126                                        LR 0.000063    Time 0.096383    
2024-02-17 13:40:49,186 - Epoch: [229][  200/  500]    Overall Loss 4.613709    Objective Loss 4.613709                                        LR 0.000063    Time 0.093956    
2024-02-17 13:40:58,020 - Epoch: [229][  300/  500]    Overall Loss 4.613374    Objective Loss 4.613374                                        LR 0.000063    Time 0.092072    
2024-02-17 13:41:07,287 - Epoch: [229][  400/  500]    Overall Loss 4.613257    Objective Loss 4.613257                                        LR 0.000063    Time 0.092212    
2024-02-17 13:41:16,074 - Epoch: [229][  500/  500]    Overall Loss 4.613093    Objective Loss 4.613093    Top1 2.000000    Top5 6.000000    LR 0.000063    Time 0.091336    
2024-02-17 13:41:16,216 - --- validate (epoch=229)-----------
2024-02-17 13:41:16,217 - 10000 samples (100 per mini-batch)
2024-02-17 13:41:22,478 - Epoch: [229][  100/  100]    Loss 4.612611    Top1 1.000000    Top5 5.000000    
2024-02-17 13:41:22,608 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.613

2024-02-17 13:41:22,616 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 229]
2024-02-17 13:41:22,616 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:41:22,695 - 

2024-02-17 13:41:22,695 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:41:32,187 - Epoch: [230][  100/  500]    Overall Loss 4.612166    Objective Loss 4.612166                                        LR 0.000063    Time 0.094852    
2024-02-17 13:41:41,217 - Epoch: [230][  200/  500]    Overall Loss 4.612475    Objective Loss 4.612475                                        LR 0.000063    Time 0.092559    
2024-02-17 13:41:50,296 - Epoch: [230][  300/  500]    Overall Loss 4.612313    Objective Loss 4.612313                                        LR 0.000063    Time 0.091955    
2024-02-17 13:41:59,557 - Epoch: [230][  400/  500]    Overall Loss 4.612350    Objective Loss 4.612350                                        LR 0.000063    Time 0.092109    
2024-02-17 13:42:08,651 - Epoch: [230][  500/  500]    Overall Loss 4.612210    Objective Loss 4.612210    Top1 0.500000    Top5 5.500000    LR 0.000063    Time 0.091868    
2024-02-17 13:42:08,813 - --- validate (epoch=230)-----------
2024-02-17 13:42:08,814 - 10000 samples (100 per mini-batch)
2024-02-17 13:42:15,045 - Epoch: [230][  100/  100]    Loss 4.612011    Top1 1.000000    Top5 5.000000    
2024-02-17 13:42:15,188 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.612

2024-02-17 13:42:15,198 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 230]
2024-02-17 13:42:15,198 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:42:15,263 - 

2024-02-17 13:42:15,263 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:42:25,096 - Epoch: [231][  100/  500]    Overall Loss 4.613463    Objective Loss 4.613463                                        LR 0.000063    Time 0.098273    
2024-02-17 13:42:34,226 - Epoch: [231][  200/  500]    Overall Loss 4.612542    Objective Loss 4.612542                                        LR 0.000063    Time 0.094766    
2024-02-17 13:42:43,423 - Epoch: [231][  300/  500]    Overall Loss 4.612797    Objective Loss 4.612797                                        LR 0.000063    Time 0.093822    
2024-02-17 13:42:52,646 - Epoch: [231][  400/  500]    Overall Loss 4.612467    Objective Loss 4.612467                                        LR 0.000063    Time 0.093414    
2024-02-17 13:43:02,015 - Epoch: [231][  500/  500]    Overall Loss 4.612060    Objective Loss 4.612060    Top1 0.500000    Top5 4.000000    LR 0.000063    Time 0.093461    
2024-02-17 13:43:02,121 - --- validate (epoch=231)-----------
2024-02-17 13:43:02,122 - 10000 samples (100 per mini-batch)
2024-02-17 13:43:07,835 - Epoch: [231][  100/  100]    Loss 4.611800    Top1 1.000000    Top5 5.000000    
2024-02-17 13:43:07,937 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.612

2024-02-17 13:43:07,946 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 231]
2024-02-17 13:43:07,947 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:43:08,023 - 

2024-02-17 13:43:08,023 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:43:17,901 - Epoch: [232][  100/  500]    Overall Loss 4.612284    Objective Loss 4.612284                                        LR 0.000063    Time 0.098714    
2024-02-17 13:43:27,074 - Epoch: [232][  200/  500]    Overall Loss 4.613261    Objective Loss 4.613261                                        LR 0.000063    Time 0.095203    
2024-02-17 13:43:36,233 - Epoch: [232][  300/  500]    Overall Loss 4.612991    Objective Loss 4.612991                                        LR 0.000063    Time 0.093984    
2024-02-17 13:43:45,359 - Epoch: [232][  400/  500]    Overall Loss 4.612855    Objective Loss 4.612855                                        LR 0.000063    Time 0.093293    
2024-02-17 13:43:54,633 - Epoch: [232][  500/  500]    Overall Loss 4.612562    Objective Loss 4.612562    Top1 1.000000    Top5 4.500000    LR 0.000063    Time 0.093175    
2024-02-17 13:43:54,763 - --- validate (epoch=232)-----------
2024-02-17 13:43:54,764 - 10000 samples (100 per mini-batch)
2024-02-17 13:43:59,933 - Epoch: [232][  100/  100]    Loss 4.612016    Top1 1.000000    Top5 5.000000    
2024-02-17 13:44:00,027 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.612

2024-02-17 13:44:00,036 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 232]
2024-02-17 13:44:00,036 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:44:00,087 - 

2024-02-17 13:44:00,087 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:44:09,361 - Epoch: [233][  100/  500]    Overall Loss 4.611549    Objective Loss 4.611549                                        LR 0.000063    Time 0.092695    
2024-02-17 13:44:18,428 - Epoch: [233][  200/  500]    Overall Loss 4.611950    Objective Loss 4.611950                                        LR 0.000063    Time 0.091662    
2024-02-17 13:44:27,489 - Epoch: [233][  300/  500]    Overall Loss 4.612156    Objective Loss 4.612156                                        LR 0.000063    Time 0.091297    
2024-02-17 13:44:36,619 - Epoch: [233][  400/  500]    Overall Loss 4.612422    Objective Loss 4.612422                                        LR 0.000063    Time 0.091289    
2024-02-17 13:44:45,722 - Epoch: [233][  500/  500]    Overall Loss 4.612502    Objective Loss 4.612502    Top1 2.000000    Top5 4.500000    LR 0.000063    Time 0.091230    
2024-02-17 13:44:45,833 - --- validate (epoch=233)-----------
2024-02-17 13:44:45,833 - 10000 samples (100 per mini-batch)
2024-02-17 13:44:51,769 - Epoch: [233][  100/  100]    Loss 4.613100    Top1 1.000000    Top5 5.000000    
2024-02-17 13:44:51,881 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.613

2024-02-17 13:44:51,893 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 233]
2024-02-17 13:44:51,893 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:44:51,964 - 

2024-02-17 13:44:51,964 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:45:01,758 - Epoch: [234][  100/  500]    Overall Loss 4.613371    Objective Loss 4.613371                                        LR 0.000063    Time 0.097886    
2024-02-17 13:45:11,254 - Epoch: [234][  200/  500]    Overall Loss 4.613407    Objective Loss 4.613407                                        LR 0.000063    Time 0.096401    
2024-02-17 13:45:20,228 - Epoch: [234][  300/  500]    Overall Loss 4.613258    Objective Loss 4.613258                                        LR 0.000063    Time 0.094169    
2024-02-17 13:45:29,199 - Epoch: [234][  400/  500]    Overall Loss 4.613813    Objective Loss 4.613813                                        LR 0.000063    Time 0.093045    
2024-02-17 13:45:37,571 - Epoch: [234][  500/  500]    Overall Loss 4.614230    Objective Loss 4.614230    Top1 1.000000    Top5 3.500000    LR 0.000063    Time 0.091174    
2024-02-17 13:45:37,679 - --- validate (epoch=234)-----------
2024-02-17 13:45:37,679 - 10000 samples (100 per mini-batch)
2024-02-17 13:45:43,507 - Epoch: [234][  100/  100]    Loss 4.613986    Top1 1.000000    Top5 5.000000    
2024-02-17 13:45:43,635 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.614

2024-02-17 13:45:43,643 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:45:43,644 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:45:43,707 - 

2024-02-17 13:45:43,708 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:45:53,306 - Epoch: [235][  100/  500]    Overall Loss 4.613498    Objective Loss 4.613498                                        LR 0.000063    Time 0.095926    
2024-02-17 13:46:02,468 - Epoch: [235][  200/  500]    Overall Loss 4.612948    Objective Loss 4.612948                                        LR 0.000063    Time 0.093751    
2024-02-17 13:46:11,091 - Epoch: [235][  300/  500]    Overall Loss 4.613409    Objective Loss 4.613409                                        LR 0.000063    Time 0.091233    
2024-02-17 13:46:20,316 - Epoch: [235][  400/  500]    Overall Loss 4.613349    Objective Loss 4.613349                                        LR 0.000063    Time 0.091477    
2024-02-17 13:46:29,469 - Epoch: [235][  500/  500]    Overall Loss 4.613572    Objective Loss 4.613572    Top1 1.500000    Top5 5.000000    LR 0.000063    Time 0.091479    
2024-02-17 13:46:29,610 - --- validate (epoch=235)-----------
2024-02-17 13:46:29,610 - 10000 samples (100 per mini-batch)
2024-02-17 13:46:35,655 - Epoch: [235][  100/  100]    Loss 4.613505    Top1 1.000000    Top5 5.000000    
2024-02-17 13:46:35,819 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.614

2024-02-17 13:46:35,829 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 235]
2024-02-17 13:46:35,830 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:46:35,892 - 

2024-02-17 13:46:35,892 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:46:45,925 - Epoch: [236][  100/  500]    Overall Loss 4.616255    Objective Loss 4.616255                                        LR 0.000063    Time 0.100283    
2024-02-17 13:46:54,828 - Epoch: [236][  200/  500]    Overall Loss 4.614068    Objective Loss 4.614068                                        LR 0.000063    Time 0.094634    
2024-02-17 13:47:03,730 - Epoch: [236][  300/  500]    Overall Loss 4.613940    Objective Loss 4.613940                                        LR 0.000063    Time 0.092751    
2024-02-17 13:47:12,941 - Epoch: [236][  400/  500]    Overall Loss 4.613990    Objective Loss 4.613990                                        LR 0.000063    Time 0.092581    
2024-02-17 13:47:22,115 - Epoch: [236][  500/  500]    Overall Loss 4.614043    Objective Loss 4.614043    Top1 0.000000    Top5 5.500000    LR 0.000063    Time 0.092404    
2024-02-17 13:47:22,297 - --- validate (epoch=236)-----------
2024-02-17 13:47:22,298 - 10000 samples (100 per mini-batch)
2024-02-17 13:47:27,829 - Epoch: [236][  100/  100]    Loss 4.612963    Top1 1.000000    Top5 5.000000    
2024-02-17 13:47:27,966 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.613

2024-02-17 13:47:27,972 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 236]
2024-02-17 13:47:27,973 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:47:28,036 - 

2024-02-17 13:47:28,036 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:47:37,530 - Epoch: [237][  100/  500]    Overall Loss 4.612379    Objective Loss 4.612379                                        LR 0.000063    Time 0.094894    
2024-02-17 13:47:46,661 - Epoch: [237][  200/  500]    Overall Loss 4.612557    Objective Loss 4.612557                                        LR 0.000063    Time 0.093082    
2024-02-17 13:47:55,872 - Epoch: [237][  300/  500]    Overall Loss 4.612866    Objective Loss 4.612866                                        LR 0.000063    Time 0.092746    
2024-02-17 13:48:05,095 - Epoch: [237][  400/  500]    Overall Loss 4.612937    Objective Loss 4.612937                                        LR 0.000063    Time 0.092606    
2024-02-17 13:48:14,273 - Epoch: [237][  500/  500]    Overall Loss 4.612977    Objective Loss 4.612977    Top1 0.000000    Top5 4.500000    LR 0.000063    Time 0.092431    
2024-02-17 13:48:14,400 - --- validate (epoch=237)-----------
2024-02-17 13:48:14,401 - 10000 samples (100 per mini-batch)
2024-02-17 13:48:19,771 - Epoch: [237][  100/  100]    Loss 4.612823    Top1 1.000000    Top5 5.000000    
2024-02-17 13:48:19,884 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.613

2024-02-17 13:48:19,893 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 237]
2024-02-17 13:48:19,893 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:48:19,959 - 

2024-02-17 13:48:19,959 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:48:29,787 - Epoch: [238][  100/  500]    Overall Loss 4.613091    Objective Loss 4.613091                                        LR 0.000063    Time 0.098234    
2024-02-17 13:48:38,935 - Epoch: [238][  200/  500]    Overall Loss 4.613240    Objective Loss 4.613240                                        LR 0.000063    Time 0.094836    
2024-02-17 13:48:48,068 - Epoch: [238][  300/  500]    Overall Loss 4.613293    Objective Loss 4.613293                                        LR 0.000063    Time 0.093653    
2024-02-17 13:48:56,970 - Epoch: [238][  400/  500]    Overall Loss 4.612683    Objective Loss 4.612683                                        LR 0.000063    Time 0.092483    
2024-02-17 13:49:06,251 - Epoch: [238][  500/  500]    Overall Loss 4.612707    Objective Loss 4.612707    Top1 1.000000    Top5 2.500000    LR 0.000063    Time 0.092540    
2024-02-17 13:49:06,379 - --- validate (epoch=238)-----------
2024-02-17 13:49:06,380 - 10000 samples (100 per mini-batch)
2024-02-17 13:49:11,839 - Epoch: [238][  100/  100]    Loss 4.612187    Top1 1.000000    Top5 5.000000    
2024-02-17 13:49:11,962 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.612

2024-02-17 13:49:11,971 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 238]
2024-02-17 13:49:11,972 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:49:12,035 - 

2024-02-17 13:49:12,035 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:49:21,505 - Epoch: [239][  100/  500]    Overall Loss 4.611914    Objective Loss 4.611914                                        LR 0.000063    Time 0.094645    
2024-02-17 13:49:30,576 - Epoch: [239][  200/  500]    Overall Loss 4.612515    Objective Loss 4.612515                                        LR 0.000063    Time 0.092657    
2024-02-17 13:49:39,672 - Epoch: [239][  300/  500]    Overall Loss 4.612822    Objective Loss 4.612822                                        LR 0.000063    Time 0.092079    
2024-02-17 13:49:48,917 - Epoch: [239][  400/  500]    Overall Loss 4.613022    Objective Loss 4.613022                                        LR 0.000063    Time 0.092164    
2024-02-17 13:49:58,221 - Epoch: [239][  500/  500]    Overall Loss 4.612622    Objective Loss 4.612622    Top1 1.000000    Top5 5.000000    LR 0.000063    Time 0.092329    
2024-02-17 13:49:58,360 - --- validate (epoch=239)-----------
2024-02-17 13:49:58,361 - 10000 samples (100 per mini-batch)
2024-02-17 13:50:04,433 - Epoch: [239][  100/  100]    Loss 4.611875    Top1 1.000000    Top5 5.000000    
2024-02-17 13:50:04,533 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.612

2024-02-17 13:50:04,542 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 239]
2024-02-17 13:50:04,543 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:50:04,608 - 

2024-02-17 13:50:04,609 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:50:14,451 - Epoch: [240][  100/  500]    Overall Loss 4.612290    Objective Loss 4.612290                                        LR 0.000063    Time 0.098376    
2024-02-17 13:50:23,563 - Epoch: [240][  200/  500]    Overall Loss 4.612526    Objective Loss 4.612526                                        LR 0.000063    Time 0.094728    
2024-02-17 13:50:32,690 - Epoch: [240][  300/  500]    Overall Loss 4.613065    Objective Loss 4.613065                                        LR 0.000063    Time 0.093559    
2024-02-17 13:50:42,012 - Epoch: [240][  400/  500]    Overall Loss 4.612840    Objective Loss 4.612840                                        LR 0.000063    Time 0.093465    
2024-02-17 13:50:51,106 - Epoch: [240][  500/  500]    Overall Loss 4.612653    Objective Loss 4.612653    Top1 0.500000    Top5 3.000000    LR 0.000063    Time 0.092951    
2024-02-17 13:50:51,253 - --- validate (epoch=240)-----------
2024-02-17 13:50:51,255 - 10000 samples (100 per mini-batch)
2024-02-17 13:50:57,149 - Epoch: [240][  100/  100]    Loss 4.610782    Top1 1.000000    Top5 5.000000    
2024-02-17 13:50:57,261 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.611

2024-02-17 13:50:57,270 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 240]
2024-02-17 13:50:57,270 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:50:57,347 - 

2024-02-17 13:50:57,347 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:51:06,946 - Epoch: [241][  100/  500]    Overall Loss 4.612375    Objective Loss 4.612375                                        LR 0.000063    Time 0.095929    
2024-02-17 13:51:16,079 - Epoch: [241][  200/  500]    Overall Loss 4.611651    Objective Loss 4.611651                                        LR 0.000063    Time 0.093608    
2024-02-17 13:51:25,352 - Epoch: [241][  300/  500]    Overall Loss 4.611119    Objective Loss 4.611119                                        LR 0.000063    Time 0.093301    
2024-02-17 13:51:34,449 - Epoch: [241][  400/  500]    Overall Loss 4.611173    Objective Loss 4.611173                                        LR 0.000063    Time 0.092709    
2024-02-17 13:51:43,833 - Epoch: [241][  500/  500]    Overall Loss 4.610579    Objective Loss 4.610579    Top1 0.500000    Top5 4.000000    LR 0.000063    Time 0.092926    
2024-02-17 13:51:43,981 - --- validate (epoch=241)-----------
2024-02-17 13:51:43,982 - 10000 samples (100 per mini-batch)
2024-02-17 13:51:49,511 - Epoch: [241][  100/  100]    Loss 4.609542    Top1 1.000000    Top5 5.000000    
2024-02-17 13:51:49,629 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.610

2024-02-17 13:51:49,639 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 241]
2024-02-17 13:51:49,640 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:51:49,705 - 

2024-02-17 13:51:49,705 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:51:59,043 - Epoch: [242][  100/  500]    Overall Loss 4.611150    Objective Loss 4.611150                                        LR 0.000063    Time 0.093329    
2024-02-17 13:52:08,065 - Epoch: [242][  200/  500]    Overall Loss 4.610592    Objective Loss 4.610592                                        LR 0.000063    Time 0.091756    
2024-02-17 13:52:17,244 - Epoch: [242][  300/  500]    Overall Loss 4.609809    Objective Loss 4.609809                                        LR 0.000063    Time 0.091755    
2024-02-17 13:52:26,397 - Epoch: [242][  400/  500]    Overall Loss 4.609666    Objective Loss 4.609666                                        LR 0.000063    Time 0.091687    
2024-02-17 13:52:35,815 - Epoch: [242][  500/  500]    Overall Loss 4.609391    Objective Loss 4.609391    Top1 0.500000    Top5 4.000000    LR 0.000063    Time 0.092178    
2024-02-17 13:52:36,006 - --- validate (epoch=242)-----------
2024-02-17 13:52:36,007 - 10000 samples (100 per mini-batch)
2024-02-17 13:52:41,738 - Epoch: [242][  100/  100]    Loss 4.607562    Top1 1.000000    Top5 5.000000    
2024-02-17 13:52:41,877 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.608

2024-02-17 13:52:41,888 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 242]
2024-02-17 13:52:41,889 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:52:41,955 - 

2024-02-17 13:52:41,955 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:52:51,842 - Epoch: [243][  100/  500]    Overall Loss 4.607693    Objective Loss 4.607693                                        LR 0.000063    Time 0.098815    
2024-02-17 13:53:00,543 - Epoch: [243][  200/  500]    Overall Loss 4.607110    Objective Loss 4.607110                                        LR 0.000063    Time 0.092897    
2024-02-17 13:53:09,107 - Epoch: [243][  300/  500]    Overall Loss 4.607472    Objective Loss 4.607472                                        LR 0.000063    Time 0.090468    
2024-02-17 13:53:17,940 - Epoch: [243][  400/  500]    Overall Loss 4.607340    Objective Loss 4.607340                                        LR 0.000063    Time 0.089924    
2024-02-17 13:53:27,012 - Epoch: [243][  500/  500]    Overall Loss 4.607460    Objective Loss 4.607460    Top1 2.500000    Top5 6.000000    LR 0.000063    Time 0.090077    
2024-02-17 13:53:27,120 - --- validate (epoch=243)-----------
2024-02-17 13:53:27,120 - 10000 samples (100 per mini-batch)
2024-02-17 13:53:32,657 - Epoch: [243][  100/  100]    Loss 4.607562    Top1 1.000000    Top5 5.000000    
2024-02-17 13:53:32,777 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.608

2024-02-17 13:53:32,787 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 243]
2024-02-17 13:53:32,787 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:53:32,861 - 

2024-02-17 13:53:32,861 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:53:42,638 - Epoch: [244][  100/  500]    Overall Loss 4.607292    Objective Loss 4.607292                                        LR 0.000063    Time 0.097711    
2024-02-17 13:53:51,710 - Epoch: [244][  200/  500]    Overall Loss 4.607724    Objective Loss 4.607724                                        LR 0.000063    Time 0.094200    
2024-02-17 13:54:00,705 - Epoch: [244][  300/  500]    Overall Loss 4.607737    Objective Loss 4.607737                                        LR 0.000063    Time 0.092771    
2024-02-17 13:54:09,748 - Epoch: [244][  400/  500]    Overall Loss 4.607498    Objective Loss 4.607498                                        LR 0.000063    Time 0.092176    
2024-02-17 13:54:19,056 - Epoch: [244][  500/  500]    Overall Loss 4.607289    Objective Loss 4.607289    Top1 0.000000    Top5 3.500000    LR 0.000063    Time 0.092348    
2024-02-17 13:54:19,184 - --- validate (epoch=244)-----------
2024-02-17 13:54:19,185 - 10000 samples (100 per mini-batch)
2024-02-17 13:54:25,566 - Epoch: [244][  100/  100]    Loss 4.606547    Top1 1.000000    Top5 5.000000    
2024-02-17 13:54:25,688 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.607

2024-02-17 13:54:25,700 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 244]
2024-02-17 13:54:25,701 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:54:25,767 - 

2024-02-17 13:54:25,767 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:54:35,457 - Epoch: [245][  100/  500]    Overall Loss 4.605871    Objective Loss 4.605871                                        LR 0.000063    Time 0.096839    
2024-02-17 13:54:44,601 - Epoch: [245][  200/  500]    Overall Loss 4.606939    Objective Loss 4.606939                                        LR 0.000063    Time 0.094122    
2024-02-17 13:54:53,335 - Epoch: [245][  300/  500]    Overall Loss 4.606709    Objective Loss 4.606709                                        LR 0.000063    Time 0.091851    
2024-02-17 13:55:02,378 - Epoch: [245][  400/  500]    Overall Loss 4.606740    Objective Loss 4.606740                                        LR 0.000063    Time 0.091484    
2024-02-17 13:55:11,618 - Epoch: [245][  500/  500]    Overall Loss 4.606599    Objective Loss 4.606599    Top1 2.000000    Top5 7.000000    LR 0.000063    Time 0.091659    
2024-02-17 13:55:11,732 - --- validate (epoch=245)-----------
2024-02-17 13:55:11,733 - 10000 samples (100 per mini-batch)
2024-02-17 13:55:17,743 - Epoch: [245][  100/  100]    Loss 4.606283    Top1 1.000000    Top5 5.000000    
2024-02-17 13:55:17,862 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.606

2024-02-17 13:55:17,872 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 245]
2024-02-17 13:55:17,872 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:55:17,940 - 

2024-02-17 13:55:17,941 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:55:27,673 - Epoch: [246][  100/  500]    Overall Loss 4.606112    Objective Loss 4.606112                                        LR 0.000063    Time 0.097270    
2024-02-17 13:55:36,410 - Epoch: [246][  200/  500]    Overall Loss 4.606639    Objective Loss 4.606639                                        LR 0.000063    Time 0.092304    
2024-02-17 13:55:45,144 - Epoch: [246][  300/  500]    Overall Loss 4.606444    Objective Loss 4.606444                                        LR 0.000063    Time 0.090637    
2024-02-17 13:55:54,172 - Epoch: [246][  400/  500]    Overall Loss 4.606312    Objective Loss 4.606312                                        LR 0.000063    Time 0.090539    
2024-02-17 13:56:03,371 - Epoch: [246][  500/  500]    Overall Loss 4.606397    Objective Loss 4.606397    Top1 1.000000    Top5 6.000000    LR 0.000063    Time 0.090820    
2024-02-17 13:56:03,542 - --- validate (epoch=246)-----------
2024-02-17 13:56:03,543 - 10000 samples (100 per mini-batch)
2024-02-17 13:56:09,758 - Epoch: [246][  100/  100]    Loss 4.606283    Top1 1.000000    Top5 5.000000    
2024-02-17 13:56:09,882 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.606

2024-02-17 13:56:09,887 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 13:56:09,888 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:56:09,968 - 

2024-02-17 13:56:09,968 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:56:19,685 - Epoch: [247][  100/  500]    Overall Loss 4.606065    Objective Loss 4.606065                                        LR 0.000063    Time 0.097115    
2024-02-17 13:56:28,826 - Epoch: [247][  200/  500]    Overall Loss 4.606370    Objective Loss 4.606370                                        LR 0.000063    Time 0.094242    
2024-02-17 13:56:38,045 - Epoch: [247][  300/  500]    Overall Loss 4.606105    Objective Loss 4.606105                                        LR 0.000063    Time 0.093542    
2024-02-17 13:56:47,329 - Epoch: [247][  400/  500]    Overall Loss 4.605871    Objective Loss 4.605871                                        LR 0.000063    Time 0.093357    
2024-02-17 13:56:56,509 - Epoch: [247][  500/  500]    Overall Loss 4.605752    Objective Loss 4.605752    Top1 3.000000    Top5 7.500000    LR 0.000063    Time 0.093039    
2024-02-17 13:56:56,630 - --- validate (epoch=247)-----------
2024-02-17 13:56:56,631 - 10000 samples (100 per mini-batch)
2024-02-17 13:57:01,627 - Epoch: [247][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 13:57:01,746 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 13:57:01,755 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 247]
2024-02-17 13:57:01,755 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:57:01,811 - 

2024-02-17 13:57:01,811 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:57:10,868 - Epoch: [248][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090526    
2024-02-17 13:57:19,914 - Epoch: [248][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090473    
2024-02-17 13:57:28,946 - Epoch: [248][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090412    
2024-02-17 13:57:38,205 - Epoch: [248][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090947    
2024-02-17 13:57:47,238 - Epoch: [248][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 2.500000    Top5 5.500000    LR 0.000063    Time 0.090815    
2024-02-17 13:57:47,397 - --- validate (epoch=248)-----------
2024-02-17 13:57:47,398 - 10000 samples (100 per mini-batch)
2024-02-17 13:57:53,324 - Epoch: [248][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 13:57:53,469 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 13:57:53,479 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 248]
2024-02-17 13:57:53,480 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:57:53,544 - 

2024-02-17 13:57:53,545 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:58:03,149 - Epoch: [249][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095990    
2024-02-17 13:58:12,274 - Epoch: [249][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093599    
2024-02-17 13:58:21,336 - Epoch: [249][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092595    
2024-02-17 13:58:30,070 - Epoch: [249][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091272    
2024-02-17 13:58:39,277 - Epoch: [249][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.000000    Top5 2.500000    LR 0.000063    Time 0.091425    
2024-02-17 13:58:39,451 - --- validate (epoch=249)-----------
2024-02-17 13:58:39,452 - 10000 samples (100 per mini-batch)
2024-02-17 13:58:44,718 - Epoch: [249][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 13:58:44,863 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 13:58:44,871 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 249]
2024-02-17 13:58:44,871 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:58:44,936 - 

2024-02-17 13:58:44,936 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:58:54,577 - Epoch: [250][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.096347    
2024-02-17 13:59:03,511 - Epoch: [250][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092828    
2024-02-17 13:59:12,585 - Epoch: [250][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092118    
2024-02-17 13:59:21,755 - Epoch: [250][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092004    
2024-02-17 13:59:30,925 - Epoch: [250][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 4.000000    LR 0.000063    Time 0.091934    
2024-02-17 13:59:31,050 - --- validate (epoch=250)-----------
2024-02-17 13:59:31,050 - 10000 samples (100 per mini-batch)
2024-02-17 13:59:36,648 - Epoch: [250][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 13:59:36,772 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 13:59:36,783 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 250]
2024-02-17 13:59:36,783 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 13:59:36,850 - 

2024-02-17 13:59:36,850 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:59:46,455 - Epoch: [251][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095998    
2024-02-17 13:59:55,607 - Epoch: [251][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093740    
2024-02-17 14:00:04,876 - Epoch: [251][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093376    
2024-02-17 14:00:14,094 - Epoch: [251][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093067    
2024-02-17 14:00:23,403 - Epoch: [251][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.000000    Top5 4.500000    LR 0.000063    Time 0.093063    
2024-02-17 14:00:23,584 - --- validate (epoch=251)-----------
2024-02-17 14:00:23,585 - 10000 samples (100 per mini-batch)
2024-02-17 14:00:29,579 - Epoch: [251][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:00:29,712 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:00:29,720 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 251]
2024-02-17 14:00:29,720 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:00:29,785 - 

2024-02-17 14:00:29,785 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:00:39,579 - Epoch: [252][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.097886    
2024-02-17 14:00:48,655 - Epoch: [252][  200/  500]    Overall Loss 4.605258    Objective Loss 4.605258                                        LR 0.000063    Time 0.094300    
2024-02-17 14:00:57,707 - Epoch: [252][  300/  500]    Overall Loss 4.605230    Objective Loss 4.605230                                        LR 0.000063    Time 0.093030    
2024-02-17 14:01:06,873 - Epoch: [252][  400/  500]    Overall Loss 4.605216    Objective Loss 4.605216                                        LR 0.000063    Time 0.092678    
2024-02-17 14:01:16,092 - Epoch: [252][  500/  500]    Overall Loss 4.605207    Objective Loss 4.605207    Top1 1.000000    Top5 5.000000    LR 0.000063    Time 0.092571    
2024-02-17 14:01:16,218 - --- validate (epoch=252)-----------
2024-02-17 14:01:16,219 - 10000 samples (100 per mini-batch)
2024-02-17 14:01:21,825 - Epoch: [252][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:01:21,982 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:01:21,993 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 252]
2024-02-17 14:01:21,993 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:01:22,067 - 

2024-02-17 14:01:22,067 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:01:31,709 - Epoch: [253][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.096355    
2024-02-17 14:01:40,793 - Epoch: [253][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093580    
2024-02-17 14:01:50,042 - Epoch: [253][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093204    
2024-02-17 14:01:59,238 - Epoch: [253][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092882    
2024-02-17 14:02:08,520 - Epoch: [253][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.000000    Top5 5.000000    LR 0.000063    Time 0.092863    
2024-02-17 14:02:08,662 - --- validate (epoch=253)-----------
2024-02-17 14:02:08,663 - 10000 samples (100 per mini-batch)
2024-02-17 14:02:14,240 - Epoch: [253][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:02:14,425 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:02:14,435 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 253]
2024-02-17 14:02:14,436 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:02:14,502 - 

2024-02-17 14:02:14,502 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:02:24,277 - Epoch: [254][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.097691    
2024-02-17 14:02:33,402 - Epoch: [254][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094452    
2024-02-17 14:02:42,556 - Epoch: [254][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093467    
2024-02-17 14:02:51,733 - Epoch: [254][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093034    
2024-02-17 14:03:00,883 - Epoch: [254][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.000000    Top5 6.500000    LR 0.000063    Time 0.092718    
2024-02-17 14:03:01,071 - --- validate (epoch=254)-----------
2024-02-17 14:03:01,072 - 10000 samples (100 per mini-batch)
2024-02-17 14:03:06,705 - Epoch: [254][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:03:06,832 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:03:06,843 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 254]
2024-02-17 14:03:06,844 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:03:06,909 - 

2024-02-17 14:03:06,909 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:03:16,410 - Epoch: [255][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094957    
2024-02-17 14:03:25,509 - Epoch: [255][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092955    
2024-02-17 14:03:34,693 - Epoch: [255][  300/  500]    Overall Loss 4.605205    Objective Loss 4.605205                                        LR 0.000063    Time 0.092569    
2024-02-17 14:03:43,817 - Epoch: [255][  400/  500]    Overall Loss 4.605196    Objective Loss 4.605196                                        LR 0.000063    Time 0.092226    
2024-02-17 14:03:53,244 - Epoch: [255][  500/  500]    Overall Loss 4.605191    Objective Loss 4.605191    Top1 1.500000    Top5 7.500000    LR 0.000063    Time 0.092627    
2024-02-17 14:03:53,397 - --- validate (epoch=255)-----------
2024-02-17 14:03:53,397 - 10000 samples (100 per mini-batch)
2024-02-17 14:03:58,938 - Epoch: [255][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:03:59,080 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:03:59,090 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 255]
2024-02-17 14:03:59,091 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:03:59,153 - 

2024-02-17 14:03:59,154 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:04:08,681 - Epoch: [256][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095225    
2024-02-17 14:04:17,772 - Epoch: [256][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093047    
2024-02-17 14:04:26,873 - Epoch: [256][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092353    
2024-02-17 14:04:35,804 - Epoch: [256][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091584    
2024-02-17 14:04:45,112 - Epoch: [256][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 2.000000    Top5 5.500000    LR 0.000063    Time 0.091876    
2024-02-17 14:04:45,256 - --- validate (epoch=256)-----------
2024-02-17 14:04:45,257 - 10000 samples (100 per mini-batch)
2024-02-17 14:04:51,920 - Epoch: [256][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:04:52,071 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:04:52,083 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 256]
2024-02-17 14:04:52,084 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:04:52,150 - 

2024-02-17 14:04:52,151 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:05:01,755 - Epoch: [257][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095995    
2024-02-17 14:05:10,955 - Epoch: [257][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093977    
2024-02-17 14:05:20,173 - Epoch: [257][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093362    
2024-02-17 14:05:29,176 - Epoch: [257][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092520    
2024-02-17 14:05:38,095 - Epoch: [257][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 4.000000    LR 0.000063    Time 0.091848    
2024-02-17 14:05:38,193 - --- validate (epoch=257)-----------
2024-02-17 14:05:38,194 - 10000 samples (100 per mini-batch)
2024-02-17 14:05:43,684 - Epoch: [257][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:05:43,784 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:05:43,797 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 257]
2024-02-17 14:05:43,797 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:05:43,865 - 

2024-02-17 14:05:43,865 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:05:53,459 - Epoch: [258][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095893    
2024-02-17 14:06:02,569 - Epoch: [258][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093476    
2024-02-17 14:06:11,592 - Epoch: [258][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092383    
2024-02-17 14:06:20,413 - Epoch: [258][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091331    
2024-02-17 14:06:29,602 - Epoch: [258][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.000000    Top5 5.000000    LR 0.000063    Time 0.091433    
2024-02-17 14:06:29,766 - --- validate (epoch=258)-----------
2024-02-17 14:06:29,767 - 10000 samples (100 per mini-batch)
2024-02-17 14:06:35,535 - Epoch: [258][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:06:35,643 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:06:35,654 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 258]
2024-02-17 14:06:35,655 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:06:35,720 - 

2024-02-17 14:06:35,720 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:06:45,097 - Epoch: [259][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093718    
2024-02-17 14:06:53,697 - Epoch: [259][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.089845    
2024-02-17 14:07:02,485 - Epoch: [259][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.089179    
2024-02-17 14:07:11,573 - Epoch: [259][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.089595    
2024-02-17 14:07:20,829 - Epoch: [259][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.500000    Top5 6.000000    LR 0.000063    Time 0.090180    
2024-02-17 14:07:20,998 - --- validate (epoch=259)-----------
2024-02-17 14:07:20,999 - 10000 samples (100 per mini-batch)
2024-02-17 14:07:27,180 - Epoch: [259][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:07:27,295 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:07:27,307 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 259]
2024-02-17 14:07:27,307 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:07:27,373 - 

2024-02-17 14:07:27,374 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:07:36,755 - Epoch: [260][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093759    
2024-02-17 14:07:46,027 - Epoch: [260][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093221    
2024-02-17 14:07:55,043 - Epoch: [260][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092189    
2024-02-17 14:08:04,136 - Epoch: [260][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091866    
2024-02-17 14:08:13,295 - Epoch: [260][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 5.000000    LR 0.000063    Time 0.091803    
2024-02-17 14:08:13,421 - --- validate (epoch=260)-----------
2024-02-17 14:08:13,421 - 10000 samples (100 per mini-batch)
2024-02-17 14:08:18,924 - Epoch: [260][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:08:19,058 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:08:19,068 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 260]
2024-02-17 14:08:19,069 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:08:19,123 - 

2024-02-17 14:08:19,123 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:08:28,141 - Epoch: [261][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090141    
2024-02-17 14:08:37,148 - Epoch: [261][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090085    
2024-02-17 14:08:46,327 - Epoch: [261][  300/  500]    Overall Loss 4.605235    Objective Loss 4.605235                                        LR 0.000063    Time 0.090640    
2024-02-17 14:08:55,587 - Epoch: [261][  400/  500]    Overall Loss 4.605219    Objective Loss 4.605219                                        LR 0.000063    Time 0.091121    
2024-02-17 14:09:04,819 - Epoch: [261][  500/  500]    Overall Loss 4.605210    Objective Loss 4.605210    Top1 0.500000    Top5 6.500000    LR 0.000063    Time 0.091352    
2024-02-17 14:09:04,965 - --- validate (epoch=261)-----------
2024-02-17 14:09:04,966 - 10000 samples (100 per mini-batch)
2024-02-17 14:09:10,719 - Epoch: [261][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:09:10,829 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:09:10,839 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 261]
2024-02-17 14:09:10,840 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:09:10,904 - 

2024-02-17 14:09:10,905 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:09:20,839 - Epoch: [262][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.099293    
2024-02-17 14:09:30,057 - Epoch: [262][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095713    
2024-02-17 14:09:39,141 - Epoch: [262][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094076    
2024-02-17 14:09:48,251 - Epoch: [262][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093324    
2024-02-17 14:09:57,325 - Epoch: [262][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 3.000000    LR 0.000063    Time 0.092800    
2024-02-17 14:09:57,433 - --- validate (epoch=262)-----------
2024-02-17 14:09:57,434 - 10000 samples (100 per mini-batch)
2024-02-17 14:10:03,714 - Epoch: [262][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:10:03,811 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:10:03,821 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 262]
2024-02-17 14:10:03,821 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:10:03,886 - 

2024-02-17 14:10:03,887 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:10:13,522 - Epoch: [263][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.096301    
2024-02-17 14:10:22,666 - Epoch: [263][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093848    
2024-02-17 14:10:31,840 - Epoch: [263][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093133    
2024-02-17 14:10:40,997 - Epoch: [263][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092733    
2024-02-17 14:10:50,219 - Epoch: [263][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.000000    Top5 4.500000    LR 0.000063    Time 0.092623    
2024-02-17 14:10:50,409 - --- validate (epoch=263)-----------
2024-02-17 14:10:50,410 - 10000 samples (100 per mini-batch)
2024-02-17 14:10:55,928 - Epoch: [263][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:10:56,056 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:10:56,068 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 263]
2024-02-17 14:10:56,068 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:10:56,136 - 

2024-02-17 14:10:56,137 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:11:06,095 - Epoch: [264][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.099531    
2024-02-17 14:11:15,158 - Epoch: [264][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095058    
2024-02-17 14:11:24,290 - Epoch: [264][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093800    
2024-02-17 14:11:33,068 - Epoch: [264][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092285    
2024-02-17 14:11:42,175 - Epoch: [264][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 2.500000    Top5 6.000000    LR 0.000063    Time 0.092035    
2024-02-17 14:11:42,303 - --- validate (epoch=264)-----------
2024-02-17 14:11:42,303 - 10000 samples (100 per mini-batch)
2024-02-17 14:11:47,541 - Epoch: [264][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:11:47,691 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:11:47,701 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 264]
2024-02-17 14:11:47,701 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:11:47,766 - 

2024-02-17 14:11:47,766 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:11:57,367 - Epoch: [265][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095953    
2024-02-17 14:12:06,343 - Epoch: [265][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092838    
2024-02-17 14:12:15,041 - Epoch: [265][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090873    
2024-02-17 14:12:23,970 - Epoch: [265][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090470    
2024-02-17 14:12:33,234 - Epoch: [265][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.000000    Top5 5.000000    LR 0.000063    Time 0.090895    
2024-02-17 14:12:33,402 - --- validate (epoch=265)-----------
2024-02-17 14:12:33,402 - 10000 samples (100 per mini-batch)
2024-02-17 14:12:39,039 - Epoch: [265][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:12:39,126 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:12:39,137 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 265]
2024-02-17 14:12:39,138 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:12:39,191 - 

2024-02-17 14:12:39,191 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:12:48,296 - Epoch: [266][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091005    
2024-02-17 14:12:57,369 - Epoch: [266][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090850    
2024-02-17 14:13:06,687 - Epoch: [266][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091612    
2024-02-17 14:13:15,892 - Epoch: [266][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091710    
2024-02-17 14:13:25,180 - Epoch: [266][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 5.500000    LR 0.000063    Time 0.091936    
2024-02-17 14:13:25,296 - --- validate (epoch=266)-----------
2024-02-17 14:13:25,297 - 10000 samples (100 per mini-batch)
2024-02-17 14:13:31,151 - Epoch: [266][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:13:31,260 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:13:31,271 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 266]
2024-02-17 14:13:31,271 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:13:31,338 - 

2024-02-17 14:13:31,339 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:13:40,857 - Epoch: [267][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095136    
2024-02-17 14:13:49,908 - Epoch: [267][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092803    
2024-02-17 14:13:58,977 - Epoch: [267][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092088    
2024-02-17 14:14:08,039 - Epoch: [267][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091709    
2024-02-17 14:14:16,957 - Epoch: [267][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 4.000000    LR 0.000063    Time 0.091198    
2024-02-17 14:14:17,064 - --- validate (epoch=267)-----------
2024-02-17 14:14:17,064 - 10000 samples (100 per mini-batch)
2024-02-17 14:14:23,161 - Epoch: [267][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:14:23,285 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:14:23,296 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 267]
2024-02-17 14:14:23,297 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:14:23,363 - 

2024-02-17 14:14:23,363 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:14:32,940 - Epoch: [268][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095711    
2024-02-17 14:14:41,784 - Epoch: [268][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092059    
2024-02-17 14:14:50,233 - Epoch: [268][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.089527    
2024-02-17 14:14:59,199 - Epoch: [268][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.089550    
2024-02-17 14:15:08,391 - Epoch: [268][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 3.500000    LR 0.000063    Time 0.090016    
2024-02-17 14:15:08,526 - --- validate (epoch=268)-----------
2024-02-17 14:15:08,527 - 10000 samples (100 per mini-batch)
2024-02-17 14:15:14,624 - Epoch: [268][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:15:14,771 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:15:14,781 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 268]
2024-02-17 14:15:14,781 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:15:14,848 - 

2024-02-17 14:15:14,848 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:15:24,396 - Epoch: [269][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095433    
2024-02-17 14:15:33,527 - Epoch: [269][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093349    
2024-02-17 14:15:42,700 - Epoch: [269][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092798    
2024-02-17 14:15:51,739 - Epoch: [269][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092186    
2024-02-17 14:16:00,883 - Epoch: [269][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 5.500000    LR 0.000063    Time 0.092029    
2024-02-17 14:16:00,995 - --- validate (epoch=269)-----------
2024-02-17 14:16:00,996 - 10000 samples (100 per mini-batch)
2024-02-17 14:16:07,323 - Epoch: [269][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:16:07,443 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:16:07,454 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 269]
2024-02-17 14:16:07,454 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:16:07,520 - 

2024-02-17 14:16:07,520 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:16:17,365 - Epoch: [270][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.098398    
2024-02-17 14:16:26,426 - Epoch: [270][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094485    
2024-02-17 14:16:35,311 - Epoch: [270][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092594    
2024-02-17 14:16:44,220 - Epoch: [270][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091709    
2024-02-17 14:16:53,475 - Epoch: [270][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.500000    Top5 6.000000    LR 0.000063    Time 0.091869    
2024-02-17 14:16:53,598 - --- validate (epoch=270)-----------
2024-02-17 14:16:53,599 - 10000 samples (100 per mini-batch)
2024-02-17 14:16:59,360 - Epoch: [270][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:16:59,465 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:16:59,475 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 270]
2024-02-17 14:16:59,476 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:16:59,544 - 

2024-02-17 14:16:59,545 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:17:08,960 - Epoch: [271][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094084    
2024-02-17 14:17:18,051 - Epoch: [271][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092475    
2024-02-17 14:17:27,040 - Epoch: [271][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091600    
2024-02-17 14:17:36,016 - Epoch: [271][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091132    
2024-02-17 14:17:45,245 - Epoch: [271][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.500000    Top5 8.500000    LR 0.000063    Time 0.091356    
2024-02-17 14:17:45,384 - --- validate (epoch=271)-----------
2024-02-17 14:17:45,385 - 10000 samples (100 per mini-batch)
2024-02-17 14:17:50,821 - Epoch: [271][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:17:50,930 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:17:50,940 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 271]
2024-02-17 14:17:50,940 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:17:51,006 - 

2024-02-17 14:17:51,006 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:18:00,556 - Epoch: [272][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095451    
2024-02-17 14:18:09,389 - Epoch: [272][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091870    
2024-02-17 14:18:18,347 - Epoch: [272][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091097    
2024-02-17 14:18:27,359 - Epoch: [272][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090842    
2024-02-17 14:18:36,495 - Epoch: [272][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 2.000000    Top5 5.500000    LR 0.000063    Time 0.090938    
2024-02-17 14:18:36,654 - --- validate (epoch=272)-----------
2024-02-17 14:18:36,655 - 10000 samples (100 per mini-batch)
2024-02-17 14:18:42,603 - Epoch: [272][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:18:42,748 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:18:42,758 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 272]
2024-02-17 14:18:42,759 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:18:42,822 - 

2024-02-17 14:18:42,823 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:18:52,231 - Epoch: [273][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094030    
2024-02-17 14:19:01,250 - Epoch: [273][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092091    
2024-02-17 14:19:10,260 - Epoch: [273][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091416    
2024-02-17 14:19:18,956 - Epoch: [273][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090293    
2024-02-17 14:19:28,165 - Epoch: [273][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.500000    Top5 7.000000    LR 0.000063    Time 0.090644    
2024-02-17 14:19:28,281 - --- validate (epoch=273)-----------
2024-02-17 14:19:28,282 - 10000 samples (100 per mini-batch)
2024-02-17 14:19:34,159 - Epoch: [273][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:19:34,328 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:19:34,337 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 273]
2024-02-17 14:19:34,337 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:19:34,422 - 

2024-02-17 14:19:34,423 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:19:44,230 - Epoch: [274][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.098009    
2024-02-17 14:19:53,248 - Epoch: [274][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094078    
2024-02-17 14:20:02,280 - Epoch: [274][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092810    
2024-02-17 14:20:10,900 - Epoch: [274][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091151    
2024-02-17 14:20:20,070 - Epoch: [274][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.000000    Top5 5.500000    LR 0.000063    Time 0.091254    
2024-02-17 14:20:20,196 - --- validate (epoch=274)-----------
2024-02-17 14:20:20,197 - 10000 samples (100 per mini-batch)
2024-02-17 14:20:25,982 - Epoch: [274][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:20:26,155 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:20:26,166 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 274]
2024-02-17 14:20:26,166 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:20:26,232 - 

2024-02-17 14:20:26,232 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:20:35,874 - Epoch: [275][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.096371    
2024-02-17 14:20:44,968 - Epoch: [275][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093637    
2024-02-17 14:20:53,979 - Epoch: [275][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092446    
2024-02-17 14:21:02,920 - Epoch: [275][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091679    
2024-02-17 14:21:12,016 - Epoch: [275][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.000000    Top5 6.000000    LR 0.000063    Time 0.091528    
2024-02-17 14:21:12,166 - --- validate (epoch=275)-----------
2024-02-17 14:21:12,167 - 10000 samples (100 per mini-batch)
2024-02-17 14:21:18,447 - Epoch: [275][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:21:18,646 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:21:18,656 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 275]
2024-02-17 14:21:18,656 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:21:18,722 - 

2024-02-17 14:21:18,722 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:21:28,528 - Epoch: [276][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.098003    
2024-02-17 14:21:37,631 - Epoch: [276][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094497    
2024-02-17 14:21:46,551 - Epoch: [276][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092718    
2024-02-17 14:21:55,677 - Epoch: [276][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092344    
2024-02-17 14:22:04,759 - Epoch: [276][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 2.000000    Top5 6.500000    LR 0.000063    Time 0.092032    
2024-02-17 14:22:04,920 - --- validate (epoch=276)-----------
2024-02-17 14:22:04,921 - 10000 samples (100 per mini-batch)
2024-02-17 14:22:10,441 - Epoch: [276][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:22:10,558 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:22:10,568 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 276]
2024-02-17 14:22:10,568 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:22:10,643 - 

2024-02-17 14:22:10,643 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:22:20,268 - Epoch: [277][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.096189    
2024-02-17 14:22:29,458 - Epoch: [277][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094024    
2024-02-17 14:22:38,162 - Epoch: [277][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091684    
2024-02-17 14:22:46,665 - Epoch: [277][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090013    
2024-02-17 14:22:55,956 - Epoch: [277][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.000000    Top5 1.500000    LR 0.000063    Time 0.090585    
2024-02-17 14:22:56,104 - --- validate (epoch=277)-----------
2024-02-17 14:22:56,106 - 10000 samples (100 per mini-batch)
2024-02-17 14:23:02,042 - Epoch: [277][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:23:02,141 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:23:02,151 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 277]
2024-02-17 14:23:02,151 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:23:02,215 - 

2024-02-17 14:23:02,215 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:23:11,771 - Epoch: [278][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095503    
2024-02-17 14:23:21,064 - Epoch: [278][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094195    
2024-02-17 14:23:30,367 - Epoch: [278][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093795    
2024-02-17 14:23:39,620 - Epoch: [278][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093469    
2024-02-17 14:23:48,853 - Epoch: [278][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.000000    Top5 2.500000    LR 0.000063    Time 0.093232    
2024-02-17 14:23:49,012 - --- validate (epoch=278)-----------
2024-02-17 14:23:49,012 - 10000 samples (100 per mini-batch)
2024-02-17 14:23:55,221 - Epoch: [278][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:23:55,378 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:23:55,389 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 278]
2024-02-17 14:23:55,390 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:23:55,454 - 

2024-02-17 14:23:55,454 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:24:04,995 - Epoch: [279][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095355    
2024-02-17 14:24:13,612 - Epoch: [279][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090745    
2024-02-17 14:24:22,860 - Epoch: [279][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091310    
2024-02-17 14:24:31,884 - Epoch: [279][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091034    
2024-02-17 14:24:40,758 - Epoch: [279][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 7.500000    LR 0.000063    Time 0.090568    
2024-02-17 14:24:40,911 - --- validate (epoch=279)-----------
2024-02-17 14:24:40,911 - 10000 samples (100 per mini-batch)
2024-02-17 14:24:45,693 - Epoch: [279][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:24:45,796 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:24:45,805 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 279]
2024-02-17 14:24:45,805 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:24:45,857 - 

2024-02-17 14:24:45,858 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:24:55,187 - Epoch: [280][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093250    
2024-02-17 14:25:04,317 - Epoch: [280][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092254    
2024-02-17 14:25:13,462 - Epoch: [280][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091974    
2024-02-17 14:25:22,769 - Epoch: [280][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092237    
2024-02-17 14:25:31,905 - Epoch: [280][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 4.500000    LR 0.000063    Time 0.092055    
2024-02-17 14:25:32,061 - --- validate (epoch=280)-----------
2024-02-17 14:25:32,061 - 10000 samples (100 per mini-batch)
2024-02-17 14:25:37,512 - Epoch: [280][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:25:37,639 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:25:37,650 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 280]
2024-02-17 14:25:37,650 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:25:37,715 - 

2024-02-17 14:25:37,716 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:25:47,360 - Epoch: [281][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.096384    
2024-02-17 14:25:56,689 - Epoch: [281][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094816    
2024-02-17 14:26:05,743 - Epoch: [281][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093379    
2024-02-17 14:26:15,052 - Epoch: [281][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093297    
2024-02-17 14:26:24,187 - Epoch: [281][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.500000    Top5 5.500000    LR 0.000063    Time 0.092899    
2024-02-17 14:26:24,306 - --- validate (epoch=281)-----------
2024-02-17 14:26:24,308 - 10000 samples (100 per mini-batch)
2024-02-17 14:26:29,298 - Epoch: [281][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:26:29,397 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:26:29,406 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 281]
2024-02-17 14:26:29,407 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:26:29,458 - 

2024-02-17 14:26:29,458 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:26:38,128 - Epoch: [282][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.086662    
2024-02-17 14:26:47,252 - Epoch: [282][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.088931    
2024-02-17 14:26:56,255 - Epoch: [282][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.089285    
2024-02-17 14:27:05,459 - Epoch: [282][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.089964    
2024-02-17 14:27:14,593 - Epoch: [282][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.000000    Top5 7.000000    LR 0.000063    Time 0.090231    
2024-02-17 14:27:14,695 - --- validate (epoch=282)-----------
2024-02-17 14:27:14,697 - 10000 samples (100 per mini-batch)
2024-02-17 14:27:19,693 - Epoch: [282][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:27:19,806 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:27:19,815 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 282]
2024-02-17 14:27:19,816 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:27:19,873 - 

2024-02-17 14:27:19,874 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:27:28,644 - Epoch: [283][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.087659    
2024-02-17 14:27:37,808 - Epoch: [283][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.089630    
2024-02-17 14:27:46,536 - Epoch: [283][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.088835    
2024-02-17 14:27:55,779 - Epoch: [283][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.089725    
2024-02-17 14:28:05,232 - Epoch: [283][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.000000    Top5 3.500000    LR 0.000063    Time 0.090678    
2024-02-17 14:28:05,405 - --- validate (epoch=283)-----------
2024-02-17 14:28:05,406 - 10000 samples (100 per mini-batch)
2024-02-17 14:28:10,745 - Epoch: [283][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:28:10,920 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:28:10,931 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 283]
2024-02-17 14:28:10,931 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:28:10,994 - 

2024-02-17 14:28:10,994 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:28:20,677 - Epoch: [284][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.096781    
2024-02-17 14:28:29,637 - Epoch: [284][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093169    
2024-02-17 14:28:38,426 - Epoch: [284][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091401    
2024-02-17 14:28:47,634 - Epoch: [284][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091560    
2024-02-17 14:28:56,357 - Epoch: [284][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 2.000000    Top5 6.000000    LR 0.000063    Time 0.090688    
2024-02-17 14:28:56,471 - --- validate (epoch=284)-----------
2024-02-17 14:28:56,472 - 10000 samples (100 per mini-batch)
2024-02-17 14:29:02,652 - Epoch: [284][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:29:02,760 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:29:02,773 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 284]
2024-02-17 14:29:02,773 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:29:02,842 - 

2024-02-17 14:29:02,842 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:29:12,299 - Epoch: [285][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094514    
2024-02-17 14:29:21,289 - Epoch: [285][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092187    
2024-02-17 14:29:30,159 - Epoch: [285][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091013    
2024-02-17 14:29:39,429 - Epoch: [285][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091428    
2024-02-17 14:29:48,606 - Epoch: [285][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 5.500000    LR 0.000063    Time 0.091488    
2024-02-17 14:29:48,794 - --- validate (epoch=285)-----------
2024-02-17 14:29:48,795 - 10000 samples (100 per mini-batch)
2024-02-17 14:29:54,615 - Epoch: [285][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:29:54,778 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:29:54,790 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 285]
2024-02-17 14:29:54,791 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:29:54,859 - 

2024-02-17 14:29:54,860 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:30:04,871 - Epoch: [286][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.100040    
2024-02-17 14:30:13,998 - Epoch: [286][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095633    
2024-02-17 14:30:23,150 - Epoch: [286][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094249    
2024-02-17 14:30:32,426 - Epoch: [286][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093869    
2024-02-17 14:30:41,491 - Epoch: [286][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.000000    Top5 5.500000    LR 0.000063    Time 0.093217    
2024-02-17 14:30:41,610 - --- validate (epoch=286)-----------
2024-02-17 14:30:41,611 - 10000 samples (100 per mini-batch)
2024-02-17 14:30:47,044 - Epoch: [286][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:30:47,222 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:30:47,230 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 286]
2024-02-17 14:30:47,230 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:30:47,293 - 

2024-02-17 14:30:47,293 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:30:56,825 - Epoch: [287][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095268    
2024-02-17 14:31:05,684 - Epoch: [287][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091910    
2024-02-17 14:31:14,819 - Epoch: [287][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091710    
2024-02-17 14:31:23,983 - Epoch: [287][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091682    
2024-02-17 14:31:32,957 - Epoch: [287][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 2.000000    Top5 5.000000    LR 0.000063    Time 0.091286    
2024-02-17 14:31:33,138 - --- validate (epoch=287)-----------
2024-02-17 14:31:33,139 - 10000 samples (100 per mini-batch)
2024-02-17 14:31:38,628 - Epoch: [287][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:31:38,754 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:31:38,764 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 287]
2024-02-17 14:31:38,765 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:31:38,840 - 

2024-02-17 14:31:38,841 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:31:48,471 - Epoch: [288][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.096238    
2024-02-17 14:31:57,508 - Epoch: [288][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093285    
2024-02-17 14:32:06,722 - Epoch: [288][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092891    
2024-02-17 14:32:15,747 - Epoch: [288][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092223    
2024-02-17 14:32:24,630 - Epoch: [288][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.000000    Top5 4.500000    LR 0.000063    Time 0.091536    
2024-02-17 14:32:24,776 - --- validate (epoch=288)-----------
2024-02-17 14:32:24,777 - 10000 samples (100 per mini-batch)
2024-02-17 14:32:30,469 - Epoch: [288][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:32:30,570 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:32:30,580 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 288]
2024-02-17 14:32:30,580 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:32:30,644 - 

2024-02-17 14:32:30,644 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:32:40,164 - Epoch: [289][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095147    
2024-02-17 14:32:49,401 - Epoch: [289][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093741    
2024-02-17 14:32:58,635 - Epoch: [289][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093262    
2024-02-17 14:33:07,688 - Epoch: [289][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092568    
2024-02-17 14:33:16,856 - Epoch: [289][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.000000    Top5 4.500000    LR 0.000063    Time 0.092383    
2024-02-17 14:33:16,980 - --- validate (epoch=289)-----------
2024-02-17 14:33:16,981 - 10000 samples (100 per mini-batch)
2024-02-17 14:33:23,215 - Epoch: [289][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:33:23,324 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:33:23,335 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 289]
2024-02-17 14:33:23,335 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:33:23,402 - 

2024-02-17 14:33:23,402 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:33:33,282 - Epoch: [290][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.098746    
2024-02-17 14:33:42,068 - Epoch: [290][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093287    
2024-02-17 14:33:51,325 - Epoch: [290][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.093034    
2024-02-17 14:34:00,431 - Epoch: [290][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092533    
2024-02-17 14:34:09,669 - Epoch: [290][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 3.500000    LR 0.000063    Time 0.092493    
2024-02-17 14:34:09,854 - --- validate (epoch=290)-----------
2024-02-17 14:34:09,855 - 10000 samples (100 per mini-batch)
2024-02-17 14:34:15,951 - Epoch: [290][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:34:16,105 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:34:16,116 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 290]
2024-02-17 14:34:16,117 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:34:16,187 - 

2024-02-17 14:34:16,187 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:34:26,218 - Epoch: [291][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.100247    
2024-02-17 14:34:35,763 - Epoch: [291][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.097830    
2024-02-17 14:34:44,716 - Epoch: [291][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095052    
2024-02-17 14:34:53,317 - Epoch: [291][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092782    
2024-02-17 14:35:01,964 - Epoch: [291][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 3.500000    LR 0.000063    Time 0.091514    
2024-02-17 14:35:02,136 - --- validate (epoch=291)-----------
2024-02-17 14:35:02,137 - 10000 samples (100 per mini-batch)
2024-02-17 14:35:07,340 - Epoch: [291][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:35:07,420 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:35:07,428 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 291]
2024-02-17 14:35:07,428 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:35:07,496 - 

2024-02-17 14:35:07,496 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:35:16,400 - Epoch: [292][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.089001    
2024-02-17 14:35:25,539 - Epoch: [292][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090176    
2024-02-17 14:35:34,885 - Epoch: [292][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091256    
2024-02-17 14:35:44,032 - Epoch: [292][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091299    
2024-02-17 14:35:53,006 - Epoch: [292][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 2.000000    Top5 5.000000    LR 0.000063    Time 0.090979    
2024-02-17 14:35:53,185 - --- validate (epoch=292)-----------
2024-02-17 14:35:53,185 - 10000 samples (100 per mini-batch)
2024-02-17 14:35:58,980 - Epoch: [292][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:35:59,094 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:35:59,107 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 292]
2024-02-17 14:35:59,107 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:35:59,174 - 

2024-02-17 14:35:59,174 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:36:08,789 - Epoch: [293][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.096092    
2024-02-17 14:36:17,133 - Epoch: [293][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.089754    
2024-02-17 14:36:25,594 - Epoch: [293][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.088030    
2024-02-17 14:36:34,323 - Epoch: [293][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.087837    
2024-02-17 14:36:42,985 - Epoch: [293][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.000000    Top5 7.000000    LR 0.000063    Time 0.087586    
2024-02-17 14:36:43,129 - --- validate (epoch=293)-----------
2024-02-17 14:36:43,129 - 10000 samples (100 per mini-batch)
2024-02-17 14:36:48,329 - Epoch: [293][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:36:48,441 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:36:48,448 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 293]
2024-02-17 14:36:48,448 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:36:48,500 - 

2024-02-17 14:36:48,500 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:36:58,231 - Epoch: [294][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.097263    
2024-02-17 14:37:07,315 - Epoch: [294][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094033    
2024-02-17 14:37:16,193 - Epoch: [294][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092268    
2024-02-17 14:37:25,223 - Epoch: [294][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091768    
2024-02-17 14:37:34,329 - Epoch: [294][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 5.500000    LR 0.000063    Time 0.091618    
2024-02-17 14:37:34,460 - --- validate (epoch=294)-----------
2024-02-17 14:37:34,461 - 10000 samples (100 per mini-batch)
2024-02-17 14:37:40,206 - Epoch: [294][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:37:40,393 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:37:40,405 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 294]
2024-02-17 14:37:40,405 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:37:40,468 - 

2024-02-17 14:37:40,469 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:37:49,909 - Epoch: [295][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094350    
2024-02-17 14:37:58,945 - Epoch: [295][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092338    
2024-02-17 14:38:08,050 - Epoch: [295][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091895    
2024-02-17 14:38:16,554 - Epoch: [295][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090175    
2024-02-17 14:38:25,621 - Epoch: [295][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.500000    Top5 7.500000    LR 0.000063    Time 0.090266    
2024-02-17 14:38:25,799 - --- validate (epoch=295)-----------
2024-02-17 14:38:25,800 - 10000 samples (100 per mini-batch)
2024-02-17 14:38:31,459 - Epoch: [295][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:38:31,591 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:38:31,601 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 295]
2024-02-17 14:38:31,601 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:38:31,667 - 

2024-02-17 14:38:31,667 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:38:41,300 - Epoch: [296][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.096278    
2024-02-17 14:38:50,254 - Epoch: [296][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092890    
2024-02-17 14:38:59,211 - Epoch: [296][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091769    
2024-02-17 14:39:08,235 - Epoch: [296][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091379    
2024-02-17 14:39:16,982 - Epoch: [296][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 0.000000    Top5 4.500000    LR 0.000063    Time 0.090590    
2024-02-17 14:39:17,103 - --- validate (epoch=296)-----------
2024-02-17 14:39:17,104 - 10000 samples (100 per mini-batch)
2024-02-17 14:39:22,319 - Epoch: [296][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:39:22,501 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:39:22,511 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 296]
2024-02-17 14:39:22,512 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:39:22,574 - 

2024-02-17 14:39:22,574 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:39:32,044 - Epoch: [297][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094647    
2024-02-17 14:39:41,028 - Epoch: [297][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092224    
2024-02-17 14:39:50,033 - Epoch: [297][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.091488    
2024-02-17 14:39:58,977 - Epoch: [297][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090967    
2024-02-17 14:40:07,997 - Epoch: [297][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.500000    Top5 7.000000    LR 0.000063    Time 0.090805    
2024-02-17 14:40:08,118 - --- validate (epoch=297)-----------
2024-02-17 14:40:08,119 - 10000 samples (100 per mini-batch)
2024-02-17 14:40:14,160 - Epoch: [297][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:40:14,260 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:40:14,271 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 297]
2024-02-17 14:40:14,272 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:40:14,337 - 

2024-02-17 14:40:14,338 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:40:23,856 - Epoch: [298][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.095131    
2024-02-17 14:40:32,401 - Epoch: [298][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090273    
2024-02-17 14:40:41,388 - Epoch: [298][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090125    
2024-02-17 14:40:50,619 - Epoch: [298][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090662    
2024-02-17 14:40:59,574 - Epoch: [298][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.000000    Top5 5.000000    LR 0.000063    Time 0.090432    
2024-02-17 14:40:59,736 - --- validate (epoch=298)-----------
2024-02-17 14:40:59,736 - 10000 samples (100 per mini-batch)
2024-02-17 14:41:06,040 - Epoch: [298][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:41:06,139 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:41:06,149 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 298]
2024-02-17 14:41:06,150 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:41:06,213 - 

2024-02-17 14:41:06,214 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:41:15,675 - Epoch: [299][  100/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.094565    
2024-02-17 14:41:24,676 - Epoch: [299][  200/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.092267    
2024-02-17 14:41:33,469 - Epoch: [299][  300/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090808    
2024-02-17 14:41:42,441 - Epoch: [299][  400/  500]    Overall Loss 4.605172    Objective Loss 4.605172                                        LR 0.000063    Time 0.090528    
2024-02-17 14:41:51,433 - Epoch: [299][  500/  500]    Overall Loss 4.605172    Objective Loss 4.605172    Top1 1.500000    Top5 5.000000    LR 0.000063    Time 0.090398    
2024-02-17 14:41:51,622 - --- validate (epoch=299)-----------
2024-02-17 14:41:51,623 - 10000 samples (100 per mini-batch)
2024-02-17 14:41:57,783 - Epoch: [299][  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:41:57,951 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:41:57,963 - ==> Best [Top1: 1.000   Top5: 5.000   Sparsity:0.00   Params: 753952 on epoch: 299]
2024-02-17 14:41:57,963 - Saving checkpoint to: logs/2024.02.17-110226/qat_checkpoint.pth.tar
2024-02-17 14:41:58,026 - --- test ---------------------
2024-02-17 14:41:58,026 - 10000 samples (100 per mini-batch)
2024-02-17 14:42:03,539 - Test: [  100/  100]    Loss 4.605172    Top1 1.000000    Top5 5.000000    
2024-02-17 14:42:03,705 - ==> Top1: 1.000    Top5: 5.000    Loss: 4.605

2024-02-17 14:42:03,717 - 
2024-02-17 14:42:03,718 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.02.17-110226/2024.02.17-110226.log
