2024-02-17 11:01:19,211 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.02.17-110119/2024.02.17-110119.log
2024-02-17 11:01:22,333 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-02-17 11:01:22,334 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-02-17 11:01:23,870 - Dataset sizes:
	training=50000
	validation=10000
	test=10000
2024-02-17 11:01:23,871 - Reading compression schedule from: policies/schedule-cifar100-effnet2.yaml
2024-02-17 11:01:23,879 - 

2024-02-17 11:01:23,879 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:01:31,682 - Epoch: [0][  100/  500]    Overall Loss 4.275056    Objective Loss 4.275056                                        LR 0.001000    Time 0.077990    
2024-02-17 11:01:38,467 - Epoch: [0][  200/  500]    Overall Loss 4.121238    Objective Loss 4.121238                                        LR 0.001000    Time 0.072903    
2024-02-17 11:01:45,677 - Epoch: [0][  300/  500]    Overall Loss 4.013989    Objective Loss 4.013989                                        LR 0.001000    Time 0.072620    
2024-02-17 11:01:52,829 - Epoch: [0][  400/  500]    Overall Loss 3.929156    Objective Loss 3.929156                                        LR 0.001000    Time 0.072335    
2024-02-17 11:01:59,455 - Epoch: [0][  500/  500]    Overall Loss 3.866253    Objective Loss 3.866253    Top1 11.500000    Top5 46.000000    LR 0.001000    Time 0.071115    
2024-02-17 11:01:59,577 - --- validate (epoch=0)-----------
2024-02-17 11:01:59,578 - 10000 samples (100 per mini-batch)
2024-02-17 11:02:02,962 - Epoch: [0][  100/  100]    Loss 6.616838    Top1 1.510000    Top5 6.210000    
2024-02-17 11:02:03,056 - ==> Top1: 1.510    Top5: 6.210    Loss: 6.617

2024-02-17 11:02:03,063 - ==> Best [Top1: 1.510   Top5: 6.210   Sparsity:0.00   Params: 753952 on epoch: 0]
2024-02-17 11:02:03,064 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:02:03,137 - 

2024-02-17 11:02:03,138 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:02:10,995 - Epoch: [1][  100/  500]    Overall Loss 3.500466    Objective Loss 3.500466                                        LR 0.001000    Time 0.078506    
2024-02-17 11:02:18,313 - Epoch: [1][  200/  500]    Overall Loss 3.457511    Objective Loss 3.457511                                        LR 0.001000    Time 0.075819    
2024-02-17 11:02:25,482 - Epoch: [1][  300/  500]    Overall Loss 3.418027    Objective Loss 3.418027                                        LR 0.001000    Time 0.074431    
2024-02-17 11:02:32,451 - Epoch: [1][  400/  500]    Overall Loss 3.380266    Objective Loss 3.380266                                        LR 0.001000    Time 0.073236    
2024-02-17 11:02:39,533 - Epoch: [1][  500/  500]    Overall Loss 3.341529    Objective Loss 3.341529    Top1 16.000000    Top5 45.000000    LR 0.001000    Time 0.072743    
2024-02-17 11:02:39,685 - --- validate (epoch=1)-----------
2024-02-17 11:02:39,685 - 10000 samples (100 per mini-batch)
2024-02-17 11:02:42,664 - Epoch: [1][  100/  100]    Loss 3.431657    Top1 17.000000    Top5 44.840000    
2024-02-17 11:02:42,769 - ==> Top1: 17.000    Top5: 44.840    Loss: 3.432

2024-02-17 11:02:42,781 - ==> Best [Top1: 17.000   Top5: 44.840   Sparsity:0.00   Params: 753952 on epoch: 1]
2024-02-17 11:02:42,781 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:02:42,871 - 

2024-02-17 11:02:42,871 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:02:50,864 - Epoch: [2][  100/  500]    Overall Loss 3.099394    Objective Loss 3.099394                                        LR 0.001000    Time 0.079846    
2024-02-17 11:02:58,078 - Epoch: [2][  200/  500]    Overall Loss 3.083873    Objective Loss 3.083873                                        LR 0.001000    Time 0.075972    
2024-02-17 11:03:05,278 - Epoch: [2][  300/  500]    Overall Loss 3.067328    Objective Loss 3.067328                                        LR 0.001000    Time 0.074633    
2024-02-17 11:03:12,587 - Epoch: [2][  400/  500]    Overall Loss 3.046143    Objective Loss 3.046143                                        LR 0.001000    Time 0.074236    
2024-02-17 11:03:19,867 - Epoch: [2][  500/  500]    Overall Loss 3.019589    Objective Loss 3.019589    Top1 23.000000    Top5 60.000000    LR 0.001000    Time 0.073941    
2024-02-17 11:03:20,032 - --- validate (epoch=2)-----------
2024-02-17 11:03:20,033 - 10000 samples (100 per mini-batch)
2024-02-17 11:03:22,936 - Epoch: [2][  100/  100]    Loss 3.225702    Top1 22.180000    Top5 51.550000    
2024-02-17 11:03:23,065 - ==> Top1: 22.180    Top5: 51.550    Loss: 3.226

2024-02-17 11:03:23,076 - ==> Best [Top1: 22.180   Top5: 51.550   Sparsity:0.00   Params: 753952 on epoch: 2]
2024-02-17 11:03:23,076 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:03:23,152 - 

2024-02-17 11:03:23,153 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:03:30,984 - Epoch: [3][  100/  500]    Overall Loss 2.865246    Objective Loss 2.865246                                        LR 0.001000    Time 0.078261    
2024-02-17 11:03:38,345 - Epoch: [3][  200/  500]    Overall Loss 2.844952    Objective Loss 2.844952                                        LR 0.001000    Time 0.075913    
2024-02-17 11:03:45,565 - Epoch: [3][  300/  500]    Overall Loss 2.833951    Objective Loss 2.833951                                        LR 0.001000    Time 0.074661    
2024-02-17 11:03:52,800 - Epoch: [3][  400/  500]    Overall Loss 2.819812    Objective Loss 2.819812                                        LR 0.001000    Time 0.074072    
2024-02-17 11:03:59,722 - Epoch: [3][  500/  500]    Overall Loss 2.805881    Objective Loss 2.805881    Top1 25.000000    Top5 62.000000    LR 0.001000    Time 0.073095    
2024-02-17 11:03:59,924 - --- validate (epoch=3)-----------
2024-02-17 11:03:59,925 - 10000 samples (100 per mini-batch)
2024-02-17 11:04:02,893 - Epoch: [3][  100/  100]    Loss 3.079837    Top1 24.790000    Top5 56.140000    
2024-02-17 11:04:03,006 - ==> Top1: 24.790    Top5: 56.140    Loss: 3.080

2024-02-17 11:04:03,013 - ==> Best [Top1: 24.790   Top5: 56.140   Sparsity:0.00   Params: 753952 on epoch: 3]
2024-02-17 11:04:03,013 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:04:03,096 - 

2024-02-17 11:04:03,097 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:04:10,663 - Epoch: [4][  100/  500]    Overall Loss 2.697732    Objective Loss 2.697732                                        LR 0.001000    Time 0.075585    
2024-02-17 11:04:17,902 - Epoch: [4][  200/  500]    Overall Loss 2.681969    Objective Loss 2.681969                                        LR 0.001000    Time 0.073970    
2024-02-17 11:04:25,076 - Epoch: [4][  300/  500]    Overall Loss 2.668564    Objective Loss 2.668564                                        LR 0.001000    Time 0.073210    
2024-02-17 11:04:32,295 - Epoch: [4][  400/  500]    Overall Loss 2.648206    Objective Loss 2.648206                                        LR 0.001000    Time 0.072945    
2024-02-17 11:04:39,650 - Epoch: [4][  500/  500]    Overall Loss 2.628857    Objective Loss 2.628857    Top1 30.000000    Top5 64.500000    LR 0.001000    Time 0.073058    
2024-02-17 11:04:39,831 - --- validate (epoch=4)-----------
2024-02-17 11:04:39,831 - 10000 samples (100 per mini-batch)
2024-02-17 11:04:43,225 - Epoch: [4][  100/  100]    Loss 2.708755    Top1 30.410000    Top5 63.190000    
2024-02-17 11:04:43,363 - ==> Top1: 30.410    Top5: 63.190    Loss: 2.709

2024-02-17 11:04:43,373 - ==> Best [Top1: 30.410   Top5: 63.190   Sparsity:0.00   Params: 753952 on epoch: 4]
2024-02-17 11:04:43,374 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:04:43,450 - 

2024-02-17 11:04:43,450 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:04:51,169 - Epoch: [5][  100/  500]    Overall Loss 2.506355    Objective Loss 2.506355                                        LR 0.001000    Time 0.077135    
2024-02-17 11:04:58,457 - Epoch: [5][  200/  500]    Overall Loss 2.506461    Objective Loss 2.506461                                        LR 0.001000    Time 0.074986    
2024-02-17 11:05:05,676 - Epoch: [5][  300/  500]    Overall Loss 2.498337    Objective Loss 2.498337                                        LR 0.001000    Time 0.074039    
2024-02-17 11:05:12,900 - Epoch: [5][  400/  500]    Overall Loss 2.493585    Objective Loss 2.493585                                        LR 0.001000    Time 0.073579    
2024-02-17 11:05:20,033 - Epoch: [5][  500/  500]    Overall Loss 2.480782    Objective Loss 2.480782    Top1 38.000000    Top5 68.500000    LR 0.001000    Time 0.073119    
2024-02-17 11:05:20,178 - --- validate (epoch=5)-----------
2024-02-17 11:05:20,179 - 10000 samples (100 per mini-batch)
2024-02-17 11:05:23,215 - Epoch: [5][  100/  100]    Loss 2.529645    Top1 34.250000    Top5 67.130000    
2024-02-17 11:05:23,313 - ==> Top1: 34.250    Top5: 67.130    Loss: 2.530

2024-02-17 11:05:23,324 - ==> Best [Top1: 34.250   Top5: 67.130   Sparsity:0.00   Params: 753952 on epoch: 5]
2024-02-17 11:05:23,325 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:05:23,405 - 

2024-02-17 11:05:23,406 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:05:31,009 - Epoch: [6][  100/  500]    Overall Loss 2.366514    Objective Loss 2.366514                                        LR 0.001000    Time 0.075977    
2024-02-17 11:05:38,219 - Epoch: [6][  200/  500]    Overall Loss 2.383490    Objective Loss 2.383490                                        LR 0.001000    Time 0.074015    
2024-02-17 11:05:45,439 - Epoch: [6][  300/  500]    Overall Loss 2.374303    Objective Loss 2.374303                                        LR 0.001000    Time 0.073396    
2024-02-17 11:05:52,682 - Epoch: [6][  400/  500]    Overall Loss 2.364162    Objective Loss 2.364162                                        LR 0.001000    Time 0.073142    
2024-02-17 11:05:59,974 - Epoch: [6][  500/  500]    Overall Loss 2.355942    Objective Loss 2.355942    Top1 34.500000    Top5 65.000000    LR 0.001000    Time 0.073090    
2024-02-17 11:06:00,111 - --- validate (epoch=6)-----------
2024-02-17 11:06:00,112 - 10000 samples (100 per mini-batch)
2024-02-17 11:06:03,461 - Epoch: [6][  100/  100]    Loss 2.720212    Top1 32.220000    Top5 64.090000    
2024-02-17 11:06:03,610 - ==> Top1: 32.220    Top5: 64.090    Loss: 2.720

2024-02-17 11:06:03,619 - ==> Best [Top1: 34.250   Top5: 67.130   Sparsity:0.00   Params: 753952 on epoch: 5]
2024-02-17 11:06:03,620 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:06:03,685 - 

2024-02-17 11:06:03,685 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:06:11,507 - Epoch: [7][  100/  500]    Overall Loss 2.270916    Objective Loss 2.270916                                        LR 0.001000    Time 0.078161    
2024-02-17 11:06:18,895 - Epoch: [7][  200/  500]    Overall Loss 2.274110    Objective Loss 2.274110                                        LR 0.001000    Time 0.075995    
2024-02-17 11:06:26,118 - Epoch: [7][  300/  500]    Overall Loss 2.270804    Objective Loss 2.270804                                        LR 0.001000    Time 0.074726    
2024-02-17 11:06:33,194 - Epoch: [7][  400/  500]    Overall Loss 2.270610    Objective Loss 2.270610                                        LR 0.001000    Time 0.073725    
2024-02-17 11:06:40,253 - Epoch: [7][  500/  500]    Overall Loss 2.261209    Objective Loss 2.261209    Top1 35.000000    Top5 70.500000    LR 0.001000    Time 0.073089    
2024-02-17 11:06:40,398 - --- validate (epoch=7)-----------
2024-02-17 11:06:40,399 - 10000 samples (100 per mini-batch)
2024-02-17 11:06:43,435 - Epoch: [7][  100/  100]    Loss 2.439252    Top1 37.610000    Top5 69.580000    
2024-02-17 11:06:43,626 - ==> Top1: 37.610    Top5: 69.580    Loss: 2.439

2024-02-17 11:06:43,638 - ==> Best [Top1: 37.610   Top5: 69.580   Sparsity:0.00   Params: 753952 on epoch: 7]
2024-02-17 11:06:43,638 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:06:43,719 - 

2024-02-17 11:06:43,719 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:06:51,888 - Epoch: [8][  100/  500]    Overall Loss 2.151179    Objective Loss 2.151179                                        LR 0.001000    Time 0.081624    
2024-02-17 11:06:59,165 - Epoch: [8][  200/  500]    Overall Loss 2.173651    Objective Loss 2.173651                                        LR 0.001000    Time 0.077176    
2024-02-17 11:07:06,407 - Epoch: [8][  300/  500]    Overall Loss 2.162682    Objective Loss 2.162682                                        LR 0.001000    Time 0.075576    
2024-02-17 11:07:13,516 - Epoch: [8][  400/  500]    Overall Loss 2.168870    Objective Loss 2.168870                                        LR 0.001000    Time 0.074443    
2024-02-17 11:07:20,737 - Epoch: [8][  500/  500]    Overall Loss 2.163665    Objective Loss 2.163665    Top1 41.000000    Top5 75.500000    LR 0.001000    Time 0.073988    
2024-02-17 11:07:20,863 - --- validate (epoch=8)-----------
2024-02-17 11:07:20,865 - 10000 samples (100 per mini-batch)
2024-02-17 11:07:23,878 - Epoch: [8][  100/  100]    Loss 2.393116    Top1 38.040000    Top5 70.480000    
2024-02-17 11:07:24,048 - ==> Top1: 38.040    Top5: 70.480    Loss: 2.393

2024-02-17 11:07:24,059 - ==> Best [Top1: 38.040   Top5: 70.480   Sparsity:0.00   Params: 753952 on epoch: 8]
2024-02-17 11:07:24,059 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:07:24,131 - 

2024-02-17 11:07:24,131 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:07:31,601 - Epoch: [9][  100/  500]    Overall Loss 2.059027    Objective Loss 2.059027                                        LR 0.001000    Time 0.074646    
2024-02-17 11:07:38,889 - Epoch: [9][  200/  500]    Overall Loss 2.077117    Objective Loss 2.077117                                        LR 0.001000    Time 0.073737    
2024-02-17 11:07:46,144 - Epoch: [9][  300/  500]    Overall Loss 2.086387    Objective Loss 2.086387                                        LR 0.001000    Time 0.073329    
2024-02-17 11:07:53,243 - Epoch: [9][  400/  500]    Overall Loss 2.082988    Objective Loss 2.082988                                        LR 0.001000    Time 0.072733    
2024-02-17 11:08:00,546 - Epoch: [9][  500/  500]    Overall Loss 2.083254    Objective Loss 2.083254    Top1 47.000000    Top5 78.000000    LR 0.001000    Time 0.072786    
2024-02-17 11:08:00,669 - --- validate (epoch=9)-----------
2024-02-17 11:08:00,669 - 10000 samples (100 per mini-batch)
2024-02-17 11:08:03,722 - Epoch: [9][  100/  100]    Loss 2.423922    Top1 39.470000    Top5 70.630000    
2024-02-17 11:08:03,889 - ==> Top1: 39.470    Top5: 70.630    Loss: 2.424

2024-02-17 11:08:03,899 - ==> Best [Top1: 39.470   Top5: 70.630   Sparsity:0.00   Params: 753952 on epoch: 9]
2024-02-17 11:08:03,899 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:08:03,970 - 

2024-02-17 11:08:03,970 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:08:11,580 - Epoch: [10][  100/  500]    Overall Loss 2.034494    Objective Loss 2.034494                                        LR 0.001000    Time 0.076029    
2024-02-17 11:08:18,684 - Epoch: [10][  200/  500]    Overall Loss 2.030089    Objective Loss 2.030089                                        LR 0.001000    Time 0.073517    
2024-02-17 11:08:25,893 - Epoch: [10][  300/  500]    Overall Loss 2.026545    Objective Loss 2.026545                                        LR 0.001000    Time 0.073028    
2024-02-17 11:08:33,042 - Epoch: [10][  400/  500]    Overall Loss 2.018472    Objective Loss 2.018472                                        LR 0.001000    Time 0.072632    
2024-02-17 11:08:40,551 - Epoch: [10][  500/  500]    Overall Loss 2.021649    Objective Loss 2.021649    Top1 43.000000    Top5 74.500000    LR 0.001000    Time 0.073114    
2024-02-17 11:08:40,700 - --- validate (epoch=10)-----------
2024-02-17 11:08:40,700 - 10000 samples (100 per mini-batch)
2024-02-17 11:08:43,898 - Epoch: [10][  100/  100]    Loss 2.272644    Top1 40.380000    Top5 72.820000    
2024-02-17 11:08:44,028 - ==> Top1: 40.380    Top5: 72.820    Loss: 2.273

2024-02-17 11:08:44,038 - ==> Best [Top1: 40.380   Top5: 72.820   Sparsity:0.00   Params: 753952 on epoch: 10]
2024-02-17 11:08:44,038 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:08:44,112 - 

2024-02-17 11:08:44,112 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:08:51,687 - Epoch: [11][  100/  500]    Overall Loss 1.962647    Objective Loss 1.962647                                        LR 0.001000    Time 0.075690    
2024-02-17 11:08:58,899 - Epoch: [11][  200/  500]    Overall Loss 1.956996    Objective Loss 1.956996                                        LR 0.001000    Time 0.073885    
2024-02-17 11:09:06,188 - Epoch: [11][  300/  500]    Overall Loss 1.955405    Objective Loss 1.955405                                        LR 0.001000    Time 0.073538    
2024-02-17 11:09:13,062 - Epoch: [11][  400/  500]    Overall Loss 1.954840    Objective Loss 1.954840                                        LR 0.001000    Time 0.072329    
2024-02-17 11:09:20,084 - Epoch: [11][  500/  500]    Overall Loss 1.954866    Objective Loss 1.954866    Top1 53.000000    Top5 78.500000    LR 0.001000    Time 0.071899    
2024-02-17 11:09:20,193 - --- validate (epoch=11)-----------
2024-02-17 11:09:20,193 - 10000 samples (100 per mini-batch)
2024-02-17 11:09:23,194 - Epoch: [11][  100/  100]    Loss 2.191544    Top1 42.860000    Top5 74.630000    
2024-02-17 11:09:23,317 - ==> Top1: 42.860    Top5: 74.630    Loss: 2.192

2024-02-17 11:09:23,328 - ==> Best [Top1: 42.860   Top5: 74.630   Sparsity:0.00   Params: 753952 on epoch: 11]
2024-02-17 11:09:23,328 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:09:23,404 - 

2024-02-17 11:09:23,404 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:09:31,185 - Epoch: [12][  100/  500]    Overall Loss 1.905880    Objective Loss 1.905880                                        LR 0.001000    Time 0.077753    
2024-02-17 11:09:38,436 - Epoch: [12][  200/  500]    Overall Loss 1.911123    Objective Loss 1.911123                                        LR 0.001000    Time 0.075111    
2024-02-17 11:09:45,454 - Epoch: [12][  300/  500]    Overall Loss 1.905539    Objective Loss 1.905539                                        LR 0.001000    Time 0.073455    
2024-02-17 11:09:52,631 - Epoch: [12][  400/  500]    Overall Loss 1.901324    Objective Loss 1.901324                                        LR 0.001000    Time 0.073022    
2024-02-17 11:09:59,853 - Epoch: [12][  500/  500]    Overall Loss 1.901744    Objective Loss 1.901744    Top1 49.000000    Top5 80.000000    LR 0.001000    Time 0.072853    
2024-02-17 11:09:59,971 - --- validate (epoch=12)-----------
2024-02-17 11:09:59,972 - 10000 samples (100 per mini-batch)
2024-02-17 11:10:03,016 - Epoch: [12][  100/  100]    Loss 2.092381    Top1 45.170000    Top5 76.320000    
2024-02-17 11:10:03,115 - ==> Top1: 45.170    Top5: 76.320    Loss: 2.092

2024-02-17 11:10:03,125 - ==> Best [Top1: 45.170   Top5: 76.320   Sparsity:0.00   Params: 753952 on epoch: 12]
2024-02-17 11:10:03,126 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:10:03,199 - 

2024-02-17 11:10:03,200 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:10:10,971 - Epoch: [13][  100/  500]    Overall Loss 1.821593    Objective Loss 1.821593                                        LR 0.001000    Time 0.077656    
2024-02-17 11:10:18,182 - Epoch: [13][  200/  500]    Overall Loss 1.839496    Objective Loss 1.839496                                        LR 0.001000    Time 0.074861    
2024-02-17 11:10:25,386 - Epoch: [13][  300/  500]    Overall Loss 1.848061    Objective Loss 1.848061                                        LR 0.001000    Time 0.073904    
2024-02-17 11:10:32,613 - Epoch: [13][  400/  500]    Overall Loss 1.847638    Objective Loss 1.847638                                        LR 0.001000    Time 0.073486    
2024-02-17 11:10:39,811 - Epoch: [13][  500/  500]    Overall Loss 1.848399    Objective Loss 1.848399    Top1 49.000000    Top5 80.000000    LR 0.001000    Time 0.073176    
2024-02-17 11:10:39,958 - --- validate (epoch=13)-----------
2024-02-17 11:10:39,958 - 10000 samples (100 per mini-batch)
2024-02-17 11:10:43,054 - Epoch: [13][  100/  100]    Loss 2.009546    Top1 46.370000    Top5 77.500000    
2024-02-17 11:10:43,187 - ==> Top1: 46.370    Top5: 77.500    Loss: 2.010

2024-02-17 11:10:43,198 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-17 11:10:43,199 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:10:43,271 - 

2024-02-17 11:10:43,272 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:10:50,793 - Epoch: [14][  100/  500]    Overall Loss 1.775488    Objective Loss 1.775488                                        LR 0.001000    Time 0.075168    
2024-02-17 11:10:58,053 - Epoch: [14][  200/  500]    Overall Loss 1.784257    Objective Loss 1.784257                                        LR 0.001000    Time 0.073860    
2024-02-17 11:11:05,359 - Epoch: [14][  300/  500]    Overall Loss 1.796584    Objective Loss 1.796584                                        LR 0.001000    Time 0.073580    
2024-02-17 11:11:12,418 - Epoch: [14][  400/  500]    Overall Loss 1.795666    Objective Loss 1.795666                                        LR 0.001000    Time 0.072820    
2024-02-17 11:11:19,520 - Epoch: [14][  500/  500]    Overall Loss 1.796371    Objective Loss 1.796371    Top1 48.000000    Top5 74.500000    LR 0.001000    Time 0.072454    
2024-02-17 11:11:19,637 - --- validate (epoch=14)-----------
2024-02-17 11:11:19,637 - 10000 samples (100 per mini-batch)
2024-02-17 11:11:23,180 - Epoch: [14][  100/  100]    Loss 2.156361    Top1 43.530000    Top5 76.080000    
2024-02-17 11:11:23,286 - ==> Top1: 43.530    Top5: 76.080    Loss: 2.156

2024-02-17 11:11:23,296 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-17 11:11:23,297 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:11:23,358 - 

2024-02-17 11:11:23,359 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:11:30,933 - Epoch: [15][  100/  500]    Overall Loss 1.753944    Objective Loss 1.753944                                        LR 0.001000    Time 0.075691    
2024-02-17 11:11:38,287 - Epoch: [15][  200/  500]    Overall Loss 1.765189    Objective Loss 1.765189                                        LR 0.001000    Time 0.074594    
2024-02-17 11:11:45,518 - Epoch: [15][  300/  500]    Overall Loss 1.756644    Objective Loss 1.756644                                        LR 0.001000    Time 0.073817    
2024-02-17 11:11:52,744 - Epoch: [15][  400/  500]    Overall Loss 1.757607    Objective Loss 1.757607                                        LR 0.001000    Time 0.073416    
2024-02-17 11:11:59,851 - Epoch: [15][  500/  500]    Overall Loss 1.759161    Objective Loss 1.759161    Top1 54.000000    Top5 80.000000    LR 0.001000    Time 0.072939    
2024-02-17 11:12:00,103 - --- validate (epoch=15)-----------
2024-02-17 11:12:00,103 - 10000 samples (100 per mini-batch)
2024-02-17 11:12:03,345 - Epoch: [15][  100/  100]    Loss 2.198651    Top1 44.390000    Top5 74.910000    
2024-02-17 11:12:03,482 - ==> Top1: 44.390    Top5: 74.910    Loss: 2.199

2024-02-17 11:12:03,491 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-17 11:12:03,491 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:12:03,556 - 

2024-02-17 11:12:03,557 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:12:11,634 - Epoch: [16][  100/  500]    Overall Loss 1.711494    Objective Loss 1.711494                                        LR 0.001000    Time 0.080704    
2024-02-17 11:12:18,871 - Epoch: [16][  200/  500]    Overall Loss 1.725115    Objective Loss 1.725115                                        LR 0.001000    Time 0.076515    
2024-02-17 11:12:26,125 - Epoch: [16][  300/  500]    Overall Loss 1.719435    Objective Loss 1.719435                                        LR 0.001000    Time 0.075176    
2024-02-17 11:12:33,357 - Epoch: [16][  400/  500]    Overall Loss 1.718150    Objective Loss 1.718150                                        LR 0.001000    Time 0.074452    
2024-02-17 11:12:40,585 - Epoch: [16][  500/  500]    Overall Loss 1.720831    Objective Loss 1.720831    Top1 49.500000    Top5 82.500000    LR 0.001000    Time 0.074008    
2024-02-17 11:12:40,757 - --- validate (epoch=16)-----------
2024-02-17 11:12:40,757 - 10000 samples (100 per mini-batch)
2024-02-17 11:12:43,871 - Epoch: [16][  100/  100]    Loss 2.099510    Top1 45.580000    Top5 77.060000    
2024-02-17 11:12:43,989 - ==> Top1: 45.580    Top5: 77.060    Loss: 2.100

2024-02-17 11:12:43,995 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-17 11:12:43,995 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:12:44,074 - 

2024-02-17 11:12:44,075 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:12:51,798 - Epoch: [17][  100/  500]    Overall Loss 1.660831    Objective Loss 1.660831                                        LR 0.001000    Time 0.077179    
2024-02-17 11:12:58,931 - Epoch: [17][  200/  500]    Overall Loss 1.676588    Objective Loss 1.676588                                        LR 0.001000    Time 0.074231    
2024-02-17 11:13:06,109 - Epoch: [17][  300/  500]    Overall Loss 1.675820    Objective Loss 1.675820                                        LR 0.001000    Time 0.073400    
2024-02-17 11:13:13,027 - Epoch: [17][  400/  500]    Overall Loss 1.679714    Objective Loss 1.679714                                        LR 0.001000    Time 0.072337    
2024-02-17 11:13:20,167 - Epoch: [17][  500/  500]    Overall Loss 1.685002    Objective Loss 1.685002    Top1 53.500000    Top5 84.500000    LR 0.001000    Time 0.072140    
2024-02-17 11:13:20,299 - --- validate (epoch=17)-----------
2024-02-17 11:13:20,299 - 10000 samples (100 per mini-batch)
2024-02-17 11:13:23,346 - Epoch: [17][  100/  100]    Loss 2.105406    Top1 45.680000    Top5 77.190000    
2024-02-17 11:13:23,454 - ==> Top1: 45.680    Top5: 77.190    Loss: 2.105

2024-02-17 11:13:23,465 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-17 11:13:23,465 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:13:23,526 - 

2024-02-17 11:13:23,526 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:13:31,047 - Epoch: [18][  100/  500]    Overall Loss 1.621041    Objective Loss 1.621041                                        LR 0.001000    Time 0.075150    
2024-02-17 11:13:38,301 - Epoch: [18][  200/  500]    Overall Loss 1.613933    Objective Loss 1.613933                                        LR 0.001000    Time 0.073823    
2024-02-17 11:13:45,605 - Epoch: [18][  300/  500]    Overall Loss 1.632973    Objective Loss 1.632973                                        LR 0.001000    Time 0.073549    
2024-02-17 11:13:52,805 - Epoch: [18][  400/  500]    Overall Loss 1.638953    Objective Loss 1.638953                                        LR 0.001000    Time 0.073151    
2024-02-17 11:13:59,988 - Epoch: [18][  500/  500]    Overall Loss 1.642707    Objective Loss 1.642707    Top1 50.500000    Top5 84.000000    LR 0.001000    Time 0.072878    
2024-02-17 11:14:00,186 - --- validate (epoch=18)-----------
2024-02-17 11:14:00,187 - 10000 samples (100 per mini-batch)
2024-02-17 11:14:03,286 - Epoch: [18][  100/  100]    Loss 1.904714    Top1 49.260000    Top5 79.860000    
2024-02-17 11:14:03,381 - ==> Top1: 49.260    Top5: 79.860    Loss: 1.905

2024-02-17 11:14:03,392 - ==> Best [Top1: 49.260   Top5: 79.860   Sparsity:0.00   Params: 753952 on epoch: 18]
2024-02-17 11:14:03,393 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:14:03,685 - 

2024-02-17 11:14:03,686 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:14:11,295 - Epoch: [19][  100/  500]    Overall Loss 1.607954    Objective Loss 1.607954                                        LR 0.001000    Time 0.076037    
2024-02-17 11:14:18,603 - Epoch: [19][  200/  500]    Overall Loss 1.585529    Objective Loss 1.585529                                        LR 0.001000    Time 0.074536    
2024-02-17 11:14:25,857 - Epoch: [19][  300/  500]    Overall Loss 1.596851    Objective Loss 1.596851                                        LR 0.001000    Time 0.073856    
2024-02-17 11:14:32,969 - Epoch: [19][  400/  500]    Overall Loss 1.601803    Objective Loss 1.601803                                        LR 0.001000    Time 0.073161    
2024-02-17 11:14:40,307 - Epoch: [19][  500/  500]    Overall Loss 1.603009    Objective Loss 1.603009    Top1 52.500000    Top5 87.000000    LR 0.001000    Time 0.073196    
2024-02-17 11:14:40,428 - --- validate (epoch=19)-----------
2024-02-17 11:14:40,429 - 10000 samples (100 per mini-batch)
2024-02-17 11:14:43,407 - Epoch: [19][  100/  100]    Loss 1.988589    Top1 48.330000    Top5 79.250000    
2024-02-17 11:14:43,532 - ==> Top1: 48.330    Top5: 79.250    Loss: 1.989

2024-02-17 11:14:43,542 - ==> Best [Top1: 49.260   Top5: 79.860   Sparsity:0.00   Params: 753952 on epoch: 18]
2024-02-17 11:14:43,542 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:14:43,603 - 

2024-02-17 11:14:43,604 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:14:51,438 - Epoch: [20][  100/  500]    Overall Loss 1.564594    Objective Loss 1.564594                                        LR 0.001000    Time 0.078288    
2024-02-17 11:14:58,514 - Epoch: [20][  200/  500]    Overall Loss 1.562131    Objective Loss 1.562131                                        LR 0.001000    Time 0.074503    
2024-02-17 11:15:05,801 - Epoch: [20][  300/  500]    Overall Loss 1.562905    Objective Loss 1.562905                                        LR 0.001000    Time 0.073943    
2024-02-17 11:15:12,926 - Epoch: [20][  400/  500]    Overall Loss 1.571484    Objective Loss 1.571484                                        LR 0.001000    Time 0.073260    
2024-02-17 11:15:20,185 - Epoch: [20][  500/  500]    Overall Loss 1.575743    Objective Loss 1.575743    Top1 57.000000    Top5 87.500000    LR 0.001000    Time 0.073117    
2024-02-17 11:15:20,363 - --- validate (epoch=20)-----------
2024-02-17 11:15:20,363 - 10000 samples (100 per mini-batch)
2024-02-17 11:15:23,676 - Epoch: [20][  100/  100]    Loss 1.934092    Top1 49.540000    Top5 80.070000    
2024-02-17 11:15:23,806 - ==> Top1: 49.540    Top5: 80.070    Loss: 1.934

2024-02-17 11:15:23,817 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-17 11:15:23,817 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:15:23,896 - 

2024-02-17 11:15:23,896 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:15:31,607 - Epoch: [21][  100/  500]    Overall Loss 1.538992    Objective Loss 1.538992                                        LR 0.001000    Time 0.077055    
2024-02-17 11:15:38,773 - Epoch: [21][  200/  500]    Overall Loss 1.546913    Objective Loss 1.546913                                        LR 0.001000    Time 0.074337    
2024-02-17 11:15:45,981 - Epoch: [21][  300/  500]    Overall Loss 1.546955    Objective Loss 1.546955                                        LR 0.001000    Time 0.073567    
2024-02-17 11:15:53,132 - Epoch: [21][  400/  500]    Overall Loss 1.549520    Objective Loss 1.549520                                        LR 0.001000    Time 0.073043    
2024-02-17 11:16:00,236 - Epoch: [21][  500/  500]    Overall Loss 1.548122    Objective Loss 1.548122    Top1 51.500000    Top5 83.000000    LR 0.001000    Time 0.072634    
2024-02-17 11:16:00,365 - --- validate (epoch=21)-----------
2024-02-17 11:16:00,367 - 10000 samples (100 per mini-batch)
2024-02-17 11:16:03,445 - Epoch: [21][  100/  100]    Loss 2.062266    Top1 47.660000    Top5 77.650000    
2024-02-17 11:16:03,551 - ==> Top1: 47.660    Top5: 77.650    Loss: 2.062

2024-02-17 11:16:03,564 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-17 11:16:03,564 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:16:03,641 - 

2024-02-17 11:16:03,642 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:16:11,774 - Epoch: [22][  100/  500]    Overall Loss 1.496551    Objective Loss 1.496551                                        LR 0.001000    Time 0.081260    
2024-02-17 11:16:18,927 - Epoch: [22][  200/  500]    Overall Loss 1.495316    Objective Loss 1.495316                                        LR 0.001000    Time 0.076373    
2024-02-17 11:16:26,211 - Epoch: [22][  300/  500]    Overall Loss 1.502963    Objective Loss 1.502963                                        LR 0.001000    Time 0.075183    
2024-02-17 11:16:33,576 - Epoch: [22][  400/  500]    Overall Loss 1.511468    Objective Loss 1.511468                                        LR 0.001000    Time 0.074789    
2024-02-17 11:16:40,918 - Epoch: [22][  500/  500]    Overall Loss 1.516580    Objective Loss 1.516580    Top1 61.000000    Top5 85.500000    LR 0.001000    Time 0.074506    
2024-02-17 11:16:41,020 - --- validate (epoch=22)-----------
2024-02-17 11:16:41,021 - 10000 samples (100 per mini-batch)
2024-02-17 11:16:44,037 - Epoch: [22][  100/  100]    Loss 2.009924    Top1 49.130000    Top5 79.100000    
2024-02-17 11:16:44,145 - ==> Top1: 49.130    Top5: 79.100    Loss: 2.010

2024-02-17 11:16:44,157 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-17 11:16:44,157 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:16:44,225 - 

2024-02-17 11:16:44,226 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:16:51,883 - Epoch: [23][  100/  500]    Overall Loss 1.491574    Objective Loss 1.491574                                        LR 0.001000    Time 0.076513    
2024-02-17 11:16:59,131 - Epoch: [23][  200/  500]    Overall Loss 1.483728    Objective Loss 1.483728                                        LR 0.001000    Time 0.074481    
2024-02-17 11:17:06,356 - Epoch: [23][  300/  500]    Overall Loss 1.485817    Objective Loss 1.485817                                        LR 0.001000    Time 0.073721    
2024-02-17 11:17:13,439 - Epoch: [23][  400/  500]    Overall Loss 1.494041    Objective Loss 1.494041                                        LR 0.001000    Time 0.072988    
2024-02-17 11:17:20,711 - Epoch: [23][  500/  500]    Overall Loss 1.495390    Objective Loss 1.495390    Top1 51.500000    Top5 80.000000    LR 0.001000    Time 0.072926    
2024-02-17 11:17:20,830 - --- validate (epoch=23)-----------
2024-02-17 11:17:20,831 - 10000 samples (100 per mini-batch)
2024-02-17 11:17:23,805 - Epoch: [23][  100/  100]    Loss 1.921122    Top1 49.480000    Top5 80.280000    
2024-02-17 11:17:23,930 - ==> Top1: 49.480    Top5: 80.280    Loss: 1.921

2024-02-17 11:17:23,939 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-17 11:17:23,940 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:17:24,001 - 

2024-02-17 11:17:24,002 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:17:31,890 - Epoch: [24][  100/  500]    Overall Loss 1.432018    Objective Loss 1.432018                                        LR 0.001000    Time 0.078828    
2024-02-17 11:17:39,174 - Epoch: [24][  200/  500]    Overall Loss 1.439184    Objective Loss 1.439184                                        LR 0.001000    Time 0.075811    
2024-02-17 11:17:46,445 - Epoch: [24][  300/  500]    Overall Loss 1.446274    Objective Loss 1.446274                                        LR 0.001000    Time 0.074762    
2024-02-17 11:17:53,517 - Epoch: [24][  400/  500]    Overall Loss 1.455156    Objective Loss 1.455156                                        LR 0.001000    Time 0.073742    
2024-02-17 11:18:00,660 - Epoch: [24][  500/  500]    Overall Loss 1.462438    Objective Loss 1.462438    Top1 54.500000    Top5 88.000000    LR 0.001000    Time 0.073272    
2024-02-17 11:18:00,762 - --- validate (epoch=24)-----------
2024-02-17 11:18:00,763 - 10000 samples (100 per mini-batch)
2024-02-17 11:18:03,735 - Epoch: [24][  100/  100]    Loss 2.288580    Top1 45.180000    Top5 76.230000    
2024-02-17 11:18:03,861 - ==> Top1: 45.180    Top5: 76.230    Loss: 2.289

2024-02-17 11:18:03,872 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-17 11:18:03,872 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:18:03,937 - 

2024-02-17 11:18:03,938 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:18:11,672 - Epoch: [25][  100/  500]    Overall Loss 1.423045    Objective Loss 1.423045                                        LR 0.001000    Time 0.077250    
2024-02-17 11:18:19,009 - Epoch: [25][  200/  500]    Overall Loss 1.432119    Objective Loss 1.432119                                        LR 0.001000    Time 0.075288    
2024-02-17 11:18:26,121 - Epoch: [25][  300/  500]    Overall Loss 1.435971    Objective Loss 1.435971                                        LR 0.001000    Time 0.073886    
2024-02-17 11:18:33,184 - Epoch: [25][  400/  500]    Overall Loss 1.439155    Objective Loss 1.439155                                        LR 0.001000    Time 0.073061    
2024-02-17 11:18:40,251 - Epoch: [25][  500/  500]    Overall Loss 1.446353    Objective Loss 1.446353    Top1 59.000000    Top5 88.000000    LR 0.001000    Time 0.072575    
2024-02-17 11:18:40,355 - --- validate (epoch=25)-----------
2024-02-17 11:18:40,355 - 10000 samples (100 per mini-batch)
2024-02-17 11:18:43,321 - Epoch: [25][  100/  100]    Loss 1.934736    Top1 50.320000    Top5 80.460000    
2024-02-17 11:18:43,428 - ==> Top1: 50.320    Top5: 80.460    Loss: 1.935

2024-02-17 11:18:43,439 - ==> Best [Top1: 50.320   Top5: 80.460   Sparsity:0.00   Params: 753952 on epoch: 25]
2024-02-17 11:18:43,439 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:18:43,519 - 

2024-02-17 11:18:43,520 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:18:51,075 - Epoch: [26][  100/  500]    Overall Loss 1.370702    Objective Loss 1.370702                                        LR 0.001000    Time 0.075505    
2024-02-17 11:18:58,322 - Epoch: [26][  200/  500]    Overall Loss 1.381659    Objective Loss 1.381659                                        LR 0.001000    Time 0.073964    
2024-02-17 11:19:05,581 - Epoch: [26][  300/  500]    Overall Loss 1.401317    Objective Loss 1.401317                                        LR 0.001000    Time 0.073491    
2024-02-17 11:19:12,901 - Epoch: [26][  400/  500]    Overall Loss 1.416794    Objective Loss 1.416794                                        LR 0.001000    Time 0.073406    
2024-02-17 11:19:20,274 - Epoch: [26][  500/  500]    Overall Loss 1.416493    Objective Loss 1.416493    Top1 64.500000    Top5 84.500000    LR 0.001000    Time 0.073463    
2024-02-17 11:19:20,476 - --- validate (epoch=26)-----------
2024-02-17 11:19:20,476 - 10000 samples (100 per mini-batch)
2024-02-17 11:19:23,668 - Epoch: [26][  100/  100]    Loss 1.971634    Top1 49.450000    Top5 79.280000    
2024-02-17 11:19:23,772 - ==> Top1: 49.450    Top5: 79.280    Loss: 1.972

2024-02-17 11:19:23,783 - ==> Best [Top1: 50.320   Top5: 80.460   Sparsity:0.00   Params: 753952 on epoch: 25]
2024-02-17 11:19:23,783 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:19:23,842 - 

2024-02-17 11:19:23,842 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:19:31,574 - Epoch: [27][  100/  500]    Overall Loss 1.348677    Objective Loss 1.348677                                        LR 0.001000    Time 0.077256    
2024-02-17 11:19:38,836 - Epoch: [27][  200/  500]    Overall Loss 1.366492    Objective Loss 1.366492                                        LR 0.001000    Time 0.074920    
2024-02-17 11:19:45,983 - Epoch: [27][  300/  500]    Overall Loss 1.378561    Objective Loss 1.378561                                        LR 0.001000    Time 0.073754    
2024-02-17 11:19:53,057 - Epoch: [27][  400/  500]    Overall Loss 1.381536    Objective Loss 1.381536                                        LR 0.001000    Time 0.072991    
2024-02-17 11:20:00,345 - Epoch: [27][  500/  500]    Overall Loss 1.394964    Objective Loss 1.394964    Top1 60.500000    Top5 88.000000    LR 0.001000    Time 0.072960    
2024-02-17 11:20:00,469 - --- validate (epoch=27)-----------
2024-02-17 11:20:00,469 - 10000 samples (100 per mini-batch)
2024-02-17 11:20:03,581 - Epoch: [27][  100/  100]    Loss 2.050875    Top1 49.450000    Top5 78.590000    
2024-02-17 11:20:03,730 - ==> Top1: 49.450    Top5: 78.590    Loss: 2.051

2024-02-17 11:20:03,741 - ==> Best [Top1: 50.320   Top5: 80.460   Sparsity:0.00   Params: 753952 on epoch: 25]
2024-02-17 11:20:03,742 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:20:03,806 - 

2024-02-17 11:20:03,806 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:20:11,803 - Epoch: [28][  100/  500]    Overall Loss 1.328535    Objective Loss 1.328535                                        LR 0.001000    Time 0.079916    
2024-02-17 11:20:18,962 - Epoch: [28][  200/  500]    Overall Loss 1.350845    Objective Loss 1.350845                                        LR 0.001000    Time 0.075729    
2024-02-17 11:20:26,118 - Epoch: [28][  300/  500]    Overall Loss 1.362088    Objective Loss 1.362088                                        LR 0.001000    Time 0.074327    
2024-02-17 11:20:33,224 - Epoch: [28][  400/  500]    Overall Loss 1.363851    Objective Loss 1.363851                                        LR 0.001000    Time 0.073499    
2024-02-17 11:20:40,402 - Epoch: [28][  500/  500]    Overall Loss 1.367499    Objective Loss 1.367499    Top1 62.000000    Top5 87.500000    LR 0.001000    Time 0.073148    
2024-02-17 11:20:40,521 - --- validate (epoch=28)-----------
2024-02-17 11:20:40,523 - 10000 samples (100 per mini-batch)
2024-02-17 11:20:43,615 - Epoch: [28][  100/  100]    Loss 1.873124    Top1 51.380000    Top5 81.140000    
2024-02-17 11:20:43,712 - ==> Top1: 51.380    Top5: 81.140    Loss: 1.873

2024-02-17 11:20:43,722 - ==> Best [Top1: 51.380   Top5: 81.140   Sparsity:0.00   Params: 753952 on epoch: 28]
2024-02-17 11:20:43,723 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:20:43,796 - 

2024-02-17 11:20:43,797 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:20:51,309 - Epoch: [29][  100/  500]    Overall Loss 1.325078    Objective Loss 1.325078                                        LR 0.001000    Time 0.075072    
2024-02-17 11:20:58,017 - Epoch: [29][  200/  500]    Overall Loss 1.337117    Objective Loss 1.337117                                        LR 0.001000    Time 0.071058    
2024-02-17 11:21:05,090 - Epoch: [29][  300/  500]    Overall Loss 1.347000    Objective Loss 1.347000                                        LR 0.001000    Time 0.070936    
2024-02-17 11:21:12,211 - Epoch: [29][  400/  500]    Overall Loss 1.351536    Objective Loss 1.351536                                        LR 0.001000    Time 0.070996    
2024-02-17 11:21:19,424 - Epoch: [29][  500/  500]    Overall Loss 1.354046    Objective Loss 1.354046    Top1 63.000000    Top5 88.500000    LR 0.001000    Time 0.071213    
2024-02-17 11:21:19,585 - --- validate (epoch=29)-----------
2024-02-17 11:21:19,586 - 10000 samples (100 per mini-batch)
2024-02-17 11:21:22,656 - Epoch: [29][  100/  100]    Loss 1.797290    Top1 53.410000    Top5 81.720000    
2024-02-17 11:21:22,798 - ==> Top1: 53.410    Top5: 81.720    Loss: 1.797

2024-02-17 11:21:22,807 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:21:22,807 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:21:22,892 - 

2024-02-17 11:21:22,893 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:21:30,809 - Epoch: [30][  100/  500]    Overall Loss 1.287730    Objective Loss 1.287730                                        LR 0.001000    Time 0.079082    
2024-02-17 11:21:38,176 - Epoch: [30][  200/  500]    Overall Loss 1.299301    Objective Loss 1.299301                                        LR 0.001000    Time 0.076352    
2024-02-17 11:21:45,281 - Epoch: [30][  300/  500]    Overall Loss 1.313185    Objective Loss 1.313185                                        LR 0.001000    Time 0.074570    
2024-02-17 11:21:52,355 - Epoch: [30][  400/  500]    Overall Loss 1.322461    Objective Loss 1.322461                                        LR 0.001000    Time 0.073602    
2024-02-17 11:21:59,361 - Epoch: [30][  500/  500]    Overall Loss 1.331671    Objective Loss 1.331671    Top1 67.000000    Top5 89.000000    LR 0.001000    Time 0.072886    
2024-02-17 11:21:59,509 - --- validate (epoch=30)-----------
2024-02-17 11:21:59,510 - 10000 samples (100 per mini-batch)
2024-02-17 11:22:02,721 - Epoch: [30][  100/  100]    Loss 1.824264    Top1 52.090000    Top5 80.960000    
2024-02-17 11:22:02,882 - ==> Top1: 52.090    Top5: 80.960    Loss: 1.824

2024-02-17 11:22:02,892 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:22:02,893 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:22:02,956 - 

2024-02-17 11:22:02,956 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:22:10,525 - Epoch: [31][  100/  500]    Overall Loss 1.285199    Objective Loss 1.285199                                        LR 0.001000    Time 0.075625    
2024-02-17 11:22:17,739 - Epoch: [31][  200/  500]    Overall Loss 1.281403    Objective Loss 1.281403                                        LR 0.001000    Time 0.073859    
2024-02-17 11:22:24,928 - Epoch: [31][  300/  500]    Overall Loss 1.289112    Objective Loss 1.289112                                        LR 0.001000    Time 0.073190    
2024-02-17 11:22:31,967 - Epoch: [31][  400/  500]    Overall Loss 1.297153    Objective Loss 1.297153                                        LR 0.001000    Time 0.072480    
2024-02-17 11:22:39,188 - Epoch: [31][  500/  500]    Overall Loss 1.304195    Objective Loss 1.304195    Top1 65.000000    Top5 88.000000    LR 0.001000    Time 0.072417    
2024-02-17 11:22:39,369 - --- validate (epoch=31)-----------
2024-02-17 11:22:39,371 - 10000 samples (100 per mini-batch)
2024-02-17 11:22:42,264 - Epoch: [31][  100/  100]    Loss 1.831615    Top1 52.490000    Top5 81.970000    
2024-02-17 11:22:42,382 - ==> Top1: 52.490    Top5: 81.970    Loss: 1.832

2024-02-17 11:22:42,393 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:22:42,393 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:22:42,453 - 

2024-02-17 11:22:42,454 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:22:50,333 - Epoch: [32][  100/  500]    Overall Loss 1.256892    Objective Loss 1.256892                                        LR 0.001000    Time 0.078737    
2024-02-17 11:22:57,641 - Epoch: [32][  200/  500]    Overall Loss 1.268618    Objective Loss 1.268618                                        LR 0.001000    Time 0.075884    
2024-02-17 11:23:04,886 - Epoch: [32][  300/  500]    Overall Loss 1.278748    Objective Loss 1.278748                                        LR 0.001000    Time 0.074726    
2024-02-17 11:23:11,935 - Epoch: [32][  400/  500]    Overall Loss 1.282109    Objective Loss 1.282109                                        LR 0.001000    Time 0.073657    
2024-02-17 11:23:19,128 - Epoch: [32][  500/  500]    Overall Loss 1.286492    Objective Loss 1.286492    Top1 62.000000    Top5 92.000000    LR 0.001000    Time 0.073302    
2024-02-17 11:23:19,247 - --- validate (epoch=32)-----------
2024-02-17 11:23:19,248 - 10000 samples (100 per mini-batch)
2024-02-17 11:23:22,139 - Epoch: [32][  100/  100]    Loss 1.907953    Top1 51.330000    Top5 81.220000    
2024-02-17 11:23:22,275 - ==> Top1: 51.330    Top5: 81.220    Loss: 1.908

2024-02-17 11:23:22,286 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:23:22,287 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:23:22,347 - 

2024-02-17 11:23:22,348 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:23:29,910 - Epoch: [33][  100/  500]    Overall Loss 1.234660    Objective Loss 1.234660                                        LR 0.001000    Time 0.075566    
2024-02-17 11:23:36,951 - Epoch: [33][  200/  500]    Overall Loss 1.252759    Objective Loss 1.252759                                        LR 0.001000    Time 0.072969    
2024-02-17 11:23:44,280 - Epoch: [33][  300/  500]    Overall Loss 1.261966    Objective Loss 1.261966                                        LR 0.001000    Time 0.073063    
2024-02-17 11:23:51,421 - Epoch: [33][  400/  500]    Overall Loss 1.266817    Objective Loss 1.266817                                        LR 0.001000    Time 0.072638    
2024-02-17 11:23:58,658 - Epoch: [33][  500/  500]    Overall Loss 1.273002    Objective Loss 1.273002    Top1 59.500000    Top5 85.000000    LR 0.001000    Time 0.072576    
2024-02-17 11:23:58,754 - --- validate (epoch=33)-----------
2024-02-17 11:23:58,754 - 10000 samples (100 per mini-batch)
2024-02-17 11:24:01,703 - Epoch: [33][  100/  100]    Loss 1.876940    Top1 51.540000    Top5 81.710000    
2024-02-17 11:24:01,851 - ==> Top1: 51.540    Top5: 81.710    Loss: 1.877

2024-02-17 11:24:01,862 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:24:01,863 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:24:01,924 - 

2024-02-17 11:24:01,924 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:24:09,730 - Epoch: [34][  100/  500]    Overall Loss 1.218805    Objective Loss 1.218805                                        LR 0.001000    Time 0.078011    
2024-02-17 11:24:16,804 - Epoch: [34][  200/  500]    Overall Loss 1.223326    Objective Loss 1.223326                                        LR 0.001000    Time 0.074354    
2024-02-17 11:24:23,986 - Epoch: [34][  300/  500]    Overall Loss 1.228984    Objective Loss 1.228984                                        LR 0.001000    Time 0.073495    
2024-02-17 11:24:31,003 - Epoch: [34][  400/  500]    Overall Loss 1.236273    Objective Loss 1.236273                                        LR 0.001000    Time 0.072653    
2024-02-17 11:24:38,122 - Epoch: [34][  500/  500]    Overall Loss 1.248150    Objective Loss 1.248150    Top1 64.000000    Top5 90.500000    LR 0.001000    Time 0.072353    
2024-02-17 11:24:38,297 - --- validate (epoch=34)-----------
2024-02-17 11:24:38,298 - 10000 samples (100 per mini-batch)
2024-02-17 11:24:41,156 - Epoch: [34][  100/  100]    Loss 1.937653    Top1 52.230000    Top5 80.870000    
2024-02-17 11:24:41,357 - ==> Top1: 52.230    Top5: 80.870    Loss: 1.938

2024-02-17 11:24:41,368 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:24:41,369 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:24:41,431 - 

2024-02-17 11:24:41,431 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:24:49,201 - Epoch: [35][  100/  500]    Overall Loss 1.183362    Objective Loss 1.183362                                        LR 0.001000    Time 0.077647    
2024-02-17 11:24:56,275 - Epoch: [35][  200/  500]    Overall Loss 1.197224    Objective Loss 1.197224                                        LR 0.001000    Time 0.074173    
2024-02-17 11:25:03,589 - Epoch: [35][  300/  500]    Overall Loss 1.205798    Objective Loss 1.205798                                        LR 0.001000    Time 0.073813    
2024-02-17 11:25:10,644 - Epoch: [35][  400/  500]    Overall Loss 1.225171    Objective Loss 1.225171                                        LR 0.001000    Time 0.072988    
2024-02-17 11:25:17,850 - Epoch: [35][  500/  500]    Overall Loss 1.231215    Objective Loss 1.231215    Top1 63.000000    Top5 90.000000    LR 0.001000    Time 0.072793    
2024-02-17 11:25:18,032 - --- validate (epoch=35)-----------
2024-02-17 11:25:18,033 - 10000 samples (100 per mini-batch)
2024-02-17 11:25:20,997 - Epoch: [35][  100/  100]    Loss 1.796121    Top1 53.010000    Top5 82.540000    
2024-02-17 11:25:21,090 - ==> Top1: 53.010    Top5: 82.540    Loss: 1.796

2024-02-17 11:25:21,100 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:25:21,100 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:25:21,161 - 

2024-02-17 11:25:21,162 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:25:28,787 - Epoch: [36][  100/  500]    Overall Loss 1.157656    Objective Loss 1.157656                                        LR 0.001000    Time 0.076206    
2024-02-17 11:25:36,042 - Epoch: [36][  200/  500]    Overall Loss 1.183921    Objective Loss 1.183921                                        LR 0.001000    Time 0.074357    
2024-02-17 11:25:43,202 - Epoch: [36][  300/  500]    Overall Loss 1.203144    Objective Loss 1.203144                                        LR 0.001000    Time 0.073426    
2024-02-17 11:25:50,302 - Epoch: [36][  400/  500]    Overall Loss 1.207459    Objective Loss 1.207459                                        LR 0.001000    Time 0.072809    
2024-02-17 11:25:57,529 - Epoch: [36][  500/  500]    Overall Loss 1.211898    Objective Loss 1.211898    Top1 68.000000    Top5 90.500000    LR 0.001000    Time 0.072693    
2024-02-17 11:25:57,670 - --- validate (epoch=36)-----------
2024-02-17 11:25:57,671 - 10000 samples (100 per mini-batch)
2024-02-17 11:26:00,548 - Epoch: [36][  100/  100]    Loss 1.850014    Top1 52.670000    Top5 81.390000    
2024-02-17 11:26:00,682 - ==> Top1: 52.670    Top5: 81.390    Loss: 1.850

2024-02-17 11:26:00,693 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:26:00,693 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:26:00,759 - 

2024-02-17 11:26:00,760 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:26:08,449 - Epoch: [37][  100/  500]    Overall Loss 1.168624    Objective Loss 1.168624                                        LR 0.001000    Time 0.076837    
2024-02-17 11:26:15,629 - Epoch: [37][  200/  500]    Overall Loss 1.180387    Objective Loss 1.180387                                        LR 0.001000    Time 0.074300    
2024-02-17 11:26:22,787 - Epoch: [37][  300/  500]    Overall Loss 1.177521    Objective Loss 1.177521                                        LR 0.001000    Time 0.073379    
2024-02-17 11:26:29,885 - Epoch: [37][  400/  500]    Overall Loss 1.183165    Objective Loss 1.183165                                        LR 0.001000    Time 0.072769    
2024-02-17 11:26:37,036 - Epoch: [37][  500/  500]    Overall Loss 1.195524    Objective Loss 1.195524    Top1 57.000000    Top5 86.000000    LR 0.001000    Time 0.072508    
2024-02-17 11:26:37,227 - --- validate (epoch=37)-----------
2024-02-17 11:26:37,227 - 10000 samples (100 per mini-batch)
2024-02-17 11:26:40,271 - Epoch: [37][  100/  100]    Loss 1.863734    Top1 52.960000    Top5 81.110000    
2024-02-17 11:26:40,430 - ==> Top1: 52.960    Top5: 81.110    Loss: 1.864

2024-02-17 11:26:40,442 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:26:40,442 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:26:40,507 - 

2024-02-17 11:26:40,507 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:26:48,383 - Epoch: [38][  100/  500]    Overall Loss 1.126354    Objective Loss 1.126354                                        LR 0.001000    Time 0.078701    
2024-02-17 11:26:55,635 - Epoch: [38][  200/  500]    Overall Loss 1.148542    Objective Loss 1.148542                                        LR 0.001000    Time 0.075586    
2024-02-17 11:27:02,771 - Epoch: [38][  300/  500]    Overall Loss 1.159107    Objective Loss 1.159107                                        LR 0.001000    Time 0.074164    
2024-02-17 11:27:09,832 - Epoch: [38][  400/  500]    Overall Loss 1.166049    Objective Loss 1.166049                                        LR 0.001000    Time 0.073265    
2024-02-17 11:27:16,790 - Epoch: [38][  500/  500]    Overall Loss 1.173457    Objective Loss 1.173457    Top1 60.000000    Top5 89.500000    LR 0.001000    Time 0.072521    
2024-02-17 11:27:16,910 - --- validate (epoch=38)-----------
2024-02-17 11:27:16,911 - 10000 samples (100 per mini-batch)
2024-02-17 11:27:19,993 - Epoch: [38][  100/  100]    Loss 1.933706    Top1 51.900000    Top5 81.390000    
2024-02-17 11:27:20,089 - ==> Top1: 51.900    Top5: 81.390    Loss: 1.934

2024-02-17 11:27:20,100 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:27:20,100 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:27:20,163 - 

2024-02-17 11:27:20,163 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:27:27,868 - Epoch: [39][  100/  500]    Overall Loss 1.136036    Objective Loss 1.136036                                        LR 0.001000    Time 0.076985    
2024-02-17 11:27:35,100 - Epoch: [39][  200/  500]    Overall Loss 1.146980    Objective Loss 1.146980                                        LR 0.001000    Time 0.074633    
2024-02-17 11:27:42,247 - Epoch: [39][  300/  500]    Overall Loss 1.155615    Objective Loss 1.155615                                        LR 0.001000    Time 0.073566    
2024-02-17 11:27:49,410 - Epoch: [39][  400/  500]    Overall Loss 1.160542    Objective Loss 1.160542                                        LR 0.001000    Time 0.073071    
2024-02-17 11:27:56,622 - Epoch: [39][  500/  500]    Overall Loss 1.164606    Objective Loss 1.164606    Top1 64.500000    Top5 92.500000    LR 0.001000    Time 0.072871    
2024-02-17 11:27:56,793 - --- validate (epoch=39)-----------
2024-02-17 11:27:56,794 - 10000 samples (100 per mini-batch)
2024-02-17 11:27:59,759 - Epoch: [39][  100/  100]    Loss 1.959881    Top1 52.020000    Top5 80.500000    
2024-02-17 11:27:59,939 - ==> Top1: 52.020    Top5: 80.500    Loss: 1.960

2024-02-17 11:27:59,949 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-17 11:27:59,949 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:28:00,011 - 

2024-02-17 11:28:00,011 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:28:07,884 - Epoch: [40][  100/  500]    Overall Loss 1.099555    Objective Loss 1.099555                                        LR 0.001000    Time 0.078676    
2024-02-17 11:28:14,953 - Epoch: [40][  200/  500]    Overall Loss 1.107798    Objective Loss 1.107798                                        LR 0.001000    Time 0.074660    
2024-02-17 11:28:22,214 - Epoch: [40][  300/  500]    Overall Loss 1.119186    Objective Loss 1.119186                                        LR 0.001000    Time 0.073962    
2024-02-17 11:28:28,954 - Epoch: [40][  400/  500]    Overall Loss 1.135157    Objective Loss 1.135157                                        LR 0.001000    Time 0.072314    
2024-02-17 11:28:36,086 - Epoch: [40][  500/  500]    Overall Loss 1.139456    Objective Loss 1.139456    Top1 67.500000    Top5 91.000000    LR 0.001000    Time 0.072106    
2024-02-17 11:28:36,231 - --- validate (epoch=40)-----------
2024-02-17 11:28:36,232 - 10000 samples (100 per mini-batch)
2024-02-17 11:28:39,127 - Epoch: [40][  100/  100]    Loss 1.839705    Top1 53.910000    Top5 82.340000    
2024-02-17 11:28:39,220 - ==> Top1: 53.910    Top5: 82.340    Loss: 1.840

2024-02-17 11:28:39,232 - ==> Best [Top1: 53.910   Top5: 82.340   Sparsity:0.00   Params: 753952 on epoch: 40]
2024-02-17 11:28:39,233 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:28:39,308 - 

2024-02-17 11:28:39,309 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:28:47,033 - Epoch: [41][  100/  500]    Overall Loss 1.098113    Objective Loss 1.098113                                        LR 0.001000    Time 0.077186    
2024-02-17 11:28:54,343 - Epoch: [41][  200/  500]    Overall Loss 1.099937    Objective Loss 1.099937                                        LR 0.001000    Time 0.075120    
2024-02-17 11:29:01,383 - Epoch: [41][  300/  500]    Overall Loss 1.105861    Objective Loss 1.105861                                        LR 0.001000    Time 0.073535    
2024-02-17 11:29:08,516 - Epoch: [41][  400/  500]    Overall Loss 1.114760    Objective Loss 1.114760                                        LR 0.001000    Time 0.072972    
2024-02-17 11:29:15,732 - Epoch: [41][  500/  500]    Overall Loss 1.122951    Objective Loss 1.122951    Top1 68.000000    Top5 91.500000    LR 0.001000    Time 0.072801    
2024-02-17 11:29:15,896 - --- validate (epoch=41)-----------
2024-02-17 11:29:15,897 - 10000 samples (100 per mini-batch)
2024-02-17 11:29:18,708 - Epoch: [41][  100/  100]    Loss 1.782460    Top1 54.690000    Top5 82.720000    
2024-02-17 11:29:18,867 - ==> Top1: 54.690    Top5: 82.720    Loss: 1.782

2024-02-17 11:29:18,877 - ==> Best [Top1: 54.690   Top5: 82.720   Sparsity:0.00   Params: 753952 on epoch: 41]
2024-02-17 11:29:18,878 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:29:18,954 - 

2024-02-17 11:29:18,954 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:29:26,672 - Epoch: [42][  100/  500]    Overall Loss 1.089304    Objective Loss 1.089304                                        LR 0.001000    Time 0.077128    
2024-02-17 11:29:33,936 - Epoch: [42][  200/  500]    Overall Loss 1.088567    Objective Loss 1.088567                                        LR 0.001000    Time 0.074861    
2024-02-17 11:29:41,046 - Epoch: [42][  300/  500]    Overall Loss 1.090409    Objective Loss 1.090409                                        LR 0.001000    Time 0.073594    
2024-02-17 11:29:48,285 - Epoch: [42][  400/  500]    Overall Loss 1.103778    Objective Loss 1.103778                                        LR 0.001000    Time 0.073281    
2024-02-17 11:29:55,521 - Epoch: [42][  500/  500]    Overall Loss 1.108860    Objective Loss 1.108860    Top1 71.500000    Top5 90.000000    LR 0.001000    Time 0.073086    
2024-02-17 11:29:55,666 - --- validate (epoch=42)-----------
2024-02-17 11:29:55,667 - 10000 samples (100 per mini-batch)
2024-02-17 11:29:58,853 - Epoch: [42][  100/  100]    Loss 1.801879    Top1 54.520000    Top5 82.590000    
2024-02-17 11:29:58,994 - ==> Top1: 54.520    Top5: 82.590    Loss: 1.802

2024-02-17 11:29:59,004 - ==> Best [Top1: 54.690   Top5: 82.720   Sparsity:0.00   Params: 753952 on epoch: 41]
2024-02-17 11:29:59,004 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:29:59,066 - 

2024-02-17 11:29:59,066 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:30:06,747 - Epoch: [43][  100/  500]    Overall Loss 1.059019    Objective Loss 1.059019                                        LR 0.001000    Time 0.076760    
2024-02-17 11:30:13,870 - Epoch: [43][  200/  500]    Overall Loss 1.070833    Objective Loss 1.070833                                        LR 0.001000    Time 0.073975    
2024-02-17 11:30:21,018 - Epoch: [43][  300/  500]    Overall Loss 1.076827    Objective Loss 1.076827                                        LR 0.001000    Time 0.073128    
2024-02-17 11:30:28,200 - Epoch: [43][  400/  500]    Overall Loss 1.089423    Objective Loss 1.089423                                        LR 0.001000    Time 0.072790    
2024-02-17 11:30:35,245 - Epoch: [43][  500/  500]    Overall Loss 1.100200    Objective Loss 1.100200    Top1 63.000000    Top5 89.000000    LR 0.001000    Time 0.072315    
2024-02-17 11:30:35,394 - --- validate (epoch=43)-----------
2024-02-17 11:30:35,395 - 10000 samples (100 per mini-batch)
2024-02-17 11:30:38,334 - Epoch: [43][  100/  100]    Loss 1.852823    Top1 53.770000    Top5 83.190000    
2024-02-17 11:30:38,428 - ==> Top1: 53.770    Top5: 83.190    Loss: 1.853

2024-02-17 11:30:38,440 - ==> Best [Top1: 54.690   Top5: 82.720   Sparsity:0.00   Params: 753952 on epoch: 41]
2024-02-17 11:30:38,440 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:30:38,501 - 

2024-02-17 11:30:38,501 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:30:46,151 - Epoch: [44][  100/  500]    Overall Loss 1.047904    Objective Loss 1.047904                                        LR 0.001000    Time 0.076438    
2024-02-17 11:30:53,268 - Epoch: [44][  200/  500]    Overall Loss 1.062250    Objective Loss 1.062250                                        LR 0.001000    Time 0.073784    
2024-02-17 11:31:00,471 - Epoch: [44][  300/  500]    Overall Loss 1.065268    Objective Loss 1.065268                                        LR 0.001000    Time 0.073186    
2024-02-17 11:31:07,658 - Epoch: [44][  400/  500]    Overall Loss 1.066647    Objective Loss 1.066647                                        LR 0.001000    Time 0.072845    
2024-02-17 11:31:14,848 - Epoch: [44][  500/  500]    Overall Loss 1.078985    Objective Loss 1.078985    Top1 67.000000    Top5 87.500000    LR 0.001000    Time 0.072647    
2024-02-17 11:31:14,970 - --- validate (epoch=44)-----------
2024-02-17 11:31:14,971 - 10000 samples (100 per mini-batch)
2024-02-17 11:31:18,067 - Epoch: [44][  100/  100]    Loss 1.821990    Top1 54.740000    Top5 82.280000    
2024-02-17 11:31:18,221 - ==> Top1: 54.740    Top5: 82.280    Loss: 1.822

2024-02-17 11:31:18,233 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-17 11:31:18,233 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:31:18,308 - 

2024-02-17 11:31:18,309 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:31:25,830 - Epoch: [45][  100/  500]    Overall Loss 1.003887    Objective Loss 1.003887                                        LR 0.001000    Time 0.075158    
2024-02-17 11:31:32,865 - Epoch: [45][  200/  500]    Overall Loss 1.031504    Objective Loss 1.031504                                        LR 0.001000    Time 0.072734    
2024-02-17 11:31:40,043 - Epoch: [45][  300/  500]    Overall Loss 1.046354    Objective Loss 1.046354                                        LR 0.001000    Time 0.072404    
2024-02-17 11:31:47,153 - Epoch: [45][  400/  500]    Overall Loss 1.056035    Objective Loss 1.056035                                        LR 0.001000    Time 0.072067    
2024-02-17 11:31:54,321 - Epoch: [45][  500/  500]    Overall Loss 1.068227    Objective Loss 1.068227    Top1 66.000000    Top5 89.000000    LR 0.001000    Time 0.071980    
2024-02-17 11:31:54,495 - --- validate (epoch=45)-----------
2024-02-17 11:31:54,496 - 10000 samples (100 per mini-batch)
2024-02-17 11:31:57,398 - Epoch: [45][  100/  100]    Loss 1.828801    Top1 54.110000    Top5 82.480000    
2024-02-17 11:31:57,554 - ==> Top1: 54.110    Top5: 82.480    Loss: 1.829

2024-02-17 11:31:57,564 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-17 11:31:57,565 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:31:57,626 - 

2024-02-17 11:31:57,626 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:32:05,638 - Epoch: [46][  100/  500]    Overall Loss 1.009476    Objective Loss 1.009476                                        LR 0.001000    Time 0.080059    
2024-02-17 11:32:12,874 - Epoch: [46][  200/  500]    Overall Loss 1.027685    Objective Loss 1.027685                                        LR 0.001000    Time 0.076187    
2024-02-17 11:32:20,162 - Epoch: [46][  300/  500]    Overall Loss 1.036520    Objective Loss 1.036520                                        LR 0.001000    Time 0.075070    
2024-02-17 11:32:27,253 - Epoch: [46][  400/  500]    Overall Loss 1.042552    Objective Loss 1.042552                                        LR 0.001000    Time 0.074020    
2024-02-17 11:32:34,439 - Epoch: [46][  500/  500]    Overall Loss 1.052531    Objective Loss 1.052531    Top1 73.000000    Top5 96.000000    LR 0.001000    Time 0.073581    
2024-02-17 11:32:34,615 - --- validate (epoch=46)-----------
2024-02-17 11:32:34,616 - 10000 samples (100 per mini-batch)
2024-02-17 11:32:37,531 - Epoch: [46][  100/  100]    Loss 1.830720    Top1 53.730000    Top5 82.630000    
2024-02-17 11:32:37,632 - ==> Top1: 53.730    Top5: 82.630    Loss: 1.831

2024-02-17 11:32:37,643 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-17 11:32:37,643 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:32:37,703 - 

2024-02-17 11:32:37,703 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:32:45,343 - Epoch: [47][  100/  500]    Overall Loss 0.999660    Objective Loss 0.999660                                        LR 0.001000    Time 0.076345    
2024-02-17 11:32:52,413 - Epoch: [47][  200/  500]    Overall Loss 1.003852    Objective Loss 1.003852                                        LR 0.001000    Time 0.073499    
2024-02-17 11:32:59,462 - Epoch: [47][  300/  500]    Overall Loss 1.014563    Objective Loss 1.014563                                        LR 0.001000    Time 0.072484    
2024-02-17 11:33:06,552 - Epoch: [47][  400/  500]    Overall Loss 1.020945    Objective Loss 1.020945                                        LR 0.001000    Time 0.072077    
2024-02-17 11:33:13,805 - Epoch: [47][  500/  500]    Overall Loss 1.030677    Objective Loss 1.030677    Top1 70.000000    Top5 95.000000    LR 0.001000    Time 0.072161    
2024-02-17 11:33:13,913 - --- validate (epoch=47)-----------
2024-02-17 11:33:13,914 - 10000 samples (100 per mini-batch)
2024-02-17 11:33:16,828 - Epoch: [47][  100/  100]    Loss 1.896644    Top1 54.310000    Top5 82.350000    
2024-02-17 11:33:16,924 - ==> Top1: 54.310    Top5: 82.350    Loss: 1.897

2024-02-17 11:33:16,935 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-17 11:33:16,935 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:33:16,996 - 

2024-02-17 11:33:16,996 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:33:24,696 - Epoch: [48][  100/  500]    Overall Loss 1.005949    Objective Loss 1.005949                                        LR 0.001000    Time 0.076945    
2024-02-17 11:33:31,857 - Epoch: [48][  200/  500]    Overall Loss 1.002851    Objective Loss 1.002851                                        LR 0.001000    Time 0.074255    
2024-02-17 11:33:39,120 - Epoch: [48][  300/  500]    Overall Loss 1.013319    Objective Loss 1.013319                                        LR 0.001000    Time 0.073697    
2024-02-17 11:33:46,149 - Epoch: [48][  400/  500]    Overall Loss 1.015516    Objective Loss 1.015516                                        LR 0.001000    Time 0.072836    
2024-02-17 11:33:53,486 - Epoch: [48][  500/  500]    Overall Loss 1.024054    Objective Loss 1.024054    Top1 69.000000    Top5 93.000000    LR 0.001000    Time 0.072934    
2024-02-17 11:33:53,657 - --- validate (epoch=48)-----------
2024-02-17 11:33:53,658 - 10000 samples (100 per mini-batch)
2024-02-17 11:33:56,766 - Epoch: [48][  100/  100]    Loss 1.873272    Top1 54.180000    Top5 82.180000    
2024-02-17 11:33:56,940 - ==> Top1: 54.180    Top5: 82.180    Loss: 1.873

2024-02-17 11:33:56,952 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-17 11:33:56,953 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:33:57,015 - 

2024-02-17 11:33:57,015 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:34:04,728 - Epoch: [49][  100/  500]    Overall Loss 0.991793    Objective Loss 0.991793                                        LR 0.001000    Time 0.077069    
2024-02-17 11:34:11,943 - Epoch: [49][  200/  500]    Overall Loss 0.981546    Objective Loss 0.981546                                        LR 0.001000    Time 0.074588    
2024-02-17 11:34:19,244 - Epoch: [49][  300/  500]    Overall Loss 0.990645    Objective Loss 0.990645                                        LR 0.001000    Time 0.074046    
2024-02-17 11:34:26,266 - Epoch: [49][  400/  500]    Overall Loss 1.000108    Objective Loss 1.000108                                        LR 0.001000    Time 0.073081    
2024-02-17 11:34:33,687 - Epoch: [49][  500/  500]    Overall Loss 1.004350    Objective Loss 1.004350    Top1 66.000000    Top5 91.000000    LR 0.001000    Time 0.073297    
2024-02-17 11:34:33,877 - --- validate (epoch=49)-----------
2024-02-17 11:34:33,878 - 10000 samples (100 per mini-batch)
2024-02-17 11:34:36,842 - Epoch: [49][  100/  100]    Loss 1.923390    Top1 53.300000    Top5 82.380000    
2024-02-17 11:34:36,994 - ==> Top1: 53.300    Top5: 82.380    Loss: 1.923

2024-02-17 11:34:37,002 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-17 11:34:37,002 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:34:37,094 - 

2024-02-17 11:34:37,094 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:34:45,104 - Epoch: [50][  100/  500]    Overall Loss 0.891832    Objective Loss 0.891832                                        LR 0.000500    Time 0.080037    
2024-02-17 11:34:52,309 - Epoch: [50][  200/  500]    Overall Loss 0.875344    Objective Loss 0.875344                                        LR 0.000500    Time 0.076025    
2024-02-17 11:34:59,550 - Epoch: [50][  300/  500]    Overall Loss 0.871916    Objective Loss 0.871916                                        LR 0.000500    Time 0.074806    
2024-02-17 11:35:06,638 - Epoch: [50][  400/  500]    Overall Loss 0.872488    Objective Loss 0.872488                                        LR 0.000500    Time 0.073813    
2024-02-17 11:35:13,880 - Epoch: [50][  500/  500]    Overall Loss 0.877727    Objective Loss 0.877727    Top1 69.000000    Top5 92.500000    LR 0.000500    Time 0.073526    
2024-02-17 11:35:14,059 - --- validate (epoch=50)-----------
2024-02-17 11:35:14,060 - 10000 samples (100 per mini-batch)
2024-02-17 11:35:16,975 - Epoch: [50][  100/  100]    Loss 1.586217    Top1 58.580000    Top5 85.530000    
2024-02-17 11:35:17,136 - ==> Top1: 58.580    Top5: 85.530    Loss: 1.586

2024-02-17 11:35:17,147 - ==> Best [Top1: 58.580   Top5: 85.530   Sparsity:0.00   Params: 753952 on epoch: 50]
2024-02-17 11:35:17,148 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:35:17,227 - 

2024-02-17 11:35:17,227 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:35:24,939 - Epoch: [51][  100/  500]    Overall Loss 0.807896    Objective Loss 0.807896                                        LR 0.000500    Time 0.077058    
2024-02-17 11:35:31,995 - Epoch: [51][  200/  500]    Overall Loss 0.833882    Objective Loss 0.833882                                        LR 0.000500    Time 0.073787    
2024-02-17 11:35:39,143 - Epoch: [51][  300/  500]    Overall Loss 0.841966    Objective Loss 0.841966                                        LR 0.000500    Time 0.073006    
2024-02-17 11:35:46,239 - Epoch: [51][  400/  500]    Overall Loss 0.849738    Objective Loss 0.849738                                        LR 0.000500    Time 0.072485    
2024-02-17 11:35:53,482 - Epoch: [51][  500/  500]    Overall Loss 0.849891    Objective Loss 0.849891    Top1 72.000000    Top5 95.500000    LR 0.000500    Time 0.072466    
2024-02-17 11:35:53,610 - --- validate (epoch=51)-----------
2024-02-17 11:35:53,611 - 10000 samples (100 per mini-batch)
2024-02-17 11:35:56,530 - Epoch: [51][  100/  100]    Loss 1.623510    Top1 58.210000    Top5 85.200000    
2024-02-17 11:35:56,721 - ==> Top1: 58.210    Top5: 85.200    Loss: 1.624

2024-02-17 11:35:56,731 - ==> Best [Top1: 58.580   Top5: 85.530   Sparsity:0.00   Params: 753952 on epoch: 50]
2024-02-17 11:35:56,732 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:35:56,797 - 

2024-02-17 11:35:56,798 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:36:04,713 - Epoch: [52][  100/  500]    Overall Loss 0.800980    Objective Loss 0.800980                                        LR 0.000500    Time 0.079100    
2024-02-17 11:36:11,873 - Epoch: [52][  200/  500]    Overall Loss 0.809246    Objective Loss 0.809246                                        LR 0.000500    Time 0.075325    
2024-02-17 11:36:18,979 - Epoch: [52][  300/  500]    Overall Loss 0.815269    Objective Loss 0.815269                                        LR 0.000500    Time 0.073889    
2024-02-17 11:36:26,136 - Epoch: [52][  400/  500]    Overall Loss 0.828829    Objective Loss 0.828829                                        LR 0.000500    Time 0.073299    
2024-02-17 11:36:33,214 - Epoch: [52][  500/  500]    Overall Loss 0.833809    Objective Loss 0.833809    Top1 72.000000    Top5 93.000000    LR 0.000500    Time 0.072788    
2024-02-17 11:36:33,345 - --- validate (epoch=52)-----------
2024-02-17 11:36:33,346 - 10000 samples (100 per mini-batch)
2024-02-17 11:36:36,266 - Epoch: [52][  100/  100]    Loss 1.649348    Top1 58.060000    Top5 85.130000    
2024-02-17 11:36:36,417 - ==> Top1: 58.060    Top5: 85.130    Loss: 1.649

2024-02-17 11:36:36,428 - ==> Best [Top1: 58.580   Top5: 85.530   Sparsity:0.00   Params: 753952 on epoch: 50]
2024-02-17 11:36:36,428 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:36:36,488 - 

2024-02-17 11:36:36,488 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:36:44,136 - Epoch: [53][  100/  500]    Overall Loss 0.789713    Objective Loss 0.789713                                        LR 0.000500    Time 0.076414    
2024-02-17 11:36:51,315 - Epoch: [53][  200/  500]    Overall Loss 0.799589    Objective Loss 0.799589                                        LR 0.000500    Time 0.074081    
2024-02-17 11:36:58,511 - Epoch: [53][  300/  500]    Overall Loss 0.810559    Objective Loss 0.810559                                        LR 0.000500    Time 0.073360    
2024-02-17 11:37:05,654 - Epoch: [53][  400/  500]    Overall Loss 0.815939    Objective Loss 0.815939                                        LR 0.000500    Time 0.072869    
2024-02-17 11:37:12,810 - Epoch: [53][  500/  500]    Overall Loss 0.820874    Objective Loss 0.820874    Top1 70.000000    Top5 95.000000    LR 0.000500    Time 0.072599    
2024-02-17 11:37:12,935 - --- validate (epoch=53)-----------
2024-02-17 11:37:12,936 - 10000 samples (100 per mini-batch)
2024-02-17 11:37:15,803 - Epoch: [53][  100/  100]    Loss 1.603811    Top1 58.960000    Top5 85.370000    
2024-02-17 11:37:15,921 - ==> Top1: 58.960    Top5: 85.370    Loss: 1.604

2024-02-17 11:37:15,932 - ==> Best [Top1: 58.960   Top5: 85.370   Sparsity:0.00   Params: 753952 on epoch: 53]
2024-02-17 11:37:15,932 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:37:16,009 - 

2024-02-17 11:37:16,009 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:37:23,710 - Epoch: [54][  100/  500]    Overall Loss 0.796024    Objective Loss 0.796024                                        LR 0.000500    Time 0.076950    
2024-02-17 11:37:30,891 - Epoch: [54][  200/  500]    Overall Loss 0.797079    Objective Loss 0.797079                                        LR 0.000500    Time 0.074356    
2024-02-17 11:37:38,018 - Epoch: [54][  300/  500]    Overall Loss 0.806079    Objective Loss 0.806079                                        LR 0.000500    Time 0.073315    
2024-02-17 11:37:45,175 - Epoch: [54][  400/  500]    Overall Loss 0.813309    Objective Loss 0.813309                                        LR 0.000500    Time 0.072868    
2024-02-17 11:37:52,387 - Epoch: [54][  500/  500]    Overall Loss 0.818176    Objective Loss 0.818176    Top1 76.500000    Top5 96.000000    LR 0.000500    Time 0.072711    
2024-02-17 11:37:52,556 - --- validate (epoch=54)-----------
2024-02-17 11:37:52,557 - 10000 samples (100 per mini-batch)
2024-02-17 11:37:55,649 - Epoch: [54][  100/  100]    Loss 1.654874    Top1 58.370000    Top5 84.970000    
2024-02-17 11:37:55,748 - ==> Top1: 58.370    Top5: 84.970    Loss: 1.655

2024-02-17 11:37:55,760 - ==> Best [Top1: 58.960   Top5: 85.370   Sparsity:0.00   Params: 753952 on epoch: 53]
2024-02-17 11:37:55,760 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:37:55,822 - 

2024-02-17 11:37:55,822 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:38:03,485 - Epoch: [55][  100/  500]    Overall Loss 0.769146    Objective Loss 0.769146                                        LR 0.000500    Time 0.076579    
2024-02-17 11:38:10,552 - Epoch: [55][  200/  500]    Overall Loss 0.780171    Objective Loss 0.780171                                        LR 0.000500    Time 0.073604    
2024-02-17 11:38:17,669 - Epoch: [55][  300/  500]    Overall Loss 0.789821    Objective Loss 0.789821                                        LR 0.000500    Time 0.072778    
2024-02-17 11:38:24,772 - Epoch: [55][  400/  500]    Overall Loss 0.797652    Objective Loss 0.797652                                        LR 0.000500    Time 0.072332    
2024-02-17 11:38:31,872 - Epoch: [55][  500/  500]    Overall Loss 0.802727    Objective Loss 0.802727    Top1 80.000000    Top5 95.500000    LR 0.000500    Time 0.072057    
2024-02-17 11:38:32,047 - --- validate (epoch=55)-----------
2024-02-17 11:38:32,048 - 10000 samples (100 per mini-batch)
2024-02-17 11:38:35,023 - Epoch: [55][  100/  100]    Loss 1.577737    Top1 59.690000    Top5 85.980000    
2024-02-17 11:38:35,151 - ==> Top1: 59.690    Top5: 85.980    Loss: 1.578

2024-02-17 11:38:35,162 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:38:35,162 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:38:35,236 - 

2024-02-17 11:38:35,236 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:38:43,128 - Epoch: [56][  100/  500]    Overall Loss 0.767662    Objective Loss 0.767662                                        LR 0.000500    Time 0.078863    
2024-02-17 11:38:50,218 - Epoch: [56][  200/  500]    Overall Loss 0.775037    Objective Loss 0.775037                                        LR 0.000500    Time 0.074863    
2024-02-17 11:38:57,362 - Epoch: [56][  300/  500]    Overall Loss 0.782996    Objective Loss 0.782996                                        LR 0.000500    Time 0.073708    
2024-02-17 11:39:04,524 - Epoch: [56][  400/  500]    Overall Loss 0.793193    Objective Loss 0.793193                                        LR 0.000500    Time 0.073176    
2024-02-17 11:39:11,662 - Epoch: [56][  500/  500]    Overall Loss 0.798635    Objective Loss 0.798635    Top1 76.500000    Top5 95.500000    LR 0.000500    Time 0.072808    
2024-02-17 11:39:11,791 - --- validate (epoch=56)-----------
2024-02-17 11:39:11,792 - 10000 samples (100 per mini-batch)
2024-02-17 11:39:14,954 - Epoch: [56][  100/  100]    Loss 1.677374    Top1 57.960000    Top5 85.060000    
2024-02-17 11:39:15,102 - ==> Top1: 57.960    Top5: 85.060    Loss: 1.677

2024-02-17 11:39:15,108 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:39:15,108 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:39:15,168 - 

2024-02-17 11:39:15,168 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:39:22,927 - Epoch: [57][  100/  500]    Overall Loss 0.748854    Objective Loss 0.748854                                        LR 0.000500    Time 0.077505    
2024-02-17 11:39:30,156 - Epoch: [57][  200/  500]    Overall Loss 0.757948    Objective Loss 0.757948                                        LR 0.000500    Time 0.074875    
2024-02-17 11:39:37,215 - Epoch: [57][  300/  500]    Overall Loss 0.768813    Objective Loss 0.768813                                        LR 0.000500    Time 0.073435    
2024-02-17 11:39:44,377 - Epoch: [57][  400/  500]    Overall Loss 0.777358    Objective Loss 0.777358                                        LR 0.000500    Time 0.072971    
2024-02-17 11:39:51,478 - Epoch: [57][  500/  500]    Overall Loss 0.782456    Objective Loss 0.782456    Top1 78.000000    Top5 95.000000    LR 0.000500    Time 0.072570    
2024-02-17 11:39:51,651 - --- validate (epoch=57)-----------
2024-02-17 11:39:51,652 - 10000 samples (100 per mini-batch)
2024-02-17 11:39:54,668 - Epoch: [57][  100/  100]    Loss 1.637951    Top1 58.710000    Top5 85.710000    
2024-02-17 11:39:54,766 - ==> Top1: 58.710    Top5: 85.710    Loss: 1.638

2024-02-17 11:39:54,779 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:39:54,779 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:39:54,845 - 

2024-02-17 11:39:54,845 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:40:02,560 - Epoch: [58][  100/  500]    Overall Loss 0.757408    Objective Loss 0.757408                                        LR 0.000500    Time 0.077092    
2024-02-17 11:40:09,750 - Epoch: [58][  200/  500]    Overall Loss 0.752679    Objective Loss 0.752679                                        LR 0.000500    Time 0.074476    
2024-02-17 11:40:16,829 - Epoch: [58][  300/  500]    Overall Loss 0.761102    Objective Loss 0.761102                                        LR 0.000500    Time 0.073233    
2024-02-17 11:40:24,058 - Epoch: [58][  400/  500]    Overall Loss 0.769629    Objective Loss 0.769629                                        LR 0.000500    Time 0.072987    
2024-02-17 11:40:31,241 - Epoch: [58][  500/  500]    Overall Loss 0.776744    Objective Loss 0.776744    Top1 75.500000    Top5 94.500000    LR 0.000500    Time 0.072746    
2024-02-17 11:40:31,361 - --- validate (epoch=58)-----------
2024-02-17 11:40:31,363 - 10000 samples (100 per mini-batch)
2024-02-17 11:40:34,650 - Epoch: [58][  100/  100]    Loss 1.693725    Top1 58.040000    Top5 84.660000    
2024-02-17 11:40:34,751 - ==> Top1: 58.040    Top5: 84.660    Loss: 1.694

2024-02-17 11:40:34,763 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:40:34,764 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:40:34,831 - 

2024-02-17 11:40:34,831 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:40:42,694 - Epoch: [59][  100/  500]    Overall Loss 0.725762    Objective Loss 0.725762                                        LR 0.000500    Time 0.078562    
2024-02-17 11:40:49,883 - Epoch: [59][  200/  500]    Overall Loss 0.742909    Objective Loss 0.742909                                        LR 0.000500    Time 0.075207    
2024-02-17 11:40:56,996 - Epoch: [59][  300/  500]    Overall Loss 0.745777    Objective Loss 0.745777                                        LR 0.000500    Time 0.073832    
2024-02-17 11:41:04,195 - Epoch: [59][  400/  500]    Overall Loss 0.756595    Objective Loss 0.756595                                        LR 0.000500    Time 0.073361    
2024-02-17 11:41:11,766 - Epoch: [59][  500/  500]    Overall Loss 0.762398    Objective Loss 0.762398    Top1 74.500000    Top5 96.000000    LR 0.000500    Time 0.073822    
2024-02-17 11:41:11,872 - --- validate (epoch=59)-----------
2024-02-17 11:41:11,873 - 10000 samples (100 per mini-batch)
2024-02-17 11:41:14,947 - Epoch: [59][  100/  100]    Loss 1.658248    Top1 58.860000    Top5 85.150000    
2024-02-17 11:41:15,056 - ==> Top1: 58.860    Top5: 85.150    Loss: 1.658

2024-02-17 11:41:15,067 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:41:15,067 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:41:15,137 - 

2024-02-17 11:41:15,137 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:41:23,212 - Epoch: [60][  100/  500]    Overall Loss 0.717924    Objective Loss 0.717924                                        LR 0.000500    Time 0.080692    
2024-02-17 11:41:30,332 - Epoch: [60][  200/  500]    Overall Loss 0.740746    Objective Loss 0.740746                                        LR 0.000500    Time 0.075926    
2024-02-17 11:41:37,392 - Epoch: [60][  300/  500]    Overall Loss 0.746455    Objective Loss 0.746455                                        LR 0.000500    Time 0.074137    
2024-02-17 11:41:44,470 - Epoch: [60][  400/  500]    Overall Loss 0.755625    Objective Loss 0.755625                                        LR 0.000500    Time 0.073285    
2024-02-17 11:41:51,709 - Epoch: [60][  500/  500]    Overall Loss 0.761782    Objective Loss 0.761782    Top1 77.000000    Top5 96.000000    LR 0.000500    Time 0.073099    
2024-02-17 11:41:51,836 - --- validate (epoch=60)-----------
2024-02-17 11:41:51,837 - 10000 samples (100 per mini-batch)
2024-02-17 11:41:55,010 - Epoch: [60][  100/  100]    Loss 1.683339    Top1 57.680000    Top5 85.160000    
2024-02-17 11:41:55,135 - ==> Top1: 57.680    Top5: 85.160    Loss: 1.683

2024-02-17 11:41:55,147 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:41:55,147 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:41:55,209 - 

2024-02-17 11:41:55,209 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:42:02,818 - Epoch: [61][  100/  500]    Overall Loss 0.723786    Objective Loss 0.723786                                        LR 0.000500    Time 0.076037    
2024-02-17 11:42:09,984 - Epoch: [61][  200/  500]    Overall Loss 0.725941    Objective Loss 0.725941                                        LR 0.000500    Time 0.073826    
2024-02-17 11:42:17,098 - Epoch: [61][  300/  500]    Overall Loss 0.736931    Objective Loss 0.736931                                        LR 0.000500    Time 0.072917    
2024-02-17 11:42:24,191 - Epoch: [61][  400/  500]    Overall Loss 0.743888    Objective Loss 0.743888                                        LR 0.000500    Time 0.072408    
2024-02-17 11:42:31,345 - Epoch: [61][  500/  500]    Overall Loss 0.750233    Objective Loss 0.750233    Top1 76.500000    Top5 97.000000    LR 0.000500    Time 0.072228    
2024-02-17 11:42:31,494 - --- validate (epoch=61)-----------
2024-02-17 11:42:31,494 - 10000 samples (100 per mini-batch)
2024-02-17 11:42:34,577 - Epoch: [61][  100/  100]    Loss 1.703892    Top1 58.030000    Top5 84.660000    
2024-02-17 11:42:34,684 - ==> Top1: 58.030    Top5: 84.660    Loss: 1.704

2024-02-17 11:42:34,697 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:42:34,698 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:42:34,760 - 

2024-02-17 11:42:34,761 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:42:42,753 - Epoch: [62][  100/  500]    Overall Loss 0.716316    Objective Loss 0.716316                                        LR 0.000500    Time 0.079869    
2024-02-17 11:42:49,925 - Epoch: [62][  200/  500]    Overall Loss 0.725154    Objective Loss 0.725154                                        LR 0.000500    Time 0.075771    
2024-02-17 11:42:57,256 - Epoch: [62][  300/  500]    Overall Loss 0.726598    Objective Loss 0.726598                                        LR 0.000500    Time 0.074938    
2024-02-17 11:43:04,572 - Epoch: [62][  400/  500]    Overall Loss 0.732765    Objective Loss 0.732765                                        LR 0.000500    Time 0.074482    
2024-02-17 11:43:11,887 - Epoch: [62][  500/  500]    Overall Loss 0.735718    Objective Loss 0.735718    Top1 77.500000    Top5 97.000000    LR 0.000500    Time 0.074209    
2024-02-17 11:43:12,001 - --- validate (epoch=62)-----------
2024-02-17 11:43:12,002 - 10000 samples (100 per mini-batch)
2024-02-17 11:43:15,035 - Epoch: [62][  100/  100]    Loss 1.695187    Top1 58.080000    Top5 84.730000    
2024-02-17 11:43:15,151 - ==> Top1: 58.080    Top5: 84.730    Loss: 1.695

2024-02-17 11:43:15,163 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:43:15,163 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:43:15,226 - 

2024-02-17 11:43:15,226 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:43:23,026 - Epoch: [63][  100/  500]    Overall Loss 0.708055    Objective Loss 0.708055                                        LR 0.000500    Time 0.077941    
2024-02-17 11:43:30,250 - Epoch: [63][  200/  500]    Overall Loss 0.707810    Objective Loss 0.707810                                        LR 0.000500    Time 0.075070    
2024-02-17 11:43:37,370 - Epoch: [63][  300/  500]    Overall Loss 0.714700    Objective Loss 0.714700                                        LR 0.000500    Time 0.073765    
2024-02-17 11:43:44,439 - Epoch: [63][  400/  500]    Overall Loss 0.722657    Objective Loss 0.722657                                        LR 0.000500    Time 0.072986    
2024-02-17 11:43:51,797 - Epoch: [63][  500/  500]    Overall Loss 0.728273    Objective Loss 0.728273    Top1 78.000000    Top5 94.500000    LR 0.000500    Time 0.073096    
2024-02-17 11:43:51,924 - --- validate (epoch=63)-----------
2024-02-17 11:43:51,926 - 10000 samples (100 per mini-batch)
2024-02-17 11:43:55,204 - Epoch: [63][  100/  100]    Loss 1.712738    Top1 58.530000    Top5 85.230000    
2024-02-17 11:43:55,299 - ==> Top1: 58.530    Top5: 85.230    Loss: 1.713

2024-02-17 11:43:55,310 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:43:55,311 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:43:55,371 - 

2024-02-17 11:43:55,371 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:44:03,459 - Epoch: [64][  100/  500]    Overall Loss 0.699875    Objective Loss 0.699875                                        LR 0.000500    Time 0.080809    
2024-02-17 11:44:10,720 - Epoch: [64][  200/  500]    Overall Loss 0.711025    Objective Loss 0.711025                                        LR 0.000500    Time 0.076689    
2024-02-17 11:44:17,850 - Epoch: [64][  300/  500]    Overall Loss 0.711866    Objective Loss 0.711866                                        LR 0.000500    Time 0.074880    
2024-02-17 11:44:24,911 - Epoch: [64][  400/  500]    Overall Loss 0.718434    Objective Loss 0.718434                                        LR 0.000500    Time 0.073802    
2024-02-17 11:44:32,114 - Epoch: [64][  500/  500]    Overall Loss 0.721861    Objective Loss 0.721861    Top1 80.000000    Top5 97.500000    LR 0.000500    Time 0.073438    
2024-02-17 11:44:32,249 - --- validate (epoch=64)-----------
2024-02-17 11:44:32,249 - 10000 samples (100 per mini-batch)
2024-02-17 11:44:35,448 - Epoch: [64][  100/  100]    Loss 1.672986    Top1 58.580000    Top5 85.230000    
2024-02-17 11:44:35,557 - ==> Top1: 58.580    Top5: 85.230    Loss: 1.673

2024-02-17 11:44:35,564 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:44:35,564 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:44:35,642 - 

2024-02-17 11:44:35,643 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:44:43,351 - Epoch: [65][  100/  500]    Overall Loss 0.685307    Objective Loss 0.685307                                        LR 0.000500    Time 0.077020    
2024-02-17 11:44:50,412 - Epoch: [65][  200/  500]    Overall Loss 0.691732    Objective Loss 0.691732                                        LR 0.000500    Time 0.073796    
2024-02-17 11:44:57,470 - Epoch: [65][  300/  500]    Overall Loss 0.702046    Objective Loss 0.702046                                        LR 0.000500    Time 0.072709    
2024-02-17 11:45:04,540 - Epoch: [65][  400/  500]    Overall Loss 0.707181    Objective Loss 0.707181                                        LR 0.000500    Time 0.072196    
2024-02-17 11:45:11,347 - Epoch: [65][  500/  500]    Overall Loss 0.714602    Objective Loss 0.714602    Top1 77.000000    Top5 96.000000    LR 0.000500    Time 0.071365    
2024-02-17 11:45:11,463 - --- validate (epoch=65)-----------
2024-02-17 11:45:11,464 - 10000 samples (100 per mini-batch)
2024-02-17 11:45:14,534 - Epoch: [65][  100/  100]    Loss 1.658163    Top1 58.720000    Top5 85.510000    
2024-02-17 11:45:14,660 - ==> Top1: 58.720    Top5: 85.510    Loss: 1.658

2024-02-17 11:45:14,669 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:45:14,669 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:45:14,732 - 

2024-02-17 11:45:14,732 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:45:22,500 - Epoch: [66][  100/  500]    Overall Loss 0.674366    Objective Loss 0.674366                                        LR 0.000500    Time 0.077616    
2024-02-17 11:45:29,622 - Epoch: [66][  200/  500]    Overall Loss 0.684975    Objective Loss 0.684975                                        LR 0.000500    Time 0.074398    
2024-02-17 11:45:36,698 - Epoch: [66][  300/  500]    Overall Loss 0.694046    Objective Loss 0.694046                                        LR 0.000500    Time 0.073170    
2024-02-17 11:45:43,826 - Epoch: [66][  400/  500]    Overall Loss 0.699602    Objective Loss 0.699602                                        LR 0.000500    Time 0.072686    
2024-02-17 11:45:51,022 - Epoch: [66][  500/  500]    Overall Loss 0.704723    Objective Loss 0.704723    Top1 74.000000    Top5 93.000000    LR 0.000500    Time 0.072533    
2024-02-17 11:45:51,161 - --- validate (epoch=66)-----------
2024-02-17 11:45:51,162 - 10000 samples (100 per mini-batch)
2024-02-17 11:45:54,471 - Epoch: [66][  100/  100]    Loss 1.779810    Top1 57.320000    Top5 84.590000    
2024-02-17 11:45:54,613 - ==> Top1: 57.320    Top5: 84.590    Loss: 1.780

2024-02-17 11:45:54,628 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-17 11:45:54,628 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:45:54,696 - 

2024-02-17 11:45:54,696 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:46:02,400 - Epoch: [67][  100/  500]    Overall Loss 0.667879    Objective Loss 0.667879                                        LR 0.000500    Time 0.076982    
2024-02-17 11:46:09,625 - Epoch: [67][  200/  500]    Overall Loss 0.670391    Objective Loss 0.670391                                        LR 0.000500    Time 0.074593    
2024-02-17 11:46:16,348 - Epoch: [67][  300/  500]    Overall Loss 0.682634    Objective Loss 0.682634                                        LR 0.000500    Time 0.072130    
2024-02-17 11:46:23,141 - Epoch: [67][  400/  500]    Overall Loss 0.693407    Objective Loss 0.693407                                        LR 0.000500    Time 0.071072    
2024-02-17 11:46:30,325 - Epoch: [67][  500/  500]    Overall Loss 0.701100    Objective Loss 0.701100    Top1 82.000000    Top5 97.500000    LR 0.000500    Time 0.071219    
2024-02-17 11:46:30,461 - --- validate (epoch=67)-----------
2024-02-17 11:46:30,462 - 10000 samples (100 per mini-batch)
2024-02-17 11:46:33,458 - Epoch: [67][  100/  100]    Loss 1.624452    Top1 59.700000    Top5 85.970000    
2024-02-17 11:46:33,603 - ==> Top1: 59.700    Top5: 85.970    Loss: 1.624

2024-02-17 11:46:33,614 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:46:33,614 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:46:33,691 - 

2024-02-17 11:46:33,691 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:46:41,580 - Epoch: [68][  100/  500]    Overall Loss 0.666309    Objective Loss 0.666309                                        LR 0.000500    Time 0.078839    
2024-02-17 11:46:48,708 - Epoch: [68][  200/  500]    Overall Loss 0.671433    Objective Loss 0.671433                                        LR 0.000500    Time 0.075035    
2024-02-17 11:46:55,807 - Epoch: [68][  300/  500]    Overall Loss 0.681416    Objective Loss 0.681416                                        LR 0.000500    Time 0.073675    
2024-02-17 11:47:03,057 - Epoch: [68][  400/  500]    Overall Loss 0.681536    Objective Loss 0.681536                                        LR 0.000500    Time 0.073370    
2024-02-17 11:47:10,287 - Epoch: [68][  500/  500]    Overall Loss 0.689015    Objective Loss 0.689015    Top1 81.000000    Top5 96.500000    LR 0.000500    Time 0.073148    
2024-02-17 11:47:10,412 - --- validate (epoch=68)-----------
2024-02-17 11:47:10,413 - 10000 samples (100 per mini-batch)
2024-02-17 11:47:13,282 - Epoch: [68][  100/  100]    Loss 1.762042    Top1 57.330000    Top5 84.180000    
2024-02-17 11:47:13,406 - ==> Top1: 57.330    Top5: 84.180    Loss: 1.762

2024-02-17 11:47:13,418 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:47:13,418 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:47:13,478 - 

2024-02-17 11:47:13,478 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:47:21,116 - Epoch: [69][  100/  500]    Overall Loss 0.670748    Objective Loss 0.670748                                        LR 0.000500    Time 0.076323    
2024-02-17 11:47:28,334 - Epoch: [69][  200/  500]    Overall Loss 0.678400    Objective Loss 0.678400                                        LR 0.000500    Time 0.074230    
2024-02-17 11:47:35,350 - Epoch: [69][  300/  500]    Overall Loss 0.680186    Objective Loss 0.680186                                        LR 0.000500    Time 0.072860    
2024-02-17 11:47:42,471 - Epoch: [69][  400/  500]    Overall Loss 0.683780    Objective Loss 0.683780                                        LR 0.000500    Time 0.072437    
2024-02-17 11:47:49,710 - Epoch: [69][  500/  500]    Overall Loss 0.688127    Objective Loss 0.688127    Top1 75.000000    Top5 95.500000    LR 0.000500    Time 0.072420    
2024-02-17 11:47:49,840 - --- validate (epoch=69)-----------
2024-02-17 11:47:49,842 - 10000 samples (100 per mini-batch)
2024-02-17 11:47:52,810 - Epoch: [69][  100/  100]    Loss 1.698582    Top1 58.650000    Top5 85.260000    
2024-02-17 11:47:53,001 - ==> Top1: 58.650    Top5: 85.260    Loss: 1.699

2024-02-17 11:47:53,011 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:47:53,012 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:47:53,073 - 

2024-02-17 11:47:53,073 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:48:00,795 - Epoch: [70][  100/  500]    Overall Loss 0.654303    Objective Loss 0.654303                                        LR 0.000500    Time 0.077166    
2024-02-17 11:48:07,801 - Epoch: [70][  200/  500]    Overall Loss 0.663836    Objective Loss 0.663836                                        LR 0.000500    Time 0.073593    
2024-02-17 11:48:14,995 - Epoch: [70][  300/  500]    Overall Loss 0.670636    Objective Loss 0.670636                                        LR 0.000500    Time 0.073026    
2024-02-17 11:48:22,230 - Epoch: [70][  400/  500]    Overall Loss 0.675985    Objective Loss 0.675985                                        LR 0.000500    Time 0.072848    
2024-02-17 11:48:29,386 - Epoch: [70][  500/  500]    Overall Loss 0.682836    Objective Loss 0.682836    Top1 80.000000    Top5 96.500000    LR 0.000500    Time 0.072582    
2024-02-17 11:48:29,515 - --- validate (epoch=70)-----------
2024-02-17 11:48:29,516 - 10000 samples (100 per mini-batch)
2024-02-17 11:48:32,676 - Epoch: [70][  100/  100]    Loss 1.732679    Top1 58.640000    Top5 84.830000    
2024-02-17 11:48:32,770 - ==> Top1: 58.640    Top5: 84.830    Loss: 1.733

2024-02-17 11:48:32,781 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:48:32,781 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:48:32,843 - 

2024-02-17 11:48:32,843 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:48:40,516 - Epoch: [71][  100/  500]    Overall Loss 0.640584    Objective Loss 0.640584                                        LR 0.000500    Time 0.076670    
2024-02-17 11:48:47,641 - Epoch: [71][  200/  500]    Overall Loss 0.644814    Objective Loss 0.644814                                        LR 0.000500    Time 0.073937    
2024-02-17 11:48:54,823 - Epoch: [71][  300/  500]    Overall Loss 0.658395    Objective Loss 0.658395                                        LR 0.000500    Time 0.073221    
2024-02-17 11:49:01,985 - Epoch: [71][  400/  500]    Overall Loss 0.664975    Objective Loss 0.664975                                        LR 0.000500    Time 0.072808    
2024-02-17 11:49:09,182 - Epoch: [71][  500/  500]    Overall Loss 0.673418    Objective Loss 0.673418    Top1 76.500000    Top5 97.500000    LR 0.000500    Time 0.072633    
2024-02-17 11:49:09,307 - --- validate (epoch=71)-----------
2024-02-17 11:49:09,307 - 10000 samples (100 per mini-batch)
2024-02-17 11:49:12,291 - Epoch: [71][  100/  100]    Loss 1.694343    Top1 59.110000    Top5 85.550000    
2024-02-17 11:49:12,405 - ==> Top1: 59.110    Top5: 85.550    Loss: 1.694

2024-02-17 11:49:12,416 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:49:12,416 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:49:12,478 - 

2024-02-17 11:49:12,478 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:49:20,522 - Epoch: [72][  100/  500]    Overall Loss 0.634068    Objective Loss 0.634068                                        LR 0.000500    Time 0.080379    
2024-02-17 11:49:27,683 - Epoch: [72][  200/  500]    Overall Loss 0.639392    Objective Loss 0.639392                                        LR 0.000500    Time 0.075976    
2024-02-17 11:49:34,811 - Epoch: [72][  300/  500]    Overall Loss 0.649119    Objective Loss 0.649119                                        LR 0.000500    Time 0.074397    
2024-02-17 11:49:41,889 - Epoch: [72][  400/  500]    Overall Loss 0.660243    Objective Loss 0.660243                                        LR 0.000500    Time 0.073481    
2024-02-17 11:49:49,094 - Epoch: [72][  500/  500]    Overall Loss 0.662036    Objective Loss 0.662036    Top1 75.500000    Top5 97.000000    LR 0.000500    Time 0.073188    
2024-02-17 11:49:49,206 - --- validate (epoch=72)-----------
2024-02-17 11:49:49,207 - 10000 samples (100 per mini-batch)
2024-02-17 11:49:52,110 - Epoch: [72][  100/  100]    Loss 1.789423    Top1 58.120000    Top5 84.880000    
2024-02-17 11:49:52,227 - ==> Top1: 58.120    Top5: 84.880    Loss: 1.789

2024-02-17 11:49:52,238 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:49:52,239 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:49:52,308 - 

2024-02-17 11:49:52,308 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:49:59,940 - Epoch: [73][  100/  500]    Overall Loss 0.635874    Objective Loss 0.635874                                        LR 0.000500    Time 0.076273    
2024-02-17 11:50:07,001 - Epoch: [73][  200/  500]    Overall Loss 0.634746    Objective Loss 0.634746                                        LR 0.000500    Time 0.073420    
2024-02-17 11:50:14,147 - Epoch: [73][  300/  500]    Overall Loss 0.643160    Objective Loss 0.643160                                        LR 0.000500    Time 0.072753    
2024-02-17 11:50:21,264 - Epoch: [73][  400/  500]    Overall Loss 0.652762    Objective Loss 0.652762                                        LR 0.000500    Time 0.072347    
2024-02-17 11:50:28,387 - Epoch: [73][  500/  500]    Overall Loss 0.657868    Objective Loss 0.657868    Top1 81.000000    Top5 97.000000    LR 0.000500    Time 0.072114    
2024-02-17 11:50:28,618 - --- validate (epoch=73)-----------
2024-02-17 11:50:28,619 - 10000 samples (100 per mini-batch)
2024-02-17 11:50:31,572 - Epoch: [73][  100/  100]    Loss 1.707734    Top1 58.790000    Top5 85.400000    
2024-02-17 11:50:31,707 - ==> Top1: 58.790    Top5: 85.400    Loss: 1.708

2024-02-17 11:50:31,718 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:50:31,719 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:50:31,781 - 

2024-02-17 11:50:31,781 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:50:39,751 - Epoch: [74][  100/  500]    Overall Loss 0.609792    Objective Loss 0.609792                                        LR 0.000500    Time 0.079638    
2024-02-17 11:50:47,025 - Epoch: [74][  200/  500]    Overall Loss 0.622190    Objective Loss 0.622190                                        LR 0.000500    Time 0.076166    
2024-02-17 11:50:54,380 - Epoch: [74][  300/  500]    Overall Loss 0.634530    Objective Loss 0.634530                                        LR 0.000500    Time 0.075281    
2024-02-17 11:51:01,715 - Epoch: [74][  400/  500]    Overall Loss 0.644153    Objective Loss 0.644153                                        LR 0.000500    Time 0.074788    
2024-02-17 11:51:08,917 - Epoch: [74][  500/  500]    Overall Loss 0.649697    Objective Loss 0.649697    Top1 84.000000    Top5 98.000000    LR 0.000500    Time 0.074227    
2024-02-17 11:51:09,040 - --- validate (epoch=74)-----------
2024-02-17 11:51:09,040 - 10000 samples (100 per mini-batch)
2024-02-17 11:51:12,131 - Epoch: [74][  100/  100]    Loss 1.735290    Top1 58.450000    Top5 85.140000    
2024-02-17 11:51:12,243 - ==> Top1: 58.450    Top5: 85.140    Loss: 1.735

2024-02-17 11:51:12,254 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:51:12,255 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:51:12,316 - 

2024-02-17 11:51:12,316 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:51:20,004 - Epoch: [75][  100/  500]    Overall Loss 0.620486    Objective Loss 0.620486                                        LR 0.000500    Time 0.076825    
2024-02-17 11:51:27,133 - Epoch: [75][  200/  500]    Overall Loss 0.633876    Objective Loss 0.633876                                        LR 0.000500    Time 0.074037    
2024-02-17 11:51:34,357 - Epoch: [75][  300/  500]    Overall Loss 0.637861    Objective Loss 0.637861                                        LR 0.000500    Time 0.073422    
2024-02-17 11:51:41,621 - Epoch: [75][  400/  500]    Overall Loss 0.641115    Objective Loss 0.641115                                        LR 0.000500    Time 0.073216    
2024-02-17 11:51:48,964 - Epoch: [75][  500/  500]    Overall Loss 0.644184    Objective Loss 0.644184    Top1 79.500000    Top5 97.000000    LR 0.000500    Time 0.073252    
2024-02-17 11:51:49,100 - --- validate (epoch=75)-----------
2024-02-17 11:51:49,102 - 10000 samples (100 per mini-batch)
2024-02-17 11:51:52,145 - Epoch: [75][  100/  100]    Loss 1.705996    Top1 59.100000    Top5 85.270000    
2024-02-17 11:51:52,298 - ==> Top1: 59.100    Top5: 85.270    Loss: 1.706

2024-02-17 11:51:52,309 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:51:52,309 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:51:52,369 - 

2024-02-17 11:51:52,370 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:52:00,329 - Epoch: [76][  100/  500]    Overall Loss 0.610907    Objective Loss 0.610907                                        LR 0.000500    Time 0.079538    
2024-02-17 11:52:07,576 - Epoch: [76][  200/  500]    Overall Loss 0.624727    Objective Loss 0.624727                                        LR 0.000500    Time 0.075982    
2024-02-17 11:52:14,768 - Epoch: [76][  300/  500]    Overall Loss 0.624320    Objective Loss 0.624320                                        LR 0.000500    Time 0.074614    
2024-02-17 11:52:22,265 - Epoch: [76][  400/  500]    Overall Loss 0.631084    Objective Loss 0.631084                                        LR 0.000500    Time 0.074693    
2024-02-17 11:52:29,473 - Epoch: [76][  500/  500]    Overall Loss 0.636151    Objective Loss 0.636151    Top1 77.500000    Top5 98.500000    LR 0.000500    Time 0.074161    
2024-02-17 11:52:29,609 - --- validate (epoch=76)-----------
2024-02-17 11:52:29,609 - 10000 samples (100 per mini-batch)
2024-02-17 11:52:32,695 - Epoch: [76][  100/  100]    Loss 1.739712    Top1 58.250000    Top5 85.250000    
2024-02-17 11:52:32,793 - ==> Top1: 58.250    Top5: 85.250    Loss: 1.740

2024-02-17 11:52:32,810 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:52:32,811 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:52:32,892 - 

2024-02-17 11:52:32,892 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:52:40,652 - Epoch: [77][  100/  500]    Overall Loss 0.597206    Objective Loss 0.597206                                        LR 0.000500    Time 0.077526    
2024-02-17 11:52:47,760 - Epoch: [77][  200/  500]    Overall Loss 0.601952    Objective Loss 0.601952                                        LR 0.000500    Time 0.074279    
2024-02-17 11:52:55,022 - Epoch: [77][  300/  500]    Overall Loss 0.609414    Objective Loss 0.609414                                        LR 0.000500    Time 0.073712    
2024-02-17 11:53:02,276 - Epoch: [77][  400/  500]    Overall Loss 0.621360    Objective Loss 0.621360                                        LR 0.000500    Time 0.073409    
2024-02-17 11:53:09,406 - Epoch: [77][  500/  500]    Overall Loss 0.630023    Objective Loss 0.630023    Top1 84.000000    Top5 99.000000    LR 0.000500    Time 0.072981    
2024-02-17 11:53:09,511 - --- validate (epoch=77)-----------
2024-02-17 11:53:09,513 - 10000 samples (100 per mini-batch)
2024-02-17 11:53:12,566 - Epoch: [77][  100/  100]    Loss 1.715761    Top1 58.450000    Top5 85.800000    
2024-02-17 11:53:12,755 - ==> Top1: 58.450    Top5: 85.800    Loss: 1.716

2024-02-17 11:53:12,766 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:53:12,767 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:53:12,827 - 

2024-02-17 11:53:12,828 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:53:20,824 - Epoch: [78][  100/  500]    Overall Loss 0.602155    Objective Loss 0.602155                                        LR 0.000500    Time 0.079905    
2024-02-17 11:53:28,041 - Epoch: [78][  200/  500]    Overall Loss 0.619924    Objective Loss 0.619924                                        LR 0.000500    Time 0.076016    
2024-02-17 11:53:35,140 - Epoch: [78][  300/  500]    Overall Loss 0.618334    Objective Loss 0.618334                                        LR 0.000500    Time 0.074328    
2024-02-17 11:53:42,334 - Epoch: [78][  400/  500]    Overall Loss 0.623308    Objective Loss 0.623308                                        LR 0.000500    Time 0.073718    
2024-02-17 11:53:49,535 - Epoch: [78][  500/  500]    Overall Loss 0.626740    Objective Loss 0.626740    Top1 73.500000    Top5 97.500000    LR 0.000500    Time 0.073368    
2024-02-17 11:53:49,663 - --- validate (epoch=78)-----------
2024-02-17 11:53:49,663 - 10000 samples (100 per mini-batch)
2024-02-17 11:53:52,652 - Epoch: [78][  100/  100]    Loss 1.753041    Top1 57.960000    Top5 85.190000    
2024-02-17 11:53:52,771 - ==> Top1: 57.960    Top5: 85.190    Loss: 1.753

2024-02-17 11:53:52,779 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:53:52,779 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:53:52,839 - 

2024-02-17 11:53:52,839 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:54:00,486 - Epoch: [79][  100/  500]    Overall Loss 0.591097    Objective Loss 0.591097                                        LR 0.000500    Time 0.076413    
2024-02-17 11:54:07,751 - Epoch: [79][  200/  500]    Overall Loss 0.602335    Objective Loss 0.602335                                        LR 0.000500    Time 0.074507    
2024-02-17 11:54:14,959 - Epoch: [79][  300/  500]    Overall Loss 0.608733    Objective Loss 0.608733                                        LR 0.000500    Time 0.073685    
2024-02-17 11:54:21,949 - Epoch: [79][  400/  500]    Overall Loss 0.613700    Objective Loss 0.613700                                        LR 0.000500    Time 0.072730    
2024-02-17 11:54:29,016 - Epoch: [79][  500/  500]    Overall Loss 0.619532    Objective Loss 0.619532    Top1 76.000000    Top5 97.000000    LR 0.000500    Time 0.072310    
2024-02-17 11:54:29,125 - --- validate (epoch=79)-----------
2024-02-17 11:54:29,126 - 10000 samples (100 per mini-batch)
2024-02-17 11:54:32,262 - Epoch: [79][  100/  100]    Loss 1.748150    Top1 58.340000    Top5 85.160000    
2024-02-17 11:54:32,369 - ==> Top1: 58.340    Top5: 85.160    Loss: 1.748

2024-02-17 11:54:32,380 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:54:32,380 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:54:32,441 - 

2024-02-17 11:54:32,442 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:54:40,394 - Epoch: [80][  100/  500]    Overall Loss 0.586069    Objective Loss 0.586069                                        LR 0.000500    Time 0.079470    
2024-02-17 11:54:47,525 - Epoch: [80][  200/  500]    Overall Loss 0.584702    Objective Loss 0.584702                                        LR 0.000500    Time 0.075371    
2024-02-17 11:54:54,660 - Epoch: [80][  300/  500]    Overall Loss 0.597921    Objective Loss 0.597921                                        LR 0.000500    Time 0.074015    
2024-02-17 11:55:01,782 - Epoch: [80][  400/  500]    Overall Loss 0.604512    Objective Loss 0.604512                                        LR 0.000500    Time 0.073307    
2024-02-17 11:55:08,883 - Epoch: [80][  500/  500]    Overall Loss 0.610524    Objective Loss 0.610524    Top1 83.500000    Top5 97.500000    LR 0.000500    Time 0.072839    
2024-02-17 11:55:08,998 - --- validate (epoch=80)-----------
2024-02-17 11:55:08,999 - 10000 samples (100 per mini-batch)
2024-02-17 11:55:11,999 - Epoch: [80][  100/  100]    Loss 1.771340    Top1 58.120000    Top5 84.990000    
2024-02-17 11:55:12,173 - ==> Top1: 58.120    Top5: 84.990    Loss: 1.771

2024-02-17 11:55:12,182 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:55:12,183 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:55:12,250 - 

2024-02-17 11:55:12,251 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:55:19,951 - Epoch: [81][  100/  500]    Overall Loss 0.581604    Objective Loss 0.581604                                        LR 0.000500    Time 0.076953    
2024-02-17 11:55:27,116 - Epoch: [81][  200/  500]    Overall Loss 0.582514    Objective Loss 0.582514                                        LR 0.000500    Time 0.074279    
2024-02-17 11:55:34,306 - Epoch: [81][  300/  500]    Overall Loss 0.598248    Objective Loss 0.598248                                        LR 0.000500    Time 0.073472    
2024-02-17 11:55:41,433 - Epoch: [81][  400/  500]    Overall Loss 0.606046    Objective Loss 0.606046                                        LR 0.000500    Time 0.072910    
2024-02-17 11:55:48,670 - Epoch: [81][  500/  500]    Overall Loss 0.609403    Objective Loss 0.609403    Top1 82.000000    Top5 97.000000    LR 0.000500    Time 0.072794    
2024-02-17 11:55:48,803 - --- validate (epoch=81)-----------
2024-02-17 11:55:48,804 - 10000 samples (100 per mini-batch)
2024-02-17 11:55:51,802 - Epoch: [81][  100/  100]    Loss 1.777510    Top1 58.730000    Top5 84.850000    
2024-02-17 11:55:51,897 - ==> Top1: 58.730    Top5: 84.850    Loss: 1.778

2024-02-17 11:55:51,907 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:55:51,908 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:55:51,974 - 

2024-02-17 11:55:51,974 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:55:59,929 - Epoch: [82][  100/  500]    Overall Loss 0.580655    Objective Loss 0.580655                                        LR 0.000500    Time 0.079496    
2024-02-17 11:56:07,121 - Epoch: [82][  200/  500]    Overall Loss 0.586616    Objective Loss 0.586616                                        LR 0.000500    Time 0.075686    
2024-02-17 11:56:14,574 - Epoch: [82][  300/  500]    Overall Loss 0.591215    Objective Loss 0.591215                                        LR 0.000500    Time 0.075285    
2024-02-17 11:56:21,673 - Epoch: [82][  400/  500]    Overall Loss 0.591351    Objective Loss 0.591351                                        LR 0.000500    Time 0.074202    
2024-02-17 11:56:28,774 - Epoch: [82][  500/  500]    Overall Loss 0.597625    Objective Loss 0.597625    Top1 83.500000    Top5 99.000000    LR 0.000500    Time 0.073555    
2024-02-17 11:56:28,896 - --- validate (epoch=82)-----------
2024-02-17 11:56:28,897 - 10000 samples (100 per mini-batch)
2024-02-17 11:56:31,733 - Epoch: [82][  100/  100]    Loss 1.825459    Top1 57.690000    Top5 84.730000    
2024-02-17 11:56:31,838 - ==> Top1: 57.690    Top5: 84.730    Loss: 1.825

2024-02-17 11:56:31,847 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:56:31,847 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:56:31,915 - 

2024-02-17 11:56:31,916 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:56:39,503 - Epoch: [83][  100/  500]    Overall Loss 0.563809    Objective Loss 0.563809                                        LR 0.000500    Time 0.075822    
2024-02-17 11:56:46,753 - Epoch: [83][  200/  500]    Overall Loss 0.573816    Objective Loss 0.573816                                        LR 0.000500    Time 0.074140    
2024-02-17 11:56:53,734 - Epoch: [83][  300/  500]    Overall Loss 0.576394    Objective Loss 0.576394                                        LR 0.000500    Time 0.072685    
2024-02-17 11:57:00,544 - Epoch: [83][  400/  500]    Overall Loss 0.585076    Objective Loss 0.585076                                        LR 0.000500    Time 0.071530    
2024-02-17 11:57:07,268 - Epoch: [83][  500/  500]    Overall Loss 0.590422    Objective Loss 0.590422    Top1 83.000000    Top5 97.000000    LR 0.000500    Time 0.070665    
2024-02-17 11:57:07,386 - --- validate (epoch=83)-----------
2024-02-17 11:57:07,387 - 10000 samples (100 per mini-batch)
2024-02-17 11:57:10,296 - Epoch: [83][  100/  100]    Loss 1.793144    Top1 58.300000    Top5 85.080000    
2024-02-17 11:57:10,401 - ==> Top1: 58.300    Top5: 85.080    Loss: 1.793

2024-02-17 11:57:10,413 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:57:10,413 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:57:10,474 - 

2024-02-17 11:57:10,475 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:57:18,324 - Epoch: [84][  100/  500]    Overall Loss 0.537897    Objective Loss 0.537897                                        LR 0.000500    Time 0.078436    
2024-02-17 11:57:25,498 - Epoch: [84][  200/  500]    Overall Loss 0.562149    Objective Loss 0.562149                                        LR 0.000500    Time 0.075068    
2024-02-17 11:57:32,812 - Epoch: [84][  300/  500]    Overall Loss 0.570473    Objective Loss 0.570473                                        LR 0.000500    Time 0.074412    
2024-02-17 11:57:39,870 - Epoch: [84][  400/  500]    Overall Loss 0.577448    Objective Loss 0.577448                                        LR 0.000500    Time 0.073443    
2024-02-17 11:57:46,912 - Epoch: [84][  500/  500]    Overall Loss 0.587891    Objective Loss 0.587891    Top1 81.000000    Top5 97.000000    LR 0.000500    Time 0.072829    
2024-02-17 11:57:47,093 - --- validate (epoch=84)-----------
2024-02-17 11:57:47,094 - 10000 samples (100 per mini-batch)
2024-02-17 11:57:50,070 - Epoch: [84][  100/  100]    Loss 1.739641    Top1 58.970000    Top5 85.100000    
2024-02-17 11:57:50,175 - ==> Top1: 58.970    Top5: 85.100    Loss: 1.740

2024-02-17 11:57:50,187 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:57:50,187 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:57:50,247 - 

2024-02-17 11:57:50,247 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:57:57,986 - Epoch: [85][  100/  500]    Overall Loss 0.554587    Objective Loss 0.554587                                        LR 0.000500    Time 0.077323    
2024-02-17 11:58:05,029 - Epoch: [85][  200/  500]    Overall Loss 0.572589    Objective Loss 0.572589                                        LR 0.000500    Time 0.073857    
2024-02-17 11:58:12,197 - Epoch: [85][  300/  500]    Overall Loss 0.576759    Objective Loss 0.576759                                        LR 0.000500    Time 0.073118    
2024-02-17 11:58:19,317 - Epoch: [85][  400/  500]    Overall Loss 0.583177    Objective Loss 0.583177                                        LR 0.000500    Time 0.072629    
2024-02-17 11:58:26,468 - Epoch: [85][  500/  500]    Overall Loss 0.589292    Objective Loss 0.589292    Top1 81.000000    Top5 97.000000    LR 0.000500    Time 0.072396    
2024-02-17 11:58:26,589 - --- validate (epoch=85)-----------
2024-02-17 11:58:26,590 - 10000 samples (100 per mini-batch)
2024-02-17 11:58:29,432 - Epoch: [85][  100/  100]    Loss 1.771237    Top1 58.690000    Top5 85.650000    
2024-02-17 11:58:29,538 - ==> Top1: 58.690    Top5: 85.650    Loss: 1.771

2024-02-17 11:58:29,549 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:58:29,550 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:58:29,611 - 

2024-02-17 11:58:29,611 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:58:37,288 - Epoch: [86][  100/  500]    Overall Loss 0.539606    Objective Loss 0.539606                                        LR 0.000500    Time 0.076714    
2024-02-17 11:58:44,555 - Epoch: [86][  200/  500]    Overall Loss 0.546295    Objective Loss 0.546295                                        LR 0.000500    Time 0.074672    
2024-02-17 11:58:51,881 - Epoch: [86][  300/  500]    Overall Loss 0.558972    Objective Loss 0.558972                                        LR 0.000500    Time 0.074186    
2024-02-17 11:58:59,037 - Epoch: [86][  400/  500]    Overall Loss 0.567789    Objective Loss 0.567789                                        LR 0.000500    Time 0.073519    
2024-02-17 11:59:06,192 - Epoch: [86][  500/  500]    Overall Loss 0.574149    Objective Loss 0.574149    Top1 82.000000    Top5 97.000000    LR 0.000500    Time 0.073116    
2024-02-17 11:59:06,318 - --- validate (epoch=86)-----------
2024-02-17 11:59:06,320 - 10000 samples (100 per mini-batch)
2024-02-17 11:59:09,422 - Epoch: [86][  100/  100]    Loss 1.823585    Top1 57.930000    Top5 84.860000    
2024-02-17 11:59:09,556 - ==> Top1: 57.930    Top5: 84.860    Loss: 1.824

2024-02-17 11:59:09,566 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:59:09,567 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:59:09,627 - 

2024-02-17 11:59:09,627 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:59:16,943 - Epoch: [87][  100/  500]    Overall Loss 0.556764    Objective Loss 0.556764                                        LR 0.000500    Time 0.073116    
2024-02-17 11:59:24,271 - Epoch: [87][  200/  500]    Overall Loss 0.549502    Objective Loss 0.549502                                        LR 0.000500    Time 0.073175    
2024-02-17 11:59:31,295 - Epoch: [87][  300/  500]    Overall Loss 0.558405    Objective Loss 0.558405                                        LR 0.000500    Time 0.072184    
2024-02-17 11:59:38,499 - Epoch: [87][  400/  500]    Overall Loss 0.566278    Objective Loss 0.566278                                        LR 0.000500    Time 0.072138    
2024-02-17 11:59:45,625 - Epoch: [87][  500/  500]    Overall Loss 0.571798    Objective Loss 0.571798    Top1 79.000000    Top5 97.500000    LR 0.000500    Time 0.071953    
2024-02-17 11:59:45,780 - --- validate (epoch=87)-----------
2024-02-17 11:59:45,781 - 10000 samples (100 per mini-batch)
2024-02-17 11:59:48,739 - Epoch: [87][  100/  100]    Loss 1.827984    Top1 58.240000    Top5 84.840000    
2024-02-17 11:59:48,924 - ==> Top1: 58.240    Top5: 84.840    Loss: 1.828

2024-02-17 11:59:48,935 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 11:59:48,935 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 11:59:48,995 - 

2024-02-17 11:59:48,995 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 11:59:56,659 - Epoch: [88][  100/  500]    Overall Loss 0.547444    Objective Loss 0.547444                                        LR 0.000500    Time 0.076586    
2024-02-17 12:00:03,768 - Epoch: [88][  200/  500]    Overall Loss 0.558846    Objective Loss 0.558846                                        LR 0.000500    Time 0.073815    
2024-02-17 12:00:10,810 - Epoch: [88][  300/  500]    Overall Loss 0.563672    Objective Loss 0.563672                                        LR 0.000500    Time 0.072671    
2024-02-17 12:00:17,998 - Epoch: [88][  400/  500]    Overall Loss 0.568608    Objective Loss 0.568608                                        LR 0.000500    Time 0.072463    
2024-02-17 12:00:25,229 - Epoch: [88][  500/  500]    Overall Loss 0.572333    Objective Loss 0.572333    Top1 87.000000    Top5 98.000000    LR 0.000500    Time 0.072425    
2024-02-17 12:00:25,388 - --- validate (epoch=88)-----------
2024-02-17 12:00:25,389 - 10000 samples (100 per mini-batch)
2024-02-17 12:00:28,524 - Epoch: [88][  100/  100]    Loss 1.751668    Top1 58.800000    Top5 85.800000    
2024-02-17 12:00:28,650 - ==> Top1: 58.800    Top5: 85.800    Loss: 1.752

2024-02-17 12:00:28,662 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:00:28,662 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:00:28,722 - 

2024-02-17 12:00:28,723 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:00:36,478 - Epoch: [89][  100/  500]    Overall Loss 0.537153    Objective Loss 0.537153                                        LR 0.000500    Time 0.077503    
2024-02-17 12:00:43,671 - Epoch: [89][  200/  500]    Overall Loss 0.542063    Objective Loss 0.542063                                        LR 0.000500    Time 0.074692    
2024-02-17 12:00:50,889 - Epoch: [89][  300/  500]    Overall Loss 0.545037    Objective Loss 0.545037                                        LR 0.000500    Time 0.073843    
2024-02-17 12:00:58,054 - Epoch: [89][  400/  500]    Overall Loss 0.550915    Objective Loss 0.550915                                        LR 0.000500    Time 0.073284    
2024-02-17 12:01:05,095 - Epoch: [89][  500/  500]    Overall Loss 0.556556    Objective Loss 0.556556    Top1 87.000000    Top5 97.000000    LR 0.000500    Time 0.072702    
2024-02-17 12:01:05,245 - --- validate (epoch=89)-----------
2024-02-17 12:01:05,246 - 10000 samples (100 per mini-batch)
2024-02-17 12:01:08,076 - Epoch: [89][  100/  100]    Loss 1.848719    Top1 57.640000    Top5 84.930000    
2024-02-17 12:01:08,200 - ==> Top1: 57.640    Top5: 84.930    Loss: 1.849

2024-02-17 12:01:08,210 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:01:08,211 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:01:08,270 - 

2024-02-17 12:01:08,271 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:01:16,038 - Epoch: [90][  100/  500]    Overall Loss 0.529408    Objective Loss 0.529408                                        LR 0.000500    Time 0.077618    
2024-02-17 12:01:23,200 - Epoch: [90][  200/  500]    Overall Loss 0.539266    Objective Loss 0.539266                                        LR 0.000500    Time 0.074600    
2024-02-17 12:01:30,353 - Epoch: [90][  300/  500]    Overall Loss 0.540605    Objective Loss 0.540605                                        LR 0.000500    Time 0.073562    
2024-02-17 12:01:37,559 - Epoch: [90][  400/  500]    Overall Loss 0.546338    Objective Loss 0.546338                                        LR 0.000500    Time 0.073178    
2024-02-17 12:01:44,645 - Epoch: [90][  500/  500]    Overall Loss 0.556061    Objective Loss 0.556061    Top1 83.000000    Top5 97.500000    LR 0.000500    Time 0.072705    
2024-02-17 12:01:44,814 - --- validate (epoch=90)-----------
2024-02-17 12:01:44,815 - 10000 samples (100 per mini-batch)
2024-02-17 12:01:47,673 - Epoch: [90][  100/  100]    Loss 1.862603    Top1 57.940000    Top5 84.360000    
2024-02-17 12:01:47,760 - ==> Top1: 57.940    Top5: 84.360    Loss: 1.863

2024-02-17 12:01:47,771 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:01:47,771 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:01:47,832 - 

2024-02-17 12:01:47,832 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:01:55,515 - Epoch: [91][  100/  500]    Overall Loss 0.518050    Objective Loss 0.518050                                        LR 0.000500    Time 0.076780    
2024-02-17 12:02:02,620 - Epoch: [91][  200/  500]    Overall Loss 0.528958    Objective Loss 0.528958                                        LR 0.000500    Time 0.073894    
2024-02-17 12:02:09,690 - Epoch: [91][  300/  500]    Overall Loss 0.539271    Objective Loss 0.539271                                        LR 0.000500    Time 0.072816    
2024-02-17 12:02:16,913 - Epoch: [91][  400/  500]    Overall Loss 0.544243    Objective Loss 0.544243                                        LR 0.000500    Time 0.072659    
2024-02-17 12:02:24,109 - Epoch: [91][  500/  500]    Overall Loss 0.549738    Objective Loss 0.549738    Top1 87.000000    Top5 99.000000    LR 0.000500    Time 0.072512    
2024-02-17 12:02:24,234 - --- validate (epoch=91)-----------
2024-02-17 12:02:24,235 - 10000 samples (100 per mini-batch)
2024-02-17 12:02:27,191 - Epoch: [91][  100/  100]    Loss 1.888735    Top1 57.300000    Top5 84.190000    
2024-02-17 12:02:27,312 - ==> Top1: 57.300    Top5: 84.190    Loss: 1.889

2024-02-17 12:02:27,323 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:02:27,324 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:02:27,382 - 

2024-02-17 12:02:27,383 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:02:34,989 - Epoch: [92][  100/  500]    Overall Loss 0.512143    Objective Loss 0.512143                                        LR 0.000500    Time 0.076014    
2024-02-17 12:02:42,110 - Epoch: [92][  200/  500]    Overall Loss 0.524299    Objective Loss 0.524299                                        LR 0.000500    Time 0.073590    
2024-02-17 12:02:49,007 - Epoch: [92][  300/  500]    Overall Loss 0.532035    Objective Loss 0.532035                                        LR 0.000500    Time 0.072040    
2024-02-17 12:02:56,136 - Epoch: [92][  400/  500]    Overall Loss 0.539652    Objective Loss 0.539652                                        LR 0.000500    Time 0.071841    
2024-02-17 12:03:03,224 - Epoch: [92][  500/  500]    Overall Loss 0.544782    Objective Loss 0.544782    Top1 77.500000    Top5 96.500000    LR 0.000500    Time 0.071641    
2024-02-17 12:03:03,394 - --- validate (epoch=92)-----------
2024-02-17 12:03:03,395 - 10000 samples (100 per mini-batch)
2024-02-17 12:03:06,648 - Epoch: [92][  100/  100]    Loss 1.756985    Top1 59.200000    Top5 85.740000    
2024-02-17 12:03:06,759 - ==> Top1: 59.200    Top5: 85.740    Loss: 1.757

2024-02-17 12:03:06,771 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:03:06,772 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:03:06,833 - 

2024-02-17 12:03:06,833 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:03:14,500 - Epoch: [93][  100/  500]    Overall Loss 0.506487    Objective Loss 0.506487                                        LR 0.000500    Time 0.076614    
2024-02-17 12:03:21,783 - Epoch: [93][  200/  500]    Overall Loss 0.517290    Objective Loss 0.517290                                        LR 0.000500    Time 0.074703    
2024-02-17 12:03:28,913 - Epoch: [93][  300/  500]    Overall Loss 0.525091    Objective Loss 0.525091                                        LR 0.000500    Time 0.073553    
2024-02-17 12:03:36,192 - Epoch: [93][  400/  500]    Overall Loss 0.529492    Objective Loss 0.529492                                        LR 0.000500    Time 0.073352    
2024-02-17 12:03:43,425 - Epoch: [93][  500/  500]    Overall Loss 0.537910    Objective Loss 0.537910    Top1 83.000000    Top5 99.000000    LR 0.000500    Time 0.073140    
2024-02-17 12:03:43,623 - --- validate (epoch=93)-----------
2024-02-17 12:03:43,623 - 10000 samples (100 per mini-batch)
2024-02-17 12:03:46,659 - Epoch: [93][  100/  100]    Loss 1.832554    Top1 58.650000    Top5 84.650000    
2024-02-17 12:03:46,762 - ==> Top1: 58.650    Top5: 84.650    Loss: 1.833

2024-02-17 12:03:46,773 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:03:46,774 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:03:46,833 - 

2024-02-17 12:03:46,834 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:03:54,494 - Epoch: [94][  100/  500]    Overall Loss 0.500161    Objective Loss 0.500161                                        LR 0.000500    Time 0.076553    
2024-02-17 12:04:01,750 - Epoch: [94][  200/  500]    Overall Loss 0.509390    Objective Loss 0.509390                                        LR 0.000500    Time 0.074533    
2024-02-17 12:04:08,999 - Epoch: [94][  300/  500]    Overall Loss 0.520344    Objective Loss 0.520344                                        LR 0.000500    Time 0.073839    
2024-02-17 12:04:16,090 - Epoch: [94][  400/  500]    Overall Loss 0.527340    Objective Loss 0.527340                                        LR 0.000500    Time 0.073096    
2024-02-17 12:04:23,226 - Epoch: [94][  500/  500]    Overall Loss 0.534484    Objective Loss 0.534484    Top1 84.000000    Top5 98.000000    LR 0.000500    Time 0.072740    
2024-02-17 12:04:23,364 - --- validate (epoch=94)-----------
2024-02-17 12:04:23,365 - 10000 samples (100 per mini-batch)
2024-02-17 12:04:26,465 - Epoch: [94][  100/  100]    Loss 1.857067    Top1 57.960000    Top5 84.550000    
2024-02-17 12:04:26,549 - ==> Top1: 57.960    Top5: 84.550    Loss: 1.857

2024-02-17 12:04:26,554 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:04:26,554 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:04:26,604 - 

2024-02-17 12:04:26,604 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:04:33,925 - Epoch: [95][  100/  500]    Overall Loss 0.505093    Objective Loss 0.505093                                        LR 0.000500    Time 0.073160    
2024-02-17 12:04:41,121 - Epoch: [95][  200/  500]    Overall Loss 0.510239    Objective Loss 0.510239                                        LR 0.000500    Time 0.072541    
2024-02-17 12:04:48,271 - Epoch: [95][  300/  500]    Overall Loss 0.512875    Objective Loss 0.512875                                        LR 0.000500    Time 0.072178    
2024-02-17 12:04:55,401 - Epoch: [95][  400/  500]    Overall Loss 0.522760    Objective Loss 0.522760                                        LR 0.000500    Time 0.071950    
2024-02-17 12:05:02,503 - Epoch: [95][  500/  500]    Overall Loss 0.532060    Objective Loss 0.532060    Top1 84.000000    Top5 97.000000    LR 0.000500    Time 0.071755    
2024-02-17 12:05:02,683 - --- validate (epoch=95)-----------
2024-02-17 12:05:02,684 - 10000 samples (100 per mini-batch)
2024-02-17 12:05:05,574 - Epoch: [95][  100/  100]    Loss 1.794046    Top1 58.590000    Top5 85.450000    
2024-02-17 12:05:05,670 - ==> Top1: 58.590    Top5: 85.450    Loss: 1.794

2024-02-17 12:05:05,682 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:05:05,683 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:05:05,743 - 

2024-02-17 12:05:05,744 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:05:13,675 - Epoch: [96][  100/  500]    Overall Loss 0.506437    Objective Loss 0.506437                                        LR 0.000500    Time 0.079261    
2024-02-17 12:05:20,797 - Epoch: [96][  200/  500]    Overall Loss 0.510144    Objective Loss 0.510144                                        LR 0.000500    Time 0.075219    
2024-02-17 12:05:27,701 - Epoch: [96][  300/  500]    Overall Loss 0.513762    Objective Loss 0.513762                                        LR 0.000500    Time 0.073146    
2024-02-17 12:05:34,646 - Epoch: [96][  400/  500]    Overall Loss 0.521659    Objective Loss 0.521659                                        LR 0.000500    Time 0.072213    
2024-02-17 12:05:41,821 - Epoch: [96][  500/  500]    Overall Loss 0.523922    Objective Loss 0.523922    Top1 86.000000    Top5 98.500000    LR 0.000500    Time 0.072112    
2024-02-17 12:05:41,969 - --- validate (epoch=96)-----------
2024-02-17 12:05:41,970 - 10000 samples (100 per mini-batch)
2024-02-17 12:05:44,887 - Epoch: [96][  100/  100]    Loss 1.863796    Top1 57.850000    Top5 84.610000    
2024-02-17 12:05:44,984 - ==> Top1: 57.850    Top5: 84.610    Loss: 1.864

2024-02-17 12:05:44,996 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:05:44,997 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:05:45,056 - 

2024-02-17 12:05:45,057 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:05:52,707 - Epoch: [97][  100/  500]    Overall Loss 0.492927    Objective Loss 0.492927                                        LR 0.000500    Time 0.076445    
2024-02-17 12:05:59,822 - Epoch: [97][  200/  500]    Overall Loss 0.510134    Objective Loss 0.510134                                        LR 0.000500    Time 0.073779    
2024-02-17 12:06:07,092 - Epoch: [97][  300/  500]    Overall Loss 0.511359    Objective Loss 0.511359                                        LR 0.000500    Time 0.073405    
2024-02-17 12:06:14,222 - Epoch: [97][  400/  500]    Overall Loss 0.517971    Objective Loss 0.517971                                        LR 0.000500    Time 0.072869    
2024-02-17 12:06:21,429 - Epoch: [97][  500/  500]    Overall Loss 0.522544    Objective Loss 0.522544    Top1 80.000000    Top5 96.500000    LR 0.000500    Time 0.072701    
2024-02-17 12:06:21,636 - --- validate (epoch=97)-----------
2024-02-17 12:06:21,637 - 10000 samples (100 per mini-batch)
2024-02-17 12:06:24,572 - Epoch: [97][  100/  100]    Loss 1.799315    Top1 58.500000    Top5 85.210000    
2024-02-17 12:06:24,670 - ==> Top1: 58.500    Top5: 85.210    Loss: 1.799

2024-02-17 12:06:24,681 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:06:24,681 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:06:24,748 - 

2024-02-17 12:06:24,748 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:06:32,617 - Epoch: [98][  100/  500]    Overall Loss 0.492416    Objective Loss 0.492416                                        LR 0.000500    Time 0.078635    
2024-02-17 12:06:39,741 - Epoch: [98][  200/  500]    Overall Loss 0.509689    Objective Loss 0.509689                                        LR 0.000500    Time 0.074918    
2024-02-17 12:06:47,137 - Epoch: [98][  300/  500]    Overall Loss 0.514820    Objective Loss 0.514820                                        LR 0.000500    Time 0.074583    
2024-02-17 12:06:54,318 - Epoch: [98][  400/  500]    Overall Loss 0.519473    Objective Loss 0.519473                                        LR 0.000500    Time 0.073880    
2024-02-17 12:07:01,558 - Epoch: [98][  500/  500]    Overall Loss 0.520509    Objective Loss 0.520509    Top1 78.500000    Top5 96.000000    LR 0.000500    Time 0.073572    
2024-02-17 12:07:01,730 - --- validate (epoch=98)-----------
2024-02-17 12:07:01,731 - 10000 samples (100 per mini-batch)
2024-02-17 12:07:04,735 - Epoch: [98][  100/  100]    Loss 1.888811    Top1 57.210000    Top5 84.670000    
2024-02-17 12:07:04,898 - ==> Top1: 57.210    Top5: 84.670    Loss: 1.889

2024-02-17 12:07:04,911 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:07:04,911 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:07:04,975 - 

2024-02-17 12:07:04,975 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:07:12,602 - Epoch: [99][  100/  500]    Overall Loss 0.491538    Objective Loss 0.491538                                        LR 0.000500    Time 0.076214    
2024-02-17 12:07:19,951 - Epoch: [99][  200/  500]    Overall Loss 0.495809    Objective Loss 0.495809                                        LR 0.000500    Time 0.074832    
2024-02-17 12:07:27,268 - Epoch: [99][  300/  500]    Overall Loss 0.503789    Objective Loss 0.503789                                        LR 0.000500    Time 0.074262    
2024-02-17 12:07:34,434 - Epoch: [99][  400/  500]    Overall Loss 0.509748    Objective Loss 0.509748                                        LR 0.000500    Time 0.073600    
2024-02-17 12:07:41,578 - Epoch: [99][  500/  500]    Overall Loss 0.509678    Objective Loss 0.509678    Top1 83.000000    Top5 98.000000    LR 0.000500    Time 0.073159    
2024-02-17 12:07:41,674 - --- validate (epoch=99)-----------
2024-02-17 12:07:41,675 - 10000 samples (100 per mini-batch)
2024-02-17 12:07:44,709 - Epoch: [99][  100/  100]    Loss 1.846241    Top1 58.420000    Top5 85.290000    
2024-02-17 12:07:44,809 - ==> Top1: 58.420    Top5: 85.290    Loss: 1.846

2024-02-17 12:07:44,815 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-17 12:07:44,815 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:07:44,872 - 

2024-02-17 12:07:44,873 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:07:52,681 - Epoch: [100][  100/  500]    Overall Loss 0.451988    Objective Loss 0.451988                                        LR 0.000250    Time 0.078032    
2024-02-17 12:07:59,864 - Epoch: [100][  200/  500]    Overall Loss 0.452809    Objective Loss 0.452809                                        LR 0.000250    Time 0.074908    
2024-02-17 12:08:07,113 - Epoch: [100][  300/  500]    Overall Loss 0.448110    Objective Loss 0.448110                                        LR 0.000250    Time 0.074088    
2024-02-17 12:08:14,272 - Epoch: [100][  400/  500]    Overall Loss 0.446328    Objective Loss 0.446328                                        LR 0.000250    Time 0.073454    
2024-02-17 12:08:21,449 - Epoch: [100][  500/  500]    Overall Loss 0.444304    Objective Loss 0.444304    Top1 86.000000    Top5 99.500000    LR 0.000250    Time 0.073110    
2024-02-17 12:08:21,592 - --- validate (epoch=100)-----------
2024-02-17 12:08:21,593 - 10000 samples (100 per mini-batch)
2024-02-17 12:08:24,551 - Epoch: [100][  100/  100]    Loss 1.728898    Top1 59.900000    Top5 85.980000    
2024-02-17 12:08:24,671 - ==> Top1: 59.900    Top5: 85.980    Loss: 1.729

2024-02-17 12:08:24,681 - ==> Best [Top1: 59.900   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 100]
2024-02-17 12:08:24,681 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:08:24,762 - 

2024-02-17 12:08:24,762 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:08:32,393 - Epoch: [101][  100/  500]    Overall Loss 0.418033    Objective Loss 0.418033                                        LR 0.000250    Time 0.076256    
2024-02-17 12:08:39,571 - Epoch: [101][  200/  500]    Overall Loss 0.421524    Objective Loss 0.421524                                        LR 0.000250    Time 0.073996    
2024-02-17 12:08:46,550 - Epoch: [101][  300/  500]    Overall Loss 0.426896    Objective Loss 0.426896                                        LR 0.000250    Time 0.072580    
2024-02-17 12:08:53,317 - Epoch: [101][  400/  500]    Overall Loss 0.427725    Objective Loss 0.427725                                        LR 0.000250    Time 0.071344    
2024-02-17 12:09:00,313 - Epoch: [101][  500/  500]    Overall Loss 0.429468    Objective Loss 0.429468    Top1 86.000000    Top5 98.500000    LR 0.000250    Time 0.071061    
2024-02-17 12:09:00,437 - --- validate (epoch=101)-----------
2024-02-17 12:09:00,437 - 10000 samples (100 per mini-batch)
2024-02-17 12:09:03,409 - Epoch: [101][  100/  100]    Loss 1.757559    Top1 59.600000    Top5 86.150000    
2024-02-17 12:09:03,552 - ==> Top1: 59.600    Top5: 86.150    Loss: 1.758

2024-02-17 12:09:03,560 - ==> Best [Top1: 59.900   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 100]
2024-02-17 12:09:03,560 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:09:03,623 - 

2024-02-17 12:09:03,623 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:09:11,517 - Epoch: [102][  100/  500]    Overall Loss 0.416229    Objective Loss 0.416229                                        LR 0.000250    Time 0.078888    
2024-02-17 12:09:18,735 - Epoch: [102][  200/  500]    Overall Loss 0.413444    Objective Loss 0.413444                                        LR 0.000250    Time 0.075514    
2024-02-17 12:09:25,911 - Epoch: [102][  300/  500]    Overall Loss 0.420871    Objective Loss 0.420871                                        LR 0.000250    Time 0.074249    
2024-02-17 12:09:33,099 - Epoch: [102][  400/  500]    Overall Loss 0.427168    Objective Loss 0.427168                                        LR 0.000250    Time 0.073645    
2024-02-17 12:09:40,417 - Epoch: [102][  500/  500]    Overall Loss 0.427152    Objective Loss 0.427152    Top1 89.000000    Top5 99.500000    LR 0.000250    Time 0.073543    
2024-02-17 12:09:40,542 - --- validate (epoch=102)-----------
2024-02-17 12:09:40,543 - 10000 samples (100 per mini-batch)
2024-02-17 12:09:43,653 - Epoch: [102][  100/  100]    Loss 1.739574    Top1 60.070000    Top5 86.210000    
2024-02-17 12:09:43,755 - ==> Top1: 60.070    Top5: 86.210    Loss: 1.740

2024-02-17 12:09:43,761 - ==> Best [Top1: 60.070   Top5: 86.210   Sparsity:0.00   Params: 753952 on epoch: 102]
2024-02-17 12:09:43,761 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:09:43,850 - 

2024-02-17 12:09:43,850 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:09:51,498 - Epoch: [103][  100/  500]    Overall Loss 0.403438    Objective Loss 0.403438                                        LR 0.000250    Time 0.076425    
2024-02-17 12:09:58,615 - Epoch: [103][  200/  500]    Overall Loss 0.401079    Objective Loss 0.401079                                        LR 0.000250    Time 0.073777    
2024-02-17 12:10:05,792 - Epoch: [103][  300/  500]    Overall Loss 0.409565    Objective Loss 0.409565                                        LR 0.000250    Time 0.073094    
2024-02-17 12:10:12,970 - Epoch: [103][  400/  500]    Overall Loss 0.415376    Objective Loss 0.415376                                        LR 0.000250    Time 0.072754    
2024-02-17 12:10:20,288 - Epoch: [103][  500/  500]    Overall Loss 0.418406    Objective Loss 0.418406    Top1 89.000000    Top5 99.500000    LR 0.000250    Time 0.072830    
2024-02-17 12:10:20,416 - --- validate (epoch=103)-----------
2024-02-17 12:10:20,417 - 10000 samples (100 per mini-batch)
2024-02-17 12:10:23,641 - Epoch: [103][  100/  100]    Loss 1.754008    Top1 59.800000    Top5 85.760000    
2024-02-17 12:10:23,775 - ==> Top1: 59.800    Top5: 85.760    Loss: 1.754

2024-02-17 12:10:23,792 - ==> Best [Top1: 60.070   Top5: 86.210   Sparsity:0.00   Params: 753952 on epoch: 102]
2024-02-17 12:10:23,792 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:10:23,861 - 

2024-02-17 12:10:23,861 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:10:31,527 - Epoch: [104][  100/  500]    Overall Loss 0.394743    Objective Loss 0.394743                                        LR 0.000250    Time 0.076594    
2024-02-17 12:10:38,853 - Epoch: [104][  200/  500]    Overall Loss 0.400930    Objective Loss 0.400930                                        LR 0.000250    Time 0.074909    
2024-02-17 12:10:46,037 - Epoch: [104][  300/  500]    Overall Loss 0.403892    Objective Loss 0.403892                                        LR 0.000250    Time 0.073872    
2024-02-17 12:10:53,207 - Epoch: [104][  400/  500]    Overall Loss 0.407532    Objective Loss 0.407532                                        LR 0.000250    Time 0.073318    
2024-02-17 12:11:00,530 - Epoch: [104][  500/  500]    Overall Loss 0.412013    Objective Loss 0.412013    Top1 87.000000    Top5 99.000000    LR 0.000250    Time 0.073292    
2024-02-17 12:11:00,668 - --- validate (epoch=104)-----------
2024-02-17 12:11:00,669 - 10000 samples (100 per mini-batch)
2024-02-17 12:11:04,190 - Epoch: [104][  100/  100]    Loss 1.762275    Top1 60.200000    Top5 86.020000    
2024-02-17 12:11:04,303 - ==> Top1: 60.200    Top5: 86.020    Loss: 1.762

2024-02-17 12:11:04,311 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:11:04,311 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:11:04,394 - 

2024-02-17 12:11:04,395 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:11:12,469 - Epoch: [105][  100/  500]    Overall Loss 0.393309    Objective Loss 0.393309                                        LR 0.000250    Time 0.080670    
2024-02-17 12:11:19,740 - Epoch: [105][  200/  500]    Overall Loss 0.400789    Objective Loss 0.400789                                        LR 0.000250    Time 0.076669    
2024-02-17 12:11:26,883 - Epoch: [105][  300/  500]    Overall Loss 0.402713    Objective Loss 0.402713                                        LR 0.000250    Time 0.074909    
2024-02-17 12:11:34,078 - Epoch: [105][  400/  500]    Overall Loss 0.410494    Objective Loss 0.410494                                        LR 0.000250    Time 0.074157    
2024-02-17 12:11:41,297 - Epoch: [105][  500/  500]    Overall Loss 0.411551    Objective Loss 0.411551    Top1 88.500000    Top5 99.500000    LR 0.000250    Time 0.073756    
2024-02-17 12:11:41,432 - --- validate (epoch=105)-----------
2024-02-17 12:11:41,433 - 10000 samples (100 per mini-batch)
2024-02-17 12:11:44,499 - Epoch: [105][  100/  100]    Loss 1.748009    Top1 59.960000    Top5 86.130000    
2024-02-17 12:11:44,607 - ==> Top1: 59.960    Top5: 86.130    Loss: 1.748

2024-02-17 12:11:44,616 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:11:44,617 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:11:44,693 - 

2024-02-17 12:11:44,693 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:11:52,628 - Epoch: [106][  100/  500]    Overall Loss 0.394131    Objective Loss 0.394131                                        LR 0.000250    Time 0.079291    
2024-02-17 12:11:59,874 - Epoch: [106][  200/  500]    Overall Loss 0.396050    Objective Loss 0.396050                                        LR 0.000250    Time 0.075849    
2024-02-17 12:12:07,051 - Epoch: [106][  300/  500]    Overall Loss 0.398229    Objective Loss 0.398229                                        LR 0.000250    Time 0.074477    
2024-02-17 12:12:14,236 - Epoch: [106][  400/  500]    Overall Loss 0.399904    Objective Loss 0.399904                                        LR 0.000250    Time 0.073808    
2024-02-17 12:12:21,472 - Epoch: [106][  500/  500]    Overall Loss 0.403155    Objective Loss 0.403155    Top1 86.500000    Top5 99.500000    LR 0.000250    Time 0.073509    
2024-02-17 12:12:21,630 - --- validate (epoch=106)-----------
2024-02-17 12:12:21,631 - 10000 samples (100 per mini-batch)
2024-02-17 12:12:24,764 - Epoch: [106][  100/  100]    Loss 1.801233    Top1 59.730000    Top5 85.940000    
2024-02-17 12:12:24,915 - ==> Top1: 59.730    Top5: 85.940    Loss: 1.801

2024-02-17 12:12:24,922 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:12:24,922 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:12:24,983 - 

2024-02-17 12:12:24,984 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:12:32,715 - Epoch: [107][  100/  500]    Overall Loss 0.401932    Objective Loss 0.401932                                        LR 0.000250    Time 0.077257    
2024-02-17 12:12:39,746 - Epoch: [107][  200/  500]    Overall Loss 0.399534    Objective Loss 0.399534                                        LR 0.000250    Time 0.073763    
2024-02-17 12:12:46,973 - Epoch: [107][  300/  500]    Overall Loss 0.402269    Objective Loss 0.402269                                        LR 0.000250    Time 0.073252    
2024-02-17 12:12:54,057 - Epoch: [107][  400/  500]    Overall Loss 0.400546    Objective Loss 0.400546                                        LR 0.000250    Time 0.072639    
2024-02-17 12:13:01,197 - Epoch: [107][  500/  500]    Overall Loss 0.405310    Objective Loss 0.405310    Top1 87.000000    Top5 100.000000    LR 0.000250    Time 0.072382    
2024-02-17 12:13:01,351 - --- validate (epoch=107)-----------
2024-02-17 12:13:01,351 - 10000 samples (100 per mini-batch)
2024-02-17 12:13:04,421 - Epoch: [107][  100/  100]    Loss 1.785273    Top1 59.360000    Top5 86.040000    
2024-02-17 12:13:04,527 - ==> Top1: 59.360    Top5: 86.040    Loss: 1.785

2024-02-17 12:13:04,543 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:13:04,543 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:13:04,614 - 

2024-02-17 12:13:04,614 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:13:12,296 - Epoch: [108][  100/  500]    Overall Loss 0.384186    Objective Loss 0.384186                                        LR 0.000250    Time 0.076760    
2024-02-17 12:13:19,433 - Epoch: [108][  200/  500]    Overall Loss 0.387768    Objective Loss 0.387768                                        LR 0.000250    Time 0.074044    
2024-02-17 12:13:26,598 - Epoch: [108][  300/  500]    Overall Loss 0.390102    Objective Loss 0.390102                                        LR 0.000250    Time 0.073231    
2024-02-17 12:13:33,702 - Epoch: [108][  400/  500]    Overall Loss 0.397599    Objective Loss 0.397599                                        LR 0.000250    Time 0.072672    
2024-02-17 12:13:41,001 - Epoch: [108][  500/  500]    Overall Loss 0.399284    Objective Loss 0.399284    Top1 87.000000    Top5 98.500000    LR 0.000250    Time 0.072727    
2024-02-17 12:13:41,183 - --- validate (epoch=108)-----------
2024-02-17 12:13:41,184 - 10000 samples (100 per mini-batch)
2024-02-17 12:13:44,506 - Epoch: [108][  100/  100]    Loss 1.784492    Top1 60.080000    Top5 85.660000    
2024-02-17 12:13:44,612 - ==> Top1: 60.080    Top5: 85.660    Loss: 1.784

2024-02-17 12:13:44,618 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:13:44,618 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:13:44,682 - 

2024-02-17 12:13:44,682 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:13:52,350 - Epoch: [109][  100/  500]    Overall Loss 0.383582    Objective Loss 0.383582                                        LR 0.000250    Time 0.076626    
2024-02-17 12:13:59,445 - Epoch: [109][  200/  500]    Overall Loss 0.395178    Objective Loss 0.395178                                        LR 0.000250    Time 0.073766    
2024-02-17 12:14:06,660 - Epoch: [109][  300/  500]    Overall Loss 0.394470    Objective Loss 0.394470                                        LR 0.000250    Time 0.073214    
2024-02-17 12:14:13,806 - Epoch: [109][  400/  500]    Overall Loss 0.396336    Objective Loss 0.396336                                        LR 0.000250    Time 0.072765    
2024-02-17 12:14:20,916 - Epoch: [109][  500/  500]    Overall Loss 0.397936    Objective Loss 0.397936    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.072422    
2024-02-17 12:14:21,060 - --- validate (epoch=109)-----------
2024-02-17 12:14:21,061 - 10000 samples (100 per mini-batch)
2024-02-17 12:14:24,078 - Epoch: [109][  100/  100]    Loss 1.760970    Top1 60.100000    Top5 86.090000    
2024-02-17 12:14:24,193 - ==> Top1: 60.100    Top5: 86.090    Loss: 1.761

2024-02-17 12:14:24,205 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:14:24,205 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:14:24,272 - 

2024-02-17 12:14:24,273 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:14:32,244 - Epoch: [110][  100/  500]    Overall Loss 0.375902    Objective Loss 0.375902                                        LR 0.000250    Time 0.079631    
2024-02-17 12:14:39,280 - Epoch: [110][  200/  500]    Overall Loss 0.385555    Objective Loss 0.385555                                        LR 0.000250    Time 0.074972    
2024-02-17 12:14:46,142 - Epoch: [110][  300/  500]    Overall Loss 0.391136    Objective Loss 0.391136                                        LR 0.000250    Time 0.072845    
2024-02-17 12:14:53,197 - Epoch: [110][  400/  500]    Overall Loss 0.393006    Objective Loss 0.393006                                        LR 0.000250    Time 0.072261    
2024-02-17 12:15:00,389 - Epoch: [110][  500/  500]    Overall Loss 0.395539    Objective Loss 0.395539    Top1 88.000000    Top5 98.500000    LR 0.000250    Time 0.072184    
2024-02-17 12:15:00,562 - --- validate (epoch=110)-----------
2024-02-17 12:15:00,563 - 10000 samples (100 per mini-batch)
2024-02-17 12:15:03,591 - Epoch: [110][  100/  100]    Loss 1.768408    Top1 59.650000    Top5 85.850000    
2024-02-17 12:15:03,702 - ==> Top1: 59.650    Top5: 85.850    Loss: 1.768

2024-02-17 12:15:03,710 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:15:03,711 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:15:03,778 - 

2024-02-17 12:15:03,778 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:15:11,387 - Epoch: [111][  100/  500]    Overall Loss 0.376204    Objective Loss 0.376204                                        LR 0.000250    Time 0.076033    
2024-02-17 12:15:18,429 - Epoch: [111][  200/  500]    Overall Loss 0.375309    Objective Loss 0.375309                                        LR 0.000250    Time 0.073210    
2024-02-17 12:15:25,609 - Epoch: [111][  300/  500]    Overall Loss 0.379431    Objective Loss 0.379431                                        LR 0.000250    Time 0.072725    
2024-02-17 12:15:32,730 - Epoch: [111][  400/  500]    Overall Loss 0.384439    Objective Loss 0.384439                                        LR 0.000250    Time 0.072336    
2024-02-17 12:15:39,939 - Epoch: [111][  500/  500]    Overall Loss 0.384868    Objective Loss 0.384868    Top1 91.500000    Top5 99.500000    LR 0.000250    Time 0.072279    
2024-02-17 12:15:40,059 - --- validate (epoch=111)-----------
2024-02-17 12:15:40,061 - 10000 samples (100 per mini-batch)
2024-02-17 12:15:43,123 - Epoch: [111][  100/  100]    Loss 1.789759    Top1 59.550000    Top5 85.860000    
2024-02-17 12:15:43,253 - ==> Top1: 59.550    Top5: 85.860    Loss: 1.790

2024-02-17 12:15:43,265 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:15:43,266 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:15:43,334 - 

2024-02-17 12:15:43,335 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:15:51,766 - Epoch: [112][  100/  500]    Overall Loss 0.372916    Objective Loss 0.372916                                        LR 0.000250    Time 0.084258    
2024-02-17 12:15:59,159 - Epoch: [112][  200/  500]    Overall Loss 0.377291    Objective Loss 0.377291                                        LR 0.000250    Time 0.079072    
2024-02-17 12:16:06,641 - Epoch: [112][  300/  500]    Overall Loss 0.377563    Objective Loss 0.377563                                        LR 0.000250    Time 0.077640    
2024-02-17 12:16:14,068 - Epoch: [112][  400/  500]    Overall Loss 0.383397    Objective Loss 0.383397                                        LR 0.000250    Time 0.076785    
2024-02-17 12:16:21,454 - Epoch: [112][  500/  500]    Overall Loss 0.386634    Objective Loss 0.386634    Top1 85.500000    Top5 99.500000    LR 0.000250    Time 0.076191    
2024-02-17 12:16:21,558 - --- validate (epoch=112)-----------
2024-02-17 12:16:21,559 - 10000 samples (100 per mini-batch)
2024-02-17 12:16:24,590 - Epoch: [112][  100/  100]    Loss 1.808364    Top1 59.860000    Top5 86.170000    
2024-02-17 12:16:24,688 - ==> Top1: 59.860    Top5: 86.170    Loss: 1.808

2024-02-17 12:16:24,700 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:16:24,700 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:16:24,766 - 

2024-02-17 12:16:24,766 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:16:32,786 - Epoch: [113][  100/  500]    Overall Loss 0.379976    Objective Loss 0.379976                                        LR 0.000250    Time 0.080129    
2024-02-17 12:16:40,148 - Epoch: [113][  200/  500]    Overall Loss 0.376639    Objective Loss 0.376639                                        LR 0.000250    Time 0.076855    
2024-02-17 12:16:47,550 - Epoch: [113][  300/  500]    Overall Loss 0.377383    Objective Loss 0.377383                                        LR 0.000250    Time 0.075896    
2024-02-17 12:16:55,011 - Epoch: [113][  400/  500]    Overall Loss 0.382346    Objective Loss 0.382346                                        LR 0.000250    Time 0.075562    
2024-02-17 12:17:02,448 - Epoch: [113][  500/  500]    Overall Loss 0.384519    Objective Loss 0.384519    Top1 86.000000    Top5 99.500000    LR 0.000250    Time 0.075315    
2024-02-17 12:17:02,555 - --- validate (epoch=113)-----------
2024-02-17 12:17:02,556 - 10000 samples (100 per mini-batch)
2024-02-17 12:17:05,657 - Epoch: [113][  100/  100]    Loss 1.799925    Top1 59.570000    Top5 85.930000    
2024-02-17 12:17:05,766 - ==> Top1: 59.570    Top5: 85.930    Loss: 1.800

2024-02-17 12:17:05,777 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:17:05,778 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:17:05,840 - 

2024-02-17 12:17:05,840 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:17:14,086 - Epoch: [114][  100/  500]    Overall Loss 0.362519    Objective Loss 0.362519                                        LR 0.000250    Time 0.082405    
2024-02-17 12:17:21,419 - Epoch: [114][  200/  500]    Overall Loss 0.368233    Objective Loss 0.368233                                        LR 0.000250    Time 0.077843    
2024-02-17 12:17:28,798 - Epoch: [114][  300/  500]    Overall Loss 0.368697    Objective Loss 0.368697                                        LR 0.000250    Time 0.076479    
2024-02-17 12:17:36,127 - Epoch: [114][  400/  500]    Overall Loss 0.373663    Objective Loss 0.373663                                        LR 0.000250    Time 0.075672    
2024-02-17 12:17:43,547 - Epoch: [114][  500/  500]    Overall Loss 0.380259    Objective Loss 0.380259    Top1 90.000000    Top5 99.000000    LR 0.000250    Time 0.075369    
2024-02-17 12:17:43,722 - --- validate (epoch=114)-----------
2024-02-17 12:17:43,723 - 10000 samples (100 per mini-batch)
2024-02-17 12:17:46,799 - Epoch: [114][  100/  100]    Loss 1.824426    Top1 59.310000    Top5 85.840000    
2024-02-17 12:17:46,897 - ==> Top1: 59.310    Top5: 85.840    Loss: 1.824

2024-02-17 12:17:46,906 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:17:46,907 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:17:46,966 - 

2024-02-17 12:17:46,966 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:17:54,841 - Epoch: [115][  100/  500]    Overall Loss 0.372828    Objective Loss 0.372828                                        LR 0.000250    Time 0.078690    
2024-02-17 12:18:02,362 - Epoch: [115][  200/  500]    Overall Loss 0.373907    Objective Loss 0.373907                                        LR 0.000250    Time 0.076928    
2024-02-17 12:18:10,028 - Epoch: [115][  300/  500]    Overall Loss 0.372180    Objective Loss 0.372180                                        LR 0.000250    Time 0.076823    
2024-02-17 12:18:17,342 - Epoch: [115][  400/  500]    Overall Loss 0.377547    Objective Loss 0.377547                                        LR 0.000250    Time 0.075894    
2024-02-17 12:18:24,718 - Epoch: [115][  500/  500]    Overall Loss 0.378982    Objective Loss 0.378982    Top1 85.000000    Top5 98.500000    LR 0.000250    Time 0.075458    
2024-02-17 12:18:24,832 - --- validate (epoch=115)-----------
2024-02-17 12:18:24,833 - 10000 samples (100 per mini-batch)
2024-02-17 12:18:27,815 - Epoch: [115][  100/  100]    Loss 1.803950    Top1 59.830000    Top5 85.820000    
2024-02-17 12:18:27,930 - ==> Top1: 59.830    Top5: 85.820    Loss: 1.804

2024-02-17 12:18:27,941 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:18:27,941 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:18:28,003 - 

2024-02-17 12:18:28,003 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:18:36,166 - Epoch: [116][  100/  500]    Overall Loss 0.370018    Objective Loss 0.370018                                        LR 0.000250    Time 0.081575    
2024-02-17 12:18:43,590 - Epoch: [116][  200/  500]    Overall Loss 0.365850    Objective Loss 0.365850                                        LR 0.000250    Time 0.077883    
2024-02-17 12:18:50,879 - Epoch: [116][  300/  500]    Overall Loss 0.368996    Objective Loss 0.368996                                        LR 0.000250    Time 0.076206    
2024-02-17 12:18:58,318 - Epoch: [116][  400/  500]    Overall Loss 0.370000    Objective Loss 0.370000                                        LR 0.000250    Time 0.075741    
2024-02-17 12:19:05,716 - Epoch: [116][  500/  500]    Overall Loss 0.374056    Objective Loss 0.374056    Top1 85.000000    Top5 99.500000    LR 0.000250    Time 0.075379    
2024-02-17 12:19:05,839 - --- validate (epoch=116)-----------
2024-02-17 12:19:05,840 - 10000 samples (100 per mini-batch)
2024-02-17 12:19:08,776 - Epoch: [116][  100/  100]    Loss 1.815954    Top1 59.720000    Top5 85.730000    
2024-02-17 12:19:08,882 - ==> Top1: 59.720    Top5: 85.730    Loss: 1.816

2024-02-17 12:19:08,894 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:19:08,895 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:19:08,959 - 

2024-02-17 12:19:08,959 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:19:16,715 - Epoch: [117][  100/  500]    Overall Loss 0.357760    Objective Loss 0.357760                                        LR 0.000250    Time 0.077502    
2024-02-17 12:19:23,982 - Epoch: [117][  200/  500]    Overall Loss 0.356955    Objective Loss 0.356955                                        LR 0.000250    Time 0.075068    
2024-02-17 12:19:31,298 - Epoch: [117][  300/  500]    Overall Loss 0.364442    Objective Loss 0.364442                                        LR 0.000250    Time 0.074418    
2024-02-17 12:19:38,638 - Epoch: [117][  400/  500]    Overall Loss 0.370243    Objective Loss 0.370243                                        LR 0.000250    Time 0.074151    
2024-02-17 12:19:46,078 - Epoch: [117][  500/  500]    Overall Loss 0.372194    Objective Loss 0.372194    Top1 89.500000    Top5 99.500000    LR 0.000250    Time 0.074193    
2024-02-17 12:19:46,200 - --- validate (epoch=117)-----------
2024-02-17 12:19:46,201 - 10000 samples (100 per mini-batch)
2024-02-17 12:19:49,208 - Epoch: [117][  100/  100]    Loss 1.813385    Top1 60.020000    Top5 85.900000    
2024-02-17 12:19:49,320 - ==> Top1: 60.020    Top5: 85.900    Loss: 1.813

2024-02-17 12:19:49,333 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:19:49,333 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:19:49,397 - 

2024-02-17 12:19:49,397 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:19:57,205 - Epoch: [118][  100/  500]    Overall Loss 0.357653    Objective Loss 0.357653                                        LR 0.000250    Time 0.078022    
2024-02-17 12:20:04,780 - Epoch: [118][  200/  500]    Overall Loss 0.353822    Objective Loss 0.353822                                        LR 0.000250    Time 0.076864    
2024-02-17 12:20:12,093 - Epoch: [118][  300/  500]    Overall Loss 0.354413    Objective Loss 0.354413                                        LR 0.000250    Time 0.075606    
2024-02-17 12:20:19,514 - Epoch: [118][  400/  500]    Overall Loss 0.362473    Objective Loss 0.362473                                        LR 0.000250    Time 0.075245    
2024-02-17 12:20:27,032 - Epoch: [118][  500/  500]    Overall Loss 0.368500    Objective Loss 0.368500    Top1 89.000000    Top5 99.500000    LR 0.000250    Time 0.075225    
2024-02-17 12:20:27,193 - --- validate (epoch=118)-----------
2024-02-17 12:20:27,193 - 10000 samples (100 per mini-batch)
2024-02-17 12:20:30,490 - Epoch: [118][  100/  100]    Loss 1.849383    Top1 59.390000    Top5 85.570000    
2024-02-17 12:20:30,612 - ==> Top1: 59.390    Top5: 85.570    Loss: 1.849

2024-02-17 12:20:30,623 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:20:30,624 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:20:30,686 - 

2024-02-17 12:20:30,687 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:20:38,549 - Epoch: [119][  100/  500]    Overall Loss 0.345665    Objective Loss 0.345665                                        LR 0.000250    Time 0.078566    
2024-02-17 12:20:46,174 - Epoch: [119][  200/  500]    Overall Loss 0.359003    Objective Loss 0.359003                                        LR 0.000250    Time 0.077386    
2024-02-17 12:20:53,562 - Epoch: [119][  300/  500]    Overall Loss 0.360961    Objective Loss 0.360961                                        LR 0.000250    Time 0.076205    
2024-02-17 12:21:01,008 - Epoch: [119][  400/  500]    Overall Loss 0.365260    Objective Loss 0.365260                                        LR 0.000250    Time 0.075758    
2024-02-17 12:21:08,418 - Epoch: [119][  500/  500]    Overall Loss 0.368261    Objective Loss 0.368261    Top1 88.000000    Top5 99.500000    LR 0.000250    Time 0.075418    
2024-02-17 12:21:08,535 - --- validate (epoch=119)-----------
2024-02-17 12:21:08,536 - 10000 samples (100 per mini-batch)
2024-02-17 12:21:11,561 - Epoch: [119][  100/  100]    Loss 1.855645    Top1 59.090000    Top5 85.700000    
2024-02-17 12:21:11,659 - ==> Top1: 59.090    Top5: 85.700    Loss: 1.856

2024-02-17 12:21:11,671 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:21:11,671 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:21:11,733 - 

2024-02-17 12:21:11,733 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:21:19,815 - Epoch: [120][  100/  500]    Overall Loss 0.339139    Objective Loss 0.339139                                        LR 0.000250    Time 0.080768    
2024-02-17 12:21:27,290 - Epoch: [120][  200/  500]    Overall Loss 0.346002    Objective Loss 0.346002                                        LR 0.000250    Time 0.077731    
2024-02-17 12:21:34,630 - Epoch: [120][  300/  500]    Overall Loss 0.356069    Objective Loss 0.356069                                        LR 0.000250    Time 0.076273    
2024-02-17 12:21:41,928 - Epoch: [120][  400/  500]    Overall Loss 0.359483    Objective Loss 0.359483                                        LR 0.000250    Time 0.075441    
2024-02-17 12:21:49,270 - Epoch: [120][  500/  500]    Overall Loss 0.365972    Objective Loss 0.365972    Top1 89.000000    Top5 98.500000    LR 0.000250    Time 0.075029    
2024-02-17 12:21:49,406 - --- validate (epoch=120)-----------
2024-02-17 12:21:49,406 - 10000 samples (100 per mini-batch)
2024-02-17 12:21:52,387 - Epoch: [120][  100/  100]    Loss 1.849578    Top1 59.150000    Top5 85.530000    
2024-02-17 12:21:52,487 - ==> Top1: 59.150    Top5: 85.530    Loss: 1.850

2024-02-17 12:21:52,500 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:21:52,500 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:21:52,566 - 

2024-02-17 12:21:52,566 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:22:00,505 - Epoch: [121][  100/  500]    Overall Loss 0.353543    Objective Loss 0.353543                                        LR 0.000250    Time 0.079309    
2024-02-17 12:22:07,881 - Epoch: [121][  200/  500]    Overall Loss 0.355225    Objective Loss 0.355225                                        LR 0.000250    Time 0.076515    
2024-02-17 12:22:15,239 - Epoch: [121][  300/  500]    Overall Loss 0.357259    Objective Loss 0.357259                                        LR 0.000250    Time 0.075522    
2024-02-17 12:22:22,778 - Epoch: [121][  400/  500]    Overall Loss 0.362525    Objective Loss 0.362525                                        LR 0.000250    Time 0.075479    
2024-02-17 12:22:30,209 - Epoch: [121][  500/  500]    Overall Loss 0.365523    Objective Loss 0.365523    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.075237    
2024-02-17 12:22:30,335 - --- validate (epoch=121)-----------
2024-02-17 12:22:30,336 - 10000 samples (100 per mini-batch)
2024-02-17 12:22:33,372 - Epoch: [121][  100/  100]    Loss 1.824821    Top1 59.830000    Top5 86.040000    
2024-02-17 12:22:33,500 - ==> Top1: 59.830    Top5: 86.040    Loss: 1.825

2024-02-17 12:22:33,511 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:22:33,512 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:22:33,580 - 

2024-02-17 12:22:33,581 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:22:41,425 - Epoch: [122][  100/  500]    Overall Loss 0.342752    Objective Loss 0.342752                                        LR 0.000250    Time 0.078387    
2024-02-17 12:22:48,967 - Epoch: [122][  200/  500]    Overall Loss 0.351260    Objective Loss 0.351260                                        LR 0.000250    Time 0.076882    
2024-02-17 12:22:56,307 - Epoch: [122][  300/  500]    Overall Loss 0.356273    Objective Loss 0.356273                                        LR 0.000250    Time 0.075709    
2024-02-17 12:23:03,659 - Epoch: [122][  400/  500]    Overall Loss 0.360148    Objective Loss 0.360148                                        LR 0.000250    Time 0.075151    
2024-02-17 12:23:11,050 - Epoch: [122][  500/  500]    Overall Loss 0.361480    Objective Loss 0.361480    Top1 86.500000    Top5 99.500000    LR 0.000250    Time 0.074895    
2024-02-17 12:23:11,169 - --- validate (epoch=122)-----------
2024-02-17 12:23:11,170 - 10000 samples (100 per mini-batch)
2024-02-17 12:23:14,588 - Epoch: [122][  100/  100]    Loss 1.836520    Top1 59.600000    Top5 85.500000    
2024-02-17 12:23:14,727 - ==> Top1: 59.600    Top5: 85.500    Loss: 1.837

2024-02-17 12:23:14,736 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:23:14,736 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:23:14,796 - 

2024-02-17 12:23:14,796 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:23:22,646 - Epoch: [123][  100/  500]    Overall Loss 0.335022    Objective Loss 0.335022                                        LR 0.000250    Time 0.078442    
2024-02-17 12:23:29,986 - Epoch: [123][  200/  500]    Overall Loss 0.342234    Objective Loss 0.342234                                        LR 0.000250    Time 0.075900    
2024-02-17 12:23:37,343 - Epoch: [123][  300/  500]    Overall Loss 0.348723    Objective Loss 0.348723                                        LR 0.000250    Time 0.075107    
2024-02-17 12:23:44,629 - Epoch: [123][  400/  500]    Overall Loss 0.351100    Objective Loss 0.351100                                        LR 0.000250    Time 0.074536    
2024-02-17 12:23:51,974 - Epoch: [123][  500/  500]    Overall Loss 0.353314    Objective Loss 0.353314    Top1 84.500000    Top5 100.000000    LR 0.000250    Time 0.074307    
2024-02-17 12:23:52,097 - --- validate (epoch=123)-----------
2024-02-17 12:23:52,097 - 10000 samples (100 per mini-batch)
2024-02-17 12:23:55,262 - Epoch: [123][  100/  100]    Loss 1.858697    Top1 59.060000    Top5 85.740000    
2024-02-17 12:23:55,376 - ==> Top1: 59.060    Top5: 85.740    Loss: 1.859

2024-02-17 12:23:55,387 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:23:55,387 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:23:55,452 - 

2024-02-17 12:23:55,452 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:24:03,661 - Epoch: [124][  100/  500]    Overall Loss 0.339974    Objective Loss 0.339974                                        LR 0.000250    Time 0.082031    
2024-02-17 12:24:10,999 - Epoch: [124][  200/  500]    Overall Loss 0.345771    Objective Loss 0.345771                                        LR 0.000250    Time 0.077683    
2024-02-17 12:24:18,263 - Epoch: [124][  300/  500]    Overall Loss 0.345579    Objective Loss 0.345579                                        LR 0.000250    Time 0.075989    
2024-02-17 12:24:25,569 - Epoch: [124][  400/  500]    Overall Loss 0.349166    Objective Loss 0.349166                                        LR 0.000250    Time 0.075247    
2024-02-17 12:24:32,979 - Epoch: [124][  500/  500]    Overall Loss 0.353267    Objective Loss 0.353267    Top1 87.000000    Top5 99.000000    LR 0.000250    Time 0.075011    
2024-02-17 12:24:33,122 - --- validate (epoch=124)-----------
2024-02-17 12:24:33,123 - 10000 samples (100 per mini-batch)
2024-02-17 12:24:36,387 - Epoch: [124][  100/  100]    Loss 1.852374    Top1 59.910000    Top5 85.740000    
2024-02-17 12:24:36,540 - ==> Top1: 59.910    Top5: 85.740    Loss: 1.852

2024-02-17 12:24:36,553 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:24:36,554 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:24:36,613 - 

2024-02-17 12:24:36,614 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:24:44,699 - Epoch: [125][  100/  500]    Overall Loss 0.342641    Objective Loss 0.342641                                        LR 0.000250    Time 0.080800    
2024-02-17 12:24:52,184 - Epoch: [125][  200/  500]    Overall Loss 0.339652    Objective Loss 0.339652                                        LR 0.000250    Time 0.077802    
2024-02-17 12:24:59,495 - Epoch: [125][  300/  500]    Overall Loss 0.342186    Objective Loss 0.342186                                        LR 0.000250    Time 0.076224    
2024-02-17 12:25:06,832 - Epoch: [125][  400/  500]    Overall Loss 0.347361    Objective Loss 0.347361                                        LR 0.000250    Time 0.075498    
2024-02-17 12:25:14,183 - Epoch: [125][  500/  500]    Overall Loss 0.349484    Objective Loss 0.349484    Top1 92.500000    Top5 100.000000    LR 0.000250    Time 0.075093    
2024-02-17 12:25:14,314 - --- validate (epoch=125)-----------
2024-02-17 12:25:14,315 - 10000 samples (100 per mini-batch)
2024-02-17 12:25:17,383 - Epoch: [125][  100/  100]    Loss 1.864347    Top1 59.370000    Top5 85.530000    
2024-02-17 12:25:17,489 - ==> Top1: 59.370    Top5: 85.530    Loss: 1.864

2024-02-17 12:25:17,501 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:25:17,502 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:25:17,565 - 

2024-02-17 12:25:17,566 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:25:25,717 - Epoch: [126][  100/  500]    Overall Loss 0.328410    Objective Loss 0.328410                                        LR 0.000250    Time 0.081452    
2024-02-17 12:25:33,081 - Epoch: [126][  200/  500]    Overall Loss 0.342120    Objective Loss 0.342120                                        LR 0.000250    Time 0.077525    
2024-02-17 12:25:40,418 - Epoch: [126][  300/  500]    Overall Loss 0.346524    Objective Loss 0.346524                                        LR 0.000250    Time 0.076126    
2024-02-17 12:25:47,776 - Epoch: [126][  400/  500]    Overall Loss 0.350320    Objective Loss 0.350320                                        LR 0.000250    Time 0.075479    
2024-02-17 12:25:55,309 - Epoch: [126][  500/  500]    Overall Loss 0.349495    Objective Loss 0.349495    Top1 89.500000    Top5 98.500000    LR 0.000250    Time 0.075441    
2024-02-17 12:25:55,454 - --- validate (epoch=126)-----------
2024-02-17 12:25:55,454 - 10000 samples (100 per mini-batch)
2024-02-17 12:25:58,481 - Epoch: [126][  100/  100]    Loss 1.874391    Top1 58.960000    Top5 85.670000    
2024-02-17 12:25:58,622 - ==> Top1: 58.960    Top5: 85.670    Loss: 1.874

2024-02-17 12:25:58,635 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:25:58,635 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:25:58,696 - 

2024-02-17 12:25:58,697 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:26:06,493 - Epoch: [127][  100/  500]    Overall Loss 0.337505    Objective Loss 0.337505                                        LR 0.000250    Time 0.077910    
2024-02-17 12:26:13,833 - Epoch: [127][  200/  500]    Overall Loss 0.341469    Objective Loss 0.341469                                        LR 0.000250    Time 0.075631    
2024-02-17 12:26:21,280 - Epoch: [127][  300/  500]    Overall Loss 0.342730    Objective Loss 0.342730                                        LR 0.000250    Time 0.075232    
2024-02-17 12:26:28,624 - Epoch: [127][  400/  500]    Overall Loss 0.347414    Objective Loss 0.347414                                        LR 0.000250    Time 0.074775    
2024-02-17 12:26:35,772 - Epoch: [127][  500/  500]    Overall Loss 0.350394    Objective Loss 0.350394    Top1 87.500000    Top5 99.000000    LR 0.000250    Time 0.074108    
2024-02-17 12:26:35,899 - --- validate (epoch=127)-----------
2024-02-17 12:26:35,899 - 10000 samples (100 per mini-batch)
2024-02-17 12:26:38,965 - Epoch: [127][  100/  100]    Loss 1.868177    Top1 59.330000    Top5 85.890000    
2024-02-17 12:26:39,076 - ==> Top1: 59.330    Top5: 85.890    Loss: 1.868

2024-02-17 12:26:39,088 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:26:39,088 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:26:39,151 - 

2024-02-17 12:26:39,151 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:26:46,980 - Epoch: [128][  100/  500]    Overall Loss 0.321977    Objective Loss 0.321977                                        LR 0.000250    Time 0.078234    
2024-02-17 12:26:54,367 - Epoch: [128][  200/  500]    Overall Loss 0.328395    Objective Loss 0.328395                                        LR 0.000250    Time 0.076029    
2024-02-17 12:27:01,958 - Epoch: [128][  300/  500]    Overall Loss 0.335899    Objective Loss 0.335899                                        LR 0.000250    Time 0.075976    
2024-02-17 12:27:09,419 - Epoch: [128][  400/  500]    Overall Loss 0.340811    Objective Loss 0.340811                                        LR 0.000250    Time 0.075624    
2024-02-17 12:27:16,766 - Epoch: [128][  500/  500]    Overall Loss 0.344051    Objective Loss 0.344051    Top1 90.000000    Top5 100.000000    LR 0.000250    Time 0.075186    
2024-02-17 12:27:16,914 - --- validate (epoch=128)-----------
2024-02-17 12:27:16,915 - 10000 samples (100 per mini-batch)
2024-02-17 12:27:20,163 - Epoch: [128][  100/  100]    Loss 1.862338    Top1 59.780000    Top5 86.150000    
2024-02-17 12:27:20,286 - ==> Top1: 59.780    Top5: 86.150    Loss: 1.862

2024-02-17 12:27:20,297 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:27:20,298 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:27:20,365 - 

2024-02-17 12:27:20,366 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:27:28,133 - Epoch: [129][  100/  500]    Overall Loss 0.327128    Objective Loss 0.327128                                        LR 0.000250    Time 0.077620    
2024-02-17 12:27:35,690 - Epoch: [129][  200/  500]    Overall Loss 0.330816    Objective Loss 0.330816                                        LR 0.000250    Time 0.076573    
2024-02-17 12:27:43,090 - Epoch: [129][  300/  500]    Overall Loss 0.334286    Objective Loss 0.334286                                        LR 0.000250    Time 0.075701    
2024-02-17 12:27:50,461 - Epoch: [129][  400/  500]    Overall Loss 0.336386    Objective Loss 0.336386                                        LR 0.000250    Time 0.075193    
2024-02-17 12:27:57,872 - Epoch: [129][  500/  500]    Overall Loss 0.339072    Objective Loss 0.339072    Top1 89.500000    Top5 100.000000    LR 0.000250    Time 0.074968    
2024-02-17 12:27:58,016 - --- validate (epoch=129)-----------
2024-02-17 12:27:58,017 - 10000 samples (100 per mini-batch)
2024-02-17 12:28:01,065 - Epoch: [129][  100/  100]    Loss 1.913295    Top1 59.320000    Top5 85.110000    
2024-02-17 12:28:01,191 - ==> Top1: 59.320    Top5: 85.110    Loss: 1.913

2024-02-17 12:28:01,203 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:28:01,204 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:28:01,265 - 

2024-02-17 12:28:01,266 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:28:09,344 - Epoch: [130][  100/  500]    Overall Loss 0.334636    Objective Loss 0.334636                                        LR 0.000250    Time 0.080725    
2024-02-17 12:28:16,798 - Epoch: [130][  200/  500]    Overall Loss 0.330480    Objective Loss 0.330480                                        LR 0.000250    Time 0.077614    
2024-02-17 12:28:23,944 - Epoch: [130][  300/  500]    Overall Loss 0.327833    Objective Loss 0.327833                                        LR 0.000250    Time 0.075549    
2024-02-17 12:28:31,409 - Epoch: [130][  400/  500]    Overall Loss 0.331335    Objective Loss 0.331335                                        LR 0.000250    Time 0.075314    
2024-02-17 12:28:38,827 - Epoch: [130][  500/  500]    Overall Loss 0.335437    Objective Loss 0.335437    Top1 90.000000    Top5 98.500000    LR 0.000250    Time 0.075080    
2024-02-17 12:28:38,959 - --- validate (epoch=130)-----------
2024-02-17 12:28:38,960 - 10000 samples (100 per mini-batch)
2024-02-17 12:28:41,914 - Epoch: [130][  100/  100]    Loss 1.907367    Top1 59.130000    Top5 85.190000    
2024-02-17 12:28:42,041 - ==> Top1: 59.130    Top5: 85.190    Loss: 1.907

2024-02-17 12:28:42,052 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:28:42,052 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:28:42,112 - 

2024-02-17 12:28:42,113 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:28:50,007 - Epoch: [131][  100/  500]    Overall Loss 0.317695    Objective Loss 0.317695                                        LR 0.000250    Time 0.078887    
2024-02-17 12:28:57,348 - Epoch: [131][  200/  500]    Overall Loss 0.322430    Objective Loss 0.322430                                        LR 0.000250    Time 0.076126    
2024-02-17 12:29:04,727 - Epoch: [131][  300/  500]    Overall Loss 0.333403    Objective Loss 0.333403                                        LR 0.000250    Time 0.075333    
2024-02-17 12:29:12,180 - Epoch: [131][  400/  500]    Overall Loss 0.334155    Objective Loss 0.334155                                        LR 0.000250    Time 0.075121    
2024-02-17 12:29:19,648 - Epoch: [131][  500/  500]    Overall Loss 0.337027    Objective Loss 0.337027    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.075026    
2024-02-17 12:29:19,773 - --- validate (epoch=131)-----------
2024-02-17 12:29:19,774 - 10000 samples (100 per mini-batch)
2024-02-17 12:29:22,740 - Epoch: [131][  100/  100]    Loss 1.899934    Top1 59.270000    Top5 85.610000    
2024-02-17 12:29:22,865 - ==> Top1: 59.270    Top5: 85.610    Loss: 1.900

2024-02-17 12:29:22,874 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:29:22,875 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:29:22,932 - 

2024-02-17 12:29:22,932 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:29:30,815 - Epoch: [132][  100/  500]    Overall Loss 0.324536    Objective Loss 0.324536                                        LR 0.000250    Time 0.078767    
2024-02-17 12:29:38,228 - Epoch: [132][  200/  500]    Overall Loss 0.326878    Objective Loss 0.326878                                        LR 0.000250    Time 0.076429    
2024-02-17 12:29:45,773 - Epoch: [132][  300/  500]    Overall Loss 0.329249    Objective Loss 0.329249                                        LR 0.000250    Time 0.076090    
2024-02-17 12:29:53,151 - Epoch: [132][  400/  500]    Overall Loss 0.333414    Objective Loss 0.333414                                        LR 0.000250    Time 0.075500    
2024-02-17 12:30:00,464 - Epoch: [132][  500/  500]    Overall Loss 0.336415    Objective Loss 0.336415    Top1 88.000000    Top5 99.500000    LR 0.000250    Time 0.075019    
2024-02-17 12:30:00,577 - --- validate (epoch=132)-----------
2024-02-17 12:30:00,578 - 10000 samples (100 per mini-batch)
2024-02-17 12:30:03,452 - Epoch: [132][  100/  100]    Loss 1.892687    Top1 59.240000    Top5 85.570000    
2024-02-17 12:30:03,595 - ==> Top1: 59.240    Top5: 85.570    Loss: 1.893

2024-02-17 12:30:03,841 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:30:03,841 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:30:03,896 - 

2024-02-17 12:30:03,896 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:30:11,917 - Epoch: [133][  100/  500]    Overall Loss 0.314647    Objective Loss 0.314647                                        LR 0.000250    Time 0.080149    
2024-02-17 12:30:19,457 - Epoch: [133][  200/  500]    Overall Loss 0.318626    Objective Loss 0.318626                                        LR 0.000250    Time 0.077757    
2024-02-17 12:30:26,880 - Epoch: [133][  300/  500]    Overall Loss 0.325949    Objective Loss 0.325949                                        LR 0.000250    Time 0.076568    
2024-02-17 12:30:34,191 - Epoch: [133][  400/  500]    Overall Loss 0.330286    Objective Loss 0.330286                                        LR 0.000250    Time 0.075692    
2024-02-17 12:30:41,497 - Epoch: [133][  500/  500]    Overall Loss 0.332519    Objective Loss 0.332519    Top1 92.500000    Top5 100.000000    LR 0.000250    Time 0.075158    
2024-02-17 12:30:41,609 - --- validate (epoch=133)-----------
2024-02-17 12:30:41,610 - 10000 samples (100 per mini-batch)
2024-02-17 12:30:44,547 - Epoch: [133][  100/  100]    Loss 1.894338    Top1 59.280000    Top5 85.410000    
2024-02-17 12:30:44,725 - ==> Top1: 59.280    Top5: 85.410    Loss: 1.894

2024-02-17 12:30:44,737 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:30:44,737 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:30:44,800 - 

2024-02-17 12:30:44,800 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:30:52,749 - Epoch: [134][  100/  500]    Overall Loss 0.323956    Objective Loss 0.323956                                        LR 0.000250    Time 0.079431    
2024-02-17 12:31:00,146 - Epoch: [134][  200/  500]    Overall Loss 0.318200    Objective Loss 0.318200                                        LR 0.000250    Time 0.076682    
2024-02-17 12:31:07,434 - Epoch: [134][  300/  500]    Overall Loss 0.323282    Objective Loss 0.323282                                        LR 0.000250    Time 0.075403    
2024-02-17 12:31:14,850 - Epoch: [134][  400/  500]    Overall Loss 0.326481    Objective Loss 0.326481                                        LR 0.000250    Time 0.075082    
2024-02-17 12:31:22,404 - Epoch: [134][  500/  500]    Overall Loss 0.330671    Objective Loss 0.330671    Top1 89.500000    Top5 99.000000    LR 0.000250    Time 0.075165    
2024-02-17 12:31:22,522 - --- validate (epoch=134)-----------
2024-02-17 12:31:22,523 - 10000 samples (100 per mini-batch)
2024-02-17 12:31:25,696 - Epoch: [134][  100/  100]    Loss 1.921497    Top1 59.110000    Top5 85.390000    
2024-02-17 12:31:25,856 - ==> Top1: 59.110    Top5: 85.390    Loss: 1.921

2024-02-17 12:31:25,867 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:31:25,867 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:31:25,930 - 

2024-02-17 12:31:25,930 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:31:33,927 - Epoch: [135][  100/  500]    Overall Loss 0.319096    Objective Loss 0.319096                                        LR 0.000250    Time 0.079902    
2024-02-17 12:31:41,292 - Epoch: [135][  200/  500]    Overall Loss 0.320444    Objective Loss 0.320444                                        LR 0.000250    Time 0.076757    
2024-02-17 12:31:48,520 - Epoch: [135][  300/  500]    Overall Loss 0.323427    Objective Loss 0.323427                                        LR 0.000250    Time 0.075253    
2024-02-17 12:31:55,801 - Epoch: [135][  400/  500]    Overall Loss 0.329200    Objective Loss 0.329200                                        LR 0.000250    Time 0.074631    
2024-02-17 12:32:03,217 - Epoch: [135][  500/  500]    Overall Loss 0.330982    Objective Loss 0.330982    Top1 90.000000    Top5 99.500000    LR 0.000250    Time 0.074530    
2024-02-17 12:32:03,391 - --- validate (epoch=135)-----------
2024-02-17 12:32:03,392 - 10000 samples (100 per mini-batch)
2024-02-17 12:32:06,367 - Epoch: [135][  100/  100]    Loss 1.874001    Top1 59.550000    Top5 85.790000    
2024-02-17 12:32:06,483 - ==> Top1: 59.550    Top5: 85.790    Loss: 1.874

2024-02-17 12:32:06,495 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:32:06,495 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:32:06,562 - 

2024-02-17 12:32:06,563 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:32:14,585 - Epoch: [136][  100/  500]    Overall Loss 0.312774    Objective Loss 0.312774                                        LR 0.000250    Time 0.080169    
2024-02-17 12:32:21,959 - Epoch: [136][  200/  500]    Overall Loss 0.318205    Objective Loss 0.318205                                        LR 0.000250    Time 0.076935    
2024-02-17 12:32:29,351 - Epoch: [136][  300/  500]    Overall Loss 0.322399    Objective Loss 0.322399                                        LR 0.000250    Time 0.075916    
2024-02-17 12:32:36,607 - Epoch: [136][  400/  500]    Overall Loss 0.329251    Objective Loss 0.329251                                        LR 0.000250    Time 0.075068    
2024-02-17 12:32:43,992 - Epoch: [136][  500/  500]    Overall Loss 0.331625    Objective Loss 0.331625    Top1 91.000000    Top5 99.500000    LR 0.000250    Time 0.074816    
2024-02-17 12:32:44,151 - --- validate (epoch=136)-----------
2024-02-17 12:32:44,152 - 10000 samples (100 per mini-batch)
2024-02-17 12:32:47,079 - Epoch: [136][  100/  100]    Loss 1.928612    Top1 58.880000    Top5 85.260000    
2024-02-17 12:32:47,261 - ==> Top1: 58.880    Top5: 85.260    Loss: 1.929

2024-02-17 12:32:47,274 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:32:47,275 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:32:47,337 - 

2024-02-17 12:32:47,338 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:32:55,276 - Epoch: [137][  100/  500]    Overall Loss 0.320526    Objective Loss 0.320526                                        LR 0.000250    Time 0.079299    
2024-02-17 12:33:02,725 - Epoch: [137][  200/  500]    Overall Loss 0.319600    Objective Loss 0.319600                                        LR 0.000250    Time 0.076876    
2024-02-17 12:33:10,175 - Epoch: [137][  300/  500]    Overall Loss 0.321798    Objective Loss 0.321798                                        LR 0.000250    Time 0.076070    
2024-02-17 12:33:17,514 - Epoch: [137][  400/  500]    Overall Loss 0.324250    Objective Loss 0.324250                                        LR 0.000250    Time 0.075389    
2024-02-17 12:33:24,926 - Epoch: [137][  500/  500]    Overall Loss 0.326408    Objective Loss 0.326408    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.075126    
2024-02-17 12:33:25,088 - --- validate (epoch=137)-----------
2024-02-17 12:33:25,088 - 10000 samples (100 per mini-batch)
2024-02-17 12:33:28,033 - Epoch: [137][  100/  100]    Loss 1.924970    Top1 59.600000    Top5 85.320000    
2024-02-17 12:33:28,173 - ==> Top1: 59.600    Top5: 85.320    Loss: 1.925

2024-02-17 12:33:28,184 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:33:28,184 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:33:28,252 - 

2024-02-17 12:33:28,253 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:33:36,373 - Epoch: [138][  100/  500]    Overall Loss 0.312813    Objective Loss 0.312813                                        LR 0.000250    Time 0.081148    
2024-02-17 12:33:43,733 - Epoch: [138][  200/  500]    Overall Loss 0.319293    Objective Loss 0.319293                                        LR 0.000250    Time 0.077353    
2024-02-17 12:33:51,158 - Epoch: [138][  300/  500]    Overall Loss 0.317928    Objective Loss 0.317928                                        LR 0.000250    Time 0.076304    
2024-02-17 12:33:58,498 - Epoch: [138][  400/  500]    Overall Loss 0.321298    Objective Loss 0.321298                                        LR 0.000250    Time 0.075568    
2024-02-17 12:34:05,839 - Epoch: [138][  500/  500]    Overall Loss 0.325568    Objective Loss 0.325568    Top1 89.500000    Top5 99.500000    LR 0.000250    Time 0.075128    
2024-02-17 12:34:05,961 - --- validate (epoch=138)-----------
2024-02-17 12:34:05,961 - 10000 samples (100 per mini-batch)
2024-02-17 12:34:08,920 - Epoch: [138][  100/  100]    Loss 1.897192    Top1 59.600000    Top5 85.370000    
2024-02-17 12:34:09,103 - ==> Top1: 59.600    Top5: 85.370    Loss: 1.897

2024-02-17 12:34:09,119 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:34:09,119 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:34:09,177 - 

2024-02-17 12:34:09,177 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:34:17,054 - Epoch: [139][  100/  500]    Overall Loss 0.313691    Objective Loss 0.313691                                        LR 0.000250    Time 0.078696    
2024-02-17 12:34:24,490 - Epoch: [139][  200/  500]    Overall Loss 0.316112    Objective Loss 0.316112                                        LR 0.000250    Time 0.076507    
2024-02-17 12:34:31,849 - Epoch: [139][  300/  500]    Overall Loss 0.321306    Objective Loss 0.321306                                        LR 0.000250    Time 0.075524    
2024-02-17 12:34:39,144 - Epoch: [139][  400/  500]    Overall Loss 0.322199    Objective Loss 0.322199                                        LR 0.000250    Time 0.074870    
2024-02-17 12:34:46,492 - Epoch: [139][  500/  500]    Overall Loss 0.323036    Objective Loss 0.323036    Top1 88.500000    Top5 99.000000    LR 0.000250    Time 0.074584    
2024-02-17 12:34:46,614 - --- validate (epoch=139)-----------
2024-02-17 12:34:46,614 - 10000 samples (100 per mini-batch)
2024-02-17 12:34:49,538 - Epoch: [139][  100/  100]    Loss 1.915504    Top1 59.400000    Top5 85.500000    
2024-02-17 12:34:49,729 - ==> Top1: 59.400    Top5: 85.500    Loss: 1.916

2024-02-17 12:34:49,742 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:34:49,742 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:34:49,804 - 

2024-02-17 12:34:49,804 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:34:58,138 - Epoch: [140][  100/  500]    Overall Loss 0.308380    Objective Loss 0.308380                                        LR 0.000250    Time 0.083278    
2024-02-17 12:35:05,448 - Epoch: [140][  200/  500]    Overall Loss 0.316878    Objective Loss 0.316878                                        LR 0.000250    Time 0.078166    
2024-02-17 12:35:12,913 - Epoch: [140][  300/  500]    Overall Loss 0.317922    Objective Loss 0.317922                                        LR 0.000250    Time 0.076981    
2024-02-17 12:35:20,362 - Epoch: [140][  400/  500]    Overall Loss 0.319950    Objective Loss 0.319950                                        LR 0.000250    Time 0.076347    
2024-02-17 12:35:27,771 - Epoch: [140][  500/  500]    Overall Loss 0.322267    Objective Loss 0.322267    Top1 92.000000    Top5 99.500000    LR 0.000250    Time 0.075886    
2024-02-17 12:35:27,942 - --- validate (epoch=140)-----------
2024-02-17 12:35:27,942 - 10000 samples (100 per mini-batch)
2024-02-17 12:35:31,064 - Epoch: [140][  100/  100]    Loss 1.888656    Top1 59.530000    Top5 85.440000    
2024-02-17 12:35:31,173 - ==> Top1: 59.530    Top5: 85.440    Loss: 1.889

2024-02-17 12:35:31,185 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:35:31,186 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:35:31,248 - 

2024-02-17 12:35:31,248 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:35:39,070 - Epoch: [141][  100/  500]    Overall Loss 0.303841    Objective Loss 0.303841                                        LR 0.000250    Time 0.078161    
2024-02-17 12:35:46,346 - Epoch: [141][  200/  500]    Overall Loss 0.305617    Objective Loss 0.305617                                        LR 0.000250    Time 0.075440    
2024-02-17 12:35:53,890 - Epoch: [141][  300/  500]    Overall Loss 0.307391    Objective Loss 0.307391                                        LR 0.000250    Time 0.075428    
2024-02-17 12:36:01,670 - Epoch: [141][  400/  500]    Overall Loss 0.311601    Objective Loss 0.311601                                        LR 0.000250    Time 0.076009    
2024-02-17 12:36:09,006 - Epoch: [141][  500/  500]    Overall Loss 0.314979    Objective Loss 0.314979    Top1 92.000000    Top5 99.500000    LR 0.000250    Time 0.075472    
2024-02-17 12:36:09,136 - --- validate (epoch=141)-----------
2024-02-17 12:36:09,137 - 10000 samples (100 per mini-batch)
2024-02-17 12:36:12,122 - Epoch: [141][  100/  100]    Loss 1.918699    Top1 59.460000    Top5 85.740000    
2024-02-17 12:36:12,250 - ==> Top1: 59.460    Top5: 85.740    Loss: 1.919

2024-02-17 12:36:12,261 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:36:12,261 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:36:12,334 - 

2024-02-17 12:36:12,334 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:36:20,498 - Epoch: [142][  100/  500]    Overall Loss 0.301498    Objective Loss 0.301498                                        LR 0.000250    Time 0.081585    
2024-02-17 12:36:27,829 - Epoch: [142][  200/  500]    Overall Loss 0.307584    Objective Loss 0.307584                                        LR 0.000250    Time 0.077424    
2024-02-17 12:36:35,171 - Epoch: [142][  300/  500]    Overall Loss 0.312257    Objective Loss 0.312257                                        LR 0.000250    Time 0.076073    
2024-02-17 12:36:42,462 - Epoch: [142][  400/  500]    Overall Loss 0.315166    Objective Loss 0.315166                                        LR 0.000250    Time 0.075273    
2024-02-17 12:36:49,877 - Epoch: [142][  500/  500]    Overall Loss 0.318074    Objective Loss 0.318074    Top1 90.000000    Top5 100.000000    LR 0.000250    Time 0.075039    
2024-02-17 12:36:49,999 - --- validate (epoch=142)-----------
2024-02-17 12:36:49,999 - 10000 samples (100 per mini-batch)
2024-02-17 12:36:53,070 - Epoch: [142][  100/  100]    Loss 1.891356    Top1 59.630000    Top5 85.490000    
2024-02-17 12:36:53,180 - ==> Top1: 59.630    Top5: 85.490    Loss: 1.891

2024-02-17 12:36:53,191 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:36:53,191 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:36:53,258 - 

2024-02-17 12:36:53,258 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:37:01,074 - Epoch: [143][  100/  500]    Overall Loss 0.305017    Objective Loss 0.305017                                        LR 0.000250    Time 0.078106    
2024-02-17 12:37:08,553 - Epoch: [143][  200/  500]    Overall Loss 0.305078    Objective Loss 0.305078                                        LR 0.000250    Time 0.076423    
2024-02-17 12:37:15,985 - Epoch: [143][  300/  500]    Overall Loss 0.305630    Objective Loss 0.305630                                        LR 0.000250    Time 0.075710    
2024-02-17 12:37:23,242 - Epoch: [143][  400/  500]    Overall Loss 0.308593    Objective Loss 0.308593                                        LR 0.000250    Time 0.074914    
2024-02-17 12:37:30,658 - Epoch: [143][  500/  500]    Overall Loss 0.310301    Objective Loss 0.310301    Top1 92.000000    Top5 99.500000    LR 0.000250    Time 0.074754    
2024-02-17 12:37:30,781 - --- validate (epoch=143)-----------
2024-02-17 12:37:30,782 - 10000 samples (100 per mini-batch)
2024-02-17 12:37:33,799 - Epoch: [143][  100/  100]    Loss 1.907204    Top1 60.080000    Top5 85.530000    
2024-02-17 12:37:33,910 - ==> Top1: 60.080    Top5: 85.530    Loss: 1.907

2024-02-17 12:37:33,922 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:37:33,923 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:37:33,986 - 

2024-02-17 12:37:33,986 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:37:41,891 - Epoch: [144][  100/  500]    Overall Loss 0.296074    Objective Loss 0.296074                                        LR 0.000250    Time 0.078992    
2024-02-17 12:37:49,244 - Epoch: [144][  200/  500]    Overall Loss 0.292306    Objective Loss 0.292306                                        LR 0.000250    Time 0.076238    
2024-02-17 12:37:56,674 - Epoch: [144][  300/  500]    Overall Loss 0.299635    Objective Loss 0.299635                                        LR 0.000250    Time 0.075581    
2024-02-17 12:38:04,086 - Epoch: [144][  400/  500]    Overall Loss 0.302514    Objective Loss 0.302514                                        LR 0.000250    Time 0.075205    
2024-02-17 12:38:11,458 - Epoch: [144][  500/  500]    Overall Loss 0.306938    Objective Loss 0.306938    Top1 91.000000    Top5 100.000000    LR 0.000250    Time 0.074900    
2024-02-17 12:38:11,598 - --- validate (epoch=144)-----------
2024-02-17 12:38:11,599 - 10000 samples (100 per mini-batch)
2024-02-17 12:38:14,643 - Epoch: [144][  100/  100]    Loss 1.907192    Top1 59.280000    Top5 85.520000    
2024-02-17 12:38:14,824 - ==> Top1: 59.280    Top5: 85.520    Loss: 1.907

2024-02-17 12:38:14,836 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:38:14,836 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:38:14,900 - 

2024-02-17 12:38:14,900 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:38:23,285 - Epoch: [145][  100/  500]    Overall Loss 0.282330    Objective Loss 0.282330                                        LR 0.000250    Time 0.083790    
2024-02-17 12:38:30,741 - Epoch: [145][  200/  500]    Overall Loss 0.292444    Objective Loss 0.292444                                        LR 0.000250    Time 0.079152    
2024-02-17 12:38:38,081 - Epoch: [145][  300/  500]    Overall Loss 0.299170    Objective Loss 0.299170                                        LR 0.000250    Time 0.077222    
2024-02-17 12:38:45,473 - Epoch: [145][  400/  500]    Overall Loss 0.304370    Objective Loss 0.304370                                        LR 0.000250    Time 0.076387    
2024-02-17 12:38:52,888 - Epoch: [145][  500/  500]    Overall Loss 0.308219    Objective Loss 0.308219    Top1 92.500000    Top5 98.500000    LR 0.000250    Time 0.075931    
2024-02-17 12:38:53,090 - --- validate (epoch=145)-----------
2024-02-17 12:38:53,090 - 10000 samples (100 per mini-batch)
2024-02-17 12:38:56,168 - Epoch: [145][  100/  100]    Loss 1.923322    Top1 59.140000    Top5 85.370000    
2024-02-17 12:38:56,344 - ==> Top1: 59.140    Top5: 85.370    Loss: 1.923

2024-02-17 12:38:56,356 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:38:56,356 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:38:56,416 - 

2024-02-17 12:38:56,416 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:39:04,513 - Epoch: [146][  100/  500]    Overall Loss 0.295699    Objective Loss 0.295699                                        LR 0.000250    Time 0.080916    
2024-02-17 12:39:11,743 - Epoch: [146][  200/  500]    Overall Loss 0.296993    Objective Loss 0.296993                                        LR 0.000250    Time 0.076586    
2024-02-17 12:39:19,034 - Epoch: [146][  300/  500]    Overall Loss 0.299033    Objective Loss 0.299033                                        LR 0.000250    Time 0.075347    
2024-02-17 12:39:26,390 - Epoch: [146][  400/  500]    Overall Loss 0.301379    Objective Loss 0.301379                                        LR 0.000250    Time 0.074891    
2024-02-17 12:39:33,844 - Epoch: [146][  500/  500]    Overall Loss 0.305143    Objective Loss 0.305143    Top1 88.500000    Top5 99.500000    LR 0.000250    Time 0.074811    
2024-02-17 12:39:34,023 - --- validate (epoch=146)-----------
2024-02-17 12:39:34,024 - 10000 samples (100 per mini-batch)
2024-02-17 12:39:37,247 - Epoch: [146][  100/  100]    Loss 1.971627    Top1 58.810000    Top5 85.000000    
2024-02-17 12:39:37,403 - ==> Top1: 58.810    Top5: 85.000    Loss: 1.972

2024-02-17 12:39:37,415 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:39:37,415 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:39:37,490 - 

2024-02-17 12:39:37,491 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:39:45,327 - Epoch: [147][  100/  500]    Overall Loss 0.309138    Objective Loss 0.309138                                        LR 0.000250    Time 0.078297    
2024-02-17 12:39:52,646 - Epoch: [147][  200/  500]    Overall Loss 0.306801    Objective Loss 0.306801                                        LR 0.000250    Time 0.075725    
2024-02-17 12:40:00,312 - Epoch: [147][  300/  500]    Overall Loss 0.305706    Objective Loss 0.305706                                        LR 0.000250    Time 0.076025    
2024-02-17 12:40:07,816 - Epoch: [147][  400/  500]    Overall Loss 0.307134    Objective Loss 0.307134                                        LR 0.000250    Time 0.075769    
2024-02-17 12:40:15,168 - Epoch: [147][  500/  500]    Overall Loss 0.307280    Objective Loss 0.307280    Top1 94.000000    Top5 99.500000    LR 0.000250    Time 0.075310    
2024-02-17 12:40:15,295 - --- validate (epoch=147)-----------
2024-02-17 12:40:15,296 - 10000 samples (100 per mini-batch)
2024-02-17 12:40:18,266 - Epoch: [147][  100/  100]    Loss 1.915154    Top1 59.680000    Top5 85.160000    
2024-02-17 12:40:18,379 - ==> Top1: 59.680    Top5: 85.160    Loss: 1.915

2024-02-17 12:40:18,387 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-17 12:40:18,387 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:40:18,442 - 

2024-02-17 12:40:18,442 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:40:26,656 - Epoch: [148][  100/  500]    Overall Loss 0.302657    Objective Loss 0.302657                                        LR 0.000250    Time 0.082078    
2024-02-17 12:40:34,128 - Epoch: [148][  200/  500]    Overall Loss 0.302141    Objective Loss 0.302141                                        LR 0.000250    Time 0.078377    
2024-02-17 12:40:41,525 - Epoch: [148][  300/  500]    Overall Loss 0.303867    Objective Loss 0.303867                                        LR 0.000250    Time 0.076894    
2024-02-17 12:40:48,830 - Epoch: [148][  400/  500]    Overall Loss 0.304256    Objective Loss 0.304256                                        LR 0.000250    Time 0.075922    
2024-02-17 12:40:56,237 - Epoch: [148][  500/  500]    Overall Loss 0.306868    Objective Loss 0.306868    Top1 88.000000    Top5 100.000000    LR 0.000250    Time 0.075545    
2024-02-17 12:40:56,369 - --- validate (epoch=148)-----------
2024-02-17 12:40:56,370 - 10000 samples (100 per mini-batch)
2024-02-17 12:40:59,351 - Epoch: [148][  100/  100]    Loss 1.888129    Top1 60.240000    Top5 85.950000    
2024-02-17 12:40:59,473 - ==> Top1: 60.240    Top5: 85.950    Loss: 1.888

2024-02-17 12:40:59,484 - ==> Best [Top1: 60.240   Top5: 85.950   Sparsity:0.00   Params: 753952 on epoch: 148]
2024-02-17 12:40:59,485 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:40:59,570 - 

2024-02-17 12:40:59,571 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:41:07,456 - Epoch: [149][  100/  500]    Overall Loss 0.288324    Objective Loss 0.288324                                        LR 0.000250    Time 0.078768    
2024-02-17 12:41:15,040 - Epoch: [149][  200/  500]    Overall Loss 0.292148    Objective Loss 0.292148                                        LR 0.000250    Time 0.077283    
2024-02-17 12:41:22,443 - Epoch: [149][  300/  500]    Overall Loss 0.299755    Objective Loss 0.299755                                        LR 0.000250    Time 0.076185    
2024-02-17 12:41:29,892 - Epoch: [149][  400/  500]    Overall Loss 0.303344    Objective Loss 0.303344                                        LR 0.000250    Time 0.075750    
2024-02-17 12:41:37,329 - Epoch: [149][  500/  500]    Overall Loss 0.304277    Objective Loss 0.304277    Top1 90.000000    Top5 99.000000    LR 0.000250    Time 0.075465    
2024-02-17 12:41:37,487 - --- validate (epoch=149)-----------
2024-02-17 12:41:37,487 - 10000 samples (100 per mini-batch)
2024-02-17 12:41:40,545 - Epoch: [149][  100/  100]    Loss 1.935919    Top1 59.500000    Top5 85.440000    
2024-02-17 12:41:40,681 - ==> Top1: 59.500    Top5: 85.440    Loss: 1.936

2024-02-17 12:41:40,694 - ==> Best [Top1: 60.240   Top5: 85.950   Sparsity:0.00   Params: 753952 on epoch: 148]
2024-02-17 12:41:40,695 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:41:40,762 - 

2024-02-17 12:41:40,762 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:41:48,881 - Epoch: [150][  100/  500]    Overall Loss 0.273165    Objective Loss 0.273165                                        LR 0.000125    Time 0.081135    
2024-02-17 12:41:56,317 - Epoch: [150][  200/  500]    Overall Loss 0.268597    Objective Loss 0.268597                                        LR 0.000125    Time 0.077727    
2024-02-17 12:42:03,664 - Epoch: [150][  300/  500]    Overall Loss 0.272199    Objective Loss 0.272199                                        LR 0.000125    Time 0.076293    
2024-02-17 12:42:11,089 - Epoch: [150][  400/  500]    Overall Loss 0.273386    Objective Loss 0.273386                                        LR 0.000125    Time 0.075771    
2024-02-17 12:42:18,455 - Epoch: [150][  500/  500]    Overall Loss 0.273813    Objective Loss 0.273813    Top1 90.500000    Top5 99.500000    LR 0.000125    Time 0.075342    
2024-02-17 12:42:18,572 - --- validate (epoch=150)-----------
2024-02-17 12:42:18,573 - 10000 samples (100 per mini-batch)
2024-02-17 12:42:21,661 - Epoch: [150][  100/  100]    Loss 1.883507    Top1 60.170000    Top5 85.790000    
2024-02-17 12:42:21,778 - ==> Top1: 60.170    Top5: 85.790    Loss: 1.884

2024-02-17 12:42:21,785 - ==> Best [Top1: 60.240   Top5: 85.950   Sparsity:0.00   Params: 753952 on epoch: 148]
2024-02-17 12:42:21,785 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:42:21,868 - 

2024-02-17 12:42:21,868 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:42:30,018 - Epoch: [151][  100/  500]    Overall Loss 0.265116    Objective Loss 0.265116                                        LR 0.000125    Time 0.081428    
2024-02-17 12:42:37,445 - Epoch: [151][  200/  500]    Overall Loss 0.262215    Objective Loss 0.262215                                        LR 0.000125    Time 0.077828    
2024-02-17 12:42:44,779 - Epoch: [151][  300/  500]    Overall Loss 0.262135    Objective Loss 0.262135                                        LR 0.000125    Time 0.076318    
2024-02-17 12:42:52,185 - Epoch: [151][  400/  500]    Overall Loss 0.263139    Objective Loss 0.263139                                        LR 0.000125    Time 0.075744    
2024-02-17 12:42:59,661 - Epoch: [151][  500/  500]    Overall Loss 0.265369    Objective Loss 0.265369    Top1 94.500000    Top5 100.000000    LR 0.000125    Time 0.075537    
2024-02-17 12:42:59,783 - --- validate (epoch=151)-----------
2024-02-17 12:42:59,784 - 10000 samples (100 per mini-batch)
2024-02-17 12:43:02,910 - Epoch: [151][  100/  100]    Loss 1.877078    Top1 60.580000    Top5 85.860000    
2024-02-17 12:43:03,031 - ==> Top1: 60.580    Top5: 85.860    Loss: 1.877

2024-02-17 12:43:03,040 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:43:03,040 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:43:03,117 - 

2024-02-17 12:43:03,117 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:43:11,140 - Epoch: [152][  100/  500]    Overall Loss 0.258555    Objective Loss 0.258555                                        LR 0.000125    Time 0.080168    
2024-02-17 12:43:18,455 - Epoch: [152][  200/  500]    Overall Loss 0.261813    Objective Loss 0.261813                                        LR 0.000125    Time 0.076639    
2024-02-17 12:43:25,827 - Epoch: [152][  300/  500]    Overall Loss 0.261460    Objective Loss 0.261460                                        LR 0.000125    Time 0.075653    
2024-02-17 12:43:33,315 - Epoch: [152][  400/  500]    Overall Loss 0.264246    Objective Loss 0.264246                                        LR 0.000125    Time 0.075448    
2024-02-17 12:43:40,704 - Epoch: [152][  500/  500]    Overall Loss 0.264172    Objective Loss 0.264172    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.075129    
2024-02-17 12:43:40,839 - --- validate (epoch=152)-----------
2024-02-17 12:43:40,840 - 10000 samples (100 per mini-batch)
2024-02-17 12:43:44,434 - Epoch: [152][  100/  100]    Loss 1.897309    Top1 60.000000    Top5 86.000000    
2024-02-17 12:43:44,551 - ==> Top1: 60.000    Top5: 86.000    Loss: 1.897

2024-02-17 12:43:44,559 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:43:44,559 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:43:44,639 - 

2024-02-17 12:43:44,640 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:43:52,762 - Epoch: [153][  100/  500]    Overall Loss 0.254941    Objective Loss 0.254941                                        LR 0.000125    Time 0.081157    
2024-02-17 12:44:00,202 - Epoch: [153][  200/  500]    Overall Loss 0.253205    Objective Loss 0.253205                                        LR 0.000125    Time 0.077758    
2024-02-17 12:44:07,522 - Epoch: [153][  300/  500]    Overall Loss 0.257455    Objective Loss 0.257455                                        LR 0.000125    Time 0.076224    
2024-02-17 12:44:15,010 - Epoch: [153][  400/  500]    Overall Loss 0.258693    Objective Loss 0.258693                                        LR 0.000125    Time 0.075878    
2024-02-17 12:44:22,497 - Epoch: [153][  500/  500]    Overall Loss 0.261254    Objective Loss 0.261254    Top1 95.500000    Top5 100.000000    LR 0.000125    Time 0.075668    
2024-02-17 12:44:22,629 - --- validate (epoch=153)-----------
2024-02-17 12:44:22,630 - 10000 samples (100 per mini-batch)
2024-02-17 12:44:25,790 - Epoch: [153][  100/  100]    Loss 1.893290    Top1 60.220000    Top5 85.750000    
2024-02-17 12:44:25,970 - ==> Top1: 60.220    Top5: 85.750    Loss: 1.893

2024-02-17 12:44:25,981 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:44:25,981 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:44:26,049 - 

2024-02-17 12:44:26,049 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:44:34,344 - Epoch: [154][  100/  500]    Overall Loss 0.248995    Objective Loss 0.248995                                        LR 0.000125    Time 0.082887    
2024-02-17 12:44:41,698 - Epoch: [154][  200/  500]    Overall Loss 0.251812    Objective Loss 0.251812                                        LR 0.000125    Time 0.078197    
2024-02-17 12:44:49,004 - Epoch: [154][  300/  500]    Overall Loss 0.256797    Objective Loss 0.256797                                        LR 0.000125    Time 0.076473    
2024-02-17 12:44:56,207 - Epoch: [154][  400/  500]    Overall Loss 0.259046    Objective Loss 0.259046                                        LR 0.000125    Time 0.075351    
2024-02-17 12:45:03,709 - Epoch: [154][  500/  500]    Overall Loss 0.261252    Objective Loss 0.261252    Top1 89.500000    Top5 100.000000    LR 0.000125    Time 0.075277    
2024-02-17 12:45:03,840 - --- validate (epoch=154)-----------
2024-02-17 12:45:03,840 - 10000 samples (100 per mini-batch)
2024-02-17 12:45:07,180 - Epoch: [154][  100/  100]    Loss 1.909400    Top1 59.950000    Top5 85.850000    
2024-02-17 12:45:07,304 - ==> Top1: 59.950    Top5: 85.850    Loss: 1.909

2024-02-17 12:45:07,317 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:45:07,317 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:45:07,385 - 

2024-02-17 12:45:07,385 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:45:15,318 - Epoch: [155][  100/  500]    Overall Loss 0.246360    Objective Loss 0.246360                                        LR 0.000125    Time 0.079275    
2024-02-17 12:45:22,755 - Epoch: [155][  200/  500]    Overall Loss 0.251740    Objective Loss 0.251740                                        LR 0.000125    Time 0.076803    
2024-02-17 12:45:30,119 - Epoch: [155][  300/  500]    Overall Loss 0.255473    Objective Loss 0.255473                                        LR 0.000125    Time 0.075735    
2024-02-17 12:45:37,452 - Epoch: [155][  400/  500]    Overall Loss 0.254105    Objective Loss 0.254105                                        LR 0.000125    Time 0.075124    
2024-02-17 12:45:44,871 - Epoch: [155][  500/  500]    Overall Loss 0.255617    Objective Loss 0.255617    Top1 95.500000    Top5 100.000000    LR 0.000125    Time 0.074929    
2024-02-17 12:45:45,006 - --- validate (epoch=155)-----------
2024-02-17 12:45:45,007 - 10000 samples (100 per mini-batch)
2024-02-17 12:45:48,307 - Epoch: [155][  100/  100]    Loss 1.907299    Top1 59.790000    Top5 85.910000    
2024-02-17 12:45:48,464 - ==> Top1: 59.790    Top5: 85.910    Loss: 1.907

2024-02-17 12:45:48,477 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:45:48,477 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:45:48,543 - 

2024-02-17 12:45:48,543 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:45:56,720 - Epoch: [156][  100/  500]    Overall Loss 0.252096    Objective Loss 0.252096                                        LR 0.000125    Time 0.081685    
2024-02-17 12:46:04,198 - Epoch: [156][  200/  500]    Overall Loss 0.250345    Objective Loss 0.250345                                        LR 0.000125    Time 0.078211    
2024-02-17 12:46:11,636 - Epoch: [156][  300/  500]    Overall Loss 0.254333    Objective Loss 0.254333                                        LR 0.000125    Time 0.076921    
2024-02-17 12:46:18,964 - Epoch: [156][  400/  500]    Overall Loss 0.256664    Objective Loss 0.256664                                        LR 0.000125    Time 0.076002    
2024-02-17 12:46:26,375 - Epoch: [156][  500/  500]    Overall Loss 0.256761    Objective Loss 0.256761    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.075614    
2024-02-17 12:46:26,552 - --- validate (epoch=156)-----------
2024-02-17 12:46:26,552 - 10000 samples (100 per mini-batch)
2024-02-17 12:46:29,663 - Epoch: [156][  100/  100]    Loss 1.902428    Top1 60.500000    Top5 85.740000    
2024-02-17 12:46:29,805 - ==> Top1: 60.500    Top5: 85.740    Loss: 1.902

2024-02-17 12:46:29,817 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:46:29,817 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:46:29,890 - 

2024-02-17 12:46:29,890 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:46:38,161 - Epoch: [157][  100/  500]    Overall Loss 0.245394    Objective Loss 0.245394                                        LR 0.000125    Time 0.082652    
2024-02-17 12:46:45,591 - Epoch: [157][  200/  500]    Overall Loss 0.251643    Objective Loss 0.251643                                        LR 0.000125    Time 0.078453    
2024-02-17 12:46:52,873 - Epoch: [157][  300/  500]    Overall Loss 0.251384    Objective Loss 0.251384                                        LR 0.000125    Time 0.076565    
2024-02-17 12:47:00,084 - Epoch: [157][  400/  500]    Overall Loss 0.255264    Objective Loss 0.255264                                        LR 0.000125    Time 0.075440    
2024-02-17 12:47:07,507 - Epoch: [157][  500/  500]    Overall Loss 0.256547    Objective Loss 0.256547    Top1 95.500000    Top5 99.500000    LR 0.000125    Time 0.075191    
2024-02-17 12:47:07,693 - --- validate (epoch=157)-----------
2024-02-17 12:47:07,694 - 10000 samples (100 per mini-batch)
2024-02-17 12:47:10,706 - Epoch: [157][  100/  100]    Loss 1.920516    Top1 59.920000    Top5 85.730000    
2024-02-17 12:47:10,825 - ==> Top1: 59.920    Top5: 85.730    Loss: 1.921

2024-02-17 12:47:10,836 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:47:10,836 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:47:10,899 - 

2024-02-17 12:47:10,899 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:47:18,813 - Epoch: [158][  100/  500]    Overall Loss 0.243929    Objective Loss 0.243929                                        LR 0.000125    Time 0.079082    
2024-02-17 12:47:26,228 - Epoch: [158][  200/  500]    Overall Loss 0.251566    Objective Loss 0.251566                                        LR 0.000125    Time 0.076598    
2024-02-17 12:47:33,646 - Epoch: [158][  300/  500]    Overall Loss 0.253808    Objective Loss 0.253808                                        LR 0.000125    Time 0.075777    
2024-02-17 12:47:41,066 - Epoch: [158][  400/  500]    Overall Loss 0.257415    Objective Loss 0.257415                                        LR 0.000125    Time 0.075373    
2024-02-17 12:47:48,493 - Epoch: [158][  500/  500]    Overall Loss 0.258460    Objective Loss 0.258460    Top1 89.500000    Top5 100.000000    LR 0.000125    Time 0.075144    
2024-02-17 12:47:48,601 - --- validate (epoch=158)-----------
2024-02-17 12:47:48,602 - 10000 samples (100 per mini-batch)
2024-02-17 12:47:51,809 - Epoch: [158][  100/  100]    Loss 1.905086    Top1 60.190000    Top5 85.770000    
2024-02-17 12:47:51,927 - ==> Top1: 60.190    Top5: 85.770    Loss: 1.905

2024-02-17 12:47:51,943 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:47:51,944 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:47:52,015 - 

2024-02-17 12:47:52,015 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:47:59,997 - Epoch: [159][  100/  500]    Overall Loss 0.240422    Objective Loss 0.240422                                        LR 0.000125    Time 0.079758    
2024-02-17 12:48:07,415 - Epoch: [159][  200/  500]    Overall Loss 0.247656    Objective Loss 0.247656                                        LR 0.000125    Time 0.076949    
2024-02-17 12:48:14,800 - Epoch: [159][  300/  500]    Overall Loss 0.253079    Objective Loss 0.253079                                        LR 0.000125    Time 0.075903    
2024-02-17 12:48:22,123 - Epoch: [159][  400/  500]    Overall Loss 0.255299    Objective Loss 0.255299                                        LR 0.000125    Time 0.075225    
2024-02-17 12:48:29,526 - Epoch: [159][  500/  500]    Overall Loss 0.253614    Objective Loss 0.253614    Top1 92.500000    Top5 99.500000    LR 0.000125    Time 0.074978    
2024-02-17 12:48:29,679 - --- validate (epoch=159)-----------
2024-02-17 12:48:29,680 - 10000 samples (100 per mini-batch)
2024-02-17 12:48:32,750 - Epoch: [159][  100/  100]    Loss 1.922087    Top1 59.890000    Top5 85.770000    
2024-02-17 12:48:32,891 - ==> Top1: 59.890    Top5: 85.770    Loss: 1.922

2024-02-17 12:48:32,899 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:48:32,900 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:48:32,964 - 

2024-02-17 12:48:32,964 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:48:40,807 - Epoch: [160][  100/  500]    Overall Loss 0.250435    Objective Loss 0.250435                                        LR 0.000125    Time 0.078366    
2024-02-17 12:48:48,235 - Epoch: [160][  200/  500]    Overall Loss 0.255699    Objective Loss 0.255699                                        LR 0.000125    Time 0.076304    
2024-02-17 12:48:55,522 - Epoch: [160][  300/  500]    Overall Loss 0.255090    Objective Loss 0.255090                                        LR 0.000125    Time 0.075147    
2024-02-17 12:49:02,887 - Epoch: [160][  400/  500]    Overall Loss 0.253042    Objective Loss 0.253042                                        LR 0.000125    Time 0.074762    
2024-02-17 12:49:10,499 - Epoch: [160][  500/  500]    Overall Loss 0.252557    Objective Loss 0.252557    Top1 94.500000    Top5 100.000000    LR 0.000125    Time 0.075025    
2024-02-17 12:49:10,636 - --- validate (epoch=160)-----------
2024-02-17 12:49:10,637 - 10000 samples (100 per mini-batch)
2024-02-17 12:49:13,876 - Epoch: [160][  100/  100]    Loss 1.924850    Top1 60.170000    Top5 85.660000    
2024-02-17 12:49:14,034 - ==> Top1: 60.170    Top5: 85.660    Loss: 1.925

2024-02-17 12:49:14,044 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:49:14,044 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:49:14,118 - 

2024-02-17 12:49:14,118 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:49:22,190 - Epoch: [161][  100/  500]    Overall Loss 0.242642    Objective Loss 0.242642                                        LR 0.000125    Time 0.080649    
2024-02-17 12:49:29,531 - Epoch: [161][  200/  500]    Overall Loss 0.249146    Objective Loss 0.249146                                        LR 0.000125    Time 0.077008    
2024-02-17 12:49:36,851 - Epoch: [161][  300/  500]    Overall Loss 0.249139    Objective Loss 0.249139                                        LR 0.000125    Time 0.075727    
2024-02-17 12:49:44,207 - Epoch: [161][  400/  500]    Overall Loss 0.250134    Objective Loss 0.250134                                        LR 0.000125    Time 0.075175    
2024-02-17 12:49:51,787 - Epoch: [161][  500/  500]    Overall Loss 0.251034    Objective Loss 0.251034    Top1 93.500000    Top5 100.000000    LR 0.000125    Time 0.075291    
2024-02-17 12:49:51,913 - --- validate (epoch=161)-----------
2024-02-17 12:49:51,914 - 10000 samples (100 per mini-batch)
2024-02-17 12:49:55,062 - Epoch: [161][  100/  100]    Loss 1.905843    Top1 60.080000    Top5 85.760000    
2024-02-17 12:49:55,160 - ==> Top1: 60.080    Top5: 85.760    Loss: 1.906

2024-02-17 12:49:55,173 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:49:55,173 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:49:55,240 - 

2024-02-17 12:49:55,240 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:50:03,269 - Epoch: [162][  100/  500]    Overall Loss 0.234019    Objective Loss 0.234019                                        LR 0.000125    Time 0.080231    
2024-02-17 12:50:10,775 - Epoch: [162][  200/  500]    Overall Loss 0.244368    Objective Loss 0.244368                                        LR 0.000125    Time 0.077628    
2024-02-17 12:50:17,797 - Epoch: [162][  300/  500]    Overall Loss 0.245240    Objective Loss 0.245240                                        LR 0.000125    Time 0.075150    
2024-02-17 12:50:24,995 - Epoch: [162][  400/  500]    Overall Loss 0.245359    Objective Loss 0.245359                                        LR 0.000125    Time 0.074347    
2024-02-17 12:50:32,411 - Epoch: [162][  500/  500]    Overall Loss 0.247341    Objective Loss 0.247341    Top1 91.000000    Top5 99.500000    LR 0.000125    Time 0.074302    
2024-02-17 12:50:32,514 - --- validate (epoch=162)-----------
2024-02-17 12:50:32,515 - 10000 samples (100 per mini-batch)
2024-02-17 12:50:35,749 - Epoch: [162][  100/  100]    Loss 1.919250    Top1 60.410000    Top5 85.600000    
2024-02-17 12:50:35,907 - ==> Top1: 60.410    Top5: 85.600    Loss: 1.919

2024-02-17 12:50:35,919 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:50:35,919 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:50:35,984 - 

2024-02-17 12:50:35,984 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:50:43,911 - Epoch: [163][  100/  500]    Overall Loss 0.238383    Objective Loss 0.238383                                        LR 0.000125    Time 0.079209    
2024-02-17 12:50:51,239 - Epoch: [163][  200/  500]    Overall Loss 0.246432    Objective Loss 0.246432                                        LR 0.000125    Time 0.076228    
2024-02-17 12:50:58,609 - Epoch: [163][  300/  500]    Overall Loss 0.249270    Objective Loss 0.249270                                        LR 0.000125    Time 0.075369    
2024-02-17 12:51:06,007 - Epoch: [163][  400/  500]    Overall Loss 0.248447    Objective Loss 0.248447                                        LR 0.000125    Time 0.075013    
2024-02-17 12:51:13,504 - Epoch: [163][  500/  500]    Overall Loss 0.248890    Objective Loss 0.248890    Top1 93.500000    Top5 99.500000    LR 0.000125    Time 0.074995    
2024-02-17 12:51:13,623 - --- validate (epoch=163)-----------
2024-02-17 12:51:13,623 - 10000 samples (100 per mini-batch)
2024-02-17 12:51:16,817 - Epoch: [163][  100/  100]    Loss 1.931699    Top1 59.970000    Top5 85.960000    
2024-02-17 12:51:16,941 - ==> Top1: 59.970    Top5: 85.960    Loss: 1.932

2024-02-17 12:51:16,947 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:51:16,947 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:51:17,006 - 

2024-02-17 12:51:17,007 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:51:25,098 - Epoch: [164][  100/  500]    Overall Loss 0.241553    Objective Loss 0.241553                                        LR 0.000125    Time 0.080861    
2024-02-17 12:51:32,597 - Epoch: [164][  200/  500]    Overall Loss 0.247464    Objective Loss 0.247464                                        LR 0.000125    Time 0.077909    
2024-02-17 12:51:39,666 - Epoch: [164][  300/  500]    Overall Loss 0.247544    Objective Loss 0.247544                                        LR 0.000125    Time 0.075489    
2024-02-17 12:51:46,903 - Epoch: [164][  400/  500]    Overall Loss 0.249057    Objective Loss 0.249057                                        LR 0.000125    Time 0.074702    
2024-02-17 12:51:54,406 - Epoch: [164][  500/  500]    Overall Loss 0.249866    Objective Loss 0.249866    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.074757    
2024-02-17 12:51:54,526 - --- validate (epoch=164)-----------
2024-02-17 12:51:54,527 - 10000 samples (100 per mini-batch)
2024-02-17 12:51:57,764 - Epoch: [164][  100/  100]    Loss 1.929833    Top1 59.980000    Top5 85.800000    
2024-02-17 12:51:57,885 - ==> Top1: 59.980    Top5: 85.800    Loss: 1.930

2024-02-17 12:51:57,897 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:51:57,898 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:51:57,974 - 

2024-02-17 12:51:57,975 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:52:05,848 - Epoch: [165][  100/  500]    Overall Loss 0.238838    Objective Loss 0.238838                                        LR 0.000125    Time 0.078670    
2024-02-17 12:52:13,235 - Epoch: [165][  200/  500]    Overall Loss 0.240462    Objective Loss 0.240462                                        LR 0.000125    Time 0.076251    
2024-02-17 12:52:20,567 - Epoch: [165][  300/  500]    Overall Loss 0.243240    Objective Loss 0.243240                                        LR 0.000125    Time 0.075259    
2024-02-17 12:52:27,966 - Epoch: [165][  400/  500]    Overall Loss 0.244188    Objective Loss 0.244188                                        LR 0.000125    Time 0.074929    
2024-02-17 12:52:35,458 - Epoch: [165][  500/  500]    Overall Loss 0.244595    Objective Loss 0.244595    Top1 92.500000    Top5 100.000000    LR 0.000125    Time 0.074920    
2024-02-17 12:52:35,645 - --- validate (epoch=165)-----------
2024-02-17 12:52:35,645 - 10000 samples (100 per mini-batch)
2024-02-17 12:52:38,812 - Epoch: [165][  100/  100]    Loss 1.920215    Top1 60.150000    Top5 85.790000    
2024-02-17 12:52:38,940 - ==> Top1: 60.150    Top5: 85.790    Loss: 1.920

2024-02-17 12:52:38,948 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:52:38,948 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:52:39,009 - 

2024-02-17 12:52:39,010 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:52:47,395 - Epoch: [166][  100/  500]    Overall Loss 0.245896    Objective Loss 0.245896                                        LR 0.000125    Time 0.083785    
2024-02-17 12:52:54,691 - Epoch: [166][  200/  500]    Overall Loss 0.247981    Objective Loss 0.247981                                        LR 0.000125    Time 0.078355    
2024-02-17 12:53:01,727 - Epoch: [166][  300/  500]    Overall Loss 0.246354    Objective Loss 0.246354                                        LR 0.000125    Time 0.075680    
2024-02-17 12:53:09,045 - Epoch: [166][  400/  500]    Overall Loss 0.246137    Objective Loss 0.246137                                        LR 0.000125    Time 0.075046    
2024-02-17 12:53:16,476 - Epoch: [166][  500/  500]    Overall Loss 0.246829    Objective Loss 0.246829    Top1 91.000000    Top5 100.000000    LR 0.000125    Time 0.074889    
2024-02-17 12:53:16,606 - --- validate (epoch=166)-----------
2024-02-17 12:53:16,607 - 10000 samples (100 per mini-batch)
2024-02-17 12:53:19,766 - Epoch: [166][  100/  100]    Loss 1.935571    Top1 59.970000    Top5 85.610000    
2024-02-17 12:53:19,917 - ==> Top1: 59.970    Top5: 85.610    Loss: 1.936

2024-02-17 12:53:19,925 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:53:19,925 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:53:19,984 - 

2024-02-17 12:53:19,984 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:53:27,838 - Epoch: [167][  100/  500]    Overall Loss 0.236638    Objective Loss 0.236638                                        LR 0.000125    Time 0.078478    
2024-02-17 12:53:35,336 - Epoch: [167][  200/  500]    Overall Loss 0.237886    Objective Loss 0.237886                                        LR 0.000125    Time 0.076712    
2024-02-17 12:53:42,629 - Epoch: [167][  300/  500]    Overall Loss 0.240551    Objective Loss 0.240551                                        LR 0.000125    Time 0.075438    
2024-02-17 12:53:50,069 - Epoch: [167][  400/  500]    Overall Loss 0.241208    Objective Loss 0.241208                                        LR 0.000125    Time 0.075168    
2024-02-17 12:53:57,460 - Epoch: [167][  500/  500]    Overall Loss 0.244225    Objective Loss 0.244225    Top1 88.500000    Top5 100.000000    LR 0.000125    Time 0.074907    
2024-02-17 12:53:57,591 - --- validate (epoch=167)-----------
2024-02-17 12:53:57,591 - 10000 samples (100 per mini-batch)
2024-02-17 12:54:00,747 - Epoch: [167][  100/  100]    Loss 1.930874    Top1 60.170000    Top5 85.860000    
2024-02-17 12:54:00,871 - ==> Top1: 60.170    Top5: 85.860    Loss: 1.931

2024-02-17 12:54:00,878 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:54:00,878 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:54:00,939 - 

2024-02-17 12:54:00,939 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:54:09,162 - Epoch: [168][  100/  500]    Overall Loss 0.232428    Objective Loss 0.232428                                        LR 0.000125    Time 0.082169    
2024-02-17 12:54:16,370 - Epoch: [168][  200/  500]    Overall Loss 0.237562    Objective Loss 0.237562                                        LR 0.000125    Time 0.077105    
2024-02-17 12:54:23,589 - Epoch: [168][  300/  500]    Overall Loss 0.240998    Objective Loss 0.240998                                        LR 0.000125    Time 0.075453    
2024-02-17 12:54:31,029 - Epoch: [168][  400/  500]    Overall Loss 0.243139    Objective Loss 0.243139                                        LR 0.000125    Time 0.075181    
2024-02-17 12:54:38,401 - Epoch: [168][  500/  500]    Overall Loss 0.242613    Objective Loss 0.242613    Top1 94.000000    Top5 99.500000    LR 0.000125    Time 0.074880    
2024-02-17 12:54:38,530 - --- validate (epoch=168)-----------
2024-02-17 12:54:38,531 - 10000 samples (100 per mini-batch)
2024-02-17 12:54:41,758 - Epoch: [168][  100/  100]    Loss 1.940044    Top1 60.110000    Top5 85.750000    
2024-02-17 12:54:41,866 - ==> Top1: 60.110    Top5: 85.750    Loss: 1.940

2024-02-17 12:54:41,872 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:54:41,873 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:54:41,933 - 

2024-02-17 12:54:41,933 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:54:49,784 - Epoch: [169][  100/  500]    Overall Loss 0.233130    Objective Loss 0.233130                                        LR 0.000125    Time 0.078456    
2024-02-17 12:54:57,195 - Epoch: [169][  200/  500]    Overall Loss 0.239286    Objective Loss 0.239286                                        LR 0.000125    Time 0.076261    
2024-02-17 12:55:04,708 - Epoch: [169][  300/  500]    Overall Loss 0.239623    Objective Loss 0.239623                                        LR 0.000125    Time 0.075872    
2024-02-17 12:55:12,132 - Epoch: [169][  400/  500]    Overall Loss 0.240834    Objective Loss 0.240834                                        LR 0.000125    Time 0.075452    
2024-02-17 12:55:19,442 - Epoch: [169][  500/  500]    Overall Loss 0.241750    Objective Loss 0.241750    Top1 90.500000    Top5 100.000000    LR 0.000125    Time 0.074976    
2024-02-17 12:55:19,586 - --- validate (epoch=169)-----------
2024-02-17 12:55:19,587 - 10000 samples (100 per mini-batch)
2024-02-17 12:55:22,991 - Epoch: [169][  100/  100]    Loss 1.938254    Top1 60.110000    Top5 85.580000    
2024-02-17 12:55:23,133 - ==> Top1: 60.110    Top5: 85.580    Loss: 1.938

2024-02-17 12:55:23,139 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:55:23,139 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:55:23,196 - 

2024-02-17 12:55:23,196 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:55:31,341 - Epoch: [170][  100/  500]    Overall Loss 0.229916    Objective Loss 0.229916                                        LR 0.000125    Time 0.081382    
2024-02-17 12:55:38,647 - Epoch: [170][  200/  500]    Overall Loss 0.236218    Objective Loss 0.236218                                        LR 0.000125    Time 0.077205    
2024-02-17 12:55:46,002 - Epoch: [170][  300/  500]    Overall Loss 0.237610    Objective Loss 0.237610                                        LR 0.000125    Time 0.075972    
2024-02-17 12:55:53,486 - Epoch: [170][  400/  500]    Overall Loss 0.239643    Objective Loss 0.239643                                        LR 0.000125    Time 0.075678    
2024-02-17 12:56:00,809 - Epoch: [170][  500/  500]    Overall Loss 0.242543    Objective Loss 0.242543    Top1 94.000000    Top5 100.000000    LR 0.000125    Time 0.075181    
2024-02-17 12:56:00,949 - --- validate (epoch=170)-----------
2024-02-17 12:56:00,950 - 10000 samples (100 per mini-batch)
2024-02-17 12:56:04,114 - Epoch: [170][  100/  100]    Loss 1.934659    Top1 60.060000    Top5 85.940000    
2024-02-17 12:56:04,220 - ==> Top1: 60.060    Top5: 85.940    Loss: 1.935

2024-02-17 12:56:04,228 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:56:04,228 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:56:04,295 - 

2024-02-17 12:56:04,295 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:56:12,371 - Epoch: [171][  100/  500]    Overall Loss 0.222846    Objective Loss 0.222846                                        LR 0.000125    Time 0.080700    
2024-02-17 12:56:20,039 - Epoch: [171][  200/  500]    Overall Loss 0.231142    Objective Loss 0.231142                                        LR 0.000125    Time 0.078669    
2024-02-17 12:56:27,542 - Epoch: [171][  300/  500]    Overall Loss 0.233896    Objective Loss 0.233896                                        LR 0.000125    Time 0.077445    
2024-02-17 12:56:35,036 - Epoch: [171][  400/  500]    Overall Loss 0.235802    Objective Loss 0.235802                                        LR 0.000125    Time 0.076808    
2024-02-17 12:56:42,698 - Epoch: [171][  500/  500]    Overall Loss 0.236756    Objective Loss 0.236756    Top1 92.000000    Top5 99.500000    LR 0.000125    Time 0.076762    
2024-02-17 12:56:42,857 - --- validate (epoch=171)-----------
2024-02-17 12:56:42,857 - 10000 samples (100 per mini-batch)
2024-02-17 12:56:45,992 - Epoch: [171][  100/  100]    Loss 1.950507    Top1 59.930000    Top5 85.490000    
2024-02-17 12:56:46,124 - ==> Top1: 59.930    Top5: 85.490    Loss: 1.951

2024-02-17 12:56:46,132 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:56:46,132 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:56:46,198 - 

2024-02-17 12:56:46,199 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:56:54,564 - Epoch: [172][  100/  500]    Overall Loss 0.233213    Objective Loss 0.233213                                        LR 0.000125    Time 0.083589    
2024-02-17 12:57:01,924 - Epoch: [172][  200/  500]    Overall Loss 0.233640    Objective Loss 0.233640                                        LR 0.000125    Time 0.078575    
2024-02-17 12:57:09,394 - Epoch: [172][  300/  500]    Overall Loss 0.234297    Objective Loss 0.234297                                        LR 0.000125    Time 0.077270    
2024-02-17 12:57:16,905 - Epoch: [172][  400/  500]    Overall Loss 0.237797    Objective Loss 0.237797                                        LR 0.000125    Time 0.076719    
2024-02-17 12:57:24,323 - Epoch: [172][  500/  500]    Overall Loss 0.237228    Objective Loss 0.237228    Top1 94.500000    Top5 100.000000    LR 0.000125    Time 0.076204    
2024-02-17 12:57:24,453 - --- validate (epoch=172)-----------
2024-02-17 12:57:24,454 - 10000 samples (100 per mini-batch)
2024-02-17 12:57:27,699 - Epoch: [172][  100/  100]    Loss 1.936042    Top1 59.900000    Top5 85.730000    
2024-02-17 12:57:27,834 - ==> Top1: 59.900    Top5: 85.730    Loss: 1.936

2024-02-17 12:57:27,843 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:57:27,843 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:57:27,903 - 

2024-02-17 12:57:27,903 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:57:35,871 - Epoch: [173][  100/  500]    Overall Loss 0.222833    Objective Loss 0.222833                                        LR 0.000125    Time 0.079621    
2024-02-17 12:57:43,219 - Epoch: [173][  200/  500]    Overall Loss 0.226368    Objective Loss 0.226368                                        LR 0.000125    Time 0.076529    
2024-02-17 12:57:50,645 - Epoch: [173][  300/  500]    Overall Loss 0.233803    Objective Loss 0.233803                                        LR 0.000125    Time 0.075760    
2024-02-17 12:57:57,995 - Epoch: [173][  400/  500]    Overall Loss 0.236299    Objective Loss 0.236299                                        LR 0.000125    Time 0.075183    
2024-02-17 12:58:05,632 - Epoch: [173][  500/  500]    Overall Loss 0.237052    Objective Loss 0.237052    Top1 94.000000    Top5 100.000000    LR 0.000125    Time 0.075413    
2024-02-17 12:58:05,756 - --- validate (epoch=173)-----------
2024-02-17 12:58:05,757 - 10000 samples (100 per mini-batch)
2024-02-17 12:58:09,066 - Epoch: [173][  100/  100]    Loss 1.957766    Top1 59.780000    Top5 85.580000    
2024-02-17 12:58:09,174 - ==> Top1: 59.780    Top5: 85.580    Loss: 1.958

2024-02-17 12:58:09,185 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:58:09,186 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:58:09,253 - 

2024-02-17 12:58:09,254 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:58:17,081 - Epoch: [174][  100/  500]    Overall Loss 0.225888    Objective Loss 0.225888                                        LR 0.000125    Time 0.078218    
2024-02-17 12:58:24,480 - Epoch: [174][  200/  500]    Overall Loss 0.232191    Objective Loss 0.232191                                        LR 0.000125    Time 0.076082    
2024-02-17 12:58:31,865 - Epoch: [174][  300/  500]    Overall Loss 0.234775    Objective Loss 0.234775                                        LR 0.000125    Time 0.075325    
2024-02-17 12:58:39,147 - Epoch: [174][  400/  500]    Overall Loss 0.236206    Objective Loss 0.236206                                        LR 0.000125    Time 0.074689    
2024-02-17 12:58:46,585 - Epoch: [174][  500/  500]    Overall Loss 0.237734    Objective Loss 0.237734    Top1 92.500000    Top5 99.500000    LR 0.000125    Time 0.074619    
2024-02-17 12:58:46,720 - --- validate (epoch=174)-----------
2024-02-17 12:58:46,721 - 10000 samples (100 per mini-batch)
2024-02-17 12:58:50,296 - Epoch: [174][  100/  100]    Loss 1.943706    Top1 59.710000    Top5 85.770000    
2024-02-17 12:58:50,439 - ==> Top1: 59.710    Top5: 85.770    Loss: 1.944

2024-02-17 12:58:50,454 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:58:50,454 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:58:50,520 - 

2024-02-17 12:58:50,521 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:58:58,417 - Epoch: [175][  100/  500]    Overall Loss 0.225993    Objective Loss 0.225993                                        LR 0.000125    Time 0.078901    
2024-02-17 12:59:05,732 - Epoch: [175][  200/  500]    Overall Loss 0.233519    Objective Loss 0.233519                                        LR 0.000125    Time 0.076005    
2024-02-17 12:59:13,208 - Epoch: [175][  300/  500]    Overall Loss 0.234766    Objective Loss 0.234766                                        LR 0.000125    Time 0.075578    
2024-02-17 12:59:20,599 - Epoch: [175][  400/  500]    Overall Loss 0.235085    Objective Loss 0.235085                                        LR 0.000125    Time 0.075149    
2024-02-17 12:59:28,014 - Epoch: [175][  500/  500]    Overall Loss 0.236514    Objective Loss 0.236514    Top1 94.000000    Top5 100.000000    LR 0.000125    Time 0.074943    
2024-02-17 12:59:28,173 - --- validate (epoch=175)-----------
2024-02-17 12:59:28,174 - 10000 samples (100 per mini-batch)
2024-02-17 12:59:31,397 - Epoch: [175][  100/  100]    Loss 1.950114    Top1 59.730000    Top5 85.760000    
2024-02-17 12:59:31,526 - ==> Top1: 59.730    Top5: 85.760    Loss: 1.950

2024-02-17 12:59:31,533 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 12:59:31,533 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 12:59:31,621 - 

2024-02-17 12:59:31,622 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 12:59:39,791 - Epoch: [176][  100/  500]    Overall Loss 0.237072    Objective Loss 0.237072                                        LR 0.000125    Time 0.081614    
2024-02-17 12:59:47,324 - Epoch: [176][  200/  500]    Overall Loss 0.234331    Objective Loss 0.234331                                        LR 0.000125    Time 0.078456    
2024-02-17 12:59:54,558 - Epoch: [176][  300/  500]    Overall Loss 0.234554    Objective Loss 0.234554                                        LR 0.000125    Time 0.076404    
2024-02-17 13:00:01,835 - Epoch: [176][  400/  500]    Overall Loss 0.234573    Objective Loss 0.234573                                        LR 0.000125    Time 0.075485    
2024-02-17 13:00:09,189 - Epoch: [176][  500/  500]    Overall Loss 0.234733    Objective Loss 0.234733    Top1 96.500000    Top5 100.000000    LR 0.000125    Time 0.075090    
2024-02-17 13:00:09,373 - --- validate (epoch=176)-----------
2024-02-17 13:00:09,375 - 10000 samples (100 per mini-batch)
2024-02-17 13:00:12,467 - Epoch: [176][  100/  100]    Loss 1.951452    Top1 59.990000    Top5 85.820000    
2024-02-17 13:00:12,655 - ==> Top1: 59.990    Top5: 85.820    Loss: 1.951

2024-02-17 13:00:12,664 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:00:12,664 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:00:12,731 - 

2024-02-17 13:00:12,731 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:00:20,608 - Epoch: [177][  100/  500]    Overall Loss 0.229778    Objective Loss 0.229778                                        LR 0.000125    Time 0.078708    
2024-02-17 13:00:27,980 - Epoch: [177][  200/  500]    Overall Loss 0.233496    Objective Loss 0.233496                                        LR 0.000125    Time 0.076195    
2024-02-17 13:00:35,458 - Epoch: [177][  300/  500]    Overall Loss 0.234882    Objective Loss 0.234882                                        LR 0.000125    Time 0.075709    
2024-02-17 13:00:43,023 - Epoch: [177][  400/  500]    Overall Loss 0.234475    Objective Loss 0.234475                                        LR 0.000125    Time 0.075685    
2024-02-17 13:00:50,441 - Epoch: [177][  500/  500]    Overall Loss 0.233947    Objective Loss 0.233947    Top1 97.000000    Top5 100.000000    LR 0.000125    Time 0.075377    
2024-02-17 13:00:50,629 - --- validate (epoch=177)-----------
2024-02-17 13:00:50,629 - 10000 samples (100 per mini-batch)
2024-02-17 13:00:53,864 - Epoch: [177][  100/  100]    Loss 1.948968    Top1 59.860000    Top5 85.470000    
2024-02-17 13:00:54,005 - ==> Top1: 59.860    Top5: 85.470    Loss: 1.949

2024-02-17 13:00:54,018 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:00:54,019 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:00:54,083 - 

2024-02-17 13:00:54,084 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:01:02,926 - Epoch: [178][  100/  500]    Overall Loss 0.229757    Objective Loss 0.229757                                        LR 0.000125    Time 0.088364    
2024-02-17 13:01:10,328 - Epoch: [178][  200/  500]    Overall Loss 0.227889    Objective Loss 0.227889                                        LR 0.000125    Time 0.081170    
2024-02-17 13:01:17,612 - Epoch: [178][  300/  500]    Overall Loss 0.233380    Objective Loss 0.233380                                        LR 0.000125    Time 0.078379    
2024-02-17 13:01:25,051 - Epoch: [178][  400/  500]    Overall Loss 0.233113    Objective Loss 0.233113                                        LR 0.000125    Time 0.077370    
2024-02-17 13:01:32,495 - Epoch: [178][  500/  500]    Overall Loss 0.232737    Objective Loss 0.232737    Top1 91.000000    Top5 100.000000    LR 0.000125    Time 0.076777    
2024-02-17 13:01:32,645 - --- validate (epoch=178)-----------
2024-02-17 13:01:32,646 - 10000 samples (100 per mini-batch)
2024-02-17 13:01:35,760 - Epoch: [178][  100/  100]    Loss 1.957101    Top1 60.500000    Top5 85.740000    
2024-02-17 13:01:35,871 - ==> Top1: 60.500    Top5: 85.740    Loss: 1.957

2024-02-17 13:01:35,885 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:01:35,885 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:01:35,953 - 

2024-02-17 13:01:35,953 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:01:43,937 - Epoch: [179][  100/  500]    Overall Loss 0.225508    Objective Loss 0.225508                                        LR 0.000125    Time 0.079773    
2024-02-17 13:01:51,283 - Epoch: [179][  200/  500]    Overall Loss 0.226666    Objective Loss 0.226666                                        LR 0.000125    Time 0.076593    
2024-02-17 13:01:58,682 - Epoch: [179][  300/  500]    Overall Loss 0.228379    Objective Loss 0.228379                                        LR 0.000125    Time 0.075713    
2024-02-17 13:02:06,095 - Epoch: [179][  400/  500]    Overall Loss 0.229011    Objective Loss 0.229011                                        LR 0.000125    Time 0.075306    
2024-02-17 13:02:13,667 - Epoch: [179][  500/  500]    Overall Loss 0.229008    Objective Loss 0.229008    Top1 94.000000    Top5 100.000000    LR 0.000125    Time 0.075383    
2024-02-17 13:02:13,779 - --- validate (epoch=179)-----------
2024-02-17 13:02:13,780 - 10000 samples (100 per mini-batch)
2024-02-17 13:02:16,825 - Epoch: [179][  100/  100]    Loss 1.946505    Top1 60.290000    Top5 85.820000    
2024-02-17 13:02:16,923 - ==> Top1: 60.290    Top5: 85.820    Loss: 1.947

2024-02-17 13:02:16,937 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:02:16,937 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:02:17,001 - 

2024-02-17 13:02:17,002 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:02:25,198 - Epoch: [180][  100/  500]    Overall Loss 0.226473    Objective Loss 0.226473                                        LR 0.000125    Time 0.081912    
2024-02-17 13:02:32,512 - Epoch: [180][  200/  500]    Overall Loss 0.226837    Objective Loss 0.226837                                        LR 0.000125    Time 0.077505    
2024-02-17 13:02:39,766 - Epoch: [180][  300/  500]    Overall Loss 0.230913    Objective Loss 0.230913                                        LR 0.000125    Time 0.075837    
2024-02-17 13:02:47,097 - Epoch: [180][  400/  500]    Overall Loss 0.231669    Objective Loss 0.231669                                        LR 0.000125    Time 0.075195    
2024-02-17 13:02:54,096 - Epoch: [180][  500/  500]    Overall Loss 0.230858    Objective Loss 0.230858    Top1 91.000000    Top5 100.000000    LR 0.000125    Time 0.074146    
2024-02-17 13:02:54,218 - --- validate (epoch=180)-----------
2024-02-17 13:02:54,219 - 10000 samples (100 per mini-batch)
2024-02-17 13:02:57,375 - Epoch: [180][  100/  100]    Loss 1.952863    Top1 60.010000    Top5 85.820000    
2024-02-17 13:02:57,476 - ==> Top1: 60.010    Top5: 85.820    Loss: 1.953

2024-02-17 13:02:57,483 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:02:57,483 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:02:57,551 - 

2024-02-17 13:02:57,551 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:03:05,553 - Epoch: [181][  100/  500]    Overall Loss 0.221967    Objective Loss 0.221967                                        LR 0.000125    Time 0.079965    
2024-02-17 13:03:12,964 - Epoch: [181][  200/  500]    Overall Loss 0.225882    Objective Loss 0.225882                                        LR 0.000125    Time 0.077013    
2024-02-17 13:03:20,404 - Epoch: [181][  300/  500]    Overall Loss 0.229935    Objective Loss 0.229935                                        LR 0.000125    Time 0.076131    
2024-02-17 13:03:27,850 - Epoch: [181][  400/  500]    Overall Loss 0.229989    Objective Loss 0.229989                                        LR 0.000125    Time 0.075703    
2024-02-17 13:03:35,250 - Epoch: [181][  500/  500]    Overall Loss 0.229479    Objective Loss 0.229479    Top1 94.500000    Top5 100.000000    LR 0.000125    Time 0.075354    
2024-02-17 13:03:35,430 - --- validate (epoch=181)-----------
2024-02-17 13:03:35,431 - 10000 samples (100 per mini-batch)
2024-02-17 13:03:38,512 - Epoch: [181][  100/  100]    Loss 1.967669    Top1 59.920000    Top5 85.520000    
2024-02-17 13:03:38,702 - ==> Top1: 59.920    Top5: 85.520    Loss: 1.968

2024-02-17 13:03:38,716 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:03:38,716 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:03:38,780 - 

2024-02-17 13:03:38,780 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:03:46,720 - Epoch: [182][  100/  500]    Overall Loss 0.228324    Objective Loss 0.228324                                        LR 0.000125    Time 0.079348    
2024-02-17 13:03:54,104 - Epoch: [182][  200/  500]    Overall Loss 0.222645    Objective Loss 0.222645                                        LR 0.000125    Time 0.076569    
2024-02-17 13:04:01,337 - Epoch: [182][  300/  500]    Overall Loss 0.223732    Objective Loss 0.223732                                        LR 0.000125    Time 0.075143    
2024-02-17 13:04:08,697 - Epoch: [182][  400/  500]    Overall Loss 0.227632    Objective Loss 0.227632                                        LR 0.000125    Time 0.074748    
2024-02-17 13:04:16,014 - Epoch: [182][  500/  500]    Overall Loss 0.229066    Objective Loss 0.229066    Top1 92.500000    Top5 99.500000    LR 0.000125    Time 0.074425    
2024-02-17 13:04:16,134 - --- validate (epoch=182)-----------
2024-02-17 13:04:16,135 - 10000 samples (100 per mini-batch)
2024-02-17 13:04:19,589 - Epoch: [182][  100/  100]    Loss 1.974157    Top1 59.970000    Top5 85.750000    
2024-02-17 13:04:19,725 - ==> Top1: 59.970    Top5: 85.750    Loss: 1.974

2024-02-17 13:04:19,737 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:04:19,737 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:04:19,804 - 

2024-02-17 13:04:19,804 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:04:27,684 - Epoch: [183][  100/  500]    Overall Loss 0.215227    Objective Loss 0.215227                                        LR 0.000125    Time 0.078727    
2024-02-17 13:04:35,011 - Epoch: [183][  200/  500]    Overall Loss 0.222679    Objective Loss 0.222679                                        LR 0.000125    Time 0.075978    
2024-02-17 13:04:42,316 - Epoch: [183][  300/  500]    Overall Loss 0.226788    Objective Loss 0.226788                                        LR 0.000125    Time 0.074989    
2024-02-17 13:04:49,713 - Epoch: [183][  400/  500]    Overall Loss 0.227187    Objective Loss 0.227187                                        LR 0.000125    Time 0.074725    
2024-02-17 13:04:57,131 - Epoch: [183][  500/  500]    Overall Loss 0.227088    Objective Loss 0.227088    Top1 94.000000    Top5 99.000000    LR 0.000125    Time 0.074607    
2024-02-17 13:04:57,233 - --- validate (epoch=183)-----------
2024-02-17 13:04:57,234 - 10000 samples (100 per mini-batch)
2024-02-17 13:05:00,413 - Epoch: [183][  100/  100]    Loss 1.957040    Top1 59.830000    Top5 85.790000    
2024-02-17 13:05:00,527 - ==> Top1: 59.830    Top5: 85.790    Loss: 1.957

2024-02-17 13:05:00,538 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:05:00,539 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:05:00,601 - 

2024-02-17 13:05:00,601 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:05:08,627 - Epoch: [184][  100/  500]    Overall Loss 0.219644    Objective Loss 0.219644                                        LR 0.000125    Time 0.080196    
2024-02-17 13:05:16,054 - Epoch: [184][  200/  500]    Overall Loss 0.224112    Objective Loss 0.224112                                        LR 0.000125    Time 0.077210    
2024-02-17 13:05:23,438 - Epoch: [184][  300/  500]    Overall Loss 0.224402    Objective Loss 0.224402                                        LR 0.000125    Time 0.076074    
2024-02-17 13:05:30,782 - Epoch: [184][  400/  500]    Overall Loss 0.227515    Objective Loss 0.227515                                        LR 0.000125    Time 0.075406    
2024-02-17 13:05:38,058 - Epoch: [184][  500/  500]    Overall Loss 0.229596    Objective Loss 0.229596    Top1 93.500000    Top5 99.500000    LR 0.000125    Time 0.074870    
2024-02-17 13:05:38,284 - --- validate (epoch=184)-----------
2024-02-17 13:05:38,284 - 10000 samples (100 per mini-batch)
2024-02-17 13:05:41,604 - Epoch: [184][  100/  100]    Loss 1.966017    Top1 60.000000    Top5 85.630000    
2024-02-17 13:05:41,750 - ==> Top1: 60.000    Top5: 85.630    Loss: 1.966

2024-02-17 13:05:41,761 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:05:41,761 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:05:41,824 - 

2024-02-17 13:05:41,824 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:05:49,658 - Epoch: [185][  100/  500]    Overall Loss 0.227796    Objective Loss 0.227796                                        LR 0.000125    Time 0.078284    
2024-02-17 13:05:57,079 - Epoch: [185][  200/  500]    Overall Loss 0.223938    Objective Loss 0.223938                                        LR 0.000125    Time 0.076226    
2024-02-17 13:06:04,410 - Epoch: [185][  300/  500]    Overall Loss 0.226002    Objective Loss 0.226002                                        LR 0.000125    Time 0.075242    
2024-02-17 13:06:11,640 - Epoch: [185][  400/  500]    Overall Loss 0.225594    Objective Loss 0.225594                                        LR 0.000125    Time 0.074496    
2024-02-17 13:06:18,906 - Epoch: [185][  500/  500]    Overall Loss 0.225943    Objective Loss 0.225943    Top1 93.500000    Top5 100.000000    LR 0.000125    Time 0.074122    
2024-02-17 13:06:19,027 - --- validate (epoch=185)-----------
2024-02-17 13:06:19,028 - 10000 samples (100 per mini-batch)
2024-02-17 13:06:22,021 - Epoch: [185][  100/  100]    Loss 1.967303    Top1 59.800000    Top5 85.760000    
2024-02-17 13:06:22,194 - ==> Top1: 59.800    Top5: 85.760    Loss: 1.967

2024-02-17 13:06:22,204 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:06:22,204 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:06:22,294 - 

2024-02-17 13:06:22,295 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:06:30,480 - Epoch: [186][  100/  500]    Overall Loss 0.210687    Objective Loss 0.210687                                        LR 0.000125    Time 0.081802    
2024-02-17 13:06:37,772 - Epoch: [186][  200/  500]    Overall Loss 0.218706    Objective Loss 0.218706                                        LR 0.000125    Time 0.077340    
2024-02-17 13:06:45,191 - Epoch: [186][  300/  500]    Overall Loss 0.220617    Objective Loss 0.220617                                        LR 0.000125    Time 0.076276    
2024-02-17 13:06:52,351 - Epoch: [186][  400/  500]    Overall Loss 0.221219    Objective Loss 0.221219                                        LR 0.000125    Time 0.075098    
2024-02-17 13:06:59,418 - Epoch: [186][  500/  500]    Overall Loss 0.224767    Objective Loss 0.224767    Top1 93.000000    Top5 99.500000    LR 0.000125    Time 0.074206    
2024-02-17 13:06:59,593 - --- validate (epoch=186)-----------
2024-02-17 13:06:59,594 - 10000 samples (100 per mini-batch)
2024-02-17 13:07:02,787 - Epoch: [186][  100/  100]    Loss 1.972442    Top1 59.790000    Top5 85.870000    
2024-02-17 13:07:02,908 - ==> Top1: 59.790    Top5: 85.870    Loss: 1.972

2024-02-17 13:07:02,920 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:07:02,921 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:07:02,988 - 

2024-02-17 13:07:02,988 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:07:10,893 - Epoch: [187][  100/  500]    Overall Loss 0.222190    Objective Loss 0.222190                                        LR 0.000125    Time 0.078990    
2024-02-17 13:07:18,166 - Epoch: [187][  200/  500]    Overall Loss 0.221114    Objective Loss 0.221114                                        LR 0.000125    Time 0.075842    
2024-02-17 13:07:25,706 - Epoch: [187][  300/  500]    Overall Loss 0.221460    Objective Loss 0.221460                                        LR 0.000125    Time 0.075679    
2024-02-17 13:07:33,031 - Epoch: [187][  400/  500]    Overall Loss 0.224399    Objective Loss 0.224399                                        LR 0.000125    Time 0.075062    
2024-02-17 13:07:40,353 - Epoch: [187][  500/  500]    Overall Loss 0.226769    Objective Loss 0.226769    Top1 93.000000    Top5 100.000000    LR 0.000125    Time 0.074686    
2024-02-17 13:07:40,456 - --- validate (epoch=187)-----------
2024-02-17 13:07:40,456 - 10000 samples (100 per mini-batch)
2024-02-17 13:07:43,757 - Epoch: [187][  100/  100]    Loss 1.984545    Top1 59.840000    Top5 85.680000    
2024-02-17 13:07:43,926 - ==> Top1: 59.840    Top5: 85.680    Loss: 1.985

2024-02-17 13:07:43,935 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:07:43,935 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:07:44,000 - 

2024-02-17 13:07:44,000 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:07:51,712 - Epoch: [188][  100/  500]    Overall Loss 0.213649    Objective Loss 0.213649                                        LR 0.000125    Time 0.077060    
2024-02-17 13:07:58,873 - Epoch: [188][  200/  500]    Overall Loss 0.218540    Objective Loss 0.218540                                        LR 0.000125    Time 0.074318    
2024-02-17 13:08:06,231 - Epoch: [188][  300/  500]    Overall Loss 0.218849    Objective Loss 0.218849                                        LR 0.000125    Time 0.074056    
2024-02-17 13:08:13,551 - Epoch: [188][  400/  500]    Overall Loss 0.223136    Objective Loss 0.223136                                        LR 0.000125    Time 0.073831    
2024-02-17 13:08:20,913 - Epoch: [188][  500/  500]    Overall Loss 0.225520    Objective Loss 0.225520    Top1 90.000000    Top5 100.000000    LR 0.000125    Time 0.073782    
2024-02-17 13:08:21,047 - --- validate (epoch=188)-----------
2024-02-17 13:08:21,048 - 10000 samples (100 per mini-batch)
2024-02-17 13:08:24,653 - Epoch: [188][  100/  100]    Loss 1.987643    Top1 59.360000    Top5 85.380000    
2024-02-17 13:08:24,804 - ==> Top1: 59.360    Top5: 85.380    Loss: 1.988

2024-02-17 13:08:24,812 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:08:24,812 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:08:24,875 - 

2024-02-17 13:08:24,875 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:08:32,774 - Epoch: [189][  100/  500]    Overall Loss 0.225949    Objective Loss 0.225949                                        LR 0.000125    Time 0.078942    
2024-02-17 13:08:40,051 - Epoch: [189][  200/  500]    Overall Loss 0.222795    Objective Loss 0.222795                                        LR 0.000125    Time 0.075832    
2024-02-17 13:08:47,256 - Epoch: [189][  300/  500]    Overall Loss 0.224683    Objective Loss 0.224683                                        LR 0.000125    Time 0.074560    
2024-02-17 13:08:54,466 - Epoch: [189][  400/  500]    Overall Loss 0.223539    Objective Loss 0.223539                                        LR 0.000125    Time 0.073934    
2024-02-17 13:09:01,550 - Epoch: [189][  500/  500]    Overall Loss 0.226418    Objective Loss 0.226418    Top1 93.000000    Top5 98.500000    LR 0.000125    Time 0.073309    
2024-02-17 13:09:01,734 - --- validate (epoch=189)-----------
2024-02-17 13:09:01,735 - 10000 samples (100 per mini-batch)
2024-02-17 13:09:04,657 - Epoch: [189][  100/  100]    Loss 1.986064    Top1 60.010000    Top5 85.360000    
2024-02-17 13:09:04,770 - ==> Top1: 60.010    Top5: 85.360    Loss: 1.986

2024-02-17 13:09:04,782 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:09:04,782 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:09:04,842 - 

2024-02-17 13:09:04,842 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:09:12,908 - Epoch: [190][  100/  500]    Overall Loss 0.211893    Objective Loss 0.211893                                        LR 0.000125    Time 0.080604    
2024-02-17 13:09:20,170 - Epoch: [190][  200/  500]    Overall Loss 0.216724    Objective Loss 0.216724                                        LR 0.000125    Time 0.076594    
2024-02-17 13:09:27,687 - Epoch: [190][  300/  500]    Overall Loss 0.217644    Objective Loss 0.217644                                        LR 0.000125    Time 0.076105    
2024-02-17 13:09:35,059 - Epoch: [190][  400/  500]    Overall Loss 0.220819    Objective Loss 0.220819                                        LR 0.000125    Time 0.075497    
2024-02-17 13:09:42,475 - Epoch: [190][  500/  500]    Overall Loss 0.222200    Objective Loss 0.222200    Top1 94.500000    Top5 99.500000    LR 0.000125    Time 0.075221    
2024-02-17 13:09:42,596 - --- validate (epoch=190)-----------
2024-02-17 13:09:42,597 - 10000 samples (100 per mini-batch)
2024-02-17 13:09:45,557 - Epoch: [190][  100/  100]    Loss 1.970894    Top1 59.700000    Top5 85.680000    
2024-02-17 13:09:45,716 - ==> Top1: 59.700    Top5: 85.680    Loss: 1.971

2024-02-17 13:09:45,727 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:09:45,727 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:09:45,802 - 

2024-02-17 13:09:45,802 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:09:53,774 - Epoch: [191][  100/  500]    Overall Loss 0.219249    Objective Loss 0.219249                                        LR 0.000125    Time 0.079644    
2024-02-17 13:10:01,136 - Epoch: [191][  200/  500]    Overall Loss 0.219000    Objective Loss 0.219000                                        LR 0.000125    Time 0.076610    
2024-02-17 13:10:08,556 - Epoch: [191][  300/  500]    Overall Loss 0.219732    Objective Loss 0.219732                                        LR 0.000125    Time 0.075795    
2024-02-17 13:10:15,828 - Epoch: [191][  400/  500]    Overall Loss 0.221630    Objective Loss 0.221630                                        LR 0.000125    Time 0.075016    
2024-02-17 13:10:22,864 - Epoch: [191][  500/  500]    Overall Loss 0.222612    Objective Loss 0.222612    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.074077    
2024-02-17 13:10:23,025 - --- validate (epoch=191)-----------
2024-02-17 13:10:23,026 - 10000 samples (100 per mini-batch)
2024-02-17 13:10:25,987 - Epoch: [191][  100/  100]    Loss 1.991651    Top1 59.920000    Top5 85.580000    
2024-02-17 13:10:26,170 - ==> Top1: 59.920    Top5: 85.580    Loss: 1.992

2024-02-17 13:10:26,182 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:10:26,182 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:10:26,242 - 

2024-02-17 13:10:26,243 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:10:34,085 - Epoch: [192][  100/  500]    Overall Loss 0.218386    Objective Loss 0.218386                                        LR 0.000125    Time 0.078363    
2024-02-17 13:10:41,414 - Epoch: [192][  200/  500]    Overall Loss 0.217557    Objective Loss 0.217557                                        LR 0.000125    Time 0.075807    
2024-02-17 13:10:48,867 - Epoch: [192][  300/  500]    Overall Loss 0.215115    Objective Loss 0.215115                                        LR 0.000125    Time 0.075367    
2024-02-17 13:10:56,223 - Epoch: [192][  400/  500]    Overall Loss 0.217083    Objective Loss 0.217083                                        LR 0.000125    Time 0.074905    
2024-02-17 13:11:03,632 - Epoch: [192][  500/  500]    Overall Loss 0.219166    Objective Loss 0.219166    Top1 97.000000    Top5 100.000000    LR 0.000125    Time 0.074734    
2024-02-17 13:11:03,732 - --- validate (epoch=192)-----------
2024-02-17 13:11:03,733 - 10000 samples (100 per mini-batch)
2024-02-17 13:11:06,988 - Epoch: [192][  100/  100]    Loss 1.972215    Top1 59.890000    Top5 85.600000    
2024-02-17 13:11:07,125 - ==> Top1: 59.890    Top5: 85.600    Loss: 1.972

2024-02-17 13:11:07,138 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:11:07,138 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:11:07,201 - 

2024-02-17 13:11:07,201 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:11:14,956 - Epoch: [193][  100/  500]    Overall Loss 0.213690    Objective Loss 0.213690                                        LR 0.000125    Time 0.077493    
2024-02-17 13:11:22,448 - Epoch: [193][  200/  500]    Overall Loss 0.216133    Objective Loss 0.216133                                        LR 0.000125    Time 0.076186    
2024-02-17 13:11:29,935 - Epoch: [193][  300/  500]    Overall Loss 0.217282    Objective Loss 0.217282                                        LR 0.000125    Time 0.075733    
2024-02-17 13:11:37,441 - Epoch: [193][  400/  500]    Overall Loss 0.218157    Objective Loss 0.218157                                        LR 0.000125    Time 0.075554    
2024-02-17 13:11:45,039 - Epoch: [193][  500/  500]    Overall Loss 0.217944    Objective Loss 0.217944    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.075631    
2024-02-17 13:11:45,172 - --- validate (epoch=193)-----------
2024-02-17 13:11:45,174 - 10000 samples (100 per mini-batch)
2024-02-17 13:11:48,155 - Epoch: [193][  100/  100]    Loss 1.982611    Top1 59.880000    Top5 85.910000    
2024-02-17 13:11:48,328 - ==> Top1: 59.880    Top5: 85.910    Loss: 1.983

2024-02-17 13:11:48,341 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:11:48,341 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:11:48,403 - 

2024-02-17 13:11:48,404 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:11:56,250 - Epoch: [194][  100/  500]    Overall Loss 0.203038    Objective Loss 0.203038                                        LR 0.000125    Time 0.078406    
2024-02-17 13:12:03,735 - Epoch: [194][  200/  500]    Overall Loss 0.209588    Objective Loss 0.209588                                        LR 0.000125    Time 0.076610    
2024-02-17 13:12:10,829 - Epoch: [194][  300/  500]    Overall Loss 0.212824    Objective Loss 0.212824                                        LR 0.000125    Time 0.074707    
2024-02-17 13:12:18,156 - Epoch: [194][  400/  500]    Overall Loss 0.214587    Objective Loss 0.214587                                        LR 0.000125    Time 0.074339    
2024-02-17 13:12:25,505 - Epoch: [194][  500/  500]    Overall Loss 0.216752    Objective Loss 0.216752    Top1 92.000000    Top5 99.500000    LR 0.000125    Time 0.074162    
2024-02-17 13:12:25,686 - --- validate (epoch=194)-----------
2024-02-17 13:12:25,687 - 10000 samples (100 per mini-batch)
2024-02-17 13:12:28,902 - Epoch: [194][  100/  100]    Loss 2.009548    Top1 59.420000    Top5 85.450000    
2024-02-17 13:12:29,084 - ==> Top1: 59.420    Top5: 85.450    Loss: 2.010

2024-02-17 13:12:29,097 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:12:29,097 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:12:29,162 - 

2024-02-17 13:12:29,162 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:12:36,990 - Epoch: [195][  100/  500]    Overall Loss 0.218217    Objective Loss 0.218217                                        LR 0.000125    Time 0.078220    
2024-02-17 13:12:44,349 - Epoch: [195][  200/  500]    Overall Loss 0.218245    Objective Loss 0.218245                                        LR 0.000125    Time 0.075882    
2024-02-17 13:12:51,664 - Epoch: [195][  300/  500]    Overall Loss 0.219620    Objective Loss 0.219620                                        LR 0.000125    Time 0.074961    
2024-02-17 13:12:58,997 - Epoch: [195][  400/  500]    Overall Loss 0.220032    Objective Loss 0.220032                                        LR 0.000125    Time 0.074543    
2024-02-17 13:13:06,419 - Epoch: [195][  500/  500]    Overall Loss 0.220848    Objective Loss 0.220848    Top1 93.000000    Top5 100.000000    LR 0.000125    Time 0.074471    
2024-02-17 13:13:06,563 - --- validate (epoch=195)-----------
2024-02-17 13:13:06,564 - 10000 samples (100 per mini-batch)
2024-02-17 13:13:09,548 - Epoch: [195][  100/  100]    Loss 1.998598    Top1 59.870000    Top5 85.750000    
2024-02-17 13:13:09,756 - ==> Top1: 59.870    Top5: 85.750    Loss: 1.999

2024-02-17 13:13:09,766 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:13:09,767 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:13:09,829 - 

2024-02-17 13:13:09,829 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:13:17,965 - Epoch: [196][  100/  500]    Overall Loss 0.215504    Objective Loss 0.215504                                        LR 0.000125    Time 0.081308    
2024-02-17 13:13:25,391 - Epoch: [196][  200/  500]    Overall Loss 0.215083    Objective Loss 0.215083                                        LR 0.000125    Time 0.077763    
2024-02-17 13:13:32,672 - Epoch: [196][  300/  500]    Overall Loss 0.214971    Objective Loss 0.214971                                        LR 0.000125    Time 0.076099    
2024-02-17 13:13:40,056 - Epoch: [196][  400/  500]    Overall Loss 0.215812    Objective Loss 0.215812                                        LR 0.000125    Time 0.075523    
2024-02-17 13:13:47,448 - Epoch: [196][  500/  500]    Overall Loss 0.216520    Objective Loss 0.216520    Top1 95.500000    Top5 100.000000    LR 0.000125    Time 0.075194    
2024-02-17 13:13:47,591 - --- validate (epoch=196)-----------
2024-02-17 13:13:47,592 - 10000 samples (100 per mini-batch)
2024-02-17 13:13:50,599 - Epoch: [196][  100/  100]    Loss 2.017509    Top1 59.410000    Top5 85.360000    
2024-02-17 13:13:50,694 - ==> Top1: 59.410    Top5: 85.360    Loss: 2.018

2024-02-17 13:13:50,700 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:13:50,700 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:13:50,761 - 

2024-02-17 13:13:50,761 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:13:58,739 - Epoch: [197][  100/  500]    Overall Loss 0.199093    Objective Loss 0.199093                                        LR 0.000125    Time 0.079721    
2024-02-17 13:14:06,059 - Epoch: [197][  200/  500]    Overall Loss 0.210532    Objective Loss 0.210532                                        LR 0.000125    Time 0.076440    
2024-02-17 13:14:13,289 - Epoch: [197][  300/  500]    Overall Loss 0.213149    Objective Loss 0.213149                                        LR 0.000125    Time 0.075049    
2024-02-17 13:14:20,620 - Epoch: [197][  400/  500]    Overall Loss 0.213956    Objective Loss 0.213956                                        LR 0.000125    Time 0.074604    
2024-02-17 13:14:27,953 - Epoch: [197][  500/  500]    Overall Loss 0.215248    Objective Loss 0.215248    Top1 93.000000    Top5 100.000000    LR 0.000125    Time 0.074340    
2024-02-17 13:14:28,134 - --- validate (epoch=197)-----------
2024-02-17 13:14:28,135 - 10000 samples (100 per mini-batch)
2024-02-17 13:14:31,523 - Epoch: [197][  100/  100]    Loss 1.980144    Top1 60.340000    Top5 85.590000    
2024-02-17 13:14:31,649 - ==> Top1: 60.340    Top5: 85.590    Loss: 1.980

2024-02-17 13:14:31,659 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:14:31,659 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:14:31,729 - 

2024-02-17 13:14:31,729 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:14:39,917 - Epoch: [198][  100/  500]    Overall Loss 0.212729    Objective Loss 0.212729                                        LR 0.000125    Time 0.081824    
2024-02-17 13:14:47,535 - Epoch: [198][  200/  500]    Overall Loss 0.210995    Objective Loss 0.210995                                        LR 0.000125    Time 0.078984    
2024-02-17 13:14:54,820 - Epoch: [198][  300/  500]    Overall Loss 0.211916    Objective Loss 0.211916                                        LR 0.000125    Time 0.076925    
2024-02-17 13:15:01,841 - Epoch: [198][  400/  500]    Overall Loss 0.213681    Objective Loss 0.213681                                        LR 0.000125    Time 0.075237    
2024-02-17 13:15:09,414 - Epoch: [198][  500/  500]    Overall Loss 0.216552    Objective Loss 0.216552    Top1 91.500000    Top5 100.000000    LR 0.000125    Time 0.075328    
2024-02-17 13:15:09,598 - --- validate (epoch=198)-----------
2024-02-17 13:15:09,599 - 10000 samples (100 per mini-batch)
2024-02-17 13:15:12,744 - Epoch: [198][  100/  100]    Loss 2.016967    Top1 59.390000    Top5 85.560000    
2024-02-17 13:15:12,874 - ==> Top1: 59.390    Top5: 85.560    Loss: 2.017

2024-02-17 13:15:12,881 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:15:12,881 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:15:12,944 - 

2024-02-17 13:15:12,944 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:15:20,957 - Epoch: [199][  100/  500]    Overall Loss 0.208800    Objective Loss 0.208800                                        LR 0.000125    Time 0.080073    
2024-02-17 13:15:28,172 - Epoch: [199][  200/  500]    Overall Loss 0.209824    Objective Loss 0.209824                                        LR 0.000125    Time 0.076088    
2024-02-17 13:15:35,422 - Epoch: [199][  300/  500]    Overall Loss 0.211934    Objective Loss 0.211934                                        LR 0.000125    Time 0.074880    
2024-02-17 13:15:42,702 - Epoch: [199][  400/  500]    Overall Loss 0.214977    Objective Loss 0.214977                                        LR 0.000125    Time 0.074350    
2024-02-17 13:15:50,050 - Epoch: [199][  500/  500]    Overall Loss 0.216143    Objective Loss 0.216143    Top1 93.500000    Top5 100.000000    LR 0.000125    Time 0.074169    
2024-02-17 13:15:50,179 - --- validate (epoch=199)-----------
2024-02-17 13:15:50,179 - 10000 samples (100 per mini-batch)
2024-02-17 13:15:53,458 - Epoch: [199][  100/  100]    Loss 1.993669    Top1 59.600000    Top5 85.480000    
2024-02-17 13:15:53,577 - ==> Top1: 59.600    Top5: 85.480    Loss: 1.994

2024-02-17 13:15:53,586 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:15:53,586 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:15:53,647 - 

2024-02-17 13:15:53,647 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:16:01,784 - Epoch: [200][  100/  500]    Overall Loss 0.203186    Objective Loss 0.203186                                        LR 0.000063    Time 0.081303    
2024-02-17 13:16:08,939 - Epoch: [200][  200/  500]    Overall Loss 0.200658    Objective Loss 0.200658                                        LR 0.000063    Time 0.076406    
2024-02-17 13:16:16,155 - Epoch: [200][  300/  500]    Overall Loss 0.199368    Objective Loss 0.199368                                        LR 0.000063    Time 0.074979    
2024-02-17 13:16:23,494 - Epoch: [200][  400/  500]    Overall Loss 0.198770    Objective Loss 0.198770                                        LR 0.000063    Time 0.074571    
2024-02-17 13:16:30,898 - Epoch: [200][  500/  500]    Overall Loss 0.200164    Objective Loss 0.200164    Top1 94.500000    Top5 100.000000    LR 0.000063    Time 0.074457    
2024-02-17 13:16:31,034 - --- validate (epoch=200)-----------
2024-02-17 13:16:31,035 - 10000 samples (100 per mini-batch)
2024-02-17 13:16:34,091 - Epoch: [200][  100/  100]    Loss 1.965052    Top1 59.960000    Top5 85.850000    
2024-02-17 13:16:34,231 - ==> Top1: 59.960    Top5: 85.850    Loss: 1.965

2024-02-17 13:16:34,245 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:16:34,246 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:16:34,314 - 

2024-02-17 13:16:34,315 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:16:42,512 - Epoch: [201][  100/  500]    Overall Loss 0.194777    Objective Loss 0.194777                                        LR 0.000063    Time 0.081915    
2024-02-17 13:16:49,970 - Epoch: [201][  200/  500]    Overall Loss 0.195865    Objective Loss 0.195865                                        LR 0.000063    Time 0.078224    
2024-02-17 13:16:56,913 - Epoch: [201][  300/  500]    Overall Loss 0.197402    Objective Loss 0.197402                                        LR 0.000063    Time 0.075282    
2024-02-17 13:17:04,056 - Epoch: [201][  400/  500]    Overall Loss 0.197737    Objective Loss 0.197737                                        LR 0.000063    Time 0.074311    
2024-02-17 13:17:11,296 - Epoch: [201][  500/  500]    Overall Loss 0.198817    Objective Loss 0.198817    Top1 92.000000    Top5 99.500000    LR 0.000063    Time 0.073922    
2024-02-17 13:17:11,422 - --- validate (epoch=201)-----------
2024-02-17 13:17:11,423 - 10000 samples (100 per mini-batch)
2024-02-17 13:17:14,502 - Epoch: [201][  100/  100]    Loss 1.979687    Top1 60.100000    Top5 85.590000    
2024-02-17 13:17:14,648 - ==> Top1: 60.100    Top5: 85.590    Loss: 1.980

2024-02-17 13:17:14,661 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:17:14,662 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:17:14,726 - 

2024-02-17 13:17:14,727 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:17:22,816 - Epoch: [202][  100/  500]    Overall Loss 0.196987    Objective Loss 0.196987                                        LR 0.000063    Time 0.080840    
2024-02-17 13:17:30,155 - Epoch: [202][  200/  500]    Overall Loss 0.198782    Objective Loss 0.198782                                        LR 0.000063    Time 0.077097    
2024-02-17 13:17:37,485 - Epoch: [202][  300/  500]    Overall Loss 0.199579    Objective Loss 0.199579                                        LR 0.000063    Time 0.075819    
2024-02-17 13:17:44,940 - Epoch: [202][  400/  500]    Overall Loss 0.202158    Objective Loss 0.202158                                        LR 0.000063    Time 0.075492    
2024-02-17 13:17:52,413 - Epoch: [202][  500/  500]    Overall Loss 0.202946    Objective Loss 0.202946    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.075331    
2024-02-17 13:17:52,541 - --- validate (epoch=202)-----------
2024-02-17 13:17:52,542 - 10000 samples (100 per mini-batch)
2024-02-17 13:17:55,627 - Epoch: [202][  100/  100]    Loss 1.980951    Top1 60.160000    Top5 85.550000    
2024-02-17 13:17:55,732 - ==> Top1: 60.160    Top5: 85.550    Loss: 1.981

2024-02-17 13:17:55,744 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:17:55,744 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:17:55,810 - 

2024-02-17 13:17:55,810 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:18:03,669 - Epoch: [203][  100/  500]    Overall Loss 0.198696    Objective Loss 0.198696                                        LR 0.000063    Time 0.078536    
2024-02-17 13:18:10,716 - Epoch: [203][  200/  500]    Overall Loss 0.202378    Objective Loss 0.202378                                        LR 0.000063    Time 0.074490    
2024-02-17 13:18:17,836 - Epoch: [203][  300/  500]    Overall Loss 0.199438    Objective Loss 0.199438                                        LR 0.000063    Time 0.073380    
2024-02-17 13:18:24,952 - Epoch: [203][  400/  500]    Overall Loss 0.200565    Objective Loss 0.200565                                        LR 0.000063    Time 0.072818    
2024-02-17 13:18:32,415 - Epoch: [203][  500/  500]    Overall Loss 0.198712    Objective Loss 0.198712    Top1 93.500000    Top5 100.000000    LR 0.000063    Time 0.073172    
2024-02-17 13:18:32,529 - --- validate (epoch=203)-----------
2024-02-17 13:18:32,530 - 10000 samples (100 per mini-batch)
2024-02-17 13:18:35,585 - Epoch: [203][  100/  100]    Loss 1.983417    Top1 60.080000    Top5 85.490000    
2024-02-17 13:18:35,756 - ==> Top1: 60.080    Top5: 85.490    Loss: 1.983

2024-02-17 13:18:35,768 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:18:35,768 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:18:35,832 - 

2024-02-17 13:18:35,832 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:18:43,605 - Epoch: [204][  100/  500]    Overall Loss 0.194937    Objective Loss 0.194937                                        LR 0.000063    Time 0.077673    
2024-02-17 13:18:51,003 - Epoch: [204][  200/  500]    Overall Loss 0.194596    Objective Loss 0.194596                                        LR 0.000063    Time 0.075806    
2024-02-17 13:18:58,358 - Epoch: [204][  300/  500]    Overall Loss 0.192799    Objective Loss 0.192799                                        LR 0.000063    Time 0.075040    
2024-02-17 13:19:05,464 - Epoch: [204][  400/  500]    Overall Loss 0.195310    Objective Loss 0.195310                                        LR 0.000063    Time 0.074038    
2024-02-17 13:19:12,817 - Epoch: [204][  500/  500]    Overall Loss 0.196354    Objective Loss 0.196354    Top1 93.500000    Top5 99.500000    LR 0.000063    Time 0.073928    
2024-02-17 13:19:12,973 - --- validate (epoch=204)-----------
2024-02-17 13:19:12,974 - 10000 samples (100 per mini-batch)
2024-02-17 13:19:16,441 - Epoch: [204][  100/  100]    Loss 1.986956    Top1 60.240000    Top5 85.410000    
2024-02-17 13:19:16,566 - ==> Top1: 60.240    Top5: 85.410    Loss: 1.987

2024-02-17 13:19:16,573 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:19:16,573 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:19:16,636 - 

2024-02-17 13:19:16,636 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:19:24,652 - Epoch: [205][  100/  500]    Overall Loss 0.195522    Objective Loss 0.195522                                        LR 0.000063    Time 0.080104    
2024-02-17 13:19:32,038 - Epoch: [205][  200/  500]    Overall Loss 0.197703    Objective Loss 0.197703                                        LR 0.000063    Time 0.076960    
2024-02-17 13:19:39,447 - Epoch: [205][  300/  500]    Overall Loss 0.197991    Objective Loss 0.197991                                        LR 0.000063    Time 0.075991    
2024-02-17 13:19:46,475 - Epoch: [205][  400/  500]    Overall Loss 0.197787    Objective Loss 0.197787                                        LR 0.000063    Time 0.074554    
2024-02-17 13:19:53,729 - Epoch: [205][  500/  500]    Overall Loss 0.198011    Objective Loss 0.198011    Top1 96.000000    Top5 100.000000    LR 0.000063    Time 0.074145    
2024-02-17 13:19:53,869 - --- validate (epoch=205)-----------
2024-02-17 13:19:53,869 - 10000 samples (100 per mini-batch)
2024-02-17 13:19:57,165 - Epoch: [205][  100/  100]    Loss 1.993326    Top1 59.860000    Top5 85.530000    
2024-02-17 13:19:57,297 - ==> Top1: 59.860    Top5: 85.530    Loss: 1.993

2024-02-17 13:19:57,310 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:19:57,310 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:19:57,376 - 

2024-02-17 13:19:57,377 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:20:05,445 - Epoch: [206][  100/  500]    Overall Loss 0.187737    Objective Loss 0.187737                                        LR 0.000063    Time 0.080612    
2024-02-17 13:20:12,747 - Epoch: [206][  200/  500]    Overall Loss 0.190697    Objective Loss 0.190697                                        LR 0.000063    Time 0.076797    
2024-02-17 13:20:20,046 - Epoch: [206][  300/  500]    Overall Loss 0.191348    Objective Loss 0.191348                                        LR 0.000063    Time 0.075516    
2024-02-17 13:20:27,339 - Epoch: [206][  400/  500]    Overall Loss 0.193628    Objective Loss 0.193628                                        LR 0.000063    Time 0.074858    
2024-02-17 13:20:34,764 - Epoch: [206][  500/  500]    Overall Loss 0.194200    Objective Loss 0.194200    Top1 91.000000    Top5 100.000000    LR 0.000063    Time 0.074730    
2024-02-17 13:20:34,886 - --- validate (epoch=206)-----------
2024-02-17 13:20:34,886 - 10000 samples (100 per mini-batch)
2024-02-17 13:20:38,371 - Epoch: [206][  100/  100]    Loss 1.985267    Top1 59.780000    Top5 85.580000    
2024-02-17 13:20:38,525 - ==> Top1: 59.780    Top5: 85.580    Loss: 1.985

2024-02-17 13:20:38,536 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:20:38,536 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:20:38,600 - 

2024-02-17 13:20:38,600 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:20:46,615 - Epoch: [207][  100/  500]    Overall Loss 0.194213    Objective Loss 0.194213                                        LR 0.000063    Time 0.080093    
2024-02-17 13:20:53,970 - Epoch: [207][  200/  500]    Overall Loss 0.199908    Objective Loss 0.199908                                        LR 0.000063    Time 0.076802    
2024-02-17 13:21:00,950 - Epoch: [207][  300/  500]    Overall Loss 0.195590    Objective Loss 0.195590                                        LR 0.000063    Time 0.074456    
2024-02-17 13:21:08,373 - Epoch: [207][  400/  500]    Overall Loss 0.196481    Objective Loss 0.196481                                        LR 0.000063    Time 0.074389    
2024-02-17 13:21:15,660 - Epoch: [207][  500/  500]    Overall Loss 0.196540    Objective Loss 0.196540    Top1 96.500000    Top5 100.000000    LR 0.000063    Time 0.074079    
2024-02-17 13:21:15,792 - --- validate (epoch=207)-----------
2024-02-17 13:21:15,792 - 10000 samples (100 per mini-batch)
2024-02-17 13:21:19,010 - Epoch: [207][  100/  100]    Loss 1.995921    Top1 60.050000    Top5 85.430000    
2024-02-17 13:21:19,116 - ==> Top1: 60.050    Top5: 85.430    Loss: 1.996

2024-02-17 13:21:19,123 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:21:19,123 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:21:19,179 - 

2024-02-17 13:21:19,180 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:21:27,658 - Epoch: [208][  100/  500]    Overall Loss 0.186295    Objective Loss 0.186295                                        LR 0.000063    Time 0.084719    
2024-02-17 13:21:34,955 - Epoch: [208][  200/  500]    Overall Loss 0.191939    Objective Loss 0.191939                                        LR 0.000063    Time 0.078821    
2024-02-17 13:21:42,378 - Epoch: [208][  300/  500]    Overall Loss 0.191132    Objective Loss 0.191132                                        LR 0.000063    Time 0.077280    
2024-02-17 13:21:49,681 - Epoch: [208][  400/  500]    Overall Loss 0.191322    Objective Loss 0.191322                                        LR 0.000063    Time 0.076207    
2024-02-17 13:21:57,085 - Epoch: [208][  500/  500]    Overall Loss 0.191751    Objective Loss 0.191751    Top1 94.500000    Top5 99.500000    LR 0.000063    Time 0.075764    
2024-02-17 13:21:57,209 - --- validate (epoch=208)-----------
2024-02-17 13:21:57,210 - 10000 samples (100 per mini-batch)
2024-02-17 13:22:00,415 - Epoch: [208][  100/  100]    Loss 1.989587    Top1 59.850000    Top5 85.630000    
2024-02-17 13:22:00,550 - ==> Top1: 59.850    Top5: 85.630    Loss: 1.990

2024-02-17 13:22:00,561 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:22:00,562 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:22:00,631 - 

2024-02-17 13:22:00,631 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:22:08,668 - Epoch: [209][  100/  500]    Overall Loss 0.182289    Objective Loss 0.182289                                        LR 0.000063    Time 0.080311    
2024-02-17 13:22:16,052 - Epoch: [209][  200/  500]    Overall Loss 0.184634    Objective Loss 0.184634                                        LR 0.000063    Time 0.077056    
2024-02-17 13:22:23,407 - Epoch: [209][  300/  500]    Overall Loss 0.189662    Objective Loss 0.189662                                        LR 0.000063    Time 0.075875    
2024-02-17 13:22:30,720 - Epoch: [209][  400/  500]    Overall Loss 0.189371    Objective Loss 0.189371                                        LR 0.000063    Time 0.075176    
2024-02-17 13:22:37,891 - Epoch: [209][  500/  500]    Overall Loss 0.191692    Objective Loss 0.191692    Top1 97.500000    Top5 100.000000    LR 0.000063    Time 0.074476    
2024-02-17 13:22:38,011 - --- validate (epoch=209)-----------
2024-02-17 13:22:38,012 - 10000 samples (100 per mini-batch)
2024-02-17 13:22:41,060 - Epoch: [209][  100/  100]    Loss 1.987464    Top1 60.260000    Top5 85.570000    
2024-02-17 13:22:41,166 - ==> Top1: 60.260    Top5: 85.570    Loss: 1.987

2024-02-17 13:22:41,175 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-17 13:22:41,175 - Saving checkpoint to: logs/2024.02.17-110119/checkpoint.pth.tar
2024-02-17 13:22:41,237 - 

2024-02-17 13:22:41,237 - Initiating quantization aware training (QAT)...
2024-02-17 13:22:41,303 - 

2024-02-17 13:22:41,304 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:22:51,507 - Epoch: [210][  100/  500]    Overall Loss 0.825296    Objective Loss 0.825296                                        LR 0.000063    Time 0.101981    
2024-02-17 13:23:01,017 - Epoch: [210][  200/  500]    Overall Loss 0.658712    Objective Loss 0.658712                                        LR 0.000063    Time 0.098523    
2024-02-17 13:23:10,252 - Epoch: [210][  300/  500]    Overall Loss 0.594530    Objective Loss 0.594530                                        LR 0.000063    Time 0.096452    
2024-02-17 13:23:19,299 - Epoch: [210][  400/  500]    Overall Loss 0.562421    Objective Loss 0.562421                                        LR 0.000063    Time 0.094948    
2024-02-17 13:23:28,466 - Epoch: [210][  500/  500]    Overall Loss 0.539712    Objective Loss 0.539712    Top1 94.500000    Top5 100.000000    LR 0.000063    Time 0.094283    
2024-02-17 13:23:28,596 - --- validate (epoch=210)-----------
2024-02-17 13:23:28,596 - 10000 samples (100 per mini-batch)
2024-02-17 13:23:34,019 - Epoch: [210][  100/  100]    Loss 1.573703    Top1 59.060000    Top5 85.210000    
2024-02-17 13:23:34,214 - ==> Top1: 59.060    Top5: 85.210    Loss: 1.574

2024-02-17 13:23:34,224 - ==> Best [Top1: 59.060   Top5: 85.210   Sparsity:0.00   Params: 753952 on epoch: 210]
2024-02-17 13:23:34,224 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:23:34,279 - 

2024-02-17 13:23:34,280 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:23:43,892 - Epoch: [211][  100/  500]    Overall Loss 0.432885    Objective Loss 0.432885                                        LR 0.000063    Time 0.096069    
2024-02-17 13:23:53,263 - Epoch: [211][  200/  500]    Overall Loss 0.432243    Objective Loss 0.432243                                        LR 0.000063    Time 0.094870    
2024-02-17 13:24:02,381 - Epoch: [211][  300/  500]    Overall Loss 0.433941    Objective Loss 0.433941                                        LR 0.000063    Time 0.093627    
2024-02-17 13:24:11,455 - Epoch: [211][  400/  500]    Overall Loss 0.435255    Objective Loss 0.435255                                        LR 0.000063    Time 0.092895    
2024-02-17 13:24:20,322 - Epoch: [211][  500/  500]    Overall Loss 0.434620    Objective Loss 0.434620    Top1 94.000000    Top5 99.500000    LR 0.000063    Time 0.092045    
2024-02-17 13:24:20,423 - --- validate (epoch=211)-----------
2024-02-17 13:24:20,424 - 10000 samples (100 per mini-batch)
2024-02-17 13:24:25,363 - Epoch: [211][  100/  100]    Loss 1.568015    Top1 59.320000    Top5 85.150000    
2024-02-17 13:24:25,468 - ==> Top1: 59.320    Top5: 85.150    Loss: 1.568

2024-02-17 13:24:25,477 - ==> Best [Top1: 59.320   Top5: 85.150   Sparsity:0.00   Params: 753952 on epoch: 211]
2024-02-17 13:24:25,478 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:24:25,531 - 

2024-02-17 13:24:25,531 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:24:34,451 - Epoch: [212][  100/  500]    Overall Loss 0.415723    Objective Loss 0.415723                                        LR 0.000063    Time 0.089156    
2024-02-17 13:24:43,716 - Epoch: [212][  200/  500]    Overall Loss 0.413187    Objective Loss 0.413187                                        LR 0.000063    Time 0.090881    
2024-02-17 13:24:53,046 - Epoch: [212][  300/  500]    Overall Loss 0.416873    Objective Loss 0.416873                                        LR 0.000063    Time 0.091675    
2024-02-17 13:25:02,287 - Epoch: [212][  400/  500]    Overall Loss 0.420923    Objective Loss 0.420923                                        LR 0.000063    Time 0.091849    
2024-02-17 13:25:11,649 - Epoch: [212][  500/  500]    Overall Loss 0.422652    Objective Loss 0.422652    Top1 91.500000    Top5 100.000000    LR 0.000063    Time 0.092195    
2024-02-17 13:25:11,774 - --- validate (epoch=212)-----------
2024-02-17 13:25:11,775 - 10000 samples (100 per mini-batch)
2024-02-17 13:25:17,845 - Epoch: [212][  100/  100]    Loss 1.544224    Top1 59.490000    Top5 85.780000    
2024-02-17 13:25:17,977 - ==> Top1: 59.490    Top5: 85.780    Loss: 1.544

2024-02-17 13:25:17,988 - ==> Best [Top1: 59.490   Top5: 85.780   Sparsity:0.00   Params: 753952 on epoch: 212]
2024-02-17 13:25:17,989 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:25:18,055 - 

2024-02-17 13:25:18,055 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:25:27,804 - Epoch: [213][  100/  500]    Overall Loss 0.404739    Objective Loss 0.404739                                        LR 0.000063    Time 0.097432    
2024-02-17 13:25:36,738 - Epoch: [213][  200/  500]    Overall Loss 0.414486    Objective Loss 0.414486                                        LR 0.000063    Time 0.093367    
2024-02-17 13:25:45,863 - Epoch: [213][  300/  500]    Overall Loss 0.413150    Objective Loss 0.413150                                        LR 0.000063    Time 0.092651    
2024-02-17 13:25:55,167 - Epoch: [213][  400/  500]    Overall Loss 0.414269    Objective Loss 0.414269                                        LR 0.000063    Time 0.092739    
2024-02-17 13:26:04,391 - Epoch: [213][  500/  500]    Overall Loss 0.414467    Objective Loss 0.414467    Top1 93.000000    Top5 99.500000    LR 0.000063    Time 0.092631    
2024-02-17 13:26:04,521 - --- validate (epoch=213)-----------
2024-02-17 13:26:04,521 - 10000 samples (100 per mini-batch)
2024-02-17 13:26:10,395 - Epoch: [213][  100/  100]    Loss 1.578409    Top1 59.090000    Top5 85.640000    
2024-02-17 13:26:10,544 - ==> Top1: 59.090    Top5: 85.640    Loss: 1.578

2024-02-17 13:26:10,557 - ==> Best [Top1: 59.490   Top5: 85.780   Sparsity:0.00   Params: 753952 on epoch: 212]
2024-02-17 13:26:10,557 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:26:10,616 - 

2024-02-17 13:26:10,616 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:26:20,792 - Epoch: [214][  100/  500]    Overall Loss 0.397157    Objective Loss 0.397157                                        LR 0.000063    Time 0.101705    
2024-02-17 13:26:30,113 - Epoch: [214][  200/  500]    Overall Loss 0.402221    Objective Loss 0.402221                                        LR 0.000063    Time 0.097439    
2024-02-17 13:26:39,656 - Epoch: [214][  300/  500]    Overall Loss 0.404626    Objective Loss 0.404626                                        LR 0.000063    Time 0.096755    
2024-02-17 13:26:48,922 - Epoch: [214][  400/  500]    Overall Loss 0.405333    Objective Loss 0.405333                                        LR 0.000063    Time 0.095722    
2024-02-17 13:26:58,122 - Epoch: [214][  500/  500]    Overall Loss 0.407671    Objective Loss 0.407671    Top1 90.500000    Top5 100.000000    LR 0.000063    Time 0.094970    
2024-02-17 13:26:58,232 - --- validate (epoch=214)-----------
2024-02-17 13:26:58,232 - 10000 samples (100 per mini-batch)
2024-02-17 13:27:04,457 - Epoch: [214][  100/  100]    Loss 1.576521    Top1 59.350000    Top5 85.300000    
2024-02-17 13:27:04,581 - ==> Top1: 59.350    Top5: 85.300    Loss: 1.577

2024-02-17 13:27:04,591 - ==> Best [Top1: 59.490   Top5: 85.780   Sparsity:0.00   Params: 753952 on epoch: 212]
2024-02-17 13:27:04,592 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:27:04,644 - 

2024-02-17 13:27:04,645 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:27:14,384 - Epoch: [215][  100/  500]    Overall Loss 0.400386    Objective Loss 0.400386                                        LR 0.000063    Time 0.097340    
2024-02-17 13:27:23,538 - Epoch: [215][  200/  500]    Overall Loss 0.399659    Objective Loss 0.399659                                        LR 0.000063    Time 0.094421    
2024-02-17 13:27:32,782 - Epoch: [215][  300/  500]    Overall Loss 0.403961    Objective Loss 0.403961                                        LR 0.000063    Time 0.093748    
2024-02-17 13:27:41,990 - Epoch: [215][  400/  500]    Overall Loss 0.404847    Objective Loss 0.404847                                        LR 0.000063    Time 0.093322    
2024-02-17 13:27:51,131 - Epoch: [215][  500/  500]    Overall Loss 0.407196    Objective Loss 0.407196    Top1 91.000000    Top5 100.000000    LR 0.000063    Time 0.092931    
2024-02-17 13:27:51,248 - --- validate (epoch=215)-----------
2024-02-17 13:27:51,249 - 10000 samples (100 per mini-batch)
2024-02-17 13:27:56,502 - Epoch: [215][  100/  100]    Loss 1.571101    Top1 59.490000    Top5 85.670000    
2024-02-17 13:27:56,633 - ==> Top1: 59.490    Top5: 85.670    Loss: 1.571

2024-02-17 13:27:56,645 - ==> Best [Top1: 59.490   Top5: 85.780   Sparsity:0.00   Params: 753952 on epoch: 212]
2024-02-17 13:27:56,645 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:27:56,693 - 

2024-02-17 13:27:56,694 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:28:06,028 - Epoch: [216][  100/  500]    Overall Loss 0.392710    Objective Loss 0.392710                                        LR 0.000063    Time 0.093279    
2024-02-17 13:28:15,090 - Epoch: [216][  200/  500]    Overall Loss 0.398097    Objective Loss 0.398097                                        LR 0.000063    Time 0.091929    
2024-02-17 13:28:24,060 - Epoch: [216][  300/  500]    Overall Loss 0.402762    Objective Loss 0.402762                                        LR 0.000063    Time 0.091175    
2024-02-17 13:28:32,996 - Epoch: [216][  400/  500]    Overall Loss 0.404504    Objective Loss 0.404504                                        LR 0.000063    Time 0.090711    
2024-02-17 13:28:41,390 - Epoch: [216][  500/  500]    Overall Loss 0.406229    Objective Loss 0.406229    Top1 89.500000    Top5 99.500000    LR 0.000063    Time 0.089351    
2024-02-17 13:28:41,509 - --- validate (epoch=216)-----------
2024-02-17 13:28:41,510 - 10000 samples (100 per mini-batch)
2024-02-17 13:28:47,115 - Epoch: [216][  100/  100]    Loss 1.577695    Top1 59.580000    Top5 85.960000    
2024-02-17 13:28:47,268 - ==> Top1: 59.580    Top5: 85.960    Loss: 1.578

2024-02-17 13:28:47,278 - ==> Best [Top1: 59.580   Top5: 85.960   Sparsity:0.00   Params: 753952 on epoch: 216]
2024-02-17 13:28:47,278 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:28:47,343 - 

2024-02-17 13:28:47,344 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:28:57,129 - Epoch: [217][  100/  500]    Overall Loss 0.396666    Objective Loss 0.396666                                        LR 0.000063    Time 0.097806    
2024-02-17 13:29:06,265 - Epoch: [217][  200/  500]    Overall Loss 0.396698    Objective Loss 0.396698                                        LR 0.000063    Time 0.094558    
2024-02-17 13:29:14,997 - Epoch: [217][  300/  500]    Overall Loss 0.398239    Objective Loss 0.398239                                        LR 0.000063    Time 0.092135    
2024-02-17 13:29:24,219 - Epoch: [217][  400/  500]    Overall Loss 0.399999    Objective Loss 0.399999                                        LR 0.000063    Time 0.092146    
2024-02-17 13:29:33,331 - Epoch: [217][  500/  500]    Overall Loss 0.400253    Objective Loss 0.400253    Top1 89.000000    Top5 99.500000    LR 0.000063    Time 0.091934    
2024-02-17 13:29:33,478 - --- validate (epoch=217)-----------
2024-02-17 13:29:33,480 - 10000 samples (100 per mini-batch)
2024-02-17 13:29:39,125 - Epoch: [217][  100/  100]    Loss 1.579948    Top1 59.720000    Top5 85.490000    
2024-02-17 13:29:39,238 - ==> Top1: 59.720    Top5: 85.490    Loss: 1.580

2024-02-17 13:29:39,248 - ==> Best [Top1: 59.720   Top5: 85.490   Sparsity:0.00   Params: 753952 on epoch: 217]
2024-02-17 13:29:39,249 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:29:39,313 - 

2024-02-17 13:29:39,313 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:29:49,333 - Epoch: [218][  100/  500]    Overall Loss 0.389178    Objective Loss 0.389178                                        LR 0.000063    Time 0.100135    
2024-02-17 13:29:58,474 - Epoch: [218][  200/  500]    Overall Loss 0.384923    Objective Loss 0.384923                                        LR 0.000063    Time 0.095757    
2024-02-17 13:30:07,799 - Epoch: [218][  300/  500]    Overall Loss 0.390595    Objective Loss 0.390595                                        LR 0.000063    Time 0.094907    
2024-02-17 13:30:16,912 - Epoch: [218][  400/  500]    Overall Loss 0.394707    Objective Loss 0.394707                                        LR 0.000063    Time 0.093953    
2024-02-17 13:30:26,222 - Epoch: [218][  500/  500]    Overall Loss 0.396882    Objective Loss 0.396882    Top1 92.500000    Top5 100.000000    LR 0.000063    Time 0.093776    
2024-02-17 13:30:26,337 - --- validate (epoch=218)-----------
2024-02-17 13:30:26,338 - 10000 samples (100 per mini-batch)
2024-02-17 13:30:32,050 - Epoch: [218][  100/  100]    Loss 1.564393    Top1 59.490000    Top5 85.980000    
2024-02-17 13:30:32,151 - ==> Top1: 59.490    Top5: 85.980    Loss: 1.564

2024-02-17 13:30:32,161 - ==> Best [Top1: 59.720   Top5: 85.490   Sparsity:0.00   Params: 753952 on epoch: 217]
2024-02-17 13:30:32,161 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:30:32,218 - 

2024-02-17 13:30:32,218 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:30:41,867 - Epoch: [219][  100/  500]    Overall Loss 0.377059    Objective Loss 0.377059                                        LR 0.000063    Time 0.096418    
2024-02-17 13:30:50,871 - Epoch: [219][  200/  500]    Overall Loss 0.391408    Objective Loss 0.391408                                        LR 0.000063    Time 0.093208    
2024-02-17 13:30:59,948 - Epoch: [219][  300/  500]    Overall Loss 0.393297    Objective Loss 0.393297                                        LR 0.000063    Time 0.092383    
2024-02-17 13:31:08,964 - Epoch: [219][  400/  500]    Overall Loss 0.393890    Objective Loss 0.393890                                        LR 0.000063    Time 0.091818    
2024-02-17 13:31:18,039 - Epoch: [219][  500/  500]    Overall Loss 0.394840    Objective Loss 0.394840    Top1 89.500000    Top5 98.500000    LR 0.000063    Time 0.091598    
2024-02-17 13:31:18,178 - --- validate (epoch=219)-----------
2024-02-17 13:31:18,180 - 10000 samples (100 per mini-batch)
2024-02-17 13:31:23,982 - Epoch: [219][  100/  100]    Loss 1.573072    Top1 59.830000    Top5 85.680000    
2024-02-17 13:31:24,093 - ==> Top1: 59.830    Top5: 85.680    Loss: 1.573

2024-02-17 13:31:24,104 - ==> Best [Top1: 59.830   Top5: 85.680   Sparsity:0.00   Params: 753952 on epoch: 219]
2024-02-17 13:31:24,104 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:31:24,170 - 

2024-02-17 13:31:24,171 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:31:33,769 - Epoch: [220][  100/  500]    Overall Loss 0.387672    Objective Loss 0.387672                                        LR 0.000063    Time 0.095933    
2024-02-17 13:31:42,844 - Epoch: [220][  200/  500]    Overall Loss 0.386881    Objective Loss 0.386881                                        LR 0.000063    Time 0.093320    
2024-02-17 13:31:52,271 - Epoch: [220][  300/  500]    Overall Loss 0.388288    Objective Loss 0.388288                                        LR 0.000063    Time 0.093626    
2024-02-17 13:32:01,707 - Epoch: [220][  400/  500]    Overall Loss 0.389550    Objective Loss 0.389550                                        LR 0.000063    Time 0.093799    
2024-02-17 13:32:10,871 - Epoch: [220][  500/  500]    Overall Loss 0.392038    Objective Loss 0.392038    Top1 88.500000    Top5 100.000000    LR 0.000063    Time 0.093359    
2024-02-17 13:32:11,041 - --- validate (epoch=220)-----------
2024-02-17 13:32:11,042 - 10000 samples (100 per mini-batch)
2024-02-17 13:32:17,168 - Epoch: [220][  100/  100]    Loss 1.580759    Top1 59.470000    Top5 85.700000    
2024-02-17 13:32:17,336 - ==> Top1: 59.470    Top5: 85.700    Loss: 1.581

2024-02-17 13:32:17,346 - ==> Best [Top1: 59.830   Top5: 85.680   Sparsity:0.00   Params: 753952 on epoch: 219]
2024-02-17 13:32:17,347 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:32:17,640 - 

2024-02-17 13:32:17,640 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:32:27,339 - Epoch: [221][  100/  500]    Overall Loss 0.381845    Objective Loss 0.381845                                        LR 0.000063    Time 0.096926    
2024-02-17 13:32:36,596 - Epoch: [221][  200/  500]    Overall Loss 0.382362    Objective Loss 0.382362                                        LR 0.000063    Time 0.094725    
2024-02-17 13:32:45,918 - Epoch: [221][  300/  500]    Overall Loss 0.384944    Objective Loss 0.384944                                        LR 0.000063    Time 0.094212    
2024-02-17 13:32:55,457 - Epoch: [221][  400/  500]    Overall Loss 0.387777    Objective Loss 0.387777                                        LR 0.000063    Time 0.094497    
2024-02-17 13:33:04,670 - Epoch: [221][  500/  500]    Overall Loss 0.388477    Objective Loss 0.388477    Top1 92.500000    Top5 100.000000    LR 0.000063    Time 0.094015    
2024-02-17 13:33:04,799 - --- validate (epoch=221)-----------
2024-02-17 13:33:04,800 - 10000 samples (100 per mini-batch)
2024-02-17 13:33:10,501 - Epoch: [221][  100/  100]    Loss 1.590310    Top1 59.360000    Top5 85.520000    
2024-02-17 13:33:10,621 - ==> Top1: 59.360    Top5: 85.520    Loss: 1.590

2024-02-17 13:33:10,633 - ==> Best [Top1: 59.830   Top5: 85.680   Sparsity:0.00   Params: 753952 on epoch: 219]
2024-02-17 13:33:10,633 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:33:10,685 - 

2024-02-17 13:33:10,685 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:33:20,693 - Epoch: [222][  100/  500]    Overall Loss 0.377717    Objective Loss 0.377717                                        LR 0.000063    Time 0.100023    
2024-02-17 13:33:29,959 - Epoch: [222][  200/  500]    Overall Loss 0.377698    Objective Loss 0.377698                                        LR 0.000063    Time 0.096323    
2024-02-17 13:33:39,230 - Epoch: [222][  300/  500]    Overall Loss 0.380892    Objective Loss 0.380892                                        LR 0.000063    Time 0.095104    
2024-02-17 13:33:48,417 - Epoch: [222][  400/  500]    Overall Loss 0.382652    Objective Loss 0.382652                                        LR 0.000063    Time 0.094285    
2024-02-17 13:33:57,475 - Epoch: [222][  500/  500]    Overall Loss 0.384799    Objective Loss 0.384799    Top1 92.000000    Top5 100.000000    LR 0.000063    Time 0.093537    
2024-02-17 13:33:57,616 - --- validate (epoch=222)-----------
2024-02-17 13:33:57,617 - 10000 samples (100 per mini-batch)
2024-02-17 13:34:03,783 - Epoch: [222][  100/  100]    Loss 1.573111    Top1 59.730000    Top5 85.770000    
2024-02-17 13:34:03,885 - ==> Top1: 59.730    Top5: 85.770    Loss: 1.573

2024-02-17 13:34:03,896 - ==> Best [Top1: 59.830   Top5: 85.680   Sparsity:0.00   Params: 753952 on epoch: 219]
2024-02-17 13:34:03,897 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:34:03,949 - 

2024-02-17 13:34:03,949 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:34:13,656 - Epoch: [223][  100/  500]    Overall Loss 0.376198    Objective Loss 0.376198                                        LR 0.000063    Time 0.097011    
2024-02-17 13:34:22,385 - Epoch: [223][  200/  500]    Overall Loss 0.375544    Objective Loss 0.375544                                        LR 0.000063    Time 0.092138    
2024-02-17 13:34:31,649 - Epoch: [223][  300/  500]    Overall Loss 0.378363    Objective Loss 0.378363                                        LR 0.000063    Time 0.092287    
2024-02-17 13:34:40,943 - Epoch: [223][  400/  500]    Overall Loss 0.382080    Objective Loss 0.382080                                        LR 0.000063    Time 0.092442    
2024-02-17 13:34:50,321 - Epoch: [223][  500/  500]    Overall Loss 0.385549    Objective Loss 0.385549    Top1 91.500000    Top5 99.000000    LR 0.000063    Time 0.092700    
2024-02-17 13:34:50,483 - --- validate (epoch=223)-----------
2024-02-17 13:34:50,484 - 10000 samples (100 per mini-batch)
2024-02-17 13:34:56,316 - Epoch: [223][  100/  100]    Loss 1.607582    Top1 59.330000    Top5 85.530000    
2024-02-17 13:34:56,509 - ==> Top1: 59.330    Top5: 85.530    Loss: 1.608

2024-02-17 13:34:56,518 - ==> Best [Top1: 59.830   Top5: 85.680   Sparsity:0.00   Params: 753952 on epoch: 219]
2024-02-17 13:34:56,518 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:34:56,572 - 

2024-02-17 13:34:56,572 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:35:06,374 - Epoch: [224][  100/  500]    Overall Loss 0.373600    Objective Loss 0.373600                                        LR 0.000063    Time 0.097943    
2024-02-17 13:35:15,914 - Epoch: [224][  200/  500]    Overall Loss 0.371272    Objective Loss 0.371272                                        LR 0.000063    Time 0.096656    
2024-02-17 13:35:25,222 - Epoch: [224][  300/  500]    Overall Loss 0.375784    Objective Loss 0.375784                                        LR 0.000063    Time 0.095450    
2024-02-17 13:35:34,678 - Epoch: [224][  400/  500]    Overall Loss 0.377506    Objective Loss 0.377506                                        LR 0.000063    Time 0.095217    
2024-02-17 13:35:43,835 - Epoch: [224][  500/  500]    Overall Loss 0.380157    Objective Loss 0.380157    Top1 91.500000    Top5 100.000000    LR 0.000063    Time 0.094481    
2024-02-17 13:35:43,973 - --- validate (epoch=224)-----------
2024-02-17 13:35:43,974 - 10000 samples (100 per mini-batch)
2024-02-17 13:35:49,859 - Epoch: [224][  100/  100]    Loss 1.608261    Top1 59.120000    Top5 85.580000    
2024-02-17 13:35:50,021 - ==> Top1: 59.120    Top5: 85.580    Loss: 1.608

2024-02-17 13:35:50,031 - ==> Best [Top1: 59.830   Top5: 85.680   Sparsity:0.00   Params: 753952 on epoch: 219]
2024-02-17 13:35:50,031 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:35:50,084 - 

2024-02-17 13:35:50,085 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:35:59,841 - Epoch: [225][  100/  500]    Overall Loss 0.377982    Objective Loss 0.377982                                        LR 0.000063    Time 0.097505    
2024-02-17 13:36:09,149 - Epoch: [225][  200/  500]    Overall Loss 0.377601    Objective Loss 0.377601                                        LR 0.000063    Time 0.095270    
2024-02-17 13:36:18,527 - Epoch: [225][  300/  500]    Overall Loss 0.379720    Objective Loss 0.379720                                        LR 0.000063    Time 0.094759    
2024-02-17 13:36:27,680 - Epoch: [225][  400/  500]    Overall Loss 0.381933    Objective Loss 0.381933                                        LR 0.000063    Time 0.093940    
2024-02-17 13:36:36,882 - Epoch: [225][  500/  500]    Overall Loss 0.384816    Objective Loss 0.384816    Top1 90.000000    Top5 99.000000    LR 0.000063    Time 0.093549    
2024-02-17 13:36:37,046 - --- validate (epoch=225)-----------
2024-02-17 13:36:37,047 - 10000 samples (100 per mini-batch)
2024-02-17 13:36:43,116 - Epoch: [225][  100/  100]    Loss 1.566775    Top1 60.090000    Top5 85.830000    
2024-02-17 13:36:43,291 - ==> Top1: 60.090    Top5: 85.830    Loss: 1.567

2024-02-17 13:36:43,303 - ==> Best [Top1: 60.090   Top5: 85.830   Sparsity:0.00   Params: 753952 on epoch: 225]
2024-02-17 13:36:43,303 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:36:43,368 - 

2024-02-17 13:36:43,369 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:36:52,722 - Epoch: [226][  100/  500]    Overall Loss 0.362059    Objective Loss 0.362059                                        LR 0.000063    Time 0.093489    
2024-02-17 13:37:02,008 - Epoch: [226][  200/  500]    Overall Loss 0.368455    Objective Loss 0.368455                                        LR 0.000063    Time 0.093153    
2024-02-17 13:37:11,427 - Epoch: [226][  300/  500]    Overall Loss 0.370585    Objective Loss 0.370585                                        LR 0.000063    Time 0.093482    
2024-02-17 13:37:20,704 - Epoch: [226][  400/  500]    Overall Loss 0.375264    Objective Loss 0.375264                                        LR 0.000063    Time 0.093296    
2024-02-17 13:37:29,906 - Epoch: [226][  500/  500]    Overall Loss 0.378542    Objective Loss 0.378542    Top1 90.500000    Top5 100.000000    LR 0.000063    Time 0.093033    
2024-02-17 13:37:30,000 - --- validate (epoch=226)-----------
2024-02-17 13:37:30,001 - 10000 samples (100 per mini-batch)
2024-02-17 13:37:35,470 - Epoch: [226][  100/  100]    Loss 1.588563    Top1 59.960000    Top5 85.730000    
2024-02-17 13:37:35,673 - ==> Top1: 59.960    Top5: 85.730    Loss: 1.589

2024-02-17 13:37:35,685 - ==> Best [Top1: 60.090   Top5: 85.830   Sparsity:0.00   Params: 753952 on epoch: 225]
2024-02-17 13:37:35,685 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:37:35,974 - 

2024-02-17 13:37:35,975 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:37:45,803 - Epoch: [227][  100/  500]    Overall Loss 0.366205    Objective Loss 0.366205                                        LR 0.000063    Time 0.098213    
2024-02-17 13:37:55,141 - Epoch: [227][  200/  500]    Overall Loss 0.375463    Objective Loss 0.375463                                        LR 0.000063    Time 0.095780    
2024-02-17 13:38:04,460 - Epoch: [227][  300/  500]    Overall Loss 0.377070    Objective Loss 0.377070                                        LR 0.000063    Time 0.094900    
2024-02-17 13:38:13,952 - Epoch: [227][  400/  500]    Overall Loss 0.378377    Objective Loss 0.378377                                        LR 0.000063    Time 0.094896    
2024-02-17 13:38:23,200 - Epoch: [227][  500/  500]    Overall Loss 0.381429    Objective Loss 0.381429    Top1 93.000000    Top5 100.000000    LR 0.000063    Time 0.094404    
2024-02-17 13:38:23,325 - --- validate (epoch=227)-----------
2024-02-17 13:38:23,326 - 10000 samples (100 per mini-batch)
2024-02-17 13:38:29,076 - Epoch: [227][  100/  100]    Loss 1.620548    Top1 58.790000    Top5 85.720000    
2024-02-17 13:38:29,192 - ==> Top1: 58.790    Top5: 85.720    Loss: 1.621

2024-02-17 13:38:29,200 - ==> Best [Top1: 60.090   Top5: 85.830   Sparsity:0.00   Params: 753952 on epoch: 225]
2024-02-17 13:38:29,201 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:38:29,246 - 

2024-02-17 13:38:29,246 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:38:39,628 - Epoch: [228][  100/  500]    Overall Loss 0.372870    Objective Loss 0.372870                                        LR 0.000063    Time 0.103760    
2024-02-17 13:38:49,003 - Epoch: [228][  200/  500]    Overall Loss 0.372707    Objective Loss 0.372707                                        LR 0.000063    Time 0.098732    
2024-02-17 13:38:58,306 - Epoch: [228][  300/  500]    Overall Loss 0.372815    Objective Loss 0.372815                                        LR 0.000063    Time 0.096821    
2024-02-17 13:39:07,336 - Epoch: [228][  400/  500]    Overall Loss 0.377055    Objective Loss 0.377055                                        LR 0.000063    Time 0.095181    
2024-02-17 13:39:16,456 - Epoch: [228][  500/  500]    Overall Loss 0.379063    Objective Loss 0.379063    Top1 89.500000    Top5 98.500000    LR 0.000063    Time 0.094377    
2024-02-17 13:39:16,589 - --- validate (epoch=228)-----------
2024-02-17 13:39:16,590 - 10000 samples (100 per mini-batch)
2024-02-17 13:39:22,842 - Epoch: [228][  100/  100]    Loss 1.584236    Top1 60.180000    Top5 86.050000    
2024-02-17 13:39:22,994 - ==> Top1: 60.180    Top5: 86.050    Loss: 1.584

2024-02-17 13:39:23,004 - ==> Best [Top1: 60.180   Top5: 86.050   Sparsity:0.00   Params: 753952 on epoch: 228]
2024-02-17 13:39:23,004 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:39:23,071 - 

2024-02-17 13:39:23,071 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:39:32,974 - Epoch: [229][  100/  500]    Overall Loss 0.368439    Objective Loss 0.368439                                        LR 0.000063    Time 0.098971    
2024-02-17 13:39:42,618 - Epoch: [229][  200/  500]    Overall Loss 0.368538    Objective Loss 0.368538                                        LR 0.000063    Time 0.097688    
2024-02-17 13:39:52,124 - Epoch: [229][  300/  500]    Overall Loss 0.370521    Objective Loss 0.370521                                        LR 0.000063    Time 0.096797    
2024-02-17 13:40:01,938 - Epoch: [229][  400/  500]    Overall Loss 0.372252    Objective Loss 0.372252                                        LR 0.000063    Time 0.097123    
2024-02-17 13:40:11,691 - Epoch: [229][  500/  500]    Overall Loss 0.375424    Objective Loss 0.375424    Top1 90.500000    Top5 99.500000    LR 0.000063    Time 0.097195    
2024-02-17 13:40:11,862 - --- validate (epoch=229)-----------
2024-02-17 13:40:11,862 - 10000 samples (100 per mini-batch)
2024-02-17 13:40:17,863 - Epoch: [229][  100/  100]    Loss 1.591282    Top1 59.500000    Top5 85.940000    
2024-02-17 13:40:17,962 - ==> Top1: 59.500    Top5: 85.940    Loss: 1.591

2024-02-17 13:40:17,972 - ==> Best [Top1: 60.180   Top5: 86.050   Sparsity:0.00   Params: 753952 on epoch: 228]
2024-02-17 13:40:17,973 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:40:18,042 - 

2024-02-17 13:40:18,042 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:40:27,882 - Epoch: [230][  100/  500]    Overall Loss 0.370761    Objective Loss 0.370761                                        LR 0.000063    Time 0.098344    
2024-02-17 13:40:37,055 - Epoch: [230][  200/  500]    Overall Loss 0.368476    Objective Loss 0.368476                                        LR 0.000063    Time 0.095017    
2024-02-17 13:40:46,204 - Epoch: [230][  300/  500]    Overall Loss 0.366047    Objective Loss 0.366047                                        LR 0.000063    Time 0.093828    
2024-02-17 13:40:55,343 - Epoch: [230][  400/  500]    Overall Loss 0.368331    Objective Loss 0.368331                                        LR 0.000063    Time 0.093209    
2024-02-17 13:41:04,516 - Epoch: [230][  500/  500]    Overall Loss 0.371289    Objective Loss 0.371289    Top1 90.000000    Top5 99.500000    LR 0.000063    Time 0.092906    
2024-02-17 13:41:04,627 - --- validate (epoch=230)-----------
2024-02-17 13:41:04,629 - 10000 samples (100 per mini-batch)
2024-02-17 13:41:09,747 - Epoch: [230][  100/  100]    Loss 1.586441    Top1 59.790000    Top5 85.760000    
2024-02-17 13:41:09,850 - ==> Top1: 59.790    Top5: 85.760    Loss: 1.586

2024-02-17 13:41:09,859 - ==> Best [Top1: 60.180   Top5: 86.050   Sparsity:0.00   Params: 753952 on epoch: 228]
2024-02-17 13:41:09,859 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:41:09,902 - 

2024-02-17 13:41:09,902 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:41:19,420 - Epoch: [231][  100/  500]    Overall Loss 0.359949    Objective Loss 0.359949                                        LR 0.000063    Time 0.095129    
2024-02-17 13:41:28,625 - Epoch: [231][  200/  500]    Overall Loss 0.365588    Objective Loss 0.365588                                        LR 0.000063    Time 0.093572    
2024-02-17 13:41:37,885 - Epoch: [231][  300/  500]    Overall Loss 0.367331    Objective Loss 0.367331                                        LR 0.000063    Time 0.093233    
2024-02-17 13:41:46,997 - Epoch: [231][  400/  500]    Overall Loss 0.369138    Objective Loss 0.369138                                        LR 0.000063    Time 0.092696    
2024-02-17 13:41:56,247 - Epoch: [231][  500/  500]    Overall Loss 0.369601    Objective Loss 0.369601    Top1 91.500000    Top5 100.000000    LR 0.000063    Time 0.092648    
2024-02-17 13:41:56,422 - --- validate (epoch=231)-----------
2024-02-17 13:41:56,423 - 10000 samples (100 per mini-batch)
2024-02-17 13:42:02,068 - Epoch: [231][  100/  100]    Loss 1.593277    Top1 59.560000    Top5 85.810000    
2024-02-17 13:42:02,230 - ==> Top1: 59.560    Top5: 85.810    Loss: 1.593

2024-02-17 13:42:02,242 - ==> Best [Top1: 60.180   Top5: 86.050   Sparsity:0.00   Params: 753952 on epoch: 228]
2024-02-17 13:42:02,242 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:42:02,296 - 

2024-02-17 13:42:02,296 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:42:11,865 - Epoch: [232][  100/  500]    Overall Loss 0.368187    Objective Loss 0.368187                                        LR 0.000063    Time 0.095633    
2024-02-17 13:42:21,147 - Epoch: [232][  200/  500]    Overall Loss 0.365371    Objective Loss 0.365371                                        LR 0.000063    Time 0.094208    
2024-02-17 13:42:30,673 - Epoch: [232][  300/  500]    Overall Loss 0.365728    Objective Loss 0.365728                                        LR 0.000063    Time 0.094544    
2024-02-17 13:42:39,916 - Epoch: [232][  400/  500]    Overall Loss 0.367928    Objective Loss 0.367928                                        LR 0.000063    Time 0.094007    
2024-02-17 13:42:49,062 - Epoch: [232][  500/  500]    Overall Loss 0.369119    Objective Loss 0.369119    Top1 92.000000    Top5 100.000000    LR 0.000063    Time 0.093488    
2024-02-17 13:42:49,219 - --- validate (epoch=232)-----------
2024-02-17 13:42:49,220 - 10000 samples (100 per mini-batch)
2024-02-17 13:42:55,285 - Epoch: [232][  100/  100]    Loss 1.576517    Top1 60.180000    Top5 85.930000    
2024-02-17 13:42:55,415 - ==> Top1: 60.180    Top5: 85.930    Loss: 1.577

2024-02-17 13:42:55,426 - ==> Best [Top1: 60.180   Top5: 86.050   Sparsity:0.00   Params: 753952 on epoch: 228]
2024-02-17 13:42:55,427 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:42:55,677 - 

2024-02-17 13:42:55,677 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:43:05,407 - Epoch: [233][  100/  500]    Overall Loss 0.369110    Objective Loss 0.369110                                        LR 0.000063    Time 0.097248    
2024-02-17 13:43:14,677 - Epoch: [233][  200/  500]    Overall Loss 0.362470    Objective Loss 0.362470                                        LR 0.000063    Time 0.094953    
2024-02-17 13:43:23,828 - Epoch: [233][  300/  500]    Overall Loss 0.361408    Objective Loss 0.361408                                        LR 0.000063    Time 0.093794    
2024-02-17 13:43:32,852 - Epoch: [233][  400/  500]    Overall Loss 0.363409    Objective Loss 0.363409                                        LR 0.000063    Time 0.092896    
2024-02-17 13:43:41,925 - Epoch: [233][  500/  500]    Overall Loss 0.364125    Objective Loss 0.364125    Top1 91.000000    Top5 99.500000    LR 0.000063    Time 0.092455    
2024-02-17 13:43:42,104 - --- validate (epoch=233)-----------
2024-02-17 13:43:42,105 - 10000 samples (100 per mini-batch)
2024-02-17 13:43:47,580 - Epoch: [233][  100/  100]    Loss 1.600707    Top1 59.560000    Top5 85.590000    
2024-02-17 13:43:47,715 - ==> Top1: 59.560    Top5: 85.590    Loss: 1.601

2024-02-17 13:43:47,726 - ==> Best [Top1: 60.180   Top5: 86.050   Sparsity:0.00   Params: 753952 on epoch: 228]
2024-02-17 13:43:47,726 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:43:47,778 - 

2024-02-17 13:43:47,779 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:43:57,696 - Epoch: [234][  100/  500]    Overall Loss 0.356519    Objective Loss 0.356519                                        LR 0.000063    Time 0.099121    
2024-02-17 13:44:06,566 - Epoch: [234][  200/  500]    Overall Loss 0.364215    Objective Loss 0.364215                                        LR 0.000063    Time 0.093893    
2024-02-17 13:44:15,872 - Epoch: [234][  300/  500]    Overall Loss 0.366020    Objective Loss 0.366020                                        LR 0.000063    Time 0.093603    
2024-02-17 13:44:25,109 - Epoch: [234][  400/  500]    Overall Loss 0.368554    Objective Loss 0.368554                                        LR 0.000063    Time 0.093284    
2024-02-17 13:44:34,358 - Epoch: [234][  500/  500]    Overall Loss 0.368707    Objective Loss 0.368707    Top1 92.000000    Top5 100.000000    LR 0.000063    Time 0.093119    
2024-02-17 13:44:34,485 - --- validate (epoch=234)-----------
2024-02-17 13:44:34,486 - 10000 samples (100 per mini-batch)
2024-02-17 13:44:40,102 - Epoch: [234][  100/  100]    Loss 1.584553    Top1 60.210000    Top5 85.790000    
2024-02-17 13:44:40,208 - ==> Top1: 60.210    Top5: 85.790    Loss: 1.585

2024-02-17 13:44:40,218 - ==> Best [Top1: 60.210   Top5: 85.790   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:44:40,219 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:44:40,284 - 

2024-02-17 13:44:40,284 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:44:49,966 - Epoch: [235][  100/  500]    Overall Loss 0.355581    Objective Loss 0.355581                                        LR 0.000063    Time 0.096766    
2024-02-17 13:44:59,327 - Epoch: [235][  200/  500]    Overall Loss 0.360724    Objective Loss 0.360724                                        LR 0.000063    Time 0.095166    
2024-02-17 13:45:08,493 - Epoch: [235][  300/  500]    Overall Loss 0.362328    Objective Loss 0.362328                                        LR 0.000063    Time 0.093982    
2024-02-17 13:45:17,614 - Epoch: [235][  400/  500]    Overall Loss 0.366157    Objective Loss 0.366157                                        LR 0.000063    Time 0.093282    
2024-02-17 13:45:26,734 - Epoch: [235][  500/  500]    Overall Loss 0.366394    Objective Loss 0.366394    Top1 91.500000    Top5 99.500000    LR 0.000063    Time 0.092857    
2024-02-17 13:45:26,851 - --- validate (epoch=235)-----------
2024-02-17 13:45:26,852 - 10000 samples (100 per mini-batch)
2024-02-17 13:45:31,800 - Epoch: [235][  100/  100]    Loss 1.588008    Top1 59.670000    Top5 85.810000    
2024-02-17 13:45:31,895 - ==> Top1: 59.670    Top5: 85.810    Loss: 1.588

2024-02-17 13:45:31,905 - ==> Best [Top1: 60.210   Top5: 85.790   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:45:31,905 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:45:31,949 - 

2024-02-17 13:45:31,949 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:45:40,892 - Epoch: [236][  100/  500]    Overall Loss 0.360538    Objective Loss 0.360538                                        LR 0.000063    Time 0.089382    
2024-02-17 13:45:50,232 - Epoch: [236][  200/  500]    Overall Loss 0.367419    Objective Loss 0.367419                                        LR 0.000063    Time 0.091370    
2024-02-17 13:45:59,284 - Epoch: [236][  300/  500]    Overall Loss 0.365785    Objective Loss 0.365785                                        LR 0.000063    Time 0.091073    
2024-02-17 13:46:08,252 - Epoch: [236][  400/  500]    Overall Loss 0.364808    Objective Loss 0.364808                                        LR 0.000063    Time 0.090716    
2024-02-17 13:46:17,254 - Epoch: [236][  500/  500]    Overall Loss 0.363818    Objective Loss 0.363818    Top1 91.000000    Top5 99.500000    LR 0.000063    Time 0.090570    
2024-02-17 13:46:17,467 - --- validate (epoch=236)-----------
2024-02-17 13:46:17,468 - 10000 samples (100 per mini-batch)
2024-02-17 13:46:23,238 - Epoch: [236][  100/  100]    Loss 1.624952    Top1 59.170000    Top5 85.440000    
2024-02-17 13:46:23,349 - ==> Top1: 59.170    Top5: 85.440    Loss: 1.625

2024-02-17 13:46:23,359 - ==> Best [Top1: 60.210   Top5: 85.790   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:46:23,359 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:46:23,410 - 

2024-02-17 13:46:23,410 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:46:33,295 - Epoch: [237][  100/  500]    Overall Loss 0.349710    Objective Loss 0.349710                                        LR 0.000063    Time 0.098790    
2024-02-17 13:46:42,492 - Epoch: [237][  200/  500]    Overall Loss 0.356558    Objective Loss 0.356558                                        LR 0.000063    Time 0.095363    
2024-02-17 13:46:51,603 - Epoch: [237][  300/  500]    Overall Loss 0.357869    Objective Loss 0.357869                                        LR 0.000063    Time 0.093932    
2024-02-17 13:47:00,324 - Epoch: [237][  400/  500]    Overall Loss 0.361158    Objective Loss 0.361158                                        LR 0.000063    Time 0.092244    
2024-02-17 13:47:09,609 - Epoch: [237][  500/  500]    Overall Loss 0.363836    Objective Loss 0.363836    Top1 90.500000    Top5 98.500000    LR 0.000063    Time 0.092356    
2024-02-17 13:47:09,735 - --- validate (epoch=237)-----------
2024-02-17 13:47:09,735 - 10000 samples (100 per mini-batch)
2024-02-17 13:47:15,145 - Epoch: [237][  100/  100]    Loss 1.629663    Top1 59.650000    Top5 85.220000    
2024-02-17 13:47:15,310 - ==> Top1: 59.650    Top5: 85.220    Loss: 1.630

2024-02-17 13:47:15,321 - ==> Best [Top1: 60.210   Top5: 85.790   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:47:15,321 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:47:15,372 - 

2024-02-17 13:47:15,372 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:47:24,945 - Epoch: [238][  100/  500]    Overall Loss 0.344113    Objective Loss 0.344113                                        LR 0.000063    Time 0.095678    
2024-02-17 13:47:34,099 - Epoch: [238][  200/  500]    Overall Loss 0.352442    Objective Loss 0.352442                                        LR 0.000063    Time 0.093589    
2024-02-17 13:47:43,224 - Epoch: [238][  300/  500]    Overall Loss 0.356697    Objective Loss 0.356697                                        LR 0.000063    Time 0.092797    
2024-02-17 13:47:52,814 - Epoch: [238][  400/  500]    Overall Loss 0.359450    Objective Loss 0.359450                                        LR 0.000063    Time 0.093563    
2024-02-17 13:48:02,176 - Epoch: [238][  500/  500]    Overall Loss 0.361206    Objective Loss 0.361206    Top1 90.000000    Top5 99.500000    LR 0.000063    Time 0.093568    
2024-02-17 13:48:02,300 - --- validate (epoch=238)-----------
2024-02-17 13:48:02,301 - 10000 samples (100 per mini-batch)
2024-02-17 13:48:08,433 - Epoch: [238][  100/  100]    Loss 1.611247    Top1 59.740000    Top5 85.580000    
2024-02-17 13:48:08,572 - ==> Top1: 59.740    Top5: 85.580    Loss: 1.611

2024-02-17 13:48:08,582 - ==> Best [Top1: 60.210   Top5: 85.790   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:48:08,583 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:48:08,633 - 

2024-02-17 13:48:08,634 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:48:18,187 - Epoch: [239][  100/  500]    Overall Loss 0.353774    Objective Loss 0.353774                                        LR 0.000063    Time 0.095479    
2024-02-17 13:48:27,457 - Epoch: [239][  200/  500]    Overall Loss 0.354155    Objective Loss 0.354155                                        LR 0.000063    Time 0.094072    
2024-02-17 13:48:36,621 - Epoch: [239][  300/  500]    Overall Loss 0.352033    Objective Loss 0.352033                                        LR 0.000063    Time 0.093250    
2024-02-17 13:48:45,812 - Epoch: [239][  400/  500]    Overall Loss 0.355857    Objective Loss 0.355857                                        LR 0.000063    Time 0.092905    
2024-02-17 13:48:55,300 - Epoch: [239][  500/  500]    Overall Loss 0.357925    Objective Loss 0.357925    Top1 93.000000    Top5 100.000000    LR 0.000063    Time 0.093293    
2024-02-17 13:48:55,429 - --- validate (epoch=239)-----------
2024-02-17 13:48:55,430 - 10000 samples (100 per mini-batch)
2024-02-17 13:49:01,292 - Epoch: [239][  100/  100]    Loss 1.582629    Top1 60.150000    Top5 85.940000    
2024-02-17 13:49:01,446 - ==> Top1: 60.150    Top5: 85.940    Loss: 1.583

2024-02-17 13:49:01,457 - ==> Best [Top1: 60.210   Top5: 85.790   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:49:01,458 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:49:01,510 - 

2024-02-17 13:49:01,511 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:49:11,557 - Epoch: [240][  100/  500]    Overall Loss 0.350717    Objective Loss 0.350717                                        LR 0.000063    Time 0.100412    
2024-02-17 13:49:20,671 - Epoch: [240][  200/  500]    Overall Loss 0.358378    Objective Loss 0.358378                                        LR 0.000063    Time 0.095754    
2024-02-17 13:49:29,414 - Epoch: [240][  300/  500]    Overall Loss 0.360626    Objective Loss 0.360626                                        LR 0.000063    Time 0.092969    
2024-02-17 13:49:38,292 - Epoch: [240][  400/  500]    Overall Loss 0.361282    Objective Loss 0.361282                                        LR 0.000063    Time 0.091913    
2024-02-17 13:49:47,502 - Epoch: [240][  500/  500]    Overall Loss 0.359848    Objective Loss 0.359848    Top1 91.500000    Top5 100.000000    LR 0.000063    Time 0.091944    
2024-02-17 13:49:47,658 - --- validate (epoch=240)-----------
2024-02-17 13:49:47,658 - 10000 samples (100 per mini-batch)
2024-02-17 13:49:53,287 - Epoch: [240][  100/  100]    Loss 1.620050    Top1 59.630000    Top5 85.500000    
2024-02-17 13:49:53,396 - ==> Top1: 59.630    Top5: 85.500    Loss: 1.620

2024-02-17 13:49:53,408 - ==> Best [Top1: 60.210   Top5: 85.790   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:49:53,408 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:49:53,460 - 

2024-02-17 13:49:53,460 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:50:03,287 - Epoch: [241][  100/  500]    Overall Loss 0.351054    Objective Loss 0.351054                                        LR 0.000063    Time 0.098217    
2024-02-17 13:50:12,495 - Epoch: [241][  200/  500]    Overall Loss 0.353628    Objective Loss 0.353628                                        LR 0.000063    Time 0.095125    
2024-02-17 13:50:21,583 - Epoch: [241][  300/  500]    Overall Loss 0.356860    Objective Loss 0.356860                                        LR 0.000063    Time 0.093697    
2024-02-17 13:50:30,782 - Epoch: [241][  400/  500]    Overall Loss 0.359731    Objective Loss 0.359731                                        LR 0.000063    Time 0.093261    
2024-02-17 13:50:39,986 - Epoch: [241][  500/  500]    Overall Loss 0.361122    Objective Loss 0.361122    Top1 88.000000    Top5 99.000000    LR 0.000063    Time 0.093008    
2024-02-17 13:50:40,134 - --- validate (epoch=241)-----------
2024-02-17 13:50:40,135 - 10000 samples (100 per mini-batch)
2024-02-17 13:50:46,370 - Epoch: [241][  100/  100]    Loss 1.630037    Top1 59.480000    Top5 85.640000    
2024-02-17 13:50:46,557 - ==> Top1: 59.480    Top5: 85.640    Loss: 1.630

2024-02-17 13:50:46,564 - ==> Best [Top1: 60.210   Top5: 85.790   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:50:46,565 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:50:46,615 - 

2024-02-17 13:50:46,615 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:50:56,753 - Epoch: [242][  100/  500]    Overall Loss 0.352307    Objective Loss 0.352307                                        LR 0.000063    Time 0.101330    
2024-02-17 13:51:05,940 - Epoch: [242][  200/  500]    Overall Loss 0.350647    Objective Loss 0.350647                                        LR 0.000063    Time 0.096581    
2024-02-17 13:51:15,201 - Epoch: [242][  300/  500]    Overall Loss 0.348387    Objective Loss 0.348387                                        LR 0.000063    Time 0.095243    
2024-02-17 13:51:24,486 - Epoch: [242][  400/  500]    Overall Loss 0.351729    Objective Loss 0.351729                                        LR 0.000063    Time 0.094636    
2024-02-17 13:51:33,665 - Epoch: [242][  500/  500]    Overall Loss 0.353078    Objective Loss 0.353078    Top1 91.000000    Top5 99.000000    LR 0.000063    Time 0.094060    
2024-02-17 13:51:33,785 - --- validate (epoch=242)-----------
2024-02-17 13:51:33,786 - 10000 samples (100 per mini-batch)
2024-02-17 13:51:39,948 - Epoch: [242][  100/  100]    Loss 1.624601    Top1 59.530000    Top5 85.490000    
2024-02-17 13:51:40,057 - ==> Top1: 59.530    Top5: 85.490    Loss: 1.625

2024-02-17 13:51:40,067 - ==> Best [Top1: 60.210   Top5: 85.790   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:51:40,068 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:51:40,120 - 

2024-02-17 13:51:40,120 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:51:50,042 - Epoch: [243][  100/  500]    Overall Loss 0.348809    Objective Loss 0.348809                                        LR 0.000063    Time 0.099160    
2024-02-17 13:51:58,982 - Epoch: [243][  200/  500]    Overall Loss 0.347557    Objective Loss 0.347557                                        LR 0.000063    Time 0.094261    
2024-02-17 13:52:08,099 - Epoch: [243][  300/  500]    Overall Loss 0.350799    Objective Loss 0.350799                                        LR 0.000063    Time 0.093221    
2024-02-17 13:52:17,309 - Epoch: [243][  400/  500]    Overall Loss 0.352769    Objective Loss 0.352769                                        LR 0.000063    Time 0.092931    
2024-02-17 13:52:26,501 - Epoch: [243][  500/  500]    Overall Loss 0.353462    Objective Loss 0.353462    Top1 89.000000    Top5 99.500000    LR 0.000063    Time 0.092721    
2024-02-17 13:52:26,606 - --- validate (epoch=243)-----------
2024-02-17 13:52:26,607 - 10000 samples (100 per mini-batch)
2024-02-17 13:52:32,733 - Epoch: [243][  100/  100]    Loss 1.631166    Top1 59.550000    Top5 85.800000    
2024-02-17 13:52:32,848 - ==> Top1: 59.550    Top5: 85.800    Loss: 1.631

2024-02-17 13:52:32,859 - ==> Best [Top1: 60.210   Top5: 85.790   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:52:32,860 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:52:32,914 - 

2024-02-17 13:52:32,915 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:52:43,013 - Epoch: [244][  100/  500]    Overall Loss 0.343236    Objective Loss 0.343236                                        LR 0.000063    Time 0.100926    
2024-02-17 13:52:52,461 - Epoch: [244][  200/  500]    Overall Loss 0.347661    Objective Loss 0.347661                                        LR 0.000063    Time 0.097681    
2024-02-17 13:53:01,208 - Epoch: [244][  300/  500]    Overall Loss 0.347762    Objective Loss 0.347762                                        LR 0.000063    Time 0.094265    
2024-02-17 13:53:09,952 - Epoch: [244][  400/  500]    Overall Loss 0.350041    Objective Loss 0.350041                                        LR 0.000063    Time 0.092551    
2024-02-17 13:53:18,933 - Epoch: [244][  500/  500]    Overall Loss 0.350326    Objective Loss 0.350326    Top1 91.500000    Top5 100.000000    LR 0.000063    Time 0.091995    
2024-02-17 13:53:19,056 - --- validate (epoch=244)-----------
2024-02-17 13:53:19,057 - 10000 samples (100 per mini-batch)
2024-02-17 13:53:24,879 - Epoch: [244][  100/  100]    Loss 1.602397    Top1 59.790000    Top5 85.930000    
2024-02-17 13:53:25,001 - ==> Top1: 59.790    Top5: 85.930    Loss: 1.602

2024-02-17 13:53:25,010 - ==> Best [Top1: 60.210   Top5: 85.790   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:53:25,010 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:53:25,061 - 

2024-02-17 13:53:25,062 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:53:34,820 - Epoch: [245][  100/  500]    Overall Loss 0.339598    Objective Loss 0.339598                                        LR 0.000063    Time 0.097510    
2024-02-17 13:53:43,991 - Epoch: [245][  200/  500]    Overall Loss 0.346275    Objective Loss 0.346275                                        LR 0.000063    Time 0.094592    
2024-02-17 13:53:53,063 - Epoch: [245][  300/  500]    Overall Loss 0.349118    Objective Loss 0.349118                                        LR 0.000063    Time 0.093288    
2024-02-17 13:54:02,212 - Epoch: [245][  400/  500]    Overall Loss 0.350641    Objective Loss 0.350641                                        LR 0.000063    Time 0.092829    
2024-02-17 13:54:11,448 - Epoch: [245][  500/  500]    Overall Loss 0.352650    Objective Loss 0.352650    Top1 95.500000    Top5 99.500000    LR 0.000063    Time 0.092728    
2024-02-17 13:54:11,624 - --- validate (epoch=245)-----------
2024-02-17 13:54:11,625 - 10000 samples (100 per mini-batch)
2024-02-17 13:54:17,536 - Epoch: [245][  100/  100]    Loss 1.605249    Top1 59.520000    Top5 85.710000    
2024-02-17 13:54:17,712 - ==> Top1: 59.520    Top5: 85.710    Loss: 1.605

2024-02-17 13:54:17,724 - ==> Best [Top1: 60.210   Top5: 85.790   Sparsity:0.00   Params: 753952 on epoch: 234]
2024-02-17 13:54:17,725 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:54:17,776 - 

2024-02-17 13:54:17,776 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:54:27,794 - Epoch: [246][  100/  500]    Overall Loss 0.344257    Objective Loss 0.344257                                        LR 0.000063    Time 0.100124    
2024-02-17 13:54:36,982 - Epoch: [246][  200/  500]    Overall Loss 0.347975    Objective Loss 0.347975                                        LR 0.000063    Time 0.095986    
2024-02-17 13:54:46,277 - Epoch: [246][  300/  500]    Overall Loss 0.348506    Objective Loss 0.348506                                        LR 0.000063    Time 0.094959    
2024-02-17 13:54:55,139 - Epoch: [246][  400/  500]    Overall Loss 0.350638    Objective Loss 0.350638                                        LR 0.000063    Time 0.093366    
2024-02-17 13:55:04,296 - Epoch: [246][  500/  500]    Overall Loss 0.351921    Objective Loss 0.351921    Top1 94.500000    Top5 99.500000    LR 0.000063    Time 0.093000    
2024-02-17 13:55:04,415 - --- validate (epoch=246)-----------
2024-02-17 13:55:04,416 - 10000 samples (100 per mini-batch)
2024-02-17 13:55:10,215 - Epoch: [246][  100/  100]    Loss 1.601975    Top1 60.210000    Top5 85.860000    
2024-02-17 13:55:10,378 - ==> Top1: 60.210    Top5: 85.860    Loss: 1.602

2024-02-17 13:55:10,390 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 13:55:10,390 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:55:10,456 - 

2024-02-17 13:55:10,457 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:55:20,280 - Epoch: [247][  100/  500]    Overall Loss 0.332752    Objective Loss 0.332752                                        LR 0.000063    Time 0.098179    
2024-02-17 13:55:29,330 - Epoch: [247][  200/  500]    Overall Loss 0.333347    Objective Loss 0.333347                                        LR 0.000063    Time 0.094322    
2024-02-17 13:55:38,134 - Epoch: [247][  300/  500]    Overall Loss 0.340589    Objective Loss 0.340589                                        LR 0.000063    Time 0.092215    
2024-02-17 13:55:46,940 - Epoch: [247][  400/  500]    Overall Loss 0.346906    Objective Loss 0.346906                                        LR 0.000063    Time 0.091168    
2024-02-17 13:55:56,160 - Epoch: [247][  500/  500]    Overall Loss 0.349363    Objective Loss 0.349363    Top1 92.500000    Top5 100.000000    LR 0.000063    Time 0.091365    
2024-02-17 13:55:56,365 - --- validate (epoch=247)-----------
2024-02-17 13:55:56,365 - 10000 samples (100 per mini-batch)
2024-02-17 13:56:01,728 - Epoch: [247][  100/  100]    Loss 1.652948    Top1 59.120000    Top5 85.280000    
2024-02-17 13:56:01,880 - ==> Top1: 59.120    Top5: 85.280    Loss: 1.653

2024-02-17 13:56:01,891 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 13:56:01,891 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:56:01,940 - 

2024-02-17 13:56:01,941 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:56:11,765 - Epoch: [248][  100/  500]    Overall Loss 0.331586    Objective Loss 0.331586                                        LR 0.000063    Time 0.098192    
2024-02-17 13:56:20,840 - Epoch: [248][  200/  500]    Overall Loss 0.340838    Objective Loss 0.340838                                        LR 0.000063    Time 0.094451    
2024-02-17 13:56:29,456 - Epoch: [248][  300/  500]    Overall Loss 0.343931    Objective Loss 0.343931                                        LR 0.000063    Time 0.091677    
2024-02-17 13:56:38,160 - Epoch: [248][  400/  500]    Overall Loss 0.345091    Objective Loss 0.345091                                        LR 0.000063    Time 0.090508    
2024-02-17 13:56:47,112 - Epoch: [248][  500/  500]    Overall Loss 0.347848    Objective Loss 0.347848    Top1 94.500000    Top5 99.500000    LR 0.000063    Time 0.090304    
2024-02-17 13:56:47,286 - --- validate (epoch=248)-----------
2024-02-17 13:56:47,287 - 10000 samples (100 per mini-batch)
2024-02-17 13:56:52,843 - Epoch: [248][  100/  100]    Loss 1.622888    Top1 59.890000    Top5 85.920000    
2024-02-17 13:56:52,943 - ==> Top1: 59.890    Top5: 85.920    Loss: 1.623

2024-02-17 13:56:52,952 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 13:56:52,952 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:56:53,004 - 

2024-02-17 13:56:53,004 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:57:02,495 - Epoch: [249][  100/  500]    Overall Loss 0.331153    Objective Loss 0.331153                                        LR 0.000063    Time 0.094864    
2024-02-17 13:57:11,541 - Epoch: [249][  200/  500]    Overall Loss 0.341420    Objective Loss 0.341420                                        LR 0.000063    Time 0.092639    
2024-02-17 13:57:20,747 - Epoch: [249][  300/  500]    Overall Loss 0.340586    Objective Loss 0.340586                                        LR 0.000063    Time 0.092436    
2024-02-17 13:57:29,901 - Epoch: [249][  400/  500]    Overall Loss 0.343007    Objective Loss 0.343007                                        LR 0.000063    Time 0.092203    
2024-02-17 13:57:39,183 - Epoch: [249][  500/  500]    Overall Loss 0.345505    Objective Loss 0.345505    Top1 93.000000    Top5 99.500000    LR 0.000063    Time 0.092317    
2024-02-17 13:57:39,323 - --- validate (epoch=249)-----------
2024-02-17 13:57:39,324 - 10000 samples (100 per mini-batch)
2024-02-17 13:57:44,753 - Epoch: [249][  100/  100]    Loss 1.631932    Top1 59.700000    Top5 85.340000    
2024-02-17 13:57:44,862 - ==> Top1: 59.700    Top5: 85.340    Loss: 1.632

2024-02-17 13:57:44,875 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 13:57:44,876 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:57:44,925 - 

2024-02-17 13:57:44,925 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:57:54,962 - Epoch: [250][  100/  500]    Overall Loss 0.331972    Objective Loss 0.331972                                        LR 0.000063    Time 0.100314    
2024-02-17 13:58:04,146 - Epoch: [250][  200/  500]    Overall Loss 0.341715    Objective Loss 0.341715                                        LR 0.000063    Time 0.096059    
2024-02-17 13:58:13,328 - Epoch: [250][  300/  500]    Overall Loss 0.344009    Objective Loss 0.344009                                        LR 0.000063    Time 0.094636    
2024-02-17 13:58:22,640 - Epoch: [250][  400/  500]    Overall Loss 0.344829    Objective Loss 0.344829                                        LR 0.000063    Time 0.094248    
2024-02-17 13:58:31,565 - Epoch: [250][  500/  500]    Overall Loss 0.345127    Objective Loss 0.345127    Top1 92.000000    Top5 99.000000    LR 0.000063    Time 0.093240    
2024-02-17 13:58:31,692 - --- validate (epoch=250)-----------
2024-02-17 13:58:31,693 - 10000 samples (100 per mini-batch)
2024-02-17 13:58:37,339 - Epoch: [250][  100/  100]    Loss 1.619728    Top1 59.600000    Top5 85.940000    
2024-02-17 13:58:37,451 - ==> Top1: 59.600    Top5: 85.940    Loss: 1.620

2024-02-17 13:58:37,462 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 13:58:37,462 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:58:37,523 - 

2024-02-17 13:58:37,524 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:58:46,965 - Epoch: [251][  100/  500]    Overall Loss 0.334117    Objective Loss 0.334117                                        LR 0.000063    Time 0.094368    
2024-02-17 13:58:56,052 - Epoch: [251][  200/  500]    Overall Loss 0.337987    Objective Loss 0.337987                                        LR 0.000063    Time 0.092601    
2024-02-17 13:59:05,090 - Epoch: [251][  300/  500]    Overall Loss 0.341069    Objective Loss 0.341069                                        LR 0.000063    Time 0.091848    
2024-02-17 13:59:14,302 - Epoch: [251][  400/  500]    Overall Loss 0.341414    Objective Loss 0.341414                                        LR 0.000063    Time 0.091904    
2024-02-17 13:59:23,708 - Epoch: [251][  500/  500]    Overall Loss 0.342648    Objective Loss 0.342648    Top1 92.500000    Top5 99.500000    LR 0.000063    Time 0.092327    
2024-02-17 13:59:23,848 - --- validate (epoch=251)-----------
2024-02-17 13:59:23,849 - 10000 samples (100 per mini-batch)
2024-02-17 13:59:29,757 - Epoch: [251][  100/  100]    Loss 1.645856    Top1 59.960000    Top5 85.600000    
2024-02-17 13:59:29,929 - ==> Top1: 59.960    Top5: 85.600    Loss: 1.646

2024-02-17 13:59:29,939 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 13:59:29,939 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 13:59:29,992 - 

2024-02-17 13:59:29,993 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 13:59:39,753 - Epoch: [252][  100/  500]    Overall Loss 0.332145    Objective Loss 0.332145                                        LR 0.000063    Time 0.097547    
2024-02-17 13:59:48,870 - Epoch: [252][  200/  500]    Overall Loss 0.336864    Objective Loss 0.336864                                        LR 0.000063    Time 0.094343    
2024-02-17 13:59:57,998 - Epoch: [252][  300/  500]    Overall Loss 0.339258    Objective Loss 0.339258                                        LR 0.000063    Time 0.093308    
2024-02-17 14:00:07,283 - Epoch: [252][  400/  500]    Overall Loss 0.343324    Objective Loss 0.343324                                        LR 0.000063    Time 0.093182    
2024-02-17 14:00:16,660 - Epoch: [252][  500/  500]    Overall Loss 0.343514    Objective Loss 0.343514    Top1 91.000000    Top5 100.000000    LR 0.000063    Time 0.093291    
2024-02-17 14:00:16,825 - --- validate (epoch=252)-----------
2024-02-17 14:00:16,825 - 10000 samples (100 per mini-batch)
2024-02-17 14:00:22,222 - Epoch: [252][  100/  100]    Loss 1.643515    Top1 59.540000    Top5 85.530000    
2024-02-17 14:00:22,370 - ==> Top1: 59.540    Top5: 85.530    Loss: 1.644

2024-02-17 14:00:22,380 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:00:22,380 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:00:22,653 - 

2024-02-17 14:00:22,654 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:00:32,655 - Epoch: [253][  100/  500]    Overall Loss 0.331462    Objective Loss 0.331462                                        LR 0.000063    Time 0.099955    
2024-02-17 14:00:41,995 - Epoch: [253][  200/  500]    Overall Loss 0.333643    Objective Loss 0.333643                                        LR 0.000063    Time 0.096657    
2024-02-17 14:00:51,105 - Epoch: [253][  300/  500]    Overall Loss 0.334613    Objective Loss 0.334613                                        LR 0.000063    Time 0.094795    
2024-02-17 14:01:00,273 - Epoch: [253][  400/  500]    Overall Loss 0.337920    Objective Loss 0.337920                                        LR 0.000063    Time 0.094005    
2024-02-17 14:01:09,519 - Epoch: [253][  500/  500]    Overall Loss 0.336223    Objective Loss 0.336223    Top1 93.000000    Top5 100.000000    LR 0.000063    Time 0.093690    
2024-02-17 14:01:09,680 - --- validate (epoch=253)-----------
2024-02-17 14:01:09,681 - 10000 samples (100 per mini-batch)
2024-02-17 14:01:15,096 - Epoch: [253][  100/  100]    Loss 1.639505    Top1 59.160000    Top5 85.950000    
2024-02-17 14:01:15,255 - ==> Top1: 59.160    Top5: 85.950    Loss: 1.640

2024-02-17 14:01:15,263 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:01:15,263 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:01:15,331 - 

2024-02-17 14:01:15,332 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:01:25,364 - Epoch: [254][  100/  500]    Overall Loss 0.330170    Objective Loss 0.330170                                        LR 0.000063    Time 0.100276    
2024-02-17 14:01:34,424 - Epoch: [254][  200/  500]    Overall Loss 0.332225    Objective Loss 0.332225                                        LR 0.000063    Time 0.095417    
2024-02-17 14:01:43,467 - Epoch: [254][  300/  500]    Overall Loss 0.334258    Objective Loss 0.334258                                        LR 0.000063    Time 0.093744    
2024-02-17 14:01:52,686 - Epoch: [254][  400/  500]    Overall Loss 0.337880    Objective Loss 0.337880                                        LR 0.000063    Time 0.093347    
2024-02-17 14:02:01,920 - Epoch: [254][  500/  500]    Overall Loss 0.340866    Objective Loss 0.340866    Top1 93.000000    Top5 99.500000    LR 0.000063    Time 0.093138    
2024-02-17 14:02:02,084 - --- validate (epoch=254)-----------
2024-02-17 14:02:02,085 - 10000 samples (100 per mini-batch)
2024-02-17 14:02:07,589 - Epoch: [254][  100/  100]    Loss 1.633448    Top1 59.750000    Top5 85.830000    
2024-02-17 14:02:07,749 - ==> Top1: 59.750    Top5: 85.830    Loss: 1.633

2024-02-17 14:02:07,763 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:02:07,763 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:02:07,815 - 

2024-02-17 14:02:07,815 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:02:17,551 - Epoch: [255][  100/  500]    Overall Loss 0.334513    Objective Loss 0.334513                                        LR 0.000063    Time 0.097308    
2024-02-17 14:02:26,892 - Epoch: [255][  200/  500]    Overall Loss 0.335560    Objective Loss 0.335560                                        LR 0.000063    Time 0.095341    
2024-02-17 14:02:36,107 - Epoch: [255][  300/  500]    Overall Loss 0.338616    Objective Loss 0.338616                                        LR 0.000063    Time 0.094263    
2024-02-17 14:02:45,512 - Epoch: [255][  400/  500]    Overall Loss 0.337330    Objective Loss 0.337330                                        LR 0.000063    Time 0.094201    
2024-02-17 14:02:54,763 - Epoch: [255][  500/  500]    Overall Loss 0.337991    Objective Loss 0.337991    Top1 92.500000    Top5 99.500000    LR 0.000063    Time 0.093855    
2024-02-17 14:02:54,982 - --- validate (epoch=255)-----------
2024-02-17 14:02:54,983 - 10000 samples (100 per mini-batch)
2024-02-17 14:03:00,532 - Epoch: [255][  100/  100]    Loss 1.633615    Top1 59.930000    Top5 85.860000    
2024-02-17 14:03:00,650 - ==> Top1: 59.930    Top5: 85.860    Loss: 1.634

2024-02-17 14:03:00,661 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:03:00,662 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:03:00,714 - 

2024-02-17 14:03:00,714 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:03:10,283 - Epoch: [256][  100/  500]    Overall Loss 0.316030    Objective Loss 0.316030                                        LR 0.000063    Time 0.095644    
2024-02-17 14:03:19,336 - Epoch: [256][  200/  500]    Overall Loss 0.324300    Objective Loss 0.324300                                        LR 0.000063    Time 0.093067    
2024-02-17 14:03:28,447 - Epoch: [256][  300/  500]    Overall Loss 0.331682    Objective Loss 0.331682                                        LR 0.000063    Time 0.092402    
2024-02-17 14:03:37,592 - Epoch: [256][  400/  500]    Overall Loss 0.331892    Objective Loss 0.331892                                        LR 0.000063    Time 0.092156    
2024-02-17 14:03:46,753 - Epoch: [256][  500/  500]    Overall Loss 0.335062    Objective Loss 0.335062    Top1 91.500000    Top5 100.000000    LR 0.000063    Time 0.092039    
2024-02-17 14:03:46,965 - --- validate (epoch=256)-----------
2024-02-17 14:03:46,965 - 10000 samples (100 per mini-batch)
2024-02-17 14:03:53,653 - Epoch: [256][  100/  100]    Loss 1.642246    Top1 59.900000    Top5 85.890000    
2024-02-17 14:03:53,799 - ==> Top1: 59.900    Top5: 85.890    Loss: 1.642

2024-02-17 14:03:53,810 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:03:53,810 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:03:53,860 - 

2024-02-17 14:03:53,861 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:04:03,825 - Epoch: [257][  100/  500]    Overall Loss 0.330043    Objective Loss 0.330043                                        LR 0.000063    Time 0.099588    
2024-02-17 14:04:12,908 - Epoch: [257][  200/  500]    Overall Loss 0.330762    Objective Loss 0.330762                                        LR 0.000063    Time 0.095189    
2024-02-17 14:04:22,070 - Epoch: [257][  300/  500]    Overall Loss 0.333891    Objective Loss 0.333891                                        LR 0.000063    Time 0.093989    
2024-02-17 14:04:31,121 - Epoch: [257][  400/  500]    Overall Loss 0.335550    Objective Loss 0.335550                                        LR 0.000063    Time 0.093108    
2024-02-17 14:04:40,476 - Epoch: [257][  500/  500]    Overall Loss 0.337184    Objective Loss 0.337184    Top1 91.000000    Top5 99.500000    LR 0.000063    Time 0.093189    
2024-02-17 14:04:40,613 - --- validate (epoch=257)-----------
2024-02-17 14:04:40,614 - 10000 samples (100 per mini-batch)
2024-02-17 14:04:46,154 - Epoch: [257][  100/  100]    Loss 1.622859    Top1 59.770000    Top5 85.880000    
2024-02-17 14:04:46,273 - ==> Top1: 59.770    Top5: 85.880    Loss: 1.623

2024-02-17 14:04:46,284 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:04:46,284 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:04:46,340 - 

2024-02-17 14:04:46,341 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:04:56,068 - Epoch: [258][  100/  500]    Overall Loss 0.325371    Objective Loss 0.325371                                        LR 0.000063    Time 0.097221    
2024-02-17 14:05:05,181 - Epoch: [258][  200/  500]    Overall Loss 0.332114    Objective Loss 0.332114                                        LR 0.000063    Time 0.094156    
2024-02-17 14:05:14,413 - Epoch: [258][  300/  500]    Overall Loss 0.329920    Objective Loss 0.329920                                        LR 0.000063    Time 0.093531    
2024-02-17 14:05:23,568 - Epoch: [258][  400/  500]    Overall Loss 0.330781    Objective Loss 0.330781                                        LR 0.000063    Time 0.093025    
2024-02-17 14:05:32,944 - Epoch: [258][  500/  500]    Overall Loss 0.335204    Objective Loss 0.335204    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.093165    
2024-02-17 14:05:33,074 - --- validate (epoch=258)-----------
2024-02-17 14:05:33,075 - 10000 samples (100 per mini-batch)
2024-02-17 14:05:38,770 - Epoch: [258][  100/  100]    Loss 1.631463    Top1 59.970000    Top5 85.690000    
2024-02-17 14:05:38,909 - ==> Top1: 59.970    Top5: 85.690    Loss: 1.631

2024-02-17 14:05:38,921 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:05:38,921 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:05:38,973 - 

2024-02-17 14:05:38,974 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:05:48,589 - Epoch: [259][  100/  500]    Overall Loss 0.317306    Objective Loss 0.317306                                        LR 0.000063    Time 0.096104    
2024-02-17 14:05:57,371 - Epoch: [259][  200/  500]    Overall Loss 0.325772    Objective Loss 0.325772                                        LR 0.000063    Time 0.091943    
2024-02-17 14:06:06,589 - Epoch: [259][  300/  500]    Overall Loss 0.328648    Objective Loss 0.328648                                        LR 0.000063    Time 0.092011    
2024-02-17 14:06:15,562 - Epoch: [259][  400/  500]    Overall Loss 0.331416    Objective Loss 0.331416                                        LR 0.000063    Time 0.091431    
2024-02-17 14:06:24,631 - Epoch: [259][  500/  500]    Overall Loss 0.332789    Objective Loss 0.332789    Top1 91.500000    Top5 99.500000    LR 0.000063    Time 0.091275    
2024-02-17 14:06:24,785 - --- validate (epoch=259)-----------
2024-02-17 14:06:24,787 - 10000 samples (100 per mini-batch)
2024-02-17 14:06:30,967 - Epoch: [259][  100/  100]    Loss 1.650644    Top1 58.950000    Top5 85.590000    
2024-02-17 14:06:31,105 - ==> Top1: 58.950    Top5: 85.590    Loss: 1.651

2024-02-17 14:06:31,114 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:06:31,115 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:06:31,159 - 

2024-02-17 14:06:31,160 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:06:41,116 - Epoch: [260][  100/  500]    Overall Loss 0.327695    Objective Loss 0.327695                                        LR 0.000063    Time 0.099511    
2024-02-17 14:06:49,796 - Epoch: [260][  200/  500]    Overall Loss 0.329370    Objective Loss 0.329370                                        LR 0.000063    Time 0.093136    
2024-02-17 14:06:58,462 - Epoch: [260][  300/  500]    Overall Loss 0.333004    Objective Loss 0.333004                                        LR 0.000063    Time 0.090968    
2024-02-17 14:07:07,599 - Epoch: [260][  400/  500]    Overall Loss 0.335207    Objective Loss 0.335207                                        LR 0.000063    Time 0.091057    
2024-02-17 14:07:16,600 - Epoch: [260][  500/  500]    Overall Loss 0.333771    Objective Loss 0.333771    Top1 94.500000    Top5 99.500000    LR 0.000063    Time 0.090842    
2024-02-17 14:07:16,716 - --- validate (epoch=260)-----------
2024-02-17 14:07:16,716 - 10000 samples (100 per mini-batch)
2024-02-17 14:07:22,229 - Epoch: [260][  100/  100]    Loss 1.642832    Top1 59.770000    Top5 85.600000    
2024-02-17 14:07:22,342 - ==> Top1: 59.770    Top5: 85.600    Loss: 1.643

2024-02-17 14:07:22,351 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:07:22,351 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:07:22,408 - 

2024-02-17 14:07:22,409 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:07:32,252 - Epoch: [261][  100/  500]    Overall Loss 0.331821    Objective Loss 0.331821                                        LR 0.000063    Time 0.098383    
2024-02-17 14:07:41,553 - Epoch: [261][  200/  500]    Overall Loss 0.329595    Objective Loss 0.329595                                        LR 0.000063    Time 0.095677    
2024-02-17 14:07:50,787 - Epoch: [261][  300/  500]    Overall Loss 0.327539    Objective Loss 0.327539                                        LR 0.000063    Time 0.094551    
2024-02-17 14:07:59,804 - Epoch: [261][  400/  500]    Overall Loss 0.328360    Objective Loss 0.328360                                        LR 0.000063    Time 0.093445    
2024-02-17 14:08:08,757 - Epoch: [261][  500/  500]    Overall Loss 0.330114    Objective Loss 0.330114    Top1 94.500000    Top5 100.000000    LR 0.000063    Time 0.092655    
2024-02-17 14:08:08,903 - --- validate (epoch=261)-----------
2024-02-17 14:08:08,904 - 10000 samples (100 per mini-batch)
2024-02-17 14:08:14,355 - Epoch: [261][  100/  100]    Loss 1.624710    Top1 59.850000    Top5 85.730000    
2024-02-17 14:08:14,546 - ==> Top1: 59.850    Top5: 85.730    Loss: 1.625

2024-02-17 14:08:14,556 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:08:14,557 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:08:14,609 - 

2024-02-17 14:08:14,609 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:08:23,894 - Epoch: [262][  100/  500]    Overall Loss 0.318550    Objective Loss 0.318550                                        LR 0.000063    Time 0.092796    
2024-02-17 14:08:32,907 - Epoch: [262][  200/  500]    Overall Loss 0.321525    Objective Loss 0.321525                                        LR 0.000063    Time 0.091447    
2024-02-17 14:08:41,987 - Epoch: [262][  300/  500]    Overall Loss 0.325660    Objective Loss 0.325660                                        LR 0.000063    Time 0.091219    
2024-02-17 14:08:51,090 - Epoch: [262][  400/  500]    Overall Loss 0.328182    Objective Loss 0.328182                                        LR 0.000063    Time 0.091163    
2024-02-17 14:09:00,187 - Epoch: [262][  500/  500]    Overall Loss 0.330879    Objective Loss 0.330879    Top1 83.500000    Top5 100.000000    LR 0.000063    Time 0.091116    
2024-02-17 14:09:00,340 - --- validate (epoch=262)-----------
2024-02-17 14:09:00,341 - 10000 samples (100 per mini-batch)
2024-02-17 14:09:06,671 - Epoch: [262][  100/  100]    Loss 1.662917    Top1 59.370000    Top5 85.580000    
2024-02-17 14:09:06,793 - ==> Top1: 59.370    Top5: 85.580    Loss: 1.663

2024-02-17 14:09:06,803 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:09:06,804 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:09:06,861 - 

2024-02-17 14:09:06,861 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:09:16,826 - Epoch: [263][  100/  500]    Overall Loss 0.326958    Objective Loss 0.326958                                        LR 0.000063    Time 0.099584    
2024-02-17 14:09:26,452 - Epoch: [263][  200/  500]    Overall Loss 0.330873    Objective Loss 0.330873                                        LR 0.000063    Time 0.097901    
2024-02-17 14:09:35,669 - Epoch: [263][  300/  500]    Overall Loss 0.330221    Objective Loss 0.330221                                        LR 0.000063    Time 0.095978    
2024-02-17 14:09:44,832 - Epoch: [263][  400/  500]    Overall Loss 0.332586    Objective Loss 0.332586                                        LR 0.000063    Time 0.094883    
2024-02-17 14:09:53,908 - Epoch: [263][  500/  500]    Overall Loss 0.332194    Objective Loss 0.332194    Top1 95.000000    Top5 100.000000    LR 0.000063    Time 0.094051    
2024-02-17 14:09:54,056 - --- validate (epoch=263)-----------
2024-02-17 14:09:54,057 - 10000 samples (100 per mini-batch)
2024-02-17 14:09:59,879 - Epoch: [263][  100/  100]    Loss 1.630701    Top1 59.510000    Top5 85.860000    
2024-02-17 14:10:00,013 - ==> Top1: 59.510    Top5: 85.860    Loss: 1.631

2024-02-17 14:10:00,023 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:10:00,024 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:10:00,088 - 

2024-02-17 14:10:00,088 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:10:09,880 - Epoch: [264][  100/  500]    Overall Loss 0.318442    Objective Loss 0.318442                                        LR 0.000063    Time 0.097866    
2024-02-17 14:10:19,122 - Epoch: [264][  200/  500]    Overall Loss 0.318028    Objective Loss 0.318028                                        LR 0.000063    Time 0.095125    
2024-02-17 14:10:28,409 - Epoch: [264][  300/  500]    Overall Loss 0.323428    Objective Loss 0.323428                                        LR 0.000063    Time 0.094358    
2024-02-17 14:10:37,637 - Epoch: [264][  400/  500]    Overall Loss 0.325919    Objective Loss 0.325919                                        LR 0.000063    Time 0.093829    
2024-02-17 14:10:46,743 - Epoch: [264][  500/  500]    Overall Loss 0.327836    Objective Loss 0.327836    Top1 91.500000    Top5 99.500000    LR 0.000063    Time 0.093268    
2024-02-17 14:10:46,879 - --- validate (epoch=264)-----------
2024-02-17 14:10:46,880 - 10000 samples (100 per mini-batch)
2024-02-17 14:10:52,625 - Epoch: [264][  100/  100]    Loss 1.649169    Top1 59.650000    Top5 85.600000    
2024-02-17 14:10:52,728 - ==> Top1: 59.650    Top5: 85.600    Loss: 1.649

2024-02-17 14:10:52,741 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:10:52,741 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:10:52,793 - 

2024-02-17 14:10:52,793 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:11:02,620 - Epoch: [265][  100/  500]    Overall Loss 0.317598    Objective Loss 0.317598                                        LR 0.000063    Time 0.098223    
2024-02-17 14:11:11,733 - Epoch: [265][  200/  500]    Overall Loss 0.320087    Objective Loss 0.320087                                        LR 0.000063    Time 0.094656    
2024-02-17 14:11:20,880 - Epoch: [265][  300/  500]    Overall Loss 0.324163    Objective Loss 0.324163                                        LR 0.000063    Time 0.093579    
2024-02-17 14:11:29,853 - Epoch: [265][  400/  500]    Overall Loss 0.323577    Objective Loss 0.323577                                        LR 0.000063    Time 0.092609    
2024-02-17 14:11:38,687 - Epoch: [265][  500/  500]    Overall Loss 0.325238    Objective Loss 0.325238    Top1 94.500000    Top5 100.000000    LR 0.000063    Time 0.091748    
2024-02-17 14:11:38,825 - --- validate (epoch=265)-----------
2024-02-17 14:11:38,826 - 10000 samples (100 per mini-batch)
2024-02-17 14:11:44,019 - Epoch: [265][  100/  100]    Loss 1.661510    Top1 59.330000    Top5 85.670000    
2024-02-17 14:11:44,108 - ==> Top1: 59.330    Top5: 85.670    Loss: 1.662

2024-02-17 14:11:44,117 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:11:44,117 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:11:44,162 - 

2024-02-17 14:11:44,162 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:11:54,037 - Epoch: [266][  100/  500]    Overall Loss 0.318224    Objective Loss 0.318224                                        LR 0.000063    Time 0.098703    
2024-02-17 14:12:02,702 - Epoch: [266][  200/  500]    Overall Loss 0.314281    Objective Loss 0.314281                                        LR 0.000063    Time 0.092659    
2024-02-17 14:12:11,753 - Epoch: [266][  300/  500]    Overall Loss 0.318854    Objective Loss 0.318854                                        LR 0.000063    Time 0.091930    
2024-02-17 14:12:20,381 - Epoch: [266][  400/  500]    Overall Loss 0.325551    Objective Loss 0.325551                                        LR 0.000063    Time 0.090511    
2024-02-17 14:12:29,367 - Epoch: [266][  500/  500]    Overall Loss 0.328366    Objective Loss 0.328366    Top1 88.500000    Top5 99.000000    LR 0.000063    Time 0.090373    
2024-02-17 14:12:29,492 - --- validate (epoch=266)-----------
2024-02-17 14:12:29,493 - 10000 samples (100 per mini-batch)
2024-02-17 14:12:35,056 - Epoch: [266][  100/  100]    Loss 1.662021    Top1 59.200000    Top5 85.650000    
2024-02-17 14:12:35,170 - ==> Top1: 59.200    Top5: 85.650    Loss: 1.662

2024-02-17 14:12:35,180 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:12:35,180 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:12:35,230 - 

2024-02-17 14:12:35,230 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:12:44,227 - Epoch: [267][  100/  500]    Overall Loss 0.322608    Objective Loss 0.322608                                        LR 0.000063    Time 0.089922    
2024-02-17 14:12:53,038 - Epoch: [267][  200/  500]    Overall Loss 0.319587    Objective Loss 0.319587                                        LR 0.000063    Time 0.089001    
2024-02-17 14:13:02,230 - Epoch: [267][  300/  500]    Overall Loss 0.324112    Objective Loss 0.324112                                        LR 0.000063    Time 0.089960    
2024-02-17 14:13:11,277 - Epoch: [267][  400/  500]    Overall Loss 0.326440    Objective Loss 0.326440                                        LR 0.000063    Time 0.090079    
2024-02-17 14:13:20,460 - Epoch: [267][  500/  500]    Overall Loss 0.325142    Objective Loss 0.325142    Top1 93.000000    Top5 100.000000    LR 0.000063    Time 0.090420    
2024-02-17 14:13:20,615 - --- validate (epoch=267)-----------
2024-02-17 14:13:20,616 - 10000 samples (100 per mini-batch)
2024-02-17 14:13:26,422 - Epoch: [267][  100/  100]    Loss 1.678092    Top1 58.960000    Top5 85.420000    
2024-02-17 14:13:26,520 - ==> Top1: 58.960    Top5: 85.420    Loss: 1.678

2024-02-17 14:13:26,529 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:13:26,529 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:13:26,584 - 

2024-02-17 14:13:26,584 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:13:36,677 - Epoch: [268][  100/  500]    Overall Loss 0.318040    Objective Loss 0.318040                                        LR 0.000063    Time 0.100868    
2024-02-17 14:13:45,797 - Epoch: [268][  200/  500]    Overall Loss 0.317125    Objective Loss 0.317125                                        LR 0.000063    Time 0.096015    
2024-02-17 14:13:55,186 - Epoch: [268][  300/  500]    Overall Loss 0.321165    Objective Loss 0.321165                                        LR 0.000063    Time 0.095291    
2024-02-17 14:14:04,093 - Epoch: [268][  400/  500]    Overall Loss 0.320034    Objective Loss 0.320034                                        LR 0.000063    Time 0.093726    
2024-02-17 14:14:13,064 - Epoch: [268][  500/  500]    Overall Loss 0.321571    Objective Loss 0.321571    Top1 94.500000    Top5 100.000000    LR 0.000063    Time 0.092915    
2024-02-17 14:14:13,181 - --- validate (epoch=268)-----------
2024-02-17 14:14:13,182 - 10000 samples (100 per mini-batch)
2024-02-17 14:14:18,721 - Epoch: [268][  100/  100]    Loss 1.637682    Top1 59.570000    Top5 86.110000    
2024-02-17 14:14:18,836 - ==> Top1: 59.570    Top5: 86.110    Loss: 1.638

2024-02-17 14:14:18,847 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:14:18,847 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:14:18,916 - 

2024-02-17 14:14:18,916 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:14:28,698 - Epoch: [269][  100/  500]    Overall Loss 0.314973    Objective Loss 0.314973                                        LR 0.000063    Time 0.097726    
2024-02-17 14:14:37,711 - Epoch: [269][  200/  500]    Overall Loss 0.316822    Objective Loss 0.316822                                        LR 0.000063    Time 0.093906    
2024-02-17 14:14:45,967 - Epoch: [269][  300/  500]    Overall Loss 0.319818    Objective Loss 0.319818                                        LR 0.000063    Time 0.090115    
2024-02-17 14:14:54,565 - Epoch: [269][  400/  500]    Overall Loss 0.322626    Objective Loss 0.322626                                        LR 0.000063    Time 0.089075    
2024-02-17 14:15:03,876 - Epoch: [269][  500/  500]    Overall Loss 0.324344    Objective Loss 0.324344    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.089873    
2024-02-17 14:15:04,007 - --- validate (epoch=269)-----------
2024-02-17 14:15:04,008 - 10000 samples (100 per mini-batch)
2024-02-17 14:15:09,913 - Epoch: [269][  100/  100]    Loss 1.677973    Top1 59.420000    Top5 85.480000    
2024-02-17 14:15:10,036 - ==> Top1: 59.420    Top5: 85.480    Loss: 1.678

2024-02-17 14:15:10,045 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:15:10,046 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:15:10,107 - 

2024-02-17 14:15:10,107 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:15:19,712 - Epoch: [270][  100/  500]    Overall Loss 0.310452    Objective Loss 0.310452                                        LR 0.000063    Time 0.095990    
2024-02-17 14:15:28,873 - Epoch: [270][  200/  500]    Overall Loss 0.316036    Objective Loss 0.316036                                        LR 0.000063    Time 0.093779    
2024-02-17 14:15:37,898 - Epoch: [270][  300/  500]    Overall Loss 0.319439    Objective Loss 0.319439                                        LR 0.000063    Time 0.092589    
2024-02-17 14:15:47,053 - Epoch: [270][  400/  500]    Overall Loss 0.320717    Objective Loss 0.320717                                        LR 0.000063    Time 0.092319    
2024-02-17 14:15:55,995 - Epoch: [270][  500/  500]    Overall Loss 0.321191    Objective Loss 0.321191    Top1 91.000000    Top5 100.000000    LR 0.000063    Time 0.091732    
2024-02-17 14:15:56,100 - --- validate (epoch=270)-----------
2024-02-17 14:15:56,101 - 10000 samples (100 per mini-batch)
2024-02-17 14:16:01,797 - Epoch: [270][  100/  100]    Loss 1.645448    Top1 59.440000    Top5 85.700000    
2024-02-17 14:16:01,912 - ==> Top1: 59.440    Top5: 85.700    Loss: 1.645

2024-02-17 14:16:01,920 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:16:01,921 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:16:01,972 - 

2024-02-17 14:16:01,973 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:16:11,612 - Epoch: [271][  100/  500]    Overall Loss 0.313599    Objective Loss 0.313599                                        LR 0.000063    Time 0.096339    
2024-02-17 14:16:20,764 - Epoch: [271][  200/  500]    Overall Loss 0.318174    Objective Loss 0.318174                                        LR 0.000063    Time 0.093908    
2024-02-17 14:16:29,838 - Epoch: [271][  300/  500]    Overall Loss 0.318219    Objective Loss 0.318219                                        LR 0.000063    Time 0.092839    
2024-02-17 14:16:38,910 - Epoch: [271][  400/  500]    Overall Loss 0.321407    Objective Loss 0.321407                                        LR 0.000063    Time 0.092299    
2024-02-17 14:16:47,877 - Epoch: [271][  500/  500]    Overall Loss 0.322590    Objective Loss 0.322590    Top1 92.000000    Top5 99.500000    LR 0.000063    Time 0.091764    
2024-02-17 14:16:48,027 - --- validate (epoch=271)-----------
2024-02-17 14:16:48,027 - 10000 samples (100 per mini-batch)
2024-02-17 14:16:53,351 - Epoch: [271][  100/  100]    Loss 1.683558    Top1 59.340000    Top5 85.440000    
2024-02-17 14:16:53,447 - ==> Top1: 59.340    Top5: 85.440    Loss: 1.684

2024-02-17 14:16:53,457 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:16:53,457 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:16:53,503 - 

2024-02-17 14:16:53,503 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:17:03,313 - Epoch: [272][  100/  500]    Overall Loss 0.310465    Objective Loss 0.310465                                        LR 0.000063    Time 0.098053    
2024-02-17 14:17:12,546 - Epoch: [272][  200/  500]    Overall Loss 0.307598    Objective Loss 0.307598                                        LR 0.000063    Time 0.095169    
2024-02-17 14:17:21,559 - Epoch: [272][  300/  500]    Overall Loss 0.312143    Objective Loss 0.312143                                        LR 0.000063    Time 0.093477    
2024-02-17 14:17:30,533 - Epoch: [272][  400/  500]    Overall Loss 0.313023    Objective Loss 0.313023                                        LR 0.000063    Time 0.092531    
2024-02-17 14:17:39,377 - Epoch: [272][  500/  500]    Overall Loss 0.315239    Objective Loss 0.315239    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.091708    
2024-02-17 14:17:39,500 - --- validate (epoch=272)-----------
2024-02-17 14:17:39,500 - 10000 samples (100 per mini-batch)
2024-02-17 14:17:44,933 - Epoch: [272][  100/  100]    Loss 1.679993    Top1 59.050000    Top5 85.480000    
2024-02-17 14:17:45,050 - ==> Top1: 59.050    Top5: 85.480    Loss: 1.680

2024-02-17 14:17:45,061 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:17:45,062 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:17:45,128 - 

2024-02-17 14:17:45,128 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:17:54,646 - Epoch: [273][  100/  500]    Overall Loss 0.308167    Objective Loss 0.308167                                        LR 0.000063    Time 0.095125    
2024-02-17 14:18:03,762 - Epoch: [273][  200/  500]    Overall Loss 0.312618    Objective Loss 0.312618                                        LR 0.000063    Time 0.093122    
2024-02-17 14:18:12,647 - Epoch: [273][  300/  500]    Overall Loss 0.312267    Objective Loss 0.312267                                        LR 0.000063    Time 0.091684    
2024-02-17 14:18:21,506 - Epoch: [273][  400/  500]    Overall Loss 0.317766    Objective Loss 0.317766                                        LR 0.000063    Time 0.090901    
2024-02-17 14:18:30,486 - Epoch: [273][  500/  500]    Overall Loss 0.318953    Objective Loss 0.318953    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.090674    
2024-02-17 14:18:30,617 - --- validate (epoch=273)-----------
2024-02-17 14:18:30,619 - 10000 samples (100 per mini-batch)
2024-02-17 14:18:36,378 - Epoch: [273][  100/  100]    Loss 1.633636    Top1 59.760000    Top5 85.850000    
2024-02-17 14:18:36,480 - ==> Top1: 59.760    Top5: 85.850    Loss: 1.634

2024-02-17 14:18:36,490 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:18:36,490 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:18:36,544 - 

2024-02-17 14:18:36,545 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:18:46,499 - Epoch: [274][  100/  500]    Overall Loss 0.309627    Objective Loss 0.309627                                        LR 0.000063    Time 0.099485    
2024-02-17 14:18:55,406 - Epoch: [274][  200/  500]    Overall Loss 0.310628    Objective Loss 0.310628                                        LR 0.000063    Time 0.094263    
2024-02-17 14:19:04,483 - Epoch: [274][  300/  500]    Overall Loss 0.317822    Objective Loss 0.317822                                        LR 0.000063    Time 0.093087    
2024-02-17 14:19:13,204 - Epoch: [274][  400/  500]    Overall Loss 0.321222    Objective Loss 0.321222                                        LR 0.000063    Time 0.091609    
2024-02-17 14:19:22,180 - Epoch: [274][  500/  500]    Overall Loss 0.321399    Objective Loss 0.321399    Top1 94.000000    Top5 99.000000    LR 0.000063    Time 0.091232    
2024-02-17 14:19:22,286 - --- validate (epoch=274)-----------
2024-02-17 14:19:22,287 - 10000 samples (100 per mini-batch)
2024-02-17 14:19:28,210 - Epoch: [274][  100/  100]    Loss 1.673430    Top1 59.460000    Top5 85.620000    
2024-02-17 14:19:28,376 - ==> Top1: 59.460    Top5: 85.620    Loss: 1.673

2024-02-17 14:19:28,387 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:19:28,387 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:19:28,438 - 

2024-02-17 14:19:28,439 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:19:38,113 - Epoch: [275][  100/  500]    Overall Loss 0.315900    Objective Loss 0.315900                                        LR 0.000063    Time 0.096693    
2024-02-17 14:19:47,199 - Epoch: [275][  200/  500]    Overall Loss 0.310841    Objective Loss 0.310841                                        LR 0.000063    Time 0.093756    
2024-02-17 14:19:56,273 - Epoch: [275][  300/  500]    Overall Loss 0.310453    Objective Loss 0.310453                                        LR 0.000063    Time 0.092735    
2024-02-17 14:20:05,215 - Epoch: [275][  400/  500]    Overall Loss 0.312025    Objective Loss 0.312025                                        LR 0.000063    Time 0.091898    
2024-02-17 14:20:13,794 - Epoch: [275][  500/  500]    Overall Loss 0.314332    Objective Loss 0.314332    Top1 89.500000    Top5 99.500000    LR 0.000063    Time 0.090670    
2024-02-17 14:20:13,916 - --- validate (epoch=275)-----------
2024-02-17 14:20:13,917 - 10000 samples (100 per mini-batch)
2024-02-17 14:20:19,628 - Epoch: [275][  100/  100]    Loss 1.672244    Top1 59.450000    Top5 85.570000    
2024-02-17 14:20:19,808 - ==> Top1: 59.450    Top5: 85.570    Loss: 1.672

2024-02-17 14:20:19,820 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:20:19,820 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:20:19,870 - 

2024-02-17 14:20:19,871 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:20:29,658 - Epoch: [276][  100/  500]    Overall Loss 0.300050    Objective Loss 0.300050                                        LR 0.000063    Time 0.097809    
2024-02-17 14:20:38,682 - Epoch: [276][  200/  500]    Overall Loss 0.309551    Objective Loss 0.309551                                        LR 0.000063    Time 0.094004    
2024-02-17 14:20:47,585 - Epoch: [276][  300/  500]    Overall Loss 0.309236    Objective Loss 0.309236                                        LR 0.000063    Time 0.092334    
2024-02-17 14:20:56,609 - Epoch: [276][  400/  500]    Overall Loss 0.312820    Objective Loss 0.312820                                        LR 0.000063    Time 0.091800    
2024-02-17 14:21:05,491 - Epoch: [276][  500/  500]    Overall Loss 0.315636    Objective Loss 0.315636    Top1 95.000000    Top5 99.000000    LR 0.000063    Time 0.091198    
2024-02-17 14:21:05,632 - --- validate (epoch=276)-----------
2024-02-17 14:21:05,632 - 10000 samples (100 per mini-batch)
2024-02-17 14:21:11,209 - Epoch: [276][  100/  100]    Loss 1.676353    Top1 59.300000    Top5 85.520000    
2024-02-17 14:21:11,305 - ==> Top1: 59.300    Top5: 85.520    Loss: 1.676

2024-02-17 14:21:11,315 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:21:11,316 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:21:11,366 - 

2024-02-17 14:21:11,366 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:21:21,230 - Epoch: [277][  100/  500]    Overall Loss 0.305720    Objective Loss 0.305720                                        LR 0.000063    Time 0.098588    
2024-02-17 14:21:30,163 - Epoch: [277][  200/  500]    Overall Loss 0.312044    Objective Loss 0.312044                                        LR 0.000063    Time 0.093938    
2024-02-17 14:21:39,159 - Epoch: [277][  300/  500]    Overall Loss 0.314766    Objective Loss 0.314766                                        LR 0.000063    Time 0.092601    
2024-02-17 14:21:48,083 - Epoch: [277][  400/  500]    Overall Loss 0.316566    Objective Loss 0.316566                                        LR 0.000063    Time 0.091752    
2024-02-17 14:21:57,196 - Epoch: [277][  500/  500]    Overall Loss 0.317525    Objective Loss 0.317525    Top1 93.000000    Top5 100.000000    LR 0.000063    Time 0.091619    
2024-02-17 14:21:57,333 - --- validate (epoch=277)-----------
2024-02-17 14:21:57,335 - 10000 samples (100 per mini-batch)
2024-02-17 14:22:02,924 - Epoch: [277][  100/  100]    Loss 1.659990    Top1 59.770000    Top5 85.780000    
2024-02-17 14:22:03,023 - ==> Top1: 59.770    Top5: 85.780    Loss: 1.660

2024-02-17 14:22:03,030 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:22:03,031 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:22:03,078 - 

2024-02-17 14:22:03,079 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:22:12,659 - Epoch: [278][  100/  500]    Overall Loss 0.311146    Objective Loss 0.311146                                        LR 0.000063    Time 0.095754    
2024-02-17 14:22:21,644 - Epoch: [278][  200/  500]    Overall Loss 0.311058    Objective Loss 0.311058                                        LR 0.000063    Time 0.092778    
2024-02-17 14:22:30,689 - Epoch: [278][  300/  500]    Overall Loss 0.309432    Objective Loss 0.309432                                        LR 0.000063    Time 0.091991    
2024-02-17 14:22:39,449 - Epoch: [278][  400/  500]    Overall Loss 0.311579    Objective Loss 0.311579                                        LR 0.000063    Time 0.090884    
2024-02-17 14:22:48,288 - Epoch: [278][  500/  500]    Overall Loss 0.313886    Objective Loss 0.313886    Top1 92.500000    Top5 100.000000    LR 0.000063    Time 0.090379    
2024-02-17 14:22:48,391 - --- validate (epoch=278)-----------
2024-02-17 14:22:48,393 - 10000 samples (100 per mini-batch)
2024-02-17 14:22:54,071 - Epoch: [278][  100/  100]    Loss 1.657423    Top1 59.910000    Top5 85.670000    
2024-02-17 14:22:54,196 - ==> Top1: 59.910    Top5: 85.670    Loss: 1.657

2024-02-17 14:22:54,201 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:22:54,202 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:22:54,247 - 

2024-02-17 14:22:54,247 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:23:03,834 - Epoch: [279][  100/  500]    Overall Loss 0.300178    Objective Loss 0.300178                                        LR 0.000063    Time 0.095817    
2024-02-17 14:23:12,905 - Epoch: [279][  200/  500]    Overall Loss 0.303000    Objective Loss 0.303000                                        LR 0.000063    Time 0.093244    
2024-02-17 14:23:21,982 - Epoch: [279][  300/  500]    Overall Loss 0.306253    Objective Loss 0.306253                                        LR 0.000063    Time 0.092407    
2024-02-17 14:23:30,926 - Epoch: [279][  400/  500]    Overall Loss 0.310467    Objective Loss 0.310467                                        LR 0.000063    Time 0.091656    
2024-02-17 14:23:40,112 - Epoch: [279][  500/  500]    Overall Loss 0.311441    Objective Loss 0.311441    Top1 95.500000    Top5 100.000000    LR 0.000063    Time 0.091689    
2024-02-17 14:23:40,260 - --- validate (epoch=279)-----------
2024-02-17 14:23:40,260 - 10000 samples (100 per mini-batch)
2024-02-17 14:23:45,617 - Epoch: [279][  100/  100]    Loss 1.647080    Top1 59.690000    Top5 85.850000    
2024-02-17 14:23:45,785 - ==> Top1: 59.690    Top5: 85.850    Loss: 1.647

2024-02-17 14:23:45,798 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:23:45,799 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:23:45,854 - 

2024-02-17 14:23:45,854 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:23:55,513 - Epoch: [280][  100/  500]    Overall Loss 0.312251    Objective Loss 0.312251                                        LR 0.000063    Time 0.096539    
2024-02-17 14:24:04,599 - Epoch: [280][  200/  500]    Overall Loss 0.307332    Objective Loss 0.307332                                        LR 0.000063    Time 0.093676    
2024-02-17 14:24:12,985 - Epoch: [280][  300/  500]    Overall Loss 0.308300    Objective Loss 0.308300                                        LR 0.000063    Time 0.090395    
2024-02-17 14:24:21,992 - Epoch: [280][  400/  500]    Overall Loss 0.309923    Objective Loss 0.309923                                        LR 0.000063    Time 0.090305    
2024-02-17 14:24:30,945 - Epoch: [280][  500/  500]    Overall Loss 0.311150    Objective Loss 0.311150    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.090141    
2024-02-17 14:24:31,028 - --- validate (epoch=280)-----------
2024-02-17 14:24:31,029 - 10000 samples (100 per mini-batch)
2024-02-17 14:24:36,230 - Epoch: [280][  100/  100]    Loss 1.656391    Top1 59.220000    Top5 85.690000    
2024-02-17 14:24:36,339 - ==> Top1: 59.220    Top5: 85.690    Loss: 1.656

2024-02-17 14:24:36,350 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:24:36,351 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:24:36,400 - 

2024-02-17 14:24:36,400 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:24:45,144 - Epoch: [281][  100/  500]    Overall Loss 0.296394    Objective Loss 0.296394                                        LR 0.000063    Time 0.087395    
2024-02-17 14:24:53,778 - Epoch: [281][  200/  500]    Overall Loss 0.296420    Objective Loss 0.296420                                        LR 0.000063    Time 0.086851    
2024-02-17 14:25:02,723 - Epoch: [281][  300/  500]    Overall Loss 0.302684    Objective Loss 0.302684                                        LR 0.000063    Time 0.087702    
2024-02-17 14:25:11,749 - Epoch: [281][  400/  500]    Overall Loss 0.306061    Objective Loss 0.306061                                        LR 0.000063    Time 0.088334    
2024-02-17 14:25:20,890 - Epoch: [281][  500/  500]    Overall Loss 0.306399    Objective Loss 0.306399    Top1 95.500000    Top5 100.000000    LR 0.000063    Time 0.088939    
2024-02-17 14:25:21,022 - --- validate (epoch=281)-----------
2024-02-17 14:25:21,022 - 10000 samples (100 per mini-batch)
2024-02-17 14:25:26,454 - Epoch: [281][  100/  100]    Loss 1.717471    Top1 58.860000    Top5 85.230000    
2024-02-17 14:25:26,552 - ==> Top1: 58.860    Top5: 85.230    Loss: 1.717

2024-02-17 14:25:26,558 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:25:26,558 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:25:26,605 - 

2024-02-17 14:25:26,605 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:25:36,456 - Epoch: [282][  100/  500]    Overall Loss 0.297435    Objective Loss 0.297435                                        LR 0.000063    Time 0.098455    
2024-02-17 14:25:45,410 - Epoch: [282][  200/  500]    Overall Loss 0.303690    Objective Loss 0.303690                                        LR 0.000063    Time 0.093977    
2024-02-17 14:25:54,703 - Epoch: [282][  300/  500]    Overall Loss 0.304369    Objective Loss 0.304369                                        LR 0.000063    Time 0.093616    
2024-02-17 14:26:03,705 - Epoch: [282][  400/  500]    Overall Loss 0.308210    Objective Loss 0.308210                                        LR 0.000063    Time 0.092707    
2024-02-17 14:26:12,892 - Epoch: [282][  500/  500]    Overall Loss 0.307493    Objective Loss 0.307493    Top1 91.000000    Top5 100.000000    LR 0.000063    Time 0.092531    
2024-02-17 14:26:13,033 - --- validate (epoch=282)-----------
2024-02-17 14:26:13,034 - 10000 samples (100 per mini-batch)
2024-02-17 14:26:18,473 - Epoch: [282][  100/  100]    Loss 1.668078    Top1 60.180000    Top5 85.730000    
2024-02-17 14:26:18,563 - ==> Top1: 60.180    Top5: 85.730    Loss: 1.668

2024-02-17 14:26:18,574 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:26:18,575 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:26:18,626 - 

2024-02-17 14:26:18,626 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:26:28,026 - Epoch: [283][  100/  500]    Overall Loss 0.298780    Objective Loss 0.298780                                        LR 0.000063    Time 0.093950    
2024-02-17 14:26:36,370 - Epoch: [283][  200/  500]    Overall Loss 0.306446    Objective Loss 0.306446                                        LR 0.000063    Time 0.088679    
2024-02-17 14:26:45,443 - Epoch: [283][  300/  500]    Overall Loss 0.309016    Objective Loss 0.309016                                        LR 0.000063    Time 0.089348    
2024-02-17 14:26:54,448 - Epoch: [283][  400/  500]    Overall Loss 0.308282    Objective Loss 0.308282                                        LR 0.000063    Time 0.089516    
2024-02-17 14:27:03,503 - Epoch: [283][  500/  500]    Overall Loss 0.310389    Objective Loss 0.310389    Top1 97.500000    Top5 99.500000    LR 0.000063    Time 0.089714    
2024-02-17 14:27:03,630 - --- validate (epoch=283)-----------
2024-02-17 14:27:03,630 - 10000 samples (100 per mini-batch)
2024-02-17 14:27:09,454 - Epoch: [283][  100/  100]    Loss 1.658533    Top1 59.450000    Top5 85.930000    
2024-02-17 14:27:09,552 - ==> Top1: 59.450    Top5: 85.930    Loss: 1.659

2024-02-17 14:27:09,561 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:27:09,562 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:27:09,609 - 

2024-02-17 14:27:09,610 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:27:18,940 - Epoch: [284][  100/  500]    Overall Loss 0.295189    Objective Loss 0.295189                                        LR 0.000063    Time 0.093253    
2024-02-17 14:27:27,601 - Epoch: [284][  200/  500]    Overall Loss 0.298982    Objective Loss 0.298982                                        LR 0.000063    Time 0.089917    
2024-02-17 14:27:36,741 - Epoch: [284][  300/  500]    Overall Loss 0.301188    Objective Loss 0.301188                                        LR 0.000063    Time 0.090399    
2024-02-17 14:27:45,354 - Epoch: [284][  400/  500]    Overall Loss 0.302356    Objective Loss 0.302356                                        LR 0.000063    Time 0.089322    
2024-02-17 14:27:54,627 - Epoch: [284][  500/  500]    Overall Loss 0.304555    Objective Loss 0.304555    Top1 95.000000    Top5 100.000000    LR 0.000063    Time 0.089997    
2024-02-17 14:27:54,745 - --- validate (epoch=284)-----------
2024-02-17 14:27:54,746 - 10000 samples (100 per mini-batch)
2024-02-17 14:28:00,675 - Epoch: [284][  100/  100]    Loss 1.668351    Top1 59.910000    Top5 85.710000    
2024-02-17 14:28:00,799 - ==> Top1: 59.910    Top5: 85.710    Loss: 1.668

2024-02-17 14:28:00,810 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:28:00,811 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:28:00,859 - 

2024-02-17 14:28:00,860 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:28:10,524 - Epoch: [285][  100/  500]    Overall Loss 0.298869    Objective Loss 0.298869                                        LR 0.000063    Time 0.096593    
2024-02-17 14:28:19,597 - Epoch: [285][  200/  500]    Overall Loss 0.302835    Objective Loss 0.302835                                        LR 0.000063    Time 0.093644    
2024-02-17 14:28:28,746 - Epoch: [285][  300/  500]    Overall Loss 0.304866    Objective Loss 0.304866                                        LR 0.000063    Time 0.092911    
2024-02-17 14:28:37,682 - Epoch: [285][  400/  500]    Overall Loss 0.306172    Objective Loss 0.306172                                        LR 0.000063    Time 0.092015    
2024-02-17 14:28:47,180 - Epoch: [285][  500/  500]    Overall Loss 0.306695    Objective Loss 0.306695    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.092598    
2024-02-17 14:28:47,313 - --- validate (epoch=285)-----------
2024-02-17 14:28:47,314 - 10000 samples (100 per mini-batch)
2024-02-17 14:28:52,688 - Epoch: [285][  100/  100]    Loss 1.671461    Top1 59.390000    Top5 85.920000    
2024-02-17 14:28:52,769 - ==> Top1: 59.390    Top5: 85.920    Loss: 1.671

2024-02-17 14:28:52,778 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:28:52,779 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:28:52,822 - 

2024-02-17 14:28:52,823 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:29:01,989 - Epoch: [286][  100/  500]    Overall Loss 0.289274    Objective Loss 0.289274                                        LR 0.000063    Time 0.091625    
2024-02-17 14:29:11,289 - Epoch: [286][  200/  500]    Overall Loss 0.292750    Objective Loss 0.292750                                        LR 0.000063    Time 0.092289    
2024-02-17 14:29:20,248 - Epoch: [286][  300/  500]    Overall Loss 0.299358    Objective Loss 0.299358                                        LR 0.000063    Time 0.091378    
2024-02-17 14:29:29,263 - Epoch: [286][  400/  500]    Overall Loss 0.300226    Objective Loss 0.300226                                        LR 0.000063    Time 0.091060    
2024-02-17 14:29:38,194 - Epoch: [286][  500/  500]    Overall Loss 0.301991    Objective Loss 0.301991    Top1 92.000000    Top5 99.000000    LR 0.000063    Time 0.090703    
2024-02-17 14:29:38,329 - --- validate (epoch=286)-----------
2024-02-17 14:29:38,330 - 10000 samples (100 per mini-batch)
2024-02-17 14:29:43,801 - Epoch: [286][  100/  100]    Loss 1.685505    Top1 59.410000    Top5 85.710000    
2024-02-17 14:29:43,973 - ==> Top1: 59.410    Top5: 85.710    Loss: 1.686

2024-02-17 14:29:43,983 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:29:43,984 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:29:44,033 - 

2024-02-17 14:29:44,033 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:29:53,625 - Epoch: [287][  100/  500]    Overall Loss 0.304729    Objective Loss 0.304729                                        LR 0.000063    Time 0.095869    
2024-02-17 14:30:02,858 - Epoch: [287][  200/  500]    Overall Loss 0.304192    Objective Loss 0.304192                                        LR 0.000063    Time 0.094077    
2024-02-17 14:30:11,839 - Epoch: [287][  300/  500]    Overall Loss 0.304582    Objective Loss 0.304582                                        LR 0.000063    Time 0.092642    
2024-02-17 14:30:20,855 - Epoch: [287][  400/  500]    Overall Loss 0.307853    Objective Loss 0.307853                                        LR 0.000063    Time 0.092010    
2024-02-17 14:30:30,210 - Epoch: [287][  500/  500]    Overall Loss 0.308328    Objective Loss 0.308328    Top1 92.500000    Top5 99.500000    LR 0.000063    Time 0.092310    
2024-02-17 14:30:30,321 - --- validate (epoch=287)-----------
2024-02-17 14:30:30,323 - 10000 samples (100 per mini-batch)
2024-02-17 14:30:35,627 - Epoch: [287][  100/  100]    Loss 1.687764    Top1 59.820000    Top5 85.520000    
2024-02-17 14:30:35,746 - ==> Top1: 59.820    Top5: 85.520    Loss: 1.688

2024-02-17 14:30:35,756 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:30:35,756 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:30:35,808 - 

2024-02-17 14:30:35,808 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:30:45,488 - Epoch: [288][  100/  500]    Overall Loss 0.293155    Objective Loss 0.293155                                        LR 0.000063    Time 0.096750    
2024-02-17 14:30:54,669 - Epoch: [288][  200/  500]    Overall Loss 0.300195    Objective Loss 0.300195                                        LR 0.000063    Time 0.094260    
2024-02-17 14:31:03,444 - Epoch: [288][  300/  500]    Overall Loss 0.299501    Objective Loss 0.299501                                        LR 0.000063    Time 0.092077    
2024-02-17 14:31:12,490 - Epoch: [288][  400/  500]    Overall Loss 0.303071    Objective Loss 0.303071                                        LR 0.000063    Time 0.091663    
2024-02-17 14:31:21,745 - Epoch: [288][  500/  500]    Overall Loss 0.304227    Objective Loss 0.304227    Top1 90.000000    Top5 99.500000    LR 0.000063    Time 0.091834    
2024-02-17 14:31:21,864 - --- validate (epoch=288)-----------
2024-02-17 14:31:21,865 - 10000 samples (100 per mini-batch)
2024-02-17 14:31:27,875 - Epoch: [288][  100/  100]    Loss 1.676494    Top1 59.510000    Top5 85.530000    
2024-02-17 14:31:27,990 - ==> Top1: 59.510    Top5: 85.530    Loss: 1.676

2024-02-17 14:31:28,005 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:31:28,005 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:31:28,061 - 

2024-02-17 14:31:28,061 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:31:37,656 - Epoch: [289][  100/  500]    Overall Loss 0.293441    Objective Loss 0.293441                                        LR 0.000063    Time 0.095887    
2024-02-17 14:31:46,646 - Epoch: [289][  200/  500]    Overall Loss 0.296398    Objective Loss 0.296398                                        LR 0.000063    Time 0.092874    
2024-02-17 14:31:55,810 - Epoch: [289][  300/  500]    Overall Loss 0.299673    Objective Loss 0.299673                                        LR 0.000063    Time 0.092449    
2024-02-17 14:32:05,020 - Epoch: [289][  400/  500]    Overall Loss 0.302061    Objective Loss 0.302061                                        LR 0.000063    Time 0.092351    
2024-02-17 14:32:14,197 - Epoch: [289][  500/  500]    Overall Loss 0.303782    Objective Loss 0.303782    Top1 94.000000    Top5 99.500000    LR 0.000063    Time 0.092226    
2024-02-17 14:32:14,373 - --- validate (epoch=289)-----------
2024-02-17 14:32:14,374 - 10000 samples (100 per mini-batch)
2024-02-17 14:32:19,505 - Epoch: [289][  100/  100]    Loss 1.675205    Top1 59.540000    Top5 85.460000    
2024-02-17 14:32:19,590 - ==> Top1: 59.540    Top5: 85.460    Loss: 1.675

2024-02-17 14:32:19,600 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:32:19,600 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:32:19,648 - 

2024-02-17 14:32:19,648 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:32:29,393 - Epoch: [290][  100/  500]    Overall Loss 0.294813    Objective Loss 0.294813                                        LR 0.000063    Time 0.097397    
2024-02-17 14:32:38,475 - Epoch: [290][  200/  500]    Overall Loss 0.300885    Objective Loss 0.300885                                        LR 0.000063    Time 0.094085    
2024-02-17 14:32:47,606 - Epoch: [290][  300/  500]    Overall Loss 0.299431    Objective Loss 0.299431                                        LR 0.000063    Time 0.093150    
2024-02-17 14:32:56,998 - Epoch: [290][  400/  500]    Overall Loss 0.300635    Objective Loss 0.300635                                        LR 0.000063    Time 0.093331    
2024-02-17 14:33:06,040 - Epoch: [290][  500/  500]    Overall Loss 0.300474    Objective Loss 0.300474    Top1 92.000000    Top5 100.000000    LR 0.000063    Time 0.092741    
2024-02-17 14:33:06,199 - --- validate (epoch=290)-----------
2024-02-17 14:33:06,199 - 10000 samples (100 per mini-batch)
2024-02-17 14:33:11,695 - Epoch: [290][  100/  100]    Loss 1.690913    Top1 59.380000    Top5 85.580000    
2024-02-17 14:33:11,814 - ==> Top1: 59.380    Top5: 85.580    Loss: 1.691

2024-02-17 14:33:11,824 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:33:11,825 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:33:11,874 - 

2024-02-17 14:33:11,874 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:33:21,283 - Epoch: [291][  100/  500]    Overall Loss 0.295638    Objective Loss 0.295638                                        LR 0.000063    Time 0.094040    
2024-02-17 14:33:30,314 - Epoch: [291][  200/  500]    Overall Loss 0.293932    Objective Loss 0.293932                                        LR 0.000063    Time 0.092155    
2024-02-17 14:33:39,315 - Epoch: [291][  300/  500]    Overall Loss 0.294738    Objective Loss 0.294738                                        LR 0.000063    Time 0.091429    
2024-02-17 14:33:48,201 - Epoch: [291][  400/  500]    Overall Loss 0.298468    Objective Loss 0.298468                                        LR 0.000063    Time 0.090778    
2024-02-17 14:33:57,280 - Epoch: [291][  500/  500]    Overall Loss 0.301624    Objective Loss 0.301624    Top1 92.000000    Top5 100.000000    LR 0.000063    Time 0.090772    
2024-02-17 14:33:57,426 - --- validate (epoch=291)-----------
2024-02-17 14:33:57,427 - 10000 samples (100 per mini-batch)
2024-02-17 14:34:02,705 - Epoch: [291][  100/  100]    Loss 1.698444    Top1 59.260000    Top5 85.580000    
2024-02-17 14:34:02,891 - ==> Top1: 59.260    Top5: 85.580    Loss: 1.698

2024-02-17 14:34:02,901 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:34:02,902 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:34:02,952 - 

2024-02-17 14:34:02,952 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:34:12,680 - Epoch: [292][  100/  500]    Overall Loss 0.294331    Objective Loss 0.294331                                        LR 0.000063    Time 0.097232    
2024-02-17 14:34:21,677 - Epoch: [292][  200/  500]    Overall Loss 0.293669    Objective Loss 0.293669                                        LR 0.000063    Time 0.093580    
2024-02-17 14:34:30,255 - Epoch: [292][  300/  500]    Overall Loss 0.295604    Objective Loss 0.295604                                        LR 0.000063    Time 0.090967    
2024-02-17 14:34:39,449 - Epoch: [292][  400/  500]    Overall Loss 0.297811    Objective Loss 0.297811                                        LR 0.000063    Time 0.091200    
2024-02-17 14:34:48,513 - Epoch: [292][  500/  500]    Overall Loss 0.299529    Objective Loss 0.299529    Top1 95.500000    Top5 99.000000    LR 0.000063    Time 0.091080    
2024-02-17 14:34:48,688 - --- validate (epoch=292)-----------
2024-02-17 14:34:48,688 - 10000 samples (100 per mini-batch)
2024-02-17 14:34:54,027 - Epoch: [292][  100/  100]    Loss 1.660243    Top1 60.170000    Top5 85.770000    
2024-02-17 14:34:54,133 - ==> Top1: 60.170    Top5: 85.770    Loss: 1.660

2024-02-17 14:34:54,143 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:34:54,144 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:34:54,195 - 

2024-02-17 14:34:54,195 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:35:03,599 - Epoch: [293][  100/  500]    Overall Loss 0.280867    Objective Loss 0.280867                                        LR 0.000063    Time 0.093989    
2024-02-17 14:35:12,203 - Epoch: [293][  200/  500]    Overall Loss 0.285454    Objective Loss 0.285454                                        LR 0.000063    Time 0.089998    
2024-02-17 14:35:20,910 - Epoch: [293][  300/  500]    Overall Loss 0.294537    Objective Loss 0.294537                                        LR 0.000063    Time 0.089011    
2024-02-17 14:35:29,979 - Epoch: [293][  400/  500]    Overall Loss 0.296713    Objective Loss 0.296713                                        LR 0.000063    Time 0.089421    
2024-02-17 14:35:39,143 - Epoch: [293][  500/  500]    Overall Loss 0.297796    Objective Loss 0.297796    Top1 96.500000    Top5 100.000000    LR 0.000063    Time 0.089856    
2024-02-17 14:35:39,269 - --- validate (epoch=293)-----------
2024-02-17 14:35:39,270 - 10000 samples (100 per mini-batch)
2024-02-17 14:35:44,719 - Epoch: [293][  100/  100]    Loss 1.690550    Top1 59.310000    Top5 85.660000    
2024-02-17 14:35:44,843 - ==> Top1: 59.310    Top5: 85.660    Loss: 1.691

2024-02-17 14:35:44,853 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:35:44,853 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:35:44,903 - 

2024-02-17 14:35:44,904 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:35:54,306 - Epoch: [294][  100/  500]    Overall Loss 0.291341    Objective Loss 0.291341                                        LR 0.000063    Time 0.093975    
2024-02-17 14:36:03,253 - Epoch: [294][  200/  500]    Overall Loss 0.296842    Objective Loss 0.296842                                        LR 0.000063    Time 0.091702    
2024-02-17 14:36:12,122 - Epoch: [294][  300/  500]    Overall Loss 0.295782    Objective Loss 0.295782                                        LR 0.000063    Time 0.090688    
2024-02-17 14:36:20,607 - Epoch: [294][  400/  500]    Overall Loss 0.297752    Objective Loss 0.297752                                        LR 0.000063    Time 0.089220    
2024-02-17 14:36:29,844 - Epoch: [294][  500/  500]    Overall Loss 0.298120    Objective Loss 0.298120    Top1 94.500000    Top5 100.000000    LR 0.000063    Time 0.089843    
2024-02-17 14:36:29,940 - --- validate (epoch=294)-----------
2024-02-17 14:36:29,940 - 10000 samples (100 per mini-batch)
2024-02-17 14:36:35,498 - Epoch: [294][  100/  100]    Loss 1.688233    Top1 59.510000    Top5 85.310000    
2024-02-17 14:36:35,618 - ==> Top1: 59.510    Top5: 85.310    Loss: 1.688

2024-02-17 14:36:35,625 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:36:35,625 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:36:35,668 - 

2024-02-17 14:36:35,668 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:36:45,193 - Epoch: [295][  100/  500]    Overall Loss 0.288148    Objective Loss 0.288148                                        LR 0.000063    Time 0.095204    
2024-02-17 14:36:54,144 - Epoch: [295][  200/  500]    Overall Loss 0.289266    Objective Loss 0.289266                                        LR 0.000063    Time 0.092334    
2024-02-17 14:37:03,125 - Epoch: [295][  300/  500]    Overall Loss 0.293469    Objective Loss 0.293469                                        LR 0.000063    Time 0.091480    
2024-02-17 14:37:11,959 - Epoch: [295][  400/  500]    Overall Loss 0.295301    Objective Loss 0.295301                                        LR 0.000063    Time 0.090687    
2024-02-17 14:37:20,951 - Epoch: [295][  500/  500]    Overall Loss 0.295913    Objective Loss 0.295913    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.090526    
2024-02-17 14:37:21,120 - --- validate (epoch=295)-----------
2024-02-17 14:37:21,120 - 10000 samples (100 per mini-batch)
2024-02-17 14:37:26,778 - Epoch: [295][  100/  100]    Loss 1.696506    Top1 59.990000    Top5 85.270000    
2024-02-17 14:37:26,959 - ==> Top1: 59.990    Top5: 85.270    Loss: 1.697

2024-02-17 14:37:26,970 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:37:26,971 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:37:27,021 - 

2024-02-17 14:37:27,022 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:37:36,476 - Epoch: [296][  100/  500]    Overall Loss 0.293662    Objective Loss 0.293662                                        LR 0.000063    Time 0.094487    
2024-02-17 14:37:45,478 - Epoch: [296][  200/  500]    Overall Loss 0.291871    Objective Loss 0.291871                                        LR 0.000063    Time 0.092238    
2024-02-17 14:37:54,529 - Epoch: [296][  300/  500]    Overall Loss 0.294106    Objective Loss 0.294106                                        LR 0.000063    Time 0.091646    
2024-02-17 14:38:03,394 - Epoch: [296][  400/  500]    Overall Loss 0.294598    Objective Loss 0.294598                                        LR 0.000063    Time 0.090889    
2024-02-17 14:38:12,407 - Epoch: [296][  500/  500]    Overall Loss 0.295858    Objective Loss 0.295858    Top1 94.000000    Top5 99.000000    LR 0.000063    Time 0.090730    
2024-02-17 14:38:12,532 - --- validate (epoch=296)-----------
2024-02-17 14:38:12,533 - 10000 samples (100 per mini-batch)
2024-02-17 14:38:18,075 - Epoch: [296][  100/  100]    Loss 1.678972    Top1 59.550000    Top5 85.610000    
2024-02-17 14:38:18,188 - ==> Top1: 59.550    Top5: 85.610    Loss: 1.679

2024-02-17 14:38:18,194 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:38:18,194 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:38:18,236 - 

2024-02-17 14:38:18,236 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:38:27,672 - Epoch: [297][  100/  500]    Overall Loss 0.286885    Objective Loss 0.286885                                        LR 0.000063    Time 0.094304    
2024-02-17 14:38:36,675 - Epoch: [297][  200/  500]    Overall Loss 0.287794    Objective Loss 0.287794                                        LR 0.000063    Time 0.092148    
2024-02-17 14:38:45,794 - Epoch: [297][  300/  500]    Overall Loss 0.291518    Objective Loss 0.291518                                        LR 0.000063    Time 0.091814    
2024-02-17 14:38:54,899 - Epoch: [297][  400/  500]    Overall Loss 0.291891    Objective Loss 0.291891                                        LR 0.000063    Time 0.091614    
2024-02-17 14:39:03,931 - Epoch: [297][  500/  500]    Overall Loss 0.294967    Objective Loss 0.294967    Top1 95.500000    Top5 100.000000    LR 0.000063    Time 0.091347    
2024-02-17 14:39:04,035 - --- validate (epoch=297)-----------
2024-02-17 14:39:04,036 - 10000 samples (100 per mini-batch)
2024-02-17 14:39:09,321 - Epoch: [297][  100/  100]    Loss 1.723047    Top1 58.730000    Top5 85.510000    
2024-02-17 14:39:09,420 - ==> Top1: 58.730    Top5: 85.510    Loss: 1.723

2024-02-17 14:39:09,432 - ==> Best [Top1: 60.210   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 246]
2024-02-17 14:39:09,432 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:39:09,482 - 

2024-02-17 14:39:09,482 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:39:18,823 - Epoch: [298][  100/  500]    Overall Loss 0.287612    Objective Loss 0.287612                                        LR 0.000063    Time 0.093358    
2024-02-17 14:39:27,555 - Epoch: [298][  200/  500]    Overall Loss 0.295196    Objective Loss 0.295196                                        LR 0.000063    Time 0.090326    
2024-02-17 14:39:36,592 - Epoch: [298][  300/  500]    Overall Loss 0.295998    Objective Loss 0.295998                                        LR 0.000063    Time 0.090324    
2024-02-17 14:39:45,563 - Epoch: [298][  400/  500]    Overall Loss 0.296785    Objective Loss 0.296785                                        LR 0.000063    Time 0.090161    
2024-02-17 14:39:54,560 - Epoch: [298][  500/  500]    Overall Loss 0.298427    Objective Loss 0.298427    Top1 93.000000    Top5 100.000000    LR 0.000063    Time 0.090116    
2024-02-17 14:39:54,693 - --- validate (epoch=298)-----------
2024-02-17 14:39:54,694 - 10000 samples (100 per mini-batch)
2024-02-17 14:39:59,998 - Epoch: [298][  100/  100]    Loss 1.682828    Top1 60.220000    Top5 85.340000    
2024-02-17 14:40:00,093 - ==> Top1: 60.220    Top5: 85.340    Loss: 1.683

2024-02-17 14:40:00,104 - ==> Best [Top1: 60.220   Top5: 85.340   Sparsity:0.00   Params: 753952 on epoch: 298]
2024-02-17 14:40:00,105 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:40:00,173 - 

2024-02-17 14:40:00,173 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-17 14:40:09,521 - Epoch: [299][  100/  500]    Overall Loss 0.287979    Objective Loss 0.287979                                        LR 0.000063    Time 0.093435    
2024-02-17 14:40:18,411 - Epoch: [299][  200/  500]    Overall Loss 0.293659    Objective Loss 0.293659                                        LR 0.000063    Time 0.091151    
2024-02-17 14:40:27,238 - Epoch: [299][  300/  500]    Overall Loss 0.290008    Objective Loss 0.290008                                        LR 0.000063    Time 0.090177    
2024-02-17 14:40:35,809 - Epoch: [299][  400/  500]    Overall Loss 0.293375    Objective Loss 0.293375                                        LR 0.000063    Time 0.089053    
2024-02-17 14:40:44,862 - Epoch: [299][  500/  500]    Overall Loss 0.294955    Objective Loss 0.294955    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.089342    
2024-02-17 14:40:44,972 - --- validate (epoch=299)-----------
2024-02-17 14:40:44,972 - 10000 samples (100 per mini-batch)
2024-02-17 14:40:50,098 - Epoch: [299][  100/  100]    Loss 1.688079    Top1 59.870000    Top5 85.520000    
2024-02-17 14:40:50,209 - ==> Top1: 59.870    Top5: 85.520    Loss: 1.688

2024-02-17 14:40:50,220 - ==> Best [Top1: 60.220   Top5: 85.340   Sparsity:0.00   Params: 753952 on epoch: 298]
2024-02-17 14:40:50,220 - Saving checkpoint to: logs/2024.02.17-110119/qat_checkpoint.pth.tar
2024-02-17 14:40:50,269 - --- test ---------------------
2024-02-17 14:40:50,269 - 10000 samples (100 per mini-batch)
2024-02-17 14:40:55,254 - Test: [  100/  100]    Loss 1.688079    Top1 59.870000    Top5 85.520000    
2024-02-17 14:40:55,338 - ==> Top1: 59.870    Top5: 85.520    Loss: 1.688

2024-02-17 14:40:55,349 - 
2024-02-17 14:40:55,349 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.02.17-110119/2024.02.17-110119.log
