2024-02-19 16:09:49,101 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.02.19-160949/2024.02.19-160949.log
2024-02-19 16:09:52,338 - Optimizer Type: <class 'torch.optim.sgd.SGD'>
2024-02-19 16:09:52,338 - Optimizer Args: {'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0.0001, 'nesterov': False}
2024-02-19 16:09:53,843 - Dataset sizes:
	training=50000
	validation=10000
	test=10000
2024-02-19 16:09:53,843 - Reading compression schedule from: policies/schedule-cifar100-mobilenetv2.yaml
2024-02-19 16:09:53,851 - 

2024-02-19 16:09:53,852 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:10:03,634 - Epoch: [0][  100/  391]    Overall Loss 4.416315    Objective Loss 4.416315                                        LR 0.100000    Time 0.097763    
2024-02-19 16:10:11,934 - Epoch: [0][  200/  391]    Overall Loss 4.286143    Objective Loss 4.286143                                        LR 0.100000    Time 0.090356    
2024-02-19 16:10:21,211 - Epoch: [0][  300/  391]    Overall Loss 4.195390    Objective Loss 4.195390                                        LR 0.100000    Time 0.091147    
2024-02-19 16:10:29,589 - Epoch: [0][  391/  391]    Overall Loss 4.128643    Objective Loss 4.128643    Top1 8.173077    Top5 30.769231    LR 0.100000    Time 0.091349    
2024-02-19 16:10:29,729 - --- validate (epoch=0)-----------
2024-02-19 16:10:29,730 - 10000 samples (128 per mini-batch)
2024-02-19 16:10:32,373 - Epoch: [0][   79/   79]    Loss 4.294045    Top1 5.940000    Top5 21.100000    
2024-02-19 16:10:32,620 - ==> Top1: 5.940    Top5: 21.100    Loss: 4.294

2024-02-19 16:10:32,868 - ==> Best [Top1: 5.940   Top5: 21.100   Sparsity:0.00   Params: 1341960 on epoch: 0]
2024-02-19 16:10:32,868 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:10:32,942 - 

2024-02-19 16:10:32,943 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:10:42,852 - Epoch: [1][  100/  391]    Overall Loss 3.804707    Objective Loss 3.804707                                        LR 0.100000    Time 0.099022    
2024-02-19 16:10:52,135 - Epoch: [1][  200/  391]    Overall Loss 3.776933    Objective Loss 3.776933                                        LR 0.100000    Time 0.095899    
2024-02-19 16:11:01,356 - Epoch: [1][  300/  391]    Overall Loss 3.746371    Objective Loss 3.746371                                        LR 0.100000    Time 0.094653    
2024-02-19 16:11:09,794 - Epoch: [1][  391/  391]    Overall Loss 3.722566    Objective Loss 3.722566    Top1 11.538462    Top5 36.538462    LR 0.100000    Time 0.094192    
2024-02-19 16:11:10,083 - --- validate (epoch=1)-----------
2024-02-19 16:11:10,084 - 10000 samples (128 per mini-batch)
2024-02-19 16:11:12,698 - Epoch: [1][   79/   79]    Loss 3.612136    Top1 11.770000    Top5 36.110000    
2024-02-19 16:11:13,003 - ==> Top1: 11.770    Top5: 36.110    Loss: 3.612

2024-02-19 16:11:13,012 - ==> Best [Top1: 11.770   Top5: 36.110   Sparsity:0.00   Params: 1341960 on epoch: 1]
2024-02-19 16:11:13,012 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:11:13,099 - 

2024-02-19 16:11:13,100 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:11:23,102 - Epoch: [2][  100/  391]    Overall Loss 3.567376    Objective Loss 3.567376                                        LR 0.100000    Time 0.099951    
2024-02-19 16:11:32,265 - Epoch: [2][  200/  391]    Overall Loss 3.529924    Objective Loss 3.529924                                        LR 0.100000    Time 0.095763    
2024-02-19 16:11:41,438 - Epoch: [2][  300/  391]    Overall Loss 3.513421    Objective Loss 3.513421                                        LR 0.100000    Time 0.094403    
2024-02-19 16:11:49,849 - Epoch: [2][  391/  391]    Overall Loss 3.484502    Objective Loss 3.484502    Top1 13.461538    Top5 45.192308    LR 0.100000    Time 0.093933    
2024-02-19 16:11:50,071 - --- validate (epoch=2)-----------
2024-02-19 16:11:50,072 - 10000 samples (128 per mini-batch)
2024-02-19 16:11:52,686 - Epoch: [2][   79/   79]    Loss 3.470122    Top1 14.090000    Top5 42.420000    
2024-02-19 16:11:52,866 - ==> Top1: 14.090    Top5: 42.420    Loss: 3.470

2024-02-19 16:11:52,883 - ==> Best [Top1: 14.090   Top5: 42.420   Sparsity:0.00   Params: 1341960 on epoch: 2]
2024-02-19 16:11:52,884 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:11:52,975 - 

2024-02-19 16:11:52,976 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:12:02,783 - Epoch: [3][  100/  391]    Overall Loss 3.324654    Objective Loss 3.324654                                        LR 0.100000    Time 0.098002    
2024-02-19 16:12:11,921 - Epoch: [3][  200/  391]    Overall Loss 3.292986    Objective Loss 3.292986                                        LR 0.100000    Time 0.094667    
2024-02-19 16:12:21,120 - Epoch: [3][  300/  391]    Overall Loss 3.274662    Objective Loss 3.274662                                        LR 0.100000    Time 0.093762    
2024-02-19 16:12:29,537 - Epoch: [3][  391/  391]    Overall Loss 3.251404    Objective Loss 3.251404    Top1 17.788462    Top5 50.000000    LR 0.100000    Time 0.093455    
2024-02-19 16:12:29,874 - --- validate (epoch=3)-----------
2024-02-19 16:12:29,875 - 10000 samples (128 per mini-batch)
2024-02-19 16:12:32,502 - Epoch: [3][   79/   79]    Loss 3.512974    Top1 16.070000    Top5 42.120000    
2024-02-19 16:12:32,675 - ==> Top1: 16.070    Top5: 42.120    Loss: 3.513

2024-02-19 16:12:32,694 - ==> Best [Top1: 16.070   Top5: 42.120   Sparsity:0.00   Params: 1341960 on epoch: 3]
2024-02-19 16:12:32,694 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:12:32,786 - 

2024-02-19 16:12:32,786 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:12:42,572 - Epoch: [4][  100/  391]    Overall Loss 3.115228    Objective Loss 3.115228                                        LR 0.100000    Time 0.097783    
2024-02-19 16:12:51,839 - Epoch: [4][  200/  391]    Overall Loss 3.098125    Objective Loss 3.098125                                        LR 0.100000    Time 0.095207    
2024-02-19 16:13:01,059 - Epoch: [4][  300/  391]    Overall Loss 3.082714    Objective Loss 3.082714                                        LR 0.100000    Time 0.094187    
2024-02-19 16:13:09,479 - Epoch: [4][  391/  391]    Overall Loss 3.057796    Objective Loss 3.057796    Top1 21.153846    Top5 56.730769    LR 0.100000    Time 0.093791    
2024-02-19 16:13:09,700 - --- validate (epoch=4)-----------
2024-02-19 16:13:09,700 - 10000 samples (128 per mini-batch)
2024-02-19 16:13:12,333 - Epoch: [4][   79/   79]    Loss 3.680597    Top1 15.720000    Top5 42.760000    
2024-02-19 16:13:12,645 - ==> Top1: 15.720    Top5: 42.760    Loss: 3.681

2024-02-19 16:13:12,663 - ==> Best [Top1: 16.070   Top5: 42.120   Sparsity:0.00   Params: 1341960 on epoch: 3]
2024-02-19 16:13:12,663 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:13:12,932 - 

2024-02-19 16:13:12,933 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:13:22,650 - Epoch: [5][  100/  391]    Overall Loss 2.921600    Objective Loss 2.921600                                        LR 0.100000    Time 0.097105    
2024-02-19 16:13:31,817 - Epoch: [5][  200/  391]    Overall Loss 2.925484    Objective Loss 2.925484                                        LR 0.100000    Time 0.094364    
2024-02-19 16:13:40,968 - Epoch: [5][  300/  391]    Overall Loss 2.903268    Objective Loss 2.903268                                        LR 0.100000    Time 0.093396    
2024-02-19 16:13:49,321 - Epoch: [5][  391/  391]    Overall Loss 2.888552    Objective Loss 2.888552    Top1 24.038462    Top5 55.769231    LR 0.100000    Time 0.093013    
2024-02-19 16:13:49,561 - --- validate (epoch=5)-----------
2024-02-19 16:13:49,562 - 10000 samples (128 per mini-batch)
2024-02-19 16:13:52,045 - Epoch: [5][   79/   79]    Loss 3.252491    Top1 20.500000    Top5 51.040000    
2024-02-19 16:13:52,229 - ==> Top1: 20.500    Top5: 51.040    Loss: 3.252

2024-02-19 16:13:52,246 - ==> Best [Top1: 20.500   Top5: 51.040   Sparsity:0.00   Params: 1341960 on epoch: 5]
2024-02-19 16:13:52,247 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:13:52,342 - 

2024-02-19 16:13:52,342 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:14:02,285 - Epoch: [6][  100/  391]    Overall Loss 2.782903    Objective Loss 2.782903                                        LR 0.100000    Time 0.099357    
2024-02-19 16:14:11,511 - Epoch: [6][  200/  391]    Overall Loss 2.783424    Objective Loss 2.783424                                        LR 0.100000    Time 0.095783    
2024-02-19 16:14:20,717 - Epoch: [6][  300/  391]    Overall Loss 2.762626    Objective Loss 2.762626                                        LR 0.100000    Time 0.094527    
2024-02-19 16:14:29,067 - Epoch: [6][  391/  391]    Overall Loss 2.749103    Objective Loss 2.749103    Top1 28.365385    Top5 61.057692    LR 0.100000    Time 0.093873    
2024-02-19 16:14:29,278 - --- validate (epoch=6)-----------
2024-02-19 16:14:29,279 - 10000 samples (128 per mini-batch)
2024-02-19 16:14:31,859 - Epoch: [6][   79/   79]    Loss 2.988540    Top1 23.640000    Top5 56.320000    
2024-02-19 16:14:32,069 - ==> Top1: 23.640    Top5: 56.320    Loss: 2.989

2024-02-19 16:14:32,086 - ==> Best [Top1: 23.640   Top5: 56.320   Sparsity:0.00   Params: 1341960 on epoch: 6]
2024-02-19 16:14:32,087 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:14:32,185 - 

2024-02-19 16:14:32,186 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:14:42,101 - Epoch: [7][  100/  391]    Overall Loss 2.656388    Objective Loss 2.656388                                        LR 0.100000    Time 0.099087    
2024-02-19 16:14:51,311 - Epoch: [7][  200/  391]    Overall Loss 2.651310    Objective Loss 2.651310                                        LR 0.100000    Time 0.095570    
2024-02-19 16:15:00,502 - Epoch: [7][  300/  391]    Overall Loss 2.638051    Objective Loss 2.638051                                        LR 0.100000    Time 0.094335    
2024-02-19 16:15:08,914 - Epoch: [7][  391/  391]    Overall Loss 2.628637    Objective Loss 2.628637    Top1 29.807692    Top5 65.865385    LR 0.100000    Time 0.093883    
2024-02-19 16:15:09,150 - --- validate (epoch=7)-----------
2024-02-19 16:15:09,151 - 10000 samples (128 per mini-batch)
2024-02-19 16:15:11,789 - Epoch: [7][   79/   79]    Loss 2.928358    Top1 26.420000    Top5 58.360000    
2024-02-19 16:15:12,025 - ==> Top1: 26.420    Top5: 58.360    Loss: 2.928

2024-02-19 16:15:12,035 - ==> Best [Top1: 26.420   Top5: 58.360   Sparsity:0.00   Params: 1341960 on epoch: 7]
2024-02-19 16:15:12,035 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:15:12,126 - 

2024-02-19 16:15:12,127 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:15:22,116 - Epoch: [8][  100/  391]    Overall Loss 2.557369    Objective Loss 2.557369                                        LR 0.100000    Time 0.099821    
2024-02-19 16:15:31,237 - Epoch: [8][  200/  391]    Overall Loss 2.552592    Objective Loss 2.552592                                        LR 0.100000    Time 0.095491    
2024-02-19 16:15:40,366 - Epoch: [8][  300/  391]    Overall Loss 2.547581    Objective Loss 2.547581                                        LR 0.100000    Time 0.094073    
2024-02-19 16:15:48,715 - Epoch: [8][  391/  391]    Overall Loss 2.535819    Objective Loss 2.535819    Top1 30.769231    Top5 67.788462    LR 0.100000    Time 0.093522    
2024-02-19 16:15:49,009 - --- validate (epoch=8)-----------
2024-02-19 16:15:49,010 - 10000 samples (128 per mini-batch)
2024-02-19 16:15:51,633 - Epoch: [8][   79/   79]    Loss 2.706972    Top1 29.560000    Top5 62.900000    
2024-02-19 16:15:51,848 - ==> Top1: 29.560    Top5: 62.900    Loss: 2.707

2024-02-19 16:15:51,866 - ==> Best [Top1: 29.560   Top5: 62.900   Sparsity:0.00   Params: 1341960 on epoch: 8]
2024-02-19 16:15:51,866 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:15:51,969 - 

2024-02-19 16:15:51,969 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:15:59,527 - Epoch: [9][  100/  391]    Overall Loss 2.443809    Objective Loss 2.443809                                        LR 0.100000    Time 0.075515    
2024-02-19 16:16:07,820 - Epoch: [9][  200/  391]    Overall Loss 2.461339    Objective Loss 2.461339                                        LR 0.100000    Time 0.079205    
2024-02-19 16:16:17,117 - Epoch: [9][  300/  391]    Overall Loss 2.454683    Objective Loss 2.454683                                        LR 0.100000    Time 0.083776    
2024-02-19 16:16:25,539 - Epoch: [9][  391/  391]    Overall Loss 2.455477    Objective Loss 2.455477    Top1 37.019231    Top5 63.942308    LR 0.100000    Time 0.085809    
2024-02-19 16:16:25,773 - --- validate (epoch=9)-----------
2024-02-19 16:16:25,774 - 10000 samples (128 per mini-batch)
2024-02-19 16:16:28,335 - Epoch: [9][   79/   79]    Loss 3.159537    Top1 24.220000    Top5 55.490000    
2024-02-19 16:16:28,499 - ==> Top1: 24.220    Top5: 55.490    Loss: 3.160

2024-02-19 16:16:28,516 - ==> Best [Top1: 29.560   Top5: 62.900   Sparsity:0.00   Params: 1341960 on epoch: 8]
2024-02-19 16:16:28,517 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:16:28,589 - 

2024-02-19 16:16:28,590 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:16:38,252 - Epoch: [10][  100/  391]    Overall Loss 2.413701    Objective Loss 2.413701                                        LR 0.100000    Time 0.096547    
2024-02-19 16:16:47,628 - Epoch: [10][  200/  391]    Overall Loss 2.394479    Objective Loss 2.394479                                        LR 0.100000    Time 0.095133    
2024-02-19 16:16:56,999 - Epoch: [10][  300/  391]    Overall Loss 2.385760    Objective Loss 2.385760                                        LR 0.100000    Time 0.094643    
2024-02-19 16:17:05,461 - Epoch: [10][  391/  391]    Overall Loss 2.385589    Objective Loss 2.385589    Top1 31.250000    Top5 69.711538    LR 0.100000    Time 0.094248    
2024-02-19 16:17:05,683 - --- validate (epoch=10)-----------
2024-02-19 16:17:05,684 - 10000 samples (128 per mini-batch)
2024-02-19 16:17:08,303 - Epoch: [10][   79/   79]    Loss 2.457716    Top1 33.660000    Top5 68.120000    
2024-02-19 16:17:08,560 - ==> Top1: 33.660    Top5: 68.120    Loss: 2.458

2024-02-19 16:17:08,579 - ==> Best [Top1: 33.660   Top5: 68.120   Sparsity:0.00   Params: 1341960 on epoch: 10]
2024-02-19 16:17:08,580 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:17:08,672 - 

2024-02-19 16:17:08,672 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:17:18,751 - Epoch: [11][  100/  391]    Overall Loss 2.344371    Objective Loss 2.344371                                        LR 0.100000    Time 0.100717    
2024-02-19 16:17:27,657 - Epoch: [11][  200/  391]    Overall Loss 2.329532    Objective Loss 2.329532                                        LR 0.100000    Time 0.094864    
2024-02-19 16:17:36,577 - Epoch: [11][  300/  391]    Overall Loss 2.320764    Objective Loss 2.320764                                        LR 0.100000    Time 0.092964    
2024-02-19 16:17:44,865 - Epoch: [11][  391/  391]    Overall Loss 2.318187    Objective Loss 2.318187    Top1 40.384615    Top5 67.307692    LR 0.100000    Time 0.092513    
2024-02-19 16:17:45,108 - --- validate (epoch=11)-----------
2024-02-19 16:17:45,110 - 10000 samples (128 per mini-batch)
2024-02-19 16:17:47,597 - Epoch: [11][   79/   79]    Loss 2.570210    Top1 32.130000    Top5 66.130000    
2024-02-19 16:17:47,751 - ==> Top1: 32.130    Top5: 66.130    Loss: 2.570

2024-02-19 16:17:47,770 - ==> Best [Top1: 33.660   Top5: 68.120   Sparsity:0.00   Params: 1341960 on epoch: 10]
2024-02-19 16:17:47,770 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:17:47,829 - 

2024-02-19 16:17:47,830 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:17:57,207 - Epoch: [12][  100/  391]    Overall Loss 2.279788    Objective Loss 2.279788                                        LR 0.100000    Time 0.093716    
2024-02-19 16:18:06,241 - Epoch: [12][  200/  391]    Overall Loss 2.269952    Objective Loss 2.269952                                        LR 0.100000    Time 0.092004    
2024-02-19 16:18:15,330 - Epoch: [12][  300/  391]    Overall Loss 2.270224    Objective Loss 2.270224                                        LR 0.100000    Time 0.091617    
2024-02-19 16:18:22,881 - Epoch: [12][  391/  391]    Overall Loss 2.271273    Objective Loss 2.271273    Top1 36.057692    Top5 73.076923    LR 0.100000    Time 0.089598    
2024-02-19 16:18:23,042 - --- validate (epoch=12)-----------
2024-02-19 16:18:23,043 - 10000 samples (128 per mini-batch)
2024-02-19 16:18:25,289 - Epoch: [12][   79/   79]    Loss 2.388325    Top1 36.210000    Top5 69.180000    
2024-02-19 16:18:25,490 - ==> Top1: 36.210    Top5: 69.180    Loss: 2.388

2024-02-19 16:18:25,507 - ==> Best [Top1: 36.210   Top5: 69.180   Sparsity:0.00   Params: 1341960 on epoch: 12]
2024-02-19 16:18:25,507 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:18:25,601 - 

2024-02-19 16:18:25,601 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:18:33,822 - Epoch: [13][  100/  391]    Overall Loss 2.193745    Objective Loss 2.193745                                        LR 0.100000    Time 0.082144    
2024-02-19 16:18:42,072 - Epoch: [13][  200/  391]    Overall Loss 2.201809    Objective Loss 2.201809                                        LR 0.100000    Time 0.082299    
2024-02-19 16:18:50,546 - Epoch: [13][  300/  391]    Overall Loss 2.204183    Objective Loss 2.204183                                        LR 0.100000    Time 0.083101    
2024-02-19 16:18:58,409 - Epoch: [13][  391/  391]    Overall Loss 2.202856    Objective Loss 2.202856    Top1 39.903846    Top5 68.750000    LR 0.100000    Time 0.083857    
2024-02-19 16:18:58,607 - --- validate (epoch=13)-----------
2024-02-19 16:18:58,607 - 10000 samples (128 per mini-batch)
2024-02-19 16:19:01,178 - Epoch: [13][   79/   79]    Loss 3.709286    Top1 22.120000    Top5 47.120000    
2024-02-19 16:19:01,343 - ==> Top1: 22.120    Top5: 47.120    Loss: 3.709

2024-02-19 16:19:01,362 - ==> Best [Top1: 36.210   Top5: 69.180   Sparsity:0.00   Params: 1341960 on epoch: 12]
2024-02-19 16:19:01,363 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:19:01,438 - 

2024-02-19 16:19:01,438 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:19:11,378 - Epoch: [14][  100/  391]    Overall Loss 2.149988    Objective Loss 2.149988                                        LR 0.100000    Time 0.099328    
2024-02-19 16:19:20,650 - Epoch: [14][  200/  391]    Overall Loss 2.156148    Objective Loss 2.156148                                        LR 0.100000    Time 0.095998    
2024-02-19 16:19:29,101 - Epoch: [14][  300/  391]    Overall Loss 2.161825    Objective Loss 2.161825                                        LR 0.100000    Time 0.092157    
2024-02-19 16:19:37,170 - Epoch: [14][  391/  391]    Overall Loss 2.157114    Objective Loss 2.157114    Top1 41.826923    Top5 75.000000    LR 0.100000    Time 0.091335    
2024-02-19 16:19:37,398 - --- validate (epoch=14)-----------
2024-02-19 16:19:37,399 - 10000 samples (128 per mini-batch)
2024-02-19 16:19:40,080 - Epoch: [14][   79/   79]    Loss 2.429733    Top1 36.470000    Top5 68.480000    
2024-02-19 16:19:40,289 - ==> Top1: 36.470    Top5: 68.480    Loss: 2.430

2024-02-19 16:19:40,307 - ==> Best [Top1: 36.470   Top5: 68.480   Sparsity:0.00   Params: 1341960 on epoch: 14]
2024-02-19 16:19:40,308 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:19:40,401 - 

2024-02-19 16:19:40,401 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:19:50,250 - Epoch: [15][  100/  391]    Overall Loss 2.120016    Objective Loss 2.120016                                        LR 0.100000    Time 0.098415    
2024-02-19 16:19:59,682 - Epoch: [15][  200/  391]    Overall Loss 2.116726    Objective Loss 2.116726                                        LR 0.100000    Time 0.096341    
2024-02-19 16:20:07,389 - Epoch: [15][  300/  391]    Overall Loss 2.114391    Objective Loss 2.114391                                        LR 0.100000    Time 0.089905    
2024-02-19 16:20:15,750 - Epoch: [15][  391/  391]    Overall Loss 2.116584    Objective Loss 2.116584    Top1 47.596154    Top5 78.846154    LR 0.100000    Time 0.090353    
2024-02-19 16:20:15,967 - --- validate (epoch=15)-----------
2024-02-19 16:20:15,968 - 10000 samples (128 per mini-batch)
2024-02-19 16:20:18,645 - Epoch: [15][   79/   79]    Loss 2.365633    Top1 37.020000    Top5 70.350000    
2024-02-19 16:20:18,839 - ==> Top1: 37.020    Top5: 70.350    Loss: 2.366

2024-02-19 16:20:18,849 - ==> Best [Top1: 37.020   Top5: 70.350   Sparsity:0.00   Params: 1341960 on epoch: 15]
2024-02-19 16:20:18,849 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:20:18,939 - 

2024-02-19 16:20:18,940 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:20:28,611 - Epoch: [16][  100/  391]    Overall Loss 2.047925    Objective Loss 2.047925                                        LR 0.100000    Time 0.096638    
2024-02-19 16:20:37,861 - Epoch: [16][  200/  391]    Overall Loss 2.072812    Objective Loss 2.072812                                        LR 0.100000    Time 0.094544    
2024-02-19 16:20:47,133 - Epoch: [16][  300/  391]    Overall Loss 2.064370    Objective Loss 2.064370                                        LR 0.100000    Time 0.093922    
2024-02-19 16:20:55,566 - Epoch: [16][  391/  391]    Overall Loss 2.064254    Objective Loss 2.064254    Top1 44.230769    Top5 77.403846    LR 0.100000    Time 0.093618    
2024-02-19 16:20:55,762 - --- validate (epoch=16)-----------
2024-02-19 16:20:55,762 - 10000 samples (128 per mini-batch)
2024-02-19 16:20:58,546 - Epoch: [16][   79/   79]    Loss 2.320833    Top1 38.740000    Top5 71.180000    
2024-02-19 16:20:58,757 - ==> Top1: 38.740    Top5: 71.180    Loss: 2.321

2024-02-19 16:20:58,775 - ==> Best [Top1: 38.740   Top5: 71.180   Sparsity:0.00   Params: 1341960 on epoch: 16]
2024-02-19 16:20:58,775 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:20:58,867 - 

2024-02-19 16:20:58,868 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:21:08,831 - Epoch: [17][  100/  391]    Overall Loss 2.010597    Objective Loss 2.010597                                        LR 0.100000    Time 0.099561    
2024-02-19 16:21:18,210 - Epoch: [17][  200/  391]    Overall Loss 2.013927    Objective Loss 2.013927                                        LR 0.100000    Time 0.096653    
2024-02-19 16:21:27,554 - Epoch: [17][  300/  391]    Overall Loss 2.022046    Objective Loss 2.022046                                        LR 0.100000    Time 0.095567    
2024-02-19 16:21:36,141 - Epoch: [17][  391/  391]    Overall Loss 2.025805    Objective Loss 2.025805    Top1 44.230769    Top5 77.403846    LR 0.100000    Time 0.095274    
2024-02-19 16:21:36,343 - --- validate (epoch=17)-----------
2024-02-19 16:21:36,345 - 10000 samples (128 per mini-batch)
2024-02-19 16:21:38,940 - Epoch: [17][   79/   79]    Loss 2.210307    Top1 40.720000    Top5 73.640000    
2024-02-19 16:21:39,137 - ==> Top1: 40.720    Top5: 73.640    Loss: 2.210

2024-02-19 16:21:39,146 - ==> Best [Top1: 40.720   Top5: 73.640   Sparsity:0.00   Params: 1341960 on epoch: 17]
2024-02-19 16:21:39,147 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:21:39,235 - 

2024-02-19 16:21:39,235 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:21:49,324 - Epoch: [18][  100/  391]    Overall Loss 2.002099    Objective Loss 2.002099                                        LR 0.100000    Time 0.100808    
2024-02-19 16:21:58,651 - Epoch: [18][  200/  391]    Overall Loss 1.996806    Objective Loss 1.996806                                        LR 0.100000    Time 0.097018    
2024-02-19 16:22:07,809 - Epoch: [18][  300/  391]    Overall Loss 2.003348    Objective Loss 2.003348                                        LR 0.100000    Time 0.095191    
2024-02-19 16:22:16,069 - Epoch: [18][  391/  391]    Overall Loss 2.002153    Objective Loss 2.002153    Top1 42.788462    Top5 75.000000    LR 0.100000    Time 0.094149    
2024-02-19 16:22:16,238 - --- validate (epoch=18)-----------
2024-02-19 16:22:16,239 - 10000 samples (128 per mini-batch)
2024-02-19 16:22:18,757 - Epoch: [18][   79/   79]    Loss 2.192672    Top1 41.320000    Top5 74.030000    
2024-02-19 16:22:18,941 - ==> Top1: 41.320    Top5: 74.030    Loss: 2.193

2024-02-19 16:22:18,958 - ==> Best [Top1: 41.320   Top5: 74.030   Sparsity:0.00   Params: 1341960 on epoch: 18]
2024-02-19 16:22:18,958 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:22:19,049 - 

2024-02-19 16:22:19,050 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:22:28,716 - Epoch: [19][  100/  391]    Overall Loss 1.957174    Objective Loss 1.957174                                        LR 0.100000    Time 0.096588    
2024-02-19 16:22:37,937 - Epoch: [19][  200/  391]    Overall Loss 1.959424    Objective Loss 1.959424                                        LR 0.100000    Time 0.094377    
2024-02-19 16:22:47,237 - Epoch: [19][  300/  391]    Overall Loss 1.953811    Objective Loss 1.953811                                        LR 0.100000    Time 0.093904    
2024-02-19 16:22:55,804 - Epoch: [19][  391/  391]    Overall Loss 1.957145    Objective Loss 1.957145    Top1 46.634615    Top5 79.807692    LR 0.100000    Time 0.093946    
2024-02-19 16:22:56,075 - --- validate (epoch=19)-----------
2024-02-19 16:22:56,076 - 10000 samples (128 per mini-batch)
2024-02-19 16:22:58,721 - Epoch: [19][   79/   79]    Loss 2.076991    Top1 42.880000    Top5 75.840000    
2024-02-19 16:22:58,936 - ==> Top1: 42.880    Top5: 75.840    Loss: 2.077

2024-02-19 16:22:58,954 - ==> Best [Top1: 42.880   Top5: 75.840   Sparsity:0.00   Params: 1341960 on epoch: 19]
2024-02-19 16:22:58,954 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:22:59,047 - 

2024-02-19 16:22:59,047 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:23:08,789 - Epoch: [20][  100/  391]    Overall Loss 1.917232    Objective Loss 1.917232                                        LR 0.100000    Time 0.097341    
2024-02-19 16:23:18,076 - Epoch: [20][  200/  391]    Overall Loss 1.918055    Objective Loss 1.918055                                        LR 0.100000    Time 0.095080    
2024-02-19 16:23:27,420 - Epoch: [20][  300/  391]    Overall Loss 1.924079    Objective Loss 1.924079                                        LR 0.100000    Time 0.094518    
2024-02-19 16:23:35,921 - Epoch: [20][  391/  391]    Overall Loss 1.920631    Objective Loss 1.920631    Top1 50.480769    Top5 82.692308    LR 0.100000    Time 0.094249    
2024-02-19 16:23:36,219 - --- validate (epoch=20)-----------
2024-02-19 16:23:36,220 - 10000 samples (128 per mini-batch)
2024-02-19 16:23:38,755 - Epoch: [20][   79/   79]    Loss 2.159016    Top1 40.930000    Top5 75.230000    
2024-02-19 16:23:38,913 - ==> Top1: 40.930    Top5: 75.230    Loss: 2.159

2024-02-19 16:23:38,931 - ==> Best [Top1: 42.880   Top5: 75.840   Sparsity:0.00   Params: 1341960 on epoch: 19]
2024-02-19 16:23:38,931 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:23:39,005 - 

2024-02-19 16:23:39,005 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:23:48,842 - Epoch: [21][  100/  391]    Overall Loss 1.908032    Objective Loss 1.908032                                        LR 0.100000    Time 0.098298    
2024-02-19 16:23:57,923 - Epoch: [21][  200/  391]    Overall Loss 1.902803    Objective Loss 1.902803                                        LR 0.100000    Time 0.094532    
2024-02-19 16:24:07,158 - Epoch: [21][  300/  391]    Overall Loss 1.902629    Objective Loss 1.902629                                        LR 0.100000    Time 0.093787    
2024-02-19 16:24:15,590 - Epoch: [21][  391/  391]    Overall Loss 1.899149    Objective Loss 1.899149    Top1 44.230769    Top5 75.961538    LR 0.100000    Time 0.093515    
2024-02-19 16:24:15,770 - --- validate (epoch=21)-----------
2024-02-19 16:24:15,771 - 10000 samples (128 per mini-batch)
2024-02-19 16:24:18,325 - Epoch: [21][   79/   79]    Loss 2.036169    Top1 44.570000    Top5 76.830000    
2024-02-19 16:24:18,488 - ==> Top1: 44.570    Top5: 76.830    Loss: 2.036

2024-02-19 16:24:18,506 - ==> Best [Top1: 44.570   Top5: 76.830   Sparsity:0.00   Params: 1341960 on epoch: 21]
2024-02-19 16:24:18,506 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:24:18,598 - 

2024-02-19 16:24:18,598 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:24:28,277 - Epoch: [22][  100/  391]    Overall Loss 1.867678    Objective Loss 1.867678                                        LR 0.100000    Time 0.096719    
2024-02-19 16:24:37,469 - Epoch: [22][  200/  391]    Overall Loss 1.858907    Objective Loss 1.858907                                        LR 0.100000    Time 0.094295    
2024-02-19 16:24:46,975 - Epoch: [22][  300/  391]    Overall Loss 1.868168    Objective Loss 1.868168                                        LR 0.100000    Time 0.094535    
2024-02-19 16:24:55,599 - Epoch: [22][  391/  391]    Overall Loss 1.867814    Objective Loss 1.867814    Top1 46.634615    Top5 80.288462    LR 0.100000    Time 0.094580    
2024-02-19 16:24:55,829 - --- validate (epoch=22)-----------
2024-02-19 16:24:55,830 - 10000 samples (128 per mini-batch)
2024-02-19 16:24:58,752 - Epoch: [22][   79/   79]    Loss 2.015076    Top1 44.960000    Top5 77.410000    
2024-02-19 16:24:58,943 - ==> Top1: 44.960    Top5: 77.410    Loss: 2.015

2024-02-19 16:24:58,962 - ==> Best [Top1: 44.960   Top5: 77.410   Sparsity:0.00   Params: 1341960 on epoch: 22]
2024-02-19 16:24:58,963 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:24:59,055 - 

2024-02-19 16:24:59,055 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:25:09,081 - Epoch: [23][  100/  391]    Overall Loss 1.836784    Objective Loss 1.836784                                        LR 0.100000    Time 0.100184    
2024-02-19 16:25:18,425 - Epoch: [23][  200/  391]    Overall Loss 1.845296    Objective Loss 1.845296                                        LR 0.100000    Time 0.096789    
2024-02-19 16:25:27,687 - Epoch: [23][  300/  391]    Overall Loss 1.845424    Objective Loss 1.845424                                        LR 0.100000    Time 0.095384    
2024-02-19 16:25:36,453 - Epoch: [23][  391/  391]    Overall Loss 1.846385    Objective Loss 1.846385    Top1 42.788462    Top5 74.519231    LR 0.100000    Time 0.095594    
2024-02-19 16:25:36,686 - --- validate (epoch=23)-----------
2024-02-19 16:25:36,687 - 10000 samples (128 per mini-batch)
2024-02-19 16:25:39,490 - Epoch: [23][   79/   79]    Loss 2.083110    Top1 44.040000    Top5 76.330000    
2024-02-19 16:25:39,655 - ==> Top1: 44.040    Top5: 76.330    Loss: 2.083

2024-02-19 16:25:39,673 - ==> Best [Top1: 44.960   Top5: 77.410   Sparsity:0.00   Params: 1341960 on epoch: 22]
2024-02-19 16:25:39,673 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:25:39,750 - 

2024-02-19 16:25:39,751 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:25:50,003 - Epoch: [24][  100/  391]    Overall Loss 1.795736    Objective Loss 1.795736                                        LR 0.100000    Time 0.102450    
2024-02-19 16:25:59,343 - Epoch: [24][  200/  391]    Overall Loss 1.800785    Objective Loss 1.800785                                        LR 0.100000    Time 0.097901    
2024-02-19 16:26:08,209 - Epoch: [24][  300/  391]    Overall Loss 1.814031    Objective Loss 1.814031                                        LR 0.100000    Time 0.094805    
2024-02-19 16:26:16,538 - Epoch: [24][  391/  391]    Overall Loss 1.819678    Objective Loss 1.819678    Top1 53.365385    Top5 83.653846    LR 0.100000    Time 0.094034    
2024-02-19 16:26:16,758 - --- validate (epoch=24)-----------
2024-02-19 16:26:16,759 - 10000 samples (128 per mini-batch)
2024-02-19 16:26:19,682 - Epoch: [24][   79/   79]    Loss 2.628696    Top1 35.390000    Top5 68.330000    
2024-02-19 16:26:19,900 - ==> Top1: 35.390    Top5: 68.330    Loss: 2.629

2024-02-19 16:26:19,928 - ==> Best [Top1: 44.960   Top5: 77.410   Sparsity:0.00   Params: 1341960 on epoch: 22]
2024-02-19 16:26:19,928 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:26:20,002 - 

2024-02-19 16:26:20,002 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:26:28,390 - Epoch: [25][  100/  391]    Overall Loss 1.772238    Objective Loss 1.772238                                        LR 0.100000    Time 0.083811    
2024-02-19 16:26:35,406 - Epoch: [25][  200/  391]    Overall Loss 1.775472    Objective Loss 1.775472                                        LR 0.100000    Time 0.076964    
2024-02-19 16:26:42,617 - Epoch: [25][  300/  391]    Overall Loss 1.788799    Objective Loss 1.788799                                        LR 0.100000    Time 0.075334    
2024-02-19 16:26:49,007 - Epoch: [25][  391/  391]    Overall Loss 1.791222    Objective Loss 1.791222    Top1 48.076923    Top5 81.730769    LR 0.100000    Time 0.074136    
2024-02-19 16:26:49,224 - --- validate (epoch=25)-----------
2024-02-19 16:26:49,225 - 10000 samples (128 per mini-batch)
2024-02-19 16:26:51,801 - Epoch: [25][   79/   79]    Loss 2.358221    Top1 39.670000    Top5 71.360000    
2024-02-19 16:26:52,030 - ==> Top1: 39.670    Top5: 71.360    Loss: 2.358

2024-02-19 16:26:52,047 - ==> Best [Top1: 44.960   Top5: 77.410   Sparsity:0.00   Params: 1341960 on epoch: 22]
2024-02-19 16:26:52,048 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:26:52,122 - 

2024-02-19 16:26:52,123 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:27:01,316 - Epoch: [26][  100/  391]    Overall Loss 1.733931    Objective Loss 1.733931                                        LR 0.100000    Time 0.091868    
2024-02-19 16:27:10,349 - Epoch: [26][  200/  391]    Overall Loss 1.755922    Objective Loss 1.755922                                        LR 0.100000    Time 0.091074    
2024-02-19 16:27:19,674 - Epoch: [26][  300/  391]    Overall Loss 1.762424    Objective Loss 1.762424                                        LR 0.100000    Time 0.091784    
2024-02-19 16:27:28,114 - Epoch: [26][  391/  391]    Overall Loss 1.766247    Objective Loss 1.766247    Top1 51.442308    Top5 82.692308    LR 0.100000    Time 0.091998    
2024-02-19 16:27:28,339 - --- validate (epoch=26)-----------
2024-02-19 16:27:28,340 - 10000 samples (128 per mini-batch)
2024-02-19 16:27:30,905 - Epoch: [26][   79/   79]    Loss 2.096929    Top1 43.990000    Top5 76.130000    
2024-02-19 16:27:31,058 - ==> Top1: 43.990    Top5: 76.130    Loss: 2.097

2024-02-19 16:27:31,076 - ==> Best [Top1: 44.960   Top5: 77.410   Sparsity:0.00   Params: 1341960 on epoch: 22]
2024-02-19 16:27:31,076 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:27:31,152 - 

2024-02-19 16:27:31,153 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:27:40,667 - Epoch: [27][  100/  391]    Overall Loss 1.701968    Objective Loss 1.701968                                        LR 0.100000    Time 0.095068    
2024-02-19 16:27:49,991 - Epoch: [27][  200/  391]    Overall Loss 1.725346    Objective Loss 1.725346                                        LR 0.100000    Time 0.094128    
2024-02-19 16:27:59,302 - Epoch: [27][  300/  391]    Overall Loss 1.735624    Objective Loss 1.735624                                        LR 0.100000    Time 0.093773    
2024-02-19 16:28:07,306 - Epoch: [27][  391/  391]    Overall Loss 1.742071    Objective Loss 1.742071    Top1 48.076923    Top5 81.250000    LR 0.100000    Time 0.092408    
2024-02-19 16:28:07,552 - --- validate (epoch=27)-----------
2024-02-19 16:28:07,553 - 10000 samples (128 per mini-batch)
2024-02-19 16:28:10,192 - Epoch: [27][   79/   79]    Loss 2.224197    Top1 41.210000    Top5 73.400000    
2024-02-19 16:28:10,384 - ==> Top1: 41.210    Top5: 73.400    Loss: 2.224

2024-02-19 16:28:10,402 - ==> Best [Top1: 44.960   Top5: 77.410   Sparsity:0.00   Params: 1341960 on epoch: 22]
2024-02-19 16:28:10,402 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:28:10,480 - 

2024-02-19 16:28:10,480 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:28:20,261 - Epoch: [28][  100/  391]    Overall Loss 1.722163    Objective Loss 1.722163                                        LR 0.100000    Time 0.097741    
2024-02-19 16:28:29,417 - Epoch: [28][  200/  391]    Overall Loss 1.715269    Objective Loss 1.715269                                        LR 0.100000    Time 0.094625    
2024-02-19 16:28:38,735 - Epoch: [28][  300/  391]    Overall Loss 1.721193    Objective Loss 1.721193                                        LR 0.100000    Time 0.094127    
2024-02-19 16:28:47,285 - Epoch: [28][  391/  391]    Overall Loss 1.723180    Objective Loss 1.723180    Top1 50.961538    Top5 80.769231    LR 0.100000    Time 0.094078    
2024-02-19 16:28:47,455 - --- validate (epoch=28)-----------
2024-02-19 16:28:47,456 - 10000 samples (128 per mini-batch)
2024-02-19 16:28:50,183 - Epoch: [28][   79/   79]    Loss 2.306765    Top1 40.140000    Top5 72.850000    
2024-02-19 16:28:50,342 - ==> Top1: 40.140    Top5: 72.850    Loss: 2.307

2024-02-19 16:28:50,360 - ==> Best [Top1: 44.960   Top5: 77.410   Sparsity:0.00   Params: 1341960 on epoch: 22]
2024-02-19 16:28:50,361 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:28:50,436 - 

2024-02-19 16:28:50,436 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:29:00,372 - Epoch: [29][  100/  391]    Overall Loss 1.684613    Objective Loss 1.684613                                        LR 0.100000    Time 0.099279    
2024-02-19 16:29:09,620 - Epoch: [29][  200/  391]    Overall Loss 1.698510    Objective Loss 1.698510                                        LR 0.100000    Time 0.095855    
2024-02-19 16:29:18,919 - Epoch: [29][  300/  391]    Overall Loss 1.710720    Objective Loss 1.710720                                        LR 0.100000    Time 0.094885    
2024-02-19 16:29:27,399 - Epoch: [29][  391/  391]    Overall Loss 1.714815    Objective Loss 1.714815    Top1 50.000000    Top5 83.173077    LR 0.100000    Time 0.094478    
2024-02-19 16:29:27,567 - --- validate (epoch=29)-----------
2024-02-19 16:29:27,568 - 10000 samples (128 per mini-batch)
2024-02-19 16:29:30,270 - Epoch: [29][   79/   79]    Loss 2.234177    Top1 42.070000    Top5 73.000000    
2024-02-19 16:29:30,478 - ==> Top1: 42.070    Top5: 73.000    Loss: 2.234

2024-02-19 16:29:30,493 - ==> Best [Top1: 44.960   Top5: 77.410   Sparsity:0.00   Params: 1341960 on epoch: 22]
2024-02-19 16:29:30,493 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:29:30,570 - 

2024-02-19 16:29:30,571 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:29:40,358 - Epoch: [30][  100/  391]    Overall Loss 1.644164    Objective Loss 1.644164                                        LR 0.100000    Time 0.097803    
2024-02-19 16:29:49,613 - Epoch: [30][  200/  391]    Overall Loss 1.668109    Objective Loss 1.668109                                        LR 0.100000    Time 0.095153    
2024-02-19 16:29:58,882 - Epoch: [30][  300/  391]    Overall Loss 1.679802    Objective Loss 1.679802                                        LR 0.100000    Time 0.094317    
2024-02-19 16:30:07,387 - Epoch: [30][  391/  391]    Overall Loss 1.683561    Objective Loss 1.683561    Top1 51.923077    Top5 85.096154    LR 0.100000    Time 0.094107    
2024-02-19 16:30:07,586 - --- validate (epoch=30)-----------
2024-02-19 16:30:07,587 - 10000 samples (128 per mini-batch)
2024-02-19 16:30:10,308 - Epoch: [30][   79/   79]    Loss 2.379153    Top1 39.670000    Top5 71.900000    
2024-02-19 16:30:10,485 - ==> Top1: 39.670    Top5: 71.900    Loss: 2.379

2024-02-19 16:30:10,504 - ==> Best [Top1: 44.960   Top5: 77.410   Sparsity:0.00   Params: 1341960 on epoch: 22]
2024-02-19 16:30:10,505 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:30:10,586 - 

2024-02-19 16:30:10,586 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:30:20,758 - Epoch: [31][  100/  391]    Overall Loss 1.661652    Objective Loss 1.661652                                        LR 0.100000    Time 0.101628    
2024-02-19 16:30:30,037 - Epoch: [31][  200/  391]    Overall Loss 1.659721    Objective Loss 1.659721                                        LR 0.100000    Time 0.097186    
2024-02-19 16:30:39,359 - Epoch: [31][  300/  391]    Overall Loss 1.663134    Objective Loss 1.663134                                        LR 0.100000    Time 0.095848    
2024-02-19 16:30:47,414 - Epoch: [31][  391/  391]    Overall Loss 1.668387    Objective Loss 1.668387    Top1 56.730769    Top5 82.692308    LR 0.100000    Time 0.094130    
2024-02-19 16:30:47,567 - --- validate (epoch=31)-----------
2024-02-19 16:30:47,567 - 10000 samples (128 per mini-batch)
2024-02-19 16:30:50,396 - Epoch: [31][   79/   79]    Loss 1.868021    Top1 48.600000    Top5 80.400000    
2024-02-19 16:30:50,567 - ==> Top1: 48.600    Top5: 80.400    Loss: 1.868

2024-02-19 16:30:50,579 - ==> Best [Top1: 48.600   Top5: 80.400   Sparsity:0.00   Params: 1341960 on epoch: 31]
2024-02-19 16:30:50,579 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:30:50,674 - 

2024-02-19 16:30:50,674 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:31:00,750 - Epoch: [32][  100/  391]    Overall Loss 1.627926    Objective Loss 1.627926                                        LR 0.100000    Time 0.100680    
2024-02-19 16:31:10,100 - Epoch: [32][  200/  391]    Overall Loss 1.643109    Objective Loss 1.643109                                        LR 0.100000    Time 0.097066    
2024-02-19 16:31:19,564 - Epoch: [32][  300/  391]    Overall Loss 1.644081    Objective Loss 1.644081                                        LR 0.100000    Time 0.096243    
2024-02-19 16:31:27,836 - Epoch: [32][  391/  391]    Overall Loss 1.646557    Objective Loss 1.646557    Top1 48.076923    Top5 83.653846    LR 0.100000    Time 0.094989    
2024-02-19 16:31:28,082 - --- validate (epoch=32)-----------
2024-02-19 16:31:28,083 - 10000 samples (128 per mini-batch)
2024-02-19 16:31:31,201 - Epoch: [32][   79/   79]    Loss 1.976561    Top1 45.680000    Top5 78.180000    
2024-02-19 16:31:31,428 - ==> Top1: 45.680    Top5: 78.180    Loss: 1.977

2024-02-19 16:31:31,447 - ==> Best [Top1: 48.600   Top5: 80.400   Sparsity:0.00   Params: 1341960 on epoch: 31]
2024-02-19 16:31:31,447 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:31:31,521 - 

2024-02-19 16:31:31,521 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:31:41,215 - Epoch: [33][  100/  391]    Overall Loss 1.595683    Objective Loss 1.595683                                        LR 0.100000    Time 0.096865    
2024-02-19 16:31:50,412 - Epoch: [33][  200/  391]    Overall Loss 1.606158    Objective Loss 1.606158                                        LR 0.100000    Time 0.094393    
2024-02-19 16:31:59,684 - Epoch: [33][  300/  391]    Overall Loss 1.621585    Objective Loss 1.621585                                        LR 0.100000    Time 0.093822    
2024-02-19 16:32:07,918 - Epoch: [33][  391/  391]    Overall Loss 1.629625    Objective Loss 1.629625    Top1 54.807692    Top5 82.211538    LR 0.100000    Time 0.093033    
2024-02-19 16:32:08,118 - --- validate (epoch=33)-----------
2024-02-19 16:32:08,120 - 10000 samples (128 per mini-batch)
2024-02-19 16:32:10,722 - Epoch: [33][   79/   79]    Loss 1.999365    Top1 46.460000    Top5 78.210000    
2024-02-19 16:32:10,950 - ==> Top1: 46.460    Top5: 78.210    Loss: 1.999

2024-02-19 16:32:10,968 - ==> Best [Top1: 48.600   Top5: 80.400   Sparsity:0.00   Params: 1341960 on epoch: 31]
2024-02-19 16:32:10,968 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:32:11,042 - 

2024-02-19 16:32:11,042 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:32:21,228 - Epoch: [34][  100/  391]    Overall Loss 1.594835    Objective Loss 1.594835                                        LR 0.100000    Time 0.101780    
2024-02-19 16:32:30,567 - Epoch: [34][  200/  391]    Overall Loss 1.604233    Objective Loss 1.604233                                        LR 0.100000    Time 0.097564    
2024-02-19 16:32:39,965 - Epoch: [34][  300/  391]    Overall Loss 1.605438    Objective Loss 1.605438                                        LR 0.100000    Time 0.096352    
2024-02-19 16:32:48,400 - Epoch: [34][  391/  391]    Overall Loss 1.612352    Objective Loss 1.612352    Top1 54.807692    Top5 87.500000    LR 0.100000    Time 0.095489    
2024-02-19 16:32:48,659 - --- validate (epoch=34)-----------
2024-02-19 16:32:48,660 - 10000 samples (128 per mini-batch)
2024-02-19 16:32:51,262 - Epoch: [34][   79/   79]    Loss 2.018327    Top1 46.060000    Top5 77.830000    
2024-02-19 16:32:51,418 - ==> Top1: 46.060    Top5: 77.830    Loss: 2.018

2024-02-19 16:32:51,437 - ==> Best [Top1: 48.600   Top5: 80.400   Sparsity:0.00   Params: 1341960 on epoch: 31]
2024-02-19 16:32:51,437 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:32:51,521 - 

2024-02-19 16:32:51,521 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:33:01,430 - Epoch: [35][  100/  391]    Overall Loss 1.575489    Objective Loss 1.575489                                        LR 0.100000    Time 0.099017    
2024-02-19 16:33:10,724 - Epoch: [35][  200/  391]    Overall Loss 1.586312    Objective Loss 1.586312                                        LR 0.100000    Time 0.095954    
2024-02-19 16:33:19,973 - Epoch: [35][  300/  391]    Overall Loss 1.602771    Objective Loss 1.602771                                        LR 0.100000    Time 0.094782    
2024-02-19 16:33:28,447 - Epoch: [35][  391/  391]    Overall Loss 1.606899    Objective Loss 1.606899    Top1 51.442308    Top5 86.057692    LR 0.100000    Time 0.094385    
2024-02-19 16:33:28,612 - --- validate (epoch=35)-----------
2024-02-19 16:33:28,613 - 10000 samples (128 per mini-batch)
2024-02-19 16:33:31,257 - Epoch: [35][   79/   79]    Loss 1.989054    Top1 45.770000    Top5 77.170000    
2024-02-19 16:33:31,443 - ==> Top1: 45.770    Top5: 77.170    Loss: 1.989

2024-02-19 16:33:31,461 - ==> Best [Top1: 48.600   Top5: 80.400   Sparsity:0.00   Params: 1341960 on epoch: 31]
2024-02-19 16:33:31,461 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:33:31,536 - 

2024-02-19 16:33:31,536 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:33:41,734 - Epoch: [36][  100/  391]    Overall Loss 1.539836    Objective Loss 1.539836                                        LR 0.100000    Time 0.101904    
2024-02-19 16:33:51,076 - Epoch: [36][  200/  391]    Overall Loss 1.562597    Objective Loss 1.562597                                        LR 0.100000    Time 0.097637    
2024-02-19 16:34:00,455 - Epoch: [36][  300/  391]    Overall Loss 1.576128    Objective Loss 1.576128                                        LR 0.100000    Time 0.096342    
2024-02-19 16:34:08,097 - Epoch: [36][  391/  391]    Overall Loss 1.586168    Objective Loss 1.586168    Top1 52.403846    Top5 86.057692    LR 0.100000    Time 0.093453    
2024-02-19 16:34:08,383 - --- validate (epoch=36)-----------
2024-02-19 16:34:08,383 - 10000 samples (128 per mini-batch)
2024-02-19 16:34:11,087 - Epoch: [36][   79/   79]    Loss 1.807605    Top1 50.040000    Top5 81.320000    
2024-02-19 16:34:11,224 - ==> Top1: 50.040    Top5: 81.320    Loss: 1.808

2024-02-19 16:34:11,245 - ==> Best [Top1: 50.040   Top5: 81.320   Sparsity:0.00   Params: 1341960 on epoch: 36]
2024-02-19 16:34:11,245 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:34:11,341 - 

2024-02-19 16:34:11,341 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:34:18,962 - Epoch: [37][  100/  391]    Overall Loss 1.568262    Objective Loss 1.568262                                        LR 0.100000    Time 0.076143    
2024-02-19 16:34:25,932 - Epoch: [37][  200/  391]    Overall Loss 1.577324    Objective Loss 1.577324                                        LR 0.100000    Time 0.072904    
2024-02-19 16:34:32,883 - Epoch: [37][  300/  391]    Overall Loss 1.573395    Objective Loss 1.573395                                        LR 0.100000    Time 0.071760    
2024-02-19 16:34:40,179 - Epoch: [37][  391/  391]    Overall Loss 1.579745    Objective Loss 1.579745    Top1 52.884615    Top5 84.134615    LR 0.100000    Time 0.073709    
2024-02-19 16:34:40,495 - --- validate (epoch=37)-----------
2024-02-19 16:34:40,496 - 10000 samples (128 per mini-batch)
2024-02-19 16:34:43,230 - Epoch: [37][   79/   79]    Loss 2.064832    Top1 45.690000    Top5 76.750000    
2024-02-19 16:34:43,441 - ==> Top1: 45.690    Top5: 76.750    Loss: 2.065

2024-02-19 16:34:43,459 - ==> Best [Top1: 50.040   Top5: 81.320   Sparsity:0.00   Params: 1341960 on epoch: 36]
2024-02-19 16:34:43,460 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:34:43,531 - 

2024-02-19 16:34:43,532 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:34:53,566 - Epoch: [38][  100/  391]    Overall Loss 1.527588    Objective Loss 1.527588                                        LR 0.100000    Time 0.100280    
2024-02-19 16:35:02,667 - Epoch: [38][  200/  391]    Overall Loss 1.537939    Objective Loss 1.537939                                        LR 0.100000    Time 0.095618    
2024-02-19 16:35:11,815 - Epoch: [38][  300/  391]    Overall Loss 1.550885    Objective Loss 1.550885                                        LR 0.100000    Time 0.094225    
2024-02-19 16:35:20,445 - Epoch: [38][  391/  391]    Overall Loss 1.551893    Objective Loss 1.551893    Top1 51.923077    Top5 85.096154    LR 0.100000    Time 0.094355    
2024-02-19 16:35:20,641 - --- validate (epoch=38)-----------
2024-02-19 16:35:20,643 - 10000 samples (128 per mini-batch)
2024-02-19 16:35:23,246 - Epoch: [38][   79/   79]    Loss 1.979522    Top1 47.710000    Top5 78.950000    
2024-02-19 16:35:23,454 - ==> Top1: 47.710    Top5: 78.950    Loss: 1.980

2024-02-19 16:35:23,472 - ==> Best [Top1: 50.040   Top5: 81.320   Sparsity:0.00   Params: 1341960 on epoch: 36]
2024-02-19 16:35:23,473 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:35:23,548 - 

2024-02-19 16:35:23,548 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:35:30,912 - Epoch: [39][  100/  391]    Overall Loss 1.531712    Objective Loss 1.531712                                        LR 0.100000    Time 0.073572    
2024-02-19 16:35:38,665 - Epoch: [39][  200/  391]    Overall Loss 1.542680    Objective Loss 1.542680                                        LR 0.100000    Time 0.075529    
2024-02-19 16:35:47,844 - Epoch: [39][  300/  391]    Overall Loss 1.548814    Objective Loss 1.548814                                        LR 0.100000    Time 0.080934    
2024-02-19 16:35:56,247 - Epoch: [39][  391/  391]    Overall Loss 1.550180    Objective Loss 1.550180    Top1 59.134615    Top5 87.019231    LR 0.100000    Time 0.083577    
2024-02-19 16:35:56,500 - --- validate (epoch=39)-----------
2024-02-19 16:35:56,501 - 10000 samples (128 per mini-batch)
2024-02-19 16:35:59,323 - Epoch: [39][   79/   79]    Loss 1.908074    Top1 47.730000    Top5 79.360000    
2024-02-19 16:35:59,479 - ==> Top1: 47.730    Top5: 79.360    Loss: 1.908

2024-02-19 16:35:59,499 - ==> Best [Top1: 50.040   Top5: 81.320   Sparsity:0.00   Params: 1341960 on epoch: 36]
2024-02-19 16:35:59,500 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:35:59,576 - 

2024-02-19 16:35:59,576 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:36:09,523 - Epoch: [40][  100/  391]    Overall Loss 1.499845    Objective Loss 1.499845                                        LR 0.100000    Time 0.099390    
2024-02-19 16:36:18,959 - Epoch: [40][  200/  391]    Overall Loss 1.531605    Objective Loss 1.531605                                        LR 0.100000    Time 0.096854    
2024-02-19 16:36:28,356 - Epoch: [40][  300/  391]    Overall Loss 1.545265    Objective Loss 1.545265                                        LR 0.100000    Time 0.095875    
2024-02-19 16:36:37,011 - Epoch: [40][  391/  391]    Overall Loss 1.539392    Objective Loss 1.539392    Top1 58.173077    Top5 89.903846    LR 0.100000    Time 0.095686    
2024-02-19 16:36:37,196 - --- validate (epoch=40)-----------
2024-02-19 16:36:37,197 - 10000 samples (128 per mini-batch)
2024-02-19 16:36:40,047 - Epoch: [40][   79/   79]    Loss 1.845986    Top1 48.800000    Top5 80.410000    
2024-02-19 16:36:40,220 - ==> Top1: 48.800    Top5: 80.410    Loss: 1.846

2024-02-19 16:36:40,238 - ==> Best [Top1: 50.040   Top5: 81.320   Sparsity:0.00   Params: 1341960 on epoch: 36]
2024-02-19 16:36:40,239 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:36:40,319 - 

2024-02-19 16:36:40,319 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:36:50,411 - Epoch: [41][  100/  391]    Overall Loss 1.485648    Objective Loss 1.485648                                        LR 0.100000    Time 0.100835    
2024-02-19 16:36:59,781 - Epoch: [41][  200/  391]    Overall Loss 1.491010    Objective Loss 1.491010                                        LR 0.100000    Time 0.097241    
2024-02-19 16:37:09,096 - Epoch: [41][  300/  391]    Overall Loss 1.509338    Objective Loss 1.509338                                        LR 0.100000    Time 0.095860    
2024-02-19 16:37:17,599 - Epoch: [41][  391/  391]    Overall Loss 1.520214    Objective Loss 1.520214    Top1 59.134615    Top5 88.942308    LR 0.100000    Time 0.095285    
2024-02-19 16:37:17,796 - --- validate (epoch=41)-----------
2024-02-19 16:37:17,797 - 10000 samples (128 per mini-batch)
2024-02-19 16:37:20,557 - Epoch: [41][   79/   79]    Loss 1.984574    Top1 46.930000    Top5 77.890000    
2024-02-19 16:37:20,735 - ==> Top1: 46.930    Top5: 77.890    Loss: 1.985

2024-02-19 16:37:20,754 - ==> Best [Top1: 50.040   Top5: 81.320   Sparsity:0.00   Params: 1341960 on epoch: 36]
2024-02-19 16:37:20,754 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:37:20,845 - 

2024-02-19 16:37:20,846 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:37:30,874 - Epoch: [42][  100/  391]    Overall Loss 1.489325    Objective Loss 1.489325                                        LR 0.100000    Time 0.100209    
2024-02-19 16:37:40,063 - Epoch: [42][  200/  391]    Overall Loss 1.483331    Objective Loss 1.483331                                        LR 0.100000    Time 0.096026    
2024-02-19 16:37:49,290 - Epoch: [42][  300/  391]    Overall Loss 1.500461    Objective Loss 1.500461                                        LR 0.100000    Time 0.094756    
2024-02-19 16:37:57,483 - Epoch: [42][  391/  391]    Overall Loss 1.510962    Objective Loss 1.510962    Top1 56.250000    Top5 87.019231    LR 0.100000    Time 0.093648    
2024-02-19 16:37:57,660 - --- validate (epoch=42)-----------
2024-02-19 16:37:57,660 - 10000 samples (128 per mini-batch)
2024-02-19 16:38:00,582 - Epoch: [42][   79/   79]    Loss 1.952823    Top1 47.340000    Top5 78.560000    
2024-02-19 16:38:00,797 - ==> Top1: 47.340    Top5: 78.560    Loss: 1.953

2024-02-19 16:38:00,815 - ==> Best [Top1: 50.040   Top5: 81.320   Sparsity:0.00   Params: 1341960 on epoch: 36]
2024-02-19 16:38:00,815 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:38:00,888 - 

2024-02-19 16:38:00,888 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:38:10,589 - Epoch: [43][  100/  391]    Overall Loss 1.457503    Objective Loss 1.457503                                        LR 0.100000    Time 0.096933    
2024-02-19 16:38:19,695 - Epoch: [43][  200/  391]    Overall Loss 1.475390    Objective Loss 1.475390                                        LR 0.100000    Time 0.093973    
2024-02-19 16:38:28,935 - Epoch: [43][  300/  391]    Overall Loss 1.492215    Objective Loss 1.492215                                        LR 0.100000    Time 0.093432    
2024-02-19 16:38:37,225 - Epoch: [43][  391/  391]    Overall Loss 1.502405    Objective Loss 1.502405    Top1 54.807692    Top5 82.211538    LR 0.100000    Time 0.092878    
2024-02-19 16:38:37,450 - --- validate (epoch=43)-----------
2024-02-19 16:38:37,451 - 10000 samples (128 per mini-batch)
2024-02-19 16:38:40,232 - Epoch: [43][   79/   79]    Loss 1.839245    Top1 48.860000    Top5 81.150000    
2024-02-19 16:38:40,393 - ==> Top1: 48.860    Top5: 81.150    Loss: 1.839

2024-02-19 16:38:40,411 - ==> Best [Top1: 50.040   Top5: 81.320   Sparsity:0.00   Params: 1341960 on epoch: 36]
2024-02-19 16:38:40,411 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:38:40,485 - 

2024-02-19 16:38:40,486 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:38:50,406 - Epoch: [44][  100/  391]    Overall Loss 1.465794    Objective Loss 1.465794                                        LR 0.100000    Time 0.099127    
2024-02-19 16:38:59,549 - Epoch: [44][  200/  391]    Overall Loss 1.475357    Objective Loss 1.475357                                        LR 0.100000    Time 0.095254    
2024-02-19 16:39:08,717 - Epoch: [44][  300/  391]    Overall Loss 1.490347    Objective Loss 1.490347                                        LR 0.100000    Time 0.094046    
2024-02-19 16:39:17,233 - Epoch: [44][  391/  391]    Overall Loss 1.492887    Objective Loss 1.492887    Top1 54.807692    Top5 79.326923    LR 0.100000    Time 0.093929    
2024-02-19 16:39:17,481 - --- validate (epoch=44)-----------
2024-02-19 16:39:17,482 - 10000 samples (128 per mini-batch)
2024-02-19 16:39:20,172 - Epoch: [44][   79/   79]    Loss 1.917619    Top1 48.810000    Top5 79.840000    
2024-02-19 16:39:20,388 - ==> Top1: 48.810    Top5: 79.840    Loss: 1.918

2024-02-19 16:39:20,406 - ==> Best [Top1: 50.040   Top5: 81.320   Sparsity:0.00   Params: 1341960 on epoch: 36]
2024-02-19 16:39:20,406 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:39:20,481 - 

2024-02-19 16:39:20,481 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:39:30,407 - Epoch: [45][  100/  391]    Overall Loss 1.433537    Objective Loss 1.433537                                        LR 0.100000    Time 0.099181    
2024-02-19 16:39:39,765 - Epoch: [45][  200/  391]    Overall Loss 1.449299    Objective Loss 1.449299                                        LR 0.100000    Time 0.096358    
2024-02-19 16:39:49,153 - Epoch: [45][  300/  391]    Overall Loss 1.465140    Objective Loss 1.465140                                        LR 0.100000    Time 0.095517    
2024-02-19 16:39:57,765 - Epoch: [45][  391/  391]    Overall Loss 1.475613    Objective Loss 1.475613    Top1 58.173077    Top5 87.019231    LR 0.100000    Time 0.095300    
2024-02-19 16:39:57,992 - --- validate (epoch=45)-----------
2024-02-19 16:39:57,992 - 10000 samples (128 per mini-batch)
2024-02-19 16:40:00,687 - Epoch: [45][   79/   79]    Loss 1.833996    Top1 49.530000    Top5 80.410000    
2024-02-19 16:40:00,929 - ==> Top1: 49.530    Top5: 80.410    Loss: 1.834

2024-02-19 16:40:00,948 - ==> Best [Top1: 50.040   Top5: 81.320   Sparsity:0.00   Params: 1341960 on epoch: 36]
2024-02-19 16:40:00,948 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:40:01,023 - 

2024-02-19 16:40:01,023 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:40:10,595 - Epoch: [46][  100/  391]    Overall Loss 1.404987    Objective Loss 1.404987                                        LR 0.100000    Time 0.095646    
2024-02-19 16:40:19,916 - Epoch: [46][  200/  391]    Overall Loss 1.428167    Objective Loss 1.428167                                        LR 0.100000    Time 0.094406    
2024-02-19 16:40:29,218 - Epoch: [46][  300/  391]    Overall Loss 1.445878    Objective Loss 1.445878                                        LR 0.100000    Time 0.093928    
2024-02-19 16:40:37,724 - Epoch: [46][  391/  391]    Overall Loss 1.459151    Objective Loss 1.459151    Top1 62.019231    Top5 93.269231    LR 0.100000    Time 0.093811    
2024-02-19 16:40:37,871 - --- validate (epoch=46)-----------
2024-02-19 16:40:37,872 - 10000 samples (128 per mini-batch)
2024-02-19 16:40:40,957 - Epoch: [46][   79/   79]    Loss 1.885629    Top1 50.330000    Top5 80.910000    
2024-02-19 16:40:41,152 - ==> Top1: 50.330    Top5: 80.910    Loss: 1.886

2024-02-19 16:40:41,170 - ==> Best [Top1: 50.330   Top5: 80.910   Sparsity:0.00   Params: 1341960 on epoch: 46]
2024-02-19 16:40:41,170 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:40:41,262 - 

2024-02-19 16:40:41,262 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:40:51,217 - Epoch: [47][  100/  391]    Overall Loss 1.427855    Objective Loss 1.427855                                        LR 0.100000    Time 0.099466    
2024-02-19 16:41:00,548 - Epoch: [47][  200/  391]    Overall Loss 1.431328    Objective Loss 1.431328                                        LR 0.100000    Time 0.096363    
2024-02-19 16:41:10,034 - Epoch: [47][  300/  391]    Overall Loss 1.449821    Objective Loss 1.449821                                        LR 0.100000    Time 0.095845    
2024-02-19 16:41:18,542 - Epoch: [47][  391/  391]    Overall Loss 1.456628    Objective Loss 1.456628    Top1 54.807692    Top5 90.384615    LR 0.100000    Time 0.095287    
2024-02-19 16:41:18,746 - --- validate (epoch=47)-----------
2024-02-19 16:41:18,747 - 10000 samples (128 per mini-batch)
2024-02-19 16:41:21,453 - Epoch: [47][   79/   79]    Loss 2.009425    Top1 47.200000    Top5 77.860000    
2024-02-19 16:41:21,683 - ==> Top1: 47.200    Top5: 77.860    Loss: 2.009

2024-02-19 16:41:21,700 - ==> Best [Top1: 50.330   Top5: 80.910   Sparsity:0.00   Params: 1341960 on epoch: 46]
2024-02-19 16:41:21,701 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:41:21,775 - 

2024-02-19 16:41:21,775 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:41:31,958 - Epoch: [48][  100/  391]    Overall Loss 1.426738    Objective Loss 1.426738                                        LR 0.100000    Time 0.101712    
2024-02-19 16:41:41,342 - Epoch: [48][  200/  391]    Overall Loss 1.439196    Objective Loss 1.439196                                        LR 0.100000    Time 0.097752    
2024-02-19 16:41:50,451 - Epoch: [48][  300/  391]    Overall Loss 1.440461    Objective Loss 1.440461                                        LR 0.100000    Time 0.095518    
2024-02-19 16:41:58,608 - Epoch: [48][  391/  391]    Overall Loss 1.447062    Objective Loss 1.447062    Top1 54.807692    Top5 85.096154    LR 0.100000    Time 0.094137    
2024-02-19 16:41:58,813 - --- validate (epoch=48)-----------
2024-02-19 16:41:58,815 - 10000 samples (128 per mini-batch)
2024-02-19 16:42:01,603 - Epoch: [48][   79/   79]    Loss 1.940782    Top1 48.330000    Top5 79.390000    
2024-02-19 16:42:01,788 - ==> Top1: 48.330    Top5: 79.390    Loss: 1.941

2024-02-19 16:42:01,808 - ==> Best [Top1: 50.330   Top5: 80.910   Sparsity:0.00   Params: 1341960 on epoch: 46]
2024-02-19 16:42:01,808 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:42:01,892 - 

2024-02-19 16:42:01,893 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:42:11,770 - Epoch: [49][  100/  391]    Overall Loss 1.422912    Objective Loss 1.422912                                        LR 0.100000    Time 0.098706    
2024-02-19 16:42:20,993 - Epoch: [49][  200/  391]    Overall Loss 1.418644    Objective Loss 1.418644                                        LR 0.100000    Time 0.095447    
2024-02-19 16:42:30,287 - Epoch: [49][  300/  391]    Overall Loss 1.426263    Objective Loss 1.426263                                        LR 0.100000    Time 0.094593    
2024-02-19 16:42:38,842 - Epoch: [49][  391/  391]    Overall Loss 1.433422    Objective Loss 1.433422    Top1 62.019231    Top5 87.019231    LR 0.100000    Time 0.094447    
2024-02-19 16:42:39,031 - --- validate (epoch=49)-----------
2024-02-19 16:42:39,031 - 10000 samples (128 per mini-batch)
2024-02-19 16:42:41,701 - Epoch: [49][   79/   79]    Loss 2.283702    Top1 42.440000    Top5 73.860000    
2024-02-19 16:42:41,864 - ==> Top1: 42.440    Top5: 73.860    Loss: 2.284

2024-02-19 16:42:41,883 - ==> Best [Top1: 50.330   Top5: 80.910   Sparsity:0.00   Params: 1341960 on epoch: 46]
2024-02-19 16:42:41,883 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:42:41,958 - 

2024-02-19 16:42:41,959 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:42:52,026 - Epoch: [50][  100/  391]    Overall Loss 1.403427    Objective Loss 1.403427                                        LR 0.100000    Time 0.100604    
2024-02-19 16:43:01,287 - Epoch: [50][  200/  391]    Overall Loss 1.417837    Objective Loss 1.417837                                        LR 0.100000    Time 0.096578    
2024-02-19 16:43:10,610 - Epoch: [50][  300/  391]    Overall Loss 1.419865    Objective Loss 1.419865                                        LR 0.100000    Time 0.095446    
2024-02-19 16:43:19,076 - Epoch: [50][  391/  391]    Overall Loss 1.429393    Objective Loss 1.429393    Top1 57.211538    Top5 84.615385    LR 0.100000    Time 0.094875    
2024-02-19 16:43:19,305 - --- validate (epoch=50)-----------
2024-02-19 16:43:19,306 - 10000 samples (128 per mini-batch)
2024-02-19 16:43:22,051 - Epoch: [50][   79/   79]    Loss 1.889087    Top1 50.290000    Top5 79.830000    
2024-02-19 16:43:22,258 - ==> Top1: 50.290    Top5: 79.830    Loss: 1.889

2024-02-19 16:43:22,277 - ==> Best [Top1: 50.330   Top5: 80.910   Sparsity:0.00   Params: 1341960 on epoch: 46]
2024-02-19 16:43:22,277 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:43:22,352 - 

2024-02-19 16:43:22,352 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:43:32,198 - Epoch: [51][  100/  391]    Overall Loss 1.368844    Objective Loss 1.368844                                        LR 0.100000    Time 0.098382    
2024-02-19 16:43:41,415 - Epoch: [51][  200/  391]    Overall Loss 1.400591    Objective Loss 1.400591                                        LR 0.100000    Time 0.095256    
2024-02-19 16:43:50,730 - Epoch: [51][  300/  391]    Overall Loss 1.412388    Objective Loss 1.412388                                        LR 0.100000    Time 0.094538    
2024-02-19 16:43:59,266 - Epoch: [51][  391/  391]    Overall Loss 1.425627    Objective Loss 1.425627    Top1 52.403846    Top5 84.615385    LR 0.100000    Time 0.094356    
2024-02-19 16:43:59,525 - --- validate (epoch=51)-----------
2024-02-19 16:43:59,525 - 10000 samples (128 per mini-batch)
2024-02-19 16:44:02,255 - Epoch: [51][   79/   79]    Loss 1.779124    Top1 51.110000    Top5 81.550000    
2024-02-19 16:44:02,411 - ==> Top1: 51.110    Top5: 81.550    Loss: 1.779

2024-02-19 16:44:02,429 - ==> Best [Top1: 51.110   Top5: 81.550   Sparsity:0.00   Params: 1341960 on epoch: 51]
2024-02-19 16:44:02,429 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:44:02,519 - 

2024-02-19 16:44:02,520 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:44:12,417 - Epoch: [52][  100/  391]    Overall Loss 1.356018    Objective Loss 1.356018                                        LR 0.100000    Time 0.098895    
2024-02-19 16:44:21,820 - Epoch: [52][  200/  391]    Overall Loss 1.368702    Objective Loss 1.368702                                        LR 0.100000    Time 0.096438    
2024-02-19 16:44:30,976 - Epoch: [52][  300/  391]    Overall Loss 1.390229    Objective Loss 1.390229                                        LR 0.100000    Time 0.094798    
2024-02-19 16:44:39,502 - Epoch: [52][  391/  391]    Overall Loss 1.396170    Objective Loss 1.396170    Top1 62.980769    Top5 86.538462    LR 0.100000    Time 0.094530    
2024-02-19 16:44:39,651 - --- validate (epoch=52)-----------
2024-02-19 16:44:39,652 - 10000 samples (128 per mini-batch)
2024-02-19 16:44:42,607 - Epoch: [52][   79/   79]    Loss 1.752732    Top1 51.550000    Top5 81.970000    
2024-02-19 16:44:42,875 - ==> Top1: 51.550    Top5: 81.970    Loss: 1.753

2024-02-19 16:44:42,893 - ==> Best [Top1: 51.550   Top5: 81.970   Sparsity:0.00   Params: 1341960 on epoch: 52]
2024-02-19 16:44:42,894 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:44:42,986 - 

2024-02-19 16:44:42,986 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:44:52,726 - Epoch: [53][  100/  391]    Overall Loss 1.352209    Objective Loss 1.352209                                        LR 0.100000    Time 0.097279    
2024-02-19 16:45:01,832 - Epoch: [53][  200/  391]    Overall Loss 1.385189    Objective Loss 1.385189                                        LR 0.100000    Time 0.094145    
2024-02-19 16:45:11,052 - Epoch: [53][  300/  391]    Overall Loss 1.395419    Objective Loss 1.395419                                        LR 0.100000    Time 0.093481    
2024-02-19 16:45:19,544 - Epoch: [53][  391/  391]    Overall Loss 1.400876    Objective Loss 1.400876    Top1 61.057692    Top5 88.461538    LR 0.100000    Time 0.093432    
2024-02-19 16:45:19,781 - --- validate (epoch=53)-----------
2024-02-19 16:45:19,782 - 10000 samples (128 per mini-batch)
2024-02-19 16:45:22,508 - Epoch: [53][   79/   79]    Loss 1.756776    Top1 52.330000    Top5 82.320000    
2024-02-19 16:45:22,734 - ==> Top1: 52.330    Top5: 82.320    Loss: 1.757

2024-02-19 16:45:22,755 - ==> Best [Top1: 52.330   Top5: 82.320   Sparsity:0.00   Params: 1341960 on epoch: 53]
2024-02-19 16:45:22,755 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:45:22,847 - 

2024-02-19 16:45:22,848 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:45:32,721 - Epoch: [54][  100/  391]    Overall Loss 1.365076    Objective Loss 1.365076                                        LR 0.100000    Time 0.098665    
2024-02-19 16:45:42,014 - Epoch: [54][  200/  391]    Overall Loss 1.377045    Objective Loss 1.377045                                        LR 0.100000    Time 0.095769    
2024-02-19 16:45:51,330 - Epoch: [54][  300/  391]    Overall Loss 1.386387    Objective Loss 1.386387                                        LR 0.100000    Time 0.094885    
2024-02-19 16:45:59,766 - Epoch: [54][  391/  391]    Overall Loss 1.388969    Objective Loss 1.388969    Top1 61.057692    Top5 86.538462    LR 0.100000    Time 0.094365    
2024-02-19 16:45:59,990 - --- validate (epoch=54)-----------
2024-02-19 16:45:59,990 - 10000 samples (128 per mini-batch)
2024-02-19 16:46:02,766 - Epoch: [54][   79/   79]    Loss 1.958111    Top1 48.140000    Top5 78.360000    
2024-02-19 16:46:02,970 - ==> Top1: 48.140    Top5: 78.360    Loss: 1.958

2024-02-19 16:46:02,990 - ==> Best [Top1: 52.330   Top5: 82.320   Sparsity:0.00   Params: 1341960 on epoch: 53]
2024-02-19 16:46:02,990 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:46:03,067 - 

2024-02-19 16:46:03,067 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:46:13,009 - Epoch: [55][  100/  391]    Overall Loss 1.354112    Objective Loss 1.354112                                        LR 0.100000    Time 0.099337    
2024-02-19 16:46:22,476 - Epoch: [55][  200/  391]    Overall Loss 1.363370    Objective Loss 1.363370                                        LR 0.100000    Time 0.096980    
2024-02-19 16:46:31,811 - Epoch: [55][  300/  391]    Overall Loss 1.373081    Objective Loss 1.373081                                        LR 0.100000    Time 0.095756    
2024-02-19 16:46:40,258 - Epoch: [55][  391/  391]    Overall Loss 1.380583    Objective Loss 1.380583    Top1 61.538462    Top5 89.903846    LR 0.100000    Time 0.095061    
2024-02-19 16:46:40,491 - --- validate (epoch=55)-----------
2024-02-19 16:46:40,492 - 10000 samples (128 per mini-batch)
2024-02-19 16:46:43,278 - Epoch: [55][   79/   79]    Loss 1.765769    Top1 51.630000    Top5 82.110000    
2024-02-19 16:46:43,461 - ==> Top1: 51.630    Top5: 82.110    Loss: 1.766

2024-02-19 16:46:43,479 - ==> Best [Top1: 52.330   Top5: 82.320   Sparsity:0.00   Params: 1341960 on epoch: 53]
2024-02-19 16:46:43,479 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:46:43,554 - 

2024-02-19 16:46:43,555 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:46:53,536 - Epoch: [56][  100/  391]    Overall Loss 1.326227    Objective Loss 1.326227                                        LR 0.100000    Time 0.099738    
2024-02-19 16:47:02,801 - Epoch: [56][  200/  391]    Overall Loss 1.348147    Objective Loss 1.348147                                        LR 0.100000    Time 0.096162    
2024-02-19 16:47:11,918 - Epoch: [56][  300/  391]    Overall Loss 1.367657    Objective Loss 1.367657                                        LR 0.100000    Time 0.094482    
2024-02-19 16:47:20,248 - Epoch: [56][  391/  391]    Overall Loss 1.379064    Objective Loss 1.379064    Top1 57.692308    Top5 86.538462    LR 0.100000    Time 0.093783    
2024-02-19 16:47:20,467 - --- validate (epoch=56)-----------
2024-02-19 16:47:20,468 - 10000 samples (128 per mini-batch)
2024-02-19 16:47:23,284 - Epoch: [56][   79/   79]    Loss 1.785426    Top1 51.600000    Top5 81.980000    
2024-02-19 16:47:23,466 - ==> Top1: 51.600    Top5: 81.980    Loss: 1.785

2024-02-19 16:47:23,485 - ==> Best [Top1: 52.330   Top5: 82.320   Sparsity:0.00   Params: 1341960 on epoch: 53]
2024-02-19 16:47:23,485 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:47:23,568 - 

2024-02-19 16:47:23,568 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:47:31,282 - Epoch: [57][  100/  391]    Overall Loss 1.349260    Objective Loss 1.349260                                        LR 0.100000    Time 0.077065    
2024-02-19 16:47:39,176 - Epoch: [57][  200/  391]    Overall Loss 1.363172    Objective Loss 1.363172                                        LR 0.100000    Time 0.077979    
2024-02-19 16:47:48,528 - Epoch: [57][  300/  391]    Overall Loss 1.365457    Objective Loss 1.365457                                        LR 0.100000    Time 0.083144    
2024-02-19 16:47:56,989 - Epoch: [57][  391/  391]    Overall Loss 1.366706    Objective Loss 1.366706    Top1 62.019231    Top5 88.942308    LR 0.100000    Time 0.085423    
2024-02-19 16:47:57,227 - --- validate (epoch=57)-----------
2024-02-19 16:47:57,228 - 10000 samples (128 per mini-batch)
2024-02-19 16:47:59,791 - Epoch: [57][   79/   79]    Loss 1.894377    Top1 49.460000    Top5 80.050000    
2024-02-19 16:47:59,943 - ==> Top1: 49.460    Top5: 80.050    Loss: 1.894

2024-02-19 16:47:59,962 - ==> Best [Top1: 52.330   Top5: 82.320   Sparsity:0.00   Params: 1341960 on epoch: 53]
2024-02-19 16:47:59,963 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:48:00,038 - 

2024-02-19 16:48:00,038 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:48:09,806 - Epoch: [58][  100/  391]    Overall Loss 1.325014    Objective Loss 1.325014                                        LR 0.100000    Time 0.097600    
2024-02-19 16:48:19,198 - Epoch: [58][  200/  391]    Overall Loss 1.345946    Objective Loss 1.345946                                        LR 0.100000    Time 0.095736    
2024-02-19 16:48:28,447 - Epoch: [58][  300/  391]    Overall Loss 1.349931    Objective Loss 1.349931                                        LR 0.100000    Time 0.094640    
2024-02-19 16:48:36,957 - Epoch: [58][  391/  391]    Overall Loss 1.360621    Objective Loss 1.360621    Top1 62.980769    Top5 87.019231    LR 0.100000    Time 0.094368    
2024-02-19 16:48:37,180 - --- validate (epoch=58)-----------
2024-02-19 16:48:37,181 - 10000 samples (128 per mini-batch)
2024-02-19 16:48:39,921 - Epoch: [58][   79/   79]    Loss 1.667708    Top1 54.190000    Top5 83.330000    
2024-02-19 16:48:40,072 - ==> Top1: 54.190    Top5: 83.330    Loss: 1.668

2024-02-19 16:48:40,081 - ==> Best [Top1: 54.190   Top5: 83.330   Sparsity:0.00   Params: 1341960 on epoch: 58]
2024-02-19 16:48:40,081 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:48:40,170 - 

2024-02-19 16:48:40,170 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:48:50,091 - Epoch: [59][  100/  391]    Overall Loss 1.308791    Objective Loss 1.308791                                        LR 0.100000    Time 0.099140    
2024-02-19 16:48:59,408 - Epoch: [59][  200/  391]    Overall Loss 1.326215    Objective Loss 1.326215                                        LR 0.100000    Time 0.096133    
2024-02-19 16:49:08,647 - Epoch: [59][  300/  391]    Overall Loss 1.341077    Objective Loss 1.341077                                        LR 0.100000    Time 0.094868    
2024-02-19 16:49:17,170 - Epoch: [59][  391/  391]    Overall Loss 1.348947    Objective Loss 1.348947    Top1 62.500000    Top5 88.942308    LR 0.100000    Time 0.094577    
2024-02-19 16:49:17,396 - --- validate (epoch=59)-----------
2024-02-19 16:49:17,397 - 10000 samples (128 per mini-batch)
2024-02-19 16:49:19,956 - Epoch: [59][   79/   79]    Loss 1.826966    Top1 50.750000    Top5 81.150000    
2024-02-19 16:49:20,159 - ==> Top1: 50.750    Top5: 81.150    Loss: 1.827

2024-02-19 16:49:20,177 - ==> Best [Top1: 54.190   Top5: 83.330   Sparsity:0.00   Params: 1341960 on epoch: 58]
2024-02-19 16:49:20,177 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:49:20,252 - 

2024-02-19 16:49:20,253 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:49:30,094 - Epoch: [60][  100/  391]    Overall Loss 1.305665    Objective Loss 1.305665                                        LR 0.100000    Time 0.098342    
2024-02-19 16:49:39,283 - Epoch: [60][  200/  391]    Overall Loss 1.311440    Objective Loss 1.311440                                        LR 0.100000    Time 0.095096    
2024-02-19 16:49:48,493 - Epoch: [60][  300/  391]    Overall Loss 1.328394    Objective Loss 1.328394                                        LR 0.100000    Time 0.094082    
2024-02-19 16:49:56,989 - Epoch: [60][  391/  391]    Overall Loss 1.339107    Objective Loss 1.339107    Top1 63.942308    Top5 88.461538    LR 0.100000    Time 0.093902    
2024-02-19 16:49:57,167 - --- validate (epoch=60)-----------
2024-02-19 16:49:57,168 - 10000 samples (128 per mini-batch)
2024-02-19 16:49:59,874 - Epoch: [60][   79/   79]    Loss 1.691084    Top1 52.590000    Top5 83.400000    
2024-02-19 16:50:00,019 - ==> Top1: 52.590    Top5: 83.400    Loss: 1.691

2024-02-19 16:50:00,035 - ==> Best [Top1: 54.190   Top5: 83.330   Sparsity:0.00   Params: 1341960 on epoch: 58]
2024-02-19 16:50:00,036 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:50:00,109 - 

2024-02-19 16:50:00,109 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:50:09,768 - Epoch: [61][  100/  391]    Overall Loss 1.296610    Objective Loss 1.296610                                        LR 0.100000    Time 0.096520    
2024-02-19 16:50:18,827 - Epoch: [61][  200/  391]    Overall Loss 1.326394    Objective Loss 1.326394                                        LR 0.100000    Time 0.093530    
2024-02-19 16:50:28,058 - Epoch: [61][  300/  391]    Overall Loss 1.333381    Objective Loss 1.333381                                        LR 0.100000    Time 0.093109    
2024-02-19 16:50:36,517 - Epoch: [61][  391/  391]    Overall Loss 1.339205    Objective Loss 1.339205    Top1 61.538462    Top5 86.538462    LR 0.100000    Time 0.093063    
2024-02-19 16:50:36,806 - --- validate (epoch=61)-----------
2024-02-19 16:50:36,807 - 10000 samples (128 per mini-batch)
2024-02-19 16:50:39,469 - Epoch: [61][   79/   79]    Loss 1.818900    Top1 50.560000    Top5 81.340000    
2024-02-19 16:50:39,694 - ==> Top1: 50.560    Top5: 81.340    Loss: 1.819

2024-02-19 16:50:39,711 - ==> Best [Top1: 54.190   Top5: 83.330   Sparsity:0.00   Params: 1341960 on epoch: 58]
2024-02-19 16:50:39,712 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:50:39,786 - 

2024-02-19 16:50:39,786 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:50:49,334 - Epoch: [62][  100/  391]    Overall Loss 1.288146    Objective Loss 1.288146                                        LR 0.100000    Time 0.095403    
2024-02-19 16:50:58,535 - Epoch: [62][  200/  391]    Overall Loss 1.302987    Objective Loss 1.302987                                        LR 0.100000    Time 0.093680    
2024-02-19 16:51:07,855 - Epoch: [62][  300/  391]    Overall Loss 1.328770    Objective Loss 1.328770                                        LR 0.100000    Time 0.093506    
2024-02-19 16:51:16,236 - Epoch: [62][  391/  391]    Overall Loss 1.332459    Objective Loss 1.332459    Top1 58.173077    Top5 86.538462    LR 0.100000    Time 0.093167    
2024-02-19 16:51:16,451 - --- validate (epoch=62)-----------
2024-02-19 16:51:16,451 - 10000 samples (128 per mini-batch)
2024-02-19 16:51:19,284 - Epoch: [62][   79/   79]    Loss 1.716351    Top1 52.900000    Top5 82.810000    
2024-02-19 16:51:19,510 - ==> Top1: 52.900    Top5: 82.810    Loss: 1.716

2024-02-19 16:51:19,529 - ==> Best [Top1: 54.190   Top5: 83.330   Sparsity:0.00   Params: 1341960 on epoch: 58]
2024-02-19 16:51:19,530 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:51:19,603 - 

2024-02-19 16:51:19,604 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:51:28,850 - Epoch: [63][  100/  391]    Overall Loss 1.285306    Objective Loss 1.285306                                        LR 0.100000    Time 0.092394    
2024-02-19 16:51:37,885 - Epoch: [63][  200/  391]    Overall Loss 1.292782    Objective Loss 1.292782                                        LR 0.100000    Time 0.091348    
2024-02-19 16:51:46,935 - Epoch: [63][  300/  391]    Overall Loss 1.312682    Objective Loss 1.312682                                        LR 0.100000    Time 0.091052    
2024-02-19 16:51:54,750 - Epoch: [63][  391/  391]    Overall Loss 1.317608    Objective Loss 1.317608    Top1 61.057692    Top5 87.980769    LR 0.100000    Time 0.089839    
2024-02-19 16:51:54,934 - --- validate (epoch=63)-----------
2024-02-19 16:51:54,934 - 10000 samples (128 per mini-batch)
2024-02-19 16:51:57,425 - Epoch: [63][   79/   79]    Loss 1.956995    Top1 48.160000    Top5 78.860000    
2024-02-19 16:51:57,576 - ==> Top1: 48.160    Top5: 78.860    Loss: 1.957

2024-02-19 16:51:57,596 - ==> Best [Top1: 54.190   Top5: 83.330   Sparsity:0.00   Params: 1341960 on epoch: 58]
2024-02-19 16:51:57,597 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:51:57,671 - 

2024-02-19 16:51:57,671 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:52:06,453 - Epoch: [64][  100/  391]    Overall Loss 1.297899    Objective Loss 1.297899                                        LR 0.100000    Time 0.087752    
2024-02-19 16:52:14,339 - Epoch: [64][  200/  391]    Overall Loss 1.311936    Objective Loss 1.311936                                        LR 0.100000    Time 0.083287    
2024-02-19 16:52:23,716 - Epoch: [64][  300/  391]    Overall Loss 1.316976    Objective Loss 1.316976                                        LR 0.100000    Time 0.086763    
2024-02-19 16:52:32,149 - Epoch: [64][  391/  391]    Overall Loss 1.320537    Objective Loss 1.320537    Top1 63.461538    Top5 92.307692    LR 0.100000    Time 0.088128    
2024-02-19 16:52:32,366 - --- validate (epoch=64)-----------
2024-02-19 16:52:32,368 - 10000 samples (128 per mini-batch)
2024-02-19 16:52:35,061 - Epoch: [64][   79/   79]    Loss 1.750812    Top1 51.930000    Top5 82.150000    
2024-02-19 16:52:35,303 - ==> Top1: 51.930    Top5: 82.150    Loss: 1.751

2024-02-19 16:52:35,322 - ==> Best [Top1: 54.190   Top5: 83.330   Sparsity:0.00   Params: 1341960 on epoch: 58]
2024-02-19 16:52:35,323 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:52:35,398 - 

2024-02-19 16:52:35,399 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:52:43,948 - Epoch: [65][  100/  391]    Overall Loss 1.261279    Objective Loss 1.261279                                        LR 0.100000    Time 0.085430    
2024-02-19 16:52:50,779 - Epoch: [65][  200/  391]    Overall Loss 1.285149    Objective Loss 1.285149                                        LR 0.100000    Time 0.076849    
2024-02-19 16:52:58,455 - Epoch: [65][  300/  391]    Overall Loss 1.301239    Objective Loss 1.301239                                        LR 0.100000    Time 0.076809    
2024-02-19 16:53:06,973 - Epoch: [65][  391/  391]    Overall Loss 1.310330    Objective Loss 1.310330    Top1 60.096154    Top5 87.019231    LR 0.100000    Time 0.080705    
2024-02-19 16:53:07,141 - --- validate (epoch=65)-----------
2024-02-19 16:53:07,142 - 10000 samples (128 per mini-batch)
2024-02-19 16:53:09,692 - Epoch: [65][   79/   79]    Loss 1.815695    Top1 51.080000    Top5 80.620000    
2024-02-19 16:53:09,910 - ==> Top1: 51.080    Top5: 80.620    Loss: 1.816

2024-02-19 16:53:09,929 - ==> Best [Top1: 54.190   Top5: 83.330   Sparsity:0.00   Params: 1341960 on epoch: 58]
2024-02-19 16:53:09,929 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:53:10,009 - 

2024-02-19 16:53:10,009 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:53:20,340 - Epoch: [66][  100/  391]    Overall Loss 1.250810    Objective Loss 1.250810                                        LR 0.100000    Time 0.103237    
2024-02-19 16:53:29,633 - Epoch: [66][  200/  391]    Overall Loss 1.267830    Objective Loss 1.267830                                        LR 0.100000    Time 0.098060    
2024-02-19 16:53:38,843 - Epoch: [66][  300/  391]    Overall Loss 1.283463    Objective Loss 1.283463                                        LR 0.100000    Time 0.096059    
2024-02-19 16:53:47,201 - Epoch: [66][  391/  391]    Overall Loss 1.292746    Objective Loss 1.292746    Top1 49.519231    Top5 80.769231    LR 0.100000    Time 0.095067    
2024-02-19 16:53:47,517 - --- validate (epoch=66)-----------
2024-02-19 16:53:47,518 - 10000 samples (128 per mini-batch)
2024-02-19 16:53:50,023 - Epoch: [66][   79/   79]    Loss 1.934755    Top1 49.240000    Top5 80.590000    
2024-02-19 16:53:50,164 - ==> Top1: 49.240    Top5: 80.590    Loss: 1.935

2024-02-19 16:53:50,184 - ==> Best [Top1: 54.190   Top5: 83.330   Sparsity:0.00   Params: 1341960 on epoch: 58]
2024-02-19 16:53:50,184 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:53:50,259 - 

2024-02-19 16:53:50,259 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:53:59,929 - Epoch: [67][  100/  391]    Overall Loss 1.269191    Objective Loss 1.269191                                        LR 0.100000    Time 0.096632    
2024-02-19 16:54:09,276 - Epoch: [67][  200/  391]    Overall Loss 1.276007    Objective Loss 1.276007                                        LR 0.100000    Time 0.095026    
2024-02-19 16:54:18,594 - Epoch: [67][  300/  391]    Overall Loss 1.285233    Objective Loss 1.285233                                        LR 0.100000    Time 0.094396    
2024-02-19 16:54:27,032 - Epoch: [67][  391/  391]    Overall Loss 1.298565    Objective Loss 1.298565    Top1 66.346154    Top5 89.423077    LR 0.100000    Time 0.093995    
2024-02-19 16:54:27,171 - --- validate (epoch=67)-----------
2024-02-19 16:54:27,172 - 10000 samples (128 per mini-batch)
2024-02-19 16:54:29,733 - Epoch: [67][   79/   79]    Loss 1.758080    Top1 52.600000    Top5 82.260000    
2024-02-19 16:54:29,944 - ==> Top1: 52.600    Top5: 82.260    Loss: 1.758

2024-02-19 16:54:29,957 - ==> Best [Top1: 54.190   Top5: 83.330   Sparsity:0.00   Params: 1341960 on epoch: 58]
2024-02-19 16:54:29,957 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:54:30,030 - 

2024-02-19 16:54:30,030 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:54:40,247 - Epoch: [68][  100/  391]    Overall Loss 1.250863    Objective Loss 1.250863                                        LR 0.100000    Time 0.102090    
2024-02-19 16:54:49,667 - Epoch: [68][  200/  391]    Overall Loss 1.268339    Objective Loss 1.268339                                        LR 0.100000    Time 0.098122    
2024-02-19 16:54:58,970 - Epoch: [68][  300/  391]    Overall Loss 1.273696    Objective Loss 1.273696                                        LR 0.100000    Time 0.096408    
2024-02-19 16:55:07,323 - Epoch: [68][  391/  391]    Overall Loss 1.285888    Objective Loss 1.285888    Top1 61.538462    Top5 90.865385    LR 0.100000    Time 0.095323    
2024-02-19 16:55:07,537 - --- validate (epoch=68)-----------
2024-02-19 16:55:07,538 - 10000 samples (128 per mini-batch)
2024-02-19 16:55:10,227 - Epoch: [68][   79/   79]    Loss 1.862298    Top1 50.420000    Top5 80.730000    
2024-02-19 16:55:10,419 - ==> Top1: 50.420    Top5: 80.730    Loss: 1.862

2024-02-19 16:55:10,431 - ==> Best [Top1: 54.190   Top5: 83.330   Sparsity:0.00   Params: 1341960 on epoch: 58]
2024-02-19 16:55:10,431 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:55:10,510 - 

2024-02-19 16:55:10,510 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:55:20,445 - Epoch: [69][  100/  391]    Overall Loss 1.257213    Objective Loss 1.257213                                        LR 0.100000    Time 0.099269    
2024-02-19 16:55:29,823 - Epoch: [69][  200/  391]    Overall Loss 1.259300    Objective Loss 1.259300                                        LR 0.100000    Time 0.096501    
2024-02-19 16:55:39,123 - Epoch: [69][  300/  391]    Overall Loss 1.275271    Objective Loss 1.275271                                        LR 0.100000    Time 0.095320    
2024-02-19 16:55:47,516 - Epoch: [69][  391/  391]    Overall Loss 1.284235    Objective Loss 1.284235    Top1 63.942308    Top5 87.980769    LR 0.100000    Time 0.094589    
2024-02-19 16:55:47,738 - --- validate (epoch=69)-----------
2024-02-19 16:55:47,739 - 10000 samples (128 per mini-batch)
2024-02-19 16:55:50,339 - Epoch: [69][   79/   79]    Loss 1.776082    Top1 51.820000    Top5 82.050000    
2024-02-19 16:55:50,498 - ==> Top1: 51.820    Top5: 82.050    Loss: 1.776

2024-02-19 16:55:50,516 - ==> Best [Top1: 54.190   Top5: 83.330   Sparsity:0.00   Params: 1341960 on epoch: 58]
2024-02-19 16:55:50,517 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:55:50,591 - 

2024-02-19 16:55:50,591 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:56:00,227 - Epoch: [70][  100/  391]    Overall Loss 1.246878    Objective Loss 1.246878                                        LR 0.100000    Time 0.096291    
2024-02-19 16:56:09,583 - Epoch: [70][  200/  391]    Overall Loss 1.248874    Objective Loss 1.248874                                        LR 0.100000    Time 0.094899    
2024-02-19 16:56:18,896 - Epoch: [70][  300/  391]    Overall Loss 1.265239    Objective Loss 1.265239                                        LR 0.100000    Time 0.094293    
2024-02-19 16:56:27,361 - Epoch: [70][  391/  391]    Overall Loss 1.268964    Objective Loss 1.268964    Top1 63.461538    Top5 88.461538    LR 0.100000    Time 0.093986    
2024-02-19 16:56:27,565 - --- validate (epoch=70)-----------
2024-02-19 16:56:27,565 - 10000 samples (128 per mini-batch)
2024-02-19 16:56:30,231 - Epoch: [70][   79/   79]    Loss 1.651100    Top1 54.200000    Top5 84.270000    
2024-02-19 16:56:30,402 - ==> Top1: 54.200    Top5: 84.270    Loss: 1.651

2024-02-19 16:56:30,419 - ==> Best [Top1: 54.200   Top5: 84.270   Sparsity:0.00   Params: 1341960 on epoch: 70]
2024-02-19 16:56:30,420 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:56:30,509 - 

2024-02-19 16:56:30,509 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:56:40,745 - Epoch: [71][  100/  391]    Overall Loss 1.214183    Objective Loss 1.214183                                        LR 0.100000    Time 0.102283    
2024-02-19 16:56:50,129 - Epoch: [71][  200/  391]    Overall Loss 1.237423    Objective Loss 1.237423                                        LR 0.100000    Time 0.098035    
2024-02-19 16:56:59,407 - Epoch: [71][  300/  391]    Overall Loss 1.252054    Objective Loss 1.252054                                        LR 0.100000    Time 0.096270    
2024-02-19 16:57:07,915 - Epoch: [71][  391/  391]    Overall Loss 1.269942    Objective Loss 1.269942    Top1 62.500000    Top5 92.307692    LR 0.100000    Time 0.095611    
2024-02-19 16:57:08,115 - --- validate (epoch=71)-----------
2024-02-19 16:57:08,116 - 10000 samples (128 per mini-batch)
2024-02-19 16:57:10,855 - Epoch: [71][   79/   79]    Loss 1.664598    Top1 54.580000    Top5 83.680000    
2024-02-19 16:57:11,031 - ==> Top1: 54.580    Top5: 83.680    Loss: 1.665

2024-02-19 16:57:11,046 - ==> Best [Top1: 54.580   Top5: 83.680   Sparsity:0.00   Params: 1341960 on epoch: 71]
2024-02-19 16:57:11,047 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:57:11,136 - 

2024-02-19 16:57:11,136 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:57:21,325 - Epoch: [72][  100/  391]    Overall Loss 1.228445    Objective Loss 1.228445                                        LR 0.100000    Time 0.101813    
2024-02-19 16:57:30,563 - Epoch: [72][  200/  391]    Overall Loss 1.231338    Objective Loss 1.231338                                        LR 0.100000    Time 0.097073    
2024-02-19 16:57:39,712 - Epoch: [72][  300/  391]    Overall Loss 1.256302    Objective Loss 1.256302                                        LR 0.100000    Time 0.095196    
2024-02-19 16:57:47,922 - Epoch: [72][  391/  391]    Overall Loss 1.258400    Objective Loss 1.258400    Top1 60.576923    Top5 88.461538    LR 0.100000    Time 0.094029    
2024-02-19 16:57:48,125 - --- validate (epoch=72)-----------
2024-02-19 16:57:48,126 - 10000 samples (128 per mini-batch)
2024-02-19 16:57:50,763 - Epoch: [72][   79/   79]    Loss 1.766127    Top1 52.280000    Top5 81.960000    
2024-02-19 16:57:50,909 - ==> Top1: 52.280    Top5: 81.960    Loss: 1.766

2024-02-19 16:57:50,927 - ==> Best [Top1: 54.580   Top5: 83.680   Sparsity:0.00   Params: 1341960 on epoch: 71]
2024-02-19 16:57:50,928 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:57:51,003 - 

2024-02-19 16:57:51,003 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:58:00,661 - Epoch: [73][  100/  391]    Overall Loss 1.235244    Objective Loss 1.235244                                        LR 0.100000    Time 0.096506    
2024-02-19 16:58:09,917 - Epoch: [73][  200/  391]    Overall Loss 1.225271    Objective Loss 1.225271                                        LR 0.100000    Time 0.094505    
2024-02-19 16:58:19,242 - Epoch: [73][  300/  391]    Overall Loss 1.248749    Objective Loss 1.248749                                        LR 0.100000    Time 0.094073    
2024-02-19 16:58:27,776 - Epoch: [73][  391/  391]    Overall Loss 1.258203    Objective Loss 1.258203    Top1 62.019231    Top5 92.307692    LR 0.100000    Time 0.093994    
2024-02-19 16:58:27,980 - --- validate (epoch=73)-----------
2024-02-19 16:58:27,980 - 10000 samples (128 per mini-batch)
2024-02-19 16:58:30,678 - Epoch: [73][   79/   79]    Loss 1.792526    Top1 52.330000    Top5 81.370000    
2024-02-19 16:58:30,830 - ==> Top1: 52.330    Top5: 81.370    Loss: 1.793

2024-02-19 16:58:30,849 - ==> Best [Top1: 54.580   Top5: 83.680   Sparsity:0.00   Params: 1341960 on epoch: 71]
2024-02-19 16:58:30,849 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:58:30,924 - 

2024-02-19 16:58:30,925 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:58:40,921 - Epoch: [74][  100/  391]    Overall Loss 1.213928    Objective Loss 1.213928                                        LR 0.100000    Time 0.099891    
2024-02-19 16:58:50,237 - Epoch: [74][  200/  391]    Overall Loss 1.237431    Objective Loss 1.237431                                        LR 0.100000    Time 0.096502    
2024-02-19 16:58:59,465 - Epoch: [74][  300/  391]    Overall Loss 1.250356    Objective Loss 1.250356                                        LR 0.100000    Time 0.095081    
2024-02-19 16:59:07,865 - Epoch: [74][  391/  391]    Overall Loss 1.257349    Objective Loss 1.257349    Top1 62.980769    Top5 90.865385    LR 0.100000    Time 0.094424    
2024-02-19 16:59:08,071 - --- validate (epoch=74)-----------
2024-02-19 16:59:08,072 - 10000 samples (128 per mini-batch)
2024-02-19 16:59:10,754 - Epoch: [74][   79/   79]    Loss 1.893712    Top1 50.480000    Top5 80.250000    
2024-02-19 16:59:10,952 - ==> Top1: 50.480    Top5: 80.250    Loss: 1.894

2024-02-19 16:59:10,971 - ==> Best [Top1: 54.580   Top5: 83.680   Sparsity:0.00   Params: 1341960 on epoch: 71]
2024-02-19 16:59:10,972 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:59:11,051 - 

2024-02-19 16:59:11,051 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 16:59:20,982 - Epoch: [75][  100/  391]    Overall Loss 1.223472    Objective Loss 1.223472                                        LR 0.100000    Time 0.099232    
2024-02-19 16:59:30,300 - Epoch: [75][  200/  391]    Overall Loss 1.242622    Objective Loss 1.242622                                        LR 0.100000    Time 0.096180    
2024-02-19 16:59:39,666 - Epoch: [75][  300/  391]    Overall Loss 1.249421    Objective Loss 1.249421                                        LR 0.100000    Time 0.095323    
2024-02-19 16:59:47,394 - Epoch: [75][  391/  391]    Overall Loss 1.251632    Objective Loss 1.251632    Top1 62.019231    Top5 87.500000    LR 0.100000    Time 0.092892    
2024-02-19 16:59:47,623 - --- validate (epoch=75)-----------
2024-02-19 16:59:47,624 - 10000 samples (128 per mini-batch)
2024-02-19 16:59:50,241 - Epoch: [75][   79/   79]    Loss 1.653270    Top1 54.870000    Top5 83.890000    
2024-02-19 16:59:50,412 - ==> Top1: 54.870    Top5: 83.890    Loss: 1.653

2024-02-19 16:59:50,432 - ==> Best [Top1: 54.870   Top5: 83.890   Sparsity:0.00   Params: 1341960 on epoch: 75]
2024-02-19 16:59:50,432 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 16:59:50,524 - 

2024-02-19 16:59:50,524 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:00:00,546 - Epoch: [76][  100/  391]    Overall Loss 1.170750    Objective Loss 1.170750                                        LR 0.100000    Time 0.100148    
2024-02-19 17:00:09,848 - Epoch: [76][  200/  391]    Overall Loss 1.213522    Objective Loss 1.213522                                        LR 0.100000    Time 0.096556    
2024-02-19 17:00:19,145 - Epoch: [76][  300/  391]    Overall Loss 1.231686    Objective Loss 1.231686                                        LR 0.100000    Time 0.095346    
2024-02-19 17:00:25,605 - Epoch: [76][  391/  391]    Overall Loss 1.240826    Objective Loss 1.240826    Top1 67.788462    Top5 90.865385    LR 0.100000    Time 0.089668    
2024-02-19 17:00:25,810 - --- validate (epoch=76)-----------
2024-02-19 17:00:25,811 - 10000 samples (128 per mini-batch)
2024-02-19 17:00:28,304 - Epoch: [76][   79/   79]    Loss 1.814758    Top1 51.530000    Top5 81.440000    
2024-02-19 17:00:28,483 - ==> Top1: 51.530    Top5: 81.440    Loss: 1.815

2024-02-19 17:00:28,503 - ==> Best [Top1: 54.870   Top5: 83.890   Sparsity:0.00   Params: 1341960 on epoch: 75]
2024-02-19 17:00:28,503 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:00:28,578 - 

2024-02-19 17:00:28,578 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:00:38,326 - Epoch: [77][  100/  391]    Overall Loss 1.180127    Objective Loss 1.180127                                        LR 0.100000    Time 0.097408    
2024-02-19 17:00:47,421 - Epoch: [77][  200/  391]    Overall Loss 1.209763    Objective Loss 1.209763                                        LR 0.100000    Time 0.094156    
2024-02-19 17:00:54,575 - Epoch: [77][  300/  391]    Overall Loss 1.223902    Objective Loss 1.223902                                        LR 0.100000    Time 0.086605    
2024-02-19 17:01:00,873 - Epoch: [77][  391/  391]    Overall Loss 1.233894    Objective Loss 1.233894    Top1 61.538462    Top5 92.307692    LR 0.100000    Time 0.082546    
2024-02-19 17:01:01,096 - --- validate (epoch=77)-----------
2024-02-19 17:01:01,097 - 10000 samples (128 per mini-batch)
2024-02-19 17:01:03,764 - Epoch: [77][   79/   79]    Loss 1.657645    Top1 54.100000    Top5 83.660000    
2024-02-19 17:01:03,969 - ==> Top1: 54.100    Top5: 83.660    Loss: 1.658

2024-02-19 17:01:03,986 - ==> Best [Top1: 54.870   Top5: 83.890   Sparsity:0.00   Params: 1341960 on epoch: 75]
2024-02-19 17:01:03,987 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:01:04,061 - 

2024-02-19 17:01:04,061 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:01:13,898 - Epoch: [78][  100/  391]    Overall Loss 1.201644    Objective Loss 1.201644                                        LR 0.100000    Time 0.098303    
2024-02-19 17:01:22,961 - Epoch: [78][  200/  391]    Overall Loss 1.203288    Objective Loss 1.203288                                        LR 0.100000    Time 0.094440    
2024-02-19 17:01:32,110 - Epoch: [78][  300/  391]    Overall Loss 1.218297    Objective Loss 1.218297                                        LR 0.100000    Time 0.093442    
2024-02-19 17:01:40,608 - Epoch: [78][  391/  391]    Overall Loss 1.222866    Objective Loss 1.222866    Top1 61.057692    Top5 92.307692    LR 0.100000    Time 0.093419    
2024-02-19 17:01:40,833 - --- validate (epoch=78)-----------
2024-02-19 17:01:40,834 - 10000 samples (128 per mini-batch)
2024-02-19 17:01:43,502 - Epoch: [78][   79/   79]    Loss 1.797887    Top1 52.410000    Top5 81.490000    
2024-02-19 17:01:43,675 - ==> Top1: 52.410    Top5: 81.490    Loss: 1.798

2024-02-19 17:01:43,686 - ==> Best [Top1: 54.870   Top5: 83.890   Sparsity:0.00   Params: 1341960 on epoch: 75]
2024-02-19 17:01:43,686 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:01:43,757 - 

2024-02-19 17:01:43,758 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:01:53,439 - Epoch: [79][  100/  391]    Overall Loss 1.185781    Objective Loss 1.185781                                        LR 0.100000    Time 0.096739    
2024-02-19 17:02:02,755 - Epoch: [79][  200/  391]    Overall Loss 1.206895    Objective Loss 1.206895                                        LR 0.100000    Time 0.094925    
2024-02-19 17:02:11,945 - Epoch: [79][  300/  391]    Overall Loss 1.223145    Objective Loss 1.223145                                        LR 0.100000    Time 0.093899    
2024-02-19 17:02:20,352 - Epoch: [79][  391/  391]    Overall Loss 1.228430    Objective Loss 1.228430    Top1 60.576923    Top5 89.903846    LR 0.100000    Time 0.093537    
2024-02-19 17:02:20,594 - --- validate (epoch=79)-----------
2024-02-19 17:02:20,595 - 10000 samples (128 per mini-batch)
2024-02-19 17:02:23,163 - Epoch: [79][   79/   79]    Loss 1.761844    Top1 52.140000    Top5 82.710000    
2024-02-19 17:02:23,414 - ==> Top1: 52.140    Top5: 82.710    Loss: 1.762

2024-02-19 17:02:23,433 - ==> Best [Top1: 54.870   Top5: 83.890   Sparsity:0.00   Params: 1341960 on epoch: 75]
2024-02-19 17:02:23,433 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:02:23,506 - 

2024-02-19 17:02:23,506 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:02:33,130 - Epoch: [80][  100/  391]    Overall Loss 1.183672    Objective Loss 1.183672                                        LR 0.100000    Time 0.096168    
2024-02-19 17:02:42,351 - Epoch: [80][  200/  391]    Overall Loss 1.188290    Objective Loss 1.188290                                        LR 0.100000    Time 0.094162    
2024-02-19 17:02:51,490 - Epoch: [80][  300/  391]    Overall Loss 1.207868    Objective Loss 1.207868                                        LR 0.100000    Time 0.093225    
2024-02-19 17:02:59,917 - Epoch: [80][  391/  391]    Overall Loss 1.216519    Objective Loss 1.216519    Top1 59.615385    Top5 87.019231    LR 0.100000    Time 0.093071    
2024-02-19 17:03:00,083 - --- validate (epoch=80)-----------
2024-02-19 17:03:00,084 - 10000 samples (128 per mini-batch)
2024-02-19 17:03:02,628 - Epoch: [80][   79/   79]    Loss 1.780596    Top1 51.910000    Top5 82.270000    
2024-02-19 17:03:02,815 - ==> Top1: 51.910    Top5: 82.270    Loss: 1.781

2024-02-19 17:03:02,834 - ==> Best [Top1: 54.870   Top5: 83.890   Sparsity:0.00   Params: 1341960 on epoch: 75]
2024-02-19 17:03:02,835 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:03:02,909 - 

2024-02-19 17:03:02,909 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:03:12,942 - Epoch: [81][  100/  391]    Overall Loss 1.154308    Objective Loss 1.154308                                        LR 0.100000    Time 0.100260    
2024-02-19 17:03:22,155 - Epoch: [81][  200/  391]    Overall Loss 1.192567    Objective Loss 1.192567                                        LR 0.100000    Time 0.096170    
2024-02-19 17:03:31,181 - Epoch: [81][  300/  391]    Overall Loss 1.212697    Objective Loss 1.212697                                        LR 0.100000    Time 0.094186    
2024-02-19 17:03:39,495 - Epoch: [81][  391/  391]    Overall Loss 1.216576    Objective Loss 1.216576    Top1 65.865385    Top5 88.461538    LR 0.100000    Time 0.093518    
2024-02-19 17:03:39,722 - --- validate (epoch=81)-----------
2024-02-19 17:03:39,723 - 10000 samples (128 per mini-batch)
2024-02-19 17:03:42,338 - Epoch: [81][   79/   79]    Loss 1.901255    Top1 50.050000    Top5 80.380000    
2024-02-19 17:03:42,548 - ==> Top1: 50.050    Top5: 80.380    Loss: 1.901

2024-02-19 17:03:42,572 - ==> Best [Top1: 54.870   Top5: 83.890   Sparsity:0.00   Params: 1341960 on epoch: 75]
2024-02-19 17:03:42,572 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:03:42,643 - 

2024-02-19 17:03:42,643 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:03:52,801 - Epoch: [82][  100/  391]    Overall Loss 1.181685    Objective Loss 1.181685                                        LR 0.100000    Time 0.101504    
2024-02-19 17:04:02,067 - Epoch: [82][  200/  391]    Overall Loss 1.191637    Objective Loss 1.191637                                        LR 0.100000    Time 0.097061    
2024-02-19 17:04:11,298 - Epoch: [82][  300/  391]    Overall Loss 1.195987    Objective Loss 1.195987                                        LR 0.100000    Time 0.095464    
2024-02-19 17:04:19,766 - Epoch: [82][  391/  391]    Overall Loss 1.205439    Objective Loss 1.205439    Top1 65.384615    Top5 88.461538    LR 0.100000    Time 0.094893    
2024-02-19 17:04:19,943 - --- validate (epoch=82)-----------
2024-02-19 17:04:19,944 - 10000 samples (128 per mini-batch)
2024-02-19 17:04:22,551 - Epoch: [82][   79/   79]    Loss 1.780336    Top1 52.640000    Top5 82.950000    
2024-02-19 17:04:22,737 - ==> Top1: 52.640    Top5: 82.950    Loss: 1.780

2024-02-19 17:04:22,755 - ==> Best [Top1: 54.870   Top5: 83.890   Sparsity:0.00   Params: 1341960 on epoch: 75]
2024-02-19 17:04:22,755 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:04:22,831 - 

2024-02-19 17:04:22,831 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:04:32,574 - Epoch: [83][  100/  391]    Overall Loss 1.189221    Objective Loss 1.189221                                        LR 0.100000    Time 0.097355    
2024-02-19 17:04:41,639 - Epoch: [83][  200/  391]    Overall Loss 1.189462    Objective Loss 1.189462                                        LR 0.100000    Time 0.093978    
2024-02-19 17:04:50,845 - Epoch: [83][  300/  391]    Overall Loss 1.210404    Objective Loss 1.210404                                        LR 0.100000    Time 0.093324    
2024-02-19 17:04:59,377 - Epoch: [83][  391/  391]    Overall Loss 1.212851    Objective Loss 1.212851    Top1 72.596154    Top5 90.865385    LR 0.100000    Time 0.093415    
2024-02-19 17:04:59,547 - --- validate (epoch=83)-----------
2024-02-19 17:04:59,548 - 10000 samples (128 per mini-batch)
2024-02-19 17:05:02,281 - Epoch: [83][   79/   79]    Loss 1.912212    Top1 49.810000    Top5 80.350000    
2024-02-19 17:05:02,412 - ==> Top1: 49.810    Top5: 80.350    Loss: 1.912

2024-02-19 17:05:02,429 - ==> Best [Top1: 54.870   Top5: 83.890   Sparsity:0.00   Params: 1341960 on epoch: 75]
2024-02-19 17:05:02,429 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:05:02,506 - 

2024-02-19 17:05:02,506 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:05:12,823 - Epoch: [84][  100/  391]    Overall Loss 1.144011    Objective Loss 1.144011                                        LR 0.100000    Time 0.103081    
2024-02-19 17:05:22,285 - Epoch: [84][  200/  391]    Overall Loss 1.156792    Objective Loss 1.156792                                        LR 0.100000    Time 0.098828    
2024-02-19 17:05:31,709 - Epoch: [84][  300/  391]    Overall Loss 1.189619    Objective Loss 1.189619                                        LR 0.100000    Time 0.097280    
2024-02-19 17:05:40,189 - Epoch: [84][  391/  391]    Overall Loss 1.205060    Objective Loss 1.205060    Top1 65.384615    Top5 91.346154    LR 0.100000    Time 0.096318    
2024-02-19 17:05:40,359 - --- validate (epoch=84)-----------
2024-02-19 17:05:40,360 - 10000 samples (128 per mini-batch)
2024-02-19 17:05:42,895 - Epoch: [84][   79/   79]    Loss 1.722928    Top1 53.200000    Top5 83.280000    
2024-02-19 17:05:43,037 - ==> Top1: 53.200    Top5: 83.280    Loss: 1.723

2024-02-19 17:05:43,056 - ==> Best [Top1: 54.870   Top5: 83.890   Sparsity:0.00   Params: 1341960 on epoch: 75]
2024-02-19 17:05:43,057 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:05:43,130 - 

2024-02-19 17:05:43,131 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:05:52,959 - Epoch: [85][  100/  391]    Overall Loss 1.142040    Objective Loss 1.142040                                        LR 0.100000    Time 0.098210    
2024-02-19 17:06:01,967 - Epoch: [85][  200/  391]    Overall Loss 1.177139    Objective Loss 1.177139                                        LR 0.100000    Time 0.094121    
2024-02-19 17:06:11,051 - Epoch: [85][  300/  391]    Overall Loss 1.182821    Objective Loss 1.182821                                        LR 0.100000    Time 0.093012    
2024-02-19 17:06:19,485 - Epoch: [85][  391/  391]    Overall Loss 1.191620    Objective Loss 1.191620    Top1 67.788462    Top5 89.423077    LR 0.100000    Time 0.092925    
2024-02-19 17:06:19,724 - --- validate (epoch=85)-----------
2024-02-19 17:06:19,725 - 10000 samples (128 per mini-batch)
2024-02-19 17:06:22,312 - Epoch: [85][   79/   79]    Loss 1.687304    Top1 54.170000    Top5 83.350000    
2024-02-19 17:06:22,452 - ==> Top1: 54.170    Top5: 83.350    Loss: 1.687

2024-02-19 17:06:22,469 - ==> Best [Top1: 54.870   Top5: 83.890   Sparsity:0.00   Params: 1341960 on epoch: 75]
2024-02-19 17:06:22,470 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:06:22,543 - 

2024-02-19 17:06:22,544 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:06:32,366 - Epoch: [86][  100/  391]    Overall Loss 1.130520    Objective Loss 1.130520                                        LR 0.100000    Time 0.098149    
2024-02-19 17:06:41,234 - Epoch: [86][  200/  391]    Overall Loss 1.160144    Objective Loss 1.160144                                        LR 0.100000    Time 0.093389    
2024-02-19 17:06:50,413 - Epoch: [86][  300/  391]    Overall Loss 1.178367    Objective Loss 1.178367                                        LR 0.100000    Time 0.092841    
2024-02-19 17:06:58,493 - Epoch: [86][  391/  391]    Overall Loss 1.190103    Objective Loss 1.190103    Top1 63.942308    Top5 87.980769    LR 0.100000    Time 0.091889    
2024-02-19 17:06:58,698 - --- validate (epoch=86)-----------
2024-02-19 17:06:58,698 - 10000 samples (128 per mini-batch)
2024-02-19 17:07:01,389 - Epoch: [86][   79/   79]    Loss 1.617547    Top1 55.120000    Top5 84.970000    
2024-02-19 17:07:01,580 - ==> Top1: 55.120    Top5: 84.970    Loss: 1.618

2024-02-19 17:07:01,590 - ==> Best [Top1: 55.120   Top5: 84.970   Sparsity:0.00   Params: 1341960 on epoch: 86]
2024-02-19 17:07:01,590 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:07:01,678 - 

2024-02-19 17:07:01,679 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:07:11,455 - Epoch: [87][  100/  391]    Overall Loss 1.147955    Objective Loss 1.147955                                        LR 0.100000    Time 0.097690    
2024-02-19 17:07:20,397 - Epoch: [87][  200/  391]    Overall Loss 1.160226    Objective Loss 1.160226                                        LR 0.100000    Time 0.093533    
2024-02-19 17:07:29,573 - Epoch: [87][  300/  391]    Overall Loss 1.174703    Objective Loss 1.174703                                        LR 0.100000    Time 0.092927    
2024-02-19 17:07:38,025 - Epoch: [87][  391/  391]    Overall Loss 1.181049    Objective Loss 1.181049    Top1 60.096154    Top5 89.423077    LR 0.100000    Time 0.092905    
2024-02-19 17:07:38,251 - --- validate (epoch=87)-----------
2024-02-19 17:07:38,252 - 10000 samples (128 per mini-batch)
2024-02-19 17:07:40,890 - Epoch: [87][   79/   79]    Loss 1.951335    Top1 49.510000    Top5 80.040000    
2024-02-19 17:07:41,115 - ==> Top1: 49.510    Top5: 80.040    Loss: 1.951

2024-02-19 17:07:41,133 - ==> Best [Top1: 55.120   Top5: 84.970   Sparsity:0.00   Params: 1341960 on epoch: 86]
2024-02-19 17:07:41,134 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:07:41,208 - 

2024-02-19 17:07:41,208 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:07:51,205 - Epoch: [88][  100/  391]    Overall Loss 1.139977    Objective Loss 1.139977                                        LR 0.100000    Time 0.099898    
2024-02-19 17:08:00,088 - Epoch: [88][  200/  391]    Overall Loss 1.153389    Objective Loss 1.153389                                        LR 0.100000    Time 0.094343    
2024-02-19 17:08:07,028 - Epoch: [88][  300/  391]    Overall Loss 1.167938    Objective Loss 1.167938                                        LR 0.100000    Time 0.086014    
2024-02-19 17:08:15,245 - Epoch: [88][  391/  391]    Overall Loss 1.181036    Objective Loss 1.181036    Top1 69.230769    Top5 93.269231    LR 0.100000    Time 0.087001    
2024-02-19 17:08:15,459 - --- validate (epoch=88)-----------
2024-02-19 17:08:15,459 - 10000 samples (128 per mini-batch)
2024-02-19 17:08:18,132 - Epoch: [88][   79/   79]    Loss 1.785244    Top1 52.210000    Top5 82.760000    
2024-02-19 17:08:18,346 - ==> Top1: 52.210    Top5: 82.760    Loss: 1.785

2024-02-19 17:08:18,364 - ==> Best [Top1: 55.120   Top5: 84.970   Sparsity:0.00   Params: 1341960 on epoch: 86]
2024-02-19 17:08:18,365 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:08:18,444 - 

2024-02-19 17:08:18,444 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:08:28,101 - Epoch: [89][  100/  391]    Overall Loss 1.127520    Objective Loss 1.127520                                        LR 0.100000    Time 0.096501    
2024-02-19 17:08:37,193 - Epoch: [89][  200/  391]    Overall Loss 1.147720    Objective Loss 1.147720                                        LR 0.100000    Time 0.093685    
2024-02-19 17:08:46,318 - Epoch: [89][  300/  391]    Overall Loss 1.166428    Objective Loss 1.166428                                        LR 0.100000    Time 0.092860    
2024-02-19 17:08:54,730 - Epoch: [89][  391/  391]    Overall Loss 1.177647    Objective Loss 1.177647    Top1 65.384615    Top5 89.423077    LR 0.100000    Time 0.092752    
2024-02-19 17:08:54,928 - --- validate (epoch=89)-----------
2024-02-19 17:08:54,929 - 10000 samples (128 per mini-batch)
2024-02-19 17:08:57,681 - Epoch: [89][   79/   79]    Loss 1.973575    Top1 50.370000    Top5 78.920000    
2024-02-19 17:08:57,831 - ==> Top1: 50.370    Top5: 78.920    Loss: 1.974

2024-02-19 17:08:57,842 - ==> Best [Top1: 55.120   Top5: 84.970   Sparsity:0.00   Params: 1341960 on epoch: 86]
2024-02-19 17:08:57,842 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:08:57,918 - 

2024-02-19 17:08:57,919 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:09:07,911 - Epoch: [90][  100/  391]    Overall Loss 1.121073    Objective Loss 1.121073                                        LR 0.100000    Time 0.099857    
2024-02-19 17:09:17,175 - Epoch: [90][  200/  391]    Overall Loss 1.145805    Objective Loss 1.145805                                        LR 0.100000    Time 0.096228    
2024-02-19 17:09:26,128 - Epoch: [90][  300/  391]    Overall Loss 1.156484    Objective Loss 1.156484                                        LR 0.100000    Time 0.093981    
2024-02-19 17:09:34,629 - Epoch: [90][  391/  391]    Overall Loss 1.164850    Objective Loss 1.164850    Top1 64.423077    Top5 89.423077    LR 0.100000    Time 0.093838    
2024-02-19 17:09:34,902 - --- validate (epoch=90)-----------
2024-02-19 17:09:34,903 - 10000 samples (128 per mini-batch)
2024-02-19 17:09:37,791 - Epoch: [90][   79/   79]    Loss 1.671971    Top1 54.660000    Top5 83.970000    
2024-02-19 17:09:37,908 - ==> Top1: 54.660    Top5: 83.970    Loss: 1.672

2024-02-19 17:09:37,920 - ==> Best [Top1: 55.120   Top5: 84.970   Sparsity:0.00   Params: 1341960 on epoch: 86]
2024-02-19 17:09:37,921 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:09:37,991 - 

2024-02-19 17:09:37,991 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:09:47,573 - Epoch: [91][  100/  391]    Overall Loss 1.106952    Objective Loss 1.106952                                        LR 0.100000    Time 0.095746    
2024-02-19 17:09:56,749 - Epoch: [91][  200/  391]    Overall Loss 1.141084    Objective Loss 1.141084                                        LR 0.100000    Time 0.093730    
2024-02-19 17:10:05,847 - Epoch: [91][  300/  391]    Overall Loss 1.156907    Objective Loss 1.156907                                        LR 0.100000    Time 0.092798    
2024-02-19 17:10:14,293 - Epoch: [91][  391/  391]    Overall Loss 1.162098    Objective Loss 1.162098    Top1 61.538462    Top5 86.538462    LR 0.100000    Time 0.092789    
2024-02-19 17:10:14,512 - --- validate (epoch=91)-----------
2024-02-19 17:10:14,512 - 10000 samples (128 per mini-batch)
2024-02-19 17:10:17,060 - Epoch: [91][   79/   79]    Loss 1.832772    Top1 52.330000    Top5 81.380000    
2024-02-19 17:10:17,219 - ==> Top1: 52.330    Top5: 81.380    Loss: 1.833

2024-02-19 17:10:17,237 - ==> Best [Top1: 55.120   Top5: 84.970   Sparsity:0.00   Params: 1341960 on epoch: 86]
2024-02-19 17:10:17,238 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:10:17,312 - 

2024-02-19 17:10:17,312 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:10:27,161 - Epoch: [92][  100/  391]    Overall Loss 1.128679    Objective Loss 1.128679                                        LR 0.100000    Time 0.098420    
2024-02-19 17:10:36,315 - Epoch: [92][  200/  391]    Overall Loss 1.136649    Objective Loss 1.136649                                        LR 0.100000    Time 0.094959    
2024-02-19 17:10:45,119 - Epoch: [92][  300/  391]    Overall Loss 1.152592    Objective Loss 1.152592                                        LR 0.100000    Time 0.092639    
2024-02-19 17:10:53,482 - Epoch: [92][  391/  391]    Overall Loss 1.165580    Objective Loss 1.165580    Top1 61.057692    Top5 88.461538    LR 0.100000    Time 0.092455    
2024-02-19 17:10:53,659 - --- validate (epoch=92)-----------
2024-02-19 17:10:53,660 - 10000 samples (128 per mini-batch)
2024-02-19 17:10:56,249 - Epoch: [92][   79/   79]    Loss 1.663866    Top1 55.390000    Top5 84.270000    
2024-02-19 17:10:56,465 - ==> Top1: 55.390    Top5: 84.270    Loss: 1.664

2024-02-19 17:10:56,485 - ==> Best [Top1: 55.390   Top5: 84.270   Sparsity:0.00   Params: 1341960 on epoch: 92]
2024-02-19 17:10:56,486 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:10:56,575 - 

2024-02-19 17:10:56,576 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:11:06,247 - Epoch: [93][  100/  391]    Overall Loss 1.132603    Objective Loss 1.132603                                        LR 0.100000    Time 0.096635    
2024-02-19 17:11:15,286 - Epoch: [93][  200/  391]    Overall Loss 1.157660    Objective Loss 1.157660                                        LR 0.100000    Time 0.093495    
2024-02-19 17:11:24,277 - Epoch: [93][  300/  391]    Overall Loss 1.163294    Objective Loss 1.163294                                        LR 0.100000    Time 0.092285    
2024-02-19 17:11:32,677 - Epoch: [93][  391/  391]    Overall Loss 1.168071    Objective Loss 1.168071    Top1 64.903846    Top5 92.307692    LR 0.100000    Time 0.092279    
2024-02-19 17:11:32,898 - --- validate (epoch=93)-----------
2024-02-19 17:11:32,899 - 10000 samples (128 per mini-batch)
2024-02-19 17:11:35,524 - Epoch: [93][   79/   79]    Loss 1.778660    Top1 53.460000    Top5 82.040000    
2024-02-19 17:11:35,704 - ==> Top1: 53.460    Top5: 82.040    Loss: 1.779

2024-02-19 17:11:35,723 - ==> Best [Top1: 55.390   Top5: 84.270   Sparsity:0.00   Params: 1341960 on epoch: 92]
2024-02-19 17:11:35,723 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:11:35,799 - 

2024-02-19 17:11:35,800 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:11:43,926 - Epoch: [94][  100/  391]    Overall Loss 1.124040    Objective Loss 1.124040                                        LR 0.100000    Time 0.081202    
2024-02-19 17:11:53,229 - Epoch: [94][  200/  391]    Overall Loss 1.130566    Objective Loss 1.130566                                        LR 0.100000    Time 0.087090    
2024-02-19 17:12:02,074 - Epoch: [94][  300/  391]    Overall Loss 1.136517    Objective Loss 1.136517                                        LR 0.100000    Time 0.087531    
2024-02-19 17:12:10,450 - Epoch: [94][  391/  391]    Overall Loss 1.153137    Objective Loss 1.153137    Top1 62.019231    Top5 90.865385    LR 0.100000    Time 0.088570    
2024-02-19 17:12:10,628 - --- validate (epoch=94)-----------
2024-02-19 17:12:10,629 - 10000 samples (128 per mini-batch)
2024-02-19 17:12:13,138 - Epoch: [94][   79/   79]    Loss 1.611510    Top1 55.400000    Top5 84.510000    
2024-02-19 17:12:13,288 - ==> Top1: 55.400    Top5: 84.510    Loss: 1.612

2024-02-19 17:12:13,307 - ==> Best [Top1: 55.400   Top5: 84.510   Sparsity:0.00   Params: 1341960 on epoch: 94]
2024-02-19 17:12:13,307 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:12:13,396 - 

2024-02-19 17:12:13,396 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:12:23,185 - Epoch: [95][  100/  391]    Overall Loss 1.102432    Objective Loss 1.102432                                        LR 0.100000    Time 0.097814    
2024-02-19 17:12:32,443 - Epoch: [95][  200/  391]    Overall Loss 1.122185    Objective Loss 1.122185                                        LR 0.100000    Time 0.095175    
2024-02-19 17:12:41,411 - Epoch: [95][  300/  391]    Overall Loss 1.136620    Objective Loss 1.136620                                        LR 0.100000    Time 0.093326    
2024-02-19 17:12:49,929 - Epoch: [95][  391/  391]    Overall Loss 1.147500    Objective Loss 1.147500    Top1 66.826923    Top5 92.307692    LR 0.100000    Time 0.093380    
2024-02-19 17:12:50,154 - --- validate (epoch=95)-----------
2024-02-19 17:12:50,155 - 10000 samples (128 per mini-batch)
2024-02-19 17:12:52,788 - Epoch: [95][   79/   79]    Loss 1.925001    Top1 49.310000    Top5 79.670000    
2024-02-19 17:12:52,962 - ==> Top1: 49.310    Top5: 79.670    Loss: 1.925

2024-02-19 17:12:52,981 - ==> Best [Top1: 55.400   Top5: 84.510   Sparsity:0.00   Params: 1341960 on epoch: 94]
2024-02-19 17:12:52,981 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:12:53,055 - 

2024-02-19 17:12:53,056 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:13:03,097 - Epoch: [96][  100/  391]    Overall Loss 1.119518    Objective Loss 1.119518                                        LR 0.100000    Time 0.100344    
2024-02-19 17:13:12,284 - Epoch: [96][  200/  391]    Overall Loss 1.122402    Objective Loss 1.122402                                        LR 0.100000    Time 0.096085    
2024-02-19 17:13:21,459 - Epoch: [96][  300/  391]    Overall Loss 1.134191    Objective Loss 1.134191                                        LR 0.100000    Time 0.094626    
2024-02-19 17:13:29,823 - Epoch: [96][  391/  391]    Overall Loss 1.143472    Objective Loss 1.143472    Top1 58.653846    Top5 87.980769    LR 0.100000    Time 0.093985    
2024-02-19 17:13:30,030 - --- validate (epoch=96)-----------
2024-02-19 17:13:30,031 - 10000 samples (128 per mini-batch)
2024-02-19 17:13:32,697 - Epoch: [96][   79/   79]    Loss 1.566625    Top1 57.290000    Top5 85.610000    
2024-02-19 17:13:32,852 - ==> Top1: 57.290    Top5: 85.610    Loss: 1.567

2024-02-19 17:13:32,870 - ==> Best [Top1: 57.290   Top5: 85.610   Sparsity:0.00   Params: 1341960 on epoch: 96]
2024-02-19 17:13:32,871 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:13:32,960 - 

2024-02-19 17:13:32,961 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:13:42,449 - Epoch: [97][  100/  391]    Overall Loss 1.097953    Objective Loss 1.097953                                        LR 0.100000    Time 0.094810    
2024-02-19 17:13:51,726 - Epoch: [97][  200/  391]    Overall Loss 1.116361    Objective Loss 1.116361                                        LR 0.100000    Time 0.093768    
2024-02-19 17:14:00,920 - Epoch: [97][  300/  391]    Overall Loss 1.132750    Objective Loss 1.132750                                        LR 0.100000    Time 0.093141    
2024-02-19 17:14:09,256 - Epoch: [97][  391/  391]    Overall Loss 1.143397    Objective Loss 1.143397    Top1 67.788462    Top5 91.826923    LR 0.100000    Time 0.092773    
2024-02-19 17:14:09,498 - --- validate (epoch=97)-----------
2024-02-19 17:14:09,499 - 10000 samples (128 per mini-batch)
2024-02-19 17:14:12,063 - Epoch: [97][   79/   79]    Loss 1.555645    Top1 57.460000    Top5 84.990000    
2024-02-19 17:14:12,209 - ==> Top1: 57.460    Top5: 84.990    Loss: 1.556

2024-02-19 17:14:12,228 - ==> Best [Top1: 57.460   Top5: 84.990   Sparsity:0.00   Params: 1341960 on epoch: 97]
2024-02-19 17:14:12,228 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:14:12,317 - 

2024-02-19 17:14:12,317 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:14:22,004 - Epoch: [98][  100/  391]    Overall Loss 1.112636    Objective Loss 1.112636                                        LR 0.100000    Time 0.096798    
2024-02-19 17:14:31,056 - Epoch: [98][  200/  391]    Overall Loss 1.116951    Objective Loss 1.116951                                        LR 0.100000    Time 0.093632    
2024-02-19 17:14:40,225 - Epoch: [98][  300/  391]    Overall Loss 1.128124    Objective Loss 1.128124                                        LR 0.100000    Time 0.092972    
2024-02-19 17:14:48,565 - Epoch: [98][  391/  391]    Overall Loss 1.137896    Objective Loss 1.137896    Top1 58.653846    Top5 89.903846    LR 0.100000    Time 0.092652    
2024-02-19 17:14:48,779 - --- validate (epoch=98)-----------
2024-02-19 17:14:48,780 - 10000 samples (128 per mini-batch)
2024-02-19 17:14:51,317 - Epoch: [98][   79/   79]    Loss 1.759463    Top1 53.370000    Top5 83.050000    
2024-02-19 17:14:51,542 - ==> Top1: 53.370    Top5: 83.050    Loss: 1.759

2024-02-19 17:14:51,560 - ==> Best [Top1: 57.460   Top5: 84.990   Sparsity:0.00   Params: 1341960 on epoch: 97]
2024-02-19 17:14:51,560 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:14:51,635 - 

2024-02-19 17:14:51,635 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:15:01,646 - Epoch: [99][  100/  391]    Overall Loss 1.093764    Objective Loss 1.093764                                        LR 0.100000    Time 0.100040    
2024-02-19 17:15:10,859 - Epoch: [99][  200/  391]    Overall Loss 1.125451    Objective Loss 1.125451                                        LR 0.100000    Time 0.096058    
2024-02-19 17:15:20,036 - Epoch: [99][  300/  391]    Overall Loss 1.129275    Objective Loss 1.129275                                        LR 0.100000    Time 0.094615    
2024-02-19 17:15:28,424 - Epoch: [99][  391/  391]    Overall Loss 1.134985    Objective Loss 1.134985    Top1 65.384615    Top5 91.346154    LR 0.100000    Time 0.094036    
2024-02-19 17:15:28,651 - --- validate (epoch=99)-----------
2024-02-19 17:15:28,652 - 10000 samples (128 per mini-batch)
2024-02-19 17:15:31,201 - Epoch: [99][   79/   79]    Loss 1.652775    Top1 55.010000    Top5 84.220000    
2024-02-19 17:15:31,338 - ==> Top1: 55.010    Top5: 84.220    Loss: 1.653

2024-02-19 17:15:31,357 - ==> Best [Top1: 57.460   Top5: 84.990   Sparsity:0.00   Params: 1341960 on epoch: 97]
2024-02-19 17:15:31,357 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:15:31,431 - 

2024-02-19 17:15:31,431 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:15:41,200 - Epoch: [100][  100/  391]    Overall Loss 0.903404    Objective Loss 0.903404                                        LR 0.023500    Time 0.097617    
2024-02-19 17:15:50,129 - Epoch: [100][  200/  391]    Overall Loss 0.855386    Objective Loss 0.855386                                        LR 0.023500    Time 0.093430    
2024-02-19 17:15:57,445 - Epoch: [100][  300/  391]    Overall Loss 0.837106    Objective Loss 0.837106                                        LR 0.023500    Time 0.086663    
2024-02-19 17:16:06,005 - Epoch: [100][  391/  391]    Overall Loss 0.827087    Objective Loss 0.827087    Top1 75.480769    Top5 95.673077    LR 0.023500    Time 0.088374    
2024-02-19 17:16:06,191 - --- validate (epoch=100)-----------
2024-02-19 17:16:06,192 - 10000 samples (128 per mini-batch)
2024-02-19 17:16:09,042 - Epoch: [100][   79/   79]    Loss 1.230817    Top1 65.550000    Top5 90.210000    
2024-02-19 17:16:09,232 - ==> Top1: 65.550    Top5: 90.210    Loss: 1.231

2024-02-19 17:16:09,251 - ==> Best [Top1: 65.550   Top5: 90.210   Sparsity:0.00   Params: 1341960 on epoch: 100]
2024-02-19 17:16:09,251 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:16:09,343 - 

2024-02-19 17:16:09,343 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:16:16,901 - Epoch: [101][  100/  391]    Overall Loss 0.744482    Objective Loss 0.744482                                        LR 0.023500    Time 0.075511    
2024-02-19 17:16:23,877 - Epoch: [101][  200/  391]    Overall Loss 0.752669    Objective Loss 0.752669                                        LR 0.023500    Time 0.072616    
2024-02-19 17:16:31,638 - Epoch: [101][  300/  391]    Overall Loss 0.749218    Objective Loss 0.749218                                        LR 0.023500    Time 0.074267    
2024-02-19 17:16:40,109 - Epoch: [101][  391/  391]    Overall Loss 0.749171    Objective Loss 0.749171    Top1 78.365385    Top5 96.153846    LR 0.023500    Time 0.078638    
2024-02-19 17:16:40,304 - --- validate (epoch=101)-----------
2024-02-19 17:16:40,305 - 10000 samples (128 per mini-batch)
2024-02-19 17:16:42,952 - Epoch: [101][   79/   79]    Loss 1.232268    Top1 65.080000    Top5 90.050000    
2024-02-19 17:16:43,130 - ==> Top1: 65.080    Top5: 90.050    Loss: 1.232

2024-02-19 17:16:43,149 - ==> Best [Top1: 65.550   Top5: 90.210   Sparsity:0.00   Params: 1341960 on epoch: 100]
2024-02-19 17:16:43,149 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:16:43,225 - 

2024-02-19 17:16:43,226 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:16:53,356 - Epoch: [102][  100/  391]    Overall Loss 0.727950    Objective Loss 0.727950                                        LR 0.023500    Time 0.101234    
2024-02-19 17:17:02,621 - Epoch: [102][  200/  391]    Overall Loss 0.724930    Objective Loss 0.724930                                        LR 0.023500    Time 0.096917    
2024-02-19 17:17:11,141 - Epoch: [102][  300/  391]    Overall Loss 0.721203    Objective Loss 0.721203                                        LR 0.023500    Time 0.092995    
2024-02-19 17:17:17,813 - Epoch: [102][  391/  391]    Overall Loss 0.721563    Objective Loss 0.721563    Top1 74.038462    Top5 95.192308    LR 0.023500    Time 0.088409    
2024-02-19 17:17:18,065 - --- validate (epoch=102)-----------
2024-02-19 17:17:18,067 - 10000 samples (128 per mini-batch)
2024-02-19 17:17:20,737 - Epoch: [102][   79/   79]    Loss 1.217137    Top1 65.640000    Top5 90.050000    
2024-02-19 17:17:20,880 - ==> Top1: 65.640    Top5: 90.050    Loss: 1.217

2024-02-19 17:17:20,898 - ==> Best [Top1: 65.640   Top5: 90.050   Sparsity:0.00   Params: 1341960 on epoch: 102]
2024-02-19 17:17:20,899 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:17:20,989 - 

2024-02-19 17:17:20,990 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:17:30,956 - Epoch: [103][  100/  391]    Overall Loss 0.680840    Objective Loss 0.680840                                        LR 0.023500    Time 0.099591    
2024-02-19 17:17:40,345 - Epoch: [103][  200/  391]    Overall Loss 0.682802    Objective Loss 0.682802                                        LR 0.023500    Time 0.096715    
2024-02-19 17:17:49,648 - Epoch: [103][  300/  391]    Overall Loss 0.691215    Objective Loss 0.691215                                        LR 0.023500    Time 0.095473    
2024-02-19 17:17:58,020 - Epoch: [103][  391/  391]    Overall Loss 0.697680    Objective Loss 0.697680    Top1 85.096154    Top5 95.673077    LR 0.023500    Time 0.094652    
2024-02-19 17:17:58,241 - --- validate (epoch=103)-----------
2024-02-19 17:17:58,242 - 10000 samples (128 per mini-batch)
2024-02-19 17:18:00,851 - Epoch: [103][   79/   79]    Loss 1.242191    Top1 65.060000    Top5 89.730000    
2024-02-19 17:18:00,987 - ==> Top1: 65.060    Top5: 89.730    Loss: 1.242

2024-02-19 17:18:01,005 - ==> Best [Top1: 65.640   Top5: 90.050   Sparsity:0.00   Params: 1341960 on epoch: 102]
2024-02-19 17:18:01,005 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:18:01,078 - 

2024-02-19 17:18:01,078 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:18:11,057 - Epoch: [104][  100/  391]    Overall Loss 0.668947    Objective Loss 0.668947                                        LR 0.023500    Time 0.099716    
2024-02-19 17:18:20,173 - Epoch: [104][  200/  391]    Overall Loss 0.680357    Objective Loss 0.680357                                        LR 0.023500    Time 0.095415    
2024-02-19 17:18:29,217 - Epoch: [104][  300/  391]    Overall Loss 0.679509    Objective Loss 0.679509                                        LR 0.023500    Time 0.093741    
2024-02-19 17:18:37,614 - Epoch: [104][  391/  391]    Overall Loss 0.687346    Objective Loss 0.687346    Top1 76.442308    Top5 95.192308    LR 0.023500    Time 0.093390    
2024-02-19 17:18:37,764 - --- validate (epoch=104)-----------
2024-02-19 17:18:37,765 - 10000 samples (128 per mini-batch)
2024-02-19 17:18:40,380 - Epoch: [104][   79/   79]    Loss 1.212613    Top1 66.040000    Top5 90.370000    
2024-02-19 17:18:40,596 - ==> Top1: 66.040    Top5: 90.370    Loss: 1.213

2024-02-19 17:18:40,614 - ==> Best [Top1: 66.040   Top5: 90.370   Sparsity:0.00   Params: 1341960 on epoch: 104]
2024-02-19 17:18:40,615 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:18:40,705 - 

2024-02-19 17:18:40,706 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:18:50,606 - Epoch: [105][  100/  391]    Overall Loss 0.649788    Objective Loss 0.649788                                        LR 0.023500    Time 0.098926    
2024-02-19 17:18:59,948 - Epoch: [105][  200/  391]    Overall Loss 0.655619    Objective Loss 0.655619                                        LR 0.023500    Time 0.096152    
2024-02-19 17:19:08,767 - Epoch: [105][  300/  391]    Overall Loss 0.663308    Objective Loss 0.663308                                        LR 0.023500    Time 0.093482    
2024-02-19 17:19:17,186 - Epoch: [105][  391/  391]    Overall Loss 0.667088    Objective Loss 0.667088    Top1 77.884615    Top5 98.557692    LR 0.023500    Time 0.093247    
2024-02-19 17:19:17,382 - --- validate (epoch=105)-----------
2024-02-19 17:19:17,383 - 10000 samples (128 per mini-batch)
2024-02-19 17:19:20,014 - Epoch: [105][   79/   79]    Loss 1.222828    Top1 65.370000    Top5 90.160000    
2024-02-19 17:19:20,205 - ==> Top1: 65.370    Top5: 90.160    Loss: 1.223

2024-02-19 17:19:20,226 - ==> Best [Top1: 66.040   Top5: 90.370   Sparsity:0.00   Params: 1341960 on epoch: 104]
2024-02-19 17:19:20,226 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:19:20,301 - 

2024-02-19 17:19:20,301 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:19:30,332 - Epoch: [106][  100/  391]    Overall Loss 0.647922    Objective Loss 0.647922                                        LR 0.023500    Time 0.100235    
2024-02-19 17:19:39,564 - Epoch: [106][  200/  391]    Overall Loss 0.656212    Objective Loss 0.656212                                        LR 0.023500    Time 0.096255    
2024-02-19 17:19:47,524 - Epoch: [106][  300/  391]    Overall Loss 0.650680    Objective Loss 0.650680                                        LR 0.023500    Time 0.090691    
2024-02-19 17:19:54,527 - Epoch: [106][  391/  391]    Overall Loss 0.652795    Objective Loss 0.652795    Top1 80.288462    Top5 96.634615    LR 0.023500    Time 0.087485    
2024-02-19 17:19:54,755 - --- validate (epoch=106)-----------
2024-02-19 17:19:54,756 - 10000 samples (128 per mini-batch)
2024-02-19 17:19:57,466 - Epoch: [106][   79/   79]    Loss 1.237146    Top1 65.390000    Top5 90.110000    
2024-02-19 17:19:57,683 - ==> Top1: 65.390    Top5: 90.110    Loss: 1.237

2024-02-19 17:19:57,700 - ==> Best [Top1: 66.040   Top5: 90.370   Sparsity:0.00   Params: 1341960 on epoch: 104]
2024-02-19 17:19:57,701 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:19:57,775 - 

2024-02-19 17:19:57,776 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:20:07,558 - Epoch: [107][  100/  391]    Overall Loss 0.628644    Objective Loss 0.628644                                        LR 0.023500    Time 0.097747    
2024-02-19 17:20:16,808 - Epoch: [107][  200/  391]    Overall Loss 0.638219    Objective Loss 0.638219                                        LR 0.023500    Time 0.095101    
2024-02-19 17:20:23,563 - Epoch: [107][  300/  391]    Overall Loss 0.640107    Objective Loss 0.640107                                        LR 0.023500    Time 0.085905    
2024-02-19 17:20:29,746 - Epoch: [107][  391/  391]    Overall Loss 0.648960    Objective Loss 0.648960    Top1 79.326923    Top5 98.076923    LR 0.023500    Time 0.081718    
2024-02-19 17:20:29,928 - --- validate (epoch=107)-----------
2024-02-19 17:20:29,929 - 10000 samples (128 per mini-batch)
2024-02-19 17:20:32,527 - Epoch: [107][   79/   79]    Loss 1.260121    Top1 65.170000    Top5 89.580000    
2024-02-19 17:20:32,743 - ==> Top1: 65.170    Top5: 89.580    Loss: 1.260

2024-02-19 17:20:32,760 - ==> Best [Top1: 66.040   Top5: 90.370   Sparsity:0.00   Params: 1341960 on epoch: 104]
2024-02-19 17:20:32,761 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:20:32,834 - 

2024-02-19 17:20:32,834 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:20:42,615 - Epoch: [108][  100/  391]    Overall Loss 0.618427    Objective Loss 0.618427                                        LR 0.023500    Time 0.097735    
2024-02-19 17:20:51,885 - Epoch: [108][  200/  391]    Overall Loss 0.626711    Objective Loss 0.626711                                        LR 0.023500    Time 0.095194    
2024-02-19 17:21:01,206 - Epoch: [108][  300/  391]    Overall Loss 0.635810    Objective Loss 0.635810                                        LR 0.023500    Time 0.094519    
2024-02-19 17:21:08,250 - Epoch: [108][  391/  391]    Overall Loss 0.640143    Objective Loss 0.640143    Top1 82.211538    Top5 99.519231    LR 0.023500    Time 0.090526    
2024-02-19 17:21:08,459 - --- validate (epoch=108)-----------
2024-02-19 17:21:08,459 - 10000 samples (128 per mini-batch)
2024-02-19 17:21:11,060 - Epoch: [108][   79/   79]    Loss 1.233425    Top1 65.550000    Top5 90.400000    
2024-02-19 17:21:11,360 - ==> Top1: 65.550    Top5: 90.400    Loss: 1.233

2024-02-19 17:21:11,378 - ==> Best [Top1: 66.040   Top5: 90.370   Sparsity:0.00   Params: 1341960 on epoch: 104]
2024-02-19 17:21:11,378 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:21:11,452 - 

2024-02-19 17:21:11,453 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:21:21,466 - Epoch: [109][  100/  391]    Overall Loss 0.608839    Objective Loss 0.608839                                        LR 0.023500    Time 0.100058    
2024-02-19 17:21:30,701 - Epoch: [109][  200/  391]    Overall Loss 0.617831    Objective Loss 0.617831                                        LR 0.023500    Time 0.096180    
2024-02-19 17:21:39,892 - Epoch: [109][  300/  391]    Overall Loss 0.625404    Objective Loss 0.625404                                        LR 0.023500    Time 0.094742    
2024-02-19 17:21:48,268 - Epoch: [109][  391/  391]    Overall Loss 0.631449    Objective Loss 0.631449    Top1 78.365385    Top5 96.153846    LR 0.023500    Time 0.094104    
2024-02-19 17:21:48,505 - --- validate (epoch=109)-----------
2024-02-19 17:21:48,506 - 10000 samples (128 per mini-batch)
2024-02-19 17:21:51,054 - Epoch: [109][   79/   79]    Loss 1.257949    Top1 65.170000    Top5 89.880000    
2024-02-19 17:21:51,191 - ==> Top1: 65.170    Top5: 89.880    Loss: 1.258

2024-02-19 17:21:51,209 - ==> Best [Top1: 66.040   Top5: 90.370   Sparsity:0.00   Params: 1341960 on epoch: 104]
2024-02-19 17:21:51,209 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:21:51,283 - 

2024-02-19 17:21:51,284 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:22:00,975 - Epoch: [110][  100/  391]    Overall Loss 0.593725    Objective Loss 0.593725                                        LR 0.023500    Time 0.096839    
2024-02-19 17:22:10,149 - Epoch: [110][  200/  391]    Overall Loss 0.605866    Objective Loss 0.605866                                        LR 0.023500    Time 0.094266    
2024-02-19 17:22:19,462 - Epoch: [110][  300/  391]    Overall Loss 0.614432    Objective Loss 0.614432                                        LR 0.023500    Time 0.093872    
2024-02-19 17:22:27,917 - Epoch: [110][  391/  391]    Overall Loss 0.621633    Objective Loss 0.621633    Top1 75.480769    Top5 95.192308    LR 0.023500    Time 0.093639    
2024-02-19 17:22:28,128 - --- validate (epoch=110)-----------
2024-02-19 17:22:28,128 - 10000 samples (128 per mini-batch)
2024-02-19 17:22:30,724 - Epoch: [110][   79/   79]    Loss 1.219577    Top1 66.110000    Top5 90.090000    
2024-02-19 17:22:30,917 - ==> Top1: 66.110    Top5: 90.090    Loss: 1.220

2024-02-19 17:22:30,936 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:22:30,936 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:22:31,036 - 

2024-02-19 17:22:31,036 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:22:41,011 - Epoch: [111][  100/  391]    Overall Loss 0.599360    Objective Loss 0.599360                                        LR 0.023500    Time 0.099671    
2024-02-19 17:22:50,143 - Epoch: [111][  200/  391]    Overall Loss 0.600780    Objective Loss 0.600780                                        LR 0.023500    Time 0.095476    
2024-02-19 17:22:59,578 - Epoch: [111][  300/  391]    Overall Loss 0.612345    Objective Loss 0.612345                                        LR 0.023500    Time 0.095086    
2024-02-19 17:23:08,225 - Epoch: [111][  391/  391]    Overall Loss 0.621217    Objective Loss 0.621217    Top1 82.211538    Top5 97.115385    LR 0.023500    Time 0.095061    
2024-02-19 17:23:08,387 - --- validate (epoch=111)-----------
2024-02-19 17:23:08,388 - 10000 samples (128 per mini-batch)
2024-02-19 17:23:11,148 - Epoch: [111][   79/   79]    Loss 1.307443    Top1 64.350000    Top5 89.100000    
2024-02-19 17:23:11,274 - ==> Top1: 64.350    Top5: 89.100    Loss: 1.307

2024-02-19 17:23:11,294 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:23:11,294 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:23:11,370 - 

2024-02-19 17:23:11,371 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:23:21,383 - Epoch: [112][  100/  391]    Overall Loss 0.589680    Objective Loss 0.589680                                        LR 0.023500    Time 0.100054    
2024-02-19 17:23:30,722 - Epoch: [112][  200/  391]    Overall Loss 0.594518    Objective Loss 0.594518                                        LR 0.023500    Time 0.096697    
2024-02-19 17:23:40,168 - Epoch: [112][  300/  391]    Overall Loss 0.599510    Objective Loss 0.599510                                        LR 0.023500    Time 0.095935    
2024-02-19 17:23:48,622 - Epoch: [112][  391/  391]    Overall Loss 0.609625    Objective Loss 0.609625    Top1 76.442308    Top5 96.153846    LR 0.023500    Time 0.095219    
2024-02-19 17:23:48,794 - --- validate (epoch=112)-----------
2024-02-19 17:23:48,795 - 10000 samples (128 per mini-batch)
2024-02-19 17:23:51,364 - Epoch: [112][   79/   79]    Loss 1.298559    Top1 64.930000    Top5 89.460000    
2024-02-19 17:23:51,518 - ==> Top1: 64.930    Top5: 89.460    Loss: 1.299

2024-02-19 17:23:51,537 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:23:51,537 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:23:51,612 - 

2024-02-19 17:23:51,612 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:24:00,011 - Epoch: [113][  100/  391]    Overall Loss 0.592065    Objective Loss 0.592065                                        LR 0.023500    Time 0.083916    
2024-02-19 17:24:06,763 - Epoch: [113][  200/  391]    Overall Loss 0.593936    Objective Loss 0.593936                                        LR 0.023500    Time 0.075700    
2024-02-19 17:24:13,919 - Epoch: [113][  300/  391]    Overall Loss 0.600268    Objective Loss 0.600268                                        LR 0.023500    Time 0.074310    
2024-02-19 17:24:20,097 - Epoch: [113][  391/  391]    Overall Loss 0.606185    Objective Loss 0.606185    Top1 76.442308    Top5 98.076923    LR 0.023500    Time 0.072808    
2024-02-19 17:24:20,321 - --- validate (epoch=113)-----------
2024-02-19 17:24:20,322 - 10000 samples (128 per mini-batch)
2024-02-19 17:24:23,136 - Epoch: [113][   79/   79]    Loss 1.317711    Top1 64.190000    Top5 89.450000    
2024-02-19 17:24:23,287 - ==> Top1: 64.190    Top5: 89.450    Loss: 1.318

2024-02-19 17:24:23,305 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:24:23,305 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:24:23,379 - 

2024-02-19 17:24:23,380 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:24:33,452 - Epoch: [114][  100/  391]    Overall Loss 0.574343    Objective Loss 0.574343                                        LR 0.023500    Time 0.100652    
2024-02-19 17:24:42,555 - Epoch: [114][  200/  391]    Overall Loss 0.586967    Objective Loss 0.586967                                        LR 0.023500    Time 0.095817    
2024-02-19 17:24:51,746 - Epoch: [114][  300/  391]    Overall Loss 0.596132    Objective Loss 0.596132                                        LR 0.023500    Time 0.094500    
2024-02-19 17:25:00,093 - Epoch: [114][  391/  391]    Overall Loss 0.605783    Objective Loss 0.605783    Top1 80.769231    Top5 96.153846    LR 0.023500    Time 0.093845    
2024-02-19 17:25:00,299 - --- validate (epoch=114)-----------
2024-02-19 17:25:00,299 - 10000 samples (128 per mini-batch)
2024-02-19 17:25:03,069 - Epoch: [114][   79/   79]    Loss 1.309465    Top1 64.210000    Top5 88.980000    
2024-02-19 17:25:03,269 - ==> Top1: 64.210    Top5: 88.980    Loss: 1.309

2024-02-19 17:25:03,288 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:25:03,289 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:25:03,366 - 

2024-02-19 17:25:03,366 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:25:13,336 - Epoch: [115][  100/  391]    Overall Loss 0.574954    Objective Loss 0.574954                                        LR 0.023500    Time 0.099619    
2024-02-19 17:25:22,542 - Epoch: [115][  200/  391]    Overall Loss 0.579106    Objective Loss 0.579106                                        LR 0.023500    Time 0.095814    
2024-02-19 17:25:31,792 - Epoch: [115][  300/  391]    Overall Loss 0.592322    Objective Loss 0.592322                                        LR 0.023500    Time 0.094694    
2024-02-19 17:25:40,378 - Epoch: [115][  391/  391]    Overall Loss 0.601133    Objective Loss 0.601133    Top1 81.730769    Top5 96.153846    LR 0.023500    Time 0.094602    
2024-02-19 17:25:40,547 - --- validate (epoch=115)-----------
2024-02-19 17:25:40,548 - 10000 samples (128 per mini-batch)
2024-02-19 17:25:43,359 - Epoch: [115][   79/   79]    Loss 1.320970    Top1 64.180000    Top5 88.950000    
2024-02-19 17:25:43,588 - ==> Top1: 64.180    Top5: 88.950    Loss: 1.321

2024-02-19 17:25:43,605 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:25:43,606 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:25:43,679 - 

2024-02-19 17:25:43,680 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:25:53,442 - Epoch: [116][  100/  391]    Overall Loss 0.590266    Objective Loss 0.590266                                        LR 0.023500    Time 0.097549    
2024-02-19 17:26:02,678 - Epoch: [116][  200/  391]    Overall Loss 0.591161    Objective Loss 0.591161                                        LR 0.023500    Time 0.094931    
2024-02-19 17:26:11,879 - Epoch: [116][  300/  391]    Overall Loss 0.597120    Objective Loss 0.597120                                        LR 0.023500    Time 0.093945    
2024-02-19 17:26:20,278 - Epoch: [116][  391/  391]    Overall Loss 0.602517    Objective Loss 0.602517    Top1 77.403846    Top5 96.634615    LR 0.023500    Time 0.093550    
2024-02-19 17:26:20,563 - --- validate (epoch=116)-----------
2024-02-19 17:26:20,564 - 10000 samples (128 per mini-batch)
2024-02-19 17:26:23,340 - Epoch: [116][   79/   79]    Loss 1.299381    Top1 65.010000    Top5 89.490000    
2024-02-19 17:26:23,505 - ==> Top1: 65.010    Top5: 89.490    Loss: 1.299

2024-02-19 17:26:23,517 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:26:23,517 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:26:23,589 - 

2024-02-19 17:26:23,590 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:26:32,174 - Epoch: [117][  100/  391]    Overall Loss 0.571592    Objective Loss 0.571592                                        LR 0.023500    Time 0.085771    
2024-02-19 17:26:41,449 - Epoch: [117][  200/  391]    Overall Loss 0.580793    Objective Loss 0.580793                                        LR 0.023500    Time 0.089240    
2024-02-19 17:26:50,591 - Epoch: [117][  300/  391]    Overall Loss 0.587905    Objective Loss 0.587905                                        LR 0.023500    Time 0.089953    
2024-02-19 17:26:59,009 - Epoch: [117][  391/  391]    Overall Loss 0.594131    Objective Loss 0.594131    Top1 77.403846    Top5 95.673077    LR 0.023500    Time 0.090534    
2024-02-19 17:26:59,310 - --- validate (epoch=117)-----------
2024-02-19 17:26:59,311 - 10000 samples (128 per mini-batch)
2024-02-19 17:27:02,089 - Epoch: [117][   79/   79]    Loss 1.343025    Top1 64.040000    Top5 88.790000    
2024-02-19 17:27:02,233 - ==> Top1: 64.040    Top5: 88.790    Loss: 1.343

2024-02-19 17:27:02,251 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:27:02,251 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:27:02,333 - 

2024-02-19 17:27:02,334 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:27:12,164 - Epoch: [118][  100/  391]    Overall Loss 0.565083    Objective Loss 0.565083                                        LR 0.023500    Time 0.098226    
2024-02-19 17:27:21,438 - Epoch: [118][  200/  391]    Overall Loss 0.568931    Objective Loss 0.568931                                        LR 0.023500    Time 0.095460    
2024-02-19 17:27:30,799 - Epoch: [118][  300/  391]    Overall Loss 0.579081    Objective Loss 0.579081                                        LR 0.023500    Time 0.094829    
2024-02-19 17:27:39,226 - Epoch: [118][  391/  391]    Overall Loss 0.589991    Objective Loss 0.589991    Top1 79.326923    Top5 97.596154    LR 0.023500    Time 0.094299    
2024-02-19 17:27:39,527 - --- validate (epoch=118)-----------
2024-02-19 17:27:39,527 - 10000 samples (128 per mini-batch)
2024-02-19 17:27:42,421 - Epoch: [118][   79/   79]    Loss 1.285393    Top1 65.080000    Top5 89.680000    
2024-02-19 17:27:42,583 - ==> Top1: 65.080    Top5: 89.680    Loss: 1.285

2024-02-19 17:27:42,602 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:27:42,602 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:27:42,677 - 

2024-02-19 17:27:42,677 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:27:52,489 - Epoch: [119][  100/  391]    Overall Loss 0.555229    Objective Loss 0.555229                                        LR 0.023500    Time 0.098044    
2024-02-19 17:28:01,896 - Epoch: [119][  200/  391]    Overall Loss 0.563886    Objective Loss 0.563886                                        LR 0.023500    Time 0.096035    
2024-02-19 17:28:11,288 - Epoch: [119][  300/  391]    Overall Loss 0.574306    Objective Loss 0.574306                                        LR 0.023500    Time 0.095315    
2024-02-19 17:28:19,827 - Epoch: [119][  391/  391]    Overall Loss 0.585766    Objective Loss 0.585766    Top1 77.403846    Top5 98.076923    LR 0.023500    Time 0.094961    
2024-02-19 17:28:20,054 - --- validate (epoch=119)-----------
2024-02-19 17:28:20,055 - 10000 samples (128 per mini-batch)
2024-02-19 17:28:22,675 - Epoch: [119][   79/   79]    Loss 1.281214    Top1 65.070000    Top5 89.780000    
2024-02-19 17:28:22,829 - ==> Top1: 65.070    Top5: 89.780    Loss: 1.281

2024-02-19 17:28:22,848 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:28:22,848 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:28:22,923 - 

2024-02-19 17:28:22,923 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:28:32,534 - Epoch: [120][  100/  391]    Overall Loss 0.544596    Objective Loss 0.544596                                        LR 0.023500    Time 0.096041    
2024-02-19 17:28:39,404 - Epoch: [120][  200/  391]    Overall Loss 0.561226    Objective Loss 0.561226                                        LR 0.023500    Time 0.082349    
2024-02-19 17:28:46,201 - Epoch: [120][  300/  391]    Overall Loss 0.570281    Objective Loss 0.570281                                        LR 0.023500    Time 0.077544    
2024-02-19 17:28:52,388 - Epoch: [120][  391/  391]    Overall Loss 0.578666    Objective Loss 0.578666    Top1 80.769231    Top5 98.557692    LR 0.023500    Time 0.075312    
2024-02-19 17:28:52,596 - --- validate (epoch=120)-----------
2024-02-19 17:28:52,597 - 10000 samples (128 per mini-batch)
2024-02-19 17:28:55,289 - Epoch: [120][   79/   79]    Loss 1.283224    Top1 64.780000    Top5 89.990000    
2024-02-19 17:28:55,479 - ==> Top1: 64.780    Top5: 89.990    Loss: 1.283

2024-02-19 17:28:55,501 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:28:55,501 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:28:55,581 - 

2024-02-19 17:28:55,582 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:29:05,523 - Epoch: [121][  100/  391]    Overall Loss 0.539578    Objective Loss 0.539578                                        LR 0.023500    Time 0.099342    
2024-02-19 17:29:13,572 - Epoch: [121][  200/  391]    Overall Loss 0.562012    Objective Loss 0.562012                                        LR 0.023500    Time 0.089893    
2024-02-19 17:29:22,788 - Epoch: [121][  300/  391]    Overall Loss 0.571322    Objective Loss 0.571322                                        LR 0.023500    Time 0.090636    
2024-02-19 17:29:31,230 - Epoch: [121][  391/  391]    Overall Loss 0.579879    Objective Loss 0.579879    Top1 83.173077    Top5 96.634615    LR 0.023500    Time 0.091122    
2024-02-19 17:29:31,447 - --- validate (epoch=121)-----------
2024-02-19 17:29:31,447 - 10000 samples (128 per mini-batch)
2024-02-19 17:29:34,179 - Epoch: [121][   79/   79]    Loss 1.297498    Top1 64.430000    Top5 89.680000    
2024-02-19 17:29:34,344 - ==> Top1: 64.430    Top5: 89.680    Loss: 1.297

2024-02-19 17:29:34,363 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:29:34,363 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:29:34,437 - 

2024-02-19 17:29:34,437 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:29:44,359 - Epoch: [122][  100/  391]    Overall Loss 0.538779    Objective Loss 0.538779                                        LR 0.023500    Time 0.099154    
2024-02-19 17:29:53,626 - Epoch: [122][  200/  391]    Overall Loss 0.547705    Objective Loss 0.547705                                        LR 0.023500    Time 0.095889    
2024-02-19 17:30:02,743 - Epoch: [122][  300/  391]    Overall Loss 0.560586    Objective Loss 0.560586                                        LR 0.023500    Time 0.094302    
2024-02-19 17:30:11,132 - Epoch: [122][  391/  391]    Overall Loss 0.568272    Objective Loss 0.568272    Top1 81.250000    Top5 97.596154    LR 0.023500    Time 0.093800    
2024-02-19 17:30:11,305 - --- validate (epoch=122)-----------
2024-02-19 17:30:11,307 - 10000 samples (128 per mini-batch)
2024-02-19 17:30:13,802 - Epoch: [122][   79/   79]    Loss 1.398728    Top1 63.080000    Top5 88.530000    
2024-02-19 17:30:13,953 - ==> Top1: 63.080    Top5: 88.530    Loss: 1.399

2024-02-19 17:30:13,971 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:30:13,972 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:30:14,046 - 

2024-02-19 17:30:14,046 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:30:23,788 - Epoch: [123][  100/  391]    Overall Loss 0.545120    Objective Loss 0.545120                                        LR 0.023500    Time 0.097350    
2024-02-19 17:30:32,973 - Epoch: [123][  200/  391]    Overall Loss 0.554063    Objective Loss 0.554063                                        LR 0.023500    Time 0.094574    
2024-02-19 17:30:42,118 - Epoch: [123][  300/  391]    Overall Loss 0.566640    Objective Loss 0.566640                                        LR 0.023500    Time 0.093518    
2024-02-19 17:30:50,521 - Epoch: [123][  391/  391]    Overall Loss 0.577591    Objective Loss 0.577591    Top1 75.961538    Top5 97.596154    LR 0.023500    Time 0.093235    
2024-02-19 17:30:50,763 - --- validate (epoch=123)-----------
2024-02-19 17:30:50,763 - 10000 samples (128 per mini-batch)
2024-02-19 17:30:53,397 - Epoch: [123][   79/   79]    Loss 1.291370    Top1 65.150000    Top5 89.640000    
2024-02-19 17:30:53,599 - ==> Top1: 65.150    Top5: 89.640    Loss: 1.291

2024-02-19 17:30:53,619 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:30:53,620 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:30:53,694 - 

2024-02-19 17:30:53,695 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:31:03,724 - Epoch: [124][  100/  391]    Overall Loss 0.551294    Objective Loss 0.551294                                        LR 0.023500    Time 0.100229    
2024-02-19 17:31:12,882 - Epoch: [124][  200/  391]    Overall Loss 0.559176    Objective Loss 0.559176                                        LR 0.023500    Time 0.095880    
2024-02-19 17:31:21,903 - Epoch: [124][  300/  391]    Overall Loss 0.567467    Objective Loss 0.567467                                        LR 0.023500    Time 0.093975    
2024-02-19 17:31:30,254 - Epoch: [124][  391/  391]    Overall Loss 0.575790    Objective Loss 0.575790    Top1 82.692308    Top5 97.596154    LR 0.023500    Time 0.093451    
2024-02-19 17:31:30,555 - --- validate (epoch=124)-----------
2024-02-19 17:31:30,555 - 10000 samples (128 per mini-batch)
2024-02-19 17:31:33,112 - Epoch: [124][   79/   79]    Loss 1.353544    Top1 64.360000    Top5 88.660000    
2024-02-19 17:31:33,277 - ==> Top1: 64.360    Top5: 88.660    Loss: 1.354

2024-02-19 17:31:33,297 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:31:33,298 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:31:33,371 - 

2024-02-19 17:31:33,371 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:31:43,160 - Epoch: [125][  100/  391]    Overall Loss 0.557675    Objective Loss 0.557675                                        LR 0.023500    Time 0.097821    
2024-02-19 17:31:52,217 - Epoch: [125][  200/  391]    Overall Loss 0.559029    Objective Loss 0.559029                                        LR 0.023500    Time 0.094173    
2024-02-19 17:32:01,237 - Epoch: [125][  300/  391]    Overall Loss 0.565728    Objective Loss 0.565728                                        LR 0.023500    Time 0.092832    
2024-02-19 17:32:09,683 - Epoch: [125][  391/  391]    Overall Loss 0.575140    Objective Loss 0.575140    Top1 86.538462    Top5 98.076923    LR 0.023500    Time 0.092820    
2024-02-19 17:32:09,910 - --- validate (epoch=125)-----------
2024-02-19 17:32:09,911 - 10000 samples (128 per mini-batch)
2024-02-19 17:32:12,673 - Epoch: [125][   79/   79]    Loss 1.319069    Top1 63.570000    Top5 89.240000    
2024-02-19 17:32:12,852 - ==> Top1: 63.570    Top5: 89.240    Loss: 1.319

2024-02-19 17:32:12,873 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:32:12,874 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:32:12,952 - 

2024-02-19 17:32:12,952 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:32:23,072 - Epoch: [126][  100/  391]    Overall Loss 0.531751    Objective Loss 0.531751                                        LR 0.023500    Time 0.101115    
2024-02-19 17:32:32,099 - Epoch: [126][  200/  391]    Overall Loss 0.548702    Objective Loss 0.548702                                        LR 0.023500    Time 0.095672    
2024-02-19 17:32:41,097 - Epoch: [126][  300/  391]    Overall Loss 0.562794    Objective Loss 0.562794                                        LR 0.023500    Time 0.093760    
2024-02-19 17:32:49,536 - Epoch: [126][  391/  391]    Overall Loss 0.566014    Objective Loss 0.566014    Top1 80.288462    Top5 98.076923    LR 0.023500    Time 0.093512    
2024-02-19 17:32:49,754 - --- validate (epoch=126)-----------
2024-02-19 17:32:49,756 - 10000 samples (128 per mini-batch)
2024-02-19 17:32:52,440 - Epoch: [126][   79/   79]    Loss 1.300004    Top1 64.620000    Top5 89.500000    
2024-02-19 17:32:52,647 - ==> Top1: 64.620    Top5: 89.500    Loss: 1.300

2024-02-19 17:32:52,670 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:32:52,671 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:32:52,747 - 

2024-02-19 17:32:52,748 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:33:02,601 - Epoch: [127][  100/  391]    Overall Loss 0.541477    Objective Loss 0.541477                                        LR 0.023500    Time 0.098458    
2024-02-19 17:33:11,676 - Epoch: [127][  200/  391]    Overall Loss 0.550580    Objective Loss 0.550580                                        LR 0.023500    Time 0.094584    
2024-02-19 17:33:20,882 - Epoch: [127][  300/  391]    Overall Loss 0.559187    Objective Loss 0.559187                                        LR 0.023500    Time 0.093727    
2024-02-19 17:33:29,287 - Epoch: [127][  391/  391]    Overall Loss 0.570268    Objective Loss 0.570268    Top1 78.846154    Top5 99.038462    LR 0.023500    Time 0.093397    
2024-02-19 17:33:29,476 - --- validate (epoch=127)-----------
2024-02-19 17:33:29,477 - 10000 samples (128 per mini-batch)
2024-02-19 17:33:32,197 - Epoch: [127][   79/   79]    Loss 1.424709    Top1 62.530000    Top5 88.140000    
2024-02-19 17:33:32,372 - ==> Top1: 62.530    Top5: 88.140    Loss: 1.425

2024-02-19 17:33:32,391 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:33:32,392 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:33:32,497 - 

2024-02-19 17:33:32,497 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:33:42,519 - Epoch: [128][  100/  391]    Overall Loss 0.533142    Objective Loss 0.533142                                        LR 0.023500    Time 0.100145    
2024-02-19 17:33:51,826 - Epoch: [128][  200/  391]    Overall Loss 0.540543    Objective Loss 0.540543                                        LR 0.023500    Time 0.096582    
2024-02-19 17:34:01,081 - Epoch: [128][  300/  391]    Overall Loss 0.556833    Objective Loss 0.556833                                        LR 0.023500    Time 0.095225    
2024-02-19 17:34:09,527 - Epoch: [128][  391/  391]    Overall Loss 0.567360    Objective Loss 0.567360    Top1 82.692308    Top5 98.076923    LR 0.023500    Time 0.094653    
2024-02-19 17:34:09,700 - --- validate (epoch=128)-----------
2024-02-19 17:34:09,701 - 10000 samples (128 per mini-batch)
2024-02-19 17:34:12,680 - Epoch: [128][   79/   79]    Loss 1.352653    Top1 63.800000    Top5 88.890000    
2024-02-19 17:34:12,827 - ==> Top1: 63.800    Top5: 88.890    Loss: 1.353

2024-02-19 17:34:12,848 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:34:12,849 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:34:12,927 - 

2024-02-19 17:34:12,927 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:34:22,717 - Epoch: [129][  100/  391]    Overall Loss 0.539323    Objective Loss 0.539323                                        LR 0.023500    Time 0.097826    
2024-02-19 17:34:31,241 - Epoch: [129][  200/  391]    Overall Loss 0.541701    Objective Loss 0.541701                                        LR 0.023500    Time 0.091514    
2024-02-19 17:34:40,438 - Epoch: [129][  300/  391]    Overall Loss 0.555666    Objective Loss 0.555666                                        LR 0.023500    Time 0.091649    
2024-02-19 17:34:48,760 - Epoch: [129][  391/  391]    Overall Loss 0.559215    Objective Loss 0.559215    Top1 81.250000    Top5 98.076923    LR 0.023500    Time 0.091592    
2024-02-19 17:34:48,925 - --- validate (epoch=129)-----------
2024-02-19 17:34:48,926 - 10000 samples (128 per mini-batch)
2024-02-19 17:34:51,539 - Epoch: [129][   79/   79]    Loss 1.362347    Top1 64.070000    Top5 89.020000    
2024-02-19 17:34:51,684 - ==> Top1: 64.070    Top5: 89.020    Loss: 1.362

2024-02-19 17:34:51,701 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:34:51,701 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:34:51,774 - 

2024-02-19 17:34:51,774 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:35:01,794 - Epoch: [130][  100/  391]    Overall Loss 0.514602    Objective Loss 0.514602                                        LR 0.023500    Time 0.100123    
2024-02-19 17:35:11,082 - Epoch: [130][  200/  391]    Overall Loss 0.527521    Objective Loss 0.527521                                        LR 0.023500    Time 0.096476    
2024-02-19 17:35:20,302 - Epoch: [130][  300/  391]    Overall Loss 0.536228    Objective Loss 0.536228                                        LR 0.023500    Time 0.095036    
2024-02-19 17:35:28,621 - Epoch: [130][  391/  391]    Overall Loss 0.550193    Objective Loss 0.550193    Top1 82.692308    Top5 97.596154    LR 0.023500    Time 0.094184    
2024-02-19 17:35:28,829 - --- validate (epoch=130)-----------
2024-02-19 17:35:28,830 - 10000 samples (128 per mini-batch)
2024-02-19 17:35:31,535 - Epoch: [130][   79/   79]    Loss 1.338975    Top1 64.160000    Top5 88.900000    
2024-02-19 17:35:31,672 - ==> Top1: 64.160    Top5: 88.900    Loss: 1.339

2024-02-19 17:35:31,690 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:35:31,691 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:35:31,770 - 

2024-02-19 17:35:31,770 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:35:41,652 - Epoch: [131][  100/  391]    Overall Loss 0.534401    Objective Loss 0.534401                                        LR 0.023500    Time 0.098739    
2024-02-19 17:35:51,045 - Epoch: [131][  200/  391]    Overall Loss 0.541284    Objective Loss 0.541284                                        LR 0.023500    Time 0.096311    
2024-02-19 17:36:00,387 - Epoch: [131][  300/  391]    Overall Loss 0.550552    Objective Loss 0.550552                                        LR 0.023500    Time 0.095333    
2024-02-19 17:36:08,839 - Epoch: [131][  391/  391]    Overall Loss 0.556768    Objective Loss 0.556768    Top1 79.807692    Top5 98.076923    LR 0.023500    Time 0.094750    
2024-02-19 17:36:08,989 - --- validate (epoch=131)-----------
2024-02-19 17:36:08,991 - 10000 samples (128 per mini-batch)
2024-02-19 17:36:11,685 - Epoch: [131][   79/   79]    Loss 1.422520    Top1 62.650000    Top5 88.430000    
2024-02-19 17:36:11,826 - ==> Top1: 62.650    Top5: 88.430    Loss: 1.423

2024-02-19 17:36:11,842 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:36:11,842 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:36:11,920 - 

2024-02-19 17:36:11,921 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:36:22,120 - Epoch: [132][  100/  391]    Overall Loss 0.524812    Objective Loss 0.524812                                        LR 0.023500    Time 0.101877    
2024-02-19 17:36:31,487 - Epoch: [132][  200/  391]    Overall Loss 0.534590    Objective Loss 0.534590                                        LR 0.023500    Time 0.097752    
2024-02-19 17:36:40,892 - Epoch: [132][  300/  391]    Overall Loss 0.547905    Objective Loss 0.547905                                        LR 0.023500    Time 0.096501    
2024-02-19 17:36:49,402 - Epoch: [132][  391/  391]    Overall Loss 0.561220    Objective Loss 0.561220    Top1 83.173077    Top5 98.076923    LR 0.023500    Time 0.095798    
2024-02-19 17:36:49,618 - --- validate (epoch=132)-----------
2024-02-19 17:36:49,619 - 10000 samples (128 per mini-batch)
2024-02-19 17:36:52,323 - Epoch: [132][   79/   79]    Loss 1.339014    Top1 64.200000    Top5 89.530000    
2024-02-19 17:36:52,459 - ==> Top1: 64.200    Top5: 89.530    Loss: 1.339

2024-02-19 17:36:52,478 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:36:52,478 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:36:52,559 - 

2024-02-19 17:36:52,559 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:37:02,207 - Epoch: [133][  100/  391]    Overall Loss 0.513847    Objective Loss 0.513847                                        LR 0.023500    Time 0.096392    
2024-02-19 17:37:11,280 - Epoch: [133][  200/  391]    Overall Loss 0.534833    Objective Loss 0.534833                                        LR 0.023500    Time 0.093539    
2024-02-19 17:37:20,518 - Epoch: [133][  300/  391]    Overall Loss 0.545445    Objective Loss 0.545445                                        LR 0.023500    Time 0.093137    
2024-02-19 17:37:28,874 - Epoch: [133][  391/  391]    Overall Loss 0.557363    Objective Loss 0.557363    Top1 85.096154    Top5 98.557692    LR 0.023500    Time 0.092821    
2024-02-19 17:37:29,082 - --- validate (epoch=133)-----------
2024-02-19 17:37:29,083 - 10000 samples (128 per mini-batch)
2024-02-19 17:37:31,727 - Epoch: [133][   79/   79]    Loss 1.387939    Top1 63.200000    Top5 88.800000    
2024-02-19 17:37:31,895 - ==> Top1: 63.200    Top5: 88.800    Loss: 1.388

2024-02-19 17:37:31,914 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:37:31,914 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:37:31,989 - 

2024-02-19 17:37:31,990 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:37:42,209 - Epoch: [134][  100/  391]    Overall Loss 0.520899    Objective Loss 0.520899                                        LR 0.023500    Time 0.102116    
2024-02-19 17:37:51,537 - Epoch: [134][  200/  391]    Overall Loss 0.534835    Objective Loss 0.534835                                        LR 0.023500    Time 0.097677    
2024-02-19 17:38:00,844 - Epoch: [134][  300/  391]    Overall Loss 0.546189    Objective Loss 0.546189                                        LR 0.023500    Time 0.096124    
2024-02-19 17:38:09,271 - Epoch: [134][  391/  391]    Overall Loss 0.559324    Objective Loss 0.559324    Top1 75.480769    Top5 97.596154    LR 0.023500    Time 0.095296    
2024-02-19 17:38:09,506 - --- validate (epoch=134)-----------
2024-02-19 17:38:09,507 - 10000 samples (128 per mini-batch)
2024-02-19 17:38:12,305 - Epoch: [134][   79/   79]    Loss 1.345968    Top1 64.770000    Top5 88.710000    
2024-02-19 17:38:12,501 - ==> Top1: 64.770    Top5: 88.710    Loss: 1.346

2024-02-19 17:38:12,519 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:38:12,519 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:38:12,592 - 

2024-02-19 17:38:12,592 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:38:22,196 - Epoch: [135][  100/  391]    Overall Loss 0.523758    Objective Loss 0.523758                                        LR 0.023500    Time 0.095965    
2024-02-19 17:38:31,242 - Epoch: [135][  200/  391]    Overall Loss 0.531264    Objective Loss 0.531264                                        LR 0.023500    Time 0.093188    
2024-02-19 17:38:40,439 - Epoch: [135][  300/  391]    Overall Loss 0.546272    Objective Loss 0.546272                                        LR 0.023500    Time 0.092766    
2024-02-19 17:38:48,876 - Epoch: [135][  391/  391]    Overall Loss 0.555146    Objective Loss 0.555146    Top1 81.730769    Top5 98.076923    LR 0.023500    Time 0.092745    
2024-02-19 17:38:49,054 - --- validate (epoch=135)-----------
2024-02-19 17:38:49,055 - 10000 samples (128 per mini-batch)
2024-02-19 17:38:51,742 - Epoch: [135][   79/   79]    Loss 1.408276    Top1 62.730000    Top5 88.480000    
2024-02-19 17:38:51,874 - ==> Top1: 62.730    Top5: 88.480    Loss: 1.408

2024-02-19 17:38:51,884 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:38:51,884 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:38:51,957 - 

2024-02-19 17:38:51,958 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:39:02,214 - Epoch: [136][  100/  391]    Overall Loss 0.515902    Objective Loss 0.515902                                        LR 0.023500    Time 0.102486    
2024-02-19 17:39:11,595 - Epoch: [136][  200/  391]    Overall Loss 0.523318    Objective Loss 0.523318                                        LR 0.023500    Time 0.098126    
2024-02-19 17:39:20,624 - Epoch: [136][  300/  391]    Overall Loss 0.537852    Objective Loss 0.537852                                        LR 0.023500    Time 0.095498    
2024-02-19 17:39:28,909 - Epoch: [136][  391/  391]    Overall Loss 0.549399    Objective Loss 0.549399    Top1 79.326923    Top5 98.076923    LR 0.023500    Time 0.094453    
2024-02-19 17:39:29,159 - --- validate (epoch=136)-----------
2024-02-19 17:39:29,159 - 10000 samples (128 per mini-batch)
2024-02-19 17:39:31,811 - Epoch: [136][   79/   79]    Loss 1.336822    Top1 63.610000    Top5 89.170000    
2024-02-19 17:39:31,965 - ==> Top1: 63.610    Top5: 89.170    Loss: 1.337

2024-02-19 17:39:31,981 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:39:31,981 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:39:32,055 - 

2024-02-19 17:39:32,055 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:39:40,581 - Epoch: [137][  100/  391]    Overall Loss 0.522268    Objective Loss 0.522268                                        LR 0.023500    Time 0.085189    
2024-02-19 17:39:47,535 - Epoch: [137][  200/  391]    Overall Loss 0.522617    Objective Loss 0.522617                                        LR 0.023500    Time 0.077348    
2024-02-19 17:39:54,498 - Epoch: [137][  300/  391]    Overall Loss 0.533800    Objective Loss 0.533800                                        LR 0.023500    Time 0.074764    
2024-02-19 17:40:00,844 - Epoch: [137][  391/  391]    Overall Loss 0.544992    Objective Loss 0.544992    Top1 81.250000    Top5 98.076923    LR 0.023500    Time 0.073585    
2024-02-19 17:40:01,023 - --- validate (epoch=137)-----------
2024-02-19 17:40:01,024 - 10000 samples (128 per mini-batch)
2024-02-19 17:40:03,643 - Epoch: [137][   79/   79]    Loss 1.417838    Top1 62.180000    Top5 88.250000    
2024-02-19 17:40:03,869 - ==> Top1: 62.180    Top5: 88.250    Loss: 1.418

2024-02-19 17:40:03,888 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:40:03,888 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:40:03,961 - 

2024-02-19 17:40:03,962 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:40:13,707 - Epoch: [138][  100/  391]    Overall Loss 0.518913    Objective Loss 0.518913                                        LR 0.023500    Time 0.097381    
2024-02-19 17:40:23,004 - Epoch: [138][  200/  391]    Overall Loss 0.531409    Objective Loss 0.531409                                        LR 0.023500    Time 0.095152    
2024-02-19 17:40:32,358 - Epoch: [138][  300/  391]    Overall Loss 0.538835    Objective Loss 0.538835                                        LR 0.023500    Time 0.094602    
2024-02-19 17:40:40,971 - Epoch: [138][  391/  391]    Overall Loss 0.549000    Objective Loss 0.549000    Top1 77.884615    Top5 96.153846    LR 0.023500    Time 0.094600    
2024-02-19 17:40:41,219 - --- validate (epoch=138)-----------
2024-02-19 17:40:41,220 - 10000 samples (128 per mini-batch)
2024-02-19 17:40:43,960 - Epoch: [138][   79/   79]    Loss 1.504057    Top1 61.290000    Top5 87.450000    
2024-02-19 17:40:44,111 - ==> Top1: 61.290    Top5: 87.450    Loss: 1.504

2024-02-19 17:40:44,131 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:40:44,131 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:40:44,214 - 

2024-02-19 17:40:44,214 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:40:53,504 - Epoch: [139][  100/  391]    Overall Loss 0.522495    Objective Loss 0.522495                                        LR 0.023500    Time 0.092832    
2024-02-19 17:41:02,786 - Epoch: [139][  200/  391]    Overall Loss 0.530554    Objective Loss 0.530554                                        LR 0.023500    Time 0.092800    
2024-02-19 17:41:12,087 - Epoch: [139][  300/  391]    Overall Loss 0.539933    Objective Loss 0.539933                                        LR 0.023500    Time 0.092856    
2024-02-19 17:41:20,354 - Epoch: [139][  391/  391]    Overall Loss 0.545849    Objective Loss 0.545849    Top1 79.326923    Top5 98.076923    LR 0.023500    Time 0.092379    
2024-02-19 17:41:20,504 - --- validate (epoch=139)-----------
2024-02-19 17:41:20,506 - 10000 samples (128 per mini-batch)
2024-02-19 17:41:23,090 - Epoch: [139][   79/   79]    Loss 1.368089    Top1 63.390000    Top5 88.880000    
2024-02-19 17:41:23,308 - ==> Top1: 63.390    Top5: 88.880    Loss: 1.368

2024-02-19 17:41:23,324 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:41:23,324 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:41:23,402 - 

2024-02-19 17:41:23,402 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:41:33,119 - Epoch: [140][  100/  391]    Overall Loss 0.506662    Objective Loss 0.506662                                        LR 0.023500    Time 0.097103    
2024-02-19 17:41:42,449 - Epoch: [140][  200/  391]    Overall Loss 0.516688    Objective Loss 0.516688                                        LR 0.023500    Time 0.095175    
2024-02-19 17:41:51,811 - Epoch: [140][  300/  391]    Overall Loss 0.526371    Objective Loss 0.526371                                        LR 0.023500    Time 0.094640    
2024-02-19 17:42:00,207 - Epoch: [140][  391/  391]    Overall Loss 0.537069    Objective Loss 0.537069    Top1 80.288462    Top5 98.557692    LR 0.023500    Time 0.094078    
2024-02-19 17:42:00,385 - --- validate (epoch=140)-----------
2024-02-19 17:42:00,386 - 10000 samples (128 per mini-batch)
2024-02-19 17:42:03,169 - Epoch: [140][   79/   79]    Loss 1.344355    Top1 63.930000    Top5 89.210000    
2024-02-19 17:42:03,380 - ==> Top1: 63.930    Top5: 89.210    Loss: 1.344

2024-02-19 17:42:03,399 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:42:03,399 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:42:03,474 - 

2024-02-19 17:42:03,474 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:42:12,979 - Epoch: [141][  100/  391]    Overall Loss 0.500247    Objective Loss 0.500247                                        LR 0.023500    Time 0.094976    
2024-02-19 17:42:22,355 - Epoch: [141][  200/  391]    Overall Loss 0.519171    Objective Loss 0.519171                                        LR 0.023500    Time 0.094345    
2024-02-19 17:42:31,646 - Epoch: [141][  300/  391]    Overall Loss 0.528672    Objective Loss 0.528672                                        LR 0.023500    Time 0.093852    
2024-02-19 17:42:40,161 - Epoch: [141][  391/  391]    Overall Loss 0.538246    Objective Loss 0.538246    Top1 81.250000    Top5 98.076923    LR 0.023500    Time 0.093776    
2024-02-19 17:42:40,399 - --- validate (epoch=141)-----------
2024-02-19 17:42:40,400 - 10000 samples (128 per mini-batch)
2024-02-19 17:42:42,942 - Epoch: [141][   79/   79]    Loss 1.428072    Top1 63.040000    Top5 88.220000    
2024-02-19 17:42:43,082 - ==> Top1: 63.040    Top5: 88.220    Loss: 1.428

2024-02-19 17:42:43,099 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:42:43,100 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:42:43,174 - 

2024-02-19 17:42:43,174 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:42:52,601 - Epoch: [142][  100/  391]    Overall Loss 0.508290    Objective Loss 0.508290                                        LR 0.023500    Time 0.094193    
2024-02-19 17:43:01,791 - Epoch: [142][  200/  391]    Overall Loss 0.517290    Objective Loss 0.517290                                        LR 0.023500    Time 0.093024    
2024-02-19 17:43:11,137 - Epoch: [142][  300/  391]    Overall Loss 0.529299    Objective Loss 0.529299                                        LR 0.023500    Time 0.093157    
2024-02-19 17:43:19,646 - Epoch: [142][  391/  391]    Overall Loss 0.539657    Objective Loss 0.539657    Top1 88.942308    Top5 99.038462    LR 0.023500    Time 0.093226    
2024-02-19 17:43:19,858 - --- validate (epoch=142)-----------
2024-02-19 17:43:19,859 - 10000 samples (128 per mini-batch)
2024-02-19 17:43:22,471 - Epoch: [142][   79/   79]    Loss 1.381608    Top1 63.870000    Top5 88.800000    
2024-02-19 17:43:22,668 - ==> Top1: 63.870    Top5: 88.800    Loss: 1.382

2024-02-19 17:43:22,687 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:43:22,687 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:43:22,761 - 

2024-02-19 17:43:22,762 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:43:32,606 - Epoch: [143][  100/  391]    Overall Loss 0.506073    Objective Loss 0.506073                                        LR 0.023500    Time 0.098373    
2024-02-19 17:43:41,792 - Epoch: [143][  200/  391]    Overall Loss 0.516722    Objective Loss 0.516722                                        LR 0.023500    Time 0.095090    
2024-02-19 17:43:51,005 - Epoch: [143][  300/  391]    Overall Loss 0.524782    Objective Loss 0.524782                                        LR 0.023500    Time 0.094091    
2024-02-19 17:43:59,476 - Epoch: [143][  391/  391]    Overall Loss 0.535591    Objective Loss 0.535591    Top1 79.326923    Top5 99.038462    LR 0.023500    Time 0.093846    
2024-02-19 17:43:59,666 - --- validate (epoch=143)-----------
2024-02-19 17:43:59,667 - 10000 samples (128 per mini-batch)
2024-02-19 17:44:02,381 - Epoch: [143][   79/   79]    Loss 1.403229    Top1 62.710000    Top5 88.530000    
2024-02-19 17:44:02,575 - ==> Top1: 62.710    Top5: 88.530    Loss: 1.403

2024-02-19 17:44:02,593 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:44:02,594 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:44:02,668 - 

2024-02-19 17:44:02,668 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:44:12,908 - Epoch: [144][  100/  391]    Overall Loss 0.511261    Objective Loss 0.511261                                        LR 0.023500    Time 0.102324    
2024-02-19 17:44:22,168 - Epoch: [144][  200/  391]    Overall Loss 0.515480    Objective Loss 0.515480                                        LR 0.023500    Time 0.097438    
2024-02-19 17:44:31,512 - Epoch: [144][  300/  391]    Overall Loss 0.523080    Objective Loss 0.523080                                        LR 0.023500    Time 0.096089    
2024-02-19 17:44:39,961 - Epoch: [144][  391/  391]    Overall Loss 0.534124    Objective Loss 0.534124    Top1 83.653846    Top5 99.519231    LR 0.023500    Time 0.095324    
2024-02-19 17:44:40,261 - --- validate (epoch=144)-----------
2024-02-19 17:44:40,262 - 10000 samples (128 per mini-batch)
2024-02-19 17:44:42,976 - Epoch: [144][   79/   79]    Loss 1.392520    Top1 63.310000    Top5 88.690000    
2024-02-19 17:44:43,152 - ==> Top1: 63.310    Top5: 88.690    Loss: 1.393

2024-02-19 17:44:43,166 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:44:43,167 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:44:43,238 - 

2024-02-19 17:44:43,238 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:44:53,129 - Epoch: [145][  100/  391]    Overall Loss 0.497500    Objective Loss 0.497500                                        LR 0.023500    Time 0.098840    
2024-02-19 17:45:02,524 - Epoch: [145][  200/  391]    Overall Loss 0.509858    Objective Loss 0.509858                                        LR 0.023500    Time 0.096370    
2024-02-19 17:45:11,911 - Epoch: [145][  300/  391]    Overall Loss 0.521146    Objective Loss 0.521146                                        LR 0.023500    Time 0.095520    
2024-02-19 17:45:20,366 - Epoch: [145][  391/  391]    Overall Loss 0.532100    Objective Loss 0.532100    Top1 86.057692    Top5 100.000000    LR 0.023500    Time 0.094904    
2024-02-19 17:45:20,648 - --- validate (epoch=145)-----------
2024-02-19 17:45:20,648 - 10000 samples (128 per mini-batch)
2024-02-19 17:45:23,305 - Epoch: [145][   79/   79]    Loss 1.369270    Top1 63.570000    Top5 88.880000    
2024-02-19 17:45:23,439 - ==> Top1: 63.570    Top5: 88.880    Loss: 1.369

2024-02-19 17:45:23,459 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:45:23,459 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:45:23,534 - 

2024-02-19 17:45:23,534 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:45:33,205 - Epoch: [146][  100/  391]    Overall Loss 0.505544    Objective Loss 0.505544                                        LR 0.023500    Time 0.096639    
2024-02-19 17:45:42,575 - Epoch: [146][  200/  391]    Overall Loss 0.508453    Objective Loss 0.508453                                        LR 0.023500    Time 0.095144    
2024-02-19 17:45:51,953 - Epoch: [146][  300/  391]    Overall Loss 0.518757    Objective Loss 0.518757                                        LR 0.023500    Time 0.094675    
2024-02-19 17:46:00,428 - Epoch: [146][  391/  391]    Overall Loss 0.527722    Objective Loss 0.527722    Top1 78.365385    Top5 95.192308    LR 0.023500    Time 0.094305    
2024-02-19 17:46:00,660 - --- validate (epoch=146)-----------
2024-02-19 17:46:00,660 - 10000 samples (128 per mini-batch)
2024-02-19 17:46:03,678 - Epoch: [146][   79/   79]    Loss 1.445637    Top1 62.150000    Top5 88.240000    
2024-02-19 17:46:03,823 - ==> Top1: 62.150    Top5: 88.240    Loss: 1.446

2024-02-19 17:46:03,840 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:46:03,841 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:46:03,914 - 

2024-02-19 17:46:03,915 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:46:13,795 - Epoch: [147][  100/  391]    Overall Loss 0.515762    Objective Loss 0.515762                                        LR 0.023500    Time 0.098727    
2024-02-19 17:46:23,080 - Epoch: [147][  200/  391]    Overall Loss 0.522330    Objective Loss 0.522330                                        LR 0.023500    Time 0.095766    
2024-02-19 17:46:32,458 - Epoch: [147][  300/  391]    Overall Loss 0.527639    Objective Loss 0.527639                                        LR 0.023500    Time 0.095089    
2024-02-19 17:46:40,916 - Epoch: [147][  391/  391]    Overall Loss 0.533106    Objective Loss 0.533106    Top1 87.500000    Top5 99.038462    LR 0.023500    Time 0.094579    
2024-02-19 17:46:41,111 - --- validate (epoch=147)-----------
2024-02-19 17:46:41,112 - 10000 samples (128 per mini-batch)
2024-02-19 17:46:43,836 - Epoch: [147][   79/   79]    Loss 1.429253    Top1 62.560000    Top5 88.260000    
2024-02-19 17:46:44,006 - ==> Top1: 62.560    Top5: 88.260    Loss: 1.429

2024-02-19 17:46:44,026 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:46:44,026 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:46:44,110 - 

2024-02-19 17:46:44,110 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:46:54,238 - Epoch: [148][  100/  391]    Overall Loss 0.483663    Objective Loss 0.483663                                        LR 0.023500    Time 0.101203    
2024-02-19 17:47:03,603 - Epoch: [148][  200/  391]    Overall Loss 0.503727    Objective Loss 0.503727                                        LR 0.023500    Time 0.097403    
2024-02-19 17:47:12,893 - Epoch: [148][  300/  391]    Overall Loss 0.519878    Objective Loss 0.519878                                        LR 0.023500    Time 0.095887    
2024-02-19 17:47:21,498 - Epoch: [148][  391/  391]    Overall Loss 0.528989    Objective Loss 0.528989    Top1 79.326923    Top5 97.115385    LR 0.023500    Time 0.095568    
2024-02-19 17:47:21,817 - --- validate (epoch=148)-----------
2024-02-19 17:47:21,817 - 10000 samples (128 per mini-batch)
2024-02-19 17:47:24,399 - Epoch: [148][   79/   79]    Loss 1.451930    Top1 62.220000    Top5 88.140000    
2024-02-19 17:47:24,550 - ==> Top1: 62.220    Top5: 88.140    Loss: 1.452

2024-02-19 17:47:24,569 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:47:24,570 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:47:24,645 - 

2024-02-19 17:47:24,646 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:47:34,501 - Epoch: [149][  100/  391]    Overall Loss 0.499607    Objective Loss 0.499607                                        LR 0.023500    Time 0.098478    
2024-02-19 17:47:43,838 - Epoch: [149][  200/  391]    Overall Loss 0.514419    Objective Loss 0.514419                                        LR 0.023500    Time 0.095899    
2024-02-19 17:47:53,208 - Epoch: [149][  300/  391]    Overall Loss 0.520507    Objective Loss 0.520507                                        LR 0.023500    Time 0.095153    
2024-02-19 17:48:01,733 - Epoch: [149][  391/  391]    Overall Loss 0.523791    Objective Loss 0.523791    Top1 77.884615    Top5 96.634615    LR 0.023500    Time 0.094801    
2024-02-19 17:48:01,958 - --- validate (epoch=149)-----------
2024-02-19 17:48:01,959 - 10000 samples (128 per mini-batch)
2024-02-19 17:48:04,555 - Epoch: [149][   79/   79]    Loss 1.443723    Top1 62.570000    Top5 88.140000    
2024-02-19 17:48:04,675 - ==> Top1: 62.570    Top5: 88.140    Loss: 1.444

2024-02-19 17:48:04,694 - ==> Best [Top1: 66.110   Top5: 90.090   Sparsity:0.00   Params: 1341960 on epoch: 110]
2024-02-19 17:48:04,695 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:48:04,770 - 

2024-02-19 17:48:04,770 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:48:14,743 - Epoch: [150][  100/  391]    Overall Loss 0.404760    Objective Loss 0.404760                                        LR 0.005522    Time 0.099660    
2024-02-19 17:48:24,005 - Epoch: [150][  200/  391]    Overall Loss 0.394318    Objective Loss 0.394318                                        LR 0.005522    Time 0.096120    
2024-02-19 17:48:33,320 - Epoch: [150][  300/  391]    Overall Loss 0.381782    Objective Loss 0.381782                                        LR 0.005522    Time 0.095113    
2024-02-19 17:48:41,991 - Epoch: [150][  391/  391]    Overall Loss 0.376352    Objective Loss 0.376352    Top1 91.346154    Top5 99.038462    LR 0.005522    Time 0.095143    
2024-02-19 17:48:42,225 - --- validate (epoch=150)-----------
2024-02-19 17:48:42,227 - 10000 samples (128 per mini-batch)
2024-02-19 17:48:44,823 - Epoch: [150][   79/   79]    Loss 1.232871    Top1 67.010000    Top5 90.670000    
2024-02-19 17:48:45,045 - ==> Top1: 67.010    Top5: 90.670    Loss: 1.233

2024-02-19 17:48:45,063 - ==> Best [Top1: 67.010   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 150]
2024-02-19 17:48:45,063 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:48:45,153 - 

2024-02-19 17:48:45,154 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:48:55,139 - Epoch: [151][  100/  391]    Overall Loss 0.337969    Objective Loss 0.337969                                        LR 0.005522    Time 0.099782    
2024-02-19 17:49:04,528 - Epoch: [151][  200/  391]    Overall Loss 0.335457    Objective Loss 0.335457                                        LR 0.005522    Time 0.096810    
2024-02-19 17:49:13,948 - Epoch: [151][  300/  391]    Overall Loss 0.331588    Objective Loss 0.331588                                        LR 0.005522    Time 0.095925    
2024-02-19 17:49:22,101 - Epoch: [151][  391/  391]    Overall Loss 0.332760    Objective Loss 0.332760    Top1 92.307692    Top5 99.519231    LR 0.005522    Time 0.094441    
2024-02-19 17:49:22,261 - --- validate (epoch=151)-----------
2024-02-19 17:49:22,262 - 10000 samples (128 per mini-batch)
2024-02-19 17:49:24,870 - Epoch: [151][   79/   79]    Loss 1.224059    Top1 67.100000    Top5 90.580000    
2024-02-19 17:49:25,042 - ==> Top1: 67.100    Top5: 90.580    Loss: 1.224

2024-02-19 17:49:25,059 - ==> Best [Top1: 67.100   Top5: 90.580   Sparsity:0.00   Params: 1341960 on epoch: 151]
2024-02-19 17:49:25,059 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:49:25,149 - 

2024-02-19 17:49:25,150 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:49:35,127 - Epoch: [152][  100/  391]    Overall Loss 0.314529    Objective Loss 0.314529                                        LR 0.005522    Time 0.099707    
2024-02-19 17:49:44,592 - Epoch: [152][  200/  391]    Overall Loss 0.308978    Objective Loss 0.308978                                        LR 0.005522    Time 0.097151    
2024-02-19 17:49:53,914 - Epoch: [152][  300/  391]    Overall Loss 0.311261    Objective Loss 0.311261                                        LR 0.005522    Time 0.095830    
2024-02-19 17:50:02,403 - Epoch: [152][  391/  391]    Overall Loss 0.315546    Objective Loss 0.315546    Top1 85.576923    Top5 99.519231    LR 0.005522    Time 0.095226    
2024-02-19 17:50:02,558 - --- validate (epoch=152)-----------
2024-02-19 17:50:02,559 - 10000 samples (128 per mini-batch)
2024-02-19 17:50:05,140 - Epoch: [152][   79/   79]    Loss 1.244324    Top1 67.250000    Top5 90.670000    
2024-02-19 17:50:05,284 - ==> Top1: 67.250    Top5: 90.670    Loss: 1.244

2024-02-19 17:50:05,304 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:50:05,304 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:50:05,393 - 

2024-02-19 17:50:05,393 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:50:15,384 - Epoch: [153][  100/  391]    Overall Loss 0.311488    Objective Loss 0.311488                                        LR 0.005522    Time 0.099833    
2024-02-19 17:50:24,605 - Epoch: [153][  200/  391]    Overall Loss 0.308623    Objective Loss 0.308623                                        LR 0.005522    Time 0.095997    
2024-02-19 17:50:33,958 - Epoch: [153][  300/  391]    Overall Loss 0.307036    Objective Loss 0.307036                                        LR 0.005522    Time 0.095160    
2024-02-19 17:50:42,538 - Epoch: [153][  391/  391]    Overall Loss 0.307062    Objective Loss 0.307062    Top1 88.942308    Top5 100.000000    LR 0.005522    Time 0.094946    
2024-02-19 17:50:42,770 - --- validate (epoch=153)-----------
2024-02-19 17:50:42,771 - 10000 samples (128 per mini-batch)
2024-02-19 17:50:45,423 - Epoch: [153][   79/   79]    Loss 1.239815    Top1 66.950000    Top5 90.360000    
2024-02-19 17:50:45,636 - ==> Top1: 66.950    Top5: 90.360    Loss: 1.240

2024-02-19 17:50:45,648 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:50:45,649 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:50:45,728 - 

2024-02-19 17:50:45,728 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:50:55,925 - Epoch: [154][  100/  391]    Overall Loss 0.287211    Objective Loss 0.287211                                        LR 0.005522    Time 0.101900    
2024-02-19 17:51:05,255 - Epoch: [154][  200/  391]    Overall Loss 0.291827    Objective Loss 0.291827                                        LR 0.005522    Time 0.097576    
2024-02-19 17:51:14,221 - Epoch: [154][  300/  391]    Overall Loss 0.296863    Objective Loss 0.296863                                        LR 0.005522    Time 0.094922    
2024-02-19 17:51:22,649 - Epoch: [154][  391/  391]    Overall Loss 0.298064    Objective Loss 0.298064    Top1 90.865385    Top5 99.038462    LR 0.005522    Time 0.094375    
2024-02-19 17:51:22,827 - --- validate (epoch=154)-----------
2024-02-19 17:51:22,829 - 10000 samples (128 per mini-batch)
2024-02-19 17:51:25,391 - Epoch: [154][   79/   79]    Loss 1.260500    Top1 66.990000    Top5 90.430000    
2024-02-19 17:51:25,521 - ==> Top1: 66.990    Top5: 90.430    Loss: 1.261

2024-02-19 17:51:25,541 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:51:25,541 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:51:25,617 - 

2024-02-19 17:51:25,617 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:51:35,371 - Epoch: [155][  100/  391]    Overall Loss 0.279161    Objective Loss 0.279161                                        LR 0.005522    Time 0.097467    
2024-02-19 17:51:44,743 - Epoch: [155][  200/  391]    Overall Loss 0.287515    Objective Loss 0.287515                                        LR 0.005522    Time 0.095568    
2024-02-19 17:51:53,595 - Epoch: [155][  300/  391]    Overall Loss 0.289487    Objective Loss 0.289487                                        LR 0.005522    Time 0.093203    
2024-02-19 17:52:01,999 - Epoch: [155][  391/  391]    Overall Loss 0.289827    Objective Loss 0.289827    Top1 94.230769    Top5 99.519231    LR 0.005522    Time 0.092994    
2024-02-19 17:52:02,237 - --- validate (epoch=155)-----------
2024-02-19 17:52:02,239 - 10000 samples (128 per mini-batch)
2024-02-19 17:52:04,846 - Epoch: [155][   79/   79]    Loss 1.260405    Top1 66.810000    Top5 90.430000    
2024-02-19 17:52:05,014 - ==> Top1: 66.810    Top5: 90.430    Loss: 1.260

2024-02-19 17:52:05,032 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:52:05,033 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:52:05,107 - 

2024-02-19 17:52:05,107 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:52:14,948 - Epoch: [156][  100/  391]    Overall Loss 0.276131    Objective Loss 0.276131                                        LR 0.005522    Time 0.098339    
2024-02-19 17:52:24,289 - Epoch: [156][  200/  391]    Overall Loss 0.277669    Objective Loss 0.277669                                        LR 0.005522    Time 0.095852    
2024-02-19 17:52:33,456 - Epoch: [156][  300/  391]    Overall Loss 0.281614    Objective Loss 0.281614                                        LR 0.005522    Time 0.094442    
2024-02-19 17:52:42,012 - Epoch: [156][  391/  391]    Overall Loss 0.281630    Objective Loss 0.281630    Top1 91.346154    Top5 99.038462    LR 0.005522    Time 0.094332    
2024-02-19 17:52:42,296 - --- validate (epoch=156)-----------
2024-02-19 17:52:42,296 - 10000 samples (128 per mini-batch)
2024-02-19 17:52:44,931 - Epoch: [156][   79/   79]    Loss 1.252237    Top1 66.960000    Top5 90.480000    
2024-02-19 17:52:45,118 - ==> Top1: 66.960    Top5: 90.480    Loss: 1.252

2024-02-19 17:52:45,137 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:52:45,138 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:52:45,218 - 

2024-02-19 17:52:45,219 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:52:55,379 - Epoch: [157][  100/  391]    Overall Loss 0.266113    Objective Loss 0.266113                                        LR 0.005522    Time 0.101490    
2024-02-19 17:53:04,720 - Epoch: [157][  200/  391]    Overall Loss 0.273138    Objective Loss 0.273138                                        LR 0.005522    Time 0.097427    
2024-02-19 17:53:11,975 - Epoch: [157][  300/  391]    Overall Loss 0.277272    Objective Loss 0.277272                                        LR 0.005522    Time 0.089122    
2024-02-19 17:53:18,233 - Epoch: [157][  391/  391]    Overall Loss 0.279318    Objective Loss 0.279318    Top1 91.826923    Top5 99.038462    LR 0.005522    Time 0.084378    
2024-02-19 17:53:18,529 - --- validate (epoch=157)-----------
2024-02-19 17:53:18,529 - 10000 samples (128 per mini-batch)
2024-02-19 17:53:21,066 - Epoch: [157][   79/   79]    Loss 1.282982    Top1 66.430000    Top5 90.060000    
2024-02-19 17:53:21,194 - ==> Top1: 66.430    Top5: 90.060    Loss: 1.283

2024-02-19 17:53:21,214 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:53:21,214 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:53:21,288 - 

2024-02-19 17:53:21,289 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:53:31,044 - Epoch: [158][  100/  391]    Overall Loss 0.258010    Objective Loss 0.258010                                        LR 0.005522    Time 0.097483    
2024-02-19 17:53:40,051 - Epoch: [158][  200/  391]    Overall Loss 0.270554    Objective Loss 0.270554                                        LR 0.005522    Time 0.093753    
2024-02-19 17:53:49,014 - Epoch: [158][  300/  391]    Overall Loss 0.270927    Objective Loss 0.270927                                        LR 0.005522    Time 0.092366    
2024-02-19 17:53:57,481 - Epoch: [158][  391/  391]    Overall Loss 0.271884    Objective Loss 0.271884    Top1 91.826923    Top5 98.557692    LR 0.005522    Time 0.092513    
2024-02-19 17:53:57,705 - --- validate (epoch=158)-----------
2024-02-19 17:53:57,706 - 10000 samples (128 per mini-batch)
2024-02-19 17:54:00,188 - Epoch: [158][   79/   79]    Loss 1.297263    Top1 66.580000    Top5 90.440000    
2024-02-19 17:54:00,372 - ==> Top1: 66.580    Top5: 90.440    Loss: 1.297

2024-02-19 17:54:00,389 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:54:00,390 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:54:00,463 - 

2024-02-19 17:54:00,464 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:54:10,012 - Epoch: [159][  100/  391]    Overall Loss 0.262810    Objective Loss 0.262810                                        LR 0.005522    Time 0.095417    
2024-02-19 17:54:19,112 - Epoch: [159][  200/  391]    Overall Loss 0.264519    Objective Loss 0.264519                                        LR 0.005522    Time 0.093185    
2024-02-19 17:54:28,290 - Epoch: [159][  300/  391]    Overall Loss 0.265082    Objective Loss 0.265082                                        LR 0.005522    Time 0.092702    
2024-02-19 17:54:36,641 - Epoch: [159][  391/  391]    Overall Loss 0.266618    Objective Loss 0.266618    Top1 89.423077    Top5 98.076923    LR 0.005522    Time 0.092474    
2024-02-19 17:54:36,873 - --- validate (epoch=159)-----------
2024-02-19 17:54:36,875 - 10000 samples (128 per mini-batch)
2024-02-19 17:54:39,430 - Epoch: [159][   79/   79]    Loss 1.277716    Top1 66.960000    Top5 90.310000    
2024-02-19 17:54:39,647 - ==> Top1: 66.960    Top5: 90.310    Loss: 1.278

2024-02-19 17:54:39,667 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:54:39,667 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:54:39,744 - 

2024-02-19 17:54:39,744 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:54:49,837 - Epoch: [160][  100/  391]    Overall Loss 0.251683    Objective Loss 0.251683                                        LR 0.005522    Time 0.100852    
2024-02-19 17:54:58,983 - Epoch: [160][  200/  391]    Overall Loss 0.258876    Objective Loss 0.258876                                        LR 0.005522    Time 0.096137    
2024-02-19 17:55:07,849 - Epoch: [160][  300/  391]    Overall Loss 0.260912    Objective Loss 0.260912                                        LR 0.005522    Time 0.093629    
2024-02-19 17:55:16,230 - Epoch: [160][  391/  391]    Overall Loss 0.262499    Objective Loss 0.262499    Top1 93.750000    Top5 99.519231    LR 0.005522    Time 0.093261    
2024-02-19 17:55:16,440 - --- validate (epoch=160)-----------
2024-02-19 17:55:16,440 - 10000 samples (128 per mini-batch)
2024-02-19 17:55:18,988 - Epoch: [160][   79/   79]    Loss 1.284113    Top1 66.650000    Top5 90.270000    
2024-02-19 17:55:19,108 - ==> Top1: 66.650    Top5: 90.270    Loss: 1.284

2024-02-19 17:55:19,118 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:55:19,118 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:55:19,189 - 

2024-02-19 17:55:19,189 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:55:28,838 - Epoch: [161][  100/  391]    Overall Loss 0.247426    Objective Loss 0.247426                                        LR 0.005522    Time 0.096412    
2024-02-19 17:55:38,068 - Epoch: [161][  200/  391]    Overall Loss 0.250927    Objective Loss 0.250927                                        LR 0.005522    Time 0.094334    
2024-02-19 17:55:47,438 - Epoch: [161][  300/  391]    Overall Loss 0.255053    Objective Loss 0.255053                                        LR 0.005522    Time 0.094106    
2024-02-19 17:55:55,952 - Epoch: [161][  391/  391]    Overall Loss 0.256470    Objective Loss 0.256470    Top1 94.711538    Top5 99.519231    LR 0.005522    Time 0.093970    
2024-02-19 17:55:56,152 - --- validate (epoch=161)-----------
2024-02-19 17:55:56,153 - 10000 samples (128 per mini-batch)
2024-02-19 17:55:58,769 - Epoch: [161][   79/   79]    Loss 1.288213    Top1 66.610000    Top5 90.280000    
2024-02-19 17:55:59,063 - ==> Top1: 66.610    Top5: 90.280    Loss: 1.288

2024-02-19 17:55:59,081 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:55:59,081 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:55:59,154 - 

2024-02-19 17:55:59,155 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:56:09,122 - Epoch: [162][  100/  391]    Overall Loss 0.245268    Objective Loss 0.245268                                        LR 0.005522    Time 0.099600    
2024-02-19 17:56:18,507 - Epoch: [162][  200/  391]    Overall Loss 0.249498    Objective Loss 0.249498                                        LR 0.005522    Time 0.096703    
2024-02-19 17:56:27,725 - Epoch: [162][  300/  391]    Overall Loss 0.251475    Objective Loss 0.251475                                        LR 0.005522    Time 0.095179    
2024-02-19 17:56:36,207 - Epoch: [162][  391/  391]    Overall Loss 0.253709    Objective Loss 0.253709    Top1 93.269231    Top5 100.000000    LR 0.005522    Time 0.094710    
2024-02-19 17:56:36,406 - --- validate (epoch=162)-----------
2024-02-19 17:56:36,407 - 10000 samples (128 per mini-batch)
2024-02-19 17:56:39,220 - Epoch: [162][   79/   79]    Loss 1.289234    Top1 66.760000    Top5 90.090000    
2024-02-19 17:56:39,403 - ==> Top1: 66.760    Top5: 90.090    Loss: 1.289

2024-02-19 17:56:39,424 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:56:39,425 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:56:39,507 - 

2024-02-19 17:56:39,508 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:56:49,588 - Epoch: [163][  100/  391]    Overall Loss 0.245569    Objective Loss 0.245569                                        LR 0.005522    Time 0.100719    
2024-02-19 17:56:59,228 - Epoch: [163][  200/  391]    Overall Loss 0.245899    Objective Loss 0.245899                                        LR 0.005522    Time 0.098533    
2024-02-19 17:57:08,983 - Epoch: [163][  300/  391]    Overall Loss 0.248700    Objective Loss 0.248700                                        LR 0.005522    Time 0.098191    
2024-02-19 17:57:17,733 - Epoch: [163][  391/  391]    Overall Loss 0.251160    Objective Loss 0.251160    Top1 93.750000    Top5 99.519231    LR 0.005522    Time 0.097704    
2024-02-19 17:57:17,939 - --- validate (epoch=163)-----------
2024-02-19 17:57:17,940 - 10000 samples (128 per mini-batch)
2024-02-19 17:57:20,728 - Epoch: [163][   79/   79]    Loss 1.309039    Top1 66.980000    Top5 90.130000    
2024-02-19 17:57:20,934 - ==> Top1: 66.980    Top5: 90.130    Loss: 1.309

2024-02-19 17:57:20,952 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:57:20,953 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:57:21,027 - 

2024-02-19 17:57:21,027 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:57:31,084 - Epoch: [164][  100/  391]    Overall Loss 0.241939    Objective Loss 0.241939                                        LR 0.005522    Time 0.100496    
2024-02-19 17:57:40,681 - Epoch: [164][  200/  391]    Overall Loss 0.245077    Objective Loss 0.245077                                        LR 0.005522    Time 0.098211    
2024-02-19 17:57:50,343 - Epoch: [164][  300/  391]    Overall Loss 0.247411    Objective Loss 0.247411                                        LR 0.005522    Time 0.097664    
2024-02-19 17:57:59,105 - Epoch: [164][  391/  391]    Overall Loss 0.249987    Objective Loss 0.249987    Top1 96.153846    Top5 100.000000    LR 0.005522    Time 0.097334    
2024-02-19 17:57:59,320 - --- validate (epoch=164)-----------
2024-02-19 17:57:59,321 - 10000 samples (128 per mini-batch)
2024-02-19 17:58:02,120 - Epoch: [164][   79/   79]    Loss 1.300506    Top1 66.680000    Top5 90.150000    
2024-02-19 17:58:02,367 - ==> Top1: 66.680    Top5: 90.150    Loss: 1.301

2024-02-19 17:58:02,377 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:58:02,377 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:58:02,449 - 

2024-02-19 17:58:02,450 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:58:12,854 - Epoch: [165][  100/  391]    Overall Loss 0.230396    Objective Loss 0.230396                                        LR 0.005522    Time 0.103970    
2024-02-19 17:58:22,247 - Epoch: [165][  200/  391]    Overall Loss 0.239541    Objective Loss 0.239541                                        LR 0.005522    Time 0.098924    
2024-02-19 17:58:31,919 - Epoch: [165][  300/  391]    Overall Loss 0.242799    Objective Loss 0.242799                                        LR 0.005522    Time 0.098177    
2024-02-19 17:58:40,771 - Epoch: [165][  391/  391]    Overall Loss 0.244418    Objective Loss 0.244418    Top1 90.865385    Top5 99.519231    LR 0.005522    Time 0.097955    
2024-02-19 17:58:40,993 - --- validate (epoch=165)-----------
2024-02-19 17:58:40,994 - 10000 samples (128 per mini-batch)
2024-02-19 17:58:43,717 - Epoch: [165][   79/   79]    Loss 1.300255    Top1 66.990000    Top5 90.210000    
2024-02-19 17:58:43,864 - ==> Top1: 66.990    Top5: 90.210    Loss: 1.300

2024-02-19 17:58:43,883 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:58:43,884 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:58:43,958 - 

2024-02-19 17:58:43,959 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:58:54,251 - Epoch: [166][  100/  391]    Overall Loss 0.239461    Objective Loss 0.239461                                        LR 0.005522    Time 0.102848    
2024-02-19 17:59:03,725 - Epoch: [166][  200/  391]    Overall Loss 0.239250    Objective Loss 0.239250                                        LR 0.005522    Time 0.098773    
2024-02-19 17:59:13,303 - Epoch: [166][  300/  391]    Overall Loss 0.242436    Objective Loss 0.242436                                        LR 0.005522    Time 0.097759    
2024-02-19 17:59:22,058 - Epoch: [166][  391/  391]    Overall Loss 0.242766    Objective Loss 0.242766    Top1 93.750000    Top5 99.519231    LR 0.005522    Time 0.097387    
2024-02-19 17:59:22,285 - --- validate (epoch=166)-----------
2024-02-19 17:59:22,286 - 10000 samples (128 per mini-batch)
2024-02-19 17:59:25,190 - Epoch: [166][   79/   79]    Loss 1.336991    Top1 66.440000    Top5 89.920000    
2024-02-19 17:59:25,411 - ==> Top1: 66.440    Top5: 89.920    Loss: 1.337

2024-02-19 17:59:25,430 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 17:59:25,430 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 17:59:25,505 - 

2024-02-19 17:59:25,506 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 17:59:35,729 - Epoch: [167][  100/  391]    Overall Loss 0.232500    Objective Loss 0.232500                                        LR 0.005522    Time 0.102156    
2024-02-19 17:59:45,346 - Epoch: [167][  200/  391]    Overall Loss 0.234312    Objective Loss 0.234312                                        LR 0.005522    Time 0.099144    
2024-02-19 17:59:55,026 - Epoch: [167][  300/  391]    Overall Loss 0.237491    Objective Loss 0.237491                                        LR 0.005522    Time 0.098346    
2024-02-19 18:00:03,800 - Epoch: [167][  391/  391]    Overall Loss 0.239577    Objective Loss 0.239577    Top1 90.865385    Top5 100.000000    LR 0.005522    Time 0.097887    
2024-02-19 18:00:04,116 - --- validate (epoch=167)-----------
2024-02-19 18:00:04,117 - 10000 samples (128 per mini-batch)
2024-02-19 18:00:06,970 - Epoch: [167][   79/   79]    Loss 1.324298    Top1 66.640000    Top5 90.110000    
2024-02-19 18:00:07,187 - ==> Top1: 66.640    Top5: 90.110    Loss: 1.324

2024-02-19 18:00:07,205 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 18:00:07,206 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:00:07,281 - 

2024-02-19 18:00:07,281 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:00:17,795 - Epoch: [168][  100/  391]    Overall Loss 0.222409    Objective Loss 0.222409                                        LR 0.005522    Time 0.105060    
2024-02-19 18:00:27,518 - Epoch: [168][  200/  391]    Overall Loss 0.229236    Objective Loss 0.229236                                        LR 0.005522    Time 0.101126    
2024-02-19 18:00:37,691 - Epoch: [168][  300/  391]    Overall Loss 0.233375    Objective Loss 0.233375                                        LR 0.005522    Time 0.101313    
2024-02-19 18:00:46,531 - Epoch: [168][  391/  391]    Overall Loss 0.234968    Objective Loss 0.234968    Top1 92.307692    Top5 100.000000    LR 0.005522    Time 0.100330    
2024-02-19 18:00:46,699 - --- validate (epoch=168)-----------
2024-02-19 18:00:46,700 - 10000 samples (128 per mini-batch)
2024-02-19 18:00:49,398 - Epoch: [168][   79/   79]    Loss 1.331299    Top1 66.520000    Top5 90.190000    
2024-02-19 18:00:49,653 - ==> Top1: 66.520    Top5: 90.190    Loss: 1.331

2024-02-19 18:00:49,672 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 18:00:49,672 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:00:49,748 - 

2024-02-19 18:00:49,748 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:00:59,898 - Epoch: [169][  100/  391]    Overall Loss 0.231639    Objective Loss 0.231639                                        LR 0.005522    Time 0.101427    
2024-02-19 18:01:09,459 - Epoch: [169][  200/  391]    Overall Loss 0.231629    Objective Loss 0.231629                                        LR 0.005522    Time 0.098497    
2024-02-19 18:01:18,867 - Epoch: [169][  300/  391]    Overall Loss 0.231205    Objective Loss 0.231205                                        LR 0.005522    Time 0.097007    
2024-02-19 18:01:27,386 - Epoch: [169][  391/  391]    Overall Loss 0.233654    Objective Loss 0.233654    Top1 93.750000    Top5 99.519231    LR 0.005522    Time 0.096209    
2024-02-19 18:01:27,599 - --- validate (epoch=169)-----------
2024-02-19 18:01:27,600 - 10000 samples (128 per mini-batch)
2024-02-19 18:01:30,504 - Epoch: [169][   79/   79]    Loss 1.317482    Top1 66.820000    Top5 90.010000    
2024-02-19 18:01:30,709 - ==> Top1: 66.820    Top5: 90.010    Loss: 1.317

2024-02-19 18:01:30,728 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 18:01:30,728 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:01:30,802 - 

2024-02-19 18:01:30,803 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:01:41,112 - Epoch: [170][  100/  391]    Overall Loss 0.224247    Objective Loss 0.224247                                        LR 0.005522    Time 0.103023    
2024-02-19 18:01:50,682 - Epoch: [170][  200/  391]    Overall Loss 0.227131    Objective Loss 0.227131                                        LR 0.005522    Time 0.099335    
2024-02-19 18:02:00,778 - Epoch: [170][  300/  391]    Overall Loss 0.231135    Objective Loss 0.231135                                        LR 0.005522    Time 0.099861    
2024-02-19 18:02:09,408 - Epoch: [170][  391/  391]    Overall Loss 0.233916    Objective Loss 0.233916    Top1 92.307692    Top5 99.519231    LR 0.005522    Time 0.098681    
2024-02-19 18:02:09,610 - --- validate (epoch=170)-----------
2024-02-19 18:02:09,611 - 10000 samples (128 per mini-batch)
2024-02-19 18:02:12,296 - Epoch: [170][   79/   79]    Loss 1.330065    Top1 66.560000    Top5 90.030000    
2024-02-19 18:02:12,494 - ==> Top1: 66.560    Top5: 90.030    Loss: 1.330

2024-02-19 18:02:12,514 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 18:02:12,514 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:02:12,590 - 

2024-02-19 18:02:12,591 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:02:22,599 - Epoch: [171][  100/  391]    Overall Loss 0.220583    Objective Loss 0.220583                                        LR 0.005522    Time 0.100008    
2024-02-19 18:02:32,102 - Epoch: [171][  200/  391]    Overall Loss 0.222879    Objective Loss 0.222879                                        LR 0.005522    Time 0.097495    
2024-02-19 18:02:41,418 - Epoch: [171][  300/  391]    Overall Loss 0.225976    Objective Loss 0.225976                                        LR 0.005522    Time 0.096035    
2024-02-19 18:02:50,154 - Epoch: [171][  391/  391]    Overall Loss 0.226625    Objective Loss 0.226625    Top1 91.346154    Top5 100.000000    LR 0.005522    Time 0.096016    
2024-02-19 18:02:50,343 - --- validate (epoch=171)-----------
2024-02-19 18:02:50,343 - 10000 samples (128 per mini-batch)
2024-02-19 18:02:53,129 - Epoch: [171][   79/   79]    Loss 1.344760    Top1 66.800000    Top5 89.880000    
2024-02-19 18:02:53,343 - ==> Top1: 66.800    Top5: 89.880    Loss: 1.345

2024-02-19 18:02:53,363 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 18:02:53,364 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:02:53,439 - 

2024-02-19 18:02:53,440 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:03:03,716 - Epoch: [172][  100/  391]    Overall Loss 0.217787    Objective Loss 0.217787                                        LR 0.005522    Time 0.102691    
2024-02-19 18:03:13,302 - Epoch: [172][  200/  391]    Overall Loss 0.222174    Objective Loss 0.222174                                        LR 0.005522    Time 0.099251    
2024-02-19 18:03:22,537 - Epoch: [172][  300/  391]    Overall Loss 0.223789    Objective Loss 0.223789                                        LR 0.005522    Time 0.096937    
2024-02-19 18:03:31,160 - Epoch: [172][  391/  391]    Overall Loss 0.227632    Objective Loss 0.227632    Top1 90.865385    Top5 99.519231    LR 0.005522    Time 0.096418    
2024-02-19 18:03:31,486 - --- validate (epoch=172)-----------
2024-02-19 18:03:31,487 - 10000 samples (128 per mini-batch)
2024-02-19 18:03:34,175 - Epoch: [172][   79/   79]    Loss 1.352497    Top1 66.440000    Top5 89.680000    
2024-02-19 18:03:34,324 - ==> Top1: 66.440    Top5: 89.680    Loss: 1.352

2024-02-19 18:03:34,343 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 18:03:34,343 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:03:34,419 - 

2024-02-19 18:03:34,420 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:03:44,448 - Epoch: [173][  100/  391]    Overall Loss 0.221297    Objective Loss 0.221297                                        LR 0.005522    Time 0.100215    
2024-02-19 18:03:53,952 - Epoch: [173][  200/  391]    Overall Loss 0.223977    Objective Loss 0.223977                                        LR 0.005522    Time 0.097603    
2024-02-19 18:04:03,481 - Epoch: [173][  300/  391]    Overall Loss 0.227418    Objective Loss 0.227418                                        LR 0.005522    Time 0.096818    
2024-02-19 18:04:12,104 - Epoch: [173][  391/  391]    Overall Loss 0.229388    Objective Loss 0.229388    Top1 92.788462    Top5 100.000000    LR 0.005522    Time 0.096329    
2024-02-19 18:04:12,285 - --- validate (epoch=173)-----------
2024-02-19 18:04:12,286 - 10000 samples (128 per mini-batch)
2024-02-19 18:04:14,953 - Epoch: [173][   79/   79]    Loss 1.343826    Top1 66.600000    Top5 89.750000    
2024-02-19 18:04:15,099 - ==> Top1: 66.600    Top5: 89.750    Loss: 1.344

2024-02-19 18:04:15,114 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 18:04:15,115 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:04:15,189 - 

2024-02-19 18:04:15,189 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:04:26,235 - Epoch: [174][  100/  391]    Overall Loss 0.217410    Objective Loss 0.217410                                        LR 0.005522    Time 0.110376    
2024-02-19 18:04:35,803 - Epoch: [174][  200/  391]    Overall Loss 0.221184    Objective Loss 0.221184                                        LR 0.005522    Time 0.102999    
2024-02-19 18:04:45,401 - Epoch: [174][  300/  391]    Overall Loss 0.221912    Objective Loss 0.221912                                        LR 0.005522    Time 0.100643    
2024-02-19 18:04:54,042 - Epoch: [174][  391/  391]    Overall Loss 0.225677    Objective Loss 0.225677    Top1 90.865385    Top5 100.000000    LR 0.005522    Time 0.099310    
2024-02-19 18:04:54,198 - --- validate (epoch=174)-----------
2024-02-19 18:04:54,199 - 10000 samples (128 per mini-batch)
2024-02-19 18:04:56,895 - Epoch: [174][   79/   79]    Loss 1.349080    Top1 66.700000    Top5 90.000000    
2024-02-19 18:04:57,162 - ==> Top1: 66.700    Top5: 90.000    Loss: 1.349

2024-02-19 18:04:57,182 - ==> Best [Top1: 67.250   Top5: 90.670   Sparsity:0.00   Params: 1341960 on epoch: 152]
2024-02-19 18:04:57,182 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:04:57,267 - 

2024-02-19 18:04:57,267 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:05:07,313 - Epoch: [175][  100/  391]    Overall Loss 0.200720    Objective Loss 0.200720                                        LR 0.001298    Time 0.100384    
2024-02-19 18:05:16,619 - Epoch: [175][  200/  391]    Overall Loss 0.199762    Objective Loss 0.199762                                        LR 0.001298    Time 0.096701    
2024-02-19 18:05:26,089 - Epoch: [175][  300/  391]    Overall Loss 0.198328    Objective Loss 0.198328                                        LR 0.001298    Time 0.096017    
2024-02-19 18:05:34,617 - Epoch: [175][  391/  391]    Overall Loss 0.198144    Objective Loss 0.198144    Top1 94.711538    Top5 100.000000    LR 0.001298    Time 0.095472    
2024-02-19 18:05:34,829 - --- validate (epoch=175)-----------
2024-02-19 18:05:34,830 - 10000 samples (128 per mini-batch)
2024-02-19 18:05:37,494 - Epoch: [175][   79/   79]    Loss 1.320566    Top1 67.480000    Top5 90.300000    
2024-02-19 18:05:37,776 - ==> Top1: 67.480    Top5: 90.300    Loss: 1.321

2024-02-19 18:05:37,796 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:05:37,796 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:05:37,887 - 

2024-02-19 18:05:37,888 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:05:47,942 - Epoch: [176][  100/  391]    Overall Loss 0.194081    Objective Loss 0.194081                                        LR 0.001298    Time 0.100469    
2024-02-19 18:05:57,498 - Epoch: [176][  200/  391]    Overall Loss 0.188834    Objective Loss 0.188834                                        LR 0.001298    Time 0.097992    
2024-02-19 18:06:07,064 - Epoch: [176][  300/  391]    Overall Loss 0.189702    Objective Loss 0.189702                                        LR 0.001298    Time 0.097200    
2024-02-19 18:06:15,658 - Epoch: [176][  391/  391]    Overall Loss 0.191612    Objective Loss 0.191612    Top1 92.307692    Top5 100.000000    LR 0.001298    Time 0.096546    
2024-02-19 18:06:15,902 - --- validate (epoch=176)-----------
2024-02-19 18:06:15,903 - 10000 samples (128 per mini-batch)
2024-02-19 18:06:19,005 - Epoch: [176][   79/   79]    Loss 1.327038    Top1 67.030000    Top5 89.960000    
2024-02-19 18:06:19,257 - ==> Top1: 67.030    Top5: 89.960    Loss: 1.327

2024-02-19 18:06:19,267 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:06:19,268 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:06:19,344 - 

2024-02-19 18:06:19,344 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:06:29,433 - Epoch: [177][  100/  391]    Overall Loss 0.177925    Objective Loss 0.177925                                        LR 0.001298    Time 0.100818    
2024-02-19 18:06:38,773 - Epoch: [177][  200/  391]    Overall Loss 0.182974    Objective Loss 0.182974                                        LR 0.001298    Time 0.097088    
2024-02-19 18:06:48,334 - Epoch: [177][  300/  391]    Overall Loss 0.182750    Objective Loss 0.182750                                        LR 0.001298    Time 0.096580    
2024-02-19 18:06:57,081 - Epoch: [177][  391/  391]    Overall Loss 0.184228    Objective Loss 0.184228    Top1 93.750000    Top5 100.000000    LR 0.001298    Time 0.096463    
2024-02-19 18:06:57,285 - --- validate (epoch=177)-----------
2024-02-19 18:06:57,286 - 10000 samples (128 per mini-batch)
2024-02-19 18:07:00,074 - Epoch: [177][   79/   79]    Loss 1.328166    Top1 67.210000    Top5 90.120000    
2024-02-19 18:07:00,257 - ==> Top1: 67.210    Top5: 90.120    Loss: 1.328

2024-02-19 18:07:00,277 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:07:00,278 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:07:00,353 - 

2024-02-19 18:07:00,354 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:07:10,669 - Epoch: [178][  100/  391]    Overall Loss 0.176956    Objective Loss 0.176956                                        LR 0.001298    Time 0.103080    
2024-02-19 18:07:20,202 - Epoch: [178][  200/  391]    Overall Loss 0.180543    Objective Loss 0.180543                                        LR 0.001298    Time 0.099182    
2024-02-19 18:07:29,604 - Epoch: [178][  300/  391]    Overall Loss 0.182040    Objective Loss 0.182040                                        LR 0.001298    Time 0.097449    
2024-02-19 18:07:38,143 - Epoch: [178][  391/  391]    Overall Loss 0.182313    Objective Loss 0.182313    Top1 95.192308    Top5 100.000000    LR 0.001298    Time 0.096595    
2024-02-19 18:07:38,347 - --- validate (epoch=178)-----------
2024-02-19 18:07:38,348 - 10000 samples (128 per mini-batch)
2024-02-19 18:07:41,035 - Epoch: [178][   79/   79]    Loss 1.330774    Top1 66.990000    Top5 90.280000    
2024-02-19 18:07:41,178 - ==> Top1: 66.990    Top5: 90.280    Loss: 1.331

2024-02-19 18:07:41,197 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:07:41,197 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:07:41,272 - 

2024-02-19 18:07:41,273 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:07:51,318 - Epoch: [179][  100/  391]    Overall Loss 0.183629    Objective Loss 0.183629                                        LR 0.001298    Time 0.100383    
2024-02-19 18:08:00,708 - Epoch: [179][  200/  391]    Overall Loss 0.180428    Objective Loss 0.180428                                        LR 0.001298    Time 0.097119    
2024-02-19 18:08:10,944 - Epoch: [179][  300/  391]    Overall Loss 0.180396    Objective Loss 0.180396                                        LR 0.001298    Time 0.098850    
2024-02-19 18:08:19,466 - Epoch: [179][  391/  391]    Overall Loss 0.180150    Objective Loss 0.180150    Top1 95.673077    Top5 100.000000    LR 0.001298    Time 0.097629    
2024-02-19 18:08:19,694 - --- validate (epoch=179)-----------
2024-02-19 18:08:19,695 - 10000 samples (128 per mini-batch)
2024-02-19 18:08:22,395 - Epoch: [179][   79/   79]    Loss 1.327668    Top1 67.260000    Top5 90.160000    
2024-02-19 18:08:22,692 - ==> Top1: 67.260    Top5: 90.160    Loss: 1.328

2024-02-19 18:08:22,711 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:08:22,711 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:08:22,786 - 

2024-02-19 18:08:22,786 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:08:33,310 - Epoch: [180][  100/  391]    Overall Loss 0.178427    Objective Loss 0.178427                                        LR 0.001298    Time 0.105164    
2024-02-19 18:08:42,702 - Epoch: [180][  200/  391]    Overall Loss 0.177399    Objective Loss 0.177399                                        LR 0.001298    Time 0.099516    
2024-02-19 18:08:52,034 - Epoch: [180][  300/  391]    Overall Loss 0.179766    Objective Loss 0.179766                                        LR 0.001298    Time 0.097440    
2024-02-19 18:09:00,543 - Epoch: [180][  391/  391]    Overall Loss 0.180987    Objective Loss 0.180987    Top1 93.750000    Top5 100.000000    LR 0.001298    Time 0.096513    
2024-02-19 18:09:00,856 - --- validate (epoch=180)-----------
2024-02-19 18:09:00,858 - 10000 samples (128 per mini-batch)
2024-02-19 18:09:03,582 - Epoch: [180][   79/   79]    Loss 1.322918    Top1 67.360000    Top5 90.070000    
2024-02-19 18:09:03,818 - ==> Top1: 67.360    Top5: 90.070    Loss: 1.323

2024-02-19 18:09:03,837 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:09:03,837 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:09:03,913 - 

2024-02-19 18:09:03,913 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:09:14,140 - Epoch: [181][  100/  391]    Overall Loss 0.174672    Objective Loss 0.174672                                        LR 0.001298    Time 0.102195    
2024-02-19 18:09:23,693 - Epoch: [181][  200/  391]    Overall Loss 0.177580    Objective Loss 0.177580                                        LR 0.001298    Time 0.098839    
2024-02-19 18:09:33,081 - Epoch: [181][  300/  391]    Overall Loss 0.180572    Objective Loss 0.180572                                        LR 0.001298    Time 0.097170    
2024-02-19 18:09:41,620 - Epoch: [181][  391/  391]    Overall Loss 0.180137    Objective Loss 0.180137    Top1 97.596154    Top5 100.000000    LR 0.001298    Time 0.096384    
2024-02-19 18:09:41,803 - --- validate (epoch=181)-----------
2024-02-19 18:09:41,803 - 10000 samples (128 per mini-batch)
2024-02-19 18:09:44,593 - Epoch: [181][   79/   79]    Loss 1.326092    Top1 67.060000    Top5 89.890000    
2024-02-19 18:09:44,777 - ==> Top1: 67.060    Top5: 89.890    Loss: 1.326

2024-02-19 18:09:44,793 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:09:44,793 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:09:44,876 - 

2024-02-19 18:09:44,876 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:09:54,908 - Epoch: [182][  100/  391]    Overall Loss 0.170630    Objective Loss 0.170630                                        LR 0.001298    Time 0.100239    
2024-02-19 18:10:04,271 - Epoch: [182][  200/  391]    Overall Loss 0.172889    Objective Loss 0.172889                                        LR 0.001298    Time 0.096912    
2024-02-19 18:10:13,783 - Epoch: [182][  300/  391]    Overall Loss 0.174278    Objective Loss 0.174278                                        LR 0.001298    Time 0.096298    
2024-02-19 18:10:22,464 - Epoch: [182][  391/  391]    Overall Loss 0.176877    Objective Loss 0.176877    Top1 93.750000    Top5 99.519231    LR 0.001298    Time 0.096078    
2024-02-19 18:10:22,752 - --- validate (epoch=182)-----------
2024-02-19 18:10:22,753 - 10000 samples (128 per mini-batch)
2024-02-19 18:10:25,598 - Epoch: [182][   79/   79]    Loss 1.325496    Top1 67.070000    Top5 90.160000    
2024-02-19 18:10:25,817 - ==> Top1: 67.070    Top5: 90.160    Loss: 1.325

2024-02-19 18:10:25,828 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:10:25,829 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:10:25,907 - 

2024-02-19 18:10:25,908 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:10:36,351 - Epoch: [183][  100/  391]    Overall Loss 0.172277    Objective Loss 0.172277                                        LR 0.001298    Time 0.104331    
2024-02-19 18:10:45,935 - Epoch: [183][  200/  391]    Overall Loss 0.172480    Objective Loss 0.172480                                        LR 0.001298    Time 0.100065    
2024-02-19 18:10:55,331 - Epoch: [183][  300/  391]    Overall Loss 0.173455    Objective Loss 0.173455                                        LR 0.001298    Time 0.098016    
2024-02-19 18:11:03,977 - Epoch: [183][  391/  391]    Overall Loss 0.173278    Objective Loss 0.173278    Top1 95.192308    Top5 100.000000    LR 0.001298    Time 0.097304    
2024-02-19 18:11:04,162 - --- validate (epoch=183)-----------
2024-02-19 18:11:04,162 - 10000 samples (128 per mini-batch)
2024-02-19 18:11:07,024 - Epoch: [183][   79/   79]    Loss 1.332109    Top1 67.000000    Top5 90.010000    
2024-02-19 18:11:07,200 - ==> Top1: 67.000    Top5: 90.010    Loss: 1.332

2024-02-19 18:11:07,224 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:11:07,225 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:11:07,299 - 

2024-02-19 18:11:07,299 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:11:17,295 - Epoch: [184][  100/  391]    Overall Loss 0.166013    Objective Loss 0.166013                                        LR 0.001298    Time 0.099881    
2024-02-19 18:11:26,839 - Epoch: [184][  200/  391]    Overall Loss 0.170177    Objective Loss 0.170177                                        LR 0.001298    Time 0.097640    
2024-02-19 18:11:36,214 - Epoch: [184][  300/  391]    Overall Loss 0.173037    Objective Loss 0.173037                                        LR 0.001298    Time 0.096328    
2024-02-19 18:11:44,758 - Epoch: [184][  391/  391]    Overall Loss 0.174257    Objective Loss 0.174257    Top1 95.192308    Top5 100.000000    LR 0.001298    Time 0.095750    
2024-02-19 18:11:45,009 - --- validate (epoch=184)-----------
2024-02-19 18:11:45,009 - 10000 samples (128 per mini-batch)
2024-02-19 18:11:48,192 - Epoch: [184][   79/   79]    Loss 1.328481    Top1 66.740000    Top5 90.080000    
2024-02-19 18:11:48,407 - ==> Top1: 66.740    Top5: 90.080    Loss: 1.328

2024-02-19 18:11:48,434 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:11:48,434 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:11:48,516 - 

2024-02-19 18:11:48,516 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:11:58,655 - Epoch: [185][  100/  391]    Overall Loss 0.169289    Objective Loss 0.169289                                        LR 0.001298    Time 0.101307    
2024-02-19 18:12:08,283 - Epoch: [185][  200/  391]    Overall Loss 0.170546    Objective Loss 0.170546                                        LR 0.001298    Time 0.098773    
2024-02-19 18:12:17,830 - Epoch: [185][  300/  391]    Overall Loss 0.170117    Objective Loss 0.170117                                        LR 0.001298    Time 0.097654    
2024-02-19 18:12:26,582 - Epoch: [185][  391/  391]    Overall Loss 0.170657    Objective Loss 0.170657    Top1 95.192308    Top5 100.000000    LR 0.001298    Time 0.097298    
2024-02-19 18:12:26,827 - --- validate (epoch=185)-----------
2024-02-19 18:12:26,828 - 10000 samples (128 per mini-batch)
2024-02-19 18:12:29,573 - Epoch: [185][   79/   79]    Loss 1.333425    Top1 67.110000    Top5 90.130000    
2024-02-19 18:12:29,703 - ==> Top1: 67.110    Top5: 90.130    Loss: 1.333

2024-02-19 18:12:29,721 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:12:29,721 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:12:29,797 - 

2024-02-19 18:12:29,798 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:12:40,195 - Epoch: [186][  100/  391]    Overall Loss 0.168003    Objective Loss 0.168003                                        LR 0.001298    Time 0.103898    
2024-02-19 18:12:49,821 - Epoch: [186][  200/  391]    Overall Loss 0.172662    Objective Loss 0.172662                                        LR 0.001298    Time 0.100054    
2024-02-19 18:12:59,425 - Epoch: [186][  300/  391]    Overall Loss 0.170748    Objective Loss 0.170748                                        LR 0.001298    Time 0.098702    
2024-02-19 18:13:07,917 - Epoch: [186][  391/  391]    Overall Loss 0.171379    Objective Loss 0.171379    Top1 97.115385    Top5 100.000000    LR 0.001298    Time 0.097436    
2024-02-19 18:13:08,160 - --- validate (epoch=186)-----------
2024-02-19 18:13:08,161 - 10000 samples (128 per mini-batch)
2024-02-19 18:13:10,877 - Epoch: [186][   79/   79]    Loss 1.338057    Top1 66.920000    Top5 90.140000    
2024-02-19 18:13:11,059 - ==> Top1: 66.920    Top5: 90.140    Loss: 1.338

2024-02-19 18:13:11,077 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:13:11,078 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:13:11,152 - 

2024-02-19 18:13:11,153 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:13:21,335 - Epoch: [187][  100/  391]    Overall Loss 0.171068    Objective Loss 0.171068                                        LR 0.001298    Time 0.101744    
2024-02-19 18:13:30,730 - Epoch: [187][  200/  391]    Overall Loss 0.169351    Objective Loss 0.169351                                        LR 0.001298    Time 0.097826    
2024-02-19 18:13:40,178 - Epoch: [187][  300/  391]    Overall Loss 0.170330    Objective Loss 0.170330                                        LR 0.001298    Time 0.096697    
2024-02-19 18:13:48,877 - Epoch: [187][  391/  391]    Overall Loss 0.171265    Objective Loss 0.171265    Top1 96.634615    Top5 100.000000    LR 0.001298    Time 0.096429    
2024-02-19 18:13:49,168 - --- validate (epoch=187)-----------
2024-02-19 18:13:49,168 - 10000 samples (128 per mini-batch)
2024-02-19 18:13:52,214 - Epoch: [187][   79/   79]    Loss 1.328471    Top1 66.900000    Top5 90.030000    
2024-02-19 18:13:52,447 - ==> Top1: 66.900    Top5: 90.030    Loss: 1.328

2024-02-19 18:13:52,459 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:13:52,459 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:13:52,536 - 

2024-02-19 18:13:52,536 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:14:02,893 - Epoch: [188][  100/  391]    Overall Loss 0.169394    Objective Loss 0.169394                                        LR 0.001298    Time 0.103492    
2024-02-19 18:14:12,415 - Epoch: [188][  200/  391]    Overall Loss 0.168713    Objective Loss 0.168713                                        LR 0.001298    Time 0.099335    
2024-02-19 18:14:21,971 - Epoch: [188][  300/  391]    Overall Loss 0.168231    Objective Loss 0.168231                                        LR 0.001298    Time 0.098060    
2024-02-19 18:14:30,588 - Epoch: [188][  391/  391]    Overall Loss 0.168887    Objective Loss 0.168887    Top1 96.634615    Top5 100.000000    LR 0.001298    Time 0.097266    
2024-02-19 18:14:30,826 - --- validate (epoch=188)-----------
2024-02-19 18:14:30,827 - 10000 samples (128 per mini-batch)
2024-02-19 18:14:33,421 - Epoch: [188][   79/   79]    Loss 1.331676    Top1 66.910000    Top5 90.020000    
2024-02-19 18:14:33,582 - ==> Top1: 66.910    Top5: 90.020    Loss: 1.332

2024-02-19 18:14:33,603 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:14:33,603 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:14:33,679 - 

2024-02-19 18:14:33,679 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:14:43,934 - Epoch: [189][  100/  391]    Overall Loss 0.165290    Objective Loss 0.165290                                        LR 0.001298    Time 0.102468    
2024-02-19 18:14:53,411 - Epoch: [189][  200/  391]    Overall Loss 0.167899    Objective Loss 0.167899                                        LR 0.001298    Time 0.098597    
2024-02-19 18:15:02,799 - Epoch: [189][  300/  391]    Overall Loss 0.167915    Objective Loss 0.167915                                        LR 0.001298    Time 0.097011    
2024-02-19 18:15:11,472 - Epoch: [189][  391/  391]    Overall Loss 0.170486    Objective Loss 0.170486    Top1 96.153846    Top5 100.000000    LR 0.001298    Time 0.096604    
2024-02-19 18:15:11,704 - --- validate (epoch=189)-----------
2024-02-19 18:15:11,704 - 10000 samples (128 per mini-batch)
2024-02-19 18:15:14,377 - Epoch: [189][   79/   79]    Loss 1.342635    Top1 66.830000    Top5 90.030000    
2024-02-19 18:15:14,619 - ==> Top1: 66.830    Top5: 90.030    Loss: 1.343

2024-02-19 18:15:14,637 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:15:14,638 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:15:14,712 - 

2024-02-19 18:15:14,713 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:15:24,995 - Epoch: [190][  100/  391]    Overall Loss 0.161642    Objective Loss 0.161642                                        LR 0.001298    Time 0.102746    
2024-02-19 18:15:34,502 - Epoch: [190][  200/  391]    Overall Loss 0.163029    Objective Loss 0.163029                                        LR 0.001298    Time 0.098887    
2024-02-19 18:15:44,026 - Epoch: [190][  300/  391]    Overall Loss 0.164693    Objective Loss 0.164693                                        LR 0.001298    Time 0.097654    
2024-02-19 18:15:52,684 - Epoch: [190][  391/  391]    Overall Loss 0.166364    Objective Loss 0.166364    Top1 91.826923    Top5 100.000000    LR 0.001298    Time 0.097058    
2024-02-19 18:15:52,927 - --- validate (epoch=190)-----------
2024-02-19 18:15:52,928 - 10000 samples (128 per mini-batch)
2024-02-19 18:15:55,693 - Epoch: [190][   79/   79]    Loss 1.333915    Top1 66.940000    Top5 90.200000    
2024-02-19 18:15:55,862 - ==> Top1: 66.940    Top5: 90.200    Loss: 1.334

2024-02-19 18:15:55,882 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:15:55,883 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:15:55,958 - 

2024-02-19 18:15:55,958 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:16:05,984 - Epoch: [191][  100/  391]    Overall Loss 0.167240    Objective Loss 0.167240                                        LR 0.001298    Time 0.100187    
2024-02-19 18:16:14,804 - Epoch: [191][  200/  391]    Overall Loss 0.165507    Objective Loss 0.165507                                        LR 0.001298    Time 0.094172    
2024-02-19 18:16:21,771 - Epoch: [191][  300/  391]    Overall Loss 0.166577    Objective Loss 0.166577                                        LR 0.001298    Time 0.085991    
2024-02-19 18:16:28,211 - Epoch: [191][  391/  391]    Overall Loss 0.167198    Objective Loss 0.167198    Top1 97.115385    Top5 99.519231    LR 0.001298    Time 0.082442    
2024-02-19 18:16:28,419 - --- validate (epoch=191)-----------
2024-02-19 18:16:28,419 - 10000 samples (128 per mini-batch)
2024-02-19 18:16:31,019 - Epoch: [191][   79/   79]    Loss 1.350309    Top1 67.060000    Top5 90.090000    
2024-02-19 18:16:31,213 - ==> Top1: 67.060    Top5: 90.090    Loss: 1.350

2024-02-19 18:16:31,224 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:16:31,225 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:16:31,298 - 

2024-02-19 18:16:31,298 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:16:39,989 - Epoch: [192][  100/  391]    Overall Loss 0.163152    Objective Loss 0.163152                                        LR 0.001298    Time 0.086839    
2024-02-19 18:16:48,119 - Epoch: [192][  200/  391]    Overall Loss 0.161818    Objective Loss 0.161818                                        LR 0.001298    Time 0.084052    
2024-02-19 18:16:57,492 - Epoch: [192][  300/  391]    Overall Loss 0.162984    Objective Loss 0.162984                                        LR 0.001298    Time 0.087264    
2024-02-19 18:17:06,142 - Epoch: [192][  391/  391]    Overall Loss 0.164090    Objective Loss 0.164090    Top1 95.673077    Top5 100.000000    LR 0.001298    Time 0.089067    
2024-02-19 18:17:06,363 - --- validate (epoch=192)-----------
2024-02-19 18:17:06,363 - 10000 samples (128 per mini-batch)
2024-02-19 18:17:09,278 - Epoch: [192][   79/   79]    Loss 1.332412    Top1 66.850000    Top5 90.100000    
2024-02-19 18:17:09,483 - ==> Top1: 66.850    Top5: 90.100    Loss: 1.332

2024-02-19 18:17:09,502 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:17:09,502 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:17:09,575 - 

2024-02-19 18:17:09,576 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:17:19,589 - Epoch: [193][  100/  391]    Overall Loss 0.161500    Objective Loss 0.161500                                        LR 0.001298    Time 0.100057    
2024-02-19 18:17:28,896 - Epoch: [193][  200/  391]    Overall Loss 0.163752    Objective Loss 0.163752                                        LR 0.001298    Time 0.096544    
2024-02-19 18:17:37,498 - Epoch: [193][  300/  391]    Overall Loss 0.164758    Objective Loss 0.164758                                        LR 0.001298    Time 0.093023    
2024-02-19 18:17:45,976 - Epoch: [193][  391/  391]    Overall Loss 0.166022    Objective Loss 0.166022    Top1 94.230769    Top5 99.519231    LR 0.001298    Time 0.093047    
2024-02-19 18:17:46,296 - --- validate (epoch=193)-----------
2024-02-19 18:17:46,297 - 10000 samples (128 per mini-batch)
2024-02-19 18:17:49,142 - Epoch: [193][   79/   79]    Loss 1.348482    Top1 66.940000    Top5 90.210000    
2024-02-19 18:17:49,355 - ==> Top1: 66.940    Top5: 90.210    Loss: 1.348

2024-02-19 18:17:49,374 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:17:49,374 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:17:49,449 - 

2024-02-19 18:17:49,449 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:17:59,497 - Epoch: [194][  100/  391]    Overall Loss 0.159389    Objective Loss 0.159389                                        LR 0.001298    Time 0.100406    
2024-02-19 18:18:08,836 - Epoch: [194][  200/  391]    Overall Loss 0.162840    Objective Loss 0.162840                                        LR 0.001298    Time 0.096876    
2024-02-19 18:18:15,881 - Epoch: [194][  300/  391]    Overall Loss 0.164014    Objective Loss 0.164014                                        LR 0.001298    Time 0.088056    
2024-02-19 18:18:22,244 - Epoch: [194][  391/  391]    Overall Loss 0.163814    Objective Loss 0.163814    Top1 96.153846    Top5 100.000000    LR 0.001298    Time 0.083828    
2024-02-19 18:18:22,473 - --- validate (epoch=194)-----------
2024-02-19 18:18:22,474 - 10000 samples (128 per mini-batch)
2024-02-19 18:18:25,593 - Epoch: [194][   79/   79]    Loss 1.345392    Top1 66.930000    Top5 90.060000    
2024-02-19 18:18:25,785 - ==> Top1: 66.930    Top5: 90.060    Loss: 1.345

2024-02-19 18:18:25,795 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:18:25,795 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:18:25,877 - 

2024-02-19 18:18:25,877 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:18:35,922 - Epoch: [195][  100/  391]    Overall Loss 0.162932    Objective Loss 0.162932                                        LR 0.001298    Time 0.100373    
2024-02-19 18:18:45,321 - Epoch: [195][  200/  391]    Overall Loss 0.164049    Objective Loss 0.164049                                        LR 0.001298    Time 0.097160    
2024-02-19 18:18:54,713 - Epoch: [195][  300/  391]    Overall Loss 0.164216    Objective Loss 0.164216                                        LR 0.001298    Time 0.096066    
2024-02-19 18:19:03,233 - Epoch: [195][  391/  391]    Overall Loss 0.164087    Objective Loss 0.164087    Top1 96.634615    Top5 100.000000    LR 0.001298    Time 0.095490    
2024-02-19 18:19:03,403 - --- validate (epoch=195)-----------
2024-02-19 18:19:03,403 - 10000 samples (128 per mini-batch)
2024-02-19 18:19:06,351 - Epoch: [195][   79/   79]    Loss 1.341553    Top1 66.670000    Top5 90.110000    
2024-02-19 18:19:06,487 - ==> Top1: 66.670    Top5: 90.110    Loss: 1.342

2024-02-19 18:19:06,513 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:19:06,514 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:19:06,595 - 

2024-02-19 18:19:06,596 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:19:16,758 - Epoch: [196][  100/  391]    Overall Loss 0.164768    Objective Loss 0.164768                                        LR 0.001298    Time 0.101506    
2024-02-19 18:19:26,113 - Epoch: [196][  200/  391]    Overall Loss 0.163550    Objective Loss 0.163550                                        LR 0.001298    Time 0.097506    
2024-02-19 18:19:35,513 - Epoch: [196][  300/  391]    Overall Loss 0.163167    Objective Loss 0.163167                                        LR 0.001298    Time 0.096323    
2024-02-19 18:19:44,004 - Epoch: [196][  391/  391]    Overall Loss 0.163966    Objective Loss 0.163966    Top1 97.115385    Top5 100.000000    LR 0.001298    Time 0.095611    
2024-02-19 18:19:44,242 - --- validate (epoch=196)-----------
2024-02-19 18:19:44,243 - 10000 samples (128 per mini-batch)
2024-02-19 18:19:47,370 - Epoch: [196][   79/   79]    Loss 1.365839    Top1 66.750000    Top5 89.960000    
2024-02-19 18:19:47,601 - ==> Top1: 66.750    Top5: 89.960    Loss: 1.366

2024-02-19 18:19:47,614 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:19:47,614 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:19:47,720 - 

2024-02-19 18:19:47,720 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:19:57,575 - Epoch: [197][  100/  391]    Overall Loss 0.160814    Objective Loss 0.160814                                        LR 0.001298    Time 0.098477    
2024-02-19 18:20:07,009 - Epoch: [197][  200/  391]    Overall Loss 0.160856    Objective Loss 0.160856                                        LR 0.001298    Time 0.096387    
2024-02-19 18:20:16,360 - Epoch: [197][  300/  391]    Overall Loss 0.162088    Objective Loss 0.162088                                        LR 0.001298    Time 0.095415    
2024-02-19 18:20:24,964 - Epoch: [197][  391/  391]    Overall Loss 0.162756    Objective Loss 0.162756    Top1 95.192308    Top5 100.000000    LR 0.001298    Time 0.095202    
2024-02-19 18:20:25,202 - --- validate (epoch=197)-----------
2024-02-19 18:20:25,203 - 10000 samples (128 per mini-batch)
2024-02-19 18:20:27,920 - Epoch: [197][   79/   79]    Loss 1.361022    Top1 66.480000    Top5 90.110000    
2024-02-19 18:20:28,104 - ==> Top1: 66.480    Top5: 90.110    Loss: 1.361

2024-02-19 18:20:28,123 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:20:28,123 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:20:28,203 - 

2024-02-19 18:20:28,203 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:20:38,493 - Epoch: [198][  100/  391]    Overall Loss 0.158934    Objective Loss 0.158934                                        LR 0.001298    Time 0.102809    
2024-02-19 18:20:47,878 - Epoch: [198][  200/  391]    Overall Loss 0.158053    Objective Loss 0.158053                                        LR 0.001298    Time 0.098308    
2024-02-19 18:20:57,132 - Epoch: [198][  300/  391]    Overall Loss 0.161427    Objective Loss 0.161427                                        LR 0.001298    Time 0.096371    
2024-02-19 18:21:05,714 - Epoch: [198][  391/  391]    Overall Loss 0.162402    Objective Loss 0.162402    Top1 97.115385    Top5 100.000000    LR 0.001298    Time 0.095882    
2024-02-19 18:21:06,024 - --- validate (epoch=198)-----------
2024-02-19 18:21:06,024 - 10000 samples (128 per mini-batch)
2024-02-19 18:21:08,654 - Epoch: [198][   79/   79]    Loss 1.353372    Top1 67.070000    Top5 90.060000    
2024-02-19 18:21:08,878 - ==> Top1: 67.070    Top5: 90.060    Loss: 1.353

2024-02-19 18:21:08,898 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:21:08,898 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:21:08,977 - 

2024-02-19 18:21:08,977 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:21:19,176 - Epoch: [199][  100/  391]    Overall Loss 0.161186    Objective Loss 0.161186                                        LR 0.001298    Time 0.101922    
2024-02-19 18:21:28,433 - Epoch: [199][  200/  391]    Overall Loss 0.159144    Objective Loss 0.159144                                        LR 0.001298    Time 0.097218    
2024-02-19 18:21:37,838 - Epoch: [199][  300/  391]    Overall Loss 0.159413    Objective Loss 0.159413                                        LR 0.001298    Time 0.096147    
2024-02-19 18:21:46,536 - Epoch: [199][  391/  391]    Overall Loss 0.160005    Objective Loss 0.160005    Top1 94.711538    Top5 100.000000    LR 0.001298    Time 0.096005    
2024-02-19 18:21:46,700 - --- validate (epoch=199)-----------
2024-02-19 18:21:46,701 - 10000 samples (128 per mini-batch)
2024-02-19 18:21:49,372 - Epoch: [199][   79/   79]    Loss 1.355071    Top1 66.850000    Top5 90.010000    
2024-02-19 18:21:49,563 - ==> Top1: 66.850    Top5: 90.010    Loss: 1.355

2024-02-19 18:21:49,583 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:21:49,583 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:21:49,658 - 

2024-02-19 18:21:49,658 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:22:00,028 - Epoch: [200][  100/  391]    Overall Loss 0.156741    Objective Loss 0.156741                                        LR 0.001298    Time 0.103629    
2024-02-19 18:22:09,570 - Epoch: [200][  200/  391]    Overall Loss 0.156254    Objective Loss 0.156254                                        LR 0.001298    Time 0.099502    
2024-02-19 18:22:18,974 - Epoch: [200][  300/  391]    Overall Loss 0.156901    Objective Loss 0.156901                                        LR 0.001298    Time 0.097665    
2024-02-19 18:22:27,648 - Epoch: [200][  391/  391]    Overall Loss 0.158429    Objective Loss 0.158429    Top1 97.596154    Top5 100.000000    LR 0.001298    Time 0.097109    
2024-02-19 18:22:27,879 - --- validate (epoch=200)-----------
2024-02-19 18:22:27,880 - 10000 samples (128 per mini-batch)
2024-02-19 18:22:30,633 - Epoch: [200][   79/   79]    Loss 1.349766    Top1 66.710000    Top5 90.110000    
2024-02-19 18:22:30,807 - ==> Top1: 66.710    Top5: 90.110    Loss: 1.350

2024-02-19 18:22:30,825 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:22:30,826 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:22:30,900 - 

2024-02-19 18:22:30,901 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:22:40,943 - Epoch: [201][  100/  391]    Overall Loss 0.158572    Objective Loss 0.158572                                        LR 0.001298    Time 0.100350    
2024-02-19 18:22:50,320 - Epoch: [201][  200/  391]    Overall Loss 0.159345    Objective Loss 0.159345                                        LR 0.001298    Time 0.097036    
2024-02-19 18:22:59,699 - Epoch: [201][  300/  391]    Overall Loss 0.161556    Objective Loss 0.161556                                        LR 0.001298    Time 0.095941    
2024-02-19 18:23:08,385 - Epoch: [201][  391/  391]    Overall Loss 0.161953    Objective Loss 0.161953    Top1 94.711538    Top5 100.000000    LR 0.001298    Time 0.095816    
2024-02-19 18:23:08,570 - --- validate (epoch=201)-----------
2024-02-19 18:23:08,571 - 10000 samples (128 per mini-batch)
2024-02-19 18:23:11,403 - Epoch: [201][   79/   79]    Loss 1.370276    Top1 66.690000    Top5 90.170000    
2024-02-19 18:23:11,591 - ==> Top1: 66.690    Top5: 90.170    Loss: 1.370

2024-02-19 18:23:11,610 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:23:11,610 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:23:11,687 - 

2024-02-19 18:23:11,688 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:23:22,068 - Epoch: [202][  100/  391]    Overall Loss 0.157327    Objective Loss 0.157327                                        LR 0.001298    Time 0.103734    
2024-02-19 18:23:31,465 - Epoch: [202][  200/  391]    Overall Loss 0.157594    Objective Loss 0.157594                                        LR 0.001298    Time 0.098825    
2024-02-19 18:23:40,822 - Epoch: [202][  300/  391]    Overall Loss 0.159246    Objective Loss 0.159246                                        LR 0.001298    Time 0.097059    
2024-02-19 18:23:49,435 - Epoch: [202][  391/  391]    Overall Loss 0.159891    Objective Loss 0.159891    Top1 96.634615    Top5 100.000000    LR 0.001298    Time 0.096486    
2024-02-19 18:23:49,705 - --- validate (epoch=202)-----------
2024-02-19 18:23:49,706 - 10000 samples (128 per mini-batch)
2024-02-19 18:23:52,191 - Epoch: [202][   79/   79]    Loss 1.352301    Top1 66.900000    Top5 90.090000    
2024-02-19 18:23:52,345 - ==> Top1: 66.900    Top5: 90.090    Loss: 1.352

2024-02-19 18:23:52,364 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:23:52,365 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:23:52,459 - 

2024-02-19 18:23:52,460 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:24:02,545 - Epoch: [203][  100/  391]    Overall Loss 0.156066    Objective Loss 0.156066                                        LR 0.001298    Time 0.100777    
2024-02-19 18:24:12,031 - Epoch: [203][  200/  391]    Overall Loss 0.155790    Objective Loss 0.155790                                        LR 0.001298    Time 0.097797    
2024-02-19 18:24:21,475 - Epoch: [203][  300/  391]    Overall Loss 0.156794    Objective Loss 0.156794                                        LR 0.001298    Time 0.096661    
2024-02-19 18:24:30,272 - Epoch: [203][  391/  391]    Overall Loss 0.157044    Objective Loss 0.157044    Top1 95.673077    Top5 100.000000    LR 0.001298    Time 0.096652    
2024-02-19 18:24:30,513 - --- validate (epoch=203)-----------
2024-02-19 18:24:30,513 - 10000 samples (128 per mini-batch)
2024-02-19 18:24:33,430 - Epoch: [203][   79/   79]    Loss 1.363892    Top1 66.700000    Top5 90.100000    
2024-02-19 18:24:33,678 - ==> Top1: 66.700    Top5: 90.100    Loss: 1.364

2024-02-19 18:24:33,698 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:24:33,699 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:24:33,777 - 

2024-02-19 18:24:33,777 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:24:44,197 - Epoch: [204][  100/  391]    Overall Loss 0.155895    Objective Loss 0.155895                                        LR 0.001298    Time 0.104125    
2024-02-19 18:24:53,622 - Epoch: [204][  200/  391]    Overall Loss 0.155840    Objective Loss 0.155840                                        LR 0.001298    Time 0.099162    
2024-02-19 18:25:03,100 - Epoch: [204][  300/  391]    Overall Loss 0.157687    Objective Loss 0.157687                                        LR 0.001298    Time 0.097685    
2024-02-19 18:25:11,778 - Epoch: [204][  391/  391]    Overall Loss 0.157881    Objective Loss 0.157881    Top1 98.076923    Top5 100.000000    LR 0.001298    Time 0.097134    
2024-02-19 18:25:11,957 - --- validate (epoch=204)-----------
2024-02-19 18:25:11,957 - 10000 samples (128 per mini-batch)
2024-02-19 18:25:14,824 - Epoch: [204][   79/   79]    Loss 1.361787    Top1 66.680000    Top5 90.100000    
2024-02-19 18:25:15,078 - ==> Top1: 66.680    Top5: 90.100    Loss: 1.362

2024-02-19 18:25:15,094 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:25:15,094 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:25:15,169 - 

2024-02-19 18:25:15,170 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:25:23,213 - Epoch: [205][  100/  391]    Overall Loss 0.153844    Objective Loss 0.153844                                        LR 0.001298    Time 0.080361    
2024-02-19 18:25:30,551 - Epoch: [205][  200/  391]    Overall Loss 0.156061    Objective Loss 0.156061                                        LR 0.001298    Time 0.076849    
2024-02-19 18:25:37,839 - Epoch: [205][  300/  391]    Overall Loss 0.155990    Objective Loss 0.155990                                        LR 0.001298    Time 0.075513    
2024-02-19 18:25:44,600 - Epoch: [205][  391/  391]    Overall Loss 0.156957    Objective Loss 0.156957    Top1 93.750000    Top5 100.000000    LR 0.001298    Time 0.075221    
2024-02-19 18:25:44,835 - --- validate (epoch=205)-----------
2024-02-19 18:25:44,836 - 10000 samples (128 per mini-batch)
2024-02-19 18:25:47,605 - Epoch: [205][   79/   79]    Loss 1.357810    Top1 66.900000    Top5 90.010000    
2024-02-19 18:25:47,789 - ==> Top1: 66.900    Top5: 90.010    Loss: 1.358

2024-02-19 18:25:47,809 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:25:47,809 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:25:47,886 - 

2024-02-19 18:25:47,887 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:25:57,831 - Epoch: [206][  100/  391]    Overall Loss 0.152696    Objective Loss 0.152696                                        LR 0.001298    Time 0.099370    
2024-02-19 18:26:07,289 - Epoch: [206][  200/  391]    Overall Loss 0.151574    Objective Loss 0.151574                                        LR 0.001298    Time 0.096952    
2024-02-19 18:26:16,729 - Epoch: [206][  300/  391]    Overall Loss 0.154523    Objective Loss 0.154523                                        LR 0.001298    Time 0.096086    
2024-02-19 18:26:23,574 - Epoch: [206][  391/  391]    Overall Loss 0.155076    Objective Loss 0.155076    Top1 97.115385    Top5 99.519231    LR 0.001298    Time 0.091220    
2024-02-19 18:26:23,822 - --- validate (epoch=206)-----------
2024-02-19 18:26:23,823 - 10000 samples (128 per mini-batch)
2024-02-19 18:26:26,493 - Epoch: [206][   79/   79]    Loss 1.366458    Top1 66.800000    Top5 90.100000    
2024-02-19 18:26:26,667 - ==> Top1: 66.800    Top5: 90.100    Loss: 1.366

2024-02-19 18:26:26,685 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:26:26,685 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:26:26,759 - 

2024-02-19 18:26:26,760 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:26:36,473 - Epoch: [207][  100/  391]    Overall Loss 0.153968    Objective Loss 0.153968                                        LR 0.001298    Time 0.097061    
2024-02-19 18:26:45,892 - Epoch: [207][  200/  391]    Overall Loss 0.155713    Objective Loss 0.155713                                        LR 0.001298    Time 0.095606    
2024-02-19 18:26:55,327 - Epoch: [207][  300/  391]    Overall Loss 0.156206    Objective Loss 0.156206                                        LR 0.001298    Time 0.095171    
2024-02-19 18:27:04,036 - Epoch: [207][  391/  391]    Overall Loss 0.156971    Objective Loss 0.156971    Top1 98.557692    Top5 100.000000    LR 0.001298    Time 0.095284    
2024-02-19 18:27:04,203 - --- validate (epoch=207)-----------
2024-02-19 18:27:04,204 - 10000 samples (128 per mini-batch)
2024-02-19 18:27:06,439 - Epoch: [207][   79/   79]    Loss 1.363971    Top1 66.880000    Top5 90.010000    
2024-02-19 18:27:06,665 - ==> Top1: 66.880    Top5: 90.010    Loss: 1.364

2024-02-19 18:27:06,684 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:27:06,685 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:27:06,760 - 

2024-02-19 18:27:06,760 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:27:16,515 - Epoch: [208][  100/  391]    Overall Loss 0.158013    Objective Loss 0.158013                                        LR 0.001298    Time 0.097478    
2024-02-19 18:27:25,932 - Epoch: [208][  200/  391]    Overall Loss 0.156916    Objective Loss 0.156916                                        LR 0.001298    Time 0.095797    
2024-02-19 18:27:35,356 - Epoch: [208][  300/  391]    Overall Loss 0.155556    Objective Loss 0.155556                                        LR 0.001298    Time 0.095266    
2024-02-19 18:27:43,987 - Epoch: [208][  391/  391]    Overall Loss 0.155767    Objective Loss 0.155767    Top1 97.115385    Top5 100.000000    LR 0.001298    Time 0.095157    
2024-02-19 18:27:44,180 - --- validate (epoch=208)-----------
2024-02-19 18:27:44,181 - 10000 samples (128 per mini-batch)
2024-02-19 18:27:46,903 - Epoch: [208][   79/   79]    Loss 1.374261    Top1 67.010000    Top5 90.040000    
2024-02-19 18:27:47,197 - ==> Top1: 67.010    Top5: 90.040    Loss: 1.374

2024-02-19 18:27:47,216 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:27:47,217 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:27:47,514 - 

2024-02-19 18:27:47,514 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:27:57,227 - Epoch: [209][  100/  391]    Overall Loss 0.150436    Objective Loss 0.150436                                        LR 0.001298    Time 0.097055    
2024-02-19 18:28:06,639 - Epoch: [209][  200/  391]    Overall Loss 0.148675    Objective Loss 0.148675                                        LR 0.001298    Time 0.095567    
2024-02-19 18:28:16,064 - Epoch: [209][  300/  391]    Overall Loss 0.150248    Objective Loss 0.150248                                        LR 0.001298    Time 0.095112    
2024-02-19 18:28:24,480 - Epoch: [209][  391/  391]    Overall Loss 0.151225    Objective Loss 0.151225    Top1 96.153846    Top5 100.000000    LR 0.001298    Time 0.094493    
2024-02-19 18:28:24,671 - --- validate (epoch=209)-----------
2024-02-19 18:28:24,672 - 10000 samples (128 per mini-batch)
2024-02-19 18:28:27,416 - Epoch: [209][   79/   79]    Loss 1.367225    Top1 66.730000    Top5 89.970000    
2024-02-19 18:28:27,628 - ==> Top1: 66.730    Top5: 89.970    Loss: 1.367

2024-02-19 18:28:27,653 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:28:27,654 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:28:27,744 - 

2024-02-19 18:28:27,744 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:28:38,119 - Epoch: [210][  100/  391]    Overall Loss 0.147650    Objective Loss 0.147650                                        LR 0.001298    Time 0.103663    
2024-02-19 18:28:47,474 - Epoch: [210][  200/  391]    Overall Loss 0.150896    Objective Loss 0.150896                                        LR 0.001298    Time 0.098586    
2024-02-19 18:28:56,910 - Epoch: [210][  300/  391]    Overall Loss 0.152411    Objective Loss 0.152411                                        LR 0.001298    Time 0.097163    
2024-02-19 18:29:05,686 - Epoch: [210][  391/  391]    Overall Loss 0.153246    Objective Loss 0.153246    Top1 99.519231    Top5 100.000000    LR 0.001298    Time 0.096983    
2024-02-19 18:29:05,870 - --- validate (epoch=210)-----------
2024-02-19 18:29:05,871 - 10000 samples (128 per mini-batch)
2024-02-19 18:29:08,751 - Epoch: [210][   79/   79]    Loss 1.364436    Top1 66.640000    Top5 90.050000    
2024-02-19 18:29:08,965 - ==> Top1: 66.640    Top5: 90.050    Loss: 1.364

2024-02-19 18:29:08,984 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:29:08,984 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:29:09,062 - 

2024-02-19 18:29:09,062 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:29:19,165 - Epoch: [211][  100/  391]    Overall Loss 0.150530    Objective Loss 0.150530                                        LR 0.001298    Time 0.100945    
2024-02-19 18:29:28,574 - Epoch: [211][  200/  391]    Overall Loss 0.152378    Objective Loss 0.152378                                        LR 0.001298    Time 0.097493    
2024-02-19 18:29:37,989 - Epoch: [211][  300/  391]    Overall Loss 0.153055    Objective Loss 0.153055                                        LR 0.001298    Time 0.096366    
2024-02-19 18:29:46,633 - Epoch: [211][  391/  391]    Overall Loss 0.153108    Objective Loss 0.153108    Top1 94.711538    Top5 100.000000    LR 0.001298    Time 0.096033    
2024-02-19 18:29:46,822 - --- validate (epoch=211)-----------
2024-02-19 18:29:46,822 - 10000 samples (128 per mini-batch)
2024-02-19 18:29:49,626 - Epoch: [211][   79/   79]    Loss 1.361217    Top1 66.830000    Top5 90.120000    
2024-02-19 18:29:49,820 - ==> Top1: 66.830    Top5: 90.120    Loss: 1.361

2024-02-19 18:29:49,832 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:29:49,832 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:29:49,903 - 

2024-02-19 18:29:49,904 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:29:59,915 - Epoch: [212][  100/  391]    Overall Loss 0.149963    Objective Loss 0.149963                                        LR 0.001298    Time 0.100041    
2024-02-19 18:30:09,233 - Epoch: [212][  200/  391]    Overall Loss 0.152485    Objective Loss 0.152485                                        LR 0.001298    Time 0.096585    
2024-02-19 18:30:18,533 - Epoch: [212][  300/  391]    Overall Loss 0.150824    Objective Loss 0.150824                                        LR 0.001298    Time 0.095375    
2024-02-19 18:30:27,108 - Epoch: [212][  391/  391]    Overall Loss 0.151539    Objective Loss 0.151539    Top1 97.596154    Top5 99.519231    LR 0.001298    Time 0.095100    
2024-02-19 18:30:27,325 - --- validate (epoch=212)-----------
2024-02-19 18:30:27,325 - 10000 samples (128 per mini-batch)
2024-02-19 18:30:30,270 - Epoch: [212][   79/   79]    Loss 1.375701    Top1 66.690000    Top5 90.060000    
2024-02-19 18:30:30,509 - ==> Top1: 66.690    Top5: 90.060    Loss: 1.376

2024-02-19 18:30:30,528 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:30:30,528 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:30:30,610 - 

2024-02-19 18:30:30,611 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:30:40,652 - Epoch: [213][  100/  391]    Overall Loss 0.149187    Objective Loss 0.149187                                        LR 0.001298    Time 0.100346    
2024-02-19 18:30:50,099 - Epoch: [213][  200/  391]    Overall Loss 0.151906    Objective Loss 0.151906                                        LR 0.001298    Time 0.097385    
2024-02-19 18:30:59,535 - Epoch: [213][  300/  391]    Overall Loss 0.149302    Objective Loss 0.149302                                        LR 0.001298    Time 0.096362    
2024-02-19 18:31:08,076 - Epoch: [213][  391/  391]    Overall Loss 0.150211    Objective Loss 0.150211    Top1 95.192308    Top5 100.000000    LR 0.001298    Time 0.095767    
2024-02-19 18:31:08,398 - --- validate (epoch=213)-----------
2024-02-19 18:31:08,399 - 10000 samples (128 per mini-batch)
2024-02-19 18:31:10,996 - Epoch: [213][   79/   79]    Loss 1.370440    Top1 66.830000    Top5 89.900000    
2024-02-19 18:31:11,174 - ==> Top1: 66.830    Top5: 89.900    Loss: 1.370

2024-02-19 18:31:11,192 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:31:11,193 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:31:11,266 - 

2024-02-19 18:31:11,266 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:31:20,956 - Epoch: [214][  100/  391]    Overall Loss 0.146207    Objective Loss 0.146207                                        LR 0.001298    Time 0.096827    
2024-02-19 18:31:30,231 - Epoch: [214][  200/  391]    Overall Loss 0.151502    Objective Loss 0.151502                                        LR 0.001298    Time 0.094765    
2024-02-19 18:31:39,566 - Epoch: [214][  300/  391]    Overall Loss 0.151005    Objective Loss 0.151005                                        LR 0.001298    Time 0.094280    
2024-02-19 18:31:48,074 - Epoch: [214][  391/  391]    Overall Loss 0.152154    Objective Loss 0.152154    Top1 97.596154    Top5 100.000000    LR 0.001298    Time 0.094085    
2024-02-19 18:31:48,275 - --- validate (epoch=214)-----------
2024-02-19 18:31:48,276 - 10000 samples (128 per mini-batch)
2024-02-19 18:31:51,160 - Epoch: [214][   79/   79]    Loss 1.372455    Top1 66.940000    Top5 90.040000    
2024-02-19 18:31:51,311 - ==> Top1: 66.940    Top5: 90.040    Loss: 1.372

2024-02-19 18:31:51,322 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:31:51,322 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:31:51,395 - 

2024-02-19 18:31:51,395 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:32:01,373 - Epoch: [215][  100/  391]    Overall Loss 0.148153    Objective Loss 0.148153                                        LR 0.001298    Time 0.099703    
2024-02-19 18:32:10,678 - Epoch: [215][  200/  391]    Overall Loss 0.148213    Objective Loss 0.148213                                        LR 0.001298    Time 0.096357    
2024-02-19 18:32:20,028 - Epoch: [215][  300/  391]    Overall Loss 0.149847    Objective Loss 0.149847                                        LR 0.001298    Time 0.095391    
2024-02-19 18:32:28,443 - Epoch: [215][  391/  391]    Overall Loss 0.149235    Objective Loss 0.149235    Top1 96.634615    Top5 100.000000    LR 0.001298    Time 0.094702    
2024-02-19 18:32:28,684 - --- validate (epoch=215)-----------
2024-02-19 18:32:28,685 - 10000 samples (128 per mini-batch)
2024-02-19 18:32:31,403 - Epoch: [215][   79/   79]    Loss 1.367771    Top1 67.210000    Top5 90.070000    
2024-02-19 18:32:31,606 - ==> Top1: 67.210    Top5: 90.070    Loss: 1.368

2024-02-19 18:32:31,624 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:32:31,625 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:32:31,698 - 

2024-02-19 18:32:31,699 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:32:41,723 - Epoch: [216][  100/  391]    Overall Loss 0.150643    Objective Loss 0.150643                                        LR 0.001298    Time 0.100176    
2024-02-19 18:32:51,109 - Epoch: [216][  200/  391]    Overall Loss 0.149814    Objective Loss 0.149814                                        LR 0.001298    Time 0.096995    
2024-02-19 18:33:00,407 - Epoch: [216][  300/  391]    Overall Loss 0.150779    Objective Loss 0.150779                                        LR 0.001298    Time 0.095642    
2024-02-19 18:33:08,832 - Epoch: [216][  391/  391]    Overall Loss 0.151562    Objective Loss 0.151562    Top1 97.115385    Top5 100.000000    LR 0.001298    Time 0.094920    
2024-02-19 18:33:09,153 - --- validate (epoch=216)-----------
2024-02-19 18:33:09,153 - 10000 samples (128 per mini-batch)
2024-02-19 18:33:12,051 - Epoch: [216][   79/   79]    Loss 1.377028    Top1 66.540000    Top5 89.910000    
2024-02-19 18:33:12,236 - ==> Top1: 66.540    Top5: 89.910    Loss: 1.377

2024-02-19 18:33:12,255 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:33:12,255 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:33:12,331 - 

2024-02-19 18:33:12,331 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:33:22,358 - Epoch: [217][  100/  391]    Overall Loss 0.147664    Objective Loss 0.147664                                        LR 0.001298    Time 0.100198    
2024-02-19 18:33:31,722 - Epoch: [217][  200/  391]    Overall Loss 0.148356    Objective Loss 0.148356                                        LR 0.001298    Time 0.096894    
2024-02-19 18:33:41,087 - Epoch: [217][  300/  391]    Overall Loss 0.148729    Objective Loss 0.148729                                        LR 0.001298    Time 0.095800    
2024-02-19 18:33:49,633 - Epoch: [217][  391/  391]    Overall Loss 0.149557    Objective Loss 0.149557    Top1 96.153846    Top5 99.519231    LR 0.001298    Time 0.095349    
2024-02-19 18:33:49,869 - --- validate (epoch=217)-----------
2024-02-19 18:33:49,869 - 10000 samples (128 per mini-batch)
2024-02-19 18:33:52,651 - Epoch: [217][   79/   79]    Loss 1.379279    Top1 66.840000    Top5 89.840000    
2024-02-19 18:33:52,874 - ==> Top1: 66.840    Top5: 89.840    Loss: 1.379

2024-02-19 18:33:52,894 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:33:52,895 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:33:52,970 - 

2024-02-19 18:33:52,970 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:34:03,261 - Epoch: [218][  100/  391]    Overall Loss 0.147394    Objective Loss 0.147394                                        LR 0.001298    Time 0.102840    
2024-02-19 18:34:12,674 - Epoch: [218][  200/  391]    Overall Loss 0.147511    Objective Loss 0.147511                                        LR 0.001298    Time 0.098461    
2024-02-19 18:34:22,209 - Epoch: [218][  300/  391]    Overall Loss 0.151274    Objective Loss 0.151274                                        LR 0.001298    Time 0.097409    
2024-02-19 18:34:30,777 - Epoch: [218][  391/  391]    Overall Loss 0.151410    Objective Loss 0.151410    Top1 97.596154    Top5 100.000000    LR 0.001298    Time 0.096643    
2024-02-19 18:34:31,003 - --- validate (epoch=218)-----------
2024-02-19 18:34:31,004 - 10000 samples (128 per mini-batch)
2024-02-19 18:34:33,578 - Epoch: [218][   79/   79]    Loss 1.369876    Top1 66.910000    Top5 89.930000    
2024-02-19 18:34:33,791 - ==> Top1: 66.910    Top5: 89.930    Loss: 1.370

2024-02-19 18:34:33,811 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:34:33,811 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:34:33,885 - 

2024-02-19 18:34:33,885 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:34:43,790 - Epoch: [219][  100/  391]    Overall Loss 0.143986    Objective Loss 0.143986                                        LR 0.001298    Time 0.098980    
2024-02-19 18:34:53,144 - Epoch: [219][  200/  391]    Overall Loss 0.146977    Objective Loss 0.146977                                        LR 0.001298    Time 0.096234    
2024-02-19 18:35:02,188 - Epoch: [219][  300/  391]    Overall Loss 0.148151    Objective Loss 0.148151                                        LR 0.001298    Time 0.094290    
2024-02-19 18:35:08,637 - Epoch: [219][  391/  391]    Overall Loss 0.148722    Objective Loss 0.148722    Top1 96.634615    Top5 100.000000    LR 0.001298    Time 0.088831    
2024-02-19 18:35:08,866 - --- validate (epoch=219)-----------
2024-02-19 18:35:08,867 - 10000 samples (128 per mini-batch)
2024-02-19 18:35:11,532 - Epoch: [219][   79/   79]    Loss 1.376188    Top1 66.590000    Top5 90.080000    
2024-02-19 18:35:11,714 - ==> Top1: 66.590    Top5: 90.080    Loss: 1.376

2024-02-19 18:35:11,732 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:35:11,732 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:35:11,805 - 

2024-02-19 18:35:11,805 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:35:22,000 - Epoch: [220][  100/  391]    Overall Loss 0.143094    Objective Loss 0.143094                                        LR 0.001298    Time 0.101881    
2024-02-19 18:35:31,358 - Epoch: [220][  200/  391]    Overall Loss 0.145498    Objective Loss 0.145498                                        LR 0.001298    Time 0.097707    
2024-02-19 18:35:40,789 - Epoch: [220][  300/  391]    Overall Loss 0.145782    Objective Loss 0.145782                                        LR 0.001298    Time 0.096563    
2024-02-19 18:35:49,296 - Epoch: [220][  391/  391]    Overall Loss 0.147074    Objective Loss 0.147074    Top1 95.192308    Top5 100.000000    LR 0.001298    Time 0.095835    
2024-02-19 18:35:49,510 - --- validate (epoch=220)-----------
2024-02-19 18:35:49,511 - 10000 samples (128 per mini-batch)
2024-02-19 18:35:52,199 - Epoch: [220][   79/   79]    Loss 1.374460    Top1 66.980000    Top5 90.100000    
2024-02-19 18:35:52,350 - ==> Top1: 66.980    Top5: 90.100    Loss: 1.374

2024-02-19 18:35:52,371 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:35:52,371 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:35:52,446 - 

2024-02-19 18:35:52,446 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:36:02,451 - Epoch: [221][  100/  391]    Overall Loss 0.146073    Objective Loss 0.146073                                        LR 0.001298    Time 0.099977    
2024-02-19 18:36:11,881 - Epoch: [221][  200/  391]    Overall Loss 0.148283    Objective Loss 0.148283                                        LR 0.001298    Time 0.097118    
2024-02-19 18:36:21,299 - Epoch: [221][  300/  391]    Overall Loss 0.147773    Objective Loss 0.147773                                        LR 0.001298    Time 0.096126    
2024-02-19 18:36:29,904 - Epoch: [221][  391/  391]    Overall Loss 0.148147    Objective Loss 0.148147    Top1 97.115385    Top5 100.000000    LR 0.001298    Time 0.095751    
2024-02-19 18:36:30,122 - --- validate (epoch=221)-----------
2024-02-19 18:36:30,123 - 10000 samples (128 per mini-batch)
2024-02-19 18:36:32,742 - Epoch: [221][   79/   79]    Loss 1.383237    Top1 66.900000    Top5 89.980000    
2024-02-19 18:36:32,939 - ==> Top1: 66.900    Top5: 89.980    Loss: 1.383

2024-02-19 18:36:32,957 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:36:32,957 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:36:33,031 - 

2024-02-19 18:36:33,031 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:36:43,296 - Epoch: [222][  100/  391]    Overall Loss 0.142599    Objective Loss 0.142599                                        LR 0.001298    Time 0.102583    
2024-02-19 18:36:52,783 - Epoch: [222][  200/  391]    Overall Loss 0.144419    Objective Loss 0.144419                                        LR 0.001298    Time 0.098706    
2024-02-19 18:37:02,218 - Epoch: [222][  300/  391]    Overall Loss 0.144706    Objective Loss 0.144706                                        LR 0.001298    Time 0.097239    
2024-02-19 18:37:10,699 - Epoch: [222][  391/  391]    Overall Loss 0.144844    Objective Loss 0.144844    Top1 96.153846    Top5 100.000000    LR 0.001298    Time 0.096288    
2024-02-19 18:37:10,955 - --- validate (epoch=222)-----------
2024-02-19 18:37:10,956 - 10000 samples (128 per mini-batch)
2024-02-19 18:37:13,613 - Epoch: [222][   79/   79]    Loss 1.372245    Top1 66.910000    Top5 90.000000    
2024-02-19 18:37:13,791 - ==> Top1: 66.910    Top5: 90.000    Loss: 1.372

2024-02-19 18:37:13,810 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:37:13,811 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:37:13,885 - 

2024-02-19 18:37:13,885 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:37:23,895 - Epoch: [223][  100/  391]    Overall Loss 0.134601    Objective Loss 0.134601                                        LR 0.001298    Time 0.100028    
2024-02-19 18:37:33,339 - Epoch: [223][  200/  391]    Overall Loss 0.139244    Objective Loss 0.139244                                        LR 0.001298    Time 0.097212    
2024-02-19 18:37:42,721 - Epoch: [223][  300/  391]    Overall Loss 0.143443    Objective Loss 0.143443                                        LR 0.001298    Time 0.096066    
2024-02-19 18:37:51,200 - Epoch: [223][  391/  391]    Overall Loss 0.144069    Objective Loss 0.144069    Top1 96.634615    Top5 100.000000    LR 0.001298    Time 0.095385    
2024-02-19 18:37:51,495 - --- validate (epoch=223)-----------
2024-02-19 18:37:51,496 - 10000 samples (128 per mini-batch)
2024-02-19 18:37:54,056 - Epoch: [223][   79/   79]    Loss 1.389580    Top1 66.780000    Top5 90.050000    
2024-02-19 18:37:54,197 - ==> Top1: 66.780    Top5: 90.050    Loss: 1.390

2024-02-19 18:37:54,211 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:37:54,211 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:37:54,269 - 

2024-02-19 18:37:54,269 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:38:04,017 - Epoch: [224][  100/  391]    Overall Loss 0.138409    Objective Loss 0.138409                                        LR 0.001298    Time 0.097424    
2024-02-19 18:38:13,377 - Epoch: [224][  200/  391]    Overall Loss 0.141739    Objective Loss 0.141739                                        LR 0.001298    Time 0.095493    
2024-02-19 18:38:22,787 - Epoch: [224][  300/  391]    Overall Loss 0.145121    Objective Loss 0.145121                                        LR 0.001298    Time 0.095013    
2024-02-19 18:38:31,289 - Epoch: [224][  391/  391]    Overall Loss 0.145562    Objective Loss 0.145562    Top1 95.192308    Top5 100.000000    LR 0.001298    Time 0.094634    
2024-02-19 18:38:31,513 - --- validate (epoch=224)-----------
2024-02-19 18:38:31,514 - 10000 samples (128 per mini-batch)
2024-02-19 18:38:34,087 - Epoch: [224][   79/   79]    Loss 1.386814    Top1 66.820000    Top5 89.950000    
2024-02-19 18:38:34,276 - ==> Top1: 66.820    Top5: 89.950    Loss: 1.387

2024-02-19 18:38:34,295 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:38:34,295 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:38:34,369 - 

2024-02-19 18:38:34,369 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:38:44,263 - Epoch: [225][  100/  391]    Overall Loss 0.146236    Objective Loss 0.146236                                        LR 0.001298    Time 0.098868    
2024-02-19 18:38:53,462 - Epoch: [225][  200/  391]    Overall Loss 0.145882    Objective Loss 0.145882                                        LR 0.001298    Time 0.095413    
2024-02-19 18:39:02,666 - Epoch: [225][  300/  391]    Overall Loss 0.145107    Objective Loss 0.145107                                        LR 0.001298    Time 0.094274    
2024-02-19 18:39:11,068 - Epoch: [225][  391/  391]    Overall Loss 0.145612    Objective Loss 0.145612    Top1 95.192308    Top5 100.000000    LR 0.001298    Time 0.093812    
2024-02-19 18:39:11,300 - --- validate (epoch=225)-----------
2024-02-19 18:39:11,301 - 10000 samples (128 per mini-batch)
2024-02-19 18:39:13,939 - Epoch: [225][   79/   79]    Loss 1.391739    Top1 66.650000    Top5 90.010000    
2024-02-19 18:39:14,139 - ==> Top1: 66.650    Top5: 90.010    Loss: 1.392

2024-02-19 18:39:14,158 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:39:14,159 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:39:14,231 - 

2024-02-19 18:39:14,232 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:39:24,021 - Epoch: [226][  100/  391]    Overall Loss 0.140431    Objective Loss 0.140431                                        LR 0.001298    Time 0.097821    
2024-02-19 18:39:33,215 - Epoch: [226][  200/  391]    Overall Loss 0.142976    Objective Loss 0.142976                                        LR 0.001298    Time 0.094864    
2024-02-19 18:39:42,407 - Epoch: [226][  300/  391]    Overall Loss 0.142684    Objective Loss 0.142684                                        LR 0.001298    Time 0.093870    
2024-02-19 18:39:50,809 - Epoch: [226][  391/  391]    Overall Loss 0.142966    Objective Loss 0.142966    Top1 95.673077    Top5 100.000000    LR 0.001298    Time 0.093501    
2024-02-19 18:39:51,116 - --- validate (epoch=226)-----------
2024-02-19 18:39:51,117 - 10000 samples (128 per mini-batch)
2024-02-19 18:39:53,792 - Epoch: [226][   79/   79]    Loss 1.384082    Top1 66.660000    Top5 89.920000    
2024-02-19 18:39:53,971 - ==> Top1: 66.660    Top5: 89.920    Loss: 1.384

2024-02-19 18:39:53,989 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:39:53,989 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:39:54,062 - 

2024-02-19 18:39:54,063 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:40:04,147 - Epoch: [227][  100/  391]    Overall Loss 0.143072    Objective Loss 0.143072                                        LR 0.001298    Time 0.100772    
2024-02-19 18:40:13,344 - Epoch: [227][  200/  391]    Overall Loss 0.140350    Objective Loss 0.140350                                        LR 0.001298    Time 0.096352    
2024-02-19 18:40:22,545 - Epoch: [227][  300/  391]    Overall Loss 0.142039    Objective Loss 0.142039                                        LR 0.001298    Time 0.094892    
2024-02-19 18:40:30,926 - Epoch: [227][  391/  391]    Overall Loss 0.143566    Objective Loss 0.143566    Top1 97.596154    Top5 100.000000    LR 0.001298    Time 0.094233    
2024-02-19 18:40:31,112 - --- validate (epoch=227)-----------
2024-02-19 18:40:31,113 - 10000 samples (128 per mini-batch)
2024-02-19 18:40:33,887 - Epoch: [227][   79/   79]    Loss 1.380139    Top1 67.120000    Top5 89.860000    
2024-02-19 18:40:34,047 - ==> Top1: 67.120    Top5: 89.860    Loss: 1.380

2024-02-19 18:40:34,065 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:40:34,065 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:40:34,138 - 

2024-02-19 18:40:34,138 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:40:43,738 - Epoch: [228][  100/  391]    Overall Loss 0.138481    Objective Loss 0.138481                                        LR 0.001298    Time 0.095935    
2024-02-19 18:40:52,877 - Epoch: [228][  200/  391]    Overall Loss 0.138423    Objective Loss 0.138423                                        LR 0.001298    Time 0.093641    
2024-02-19 18:41:02,098 - Epoch: [228][  300/  391]    Overall Loss 0.142423    Objective Loss 0.142423                                        LR 0.001298    Time 0.093151    
2024-02-19 18:41:10,504 - Epoch: [228][  391/  391]    Overall Loss 0.143934    Objective Loss 0.143934    Top1 97.596154    Top5 100.000000    LR 0.001298    Time 0.092959    
2024-02-19 18:41:10,727 - --- validate (epoch=228)-----------
2024-02-19 18:41:10,728 - 10000 samples (128 per mini-batch)
2024-02-19 18:41:13,629 - Epoch: [228][   79/   79]    Loss 1.403813    Top1 66.930000    Top5 89.980000    
2024-02-19 18:41:13,811 - ==> Top1: 66.930    Top5: 89.980    Loss: 1.404

2024-02-19 18:41:13,828 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:41:13,828 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:41:13,902 - 

2024-02-19 18:41:13,902 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:41:23,176 - Epoch: [229][  100/  391]    Overall Loss 0.137874    Objective Loss 0.137874                                        LR 0.001298    Time 0.092665    
2024-02-19 18:41:32,304 - Epoch: [229][  200/  391]    Overall Loss 0.141269    Objective Loss 0.141269                                        LR 0.001298    Time 0.091954    
2024-02-19 18:41:41,526 - Epoch: [229][  300/  391]    Overall Loss 0.142221    Objective Loss 0.142221                                        LR 0.001298    Time 0.092028    
2024-02-19 18:41:49,931 - Epoch: [229][  391/  391]    Overall Loss 0.142502    Objective Loss 0.142502    Top1 98.076923    Top5 100.000000    LR 0.001298    Time 0.092096    
2024-02-19 18:41:50,196 - --- validate (epoch=229)-----------
2024-02-19 18:41:50,197 - 10000 samples (128 per mini-batch)
2024-02-19 18:41:52,794 - Epoch: [229][   79/   79]    Loss 1.393058    Top1 66.780000    Top5 89.920000    
2024-02-19 18:41:53,015 - ==> Top1: 66.780    Top5: 89.920    Loss: 1.393

2024-02-19 18:41:53,035 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:41:53,035 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:41:53,110 - 

2024-02-19 18:41:53,110 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:42:03,103 - Epoch: [230][  100/  391]    Overall Loss 0.135615    Objective Loss 0.135615                                        LR 0.001298    Time 0.099868    
2024-02-19 18:42:12,282 - Epoch: [230][  200/  391]    Overall Loss 0.135953    Objective Loss 0.135953                                        LR 0.001298    Time 0.095806    
2024-02-19 18:42:21,497 - Epoch: [230][  300/  391]    Overall Loss 0.140480    Objective Loss 0.140480                                        LR 0.001298    Time 0.094574    
2024-02-19 18:42:29,883 - Epoch: [230][  391/  391]    Overall Loss 0.142514    Objective Loss 0.142514    Top1 96.634615    Top5 100.000000    LR 0.001298    Time 0.094002    
2024-02-19 18:42:30,134 - --- validate (epoch=230)-----------
2024-02-19 18:42:30,135 - 10000 samples (128 per mini-batch)
2024-02-19 18:42:32,865 - Epoch: [230][   79/   79]    Loss 1.399605    Top1 66.740000    Top5 90.010000    
2024-02-19 18:42:33,117 - ==> Top1: 66.740    Top5: 90.010    Loss: 1.400

2024-02-19 18:42:33,138 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:42:33,138 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:42:33,214 - 

2024-02-19 18:42:33,215 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:42:43,081 - Epoch: [231][  100/  391]    Overall Loss 0.135722    Objective Loss 0.135722                                        LR 0.001298    Time 0.098581    
2024-02-19 18:42:52,224 - Epoch: [231][  200/  391]    Overall Loss 0.137273    Objective Loss 0.137273                                        LR 0.001298    Time 0.094987    
2024-02-19 18:43:01,404 - Epoch: [231][  300/  391]    Overall Loss 0.139452    Objective Loss 0.139452                                        LR 0.001298    Time 0.093909    
2024-02-19 18:43:09,784 - Epoch: [231][  391/  391]    Overall Loss 0.138818    Objective Loss 0.138818    Top1 98.076923    Top5 100.000000    LR 0.001298    Time 0.093477    
2024-02-19 18:43:10,112 - --- validate (epoch=231)-----------
2024-02-19 18:43:10,113 - 10000 samples (128 per mini-batch)
2024-02-19 18:43:12,965 - Epoch: [231][   79/   79]    Loss 1.388866    Top1 66.820000    Top5 89.990000    
2024-02-19 18:43:13,136 - ==> Top1: 66.820    Top5: 89.990    Loss: 1.389

2024-02-19 18:43:13,156 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:43:13,156 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:43:13,231 - 

2024-02-19 18:43:13,232 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:43:23,255 - Epoch: [232][  100/  391]    Overall Loss 0.139538    Objective Loss 0.139538                                        LR 0.001298    Time 0.100164    
2024-02-19 18:43:32,459 - Epoch: [232][  200/  391]    Overall Loss 0.136050    Objective Loss 0.136050                                        LR 0.001298    Time 0.096080    
2024-02-19 18:43:41,653 - Epoch: [232][  300/  391]    Overall Loss 0.137587    Objective Loss 0.137587                                        LR 0.001298    Time 0.094686    
2024-02-19 18:43:50,082 - Epoch: [232][  391/  391]    Overall Loss 0.138449    Objective Loss 0.138449    Top1 97.596154    Top5 100.000000    LR 0.001298    Time 0.094198    
2024-02-19 18:43:50,386 - --- validate (epoch=232)-----------
2024-02-19 18:43:50,387 - 10000 samples (128 per mini-batch)
2024-02-19 18:43:53,109 - Epoch: [232][   79/   79]    Loss 1.391544    Top1 66.850000    Top5 89.940000    
2024-02-19 18:43:53,379 - ==> Top1: 66.850    Top5: 89.940    Loss: 1.392

2024-02-19 18:43:53,398 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:43:53,398 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:43:53,472 - 

2024-02-19 18:43:53,472 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:44:03,265 - Epoch: [233][  100/  391]    Overall Loss 0.142166    Objective Loss 0.142166                                        LR 0.001298    Time 0.097860    
2024-02-19 18:44:12,474 - Epoch: [233][  200/  391]    Overall Loss 0.140023    Objective Loss 0.140023                                        LR 0.001298    Time 0.094953    
2024-02-19 18:44:21,654 - Epoch: [233][  300/  391]    Overall Loss 0.140186    Objective Loss 0.140186                                        LR 0.001298    Time 0.093888    
2024-02-19 18:44:30,007 - Epoch: [233][  391/  391]    Overall Loss 0.141046    Objective Loss 0.141046    Top1 95.192308    Top5 100.000000    LR 0.001298    Time 0.093391    
2024-02-19 18:44:30,287 - --- validate (epoch=233)-----------
2024-02-19 18:44:30,288 - 10000 samples (128 per mini-batch)
2024-02-19 18:44:32,957 - Epoch: [233][   79/   79]    Loss 1.406705    Top1 66.780000    Top5 89.850000    
2024-02-19 18:44:33,157 - ==> Top1: 66.780    Top5: 89.850    Loss: 1.407

2024-02-19 18:44:33,176 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:44:33,176 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:44:33,250 - 

2024-02-19 18:44:33,251 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:44:43,294 - Epoch: [234][  100/  391]    Overall Loss 0.133097    Objective Loss 0.133097                                        LR 0.001298    Time 0.100367    
2024-02-19 18:44:52,521 - Epoch: [234][  200/  391]    Overall Loss 0.135117    Objective Loss 0.135117                                        LR 0.001298    Time 0.096299    
2024-02-19 18:45:01,719 - Epoch: [234][  300/  391]    Overall Loss 0.136510    Objective Loss 0.136510                                        LR 0.001298    Time 0.094845    
2024-02-19 18:45:09,990 - Epoch: [234][  391/  391]    Overall Loss 0.136712    Objective Loss 0.136712    Top1 95.673077    Top5 100.000000    LR 0.001298    Time 0.093917    
2024-02-19 18:45:10,195 - --- validate (epoch=234)-----------
2024-02-19 18:45:10,196 - 10000 samples (128 per mini-batch)
2024-02-19 18:45:12,858 - Epoch: [234][   79/   79]    Loss 1.394308    Top1 66.690000    Top5 89.850000    
2024-02-19 18:45:13,076 - ==> Top1: 66.690    Top5: 89.850    Loss: 1.394

2024-02-19 18:45:13,095 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:45:13,095 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:45:13,169 - 

2024-02-19 18:45:13,169 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:45:22,961 - Epoch: [235][  100/  391]    Overall Loss 0.137240    Objective Loss 0.137240                                        LR 0.001298    Time 0.097843    
2024-02-19 18:45:32,160 - Epoch: [235][  200/  391]    Overall Loss 0.136091    Objective Loss 0.136091                                        LR 0.001298    Time 0.094897    
2024-02-19 18:45:41,346 - Epoch: [235][  300/  391]    Overall Loss 0.136229    Objective Loss 0.136229                                        LR 0.001298    Time 0.093871    
2024-02-19 18:45:48,955 - Epoch: [235][  391/  391]    Overall Loss 0.138243    Objective Loss 0.138243    Top1 96.634615    Top5 99.519231    LR 0.001298    Time 0.091475    
2024-02-19 18:45:49,172 - --- validate (epoch=235)-----------
2024-02-19 18:45:49,173 - 10000 samples (128 per mini-batch)
2024-02-19 18:45:51,774 - Epoch: [235][   79/   79]    Loss 1.407217    Top1 66.770000    Top5 89.810000    
2024-02-19 18:45:51,963 - ==> Top1: 66.770    Top5: 89.810    Loss: 1.407

2024-02-19 18:45:51,982 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:45:51,982 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:45:52,056 - 

2024-02-19 18:45:52,056 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:46:01,867 - Epoch: [236][  100/  391]    Overall Loss 0.135627    Objective Loss 0.135627                                        LR 0.001298    Time 0.098044    
2024-02-19 18:46:11,072 - Epoch: [236][  200/  391]    Overall Loss 0.136305    Objective Loss 0.136305                                        LR 0.001298    Time 0.095023    
2024-02-19 18:46:20,261 - Epoch: [236][  300/  391]    Overall Loss 0.136108    Objective Loss 0.136108                                        LR 0.001298    Time 0.093967    
2024-02-19 18:46:28,698 - Epoch: [236][  391/  391]    Overall Loss 0.137823    Objective Loss 0.137823    Top1 97.115385    Top5 100.000000    LR 0.001298    Time 0.093665    
2024-02-19 18:46:28,928 - --- validate (epoch=236)-----------
2024-02-19 18:46:28,929 - 10000 samples (128 per mini-batch)
2024-02-19 18:46:31,846 - Epoch: [236][   79/   79]    Loss 1.390950    Top1 66.820000    Top5 89.900000    
2024-02-19 18:46:32,024 - ==> Top1: 66.820    Top5: 89.900    Loss: 1.391

2024-02-19 18:46:32,043 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:46:32,043 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:46:32,117 - 

2024-02-19 18:46:32,117 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:46:41,888 - Epoch: [237][  100/  391]    Overall Loss 0.137009    Objective Loss 0.137009                                        LR 0.001298    Time 0.097638    
2024-02-19 18:46:51,062 - Epoch: [237][  200/  391]    Overall Loss 0.137780    Objective Loss 0.137780                                        LR 0.001298    Time 0.094670    
2024-02-19 18:47:00,265 - Epoch: [237][  300/  391]    Overall Loss 0.137773    Objective Loss 0.137773                                        LR 0.001298    Time 0.093776    
2024-02-19 18:47:08,621 - Epoch: [237][  391/  391]    Overall Loss 0.137013    Objective Loss 0.137013    Top1 97.596154    Top5 100.000000    LR 0.001298    Time 0.093314    
2024-02-19 18:47:08,855 - --- validate (epoch=237)-----------
2024-02-19 18:47:08,856 - 10000 samples (128 per mini-batch)
2024-02-19 18:47:11,480 - Epoch: [237][   79/   79]    Loss 1.390644    Top1 67.080000    Top5 89.720000    
2024-02-19 18:47:11,679 - ==> Top1: 67.080    Top5: 89.720    Loss: 1.391

2024-02-19 18:47:11,700 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:47:11,700 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:47:11,774 - 

2024-02-19 18:47:11,774 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:47:21,556 - Epoch: [238][  100/  391]    Overall Loss 0.133302    Objective Loss 0.133302                                        LR 0.001298    Time 0.097754    
2024-02-19 18:47:30,758 - Epoch: [238][  200/  391]    Overall Loss 0.135627    Objective Loss 0.135627                                        LR 0.001298    Time 0.094869    
2024-02-19 18:47:39,977 - Epoch: [238][  300/  391]    Overall Loss 0.134966    Objective Loss 0.134966                                        LR 0.001298    Time 0.093963    
2024-02-19 18:47:48,232 - Epoch: [238][  391/  391]    Overall Loss 0.136560    Objective Loss 0.136560    Top1 97.115385    Top5 100.000000    LR 0.001298    Time 0.093196    
2024-02-19 18:47:48,462 - --- validate (epoch=238)-----------
2024-02-19 18:47:48,463 - 10000 samples (128 per mini-batch)
2024-02-19 18:47:51,351 - Epoch: [238][   79/   79]    Loss 1.396066    Top1 66.610000    Top5 89.800000    
2024-02-19 18:47:51,523 - ==> Top1: 66.610    Top5: 89.800    Loss: 1.396

2024-02-19 18:47:51,542 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:47:51,542 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:47:51,615 - 

2024-02-19 18:47:51,615 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:48:01,391 - Epoch: [239][  100/  391]    Overall Loss 0.131071    Objective Loss 0.131071                                        LR 0.001298    Time 0.097688    
2024-02-19 18:48:10,589 - Epoch: [239][  200/  391]    Overall Loss 0.132161    Objective Loss 0.132161                                        LR 0.001298    Time 0.094812    
2024-02-19 18:48:19,802 - Epoch: [239][  300/  391]    Overall Loss 0.134908    Objective Loss 0.134908                                        LR 0.001298    Time 0.093905    
2024-02-19 18:48:28,191 - Epoch: [239][  391/  391]    Overall Loss 0.135107    Objective Loss 0.135107    Top1 95.673077    Top5 100.000000    LR 0.001298    Time 0.093497    
2024-02-19 18:48:28,509 - --- validate (epoch=239)-----------
2024-02-19 18:48:28,510 - 10000 samples (128 per mini-batch)
2024-02-19 18:48:31,187 - Epoch: [239][   79/   79]    Loss 1.413447    Top1 66.750000    Top5 89.830000    
2024-02-19 18:48:31,397 - ==> Top1: 66.750    Top5: 89.830    Loss: 1.413

2024-02-19 18:48:31,416 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:48:31,416 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:48:31,476 - 

2024-02-19 18:48:31,476 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:48:40,898 - Epoch: [240][  100/  391]    Overall Loss 0.134128    Objective Loss 0.134128                                        LR 0.001298    Time 0.094159    
2024-02-19 18:48:50,133 - Epoch: [240][  200/  391]    Overall Loss 0.135726    Objective Loss 0.135726                                        LR 0.001298    Time 0.093230    
2024-02-19 18:48:59,474 - Epoch: [240][  300/  391]    Overall Loss 0.137159    Objective Loss 0.137159                                        LR 0.001298    Time 0.093279    
2024-02-19 18:49:07,973 - Epoch: [240][  391/  391]    Overall Loss 0.136651    Objective Loss 0.136651    Top1 96.634615    Top5 100.000000    LR 0.001298    Time 0.093296    
2024-02-19 18:49:08,218 - --- validate (epoch=240)-----------
2024-02-19 18:49:08,219 - 10000 samples (128 per mini-batch)
2024-02-19 18:49:10,913 - Epoch: [240][   79/   79]    Loss 1.391636    Top1 66.910000    Top5 89.780000    
2024-02-19 18:49:11,097 - ==> Top1: 66.910    Top5: 89.780    Loss: 1.392

2024-02-19 18:49:11,116 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:49:11,116 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:49:11,190 - 

2024-02-19 18:49:11,190 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:49:20,945 - Epoch: [241][  100/  391]    Overall Loss 0.132998    Objective Loss 0.132998                                        LR 0.001298    Time 0.097478    
2024-02-19 18:49:30,133 - Epoch: [241][  200/  391]    Overall Loss 0.133689    Objective Loss 0.133689                                        LR 0.001298    Time 0.094657    
2024-02-19 18:49:39,350 - Epoch: [241][  300/  391]    Overall Loss 0.135947    Objective Loss 0.135947                                        LR 0.001298    Time 0.093817    
2024-02-19 18:49:47,794 - Epoch: [241][  391/  391]    Overall Loss 0.136871    Objective Loss 0.136871    Top1 96.153846    Top5 100.000000    LR 0.001298    Time 0.093568    
2024-02-19 18:49:48,002 - --- validate (epoch=241)-----------
2024-02-19 18:49:48,003 - 10000 samples (128 per mini-batch)
2024-02-19 18:49:50,659 - Epoch: [241][   79/   79]    Loss 1.405901    Top1 66.990000    Top5 89.900000    
2024-02-19 18:49:50,811 - ==> Top1: 66.990    Top5: 89.900    Loss: 1.406

2024-02-19 18:49:50,822 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:49:50,823 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:49:50,896 - 

2024-02-19 18:49:50,896 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:50:00,951 - Epoch: [242][  100/  391]    Overall Loss 0.133612    Objective Loss 0.133612                                        LR 0.001298    Time 0.100484    
2024-02-19 18:50:10,166 - Epoch: [242][  200/  391]    Overall Loss 0.136332    Objective Loss 0.136332                                        LR 0.001298    Time 0.096298    
2024-02-19 18:50:19,409 - Epoch: [242][  300/  391]    Overall Loss 0.137900    Objective Loss 0.137900                                        LR 0.001298    Time 0.094992    
2024-02-19 18:50:27,805 - Epoch: [242][  391/  391]    Overall Loss 0.137970    Objective Loss 0.137970    Top1 96.153846    Top5 100.000000    LR 0.001298    Time 0.094349    
2024-02-19 18:50:28,114 - --- validate (epoch=242)-----------
2024-02-19 18:50:28,115 - 10000 samples (128 per mini-batch)
2024-02-19 18:50:30,751 - Epoch: [242][   79/   79]    Loss 1.401598    Top1 66.580000    Top5 89.920000    
2024-02-19 18:50:30,910 - ==> Top1: 66.580    Top5: 89.920    Loss: 1.402

2024-02-19 18:50:30,930 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:50:30,930 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:50:31,003 - 

2024-02-19 18:50:31,004 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:50:40,779 - Epoch: [243][  100/  391]    Overall Loss 0.132455    Objective Loss 0.132455                                        LR 0.001298    Time 0.097686    
2024-02-19 18:50:49,981 - Epoch: [243][  200/  391]    Overall Loss 0.135444    Objective Loss 0.135444                                        LR 0.001298    Time 0.094833    
2024-02-19 18:50:59,210 - Epoch: [243][  300/  391]    Overall Loss 0.137772    Objective Loss 0.137772                                        LR 0.001298    Time 0.093971    
2024-02-19 18:51:07,634 - Epoch: [243][  391/  391]    Overall Loss 0.136859    Objective Loss 0.136859    Top1 98.076923    Top5 100.000000    LR 0.001298    Time 0.093637    
2024-02-19 18:51:07,831 - --- validate (epoch=243)-----------
2024-02-19 18:51:07,832 - 10000 samples (128 per mini-batch)
2024-02-19 18:51:10,592 - Epoch: [243][   79/   79]    Loss 1.416741    Top1 66.530000    Top5 89.810000    
2024-02-19 18:51:10,786 - ==> Top1: 66.530    Top5: 89.810    Loss: 1.417

2024-02-19 18:51:10,805 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:51:10,806 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:51:10,880 - 

2024-02-19 18:51:10,880 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:51:20,907 - Epoch: [244][  100/  391]    Overall Loss 0.128695    Objective Loss 0.128695                                        LR 0.001298    Time 0.100199    
2024-02-19 18:51:30,109 - Epoch: [244][  200/  391]    Overall Loss 0.134409    Objective Loss 0.134409                                        LR 0.001298    Time 0.096090    
2024-02-19 18:51:39,418 - Epoch: [244][  300/  391]    Overall Loss 0.134102    Objective Loss 0.134102                                        LR 0.001298    Time 0.095077    
2024-02-19 18:51:47,852 - Epoch: [244][  391/  391]    Overall Loss 0.133803    Objective Loss 0.133803    Top1 96.153846    Top5 100.000000    LR 0.001298    Time 0.094511    
2024-02-19 18:51:48,163 - --- validate (epoch=244)-----------
2024-02-19 18:51:48,164 - 10000 samples (128 per mini-batch)
2024-02-19 18:51:51,002 - Epoch: [244][   79/   79]    Loss 1.412404    Top1 66.590000    Top5 89.900000    
2024-02-19 18:51:51,302 - ==> Top1: 66.590    Top5: 89.900    Loss: 1.412

2024-02-19 18:51:51,320 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:51:51,320 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:51:51,395 - 

2024-02-19 18:51:51,395 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:52:01,042 - Epoch: [245][  100/  391]    Overall Loss 0.132929    Objective Loss 0.132929                                        LR 0.001298    Time 0.096396    
2024-02-19 18:52:10,300 - Epoch: [245][  200/  391]    Overall Loss 0.135560    Objective Loss 0.135560                                        LR 0.001298    Time 0.094467    
2024-02-19 18:52:19,580 - Epoch: [245][  300/  391]    Overall Loss 0.135624    Objective Loss 0.135624                                        LR 0.001298    Time 0.093899    
2024-02-19 18:52:27,993 - Epoch: [245][  391/  391]    Overall Loss 0.134703    Objective Loss 0.134703    Top1 96.153846    Top5 100.000000    LR 0.001298    Time 0.093550    
2024-02-19 18:52:28,228 - --- validate (epoch=245)-----------
2024-02-19 18:52:28,229 - 10000 samples (128 per mini-batch)
2024-02-19 18:52:30,952 - Epoch: [245][   79/   79]    Loss 1.402414    Top1 66.760000    Top5 89.790000    
2024-02-19 18:52:31,119 - ==> Top1: 66.760    Top5: 89.790    Loss: 1.402

2024-02-19 18:52:31,138 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:52:31,138 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:52:31,212 - 

2024-02-19 18:52:31,212 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:52:41,016 - Epoch: [246][  100/  391]    Overall Loss 0.130684    Objective Loss 0.130684                                        LR 0.001298    Time 0.097972    
2024-02-19 18:52:50,232 - Epoch: [246][  200/  391]    Overall Loss 0.129410    Objective Loss 0.129410                                        LR 0.001298    Time 0.095043    
2024-02-19 18:52:59,501 - Epoch: [246][  300/  391]    Overall Loss 0.128509    Objective Loss 0.128509                                        LR 0.001298    Time 0.094245    
2024-02-19 18:53:07,893 - Epoch: [246][  391/  391]    Overall Loss 0.128682    Objective Loss 0.128682    Top1 97.596154    Top5 100.000000    LR 0.001298    Time 0.093763    
2024-02-19 18:53:08,237 - --- validate (epoch=246)-----------
2024-02-19 18:53:08,238 - 10000 samples (128 per mini-batch)
2024-02-19 18:53:10,966 - Epoch: [246][   79/   79]    Loss 1.405661    Top1 66.500000    Top5 89.870000    
2024-02-19 18:53:11,260 - ==> Top1: 66.500    Top5: 89.870    Loss: 1.406

2024-02-19 18:53:11,279 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:53:11,280 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:53:11,357 - 

2024-02-19 18:53:11,357 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:53:21,375 - Epoch: [247][  100/  391]    Overall Loss 0.131753    Objective Loss 0.131753                                        LR 0.001298    Time 0.100109    
2024-02-19 18:53:30,575 - Epoch: [247][  200/  391]    Overall Loss 0.132942    Objective Loss 0.132942                                        LR 0.001298    Time 0.096037    
2024-02-19 18:53:39,765 - Epoch: [247][  300/  391]    Overall Loss 0.135204    Objective Loss 0.135204                                        LR 0.001298    Time 0.094644    
2024-02-19 18:53:48,190 - Epoch: [247][  391/  391]    Overall Loss 0.135415    Objective Loss 0.135415    Top1 97.596154    Top5 99.519231    LR 0.001298    Time 0.094154    
2024-02-19 18:53:48,394 - --- validate (epoch=247)-----------
2024-02-19 18:53:48,395 - 10000 samples (128 per mini-batch)
2024-02-19 18:53:51,071 - Epoch: [247][   79/   79]    Loss 1.406361    Top1 66.590000    Top5 89.970000    
2024-02-19 18:53:51,271 - ==> Top1: 66.590    Top5: 89.970    Loss: 1.406

2024-02-19 18:53:51,292 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:53:51,293 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:53:51,366 - 

2024-02-19 18:53:51,366 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:54:01,175 - Epoch: [248][  100/  391]    Overall Loss 0.133819    Objective Loss 0.133819                                        LR 0.001298    Time 0.098020    
2024-02-19 18:54:10,474 - Epoch: [248][  200/  391]    Overall Loss 0.132542    Objective Loss 0.132542                                        LR 0.001298    Time 0.095482    
2024-02-19 18:54:19,703 - Epoch: [248][  300/  391]    Overall Loss 0.133138    Objective Loss 0.133138                                        LR 0.001298    Time 0.094386    
2024-02-19 18:54:28,102 - Epoch: [248][  391/  391]    Overall Loss 0.133892    Objective Loss 0.133892    Top1 98.557692    Top5 100.000000    LR 0.001298    Time 0.093891    
2024-02-19 18:54:28,316 - --- validate (epoch=248)-----------
2024-02-19 18:54:28,317 - 10000 samples (128 per mini-batch)
2024-02-19 18:54:31,159 - Epoch: [248][   79/   79]    Loss 1.405180    Top1 66.780000    Top5 89.820000    
2024-02-19 18:54:31,332 - ==> Top1: 66.780    Top5: 89.820    Loss: 1.405

2024-02-19 18:54:31,351 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:54:31,351 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:54:31,423 - 

2024-02-19 18:54:31,424 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:54:38,965 - Epoch: [249][  100/  391]    Overall Loss 0.127269    Objective Loss 0.127269                                        LR 0.001298    Time 0.075348    
2024-02-19 18:54:45,945 - Epoch: [249][  200/  391]    Overall Loss 0.131197    Objective Loss 0.131197                                        LR 0.001298    Time 0.072557    
2024-02-19 18:54:54,262 - Epoch: [249][  300/  391]    Overall Loss 0.131008    Objective Loss 0.131008                                        LR 0.001298    Time 0.076082    
2024-02-19 18:55:02,671 - Epoch: [249][  391/  391]    Overall Loss 0.131530    Objective Loss 0.131530    Top1 97.115385    Top5 100.000000    LR 0.001298    Time 0.079873    
2024-02-19 18:55:02,898 - --- validate (epoch=249)-----------
2024-02-19 18:55:02,899 - 10000 samples (128 per mini-batch)
2024-02-19 18:55:05,706 - Epoch: [249][   79/   79]    Loss 1.419577    Top1 67.060000    Top5 89.890000    
2024-02-19 18:55:05,922 - ==> Top1: 67.060    Top5: 89.890    Loss: 1.420

2024-02-19 18:55:05,940 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:55:05,940 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:55:06,014 - 

2024-02-19 18:55:06,014 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:55:15,864 - Epoch: [250][  100/  391]    Overall Loss 0.130984    Objective Loss 0.130984                                        LR 0.000305    Time 0.098430    
2024-02-19 18:55:25,202 - Epoch: [250][  200/  391]    Overall Loss 0.129739    Objective Loss 0.129739                                        LR 0.000305    Time 0.095886    
2024-02-19 18:55:34,407 - Epoch: [250][  300/  391]    Overall Loss 0.130250    Objective Loss 0.130250                                        LR 0.000305    Time 0.094594    
2024-02-19 18:55:42,796 - Epoch: [250][  391/  391]    Overall Loss 0.129752    Objective Loss 0.129752    Top1 98.557692    Top5 100.000000    LR 0.000305    Time 0.094025    
2024-02-19 18:55:42,977 - --- validate (epoch=250)-----------
2024-02-19 18:55:42,978 - 10000 samples (128 per mini-batch)
2024-02-19 18:55:45,646 - Epoch: [250][   79/   79]    Loss 1.395671    Top1 67.000000    Top5 89.970000    
2024-02-19 18:55:45,884 - ==> Top1: 67.000    Top5: 89.970    Loss: 1.396

2024-02-19 18:55:45,903 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:55:45,903 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:55:45,977 - 

2024-02-19 18:55:45,977 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:55:55,780 - Epoch: [251][  100/  391]    Overall Loss 0.126553    Objective Loss 0.126553                                        LR 0.000305    Time 0.097961    
2024-02-19 18:56:04,973 - Epoch: [251][  200/  391]    Overall Loss 0.126154    Objective Loss 0.126154                                        LR 0.000305    Time 0.094924    
2024-02-19 18:56:14,167 - Epoch: [251][  300/  391]    Overall Loss 0.126359    Objective Loss 0.126359                                        LR 0.000305    Time 0.093917    
2024-02-19 18:56:22,553 - Epoch: [251][  391/  391]    Overall Loss 0.126832    Objective Loss 0.126832    Top1 96.153846    Top5 100.000000    LR 0.000305    Time 0.093497    
2024-02-19 18:56:22,843 - --- validate (epoch=251)-----------
2024-02-19 18:56:22,844 - 10000 samples (128 per mini-batch)
2024-02-19 18:56:25,474 - Epoch: [251][   79/   79]    Loss 1.397730    Top1 67.030000    Top5 89.950000    
2024-02-19 18:56:25,626 - ==> Top1: 67.030    Top5: 89.950    Loss: 1.398

2024-02-19 18:56:25,645 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:56:25,646 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:56:25,720 - 

2024-02-19 18:56:25,720 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:56:35,761 - Epoch: [252][  100/  391]    Overall Loss 0.120232    Objective Loss 0.120232                                        LR 0.000305    Time 0.100337    
2024-02-19 18:56:45,103 - Epoch: [252][  200/  391]    Overall Loss 0.120761    Objective Loss 0.120761                                        LR 0.000305    Time 0.096862    
2024-02-19 18:56:54,303 - Epoch: [252][  300/  391]    Overall Loss 0.121917    Objective Loss 0.121917                                        LR 0.000305    Time 0.095228    
2024-02-19 18:57:02,700 - Epoch: [252][  391/  391]    Overall Loss 0.123602    Objective Loss 0.123602    Top1 96.634615    Top5 100.000000    LR 0.000305    Time 0.094529    
2024-02-19 18:57:02,941 - --- validate (epoch=252)-----------
2024-02-19 18:57:02,941 - 10000 samples (128 per mini-batch)
2024-02-19 18:57:05,654 - Epoch: [252][   79/   79]    Loss 1.404552    Top1 66.810000    Top5 89.950000    
2024-02-19 18:57:05,822 - ==> Top1: 66.810    Top5: 89.950    Loss: 1.405

2024-02-19 18:57:05,840 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:57:05,841 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:57:05,926 - 

2024-02-19 18:57:05,926 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:57:15,741 - Epoch: [253][  100/  391]    Overall Loss 0.127102    Objective Loss 0.127102                                        LR 0.000305    Time 0.098081    
2024-02-19 18:57:24,970 - Epoch: [253][  200/  391]    Overall Loss 0.126894    Objective Loss 0.126894                                        LR 0.000305    Time 0.095160    
2024-02-19 18:57:34,159 - Epoch: [253][  300/  391]    Overall Loss 0.127884    Objective Loss 0.127884                                        LR 0.000305    Time 0.094057    
2024-02-19 18:57:42,545 - Epoch: [253][  391/  391]    Overall Loss 0.127493    Objective Loss 0.127493    Top1 98.076923    Top5 100.000000    LR 0.000305    Time 0.093605    
2024-02-19 18:57:42,827 - --- validate (epoch=253)-----------
2024-02-19 18:57:42,828 - 10000 samples (128 per mini-batch)
2024-02-19 18:57:45,437 - Epoch: [253][   79/   79]    Loss 1.412941    Top1 66.890000    Top5 89.930000    
2024-02-19 18:57:45,624 - ==> Top1: 66.890    Top5: 89.930    Loss: 1.413

2024-02-19 18:57:45,642 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:57:45,643 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:57:45,716 - 

2024-02-19 18:57:45,716 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:57:55,776 - Epoch: [254][  100/  391]    Overall Loss 0.123002    Objective Loss 0.123002                                        LR 0.000305    Time 0.100530    
2024-02-19 18:58:05,092 - Epoch: [254][  200/  391]    Overall Loss 0.124629    Objective Loss 0.124629                                        LR 0.000305    Time 0.096822    
2024-02-19 18:58:14,307 - Epoch: [254][  300/  391]    Overall Loss 0.124129    Objective Loss 0.124129                                        LR 0.000305    Time 0.095252    
2024-02-19 18:58:22,716 - Epoch: [254][  391/  391]    Overall Loss 0.124696    Objective Loss 0.124696    Top1 98.076923    Top5 100.000000    LR 0.000305    Time 0.094581    
2024-02-19 18:58:23,050 - --- validate (epoch=254)-----------
2024-02-19 18:58:23,050 - 10000 samples (128 per mini-batch)
2024-02-19 18:58:25,686 - Epoch: [254][   79/   79]    Loss 1.412985    Top1 66.720000    Top5 89.900000    
2024-02-19 18:58:25,956 - ==> Top1: 66.720    Top5: 89.900    Loss: 1.413

2024-02-19 18:58:25,977 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:58:25,977 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:58:26,052 - 

2024-02-19 18:58:26,053 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:58:35,901 - Epoch: [255][  100/  391]    Overall Loss 0.123869    Objective Loss 0.123869                                        LR 0.000305    Time 0.098411    
2024-02-19 18:58:45,109 - Epoch: [255][  200/  391]    Overall Loss 0.124481    Objective Loss 0.124481                                        LR 0.000305    Time 0.095223    
2024-02-19 18:58:54,321 - Epoch: [255][  300/  391]    Overall Loss 0.124262    Objective Loss 0.124262                                        LR 0.000305    Time 0.094174    
2024-02-19 18:59:02,705 - Epoch: [255][  391/  391]    Overall Loss 0.124248    Objective Loss 0.124248    Top1 98.557692    Top5 100.000000    LR 0.000305    Time 0.093689    
2024-02-19 18:59:02,920 - --- validate (epoch=255)-----------
2024-02-19 18:59:02,920 - 10000 samples (128 per mini-batch)
2024-02-19 18:59:05,615 - Epoch: [255][   79/   79]    Loss 1.401059    Top1 66.740000    Top5 89.950000    
2024-02-19 18:59:05,789 - ==> Top1: 66.740    Top5: 89.950    Loss: 1.401

2024-02-19 18:59:05,810 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:59:05,810 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:59:05,884 - 

2024-02-19 18:59:05,884 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:59:15,977 - Epoch: [256][  100/  391]    Overall Loss 0.122677    Objective Loss 0.122677                                        LR 0.000305    Time 0.100866    
2024-02-19 18:59:25,181 - Epoch: [256][  200/  391]    Overall Loss 0.123679    Objective Loss 0.123679                                        LR 0.000305    Time 0.096433    
2024-02-19 18:59:34,397 - Epoch: [256][  300/  391]    Overall Loss 0.125234    Objective Loss 0.125234                                        LR 0.000305    Time 0.094995    
2024-02-19 18:59:42,817 - Epoch: [256][  391/  391]    Overall Loss 0.125375    Objective Loss 0.125375    Top1 98.076923    Top5 100.000000    LR 0.000305    Time 0.094409    
2024-02-19 18:59:43,054 - --- validate (epoch=256)-----------
2024-02-19 18:59:43,055 - 10000 samples (128 per mini-batch)
2024-02-19 18:59:45,714 - Epoch: [256][   79/   79]    Loss 1.405051    Top1 66.610000    Top5 90.010000    
2024-02-19 18:59:45,926 - ==> Top1: 66.610    Top5: 90.010    Loss: 1.405

2024-02-19 18:59:45,945 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 18:59:45,946 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 18:59:46,019 - 

2024-02-19 18:59:46,019 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 18:59:55,877 - Epoch: [257][  100/  391]    Overall Loss 0.124283    Objective Loss 0.124283                                        LR 0.000305    Time 0.098507    
2024-02-19 19:00:05,116 - Epoch: [257][  200/  391]    Overall Loss 0.123333    Objective Loss 0.123333                                        LR 0.000305    Time 0.095426    
2024-02-19 19:00:14,326 - Epoch: [257][  300/  391]    Overall Loss 0.122985    Objective Loss 0.122985                                        LR 0.000305    Time 0.094305    
2024-02-19 19:00:22,733 - Epoch: [257][  391/  391]    Overall Loss 0.123962    Objective Loss 0.123962    Top1 96.153846    Top5 100.000000    LR 0.000305    Time 0.093851    
2024-02-19 19:00:23,060 - --- validate (epoch=257)-----------
2024-02-19 19:00:23,061 - 10000 samples (128 per mini-batch)
2024-02-19 19:00:25,866 - Epoch: [257][   79/   79]    Loss 1.411252    Top1 66.810000    Top5 89.940000    
2024-02-19 19:00:26,081 - ==> Top1: 66.810    Top5: 89.940    Loss: 1.411

2024-02-19 19:00:26,100 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:00:26,100 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:00:26,174 - 

2024-02-19 19:00:26,174 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:00:36,084 - Epoch: [258][  100/  391]    Overall Loss 0.122301    Objective Loss 0.122301                                        LR 0.000305    Time 0.099032    
2024-02-19 19:00:45,296 - Epoch: [258][  200/  391]    Overall Loss 0.123313    Objective Loss 0.123313                                        LR 0.000305    Time 0.095554    
2024-02-19 19:00:54,502 - Epoch: [258][  300/  391]    Overall Loss 0.122237    Objective Loss 0.122237                                        LR 0.000305    Time 0.094378    
2024-02-19 19:01:02,904 - Epoch: [258][  391/  391]    Overall Loss 0.122559    Objective Loss 0.122559    Top1 97.115385    Top5 100.000000    LR 0.000305    Time 0.093890    
2024-02-19 19:01:03,101 - --- validate (epoch=258)-----------
2024-02-19 19:01:03,101 - 10000 samples (128 per mini-batch)
2024-02-19 19:01:05,744 - Epoch: [258][   79/   79]    Loss 1.412940    Top1 66.840000    Top5 89.850000    
2024-02-19 19:01:05,939 - ==> Top1: 66.840    Top5: 89.850    Loss: 1.413

2024-02-19 19:01:05,959 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:01:05,959 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:01:06,032 - 

2024-02-19 19:01:06,032 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:01:16,032 - Epoch: [259][  100/  391]    Overall Loss 0.121139    Objective Loss 0.121139                                        LR 0.000305    Time 0.099933    
2024-02-19 19:01:25,226 - Epoch: [259][  200/  391]    Overall Loss 0.122839    Objective Loss 0.122839                                        LR 0.000305    Time 0.095916    
2024-02-19 19:01:34,435 - Epoch: [259][  300/  391]    Overall Loss 0.122432    Objective Loss 0.122432                                        LR 0.000305    Time 0.094628    
2024-02-19 19:01:42,836 - Epoch: [259][  391/  391]    Overall Loss 0.122661    Objective Loss 0.122661    Top1 98.076923    Top5 100.000000    LR 0.000305    Time 0.094080    
2024-02-19 19:01:43,063 - --- validate (epoch=259)-----------
2024-02-19 19:01:43,064 - 10000 samples (128 per mini-batch)
2024-02-19 19:01:45,694 - Epoch: [259][   79/   79]    Loss 1.399499    Top1 66.630000    Top5 89.870000    
2024-02-19 19:01:45,851 - ==> Top1: 66.630    Top5: 89.870    Loss: 1.399

2024-02-19 19:01:45,869 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:01:45,870 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:01:45,943 - 

2024-02-19 19:01:45,943 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:01:55,883 - Epoch: [260][  100/  391]    Overall Loss 0.124325    Objective Loss 0.124325                                        LR 0.000305    Time 0.099333    
2024-02-19 19:02:05,078 - Epoch: [260][  200/  391]    Overall Loss 0.122828    Objective Loss 0.122828                                        LR 0.000305    Time 0.095623    
2024-02-19 19:02:14,277 - Epoch: [260][  300/  391]    Overall Loss 0.121828    Objective Loss 0.121828                                        LR 0.000305    Time 0.094398    
2024-02-19 19:02:22,669 - Epoch: [260][  391/  391]    Overall Loss 0.122630    Objective Loss 0.122630    Top1 97.115385    Top5 100.000000    LR 0.000305    Time 0.093882    
2024-02-19 19:02:22,941 - --- validate (epoch=260)-----------
2024-02-19 19:02:22,941 - 10000 samples (128 per mini-batch)
2024-02-19 19:02:25,552 - Epoch: [260][   79/   79]    Loss 1.413199    Top1 66.610000    Top5 89.830000    
2024-02-19 19:02:25,835 - ==> Top1: 66.610    Top5: 89.830    Loss: 1.413

2024-02-19 19:02:25,855 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:02:25,855 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:02:25,927 - 

2024-02-19 19:02:25,928 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:02:35,722 - Epoch: [261][  100/  391]    Overall Loss 0.126533    Objective Loss 0.126533                                        LR 0.000305    Time 0.097880    
2024-02-19 19:02:44,914 - Epoch: [261][  200/  391]    Overall Loss 0.125208    Objective Loss 0.125208                                        LR 0.000305    Time 0.094878    
2024-02-19 19:02:54,103 - Epoch: [261][  300/  391]    Overall Loss 0.123772    Objective Loss 0.123772                                        LR 0.000305    Time 0.093868    
2024-02-19 19:03:02,497 - Epoch: [261][  391/  391]    Overall Loss 0.122843    Objective Loss 0.122843    Top1 97.596154    Top5 99.519231    LR 0.000305    Time 0.093478    
2024-02-19 19:03:02,731 - --- validate (epoch=261)-----------
2024-02-19 19:03:02,732 - 10000 samples (128 per mini-batch)
2024-02-19 19:03:05,314 - Epoch: [261][   79/   79]    Loss 1.412587    Top1 66.860000    Top5 89.940000    
2024-02-19 19:03:05,573 - ==> Top1: 66.860    Top5: 89.940    Loss: 1.413

2024-02-19 19:03:05,591 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:03:05,592 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:03:05,666 - 

2024-02-19 19:03:05,666 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:03:15,667 - Epoch: [262][  100/  391]    Overall Loss 0.120850    Objective Loss 0.120850                                        LR 0.000305    Time 0.099946    
2024-02-19 19:03:24,855 - Epoch: [262][  200/  391]    Overall Loss 0.123358    Objective Loss 0.123358                                        LR 0.000305    Time 0.095892    
2024-02-19 19:03:34,047 - Epoch: [262][  300/  391]    Overall Loss 0.123575    Objective Loss 0.123575                                        LR 0.000305    Time 0.094554    
2024-02-19 19:03:42,428 - Epoch: [262][  391/  391]    Overall Loss 0.123679    Objective Loss 0.123679    Top1 96.634615    Top5 100.000000    LR 0.000305    Time 0.093974    
2024-02-19 19:03:42,659 - --- validate (epoch=262)-----------
2024-02-19 19:03:42,660 - 10000 samples (128 per mini-batch)
2024-02-19 19:03:45,392 - Epoch: [262][   79/   79]    Loss 1.400139    Top1 66.690000    Top5 89.870000    
2024-02-19 19:03:45,603 - ==> Top1: 66.690    Top5: 89.870    Loss: 1.400

2024-02-19 19:03:45,622 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:03:45,623 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:03:45,700 - 

2024-02-19 19:03:45,700 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:03:55,747 - Epoch: [263][  100/  391]    Overall Loss 0.121088    Objective Loss 0.121088                                        LR 0.000305    Time 0.100395    
2024-02-19 19:04:04,977 - Epoch: [263][  200/  391]    Overall Loss 0.120785    Objective Loss 0.120785                                        LR 0.000305    Time 0.096327    
2024-02-19 19:04:14,218 - Epoch: [263][  300/  391]    Overall Loss 0.119810    Objective Loss 0.119810                                        LR 0.000305    Time 0.095006    
2024-02-19 19:04:22,698 - Epoch: [263][  391/  391]    Overall Loss 0.121197    Objective Loss 0.121197    Top1 99.038462    Top5 100.000000    LR 0.000305    Time 0.094571    
2024-02-19 19:04:22,925 - --- validate (epoch=263)-----------
2024-02-19 19:04:22,926 - 10000 samples (128 per mini-batch)
2024-02-19 19:04:25,814 - Epoch: [263][   79/   79]    Loss 1.398897    Top1 66.670000    Top5 89.920000    
2024-02-19 19:04:26,050 - ==> Top1: 66.670    Top5: 89.920    Loss: 1.399

2024-02-19 19:04:26,070 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:04:26,070 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:04:26,148 - 

2024-02-19 19:04:26,149 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:04:36,201 - Epoch: [264][  100/  391]    Overall Loss 0.116643    Objective Loss 0.116643                                        LR 0.000305    Time 0.100455    
2024-02-19 19:04:45,422 - Epoch: [264][  200/  391]    Overall Loss 0.119304    Objective Loss 0.119304                                        LR 0.000305    Time 0.096310    
2024-02-19 19:04:54,627 - Epoch: [264][  300/  391]    Overall Loss 0.119175    Objective Loss 0.119175                                        LR 0.000305    Time 0.094876    
2024-02-19 19:05:03,061 - Epoch: [264][  391/  391]    Overall Loss 0.119854    Objective Loss 0.119854    Top1 98.557692    Top5 100.000000    LR 0.000305    Time 0.094356    
2024-02-19 19:05:03,300 - --- validate (epoch=264)-----------
2024-02-19 19:05:03,300 - 10000 samples (128 per mini-batch)
2024-02-19 19:05:06,030 - Epoch: [264][   79/   79]    Loss 1.408287    Top1 66.680000    Top5 89.760000    
2024-02-19 19:05:06,204 - ==> Top1: 66.680    Top5: 89.760    Loss: 1.408

2024-02-19 19:05:06,224 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:05:06,224 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:05:06,299 - 

2024-02-19 19:05:06,299 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:05:16,145 - Epoch: [265][  100/  391]    Overall Loss 0.119335    Objective Loss 0.119335                                        LR 0.000305    Time 0.098394    
2024-02-19 19:05:25,353 - Epoch: [265][  200/  391]    Overall Loss 0.123479    Objective Loss 0.123479                                        LR 0.000305    Time 0.095213    
2024-02-19 19:05:34,568 - Epoch: [265][  300/  391]    Overall Loss 0.123227    Objective Loss 0.123227                                        LR 0.000305    Time 0.094178    
2024-02-19 19:05:43,082 - Epoch: [265][  391/  391]    Overall Loss 0.123056    Objective Loss 0.123056    Top1 96.634615    Top5 100.000000    LR 0.000305    Time 0.094023    
2024-02-19 19:05:43,321 - --- validate (epoch=265)-----------
2024-02-19 19:05:43,322 - 10000 samples (128 per mini-batch)
2024-02-19 19:05:45,996 - Epoch: [265][   79/   79]    Loss 1.415995    Top1 66.520000    Top5 89.750000    
2024-02-19 19:05:46,167 - ==> Top1: 66.520    Top5: 89.750    Loss: 1.416

2024-02-19 19:05:46,188 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:05:46,188 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:05:46,261 - 

2024-02-19 19:05:46,261 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:05:56,001 - Epoch: [266][  100/  391]    Overall Loss 0.122448    Objective Loss 0.122448                                        LR 0.000305    Time 0.097331    
2024-02-19 19:06:05,197 - Epoch: [266][  200/  391]    Overall Loss 0.119226    Objective Loss 0.119226                                        LR 0.000305    Time 0.094627    
2024-02-19 19:06:14,389 - Epoch: [266][  300/  391]    Overall Loss 0.121751    Objective Loss 0.121751                                        LR 0.000305    Time 0.093707    
2024-02-19 19:06:22,803 - Epoch: [266][  391/  391]    Overall Loss 0.122657    Objective Loss 0.122657    Top1 96.634615    Top5 100.000000    LR 0.000305    Time 0.093410    
2024-02-19 19:06:23,081 - --- validate (epoch=266)-----------
2024-02-19 19:06:23,082 - 10000 samples (128 per mini-batch)
2024-02-19 19:06:25,696 - Epoch: [266][   79/   79]    Loss 1.412531    Top1 66.780000    Top5 89.940000    
2024-02-19 19:06:25,903 - ==> Top1: 66.780    Top5: 89.940    Loss: 1.413

2024-02-19 19:06:25,922 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:06:25,923 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:06:25,995 - 

2024-02-19 19:06:25,996 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:06:35,983 - Epoch: [267][  100/  391]    Overall Loss 0.119446    Objective Loss 0.119446                                        LR 0.000305    Time 0.099807    
2024-02-19 19:06:45,173 - Epoch: [267][  200/  391]    Overall Loss 0.119444    Objective Loss 0.119444                                        LR 0.000305    Time 0.095830    
2024-02-19 19:06:54,362 - Epoch: [267][  300/  391]    Overall Loss 0.120322    Objective Loss 0.120322                                        LR 0.000305    Time 0.094505    
2024-02-19 19:07:02,893 - Epoch: [267][  391/  391]    Overall Loss 0.120705    Objective Loss 0.120705    Top1 95.192308    Top5 100.000000    LR 0.000305    Time 0.094318    
2024-02-19 19:07:03,221 - --- validate (epoch=267)-----------
2024-02-19 19:07:03,222 - 10000 samples (128 per mini-batch)
2024-02-19 19:07:05,993 - Epoch: [267][   79/   79]    Loss 1.409565    Top1 66.570000    Top5 89.860000    
2024-02-19 19:07:06,202 - ==> Top1: 66.570    Top5: 89.860    Loss: 1.410

2024-02-19 19:07:06,221 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:07:06,221 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:07:06,295 - 

2024-02-19 19:07:06,295 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:07:16,126 - Epoch: [268][  100/  391]    Overall Loss 0.116713    Objective Loss 0.116713                                        LR 0.000305    Time 0.098234    
2024-02-19 19:07:25,313 - Epoch: [268][  200/  391]    Overall Loss 0.119321    Objective Loss 0.119321                                        LR 0.000305    Time 0.095030    
2024-02-19 19:07:34,512 - Epoch: [268][  300/  391]    Overall Loss 0.120573    Objective Loss 0.120573                                        LR 0.000305    Time 0.094004    
2024-02-19 19:07:41,660 - Epoch: [268][  391/  391]    Overall Loss 0.120823    Objective Loss 0.120823    Top1 97.596154    Top5 100.000000    LR 0.000305    Time 0.090398    
2024-02-19 19:07:41,969 - --- validate (epoch=268)-----------
2024-02-19 19:07:41,970 - 10000 samples (128 per mini-batch)
2024-02-19 19:07:44,815 - Epoch: [268][   79/   79]    Loss 1.415197    Top1 66.830000    Top5 89.800000    
2024-02-19 19:07:44,998 - ==> Top1: 66.830    Top5: 89.800    Loss: 1.415

2024-02-19 19:07:45,016 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:07:45,017 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:07:45,091 - 

2024-02-19 19:07:45,091 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:07:54,897 - Epoch: [269][  100/  391]    Overall Loss 0.118539    Objective Loss 0.118539                                        LR 0.000305    Time 0.097991    
2024-02-19 19:08:04,119 - Epoch: [269][  200/  391]    Overall Loss 0.119865    Objective Loss 0.119865                                        LR 0.000305    Time 0.095084    
2024-02-19 19:08:13,338 - Epoch: [269][  300/  391]    Overall Loss 0.120153    Objective Loss 0.120153                                        LR 0.000305    Time 0.094106    
2024-02-19 19:08:21,849 - Epoch: [269][  391/  391]    Overall Loss 0.121245    Objective Loss 0.121245    Top1 95.673077    Top5 100.000000    LR 0.000305    Time 0.093961    
2024-02-19 19:08:22,114 - --- validate (epoch=269)-----------
2024-02-19 19:08:22,115 - 10000 samples (128 per mini-batch)
2024-02-19 19:08:24,877 - Epoch: [269][   79/   79]    Loss 1.404529    Top1 66.800000    Top5 89.870000    
2024-02-19 19:08:25,098 - ==> Top1: 66.800    Top5: 89.870    Loss: 1.405

2024-02-19 19:08:25,117 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:08:25,117 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:08:25,191 - 

2024-02-19 19:08:25,191 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:08:35,271 - Epoch: [270][  100/  391]    Overall Loss 0.116357    Objective Loss 0.116357                                        LR 0.000305    Time 0.100730    
2024-02-19 19:08:44,491 - Epoch: [270][  200/  391]    Overall Loss 0.118311    Objective Loss 0.118311                                        LR 0.000305    Time 0.096443    
2024-02-19 19:08:53,695 - Epoch: [270][  300/  391]    Overall Loss 0.120071    Objective Loss 0.120071                                        LR 0.000305    Time 0.094963    
2024-02-19 19:09:02,151 - Epoch: [270][  391/  391]    Overall Loss 0.119489    Objective Loss 0.119489    Top1 97.596154    Top5 100.000000    LR 0.000305    Time 0.094477    
2024-02-19 19:09:02,362 - --- validate (epoch=270)-----------
2024-02-19 19:09:02,362 - 10000 samples (128 per mini-batch)
2024-02-19 19:09:04,992 - Epoch: [270][   79/   79]    Loss 1.423870    Top1 66.600000    Top5 89.820000    
2024-02-19 19:09:05,163 - ==> Top1: 66.600    Top5: 89.820    Loss: 1.424

2024-02-19 19:09:05,182 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:09:05,182 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:09:05,255 - 

2024-02-19 19:09:05,255 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:09:15,043 - Epoch: [271][  100/  391]    Overall Loss 0.116135    Objective Loss 0.116135                                        LR 0.000305    Time 0.097819    
2024-02-19 19:09:24,244 - Epoch: [271][  200/  391]    Overall Loss 0.118638    Objective Loss 0.118638                                        LR 0.000305    Time 0.094892    
2024-02-19 19:09:33,492 - Epoch: [271][  300/  391]    Overall Loss 0.119640    Objective Loss 0.119640                                        LR 0.000305    Time 0.094074    
2024-02-19 19:09:41,996 - Epoch: [271][  391/  391]    Overall Loss 0.119384    Objective Loss 0.119384    Top1 98.076923    Top5 100.000000    LR 0.000305    Time 0.093919    
2024-02-19 19:09:42,192 - --- validate (epoch=271)-----------
2024-02-19 19:09:42,193 - 10000 samples (128 per mini-batch)
2024-02-19 19:09:44,783 - Epoch: [271][   79/   79]    Loss 1.420567    Top1 66.570000    Top5 89.890000    
2024-02-19 19:09:45,006 - ==> Top1: 66.570    Top5: 89.890    Loss: 1.421

2024-02-19 19:09:45,026 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:09:45,026 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:09:45,100 - 

2024-02-19 19:09:45,100 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:09:55,110 - Epoch: [272][  100/  391]    Overall Loss 0.121291    Objective Loss 0.121291                                        LR 0.000305    Time 0.100027    
2024-02-19 19:10:04,310 - Epoch: [272][  200/  391]    Overall Loss 0.121051    Objective Loss 0.121051                                        LR 0.000305    Time 0.095990    
2024-02-19 19:10:13,568 - Epoch: [272][  300/  391]    Overall Loss 0.120936    Objective Loss 0.120936                                        LR 0.000305    Time 0.094843    
2024-02-19 19:10:21,884 - Epoch: [272][  391/  391]    Overall Loss 0.121130    Objective Loss 0.121130    Top1 95.192308    Top5 100.000000    LR 0.000305    Time 0.094026    
2024-02-19 19:10:22,122 - --- validate (epoch=272)-----------
2024-02-19 19:10:22,123 - 10000 samples (128 per mini-batch)
2024-02-19 19:10:24,676 - Epoch: [272][   79/   79]    Loss 1.405413    Top1 66.570000    Top5 89.820000    
2024-02-19 19:10:24,993 - ==> Top1: 66.570    Top5: 89.820    Loss: 1.405

2024-02-19 19:10:25,011 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:10:25,012 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:10:25,085 - 

2024-02-19 19:10:25,086 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:10:34,737 - Epoch: [273][  100/  391]    Overall Loss 0.116614    Objective Loss 0.116614                                        LR 0.000305    Time 0.096447    
2024-02-19 19:10:43,869 - Epoch: [273][  200/  391]    Overall Loss 0.118252    Objective Loss 0.118252                                        LR 0.000305    Time 0.093865    
2024-02-19 19:10:53,130 - Epoch: [273][  300/  391]    Overall Loss 0.118597    Objective Loss 0.118597                                        LR 0.000305    Time 0.093433    
2024-02-19 19:11:01,535 - Epoch: [273][  391/  391]    Overall Loss 0.119249    Objective Loss 0.119249    Top1 96.153846    Top5 100.000000    LR 0.000305    Time 0.093174    
2024-02-19 19:11:01,844 - --- validate (epoch=273)-----------
2024-02-19 19:11:01,845 - 10000 samples (128 per mini-batch)
2024-02-19 19:11:04,465 - Epoch: [273][   79/   79]    Loss 1.420219    Top1 66.610000    Top5 89.830000    
2024-02-19 19:11:04,697 - ==> Top1: 66.610    Top5: 89.830    Loss: 1.420

2024-02-19 19:11:04,715 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:11:04,716 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:11:04,787 - 

2024-02-19 19:11:04,788 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:11:14,871 - Epoch: [274][  100/  391]    Overall Loss 0.115297    Objective Loss 0.115297                                        LR 0.000305    Time 0.100765    
2024-02-19 19:11:24,077 - Epoch: [274][  200/  391]    Overall Loss 0.117045    Objective Loss 0.117045                                        LR 0.000305    Time 0.096392    
2024-02-19 19:11:33,314 - Epoch: [274][  300/  391]    Overall Loss 0.117885    Objective Loss 0.117885                                        LR 0.000305    Time 0.095036    
2024-02-19 19:11:41,716 - Epoch: [274][  391/  391]    Overall Loss 0.117682    Objective Loss 0.117682    Top1 98.557692    Top5 100.000000    LR 0.000305    Time 0.094397    
2024-02-19 19:11:41,968 - --- validate (epoch=274)-----------
2024-02-19 19:11:41,969 - 10000 samples (128 per mini-batch)
2024-02-19 19:11:44,577 - Epoch: [274][   79/   79]    Loss 1.415382    Top1 66.680000    Top5 89.920000    
2024-02-19 19:11:44,759 - ==> Top1: 66.680    Top5: 89.920    Loss: 1.415

2024-02-19 19:11:44,776 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:11:44,777 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:11:44,850 - 

2024-02-19 19:11:44,850 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:11:54,650 - Epoch: [275][  100/  391]    Overall Loss 0.118078    Objective Loss 0.118078                                        LR 0.000305    Time 0.097934    
2024-02-19 19:12:03,871 - Epoch: [275][  200/  391]    Overall Loss 0.117417    Objective Loss 0.117417                                        LR 0.000305    Time 0.095049    
2024-02-19 19:12:13,173 - Epoch: [275][  300/  391]    Overall Loss 0.117793    Objective Loss 0.117793                                        LR 0.000305    Time 0.094360    
2024-02-19 19:12:21,573 - Epoch: [275][  391/  391]    Overall Loss 0.118523    Objective Loss 0.118523    Top1 97.596154    Top5 100.000000    LR 0.000305    Time 0.093871    
2024-02-19 19:12:21,903 - --- validate (epoch=275)-----------
2024-02-19 19:12:21,903 - 10000 samples (128 per mini-batch)
2024-02-19 19:12:24,570 - Epoch: [275][   79/   79]    Loss 1.430337    Top1 66.670000    Top5 89.690000    
2024-02-19 19:12:24,748 - ==> Top1: 66.670    Top5: 89.690    Loss: 1.430

2024-02-19 19:12:24,768 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:12:24,768 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:12:24,848 - 

2024-02-19 19:12:24,849 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:12:34,650 - Epoch: [276][  100/  391]    Overall Loss 0.118509    Objective Loss 0.118509                                        LR 0.000305    Time 0.097945    
2024-02-19 19:12:43,851 - Epoch: [276][  200/  391]    Overall Loss 0.117977    Objective Loss 0.117977                                        LR 0.000305    Time 0.094956    
2024-02-19 19:12:53,204 - Epoch: [276][  300/  391]    Overall Loss 0.118277    Objective Loss 0.118277                                        LR 0.000305    Time 0.094468    
2024-02-19 19:13:01,618 - Epoch: [276][  391/  391]    Overall Loss 0.119813    Objective Loss 0.119813    Top1 95.192308    Top5 100.000000    LR 0.000305    Time 0.093990    
2024-02-19 19:13:01,842 - --- validate (epoch=276)-----------
2024-02-19 19:13:01,843 - 10000 samples (128 per mini-batch)
2024-02-19 19:13:04,713 - Epoch: [276][   79/   79]    Loss 1.418003    Top1 66.590000    Top5 89.780000    
2024-02-19 19:13:04,803 - ==> Top1: 66.590    Top5: 89.780    Loss: 1.418

2024-02-19 19:13:04,822 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:13:04,823 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:13:04,890 - 

2024-02-19 19:13:04,890 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:13:14,838 - Epoch: [277][  100/  391]    Overall Loss 0.113451    Objective Loss 0.113451                                        LR 0.000305    Time 0.099413    
2024-02-19 19:13:24,295 - Epoch: [277][  200/  391]    Overall Loss 0.117364    Objective Loss 0.117364                                        LR 0.000305    Time 0.096969    
2024-02-19 19:13:33,714 - Epoch: [277][  300/  391]    Overall Loss 0.118586    Objective Loss 0.118586                                        LR 0.000305    Time 0.096029    
2024-02-19 19:13:42,213 - Epoch: [277][  391/  391]    Overall Loss 0.118705    Objective Loss 0.118705    Top1 97.115385    Top5 100.000000    LR 0.000305    Time 0.095405    
2024-02-19 19:13:42,555 - --- validate (epoch=277)-----------
2024-02-19 19:13:42,555 - 10000 samples (128 per mini-batch)
2024-02-19 19:13:45,259 - Epoch: [277][   79/   79]    Loss 1.408219    Top1 66.570000    Top5 89.770000    
2024-02-19 19:13:45,469 - ==> Top1: 66.570    Top5: 89.770    Loss: 1.408

2024-02-19 19:13:45,487 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:13:45,487 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:13:45,560 - 

2024-02-19 19:13:45,560 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:13:55,344 - Epoch: [278][  100/  391]    Overall Loss 0.121716    Objective Loss 0.121716                                        LR 0.000305    Time 0.097774    
2024-02-19 19:14:04,566 - Epoch: [278][  200/  391]    Overall Loss 0.122032    Objective Loss 0.122032                                        LR 0.000305    Time 0.094972    
2024-02-19 19:14:13,758 - Epoch: [278][  300/  391]    Overall Loss 0.120645    Objective Loss 0.120645                                        LR 0.000305    Time 0.093941    
2024-02-19 19:14:22,157 - Epoch: [278][  391/  391]    Overall Loss 0.120511    Objective Loss 0.120511    Top1 96.153846    Top5 100.000000    LR 0.000305    Time 0.093549    
2024-02-19 19:14:22,401 - --- validate (epoch=278)-----------
2024-02-19 19:14:22,402 - 10000 samples (128 per mini-batch)
2024-02-19 19:14:25,268 - Epoch: [278][   79/   79]    Loss 1.412825    Top1 66.480000    Top5 89.810000    
2024-02-19 19:14:25,491 - ==> Top1: 66.480    Top5: 89.810    Loss: 1.413

2024-02-19 19:14:25,509 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:14:25,509 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:14:25,582 - 

2024-02-19 19:14:25,582 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:14:35,352 - Epoch: [279][  100/  391]    Overall Loss 0.116211    Objective Loss 0.116211                                        LR 0.000305    Time 0.097630    
2024-02-19 19:14:44,640 - Epoch: [279][  200/  391]    Overall Loss 0.118334    Objective Loss 0.118334                                        LR 0.000305    Time 0.095232    
2024-02-19 19:14:53,832 - Epoch: [279][  300/  391]    Overall Loss 0.117494    Objective Loss 0.117494                                        LR 0.000305    Time 0.094116    
2024-02-19 19:15:02,229 - Epoch: [279][  391/  391]    Overall Loss 0.117017    Objective Loss 0.117017    Top1 98.557692    Top5 100.000000    LR 0.000305    Time 0.093677    
2024-02-19 19:15:02,543 - --- validate (epoch=279)-----------
2024-02-19 19:15:02,544 - 10000 samples (128 per mini-batch)
2024-02-19 19:15:05,255 - Epoch: [279][   79/   79]    Loss 1.427211    Top1 66.700000    Top5 89.890000    
2024-02-19 19:15:05,443 - ==> Top1: 66.700    Top5: 89.890    Loss: 1.427

2024-02-19 19:15:05,462 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:15:05,463 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:15:05,536 - 

2024-02-19 19:15:05,536 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:15:15,581 - Epoch: [280][  100/  391]    Overall Loss 0.114510    Objective Loss 0.114510                                        LR 0.000305    Time 0.100375    
2024-02-19 19:15:24,858 - Epoch: [280][  200/  391]    Overall Loss 0.119711    Objective Loss 0.119711                                        LR 0.000305    Time 0.096551    
2024-02-19 19:15:34,049 - Epoch: [280][  300/  391]    Overall Loss 0.119769    Objective Loss 0.119769                                        LR 0.000305    Time 0.094990    
2024-02-19 19:15:42,445 - Epoch: [280][  391/  391]    Overall Loss 0.119766    Objective Loss 0.119766    Top1 98.557692    Top5 100.000000    LR 0.000305    Time 0.094348    
2024-02-19 19:15:42,777 - --- validate (epoch=280)-----------
2024-02-19 19:15:42,778 - 10000 samples (128 per mini-batch)
2024-02-19 19:15:45,481 - Epoch: [280][   79/   79]    Loss 1.409494    Top1 66.670000    Top5 89.730000    
2024-02-19 19:15:45,622 - ==> Top1: 66.670    Top5: 89.730    Loss: 1.409

2024-02-19 19:15:45,641 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:15:45,642 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:15:45,716 - 

2024-02-19 19:15:45,716 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:15:55,517 - Epoch: [281][  100/  391]    Overall Loss 0.113831    Objective Loss 0.113831                                        LR 0.000305    Time 0.097936    
2024-02-19 19:16:04,640 - Epoch: [281][  200/  391]    Overall Loss 0.114827    Objective Loss 0.114827                                        LR 0.000305    Time 0.094561    
2024-02-19 19:16:13,852 - Epoch: [281][  300/  391]    Overall Loss 0.118071    Objective Loss 0.118071                                        LR 0.000305    Time 0.093735    
2024-02-19 19:16:22,217 - Epoch: [281][  391/  391]    Overall Loss 0.119363    Objective Loss 0.119363    Top1 96.153846    Top5 100.000000    LR 0.000305    Time 0.093303    
2024-02-19 19:16:22,446 - --- validate (epoch=281)-----------
2024-02-19 19:16:22,447 - 10000 samples (128 per mini-batch)
2024-02-19 19:16:25,183 - Epoch: [281][   79/   79]    Loss 1.415565    Top1 66.700000    Top5 89.760000    
2024-02-19 19:16:25,359 - ==> Top1: 66.700    Top5: 89.760    Loss: 1.416

2024-02-19 19:16:25,378 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:16:25,378 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:16:25,452 - 

2024-02-19 19:16:25,453 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:16:35,481 - Epoch: [282][  100/  391]    Overall Loss 0.118123    Objective Loss 0.118123                                        LR 0.000305    Time 0.100217    
2024-02-19 19:16:44,693 - Epoch: [282][  200/  391]    Overall Loss 0.117820    Objective Loss 0.117820                                        LR 0.000305    Time 0.096145    
2024-02-19 19:16:53,855 - Epoch: [282][  300/  391]    Overall Loss 0.116906    Objective Loss 0.116906                                        LR 0.000305    Time 0.094625    
2024-02-19 19:17:02,251 - Epoch: [282][  391/  391]    Overall Loss 0.116869    Objective Loss 0.116869    Top1 98.076923    Top5 99.519231    LR 0.000305    Time 0.094065    
2024-02-19 19:17:02,533 - --- validate (epoch=282)-----------
2024-02-19 19:17:02,535 - 10000 samples (128 per mini-batch)
2024-02-19 19:17:05,339 - Epoch: [282][   79/   79]    Loss 1.406956    Top1 66.730000    Top5 89.810000    
2024-02-19 19:17:05,537 - ==> Top1: 66.730    Top5: 89.810    Loss: 1.407

2024-02-19 19:17:05,557 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:17:05,557 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:17:05,630 - 

2024-02-19 19:17:05,630 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:17:15,476 - Epoch: [283][  100/  391]    Overall Loss 0.116397    Objective Loss 0.116397                                        LR 0.000305    Time 0.098394    
2024-02-19 19:17:24,666 - Epoch: [283][  200/  391]    Overall Loss 0.118205    Objective Loss 0.118205                                        LR 0.000305    Time 0.095125    
2024-02-19 19:17:33,835 - Epoch: [283][  300/  391]    Overall Loss 0.117724    Objective Loss 0.117724                                        LR 0.000305    Time 0.093965    
2024-02-19 19:17:42,209 - Epoch: [283][  391/  391]    Overall Loss 0.118160    Objective Loss 0.118160    Top1 97.596154    Top5 100.000000    LR 0.000305    Time 0.093503    
2024-02-19 19:17:42,553 - --- validate (epoch=283)-----------
2024-02-19 19:17:42,554 - 10000 samples (128 per mini-batch)
2024-02-19 19:17:45,232 - Epoch: [283][   79/   79]    Loss 1.415274    Top1 66.650000    Top5 89.740000    
2024-02-19 19:17:45,440 - ==> Top1: 66.650    Top5: 89.740    Loss: 1.415

2024-02-19 19:17:45,461 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:17:45,461 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:17:45,534 - 

2024-02-19 19:17:45,535 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:17:55,578 - Epoch: [284][  100/  391]    Overall Loss 0.112598    Objective Loss 0.112598                                        LR 0.000305    Time 0.100369    
2024-02-19 19:18:04,726 - Epoch: [284][  200/  391]    Overall Loss 0.116129    Objective Loss 0.116129                                        LR 0.000305    Time 0.095900    
2024-02-19 19:18:13,896 - Epoch: [284][  300/  391]    Overall Loss 0.117406    Objective Loss 0.117406                                        LR 0.000305    Time 0.094487    
2024-02-19 19:18:22,285 - Epoch: [284][  391/  391]    Overall Loss 0.117846    Objective Loss 0.117846    Top1 95.673077    Top5 100.000000    LR 0.000305    Time 0.093941    
2024-02-19 19:18:22,521 - --- validate (epoch=284)-----------
2024-02-19 19:18:22,522 - 10000 samples (128 per mini-batch)
2024-02-19 19:18:25,177 - Epoch: [284][   79/   79]    Loss 1.421896    Top1 66.830000    Top5 89.840000    
2024-02-19 19:18:25,335 - ==> Top1: 66.830    Top5: 89.840    Loss: 1.422

2024-02-19 19:18:25,354 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:18:25,354 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:18:25,428 - 

2024-02-19 19:18:25,428 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:18:35,244 - Epoch: [285][  100/  391]    Overall Loss 0.122186    Objective Loss 0.122186                                        LR 0.000305    Time 0.098094    
2024-02-19 19:18:44,442 - Epoch: [285][  200/  391]    Overall Loss 0.122160    Objective Loss 0.122160                                        LR 0.000305    Time 0.095012    
2024-02-19 19:18:53,641 - Epoch: [285][  300/  391]    Overall Loss 0.120215    Objective Loss 0.120215                                        LR 0.000305    Time 0.093990    
2024-02-19 19:19:02,032 - Epoch: [285][  391/  391]    Overall Loss 0.118968    Objective Loss 0.118968    Top1 96.153846    Top5 100.000000    LR 0.000305    Time 0.093568    
2024-02-19 19:19:02,377 - --- validate (epoch=285)-----------
2024-02-19 19:19:02,379 - 10000 samples (128 per mini-batch)
2024-02-19 19:19:04,999 - Epoch: [285][   79/   79]    Loss 1.419720    Top1 66.790000    Top5 89.640000    
2024-02-19 19:19:05,214 - ==> Top1: 66.790    Top5: 89.640    Loss: 1.420

2024-02-19 19:19:05,235 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:19:05,235 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:19:05,308 - 

2024-02-19 19:19:05,308 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:19:15,175 - Epoch: [286][  100/  391]    Overall Loss 0.119305    Objective Loss 0.119305                                        LR 0.000305    Time 0.098593    
2024-02-19 19:19:24,355 - Epoch: [286][  200/  391]    Overall Loss 0.118862    Objective Loss 0.118862                                        LR 0.000305    Time 0.095179    
2024-02-19 19:19:33,525 - Epoch: [286][  300/  391]    Overall Loss 0.118437    Objective Loss 0.118437                                        LR 0.000305    Time 0.094004    
2024-02-19 19:19:41,909 - Epoch: [286][  391/  391]    Overall Loss 0.117993    Objective Loss 0.117993    Top1 98.076923    Top5 100.000000    LR 0.000305    Time 0.093559    
2024-02-19 19:19:42,139 - --- validate (epoch=286)-----------
2024-02-19 19:19:42,140 - 10000 samples (128 per mini-batch)
2024-02-19 19:19:44,801 - Epoch: [286][   79/   79]    Loss 1.413128    Top1 66.570000    Top5 89.880000    
2024-02-19 19:19:45,001 - ==> Top1: 66.570    Top5: 89.880    Loss: 1.413

2024-02-19 19:19:45,021 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:19:45,021 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:19:45,102 - 

2024-02-19 19:19:45,102 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:19:55,158 - Epoch: [287][  100/  391]    Overall Loss 0.114775    Objective Loss 0.114775                                        LR 0.000305    Time 0.100495    
2024-02-19 19:20:04,337 - Epoch: [287][  200/  391]    Overall Loss 0.116423    Objective Loss 0.116423                                        LR 0.000305    Time 0.096121    
2024-02-19 19:20:13,526 - Epoch: [287][  300/  391]    Overall Loss 0.119097    Objective Loss 0.119097                                        LR 0.000305    Time 0.094696    
2024-02-19 19:20:21,901 - Epoch: [287][  391/  391]    Overall Loss 0.118893    Objective Loss 0.118893    Top1 96.634615    Top5 100.000000    LR 0.000305    Time 0.094068    
2024-02-19 19:20:22,142 - --- validate (epoch=287)-----------
2024-02-19 19:20:22,143 - 10000 samples (128 per mini-batch)
2024-02-19 19:20:24,843 - Epoch: [287][   79/   79]    Loss 1.411296    Top1 66.770000    Top5 89.780000    
2024-02-19 19:20:25,103 - ==> Top1: 66.770    Top5: 89.780    Loss: 1.411

2024-02-19 19:20:25,123 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:20:25,123 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:20:25,211 - 

2024-02-19 19:20:25,212 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:20:35,054 - Epoch: [288][  100/  391]    Overall Loss 0.115347    Objective Loss 0.115347                                        LR 0.000305    Time 0.098350    
2024-02-19 19:20:44,243 - Epoch: [288][  200/  391]    Overall Loss 0.117561    Objective Loss 0.117561                                        LR 0.000305    Time 0.095103    
2024-02-19 19:20:53,443 - Epoch: [288][  300/  391]    Overall Loss 0.116494    Objective Loss 0.116494                                        LR 0.000305    Time 0.094055    
2024-02-19 19:21:01,841 - Epoch: [288][  391/  391]    Overall Loss 0.117576    Objective Loss 0.117576    Top1 96.634615    Top5 99.519231    LR 0.000305    Time 0.093632    
2024-02-19 19:21:02,074 - --- validate (epoch=288)-----------
2024-02-19 19:21:02,075 - 10000 samples (128 per mini-batch)
2024-02-19 19:21:05,208 - Epoch: [288][   79/   79]    Loss 1.420510    Top1 66.820000    Top5 89.790000    
2024-02-19 19:21:05,440 - ==> Top1: 66.820    Top5: 89.790    Loss: 1.421

2024-02-19 19:21:05,458 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:21:05,458 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:21:05,531 - 

2024-02-19 19:21:05,531 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:21:15,309 - Epoch: [289][  100/  391]    Overall Loss 0.115612    Objective Loss 0.115612                                        LR 0.000305    Time 0.097709    
2024-02-19 19:21:24,499 - Epoch: [289][  200/  391]    Overall Loss 0.116586    Objective Loss 0.116586                                        LR 0.000305    Time 0.094782    
2024-02-19 19:21:33,680 - Epoch: [289][  300/  391]    Overall Loss 0.115867    Objective Loss 0.115867                                        LR 0.000305    Time 0.093780    
2024-02-19 19:21:42,080 - Epoch: [289][  391/  391]    Overall Loss 0.116900    Objective Loss 0.116900    Top1 97.115385    Top5 100.000000    LR 0.000305    Time 0.093428    
2024-02-19 19:21:42,345 - --- validate (epoch=289)-----------
2024-02-19 19:21:42,346 - 10000 samples (128 per mini-batch)
2024-02-19 19:21:45,047 - Epoch: [289][   79/   79]    Loss 1.416107    Top1 66.690000    Top5 89.690000    
2024-02-19 19:21:45,333 - ==> Top1: 66.690    Top5: 89.690    Loss: 1.416

2024-02-19 19:21:45,352 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:21:45,352 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:21:45,426 - 

2024-02-19 19:21:45,426 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:21:55,477 - Epoch: [290][  100/  391]    Overall Loss 0.115425    Objective Loss 0.115425                                        LR 0.000305    Time 0.100442    
2024-02-19 19:22:04,676 - Epoch: [290][  200/  391]    Overall Loss 0.115638    Objective Loss 0.115638                                        LR 0.000305    Time 0.096199    
2024-02-19 19:22:13,880 - Epoch: [290][  300/  391]    Overall Loss 0.116615    Objective Loss 0.116615                                        LR 0.000305    Time 0.094800    
2024-02-19 19:22:22,307 - Epoch: [290][  391/  391]    Overall Loss 0.117397    Objective Loss 0.117397    Top1 97.115385    Top5 100.000000    LR 0.000305    Time 0.094280    
2024-02-19 19:22:22,538 - --- validate (epoch=290)-----------
2024-02-19 19:22:22,539 - 10000 samples (128 per mini-batch)
2024-02-19 19:22:25,223 - Epoch: [290][   79/   79]    Loss 1.412684    Top1 66.670000    Top5 89.820000    
2024-02-19 19:22:25,409 - ==> Top1: 66.670    Top5: 89.820    Loss: 1.413

2024-02-19 19:22:25,429 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:22:25,429 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:22:25,513 - 

2024-02-19 19:22:25,513 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:22:35,282 - Epoch: [291][  100/  391]    Overall Loss 0.118171    Objective Loss 0.118171                                        LR 0.000305    Time 0.097624    
2024-02-19 19:22:44,467 - Epoch: [291][  200/  391]    Overall Loss 0.118380    Objective Loss 0.118380                                        LR 0.000305    Time 0.094716    
2024-02-19 19:22:53,652 - Epoch: [291][  300/  391]    Overall Loss 0.117665    Objective Loss 0.117665                                        LR 0.000305    Time 0.093745    
2024-02-19 19:23:02,065 - Epoch: [291][  391/  391]    Overall Loss 0.118063    Objective Loss 0.118063    Top1 95.673077    Top5 100.000000    LR 0.000305    Time 0.093435    
2024-02-19 19:23:02,280 - --- validate (epoch=291)-----------
2024-02-19 19:23:02,281 - 10000 samples (128 per mini-batch)
2024-02-19 19:23:05,049 - Epoch: [291][   79/   79]    Loss 1.418015    Top1 66.700000    Top5 89.840000    
2024-02-19 19:23:05,319 - ==> Top1: 66.700    Top5: 89.840    Loss: 1.418

2024-02-19 19:23:05,339 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:23:05,339 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:23:05,415 - 

2024-02-19 19:23:05,415 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:23:15,441 - Epoch: [292][  100/  391]    Overall Loss 0.110876    Objective Loss 0.110876                                        LR 0.000305    Time 0.100196    
2024-02-19 19:23:24,608 - Epoch: [292][  200/  391]    Overall Loss 0.115799    Objective Loss 0.115799                                        LR 0.000305    Time 0.095912    
2024-02-19 19:23:33,789 - Epoch: [292][  300/  391]    Overall Loss 0.116754    Objective Loss 0.116754                                        LR 0.000305    Time 0.094530    
2024-02-19 19:23:42,170 - Epoch: [292][  391/  391]    Overall Loss 0.117144    Objective Loss 0.117144    Top1 97.115385    Top5 100.000000    LR 0.000305    Time 0.093957    
2024-02-19 19:23:42,448 - --- validate (epoch=292)-----------
2024-02-19 19:23:42,448 - 10000 samples (128 per mini-batch)
2024-02-19 19:23:45,110 - Epoch: [292][   79/   79]    Loss 1.414700    Top1 66.620000    Top5 89.870000    
2024-02-19 19:23:45,345 - ==> Top1: 66.620    Top5: 89.870    Loss: 1.415

2024-02-19 19:23:45,366 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:23:45,366 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:23:45,438 - 

2024-02-19 19:23:45,438 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:23:55,173 - Epoch: [293][  100/  391]    Overall Loss 0.113381    Objective Loss 0.113381                                        LR 0.000305    Time 0.097279    
2024-02-19 19:24:04,366 - Epoch: [293][  200/  391]    Overall Loss 0.114725    Objective Loss 0.114725                                        LR 0.000305    Time 0.094585    
2024-02-19 19:24:13,561 - Epoch: [293][  300/  391]    Overall Loss 0.116218    Objective Loss 0.116218                                        LR 0.000305    Time 0.093693    
2024-02-19 19:24:21,955 - Epoch: [293][  391/  391]    Overall Loss 0.115835    Objective Loss 0.115835    Top1 97.115385    Top5 100.000000    LR 0.000305    Time 0.093345    
2024-02-19 19:24:22,203 - --- validate (epoch=293)-----------
2024-02-19 19:24:22,204 - 10000 samples (128 per mini-batch)
2024-02-19 19:24:24,941 - Epoch: [293][   79/   79]    Loss 1.422849    Top1 66.740000    Top5 89.770000    
2024-02-19 19:24:25,139 - ==> Top1: 66.740    Top5: 89.770    Loss: 1.423

2024-02-19 19:24:25,158 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:24:25,159 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:24:25,234 - 

2024-02-19 19:24:25,234 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:24:35,269 - Epoch: [294][  100/  391]    Overall Loss 0.121928    Objective Loss 0.121928                                        LR 0.000305    Time 0.100284    
2024-02-19 19:24:44,464 - Epoch: [294][  200/  391]    Overall Loss 0.118810    Objective Loss 0.118810                                        LR 0.000305    Time 0.096098    
2024-02-19 19:24:53,689 - Epoch: [294][  300/  391]    Overall Loss 0.118375    Objective Loss 0.118375                                        LR 0.000305    Time 0.094800    
2024-02-19 19:25:02,100 - Epoch: [294][  391/  391]    Overall Loss 0.118255    Objective Loss 0.118255    Top1 97.115385    Top5 100.000000    LR 0.000305    Time 0.094237    
2024-02-19 19:25:02,330 - --- validate (epoch=294)-----------
2024-02-19 19:25:02,331 - 10000 samples (128 per mini-batch)
2024-02-19 19:25:04,980 - Epoch: [294][   79/   79]    Loss 1.417208    Top1 66.750000    Top5 89.820000    
2024-02-19 19:25:05,096 - ==> Top1: 66.750    Top5: 89.820    Loss: 1.417

2024-02-19 19:25:05,114 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:25:05,114 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:25:05,171 - 

2024-02-19 19:25:05,171 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:25:14,753 - Epoch: [295][  100/  391]    Overall Loss 0.121166    Objective Loss 0.121166                                        LR 0.000305    Time 0.095759    
2024-02-19 19:25:23,944 - Epoch: [295][  200/  391]    Overall Loss 0.121792    Objective Loss 0.121792                                        LR 0.000305    Time 0.093813    
2024-02-19 19:25:33,148 - Epoch: [295][  300/  391]    Overall Loss 0.120083    Objective Loss 0.120083                                        LR 0.000305    Time 0.093208    
2024-02-19 19:25:41,546 - Epoch: [295][  391/  391]    Overall Loss 0.118701    Objective Loss 0.118701    Top1 97.596154    Top5 100.000000    LR 0.000305    Time 0.092985    
2024-02-19 19:25:41,789 - --- validate (epoch=295)-----------
2024-02-19 19:25:41,789 - 10000 samples (128 per mini-batch)
2024-02-19 19:25:44,513 - Epoch: [295][   79/   79]    Loss 1.427009    Top1 66.720000    Top5 89.790000    
2024-02-19 19:25:44,726 - ==> Top1: 66.720    Top5: 89.790    Loss: 1.427

2024-02-19 19:25:44,745 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:25:44,745 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:25:44,820 - 

2024-02-19 19:25:44,820 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:25:54,636 - Epoch: [296][  100/  391]    Overall Loss 0.117598    Objective Loss 0.117598                                        LR 0.000305    Time 0.098093    
2024-02-19 19:26:03,797 - Epoch: [296][  200/  391]    Overall Loss 0.118681    Objective Loss 0.118681                                        LR 0.000305    Time 0.094830    
2024-02-19 19:26:12,986 - Epoch: [296][  300/  391]    Overall Loss 0.117827    Objective Loss 0.117827                                        LR 0.000305    Time 0.093834    
2024-02-19 19:26:21,371 - Epoch: [296][  391/  391]    Overall Loss 0.118408    Objective Loss 0.118408    Top1 98.557692    Top5 100.000000    LR 0.000305    Time 0.093433    
2024-02-19 19:26:21,610 - --- validate (epoch=296)-----------
2024-02-19 19:26:21,611 - 10000 samples (128 per mini-batch)
2024-02-19 19:26:24,138 - Epoch: [296][   79/   79]    Loss 1.435526    Top1 66.640000    Top5 89.750000    
2024-02-19 19:26:24,259 - ==> Top1: 66.640    Top5: 89.750    Loss: 1.436

2024-02-19 19:26:24,277 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:26:24,277 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:26:24,333 - 

2024-02-19 19:26:24,333 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:26:34,013 - Epoch: [297][  100/  391]    Overall Loss 0.120785    Objective Loss 0.120785                                        LR 0.000305    Time 0.096738    
2024-02-19 19:26:43,360 - Epoch: [297][  200/  391]    Overall Loss 0.118442    Objective Loss 0.118442                                        LR 0.000305    Time 0.095082    
2024-02-19 19:26:52,704 - Epoch: [297][  300/  391]    Overall Loss 0.118608    Objective Loss 0.118608                                        LR 0.000305    Time 0.094522    
2024-02-19 19:27:01,251 - Epoch: [297][  391/  391]    Overall Loss 0.116835    Objective Loss 0.116835    Top1 98.557692    Top5 100.000000    LR 0.000305    Time 0.094372    
2024-02-19 19:27:01,453 - --- validate (epoch=297)-----------
2024-02-19 19:27:01,454 - 10000 samples (128 per mini-batch)
2024-02-19 19:27:04,123 - Epoch: [297][   79/   79]    Loss 1.418318    Top1 66.630000    Top5 89.790000    
2024-02-19 19:27:04,326 - ==> Top1: 66.630    Top5: 89.790    Loss: 1.418

2024-02-19 19:27:04,345 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:27:04,345 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:27:04,419 - 

2024-02-19 19:27:04,419 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:27:14,144 - Epoch: [298][  100/  391]    Overall Loss 0.114862    Objective Loss 0.114862                                        LR 0.000305    Time 0.097176    
2024-02-19 19:27:23,329 - Epoch: [298][  200/  391]    Overall Loss 0.114932    Objective Loss 0.114932                                        LR 0.000305    Time 0.094491    
2024-02-19 19:27:32,513 - Epoch: [298][  300/  391]    Overall Loss 0.115527    Objective Loss 0.115527                                        LR 0.000305    Time 0.093597    
2024-02-19 19:27:40,905 - Epoch: [298][  391/  391]    Overall Loss 0.116378    Objective Loss 0.116378    Top1 96.634615    Top5 99.519231    LR 0.000305    Time 0.093267    
2024-02-19 19:27:41,092 - --- validate (epoch=298)-----------
2024-02-19 19:27:41,092 - 10000 samples (128 per mini-batch)
2024-02-19 19:27:43,665 - Epoch: [298][   79/   79]    Loss 1.412932    Top1 66.580000    Top5 89.760000    
2024-02-19 19:27:43,857 - ==> Top1: 66.580    Top5: 89.760    Loss: 1.413

2024-02-19 19:27:43,876 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:27:43,877 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:27:43,950 - 

2024-02-19 19:27:43,951 - Training epoch: 50000 samples (128 per mini-batch)
2024-02-19 19:27:53,956 - Epoch: [299][  100/  391]    Overall Loss 0.120016    Objective Loss 0.120016                                        LR 0.000305    Time 0.099989    
2024-02-19 19:28:03,162 - Epoch: [299][  200/  391]    Overall Loss 0.117731    Objective Loss 0.117731                                        LR 0.000305    Time 0.096004    
2024-02-19 19:28:12,354 - Epoch: [299][  300/  391]    Overall Loss 0.117615    Objective Loss 0.117615                                        LR 0.000305    Time 0.094629    
2024-02-19 19:28:20,767 - Epoch: [299][  391/  391]    Overall Loss 0.117280    Objective Loss 0.117280    Top1 96.634615    Top5 100.000000    LR 0.000305    Time 0.094112    
2024-02-19 19:28:21,044 - --- validate (epoch=299)-----------
2024-02-19 19:28:21,045 - 10000 samples (128 per mini-batch)
2024-02-19 19:28:23,768 - Epoch: [299][   79/   79]    Loss 1.418573    Top1 66.640000    Top5 89.840000    
2024-02-19 19:28:23,930 - ==> Top1: 66.640    Top5: 89.840    Loss: 1.419

2024-02-19 19:28:23,949 - ==> Best [Top1: 67.480   Top5: 90.300   Sparsity:0.00   Params: 1341960 on epoch: 175]
2024-02-19 19:28:23,949 - Saving checkpoint to: logs/2024.02.19-160949/checkpoint.pth.tar
2024-02-19 19:28:24,022 - --- test ---------------------
2024-02-19 19:28:24,022 - 10000 samples (128 per mini-batch)
2024-02-19 19:28:26,571 - Test: [   79/   79]    Loss 1.420266    Top1 66.640000    Top5 89.840000    
2024-02-19 19:28:26,738 - ==> Top1: 66.640    Top5: 89.840    Loss: 1.420

2024-02-19 19:28:26,751 - 
2024-02-19 19:28:26,751 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.02.19-160949/2024.02.19-160949.log
