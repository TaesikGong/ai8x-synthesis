2024-02-19 16:10:05,217 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.02.19-161005/2024.02.19-161005.log
2024-02-19 16:10:08,517 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2024-02-19 16:10:08,517 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}
2024-02-19 16:10:10,023 - Dataset sizes:
	training=50000
	validation=10000
	test=10000
2024-02-19 16:10:10,024 - Reading compression schedule from: policies/schedule-cifar100-effnet2.yaml
2024-02-19 16:10:10,033 - 

2024-02-19 16:10:10,033 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:10:18,181 - Epoch: [0][  100/  500]    Overall Loss 4.275056    Objective Loss 4.275056                                        LR 0.001000    Time 0.081430    
2024-02-19 16:10:25,039 - Epoch: [0][  200/  500]    Overall Loss 4.121238    Objective Loss 4.121238                                        LR 0.001000    Time 0.074990    
2024-02-19 16:10:31,938 - Epoch: [0][  300/  500]    Overall Loss 4.013989    Objective Loss 4.013989                                        LR 0.001000    Time 0.072976    
2024-02-19 16:10:38,859 - Epoch: [0][  400/  500]    Overall Loss 3.929156    Objective Loss 3.929156                                        LR 0.001000    Time 0.072028    
2024-02-19 16:10:45,806 - Epoch: [0][  500/  500]    Overall Loss 3.866253    Objective Loss 3.866253    Top1 11.500000    Top5 46.000000    LR 0.001000    Time 0.071511    
2024-02-19 16:10:45,949 - --- validate (epoch=0)-----------
2024-02-19 16:10:45,950 - 10000 samples (100 per mini-batch)
2024-02-19 16:10:49,195 - Epoch: [0][  100/  100]    Loss 6.616838    Top1 1.510000    Top5 6.210000    
2024-02-19 16:10:49,354 - ==> Top1: 1.510    Top5: 6.210    Loss: 6.617

2024-02-19 16:10:49,364 - ==> Best [Top1: 1.510   Top5: 6.210   Sparsity:0.00   Params: 753952 on epoch: 0]
2024-02-19 16:10:49,364 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:10:49,430 - 

2024-02-19 16:10:49,430 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:10:56,955 - Epoch: [1][  100/  500]    Overall Loss 3.500466    Objective Loss 3.500466                                        LR 0.001000    Time 0.075198    
2024-02-19 16:11:03,986 - Epoch: [1][  200/  500]    Overall Loss 3.457511    Objective Loss 3.457511                                        LR 0.001000    Time 0.072734    
2024-02-19 16:11:10,964 - Epoch: [1][  300/  500]    Overall Loss 3.418027    Objective Loss 3.418027                                        LR 0.001000    Time 0.071736    
2024-02-19 16:11:17,938 - Epoch: [1][  400/  500]    Overall Loss 3.380266    Objective Loss 3.380266                                        LR 0.001000    Time 0.071225    
2024-02-19 16:11:24,941 - Epoch: [1][  500/  500]    Overall Loss 3.341529    Objective Loss 3.341529    Top1 16.000000    Top5 45.000000    LR 0.001000    Time 0.070979    
2024-02-19 16:11:25,076 - --- validate (epoch=1)-----------
2024-02-19 16:11:25,077 - 10000 samples (100 per mini-batch)
2024-02-19 16:11:28,146 - Epoch: [1][  100/  100]    Loss 3.431657    Top1 17.000000    Top5 44.840000    
2024-02-19 16:11:28,312 - ==> Top1: 17.000    Top5: 44.840    Loss: 3.432

2024-02-19 16:11:28,322 - ==> Best [Top1: 17.000   Top5: 44.840   Sparsity:0.00   Params: 753952 on epoch: 1]
2024-02-19 16:11:28,322 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:11:28,398 - 

2024-02-19 16:11:28,398 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:11:35,797 - Epoch: [2][  100/  500]    Overall Loss 3.099394    Objective Loss 3.099394                                        LR 0.001000    Time 0.073938    
2024-02-19 16:11:42,737 - Epoch: [2][  200/  500]    Overall Loss 3.083873    Objective Loss 3.083873                                        LR 0.001000    Time 0.071651    
2024-02-19 16:11:49,719 - Epoch: [2][  300/  500]    Overall Loss 3.067328    Objective Loss 3.067328                                        LR 0.001000    Time 0.071027    
2024-02-19 16:11:56,796 - Epoch: [2][  400/  500]    Overall Loss 3.046143    Objective Loss 3.046143                                        LR 0.001000    Time 0.070953    
2024-02-19 16:12:03,764 - Epoch: [2][  500/  500]    Overall Loss 3.019589    Objective Loss 3.019589    Top1 23.000000    Top5 60.000000    LR 0.001000    Time 0.070691    
2024-02-19 16:12:03,894 - --- validate (epoch=2)-----------
2024-02-19 16:12:03,895 - 10000 samples (100 per mini-batch)
2024-02-19 16:12:07,007 - Epoch: [2][  100/  100]    Loss 3.225702    Top1 22.180000    Top5 51.550000    
2024-02-19 16:12:07,124 - ==> Top1: 22.180    Top5: 51.550    Loss: 3.226

2024-02-19 16:12:07,134 - ==> Best [Top1: 22.180   Top5: 51.550   Sparsity:0.00   Params: 753952 on epoch: 2]
2024-02-19 16:12:07,134 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:12:07,209 - 

2024-02-19 16:12:07,209 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:12:14,675 - Epoch: [3][  100/  500]    Overall Loss 2.865246    Objective Loss 2.865246                                        LR 0.001000    Time 0.074597    
2024-02-19 16:12:21,653 - Epoch: [3][  200/  500]    Overall Loss 2.844952    Objective Loss 2.844952                                        LR 0.001000    Time 0.072165    
2024-02-19 16:12:28,633 - Epoch: [3][  300/  500]    Overall Loss 2.833951    Objective Loss 2.833951                                        LR 0.001000    Time 0.071364    
2024-02-19 16:12:35,767 - Epoch: [3][  400/  500]    Overall Loss 2.819812    Objective Loss 2.819812                                        LR 0.001000    Time 0.071349    
2024-02-19 16:12:42,945 - Epoch: [3][  500/  500]    Overall Loss 2.805881    Objective Loss 2.805881    Top1 25.000000    Top5 62.000000    LR 0.001000    Time 0.071426    
2024-02-19 16:12:43,098 - --- validate (epoch=3)-----------
2024-02-19 16:12:43,098 - 10000 samples (100 per mini-batch)
2024-02-19 16:12:46,007 - Epoch: [3][  100/  100]    Loss 3.079837    Top1 24.790000    Top5 56.140000    
2024-02-19 16:12:46,121 - ==> Top1: 24.790    Top5: 56.140    Loss: 3.080

2024-02-19 16:12:46,131 - ==> Best [Top1: 24.790   Top5: 56.140   Sparsity:0.00   Params: 753952 on epoch: 3]
2024-02-19 16:12:46,131 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:12:46,205 - 

2024-02-19 16:12:46,205 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:12:53,859 - Epoch: [4][  100/  500]    Overall Loss 2.697732    Objective Loss 2.697732                                        LR 0.001000    Time 0.076481    
2024-02-19 16:13:00,801 - Epoch: [4][  200/  500]    Overall Loss 2.681969    Objective Loss 2.681969                                        LR 0.001000    Time 0.072933    
2024-02-19 16:13:07,727 - Epoch: [4][  300/  500]    Overall Loss 2.668564    Objective Loss 2.668564                                        LR 0.001000    Time 0.071694    
2024-02-19 16:13:14,747 - Epoch: [4][  400/  500]    Overall Loss 2.648206    Objective Loss 2.648206                                        LR 0.001000    Time 0.071311    
2024-02-19 16:13:21,699 - Epoch: [4][  500/  500]    Overall Loss 2.628857    Objective Loss 2.628857    Top1 30.000000    Top5 64.500000    LR 0.001000    Time 0.070945    
2024-02-19 16:13:21,830 - --- validate (epoch=4)-----------
2024-02-19 16:13:21,831 - 10000 samples (100 per mini-batch)
2024-02-19 16:13:24,776 - Epoch: [4][  100/  100]    Loss 2.708755    Top1 30.410000    Top5 63.190000    
2024-02-19 16:13:24,939 - ==> Top1: 30.410    Top5: 63.190    Loss: 2.709

2024-02-19 16:13:24,950 - ==> Best [Top1: 30.410   Top5: 63.190   Sparsity:0.00   Params: 753952 on epoch: 4]
2024-02-19 16:13:24,950 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:13:25,023 - 

2024-02-19 16:13:25,024 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:13:32,438 - Epoch: [5][  100/  500]    Overall Loss 2.506355    Objective Loss 2.506355                                        LR 0.001000    Time 0.074094    
2024-02-19 16:13:39,445 - Epoch: [5][  200/  500]    Overall Loss 2.506461    Objective Loss 2.506461                                        LR 0.001000    Time 0.072063    
2024-02-19 16:13:46,437 - Epoch: [5][  300/  500]    Overall Loss 2.498337    Objective Loss 2.498337                                        LR 0.001000    Time 0.071335    
2024-02-19 16:13:53,494 - Epoch: [5][  400/  500]    Overall Loss 2.493585    Objective Loss 2.493585                                        LR 0.001000    Time 0.071135    
2024-02-19 16:14:00,572 - Epoch: [5][  500/  500]    Overall Loss 2.480782    Objective Loss 2.480782    Top1 38.000000    Top5 68.500000    LR 0.001000    Time 0.071055    
2024-02-19 16:14:00,693 - --- validate (epoch=5)-----------
2024-02-19 16:14:00,694 - 10000 samples (100 per mini-batch)
2024-02-19 16:14:03,595 - Epoch: [5][  100/  100]    Loss 2.529645    Top1 34.250000    Top5 67.130000    
2024-02-19 16:14:03,738 - ==> Top1: 34.250    Top5: 67.130    Loss: 2.530

2024-02-19 16:14:03,750 - ==> Best [Top1: 34.250   Top5: 67.130   Sparsity:0.00   Params: 753952 on epoch: 5]
2024-02-19 16:14:03,750 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:14:03,824 - 

2024-02-19 16:14:03,824 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:14:11,494 - Epoch: [6][  100/  500]    Overall Loss 2.366514    Objective Loss 2.366514                                        LR 0.001000    Time 0.076641    
2024-02-19 16:14:18,462 - Epoch: [6][  200/  500]    Overall Loss 2.383490    Objective Loss 2.383490                                        LR 0.001000    Time 0.073143    
2024-02-19 16:14:25,413 - Epoch: [6][  300/  500]    Overall Loss 2.374303    Objective Loss 2.374303                                        LR 0.001000    Time 0.071920    
2024-02-19 16:14:32,439 - Epoch: [6][  400/  500]    Overall Loss 2.364162    Objective Loss 2.364162                                        LR 0.001000    Time 0.071495    
2024-02-19 16:14:39,384 - Epoch: [6][  500/  500]    Overall Loss 2.355942    Objective Loss 2.355942    Top1 34.500000    Top5 65.000000    LR 0.001000    Time 0.071079    
2024-02-19 16:14:39,527 - --- validate (epoch=6)-----------
2024-02-19 16:14:39,528 - 10000 samples (100 per mini-batch)
2024-02-19 16:14:42,473 - Epoch: [6][  100/  100]    Loss 2.720212    Top1 32.220000    Top5 64.090000    
2024-02-19 16:14:42,673 - ==> Top1: 32.220    Top5: 64.090    Loss: 2.720

2024-02-19 16:14:42,684 - ==> Best [Top1: 34.250   Top5: 67.130   Sparsity:0.00   Params: 753952 on epoch: 5]
2024-02-19 16:14:42,684 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:14:42,744 - 

2024-02-19 16:14:42,744 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:14:50,208 - Epoch: [7][  100/  500]    Overall Loss 2.270916    Objective Loss 2.270916                                        LR 0.001000    Time 0.074589    
2024-02-19 16:14:57,130 - Epoch: [7][  200/  500]    Overall Loss 2.274110    Objective Loss 2.274110                                        LR 0.001000    Time 0.071886    
2024-02-19 16:15:04,097 - Epoch: [7][  300/  500]    Overall Loss 2.270804    Objective Loss 2.270804                                        LR 0.001000    Time 0.071135    
2024-02-19 16:15:11,065 - Epoch: [7][  400/  500]    Overall Loss 2.270610    Objective Loss 2.270610                                        LR 0.001000    Time 0.070760    
2024-02-19 16:15:18,016 - Epoch: [7][  500/  500]    Overall Loss 2.261209    Objective Loss 2.261209    Top1 35.000000    Top5 70.500000    LR 0.001000    Time 0.070503    
2024-02-19 16:15:18,199 - --- validate (epoch=7)-----------
2024-02-19 16:15:18,199 - 10000 samples (100 per mini-batch)
2024-02-19 16:15:21,146 - Epoch: [7][  100/  100]    Loss 2.439252    Top1 37.610000    Top5 69.580000    
2024-02-19 16:15:21,362 - ==> Top1: 37.610    Top5: 69.580    Loss: 2.439

2024-02-19 16:15:21,372 - ==> Best [Top1: 37.610   Top5: 69.580   Sparsity:0.00   Params: 753952 on epoch: 7]
2024-02-19 16:15:21,372 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:15:21,458 - 

2024-02-19 16:15:21,459 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:15:29,157 - Epoch: [8][  100/  500]    Overall Loss 2.151179    Objective Loss 2.151179                                        LR 0.001000    Time 0.076925    
2024-02-19 16:15:36,101 - Epoch: [8][  200/  500]    Overall Loss 2.173651    Objective Loss 2.173651                                        LR 0.001000    Time 0.073165    
2024-02-19 16:15:42,999 - Epoch: [8][  300/  500]    Overall Loss 2.162682    Objective Loss 2.162682                                        LR 0.001000    Time 0.071755    
2024-02-19 16:15:49,949 - Epoch: [8][  400/  500]    Overall Loss 2.168870    Objective Loss 2.168870                                        LR 0.001000    Time 0.071183    
2024-02-19 16:15:56,959 - Epoch: [8][  500/  500]    Overall Loss 2.163665    Objective Loss 2.163665    Top1 41.000000    Top5 75.500000    LR 0.001000    Time 0.070958    
2024-02-19 16:15:57,082 - --- validate (epoch=8)-----------
2024-02-19 16:15:57,082 - 10000 samples (100 per mini-batch)
2024-02-19 16:16:00,012 - Epoch: [8][  100/  100]    Loss 2.393116    Top1 38.040000    Top5 70.480000    
2024-02-19 16:16:00,158 - ==> Top1: 38.040    Top5: 70.480    Loss: 2.393

2024-02-19 16:16:00,168 - ==> Best [Top1: 38.040   Top5: 70.480   Sparsity:0.00   Params: 753952 on epoch: 8]
2024-02-19 16:16:00,168 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:16:00,242 - 

2024-02-19 16:16:00,243 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:16:07,387 - Epoch: [9][  100/  500]    Overall Loss 2.059027    Objective Loss 2.059027                                        LR 0.001000    Time 0.071398    
2024-02-19 16:16:14,067 - Epoch: [9][  200/  500]    Overall Loss 2.077117    Objective Loss 2.077117                                        LR 0.001000    Time 0.069086    
2024-02-19 16:16:21,004 - Epoch: [9][  300/  500]    Overall Loss 2.086387    Objective Loss 2.086387                                        LR 0.001000    Time 0.069166    
2024-02-19 16:16:27,986 - Epoch: [9][  400/  500]    Overall Loss 2.082988    Objective Loss 2.082988                                        LR 0.001000    Time 0.069320    
2024-02-19 16:16:35,035 - Epoch: [9][  500/  500]    Overall Loss 2.083254    Objective Loss 2.083254    Top1 47.000000    Top5 78.000000    LR 0.001000    Time 0.069545    
2024-02-19 16:16:35,150 - --- validate (epoch=9)-----------
2024-02-19 16:16:35,150 - 10000 samples (100 per mini-batch)
2024-02-19 16:16:38,098 - Epoch: [9][  100/  100]    Loss 2.423922    Top1 39.470000    Top5 70.630000    
2024-02-19 16:16:38,283 - ==> Top1: 39.470    Top5: 70.630    Loss: 2.424

2024-02-19 16:16:38,295 - ==> Best [Top1: 39.470   Top5: 70.630   Sparsity:0.00   Params: 753952 on epoch: 9]
2024-02-19 16:16:38,295 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:16:38,369 - 

2024-02-19 16:16:38,370 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:16:46,117 - Epoch: [10][  100/  500]    Overall Loss 2.034494    Objective Loss 2.034494                                        LR 0.001000    Time 0.077428    
2024-02-19 16:16:53,454 - Epoch: [10][  200/  500]    Overall Loss 2.030089    Objective Loss 2.030089                                        LR 0.001000    Time 0.075380    
2024-02-19 16:17:00,789 - Epoch: [10][  300/  500]    Overall Loss 2.026545    Objective Loss 2.026545                                        LR 0.001000    Time 0.074689    
2024-02-19 16:17:07,990 - Epoch: [10][  400/  500]    Overall Loss 2.018472    Objective Loss 2.018472                                        LR 0.001000    Time 0.074009    
2024-02-19 16:17:15,212 - Epoch: [10][  500/  500]    Overall Loss 2.021649    Objective Loss 2.021649    Top1 43.000000    Top5 74.500000    LR 0.001000    Time 0.073643    
2024-02-19 16:17:15,338 - --- validate (epoch=10)-----------
2024-02-19 16:17:15,339 - 10000 samples (100 per mini-batch)
2024-02-19 16:17:18,261 - Epoch: [10][  100/  100]    Loss 2.272644    Top1 40.380000    Top5 72.820000    
2024-02-19 16:17:18,355 - ==> Top1: 40.380    Top5: 72.820    Loss: 2.273

2024-02-19 16:17:18,366 - ==> Best [Top1: 40.380   Top5: 72.820   Sparsity:0.00   Params: 753952 on epoch: 10]
2024-02-19 16:17:18,367 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:17:18,447 - 

2024-02-19 16:17:18,448 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:17:25,838 - Epoch: [11][  100/  500]    Overall Loss 1.962647    Objective Loss 1.962647                                        LR 0.001000    Time 0.073851    
2024-02-19 16:17:32,520 - Epoch: [11][  200/  500]    Overall Loss 1.956996    Objective Loss 1.956996                                        LR 0.001000    Time 0.070321    
2024-02-19 16:17:39,395 - Epoch: [11][  300/  500]    Overall Loss 1.955405    Objective Loss 1.955405                                        LR 0.001000    Time 0.069788    
2024-02-19 16:17:46,292 - Epoch: [11][  400/  500]    Overall Loss 1.954840    Objective Loss 1.954840                                        LR 0.001000    Time 0.069572    
2024-02-19 16:17:53,184 - Epoch: [11][  500/  500]    Overall Loss 1.954866    Objective Loss 1.954866    Top1 53.000000    Top5 78.500000    LR 0.001000    Time 0.069435    
2024-02-19 16:17:53,282 - --- validate (epoch=11)-----------
2024-02-19 16:17:53,283 - 10000 samples (100 per mini-batch)
2024-02-19 16:17:56,180 - Epoch: [11][  100/  100]    Loss 2.191544    Top1 42.860000    Top5 74.630000    
2024-02-19 16:17:56,290 - ==> Top1: 42.860    Top5: 74.630    Loss: 2.192

2024-02-19 16:17:56,300 - ==> Best [Top1: 42.860   Top5: 74.630   Sparsity:0.00   Params: 753952 on epoch: 11]
2024-02-19 16:17:56,300 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:17:56,361 - 

2024-02-19 16:17:56,361 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:18:03,776 - Epoch: [12][  100/  500]    Overall Loss 1.905880    Objective Loss 1.905880                                        LR 0.001000    Time 0.074107    
2024-02-19 16:18:10,777 - Epoch: [12][  200/  500]    Overall Loss 1.911123    Objective Loss 1.911123                                        LR 0.001000    Time 0.072037    
2024-02-19 16:18:17,678 - Epoch: [12][  300/  500]    Overall Loss 1.905539    Objective Loss 1.905539                                        LR 0.001000    Time 0.071015    
2024-02-19 16:18:24,354 - Epoch: [12][  400/  500]    Overall Loss 1.901324    Objective Loss 1.901324                                        LR 0.001000    Time 0.069945    
2024-02-19 16:18:31,302 - Epoch: [12][  500/  500]    Overall Loss 1.901744    Objective Loss 1.901744    Top1 49.000000    Top5 80.000000    LR 0.001000    Time 0.069845    
2024-02-19 16:18:31,510 - --- validate (epoch=12)-----------
2024-02-19 16:18:31,511 - 10000 samples (100 per mini-batch)
2024-02-19 16:18:34,358 - Epoch: [12][  100/  100]    Loss 2.092381    Top1 45.170000    Top5 76.320000    
2024-02-19 16:18:34,560 - ==> Top1: 45.170    Top5: 76.320    Loss: 2.092

2024-02-19 16:18:34,565 - ==> Best [Top1: 45.170   Top5: 76.320   Sparsity:0.00   Params: 753952 on epoch: 12]
2024-02-19 16:18:34,565 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:18:34,771 - 

2024-02-19 16:18:34,771 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:18:41,853 - Epoch: [13][  100/  500]    Overall Loss 1.821593    Objective Loss 1.821593                                        LR 0.001000    Time 0.070770    
2024-02-19 16:18:48,745 - Epoch: [13][  200/  500]    Overall Loss 1.839496    Objective Loss 1.839496                                        LR 0.001000    Time 0.069831    
2024-02-19 16:18:55,784 - Epoch: [13][  300/  500]    Overall Loss 1.848061    Objective Loss 1.848061                                        LR 0.001000    Time 0.070007    
2024-02-19 16:19:02,850 - Epoch: [13][  400/  500]    Overall Loss 1.847638    Objective Loss 1.847638                                        LR 0.001000    Time 0.070161    
2024-02-19 16:19:10,143 - Epoch: [13][  500/  500]    Overall Loss 1.848399    Objective Loss 1.848399    Top1 49.000000    Top5 80.000000    LR 0.001000    Time 0.070707    
2024-02-19 16:19:10,262 - --- validate (epoch=13)-----------
2024-02-19 16:19:10,263 - 10000 samples (100 per mini-batch)
2024-02-19 16:19:13,207 - Epoch: [13][  100/  100]    Loss 2.009546    Top1 46.370000    Top5 77.500000    
2024-02-19 16:19:13,331 - ==> Top1: 46.370    Top5: 77.500    Loss: 2.010

2024-02-19 16:19:13,342 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-19 16:19:13,343 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:19:13,417 - 

2024-02-19 16:19:13,417 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:19:21,343 - Epoch: [14][  100/  500]    Overall Loss 1.775488    Objective Loss 1.775488                                        LR 0.001000    Time 0.079205    
2024-02-19 16:19:28,232 - Epoch: [14][  200/  500]    Overall Loss 1.784257    Objective Loss 1.784257                                        LR 0.001000    Time 0.074031    
2024-02-19 16:19:35,039 - Epoch: [14][  300/  500]    Overall Loss 1.796584    Objective Loss 1.796584                                        LR 0.001000    Time 0.072034    
2024-02-19 16:19:42,025 - Epoch: [14][  400/  500]    Overall Loss 1.795666    Objective Loss 1.795666                                        LR 0.001000    Time 0.071481    
2024-02-19 16:19:49,003 - Epoch: [14][  500/  500]    Overall Loss 1.796371    Objective Loss 1.796371    Top1 48.000000    Top5 74.500000    LR 0.001000    Time 0.071134    
2024-02-19 16:19:49,113 - --- validate (epoch=14)-----------
2024-02-19 16:19:49,114 - 10000 samples (100 per mini-batch)
2024-02-19 16:19:51,999 - Epoch: [14][  100/  100]    Loss 2.156361    Top1 43.530000    Top5 76.080000    
2024-02-19 16:19:52,109 - ==> Top1: 43.530    Top5: 76.080    Loss: 2.156

2024-02-19 16:19:52,119 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-19 16:19:52,119 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:19:52,180 - 

2024-02-19 16:19:52,180 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:19:59,493 - Epoch: [15][  100/  500]    Overall Loss 1.753944    Objective Loss 1.753944                                        LR 0.001000    Time 0.073082    
2024-02-19 16:20:06,504 - Epoch: [15][  200/  500]    Overall Loss 1.765189    Objective Loss 1.765189                                        LR 0.001000    Time 0.071577    
2024-02-19 16:20:13,575 - Epoch: [15][  300/  500]    Overall Loss 1.756644    Objective Loss 1.756644                                        LR 0.001000    Time 0.071274    
2024-02-19 16:20:20,553 - Epoch: [15][  400/  500]    Overall Loss 1.757607    Objective Loss 1.757607                                        LR 0.001000    Time 0.070892    
2024-02-19 16:20:27,453 - Epoch: [15][  500/  500]    Overall Loss 1.759161    Objective Loss 1.759161    Top1 54.000000    Top5 80.000000    LR 0.001000    Time 0.070505    
2024-02-19 16:20:27,603 - --- validate (epoch=15)-----------
2024-02-19 16:20:27,604 - 10000 samples (100 per mini-batch)
2024-02-19 16:20:30,570 - Epoch: [15][  100/  100]    Loss 2.198651    Top1 44.390000    Top5 74.910000    
2024-02-19 16:20:30,754 - ==> Top1: 44.390    Top5: 74.910    Loss: 2.199

2024-02-19 16:20:30,764 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-19 16:20:30,764 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:20:30,824 - 

2024-02-19 16:20:30,824 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:20:38,245 - Epoch: [16][  100/  500]    Overall Loss 1.711494    Objective Loss 1.711494                                        LR 0.001000    Time 0.074165    
2024-02-19 16:20:45,272 - Epoch: [16][  200/  500]    Overall Loss 1.725115    Objective Loss 1.725115                                        LR 0.001000    Time 0.072197    
2024-02-19 16:20:52,232 - Epoch: [16][  300/  500]    Overall Loss 1.719435    Objective Loss 1.719435                                        LR 0.001000    Time 0.071318    
2024-02-19 16:20:59,259 - Epoch: [16][  400/  500]    Overall Loss 1.718150    Objective Loss 1.718150                                        LR 0.001000    Time 0.071045    
2024-02-19 16:21:06,283 - Epoch: [16][  500/  500]    Overall Loss 1.720831    Objective Loss 1.720831    Top1 49.500000    Top5 82.500000    LR 0.001000    Time 0.070876    
2024-02-19 16:21:06,457 - --- validate (epoch=16)-----------
2024-02-19 16:21:06,458 - 10000 samples (100 per mini-batch)
2024-02-19 16:21:09,556 - Epoch: [16][  100/  100]    Loss 2.099510    Top1 45.580000    Top5 77.060000    
2024-02-19 16:21:09,738 - ==> Top1: 45.580    Top5: 77.060    Loss: 2.100

2024-02-19 16:21:09,748 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-19 16:21:09,748 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:21:09,809 - 

2024-02-19 16:21:09,809 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:21:17,210 - Epoch: [17][  100/  500]    Overall Loss 1.660831    Objective Loss 1.660831                                        LR 0.001000    Time 0.073960    
2024-02-19 16:21:24,143 - Epoch: [17][  200/  500]    Overall Loss 1.676588    Objective Loss 1.676588                                        LR 0.001000    Time 0.071624    
2024-02-19 16:21:31,059 - Epoch: [17][  300/  500]    Overall Loss 1.675820    Objective Loss 1.675820                                        LR 0.001000    Time 0.070791    
2024-02-19 16:21:38,036 - Epoch: [17][  400/  500]    Overall Loss 1.679714    Objective Loss 1.679714                                        LR 0.001000    Time 0.070527    
2024-02-19 16:21:45,058 - Epoch: [17][  500/  500]    Overall Loss 1.685002    Objective Loss 1.685002    Top1 53.500000    Top5 84.500000    LR 0.001000    Time 0.070457    
2024-02-19 16:21:45,172 - --- validate (epoch=17)-----------
2024-02-19 16:21:45,173 - 10000 samples (100 per mini-batch)
2024-02-19 16:21:48,198 - Epoch: [17][  100/  100]    Loss 2.105406    Top1 45.680000    Top5 77.190000    
2024-02-19 16:21:48,310 - ==> Top1: 45.680    Top5: 77.190    Loss: 2.105

2024-02-19 16:21:48,320 - ==> Best [Top1: 46.370   Top5: 77.500   Sparsity:0.00   Params: 753952 on epoch: 13]
2024-02-19 16:21:48,320 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:21:48,381 - 

2024-02-19 16:21:48,382 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:21:55,982 - Epoch: [18][  100/  500]    Overall Loss 1.621041    Objective Loss 1.621041                                        LR 0.001000    Time 0.075950    
2024-02-19 16:22:02,899 - Epoch: [18][  200/  500]    Overall Loss 1.613933    Objective Loss 1.613933                                        LR 0.001000    Time 0.072542    
2024-02-19 16:22:09,812 - Epoch: [18][  300/  500]    Overall Loss 1.632973    Objective Loss 1.632973                                        LR 0.001000    Time 0.071392    
2024-02-19 16:22:16,745 - Epoch: [18][  400/  500]    Overall Loss 1.638953    Objective Loss 1.638953                                        LR 0.001000    Time 0.070868    
2024-02-19 16:22:23,765 - Epoch: [18][  500/  500]    Overall Loss 1.642707    Objective Loss 1.642707    Top1 50.500000    Top5 84.000000    LR 0.001000    Time 0.070727    
2024-02-19 16:22:23,874 - --- validate (epoch=18)-----------
2024-02-19 16:22:23,874 - 10000 samples (100 per mini-batch)
2024-02-19 16:22:26,924 - Epoch: [18][  100/  100]    Loss 1.904714    Top1 49.260000    Top5 79.860000    
2024-02-19 16:22:27,111 - ==> Top1: 49.260    Top5: 79.860    Loss: 1.905

2024-02-19 16:22:27,122 - ==> Best [Top1: 49.260   Top5: 79.860   Sparsity:0.00   Params: 753952 on epoch: 18]
2024-02-19 16:22:27,123 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:22:27,220 - 

2024-02-19 16:22:27,221 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:22:34,654 - Epoch: [19][  100/  500]    Overall Loss 1.607954    Objective Loss 1.607954                                        LR 0.001000    Time 0.074264    
2024-02-19 16:22:41,705 - Epoch: [19][  200/  500]    Overall Loss 1.585529    Objective Loss 1.585529                                        LR 0.001000    Time 0.072369    
2024-02-19 16:22:48,703 - Epoch: [19][  300/  500]    Overall Loss 1.596851    Objective Loss 1.596851                                        LR 0.001000    Time 0.071558    
2024-02-19 16:22:55,681 - Epoch: [19][  400/  500]    Overall Loss 1.601803    Objective Loss 1.601803                                        LR 0.001000    Time 0.071104    
2024-02-19 16:23:02,796 - Epoch: [19][  500/  500]    Overall Loss 1.603009    Objective Loss 1.603009    Top1 52.500000    Top5 87.000000    LR 0.001000    Time 0.071107    
2024-02-19 16:23:02,979 - --- validate (epoch=19)-----------
2024-02-19 16:23:02,980 - 10000 samples (100 per mini-batch)
2024-02-19 16:23:06,043 - Epoch: [19][  100/  100]    Loss 1.988589    Top1 48.330000    Top5 79.250000    
2024-02-19 16:23:06,155 - ==> Top1: 48.330    Top5: 79.250    Loss: 1.989

2024-02-19 16:23:06,161 - ==> Best [Top1: 49.260   Top5: 79.860   Sparsity:0.00   Params: 753952 on epoch: 18]
2024-02-19 16:23:06,161 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:23:06,220 - 

2024-02-19 16:23:06,220 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:23:13,906 - Epoch: [20][  100/  500]    Overall Loss 1.564594    Objective Loss 1.564594                                        LR 0.001000    Time 0.076807    
2024-02-19 16:23:20,834 - Epoch: [20][  200/  500]    Overall Loss 1.562131    Objective Loss 1.562131                                        LR 0.001000    Time 0.073022    
2024-02-19 16:23:27,750 - Epoch: [20][  300/  500]    Overall Loss 1.562905    Objective Loss 1.562905                                        LR 0.001000    Time 0.071725    
2024-02-19 16:23:34,666 - Epoch: [20][  400/  500]    Overall Loss 1.571484    Objective Loss 1.571484                                        LR 0.001000    Time 0.071074    
2024-02-19 16:23:41,516 - Epoch: [20][  500/  500]    Overall Loss 1.575743    Objective Loss 1.575743    Top1 57.000000    Top5 87.500000    LR 0.001000    Time 0.070552    
2024-02-19 16:23:41,713 - --- validate (epoch=20)-----------
2024-02-19 16:23:41,714 - 10000 samples (100 per mini-batch)
2024-02-19 16:23:44,804 - Epoch: [20][  100/  100]    Loss 1.934092    Top1 49.540000    Top5 80.070000    
2024-02-19 16:23:44,921 - ==> Top1: 49.540    Top5: 80.070    Loss: 1.934

2024-02-19 16:23:44,933 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-19 16:23:44,934 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:23:45,012 - 

2024-02-19 16:23:45,013 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:23:52,476 - Epoch: [21][  100/  500]    Overall Loss 1.538992    Objective Loss 1.538992                                        LR 0.001000    Time 0.074574    
2024-02-19 16:23:59,436 - Epoch: [21][  200/  500]    Overall Loss 1.546913    Objective Loss 1.546913                                        LR 0.001000    Time 0.072066    
2024-02-19 16:24:06,760 - Epoch: [21][  300/  500]    Overall Loss 1.546955    Objective Loss 1.546955                                        LR 0.001000    Time 0.072446    
2024-02-19 16:24:13,843 - Epoch: [21][  400/  500]    Overall Loss 1.549520    Objective Loss 1.549520                                        LR 0.001000    Time 0.072033    
2024-02-19 16:24:20,820 - Epoch: [21][  500/  500]    Overall Loss 1.548122    Objective Loss 1.548122    Top1 51.500000    Top5 83.000000    LR 0.001000    Time 0.071573    
2024-02-19 16:24:20,943 - --- validate (epoch=21)-----------
2024-02-19 16:24:20,943 - 10000 samples (100 per mini-batch)
2024-02-19 16:24:23,862 - Epoch: [21][  100/  100]    Loss 2.062266    Top1 47.660000    Top5 77.650000    
2024-02-19 16:24:23,999 - ==> Top1: 47.660    Top5: 77.650    Loss: 2.062

2024-02-19 16:24:24,007 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-19 16:24:24,007 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:24:24,073 - 

2024-02-19 16:24:24,073 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:24:31,491 - Epoch: [22][  100/  500]    Overall Loss 1.496551    Objective Loss 1.496551                                        LR 0.001000    Time 0.074126    
2024-02-19 16:24:38,400 - Epoch: [22][  200/  500]    Overall Loss 1.495316    Objective Loss 1.495316                                        LR 0.001000    Time 0.071588    
2024-02-19 16:24:45,318 - Epoch: [22][  300/  500]    Overall Loss 1.502963    Objective Loss 1.502963                                        LR 0.001000    Time 0.070774    
2024-02-19 16:24:52,255 - Epoch: [22][  400/  500]    Overall Loss 1.511468    Objective Loss 1.511468                                        LR 0.001000    Time 0.070415    
2024-02-19 16:24:59,269 - Epoch: [22][  500/  500]    Overall Loss 1.516580    Objective Loss 1.516580    Top1 61.000000    Top5 85.500000    LR 0.001000    Time 0.070352    
2024-02-19 16:24:59,405 - --- validate (epoch=22)-----------
2024-02-19 16:24:59,406 - 10000 samples (100 per mini-batch)
2024-02-19 16:25:02,560 - Epoch: [22][  100/  100]    Loss 2.009924    Top1 49.130000    Top5 79.100000    
2024-02-19 16:25:02,689 - ==> Top1: 49.130    Top5: 79.100    Loss: 2.010

2024-02-19 16:25:02,700 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-19 16:25:02,701 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:25:02,759 - 

2024-02-19 16:25:02,760 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:25:10,157 - Epoch: [23][  100/  500]    Overall Loss 1.491574    Objective Loss 1.491574                                        LR 0.001000    Time 0.073922    
2024-02-19 16:25:17,052 - Epoch: [23][  200/  500]    Overall Loss 1.483728    Objective Loss 1.483728                                        LR 0.001000    Time 0.071419    
2024-02-19 16:25:23,960 - Epoch: [23][  300/  500]    Overall Loss 1.485817    Objective Loss 1.485817                                        LR 0.001000    Time 0.070627    
2024-02-19 16:25:30,860 - Epoch: [23][  400/  500]    Overall Loss 1.494041    Objective Loss 1.494041                                        LR 0.001000    Time 0.070211    
2024-02-19 16:25:37,837 - Epoch: [23][  500/  500]    Overall Loss 1.495390    Objective Loss 1.495390    Top1 51.500000    Top5 80.000000    LR 0.001000    Time 0.070116    
2024-02-19 16:25:37,946 - --- validate (epoch=23)-----------
2024-02-19 16:25:37,947 - 10000 samples (100 per mini-batch)
2024-02-19 16:25:40,863 - Epoch: [23][  100/  100]    Loss 1.921122    Top1 49.480000    Top5 80.280000    
2024-02-19 16:25:41,018 - ==> Top1: 49.480    Top5: 80.280    Loss: 1.921

2024-02-19 16:25:41,029 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-19 16:25:41,030 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:25:41,090 - 

2024-02-19 16:25:41,091 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:25:48,760 - Epoch: [24][  100/  500]    Overall Loss 1.432018    Objective Loss 1.432018                                        LR 0.001000    Time 0.076646    
2024-02-19 16:25:55,656 - Epoch: [24][  200/  500]    Overall Loss 1.439184    Objective Loss 1.439184                                        LR 0.001000    Time 0.072784    
2024-02-19 16:26:02,540 - Epoch: [24][  300/  500]    Overall Loss 1.446274    Objective Loss 1.446274                                        LR 0.001000    Time 0.071456    
2024-02-19 16:26:09,438 - Epoch: [24][  400/  500]    Overall Loss 1.455156    Objective Loss 1.455156                                        LR 0.001000    Time 0.070828    
2024-02-19 16:26:16,361 - Epoch: [24][  500/  500]    Overall Loss 1.462438    Objective Loss 1.462438    Top1 54.500000    Top5 88.000000    LR 0.001000    Time 0.070500    
2024-02-19 16:26:16,512 - --- validate (epoch=24)-----------
2024-02-19 16:26:16,512 - 10000 samples (100 per mini-batch)
2024-02-19 16:26:19,694 - Epoch: [24][  100/  100]    Loss 2.288580    Top1 45.180000    Top5 76.230000    
2024-02-19 16:26:19,826 - ==> Top1: 45.180    Top5: 76.230    Loss: 2.289

2024-02-19 16:26:19,838 - ==> Best [Top1: 49.540   Top5: 80.070   Sparsity:0.00   Params: 753952 on epoch: 20]
2024-02-19 16:26:19,838 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:26:19,900 - 

2024-02-19 16:26:19,900 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:26:27,324 - Epoch: [25][  100/  500]    Overall Loss 1.423045    Objective Loss 1.423045                                        LR 0.001000    Time 0.074188    
2024-02-19 16:26:34,262 - Epoch: [25][  200/  500]    Overall Loss 1.432119    Objective Loss 1.432119                                        LR 0.001000    Time 0.071763    
2024-02-19 16:26:41,228 - Epoch: [25][  300/  500]    Overall Loss 1.435971    Objective Loss 1.435971                                        LR 0.001000    Time 0.071052    
2024-02-19 16:26:48,111 - Epoch: [25][  400/  500]    Overall Loss 1.439155    Objective Loss 1.439155                                        LR 0.001000    Time 0.070487    
2024-02-19 16:26:55,147 - Epoch: [25][  500/  500]    Overall Loss 1.446353    Objective Loss 1.446353    Top1 59.000000    Top5 88.000000    LR 0.001000    Time 0.070454    
2024-02-19 16:26:55,299 - --- validate (epoch=25)-----------
2024-02-19 16:26:55,300 - 10000 samples (100 per mini-batch)
2024-02-19 16:26:58,130 - Epoch: [25][  100/  100]    Loss 1.934736    Top1 50.320000    Top5 80.460000    
2024-02-19 16:26:58,246 - ==> Top1: 50.320    Top5: 80.460    Loss: 1.935

2024-02-19 16:26:58,257 - ==> Best [Top1: 50.320   Top5: 80.460   Sparsity:0.00   Params: 753952 on epoch: 25]
2024-02-19 16:26:58,258 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:26:58,334 - 

2024-02-19 16:26:58,335 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:27:05,801 - Epoch: [26][  100/  500]    Overall Loss 1.370702    Objective Loss 1.370702                                        LR 0.001000    Time 0.074613    
2024-02-19 16:27:12,793 - Epoch: [26][  200/  500]    Overall Loss 1.381659    Objective Loss 1.381659                                        LR 0.001000    Time 0.072247    
2024-02-19 16:27:19,811 - Epoch: [26][  300/  500]    Overall Loss 1.401317    Objective Loss 1.401317                                        LR 0.001000    Time 0.071545    
2024-02-19 16:27:26,694 - Epoch: [26][  400/  500]    Overall Loss 1.416794    Objective Loss 1.416794                                        LR 0.001000    Time 0.070856    
2024-02-19 16:27:33,690 - Epoch: [26][  500/  500]    Overall Loss 1.416493    Objective Loss 1.416493    Top1 64.500000    Top5 84.500000    LR 0.001000    Time 0.070669    
2024-02-19 16:27:33,834 - --- validate (epoch=26)-----------
2024-02-19 16:27:33,835 - 10000 samples (100 per mini-batch)
2024-02-19 16:27:37,058 - Epoch: [26][  100/  100]    Loss 1.971634    Top1 49.450000    Top5 79.280000    
2024-02-19 16:27:37,226 - ==> Top1: 49.450    Top5: 79.280    Loss: 1.972

2024-02-19 16:27:37,231 - ==> Best [Top1: 50.320   Top5: 80.460   Sparsity:0.00   Params: 753952 on epoch: 25]
2024-02-19 16:27:37,231 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:27:37,287 - 

2024-02-19 16:27:37,287 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:27:44,644 - Epoch: [27][  100/  500]    Overall Loss 1.348677    Objective Loss 1.348677                                        LR 0.001000    Time 0.073523    
2024-02-19 16:27:51,536 - Epoch: [27][  200/  500]    Overall Loss 1.366492    Objective Loss 1.366492                                        LR 0.001000    Time 0.071199    
2024-02-19 16:27:58,457 - Epoch: [27][  300/  500]    Overall Loss 1.378561    Objective Loss 1.378561                                        LR 0.001000    Time 0.070525    
2024-02-19 16:28:05,224 - Epoch: [27][  400/  500]    Overall Loss 1.381536    Objective Loss 1.381536                                        LR 0.001000    Time 0.069804    
2024-02-19 16:28:12,196 - Epoch: [27][  500/  500]    Overall Loss 1.394964    Objective Loss 1.394964    Top1 60.500000    Top5 88.000000    LR 0.001000    Time 0.069778    
2024-02-19 16:28:12,358 - --- validate (epoch=27)-----------
2024-02-19 16:28:12,359 - 10000 samples (100 per mini-batch)
2024-02-19 16:28:15,244 - Epoch: [27][  100/  100]    Loss 2.050875    Top1 49.450000    Top5 78.590000    
2024-02-19 16:28:15,365 - ==> Top1: 49.450    Top5: 78.590    Loss: 2.051

2024-02-19 16:28:15,377 - ==> Best [Top1: 50.320   Top5: 80.460   Sparsity:0.00   Params: 753952 on epoch: 25]
2024-02-19 16:28:15,378 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:28:15,439 - 

2024-02-19 16:28:15,439 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:28:23,086 - Epoch: [28][  100/  500]    Overall Loss 1.328535    Objective Loss 1.328535                                        LR 0.001000    Time 0.076420    
2024-02-19 16:28:30,023 - Epoch: [28][  200/  500]    Overall Loss 1.350845    Objective Loss 1.350845                                        LR 0.001000    Time 0.072876    
2024-02-19 16:28:36,959 - Epoch: [28][  300/  500]    Overall Loss 1.362088    Objective Loss 1.362088                                        LR 0.001000    Time 0.071691    
2024-02-19 16:28:43,937 - Epoch: [28][  400/  500]    Overall Loss 1.363851    Objective Loss 1.363851                                        LR 0.001000    Time 0.071203    
2024-02-19 16:28:50,930 - Epoch: [28][  500/  500]    Overall Loss 1.367499    Objective Loss 1.367499    Top1 62.000000    Top5 87.500000    LR 0.001000    Time 0.070942    
2024-02-19 16:28:51,099 - --- validate (epoch=28)-----------
2024-02-19 16:28:51,100 - 10000 samples (100 per mini-batch)
2024-02-19 16:28:53,906 - Epoch: [28][  100/  100]    Loss 1.873124    Top1 51.380000    Top5 81.140000    
2024-02-19 16:28:54,009 - ==> Top1: 51.380    Top5: 81.140    Loss: 1.873

2024-02-19 16:28:54,019 - ==> Best [Top1: 51.380   Top5: 81.140   Sparsity:0.00   Params: 753952 on epoch: 28]
2024-02-19 16:28:54,019 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:28:54,094 - 

2024-02-19 16:28:54,094 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:29:01,482 - Epoch: [29][  100/  500]    Overall Loss 1.325078    Objective Loss 1.325078                                        LR 0.001000    Time 0.073825    
2024-02-19 16:29:08,404 - Epoch: [29][  200/  500]    Overall Loss 1.337117    Objective Loss 1.337117                                        LR 0.001000    Time 0.071505    
2024-02-19 16:29:15,319 - Epoch: [29][  300/  500]    Overall Loss 1.347000    Objective Loss 1.347000                                        LR 0.001000    Time 0.070708    
2024-02-19 16:29:22,270 - Epoch: [29][  400/  500]    Overall Loss 1.351536    Objective Loss 1.351536                                        LR 0.001000    Time 0.070397    
2024-02-19 16:29:29,240 - Epoch: [29][  500/  500]    Overall Loss 1.354046    Objective Loss 1.354046    Top1 63.000000    Top5 88.500000    LR 0.001000    Time 0.070250    
2024-02-19 16:29:29,359 - --- validate (epoch=29)-----------
2024-02-19 16:29:29,360 - 10000 samples (100 per mini-batch)
2024-02-19 16:29:32,322 - Epoch: [29][  100/  100]    Loss 1.797290    Top1 53.410000    Top5 81.720000    
2024-02-19 16:29:32,420 - ==> Top1: 53.410    Top5: 81.720    Loss: 1.797

2024-02-19 16:29:32,431 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-19 16:29:32,431 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:29:32,506 - 

2024-02-19 16:29:32,506 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:29:39,949 - Epoch: [30][  100/  500]    Overall Loss 1.287730    Objective Loss 1.287730                                        LR 0.001000    Time 0.074377    
2024-02-19 16:29:46,916 - Epoch: [30][  200/  500]    Overall Loss 1.299301    Objective Loss 1.299301                                        LR 0.001000    Time 0.072004    
2024-02-19 16:29:53,892 - Epoch: [30][  300/  500]    Overall Loss 1.313185    Objective Loss 1.313185                                        LR 0.001000    Time 0.071241    
2024-02-19 16:30:00,870 - Epoch: [30][  400/  500]    Overall Loss 1.322461    Objective Loss 1.322461                                        LR 0.001000    Time 0.070865    
2024-02-19 16:30:07,871 - Epoch: [30][  500/  500]    Overall Loss 1.331671    Objective Loss 1.331671    Top1 67.000000    Top5 89.000000    LR 0.001000    Time 0.070686    
2024-02-19 16:30:08,015 - --- validate (epoch=30)-----------
2024-02-19 16:30:08,015 - 10000 samples (100 per mini-batch)
2024-02-19 16:30:11,302 - Epoch: [30][  100/  100]    Loss 1.824264    Top1 52.090000    Top5 80.960000    
2024-02-19 16:30:11,412 - ==> Top1: 52.090    Top5: 80.960    Loss: 1.824

2024-02-19 16:30:11,423 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-19 16:30:11,424 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:30:11,485 - 

2024-02-19 16:30:11,485 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:30:18,854 - Epoch: [31][  100/  500]    Overall Loss 1.285199    Objective Loss 1.285199                                        LR 0.001000    Time 0.073642    
2024-02-19 16:30:25,765 - Epoch: [31][  200/  500]    Overall Loss 1.281403    Objective Loss 1.281403                                        LR 0.001000    Time 0.071354    
2024-02-19 16:30:32,674 - Epoch: [31][  300/  500]    Overall Loss 1.289112    Objective Loss 1.289112                                        LR 0.001000    Time 0.070586    
2024-02-19 16:30:39,593 - Epoch: [31][  400/  500]    Overall Loss 1.297153    Objective Loss 1.297153                                        LR 0.001000    Time 0.070229    
2024-02-19 16:30:46,483 - Epoch: [31][  500/  500]    Overall Loss 1.304195    Objective Loss 1.304195    Top1 65.000000    Top5 88.000000    LR 0.001000    Time 0.069954    
2024-02-19 16:30:46,681 - --- validate (epoch=31)-----------
2024-02-19 16:30:46,681 - 10000 samples (100 per mini-batch)
2024-02-19 16:30:49,826 - Epoch: [31][  100/  100]    Loss 1.831615    Top1 52.490000    Top5 81.970000    
2024-02-19 16:30:49,943 - ==> Top1: 52.490    Top5: 81.970    Loss: 1.832

2024-02-19 16:30:49,951 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-19 16:30:49,951 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:30:50,007 - 

2024-02-19 16:30:50,007 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:30:57,715 - Epoch: [32][  100/  500]    Overall Loss 1.256892    Objective Loss 1.256892                                        LR 0.001000    Time 0.077034    
2024-02-19 16:31:04,634 - Epoch: [32][  200/  500]    Overall Loss 1.268618    Objective Loss 1.268618                                        LR 0.001000    Time 0.073091    
2024-02-19 16:31:11,530 - Epoch: [32][  300/  500]    Overall Loss 1.278748    Objective Loss 1.278748                                        LR 0.001000    Time 0.071701    
2024-02-19 16:31:18,456 - Epoch: [32][  400/  500]    Overall Loss 1.282109    Objective Loss 1.282109                                        LR 0.001000    Time 0.071082    
2024-02-19 16:31:25,442 - Epoch: [32][  500/  500]    Overall Loss 1.286492    Objective Loss 1.286492    Top1 62.000000    Top5 92.000000    LR 0.001000    Time 0.070829    
2024-02-19 16:31:25,614 - --- validate (epoch=32)-----------
2024-02-19 16:31:25,615 - 10000 samples (100 per mini-batch)
2024-02-19 16:31:28,706 - Epoch: [32][  100/  100]    Loss 1.907953    Top1 51.330000    Top5 81.220000    
2024-02-19 16:31:28,840 - ==> Top1: 51.330    Top5: 81.220    Loss: 1.908

2024-02-19 16:31:28,850 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-19 16:31:28,851 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:31:28,911 - 

2024-02-19 16:31:28,911 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:31:36,416 - Epoch: [33][  100/  500]    Overall Loss 1.234660    Objective Loss 1.234660                                        LR 0.001000    Time 0.074991    
2024-02-19 16:31:43,358 - Epoch: [33][  200/  500]    Overall Loss 1.252759    Objective Loss 1.252759                                        LR 0.001000    Time 0.072187    
2024-02-19 16:31:50,298 - Epoch: [33][  300/  500]    Overall Loss 1.261966    Objective Loss 1.261966                                        LR 0.001000    Time 0.071243    
2024-02-19 16:31:57,265 - Epoch: [33][  400/  500]    Overall Loss 1.266817    Objective Loss 1.266817                                        LR 0.001000    Time 0.070841    
2024-02-19 16:32:04,386 - Epoch: [33][  500/  500]    Overall Loss 1.273002    Objective Loss 1.273002    Top1 59.500000    Top5 85.000000    LR 0.001000    Time 0.070907    
2024-02-19 16:32:04,561 - --- validate (epoch=33)-----------
2024-02-19 16:32:04,563 - 10000 samples (100 per mini-batch)
2024-02-19 16:32:07,535 - Epoch: [33][  100/  100]    Loss 1.876940    Top1 51.540000    Top5 81.710000    
2024-02-19 16:32:07,634 - ==> Top1: 51.540    Top5: 81.710    Loss: 1.877

2024-02-19 16:32:07,644 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-19 16:32:07,645 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:32:07,708 - 

2024-02-19 16:32:07,708 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:32:15,463 - Epoch: [34][  100/  500]    Overall Loss 1.218805    Objective Loss 1.218805                                        LR 0.001000    Time 0.077496    
2024-02-19 16:32:22,400 - Epoch: [34][  200/  500]    Overall Loss 1.223326    Objective Loss 1.223326                                        LR 0.001000    Time 0.073416    
2024-02-19 16:32:29,336 - Epoch: [34][  300/  500]    Overall Loss 1.228984    Objective Loss 1.228984                                        LR 0.001000    Time 0.072050    
2024-02-19 16:32:36,263 - Epoch: [34][  400/  500]    Overall Loss 1.236273    Objective Loss 1.236273                                        LR 0.001000    Time 0.071346    
2024-02-19 16:32:43,237 - Epoch: [34][  500/  500]    Overall Loss 1.248150    Objective Loss 1.248150    Top1 64.000000    Top5 90.500000    LR 0.001000    Time 0.071017    
2024-02-19 16:32:43,371 - --- validate (epoch=34)-----------
2024-02-19 16:32:43,371 - 10000 samples (100 per mini-batch)
2024-02-19 16:32:46,166 - Epoch: [34][  100/  100]    Loss 1.937653    Top1 52.230000    Top5 80.870000    
2024-02-19 16:32:46,269 - ==> Top1: 52.230    Top5: 80.870    Loss: 1.938

2024-02-19 16:32:46,282 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-19 16:32:46,282 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:32:46,347 - 

2024-02-19 16:32:46,347 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:32:53,867 - Epoch: [35][  100/  500]    Overall Loss 1.183362    Objective Loss 1.183362                                        LR 0.001000    Time 0.075134    
2024-02-19 16:33:00,811 - Epoch: [35][  200/  500]    Overall Loss 1.197224    Objective Loss 1.197224                                        LR 0.001000    Time 0.072271    
2024-02-19 16:33:07,756 - Epoch: [35][  300/  500]    Overall Loss 1.205798    Objective Loss 1.205798                                        LR 0.001000    Time 0.071318    
2024-02-19 16:33:14,703 - Epoch: [35][  400/  500]    Overall Loss 1.225171    Objective Loss 1.225171                                        LR 0.001000    Time 0.070846    
2024-02-19 16:33:21,685 - Epoch: [35][  500/  500]    Overall Loss 1.231215    Objective Loss 1.231215    Top1 63.000000    Top5 90.000000    LR 0.001000    Time 0.070632    
2024-02-19 16:33:21,869 - --- validate (epoch=35)-----------
2024-02-19 16:33:21,870 - 10000 samples (100 per mini-batch)
2024-02-19 16:33:24,712 - Epoch: [35][  100/  100]    Loss 1.796121    Top1 53.010000    Top5 82.540000    
2024-02-19 16:33:24,805 - ==> Top1: 53.010    Top5: 82.540    Loss: 1.796

2024-02-19 16:33:24,811 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-19 16:33:24,811 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:33:24,867 - 

2024-02-19 16:33:24,868 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:33:32,654 - Epoch: [36][  100/  500]    Overall Loss 1.157656    Objective Loss 1.157656                                        LR 0.001000    Time 0.077811    
2024-02-19 16:33:39,635 - Epoch: [36][  200/  500]    Overall Loss 1.183921    Objective Loss 1.183921                                        LR 0.001000    Time 0.073792    
2024-02-19 16:33:46,617 - Epoch: [36][  300/  500]    Overall Loss 1.203144    Objective Loss 1.203144                                        LR 0.001000    Time 0.072453    
2024-02-19 16:33:53,596 - Epoch: [36][  400/  500]    Overall Loss 1.207459    Objective Loss 1.207459                                        LR 0.001000    Time 0.071778    
2024-02-19 16:34:00,597 - Epoch: [36][  500/  500]    Overall Loss 1.211898    Objective Loss 1.211898    Top1 68.000000    Top5 90.500000    LR 0.001000    Time 0.071416    
2024-02-19 16:34:00,719 - --- validate (epoch=36)-----------
2024-02-19 16:34:00,720 - 10000 samples (100 per mini-batch)
2024-02-19 16:34:03,615 - Epoch: [36][  100/  100]    Loss 1.850014    Top1 52.670000    Top5 81.390000    
2024-02-19 16:34:03,712 - ==> Top1: 52.670    Top5: 81.390    Loss: 1.850

2024-02-19 16:34:03,719 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-19 16:34:03,719 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:34:03,776 - 

2024-02-19 16:34:03,777 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:34:11,308 - Epoch: [37][  100/  500]    Overall Loss 1.168624    Objective Loss 1.168624                                        LR 0.001000    Time 0.075258    
2024-02-19 16:34:18,317 - Epoch: [37][  200/  500]    Overall Loss 1.180387    Objective Loss 1.180387                                        LR 0.001000    Time 0.072659    
2024-02-19 16:34:25,277 - Epoch: [37][  300/  500]    Overall Loss 1.177521    Objective Loss 1.177521                                        LR 0.001000    Time 0.071627    
2024-02-19 16:34:32,233 - Epoch: [37][  400/  500]    Overall Loss 1.183165    Objective Loss 1.183165                                        LR 0.001000    Time 0.071100    
2024-02-19 16:34:39,269 - Epoch: [37][  500/  500]    Overall Loss 1.195524    Objective Loss 1.195524    Top1 57.000000    Top5 86.000000    LR 0.001000    Time 0.070944    
2024-02-19 16:34:39,409 - --- validate (epoch=37)-----------
2024-02-19 16:34:39,409 - 10000 samples (100 per mini-batch)
2024-02-19 16:34:42,479 - Epoch: [37][  100/  100]    Loss 1.863734    Top1 52.960000    Top5 81.110000    
2024-02-19 16:34:42,591 - ==> Top1: 52.960    Top5: 81.110    Loss: 1.864

2024-02-19 16:34:42,603 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-19 16:34:42,604 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:34:42,665 - 

2024-02-19 16:34:42,666 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:34:50,348 - Epoch: [38][  100/  500]    Overall Loss 1.126354    Objective Loss 1.126354                                        LR 0.001000    Time 0.076769    
2024-02-19 16:34:57,290 - Epoch: [38][  200/  500]    Overall Loss 1.148542    Objective Loss 1.148542                                        LR 0.001000    Time 0.073074    
2024-02-19 16:35:04,239 - Epoch: [38][  300/  500]    Overall Loss 1.159107    Objective Loss 1.159107                                        LR 0.001000    Time 0.071867    
2024-02-19 16:35:11,187 - Epoch: [38][  400/  500]    Overall Loss 1.166049    Objective Loss 1.166049                                        LR 0.001000    Time 0.071262    
2024-02-19 16:35:18,220 - Epoch: [38][  500/  500]    Overall Loss 1.173457    Objective Loss 1.173457    Top1 60.000000    Top5 89.500000    LR 0.001000    Time 0.071066    
2024-02-19 16:35:18,397 - --- validate (epoch=38)-----------
2024-02-19 16:35:18,398 - 10000 samples (100 per mini-batch)
2024-02-19 16:35:21,356 - Epoch: [38][  100/  100]    Loss 1.933706    Top1 51.900000    Top5 81.390000    
2024-02-19 16:35:21,468 - ==> Top1: 51.900    Top5: 81.390    Loss: 1.934

2024-02-19 16:35:21,479 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-19 16:35:21,479 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:35:21,546 - 

2024-02-19 16:35:21,546 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:35:28,880 - Epoch: [39][  100/  500]    Overall Loss 1.136036    Objective Loss 1.136036                                        LR 0.001000    Time 0.073291    
2024-02-19 16:35:35,542 - Epoch: [39][  200/  500]    Overall Loss 1.146980    Objective Loss 1.146980                                        LR 0.001000    Time 0.069944    
2024-02-19 16:35:42,204 - Epoch: [39][  300/  500]    Overall Loss 1.155615    Objective Loss 1.155615                                        LR 0.001000    Time 0.068824    
2024-02-19 16:35:48,867 - Epoch: [39][  400/  500]    Overall Loss 1.160542    Objective Loss 1.160542                                        LR 0.001000    Time 0.068267    
2024-02-19 16:35:55,552 - Epoch: [39][  500/  500]    Overall Loss 1.164606    Objective Loss 1.164606    Top1 64.500000    Top5 92.500000    LR 0.001000    Time 0.067977    
2024-02-19 16:35:55,691 - --- validate (epoch=39)-----------
2024-02-19 16:35:55,692 - 10000 samples (100 per mini-batch)
2024-02-19 16:35:58,792 - Epoch: [39][  100/  100]    Loss 1.959881    Top1 52.020000    Top5 80.500000    
2024-02-19 16:35:58,901 - ==> Top1: 52.020    Top5: 80.500    Loss: 1.960

2024-02-19 16:35:58,906 - ==> Best [Top1: 53.410   Top5: 81.720   Sparsity:0.00   Params: 753952 on epoch: 29]
2024-02-19 16:35:58,906 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:35:58,965 - 

2024-02-19 16:35:58,965 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:36:06,647 - Epoch: [40][  100/  500]    Overall Loss 1.099555    Objective Loss 1.099555                                        LR 0.001000    Time 0.076766    
2024-02-19 16:36:13,523 - Epoch: [40][  200/  500]    Overall Loss 1.107798    Objective Loss 1.107798                                        LR 0.001000    Time 0.072747    
2024-02-19 16:36:20,390 - Epoch: [40][  300/  500]    Overall Loss 1.119186    Objective Loss 1.119186                                        LR 0.001000    Time 0.071376    
2024-02-19 16:36:27,273 - Epoch: [40][  400/  500]    Overall Loss 1.135157    Objective Loss 1.135157                                        LR 0.001000    Time 0.070729    
2024-02-19 16:36:34,213 - Epoch: [40][  500/  500]    Overall Loss 1.139456    Objective Loss 1.139456    Top1 67.500000    Top5 91.000000    LR 0.001000    Time 0.070457    
2024-02-19 16:36:34,339 - --- validate (epoch=40)-----------
2024-02-19 16:36:34,340 - 10000 samples (100 per mini-batch)
2024-02-19 16:36:37,102 - Epoch: [40][  100/  100]    Loss 1.839705    Top1 53.910000    Top5 82.340000    
2024-02-19 16:36:37,220 - ==> Top1: 53.910    Top5: 82.340    Loss: 1.840

2024-02-19 16:36:37,231 - ==> Best [Top1: 53.910   Top5: 82.340   Sparsity:0.00   Params: 753952 on epoch: 40]
2024-02-19 16:36:37,231 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:36:37,313 - 

2024-02-19 16:36:37,314 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:36:44,797 - Epoch: [41][  100/  500]    Overall Loss 1.098113    Objective Loss 1.098113                                        LR 0.001000    Time 0.074771    
2024-02-19 16:36:51,851 - Epoch: [41][  200/  500]    Overall Loss 1.099937    Objective Loss 1.099937                                        LR 0.001000    Time 0.072641    
2024-02-19 16:36:58,884 - Epoch: [41][  300/  500]    Overall Loss 1.105861    Objective Loss 1.105861                                        LR 0.001000    Time 0.071859    
2024-02-19 16:37:05,930 - Epoch: [41][  400/  500]    Overall Loss 1.114760    Objective Loss 1.114760                                        LR 0.001000    Time 0.071499    
2024-02-19 16:37:12,945 - Epoch: [41][  500/  500]    Overall Loss 1.122951    Objective Loss 1.122951    Top1 68.000000    Top5 91.500000    LR 0.001000    Time 0.071222    
2024-02-19 16:37:13,102 - --- validate (epoch=41)-----------
2024-02-19 16:37:13,102 - 10000 samples (100 per mini-batch)
2024-02-19 16:37:15,801 - Epoch: [41][  100/  100]    Loss 1.782460    Top1 54.690000    Top5 82.720000    
2024-02-19 16:37:15,912 - ==> Top1: 54.690    Top5: 82.720    Loss: 1.782

2024-02-19 16:37:15,924 - ==> Best [Top1: 54.690   Top5: 82.720   Sparsity:0.00   Params: 753952 on epoch: 41]
2024-02-19 16:37:15,924 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:37:15,999 - 

2024-02-19 16:37:15,999 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:37:23,517 - Epoch: [42][  100/  500]    Overall Loss 1.089304    Objective Loss 1.089304                                        LR 0.001000    Time 0.075132    
2024-02-19 16:37:30,439 - Epoch: [42][  200/  500]    Overall Loss 1.088567    Objective Loss 1.088567                                        LR 0.001000    Time 0.072158    
2024-02-19 16:37:37,372 - Epoch: [42][  300/  500]    Overall Loss 1.090409    Objective Loss 1.090409                                        LR 0.001000    Time 0.071203    
2024-02-19 16:37:44,297 - Epoch: [42][  400/  500]    Overall Loss 1.103778    Objective Loss 1.103778                                        LR 0.001000    Time 0.070706    
2024-02-19 16:37:51,266 - Epoch: [42][  500/  500]    Overall Loss 1.108860    Objective Loss 1.108860    Top1 71.500000    Top5 90.000000    LR 0.001000    Time 0.070495    
2024-02-19 16:37:51,401 - --- validate (epoch=42)-----------
2024-02-19 16:37:51,402 - 10000 samples (100 per mini-batch)
2024-02-19 16:37:54,403 - Epoch: [42][  100/  100]    Loss 1.801879    Top1 54.520000    Top5 82.590000    
2024-02-19 16:37:54,489 - ==> Top1: 54.520    Top5: 82.590    Loss: 1.802

2024-02-19 16:37:54,498 - ==> Best [Top1: 54.690   Top5: 82.720   Sparsity:0.00   Params: 753952 on epoch: 41]
2024-02-19 16:37:54,499 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:37:54,550 - 

2024-02-19 16:37:54,550 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:38:01,819 - Epoch: [43][  100/  500]    Overall Loss 1.059019    Objective Loss 1.059019                                        LR 0.001000    Time 0.072642    
2024-02-19 16:38:08,760 - Epoch: [43][  200/  500]    Overall Loss 1.070833    Objective Loss 1.070833                                        LR 0.001000    Time 0.071007    
2024-02-19 16:38:15,664 - Epoch: [43][  300/  500]    Overall Loss 1.076827    Objective Loss 1.076827                                        LR 0.001000    Time 0.070339    
2024-02-19 16:38:22,568 - Epoch: [43][  400/  500]    Overall Loss 1.089423    Objective Loss 1.089423                                        LR 0.001000    Time 0.070006    
2024-02-19 16:38:29,506 - Epoch: [43][  500/  500]    Overall Loss 1.100200    Objective Loss 1.100200    Top1 63.000000    Top5 89.000000    LR 0.001000    Time 0.069872    
2024-02-19 16:38:29,611 - --- validate (epoch=43)-----------
2024-02-19 16:38:29,611 - 10000 samples (100 per mini-batch)
2024-02-19 16:38:32,440 - Epoch: [43][  100/  100]    Loss 1.852823    Top1 53.770000    Top5 83.190000    
2024-02-19 16:38:32,552 - ==> Top1: 53.770    Top5: 83.190    Loss: 1.853

2024-02-19 16:38:32,563 - ==> Best [Top1: 54.690   Top5: 82.720   Sparsity:0.00   Params: 753952 on epoch: 41]
2024-02-19 16:38:32,563 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:38:32,615 - 

2024-02-19 16:38:32,616 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:38:40,263 - Epoch: [44][  100/  500]    Overall Loss 1.047904    Objective Loss 1.047904                                        LR 0.001000    Time 0.076406    
2024-02-19 16:38:47,236 - Epoch: [44][  200/  500]    Overall Loss 1.062250    Objective Loss 1.062250                                        LR 0.001000    Time 0.073046    
2024-02-19 16:38:54,193 - Epoch: [44][  300/  500]    Overall Loss 1.065268    Objective Loss 1.065268                                        LR 0.001000    Time 0.071876    
2024-02-19 16:39:01,155 - Epoch: [44][  400/  500]    Overall Loss 1.066647    Objective Loss 1.066647                                        LR 0.001000    Time 0.071301    
2024-02-19 16:39:08,126 - Epoch: [44][  500/  500]    Overall Loss 1.078985    Objective Loss 1.078985    Top1 67.000000    Top5 87.500000    LR 0.001000    Time 0.070975    
2024-02-19 16:39:08,248 - --- validate (epoch=44)-----------
2024-02-19 16:39:08,249 - 10000 samples (100 per mini-batch)
2024-02-19 16:39:11,016 - Epoch: [44][  100/  100]    Loss 1.821990    Top1 54.740000    Top5 82.280000    
2024-02-19 16:39:11,127 - ==> Top1: 54.740    Top5: 82.280    Loss: 1.822

2024-02-19 16:39:11,138 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-19 16:39:11,138 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:39:11,214 - 

2024-02-19 16:39:11,214 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:39:18,648 - Epoch: [45][  100/  500]    Overall Loss 1.003887    Objective Loss 1.003887                                        LR 0.001000    Time 0.074287    
2024-02-19 16:39:25,674 - Epoch: [45][  200/  500]    Overall Loss 1.031504    Objective Loss 1.031504                                        LR 0.001000    Time 0.072255    
2024-02-19 16:39:32,694 - Epoch: [45][  300/  500]    Overall Loss 1.046354    Objective Loss 1.046354                                        LR 0.001000    Time 0.071558    
2024-02-19 16:39:39,704 - Epoch: [45][  400/  500]    Overall Loss 1.056035    Objective Loss 1.056035                                        LR 0.001000    Time 0.071185    
2024-02-19 16:39:46,749 - Epoch: [45][  500/  500]    Overall Loss 1.068227    Objective Loss 1.068227    Top1 66.000000    Top5 89.000000    LR 0.001000    Time 0.071030    
2024-02-19 16:39:46,907 - --- validate (epoch=45)-----------
2024-02-19 16:39:46,907 - 10000 samples (100 per mini-batch)
2024-02-19 16:39:49,726 - Epoch: [45][  100/  100]    Loss 1.828801    Top1 54.110000    Top5 82.480000    
2024-02-19 16:39:49,823 - ==> Top1: 54.110    Top5: 82.480    Loss: 1.829

2024-02-19 16:39:49,829 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-19 16:39:49,829 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:39:49,886 - 

2024-02-19 16:39:49,886 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:39:57,706 - Epoch: [46][  100/  500]    Overall Loss 1.009476    Objective Loss 1.009476                                        LR 0.001000    Time 0.078144    
2024-02-19 16:40:04,710 - Epoch: [46][  200/  500]    Overall Loss 1.027685    Objective Loss 1.027685                                        LR 0.001000    Time 0.074074    
2024-02-19 16:40:11,646 - Epoch: [46][  300/  500]    Overall Loss 1.036520    Objective Loss 1.036520                                        LR 0.001000    Time 0.072490    
2024-02-19 16:40:18,594 - Epoch: [46][  400/  500]    Overall Loss 1.042552    Objective Loss 1.042552                                        LR 0.001000    Time 0.071728    
2024-02-19 16:40:25,600 - Epoch: [46][  500/  500]    Overall Loss 1.052531    Objective Loss 1.052531    Top1 73.000000    Top5 96.000000    LR 0.001000    Time 0.071387    
2024-02-19 16:40:25,730 - --- validate (epoch=46)-----------
2024-02-19 16:40:25,731 - 10000 samples (100 per mini-batch)
2024-02-19 16:40:28,454 - Epoch: [46][  100/  100]    Loss 1.830720    Top1 53.730000    Top5 82.630000    
2024-02-19 16:40:28,562 - ==> Top1: 53.730    Top5: 82.630    Loss: 1.831

2024-02-19 16:40:28,569 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-19 16:40:28,569 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:40:28,623 - 

2024-02-19 16:40:28,623 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:40:36,054 - Epoch: [47][  100/  500]    Overall Loss 0.999660    Objective Loss 0.999660                                        LR 0.001000    Time 0.074257    
2024-02-19 16:40:43,051 - Epoch: [47][  200/  500]    Overall Loss 1.003852    Objective Loss 1.003852                                        LR 0.001000    Time 0.072096    
2024-02-19 16:40:50,308 - Epoch: [47][  300/  500]    Overall Loss 1.014563    Objective Loss 1.014563                                        LR 0.001000    Time 0.072238    
2024-02-19 16:40:57,575 - Epoch: [47][  400/  500]    Overall Loss 1.020945    Objective Loss 1.020945                                        LR 0.001000    Time 0.072338    
2024-02-19 16:41:04,902 - Epoch: [47][  500/  500]    Overall Loss 1.030677    Objective Loss 1.030677    Top1 70.000000    Top5 95.000000    LR 0.001000    Time 0.072516    
2024-02-19 16:41:05,076 - --- validate (epoch=47)-----------
2024-02-19 16:41:05,077 - 10000 samples (100 per mini-batch)
2024-02-19 16:41:07,911 - Epoch: [47][  100/  100]    Loss 1.896644    Top1 54.310000    Top5 82.350000    
2024-02-19 16:41:08,009 - ==> Top1: 54.310    Top5: 82.350    Loss: 1.897

2024-02-19 16:41:08,019 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-19 16:41:08,019 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:41:08,079 - 

2024-02-19 16:41:08,080 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:41:16,011 - Epoch: [48][  100/  500]    Overall Loss 1.005949    Objective Loss 1.005949                                        LR 0.001000    Time 0.079251    
2024-02-19 16:41:23,062 - Epoch: [48][  200/  500]    Overall Loss 1.002851    Objective Loss 1.002851                                        LR 0.001000    Time 0.074858    
2024-02-19 16:41:30,119 - Epoch: [48][  300/  500]    Overall Loss 1.013319    Objective Loss 1.013319                                        LR 0.001000    Time 0.073418    
2024-02-19 16:41:37,103 - Epoch: [48][  400/  500]    Overall Loss 1.015516    Objective Loss 1.015516                                        LR 0.001000    Time 0.072512    
2024-02-19 16:41:44,106 - Epoch: [48][  500/  500]    Overall Loss 1.024054    Objective Loss 1.024054    Top1 69.000000    Top5 93.000000    LR 0.001000    Time 0.072008    
2024-02-19 16:41:44,252 - --- validate (epoch=48)-----------
2024-02-19 16:41:44,253 - 10000 samples (100 per mini-batch)
2024-02-19 16:41:47,108 - Epoch: [48][  100/  100]    Loss 1.873272    Top1 54.180000    Top5 82.180000    
2024-02-19 16:41:47,226 - ==> Top1: 54.180    Top5: 82.180    Loss: 1.873

2024-02-19 16:41:47,238 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-19 16:41:47,239 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:41:47,300 - 

2024-02-19 16:41:47,300 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:41:54,710 - Epoch: [49][  100/  500]    Overall Loss 0.991793    Objective Loss 0.991793                                        LR 0.001000    Time 0.074055    
2024-02-19 16:42:01,673 - Epoch: [49][  200/  500]    Overall Loss 0.981546    Objective Loss 0.981546                                        LR 0.001000    Time 0.071819    
2024-02-19 16:42:08,600 - Epoch: [49][  300/  500]    Overall Loss 0.990645    Objective Loss 0.990645                                        LR 0.001000    Time 0.070958    
2024-02-19 16:42:15,504 - Epoch: [49][  400/  500]    Overall Loss 1.000108    Objective Loss 1.000108                                        LR 0.001000    Time 0.070470    
2024-02-19 16:42:22,434 - Epoch: [49][  500/  500]    Overall Loss 1.004350    Objective Loss 1.004350    Top1 66.000000    Top5 91.000000    LR 0.001000    Time 0.070228    
2024-02-19 16:42:22,574 - --- validate (epoch=49)-----------
2024-02-19 16:42:22,575 - 10000 samples (100 per mini-batch)
2024-02-19 16:42:25,301 - Epoch: [49][  100/  100]    Loss 1.923390    Top1 53.300000    Top5 82.380000    
2024-02-19 16:42:25,424 - ==> Top1: 53.300    Top5: 82.380    Loss: 1.923

2024-02-19 16:42:25,436 - ==> Best [Top1: 54.740   Top5: 82.280   Sparsity:0.00   Params: 753952 on epoch: 44]
2024-02-19 16:42:25,437 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:42:25,498 - 

2024-02-19 16:42:25,499 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:42:33,134 - Epoch: [50][  100/  500]    Overall Loss 0.891832    Objective Loss 0.891832                                        LR 0.000500    Time 0.076303    
2024-02-19 16:42:40,051 - Epoch: [50][  200/  500]    Overall Loss 0.875344    Objective Loss 0.875344                                        LR 0.000500    Time 0.072718    
2024-02-19 16:42:47,007 - Epoch: [50][  300/  500]    Overall Loss 0.871916    Objective Loss 0.871916                                        LR 0.000500    Time 0.071652    
2024-02-19 16:42:53,918 - Epoch: [50][  400/  500]    Overall Loss 0.872488    Objective Loss 0.872488                                        LR 0.000500    Time 0.071008    
2024-02-19 16:43:01,088 - Epoch: [50][  500/  500]    Overall Loss 0.877727    Objective Loss 0.877727    Top1 69.000000    Top5 92.500000    LR 0.000500    Time 0.071139    
2024-02-19 16:43:01,207 - --- validate (epoch=50)-----------
2024-02-19 16:43:01,208 - 10000 samples (100 per mini-batch)
2024-02-19 16:43:04,070 - Epoch: [50][  100/  100]    Loss 1.586217    Top1 58.580000    Top5 85.530000    
2024-02-19 16:43:04,232 - ==> Top1: 58.580    Top5: 85.530    Loss: 1.586

2024-02-19 16:43:04,243 - ==> Best [Top1: 58.580   Top5: 85.530   Sparsity:0.00   Params: 753952 on epoch: 50]
2024-02-19 16:43:04,243 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:43:04,316 - 

2024-02-19 16:43:04,316 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:43:11,799 - Epoch: [51][  100/  500]    Overall Loss 0.807896    Objective Loss 0.807896                                        LR 0.000500    Time 0.074782    
2024-02-19 16:43:18,788 - Epoch: [51][  200/  500]    Overall Loss 0.833882    Objective Loss 0.833882                                        LR 0.000500    Time 0.072312    
2024-02-19 16:43:25,708 - Epoch: [51][  300/  500]    Overall Loss 0.841966    Objective Loss 0.841966                                        LR 0.000500    Time 0.071264    
2024-02-19 16:43:32,390 - Epoch: [51][  400/  500]    Overall Loss 0.849738    Objective Loss 0.849738                                        LR 0.000500    Time 0.070144    
2024-02-19 16:43:39,104 - Epoch: [51][  500/  500]    Overall Loss 0.849891    Objective Loss 0.849891    Top1 72.000000    Top5 95.500000    LR 0.000500    Time 0.069537    
2024-02-19 16:43:39,230 - --- validate (epoch=51)-----------
2024-02-19 16:43:39,231 - 10000 samples (100 per mini-batch)
2024-02-19 16:43:42,009 - Epoch: [51][  100/  100]    Loss 1.623510    Top1 58.210000    Top5 85.200000    
2024-02-19 16:43:42,114 - ==> Top1: 58.210    Top5: 85.200    Loss: 1.624

2024-02-19 16:43:42,125 - ==> Best [Top1: 58.580   Top5: 85.530   Sparsity:0.00   Params: 753952 on epoch: 50]
2024-02-19 16:43:42,125 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:43:42,186 - 

2024-02-19 16:43:42,187 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:43:49,581 - Epoch: [52][  100/  500]    Overall Loss 0.800980    Objective Loss 0.800980                                        LR 0.000500    Time 0.073893    
2024-02-19 16:43:56,534 - Epoch: [52][  200/  500]    Overall Loss 0.809246    Objective Loss 0.809246                                        LR 0.000500    Time 0.071691    
2024-02-19 16:44:03,451 - Epoch: [52][  300/  500]    Overall Loss 0.815269    Objective Loss 0.815269                                        LR 0.000500    Time 0.070839    
2024-02-19 16:44:10,113 - Epoch: [52][  400/  500]    Overall Loss 0.828829    Objective Loss 0.828829                                        LR 0.000500    Time 0.069777    
2024-02-19 16:44:16,888 - Epoch: [52][  500/  500]    Overall Loss 0.833809    Objective Loss 0.833809    Top1 72.000000    Top5 93.000000    LR 0.000500    Time 0.069364    
2024-02-19 16:44:17,021 - --- validate (epoch=52)-----------
2024-02-19 16:44:17,022 - 10000 samples (100 per mini-batch)
2024-02-19 16:44:20,140 - Epoch: [52][  100/  100]    Loss 1.649348    Top1 58.060000    Top5 85.130000    
2024-02-19 16:44:20,245 - ==> Top1: 58.060    Top5: 85.130    Loss: 1.649

2024-02-19 16:44:20,251 - ==> Best [Top1: 58.580   Top5: 85.530   Sparsity:0.00   Params: 753952 on epoch: 50]
2024-02-19 16:44:20,251 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:44:20,309 - 

2024-02-19 16:44:20,309 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:44:27,723 - Epoch: [53][  100/  500]    Overall Loss 0.789713    Objective Loss 0.789713                                        LR 0.000500    Time 0.074087    
2024-02-19 16:44:34,694 - Epoch: [53][  200/  500]    Overall Loss 0.799589    Objective Loss 0.799589                                        LR 0.000500    Time 0.071876    
2024-02-19 16:44:41,710 - Epoch: [53][  300/  500]    Overall Loss 0.810559    Objective Loss 0.810559                                        LR 0.000500    Time 0.071292    
2024-02-19 16:44:48,616 - Epoch: [53][  400/  500]    Overall Loss 0.815939    Objective Loss 0.815939                                        LR 0.000500    Time 0.070724    
2024-02-19 16:44:55,489 - Epoch: [53][  500/  500]    Overall Loss 0.820874    Objective Loss 0.820874    Top1 70.000000    Top5 95.000000    LR 0.000500    Time 0.070318    
2024-02-19 16:44:55,611 - --- validate (epoch=53)-----------
2024-02-19 16:44:55,611 - 10000 samples (100 per mini-batch)
2024-02-19 16:44:58,450 - Epoch: [53][  100/  100]    Loss 1.603811    Top1 58.960000    Top5 85.370000    
2024-02-19 16:44:58,618 - ==> Top1: 58.960    Top5: 85.370    Loss: 1.604

2024-02-19 16:44:58,628 - ==> Best [Top1: 58.960   Top5: 85.370   Sparsity:0.00   Params: 753952 on epoch: 53]
2024-02-19 16:44:58,629 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:44:58,703 - 

2024-02-19 16:44:58,703 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:45:06,301 - Epoch: [54][  100/  500]    Overall Loss 0.796024    Objective Loss 0.796024                                        LR 0.000500    Time 0.075929    
2024-02-19 16:45:13,199 - Epoch: [54][  200/  500]    Overall Loss 0.797079    Objective Loss 0.797079                                        LR 0.000500    Time 0.072435    
2024-02-19 16:45:20,143 - Epoch: [54][  300/  500]    Overall Loss 0.806079    Objective Loss 0.806079                                        LR 0.000500    Time 0.071425    
2024-02-19 16:45:27,133 - Epoch: [54][  400/  500]    Overall Loss 0.813309    Objective Loss 0.813309                                        LR 0.000500    Time 0.071034    
2024-02-19 16:45:34,050 - Epoch: [54][  500/  500]    Overall Loss 0.818176    Objective Loss 0.818176    Top1 76.500000    Top5 96.000000    LR 0.000500    Time 0.070654    
2024-02-19 16:45:34,185 - --- validate (epoch=54)-----------
2024-02-19 16:45:34,185 - 10000 samples (100 per mini-batch)
2024-02-19 16:45:37,181 - Epoch: [54][  100/  100]    Loss 1.654874    Top1 58.370000    Top5 84.970000    
2024-02-19 16:45:37,305 - ==> Top1: 58.370    Top5: 84.970    Loss: 1.655

2024-02-19 16:45:37,315 - ==> Best [Top1: 58.960   Top5: 85.370   Sparsity:0.00   Params: 753952 on epoch: 53]
2024-02-19 16:45:37,316 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:45:37,375 - 

2024-02-19 16:45:37,376 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:45:44,739 - Epoch: [55][  100/  500]    Overall Loss 0.769146    Objective Loss 0.769146                                        LR 0.000500    Time 0.073579    
2024-02-19 16:45:51,758 - Epoch: [55][  200/  500]    Overall Loss 0.780171    Objective Loss 0.780171                                        LR 0.000500    Time 0.071865    
2024-02-19 16:45:58,720 - Epoch: [55][  300/  500]    Overall Loss 0.789821    Objective Loss 0.789821                                        LR 0.000500    Time 0.071104    
2024-02-19 16:46:05,756 - Epoch: [55][  400/  500]    Overall Loss 0.797652    Objective Loss 0.797652                                        LR 0.000500    Time 0.070908    
2024-02-19 16:46:12,918 - Epoch: [55][  500/  500]    Overall Loss 0.802727    Objective Loss 0.802727    Top1 80.000000    Top5 95.500000    LR 0.000500    Time 0.071044    
2024-02-19 16:46:13,045 - --- validate (epoch=55)-----------
2024-02-19 16:46:13,045 - 10000 samples (100 per mini-batch)
2024-02-19 16:46:15,905 - Epoch: [55][  100/  100]    Loss 1.577737    Top1 59.690000    Top5 85.980000    
2024-02-19 16:46:16,015 - ==> Top1: 59.690    Top5: 85.980    Loss: 1.578

2024-02-19 16:46:16,021 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-19 16:46:16,021 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:46:16,092 - 

2024-02-19 16:46:16,092 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:46:23,747 - Epoch: [56][  100/  500]    Overall Loss 0.767662    Objective Loss 0.767662                                        LR 0.000500    Time 0.076494    
2024-02-19 16:46:30,731 - Epoch: [56][  200/  500]    Overall Loss 0.775037    Objective Loss 0.775037                                        LR 0.000500    Time 0.073148    
2024-02-19 16:46:37,665 - Epoch: [56][  300/  500]    Overall Loss 0.782996    Objective Loss 0.782996                                        LR 0.000500    Time 0.071866    
2024-02-19 16:46:44,598 - Epoch: [56][  400/  500]    Overall Loss 0.793193    Objective Loss 0.793193                                        LR 0.000500    Time 0.071222    
2024-02-19 16:46:51,261 - Epoch: [56][  500/  500]    Overall Loss 0.798635    Objective Loss 0.798635    Top1 76.500000    Top5 95.500000    LR 0.000500    Time 0.070299    
2024-02-19 16:46:51,427 - --- validate (epoch=56)-----------
2024-02-19 16:46:51,428 - 10000 samples (100 per mini-batch)
2024-02-19 16:46:54,180 - Epoch: [56][  100/  100]    Loss 1.677374    Top1 57.960000    Top5 85.060000    
2024-02-19 16:46:54,341 - ==> Top1: 57.960    Top5: 85.060    Loss: 1.677

2024-02-19 16:46:54,351 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-19 16:46:54,352 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:46:54,411 - 

2024-02-19 16:46:54,411 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:47:01,815 - Epoch: [57][  100/  500]    Overall Loss 0.748854    Objective Loss 0.748854                                        LR 0.000500    Time 0.073990    
2024-02-19 16:47:08,693 - Epoch: [57][  200/  500]    Overall Loss 0.757948    Objective Loss 0.757948                                        LR 0.000500    Time 0.071369    
2024-02-19 16:47:15,356 - Epoch: [57][  300/  500]    Overall Loss 0.768813    Objective Loss 0.768813                                        LR 0.000500    Time 0.069779    
2024-02-19 16:47:22,084 - Epoch: [57][  400/  500]    Overall Loss 0.777358    Objective Loss 0.777358                                        LR 0.000500    Time 0.069146    
2024-02-19 16:47:29,060 - Epoch: [57][  500/  500]    Overall Loss 0.782456    Objective Loss 0.782456    Top1 78.000000    Top5 95.000000    LR 0.000500    Time 0.069262    
2024-02-19 16:47:29,238 - --- validate (epoch=57)-----------
2024-02-19 16:47:29,239 - 10000 samples (100 per mini-batch)
2024-02-19 16:47:32,032 - Epoch: [57][  100/  100]    Loss 1.637951    Top1 58.710000    Top5 85.710000    
2024-02-19 16:47:32,131 - ==> Top1: 58.710    Top5: 85.710    Loss: 1.638

2024-02-19 16:47:32,142 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-19 16:47:32,142 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:47:32,202 - 

2024-02-19 16:47:32,202 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:47:39,934 - Epoch: [58][  100/  500]    Overall Loss 0.757408    Objective Loss 0.757408                                        LR 0.000500    Time 0.077272    
2024-02-19 16:47:47,083 - Epoch: [58][  200/  500]    Overall Loss 0.752679    Objective Loss 0.752679                                        LR 0.000500    Time 0.074359    
2024-02-19 16:47:53,991 - Epoch: [58][  300/  500]    Overall Loss 0.761102    Objective Loss 0.761102                                        LR 0.000500    Time 0.072589    
2024-02-19 16:48:00,925 - Epoch: [58][  400/  500]    Overall Loss 0.769629    Objective Loss 0.769629                                        LR 0.000500    Time 0.071767    
2024-02-19 16:48:08,000 - Epoch: [58][  500/  500]    Overall Loss 0.776744    Objective Loss 0.776744    Top1 75.500000    Top5 94.500000    LR 0.000500    Time 0.071556    
2024-02-19 16:48:08,129 - --- validate (epoch=58)-----------
2024-02-19 16:48:08,130 - 10000 samples (100 per mini-batch)
2024-02-19 16:48:10,931 - Epoch: [58][  100/  100]    Loss 1.693725    Top1 58.040000    Top5 84.660000    
2024-02-19 16:48:11,051 - ==> Top1: 58.040    Top5: 84.660    Loss: 1.694

2024-02-19 16:48:11,061 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-19 16:48:11,062 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:48:11,121 - 

2024-02-19 16:48:11,121 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:48:18,525 - Epoch: [59][  100/  500]    Overall Loss 0.725762    Objective Loss 0.725762                                        LR 0.000500    Time 0.073984    
2024-02-19 16:48:25,423 - Epoch: [59][  200/  500]    Overall Loss 0.742909    Objective Loss 0.742909                                        LR 0.000500    Time 0.071464    
2024-02-19 16:48:32,338 - Epoch: [59][  300/  500]    Overall Loss 0.745777    Objective Loss 0.745777                                        LR 0.000500    Time 0.070681    
2024-02-19 16:48:39,266 - Epoch: [59][  400/  500]    Overall Loss 0.756595    Objective Loss 0.756595                                        LR 0.000500    Time 0.070323    
2024-02-19 16:48:46,314 - Epoch: [59][  500/  500]    Overall Loss 0.762398    Objective Loss 0.762398    Top1 74.500000    Top5 96.000000    LR 0.000500    Time 0.070346    
2024-02-19 16:48:46,462 - --- validate (epoch=59)-----------
2024-02-19 16:48:46,463 - 10000 samples (100 per mini-batch)
2024-02-19 16:48:49,200 - Epoch: [59][  100/  100]    Loss 1.658248    Top1 58.860000    Top5 85.150000    
2024-02-19 16:48:49,378 - ==> Top1: 58.860    Top5: 85.150    Loss: 1.658

2024-02-19 16:48:49,388 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-19 16:48:49,389 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:48:49,450 - 

2024-02-19 16:48:49,450 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:48:57,076 - Epoch: [60][  100/  500]    Overall Loss 0.717924    Objective Loss 0.717924                                        LR 0.000500    Time 0.076213    
2024-02-19 16:49:03,983 - Epoch: [60][  200/  500]    Overall Loss 0.740746    Objective Loss 0.740746                                        LR 0.000500    Time 0.072622    
2024-02-19 16:49:10,930 - Epoch: [60][  300/  500]    Overall Loss 0.746455    Objective Loss 0.746455                                        LR 0.000500    Time 0.071561    
2024-02-19 16:49:17,844 - Epoch: [60][  400/  500]    Overall Loss 0.755625    Objective Loss 0.755625                                        LR 0.000500    Time 0.070945    
2024-02-19 16:49:24,928 - Epoch: [60][  500/  500]    Overall Loss 0.761782    Objective Loss 0.761782    Top1 77.000000    Top5 96.000000    LR 0.000500    Time 0.070916    
2024-02-19 16:49:25,053 - --- validate (epoch=60)-----------
2024-02-19 16:49:25,054 - 10000 samples (100 per mini-batch)
2024-02-19 16:49:27,931 - Epoch: [60][  100/  100]    Loss 1.683339    Top1 57.680000    Top5 85.160000    
2024-02-19 16:49:28,026 - ==> Top1: 57.680    Top5: 85.160    Loss: 1.683

2024-02-19 16:49:28,031 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-19 16:49:28,031 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:49:28,087 - 

2024-02-19 16:49:28,088 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:49:35,508 - Epoch: [61][  100/  500]    Overall Loss 0.723786    Objective Loss 0.723786                                        LR 0.000500    Time 0.074154    
2024-02-19 16:49:42,433 - Epoch: [61][  200/  500]    Overall Loss 0.725941    Objective Loss 0.725941                                        LR 0.000500    Time 0.071683    
2024-02-19 16:49:49,430 - Epoch: [61][  300/  500]    Overall Loss 0.736931    Objective Loss 0.736931                                        LR 0.000500    Time 0.071098    
2024-02-19 16:49:56,350 - Epoch: [61][  400/  500]    Overall Loss 0.743888    Objective Loss 0.743888                                        LR 0.000500    Time 0.070615    
2024-02-19 16:50:03,433 - Epoch: [61][  500/  500]    Overall Loss 0.750233    Objective Loss 0.750233    Top1 76.500000    Top5 97.000000    LR 0.000500    Time 0.070650    
2024-02-19 16:50:03,597 - --- validate (epoch=61)-----------
2024-02-19 16:50:03,598 - 10000 samples (100 per mini-batch)
2024-02-19 16:50:06,531 - Epoch: [61][  100/  100]    Loss 1.703892    Top1 58.030000    Top5 84.660000    
2024-02-19 16:50:06,629 - ==> Top1: 58.030    Top5: 84.660    Loss: 1.704

2024-02-19 16:50:06,636 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-19 16:50:06,636 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:50:06,690 - 

2024-02-19 16:50:06,691 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:50:14,040 - Epoch: [62][  100/  500]    Overall Loss 0.716316    Objective Loss 0.716316                                        LR 0.000500    Time 0.073449    
2024-02-19 16:50:20,929 - Epoch: [62][  200/  500]    Overall Loss 0.725154    Objective Loss 0.725154                                        LR 0.000500    Time 0.071151    
2024-02-19 16:50:27,988 - Epoch: [62][  300/  500]    Overall Loss 0.726598    Objective Loss 0.726598                                        LR 0.000500    Time 0.070950    
2024-02-19 16:50:35,148 - Epoch: [62][  400/  500]    Overall Loss 0.732765    Objective Loss 0.732765                                        LR 0.000500    Time 0.071105    
2024-02-19 16:50:42,168 - Epoch: [62][  500/  500]    Overall Loss 0.735718    Objective Loss 0.735718    Top1 77.500000    Top5 97.000000    LR 0.000500    Time 0.070916    
2024-02-19 16:50:42,300 - --- validate (epoch=62)-----------
2024-02-19 16:50:42,301 - 10000 samples (100 per mini-batch)
2024-02-19 16:50:45,285 - Epoch: [62][  100/  100]    Loss 1.695187    Top1 58.080000    Top5 84.730000    
2024-02-19 16:50:45,383 - ==> Top1: 58.080    Top5: 84.730    Loss: 1.695

2024-02-19 16:50:45,390 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-19 16:50:45,390 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:50:45,631 - 

2024-02-19 16:50:45,631 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:50:53,041 - Epoch: [63][  100/  500]    Overall Loss 0.708055    Objective Loss 0.708055                                        LR 0.000500    Time 0.074048    
2024-02-19 16:51:00,003 - Epoch: [63][  200/  500]    Overall Loss 0.707810    Objective Loss 0.707810                                        LR 0.000500    Time 0.071818    
2024-02-19 16:51:07,097 - Epoch: [63][  300/  500]    Overall Loss 0.714700    Objective Loss 0.714700                                        LR 0.000500    Time 0.071513    
2024-02-19 16:51:14,089 - Epoch: [63][  400/  500]    Overall Loss 0.722657    Objective Loss 0.722657                                        LR 0.000500    Time 0.071105    
2024-02-19 16:51:21,146 - Epoch: [63][  500/  500]    Overall Loss 0.728273    Objective Loss 0.728273    Top1 78.000000    Top5 94.500000    LR 0.000500    Time 0.070990    
2024-02-19 16:51:21,295 - --- validate (epoch=63)-----------
2024-02-19 16:51:21,296 - 10000 samples (100 per mini-batch)
2024-02-19 16:51:24,246 - Epoch: [63][  100/  100]    Loss 1.712738    Top1 58.530000    Top5 85.230000    
2024-02-19 16:51:24,356 - ==> Top1: 58.530    Top5: 85.230    Loss: 1.713

2024-02-19 16:51:24,366 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-19 16:51:24,367 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:51:24,428 - 

2024-02-19 16:51:24,428 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:51:31,788 - Epoch: [64][  100/  500]    Overall Loss 0.699875    Objective Loss 0.699875                                        LR 0.000500    Time 0.073543    
2024-02-19 16:51:38,725 - Epoch: [64][  200/  500]    Overall Loss 0.711025    Objective Loss 0.711025                                        LR 0.000500    Time 0.071440    
2024-02-19 16:51:45,597 - Epoch: [64][  300/  500]    Overall Loss 0.711866    Objective Loss 0.711866                                        LR 0.000500    Time 0.070520    
2024-02-19 16:51:52,282 - Epoch: [64][  400/  500]    Overall Loss 0.718434    Objective Loss 0.718434                                        LR 0.000500    Time 0.069596    
2024-02-19 16:51:59,017 - Epoch: [64][  500/  500]    Overall Loss 0.721861    Objective Loss 0.721861    Top1 80.000000    Top5 97.500000    LR 0.000500    Time 0.069140    
2024-02-19 16:51:59,181 - --- validate (epoch=64)-----------
2024-02-19 16:51:59,182 - 10000 samples (100 per mini-batch)
2024-02-19 16:52:02,169 - Epoch: [64][  100/  100]    Loss 1.672986    Top1 58.580000    Top5 85.230000    
2024-02-19 16:52:02,331 - ==> Top1: 58.580    Top5: 85.230    Loss: 1.673

2024-02-19 16:52:02,339 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-19 16:52:02,340 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:52:02,404 - 

2024-02-19 16:52:02,405 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:52:09,892 - Epoch: [65][  100/  500]    Overall Loss 0.685307    Objective Loss 0.685307                                        LR 0.000500    Time 0.074822    
2024-02-19 16:52:16,855 - Epoch: [65][  200/  500]    Overall Loss 0.691732    Objective Loss 0.691732                                        LR 0.000500    Time 0.072209    
2024-02-19 16:52:23,834 - Epoch: [65][  300/  500]    Overall Loss 0.702046    Objective Loss 0.702046                                        LR 0.000500    Time 0.071389    
2024-02-19 16:52:30,815 - Epoch: [65][  400/  500]    Overall Loss 0.707181    Objective Loss 0.707181                                        LR 0.000500    Time 0.070984    
2024-02-19 16:52:37,933 - Epoch: [65][  500/  500]    Overall Loss 0.714602    Objective Loss 0.714602    Top1 77.000000    Top5 96.000000    LR 0.000500    Time 0.071015    
2024-02-19 16:52:38,049 - --- validate (epoch=65)-----------
2024-02-19 16:52:38,049 - 10000 samples (100 per mini-batch)
2024-02-19 16:52:40,930 - Epoch: [65][  100/  100]    Loss 1.658163    Top1 58.720000    Top5 85.510000    
2024-02-19 16:52:41,040 - ==> Top1: 58.720    Top5: 85.510    Loss: 1.658

2024-02-19 16:52:41,050 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-19 16:52:41,051 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:52:41,110 - 

2024-02-19 16:52:41,110 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:52:48,890 - Epoch: [66][  100/  500]    Overall Loss 0.674366    Objective Loss 0.674366                                        LR 0.000500    Time 0.077741    
2024-02-19 16:52:55,978 - Epoch: [66][  200/  500]    Overall Loss 0.684975    Objective Loss 0.684975                                        LR 0.000500    Time 0.074297    
2024-02-19 16:53:03,047 - Epoch: [66][  300/  500]    Overall Loss 0.694046    Objective Loss 0.694046                                        LR 0.000500    Time 0.073080    
2024-02-19 16:53:10,020 - Epoch: [66][  400/  500]    Overall Loss 0.699602    Objective Loss 0.699602                                        LR 0.000500    Time 0.072235    
2024-02-19 16:53:16,961 - Epoch: [66][  500/  500]    Overall Loss 0.704723    Objective Loss 0.704723    Top1 74.000000    Top5 93.000000    LR 0.000500    Time 0.071660    
2024-02-19 16:53:17,094 - --- validate (epoch=66)-----------
2024-02-19 16:53:17,095 - 10000 samples (100 per mini-batch)
2024-02-19 16:53:19,967 - Epoch: [66][  100/  100]    Loss 1.779810    Top1 57.320000    Top5 84.590000    
2024-02-19 16:53:20,085 - ==> Top1: 57.320    Top5: 84.590    Loss: 1.780

2024-02-19 16:53:20,096 - ==> Best [Top1: 59.690   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 55]
2024-02-19 16:53:20,096 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:53:20,154 - 

2024-02-19 16:53:20,154 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:53:27,566 - Epoch: [67][  100/  500]    Overall Loss 0.667879    Objective Loss 0.667879                                        LR 0.000500    Time 0.074068    
2024-02-19 16:53:34,466 - Epoch: [67][  200/  500]    Overall Loss 0.670391    Objective Loss 0.670391                                        LR 0.000500    Time 0.071514    
2024-02-19 16:53:41,425 - Epoch: [67][  300/  500]    Overall Loss 0.682634    Objective Loss 0.682634                                        LR 0.000500    Time 0.070861    
2024-02-19 16:53:48,377 - Epoch: [67][  400/  500]    Overall Loss 0.693407    Objective Loss 0.693407                                        LR 0.000500    Time 0.070516    
2024-02-19 16:53:55,412 - Epoch: [67][  500/  500]    Overall Loss 0.701100    Objective Loss 0.701100    Top1 82.000000    Top5 97.500000    LR 0.000500    Time 0.070474    
2024-02-19 16:53:55,554 - --- validate (epoch=67)-----------
2024-02-19 16:53:55,555 - 10000 samples (100 per mini-batch)
2024-02-19 16:53:58,378 - Epoch: [67][  100/  100]    Loss 1.624452    Top1 59.700000    Top5 85.970000    
2024-02-19 16:53:58,483 - ==> Top1: 59.700    Top5: 85.970    Loss: 1.624

2024-02-19 16:53:58,494 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 16:53:58,495 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:53:58,579 - 

2024-02-19 16:53:58,580 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:54:06,561 - Epoch: [68][  100/  500]    Overall Loss 0.666309    Objective Loss 0.666309                                        LR 0.000500    Time 0.079755    
2024-02-19 16:54:13,884 - Epoch: [68][  200/  500]    Overall Loss 0.671433    Objective Loss 0.671433                                        LR 0.000500    Time 0.076475    
2024-02-19 16:54:21,032 - Epoch: [68][  300/  500]    Overall Loss 0.681416    Objective Loss 0.681416                                        LR 0.000500    Time 0.074795    
2024-02-19 16:54:28,258 - Epoch: [68][  400/  500]    Overall Loss 0.681536    Objective Loss 0.681536                                        LR 0.000500    Time 0.074153    
2024-02-19 16:54:35,372 - Epoch: [68][  500/  500]    Overall Loss 0.689015    Objective Loss 0.689015    Top1 81.000000    Top5 96.500000    LR 0.000500    Time 0.073542    
2024-02-19 16:54:35,501 - --- validate (epoch=68)-----------
2024-02-19 16:54:35,502 - 10000 samples (100 per mini-batch)
2024-02-19 16:54:38,352 - Epoch: [68][  100/  100]    Loss 1.762042    Top1 57.330000    Top5 84.180000    
2024-02-19 16:54:38,455 - ==> Top1: 57.330    Top5: 84.180    Loss: 1.762

2024-02-19 16:54:38,463 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 16:54:38,463 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:54:38,522 - 

2024-02-19 16:54:38,522 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:54:46,078 - Epoch: [69][  100/  500]    Overall Loss 0.670748    Objective Loss 0.670748                                        LR 0.000500    Time 0.075502    
2024-02-19 16:54:53,023 - Epoch: [69][  200/  500]    Overall Loss 0.678400    Objective Loss 0.678400                                        LR 0.000500    Time 0.072459    
2024-02-19 16:54:59,955 - Epoch: [69][  300/  500]    Overall Loss 0.680186    Objective Loss 0.680186                                        LR 0.000500    Time 0.071398    
2024-02-19 16:55:06,847 - Epoch: [69][  400/  500]    Overall Loss 0.683780    Objective Loss 0.683780                                        LR 0.000500    Time 0.070769    
2024-02-19 16:55:13,863 - Epoch: [69][  500/  500]    Overall Loss 0.688127    Objective Loss 0.688127    Top1 75.000000    Top5 95.500000    LR 0.000500    Time 0.070641    
2024-02-19 16:55:13,988 - --- validate (epoch=69)-----------
2024-02-19 16:55:13,989 - 10000 samples (100 per mini-batch)
2024-02-19 16:55:16,865 - Epoch: [69][  100/  100]    Loss 1.698582    Top1 58.650000    Top5 85.260000    
2024-02-19 16:55:17,027 - ==> Top1: 58.650    Top5: 85.260    Loss: 1.699

2024-02-19 16:55:17,035 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 16:55:17,035 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:55:17,088 - 

2024-02-19 16:55:17,088 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:55:24,562 - Epoch: [70][  100/  500]    Overall Loss 0.654303    Objective Loss 0.654303                                        LR 0.000500    Time 0.074686    
2024-02-19 16:55:31,554 - Epoch: [70][  200/  500]    Overall Loss 0.663836    Objective Loss 0.663836                                        LR 0.000500    Time 0.072286    
2024-02-19 16:55:38,585 - Epoch: [70][  300/  500]    Overall Loss 0.670636    Objective Loss 0.670636                                        LR 0.000500    Time 0.071612    
2024-02-19 16:55:45,525 - Epoch: [70][  400/  500]    Overall Loss 0.675985    Objective Loss 0.675985                                        LR 0.000500    Time 0.071049    
2024-02-19 16:55:52,573 - Epoch: [70][  500/  500]    Overall Loss 0.682836    Objective Loss 0.682836    Top1 80.000000    Top5 96.500000    LR 0.000500    Time 0.070928    
2024-02-19 16:55:52,750 - --- validate (epoch=70)-----------
2024-02-19 16:55:52,751 - 10000 samples (100 per mini-batch)
2024-02-19 16:55:55,914 - Epoch: [70][  100/  100]    Loss 1.732679    Top1 58.640000    Top5 84.830000    
2024-02-19 16:55:56,027 - ==> Top1: 58.640    Top5: 84.830    Loss: 1.733

2024-02-19 16:55:56,037 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 16:55:56,037 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:55:56,099 - 

2024-02-19 16:55:56,099 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:56:03,577 - Epoch: [71][  100/  500]    Overall Loss 0.640584    Objective Loss 0.640584                                        LR 0.000500    Time 0.074733    
2024-02-19 16:56:10,576 - Epoch: [71][  200/  500]    Overall Loss 0.644814    Objective Loss 0.644814                                        LR 0.000500    Time 0.072341    
2024-02-19 16:56:17,566 - Epoch: [71][  300/  500]    Overall Loss 0.658395    Objective Loss 0.658395                                        LR 0.000500    Time 0.071514    
2024-02-19 16:56:24,536 - Epoch: [71][  400/  500]    Overall Loss 0.664975    Objective Loss 0.664975                                        LR 0.000500    Time 0.071050    
2024-02-19 16:56:31,544 - Epoch: [71][  500/  500]    Overall Loss 0.673418    Objective Loss 0.673418    Top1 76.500000    Top5 97.500000    LR 0.000500    Time 0.070848    
2024-02-19 16:56:31,712 - --- validate (epoch=71)-----------
2024-02-19 16:56:31,713 - 10000 samples (100 per mini-batch)
2024-02-19 16:56:34,434 - Epoch: [71][  100/  100]    Loss 1.694343    Top1 59.110000    Top5 85.550000    
2024-02-19 16:56:34,528 - ==> Top1: 59.110    Top5: 85.550    Loss: 1.694

2024-02-19 16:56:34,539 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 16:56:34,539 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:56:34,602 - 

2024-02-19 16:56:34,602 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:56:42,270 - Epoch: [72][  100/  500]    Overall Loss 0.634068    Objective Loss 0.634068                                        LR 0.000500    Time 0.076632    
2024-02-19 16:56:49,339 - Epoch: [72][  200/  500]    Overall Loss 0.639392    Objective Loss 0.639392                                        LR 0.000500    Time 0.073639    
2024-02-19 16:56:56,336 - Epoch: [72][  300/  500]    Overall Loss 0.649119    Objective Loss 0.649119                                        LR 0.000500    Time 0.072402    
2024-02-19 16:57:03,295 - Epoch: [72][  400/  500]    Overall Loss 0.660243    Objective Loss 0.660243                                        LR 0.000500    Time 0.071690    
2024-02-19 16:57:10,356 - Epoch: [72][  500/  500]    Overall Loss 0.662036    Objective Loss 0.662036    Top1 75.500000    Top5 97.000000    LR 0.000500    Time 0.071466    
2024-02-19 16:57:10,482 - --- validate (epoch=72)-----------
2024-02-19 16:57:10,483 - 10000 samples (100 per mini-batch)
2024-02-19 16:57:13,453 - Epoch: [72][  100/  100]    Loss 1.789423    Top1 58.120000    Top5 84.880000    
2024-02-19 16:57:13,547 - ==> Top1: 58.120    Top5: 84.880    Loss: 1.789

2024-02-19 16:57:13,553 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 16:57:13,553 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:57:13,610 - 

2024-02-19 16:57:13,610 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:57:21,032 - Epoch: [73][  100/  500]    Overall Loss 0.635874    Objective Loss 0.635874                                        LR 0.000500    Time 0.074164    
2024-02-19 16:57:28,046 - Epoch: [73][  200/  500]    Overall Loss 0.634746    Objective Loss 0.634746                                        LR 0.000500    Time 0.072133    
2024-02-19 16:57:35,030 - Epoch: [73][  300/  500]    Overall Loss 0.643160    Objective Loss 0.643160                                        LR 0.000500    Time 0.071355    
2024-02-19 16:57:41,963 - Epoch: [73][  400/  500]    Overall Loss 0.652762    Objective Loss 0.652762                                        LR 0.000500    Time 0.070840    
2024-02-19 16:57:48,952 - Epoch: [73][  500/  500]    Overall Loss 0.657868    Objective Loss 0.657868    Top1 81.000000    Top5 97.000000    LR 0.000500    Time 0.070642    
2024-02-19 16:57:49,078 - --- validate (epoch=73)-----------
2024-02-19 16:57:49,078 - 10000 samples (100 per mini-batch)
2024-02-19 16:57:52,095 - Epoch: [73][  100/  100]    Loss 1.707734    Top1 58.790000    Top5 85.400000    
2024-02-19 16:57:52,243 - ==> Top1: 58.790    Top5: 85.400    Loss: 1.708

2024-02-19 16:57:52,253 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 16:57:52,253 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:57:52,314 - 

2024-02-19 16:57:52,314 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:57:59,658 - Epoch: [74][  100/  500]    Overall Loss 0.609792    Objective Loss 0.609792                                        LR 0.000500    Time 0.073395    
2024-02-19 16:58:06,320 - Epoch: [74][  200/  500]    Overall Loss 0.622190    Objective Loss 0.622190                                        LR 0.000500    Time 0.069989    
2024-02-19 16:58:12,984 - Epoch: [74][  300/  500]    Overall Loss 0.634530    Objective Loss 0.634530                                        LR 0.000500    Time 0.068864    
2024-02-19 16:58:19,655 - Epoch: [74][  400/  500]    Overall Loss 0.644153    Objective Loss 0.644153                                        LR 0.000500    Time 0.068317    
2024-02-19 16:58:26,348 - Epoch: [74][  500/  500]    Overall Loss 0.649697    Objective Loss 0.649697    Top1 84.000000    Top5 98.000000    LR 0.000500    Time 0.068035    
2024-02-19 16:58:26,507 - --- validate (epoch=74)-----------
2024-02-19 16:58:26,508 - 10000 samples (100 per mini-batch)
2024-02-19 16:58:29,477 - Epoch: [74][  100/  100]    Loss 1.735290    Top1 58.450000    Top5 85.140000    
2024-02-19 16:58:29,665 - ==> Top1: 58.450    Top5: 85.140    Loss: 1.735

2024-02-19 16:58:29,675 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 16:58:29,675 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:58:29,740 - 

2024-02-19 16:58:29,741 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:58:37,143 - Epoch: [75][  100/  500]    Overall Loss 0.620486    Objective Loss 0.620486                                        LR 0.000500    Time 0.073956    
2024-02-19 16:58:44,114 - Epoch: [75][  200/  500]    Overall Loss 0.633876    Objective Loss 0.633876                                        LR 0.000500    Time 0.071814    
2024-02-19 16:58:51,107 - Epoch: [75][  300/  500]    Overall Loss 0.637861    Objective Loss 0.637861                                        LR 0.000500    Time 0.071174    
2024-02-19 16:58:58,055 - Epoch: [75][  400/  500]    Overall Loss 0.641115    Objective Loss 0.641115                                        LR 0.000500    Time 0.070741    
2024-02-19 16:59:04,992 - Epoch: [75][  500/  500]    Overall Loss 0.644184    Objective Loss 0.644184    Top1 79.500000    Top5 97.000000    LR 0.000500    Time 0.070458    
2024-02-19 16:59:05,172 - --- validate (epoch=75)-----------
2024-02-19 16:59:05,173 - 10000 samples (100 per mini-batch)
2024-02-19 16:59:07,940 - Epoch: [75][  100/  100]    Loss 1.705996    Top1 59.100000    Top5 85.270000    
2024-02-19 16:59:08,080 - ==> Top1: 59.100    Top5: 85.270    Loss: 1.706

2024-02-19 16:59:08,092 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 16:59:08,092 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:59:08,151 - 

2024-02-19 16:59:08,151 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:59:15,809 - Epoch: [76][  100/  500]    Overall Loss 0.610907    Objective Loss 0.610907                                        LR 0.000500    Time 0.076530    
2024-02-19 16:59:22,731 - Epoch: [76][  200/  500]    Overall Loss 0.624727    Objective Loss 0.624727                                        LR 0.000500    Time 0.072858    
2024-02-19 16:59:29,642 - Epoch: [76][  300/  500]    Overall Loss 0.624320    Objective Loss 0.624320                                        LR 0.000500    Time 0.071596    
2024-02-19 16:59:36,479 - Epoch: [76][  400/  500]    Overall Loss 0.631084    Objective Loss 0.631084                                        LR 0.000500    Time 0.070780    
2024-02-19 16:59:43,331 - Epoch: [76][  500/  500]    Overall Loss 0.636151    Objective Loss 0.636151    Top1 77.500000    Top5 98.500000    LR 0.000500    Time 0.070321    
2024-02-19 16:59:43,431 - --- validate (epoch=76)-----------
2024-02-19 16:59:43,432 - 10000 samples (100 per mini-batch)
2024-02-19 16:59:46,248 - Epoch: [76][  100/  100]    Loss 1.739712    Top1 58.250000    Top5 85.250000    
2024-02-19 16:59:46,361 - ==> Top1: 58.250    Top5: 85.250    Loss: 1.740

2024-02-19 16:59:46,373 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 16:59:46,373 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 16:59:46,434 - 

2024-02-19 16:59:46,434 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 16:59:53,818 - Epoch: [77][  100/  500]    Overall Loss 0.597206    Objective Loss 0.597206                                        LR 0.000500    Time 0.073791    
2024-02-19 17:00:00,667 - Epoch: [77][  200/  500]    Overall Loss 0.601952    Objective Loss 0.601952                                        LR 0.000500    Time 0.071122    
2024-02-19 17:00:07,407 - Epoch: [77][  300/  500]    Overall Loss 0.609414    Objective Loss 0.609414                                        LR 0.000500    Time 0.069871    
2024-02-19 17:00:14,077 - Epoch: [77][  400/  500]    Overall Loss 0.621360    Objective Loss 0.621360                                        LR 0.000500    Time 0.069070    
2024-02-19 17:00:20,754 - Epoch: [77][  500/  500]    Overall Loss 0.630023    Objective Loss 0.630023    Top1 84.000000    Top5 99.000000    LR 0.000500    Time 0.068604    
2024-02-19 17:00:20,872 - --- validate (epoch=77)-----------
2024-02-19 17:00:20,873 - 10000 samples (100 per mini-batch)
2024-02-19 17:00:23,658 - Epoch: [77][  100/  100]    Loss 1.715761    Top1 58.450000    Top5 85.800000    
2024-02-19 17:00:23,833 - ==> Top1: 58.450    Top5: 85.800    Loss: 1.716

2024-02-19 17:00:23,843 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:00:23,843 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:00:23,896 - 

2024-02-19 17:00:23,896 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:00:31,112 - Epoch: [78][  100/  500]    Overall Loss 0.602155    Objective Loss 0.602155                                        LR 0.000500    Time 0.072119    
2024-02-19 17:00:38,023 - Epoch: [78][  200/  500]    Overall Loss 0.619924    Objective Loss 0.619924                                        LR 0.000500    Time 0.070595    
2024-02-19 17:00:44,903 - Epoch: [78][  300/  500]    Overall Loss 0.618334    Objective Loss 0.618334                                        LR 0.000500    Time 0.069985    
2024-02-19 17:00:51,867 - Epoch: [78][  400/  500]    Overall Loss 0.623308    Objective Loss 0.623308                                        LR 0.000500    Time 0.069889    
2024-02-19 17:00:58,858 - Epoch: [78][  500/  500]    Overall Loss 0.626740    Objective Loss 0.626740    Top1 73.500000    Top5 97.500000    LR 0.000500    Time 0.069887    
2024-02-19 17:00:59,013 - --- validate (epoch=78)-----------
2024-02-19 17:00:59,014 - 10000 samples (100 per mini-batch)
2024-02-19 17:01:02,133 - Epoch: [78][  100/  100]    Loss 1.753041    Top1 57.960000    Top5 85.190000    
2024-02-19 17:01:02,236 - ==> Top1: 57.960    Top5: 85.190    Loss: 1.753

2024-02-19 17:01:02,246 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:01:02,246 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:01:02,312 - 

2024-02-19 17:01:02,312 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:01:09,979 - Epoch: [79][  100/  500]    Overall Loss 0.591097    Objective Loss 0.591097                                        LR 0.000500    Time 0.076617    
2024-02-19 17:01:17,119 - Epoch: [79][  200/  500]    Overall Loss 0.602335    Objective Loss 0.602335                                        LR 0.000500    Time 0.073990    
2024-02-19 17:01:24,225 - Epoch: [79][  300/  500]    Overall Loss 0.608733    Objective Loss 0.608733                                        LR 0.000500    Time 0.072998    
2024-02-19 17:01:31,228 - Epoch: [79][  400/  500]    Overall Loss 0.613700    Objective Loss 0.613700                                        LR 0.000500    Time 0.072246    
2024-02-19 17:01:38,181 - Epoch: [79][  500/  500]    Overall Loss 0.619532    Objective Loss 0.619532    Top1 76.000000    Top5 97.000000    LR 0.000500    Time 0.071696    
2024-02-19 17:01:38,350 - --- validate (epoch=79)-----------
2024-02-19 17:01:38,351 - 10000 samples (100 per mini-batch)
2024-02-19 17:01:41,270 - Epoch: [79][  100/  100]    Loss 1.748150    Top1 58.340000    Top5 85.160000    
2024-02-19 17:01:41,437 - ==> Top1: 58.340    Top5: 85.160    Loss: 1.748

2024-02-19 17:01:41,449 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:01:41,449 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:01:41,511 - 

2024-02-19 17:01:41,511 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:01:49,195 - Epoch: [80][  100/  500]    Overall Loss 0.586069    Objective Loss 0.586069                                        LR 0.000500    Time 0.076787    
2024-02-19 17:01:56,113 - Epoch: [80][  200/  500]    Overall Loss 0.584702    Objective Loss 0.584702                                        LR 0.000500    Time 0.072962    
2024-02-19 17:02:03,117 - Epoch: [80][  300/  500]    Overall Loss 0.597921    Objective Loss 0.597921                                        LR 0.000500    Time 0.071977    
2024-02-19 17:02:10,291 - Epoch: [80][  400/  500]    Overall Loss 0.604512    Objective Loss 0.604512                                        LR 0.000500    Time 0.071907    
2024-02-19 17:02:17,565 - Epoch: [80][  500/  500]    Overall Loss 0.610524    Objective Loss 0.610524    Top1 83.500000    Top5 97.500000    LR 0.000500    Time 0.072068    
2024-02-19 17:02:17,718 - --- validate (epoch=80)-----------
2024-02-19 17:02:17,718 - 10000 samples (100 per mini-batch)
2024-02-19 17:02:20,585 - Epoch: [80][  100/  100]    Loss 1.771340    Top1 58.120000    Top5 84.990000    
2024-02-19 17:02:20,699 - ==> Top1: 58.120    Top5: 84.990    Loss: 1.771

2024-02-19 17:02:20,704 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:02:20,705 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:02:20,765 - 

2024-02-19 17:02:20,766 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:02:28,224 - Epoch: [81][  100/  500]    Overall Loss 0.581604    Objective Loss 0.581604                                        LR 0.000500    Time 0.074531    
2024-02-19 17:02:35,184 - Epoch: [81][  200/  500]    Overall Loss 0.582514    Objective Loss 0.582514                                        LR 0.000500    Time 0.072045    
2024-02-19 17:02:42,203 - Epoch: [81][  300/  500]    Overall Loss 0.598248    Objective Loss 0.598248                                        LR 0.000500    Time 0.071413    
2024-02-19 17:02:49,231 - Epoch: [81][  400/  500]    Overall Loss 0.606046    Objective Loss 0.606046                                        LR 0.000500    Time 0.071121    
2024-02-19 17:02:56,271 - Epoch: [81][  500/  500]    Overall Loss 0.609403    Objective Loss 0.609403    Top1 82.000000    Top5 97.000000    LR 0.000500    Time 0.070969    
2024-02-19 17:02:56,411 - --- validate (epoch=81)-----------
2024-02-19 17:02:56,412 - 10000 samples (100 per mini-batch)
2024-02-19 17:02:59,244 - Epoch: [81][  100/  100]    Loss 1.777510    Top1 58.730000    Top5 84.850000    
2024-02-19 17:02:59,339 - ==> Top1: 58.730    Top5: 84.850    Loss: 1.778

2024-02-19 17:02:59,350 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:02:59,350 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:02:59,410 - 

2024-02-19 17:02:59,410 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:03:07,192 - Epoch: [82][  100/  500]    Overall Loss 0.580655    Objective Loss 0.580655                                        LR 0.000500    Time 0.077764    
2024-02-19 17:03:14,169 - Epoch: [82][  200/  500]    Overall Loss 0.586616    Objective Loss 0.586616                                        LR 0.000500    Time 0.073748    
2024-02-19 17:03:21,176 - Epoch: [82][  300/  500]    Overall Loss 0.591215    Objective Loss 0.591215                                        LR 0.000500    Time 0.072509    
2024-02-19 17:03:28,214 - Epoch: [82][  400/  500]    Overall Loss 0.591351    Objective Loss 0.591351                                        LR 0.000500    Time 0.071965    
2024-02-19 17:03:35,238 - Epoch: [82][  500/  500]    Overall Loss 0.597625    Objective Loss 0.597625    Top1 83.500000    Top5 99.000000    LR 0.000500    Time 0.071613    
2024-02-19 17:03:35,412 - --- validate (epoch=82)-----------
2024-02-19 17:03:35,413 - 10000 samples (100 per mini-batch)
2024-02-19 17:03:38,251 - Epoch: [82][  100/  100]    Loss 1.825459    Top1 57.690000    Top5 84.730000    
2024-02-19 17:03:38,395 - ==> Top1: 57.690    Top5: 84.730    Loss: 1.825

2024-02-19 17:03:38,406 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:03:38,407 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:03:38,469 - 

2024-02-19 17:03:38,469 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:03:45,932 - Epoch: [83][  100/  500]    Overall Loss 0.563809    Objective Loss 0.563809                                        LR 0.000500    Time 0.074575    
2024-02-19 17:03:52,867 - Epoch: [83][  200/  500]    Overall Loss 0.573816    Objective Loss 0.573816                                        LR 0.000500    Time 0.071942    
2024-02-19 17:03:59,814 - Epoch: [83][  300/  500]    Overall Loss 0.576394    Objective Loss 0.576394                                        LR 0.000500    Time 0.071105    
2024-02-19 17:04:06,899 - Epoch: [83][  400/  500]    Overall Loss 0.585076    Objective Loss 0.585076                                        LR 0.000500    Time 0.071031    
2024-02-19 17:04:13,931 - Epoch: [83][  500/  500]    Overall Loss 0.590422    Objective Loss 0.590422    Top1 83.000000    Top5 97.000000    LR 0.000500    Time 0.070881    
2024-02-19 17:04:14,061 - --- validate (epoch=83)-----------
2024-02-19 17:04:14,062 - 10000 samples (100 per mini-batch)
2024-02-19 17:04:16,850 - Epoch: [83][  100/  100]    Loss 1.793144    Top1 58.300000    Top5 85.080000    
2024-02-19 17:04:16,962 - ==> Top1: 58.300    Top5: 85.080    Loss: 1.793

2024-02-19 17:04:16,973 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:04:16,973 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:04:17,032 - 

2024-02-19 17:04:17,032 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:04:24,697 - Epoch: [84][  100/  500]    Overall Loss 0.537897    Objective Loss 0.537897                                        LR 0.000500    Time 0.076594    
2024-02-19 17:04:31,550 - Epoch: [84][  200/  500]    Overall Loss 0.562149    Objective Loss 0.562149                                        LR 0.000500    Time 0.072546    
2024-02-19 17:04:38,347 - Epoch: [84][  300/  500]    Overall Loss 0.570473    Objective Loss 0.570473                                        LR 0.000500    Time 0.071010    
2024-02-19 17:04:45,245 - Epoch: [84][  400/  500]    Overall Loss 0.577448    Objective Loss 0.577448                                        LR 0.000500    Time 0.070494    
2024-02-19 17:04:52,110 - Epoch: [84][  500/  500]    Overall Loss 0.587891    Objective Loss 0.587891    Top1 81.000000    Top5 97.000000    LR 0.000500    Time 0.070118    
2024-02-19 17:04:52,232 - --- validate (epoch=84)-----------
2024-02-19 17:04:52,232 - 10000 samples (100 per mini-batch)
2024-02-19 17:04:55,123 - Epoch: [84][  100/  100]    Loss 1.739641    Top1 58.970000    Top5 85.100000    
2024-02-19 17:04:55,281 - ==> Top1: 58.970    Top5: 85.100    Loss: 1.740

2024-02-19 17:04:55,291 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:04:55,292 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:04:55,351 - 

2024-02-19 17:04:55,351 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:05:02,751 - Epoch: [85][  100/  500]    Overall Loss 0.554587    Objective Loss 0.554587                                        LR 0.000500    Time 0.073945    
2024-02-19 17:05:09,667 - Epoch: [85][  200/  500]    Overall Loss 0.572589    Objective Loss 0.572589                                        LR 0.000500    Time 0.071532    
2024-02-19 17:05:16,569 - Epoch: [85][  300/  500]    Overall Loss 0.576759    Objective Loss 0.576759                                        LR 0.000500    Time 0.070685    
2024-02-19 17:05:23,475 - Epoch: [85][  400/  500]    Overall Loss 0.583177    Objective Loss 0.583177                                        LR 0.000500    Time 0.070270    
2024-02-19 17:05:30,478 - Epoch: [85][  500/  500]    Overall Loss 0.589292    Objective Loss 0.589292    Top1 81.000000    Top5 97.000000    LR 0.000500    Time 0.070214    
2024-02-19 17:05:30,586 - --- validate (epoch=85)-----------
2024-02-19 17:05:30,587 - 10000 samples (100 per mini-batch)
2024-02-19 17:05:33,507 - Epoch: [85][  100/  100]    Loss 1.771237    Top1 58.690000    Top5 85.650000    
2024-02-19 17:05:33,601 - ==> Top1: 58.690    Top5: 85.650    Loss: 1.771

2024-02-19 17:05:33,612 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:05:33,612 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:05:33,673 - 

2024-02-19 17:05:33,674 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:05:41,288 - Epoch: [86][  100/  500]    Overall Loss 0.539606    Objective Loss 0.539606                                        LR 0.000500    Time 0.076094    
2024-02-19 17:05:48,255 - Epoch: [86][  200/  500]    Overall Loss 0.546295    Objective Loss 0.546295                                        LR 0.000500    Time 0.072864    
2024-02-19 17:05:55,194 - Epoch: [86][  300/  500]    Overall Loss 0.558972    Objective Loss 0.558972                                        LR 0.000500    Time 0.071692    
2024-02-19 17:06:02,213 - Epoch: [86][  400/  500]    Overall Loss 0.567789    Objective Loss 0.567789                                        LR 0.000500    Time 0.071306    
2024-02-19 17:06:09,310 - Epoch: [86][  500/  500]    Overall Loss 0.574149    Objective Loss 0.574149    Top1 82.000000    Top5 97.000000    LR 0.000500    Time 0.071231    
2024-02-19 17:06:09,473 - --- validate (epoch=86)-----------
2024-02-19 17:06:09,474 - 10000 samples (100 per mini-batch)
2024-02-19 17:06:12,406 - Epoch: [86][  100/  100]    Loss 1.823585    Top1 57.930000    Top5 84.860000    
2024-02-19 17:06:12,568 - ==> Top1: 57.930    Top5: 84.860    Loss: 1.824

2024-02-19 17:06:12,579 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:06:12,579 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:06:12,641 - 

2024-02-19 17:06:12,641 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:06:20,020 - Epoch: [87][  100/  500]    Overall Loss 0.556764    Objective Loss 0.556764                                        LR 0.000500    Time 0.073737    
2024-02-19 17:06:27,044 - Epoch: [87][  200/  500]    Overall Loss 0.549502    Objective Loss 0.549502                                        LR 0.000500    Time 0.071969    
2024-02-19 17:06:33,991 - Epoch: [87][  300/  500]    Overall Loss 0.558405    Objective Loss 0.558405                                        LR 0.000500    Time 0.071125    
2024-02-19 17:06:40,935 - Epoch: [87][  400/  500]    Overall Loss 0.566278    Objective Loss 0.566278                                        LR 0.000500    Time 0.070694    
2024-02-19 17:06:47,795 - Epoch: [87][  500/  500]    Overall Loss 0.571798    Objective Loss 0.571798    Top1 79.000000    Top5 97.500000    LR 0.000500    Time 0.070268    
2024-02-19 17:06:47,922 - --- validate (epoch=87)-----------
2024-02-19 17:06:47,923 - 10000 samples (100 per mini-batch)
2024-02-19 17:06:50,695 - Epoch: [87][  100/  100]    Loss 1.827984    Top1 58.240000    Top5 84.840000    
2024-02-19 17:06:50,794 - ==> Top1: 58.240    Top5: 84.840    Loss: 1.828

2024-02-19 17:06:50,805 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:06:50,805 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:06:50,854 - 

2024-02-19 17:06:50,854 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:06:58,193 - Epoch: [88][  100/  500]    Overall Loss 0.547444    Objective Loss 0.547444                                        LR 0.000500    Time 0.073348    
2024-02-19 17:07:05,152 - Epoch: [88][  200/  500]    Overall Loss 0.558846    Objective Loss 0.558846                                        LR 0.000500    Time 0.071447    
2024-02-19 17:07:12,049 - Epoch: [88][  300/  500]    Overall Loss 0.563672    Objective Loss 0.563672                                        LR 0.000500    Time 0.070612    
2024-02-19 17:07:18,952 - Epoch: [88][  400/  500]    Overall Loss 0.568608    Objective Loss 0.568608                                        LR 0.000500    Time 0.070207    
2024-02-19 17:07:25,996 - Epoch: [88][  500/  500]    Overall Loss 0.572333    Objective Loss 0.572333    Top1 87.000000    Top5 98.000000    LR 0.000500    Time 0.070245    
2024-02-19 17:07:26,098 - --- validate (epoch=88)-----------
2024-02-19 17:07:26,099 - 10000 samples (100 per mini-batch)
2024-02-19 17:07:28,901 - Epoch: [88][  100/  100]    Loss 1.751668    Top1 58.800000    Top5 85.800000    
2024-02-19 17:07:29,105 - ==> Top1: 58.800    Top5: 85.800    Loss: 1.752

2024-02-19 17:07:29,115 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:07:29,116 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:07:29,178 - 

2024-02-19 17:07:29,178 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:07:36,613 - Epoch: [89][  100/  500]    Overall Loss 0.537153    Objective Loss 0.537153                                        LR 0.000500    Time 0.074293    
2024-02-19 17:07:43,588 - Epoch: [89][  200/  500]    Overall Loss 0.542063    Objective Loss 0.542063                                        LR 0.000500    Time 0.072000    
2024-02-19 17:07:50,531 - Epoch: [89][  300/  500]    Overall Loss 0.545037    Objective Loss 0.545037                                        LR 0.000500    Time 0.071132    
2024-02-19 17:07:57,467 - Epoch: [89][  400/  500]    Overall Loss 0.550915    Objective Loss 0.550915                                        LR 0.000500    Time 0.070679    
2024-02-19 17:08:04,400 - Epoch: [89][  500/  500]    Overall Loss 0.556556    Objective Loss 0.556556    Top1 87.000000    Top5 97.000000    LR 0.000500    Time 0.070403    
2024-02-19 17:08:04,586 - --- validate (epoch=89)-----------
2024-02-19 17:08:04,587 - 10000 samples (100 per mini-batch)
2024-02-19 17:08:07,271 - Epoch: [89][  100/  100]    Loss 1.848719    Top1 57.640000    Top5 84.930000    
2024-02-19 17:08:07,382 - ==> Top1: 57.640    Top5: 84.930    Loss: 1.849

2024-02-19 17:08:07,394 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:08:07,394 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:08:07,453 - 

2024-02-19 17:08:07,454 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:08:14,822 - Epoch: [90][  100/  500]    Overall Loss 0.529408    Objective Loss 0.529408                                        LR 0.000500    Time 0.073637    
2024-02-19 17:08:21,746 - Epoch: [90][  200/  500]    Overall Loss 0.539266    Objective Loss 0.539266                                        LR 0.000500    Time 0.071418    
2024-02-19 17:08:28,625 - Epoch: [90][  300/  500]    Overall Loss 0.540605    Objective Loss 0.540605                                        LR 0.000500    Time 0.070532    
2024-02-19 17:08:35,480 - Epoch: [90][  400/  500]    Overall Loss 0.546338    Objective Loss 0.546338                                        LR 0.000500    Time 0.070027    
2024-02-19 17:08:42,432 - Epoch: [90][  500/  500]    Overall Loss 0.556061    Objective Loss 0.556061    Top1 83.000000    Top5 97.500000    LR 0.000500    Time 0.069918    
2024-02-19 17:08:42,603 - --- validate (epoch=90)-----------
2024-02-19 17:08:42,604 - 10000 samples (100 per mini-batch)
2024-02-19 17:08:45,709 - Epoch: [90][  100/  100]    Loss 1.862603    Top1 57.940000    Top5 84.360000    
2024-02-19 17:08:45,813 - ==> Top1: 57.940    Top5: 84.360    Loss: 1.863

2024-02-19 17:08:45,819 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:08:45,819 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:08:45,873 - 

2024-02-19 17:08:45,874 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:08:53,302 - Epoch: [91][  100/  500]    Overall Loss 0.518050    Objective Loss 0.518050                                        LR 0.000500    Time 0.074227    
2024-02-19 17:09:00,310 - Epoch: [91][  200/  500]    Overall Loss 0.528958    Objective Loss 0.528958                                        LR 0.000500    Time 0.072134    
2024-02-19 17:09:07,273 - Epoch: [91][  300/  500]    Overall Loss 0.539271    Objective Loss 0.539271                                        LR 0.000500    Time 0.071287    
2024-02-19 17:09:14,294 - Epoch: [91][  400/  500]    Overall Loss 0.544243    Objective Loss 0.544243                                        LR 0.000500    Time 0.071008    
2024-02-19 17:09:21,372 - Epoch: [91][  500/  500]    Overall Loss 0.549738    Objective Loss 0.549738    Top1 87.000000    Top5 99.000000    LR 0.000500    Time 0.070954    
2024-02-19 17:09:21,559 - --- validate (epoch=91)-----------
2024-02-19 17:09:21,560 - 10000 samples (100 per mini-batch)
2024-02-19 17:09:24,441 - Epoch: [91][  100/  100]    Loss 1.888735    Top1 57.300000    Top5 84.190000    
2024-02-19 17:09:24,605 - ==> Top1: 57.300    Top5: 84.190    Loss: 1.889

2024-02-19 17:09:24,615 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:09:24,616 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:09:24,675 - 

2024-02-19 17:09:24,675 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:09:32,244 - Epoch: [92][  100/  500]    Overall Loss 0.512143    Objective Loss 0.512143                                        LR 0.000500    Time 0.075644    
2024-02-19 17:09:39,175 - Epoch: [92][  200/  500]    Overall Loss 0.524299    Objective Loss 0.524299                                        LR 0.000500    Time 0.072457    
2024-02-19 17:09:46,100 - Epoch: [92][  300/  500]    Overall Loss 0.532035    Objective Loss 0.532035                                        LR 0.000500    Time 0.071374    
2024-02-19 17:09:53,017 - Epoch: [92][  400/  500]    Overall Loss 0.539652    Objective Loss 0.539652                                        LR 0.000500    Time 0.070814    
2024-02-19 17:10:00,060 - Epoch: [92][  500/  500]    Overall Loss 0.544782    Objective Loss 0.544782    Top1 77.500000    Top5 96.500000    LR 0.000500    Time 0.070730    
2024-02-19 17:10:00,171 - --- validate (epoch=92)-----------
2024-02-19 17:10:00,172 - 10000 samples (100 per mini-batch)
2024-02-19 17:10:03,061 - Epoch: [92][  100/  100]    Loss 1.756985    Top1 59.200000    Top5 85.740000    
2024-02-19 17:10:03,199 - ==> Top1: 59.200    Top5: 85.740    Loss: 1.757

2024-02-19 17:10:03,209 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:10:03,210 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:10:03,271 - 

2024-02-19 17:10:03,272 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:10:10,724 - Epoch: [93][  100/  500]    Overall Loss 0.506487    Objective Loss 0.506487                                        LR 0.000500    Time 0.074471    
2024-02-19 17:10:17,710 - Epoch: [93][  200/  500]    Overall Loss 0.517290    Objective Loss 0.517290                                        LR 0.000500    Time 0.072143    
2024-02-19 17:10:24,622 - Epoch: [93][  300/  500]    Overall Loss 0.525091    Objective Loss 0.525091                                        LR 0.000500    Time 0.071123    
2024-02-19 17:10:31,515 - Epoch: [93][  400/  500]    Overall Loss 0.529492    Objective Loss 0.529492                                        LR 0.000500    Time 0.070566    
2024-02-19 17:10:38,495 - Epoch: [93][  500/  500]    Overall Loss 0.537910    Objective Loss 0.537910    Top1 83.000000    Top5 99.000000    LR 0.000500    Time 0.070405    
2024-02-19 17:10:38,650 - --- validate (epoch=93)-----------
2024-02-19 17:10:38,651 - 10000 samples (100 per mini-batch)
2024-02-19 17:10:41,575 - Epoch: [93][  100/  100]    Loss 1.832554    Top1 58.650000    Top5 84.650000    
2024-02-19 17:10:41,734 - ==> Top1: 58.650    Top5: 84.650    Loss: 1.833

2024-02-19 17:10:41,744 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:10:41,745 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:10:41,820 - 

2024-02-19 17:10:41,821 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:10:49,216 - Epoch: [94][  100/  500]    Overall Loss 0.500161    Objective Loss 0.500161                                        LR 0.000500    Time 0.073907    
2024-02-19 17:10:56,232 - Epoch: [94][  200/  500]    Overall Loss 0.509390    Objective Loss 0.509390                                        LR 0.000500    Time 0.072014    
2024-02-19 17:11:03,160 - Epoch: [94][  300/  500]    Overall Loss 0.520344    Objective Loss 0.520344                                        LR 0.000500    Time 0.071089    
2024-02-19 17:11:10,095 - Epoch: [94][  400/  500]    Overall Loss 0.527340    Objective Loss 0.527340                                        LR 0.000500    Time 0.070643    
2024-02-19 17:11:17,124 - Epoch: [94][  500/  500]    Overall Loss 0.534484    Objective Loss 0.534484    Top1 84.000000    Top5 98.000000    LR 0.000500    Time 0.070567    
2024-02-19 17:11:17,305 - --- validate (epoch=94)-----------
2024-02-19 17:11:17,306 - 10000 samples (100 per mini-batch)
2024-02-19 17:11:20,532 - Epoch: [94][  100/  100]    Loss 1.857067    Top1 57.960000    Top5 84.550000    
2024-02-19 17:11:20,705 - ==> Top1: 57.960    Top5: 84.550    Loss: 1.857

2024-02-19 17:11:20,716 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:11:20,716 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:11:20,780 - 

2024-02-19 17:11:20,780 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:11:28,223 - Epoch: [95][  100/  500]    Overall Loss 0.505093    Objective Loss 0.505093                                        LR 0.000500    Time 0.074376    
2024-02-19 17:11:35,252 - Epoch: [95][  200/  500]    Overall Loss 0.510239    Objective Loss 0.510239                                        LR 0.000500    Time 0.072315    
2024-02-19 17:11:42,380 - Epoch: [95][  300/  500]    Overall Loss 0.512875    Objective Loss 0.512875                                        LR 0.000500    Time 0.071957    
2024-02-19 17:11:49,481 - Epoch: [95][  400/  500]    Overall Loss 0.522760    Objective Loss 0.522760                                        LR 0.000500    Time 0.071708    
2024-02-19 17:11:56,548 - Epoch: [95][  500/  500]    Overall Loss 0.532060    Objective Loss 0.532060    Top1 84.000000    Top5 97.000000    LR 0.000500    Time 0.071494    
2024-02-19 17:11:56,681 - --- validate (epoch=95)-----------
2024-02-19 17:11:56,681 - 10000 samples (100 per mini-batch)
2024-02-19 17:11:59,678 - Epoch: [95][  100/  100]    Loss 1.794046    Top1 58.590000    Top5 85.450000    
2024-02-19 17:11:59,838 - ==> Top1: 58.590    Top5: 85.450    Loss: 1.794

2024-02-19 17:11:59,844 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:11:59,844 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:11:59,895 - 

2024-02-19 17:11:59,895 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:12:07,412 - Epoch: [96][  100/  500]    Overall Loss 0.506437    Objective Loss 0.506437                                        LR 0.000500    Time 0.075122    
2024-02-19 17:12:14,390 - Epoch: [96][  200/  500]    Overall Loss 0.510144    Objective Loss 0.510144                                        LR 0.000500    Time 0.072431    
2024-02-19 17:12:21,551 - Epoch: [96][  300/  500]    Overall Loss 0.513762    Objective Loss 0.513762                                        LR 0.000500    Time 0.072146    
2024-02-19 17:12:28,770 - Epoch: [96][  400/  500]    Overall Loss 0.521659    Objective Loss 0.521659                                        LR 0.000500    Time 0.072149    
2024-02-19 17:12:35,911 - Epoch: [96][  500/  500]    Overall Loss 0.523922    Objective Loss 0.523922    Top1 86.000000    Top5 98.500000    LR 0.000500    Time 0.071992    
2024-02-19 17:12:36,084 - --- validate (epoch=96)-----------
2024-02-19 17:12:36,085 - 10000 samples (100 per mini-batch)
2024-02-19 17:12:39,058 - Epoch: [96][  100/  100]    Loss 1.863796    Top1 57.850000    Top5 84.610000    
2024-02-19 17:12:39,181 - ==> Top1: 57.850    Top5: 84.610    Loss: 1.864

2024-02-19 17:12:39,187 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:12:39,187 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:12:39,247 - 

2024-02-19 17:12:39,248 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:12:46,634 - Epoch: [97][  100/  500]    Overall Loss 0.492927    Objective Loss 0.492927                                        LR 0.000500    Time 0.073812    
2024-02-19 17:12:53,617 - Epoch: [97][  200/  500]    Overall Loss 0.510134    Objective Loss 0.510134                                        LR 0.000500    Time 0.071802    
2024-02-19 17:13:00,531 - Epoch: [97][  300/  500]    Overall Loss 0.511359    Objective Loss 0.511359                                        LR 0.000500    Time 0.070902    
2024-02-19 17:13:07,433 - Epoch: [97][  400/  500]    Overall Loss 0.517971    Objective Loss 0.517971                                        LR 0.000500    Time 0.070422    
2024-02-19 17:13:14,432 - Epoch: [97][  500/  500]    Overall Loss 0.522544    Objective Loss 0.522544    Top1 80.000000    Top5 96.500000    LR 0.000500    Time 0.070329    
2024-02-19 17:13:14,618 - --- validate (epoch=97)-----------
2024-02-19 17:13:14,619 - 10000 samples (100 per mini-batch)
2024-02-19 17:13:17,567 - Epoch: [97][  100/  100]    Loss 1.799315    Top1 58.500000    Top5 85.210000    
2024-02-19 17:13:17,674 - ==> Top1: 58.500    Top5: 85.210    Loss: 1.799

2024-02-19 17:13:17,684 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:13:17,685 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:13:17,745 - 

2024-02-19 17:13:17,745 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:13:25,126 - Epoch: [98][  100/  500]    Overall Loss 0.492416    Objective Loss 0.492416                                        LR 0.000500    Time 0.073758    
2024-02-19 17:13:32,046 - Epoch: [98][  200/  500]    Overall Loss 0.509689    Objective Loss 0.509689                                        LR 0.000500    Time 0.071464    
2024-02-19 17:13:38,999 - Epoch: [98][  300/  500]    Overall Loss 0.514820    Objective Loss 0.514820                                        LR 0.000500    Time 0.070804    
2024-02-19 17:13:45,949 - Epoch: [98][  400/  500]    Overall Loss 0.519473    Objective Loss 0.519473                                        LR 0.000500    Time 0.070469    
2024-02-19 17:13:52,985 - Epoch: [98][  500/  500]    Overall Loss 0.520509    Objective Loss 0.520509    Top1 78.500000    Top5 96.000000    LR 0.000500    Time 0.070439    
2024-02-19 17:13:53,114 - --- validate (epoch=98)-----------
2024-02-19 17:13:53,115 - 10000 samples (100 per mini-batch)
2024-02-19 17:13:56,150 - Epoch: [98][  100/  100]    Loss 1.888811    Top1 57.210000    Top5 84.670000    
2024-02-19 17:13:56,327 - ==> Top1: 57.210    Top5: 84.670    Loss: 1.889

2024-02-19 17:13:56,338 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:13:56,338 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:13:56,399 - 

2024-02-19 17:13:56,399 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:14:03,767 - Epoch: [99][  100/  500]    Overall Loss 0.491538    Objective Loss 0.491538                                        LR 0.000500    Time 0.073633    
2024-02-19 17:14:10,613 - Epoch: [99][  200/  500]    Overall Loss 0.495809    Objective Loss 0.495809                                        LR 0.000500    Time 0.071029    
2024-02-19 17:14:17,513 - Epoch: [99][  300/  500]    Overall Loss 0.503789    Objective Loss 0.503789                                        LR 0.000500    Time 0.070341    
2024-02-19 17:14:24,391 - Epoch: [99][  400/  500]    Overall Loss 0.509748    Objective Loss 0.509748                                        LR 0.000500    Time 0.069943    
2024-02-19 17:14:31,357 - Epoch: [99][  500/  500]    Overall Loss 0.509678    Objective Loss 0.509678    Top1 83.000000    Top5 98.000000    LR 0.000500    Time 0.069879    
2024-02-19 17:14:31,488 - --- validate (epoch=99)-----------
2024-02-19 17:14:31,489 - 10000 samples (100 per mini-batch)
2024-02-19 17:14:34,303 - Epoch: [99][  100/  100]    Loss 1.846241    Top1 58.420000    Top5 85.290000    
2024-02-19 17:14:34,418 - ==> Top1: 58.420    Top5: 85.290    Loss: 1.846

2024-02-19 17:14:34,423 - ==> Best [Top1: 59.700   Top5: 85.970   Sparsity:0.00   Params: 753952 on epoch: 67]
2024-02-19 17:14:34,424 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:14:34,483 - 

2024-02-19 17:14:34,483 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:14:42,109 - Epoch: [100][  100/  500]    Overall Loss 0.451988    Objective Loss 0.451988                                        LR 0.000250    Time 0.076207    
2024-02-19 17:14:48,996 - Epoch: [100][  200/  500]    Overall Loss 0.452809    Objective Loss 0.452809                                        LR 0.000250    Time 0.072522    
2024-02-19 17:14:55,914 - Epoch: [100][  300/  500]    Overall Loss 0.448110    Objective Loss 0.448110                                        LR 0.000250    Time 0.071395    
2024-02-19 17:15:02,788 - Epoch: [100][  400/  500]    Overall Loss 0.446328    Objective Loss 0.446328                                        LR 0.000250    Time 0.070721    
2024-02-19 17:15:09,727 - Epoch: [100][  500/  500]    Overall Loss 0.444304    Objective Loss 0.444304    Top1 86.000000    Top5 99.500000    LR 0.000250    Time 0.070449    
2024-02-19 17:15:09,836 - --- validate (epoch=100)-----------
2024-02-19 17:15:09,836 - 10000 samples (100 per mini-batch)
2024-02-19 17:15:12,667 - Epoch: [100][  100/  100]    Loss 1.728898    Top1 59.900000    Top5 85.980000    
2024-02-19 17:15:12,822 - ==> Top1: 59.900    Top5: 85.980    Loss: 1.729

2024-02-19 17:15:12,833 - ==> Best [Top1: 59.900   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 100]
2024-02-19 17:15:12,833 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:15:12,906 - 

2024-02-19 17:15:12,906 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:15:20,234 - Epoch: [101][  100/  500]    Overall Loss 0.418033    Objective Loss 0.418033                                        LR 0.000250    Time 0.073224    
2024-02-19 17:15:27,121 - Epoch: [101][  200/  500]    Overall Loss 0.421524    Objective Loss 0.421524                                        LR 0.000250    Time 0.071029    
2024-02-19 17:15:34,135 - Epoch: [101][  300/  500]    Overall Loss 0.426896    Objective Loss 0.426896                                        LR 0.000250    Time 0.070721    
2024-02-19 17:15:41,061 - Epoch: [101][  400/  500]    Overall Loss 0.427725    Objective Loss 0.427725                                        LR 0.000250    Time 0.070346    
2024-02-19 17:15:48,000 - Epoch: [101][  500/  500]    Overall Loss 0.429468    Objective Loss 0.429468    Top1 86.000000    Top5 98.500000    LR 0.000250    Time 0.070147    
2024-02-19 17:15:48,177 - --- validate (epoch=101)-----------
2024-02-19 17:15:48,177 - 10000 samples (100 per mini-batch)
2024-02-19 17:15:51,269 - Epoch: [101][  100/  100]    Loss 1.757559    Top1 59.600000    Top5 86.150000    
2024-02-19 17:15:51,411 - ==> Top1: 59.600    Top5: 86.150    Loss: 1.758

2024-02-19 17:15:51,422 - ==> Best [Top1: 59.900   Top5: 85.980   Sparsity:0.00   Params: 753952 on epoch: 100]
2024-02-19 17:15:51,422 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:15:51,482 - 

2024-02-19 17:15:51,483 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:15:59,221 - Epoch: [102][  100/  500]    Overall Loss 0.416229    Objective Loss 0.416229                                        LR 0.000250    Time 0.077337    
2024-02-19 17:16:06,159 - Epoch: [102][  200/  500]    Overall Loss 0.413444    Objective Loss 0.413444                                        LR 0.000250    Time 0.073339    
2024-02-19 17:16:13,147 - Epoch: [102][  300/  500]    Overall Loss 0.420871    Objective Loss 0.420871                                        LR 0.000250    Time 0.072171    
2024-02-19 17:16:20,044 - Epoch: [102][  400/  500]    Overall Loss 0.427168    Objective Loss 0.427168                                        LR 0.000250    Time 0.071361    
2024-02-19 17:16:26,962 - Epoch: [102][  500/  500]    Overall Loss 0.427152    Objective Loss 0.427152    Top1 89.000000    Top5 99.500000    LR 0.000250    Time 0.070917    
2024-02-19 17:16:27,081 - --- validate (epoch=102)-----------
2024-02-19 17:16:27,082 - 10000 samples (100 per mini-batch)
2024-02-19 17:16:30,081 - Epoch: [102][  100/  100]    Loss 1.739574    Top1 60.070000    Top5 86.210000    
2024-02-19 17:16:30,192 - ==> Top1: 60.070    Top5: 86.210    Loss: 1.740

2024-02-19 17:16:30,198 - ==> Best [Top1: 60.070   Top5: 86.210   Sparsity:0.00   Params: 753952 on epoch: 102]
2024-02-19 17:16:30,198 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:16:30,268 - 

2024-02-19 17:16:30,268 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:16:37,679 - Epoch: [103][  100/  500]    Overall Loss 0.403438    Objective Loss 0.403438                                        LR 0.000250    Time 0.074054    
2024-02-19 17:16:44,726 - Epoch: [103][  200/  500]    Overall Loss 0.401079    Objective Loss 0.401079                                        LR 0.000250    Time 0.072246    
2024-02-19 17:16:51,657 - Epoch: [103][  300/  500]    Overall Loss 0.409565    Objective Loss 0.409565                                        LR 0.000250    Time 0.071255    
2024-02-19 17:16:58,572 - Epoch: [103][  400/  500]    Overall Loss 0.415376    Objective Loss 0.415376                                        LR 0.000250    Time 0.070718    
2024-02-19 17:17:05,535 - Epoch: [103][  500/  500]    Overall Loss 0.418406    Objective Loss 0.418406    Top1 89.000000    Top5 99.500000    LR 0.000250    Time 0.070493    
2024-02-19 17:17:05,711 - --- validate (epoch=103)-----------
2024-02-19 17:17:05,712 - 10000 samples (100 per mini-batch)
2024-02-19 17:17:08,567 - Epoch: [103][  100/  100]    Loss 1.754008    Top1 59.800000    Top5 85.760000    
2024-02-19 17:17:08,687 - ==> Top1: 59.800    Top5: 85.760    Loss: 1.754

2024-02-19 17:17:08,693 - ==> Best [Top1: 60.070   Top5: 86.210   Sparsity:0.00   Params: 753952 on epoch: 102]
2024-02-19 17:17:08,693 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:17:08,755 - 

2024-02-19 17:17:08,756 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:17:16,464 - Epoch: [104][  100/  500]    Overall Loss 0.394743    Objective Loss 0.394743                                        LR 0.000250    Time 0.077033    
2024-02-19 17:17:23,426 - Epoch: [104][  200/  500]    Overall Loss 0.400930    Objective Loss 0.400930                                        LR 0.000250    Time 0.073306    
2024-02-19 17:17:30,320 - Epoch: [104][  300/  500]    Overall Loss 0.403892    Objective Loss 0.403892                                        LR 0.000250    Time 0.071842    
2024-02-19 17:17:37,228 - Epoch: [104][  400/  500]    Overall Loss 0.407532    Objective Loss 0.407532                                        LR 0.000250    Time 0.071140    
2024-02-19 17:17:44,136 - Epoch: [104][  500/  500]    Overall Loss 0.412013    Objective Loss 0.412013    Top1 87.000000    Top5 99.000000    LR 0.000250    Time 0.070721    
2024-02-19 17:17:44,254 - --- validate (epoch=104)-----------
2024-02-19 17:17:44,255 - 10000 samples (100 per mini-batch)
2024-02-19 17:17:47,084 - Epoch: [104][  100/  100]    Loss 1.762275    Top1 60.200000    Top5 86.020000    
2024-02-19 17:17:47,178 - ==> Top1: 60.200    Top5: 86.020    Loss: 1.762

2024-02-19 17:17:47,184 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:17:47,184 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:17:47,253 - 

2024-02-19 17:17:47,253 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:17:54,639 - Epoch: [105][  100/  500]    Overall Loss 0.393309    Objective Loss 0.393309                                        LR 0.000250    Time 0.073815    
2024-02-19 17:18:01,680 - Epoch: [105][  200/  500]    Overall Loss 0.400789    Objective Loss 0.400789                                        LR 0.000250    Time 0.072089    
2024-02-19 17:18:08,739 - Epoch: [105][  300/  500]    Overall Loss 0.402713    Objective Loss 0.402713                                        LR 0.000250    Time 0.071579    
2024-02-19 17:18:15,822 - Epoch: [105][  400/  500]    Overall Loss 0.410494    Objective Loss 0.410494                                        LR 0.000250    Time 0.071382    
2024-02-19 17:18:22,878 - Epoch: [105][  500/  500]    Overall Loss 0.411551    Objective Loss 0.411551    Top1 88.500000    Top5 99.500000    LR 0.000250    Time 0.071211    
2024-02-19 17:18:23,004 - --- validate (epoch=105)-----------
2024-02-19 17:18:23,004 - 10000 samples (100 per mini-batch)
2024-02-19 17:18:25,824 - Epoch: [105][  100/  100]    Loss 1.748009    Top1 59.960000    Top5 86.130000    
2024-02-19 17:18:25,918 - ==> Top1: 59.960    Top5: 86.130    Loss: 1.748

2024-02-19 17:18:25,927 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:18:25,927 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:18:25,980 - 

2024-02-19 17:18:25,980 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:18:33,244 - Epoch: [106][  100/  500]    Overall Loss 0.394131    Objective Loss 0.394131                                        LR 0.000250    Time 0.072601    
2024-02-19 17:18:40,323 - Epoch: [106][  200/  500]    Overall Loss 0.396050    Objective Loss 0.396050                                        LR 0.000250    Time 0.071675    
2024-02-19 17:18:47,260 - Epoch: [106][  300/  500]    Overall Loss 0.398229    Objective Loss 0.398229                                        LR 0.000250    Time 0.070893    
2024-02-19 17:18:54,187 - Epoch: [106][  400/  500]    Overall Loss 0.399904    Objective Loss 0.399904                                        LR 0.000250    Time 0.070479    
2024-02-19 17:19:01,132 - Epoch: [106][  500/  500]    Overall Loss 0.403155    Objective Loss 0.403155    Top1 86.500000    Top5 99.500000    LR 0.000250    Time 0.070265    
2024-02-19 17:19:01,275 - --- validate (epoch=106)-----------
2024-02-19 17:19:01,276 - 10000 samples (100 per mini-batch)
2024-02-19 17:19:04,446 - Epoch: [106][  100/  100]    Loss 1.801233    Top1 59.730000    Top5 85.940000    
2024-02-19 17:19:04,541 - ==> Top1: 59.730    Top5: 85.940    Loss: 1.801

2024-02-19 17:19:04,554 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:19:04,554 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:19:04,630 - 

2024-02-19 17:19:04,630 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:19:11,958 - Epoch: [107][  100/  500]    Overall Loss 0.401932    Objective Loss 0.401932                                        LR 0.000250    Time 0.073233    
2024-02-19 17:19:18,896 - Epoch: [107][  200/  500]    Overall Loss 0.399534    Objective Loss 0.399534                                        LR 0.000250    Time 0.071285    
2024-02-19 17:19:26,074 - Epoch: [107][  300/  500]    Overall Loss 0.402269    Objective Loss 0.402269                                        LR 0.000250    Time 0.071439    
2024-02-19 17:19:33,333 - Epoch: [107][  400/  500]    Overall Loss 0.400546    Objective Loss 0.400546                                        LR 0.000250    Time 0.071717    
2024-02-19 17:19:40,593 - Epoch: [107][  500/  500]    Overall Loss 0.405310    Objective Loss 0.405310    Top1 87.000000    Top5 100.000000    LR 0.000250    Time 0.071886    
2024-02-19 17:19:40,772 - --- validate (epoch=107)-----------
2024-02-19 17:19:40,772 - 10000 samples (100 per mini-batch)
2024-02-19 17:19:43,623 - Epoch: [107][  100/  100]    Loss 1.785273    Top1 59.360000    Top5 86.040000    
2024-02-19 17:19:43,726 - ==> Top1: 59.360    Top5: 86.040    Loss: 1.785

2024-02-19 17:19:43,736 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:19:43,737 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:19:43,799 - 

2024-02-19 17:19:43,799 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:19:50,918 - Epoch: [108][  100/  500]    Overall Loss 0.384186    Objective Loss 0.384186                                        LR 0.000250    Time 0.071146    
2024-02-19 17:19:57,641 - Epoch: [108][  200/  500]    Overall Loss 0.387768    Objective Loss 0.387768                                        LR 0.000250    Time 0.069169    
2024-02-19 17:20:04,597 - Epoch: [108][  300/  500]    Overall Loss 0.390102    Objective Loss 0.390102                                        LR 0.000250    Time 0.069287    
2024-02-19 17:20:11,466 - Epoch: [108][  400/  500]    Overall Loss 0.397599    Objective Loss 0.397599                                        LR 0.000250    Time 0.069129    
2024-02-19 17:20:18,364 - Epoch: [108][  500/  500]    Overall Loss 0.399284    Objective Loss 0.399284    Top1 87.000000    Top5 98.500000    LR 0.000250    Time 0.069091    
2024-02-19 17:20:18,502 - --- validate (epoch=108)-----------
2024-02-19 17:20:18,504 - 10000 samples (100 per mini-batch)
2024-02-19 17:20:21,447 - Epoch: [108][  100/  100]    Loss 1.784492    Top1 60.080000    Top5 85.660000    
2024-02-19 17:20:21,542 - ==> Top1: 60.080    Top5: 85.660    Loss: 1.784

2024-02-19 17:20:21,551 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:20:21,552 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:20:21,603 - 

2024-02-19 17:20:21,603 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:20:28,759 - Epoch: [109][  100/  500]    Overall Loss 0.383582    Objective Loss 0.383582                                        LR 0.000250    Time 0.071519    
2024-02-19 17:20:35,805 - Epoch: [109][  200/  500]    Overall Loss 0.395178    Objective Loss 0.395178                                        LR 0.000250    Time 0.070967    
2024-02-19 17:20:42,618 - Epoch: [109][  300/  500]    Overall Loss 0.394470    Objective Loss 0.394470                                        LR 0.000250    Time 0.070012    
2024-02-19 17:20:49,444 - Epoch: [109][  400/  500]    Overall Loss 0.396336    Objective Loss 0.396336                                        LR 0.000250    Time 0.069563    
2024-02-19 17:20:56,282 - Epoch: [109][  500/  500]    Overall Loss 0.397936    Objective Loss 0.397936    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.069319    
2024-02-19 17:20:56,409 - --- validate (epoch=109)-----------
2024-02-19 17:20:56,410 - 10000 samples (100 per mini-batch)
2024-02-19 17:20:59,217 - Epoch: [109][  100/  100]    Loss 1.760970    Top1 60.100000    Top5 86.090000    
2024-02-19 17:20:59,326 - ==> Top1: 60.100    Top5: 86.090    Loss: 1.761

2024-02-19 17:20:59,338 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:20:59,338 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:20:59,401 - 

2024-02-19 17:20:59,401 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:21:06,957 - Epoch: [110][  100/  500]    Overall Loss 0.375902    Objective Loss 0.375902                                        LR 0.000250    Time 0.075507    
2024-02-19 17:21:13,668 - Epoch: [110][  200/  500]    Overall Loss 0.385555    Objective Loss 0.385555                                        LR 0.000250    Time 0.071296    
2024-02-19 17:21:20,374 - Epoch: [110][  300/  500]    Overall Loss 0.391136    Objective Loss 0.391136                                        LR 0.000250    Time 0.069873    
2024-02-19 17:21:27,062 - Epoch: [110][  400/  500]    Overall Loss 0.393006    Objective Loss 0.393006                                        LR 0.000250    Time 0.069117    
2024-02-19 17:21:33,777 - Epoch: [110][  500/  500]    Overall Loss 0.395539    Objective Loss 0.395539    Top1 88.000000    Top5 98.500000    LR 0.000250    Time 0.068717    
2024-02-19 17:21:33,921 - --- validate (epoch=110)-----------
2024-02-19 17:21:33,921 - 10000 samples (100 per mini-batch)
2024-02-19 17:21:36,715 - Epoch: [110][  100/  100]    Loss 1.768408    Top1 59.650000    Top5 85.850000    
2024-02-19 17:21:36,883 - ==> Top1: 59.650    Top5: 85.850    Loss: 1.768

2024-02-19 17:21:36,893 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:21:36,893 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:21:36,955 - 

2024-02-19 17:21:36,955 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:21:44,429 - Epoch: [111][  100/  500]    Overall Loss 0.376204    Objective Loss 0.376204                                        LR 0.000250    Time 0.074684    
2024-02-19 17:21:51,453 - Epoch: [111][  200/  500]    Overall Loss 0.375309    Objective Loss 0.375309                                        LR 0.000250    Time 0.072447    
2024-02-19 17:21:58,562 - Epoch: [111][  300/  500]    Overall Loss 0.379431    Objective Loss 0.379431                                        LR 0.000250    Time 0.071979    
2024-02-19 17:22:05,665 - Epoch: [111][  400/  500]    Overall Loss 0.384439    Objective Loss 0.384439                                        LR 0.000250    Time 0.071733    
2024-02-19 17:22:12,710 - Epoch: [111][  500/  500]    Overall Loss 0.384868    Objective Loss 0.384868    Top1 91.500000    Top5 99.500000    LR 0.000250    Time 0.071470    
2024-02-19 17:22:12,845 - --- validate (epoch=111)-----------
2024-02-19 17:22:12,846 - 10000 samples (100 per mini-batch)
2024-02-19 17:22:15,639 - Epoch: [111][  100/  100]    Loss 1.789759    Top1 59.550000    Top5 85.860000    
2024-02-19 17:22:15,736 - ==> Top1: 59.550    Top5: 85.860    Loss: 1.790

2024-02-19 17:22:15,748 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:22:15,748 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:22:15,809 - 

2024-02-19 17:22:15,809 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:22:22,917 - Epoch: [112][  100/  500]    Overall Loss 0.372916    Objective Loss 0.372916                                        LR 0.000250    Time 0.071031    
2024-02-19 17:22:29,583 - Epoch: [112][  200/  500]    Overall Loss 0.377291    Objective Loss 0.377291                                        LR 0.000250    Time 0.068834    
2024-02-19 17:22:36,388 - Epoch: [112][  300/  500]    Overall Loss 0.377563    Objective Loss 0.377563                                        LR 0.000250    Time 0.068563    
2024-02-19 17:22:43,493 - Epoch: [112][  400/  500]    Overall Loss 0.383397    Objective Loss 0.383397                                        LR 0.000250    Time 0.069174    
2024-02-19 17:22:50,588 - Epoch: [112][  500/  500]    Overall Loss 0.386634    Objective Loss 0.386634    Top1 85.500000    Top5 99.500000    LR 0.000250    Time 0.069521    
2024-02-19 17:22:50,724 - --- validate (epoch=112)-----------
2024-02-19 17:22:50,724 - 10000 samples (100 per mini-batch)
2024-02-19 17:22:53,883 - Epoch: [112][  100/  100]    Loss 1.808364    Top1 59.860000    Top5 86.170000    
2024-02-19 17:22:54,058 - ==> Top1: 59.860    Top5: 86.170    Loss: 1.808

2024-02-19 17:22:54,068 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:22:54,068 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:22:54,129 - 

2024-02-19 17:22:54,129 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:23:01,535 - Epoch: [113][  100/  500]    Overall Loss 0.379976    Objective Loss 0.379976                                        LR 0.000250    Time 0.074003    
2024-02-19 17:23:08,494 - Epoch: [113][  200/  500]    Overall Loss 0.376639    Objective Loss 0.376639                                        LR 0.000250    Time 0.071779    
2024-02-19 17:23:15,567 - Epoch: [113][  300/  500]    Overall Loss 0.377383    Objective Loss 0.377383                                        LR 0.000250    Time 0.071414    
2024-02-19 17:23:22,828 - Epoch: [113][  400/  500]    Overall Loss 0.382346    Objective Loss 0.382346                                        LR 0.000250    Time 0.071705    
2024-02-19 17:23:30,157 - Epoch: [113][  500/  500]    Overall Loss 0.384519    Objective Loss 0.384519    Top1 86.000000    Top5 99.500000    LR 0.000250    Time 0.072015    
2024-02-19 17:23:30,280 - --- validate (epoch=113)-----------
2024-02-19 17:23:30,280 - 10000 samples (100 per mini-batch)
2024-02-19 17:23:33,094 - Epoch: [113][  100/  100]    Loss 1.799925    Top1 59.570000    Top5 85.930000    
2024-02-19 17:23:33,187 - ==> Top1: 59.570    Top5: 85.930    Loss: 1.800

2024-02-19 17:23:33,199 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:23:33,199 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:23:33,261 - 

2024-02-19 17:23:33,261 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:23:41,208 - Epoch: [114][  100/  500]    Overall Loss 0.362519    Objective Loss 0.362519                                        LR 0.000250    Time 0.079420    
2024-02-19 17:23:48,450 - Epoch: [114][  200/  500]    Overall Loss 0.368233    Objective Loss 0.368233                                        LR 0.000250    Time 0.075903    
2024-02-19 17:23:55,541 - Epoch: [114][  300/  500]    Overall Loss 0.368697    Objective Loss 0.368697                                        LR 0.000250    Time 0.074225    
2024-02-19 17:24:02,566 - Epoch: [114][  400/  500]    Overall Loss 0.373663    Objective Loss 0.373663                                        LR 0.000250    Time 0.073223    
2024-02-19 17:24:09,641 - Epoch: [114][  500/  500]    Overall Loss 0.380259    Objective Loss 0.380259    Top1 90.000000    Top5 99.000000    LR 0.000250    Time 0.072721    
2024-02-19 17:24:09,753 - --- validate (epoch=114)-----------
2024-02-19 17:24:09,754 - 10000 samples (100 per mini-batch)
2024-02-19 17:24:12,487 - Epoch: [114][  100/  100]    Loss 1.824426    Top1 59.310000    Top5 85.840000    
2024-02-19 17:24:12,608 - ==> Top1: 59.310    Top5: 85.840    Loss: 1.824

2024-02-19 17:24:12,619 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:24:12,619 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:24:12,679 - 

2024-02-19 17:24:12,680 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:24:20,101 - Epoch: [115][  100/  500]    Overall Loss 0.372828    Objective Loss 0.372828                                        LR 0.000250    Time 0.074163    
2024-02-19 17:24:27,058 - Epoch: [115][  200/  500]    Overall Loss 0.373907    Objective Loss 0.373907                                        LR 0.000250    Time 0.071845    
2024-02-19 17:24:34,011 - Epoch: [115][  300/  500]    Overall Loss 0.372180    Objective Loss 0.372180                                        LR 0.000250    Time 0.071062    
2024-02-19 17:24:40,979 - Epoch: [115][  400/  500]    Overall Loss 0.377547    Objective Loss 0.377547                                        LR 0.000250    Time 0.070706    
2024-02-19 17:24:47,931 - Epoch: [115][  500/  500]    Overall Loss 0.378982    Objective Loss 0.378982    Top1 85.000000    Top5 98.500000    LR 0.000250    Time 0.070462    
2024-02-19 17:24:48,059 - --- validate (epoch=115)-----------
2024-02-19 17:24:48,059 - 10000 samples (100 per mini-batch)
2024-02-19 17:24:50,939 - Epoch: [115][  100/  100]    Loss 1.803950    Top1 59.830000    Top5 85.820000    
2024-02-19 17:24:51,050 - ==> Top1: 59.830    Top5: 85.820    Loss: 1.804

2024-02-19 17:24:51,061 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:24:51,062 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:24:51,122 - 

2024-02-19 17:24:51,122 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:24:58,699 - Epoch: [116][  100/  500]    Overall Loss 0.370018    Objective Loss 0.370018                                        LR 0.000250    Time 0.075715    
2024-02-19 17:25:05,530 - Epoch: [116][  200/  500]    Overall Loss 0.365850    Objective Loss 0.365850                                        LR 0.000250    Time 0.071998    
2024-02-19 17:25:12,187 - Epoch: [116][  300/  500]    Overall Loss 0.368996    Objective Loss 0.368996                                        LR 0.000250    Time 0.070178    
2024-02-19 17:25:18,862 - Epoch: [116][  400/  500]    Overall Loss 0.370000    Objective Loss 0.370000                                        LR 0.000250    Time 0.069314    
2024-02-19 17:25:25,547 - Epoch: [116][  500/  500]    Overall Loss 0.374056    Objective Loss 0.374056    Top1 85.000000    Top5 99.500000    LR 0.000250    Time 0.068816    
2024-02-19 17:25:25,714 - --- validate (epoch=116)-----------
2024-02-19 17:25:25,715 - 10000 samples (100 per mini-batch)
2024-02-19 17:25:28,635 - Epoch: [116][  100/  100]    Loss 1.815954    Top1 59.720000    Top5 85.730000    
2024-02-19 17:25:28,808 - ==> Top1: 59.720    Top5: 85.730    Loss: 1.816

2024-02-19 17:25:28,819 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:25:28,819 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:25:28,880 - 

2024-02-19 17:25:28,880 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:25:36,322 - Epoch: [117][  100/  500]    Overall Loss 0.357760    Objective Loss 0.357760                                        LR 0.000250    Time 0.074361    
2024-02-19 17:25:43,287 - Epoch: [117][  200/  500]    Overall Loss 0.356955    Objective Loss 0.356955                                        LR 0.000250    Time 0.071987    
2024-02-19 17:25:50,213 - Epoch: [117][  300/  500]    Overall Loss 0.364442    Objective Loss 0.364442                                        LR 0.000250    Time 0.071067    
2024-02-19 17:25:57,220 - Epoch: [117][  400/  500]    Overall Loss 0.370243    Objective Loss 0.370243                                        LR 0.000250    Time 0.070809    
2024-02-19 17:26:04,142 - Epoch: [117][  500/  500]    Overall Loss 0.372194    Objective Loss 0.372194    Top1 89.500000    Top5 99.500000    LR 0.000250    Time 0.070483    
2024-02-19 17:26:04,273 - --- validate (epoch=117)-----------
2024-02-19 17:26:04,274 - 10000 samples (100 per mini-batch)
2024-02-19 17:26:07,177 - Epoch: [117][  100/  100]    Loss 1.813385    Top1 60.020000    Top5 85.900000    
2024-02-19 17:26:07,326 - ==> Top1: 60.020    Top5: 85.900    Loss: 1.813

2024-02-19 17:26:07,338 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:26:07,338 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:26:07,398 - 

2024-02-19 17:26:07,398 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:26:14,780 - Epoch: [118][  100/  500]    Overall Loss 0.357653    Objective Loss 0.357653                                        LR 0.000250    Time 0.073769    
2024-02-19 17:26:21,705 - Epoch: [118][  200/  500]    Overall Loss 0.353822    Objective Loss 0.353822                                        LR 0.000250    Time 0.071489    
2024-02-19 17:26:28,670 - Epoch: [118][  300/  500]    Overall Loss 0.354413    Objective Loss 0.354413                                        LR 0.000250    Time 0.070863    
2024-02-19 17:26:35,649 - Epoch: [118][  400/  500]    Overall Loss 0.362473    Objective Loss 0.362473                                        LR 0.000250    Time 0.070587    
2024-02-19 17:26:42,601 - Epoch: [118][  500/  500]    Overall Loss 0.368500    Objective Loss 0.368500    Top1 89.000000    Top5 99.500000    LR 0.000250    Time 0.070366    
2024-02-19 17:26:42,782 - --- validate (epoch=118)-----------
2024-02-19 17:26:42,783 - 10000 samples (100 per mini-batch)
2024-02-19 17:26:45,938 - Epoch: [118][  100/  100]    Loss 1.849383    Top1 59.390000    Top5 85.570000    
2024-02-19 17:26:46,038 - ==> Top1: 59.390    Top5: 85.570    Loss: 1.849

2024-02-19 17:26:46,049 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:26:46,049 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:26:46,110 - 

2024-02-19 17:26:46,111 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:26:53,468 - Epoch: [119][  100/  500]    Overall Loss 0.345665    Objective Loss 0.345665                                        LR 0.000250    Time 0.073523    
2024-02-19 17:27:00,404 - Epoch: [119][  200/  500]    Overall Loss 0.359003    Objective Loss 0.359003                                        LR 0.000250    Time 0.071423    
2024-02-19 17:27:07,339 - Epoch: [119][  300/  500]    Overall Loss 0.360961    Objective Loss 0.360961                                        LR 0.000250    Time 0.070720    
2024-02-19 17:27:14,309 - Epoch: [119][  400/  500]    Overall Loss 0.365260    Objective Loss 0.365260                                        LR 0.000250    Time 0.070456    
2024-02-19 17:27:21,184 - Epoch: [119][  500/  500]    Overall Loss 0.368261    Objective Loss 0.368261    Top1 88.000000    Top5 99.500000    LR 0.000250    Time 0.070107    
2024-02-19 17:27:21,440 - --- validate (epoch=119)-----------
2024-02-19 17:27:21,441 - 10000 samples (100 per mini-batch)
2024-02-19 17:27:24,253 - Epoch: [119][  100/  100]    Loss 1.855645    Top1 59.090000    Top5 85.700000    
2024-02-19 17:27:24,352 - ==> Top1: 59.090    Top5: 85.700    Loss: 1.856

2024-02-19 17:27:24,368 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:27:24,368 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:27:24,431 - 

2024-02-19 17:27:24,431 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:27:32,225 - Epoch: [120][  100/  500]    Overall Loss 0.339139    Objective Loss 0.339139                                        LR 0.000250    Time 0.077892    
2024-02-19 17:27:39,156 - Epoch: [120][  200/  500]    Overall Loss 0.346002    Objective Loss 0.346002                                        LR 0.000250    Time 0.073579    
2024-02-19 17:27:46,158 - Epoch: [120][  300/  500]    Overall Loss 0.356069    Objective Loss 0.356069                                        LR 0.000250    Time 0.072378    
2024-02-19 17:27:53,085 - Epoch: [120][  400/  500]    Overall Loss 0.359483    Objective Loss 0.359483                                        LR 0.000250    Time 0.071593    
2024-02-19 17:28:00,153 - Epoch: [120][  500/  500]    Overall Loss 0.365972    Objective Loss 0.365972    Top1 89.000000    Top5 98.500000    LR 0.000250    Time 0.071402    
2024-02-19 17:28:00,279 - --- validate (epoch=120)-----------
2024-02-19 17:28:00,279 - 10000 samples (100 per mini-batch)
2024-02-19 17:28:03,082 - Epoch: [120][  100/  100]    Loss 1.849578    Top1 59.150000    Top5 85.530000    
2024-02-19 17:28:03,177 - ==> Top1: 59.150    Top5: 85.530    Loss: 1.850

2024-02-19 17:28:03,186 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:28:03,187 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:28:03,250 - 

2024-02-19 17:28:03,250 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:28:10,963 - Epoch: [121][  100/  500]    Overall Loss 0.353543    Objective Loss 0.353543                                        LR 0.000250    Time 0.077080    
2024-02-19 17:28:18,235 - Epoch: [121][  200/  500]    Overall Loss 0.355225    Objective Loss 0.355225                                        LR 0.000250    Time 0.074879    
2024-02-19 17:28:25,385 - Epoch: [121][  300/  500]    Overall Loss 0.357259    Objective Loss 0.357259                                        LR 0.000250    Time 0.073739    
2024-02-19 17:28:32,399 - Epoch: [121][  400/  500]    Overall Loss 0.362525    Objective Loss 0.362525                                        LR 0.000250    Time 0.072831    
2024-02-19 17:28:39,266 - Epoch: [121][  500/  500]    Overall Loss 0.365523    Objective Loss 0.365523    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.071991    
2024-02-19 17:28:39,405 - --- validate (epoch=121)-----------
2024-02-19 17:28:39,405 - 10000 samples (100 per mini-batch)
2024-02-19 17:28:42,258 - Epoch: [121][  100/  100]    Loss 1.824821    Top1 59.830000    Top5 86.040000    
2024-02-19 17:28:42,357 - ==> Top1: 59.830    Top5: 86.040    Loss: 1.825

2024-02-19 17:28:42,367 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:28:42,368 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:28:42,428 - 

2024-02-19 17:28:42,429 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:28:50,096 - Epoch: [122][  100/  500]    Overall Loss 0.342752    Objective Loss 0.342752                                        LR 0.000250    Time 0.076621    
2024-02-19 17:28:57,074 - Epoch: [122][  200/  500]    Overall Loss 0.351260    Objective Loss 0.351260                                        LR 0.000250    Time 0.073184    
2024-02-19 17:29:03,920 - Epoch: [122][  300/  500]    Overall Loss 0.356273    Objective Loss 0.356273                                        LR 0.000250    Time 0.071596    
2024-02-19 17:29:10,572 - Epoch: [122][  400/  500]    Overall Loss 0.360148    Objective Loss 0.360148                                        LR 0.000250    Time 0.070319    
2024-02-19 17:29:17,561 - Epoch: [122][  500/  500]    Overall Loss 0.361480    Objective Loss 0.361480    Top1 86.500000    Top5 99.500000    LR 0.000250    Time 0.070228    
2024-02-19 17:29:17,706 - --- validate (epoch=122)-----------
2024-02-19 17:29:17,707 - 10000 samples (100 per mini-batch)
2024-02-19 17:29:20,553 - Epoch: [122][  100/  100]    Loss 1.836520    Top1 59.600000    Top5 85.500000    
2024-02-19 17:29:20,714 - ==> Top1: 59.600    Top5: 85.500    Loss: 1.837

2024-02-19 17:29:20,725 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:29:20,725 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:29:20,786 - 

2024-02-19 17:29:20,786 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:29:28,206 - Epoch: [123][  100/  500]    Overall Loss 0.335022    Objective Loss 0.335022                                        LR 0.000250    Time 0.074145    
2024-02-19 17:29:35,211 - Epoch: [123][  200/  500]    Overall Loss 0.342234    Objective Loss 0.342234                                        LR 0.000250    Time 0.072079    
2024-02-19 17:29:42,299 - Epoch: [123][  300/  500]    Overall Loss 0.348723    Objective Loss 0.348723                                        LR 0.000250    Time 0.071664    
2024-02-19 17:29:49,377 - Epoch: [123][  400/  500]    Overall Loss 0.351100    Objective Loss 0.351100                                        LR 0.000250    Time 0.071434    
2024-02-19 17:29:56,466 - Epoch: [123][  500/  500]    Overall Loss 0.353314    Objective Loss 0.353314    Top1 84.500000    Top5 100.000000    LR 0.000250    Time 0.071317    
2024-02-19 17:29:56,584 - --- validate (epoch=123)-----------
2024-02-19 17:29:56,584 - 10000 samples (100 per mini-batch)
2024-02-19 17:29:59,268 - Epoch: [123][  100/  100]    Loss 1.858697    Top1 59.060000    Top5 85.740000    
2024-02-19 17:29:59,374 - ==> Top1: 59.060    Top5: 85.740    Loss: 1.859

2024-02-19 17:29:59,380 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:29:59,381 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:29:59,434 - 

2024-02-19 17:29:59,435 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:30:06,793 - Epoch: [124][  100/  500]    Overall Loss 0.339974    Objective Loss 0.339974                                        LR 0.000250    Time 0.073535    
2024-02-19 17:30:13,737 - Epoch: [124][  200/  500]    Overall Loss 0.345771    Objective Loss 0.345771                                        LR 0.000250    Time 0.071467    
2024-02-19 17:30:20,740 - Epoch: [124][  300/  500]    Overall Loss 0.345579    Objective Loss 0.345579                                        LR 0.000250    Time 0.070976    
2024-02-19 17:30:27,640 - Epoch: [124][  400/  500]    Overall Loss 0.349166    Objective Loss 0.349166                                        LR 0.000250    Time 0.070474    
2024-02-19 17:30:34,689 - Epoch: [124][  500/  500]    Overall Loss 0.353267    Objective Loss 0.353267    Top1 87.000000    Top5 99.000000    LR 0.000250    Time 0.070469    
2024-02-19 17:30:34,862 - --- validate (epoch=124)-----------
2024-02-19 17:30:34,863 - 10000 samples (100 per mini-batch)
2024-02-19 17:30:37,816 - Epoch: [124][  100/  100]    Loss 1.852374    Top1 59.910000    Top5 85.740000    
2024-02-19 17:30:37,939 - ==> Top1: 59.910    Top5: 85.740    Loss: 1.852

2024-02-19 17:30:37,948 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:30:37,949 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:30:38,012 - 

2024-02-19 17:30:38,012 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:30:45,142 - Epoch: [125][  100/  500]    Overall Loss 0.342641    Objective Loss 0.342641                                        LR 0.000250    Time 0.071260    
2024-02-19 17:30:51,810 - Epoch: [125][  200/  500]    Overall Loss 0.339652    Objective Loss 0.339652                                        LR 0.000250    Time 0.068956    
2024-02-19 17:30:58,484 - Epoch: [125][  300/  500]    Overall Loss 0.342186    Objective Loss 0.342186                                        LR 0.000250    Time 0.068207    
2024-02-19 17:31:05,158 - Epoch: [125][  400/  500]    Overall Loss 0.347361    Objective Loss 0.347361                                        LR 0.000250    Time 0.067833    
2024-02-19 17:31:11,855 - Epoch: [125][  500/  500]    Overall Loss 0.349484    Objective Loss 0.349484    Top1 92.500000    Top5 100.000000    LR 0.000250    Time 0.067653    
2024-02-19 17:31:12,025 - --- validate (epoch=125)-----------
2024-02-19 17:31:12,026 - 10000 samples (100 per mini-batch)
2024-02-19 17:31:15,105 - Epoch: [125][  100/  100]    Loss 1.864347    Top1 59.370000    Top5 85.530000    
2024-02-19 17:31:15,296 - ==> Top1: 59.370    Top5: 85.530    Loss: 1.864

2024-02-19 17:31:15,307 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:31:15,308 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:31:15,367 - 

2024-02-19 17:31:15,367 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:31:22,992 - Epoch: [126][  100/  500]    Overall Loss 0.328410    Objective Loss 0.328410                                        LR 0.000250    Time 0.076196    
2024-02-19 17:31:29,912 - Epoch: [126][  200/  500]    Overall Loss 0.342120    Objective Loss 0.342120                                        LR 0.000250    Time 0.072682    
2024-02-19 17:31:36,928 - Epoch: [126][  300/  500]    Overall Loss 0.346524    Objective Loss 0.346524                                        LR 0.000250    Time 0.071825    
2024-02-19 17:31:43,827 - Epoch: [126][  400/  500]    Overall Loss 0.350320    Objective Loss 0.350320                                        LR 0.000250    Time 0.071108    
2024-02-19 17:31:50,768 - Epoch: [126][  500/  500]    Overall Loss 0.349495    Objective Loss 0.349495    Top1 89.500000    Top5 98.500000    LR 0.000250    Time 0.070762    
2024-02-19 17:31:51,001 - --- validate (epoch=126)-----------
2024-02-19 17:31:51,002 - 10000 samples (100 per mini-batch)
2024-02-19 17:31:54,033 - Epoch: [126][  100/  100]    Loss 1.874391    Top1 58.960000    Top5 85.670000    
2024-02-19 17:31:54,150 - ==> Top1: 58.960    Top5: 85.670    Loss: 1.874

2024-02-19 17:31:54,162 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:31:54,162 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:31:54,223 - 

2024-02-19 17:31:54,223 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:32:01,638 - Epoch: [127][  100/  500]    Overall Loss 0.337505    Objective Loss 0.337505                                        LR 0.000250    Time 0.074105    
2024-02-19 17:32:08,582 - Epoch: [127][  200/  500]    Overall Loss 0.341469    Objective Loss 0.341469                                        LR 0.000250    Time 0.071750    
2024-02-19 17:32:15,552 - Epoch: [127][  300/  500]    Overall Loss 0.342730    Objective Loss 0.342730                                        LR 0.000250    Time 0.071054    
2024-02-19 17:32:22,519 - Epoch: [127][  400/  500]    Overall Loss 0.347414    Objective Loss 0.347414                                        LR 0.000250    Time 0.070697    
2024-02-19 17:32:29,505 - Epoch: [127][  500/  500]    Overall Loss 0.350394    Objective Loss 0.350394    Top1 87.500000    Top5 99.000000    LR 0.000250    Time 0.070521    
2024-02-19 17:32:29,618 - --- validate (epoch=127)-----------
2024-02-19 17:32:29,619 - 10000 samples (100 per mini-batch)
2024-02-19 17:32:32,618 - Epoch: [127][  100/  100]    Loss 1.868177    Top1 59.330000    Top5 85.890000    
2024-02-19 17:32:32,758 - ==> Top1: 59.330    Top5: 85.890    Loss: 1.868

2024-02-19 17:32:32,768 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:32:32,768 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:32:32,835 - 

2024-02-19 17:32:32,835 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:32:40,237 - Epoch: [128][  100/  500]    Overall Loss 0.321977    Objective Loss 0.321977                                        LR 0.000250    Time 0.073927    
2024-02-19 17:32:47,150 - Epoch: [128][  200/  500]    Overall Loss 0.328395    Objective Loss 0.328395                                        LR 0.000250    Time 0.071514    
2024-02-19 17:32:54,088 - Epoch: [128][  300/  500]    Overall Loss 0.335899    Objective Loss 0.335899                                        LR 0.000250    Time 0.070787    
2024-02-19 17:33:01,048 - Epoch: [128][  400/  500]    Overall Loss 0.340811    Objective Loss 0.340811                                        LR 0.000250    Time 0.070482    
2024-02-19 17:33:08,024 - Epoch: [128][  500/  500]    Overall Loss 0.344051    Objective Loss 0.344051    Top1 90.000000    Top5 100.000000    LR 0.000250    Time 0.070329    
2024-02-19 17:33:08,137 - --- validate (epoch=128)-----------
2024-02-19 17:33:08,137 - 10000 samples (100 per mini-batch)
2024-02-19 17:33:11,059 - Epoch: [128][  100/  100]    Loss 1.862338    Top1 59.780000    Top5 86.150000    
2024-02-19 17:33:11,195 - ==> Top1: 59.780    Top5: 86.150    Loss: 1.862

2024-02-19 17:33:11,205 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:33:11,205 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:33:11,270 - 

2024-02-19 17:33:11,270 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:33:18,970 - Epoch: [129][  100/  500]    Overall Loss 0.327128    Objective Loss 0.327128                                        LR 0.000250    Time 0.076942    
2024-02-19 17:33:25,930 - Epoch: [129][  200/  500]    Overall Loss 0.330816    Objective Loss 0.330816                                        LR 0.000250    Time 0.073255    
2024-02-19 17:33:32,940 - Epoch: [129][  300/  500]    Overall Loss 0.334286    Objective Loss 0.334286                                        LR 0.000250    Time 0.072189    
2024-02-19 17:33:39,899 - Epoch: [129][  400/  500]    Overall Loss 0.336386    Objective Loss 0.336386                                        LR 0.000250    Time 0.071529    
2024-02-19 17:33:46,911 - Epoch: [129][  500/  500]    Overall Loss 0.339072    Objective Loss 0.339072    Top1 89.500000    Top5 100.000000    LR 0.000250    Time 0.071239    
2024-02-19 17:33:47,089 - --- validate (epoch=129)-----------
2024-02-19 17:33:47,090 - 10000 samples (100 per mini-batch)
2024-02-19 17:33:50,021 - Epoch: [129][  100/  100]    Loss 1.913295    Top1 59.320000    Top5 85.110000    
2024-02-19 17:33:50,109 - ==> Top1: 59.320    Top5: 85.110    Loss: 1.913

2024-02-19 17:33:50,114 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:33:50,114 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:33:50,171 - 

2024-02-19 17:33:50,171 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:33:57,557 - Epoch: [130][  100/  500]    Overall Loss 0.334636    Objective Loss 0.334636                                        LR 0.000250    Time 0.073802    
2024-02-19 17:34:04,499 - Epoch: [130][  200/  500]    Overall Loss 0.330480    Objective Loss 0.330480                                        LR 0.000250    Time 0.071593    
2024-02-19 17:34:11,465 - Epoch: [130][  300/  500]    Overall Loss 0.327833    Objective Loss 0.327833                                        LR 0.000250    Time 0.070934    
2024-02-19 17:34:18,465 - Epoch: [130][  400/  500]    Overall Loss 0.331335    Objective Loss 0.331335                                        LR 0.000250    Time 0.070691    
2024-02-19 17:34:25,446 - Epoch: [130][  500/  500]    Overall Loss 0.335437    Objective Loss 0.335437    Top1 90.000000    Top5 98.500000    LR 0.000250    Time 0.070509    
2024-02-19 17:34:25,558 - --- validate (epoch=130)-----------
2024-02-19 17:34:25,559 - 10000 samples (100 per mini-batch)
2024-02-19 17:34:28,676 - Epoch: [130][  100/  100]    Loss 1.907367    Top1 59.130000    Top5 85.190000    
2024-02-19 17:34:28,769 - ==> Top1: 59.130    Top5: 85.190    Loss: 1.907

2024-02-19 17:34:28,778 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:34:28,779 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:34:28,827 - 

2024-02-19 17:34:28,828 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:34:35,925 - Epoch: [131][  100/  500]    Overall Loss 0.317695    Objective Loss 0.317695                                        LR 0.000250    Time 0.070930    
2024-02-19 17:34:42,778 - Epoch: [131][  200/  500]    Overall Loss 0.322430    Objective Loss 0.322430                                        LR 0.000250    Time 0.069711    
2024-02-19 17:34:49,671 - Epoch: [131][  300/  500]    Overall Loss 0.333403    Objective Loss 0.333403                                        LR 0.000250    Time 0.069439    
2024-02-19 17:34:56,642 - Epoch: [131][  400/  500]    Overall Loss 0.334155    Objective Loss 0.334155                                        LR 0.000250    Time 0.069496    
2024-02-19 17:35:03,579 - Epoch: [131][  500/  500]    Overall Loss 0.337027    Objective Loss 0.337027    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.069465    
2024-02-19 17:35:03,692 - --- validate (epoch=131)-----------
2024-02-19 17:35:03,693 - 10000 samples (100 per mini-batch)
2024-02-19 17:35:06,467 - Epoch: [131][  100/  100]    Loss 1.899934    Top1 59.270000    Top5 85.610000    
2024-02-19 17:35:06,628 - ==> Top1: 59.270    Top5: 85.610    Loss: 1.900

2024-02-19 17:35:06,639 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:35:06,639 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:35:06,697 - 

2024-02-19 17:35:06,698 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:35:14,432 - Epoch: [132][  100/  500]    Overall Loss 0.324536    Objective Loss 0.324536                                        LR 0.000250    Time 0.077289    
2024-02-19 17:35:21,401 - Epoch: [132][  200/  500]    Overall Loss 0.326878    Objective Loss 0.326878                                        LR 0.000250    Time 0.073471    
2024-02-19 17:35:28,370 - Epoch: [132][  300/  500]    Overall Loss 0.329249    Objective Loss 0.329249                                        LR 0.000250    Time 0.072199    
2024-02-19 17:35:35,337 - Epoch: [132][  400/  500]    Overall Loss 0.333414    Objective Loss 0.333414                                        LR 0.000250    Time 0.071558    
2024-02-19 17:35:42,258 - Epoch: [132][  500/  500]    Overall Loss 0.336415    Objective Loss 0.336415    Top1 88.000000    Top5 99.500000    LR 0.000250    Time 0.071080    
2024-02-19 17:35:42,438 - --- validate (epoch=132)-----------
2024-02-19 17:35:42,439 - 10000 samples (100 per mini-batch)
2024-02-19 17:35:45,315 - Epoch: [132][  100/  100]    Loss 1.892687    Top1 59.240000    Top5 85.570000    
2024-02-19 17:35:45,411 - ==> Top1: 59.240    Top5: 85.570    Loss: 1.893

2024-02-19 17:35:45,418 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:35:45,418 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:35:45,473 - 

2024-02-19 17:35:45,474 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:35:52,882 - Epoch: [133][  100/  500]    Overall Loss 0.314647    Objective Loss 0.314647                                        LR 0.000250    Time 0.074036    
2024-02-19 17:35:59,791 - Epoch: [133][  200/  500]    Overall Loss 0.318626    Objective Loss 0.318626                                        LR 0.000250    Time 0.071543    
2024-02-19 17:36:06,711 - Epoch: [133][  300/  500]    Overall Loss 0.325949    Objective Loss 0.325949                                        LR 0.000250    Time 0.070751    
2024-02-19 17:36:13,751 - Epoch: [133][  400/  500]    Overall Loss 0.330286    Objective Loss 0.330286                                        LR 0.000250    Time 0.070652    
2024-02-19 17:36:20,998 - Epoch: [133][  500/  500]    Overall Loss 0.332519    Objective Loss 0.332519    Top1 92.500000    Top5 100.000000    LR 0.000250    Time 0.071009    
2024-02-19 17:36:21,180 - --- validate (epoch=133)-----------
2024-02-19 17:36:21,181 - 10000 samples (100 per mini-batch)
2024-02-19 17:36:24,061 - Epoch: [133][  100/  100]    Loss 1.894338    Top1 59.280000    Top5 85.410000    
2024-02-19 17:36:24,186 - ==> Top1: 59.280    Top5: 85.410    Loss: 1.894

2024-02-19 17:36:24,196 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:36:24,197 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:36:24,266 - 

2024-02-19 17:36:24,267 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:36:31,976 - Epoch: [134][  100/  500]    Overall Loss 0.323956    Objective Loss 0.323956                                        LR 0.000250    Time 0.077037    
2024-02-19 17:36:39,056 - Epoch: [134][  200/  500]    Overall Loss 0.318200    Objective Loss 0.318200                                        LR 0.000250    Time 0.073901    
2024-02-19 17:36:46,154 - Epoch: [134][  300/  500]    Overall Loss 0.323282    Objective Loss 0.323282                                        LR 0.000250    Time 0.072913    
2024-02-19 17:36:53,228 - Epoch: [134][  400/  500]    Overall Loss 0.326481    Objective Loss 0.326481                                        LR 0.000250    Time 0.072360    
2024-02-19 17:37:00,225 - Epoch: [134][  500/  500]    Overall Loss 0.330671    Objective Loss 0.330671    Top1 89.500000    Top5 99.000000    LR 0.000250    Time 0.071877    
2024-02-19 17:37:00,409 - --- validate (epoch=134)-----------
2024-02-19 17:37:00,410 - 10000 samples (100 per mini-batch)
2024-02-19 17:37:03,322 - Epoch: [134][  100/  100]    Loss 1.921497    Top1 59.110000    Top5 85.390000    
2024-02-19 17:37:03,473 - ==> Top1: 59.110    Top5: 85.390    Loss: 1.921

2024-02-19 17:37:03,484 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:37:03,485 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:37:03,546 - 

2024-02-19 17:37:03,546 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:37:10,936 - Epoch: [135][  100/  500]    Overall Loss 0.319096    Objective Loss 0.319096                                        LR 0.000250    Time 0.073854    
2024-02-19 17:37:17,762 - Epoch: [135][  200/  500]    Overall Loss 0.320444    Objective Loss 0.320444                                        LR 0.000250    Time 0.071040    
2024-02-19 17:37:24,598 - Epoch: [135][  300/  500]    Overall Loss 0.323427    Objective Loss 0.323427                                        LR 0.000250    Time 0.070135    
2024-02-19 17:37:31,462 - Epoch: [135][  400/  500]    Overall Loss 0.329200    Objective Loss 0.329200                                        LR 0.000250    Time 0.069751    
2024-02-19 17:37:38,472 - Epoch: [135][  500/  500]    Overall Loss 0.330982    Objective Loss 0.330982    Top1 90.000000    Top5 99.500000    LR 0.000250    Time 0.069812    
2024-02-19 17:37:38,610 - --- validate (epoch=135)-----------
2024-02-19 17:37:38,611 - 10000 samples (100 per mini-batch)
2024-02-19 17:37:41,508 - Epoch: [135][  100/  100]    Loss 1.874001    Top1 59.550000    Top5 85.790000    
2024-02-19 17:37:41,612 - ==> Top1: 59.550    Top5: 85.790    Loss: 1.874

2024-02-19 17:37:41,619 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:37:41,619 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:37:41,676 - 

2024-02-19 17:37:41,677 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:37:49,405 - Epoch: [136][  100/  500]    Overall Loss 0.312774    Objective Loss 0.312774                                        LR 0.000250    Time 0.077211    
2024-02-19 17:37:56,512 - Epoch: [136][  200/  500]    Overall Loss 0.318205    Objective Loss 0.318205                                        LR 0.000250    Time 0.074122    
2024-02-19 17:38:03,671 - Epoch: [136][  300/  500]    Overall Loss 0.322399    Objective Loss 0.322399                                        LR 0.000250    Time 0.073268    
2024-02-19 17:38:10,791 - Epoch: [136][  400/  500]    Overall Loss 0.329251    Objective Loss 0.329251                                        LR 0.000250    Time 0.072740    
2024-02-19 17:38:17,767 - Epoch: [136][  500/  500]    Overall Loss 0.331625    Objective Loss 0.331625    Top1 91.000000    Top5 99.500000    LR 0.000250    Time 0.072137    
2024-02-19 17:38:17,928 - --- validate (epoch=136)-----------
2024-02-19 17:38:17,930 - 10000 samples (100 per mini-batch)
2024-02-19 17:38:20,818 - Epoch: [136][  100/  100]    Loss 1.928612    Top1 58.880000    Top5 85.260000    
2024-02-19 17:38:20,973 - ==> Top1: 58.880    Top5: 85.260    Loss: 1.929

2024-02-19 17:38:20,984 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:38:20,985 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:38:21,044 - 

2024-02-19 17:38:21,045 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:38:28,164 - Epoch: [137][  100/  500]    Overall Loss 0.320526    Objective Loss 0.320526                                        LR 0.000250    Time 0.071144    
2024-02-19 17:38:34,810 - Epoch: [137][  200/  500]    Overall Loss 0.319600    Objective Loss 0.319600                                        LR 0.000250    Time 0.068790    
2024-02-19 17:38:41,483 - Epoch: [137][  300/  500]    Overall Loss 0.321798    Objective Loss 0.321798                                        LR 0.000250    Time 0.068094    
2024-02-19 17:38:48,155 - Epoch: [137][  400/  500]    Overall Loss 0.324250    Objective Loss 0.324250                                        LR 0.000250    Time 0.067741    
2024-02-19 17:38:54,905 - Epoch: [137][  500/  500]    Overall Loss 0.326408    Objective Loss 0.326408    Top1 92.500000    Top5 99.500000    LR 0.000250    Time 0.067686    
2024-02-19 17:38:55,007 - --- validate (epoch=137)-----------
2024-02-19 17:38:55,008 - 10000 samples (100 per mini-batch)
2024-02-19 17:38:57,743 - Epoch: [137][  100/  100]    Loss 1.924970    Top1 59.600000    Top5 85.320000    
2024-02-19 17:38:57,839 - ==> Top1: 59.600    Top5: 85.320    Loss: 1.925

2024-02-19 17:38:57,844 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:38:57,845 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:38:57,900 - 

2024-02-19 17:38:57,900 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:39:05,517 - Epoch: [138][  100/  500]    Overall Loss 0.312813    Objective Loss 0.312813                                        LR 0.000250    Time 0.076123    
2024-02-19 17:39:12,485 - Epoch: [138][  200/  500]    Overall Loss 0.319293    Objective Loss 0.319293                                        LR 0.000250    Time 0.072884    
2024-02-19 17:39:19,413 - Epoch: [138][  300/  500]    Overall Loss 0.317928    Objective Loss 0.317928                                        LR 0.000250    Time 0.071669    
2024-02-19 17:39:26,324 - Epoch: [138][  400/  500]    Overall Loss 0.321298    Objective Loss 0.321298                                        LR 0.000250    Time 0.071019    
2024-02-19 17:39:33,348 - Epoch: [138][  500/  500]    Overall Loss 0.325568    Objective Loss 0.325568    Top1 89.500000    Top5 99.500000    LR 0.000250    Time 0.070857    
2024-02-19 17:39:33,530 - --- validate (epoch=138)-----------
2024-02-19 17:39:33,531 - 10000 samples (100 per mini-batch)
2024-02-19 17:39:36,322 - Epoch: [138][  100/  100]    Loss 1.897192    Top1 59.600000    Top5 85.370000    
2024-02-19 17:39:36,525 - ==> Top1: 59.600    Top5: 85.370    Loss: 1.897

2024-02-19 17:39:36,537 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:39:36,537 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:39:36,598 - 

2024-02-19 17:39:36,598 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:39:44,007 - Epoch: [139][  100/  500]    Overall Loss 0.313691    Objective Loss 0.313691                                        LR 0.000250    Time 0.074038    
2024-02-19 17:39:50,975 - Epoch: [139][  200/  500]    Overall Loss 0.316112    Objective Loss 0.316112                                        LR 0.000250    Time 0.071840    
2024-02-19 17:39:57,886 - Epoch: [139][  300/  500]    Overall Loss 0.321306    Objective Loss 0.321306                                        LR 0.000250    Time 0.070918    
2024-02-19 17:40:04,876 - Epoch: [139][  400/  500]    Overall Loss 0.322199    Objective Loss 0.322199                                        LR 0.000250    Time 0.070652    
2024-02-19 17:40:11,853 - Epoch: [139][  500/  500]    Overall Loss 0.323036    Objective Loss 0.323036    Top1 88.500000    Top5 99.000000    LR 0.000250    Time 0.070468    
2024-02-19 17:40:11,971 - --- validate (epoch=139)-----------
2024-02-19 17:40:11,972 - 10000 samples (100 per mini-batch)
2024-02-19 17:40:14,922 - Epoch: [139][  100/  100]    Loss 1.915504    Top1 59.400000    Top5 85.500000    
2024-02-19 17:40:15,020 - ==> Top1: 59.400    Top5: 85.500    Loss: 1.916

2024-02-19 17:40:15,026 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:40:15,026 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:40:15,084 - 

2024-02-19 17:40:15,085 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:40:22,452 - Epoch: [140][  100/  500]    Overall Loss 0.308380    Objective Loss 0.308380                                        LR 0.000250    Time 0.073629    
2024-02-19 17:40:29,386 - Epoch: [140][  200/  500]    Overall Loss 0.316878    Objective Loss 0.316878                                        LR 0.000250    Time 0.071466    
2024-02-19 17:40:36,285 - Epoch: [140][  300/  500]    Overall Loss 0.317922    Objective Loss 0.317922                                        LR 0.000250    Time 0.070626    
2024-02-19 17:40:43,206 - Epoch: [140][  400/  500]    Overall Loss 0.319950    Objective Loss 0.319950                                        LR 0.000250    Time 0.070262    
2024-02-19 17:40:50,242 - Epoch: [140][  500/  500]    Overall Loss 0.322267    Objective Loss 0.322267    Top1 92.000000    Top5 99.500000    LR 0.000250    Time 0.070274    
2024-02-19 17:40:50,369 - --- validate (epoch=140)-----------
2024-02-19 17:40:50,371 - 10000 samples (100 per mini-batch)
2024-02-19 17:40:53,352 - Epoch: [140][  100/  100]    Loss 1.888656    Top1 59.530000    Top5 85.440000    
2024-02-19 17:40:53,473 - ==> Top1: 59.530    Top5: 85.440    Loss: 1.889

2024-02-19 17:40:53,484 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:40:53,484 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:40:53,544 - 

2024-02-19 17:40:53,545 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:41:01,123 - Epoch: [141][  100/  500]    Overall Loss 0.303841    Objective Loss 0.303841                                        LR 0.000250    Time 0.075736    
2024-02-19 17:41:08,185 - Epoch: [141][  200/  500]    Overall Loss 0.305617    Objective Loss 0.305617                                        LR 0.000250    Time 0.073159    
2024-02-19 17:41:15,128 - Epoch: [141][  300/  500]    Overall Loss 0.307391    Objective Loss 0.307391                                        LR 0.000250    Time 0.071905    
2024-02-19 17:41:22,021 - Epoch: [141][  400/  500]    Overall Loss 0.311601    Objective Loss 0.311601                                        LR 0.000250    Time 0.071151    
2024-02-19 17:41:28,991 - Epoch: [141][  500/  500]    Overall Loss 0.314979    Objective Loss 0.314979    Top1 92.000000    Top5 99.500000    LR 0.000250    Time 0.070854    
2024-02-19 17:41:29,112 - --- validate (epoch=141)-----------
2024-02-19 17:41:29,112 - 10000 samples (100 per mini-batch)
2024-02-19 17:41:32,055 - Epoch: [141][  100/  100]    Loss 1.918699    Top1 59.460000    Top5 85.740000    
2024-02-19 17:41:32,161 - ==> Top1: 59.460    Top5: 85.740    Loss: 1.919

2024-02-19 17:41:32,172 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:41:32,172 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:41:32,236 - 

2024-02-19 17:41:32,236 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:41:40,000 - Epoch: [142][  100/  500]    Overall Loss 0.301498    Objective Loss 0.301498                                        LR 0.000250    Time 0.077589    
2024-02-19 17:41:47,064 - Epoch: [142][  200/  500]    Overall Loss 0.307584    Objective Loss 0.307584                                        LR 0.000250    Time 0.074097    
2024-02-19 17:41:54,117 - Epoch: [142][  300/  500]    Overall Loss 0.312257    Objective Loss 0.312257                                        LR 0.000250    Time 0.072895    
2024-02-19 17:42:01,158 - Epoch: [142][  400/  500]    Overall Loss 0.315166    Objective Loss 0.315166                                        LR 0.000250    Time 0.072265    
2024-02-19 17:42:08,137 - Epoch: [142][  500/  500]    Overall Loss 0.318074    Objective Loss 0.318074    Top1 90.000000    Top5 100.000000    LR 0.000250    Time 0.071763    
2024-02-19 17:42:08,262 - --- validate (epoch=142)-----------
2024-02-19 17:42:08,263 - 10000 samples (100 per mini-batch)
2024-02-19 17:42:11,332 - Epoch: [142][  100/  100]    Loss 1.891356    Top1 59.630000    Top5 85.490000    
2024-02-19 17:42:11,429 - ==> Top1: 59.630    Top5: 85.490    Loss: 1.891

2024-02-19 17:42:11,434 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:42:11,434 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:42:11,490 - 

2024-02-19 17:42:11,490 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:42:18,872 - Epoch: [143][  100/  500]    Overall Loss 0.305017    Objective Loss 0.305017                                        LR 0.000250    Time 0.073767    
2024-02-19 17:42:25,837 - Epoch: [143][  200/  500]    Overall Loss 0.305078    Objective Loss 0.305078                                        LR 0.000250    Time 0.071689    
2024-02-19 17:42:32,807 - Epoch: [143][  300/  500]    Overall Loss 0.305630    Objective Loss 0.305630                                        LR 0.000250    Time 0.071014    
2024-02-19 17:42:39,715 - Epoch: [143][  400/  500]    Overall Loss 0.308593    Objective Loss 0.308593                                        LR 0.000250    Time 0.070523    
2024-02-19 17:42:46,728 - Epoch: [143][  500/  500]    Overall Loss 0.310301    Objective Loss 0.310301    Top1 92.000000    Top5 99.500000    LR 0.000250    Time 0.070436    
2024-02-19 17:42:46,848 - --- validate (epoch=143)-----------
2024-02-19 17:42:46,848 - 10000 samples (100 per mini-batch)
2024-02-19 17:42:49,676 - Epoch: [143][  100/  100]    Loss 1.907204    Top1 60.080000    Top5 85.530000    
2024-02-19 17:42:49,798 - ==> Top1: 60.080    Top5: 85.530    Loss: 1.907

2024-02-19 17:42:49,809 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:42:49,810 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:42:49,884 - 

2024-02-19 17:42:49,884 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:42:57,501 - Epoch: [144][  100/  500]    Overall Loss 0.296074    Objective Loss 0.296074                                        LR 0.000250    Time 0.076108    
2024-02-19 17:43:04,331 - Epoch: [144][  200/  500]    Overall Loss 0.292306    Objective Loss 0.292306                                        LR 0.000250    Time 0.072190    
2024-02-19 17:43:11,237 - Epoch: [144][  300/  500]    Overall Loss 0.299635    Objective Loss 0.299635                                        LR 0.000250    Time 0.071134    
2024-02-19 17:43:18,073 - Epoch: [144][  400/  500]    Overall Loss 0.302514    Objective Loss 0.302514                                        LR 0.000250    Time 0.070432    
2024-02-19 17:43:25,047 - Epoch: [144][  500/  500]    Overall Loss 0.306938    Objective Loss 0.306938    Top1 91.000000    Top5 100.000000    LR 0.000250    Time 0.070285    
2024-02-19 17:43:25,157 - --- validate (epoch=144)-----------
2024-02-19 17:43:25,158 - 10000 samples (100 per mini-batch)
2024-02-19 17:43:27,916 - Epoch: [144][  100/  100]    Loss 1.907192    Top1 59.280000    Top5 85.520000    
2024-02-19 17:43:28,013 - ==> Top1: 59.280    Top5: 85.520    Loss: 1.907

2024-02-19 17:43:28,019 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:43:28,019 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:43:28,075 - 

2024-02-19 17:43:28,075 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:43:35,471 - Epoch: [145][  100/  500]    Overall Loss 0.282330    Objective Loss 0.282330                                        LR 0.000250    Time 0.073908    
2024-02-19 17:43:42,362 - Epoch: [145][  200/  500]    Overall Loss 0.292444    Objective Loss 0.292444                                        LR 0.000250    Time 0.071393    
2024-02-19 17:43:49,289 - Epoch: [145][  300/  500]    Overall Loss 0.299170    Objective Loss 0.299170                                        LR 0.000250    Time 0.070672    
2024-02-19 17:43:56,225 - Epoch: [145][  400/  500]    Overall Loss 0.304370    Objective Loss 0.304370                                        LR 0.000250    Time 0.070333    
2024-02-19 17:44:03,221 - Epoch: [145][  500/  500]    Overall Loss 0.308219    Objective Loss 0.308219    Top1 92.500000    Top5 98.500000    LR 0.000250    Time 0.070252    
2024-02-19 17:44:03,395 - --- validate (epoch=145)-----------
2024-02-19 17:44:03,396 - 10000 samples (100 per mini-batch)
2024-02-19 17:44:06,159 - Epoch: [145][  100/  100]    Loss 1.923322    Top1 59.140000    Top5 85.370000    
2024-02-19 17:44:06,341 - ==> Top1: 59.140    Top5: 85.370    Loss: 1.923

2024-02-19 17:44:06,352 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:44:06,352 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:44:06,414 - 

2024-02-19 17:44:06,414 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:44:14,111 - Epoch: [146][  100/  500]    Overall Loss 0.295699    Objective Loss 0.295699                                        LR 0.000250    Time 0.076915    
2024-02-19 17:44:21,016 - Epoch: [146][  200/  500]    Overall Loss 0.296993    Objective Loss 0.296993                                        LR 0.000250    Time 0.072966    
2024-02-19 17:44:27,925 - Epoch: [146][  300/  500]    Overall Loss 0.299033    Objective Loss 0.299033                                        LR 0.000250    Time 0.071662    
2024-02-19 17:44:34,782 - Epoch: [146][  400/  500]    Overall Loss 0.301379    Objective Loss 0.301379                                        LR 0.000250    Time 0.070880    
2024-02-19 17:44:41,757 - Epoch: [146][  500/  500]    Overall Loss 0.305143    Objective Loss 0.305143    Top1 88.500000    Top5 99.500000    LR 0.000250    Time 0.070646    
2024-02-19 17:44:41,909 - --- validate (epoch=146)-----------
2024-02-19 17:44:41,910 - 10000 samples (100 per mini-batch)
2024-02-19 17:44:44,780 - Epoch: [146][  100/  100]    Loss 1.971627    Top1 58.810000    Top5 85.000000    
2024-02-19 17:44:44,889 - ==> Top1: 58.810    Top5: 85.000    Loss: 1.972

2024-02-19 17:44:44,900 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:44:44,900 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:44:44,959 - 

2024-02-19 17:44:44,960 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:44:52,460 - Epoch: [147][  100/  500]    Overall Loss 0.309138    Objective Loss 0.309138                                        LR 0.000250    Time 0.074957    
2024-02-19 17:44:59,349 - Epoch: [147][  200/  500]    Overall Loss 0.306801    Objective Loss 0.306801                                        LR 0.000250    Time 0.071903    
2024-02-19 17:45:06,254 - Epoch: [147][  300/  500]    Overall Loss 0.305706    Objective Loss 0.305706                                        LR 0.000250    Time 0.070940    
2024-02-19 17:45:13,161 - Epoch: [147][  400/  500]    Overall Loss 0.307134    Objective Loss 0.307134                                        LR 0.000250    Time 0.070463    
2024-02-19 17:45:20,080 - Epoch: [147][  500/  500]    Overall Loss 0.307280    Objective Loss 0.307280    Top1 94.000000    Top5 99.500000    LR 0.000250    Time 0.070203    
2024-02-19 17:45:20,238 - --- validate (epoch=147)-----------
2024-02-19 17:45:20,239 - 10000 samples (100 per mini-batch)
2024-02-19 17:45:23,180 - Epoch: [147][  100/  100]    Loss 1.915154    Top1 59.680000    Top5 85.160000    
2024-02-19 17:45:23,319 - ==> Top1: 59.680    Top5: 85.160    Loss: 1.915

2024-02-19 17:45:23,330 - ==> Best [Top1: 60.200   Top5: 86.020   Sparsity:0.00   Params: 753952 on epoch: 104]
2024-02-19 17:45:23,331 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:45:23,390 - 

2024-02-19 17:45:23,390 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:45:30,820 - Epoch: [148][  100/  500]    Overall Loss 0.302657    Objective Loss 0.302657                                        LR 0.000250    Time 0.074245    
2024-02-19 17:45:37,724 - Epoch: [148][  200/  500]    Overall Loss 0.302141    Objective Loss 0.302141                                        LR 0.000250    Time 0.071626    
2024-02-19 17:45:44,609 - Epoch: [148][  300/  500]    Overall Loss 0.303867    Objective Loss 0.303867                                        LR 0.000250    Time 0.070686    
2024-02-19 17:45:51,585 - Epoch: [148][  400/  500]    Overall Loss 0.304256    Objective Loss 0.304256                                        LR 0.000250    Time 0.070446    
2024-02-19 17:45:58,512 - Epoch: [148][  500/  500]    Overall Loss 0.306868    Objective Loss 0.306868    Top1 88.000000    Top5 100.000000    LR 0.000250    Time 0.070204    
2024-02-19 17:45:58,674 - --- validate (epoch=148)-----------
2024-02-19 17:45:58,675 - 10000 samples (100 per mini-batch)
2024-02-19 17:46:01,727 - Epoch: [148][  100/  100]    Loss 1.888129    Top1 60.240000    Top5 85.950000    
2024-02-19 17:46:01,832 - ==> Top1: 60.240    Top5: 85.950    Loss: 1.888

2024-02-19 17:46:01,844 - ==> Best [Top1: 60.240   Top5: 85.950   Sparsity:0.00   Params: 753952 on epoch: 148]
2024-02-19 17:46:01,844 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:46:01,920 - 

2024-02-19 17:46:01,920 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:46:09,426 - Epoch: [149][  100/  500]    Overall Loss 0.288324    Objective Loss 0.288324                                        LR 0.000250    Time 0.075004    
2024-02-19 17:46:16,379 - Epoch: [149][  200/  500]    Overall Loss 0.292148    Objective Loss 0.292148                                        LR 0.000250    Time 0.072246    
2024-02-19 17:46:23,324 - Epoch: [149][  300/  500]    Overall Loss 0.299755    Objective Loss 0.299755                                        LR 0.000250    Time 0.071302    
2024-02-19 17:46:30,371 - Epoch: [149][  400/  500]    Overall Loss 0.303344    Objective Loss 0.303344                                        LR 0.000250    Time 0.071084    
2024-02-19 17:46:37,349 - Epoch: [149][  500/  500]    Overall Loss 0.304277    Objective Loss 0.304277    Top1 90.000000    Top5 99.000000    LR 0.000250    Time 0.070814    
2024-02-19 17:46:37,455 - --- validate (epoch=149)-----------
2024-02-19 17:46:37,455 - 10000 samples (100 per mini-batch)
2024-02-19 17:46:40,277 - Epoch: [149][  100/  100]    Loss 1.935919    Top1 59.500000    Top5 85.440000    
2024-02-19 17:46:40,375 - ==> Top1: 59.500    Top5: 85.440    Loss: 1.936

2024-02-19 17:46:40,386 - ==> Best [Top1: 60.240   Top5: 85.950   Sparsity:0.00   Params: 753952 on epoch: 148]
2024-02-19 17:46:40,386 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:46:40,456 - 

2024-02-19 17:46:40,456 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:46:47,967 - Epoch: [150][  100/  500]    Overall Loss 0.273165    Objective Loss 0.273165                                        LR 0.000125    Time 0.075058    
2024-02-19 17:46:54,885 - Epoch: [150][  200/  500]    Overall Loss 0.268597    Objective Loss 0.268597                                        LR 0.000125    Time 0.072102    
2024-02-19 17:47:01,809 - Epoch: [150][  300/  500]    Overall Loss 0.272199    Objective Loss 0.272199                                        LR 0.000125    Time 0.071134    
2024-02-19 17:47:08,736 - Epoch: [150][  400/  500]    Overall Loss 0.273386    Objective Loss 0.273386                                        LR 0.000125    Time 0.070660    
2024-02-19 17:47:15,680 - Epoch: [150][  500/  500]    Overall Loss 0.273813    Objective Loss 0.273813    Top1 90.500000    Top5 99.500000    LR 0.000125    Time 0.070408    
2024-02-19 17:47:15,800 - --- validate (epoch=150)-----------
2024-02-19 17:47:15,801 - 10000 samples (100 per mini-batch)
2024-02-19 17:47:18,787 - Epoch: [150][  100/  100]    Loss 1.883507    Top1 60.170000    Top5 85.790000    
2024-02-19 17:47:18,908 - ==> Top1: 60.170    Top5: 85.790    Loss: 1.884

2024-02-19 17:47:18,919 - ==> Best [Top1: 60.240   Top5: 85.950   Sparsity:0.00   Params: 753952 on epoch: 148]
2024-02-19 17:47:18,920 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:47:18,979 - 

2024-02-19 17:47:18,979 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:47:26,446 - Epoch: [151][  100/  500]    Overall Loss 0.265116    Objective Loss 0.265116                                        LR 0.000125    Time 0.074622    
2024-02-19 17:47:33,319 - Epoch: [151][  200/  500]    Overall Loss 0.262215    Objective Loss 0.262215                                        LR 0.000125    Time 0.071654    
2024-02-19 17:47:40,158 - Epoch: [151][  300/  500]    Overall Loss 0.262135    Objective Loss 0.262135                                        LR 0.000125    Time 0.070556    
2024-02-19 17:47:47,081 - Epoch: [151][  400/  500]    Overall Loss 0.263139    Objective Loss 0.263139                                        LR 0.000125    Time 0.070214    
2024-02-19 17:47:54,185 - Epoch: [151][  500/  500]    Overall Loss 0.265369    Objective Loss 0.265369    Top1 94.500000    Top5 100.000000    LR 0.000125    Time 0.070371    
2024-02-19 17:47:54,359 - --- validate (epoch=151)-----------
2024-02-19 17:47:54,360 - 10000 samples (100 per mini-batch)
2024-02-19 17:47:57,237 - Epoch: [151][  100/  100]    Loss 1.877078    Top1 60.580000    Top5 85.860000    
2024-02-19 17:47:57,349 - ==> Top1: 60.580    Top5: 85.860    Loss: 1.877

2024-02-19 17:47:57,361 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:47:57,361 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:47:57,435 - 

2024-02-19 17:47:57,436 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:48:04,866 - Epoch: [152][  100/  500]    Overall Loss 0.258555    Objective Loss 0.258555                                        LR 0.000125    Time 0.074254    
2024-02-19 17:48:11,762 - Epoch: [152][  200/  500]    Overall Loss 0.261813    Objective Loss 0.261813                                        LR 0.000125    Time 0.071587    
2024-02-19 17:48:18,621 - Epoch: [152][  300/  500]    Overall Loss 0.261460    Objective Loss 0.261460                                        LR 0.000125    Time 0.070576    
2024-02-19 17:48:25,446 - Epoch: [152][  400/  500]    Overall Loss 0.264246    Objective Loss 0.264246                                        LR 0.000125    Time 0.069986    
2024-02-19 17:48:32,327 - Epoch: [152][  500/  500]    Overall Loss 0.264172    Objective Loss 0.264172    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.069744    
2024-02-19 17:48:32,454 - --- validate (epoch=152)-----------
2024-02-19 17:48:32,454 - 10000 samples (100 per mini-batch)
2024-02-19 17:48:35,425 - Epoch: [152][  100/  100]    Loss 1.897309    Top1 60.000000    Top5 86.000000    
2024-02-19 17:48:35,525 - ==> Top1: 60.000    Top5: 86.000    Loss: 1.897

2024-02-19 17:48:35,536 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:48:35,536 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:48:35,594 - 

2024-02-19 17:48:35,594 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:48:42,965 - Epoch: [153][  100/  500]    Overall Loss 0.254941    Objective Loss 0.254941                                        LR 0.000125    Time 0.073657    
2024-02-19 17:48:49,974 - Epoch: [153][  200/  500]    Overall Loss 0.253205    Objective Loss 0.253205                                        LR 0.000125    Time 0.071853    
2024-02-19 17:48:56,879 - Epoch: [153][  300/  500]    Overall Loss 0.257455    Objective Loss 0.257455                                        LR 0.000125    Time 0.070906    
2024-02-19 17:49:03,780 - Epoch: [153][  400/  500]    Overall Loss 0.258693    Objective Loss 0.258693                                        LR 0.000125    Time 0.070423    
2024-02-19 17:49:10,612 - Epoch: [153][  500/  500]    Overall Loss 0.261254    Objective Loss 0.261254    Top1 95.500000    Top5 100.000000    LR 0.000125    Time 0.069995    
2024-02-19 17:49:10,737 - --- validate (epoch=153)-----------
2024-02-19 17:49:10,737 - 10000 samples (100 per mini-batch)
2024-02-19 17:49:13,699 - Epoch: [153][  100/  100]    Loss 1.893290    Top1 60.220000    Top5 85.750000    
2024-02-19 17:49:13,815 - ==> Top1: 60.220    Top5: 85.750    Loss: 1.893

2024-02-19 17:49:13,826 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:49:13,826 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:49:13,887 - 

2024-02-19 17:49:13,888 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:49:21,561 - Epoch: [154][  100/  500]    Overall Loss 0.248995    Objective Loss 0.248995                                        LR 0.000125    Time 0.076682    
2024-02-19 17:49:28,784 - Epoch: [154][  200/  500]    Overall Loss 0.251812    Objective Loss 0.251812                                        LR 0.000125    Time 0.074434    
2024-02-19 17:49:35,744 - Epoch: [154][  300/  500]    Overall Loss 0.256797    Objective Loss 0.256797                                        LR 0.000125    Time 0.072811    
2024-02-19 17:49:42,697 - Epoch: [154][  400/  500]    Overall Loss 0.259046    Objective Loss 0.259046                                        LR 0.000125    Time 0.071981    
2024-02-19 17:49:49,811 - Epoch: [154][  500/  500]    Overall Loss 0.261252    Objective Loss 0.261252    Top1 89.500000    Top5 100.000000    LR 0.000125    Time 0.071806    
2024-02-19 17:49:49,924 - --- validate (epoch=154)-----------
2024-02-19 17:49:49,925 - 10000 samples (100 per mini-batch)
2024-02-19 17:49:52,791 - Epoch: [154][  100/  100]    Loss 1.909400    Top1 59.950000    Top5 85.850000    
2024-02-19 17:49:52,958 - ==> Top1: 59.950    Top5: 85.850    Loss: 1.909

2024-02-19 17:49:52,969 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:49:52,969 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:49:53,031 - 

2024-02-19 17:49:53,031 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:50:00,471 - Epoch: [155][  100/  500]    Overall Loss 0.246360    Objective Loss 0.246360                                        LR 0.000125    Time 0.074352    
2024-02-19 17:50:07,526 - Epoch: [155][  200/  500]    Overall Loss 0.251740    Objective Loss 0.251740                                        LR 0.000125    Time 0.072426    
2024-02-19 17:50:14,518 - Epoch: [155][  300/  500]    Overall Loss 0.255473    Objective Loss 0.255473                                        LR 0.000125    Time 0.071579    
2024-02-19 17:50:21,510 - Epoch: [155][  400/  500]    Overall Loss 0.254105    Objective Loss 0.254105                                        LR 0.000125    Time 0.071155    
2024-02-19 17:50:28,573 - Epoch: [155][  500/  500]    Overall Loss 0.255617    Objective Loss 0.255617    Top1 95.500000    Top5 100.000000    LR 0.000125    Time 0.071043    
2024-02-19 17:50:28,687 - --- validate (epoch=155)-----------
2024-02-19 17:50:28,688 - 10000 samples (100 per mini-batch)
2024-02-19 17:50:31,649 - Epoch: [155][  100/  100]    Loss 1.907299    Top1 59.790000    Top5 85.910000    
2024-02-19 17:50:31,821 - ==> Top1: 59.790    Top5: 85.910    Loss: 1.907

2024-02-19 17:50:31,833 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:50:31,834 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:50:31,892 - 

2024-02-19 17:50:31,892 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:50:39,569 - Epoch: [156][  100/  500]    Overall Loss 0.252096    Objective Loss 0.252096                                        LR 0.000125    Time 0.076718    
2024-02-19 17:50:46,564 - Epoch: [156][  200/  500]    Overall Loss 0.250345    Objective Loss 0.250345                                        LR 0.000125    Time 0.073311    
2024-02-19 17:50:53,479 - Epoch: [156][  300/  500]    Overall Loss 0.254333    Objective Loss 0.254333                                        LR 0.000125    Time 0.071913    
2024-02-19 17:51:00,379 - Epoch: [156][  400/  500]    Overall Loss 0.256664    Objective Loss 0.256664                                        LR 0.000125    Time 0.071175    
2024-02-19 17:51:07,345 - Epoch: [156][  500/  500]    Overall Loss 0.256761    Objective Loss 0.256761    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.070865    
2024-02-19 17:51:07,491 - --- validate (epoch=156)-----------
2024-02-19 17:51:07,492 - 10000 samples (100 per mini-batch)
2024-02-19 17:51:10,400 - Epoch: [156][  100/  100]    Loss 1.902428    Top1 60.500000    Top5 85.740000    
2024-02-19 17:51:10,523 - ==> Top1: 60.500    Top5: 85.740    Loss: 1.902

2024-02-19 17:51:10,534 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:51:10,534 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:51:10,595 - 

2024-02-19 17:51:10,595 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:51:17,971 - Epoch: [157][  100/  500]    Overall Loss 0.245394    Objective Loss 0.245394                                        LR 0.000125    Time 0.073717    
2024-02-19 17:51:24,909 - Epoch: [157][  200/  500]    Overall Loss 0.251643    Objective Loss 0.251643                                        LR 0.000125    Time 0.071526    
2024-02-19 17:51:31,886 - Epoch: [157][  300/  500]    Overall Loss 0.251384    Objective Loss 0.251384                                        LR 0.000125    Time 0.070929    
2024-02-19 17:51:38,796 - Epoch: [157][  400/  500]    Overall Loss 0.255264    Objective Loss 0.255264                                        LR 0.000125    Time 0.070462    
2024-02-19 17:51:45,741 - Epoch: [157][  500/  500]    Overall Loss 0.256547    Objective Loss 0.256547    Top1 95.500000    Top5 99.500000    LR 0.000125    Time 0.070253    
2024-02-19 17:51:45,903 - --- validate (epoch=157)-----------
2024-02-19 17:51:45,904 - 10000 samples (100 per mini-batch)
2024-02-19 17:51:48,869 - Epoch: [157][  100/  100]    Loss 1.920516    Top1 59.920000    Top5 85.730000    
2024-02-19 17:51:48,992 - ==> Top1: 59.920    Top5: 85.730    Loss: 1.921

2024-02-19 17:51:49,003 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:51:49,004 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:51:49,065 - 

2024-02-19 17:51:49,066 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:51:56,715 - Epoch: [158][  100/  500]    Overall Loss 0.243929    Objective Loss 0.243929                                        LR 0.000125    Time 0.076420    
2024-02-19 17:52:03,687 - Epoch: [158][  200/  500]    Overall Loss 0.251566    Objective Loss 0.251566                                        LR 0.000125    Time 0.073055    
2024-02-19 17:52:10,630 - Epoch: [158][  300/  500]    Overall Loss 0.253808    Objective Loss 0.253808                                        LR 0.000125    Time 0.071832    
2024-02-19 17:52:17,558 - Epoch: [158][  400/  500]    Overall Loss 0.257415    Objective Loss 0.257415                                        LR 0.000125    Time 0.071185    
2024-02-19 17:52:24,537 - Epoch: [158][  500/  500]    Overall Loss 0.258460    Objective Loss 0.258460    Top1 89.500000    Top5 100.000000    LR 0.000125    Time 0.070897    
2024-02-19 17:52:24,647 - --- validate (epoch=158)-----------
2024-02-19 17:52:24,648 - 10000 samples (100 per mini-batch)
2024-02-19 17:52:27,622 - Epoch: [158][  100/  100]    Loss 1.905086    Top1 60.190000    Top5 85.770000    
2024-02-19 17:52:27,718 - ==> Top1: 60.190    Top5: 85.770    Loss: 1.905

2024-02-19 17:52:27,729 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:52:27,730 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:52:27,791 - 

2024-02-19 17:52:27,791 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:52:35,310 - Epoch: [159][  100/  500]    Overall Loss 0.240422    Objective Loss 0.240422                                        LR 0.000125    Time 0.075144    
2024-02-19 17:52:42,315 - Epoch: [159][  200/  500]    Overall Loss 0.247656    Objective Loss 0.247656                                        LR 0.000125    Time 0.072581    
2024-02-19 17:52:49,328 - Epoch: [159][  300/  500]    Overall Loss 0.253079    Objective Loss 0.253079                                        LR 0.000125    Time 0.071750    
2024-02-19 17:52:56,239 - Epoch: [159][  400/  500]    Overall Loss 0.255299    Objective Loss 0.255299                                        LR 0.000125    Time 0.071081    
2024-02-19 17:53:03,181 - Epoch: [159][  500/  500]    Overall Loss 0.253614    Objective Loss 0.253614    Top1 92.500000    Top5 99.500000    LR 0.000125    Time 0.070741    
2024-02-19 17:53:03,310 - --- validate (epoch=159)-----------
2024-02-19 17:53:03,310 - 10000 samples (100 per mini-batch)
2024-02-19 17:53:06,237 - Epoch: [159][  100/  100]    Loss 1.922087    Top1 59.890000    Top5 85.770000    
2024-02-19 17:53:06,337 - ==> Top1: 59.890    Top5: 85.770    Loss: 1.922

2024-02-19 17:53:06,342 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:53:06,343 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:53:06,400 - 

2024-02-19 17:53:06,400 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:53:13,942 - Epoch: [160][  100/  500]    Overall Loss 0.250435    Objective Loss 0.250435                                        LR 0.000125    Time 0.075372    
2024-02-19 17:53:20,941 - Epoch: [160][  200/  500]    Overall Loss 0.255699    Objective Loss 0.255699                                        LR 0.000125    Time 0.072657    
2024-02-19 17:53:27,915 - Epoch: [160][  300/  500]    Overall Loss 0.255090    Objective Loss 0.255090                                        LR 0.000125    Time 0.071672    
2024-02-19 17:53:34,872 - Epoch: [160][  400/  500]    Overall Loss 0.253042    Objective Loss 0.253042                                        LR 0.000125    Time 0.071136    
2024-02-19 17:53:41,832 - Epoch: [160][  500/  500]    Overall Loss 0.252557    Objective Loss 0.252557    Top1 94.500000    Top5 100.000000    LR 0.000125    Time 0.070820    
2024-02-19 17:53:41,946 - --- validate (epoch=160)-----------
2024-02-19 17:53:41,947 - 10000 samples (100 per mini-batch)
2024-02-19 17:53:45,069 - Epoch: [160][  100/  100]    Loss 1.924850    Top1 60.170000    Top5 85.660000    
2024-02-19 17:53:45,168 - ==> Top1: 60.170    Top5: 85.660    Loss: 1.925

2024-02-19 17:53:45,176 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:53:45,177 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:53:45,231 - 

2024-02-19 17:53:45,231 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:53:52,500 - Epoch: [161][  100/  500]    Overall Loss 0.242642    Objective Loss 0.242642                                        LR 0.000125    Time 0.072642    
2024-02-19 17:53:59,580 - Epoch: [161][  200/  500]    Overall Loss 0.249146    Objective Loss 0.249146                                        LR 0.000125    Time 0.071707    
2024-02-19 17:54:06,632 - Epoch: [161][  300/  500]    Overall Loss 0.249139    Objective Loss 0.249139                                        LR 0.000125    Time 0.071296    
2024-02-19 17:54:13,525 - Epoch: [161][  400/  500]    Overall Loss 0.250134    Objective Loss 0.250134                                        LR 0.000125    Time 0.070697    
2024-02-19 17:54:20,463 - Epoch: [161][  500/  500]    Overall Loss 0.251034    Objective Loss 0.251034    Top1 93.500000    Top5 100.000000    LR 0.000125    Time 0.070426    
2024-02-19 17:54:20,606 - --- validate (epoch=161)-----------
2024-02-19 17:54:20,607 - 10000 samples (100 per mini-batch)
2024-02-19 17:54:23,355 - Epoch: [161][  100/  100]    Loss 1.905843    Top1 60.080000    Top5 85.760000    
2024-02-19 17:54:23,511 - ==> Top1: 60.080    Top5: 85.760    Loss: 1.906

2024-02-19 17:54:23,522 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:54:23,523 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:54:23,583 - 

2024-02-19 17:54:23,583 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:54:31,254 - Epoch: [162][  100/  500]    Overall Loss 0.234019    Objective Loss 0.234019                                        LR 0.000125    Time 0.076661    
2024-02-19 17:54:38,182 - Epoch: [162][  200/  500]    Overall Loss 0.244368    Objective Loss 0.244368                                        LR 0.000125    Time 0.072950    
2024-02-19 17:54:45,116 - Epoch: [162][  300/  500]    Overall Loss 0.245240    Objective Loss 0.245240                                        LR 0.000125    Time 0.071736    
2024-02-19 17:54:52,104 - Epoch: [162][  400/  500]    Overall Loss 0.245359    Objective Loss 0.245359                                        LR 0.000125    Time 0.071260    
2024-02-19 17:54:59,103 - Epoch: [162][  500/  500]    Overall Loss 0.247341    Objective Loss 0.247341    Top1 91.000000    Top5 99.500000    LR 0.000125    Time 0.070998    
2024-02-19 17:54:59,278 - --- validate (epoch=162)-----------
2024-02-19 17:54:59,278 - 10000 samples (100 per mini-batch)
2024-02-19 17:55:02,184 - Epoch: [162][  100/  100]    Loss 1.919250    Top1 60.410000    Top5 85.600000    
2024-02-19 17:55:02,298 - ==> Top1: 60.410    Top5: 85.600    Loss: 1.919

2024-02-19 17:55:02,310 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:55:02,310 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:55:02,372 - 

2024-02-19 17:55:02,372 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:55:09,878 - Epoch: [163][  100/  500]    Overall Loss 0.238383    Objective Loss 0.238383                                        LR 0.000125    Time 0.075008    
2024-02-19 17:55:16,854 - Epoch: [163][  200/  500]    Overall Loss 0.246432    Objective Loss 0.246432                                        LR 0.000125    Time 0.072362    
2024-02-19 17:55:23,623 - Epoch: [163][  300/  500]    Overall Loss 0.249270    Objective Loss 0.249270                                        LR 0.000125    Time 0.070793    
2024-02-19 17:55:30,547 - Epoch: [163][  400/  500]    Overall Loss 0.248447    Objective Loss 0.248447                                        LR 0.000125    Time 0.070397    
2024-02-19 17:55:37,756 - Epoch: [163][  500/  500]    Overall Loss 0.248890    Objective Loss 0.248890    Top1 93.500000    Top5 99.500000    LR 0.000125    Time 0.070730    
2024-02-19 17:55:37,938 - --- validate (epoch=163)-----------
2024-02-19 17:55:37,939 - 10000 samples (100 per mini-batch)
2024-02-19 17:55:40,672 - Epoch: [163][  100/  100]    Loss 1.931699    Top1 59.970000    Top5 85.960000    
2024-02-19 17:55:40,771 - ==> Top1: 59.970    Top5: 85.960    Loss: 1.932

2024-02-19 17:55:40,783 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:55:40,783 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:55:40,843 - 

2024-02-19 17:55:40,844 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:55:48,381 - Epoch: [164][  100/  500]    Overall Loss 0.241553    Objective Loss 0.241553                                        LR 0.000125    Time 0.075322    
2024-02-19 17:55:55,266 - Epoch: [164][  200/  500]    Overall Loss 0.247464    Objective Loss 0.247464                                        LR 0.000125    Time 0.072070    
2024-02-19 17:56:02,297 - Epoch: [164][  300/  500]    Overall Loss 0.247544    Objective Loss 0.247544                                        LR 0.000125    Time 0.071469    
2024-02-19 17:56:09,220 - Epoch: [164][  400/  500]    Overall Loss 0.249057    Objective Loss 0.249057                                        LR 0.000125    Time 0.070899    
2024-02-19 17:56:16,229 - Epoch: [164][  500/  500]    Overall Loss 0.249866    Objective Loss 0.249866    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.070729    
2024-02-19 17:56:16,399 - --- validate (epoch=164)-----------
2024-02-19 17:56:16,400 - 10000 samples (100 per mini-batch)
2024-02-19 17:56:19,272 - Epoch: [164][  100/  100]    Loss 1.929833    Top1 59.980000    Top5 85.800000    
2024-02-19 17:56:19,357 - ==> Top1: 59.980    Top5: 85.800    Loss: 1.930

2024-02-19 17:56:19,375 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:56:19,375 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:56:19,427 - 

2024-02-19 17:56:19,427 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:56:26,660 - Epoch: [165][  100/  500]    Overall Loss 0.238838    Objective Loss 0.238838                                        LR 0.000125    Time 0.072282    
2024-02-19 17:56:33,600 - Epoch: [165][  200/  500]    Overall Loss 0.240462    Objective Loss 0.240462                                        LR 0.000125    Time 0.070821    
2024-02-19 17:56:40,543 - Epoch: [165][  300/  500]    Overall Loss 0.243240    Objective Loss 0.243240                                        LR 0.000125    Time 0.070345    
2024-02-19 17:56:47,458 - Epoch: [165][  400/  500]    Overall Loss 0.244188    Objective Loss 0.244188                                        LR 0.000125    Time 0.070038    
2024-02-19 17:56:54,402 - Epoch: [165][  500/  500]    Overall Loss 0.244595    Objective Loss 0.244595    Top1 92.500000    Top5 100.000000    LR 0.000125    Time 0.069910    
2024-02-19 17:56:54,511 - --- validate (epoch=165)-----------
2024-02-19 17:56:54,512 - 10000 samples (100 per mini-batch)
2024-02-19 17:56:57,213 - Epoch: [165][  100/  100]    Loss 1.920215    Top1 60.150000    Top5 85.790000    
2024-02-19 17:56:57,310 - ==> Top1: 60.150    Top5: 85.790    Loss: 1.920

2024-02-19 17:56:57,316 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:56:57,316 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:56:57,375 - 

2024-02-19 17:56:57,375 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:57:04,771 - Epoch: [166][  100/  500]    Overall Loss 0.245896    Objective Loss 0.245896                                        LR 0.000125    Time 0.073915    
2024-02-19 17:57:11,675 - Epoch: [166][  200/  500]    Overall Loss 0.247981    Objective Loss 0.247981                                        LR 0.000125    Time 0.071456    
2024-02-19 17:57:18,606 - Epoch: [166][  300/  500]    Overall Loss 0.246354    Objective Loss 0.246354                                        LR 0.000125    Time 0.070729    
2024-02-19 17:57:25,596 - Epoch: [166][  400/  500]    Overall Loss 0.246137    Objective Loss 0.246137                                        LR 0.000125    Time 0.070512    
2024-02-19 17:57:32,564 - Epoch: [166][  500/  500]    Overall Loss 0.246829    Objective Loss 0.246829    Top1 91.000000    Top5 100.000000    LR 0.000125    Time 0.070339    
2024-02-19 17:57:32,704 - --- validate (epoch=166)-----------
2024-02-19 17:57:32,705 - 10000 samples (100 per mini-batch)
2024-02-19 17:57:35,701 - Epoch: [166][  100/  100]    Loss 1.935571    Top1 59.970000    Top5 85.610000    
2024-02-19 17:57:35,852 - ==> Top1: 59.970    Top5: 85.610    Loss: 1.936

2024-02-19 17:57:35,863 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:57:35,863 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:57:35,923 - 

2024-02-19 17:57:35,923 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:57:43,355 - Epoch: [167][  100/  500]    Overall Loss 0.236638    Objective Loss 0.236638                                        LR 0.000125    Time 0.074268    
2024-02-19 17:57:50,222 - Epoch: [167][  200/  500]    Overall Loss 0.237886    Objective Loss 0.237886                                        LR 0.000125    Time 0.071452    
2024-02-19 17:57:57,068 - Epoch: [167][  300/  500]    Overall Loss 0.240551    Objective Loss 0.240551                                        LR 0.000125    Time 0.070443    
2024-02-19 17:58:04,080 - Epoch: [167][  400/  500]    Overall Loss 0.241208    Objective Loss 0.241208                                        LR 0.000125    Time 0.070353    
2024-02-19 17:58:11,012 - Epoch: [167][  500/  500]    Overall Loss 0.244225    Objective Loss 0.244225    Top1 88.500000    Top5 100.000000    LR 0.000125    Time 0.070138    
2024-02-19 17:58:11,167 - --- validate (epoch=167)-----------
2024-02-19 17:58:11,168 - 10000 samples (100 per mini-batch)
2024-02-19 17:58:13,955 - Epoch: [167][  100/  100]    Loss 1.930874    Top1 60.170000    Top5 85.860000    
2024-02-19 17:58:14,050 - ==> Top1: 60.170    Top5: 85.860    Loss: 1.931

2024-02-19 17:58:14,056 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:58:14,056 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:58:14,112 - 

2024-02-19 17:58:14,112 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:58:21,731 - Epoch: [168][  100/  500]    Overall Loss 0.232428    Objective Loss 0.232428                                        LR 0.000125    Time 0.076146    
2024-02-19 17:58:28,656 - Epoch: [168][  200/  500]    Overall Loss 0.237562    Objective Loss 0.237562                                        LR 0.000125    Time 0.072679    
2024-02-19 17:58:35,557 - Epoch: [168][  300/  500]    Overall Loss 0.240998    Objective Loss 0.240998                                        LR 0.000125    Time 0.071442    
2024-02-19 17:58:42,509 - Epoch: [168][  400/  500]    Overall Loss 0.243139    Objective Loss 0.243139                                        LR 0.000125    Time 0.070954    
2024-02-19 17:58:49,479 - Epoch: [168][  500/  500]    Overall Loss 0.242613    Objective Loss 0.242613    Top1 94.000000    Top5 99.500000    LR 0.000125    Time 0.070694    
2024-02-19 17:58:49,612 - --- validate (epoch=168)-----------
2024-02-19 17:58:49,613 - 10000 samples (100 per mini-batch)
2024-02-19 17:58:52,403 - Epoch: [168][  100/  100]    Loss 1.940044    Top1 60.110000    Top5 85.750000    
2024-02-19 17:58:52,502 - ==> Top1: 60.110    Top5: 85.750    Loss: 1.940

2024-02-19 17:58:52,512 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:58:52,513 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:58:52,572 - 

2024-02-19 17:58:52,572 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:58:59,952 - Epoch: [169][  100/  500]    Overall Loss 0.233130    Objective Loss 0.233130                                        LR 0.000125    Time 0.073752    
2024-02-19 17:59:06,882 - Epoch: [169][  200/  500]    Overall Loss 0.239286    Objective Loss 0.239286                                        LR 0.000125    Time 0.071506    
2024-02-19 17:59:13,818 - Epoch: [169][  300/  500]    Overall Loss 0.239623    Objective Loss 0.239623                                        LR 0.000125    Time 0.070778    
2024-02-19 17:59:20,857 - Epoch: [169][  400/  500]    Overall Loss 0.240834    Objective Loss 0.240834                                        LR 0.000125    Time 0.070671    
2024-02-19 17:59:27,965 - Epoch: [169][  500/  500]    Overall Loss 0.241750    Objective Loss 0.241750    Top1 90.500000    Top5 100.000000    LR 0.000125    Time 0.070747    
2024-02-19 17:59:28,101 - --- validate (epoch=169)-----------
2024-02-19 17:59:28,102 - 10000 samples (100 per mini-batch)
2024-02-19 17:59:31,030 - Epoch: [169][  100/  100]    Loss 1.938254    Top1 60.110000    Top5 85.580000    
2024-02-19 17:59:31,145 - ==> Top1: 60.110    Top5: 85.580    Loss: 1.938

2024-02-19 17:59:31,157 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 17:59:31,157 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 17:59:31,216 - 

2024-02-19 17:59:31,216 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 17:59:38,997 - Epoch: [170][  100/  500]    Overall Loss 0.229916    Objective Loss 0.229916                                        LR 0.000125    Time 0.077750    
2024-02-19 17:59:46,098 - Epoch: [170][  200/  500]    Overall Loss 0.236218    Objective Loss 0.236218                                        LR 0.000125    Time 0.074360    
2024-02-19 17:59:53,069 - Epoch: [170][  300/  500]    Overall Loss 0.237610    Objective Loss 0.237610                                        LR 0.000125    Time 0.072800    
2024-02-19 18:00:00,107 - Epoch: [170][  400/  500]    Overall Loss 0.239643    Objective Loss 0.239643                                        LR 0.000125    Time 0.072185    
2024-02-19 18:00:07,133 - Epoch: [170][  500/  500]    Overall Loss 0.242543    Objective Loss 0.242543    Top1 94.000000    Top5 100.000000    LR 0.000125    Time 0.071793    
2024-02-19 18:00:07,270 - --- validate (epoch=170)-----------
2024-02-19 18:00:07,271 - 10000 samples (100 per mini-batch)
2024-02-19 18:00:10,129 - Epoch: [170][  100/  100]    Loss 1.934659    Top1 60.060000    Top5 85.940000    
2024-02-19 18:00:10,228 - ==> Top1: 60.060    Top5: 85.940    Loss: 1.935

2024-02-19 18:00:10,239 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:00:10,239 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:00:10,299 - 

2024-02-19 18:00:10,300 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:00:17,516 - Epoch: [171][  100/  500]    Overall Loss 0.222846    Objective Loss 0.222846                                        LR 0.000125    Time 0.072119    
2024-02-19 18:00:24,190 - Epoch: [171][  200/  500]    Overall Loss 0.231142    Objective Loss 0.231142                                        LR 0.000125    Time 0.069411    
2024-02-19 18:00:30,867 - Epoch: [171][  300/  500]    Overall Loss 0.233896    Objective Loss 0.233896                                        LR 0.000125    Time 0.068521    
2024-02-19 18:00:37,724 - Epoch: [171][  400/  500]    Overall Loss 0.235802    Objective Loss 0.235802                                        LR 0.000125    Time 0.068525    
2024-02-19 18:00:44,438 - Epoch: [171][  500/  500]    Overall Loss 0.236756    Objective Loss 0.236756    Top1 92.000000    Top5 99.500000    LR 0.000125    Time 0.068240    
2024-02-19 18:00:44,559 - --- validate (epoch=171)-----------
2024-02-19 18:00:44,560 - 10000 samples (100 per mini-batch)
2024-02-19 18:00:47,396 - Epoch: [171][  100/  100]    Loss 1.950507    Top1 59.930000    Top5 85.490000    
2024-02-19 18:00:47,504 - ==> Top1: 59.930    Top5: 85.490    Loss: 1.951

2024-02-19 18:00:47,515 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:00:47,516 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:00:47,575 - 

2024-02-19 18:00:47,576 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:00:54,928 - Epoch: [172][  100/  500]    Overall Loss 0.233213    Objective Loss 0.233213                                        LR 0.000125    Time 0.073473    
2024-02-19 18:01:01,825 - Epoch: [172][  200/  500]    Overall Loss 0.233640    Objective Loss 0.233640                                        LR 0.000125    Time 0.071205    
2024-02-19 18:01:08,754 - Epoch: [172][  300/  500]    Overall Loss 0.234297    Objective Loss 0.234297                                        LR 0.000125    Time 0.070551    
2024-02-19 18:01:15,642 - Epoch: [172][  400/  500]    Overall Loss 0.237797    Objective Loss 0.237797                                        LR 0.000125    Time 0.070125    
2024-02-19 18:01:22,542 - Epoch: [172][  500/  500]    Overall Loss 0.237228    Objective Loss 0.237228    Top1 94.500000    Top5 100.000000    LR 0.000125    Time 0.069893    
2024-02-19 18:01:22,680 - --- validate (epoch=172)-----------
2024-02-19 18:01:22,681 - 10000 samples (100 per mini-batch)
2024-02-19 18:01:25,564 - Epoch: [172][  100/  100]    Loss 1.936042    Top1 59.900000    Top5 85.730000    
2024-02-19 18:01:25,685 - ==> Top1: 59.900    Top5: 85.730    Loss: 1.936

2024-02-19 18:01:25,698 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:01:25,698 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:01:25,952 - 

2024-02-19 18:01:25,952 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:01:33,421 - Epoch: [173][  100/  500]    Overall Loss 0.222833    Objective Loss 0.222833                                        LR 0.000125    Time 0.074639    
2024-02-19 18:01:40,364 - Epoch: [173][  200/  500]    Overall Loss 0.226368    Objective Loss 0.226368                                        LR 0.000125    Time 0.072011    
2024-02-19 18:01:47,342 - Epoch: [173][  300/  500]    Overall Loss 0.233803    Objective Loss 0.233803                                        LR 0.000125    Time 0.071257    
2024-02-19 18:01:54,015 - Epoch: [173][  400/  500]    Overall Loss 0.236299    Objective Loss 0.236299                                        LR 0.000125    Time 0.070116    
2024-02-19 18:02:00,789 - Epoch: [173][  500/  500]    Overall Loss 0.237052    Objective Loss 0.237052    Top1 94.000000    Top5 100.000000    LR 0.000125    Time 0.069634    
2024-02-19 18:02:00,974 - --- validate (epoch=173)-----------
2024-02-19 18:02:00,975 - 10000 samples (100 per mini-batch)
2024-02-19 18:02:03,920 - Epoch: [173][  100/  100]    Loss 1.957766    Top1 59.780000    Top5 85.580000    
2024-02-19 18:02:04,086 - ==> Top1: 59.780    Top5: 85.580    Loss: 1.958

2024-02-19 18:02:04,096 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:02:04,097 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:02:04,157 - 

2024-02-19 18:02:04,157 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:02:11,518 - Epoch: [174][  100/  500]    Overall Loss 0.225888    Objective Loss 0.225888                                        LR 0.000125    Time 0.073558    
2024-02-19 18:02:18,378 - Epoch: [174][  200/  500]    Overall Loss 0.232191    Objective Loss 0.232191                                        LR 0.000125    Time 0.071057    
2024-02-19 18:02:25,222 - Epoch: [174][  300/  500]    Overall Loss 0.234775    Objective Loss 0.234775                                        LR 0.000125    Time 0.070174    
2024-02-19 18:02:32,138 - Epoch: [174][  400/  500]    Overall Loss 0.236206    Objective Loss 0.236206                                        LR 0.000125    Time 0.069910    
2024-02-19 18:02:39,070 - Epoch: [174][  500/  500]    Overall Loss 0.237734    Objective Loss 0.237734    Top1 92.500000    Top5 99.500000    LR 0.000125    Time 0.069785    
2024-02-19 18:02:39,272 - --- validate (epoch=174)-----------
2024-02-19 18:02:39,273 - 10000 samples (100 per mini-batch)
2024-02-19 18:02:42,393 - Epoch: [174][  100/  100]    Loss 1.943706    Top1 59.710000    Top5 85.770000    
2024-02-19 18:02:42,497 - ==> Top1: 59.710    Top5: 85.770    Loss: 1.944

2024-02-19 18:02:42,507 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:02:42,508 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:02:42,569 - 

2024-02-19 18:02:42,569 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:02:49,985 - Epoch: [175][  100/  500]    Overall Loss 0.225993    Objective Loss 0.225993                                        LR 0.000125    Time 0.074104    
2024-02-19 18:02:57,014 - Epoch: [175][  200/  500]    Overall Loss 0.233519    Objective Loss 0.233519                                        LR 0.000125    Time 0.072177    
2024-02-19 18:03:03,992 - Epoch: [175][  300/  500]    Overall Loss 0.234766    Objective Loss 0.234766                                        LR 0.000125    Time 0.071365    
2024-02-19 18:03:10,996 - Epoch: [175][  400/  500]    Overall Loss 0.235085    Objective Loss 0.235085                                        LR 0.000125    Time 0.071024    
2024-02-19 18:03:17,943 - Epoch: [175][  500/  500]    Overall Loss 0.236514    Objective Loss 0.236514    Top1 94.000000    Top5 100.000000    LR 0.000125    Time 0.070706    
2024-02-19 18:03:18,079 - --- validate (epoch=175)-----------
2024-02-19 18:03:18,080 - 10000 samples (100 per mini-batch)
2024-02-19 18:03:21,177 - Epoch: [175][  100/  100]    Loss 1.950114    Top1 59.730000    Top5 85.760000    
2024-02-19 18:03:21,292 - ==> Top1: 59.730    Top5: 85.760    Loss: 1.950

2024-02-19 18:03:21,303 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:03:21,304 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:03:21,363 - 

2024-02-19 18:03:21,364 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:03:29,097 - Epoch: [176][  100/  500]    Overall Loss 0.237072    Objective Loss 0.237072                                        LR 0.000125    Time 0.077276    
2024-02-19 18:03:36,136 - Epoch: [176][  200/  500]    Overall Loss 0.234331    Objective Loss 0.234331                                        LR 0.000125    Time 0.073812    
2024-02-19 18:03:43,047 - Epoch: [176][  300/  500]    Overall Loss 0.234554    Objective Loss 0.234554                                        LR 0.000125    Time 0.072233    
2024-02-19 18:03:50,001 - Epoch: [176][  400/  500]    Overall Loss 0.234573    Objective Loss 0.234573                                        LR 0.000125    Time 0.071549    
2024-02-19 18:03:56,917 - Epoch: [176][  500/  500]    Overall Loss 0.234733    Objective Loss 0.234733    Top1 96.500000    Top5 100.000000    LR 0.000125    Time 0.071065    
2024-02-19 18:03:57,055 - --- validate (epoch=176)-----------
2024-02-19 18:03:57,055 - 10000 samples (100 per mini-batch)
2024-02-19 18:04:00,074 - Epoch: [176][  100/  100]    Loss 1.951452    Top1 59.990000    Top5 85.820000    
2024-02-19 18:04:00,171 - ==> Top1: 59.990    Top5: 85.820    Loss: 1.951

2024-02-19 18:04:00,183 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:04:00,183 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:04:00,244 - 

2024-02-19 18:04:00,245 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:04:07,572 - Epoch: [177][  100/  500]    Overall Loss 0.229778    Objective Loss 0.229778                                        LR 0.000125    Time 0.073221    
2024-02-19 18:04:14,471 - Epoch: [177][  200/  500]    Overall Loss 0.233496    Objective Loss 0.233496                                        LR 0.000125    Time 0.071087    
2024-02-19 18:04:21,395 - Epoch: [177][  300/  500]    Overall Loss 0.234882    Objective Loss 0.234882                                        LR 0.000125    Time 0.070460    
2024-02-19 18:04:28,377 - Epoch: [177][  400/  500]    Overall Loss 0.234475    Objective Loss 0.234475                                        LR 0.000125    Time 0.070292    
2024-02-19 18:04:35,409 - Epoch: [177][  500/  500]    Overall Loss 0.233947    Objective Loss 0.233947    Top1 97.000000    Top5 100.000000    LR 0.000125    Time 0.070290    
2024-02-19 18:04:35,590 - --- validate (epoch=177)-----------
2024-02-19 18:04:35,591 - 10000 samples (100 per mini-batch)
2024-02-19 18:04:38,486 - Epoch: [177][  100/  100]    Loss 1.948968    Top1 59.860000    Top5 85.470000    
2024-02-19 18:04:38,644 - ==> Top1: 59.860    Top5: 85.470    Loss: 1.949

2024-02-19 18:04:38,658 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:04:38,658 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:04:38,716 - 

2024-02-19 18:04:38,716 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:04:46,422 - Epoch: [178][  100/  500]    Overall Loss 0.229757    Objective Loss 0.229757                                        LR 0.000125    Time 0.077007    
2024-02-19 18:04:53,359 - Epoch: [178][  200/  500]    Overall Loss 0.227889    Objective Loss 0.227889                                        LR 0.000125    Time 0.073171    
2024-02-19 18:05:00,309 - Epoch: [178][  300/  500]    Overall Loss 0.233380    Objective Loss 0.233380                                        LR 0.000125    Time 0.071935    
2024-02-19 18:05:07,290 - Epoch: [178][  400/  500]    Overall Loss 0.233113    Objective Loss 0.233113                                        LR 0.000125    Time 0.071393    
2024-02-19 18:05:14,207 - Epoch: [178][  500/  500]    Overall Loss 0.232737    Objective Loss 0.232737    Top1 91.000000    Top5 100.000000    LR 0.000125    Time 0.070941    
2024-02-19 18:05:14,349 - --- validate (epoch=178)-----------
2024-02-19 18:05:14,350 - 10000 samples (100 per mini-batch)
2024-02-19 18:05:17,219 - Epoch: [178][  100/  100]    Loss 1.957101    Top1 60.500000    Top5 85.740000    
2024-02-19 18:05:17,325 - ==> Top1: 60.500    Top5: 85.740    Loss: 1.957

2024-02-19 18:05:17,337 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:05:17,337 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:05:17,398 - 

2024-02-19 18:05:17,399 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:05:24,775 - Epoch: [179][  100/  500]    Overall Loss 0.225508    Objective Loss 0.225508                                        LR 0.000125    Time 0.073714    
2024-02-19 18:05:31,625 - Epoch: [179][  200/  500]    Overall Loss 0.226666    Objective Loss 0.226666                                        LR 0.000125    Time 0.071091    
2024-02-19 18:05:38,505 - Epoch: [179][  300/  500]    Overall Loss 0.228379    Objective Loss 0.228379                                        LR 0.000125    Time 0.070315    
2024-02-19 18:05:45,406 - Epoch: [179][  400/  500]    Overall Loss 0.229011    Objective Loss 0.229011                                        LR 0.000125    Time 0.069977    
2024-02-19 18:05:52,356 - Epoch: [179][  500/  500]    Overall Loss 0.229008    Objective Loss 0.229008    Top1 94.000000    Top5 100.000000    LR 0.000125    Time 0.069876    
2024-02-19 18:05:52,462 - --- validate (epoch=179)-----------
2024-02-19 18:05:52,463 - 10000 samples (100 per mini-batch)
2024-02-19 18:05:55,168 - Epoch: [179][  100/  100]    Loss 1.946505    Top1 60.290000    Top5 85.820000    
2024-02-19 18:05:55,279 - ==> Top1: 60.290    Top5: 85.820    Loss: 1.947

2024-02-19 18:05:55,290 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:05:55,290 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:05:55,350 - 

2024-02-19 18:05:55,351 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:06:03,069 - Epoch: [180][  100/  500]    Overall Loss 0.226473    Objective Loss 0.226473                                        LR 0.000125    Time 0.077135    
2024-02-19 18:06:09,968 - Epoch: [180][  200/  500]    Overall Loss 0.226837    Objective Loss 0.226837                                        LR 0.000125    Time 0.073044    
2024-02-19 18:06:16,890 - Epoch: [180][  300/  500]    Overall Loss 0.230913    Objective Loss 0.230913                                        LR 0.000125    Time 0.071756    
2024-02-19 18:06:23,801 - Epoch: [180][  400/  500]    Overall Loss 0.231669    Objective Loss 0.231669                                        LR 0.000125    Time 0.071084    
2024-02-19 18:06:30,831 - Epoch: [180][  500/  500]    Overall Loss 0.230858    Objective Loss 0.230858    Top1 91.000000    Top5 100.000000    LR 0.000125    Time 0.070921    
2024-02-19 18:06:30,986 - --- validate (epoch=180)-----------
2024-02-19 18:06:30,987 - 10000 samples (100 per mini-batch)
2024-02-19 18:06:33,791 - Epoch: [180][  100/  100]    Loss 1.952863    Top1 60.010000    Top5 85.820000    
2024-02-19 18:06:33,903 - ==> Top1: 60.010    Top5: 85.820    Loss: 1.953

2024-02-19 18:06:33,914 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:06:33,914 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:06:33,974 - 

2024-02-19 18:06:33,975 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:06:41,704 - Epoch: [181][  100/  500]    Overall Loss 0.221967    Objective Loss 0.221967                                        LR 0.000125    Time 0.077245    
2024-02-19 18:06:49,000 - Epoch: [181][  200/  500]    Overall Loss 0.225882    Objective Loss 0.225882                                        LR 0.000125    Time 0.075084    
2024-02-19 18:06:56,107 - Epoch: [181][  300/  500]    Overall Loss 0.229935    Objective Loss 0.229935                                        LR 0.000125    Time 0.073733    
2024-02-19 18:07:03,154 - Epoch: [181][  400/  500]    Overall Loss 0.229989    Objective Loss 0.229989                                        LR 0.000125    Time 0.072907    
2024-02-19 18:07:10,234 - Epoch: [181][  500/  500]    Overall Loss 0.229479    Objective Loss 0.229479    Top1 94.500000    Top5 100.000000    LR 0.000125    Time 0.072479    
2024-02-19 18:07:10,361 - --- validate (epoch=181)-----------
2024-02-19 18:07:10,362 - 10000 samples (100 per mini-batch)
2024-02-19 18:07:13,152 - Epoch: [181][  100/  100]    Loss 1.967669    Top1 59.920000    Top5 85.520000    
2024-02-19 18:07:13,317 - ==> Top1: 59.920    Top5: 85.520    Loss: 1.968

2024-02-19 18:07:13,328 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:07:13,328 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:07:13,386 - 

2024-02-19 18:07:13,387 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:07:21,039 - Epoch: [182][  100/  500]    Overall Loss 0.228324    Objective Loss 0.228324                                        LR 0.000125    Time 0.076477    
2024-02-19 18:07:27,938 - Epoch: [182][  200/  500]    Overall Loss 0.222645    Objective Loss 0.222645                                        LR 0.000125    Time 0.072717    
2024-02-19 18:07:34,842 - Epoch: [182][  300/  500]    Overall Loss 0.223732    Objective Loss 0.223732                                        LR 0.000125    Time 0.071478    
2024-02-19 18:07:41,764 - Epoch: [182][  400/  500]    Overall Loss 0.227632    Objective Loss 0.227632                                        LR 0.000125    Time 0.070904    
2024-02-19 18:07:48,708 - Epoch: [182][  500/  500]    Overall Loss 0.229066    Objective Loss 0.229066    Top1 92.500000    Top5 99.500000    LR 0.000125    Time 0.070605    
2024-02-19 18:07:48,818 - --- validate (epoch=182)-----------
2024-02-19 18:07:48,819 - 10000 samples (100 per mini-batch)
2024-02-19 18:07:51,566 - Epoch: [182][  100/  100]    Loss 1.974157    Top1 59.970000    Top5 85.750000    
2024-02-19 18:07:51,694 - ==> Top1: 59.970    Top5: 85.750    Loss: 1.974

2024-02-19 18:07:51,707 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:07:51,708 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:07:51,766 - 

2024-02-19 18:07:51,766 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:07:59,179 - Epoch: [183][  100/  500]    Overall Loss 0.215227    Objective Loss 0.215227                                        LR 0.000125    Time 0.074071    
2024-02-19 18:08:06,143 - Epoch: [183][  200/  500]    Overall Loss 0.222679    Objective Loss 0.222679                                        LR 0.000125    Time 0.071837    
2024-02-19 18:08:13,089 - Epoch: [183][  300/  500]    Overall Loss 0.226788    Objective Loss 0.226788                                        LR 0.000125    Time 0.071032    
2024-02-19 18:08:20,030 - Epoch: [183][  400/  500]    Overall Loss 0.227187    Objective Loss 0.227187                                        LR 0.000125    Time 0.070616    
2024-02-19 18:08:27,051 - Epoch: [183][  500/  500]    Overall Loss 0.227088    Objective Loss 0.227088    Top1 94.000000    Top5 99.000000    LR 0.000125    Time 0.070528    
2024-02-19 18:08:27,155 - --- validate (epoch=183)-----------
2024-02-19 18:08:27,156 - 10000 samples (100 per mini-batch)
2024-02-19 18:08:29,985 - Epoch: [183][  100/  100]    Loss 1.957040    Top1 59.830000    Top5 85.790000    
2024-02-19 18:08:30,117 - ==> Top1: 59.830    Top5: 85.790    Loss: 1.957

2024-02-19 18:08:30,127 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:08:30,128 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:08:30,188 - 

2024-02-19 18:08:30,188 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:08:37,807 - Epoch: [184][  100/  500]    Overall Loss 0.219644    Objective Loss 0.219644                                        LR 0.000125    Time 0.076147    
2024-02-19 18:08:44,696 - Epoch: [184][  200/  500]    Overall Loss 0.224112    Objective Loss 0.224112                                        LR 0.000125    Time 0.072498    
2024-02-19 18:08:51,582 - Epoch: [184][  300/  500]    Overall Loss 0.224402    Objective Loss 0.224402                                        LR 0.000125    Time 0.071275    
2024-02-19 18:08:58,533 - Epoch: [184][  400/  500]    Overall Loss 0.227515    Objective Loss 0.227515                                        LR 0.000125    Time 0.070823    
2024-02-19 18:09:05,699 - Epoch: [184][  500/  500]    Overall Loss 0.229596    Objective Loss 0.229596    Top1 93.500000    Top5 99.500000    LR 0.000125    Time 0.070983    
2024-02-19 18:09:05,818 - --- validate (epoch=184)-----------
2024-02-19 18:09:05,819 - 10000 samples (100 per mini-batch)
2024-02-19 18:09:08,877 - Epoch: [184][  100/  100]    Loss 1.966017    Top1 60.000000    Top5 85.630000    
2024-02-19 18:09:09,043 - ==> Top1: 60.000    Top5: 85.630    Loss: 1.966

2024-02-19 18:09:09,056 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:09:09,056 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:09:09,116 - 

2024-02-19 18:09:09,116 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:09:16,511 - Epoch: [185][  100/  500]    Overall Loss 0.227796    Objective Loss 0.227796                                        LR 0.000125    Time 0.073903    
2024-02-19 18:09:23,479 - Epoch: [185][  200/  500]    Overall Loss 0.223938    Objective Loss 0.223938                                        LR 0.000125    Time 0.071772    
2024-02-19 18:09:30,402 - Epoch: [185][  300/  500]    Overall Loss 0.226002    Objective Loss 0.226002                                        LR 0.000125    Time 0.070912    
2024-02-19 18:09:37,354 - Epoch: [185][  400/  500]    Overall Loss 0.225594    Objective Loss 0.225594                                        LR 0.000125    Time 0.070555    
2024-02-19 18:09:44,378 - Epoch: [185][  500/  500]    Overall Loss 0.225943    Objective Loss 0.225943    Top1 93.500000    Top5 100.000000    LR 0.000125    Time 0.070485    
2024-02-19 18:09:44,485 - --- validate (epoch=185)-----------
2024-02-19 18:09:44,485 - 10000 samples (100 per mini-batch)
2024-02-19 18:09:47,493 - Epoch: [185][  100/  100]    Loss 1.967303    Top1 59.800000    Top5 85.760000    
2024-02-19 18:09:47,591 - ==> Top1: 59.800    Top5: 85.760    Loss: 1.967

2024-02-19 18:09:47,603 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:09:47,603 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:09:47,664 - 

2024-02-19 18:09:47,664 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:09:55,129 - Epoch: [186][  100/  500]    Overall Loss 0.210687    Objective Loss 0.210687                                        LR 0.000125    Time 0.074595    
2024-02-19 18:10:02,124 - Epoch: [186][  200/  500]    Overall Loss 0.218706    Objective Loss 0.218706                                        LR 0.000125    Time 0.072253    
2024-02-19 18:10:09,137 - Epoch: [186][  300/  500]    Overall Loss 0.220617    Objective Loss 0.220617                                        LR 0.000125    Time 0.071532    
2024-02-19 18:10:16,147 - Epoch: [186][  400/  500]    Overall Loss 0.221219    Objective Loss 0.221219                                        LR 0.000125    Time 0.071164    
2024-02-19 18:10:23,180 - Epoch: [186][  500/  500]    Overall Loss 0.224767    Objective Loss 0.224767    Top1 93.000000    Top5 99.500000    LR 0.000125    Time 0.070988    
2024-02-19 18:10:23,378 - --- validate (epoch=186)-----------
2024-02-19 18:10:23,379 - 10000 samples (100 per mini-batch)
2024-02-19 18:10:26,696 - Epoch: [186][  100/  100]    Loss 1.972442    Top1 59.790000    Top5 85.870000    
2024-02-19 18:10:26,795 - ==> Top1: 59.790    Top5: 85.870    Loss: 1.972

2024-02-19 18:10:26,806 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:10:26,806 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:10:26,865 - 

2024-02-19 18:10:26,865 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:10:34,321 - Epoch: [187][  100/  500]    Overall Loss 0.222190    Objective Loss 0.222190                                        LR 0.000125    Time 0.074502    
2024-02-19 18:10:41,387 - Epoch: [187][  200/  500]    Overall Loss 0.221114    Objective Loss 0.221114                                        LR 0.000125    Time 0.072562    
2024-02-19 18:10:48,346 - Epoch: [187][  300/  500]    Overall Loss 0.221460    Objective Loss 0.221460                                        LR 0.000125    Time 0.071557    
2024-02-19 18:10:55,299 - Epoch: [187][  400/  500]    Overall Loss 0.224399    Objective Loss 0.224399                                        LR 0.000125    Time 0.071043    
2024-02-19 18:11:02,293 - Epoch: [187][  500/  500]    Overall Loss 0.226769    Objective Loss 0.226769    Top1 93.000000    Top5 100.000000    LR 0.000125    Time 0.070815    
2024-02-19 18:11:02,467 - --- validate (epoch=187)-----------
2024-02-19 18:11:02,467 - 10000 samples (100 per mini-batch)
2024-02-19 18:11:05,524 - Epoch: [187][  100/  100]    Loss 1.984545    Top1 59.840000    Top5 85.680000    
2024-02-19 18:11:05,635 - ==> Top1: 59.840    Top5: 85.680    Loss: 1.985

2024-02-19 18:11:05,643 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:11:05,643 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:11:05,701 - 

2024-02-19 18:11:05,701 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:11:13,620 - Epoch: [188][  100/  500]    Overall Loss 0.213649    Objective Loss 0.213649                                        LR 0.000125    Time 0.079142    
2024-02-19 18:11:20,909 - Epoch: [188][  200/  500]    Overall Loss 0.218540    Objective Loss 0.218540                                        LR 0.000125    Time 0.075994    
2024-02-19 18:11:27,949 - Epoch: [188][  300/  500]    Overall Loss 0.218849    Objective Loss 0.218849                                        LR 0.000125    Time 0.074115    
2024-02-19 18:11:34,938 - Epoch: [188][  400/  500]    Overall Loss 0.223136    Objective Loss 0.223136                                        LR 0.000125    Time 0.073049    
2024-02-19 18:11:41,980 - Epoch: [188][  500/  500]    Overall Loss 0.225520    Objective Loss 0.225520    Top1 90.000000    Top5 100.000000    LR 0.000125    Time 0.072516    
2024-02-19 18:11:42,112 - --- validate (epoch=188)-----------
2024-02-19 18:11:42,113 - 10000 samples (100 per mini-batch)
2024-02-19 18:11:45,082 - Epoch: [188][  100/  100]    Loss 1.987643    Top1 59.360000    Top5 85.380000    
2024-02-19 18:11:45,242 - ==> Top1: 59.360    Top5: 85.380    Loss: 1.988

2024-02-19 18:11:45,250 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:11:45,251 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:11:45,309 - 

2024-02-19 18:11:45,309 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:11:52,778 - Epoch: [189][  100/  500]    Overall Loss 0.225949    Objective Loss 0.225949                                        LR 0.000125    Time 0.074632    
2024-02-19 18:11:59,730 - Epoch: [189][  200/  500]    Overall Loss 0.222795    Objective Loss 0.222795                                        LR 0.000125    Time 0.072058    
2024-02-19 18:12:06,655 - Epoch: [189][  300/  500]    Overall Loss 0.224683    Objective Loss 0.224683                                        LR 0.000125    Time 0.071109    
2024-02-19 18:12:13,566 - Epoch: [189][  400/  500]    Overall Loss 0.223539    Objective Loss 0.223539                                        LR 0.000125    Time 0.070602    
2024-02-19 18:12:20,514 - Epoch: [189][  500/  500]    Overall Loss 0.226418    Objective Loss 0.226418    Top1 93.000000    Top5 98.500000    LR 0.000125    Time 0.070368    
2024-02-19 18:12:20,682 - --- validate (epoch=189)-----------
2024-02-19 18:12:20,683 - 10000 samples (100 per mini-batch)
2024-02-19 18:12:23,577 - Epoch: [189][  100/  100]    Loss 1.986064    Top1 60.010000    Top5 85.360000    
2024-02-19 18:12:23,690 - ==> Top1: 60.010    Top5: 85.360    Loss: 1.986

2024-02-19 18:12:23,702 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:12:23,702 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:12:23,768 - 

2024-02-19 18:12:23,768 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:12:31,560 - Epoch: [190][  100/  500]    Overall Loss 0.211893    Objective Loss 0.211893                                        LR 0.000125    Time 0.077859    
2024-02-19 18:12:38,495 - Epoch: [190][  200/  500]    Overall Loss 0.216724    Objective Loss 0.216724                                        LR 0.000125    Time 0.073584    
2024-02-19 18:12:45,642 - Epoch: [190][  300/  500]    Overall Loss 0.217644    Objective Loss 0.217644                                        LR 0.000125    Time 0.072866    
2024-02-19 18:12:52,611 - Epoch: [190][  400/  500]    Overall Loss 0.220819    Objective Loss 0.220819                                        LR 0.000125    Time 0.072064    
2024-02-19 18:12:59,596 - Epoch: [190][  500/  500]    Overall Loss 0.222200    Objective Loss 0.222200    Top1 94.500000    Top5 99.500000    LR 0.000125    Time 0.071613    
2024-02-19 18:12:59,772 - --- validate (epoch=190)-----------
2024-02-19 18:12:59,773 - 10000 samples (100 per mini-batch)
2024-02-19 18:13:02,579 - Epoch: [190][  100/  100]    Loss 1.970894    Top1 59.700000    Top5 85.680000    
2024-02-19 18:13:02,677 - ==> Top1: 59.700    Top5: 85.680    Loss: 1.971

2024-02-19 18:13:02,691 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:13:02,691 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:13:02,751 - 

2024-02-19 18:13:02,751 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:13:10,282 - Epoch: [191][  100/  500]    Overall Loss 0.219249    Objective Loss 0.219249                                        LR 0.000125    Time 0.075259    
2024-02-19 18:13:17,238 - Epoch: [191][  200/  500]    Overall Loss 0.219000    Objective Loss 0.219000                                        LR 0.000125    Time 0.072388    
2024-02-19 18:13:24,231 - Epoch: [191][  300/  500]    Overall Loss 0.219732    Objective Loss 0.219732                                        LR 0.000125    Time 0.071556    
2024-02-19 18:13:31,170 - Epoch: [191][  400/  500]    Overall Loss 0.221630    Objective Loss 0.221630                                        LR 0.000125    Time 0.071005    
2024-02-19 18:13:38,201 - Epoch: [191][  500/  500]    Overall Loss 0.222612    Objective Loss 0.222612    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.070858    
2024-02-19 18:13:38,315 - --- validate (epoch=191)-----------
2024-02-19 18:13:38,316 - 10000 samples (100 per mini-batch)
2024-02-19 18:13:41,147 - Epoch: [191][  100/  100]    Loss 1.991651    Top1 59.920000    Top5 85.580000    
2024-02-19 18:13:41,260 - ==> Top1: 59.920    Top5: 85.580    Loss: 1.992

2024-02-19 18:13:41,271 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:13:41,272 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:13:41,332 - 

2024-02-19 18:13:41,333 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:13:49,039 - Epoch: [192][  100/  500]    Overall Loss 0.218386    Objective Loss 0.218386                                        LR 0.000125    Time 0.077016    
2024-02-19 18:13:55,979 - Epoch: [192][  200/  500]    Overall Loss 0.217557    Objective Loss 0.217557                                        LR 0.000125    Time 0.073186    
2024-02-19 18:14:02,911 - Epoch: [192][  300/  500]    Overall Loss 0.215115    Objective Loss 0.215115                                        LR 0.000125    Time 0.071885    
2024-02-19 18:14:09,780 - Epoch: [192][  400/  500]    Overall Loss 0.217083    Objective Loss 0.217083                                        LR 0.000125    Time 0.071077    
2024-02-19 18:14:16,688 - Epoch: [192][  500/  500]    Overall Loss 0.219166    Objective Loss 0.219166    Top1 97.000000    Top5 100.000000    LR 0.000125    Time 0.070672    
2024-02-19 18:14:16,871 - --- validate (epoch=192)-----------
2024-02-19 18:14:16,872 - 10000 samples (100 per mini-batch)
2024-02-19 18:14:19,736 - Epoch: [192][  100/  100]    Loss 1.972215    Top1 59.890000    Top5 85.600000    
2024-02-19 18:14:19,898 - ==> Top1: 59.890    Top5: 85.600    Loss: 1.972

2024-02-19 18:14:19,910 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:14:19,911 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:14:19,970 - 

2024-02-19 18:14:19,970 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:14:27,280 - Epoch: [193][  100/  500]    Overall Loss 0.213690    Objective Loss 0.213690                                        LR 0.000125    Time 0.073051    
2024-02-19 18:14:33,915 - Epoch: [193][  200/  500]    Overall Loss 0.216133    Objective Loss 0.216133                                        LR 0.000125    Time 0.069685    
2024-02-19 18:14:40,559 - Epoch: [193][  300/  500]    Overall Loss 0.217282    Objective Loss 0.217282                                        LR 0.000125    Time 0.068594    
2024-02-19 18:14:47,190 - Epoch: [193][  400/  500]    Overall Loss 0.218157    Objective Loss 0.218157                                        LR 0.000125    Time 0.068015    
2024-02-19 18:14:53,833 - Epoch: [193][  500/  500]    Overall Loss 0.217944    Objective Loss 0.217944    Top1 95.000000    Top5 100.000000    LR 0.000125    Time 0.067693    
2024-02-19 18:14:54,001 - --- validate (epoch=193)-----------
2024-02-19 18:14:54,001 - 10000 samples (100 per mini-batch)
2024-02-19 18:14:56,804 - Epoch: [193][  100/  100]    Loss 1.982611    Top1 59.880000    Top5 85.910000    
2024-02-19 18:14:56,913 - ==> Top1: 59.880    Top5: 85.910    Loss: 1.983

2024-02-19 18:14:56,925 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:14:56,926 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:14:56,986 - 

2024-02-19 18:14:56,986 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:15:04,699 - Epoch: [194][  100/  500]    Overall Loss 0.203038    Objective Loss 0.203038                                        LR 0.000125    Time 0.077073    
2024-02-19 18:15:11,682 - Epoch: [194][  200/  500]    Overall Loss 0.209588    Objective Loss 0.209588                                        LR 0.000125    Time 0.073430    
2024-02-19 18:15:18,717 - Epoch: [194][  300/  500]    Overall Loss 0.212824    Objective Loss 0.212824                                        LR 0.000125    Time 0.072392    
2024-02-19 18:15:25,962 - Epoch: [194][  400/  500]    Overall Loss 0.214587    Objective Loss 0.214587                                        LR 0.000125    Time 0.072398    
2024-02-19 18:15:33,236 - Epoch: [194][  500/  500]    Overall Loss 0.216752    Objective Loss 0.216752    Top1 92.000000    Top5 99.500000    LR 0.000125    Time 0.072459    
2024-02-19 18:15:33,410 - --- validate (epoch=194)-----------
2024-02-19 18:15:33,411 - 10000 samples (100 per mini-batch)
2024-02-19 18:15:36,239 - Epoch: [194][  100/  100]    Loss 2.009548    Top1 59.420000    Top5 85.450000    
2024-02-19 18:15:36,330 - ==> Top1: 59.420    Top5: 85.450    Loss: 2.010

2024-02-19 18:15:36,337 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:15:36,337 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:15:36,392 - 

2024-02-19 18:15:36,393 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:15:43,756 - Epoch: [195][  100/  500]    Overall Loss 0.218217    Objective Loss 0.218217                                        LR 0.000125    Time 0.073581    
2024-02-19 18:15:50,695 - Epoch: [195][  200/  500]    Overall Loss 0.218245    Objective Loss 0.218245                                        LR 0.000125    Time 0.071466    
2024-02-19 18:15:57,723 - Epoch: [195][  300/  500]    Overall Loss 0.219620    Objective Loss 0.219620                                        LR 0.000125    Time 0.071058    
2024-02-19 18:16:04,931 - Epoch: [195][  400/  500]    Overall Loss 0.220032    Objective Loss 0.220032                                        LR 0.000125    Time 0.071304    
2024-02-19 18:16:12,090 - Epoch: [195][  500/  500]    Overall Loss 0.220848    Objective Loss 0.220848    Top1 93.000000    Top5 100.000000    LR 0.000125    Time 0.071354    
2024-02-19 18:16:12,217 - --- validate (epoch=195)-----------
2024-02-19 18:16:12,218 - 10000 samples (100 per mini-batch)
2024-02-19 18:16:15,003 - Epoch: [195][  100/  100]    Loss 1.998598    Top1 59.870000    Top5 85.750000    
2024-02-19 18:16:15,170 - ==> Top1: 59.870    Top5: 85.750    Loss: 1.999

2024-02-19 18:16:15,183 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:16:15,183 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:16:15,243 - 

2024-02-19 18:16:15,243 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:16:22,615 - Epoch: [196][  100/  500]    Overall Loss 0.215504    Objective Loss 0.215504                                        LR 0.000125    Time 0.073674    
2024-02-19 18:16:29,620 - Epoch: [196][  200/  500]    Overall Loss 0.215083    Objective Loss 0.215083                                        LR 0.000125    Time 0.071842    
2024-02-19 18:16:36,721 - Epoch: [196][  300/  500]    Overall Loss 0.214971    Objective Loss 0.214971                                        LR 0.000125    Time 0.071552    
2024-02-19 18:16:43,672 - Epoch: [196][  400/  500]    Overall Loss 0.215812    Objective Loss 0.215812                                        LR 0.000125    Time 0.071031    
2024-02-19 18:16:50,611 - Epoch: [196][  500/  500]    Overall Loss 0.216520    Objective Loss 0.216520    Top1 95.500000    Top5 100.000000    LR 0.000125    Time 0.070697    
2024-02-19 18:16:50,794 - --- validate (epoch=196)-----------
2024-02-19 18:16:50,795 - 10000 samples (100 per mini-batch)
2024-02-19 18:16:53,733 - Epoch: [196][  100/  100]    Loss 2.017509    Top1 59.410000    Top5 85.360000    
2024-02-19 18:16:53,898 - ==> Top1: 59.410    Top5: 85.360    Loss: 2.018

2024-02-19 18:16:54,116 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:16:54,116 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:16:54,168 - 

2024-02-19 18:16:54,168 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:17:01,580 - Epoch: [197][  100/  500]    Overall Loss 0.199093    Objective Loss 0.199093                                        LR 0.000125    Time 0.074064    
2024-02-19 18:17:08,711 - Epoch: [197][  200/  500]    Overall Loss 0.210532    Objective Loss 0.210532                                        LR 0.000125    Time 0.072668    
2024-02-19 18:17:15,786 - Epoch: [197][  300/  500]    Overall Loss 0.213149    Objective Loss 0.213149                                        LR 0.000125    Time 0.072019    
2024-02-19 18:17:22,772 - Epoch: [197][  400/  500]    Overall Loss 0.213956    Objective Loss 0.213956                                        LR 0.000125    Time 0.071468    
2024-02-19 18:17:29,725 - Epoch: [197][  500/  500]    Overall Loss 0.215248    Objective Loss 0.215248    Top1 93.000000    Top5 100.000000    LR 0.000125    Time 0.071073    
2024-02-19 18:17:29,846 - --- validate (epoch=197)-----------
2024-02-19 18:17:29,847 - 10000 samples (100 per mini-batch)
2024-02-19 18:17:32,545 - Epoch: [197][  100/  100]    Loss 1.980144    Top1 60.340000    Top5 85.590000    
2024-02-19 18:17:32,652 - ==> Top1: 60.340    Top5: 85.590    Loss: 1.980

2024-02-19 18:17:32,663 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:17:32,663 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:17:32,723 - 

2024-02-19 18:17:32,723 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:17:40,068 - Epoch: [198][  100/  500]    Overall Loss 0.212729    Objective Loss 0.212729                                        LR 0.000125    Time 0.073403    
2024-02-19 18:17:47,113 - Epoch: [198][  200/  500]    Overall Loss 0.210995    Objective Loss 0.210995                                        LR 0.000125    Time 0.071908    
2024-02-19 18:17:54,096 - Epoch: [198][  300/  500]    Overall Loss 0.211916    Objective Loss 0.211916                                        LR 0.000125    Time 0.071203    
2024-02-19 18:18:00,998 - Epoch: [198][  400/  500]    Overall Loss 0.213681    Objective Loss 0.213681                                        LR 0.000125    Time 0.070649    
2024-02-19 18:18:07,936 - Epoch: [198][  500/  500]    Overall Loss 0.216552    Objective Loss 0.216552    Top1 91.500000    Top5 100.000000    LR 0.000125    Time 0.070387    
2024-02-19 18:18:08,111 - --- validate (epoch=198)-----------
2024-02-19 18:18:08,111 - 10000 samples (100 per mini-batch)
2024-02-19 18:18:11,150 - Epoch: [198][  100/  100]    Loss 2.016967    Top1 59.390000    Top5 85.560000    
2024-02-19 18:18:11,294 - ==> Top1: 59.390    Top5: 85.560    Loss: 2.017

2024-02-19 18:18:11,305 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:18:11,305 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:18:11,366 - 

2024-02-19 18:18:11,366 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:18:18,709 - Epoch: [199][  100/  500]    Overall Loss 0.208800    Objective Loss 0.208800                                        LR 0.000125    Time 0.073377    
2024-02-19 18:18:25,693 - Epoch: [199][  200/  500]    Overall Loss 0.209824    Objective Loss 0.209824                                        LR 0.000125    Time 0.071592    
2024-02-19 18:18:32,630 - Epoch: [199][  300/  500]    Overall Loss 0.211934    Objective Loss 0.211934                                        LR 0.000125    Time 0.070839    
2024-02-19 18:18:39,527 - Epoch: [199][  400/  500]    Overall Loss 0.214977    Objective Loss 0.214977                                        LR 0.000125    Time 0.070361    
2024-02-19 18:18:46,472 - Epoch: [199][  500/  500]    Overall Loss 0.216143    Objective Loss 0.216143    Top1 93.500000    Top5 100.000000    LR 0.000125    Time 0.070173    
2024-02-19 18:18:46,591 - --- validate (epoch=199)-----------
2024-02-19 18:18:46,592 - 10000 samples (100 per mini-batch)
2024-02-19 18:18:49,357 - Epoch: [199][  100/  100]    Loss 1.993669    Top1 59.600000    Top5 85.480000    
2024-02-19 18:18:49,524 - ==> Top1: 59.600    Top5: 85.480    Loss: 1.994

2024-02-19 18:18:49,536 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:18:49,536 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:18:49,597 - 

2024-02-19 18:18:49,597 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:18:57,208 - Epoch: [200][  100/  500]    Overall Loss 0.203186    Objective Loss 0.203186                                        LR 0.000063    Time 0.076058    
2024-02-19 18:19:04,163 - Epoch: [200][  200/  500]    Overall Loss 0.200658    Objective Loss 0.200658                                        LR 0.000063    Time 0.072789    
2024-02-19 18:19:11,099 - Epoch: [200][  300/  500]    Overall Loss 0.199368    Objective Loss 0.199368                                        LR 0.000063    Time 0.071634    
2024-02-19 18:19:18,045 - Epoch: [200][  400/  500]    Overall Loss 0.198770    Objective Loss 0.198770                                        LR 0.000063    Time 0.071080    
2024-02-19 18:19:24,969 - Epoch: [200][  500/  500]    Overall Loss 0.200164    Objective Loss 0.200164    Top1 94.500000    Top5 100.000000    LR 0.000063    Time 0.070705    
2024-02-19 18:19:25,083 - --- validate (epoch=200)-----------
2024-02-19 18:19:25,084 - 10000 samples (100 per mini-batch)
2024-02-19 18:19:27,814 - Epoch: [200][  100/  100]    Loss 1.965052    Top1 59.960000    Top5 85.850000    
2024-02-19 18:19:27,908 - ==> Top1: 59.960    Top5: 85.850    Loss: 1.965

2024-02-19 18:19:27,915 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:19:27,915 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:19:27,973 - 

2024-02-19 18:19:27,973 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:19:35,314 - Epoch: [201][  100/  500]    Overall Loss 0.194777    Objective Loss 0.194777                                        LR 0.000063    Time 0.073354    
2024-02-19 18:19:42,204 - Epoch: [201][  200/  500]    Overall Loss 0.195865    Objective Loss 0.195865                                        LR 0.000063    Time 0.071112    
2024-02-19 18:19:49,209 - Epoch: [201][  300/  500]    Overall Loss 0.197402    Objective Loss 0.197402                                        LR 0.000063    Time 0.070745    
2024-02-19 18:19:56,139 - Epoch: [201][  400/  500]    Overall Loss 0.197737    Objective Loss 0.197737                                        LR 0.000063    Time 0.070375    
2024-02-19 18:20:03,128 - Epoch: [201][  500/  500]    Overall Loss 0.198817    Objective Loss 0.198817    Top1 92.000000    Top5 99.500000    LR 0.000063    Time 0.070270    
2024-02-19 18:20:03,255 - --- validate (epoch=201)-----------
2024-02-19 18:20:03,256 - 10000 samples (100 per mini-batch)
2024-02-19 18:20:06,076 - Epoch: [201][  100/  100]    Loss 1.979687    Top1 60.100000    Top5 85.590000    
2024-02-19 18:20:06,170 - ==> Top1: 60.100    Top5: 85.590    Loss: 1.980

2024-02-19 18:20:06,181 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:20:06,182 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:20:06,242 - 

2024-02-19 18:20:06,243 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:20:13,925 - Epoch: [202][  100/  500]    Overall Loss 0.196987    Objective Loss 0.196987                                        LR 0.000063    Time 0.076770    
2024-02-19 18:20:20,880 - Epoch: [202][  200/  500]    Overall Loss 0.198782    Objective Loss 0.198782                                        LR 0.000063    Time 0.073143    
2024-02-19 18:20:28,103 - Epoch: [202][  300/  500]    Overall Loss 0.199579    Objective Loss 0.199579                                        LR 0.000063    Time 0.072826    
2024-02-19 18:20:35,057 - Epoch: [202][  400/  500]    Overall Loss 0.202158    Objective Loss 0.202158                                        LR 0.000063    Time 0.071994    
2024-02-19 18:20:42,036 - Epoch: [202][  500/  500]    Overall Loss 0.202946    Objective Loss 0.202946    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.071546    
2024-02-19 18:20:42,224 - --- validate (epoch=202)-----------
2024-02-19 18:20:42,225 - 10000 samples (100 per mini-batch)
2024-02-19 18:20:45,119 - Epoch: [202][  100/  100]    Loss 1.980951    Top1 60.160000    Top5 85.550000    
2024-02-19 18:20:45,248 - ==> Top1: 60.160    Top5: 85.550    Loss: 1.981

2024-02-19 18:20:45,259 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:20:45,260 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:20:45,320 - 

2024-02-19 18:20:45,321 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:20:52,756 - Epoch: [203][  100/  500]    Overall Loss 0.198696    Objective Loss 0.198696                                        LR 0.000063    Time 0.074307    
2024-02-19 18:20:59,726 - Epoch: [203][  200/  500]    Overall Loss 0.202378    Objective Loss 0.202378                                        LR 0.000063    Time 0.071982    
2024-02-19 18:21:06,793 - Epoch: [203][  300/  500]    Overall Loss 0.199438    Objective Loss 0.199438                                        LR 0.000063    Time 0.071532    
2024-02-19 18:21:13,763 - Epoch: [203][  400/  500]    Overall Loss 0.200565    Objective Loss 0.200565                                        LR 0.000063    Time 0.071065    
2024-02-19 18:21:20,760 - Epoch: [203][  500/  500]    Overall Loss 0.198712    Objective Loss 0.198712    Top1 93.500000    Top5 100.000000    LR 0.000063    Time 0.070838    
2024-02-19 18:21:20,895 - --- validate (epoch=203)-----------
2024-02-19 18:21:20,896 - 10000 samples (100 per mini-batch)
2024-02-19 18:21:23,639 - Epoch: [203][  100/  100]    Loss 1.983417    Top1 60.080000    Top5 85.490000    
2024-02-19 18:21:23,753 - ==> Top1: 60.080    Top5: 85.490    Loss: 1.983

2024-02-19 18:21:23,765 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:21:23,765 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:21:23,825 - 

2024-02-19 18:21:23,826 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:21:31,389 - Epoch: [204][  100/  500]    Overall Loss 0.194937    Objective Loss 0.194937                                        LR 0.000063    Time 0.075587    
2024-02-19 18:21:38,262 - Epoch: [204][  200/  500]    Overall Loss 0.194596    Objective Loss 0.194596                                        LR 0.000063    Time 0.072142    
2024-02-19 18:21:45,247 - Epoch: [204][  300/  500]    Overall Loss 0.192799    Objective Loss 0.192799                                        LR 0.000063    Time 0.071365    
2024-02-19 18:21:52,252 - Epoch: [204][  400/  500]    Overall Loss 0.195310    Objective Loss 0.195310                                        LR 0.000063    Time 0.071026    
2024-02-19 18:21:59,229 - Epoch: [204][  500/  500]    Overall Loss 0.196354    Objective Loss 0.196354    Top1 93.500000    Top5 99.500000    LR 0.000063    Time 0.070767    
2024-02-19 18:21:59,362 - --- validate (epoch=204)-----------
2024-02-19 18:21:59,363 - 10000 samples (100 per mini-batch)
2024-02-19 18:22:02,228 - Epoch: [204][  100/  100]    Loss 1.986956    Top1 60.240000    Top5 85.410000    
2024-02-19 18:22:02,338 - ==> Top1: 60.240    Top5: 85.410    Loss: 1.987

2024-02-19 18:22:02,349 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:22:02,349 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:22:02,410 - 

2024-02-19 18:22:02,410 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:22:09,794 - Epoch: [205][  100/  500]    Overall Loss 0.195522    Objective Loss 0.195522                                        LR 0.000063    Time 0.073787    
2024-02-19 18:22:16,716 - Epoch: [205][  200/  500]    Overall Loss 0.197703    Objective Loss 0.197703                                        LR 0.000063    Time 0.071486    
2024-02-19 18:22:23,605 - Epoch: [205][  300/  500]    Overall Loss 0.197991    Objective Loss 0.197991                                        LR 0.000063    Time 0.070608    
2024-02-19 18:22:30,547 - Epoch: [205][  400/  500]    Overall Loss 0.197787    Objective Loss 0.197787                                        LR 0.000063    Time 0.070303    
2024-02-19 18:22:37,499 - Epoch: [205][  500/  500]    Overall Loss 0.198011    Objective Loss 0.198011    Top1 96.000000    Top5 100.000000    LR 0.000063    Time 0.070138    
2024-02-19 18:22:37,614 - --- validate (epoch=205)-----------
2024-02-19 18:22:37,614 - 10000 samples (100 per mini-batch)
2024-02-19 18:22:40,470 - Epoch: [205][  100/  100]    Loss 1.993326    Top1 59.860000    Top5 85.530000    
2024-02-19 18:22:40,632 - ==> Top1: 59.860    Top5: 85.530    Loss: 1.993

2024-02-19 18:22:40,642 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:22:40,643 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:22:40,703 - 

2024-02-19 18:22:40,704 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:22:48,333 - Epoch: [206][  100/  500]    Overall Loss 0.187737    Objective Loss 0.187737                                        LR 0.000063    Time 0.076245    
2024-02-19 18:22:55,226 - Epoch: [206][  200/  500]    Overall Loss 0.190697    Objective Loss 0.190697                                        LR 0.000063    Time 0.072570    
2024-02-19 18:23:02,123 - Epoch: [206][  300/  500]    Overall Loss 0.191348    Objective Loss 0.191348                                        LR 0.000063    Time 0.071358    
2024-02-19 18:23:09,410 - Epoch: [206][  400/  500]    Overall Loss 0.193628    Objective Loss 0.193628                                        LR 0.000063    Time 0.071724    
2024-02-19 18:23:16,575 - Epoch: [206][  500/  500]    Overall Loss 0.194200    Objective Loss 0.194200    Top1 91.000000    Top5 100.000000    LR 0.000063    Time 0.071702    
2024-02-19 18:23:16,689 - --- validate (epoch=206)-----------
2024-02-19 18:23:16,690 - 10000 samples (100 per mini-batch)
2024-02-19 18:23:19,528 - Epoch: [206][  100/  100]    Loss 1.985267    Top1 59.780000    Top5 85.580000    
2024-02-19 18:23:19,636 - ==> Top1: 59.780    Top5: 85.580    Loss: 1.985

2024-02-19 18:23:19,647 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:23:19,647 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:23:19,705 - 

2024-02-19 18:23:19,705 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:23:27,080 - Epoch: [207][  100/  500]    Overall Loss 0.194213    Objective Loss 0.194213                                        LR 0.000063    Time 0.073699    
2024-02-19 18:23:33,981 - Epoch: [207][  200/  500]    Overall Loss 0.199908    Objective Loss 0.199908                                        LR 0.000063    Time 0.071333    
2024-02-19 18:23:40,919 - Epoch: [207][  300/  500]    Overall Loss 0.195590    Objective Loss 0.195590                                        LR 0.000063    Time 0.070670    
2024-02-19 18:23:47,898 - Epoch: [207][  400/  500]    Overall Loss 0.196481    Objective Loss 0.196481                                        LR 0.000063    Time 0.070442    
2024-02-19 18:23:54,941 - Epoch: [207][  500/  500]    Overall Loss 0.196540    Objective Loss 0.196540    Top1 96.500000    Top5 100.000000    LR 0.000063    Time 0.070432    
2024-02-19 18:23:55,051 - --- validate (epoch=207)-----------
2024-02-19 18:23:55,051 - 10000 samples (100 per mini-batch)
2024-02-19 18:23:57,831 - Epoch: [207][  100/  100]    Loss 1.995921    Top1 60.050000    Top5 85.430000    
2024-02-19 18:23:57,960 - ==> Top1: 60.050    Top5: 85.430    Loss: 1.996

2024-02-19 18:23:57,972 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:23:57,972 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:23:58,033 - 

2024-02-19 18:23:58,033 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:24:05,766 - Epoch: [208][  100/  500]    Overall Loss 0.186295    Objective Loss 0.186295                                        LR 0.000063    Time 0.077275    
2024-02-19 18:24:12,769 - Epoch: [208][  200/  500]    Overall Loss 0.191939    Objective Loss 0.191939                                        LR 0.000063    Time 0.073629    
2024-02-19 18:24:19,793 - Epoch: [208][  300/  500]    Overall Loss 0.191132    Objective Loss 0.191132                                        LR 0.000063    Time 0.072489    
2024-02-19 18:24:26,772 - Epoch: [208][  400/  500]    Overall Loss 0.191322    Objective Loss 0.191322                                        LR 0.000063    Time 0.071804    
2024-02-19 18:24:33,810 - Epoch: [208][  500/  500]    Overall Loss 0.191751    Objective Loss 0.191751    Top1 94.500000    Top5 99.500000    LR 0.000063    Time 0.071510    
2024-02-19 18:24:33,947 - --- validate (epoch=208)-----------
2024-02-19 18:24:33,948 - 10000 samples (100 per mini-batch)
2024-02-19 18:24:36,952 - Epoch: [208][  100/  100]    Loss 1.989587    Top1 59.850000    Top5 85.630000    
2024-02-19 18:24:37,052 - ==> Top1: 59.850    Top5: 85.630    Loss: 1.990

2024-02-19 18:24:37,064 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:24:37,064 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:24:37,124 - 

2024-02-19 18:24:37,125 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:24:44,527 - Epoch: [209][  100/  500]    Overall Loss 0.182289    Objective Loss 0.182289                                        LR 0.000063    Time 0.073974    
2024-02-19 18:24:51,497 - Epoch: [209][  200/  500]    Overall Loss 0.184634    Objective Loss 0.184634                                        LR 0.000063    Time 0.071815    
2024-02-19 18:24:58,467 - Epoch: [209][  300/  500]    Overall Loss 0.189662    Objective Loss 0.189662                                        LR 0.000063    Time 0.071098    
2024-02-19 18:25:05,550 - Epoch: [209][  400/  500]    Overall Loss 0.189371    Objective Loss 0.189371                                        LR 0.000063    Time 0.071020    
2024-02-19 18:25:12,689 - Epoch: [209][  500/  500]    Overall Loss 0.191692    Objective Loss 0.191692    Top1 97.500000    Top5 100.000000    LR 0.000063    Time 0.071086    
2024-02-19 18:25:12,871 - --- validate (epoch=209)-----------
2024-02-19 18:25:12,872 - 10000 samples (100 per mini-batch)
2024-02-19 18:25:15,909 - Epoch: [209][  100/  100]    Loss 1.987464    Top1 60.260000    Top5 85.570000    
2024-02-19 18:25:16,011 - ==> Top1: 60.260    Top5: 85.570    Loss: 1.987

2024-02-19 18:25:16,022 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:25:16,022 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:25:16,082 - 

2024-02-19 18:25:16,083 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:25:23,878 - Epoch: [210][  100/  500]    Overall Loss 0.189874    Objective Loss 0.189874                                        LR 0.000063    Time 0.077899    
2024-02-19 18:25:30,968 - Epoch: [210][  200/  500]    Overall Loss 0.194038    Objective Loss 0.194038                                        LR 0.000063    Time 0.074381    
2024-02-19 18:25:38,056 - Epoch: [210][  300/  500]    Overall Loss 0.192469    Objective Loss 0.192469                                        LR 0.000063    Time 0.073201    
2024-02-19 18:25:45,122 - Epoch: [210][  400/  500]    Overall Loss 0.193836    Objective Loss 0.193836                                        LR 0.000063    Time 0.072557    
2024-02-19 18:25:52,136 - Epoch: [210][  500/  500]    Overall Loss 0.193880    Objective Loss 0.193880    Top1 95.500000    Top5 100.000000    LR 0.000063    Time 0.072066    
2024-02-19 18:25:52,293 - --- validate (epoch=210)-----------
2024-02-19 18:25:52,294 - 10000 samples (100 per mini-batch)
2024-02-19 18:25:55,341 - Epoch: [210][  100/  100]    Loss 1.989523    Top1 59.720000    Top5 85.570000    
2024-02-19 18:25:55,463 - ==> Top1: 59.720    Top5: 85.570    Loss: 1.990

2024-02-19 18:25:55,473 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:25:55,474 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:25:55,534 - 

2024-02-19 18:25:55,535 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:26:02,868 - Epoch: [211][  100/  500]    Overall Loss 0.186052    Objective Loss 0.186052                                        LR 0.000063    Time 0.073280    
2024-02-19 18:26:09,759 - Epoch: [211][  200/  500]    Overall Loss 0.188660    Objective Loss 0.188660                                        LR 0.000063    Time 0.071079    
2024-02-19 18:26:16,644 - Epoch: [211][  300/  500]    Overall Loss 0.191582    Objective Loss 0.191582                                        LR 0.000063    Time 0.070322    
2024-02-19 18:26:23,532 - Epoch: [211][  400/  500]    Overall Loss 0.192479    Objective Loss 0.192479                                        LR 0.000063    Time 0.069954    
2024-02-19 18:26:30,466 - Epoch: [211][  500/  500]    Overall Loss 0.192063    Objective Loss 0.192063    Top1 92.500000    Top5 99.500000    LR 0.000063    Time 0.069824    
2024-02-19 18:26:30,620 - --- validate (epoch=211)-----------
2024-02-19 18:26:30,621 - 10000 samples (100 per mini-batch)
2024-02-19 18:26:33,639 - Epoch: [211][  100/  100]    Loss 1.990865    Top1 60.080000    Top5 85.620000    
2024-02-19 18:26:33,777 - ==> Top1: 60.080    Top5: 85.620    Loss: 1.991

2024-02-19 18:26:33,789 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:26:33,789 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:26:33,851 - 

2024-02-19 18:26:33,851 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:26:41,638 - Epoch: [212][  100/  500]    Overall Loss 0.189843    Objective Loss 0.189843                                        LR 0.000063    Time 0.077820    
2024-02-19 18:26:48,579 - Epoch: [212][  200/  500]    Overall Loss 0.187077    Objective Loss 0.187077                                        LR 0.000063    Time 0.073595    
2024-02-19 18:26:55,487 - Epoch: [212][  300/  500]    Overall Loss 0.187261    Objective Loss 0.187261                                        LR 0.000063    Time 0.072078    
2024-02-19 18:27:02,367 - Epoch: [212][  400/  500]    Overall Loss 0.190282    Objective Loss 0.190282                                        LR 0.000063    Time 0.071251    
2024-02-19 18:27:09,246 - Epoch: [212][  500/  500]    Overall Loss 0.192728    Objective Loss 0.192728    Top1 95.000000    Top5 100.000000    LR 0.000063    Time 0.070751    
2024-02-19 18:27:09,394 - --- validate (epoch=212)-----------
2024-02-19 18:27:09,395 - 10000 samples (100 per mini-batch)
2024-02-19 18:27:12,387 - Epoch: [212][  100/  100]    Loss 2.001795    Top1 59.840000    Top5 85.450000    
2024-02-19 18:27:12,481 - ==> Top1: 59.840    Top5: 85.450    Loss: 2.002

2024-02-19 18:27:12,487 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:27:12,488 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:27:12,542 - 

2024-02-19 18:27:12,542 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:27:20,220 - Epoch: [213][  100/  500]    Overall Loss 0.185453    Objective Loss 0.185453                                        LR 0.000063    Time 0.076731    
2024-02-19 18:27:27,395 - Epoch: [213][  200/  500]    Overall Loss 0.192602    Objective Loss 0.192602                                        LR 0.000063    Time 0.074218    
2024-02-19 18:27:34,663 - Epoch: [213][  300/  500]    Overall Loss 0.192237    Objective Loss 0.192237                                        LR 0.000063    Time 0.073695    
2024-02-19 18:27:41,934 - Epoch: [213][  400/  500]    Overall Loss 0.192414    Objective Loss 0.192414                                        LR 0.000063    Time 0.073439    
2024-02-19 18:27:49,057 - Epoch: [213][  500/  500]    Overall Loss 0.192429    Objective Loss 0.192429    Top1 96.500000    Top5 100.000000    LR 0.000063    Time 0.072990    
2024-02-19 18:27:49,183 - --- validate (epoch=213)-----------
2024-02-19 18:27:49,184 - 10000 samples (100 per mini-batch)
2024-02-19 18:27:52,076 - Epoch: [213][  100/  100]    Loss 1.997129    Top1 59.970000    Top5 85.630000    
2024-02-19 18:27:52,206 - ==> Top1: 59.970    Top5: 85.630    Loss: 1.997

2024-02-19 18:27:52,217 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:27:52,218 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:27:52,277 - 

2024-02-19 18:27:52,278 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:27:59,717 - Epoch: [214][  100/  500]    Overall Loss 0.185393    Objective Loss 0.185393                                        LR 0.000063    Time 0.074342    
2024-02-19 18:28:06,672 - Epoch: [214][  200/  500]    Overall Loss 0.187770    Objective Loss 0.187770                                        LR 0.000063    Time 0.071923    
2024-02-19 18:28:13,609 - Epoch: [214][  300/  500]    Overall Loss 0.189845    Objective Loss 0.189845                                        LR 0.000063    Time 0.071061    
2024-02-19 18:28:20,611 - Epoch: [214][  400/  500]    Overall Loss 0.190834    Objective Loss 0.190834                                        LR 0.000063    Time 0.070791    
2024-02-19 18:28:27,543 - Epoch: [214][  500/  500]    Overall Loss 0.191974    Objective Loss 0.191974    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.070489    
2024-02-19 18:28:27,655 - --- validate (epoch=214)-----------
2024-02-19 18:28:27,656 - 10000 samples (100 per mini-batch)
2024-02-19 18:28:30,743 - Epoch: [214][  100/  100]    Loss 1.996534    Top1 59.810000    Top5 85.920000    
2024-02-19 18:28:30,861 - ==> Top1: 59.810    Top5: 85.920    Loss: 1.997

2024-02-19 18:28:30,872 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:28:30,872 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:28:30,932 - 

2024-02-19 18:28:30,933 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:28:38,358 - Epoch: [215][  100/  500]    Overall Loss 0.189752    Objective Loss 0.189752                                        LR 0.000063    Time 0.074203    
2024-02-19 18:28:45,286 - Epoch: [215][  200/  500]    Overall Loss 0.189251    Objective Loss 0.189251                                        LR 0.000063    Time 0.071722    
2024-02-19 18:28:52,235 - Epoch: [215][  300/  500]    Overall Loss 0.190446    Objective Loss 0.190446                                        LR 0.000063    Time 0.070965    
2024-02-19 18:28:59,176 - Epoch: [215][  400/  500]    Overall Loss 0.190908    Objective Loss 0.190908                                        LR 0.000063    Time 0.070566    
2024-02-19 18:29:06,228 - Epoch: [215][  500/  500]    Overall Loss 0.191842    Objective Loss 0.191842    Top1 98.000000    Top5 100.000000    LR 0.000063    Time 0.070549    
2024-02-19 18:29:06,338 - --- validate (epoch=215)-----------
2024-02-19 18:29:06,339 - 10000 samples (100 per mini-batch)
2024-02-19 18:29:09,426 - Epoch: [215][  100/  100]    Loss 2.001431    Top1 60.160000    Top5 85.640000    
2024-02-19 18:29:09,569 - ==> Top1: 60.160    Top5: 85.640    Loss: 2.001

2024-02-19 18:29:09,580 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:29:09,581 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:29:09,640 - 

2024-02-19 18:29:09,641 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:29:17,326 - Epoch: [216][  100/  500]    Overall Loss 0.189223    Objective Loss 0.189223                                        LR 0.000063    Time 0.076778    
2024-02-19 18:29:24,271 - Epoch: [216][  200/  500]    Overall Loss 0.189004    Objective Loss 0.189004                                        LR 0.000063    Time 0.073092    
2024-02-19 18:29:31,204 - Epoch: [216][  300/  500]    Overall Loss 0.188595    Objective Loss 0.188595                                        LR 0.000063    Time 0.071829    
2024-02-19 18:29:38,129 - Epoch: [216][  400/  500]    Overall Loss 0.191228    Objective Loss 0.191228                                        LR 0.000063    Time 0.071173    
2024-02-19 18:29:45,076 - Epoch: [216][  500/  500]    Overall Loss 0.191002    Objective Loss 0.191002    Top1 95.000000    Top5 100.000000    LR 0.000063    Time 0.070825    
2024-02-19 18:29:45,204 - --- validate (epoch=216)-----------
2024-02-19 18:29:45,205 - 10000 samples (100 per mini-batch)
2024-02-19 18:29:48,102 - Epoch: [216][  100/  100]    Loss 1.988810    Top1 59.900000    Top5 85.870000    
2024-02-19 18:29:48,228 - ==> Top1: 59.900    Top5: 85.870    Loss: 1.989

2024-02-19 18:29:48,242 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:29:48,242 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:29:48,303 - 

2024-02-19 18:29:48,304 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:29:55,791 - Epoch: [217][  100/  500]    Overall Loss 0.186071    Objective Loss 0.186071                                        LR 0.000063    Time 0.074820    
2024-02-19 18:30:02,723 - Epoch: [217][  200/  500]    Overall Loss 0.188476    Objective Loss 0.188476                                        LR 0.000063    Time 0.072048    
2024-02-19 18:30:09,664 - Epoch: [217][  300/  500]    Overall Loss 0.189922    Objective Loss 0.189922                                        LR 0.000063    Time 0.071156    
2024-02-19 18:30:16,605 - Epoch: [217][  400/  500]    Overall Loss 0.190190    Objective Loss 0.190190                                        LR 0.000063    Time 0.070711    
2024-02-19 18:30:23,689 - Epoch: [217][  500/  500]    Overall Loss 0.190432    Objective Loss 0.190432    Top1 91.000000    Top5 100.000000    LR 0.000063    Time 0.070729    
2024-02-19 18:30:23,814 - --- validate (epoch=217)-----------
2024-02-19 18:30:23,815 - 10000 samples (100 per mini-batch)
2024-02-19 18:30:26,608 - Epoch: [217][  100/  100]    Loss 2.001486    Top1 59.970000    Top5 85.490000    
2024-02-19 18:30:26,722 - ==> Top1: 59.970    Top5: 85.490    Loss: 2.001

2024-02-19 18:30:26,733 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:30:26,733 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:30:26,792 - 

2024-02-19 18:30:26,792 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:30:34,522 - Epoch: [218][  100/  500]    Overall Loss 0.187269    Objective Loss 0.187269                                        LR 0.000063    Time 0.077247    
2024-02-19 18:30:41,614 - Epoch: [218][  200/  500]    Overall Loss 0.183732    Objective Loss 0.183732                                        LR 0.000063    Time 0.074069    
2024-02-19 18:30:48,715 - Epoch: [218][  300/  500]    Overall Loss 0.185871    Objective Loss 0.185871                                        LR 0.000063    Time 0.073034    
2024-02-19 18:30:55,786 - Epoch: [218][  400/  500]    Overall Loss 0.189185    Objective Loss 0.189185                                        LR 0.000063    Time 0.072444    
2024-02-19 18:31:02,894 - Epoch: [218][  500/  500]    Overall Loss 0.189360    Objective Loss 0.189360    Top1 97.000000    Top5 100.000000    LR 0.000063    Time 0.072164    
2024-02-19 18:31:03,062 - --- validate (epoch=218)-----------
2024-02-19 18:31:03,063 - 10000 samples (100 per mini-batch)
2024-02-19 18:31:05,928 - Epoch: [218][  100/  100]    Loss 1.992123    Top1 59.960000    Top5 85.670000    
2024-02-19 18:31:06,026 - ==> Top1: 59.960    Top5: 85.670    Loss: 1.992

2024-02-19 18:31:06,037 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:31:06,037 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:31:06,095 - 

2024-02-19 18:31:06,095 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:31:13,524 - Epoch: [219][  100/  500]    Overall Loss 0.181885    Objective Loss 0.181885                                        LR 0.000063    Time 0.074232    
2024-02-19 18:31:20,430 - Epoch: [219][  200/  500]    Overall Loss 0.187779    Objective Loss 0.187779                                        LR 0.000063    Time 0.071628    
2024-02-19 18:31:27,337 - Epoch: [219][  300/  500]    Overall Loss 0.187487    Objective Loss 0.187487                                        LR 0.000063    Time 0.070766    
2024-02-19 18:31:34,254 - Epoch: [219][  400/  500]    Overall Loss 0.188190    Objective Loss 0.188190                                        LR 0.000063    Time 0.070358    
2024-02-19 18:31:41,243 - Epoch: [219][  500/  500]    Overall Loss 0.188536    Objective Loss 0.188536    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.070256    
2024-02-19 18:31:41,353 - --- validate (epoch=219)-----------
2024-02-19 18:31:41,354 - 10000 samples (100 per mini-batch)
2024-02-19 18:31:44,227 - Epoch: [219][  100/  100]    Loss 2.009096    Top1 59.890000    Top5 85.590000    
2024-02-19 18:31:44,338 - ==> Top1: 59.890    Top5: 85.590    Loss: 2.009

2024-02-19 18:31:44,349 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:31:44,350 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:31:44,411 - 

2024-02-19 18:31:44,411 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:31:52,157 - Epoch: [220][  100/  500]    Overall Loss 0.181533    Objective Loss 0.181533                                        LR 0.000063    Time 0.077401    
2024-02-19 18:31:59,106 - Epoch: [220][  200/  500]    Overall Loss 0.185505    Objective Loss 0.185505                                        LR 0.000063    Time 0.073426    
2024-02-19 18:32:06,052 - Epoch: [220][  300/  500]    Overall Loss 0.185208    Objective Loss 0.185208                                        LR 0.000063    Time 0.072092    
2024-02-19 18:32:13,018 - Epoch: [220][  400/  500]    Overall Loss 0.185818    Objective Loss 0.185818                                        LR 0.000063    Time 0.071474    
2024-02-19 18:32:20,049 - Epoch: [220][  500/  500]    Overall Loss 0.187292    Objective Loss 0.187292    Top1 92.000000    Top5 100.000000    LR 0.000063    Time 0.071234    
2024-02-19 18:32:20,234 - --- validate (epoch=220)-----------
2024-02-19 18:32:20,235 - 10000 samples (100 per mini-batch)
2024-02-19 18:32:23,285 - Epoch: [220][  100/  100]    Loss 2.002334    Top1 60.000000    Top5 85.600000    
2024-02-19 18:32:23,456 - ==> Top1: 60.000    Top5: 85.600    Loss: 2.002

2024-02-19 18:32:23,468 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:32:23,469 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:32:23,531 - 

2024-02-19 18:32:23,531 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:32:31,096 - Epoch: [221][  100/  500]    Overall Loss 0.189047    Objective Loss 0.189047                                        LR 0.000063    Time 0.075596    
2024-02-19 18:32:38,035 - Epoch: [221][  200/  500]    Overall Loss 0.185544    Objective Loss 0.185544                                        LR 0.000063    Time 0.072473    
2024-02-19 18:32:44,973 - Epoch: [221][  300/  500]    Overall Loss 0.187226    Objective Loss 0.187226                                        LR 0.000063    Time 0.071429    
2024-02-19 18:32:51,907 - Epoch: [221][  400/  500]    Overall Loss 0.186984    Objective Loss 0.186984                                        LR 0.000063    Time 0.070897    
2024-02-19 18:32:58,872 - Epoch: [221][  500/  500]    Overall Loss 0.186768    Objective Loss 0.186768    Top1 97.500000    Top5 100.000000    LR 0.000063    Time 0.070639    
2024-02-19 18:32:59,015 - --- validate (epoch=221)-----------
2024-02-19 18:32:59,015 - 10000 samples (100 per mini-batch)
2024-02-19 18:33:02,022 - Epoch: [221][  100/  100]    Loss 1.996541    Top1 59.970000    Top5 85.730000    
2024-02-19 18:33:02,176 - ==> Top1: 59.970    Top5: 85.730    Loss: 1.997

2024-02-19 18:33:02,189 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:33:02,189 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:33:02,252 - 

2024-02-19 18:33:02,253 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:33:09,388 - Epoch: [222][  100/  500]    Overall Loss 0.181075    Objective Loss 0.181075                                        LR 0.000063    Time 0.071307    
2024-02-19 18:33:16,206 - Epoch: [222][  200/  500]    Overall Loss 0.182124    Objective Loss 0.182124                                        LR 0.000063    Time 0.069730    
2024-02-19 18:33:22,857 - Epoch: [222][  300/  500]    Overall Loss 0.184688    Objective Loss 0.184688                                        LR 0.000063    Time 0.068646    
2024-02-19 18:33:29,666 - Epoch: [222][  400/  500]    Overall Loss 0.184411    Objective Loss 0.184411                                        LR 0.000063    Time 0.068499    
2024-02-19 18:33:36,497 - Epoch: [222][  500/  500]    Overall Loss 0.184642    Objective Loss 0.184642    Top1 95.500000    Top5 100.000000    LR 0.000063    Time 0.068454    
2024-02-19 18:33:36,601 - --- validate (epoch=222)-----------
2024-02-19 18:33:36,602 - 10000 samples (100 per mini-batch)
2024-02-19 18:33:39,763 - Epoch: [222][  100/  100]    Loss 2.006766    Top1 59.990000    Top5 85.670000    
2024-02-19 18:33:39,941 - ==> Top1: 59.990    Top5: 85.670    Loss: 2.007

2024-02-19 18:33:39,951 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:33:39,952 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:33:40,012 - 

2024-02-19 18:33:40,013 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:33:47,266 - Epoch: [223][  100/  500]    Overall Loss 0.184072    Objective Loss 0.184072                                        LR 0.000063    Time 0.072490    
2024-02-19 18:33:53,910 - Epoch: [223][  200/  500]    Overall Loss 0.182835    Objective Loss 0.182835                                        LR 0.000063    Time 0.069447    
2024-02-19 18:34:00,557 - Epoch: [223][  300/  500]    Overall Loss 0.184719    Objective Loss 0.184719                                        LR 0.000063    Time 0.068445    
2024-02-19 18:34:07,212 - Epoch: [223][  400/  500]    Overall Loss 0.186742    Objective Loss 0.186742                                        LR 0.000063    Time 0.067963    
2024-02-19 18:34:13,909 - Epoch: [223][  500/  500]    Overall Loss 0.189020    Objective Loss 0.189020    Top1 96.500000    Top5 100.000000    LR 0.000063    Time 0.067760    
2024-02-19 18:34:14,053 - --- validate (epoch=223)-----------
2024-02-19 18:34:14,054 - 10000 samples (100 per mini-batch)
2024-02-19 18:34:16,914 - Epoch: [223][  100/  100]    Loss 2.003324    Top1 59.820000    Top5 85.600000    
2024-02-19 18:34:17,032 - ==> Top1: 59.820    Top5: 85.600    Loss: 2.003

2024-02-19 18:34:17,044 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:34:17,044 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:34:17,105 - 

2024-02-19 18:34:17,106 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:34:24,637 - Epoch: [224][  100/  500]    Overall Loss 0.182419    Objective Loss 0.182419                                        LR 0.000063    Time 0.075261    
2024-02-19 18:34:31,734 - Epoch: [224][  200/  500]    Overall Loss 0.181418    Objective Loss 0.181418                                        LR 0.000063    Time 0.073096    
2024-02-19 18:34:38,883 - Epoch: [224][  300/  500]    Overall Loss 0.183107    Objective Loss 0.183107                                        LR 0.000063    Time 0.072549    
2024-02-19 18:34:46,044 - Epoch: [224][  400/  500]    Overall Loss 0.184033    Objective Loss 0.184033                                        LR 0.000063    Time 0.072306    
2024-02-19 18:34:53,264 - Epoch: [224][  500/  500]    Overall Loss 0.186065    Objective Loss 0.186065    Top1 95.000000    Top5 100.000000    LR 0.000063    Time 0.072276    
2024-02-19 18:34:53,390 - --- validate (epoch=224)-----------
2024-02-19 18:34:53,391 - 10000 samples (100 per mini-batch)
2024-02-19 18:34:56,444 - Epoch: [224][  100/  100]    Loss 2.017693    Top1 59.720000    Top5 85.600000    
2024-02-19 18:34:56,616 - ==> Top1: 59.720    Top5: 85.600    Loss: 2.018

2024-02-19 18:34:56,627 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:34:56,627 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:34:56,687 - 

2024-02-19 18:34:56,687 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:35:04,195 - Epoch: [225][  100/  500]    Overall Loss 0.183346    Objective Loss 0.183346                                        LR 0.000063    Time 0.075028    
2024-02-19 18:35:11,252 - Epoch: [225][  200/  500]    Overall Loss 0.185064    Objective Loss 0.185064                                        LR 0.000063    Time 0.072780    
2024-02-19 18:35:18,228 - Epoch: [225][  300/  500]    Overall Loss 0.184119    Objective Loss 0.184119                                        LR 0.000063    Time 0.071764    
2024-02-19 18:35:25,212 - Epoch: [225][  400/  500]    Overall Loss 0.185728    Objective Loss 0.185728                                        LR 0.000063    Time 0.071273    
2024-02-19 18:35:32,273 - Epoch: [225][  500/  500]    Overall Loss 0.186508    Objective Loss 0.186508    Top1 95.500000    Top5 99.000000    LR 0.000063    Time 0.071133    
2024-02-19 18:35:32,409 - --- validate (epoch=225)-----------
2024-02-19 18:35:32,410 - 10000 samples (100 per mini-batch)
2024-02-19 18:35:35,248 - Epoch: [225][  100/  100]    Loss 2.008494    Top1 59.680000    Top5 85.490000    
2024-02-19 18:35:35,396 - ==> Top1: 59.680    Top5: 85.490    Loss: 2.008

2024-02-19 18:35:35,402 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:35:35,402 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:35:35,455 - 

2024-02-19 18:35:35,455 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:35:42,812 - Epoch: [226][  100/  500]    Overall Loss 0.178117    Objective Loss 0.178117                                        LR 0.000063    Time 0.073521    
2024-02-19 18:35:49,492 - Epoch: [226][  200/  500]    Overall Loss 0.179390    Objective Loss 0.179390                                        LR 0.000063    Time 0.070147    
2024-02-19 18:35:56,487 - Epoch: [226][  300/  500]    Overall Loss 0.180614    Objective Loss 0.180614                                        LR 0.000063    Time 0.070067    
2024-02-19 18:36:03,397 - Epoch: [226][  400/  500]    Overall Loss 0.181791    Objective Loss 0.181791                                        LR 0.000063    Time 0.069818    
2024-02-19 18:36:10,313 - Epoch: [226][  500/  500]    Overall Loss 0.183044    Objective Loss 0.183044    Top1 94.500000    Top5 100.000000    LR 0.000063    Time 0.069678    
2024-02-19 18:36:10,483 - --- validate (epoch=226)-----------
2024-02-19 18:36:10,483 - 10000 samples (100 per mini-batch)
2024-02-19 18:36:13,317 - Epoch: [226][  100/  100]    Loss 2.011793    Top1 60.050000    Top5 85.680000    
2024-02-19 18:36:13,482 - ==> Top1: 60.050    Top5: 85.680    Loss: 2.012

2024-02-19 18:36:13,494 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:36:13,494 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:36:13,555 - 

2024-02-19 18:36:13,555 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:36:20,692 - Epoch: [227][  100/  500]    Overall Loss 0.177884    Objective Loss 0.177884                                        LR 0.000063    Time 0.071326    
2024-02-19 18:36:27,372 - Epoch: [227][  200/  500]    Overall Loss 0.183224    Objective Loss 0.183224                                        LR 0.000063    Time 0.069046    
2024-02-19 18:36:34,056 - Epoch: [227][  300/  500]    Overall Loss 0.184778    Objective Loss 0.184778                                        LR 0.000063    Time 0.068301    
2024-02-19 18:36:40,749 - Epoch: [227][  400/  500]    Overall Loss 0.185176    Objective Loss 0.185176                                        LR 0.000063    Time 0.067949    
2024-02-19 18:36:47,469 - Epoch: [227][  500/  500]    Overall Loss 0.188129    Objective Loss 0.188129    Top1 96.000000    Top5 100.000000    LR 0.000063    Time 0.067793    
2024-02-19 18:36:47,602 - --- validate (epoch=227)-----------
2024-02-19 18:36:47,603 - 10000 samples (100 per mini-batch)
2024-02-19 18:36:50,511 - Epoch: [227][  100/  100]    Loss 2.005703    Top1 59.850000    Top5 85.640000    
2024-02-19 18:36:50,617 - ==> Top1: 59.850    Top5: 85.640    Loss: 2.006

2024-02-19 18:36:50,629 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:36:50,629 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:36:50,688 - 

2024-02-19 18:36:50,689 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:36:58,273 - Epoch: [228][  100/  500]    Overall Loss 0.178933    Objective Loss 0.178933                                        LR 0.000063    Time 0.075793    
2024-02-19 18:37:05,078 - Epoch: [228][  200/  500]    Overall Loss 0.181658    Objective Loss 0.181658                                        LR 0.000063    Time 0.071904    
2024-02-19 18:37:11,799 - Epoch: [228][  300/  500]    Overall Loss 0.183194    Objective Loss 0.183194                                        LR 0.000063    Time 0.070330    
2024-02-19 18:37:18,431 - Epoch: [228][  400/  500]    Overall Loss 0.184447    Objective Loss 0.184447                                        LR 0.000063    Time 0.069322    
2024-02-19 18:37:25,103 - Epoch: [228][  500/  500]    Overall Loss 0.185749    Objective Loss 0.185749    Top1 95.500000    Top5 100.000000    LR 0.000063    Time 0.068794    
2024-02-19 18:37:25,231 - --- validate (epoch=228)-----------
2024-02-19 18:37:25,232 - 10000 samples (100 per mini-batch)
2024-02-19 18:37:28,082 - Epoch: [228][  100/  100]    Loss 2.018748    Top1 59.790000    Top5 85.680000    
2024-02-19 18:37:28,221 - ==> Top1: 59.790    Top5: 85.680    Loss: 2.019

2024-02-19 18:37:28,233 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:37:28,233 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:37:28,295 - 

2024-02-19 18:37:28,295 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:37:35,395 - Epoch: [229][  100/  500]    Overall Loss 0.179881    Objective Loss 0.179881                                        LR 0.000063    Time 0.070952    
2024-02-19 18:37:42,138 - Epoch: [229][  200/  500]    Overall Loss 0.179978    Objective Loss 0.179978                                        LR 0.000063    Time 0.069174    
2024-02-19 18:37:49,005 - Epoch: [229][  300/  500]    Overall Loss 0.180616    Objective Loss 0.180616                                        LR 0.000063    Time 0.068995    
2024-02-19 18:37:55,765 - Epoch: [229][  400/  500]    Overall Loss 0.182035    Objective Loss 0.182035                                        LR 0.000063    Time 0.068636    
2024-02-19 18:38:02,425 - Epoch: [229][  500/  500]    Overall Loss 0.184073    Objective Loss 0.184073    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.068224    
2024-02-19 18:38:02,605 - --- validate (epoch=229)-----------
2024-02-19 18:38:02,606 - 10000 samples (100 per mini-batch)
2024-02-19 18:38:05,466 - Epoch: [229][  100/  100]    Loss 2.021897    Top1 59.640000    Top5 85.620000    
2024-02-19 18:38:05,572 - ==> Top1: 59.640    Top5: 85.620    Loss: 2.022

2024-02-19 18:38:05,585 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:38:05,585 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:38:05,644 - 

2024-02-19 18:38:05,645 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:38:13,124 - Epoch: [230][  100/  500]    Overall Loss 0.180323    Objective Loss 0.180323                                        LR 0.000063    Time 0.074739    
2024-02-19 18:38:19,961 - Epoch: [230][  200/  500]    Overall Loss 0.180413    Objective Loss 0.180413                                        LR 0.000063    Time 0.071540    
2024-02-19 18:38:26,779 - Epoch: [230][  300/  500]    Overall Loss 0.179918    Objective Loss 0.179918                                        LR 0.000063    Time 0.070408    
2024-02-19 18:38:33,620 - Epoch: [230][  400/  500]    Overall Loss 0.180724    Objective Loss 0.180724                                        LR 0.000063    Time 0.069898    
2024-02-19 18:38:40,552 - Epoch: [230][  500/  500]    Overall Loss 0.181403    Objective Loss 0.181403    Top1 96.500000    Top5 100.000000    LR 0.000063    Time 0.069775    
2024-02-19 18:38:40,678 - --- validate (epoch=230)-----------
2024-02-19 18:38:40,678 - 10000 samples (100 per mini-batch)
2024-02-19 18:38:43,480 - Epoch: [230][  100/  100]    Loss 2.015500    Top1 59.850000    Top5 85.530000    
2024-02-19 18:38:43,590 - ==> Top1: 59.850    Top5: 85.530    Loss: 2.015

2024-02-19 18:38:43,602 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:38:43,602 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:38:43,664 - 

2024-02-19 18:38:43,664 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:38:50,993 - Epoch: [231][  100/  500]    Overall Loss 0.181237    Objective Loss 0.181237                                        LR 0.000063    Time 0.073237    
2024-02-19 18:38:57,862 - Epoch: [231][  200/  500]    Overall Loss 0.183115    Objective Loss 0.183115                                        LR 0.000063    Time 0.070945    
2024-02-19 18:39:04,706 - Epoch: [231][  300/  500]    Overall Loss 0.181559    Objective Loss 0.181559                                        LR 0.000063    Time 0.070098    
2024-02-19 18:39:11,598 - Epoch: [231][  400/  500]    Overall Loss 0.181791    Objective Loss 0.181791                                        LR 0.000063    Time 0.069794    
2024-02-19 18:39:18,687 - Epoch: [231][  500/  500]    Overall Loss 0.180699    Objective Loss 0.180699    Top1 98.000000    Top5 100.000000    LR 0.000063    Time 0.070005    
2024-02-19 18:39:18,801 - --- validate (epoch=231)-----------
2024-02-19 18:39:18,802 - 10000 samples (100 per mini-batch)
2024-02-19 18:39:21,605 - Epoch: [231][  100/  100]    Loss 2.013088    Top1 59.750000    Top5 85.350000    
2024-02-19 18:39:21,824 - ==> Top1: 59.750    Top5: 85.350    Loss: 2.013

2024-02-19 18:39:21,835 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:39:21,836 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:39:21,894 - 

2024-02-19 18:39:21,895 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:39:29,415 - Epoch: [232][  100/  500]    Overall Loss 0.186791    Objective Loss 0.186791                                        LR 0.000063    Time 0.075154    
2024-02-19 18:39:36,213 - Epoch: [232][  200/  500]    Overall Loss 0.183526    Objective Loss 0.183526                                        LR 0.000063    Time 0.071549    
2024-02-19 18:39:43,021 - Epoch: [232][  300/  500]    Overall Loss 0.182883    Objective Loss 0.182883                                        LR 0.000063    Time 0.070383    
2024-02-19 18:39:49,809 - Epoch: [232][  400/  500]    Overall Loss 0.183923    Objective Loss 0.183923                                        LR 0.000063    Time 0.069749    
2024-02-19 18:39:56,796 - Epoch: [232][  500/  500]    Overall Loss 0.185058    Objective Loss 0.185058    Top1 95.000000    Top5 100.000000    LR 0.000063    Time 0.069765    
2024-02-19 18:39:56,921 - --- validate (epoch=232)-----------
2024-02-19 18:39:56,921 - 10000 samples (100 per mini-batch)
2024-02-19 18:39:59,886 - Epoch: [232][  100/  100]    Loss 2.019557    Top1 59.750000    Top5 85.470000    
2024-02-19 18:39:59,998 - ==> Top1: 59.750    Top5: 85.470    Loss: 2.020

2024-02-19 18:40:00,009 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:40:00,010 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:40:00,070 - 

2024-02-19 18:40:00,071 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:40:07,361 - Epoch: [233][  100/  500]    Overall Loss 0.185760    Objective Loss 0.185760                                        LR 0.000063    Time 0.072852    
2024-02-19 18:40:14,300 - Epoch: [233][  200/  500]    Overall Loss 0.182757    Objective Loss 0.182757                                        LR 0.000063    Time 0.071104    
2024-02-19 18:40:21,251 - Epoch: [233][  300/  500]    Overall Loss 0.181651    Objective Loss 0.181651                                        LR 0.000063    Time 0.070562    
2024-02-19 18:40:28,190 - Epoch: [233][  400/  500]    Overall Loss 0.182432    Objective Loss 0.182432                                        LR 0.000063    Time 0.070259    
2024-02-19 18:40:35,186 - Epoch: [233][  500/  500]    Overall Loss 0.182722    Objective Loss 0.182722    Top1 95.000000    Top5 100.000000    LR 0.000063    Time 0.070192    
2024-02-19 18:40:35,306 - --- validate (epoch=233)-----------
2024-02-19 18:40:35,307 - 10000 samples (100 per mini-batch)
2024-02-19 18:40:38,173 - Epoch: [233][  100/  100]    Loss 2.019527    Top1 60.010000    Top5 85.580000    
2024-02-19 18:40:38,334 - ==> Top1: 60.010    Top5: 85.580    Loss: 2.020

2024-02-19 18:40:38,344 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:40:38,345 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:40:38,405 - 

2024-02-19 18:40:38,405 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:40:46,016 - Epoch: [234][  100/  500]    Overall Loss 0.173966    Objective Loss 0.173966                                        LR 0.000063    Time 0.076064    
2024-02-19 18:40:52,958 - Epoch: [234][  200/  500]    Overall Loss 0.179282    Objective Loss 0.179282                                        LR 0.000063    Time 0.072720    
2024-02-19 18:40:59,859 - Epoch: [234][  300/  500]    Overall Loss 0.180690    Objective Loss 0.180690                                        LR 0.000063    Time 0.071471    
2024-02-19 18:41:06,821 - Epoch: [234][  400/  500]    Overall Loss 0.182139    Objective Loss 0.182139                                        LR 0.000063    Time 0.070999    
2024-02-19 18:41:13,827 - Epoch: [234][  500/  500]    Overall Loss 0.181308    Objective Loss 0.181308    Top1 96.500000    Top5 100.000000    LR 0.000063    Time 0.070804    
2024-02-19 18:41:14,007 - --- validate (epoch=234)-----------
2024-02-19 18:41:14,008 - 10000 samples (100 per mini-batch)
2024-02-19 18:41:16,756 - Epoch: [234][  100/  100]    Loss 2.025528    Top1 59.910000    Top5 85.580000    
2024-02-19 18:41:16,869 - ==> Top1: 59.910    Top5: 85.580    Loss: 2.026

2024-02-19 18:41:16,880 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:41:16,881 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:41:16,942 - 

2024-02-19 18:41:16,942 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:41:24,434 - Epoch: [235][  100/  500]    Overall Loss 0.181025    Objective Loss 0.181025                                        LR 0.000063    Time 0.074872    
2024-02-19 18:41:31,458 - Epoch: [235][  200/  500]    Overall Loss 0.180723    Objective Loss 0.180723                                        LR 0.000063    Time 0.072536    
2024-02-19 18:41:38,467 - Epoch: [235][  300/  500]    Overall Loss 0.179428    Objective Loss 0.179428                                        LR 0.000063    Time 0.071709    
2024-02-19 18:41:45,501 - Epoch: [235][  400/  500]    Overall Loss 0.181773    Objective Loss 0.181773                                        LR 0.000063    Time 0.071358    
2024-02-19 18:41:52,531 - Epoch: [235][  500/  500]    Overall Loss 0.181660    Objective Loss 0.181660    Top1 94.000000    Top5 99.500000    LR 0.000063    Time 0.071139    
2024-02-19 18:41:52,665 - --- validate (epoch=235)-----------
2024-02-19 18:41:52,666 - 10000 samples (100 per mini-batch)
2024-02-19 18:41:55,603 - Epoch: [235][  100/  100]    Loss 2.015162    Top1 60.120000    Top5 85.620000    
2024-02-19 18:41:55,714 - ==> Top1: 60.120    Top5: 85.620    Loss: 2.015

2024-02-19 18:41:55,725 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:41:55,726 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:41:55,784 - 

2024-02-19 18:41:55,785 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:42:03,401 - Epoch: [236][  100/  500]    Overall Loss 0.179929    Objective Loss 0.179929                                        LR 0.000063    Time 0.076114    
2024-02-19 18:42:10,324 - Epoch: [236][  200/  500]    Overall Loss 0.183307    Objective Loss 0.183307                                        LR 0.000063    Time 0.072652    
2024-02-19 18:42:17,246 - Epoch: [236][  300/  500]    Overall Loss 0.180328    Objective Loss 0.180328                                        LR 0.000063    Time 0.071499    
2024-02-19 18:42:24,176 - Epoch: [236][  400/  500]    Overall Loss 0.179895    Objective Loss 0.179895                                        LR 0.000063    Time 0.070940    
2024-02-19 18:42:31,148 - Epoch: [236][  500/  500]    Overall Loss 0.180590    Objective Loss 0.180590    Top1 96.000000    Top5 100.000000    LR 0.000063    Time 0.070687    
2024-02-19 18:42:31,280 - --- validate (epoch=236)-----------
2024-02-19 18:42:31,281 - 10000 samples (100 per mini-batch)
2024-02-19 18:42:34,271 - Epoch: [236][  100/  100]    Loss 2.024616    Top1 59.990000    Top5 85.490000    
2024-02-19 18:42:34,366 - ==> Top1: 59.990    Top5: 85.490    Loss: 2.025

2024-02-19 18:42:34,371 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:42:34,372 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:42:34,425 - 

2024-02-19 18:42:34,425 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:42:41,773 - Epoch: [237][  100/  500]    Overall Loss 0.172822    Objective Loss 0.172822                                        LR 0.000063    Time 0.073430    
2024-02-19 18:42:48,681 - Epoch: [237][  200/  500]    Overall Loss 0.179009    Objective Loss 0.179009                                        LR 0.000063    Time 0.071232    
2024-02-19 18:42:55,623 - Epoch: [237][  300/  500]    Overall Loss 0.179426    Objective Loss 0.179426                                        LR 0.000063    Time 0.070618    
2024-02-19 18:43:02,544 - Epoch: [237][  400/  500]    Overall Loss 0.181027    Objective Loss 0.181027                                        LR 0.000063    Time 0.070256    
2024-02-19 18:43:09,489 - Epoch: [237][  500/  500]    Overall Loss 0.181439    Objective Loss 0.181439    Top1 95.500000    Top5 100.000000    LR 0.000063    Time 0.070088    
2024-02-19 18:43:09,632 - --- validate (epoch=237)-----------
2024-02-19 18:43:09,633 - 10000 samples (100 per mini-batch)
2024-02-19 18:43:12,698 - Epoch: [237][  100/  100]    Loss 2.018651    Top1 59.710000    Top5 85.470000    
2024-02-19 18:43:12,867 - ==> Top1: 59.710    Top5: 85.470    Loss: 2.019

2024-02-19 18:43:12,880 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:43:12,880 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:43:12,945 - 

2024-02-19 18:43:12,946 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:43:20,475 - Epoch: [238][  100/  500]    Overall Loss 0.168767    Objective Loss 0.168767                                        LR 0.000063    Time 0.075242    
2024-02-19 18:43:27,339 - Epoch: [238][  200/  500]    Overall Loss 0.172930    Objective Loss 0.172930                                        LR 0.000063    Time 0.071922    
2024-02-19 18:43:34,213 - Epoch: [238][  300/  500]    Overall Loss 0.176871    Objective Loss 0.176871                                        LR 0.000063    Time 0.070850    
2024-02-19 18:43:41,062 - Epoch: [238][  400/  500]    Overall Loss 0.178557    Objective Loss 0.178557                                        LR 0.000063    Time 0.070249    
2024-02-19 18:43:47,944 - Epoch: [238][  500/  500]    Overall Loss 0.179766    Objective Loss 0.179766    Top1 93.000000    Top5 100.000000    LR 0.000063    Time 0.069957    
2024-02-19 18:43:48,074 - --- validate (epoch=238)-----------
2024-02-19 18:43:48,075 - 10000 samples (100 per mini-batch)
2024-02-19 18:43:51,019 - Epoch: [238][  100/  100]    Loss 2.022039    Top1 60.170000    Top5 85.540000    
2024-02-19 18:43:51,154 - ==> Top1: 60.170    Top5: 85.540    Loss: 2.022

2024-02-19 18:43:51,159 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:43:51,159 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:43:51,215 - 

2024-02-19 18:43:51,215 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:43:58,622 - Epoch: [239][  100/  500]    Overall Loss 0.178845    Objective Loss 0.178845                                        LR 0.000063    Time 0.074017    
2024-02-19 18:44:05,582 - Epoch: [239][  200/  500]    Overall Loss 0.177487    Objective Loss 0.177487                                        LR 0.000063    Time 0.071791    
2024-02-19 18:44:12,530 - Epoch: [239][  300/  500]    Overall Loss 0.173485    Objective Loss 0.173485                                        LR 0.000063    Time 0.071005    
2024-02-19 18:44:19,475 - Epoch: [239][  400/  500]    Overall Loss 0.176284    Objective Loss 0.176284                                        LR 0.000063    Time 0.070607    
2024-02-19 18:44:26,478 - Epoch: [239][  500/  500]    Overall Loss 0.177914    Objective Loss 0.177914    Top1 96.500000    Top5 100.000000    LR 0.000063    Time 0.070484    
2024-02-19 18:44:26,608 - --- validate (epoch=239)-----------
2024-02-19 18:44:26,609 - 10000 samples (100 per mini-batch)
2024-02-19 18:44:29,375 - Epoch: [239][  100/  100]    Loss 2.026703    Top1 59.970000    Top5 85.470000    
2024-02-19 18:44:29,472 - ==> Top1: 59.970    Top5: 85.470    Loss: 2.027

2024-02-19 18:44:29,479 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:44:29,479 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:44:29,535 - 

2024-02-19 18:44:29,536 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:44:37,241 - Epoch: [240][  100/  500]    Overall Loss 0.183120    Objective Loss 0.183120                                        LR 0.000063    Time 0.077007    
2024-02-19 18:44:44,183 - Epoch: [240][  200/  500]    Overall Loss 0.181742    Objective Loss 0.181742                                        LR 0.000063    Time 0.073192    
2024-02-19 18:44:51,199 - Epoch: [240][  300/  500]    Overall Loss 0.181420    Objective Loss 0.181420                                        LR 0.000063    Time 0.072168    
2024-02-19 18:44:58,203 - Epoch: [240][  400/  500]    Overall Loss 0.181846    Objective Loss 0.181846                                        LR 0.000063    Time 0.071627    
2024-02-19 18:45:05,231 - Epoch: [240][  500/  500]    Overall Loss 0.182130    Objective Loss 0.182130    Top1 96.500000    Top5 100.000000    LR 0.000063    Time 0.071349    
2024-02-19 18:45:05,362 - --- validate (epoch=240)-----------
2024-02-19 18:45:05,363 - 10000 samples (100 per mini-batch)
2024-02-19 18:45:08,015 - Epoch: [240][  100/  100]    Loss 2.021136    Top1 60.050000    Top5 85.750000    
2024-02-19 18:45:08,108 - ==> Top1: 60.050    Top5: 85.750    Loss: 2.021

2024-02-19 18:45:08,118 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:45:08,118 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:45:08,167 - 

2024-02-19 18:45:08,167 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:45:15,399 - Epoch: [241][  100/  500]    Overall Loss 0.183255    Objective Loss 0.183255                                        LR 0.000063    Time 0.072270    
2024-02-19 18:45:22,423 - Epoch: [241][  200/  500]    Overall Loss 0.181417    Objective Loss 0.181417                                        LR 0.000063    Time 0.071236    
2024-02-19 18:45:29,435 - Epoch: [241][  300/  500]    Overall Loss 0.183122    Objective Loss 0.183122                                        LR 0.000063    Time 0.070852    
2024-02-19 18:45:36,442 - Epoch: [241][  400/  500]    Overall Loss 0.183774    Objective Loss 0.183774                                        LR 0.000063    Time 0.070647    
2024-02-19 18:45:43,455 - Epoch: [241][  500/  500]    Overall Loss 0.184458    Objective Loss 0.184458    Top1 92.500000    Top5 100.000000    LR 0.000063    Time 0.070535    
2024-02-19 18:45:43,645 - --- validate (epoch=241)-----------
2024-02-19 18:45:43,646 - 10000 samples (100 per mini-batch)
2024-02-19 18:45:46,590 - Epoch: [241][  100/  100]    Loss 2.018917    Top1 59.880000    Top5 85.720000    
2024-02-19 18:45:46,752 - ==> Top1: 59.880    Top5: 85.720    Loss: 2.019

2024-02-19 18:45:46,763 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:45:46,764 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:45:46,824 - 

2024-02-19 18:45:46,824 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:45:54,351 - Epoch: [242][  100/  500]    Overall Loss 0.176393    Objective Loss 0.176393                                        LR 0.000063    Time 0.075216    
2024-02-19 18:46:01,333 - Epoch: [242][  200/  500]    Overall Loss 0.175349    Objective Loss 0.175349                                        LR 0.000063    Time 0.072502    
2024-02-19 18:46:08,307 - Epoch: [242][  300/  500]    Overall Loss 0.174968    Objective Loss 0.174968                                        LR 0.000063    Time 0.071567    
2024-02-19 18:46:15,307 - Epoch: [242][  400/  500]    Overall Loss 0.176507    Objective Loss 0.176507                                        LR 0.000063    Time 0.071166    
2024-02-19 18:46:22,329 - Epoch: [242][  500/  500]    Overall Loss 0.177541    Objective Loss 0.177541    Top1 93.500000    Top5 100.000000    LR 0.000063    Time 0.070969    
2024-02-19 18:46:22,551 - --- validate (epoch=242)-----------
2024-02-19 18:46:22,551 - 10000 samples (100 per mini-batch)
2024-02-19 18:46:25,403 - Epoch: [242][  100/  100]    Loss 2.016718    Top1 59.930000    Top5 85.760000    
2024-02-19 18:46:25,516 - ==> Top1: 59.930    Top5: 85.760    Loss: 2.017

2024-02-19 18:46:25,737 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:46:25,738 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:46:25,790 - 

2024-02-19 18:46:25,790 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:46:33,326 - Epoch: [243][  100/  500]    Overall Loss 0.173436    Objective Loss 0.173436                                        LR 0.000063    Time 0.075308    
2024-02-19 18:46:40,306 - Epoch: [243][  200/  500]    Overall Loss 0.176525    Objective Loss 0.176525                                        LR 0.000063    Time 0.072534    
2024-02-19 18:46:47,279 - Epoch: [243][  300/  500]    Overall Loss 0.178981    Objective Loss 0.178981                                        LR 0.000063    Time 0.071586    
2024-02-19 18:46:54,250 - Epoch: [243][  400/  500]    Overall Loss 0.179571    Objective Loss 0.179571                                        LR 0.000063    Time 0.071108    
2024-02-19 18:47:01,275 - Epoch: [243][  500/  500]    Overall Loss 0.179307    Objective Loss 0.179307    Top1 94.000000    Top5 100.000000    LR 0.000063    Time 0.070929    
2024-02-19 18:47:01,463 - --- validate (epoch=243)-----------
2024-02-19 18:47:01,463 - 10000 samples (100 per mini-batch)
2024-02-19 18:47:04,338 - Epoch: [243][  100/  100]    Loss 2.024737    Top1 59.870000    Top5 85.590000    
2024-02-19 18:47:04,432 - ==> Top1: 59.870    Top5: 85.590    Loss: 2.025

2024-02-19 18:47:04,442 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:47:04,442 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:47:04,493 - 

2024-02-19 18:47:04,493 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:47:11,814 - Epoch: [244][  100/  500]    Overall Loss 0.172563    Objective Loss 0.172563                                        LR 0.000063    Time 0.073167    
2024-02-19 18:47:18,815 - Epoch: [244][  200/  500]    Overall Loss 0.176193    Objective Loss 0.176193                                        LR 0.000063    Time 0.071565    
2024-02-19 18:47:25,765 - Epoch: [244][  300/  500]    Overall Loss 0.176312    Objective Loss 0.176312                                        LR 0.000063    Time 0.070865    
2024-02-19 18:47:32,731 - Epoch: [244][  400/  500]    Overall Loss 0.178919    Objective Loss 0.178919                                        LR 0.000063    Time 0.070554    
2024-02-19 18:47:39,760 - Epoch: [244][  500/  500]    Overall Loss 0.177149    Objective Loss 0.177149    Top1 96.000000    Top5 100.000000    LR 0.000063    Time 0.070493    
2024-02-19 18:47:39,899 - --- validate (epoch=244)-----------
2024-02-19 18:47:39,900 - 10000 samples (100 per mini-batch)
2024-02-19 18:47:43,016 - Epoch: [244][  100/  100]    Loss 2.013264    Top1 59.870000    Top5 85.660000    
2024-02-19 18:47:43,194 - ==> Top1: 59.870    Top5: 85.660    Loss: 2.013

2024-02-19 18:47:43,204 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:47:43,205 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:47:43,266 - 

2024-02-19 18:47:43,266 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:47:50,636 - Epoch: [245][  100/  500]    Overall Loss 0.173880    Objective Loss 0.173880                                        LR 0.000063    Time 0.073652    
2024-02-19 18:47:57,541 - Epoch: [245][  200/  500]    Overall Loss 0.177394    Objective Loss 0.177394                                        LR 0.000063    Time 0.071328    
2024-02-19 18:48:04,441 - Epoch: [245][  300/  500]    Overall Loss 0.177307    Objective Loss 0.177307                                        LR 0.000063    Time 0.070541    
2024-02-19 18:48:11,405 - Epoch: [245][  400/  500]    Overall Loss 0.177693    Objective Loss 0.177693                                        LR 0.000063    Time 0.070306    
2024-02-19 18:48:18,384 - Epoch: [245][  500/  500]    Overall Loss 0.177610    Objective Loss 0.177610    Top1 96.000000    Top5 100.000000    LR 0.000063    Time 0.070194    
2024-02-19 18:48:18,522 - --- validate (epoch=245)-----------
2024-02-19 18:48:18,522 - 10000 samples (100 per mini-batch)
2024-02-19 18:48:21,371 - Epoch: [245][  100/  100]    Loss 2.020326    Top1 59.700000    Top5 85.690000    
2024-02-19 18:48:21,472 - ==> Top1: 59.700    Top5: 85.690    Loss: 2.020

2024-02-19 18:48:21,483 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:48:21,483 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:48:21,532 - 

2024-02-19 18:48:21,532 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:48:28,947 - Epoch: [246][  100/  500]    Overall Loss 0.175531    Objective Loss 0.175531                                        LR 0.000063    Time 0.074103    
2024-02-19 18:48:35,907 - Epoch: [246][  200/  500]    Overall Loss 0.178885    Objective Loss 0.178885                                        LR 0.000063    Time 0.071830    
2024-02-19 18:48:42,872 - Epoch: [246][  300/  500]    Overall Loss 0.179557    Objective Loss 0.179557                                        LR 0.000063    Time 0.071093    
2024-02-19 18:48:49,841 - Epoch: [246][  400/  500]    Overall Loss 0.179567    Objective Loss 0.179567                                        LR 0.000063    Time 0.070730    
2024-02-19 18:48:56,839 - Epoch: [246][  500/  500]    Overall Loss 0.180420    Objective Loss 0.180420    Top1 95.000000    Top5 100.000000    LR 0.000063    Time 0.070574    
2024-02-19 18:48:56,969 - --- validate (epoch=246)-----------
2024-02-19 18:48:56,969 - 10000 samples (100 per mini-batch)
2024-02-19 18:48:59,815 - Epoch: [246][  100/  100]    Loss 2.028217    Top1 59.660000    Top5 85.530000    
2024-02-19 18:48:59,972 - ==> Top1: 59.660    Top5: 85.530    Loss: 2.028

2024-02-19 18:48:59,984 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:48:59,984 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:49:00,053 - 

2024-02-19 18:49:00,053 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:49:07,406 - Epoch: [247][  100/  500]    Overall Loss 0.170767    Objective Loss 0.170767                                        LR 0.000063    Time 0.073483    
2024-02-19 18:49:14,399 - Epoch: [247][  200/  500]    Overall Loss 0.171931    Objective Loss 0.171931                                        LR 0.000063    Time 0.071683    
2024-02-19 18:49:21,476 - Epoch: [247][  300/  500]    Overall Loss 0.177160    Objective Loss 0.177160                                        LR 0.000063    Time 0.071367    
2024-02-19 18:49:28,583 - Epoch: [247][  400/  500]    Overall Loss 0.179107    Objective Loss 0.179107                                        LR 0.000063    Time 0.071283    
2024-02-19 18:49:35,665 - Epoch: [247][  500/  500]    Overall Loss 0.180049    Objective Loss 0.180049    Top1 96.500000    Top5 100.000000    LR 0.000063    Time 0.071184    
2024-02-19 18:49:35,813 - --- validate (epoch=247)-----------
2024-02-19 18:49:35,813 - 10000 samples (100 per mini-batch)
2024-02-19 18:49:38,717 - Epoch: [247][  100/  100]    Loss 2.032990    Top1 59.610000    Top5 85.530000    
2024-02-19 18:49:38,826 - ==> Top1: 59.610    Top5: 85.530    Loss: 2.033

2024-02-19 18:49:38,833 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:49:38,833 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:49:38,891 - 

2024-02-19 18:49:38,891 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:49:46,522 - Epoch: [248][  100/  500]    Overall Loss 0.174625    Objective Loss 0.174625                                        LR 0.000063    Time 0.076256    
2024-02-19 18:49:53,412 - Epoch: [248][  200/  500]    Overall Loss 0.177673    Objective Loss 0.177673                                        LR 0.000063    Time 0.072560    
2024-02-19 18:50:00,305 - Epoch: [248][  300/  500]    Overall Loss 0.180773    Objective Loss 0.180773                                        LR 0.000063    Time 0.071337    
2024-02-19 18:50:07,196 - Epoch: [248][  400/  500]    Overall Loss 0.180234    Objective Loss 0.180234                                        LR 0.000063    Time 0.070721    
2024-02-19 18:50:14,138 - Epoch: [248][  500/  500]    Overall Loss 0.180992    Objective Loss 0.180992    Top1 96.500000    Top5 100.000000    LR 0.000063    Time 0.070453    
2024-02-19 18:50:14,273 - --- validate (epoch=248)-----------
2024-02-19 18:50:14,273 - 10000 samples (100 per mini-batch)
2024-02-19 18:50:17,188 - Epoch: [248][  100/  100]    Loss 2.027722    Top1 59.860000    Top5 85.580000    
2024-02-19 18:50:17,339 - ==> Top1: 59.860    Top5: 85.580    Loss: 2.028

2024-02-19 18:50:17,351 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:50:17,352 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:50:17,412 - 

2024-02-19 18:50:17,412 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:50:24,852 - Epoch: [249][  100/  500]    Overall Loss 0.167294    Objective Loss 0.167294                                        LR 0.000063    Time 0.074348    
2024-02-19 18:50:31,878 - Epoch: [249][  200/  500]    Overall Loss 0.169717    Objective Loss 0.169717                                        LR 0.000063    Time 0.072282    
2024-02-19 18:50:38,776 - Epoch: [249][  300/  500]    Overall Loss 0.171149    Objective Loss 0.171149                                        LR 0.000063    Time 0.071170    
2024-02-19 18:50:45,691 - Epoch: [249][  400/  500]    Overall Loss 0.173507    Objective Loss 0.173507                                        LR 0.000063    Time 0.070657    
2024-02-19 18:50:52,640 - Epoch: [249][  500/  500]    Overall Loss 0.174683    Objective Loss 0.174683    Top1 94.500000    Top5 99.500000    LR 0.000063    Time 0.070416    
2024-02-19 18:50:52,762 - --- validate (epoch=249)-----------
2024-02-19 18:50:52,763 - 10000 samples (100 per mini-batch)
2024-02-19 18:50:55,639 - Epoch: [249][  100/  100]    Loss 2.046235    Top1 59.720000    Top5 85.490000    
2024-02-19 18:50:55,781 - ==> Top1: 59.720    Top5: 85.490    Loss: 2.046

2024-02-19 18:50:55,792 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:50:55,792 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:50:55,853 - 

2024-02-19 18:50:55,853 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:51:03,491 - Epoch: [250][  100/  500]    Overall Loss 0.168346    Objective Loss 0.168346                                        LR 0.000031    Time 0.076329    
2024-02-19 18:51:10,491 - Epoch: [250][  200/  500]    Overall Loss 0.175370    Objective Loss 0.175370                                        LR 0.000031    Time 0.073144    
2024-02-19 18:51:17,433 - Epoch: [250][  300/  500]    Overall Loss 0.173718    Objective Loss 0.173718                                        LR 0.000031    Time 0.071889    
2024-02-19 18:51:24,408 - Epoch: [250][  400/  500]    Overall Loss 0.173761    Objective Loss 0.173761                                        LR 0.000031    Time 0.071345    
2024-02-19 18:51:31,399 - Epoch: [250][  500/  500]    Overall Loss 0.173663    Objective Loss 0.173663    Top1 96.500000    Top5 100.000000    LR 0.000031    Time 0.071050    
2024-02-19 18:51:31,508 - --- validate (epoch=250)-----------
2024-02-19 18:51:31,509 - 10000 samples (100 per mini-batch)
2024-02-19 18:51:34,370 - Epoch: [250][  100/  100]    Loss 2.031856    Top1 59.690000    Top5 85.590000    
2024-02-19 18:51:34,483 - ==> Top1: 59.690    Top5: 85.590    Loss: 2.032

2024-02-19 18:51:34,495 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:51:34,495 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:51:34,555 - 

2024-02-19 18:51:34,556 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:51:42,018 - Epoch: [251][  100/  500]    Overall Loss 0.169299    Objective Loss 0.169299                                        LR 0.000031    Time 0.074568    
2024-02-19 18:51:49,009 - Epoch: [251][  200/  500]    Overall Loss 0.168054    Objective Loss 0.168054                                        LR 0.000031    Time 0.072220    
2024-02-19 18:51:56,031 - Epoch: [251][  300/  500]    Overall Loss 0.168209    Objective Loss 0.168209                                        LR 0.000031    Time 0.071541    
2024-02-19 18:52:03,010 - Epoch: [251][  400/  500]    Overall Loss 0.167970    Objective Loss 0.167970                                        LR 0.000031    Time 0.071093    
2024-02-19 18:52:10,015 - Epoch: [251][  500/  500]    Overall Loss 0.168109    Objective Loss 0.168109    Top1 93.500000    Top5 100.000000    LR 0.000031    Time 0.070877    
2024-02-19 18:52:10,178 - --- validate (epoch=251)-----------
2024-02-19 18:52:10,179 - 10000 samples (100 per mini-batch)
2024-02-19 18:52:13,080 - Epoch: [251][  100/  100]    Loss 2.023627    Top1 59.910000    Top5 85.550000    
2024-02-19 18:52:13,216 - ==> Top1: 59.910    Top5: 85.550    Loss: 2.024

2024-02-19 18:52:13,227 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:52:13,227 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:52:13,287 - 

2024-02-19 18:52:13,287 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:52:20,974 - Epoch: [252][  100/  500]    Overall Loss 0.165912    Objective Loss 0.165912                                        LR 0.000031    Time 0.076822    
2024-02-19 18:52:27,965 - Epoch: [252][  200/  500]    Overall Loss 0.167648    Objective Loss 0.167648                                        LR 0.000031    Time 0.073343    
2024-02-19 18:52:34,956 - Epoch: [252][  300/  500]    Overall Loss 0.168355    Objective Loss 0.168355                                        LR 0.000031    Time 0.072186    
2024-02-19 18:52:41,868 - Epoch: [252][  400/  500]    Overall Loss 0.170537    Objective Loss 0.170537                                        LR 0.000031    Time 0.071410    
2024-02-19 18:52:48,791 - Epoch: [252][  500/  500]    Overall Loss 0.169941    Objective Loss 0.169941    Top1 96.000000    Top5 100.000000    LR 0.000031    Time 0.070967    
2024-02-19 18:52:48,972 - --- validate (epoch=252)-----------
2024-02-19 18:52:48,973 - 10000 samples (100 per mini-batch)
2024-02-19 18:52:51,744 - Epoch: [252][  100/  100]    Loss 2.025589    Top1 59.990000    Top5 85.750000    
2024-02-19 18:52:51,894 - ==> Top1: 59.990    Top5: 85.750    Loss: 2.026

2024-02-19 18:52:51,905 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:52:51,906 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:52:51,965 - 

2024-02-19 18:52:51,965 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:52:59,332 - Epoch: [253][  100/  500]    Overall Loss 0.165310    Objective Loss 0.165310                                        LR 0.000031    Time 0.073613    
2024-02-19 18:53:06,185 - Epoch: [253][  200/  500]    Overall Loss 0.166437    Objective Loss 0.166437                                        LR 0.000031    Time 0.071054    
2024-02-19 18:53:13,140 - Epoch: [253][  300/  500]    Overall Loss 0.167005    Objective Loss 0.167005                                        LR 0.000031    Time 0.070540    
2024-02-19 18:53:20,084 - Epoch: [253][  400/  500]    Overall Loss 0.167179    Objective Loss 0.167179                                        LR 0.000031    Time 0.070257    
2024-02-19 18:53:27,062 - Epoch: [253][  500/  500]    Overall Loss 0.166291    Objective Loss 0.166291    Top1 98.000000    Top5 100.000000    LR 0.000031    Time 0.070153    
2024-02-19 18:53:27,193 - --- validate (epoch=253)-----------
2024-02-19 18:53:27,193 - 10000 samples (100 per mini-batch)
2024-02-19 18:53:30,042 - Epoch: [253][  100/  100]    Loss 2.025537    Top1 59.930000    Top5 85.630000    
2024-02-19 18:53:30,154 - ==> Top1: 59.930    Top5: 85.630    Loss: 2.026

2024-02-19 18:53:30,166 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:53:30,166 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:53:30,227 - 

2024-02-19 18:53:30,227 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:53:37,901 - Epoch: [254][  100/  500]    Overall Loss 0.165993    Objective Loss 0.165993                                        LR 0.000031    Time 0.076683    
2024-02-19 18:53:44,820 - Epoch: [254][  200/  500]    Overall Loss 0.166064    Objective Loss 0.166064                                        LR 0.000031    Time 0.072915    
2024-02-19 18:53:51,735 - Epoch: [254][  300/  500]    Overall Loss 0.166029    Objective Loss 0.166029                                        LR 0.000031    Time 0.071649    
2024-02-19 18:53:58,646 - Epoch: [254][  400/  500]    Overall Loss 0.167748    Objective Loss 0.167748                                        LR 0.000031    Time 0.071005    
2024-02-19 18:54:05,500 - Epoch: [254][  500/  500]    Overall Loss 0.169170    Objective Loss 0.169170    Top1 96.000000    Top5 100.000000    LR 0.000031    Time 0.070505    
2024-02-19 18:54:05,622 - --- validate (epoch=254)-----------
2024-02-19 18:54:05,623 - 10000 samples (100 per mini-batch)
2024-02-19 18:54:08,359 - Epoch: [254][  100/  100]    Loss 2.022389    Top1 60.120000    Top5 85.610000    
2024-02-19 18:54:08,508 - ==> Top1: 60.120    Top5: 85.610    Loss: 2.022

2024-02-19 18:54:08,520 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:54:08,520 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:54:08,578 - 

2024-02-19 18:54:08,578 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:54:15,976 - Epoch: [255][  100/  500]    Overall Loss 0.169605    Objective Loss 0.169605                                        LR 0.000031    Time 0.073927    
2024-02-19 18:54:22,965 - Epoch: [255][  200/  500]    Overall Loss 0.171360    Objective Loss 0.171360                                        LR 0.000031    Time 0.071889    
2024-02-19 18:54:29,936 - Epoch: [255][  300/  500]    Overall Loss 0.172574    Objective Loss 0.172574                                        LR 0.000031    Time 0.071150    
2024-02-19 18:54:36,842 - Epoch: [255][  400/  500]    Overall Loss 0.170755    Objective Loss 0.170755                                        LR 0.000031    Time 0.070617    
2024-02-19 18:54:43,795 - Epoch: [255][  500/  500]    Overall Loss 0.169089    Objective Loss 0.169089    Top1 94.500000    Top5 99.500000    LR 0.000031    Time 0.070392    
2024-02-19 18:54:43,936 - --- validate (epoch=255)-----------
2024-02-19 18:54:43,937 - 10000 samples (100 per mini-batch)
2024-02-19 18:54:46,828 - Epoch: [255][  100/  100]    Loss 2.026589    Top1 60.210000    Top5 85.620000    
2024-02-19 18:54:46,993 - ==> Top1: 60.210    Top5: 85.620    Loss: 2.027

2024-02-19 18:54:47,004 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:54:47,004 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:54:47,063 - 

2024-02-19 18:54:47,064 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:54:54,490 - Epoch: [256][  100/  500]    Overall Loss 0.161098    Objective Loss 0.161098                                        LR 0.000031    Time 0.074215    
2024-02-19 18:55:01,424 - Epoch: [256][  200/  500]    Overall Loss 0.164900    Objective Loss 0.164900                                        LR 0.000031    Time 0.071757    
2024-02-19 18:55:08,388 - Epoch: [256][  300/  500]    Overall Loss 0.166779    Objective Loss 0.166779                                        LR 0.000031    Time 0.071039    
2024-02-19 18:55:15,308 - Epoch: [256][  400/  500]    Overall Loss 0.166261    Objective Loss 0.166261                                        LR 0.000031    Time 0.070571    
2024-02-19 18:55:22,254 - Epoch: [256][  500/  500]    Overall Loss 0.166155    Objective Loss 0.166155    Top1 95.500000    Top5 100.000000    LR 0.000031    Time 0.070341    
2024-02-19 18:55:22,379 - --- validate (epoch=256)-----------
2024-02-19 18:55:22,379 - 10000 samples (100 per mini-batch)
2024-02-19 18:55:25,498 - Epoch: [256][  100/  100]    Loss 2.036793    Top1 59.880000    Top5 85.550000    
2024-02-19 18:55:25,645 - ==> Top1: 59.880    Top5: 85.550    Loss: 2.037

2024-02-19 18:55:25,656 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:55:25,656 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:55:25,716 - 

2024-02-19 18:55:25,716 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:55:33,087 - Epoch: [257][  100/  500]    Overall Loss 0.162831    Objective Loss 0.162831                                        LR 0.000031    Time 0.073661    
2024-02-19 18:55:39,983 - Epoch: [257][  200/  500]    Overall Loss 0.163210    Objective Loss 0.163210                                        LR 0.000031    Time 0.071290    
2024-02-19 18:55:46,899 - Epoch: [257][  300/  500]    Overall Loss 0.164150    Objective Loss 0.164150                                        LR 0.000031    Time 0.070568    
2024-02-19 18:55:53,764 - Epoch: [257][  400/  500]    Overall Loss 0.166307    Objective Loss 0.166307                                        LR 0.000031    Time 0.070079    
2024-02-19 18:56:00,671 - Epoch: [257][  500/  500]    Overall Loss 0.166958    Objective Loss 0.166958    Top1 95.500000    Top5 100.000000    LR 0.000031    Time 0.069869    
2024-02-19 18:56:00,782 - --- validate (epoch=257)-----------
2024-02-19 18:56:00,782 - 10000 samples (100 per mini-batch)
2024-02-19 18:56:03,616 - Epoch: [257][  100/  100]    Loss 2.033308    Top1 59.890000    Top5 85.800000    
2024-02-19 18:56:03,733 - ==> Top1: 59.890    Top5: 85.800    Loss: 2.033

2024-02-19 18:56:03,745 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:56:03,745 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:56:03,806 - 

2024-02-19 18:56:03,806 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:56:11,196 - Epoch: [258][  100/  500]    Overall Loss 0.163757    Objective Loss 0.163757                                        LR 0.000031    Time 0.073847    
2024-02-19 18:56:18,120 - Epoch: [258][  200/  500]    Overall Loss 0.165138    Objective Loss 0.165138                                        LR 0.000031    Time 0.071527    
2024-02-19 18:56:25,077 - Epoch: [258][  300/  500]    Overall Loss 0.163616    Objective Loss 0.163616                                        LR 0.000031    Time 0.070862    
2024-02-19 18:56:31,983 - Epoch: [258][  400/  500]    Overall Loss 0.163830    Objective Loss 0.163830                                        LR 0.000031    Time 0.070404    
2024-02-19 18:56:38,916 - Epoch: [258][  500/  500]    Overall Loss 0.165985    Objective Loss 0.165985    Top1 98.000000    Top5 100.000000    LR 0.000031    Time 0.070181    
2024-02-19 18:56:39,089 - --- validate (epoch=258)-----------
2024-02-19 18:56:39,090 - 10000 samples (100 per mini-batch)
2024-02-19 18:56:42,099 - Epoch: [258][  100/  100]    Loss 2.038329    Top1 59.770000    Top5 85.550000    
2024-02-19 18:56:42,218 - ==> Top1: 59.770    Top5: 85.550    Loss: 2.038

2024-02-19 18:56:42,229 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:56:42,229 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:56:42,287 - 

2024-02-19 18:56:42,287 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:56:49,565 - Epoch: [259][  100/  500]    Overall Loss 0.157689    Objective Loss 0.157689                                        LR 0.000031    Time 0.072735    
2024-02-19 18:56:56,374 - Epoch: [259][  200/  500]    Overall Loss 0.163972    Objective Loss 0.163972                                        LR 0.000031    Time 0.070392    
2024-02-19 18:57:03,211 - Epoch: [259][  300/  500]    Overall Loss 0.163723    Objective Loss 0.163723                                        LR 0.000031    Time 0.069707    
2024-02-19 18:57:10,219 - Epoch: [259][  400/  500]    Overall Loss 0.164960    Objective Loss 0.164960                                        LR 0.000031    Time 0.069791    
2024-02-19 18:57:17,124 - Epoch: [259][  500/  500]    Overall Loss 0.165225    Objective Loss 0.165225    Top1 97.000000    Top5 100.000000    LR 0.000031    Time 0.069635    
2024-02-19 18:57:17,322 - --- validate (epoch=259)-----------
2024-02-19 18:57:17,323 - 10000 samples (100 per mini-batch)
2024-02-19 18:57:20,074 - Epoch: [259][  100/  100]    Loss 2.026561    Top1 60.130000    Top5 85.600000    
2024-02-19 18:57:20,176 - ==> Top1: 60.130    Top5: 85.600    Loss: 2.027

2024-02-19 18:57:20,187 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:57:20,187 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:57:20,250 - 

2024-02-19 18:57:20,250 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:57:27,585 - Epoch: [260][  100/  500]    Overall Loss 0.170099    Objective Loss 0.170099                                        LR 0.000031    Time 0.073297    
2024-02-19 18:57:34,464 - Epoch: [260][  200/  500]    Overall Loss 0.166541    Objective Loss 0.166541                                        LR 0.000031    Time 0.071030    
2024-02-19 18:57:41,341 - Epoch: [260][  300/  500]    Overall Loss 0.168312    Objective Loss 0.168312                                        LR 0.000031    Time 0.070263    
2024-02-19 18:57:48,240 - Epoch: [260][  400/  500]    Overall Loss 0.168834    Objective Loss 0.168834                                        LR 0.000031    Time 0.069935    
2024-02-19 18:57:55,192 - Epoch: [260][  500/  500]    Overall Loss 0.166264    Objective Loss 0.166264    Top1 96.000000    Top5 100.000000    LR 0.000031    Time 0.069846    
2024-02-19 18:57:55,307 - --- validate (epoch=260)-----------
2024-02-19 18:57:55,308 - 10000 samples (100 per mini-batch)
2024-02-19 18:57:58,056 - Epoch: [260][  100/  100]    Loss 2.027102    Top1 59.960000    Top5 85.590000    
2024-02-19 18:57:58,182 - ==> Top1: 59.960    Top5: 85.590    Loss: 2.027

2024-02-19 18:57:58,193 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:57:58,194 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:57:58,253 - 

2024-02-19 18:57:58,253 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:58:05,576 - Epoch: [261][  100/  500]    Overall Loss 0.169877    Objective Loss 0.169877                                        LR 0.000031    Time 0.073179    
2024-02-19 18:58:12,444 - Epoch: [261][  200/  500]    Overall Loss 0.169982    Objective Loss 0.169982                                        LR 0.000031    Time 0.070912    
2024-02-19 18:58:19,292 - Epoch: [261][  300/  500]    Overall Loss 0.165824    Objective Loss 0.165824                                        LR 0.000031    Time 0.070087    
2024-02-19 18:58:26,227 - Epoch: [261][  400/  500]    Overall Loss 0.166379    Objective Loss 0.166379                                        LR 0.000031    Time 0.069895    
2024-02-19 18:58:33,310 - Epoch: [261][  500/  500]    Overall Loss 0.168029    Objective Loss 0.168029    Top1 94.000000    Top5 100.000000    LR 0.000031    Time 0.070074    
2024-02-19 18:58:33,530 - --- validate (epoch=261)-----------
2024-02-19 18:58:33,531 - 10000 samples (100 per mini-batch)
2024-02-19 18:58:36,354 - Epoch: [261][  100/  100]    Loss 2.037235    Top1 60.060000    Top5 85.490000    
2024-02-19 18:58:36,520 - ==> Top1: 60.060    Top5: 85.490    Loss: 2.037

2024-02-19 18:58:36,531 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:58:36,532 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:58:36,595 - 

2024-02-19 18:58:36,595 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:58:44,579 - Epoch: [262][  100/  500]    Overall Loss 0.162746    Objective Loss 0.162746                                        LR 0.000031    Time 0.079791    
2024-02-19 18:58:51,878 - Epoch: [262][  200/  500]    Overall Loss 0.162464    Objective Loss 0.162464                                        LR 0.000031    Time 0.076372    
2024-02-19 18:58:59,189 - Epoch: [262][  300/  500]    Overall Loss 0.163885    Objective Loss 0.163885                                        LR 0.000031    Time 0.075272    
2024-02-19 18:59:06,202 - Epoch: [262][  400/  500]    Overall Loss 0.165234    Objective Loss 0.165234                                        LR 0.000031    Time 0.073977    
2024-02-19 18:59:13,172 - Epoch: [262][  500/  500]    Overall Loss 0.166273    Objective Loss 0.166273    Top1 94.000000    Top5 100.000000    LR 0.000031    Time 0.073115    
2024-02-19 18:59:13,295 - --- validate (epoch=262)-----------
2024-02-19 18:59:13,296 - 10000 samples (100 per mini-batch)
2024-02-19 18:59:16,028 - Epoch: [262][  100/  100]    Loss 2.040442    Top1 59.920000    Top5 85.730000    
2024-02-19 18:59:16,142 - ==> Top1: 59.920    Top5: 85.730    Loss: 2.040

2024-02-19 18:59:16,147 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:59:16,148 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:59:16,206 - 

2024-02-19 18:59:16,206 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 18:59:23,933 - Epoch: [263][  100/  500]    Overall Loss 0.171695    Objective Loss 0.171695                                        LR 0.000031    Time 0.077216    
2024-02-19 18:59:31,273 - Epoch: [263][  200/  500]    Overall Loss 0.168445    Objective Loss 0.168445                                        LR 0.000031    Time 0.075288    
2024-02-19 18:59:38,578 - Epoch: [263][  300/  500]    Overall Loss 0.166609    Objective Loss 0.166609                                        LR 0.000031    Time 0.074529    
2024-02-19 18:59:45,675 - Epoch: [263][  400/  500]    Overall Loss 0.167964    Objective Loss 0.167964                                        LR 0.000031    Time 0.073632    
2024-02-19 18:59:52,753 - Epoch: [263][  500/  500]    Overall Loss 0.166868    Objective Loss 0.166868    Top1 96.500000    Top5 100.000000    LR 0.000031    Time 0.073053    
2024-02-19 18:59:52,935 - --- validate (epoch=263)-----------
2024-02-19 18:59:52,936 - 10000 samples (100 per mini-batch)
2024-02-19 18:59:55,835 - Epoch: [263][  100/  100]    Loss 2.032702    Top1 60.070000    Top5 85.580000    
2024-02-19 18:59:55,948 - ==> Top1: 60.070    Top5: 85.580    Loss: 2.033

2024-02-19 18:59:55,959 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 18:59:55,960 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 18:59:56,019 - 

2024-02-19 18:59:56,020 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:00:03,720 - Epoch: [264][  100/  500]    Overall Loss 0.160183    Objective Loss 0.160183                                        LR 0.000031    Time 0.076953    
2024-02-19 19:00:10,905 - Epoch: [264][  200/  500]    Overall Loss 0.161976    Objective Loss 0.161976                                        LR 0.000031    Time 0.074384    
2024-02-19 19:00:17,817 - Epoch: [264][  300/  500]    Overall Loss 0.163151    Objective Loss 0.163151                                        LR 0.000031    Time 0.072618    
2024-02-19 19:00:24,731 - Epoch: [264][  400/  500]    Overall Loss 0.163773    Objective Loss 0.163773                                        LR 0.000031    Time 0.071739    
2024-02-19 19:00:31,716 - Epoch: [264][  500/  500]    Overall Loss 0.163677    Objective Loss 0.163677    Top1 95.500000    Top5 100.000000    LR 0.000031    Time 0.071352    
2024-02-19 19:00:31,879 - --- validate (epoch=264)-----------
2024-02-19 19:00:31,880 - 10000 samples (100 per mini-batch)
2024-02-19 19:00:34,880 - Epoch: [264][  100/  100]    Loss 2.032108    Top1 60.010000    Top5 85.690000    
2024-02-19 19:00:34,997 - ==> Top1: 60.010    Top5: 85.690    Loss: 2.032

2024-02-19 19:00:35,008 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:00:35,009 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:00:35,068 - 

2024-02-19 19:00:35,069 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:00:42,487 - Epoch: [265][  100/  500]    Overall Loss 0.161509    Objective Loss 0.161509                                        LR 0.000031    Time 0.074132    
2024-02-19 19:00:49,368 - Epoch: [265][  200/  500]    Overall Loss 0.162110    Objective Loss 0.162110                                        LR 0.000031    Time 0.071453    
2024-02-19 19:00:56,222 - Epoch: [265][  300/  500]    Overall Loss 0.163578    Objective Loss 0.163578                                        LR 0.000031    Time 0.070470    
2024-02-19 19:01:03,124 - Epoch: [265][  400/  500]    Overall Loss 0.162607    Objective Loss 0.162607                                        LR 0.000031    Time 0.070097    
2024-02-19 19:01:10,197 - Epoch: [265][  500/  500]    Overall Loss 0.162571    Objective Loss 0.162571    Top1 96.500000    Top5 100.000000    LR 0.000031    Time 0.070217    
2024-02-19 19:01:10,337 - --- validate (epoch=265)-----------
2024-02-19 19:01:10,338 - 10000 samples (100 per mini-batch)
2024-02-19 19:01:13,255 - Epoch: [265][  100/  100]    Loss 2.034150    Top1 60.070000    Top5 85.540000    
2024-02-19 19:01:13,413 - ==> Top1: 60.070    Top5: 85.540    Loss: 2.034

2024-02-19 19:01:13,426 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:01:13,426 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:01:13,485 - 

2024-02-19 19:01:13,486 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:01:21,073 - Epoch: [266][  100/  500]    Overall Loss 0.164088    Objective Loss 0.164088                                        LR 0.000031    Time 0.075829    
2024-02-19 19:01:27,981 - Epoch: [266][  200/  500]    Overall Loss 0.160626    Objective Loss 0.160626                                        LR 0.000031    Time 0.072434    
2024-02-19 19:01:34,881 - Epoch: [266][  300/  500]    Overall Loss 0.163410    Objective Loss 0.163410                                        LR 0.000031    Time 0.071276    
2024-02-19 19:01:41,794 - Epoch: [266][  400/  500]    Overall Loss 0.165172    Objective Loss 0.165172                                        LR 0.000031    Time 0.070732    
2024-02-19 19:01:48,770 - Epoch: [266][  500/  500]    Overall Loss 0.166082    Objective Loss 0.166082    Top1 94.500000    Top5 99.500000    LR 0.000031    Time 0.070530    
2024-02-19 19:01:48,894 - --- validate (epoch=266)-----------
2024-02-19 19:01:48,895 - 10000 samples (100 per mini-batch)
2024-02-19 19:01:51,678 - Epoch: [266][  100/  100]    Loss 2.039566    Top1 59.940000    Top5 85.480000    
2024-02-19 19:01:51,794 - ==> Top1: 59.940    Top5: 85.480    Loss: 2.040

2024-02-19 19:01:51,807 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:01:51,807 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:01:51,867 - 

2024-02-19 19:01:51,867 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:01:59,286 - Epoch: [267][  100/  500]    Overall Loss 0.165599    Objective Loss 0.165599                                        LR 0.000031    Time 0.074140    
2024-02-19 19:02:06,219 - Epoch: [267][  200/  500]    Overall Loss 0.163765    Objective Loss 0.163765                                        LR 0.000031    Time 0.071718    
2024-02-19 19:02:13,131 - Epoch: [267][  300/  500]    Overall Loss 0.165322    Objective Loss 0.165322                                        LR 0.000031    Time 0.070840    
2024-02-19 19:02:20,055 - Epoch: [267][  400/  500]    Overall Loss 0.165137    Objective Loss 0.165137                                        LR 0.000031    Time 0.070429    
2024-02-19 19:02:27,047 - Epoch: [267][  500/  500]    Overall Loss 0.164831    Objective Loss 0.164831    Top1 97.500000    Top5 100.000000    LR 0.000031    Time 0.070320    
2024-02-19 19:02:27,147 - --- validate (epoch=267)-----------
2024-02-19 19:02:27,147 - 10000 samples (100 per mini-batch)
2024-02-19 19:02:29,937 - Epoch: [267][  100/  100]    Loss 2.034110    Top1 59.930000    Top5 85.540000    
2024-02-19 19:02:30,049 - ==> Top1: 59.930    Top5: 85.540    Loss: 2.034

2024-02-19 19:02:30,062 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:02:30,062 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:02:30,121 - 

2024-02-19 19:02:30,121 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:02:37,727 - Epoch: [268][  100/  500]    Overall Loss 0.164410    Objective Loss 0.164410                                        LR 0.000031    Time 0.076006    
2024-02-19 19:02:44,641 - Epoch: [268][  200/  500]    Overall Loss 0.162994    Objective Loss 0.162994                                        LR 0.000031    Time 0.072556    
2024-02-19 19:02:51,546 - Epoch: [268][  300/  500]    Overall Loss 0.163988    Objective Loss 0.163988                                        LR 0.000031    Time 0.071376    
2024-02-19 19:02:58,446 - Epoch: [268][  400/  500]    Overall Loss 0.162680    Objective Loss 0.162680                                        LR 0.000031    Time 0.070771    
2024-02-19 19:03:05,387 - Epoch: [268][  500/  500]    Overall Loss 0.163422    Objective Loss 0.163422    Top1 95.000000    Top5 100.000000    LR 0.000031    Time 0.070491    
2024-02-19 19:03:05,522 - --- validate (epoch=268)-----------
2024-02-19 19:03:05,523 - 10000 samples (100 per mini-batch)
2024-02-19 19:03:08,413 - Epoch: [268][  100/  100]    Loss 2.031871    Top1 60.140000    Top5 85.740000    
2024-02-19 19:03:08,540 - ==> Top1: 60.140    Top5: 85.740    Loss: 2.032

2024-02-19 19:03:08,552 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:03:08,552 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:03:08,612 - 

2024-02-19 19:03:08,613 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:03:16,062 - Epoch: [269][  100/  500]    Overall Loss 0.161506    Objective Loss 0.161506                                        LR 0.000031    Time 0.074445    
2024-02-19 19:03:23,028 - Epoch: [269][  200/  500]    Overall Loss 0.162545    Objective Loss 0.162545                                        LR 0.000031    Time 0.072030    
2024-02-19 19:03:30,009 - Epoch: [269][  300/  500]    Overall Loss 0.164455    Objective Loss 0.164455                                        LR 0.000031    Time 0.071277    
2024-02-19 19:03:36,970 - Epoch: [269][  400/  500]    Overall Loss 0.163858    Objective Loss 0.163858                                        LR 0.000031    Time 0.070851    
2024-02-19 19:03:44,005 - Epoch: [269][  500/  500]    Overall Loss 0.164579    Objective Loss 0.164579    Top1 96.000000    Top5 100.000000    LR 0.000031    Time 0.070743    
2024-02-19 19:03:44,131 - --- validate (epoch=269)-----------
2024-02-19 19:03:44,132 - 10000 samples (100 per mini-batch)
2024-02-19 19:03:47,099 - Epoch: [269][  100/  100]    Loss 2.032984    Top1 60.090000    Top5 85.560000    
2024-02-19 19:03:47,205 - ==> Top1: 60.090    Top5: 85.560    Loss: 2.033

2024-02-19 19:03:47,212 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:03:47,212 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:03:47,267 - 

2024-02-19 19:03:47,267 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:03:54,675 - Epoch: [270][  100/  500]    Overall Loss 0.161488    Objective Loss 0.161488                                        LR 0.000031    Time 0.074028    
2024-02-19 19:04:01,639 - Epoch: [270][  200/  500]    Overall Loss 0.163461    Objective Loss 0.163461                                        LR 0.000031    Time 0.071816    
2024-02-19 19:04:08,616 - Epoch: [270][  300/  500]    Overall Loss 0.164935    Objective Loss 0.164935                                        LR 0.000031    Time 0.071120    
2024-02-19 19:04:15,548 - Epoch: [270][  400/  500]    Overall Loss 0.165433    Objective Loss 0.165433                                        LR 0.000031    Time 0.070661    
2024-02-19 19:04:22,505 - Epoch: [270][  500/  500]    Overall Loss 0.164309    Objective Loss 0.164309    Top1 96.000000    Top5 99.500000    LR 0.000031    Time 0.070436    
2024-02-19 19:04:22,624 - --- validate (epoch=270)-----------
2024-02-19 19:04:22,625 - 10000 samples (100 per mini-batch)
2024-02-19 19:04:25,995 - Epoch: [270][  100/  100]    Loss 2.043544    Top1 59.820000    Top5 85.560000    
2024-02-19 19:04:26,114 - ==> Top1: 59.820    Top5: 85.560    Loss: 2.044

2024-02-19 19:04:26,125 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:04:26,125 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:04:26,183 - 

2024-02-19 19:04:26,184 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:04:33,601 - Epoch: [271][  100/  500]    Overall Loss 0.162846    Objective Loss 0.162846                                        LR 0.000031    Time 0.074126    
2024-02-19 19:04:40,537 - Epoch: [271][  200/  500]    Overall Loss 0.163603    Objective Loss 0.163603                                        LR 0.000031    Time 0.071725    
2024-02-19 19:04:47,478 - Epoch: [271][  300/  500]    Overall Loss 0.163273    Objective Loss 0.163273                                        LR 0.000031    Time 0.070940    
2024-02-19 19:04:54,408 - Epoch: [271][  400/  500]    Overall Loss 0.164507    Objective Loss 0.164507                                        LR 0.000031    Time 0.070521    
2024-02-19 19:05:01,358 - Epoch: [271][  500/  500]    Overall Loss 0.164048    Objective Loss 0.164048    Top1 95.000000    Top5 99.500000    LR 0.000031    Time 0.070310    
2024-02-19 19:05:01,459 - --- validate (epoch=271)-----------
2024-02-19 19:05:01,459 - 10000 samples (100 per mini-batch)
2024-02-19 19:05:04,388 - Epoch: [271][  100/  100]    Loss 2.040558    Top1 59.800000    Top5 85.620000    
2024-02-19 19:05:04,522 - ==> Top1: 59.800    Top5: 85.620    Loss: 2.041

2024-02-19 19:05:04,534 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:05:04,535 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:05:04,597 - 

2024-02-19 19:05:04,597 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:05:12,304 - Epoch: [272][  100/  500]    Overall Loss 0.163105    Objective Loss 0.163105                                        LR 0.000031    Time 0.077024    
2024-02-19 19:05:19,261 - Epoch: [272][  200/  500]    Overall Loss 0.158686    Objective Loss 0.158686                                        LR 0.000031    Time 0.073277    
2024-02-19 19:05:26,190 - Epoch: [272][  300/  500]    Overall Loss 0.159838    Objective Loss 0.159838                                        LR 0.000031    Time 0.071934    
2024-02-19 19:05:33,161 - Epoch: [272][  400/  500]    Overall Loss 0.161125    Objective Loss 0.161125                                        LR 0.000031    Time 0.071368    
2024-02-19 19:05:40,091 - Epoch: [272][  500/  500]    Overall Loss 0.161980    Objective Loss 0.161980    Top1 97.000000    Top5 100.000000    LR 0.000031    Time 0.070946    
2024-02-19 19:05:40,265 - --- validate (epoch=272)-----------
2024-02-19 19:05:40,266 - 10000 samples (100 per mini-batch)
2024-02-19 19:05:43,085 - Epoch: [272][  100/  100]    Loss 2.046465    Top1 59.910000    Top5 85.460000    
2024-02-19 19:05:43,270 - ==> Top1: 59.910    Top5: 85.460    Loss: 2.046

2024-02-19 19:05:43,281 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:05:43,282 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:05:43,342 - 

2024-02-19 19:05:43,343 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:05:50,785 - Epoch: [273][  100/  500]    Overall Loss 0.164491    Objective Loss 0.164491                                        LR 0.000031    Time 0.074369    
2024-02-19 19:05:57,690 - Epoch: [273][  200/  500]    Overall Loss 0.162965    Objective Loss 0.162965                                        LR 0.000031    Time 0.071694    
2024-02-19 19:06:04,596 - Epoch: [273][  300/  500]    Overall Loss 0.162980    Objective Loss 0.162980                                        LR 0.000031    Time 0.070803    
2024-02-19 19:06:11,498 - Epoch: [273][  400/  500]    Overall Loss 0.166473    Objective Loss 0.166473                                        LR 0.000031    Time 0.070347    
2024-02-19 19:06:18,430 - Epoch: [273][  500/  500]    Overall Loss 0.165309    Objective Loss 0.165309    Top1 96.500000    Top5 100.000000    LR 0.000031    Time 0.070135    
2024-02-19 19:06:18,643 - --- validate (epoch=273)-----------
2024-02-19 19:06:18,644 - 10000 samples (100 per mini-batch)
2024-02-19 19:06:21,512 - Epoch: [273][  100/  100]    Loss 2.048826    Top1 59.610000    Top5 85.490000    
2024-02-19 19:06:21,655 - ==> Top1: 59.610    Top5: 85.490    Loss: 2.049

2024-02-19 19:06:21,667 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:06:21,668 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:06:21,727 - 

2024-02-19 19:06:21,728 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:06:29,182 - Epoch: [274][  100/  500]    Overall Loss 0.163753    Objective Loss 0.163753                                        LR 0.000031    Time 0.074500    
2024-02-19 19:06:36,222 - Epoch: [274][  200/  500]    Overall Loss 0.160198    Objective Loss 0.160198                                        LR 0.000031    Time 0.072428    
2024-02-19 19:06:43,267 - Epoch: [274][  300/  500]    Overall Loss 0.162817    Objective Loss 0.162817                                        LR 0.000031    Time 0.071756    
2024-02-19 19:06:50,292 - Epoch: [274][  400/  500]    Overall Loss 0.162895    Objective Loss 0.162895                                        LR 0.000031    Time 0.071372    
2024-02-19 19:06:57,337 - Epoch: [274][  500/  500]    Overall Loss 0.163329    Objective Loss 0.163329    Top1 97.000000    Top5 100.000000    LR 0.000031    Time 0.071181    
2024-02-19 19:06:57,465 - --- validate (epoch=274)-----------
2024-02-19 19:06:57,466 - 10000 samples (100 per mini-batch)
2024-02-19 19:07:00,523 - Epoch: [274][  100/  100]    Loss 2.037717    Top1 60.120000    Top5 85.670000    
2024-02-19 19:07:00,695 - ==> Top1: 60.120    Top5: 85.670    Loss: 2.038

2024-02-19 19:07:00,707 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:07:00,708 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:07:00,770 - 

2024-02-19 19:07:00,771 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:07:08,241 - Epoch: [275][  100/  500]    Overall Loss 0.155955    Objective Loss 0.155955                                        LR 0.000031    Time 0.074652    
2024-02-19 19:07:15,278 - Epoch: [275][  200/  500]    Overall Loss 0.155214    Objective Loss 0.155214                                        LR 0.000031    Time 0.072497    
2024-02-19 19:07:22,308 - Epoch: [275][  300/  500]    Overall Loss 0.155276    Objective Loss 0.155276                                        LR 0.000031    Time 0.071750    
2024-02-19 19:07:29,280 - Epoch: [275][  400/  500]    Overall Loss 0.157284    Objective Loss 0.157284                                        LR 0.000031    Time 0.071234    
2024-02-19 19:07:36,252 - Epoch: [275][  500/  500]    Overall Loss 0.158695    Objective Loss 0.158695    Top1 97.000000    Top5 100.000000    LR 0.000031    Time 0.070925    
2024-02-19 19:07:36,382 - --- validate (epoch=275)-----------
2024-02-19 19:07:36,383 - 10000 samples (100 per mini-batch)
2024-02-19 19:07:39,108 - Epoch: [275][  100/  100]    Loss 2.043441    Top1 60.090000    Top5 85.540000    
2024-02-19 19:07:39,285 - ==> Top1: 60.090    Top5: 85.540    Loss: 2.043

2024-02-19 19:07:39,298 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:07:39,298 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:07:39,359 - 

2024-02-19 19:07:39,360 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:07:47,027 - Epoch: [276][  100/  500]    Overall Loss 0.162054    Objective Loss 0.162054                                        LR 0.000031    Time 0.076623    
2024-02-19 19:07:54,049 - Epoch: [276][  200/  500]    Overall Loss 0.161035    Objective Loss 0.161035                                        LR 0.000031    Time 0.073402    
2024-02-19 19:08:01,095 - Epoch: [276][  300/  500]    Overall Loss 0.161602    Objective Loss 0.161602                                        LR 0.000031    Time 0.072409    
2024-02-19 19:08:08,126 - Epoch: [276][  400/  500]    Overall Loss 0.162824    Objective Loss 0.162824                                        LR 0.000031    Time 0.071876    
2024-02-19 19:08:15,203 - Epoch: [276][  500/  500]    Overall Loss 0.163106    Objective Loss 0.163106    Top1 98.500000    Top5 100.000000    LR 0.000031    Time 0.071648    
2024-02-19 19:08:15,326 - --- validate (epoch=276)-----------
2024-02-19 19:08:15,327 - 10000 samples (100 per mini-batch)
2024-02-19 19:08:18,190 - Epoch: [276][  100/  100]    Loss 2.045171    Top1 59.740000    Top5 85.480000    
2024-02-19 19:08:18,369 - ==> Top1: 59.740    Top5: 85.480    Loss: 2.045

2024-02-19 19:08:18,380 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:08:18,380 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:08:18,439 - 

2024-02-19 19:08:18,440 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:08:25,838 - Epoch: [277][  100/  500]    Overall Loss 0.161903    Objective Loss 0.161903                                        LR 0.000031    Time 0.073933    
2024-02-19 19:08:32,741 - Epoch: [277][  200/  500]    Overall Loss 0.163900    Objective Loss 0.163900                                        LR 0.000031    Time 0.071464    
2024-02-19 19:08:39,646 - Epoch: [277][  300/  500]    Overall Loss 0.164419    Objective Loss 0.164419                                        LR 0.000031    Time 0.070647    
2024-02-19 19:08:46,572 - Epoch: [277][  400/  500]    Overall Loss 0.165939    Objective Loss 0.165939                                        LR 0.000031    Time 0.070292    
2024-02-19 19:08:53,516 - Epoch: [277][  500/  500]    Overall Loss 0.165522    Objective Loss 0.165522    Top1 98.500000    Top5 100.000000    LR 0.000031    Time 0.070114    
2024-02-19 19:08:53,646 - --- validate (epoch=277)-----------
2024-02-19 19:08:53,647 - 10000 samples (100 per mini-batch)
2024-02-19 19:08:56,464 - Epoch: [277][  100/  100]    Loss 2.042086    Top1 59.950000    Top5 85.620000    
2024-02-19 19:08:56,631 - ==> Top1: 59.950    Top5: 85.620    Loss: 2.042

2024-02-19 19:08:56,643 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:08:56,643 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:08:56,702 - 

2024-02-19 19:08:56,703 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:09:04,304 - Epoch: [278][  100/  500]    Overall Loss 0.167015    Objective Loss 0.167015                                        LR 0.000031    Time 0.075965    
2024-02-19 19:09:11,191 - Epoch: [278][  200/  500]    Overall Loss 0.165601    Objective Loss 0.165601                                        LR 0.000031    Time 0.072400    
2024-02-19 19:09:18,118 - Epoch: [278][  300/  500]    Overall Loss 0.162536    Objective Loss 0.162536                                        LR 0.000031    Time 0.071344    
2024-02-19 19:09:25,056 - Epoch: [278][  400/  500]    Overall Loss 0.162168    Objective Loss 0.162168                                        LR 0.000031    Time 0.070843    
2024-02-19 19:09:32,001 - Epoch: [278][  500/  500]    Overall Loss 0.161945    Objective Loss 0.161945    Top1 95.000000    Top5 100.000000    LR 0.000031    Time 0.070557    
2024-02-19 19:09:32,130 - --- validate (epoch=278)-----------
2024-02-19 19:09:32,131 - 10000 samples (100 per mini-batch)
2024-02-19 19:09:34,989 - Epoch: [278][  100/  100]    Loss 2.043813    Top1 60.050000    Top5 85.460000    
2024-02-19 19:09:35,103 - ==> Top1: 60.050    Top5: 85.460    Loss: 2.044

2024-02-19 19:09:35,115 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:09:35,115 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:09:35,173 - 

2024-02-19 19:09:35,174 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:09:42,543 - Epoch: [279][  100/  500]    Overall Loss 0.156125    Objective Loss 0.156125                                        LR 0.000031    Time 0.073649    
2024-02-19 19:09:49,556 - Epoch: [279][  200/  500]    Overall Loss 0.160811    Objective Loss 0.160811                                        LR 0.000031    Time 0.071867    
2024-02-19 19:09:56,482 - Epoch: [279][  300/  500]    Overall Loss 0.160835    Objective Loss 0.160835                                        LR 0.000031    Time 0.070986    
2024-02-19 19:10:03,452 - Epoch: [279][  400/  500]    Overall Loss 0.161339    Objective Loss 0.161339                                        LR 0.000031    Time 0.070655    
2024-02-19 19:10:10,452 - Epoch: [279][  500/  500]    Overall Loss 0.161239    Objective Loss 0.161239    Top1 99.500000    Top5 99.500000    LR 0.000031    Time 0.070517    
2024-02-19 19:10:10,574 - --- validate (epoch=279)-----------
2024-02-19 19:10:10,574 - 10000 samples (100 per mini-batch)
2024-02-19 19:10:13,499 - Epoch: [279][  100/  100]    Loss 2.039450    Top1 60.040000    Top5 85.680000    
2024-02-19 19:10:13,611 - ==> Top1: 60.040    Top5: 85.680    Loss: 2.039

2024-02-19 19:10:13,622 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:10:13,622 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:10:13,675 - 

2024-02-19 19:10:13,675 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:10:21,283 - Epoch: [280][  100/  500]    Overall Loss 0.164620    Objective Loss 0.164620                                        LR 0.000031    Time 0.076007    
2024-02-19 19:10:28,177 - Epoch: [280][  200/  500]    Overall Loss 0.161480    Objective Loss 0.161480                                        LR 0.000031    Time 0.072458    
2024-02-19 19:10:35,000 - Epoch: [280][  300/  500]    Overall Loss 0.161366    Objective Loss 0.161366                                        LR 0.000031    Time 0.071036    
2024-02-19 19:10:41,826 - Epoch: [280][  400/  500]    Overall Loss 0.161400    Objective Loss 0.161400                                        LR 0.000031    Time 0.070333    
2024-02-19 19:10:48,686 - Epoch: [280][  500/  500]    Overall Loss 0.161951    Objective Loss 0.161951    Top1 96.000000    Top5 100.000000    LR 0.000031    Time 0.069978    
2024-02-19 19:10:48,823 - --- validate (epoch=280)-----------
2024-02-19 19:10:48,824 - 10000 samples (100 per mini-batch)
2024-02-19 19:10:51,561 - Epoch: [280][  100/  100]    Loss 2.046613    Top1 59.840000    Top5 85.510000    
2024-02-19 19:10:51,653 - ==> Top1: 59.840    Top5: 85.510    Loss: 2.047

2024-02-19 19:10:51,664 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:10:51,664 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:10:51,717 - 

2024-02-19 19:10:51,718 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:10:59,084 - Epoch: [281][  100/  500]    Overall Loss 0.159117    Objective Loss 0.159117                                        LR 0.000031    Time 0.073595    
2024-02-19 19:11:05,988 - Epoch: [281][  200/  500]    Overall Loss 0.156117    Objective Loss 0.156117                                        LR 0.000031    Time 0.071298    
2024-02-19 19:11:12,845 - Epoch: [281][  300/  500]    Overall Loss 0.159060    Objective Loss 0.159060                                        LR 0.000031    Time 0.070375    
2024-02-19 19:11:19,726 - Epoch: [281][  400/  500]    Overall Loss 0.160602    Objective Loss 0.160602                                        LR 0.000031    Time 0.069976    
2024-02-19 19:11:26,639 - Epoch: [281][  500/  500]    Overall Loss 0.159300    Objective Loss 0.159300    Top1 96.000000    Top5 100.000000    LR 0.000031    Time 0.069799    
2024-02-19 19:11:26,879 - --- validate (epoch=281)-----------
2024-02-19 19:11:26,880 - 10000 samples (100 per mini-batch)
2024-02-19 19:11:29,646 - Epoch: [281][  100/  100]    Loss 2.045735    Top1 59.790000    Top5 85.580000    
2024-02-19 19:11:29,797 - ==> Top1: 59.790    Top5: 85.580    Loss: 2.046

2024-02-19 19:11:29,808 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:11:29,809 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:11:29,866 - 

2024-02-19 19:11:29,866 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:11:37,198 - Epoch: [282][  100/  500]    Overall Loss 0.155204    Objective Loss 0.155204                                        LR 0.000031    Time 0.073266    
2024-02-19 19:11:44,059 - Epoch: [282][  200/  500]    Overall Loss 0.158590    Objective Loss 0.158590                                        LR 0.000031    Time 0.070922    
2024-02-19 19:11:50,923 - Epoch: [282][  300/  500]    Overall Loss 0.157410    Objective Loss 0.157410                                        LR 0.000031    Time 0.070149    
2024-02-19 19:11:57,743 - Epoch: [282][  400/  500]    Overall Loss 0.160119    Objective Loss 0.160119                                        LR 0.000031    Time 0.069653    
2024-02-19 19:12:04,607 - Epoch: [282][  500/  500]    Overall Loss 0.159028    Objective Loss 0.159028    Top1 96.500000    Top5 100.000000    LR 0.000031    Time 0.069445    
2024-02-19 19:12:04,732 - --- validate (epoch=282)-----------
2024-02-19 19:12:04,733 - 10000 samples (100 per mini-batch)
2024-02-19 19:12:07,975 - Epoch: [282][  100/  100]    Loss 2.049648    Top1 59.910000    Top5 85.510000    
2024-02-19 19:12:08,150 - ==> Top1: 59.910    Top5: 85.510    Loss: 2.050

2024-02-19 19:12:08,161 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:12:08,162 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:12:08,221 - 

2024-02-19 19:12:08,222 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:12:15,636 - Epoch: [283][  100/  500]    Overall Loss 0.160764    Objective Loss 0.160764                                        LR 0.000031    Time 0.074091    
2024-02-19 19:12:22,582 - Epoch: [283][  200/  500]    Overall Loss 0.163497    Objective Loss 0.163497                                        LR 0.000031    Time 0.071758    
2024-02-19 19:12:29,547 - Epoch: [283][  300/  500]    Overall Loss 0.163605    Objective Loss 0.163605                                        LR 0.000031    Time 0.071040    
2024-02-19 19:12:36,503 - Epoch: [283][  400/  500]    Overall Loss 0.162052    Objective Loss 0.162052                                        LR 0.000031    Time 0.070660    
2024-02-19 19:12:43,474 - Epoch: [283][  500/  500]    Overall Loss 0.162652    Objective Loss 0.162652    Top1 99.000000    Top5 100.000000    LR 0.000031    Time 0.070463    
2024-02-19 19:12:43,601 - --- validate (epoch=283)-----------
2024-02-19 19:12:43,602 - 10000 samples (100 per mini-batch)
2024-02-19 19:12:46,393 - Epoch: [283][  100/  100]    Loss 2.038293    Top1 60.050000    Top5 85.720000    
2024-02-19 19:12:46,500 - ==> Top1: 60.050    Top5: 85.720    Loss: 2.038

2024-02-19 19:12:46,507 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:12:46,508 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:12:46,567 - 

2024-02-19 19:12:46,567 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:12:54,127 - Epoch: [284][  100/  500]    Overall Loss 0.156197    Objective Loss 0.156197                                        LR 0.000031    Time 0.075547    
2024-02-19 19:13:01,020 - Epoch: [284][  200/  500]    Overall Loss 0.158380    Objective Loss 0.158380                                        LR 0.000031    Time 0.072222    
2024-02-19 19:13:07,927 - Epoch: [284][  300/  500]    Overall Loss 0.159059    Objective Loss 0.159059                                        LR 0.000031    Time 0.071157    
2024-02-19 19:13:14,823 - Epoch: [284][  400/  500]    Overall Loss 0.159847    Objective Loss 0.159847                                        LR 0.000031    Time 0.070598    
2024-02-19 19:13:21,731 - Epoch: [284][  500/  500]    Overall Loss 0.160657    Objective Loss 0.160657    Top1 99.000000    Top5 100.000000    LR 0.000031    Time 0.070287    
2024-02-19 19:13:21,855 - --- validate (epoch=284)-----------
2024-02-19 19:13:21,855 - 10000 samples (100 per mini-batch)
2024-02-19 19:13:24,737 - Epoch: [284][  100/  100]    Loss 2.048282    Top1 60.140000    Top5 85.610000    
2024-02-19 19:13:24,911 - ==> Top1: 60.140    Top5: 85.610    Loss: 2.048

2024-02-19 19:13:24,922 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:13:24,922 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:13:24,982 - 

2024-02-19 19:13:24,982 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:13:32,428 - Epoch: [285][  100/  500]    Overall Loss 0.161601    Objective Loss 0.161601                                        LR 0.000031    Time 0.074406    
2024-02-19 19:13:39,324 - Epoch: [285][  200/  500]    Overall Loss 0.165969    Objective Loss 0.165969                                        LR 0.000031    Time 0.071664    
2024-02-19 19:13:46,228 - Epoch: [285][  300/  500]    Overall Loss 0.163929    Objective Loss 0.163929                                        LR 0.000031    Time 0.070776    
2024-02-19 19:13:53,080 - Epoch: [285][  400/  500]    Overall Loss 0.163593    Objective Loss 0.163593                                        LR 0.000031    Time 0.070203    
2024-02-19 19:14:00,025 - Epoch: [285][  500/  500]    Overall Loss 0.163501    Objective Loss 0.163501    Top1 94.500000    Top5 100.000000    LR 0.000031    Time 0.070045    
2024-02-19 19:14:00,162 - --- validate (epoch=285)-----------
2024-02-19 19:14:00,163 - 10000 samples (100 per mini-batch)
2024-02-19 19:14:03,043 - Epoch: [285][  100/  100]    Loss 2.055797    Top1 60.190000    Top5 85.590000    
2024-02-19 19:14:03,198 - ==> Top1: 60.190    Top5: 85.590    Loss: 2.056

2024-02-19 19:14:03,211 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:14:03,211 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:14:03,271 - 

2024-02-19 19:14:03,271 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:14:10,967 - Epoch: [286][  100/  500]    Overall Loss 0.155575    Objective Loss 0.155575                                        LR 0.000031    Time 0.076914    
2024-02-19 19:14:17,910 - Epoch: [286][  200/  500]    Overall Loss 0.155897    Objective Loss 0.155897                                        LR 0.000031    Time 0.073153    
2024-02-19 19:14:24,778 - Epoch: [286][  300/  500]    Overall Loss 0.158383    Objective Loss 0.158383                                        LR 0.000031    Time 0.071648    
2024-02-19 19:14:31,653 - Epoch: [286][  400/  500]    Overall Loss 0.158231    Objective Loss 0.158231                                        LR 0.000031    Time 0.070916    
2024-02-19 19:14:38,583 - Epoch: [286][  500/  500]    Overall Loss 0.159949    Objective Loss 0.159949    Top1 95.500000    Top5 100.000000    LR 0.000031    Time 0.070585    
2024-02-19 19:14:38,716 - --- validate (epoch=286)-----------
2024-02-19 19:14:38,717 - 10000 samples (100 per mini-batch)
2024-02-19 19:14:41,584 - Epoch: [286][  100/  100]    Loss 2.054215    Top1 60.030000    Top5 85.470000    
2024-02-19 19:14:41,743 - ==> Top1: 60.030    Top5: 85.470    Loss: 2.054

2024-02-19 19:14:41,754 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:14:41,754 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:14:41,814 - 

2024-02-19 19:14:41,814 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:14:49,182 - Epoch: [287][  100/  500]    Overall Loss 0.159176    Objective Loss 0.159176                                        LR 0.000031    Time 0.073635    
2024-02-19 19:14:56,090 - Epoch: [287][  200/  500]    Overall Loss 0.160366    Objective Loss 0.160366                                        LR 0.000031    Time 0.071337    
2024-02-19 19:15:02,994 - Epoch: [287][  300/  500]    Overall Loss 0.162278    Objective Loss 0.162278                                        LR 0.000031    Time 0.070559    
2024-02-19 19:15:09,962 - Epoch: [287][  400/  500]    Overall Loss 0.163459    Objective Loss 0.163459                                        LR 0.000031    Time 0.070330    
2024-02-19 19:15:16,917 - Epoch: [287][  500/  500]    Overall Loss 0.163071    Objective Loss 0.163071    Top1 96.000000    Top5 100.000000    LR 0.000031    Time 0.070167    
2024-02-19 19:15:17,052 - --- validate (epoch=287)-----------
2024-02-19 19:15:17,053 - 10000 samples (100 per mini-batch)
2024-02-19 19:15:19,948 - Epoch: [287][  100/  100]    Loss 2.051676    Top1 60.060000    Top5 85.650000    
2024-02-19 19:15:20,070 - ==> Top1: 60.060    Top5: 85.650    Loss: 2.052

2024-02-19 19:15:20,081 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:15:20,082 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:15:20,142 - 

2024-02-19 19:15:20,142 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:15:27,782 - Epoch: [288][  100/  500]    Overall Loss 0.158084    Objective Loss 0.158084                                        LR 0.000031    Time 0.076354    
2024-02-19 19:15:34,720 - Epoch: [288][  200/  500]    Overall Loss 0.161081    Objective Loss 0.161081                                        LR 0.000031    Time 0.072847    
2024-02-19 19:15:41,652 - Epoch: [288][  300/  500]    Overall Loss 0.161023    Objective Loss 0.161023                                        LR 0.000031    Time 0.071657    
2024-02-19 19:15:48,622 - Epoch: [288][  400/  500]    Overall Loss 0.161932    Objective Loss 0.161932                                        LR 0.000031    Time 0.071158    
2024-02-19 19:15:55,560 - Epoch: [288][  500/  500]    Overall Loss 0.160807    Objective Loss 0.160807    Top1 94.500000    Top5 100.000000    LR 0.000031    Time 0.070796    
2024-02-19 19:15:55,683 - --- validate (epoch=288)-----------
2024-02-19 19:15:55,684 - 10000 samples (100 per mini-batch)
2024-02-19 19:15:58,476 - Epoch: [288][  100/  100]    Loss 2.045621    Top1 60.100000    Top5 85.550000    
2024-02-19 19:15:58,567 - ==> Top1: 60.100    Top5: 85.550    Loss: 2.046

2024-02-19 19:15:58,573 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:15:58,573 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:15:58,626 - 

2024-02-19 19:15:58,626 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:16:05,831 - Epoch: [289][  100/  500]    Overall Loss 0.151162    Objective Loss 0.151162                                        LR 0.000031    Time 0.072005    
2024-02-19 19:16:12,745 - Epoch: [289][  200/  500]    Overall Loss 0.155381    Objective Loss 0.155381                                        LR 0.000031    Time 0.070551    
2024-02-19 19:16:19,677 - Epoch: [289][  300/  500]    Overall Loss 0.157123    Objective Loss 0.157123                                        LR 0.000031    Time 0.070130    
2024-02-19 19:16:26,633 - Epoch: [289][  400/  500]    Overall Loss 0.159162    Objective Loss 0.159162                                        LR 0.000031    Time 0.069977    
2024-02-19 19:16:33,567 - Epoch: [289][  500/  500]    Overall Loss 0.160110    Objective Loss 0.160110    Top1 97.500000    Top5 100.000000    LR 0.000031    Time 0.069843    
2024-02-19 19:16:33,679 - --- validate (epoch=289)-----------
2024-02-19 19:16:33,680 - 10000 samples (100 per mini-batch)
2024-02-19 19:16:36,603 - Epoch: [289][  100/  100]    Loss 2.049499    Top1 59.950000    Top5 85.580000    
2024-02-19 19:16:36,762 - ==> Top1: 59.950    Top5: 85.580    Loss: 2.049

2024-02-19 19:16:36,774 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:16:36,774 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:16:36,843 - 

2024-02-19 19:16:36,844 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:16:44,425 - Epoch: [290][  100/  500]    Overall Loss 0.164058    Objective Loss 0.164058                                        LR 0.000031    Time 0.075766    
2024-02-19 19:16:51,313 - Epoch: [290][  200/  500]    Overall Loss 0.163689    Objective Loss 0.163689                                        LR 0.000031    Time 0.072305    
2024-02-19 19:16:58,195 - Epoch: [290][  300/  500]    Overall Loss 0.160261    Objective Loss 0.160261                                        LR 0.000031    Time 0.071129    
2024-02-19 19:17:05,097 - Epoch: [290][  400/  500]    Overall Loss 0.161458    Objective Loss 0.161458                                        LR 0.000031    Time 0.070592    
2024-02-19 19:17:12,027 - Epoch: [290][  500/  500]    Overall Loss 0.161557    Objective Loss 0.161557    Top1 95.000000    Top5 100.000000    LR 0.000031    Time 0.070328    
2024-02-19 19:17:12,161 - --- validate (epoch=290)-----------
2024-02-19 19:17:12,161 - 10000 samples (100 per mini-batch)
2024-02-19 19:17:14,952 - Epoch: [290][  100/  100]    Loss 2.050099    Top1 60.020000    Top5 85.580000    
2024-02-19 19:17:15,045 - ==> Top1: 60.020    Top5: 85.580    Loss: 2.050

2024-02-19 19:17:15,052 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:17:15,053 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:17:15,108 - 

2024-02-19 19:17:15,108 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:17:22,484 - Epoch: [291][  100/  500]    Overall Loss 0.159134    Objective Loss 0.159134                                        LR 0.000031    Time 0.073712    
2024-02-19 19:17:29,414 - Epoch: [291][  200/  500]    Overall Loss 0.155413    Objective Loss 0.155413                                        LR 0.000031    Time 0.071484    
2024-02-19 19:17:36,330 - Epoch: [291][  300/  500]    Overall Loss 0.157555    Objective Loss 0.157555                                        LR 0.000031    Time 0.070698    
2024-02-19 19:17:43,246 - Epoch: [291][  400/  500]    Overall Loss 0.158694    Objective Loss 0.158694                                        LR 0.000031    Time 0.070304    
2024-02-19 19:17:50,212 - Epoch: [291][  500/  500]    Overall Loss 0.159586    Objective Loss 0.159586    Top1 96.000000    Top5 100.000000    LR 0.000031    Time 0.070168    
2024-02-19 19:17:50,355 - --- validate (epoch=291)-----------
2024-02-19 19:17:50,356 - 10000 samples (100 per mini-batch)
2024-02-19 19:17:53,209 - Epoch: [291][  100/  100]    Loss 2.053658    Top1 60.250000    Top5 85.810000    
2024-02-19 19:17:53,321 - ==> Top1: 60.250    Top5: 85.810    Loss: 2.054

2024-02-19 19:17:53,332 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:17:53,332 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:17:53,399 - 

2024-02-19 19:17:53,399 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:18:00,735 - Epoch: [292][  100/  500]    Overall Loss 0.156839    Objective Loss 0.156839                                        LR 0.000031    Time 0.073307    
2024-02-19 19:18:07,603 - Epoch: [292][  200/  500]    Overall Loss 0.157500    Objective Loss 0.157500                                        LR 0.000031    Time 0.070977    
2024-02-19 19:18:14,479 - Epoch: [292][  300/  500]    Overall Loss 0.158025    Objective Loss 0.158025                                        LR 0.000031    Time 0.070225    
2024-02-19 19:18:21,367 - Epoch: [292][  400/  500]    Overall Loss 0.158000    Objective Loss 0.158000                                        LR 0.000031    Time 0.069879    
2024-02-19 19:18:28,321 - Epoch: [292][  500/  500]    Overall Loss 0.158443    Objective Loss 0.158443    Top1 96.500000    Top5 100.000000    LR 0.000031    Time 0.069804    
2024-02-19 19:18:28,508 - --- validate (epoch=292)-----------
2024-02-19 19:18:28,509 - 10000 samples (100 per mini-batch)
2024-02-19 19:18:31,361 - Epoch: [292][  100/  100]    Loss 2.049091    Top1 60.020000    Top5 85.590000    
2024-02-19 19:18:31,474 - ==> Top1: 60.020    Top5: 85.590    Loss: 2.049

2024-02-19 19:18:31,683 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:18:31,683 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:18:31,733 - 

2024-02-19 19:18:31,733 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:18:39,075 - Epoch: [293][  100/  500]    Overall Loss 0.148177    Objective Loss 0.148177                                        LR 0.000031    Time 0.073367    
2024-02-19 19:18:45,972 - Epoch: [293][  200/  500]    Overall Loss 0.152381    Objective Loss 0.152381                                        LR 0.000031    Time 0.071148    
2024-02-19 19:18:52,652 - Epoch: [293][  300/  500]    Overall Loss 0.157303    Objective Loss 0.157303                                        LR 0.000031    Time 0.069689    
2024-02-19 19:18:59,253 - Epoch: [293][  400/  500]    Overall Loss 0.158591    Objective Loss 0.158591                                        LR 0.000031    Time 0.068763    
2024-02-19 19:19:05,891 - Epoch: [293][  500/  500]    Overall Loss 0.158960    Objective Loss 0.158960    Top1 98.000000    Top5 100.000000    LR 0.000031    Time 0.068280    
2024-02-19 19:19:06,006 - --- validate (epoch=293)-----------
2024-02-19 19:19:06,007 - 10000 samples (100 per mini-batch)
2024-02-19 19:19:08,807 - Epoch: [293][  100/  100]    Loss 2.044970    Top1 60.100000    Top5 85.640000    
2024-02-19 19:19:08,918 - ==> Top1: 60.100    Top5: 85.640    Loss: 2.045

2024-02-19 19:19:08,930 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:19:08,930 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:19:08,989 - 

2024-02-19 19:19:08,990 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:19:16,384 - Epoch: [294][  100/  500]    Overall Loss 0.160306    Objective Loss 0.160306                                        LR 0.000031    Time 0.073893    
2024-02-19 19:19:23,327 - Epoch: [294][  200/  500]    Overall Loss 0.160363    Objective Loss 0.160363                                        LR 0.000031    Time 0.071646    
2024-02-19 19:19:30,218 - Epoch: [294][  300/  500]    Overall Loss 0.160129    Objective Loss 0.160129                                        LR 0.000031    Time 0.070719    
2024-02-19 19:19:37,132 - Epoch: [294][  400/  500]    Overall Loss 0.160379    Objective Loss 0.160379                                        LR 0.000031    Time 0.070316    
2024-02-19 19:19:44,099 - Epoch: [294][  500/  500]    Overall Loss 0.159181    Objective Loss 0.159181    Top1 96.000000    Top5 99.500000    LR 0.000031    Time 0.070181    
2024-02-19 19:19:44,217 - --- validate (epoch=294)-----------
2024-02-19 19:19:44,218 - 10000 samples (100 per mini-batch)
2024-02-19 19:19:47,317 - Epoch: [294][  100/  100]    Loss 2.048920    Top1 60.020000    Top5 85.640000    
2024-02-19 19:19:47,426 - ==> Top1: 60.020    Top5: 85.640    Loss: 2.049

2024-02-19 19:19:47,437 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:19:47,437 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:19:47,495 - 

2024-02-19 19:19:47,495 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:19:55,200 - Epoch: [295][  100/  500]    Overall Loss 0.160306    Objective Loss 0.160306                                        LR 0.000031    Time 0.076995    
2024-02-19 19:20:02,493 - Epoch: [295][  200/  500]    Overall Loss 0.157873    Objective Loss 0.157873                                        LR 0.000031    Time 0.074943    
2024-02-19 19:20:09,516 - Epoch: [295][  300/  500]    Overall Loss 0.157052    Objective Loss 0.157052                                        LR 0.000031    Time 0.073361    
2024-02-19 19:20:16,477 - Epoch: [295][  400/  500]    Overall Loss 0.157447    Objective Loss 0.157447                                        LR 0.000031    Time 0.072412    
2024-02-19 19:20:23,436 - Epoch: [295][  500/  500]    Overall Loss 0.157514    Objective Loss 0.157514    Top1 97.500000    Top5 100.000000    LR 0.000031    Time 0.071842    
2024-02-19 19:20:23,636 - --- validate (epoch=295)-----------
2024-02-19 19:20:23,636 - 10000 samples (100 per mini-batch)
2024-02-19 19:20:26,586 - Epoch: [295][  100/  100]    Loss 2.047036    Top1 60.180000    Top5 85.680000    
2024-02-19 19:20:26,715 - ==> Top1: 60.180    Top5: 85.680    Loss: 2.047

2024-02-19 19:20:26,728 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:20:26,728 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:20:26,790 - 

2024-02-19 19:20:26,790 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:20:34,429 - Epoch: [296][  100/  500]    Overall Loss 0.164714    Objective Loss 0.164714                                        LR 0.000031    Time 0.076342    
2024-02-19 19:20:41,380 - Epoch: [296][  200/  500]    Overall Loss 0.162491    Objective Loss 0.162491                                        LR 0.000031    Time 0.072906    
2024-02-19 19:20:48,366 - Epoch: [296][  300/  500]    Overall Loss 0.160920    Objective Loss 0.160920                                        LR 0.000031    Time 0.071877    
2024-02-19 19:20:55,320 - Epoch: [296][  400/  500]    Overall Loss 0.159669    Objective Loss 0.159669                                        LR 0.000031    Time 0.071283    
2024-02-19 19:21:02,306 - Epoch: [296][  500/  500]    Overall Loss 0.159697    Objective Loss 0.159697    Top1 96.000000    Top5 99.500000    LR 0.000031    Time 0.070990    
2024-02-19 19:21:02,487 - --- validate (epoch=296)-----------
2024-02-19 19:21:02,487 - 10000 samples (100 per mini-batch)
2024-02-19 19:21:05,618 - Epoch: [296][  100/  100]    Loss 2.048661    Top1 60.120000    Top5 85.700000    
2024-02-19 19:21:05,744 - ==> Top1: 60.120    Top5: 85.700    Loss: 2.049

2024-02-19 19:21:05,756 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:21:05,757 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:21:05,817 - 

2024-02-19 19:21:05,818 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:21:13,180 - Epoch: [297][  100/  500]    Overall Loss 0.156764    Objective Loss 0.156764                                        LR 0.000031    Time 0.073571    
2024-02-19 19:21:20,065 - Epoch: [297][  200/  500]    Overall Loss 0.157907    Objective Loss 0.157907                                        LR 0.000031    Time 0.071193    
2024-02-19 19:21:26,973 - Epoch: [297][  300/  500]    Overall Loss 0.159215    Objective Loss 0.159215                                        LR 0.000031    Time 0.070475    
2024-02-19 19:21:33,871 - Epoch: [297][  400/  500]    Overall Loss 0.157987    Objective Loss 0.157987                                        LR 0.000031    Time 0.070091    
2024-02-19 19:21:40,808 - Epoch: [297][  500/  500]    Overall Loss 0.158392    Objective Loss 0.158392    Top1 95.500000    Top5 100.000000    LR 0.000031    Time 0.069940    
2024-02-19 19:21:40,977 - --- validate (epoch=297)-----------
2024-02-19 19:21:40,978 - 10000 samples (100 per mini-batch)
2024-02-19 19:21:43,901 - Epoch: [297][  100/  100]    Loss 2.051412    Top1 60.020000    Top5 85.740000    
2024-02-19 19:21:43,997 - ==> Top1: 60.020    Top5: 85.740    Loss: 2.051

2024-02-19 19:21:44,003 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:21:44,004 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:21:44,057 - 

2024-02-19 19:21:44,058 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:21:51,582 - Epoch: [298][  100/  500]    Overall Loss 0.151703    Objective Loss 0.151703                                        LR 0.000031    Time 0.075192    
2024-02-19 19:21:58,542 - Epoch: [298][  200/  500]    Overall Loss 0.154300    Objective Loss 0.154300                                        LR 0.000031    Time 0.072376    
2024-02-19 19:22:05,527 - Epoch: [298][  300/  500]    Overall Loss 0.155205    Objective Loss 0.155205                                        LR 0.000031    Time 0.071520    
2024-02-19 19:22:12,509 - Epoch: [298][  400/  500]    Overall Loss 0.154825    Objective Loss 0.154825                                        LR 0.000031    Time 0.071085    
2024-02-19 19:22:19,506 - Epoch: [298][  500/  500]    Overall Loss 0.157098    Objective Loss 0.157098    Top1 96.000000    Top5 100.000000    LR 0.000031    Time 0.070855    
2024-02-19 19:22:19,625 - --- validate (epoch=298)-----------
2024-02-19 19:22:19,626 - 10000 samples (100 per mini-batch)
2024-02-19 19:22:22,720 - Epoch: [298][  100/  100]    Loss 2.047274    Top1 59.810000    Top5 85.620000    
2024-02-19 19:22:22,873 - ==> Top1: 59.810    Top5: 85.620    Loss: 2.047

2024-02-19 19:22:22,884 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:22:22,884 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:22:22,944 - 

2024-02-19 19:22:22,944 - Training epoch: 50000 samples (100 per mini-batch)
2024-02-19 19:22:30,369 - Epoch: [299][  100/  500]    Overall Loss 0.159036    Objective Loss 0.159036                                        LR 0.000031    Time 0.074199    
2024-02-19 19:22:37,312 - Epoch: [299][  200/  500]    Overall Loss 0.159513    Objective Loss 0.159513                                        LR 0.000031    Time 0.071796    
2024-02-19 19:22:44,242 - Epoch: [299][  300/  500]    Overall Loss 0.157892    Objective Loss 0.157892                                        LR 0.000031    Time 0.070951    
2024-02-19 19:22:51,183 - Epoch: [299][  400/  500]    Overall Loss 0.160368    Objective Loss 0.160368                                        LR 0.000031    Time 0.070556    
2024-02-19 19:22:58,129 - Epoch: [299][  500/  500]    Overall Loss 0.159917    Objective Loss 0.159917    Top1 94.000000    Top5 100.000000    LR 0.000031    Time 0.070330    
2024-02-19 19:22:58,246 - --- validate (epoch=299)-----------
2024-02-19 19:22:58,247 - 10000 samples (100 per mini-batch)
2024-02-19 19:23:01,205 - Epoch: [299][  100/  100]    Loss 2.043493    Top1 59.770000    Top5 85.580000    
2024-02-19 19:23:01,312 - ==> Top1: 59.770    Top5: 85.580    Loss: 2.043

2024-02-19 19:23:01,324 - ==> Best [Top1: 60.580   Top5: 85.860   Sparsity:0.00   Params: 753952 on epoch: 151]
2024-02-19 19:23:01,324 - Saving checkpoint to: logs/2024.02.19-161005/checkpoint.pth.tar
2024-02-19 19:23:01,385 - --- test ---------------------
2024-02-19 19:23:01,385 - 10000 samples (100 per mini-batch)
2024-02-19 19:23:04,459 - Test: [  100/  100]    Loss 2.043493    Top1 59.770000    Top5 85.580000    
2024-02-19 19:23:04,588 - ==> Top1: 59.770    Top5: 85.580    Loss: 2.043

2024-02-19 19:23:04,598 - 
2024-02-19 19:23:04,599 - Log file for this run: /home/taesik/git/ai8x-training/logs/2024.02.19-161005/2024.02.19-161005.log
